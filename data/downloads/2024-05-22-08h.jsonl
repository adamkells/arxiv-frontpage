{"created":"2024-05-21 17:32:04","title":"Soft Synergies: Model Order Reduction of Hybrid Soft-Rigid Robots via Optimal Strain Parameterization","abstract":"Soft robots offer remarkable adaptability and safety advantages over rigid robots, but modeling their complex, nonlinear dynamics remains challenging. Strain-based models have recently emerged as a promising candidate to describe such systems, however, they tend to be high-dimensional and time consuming. This paper presents a novel model order reduction approach for soft and hybrid robots by combining strain-based modeling with Proper Orthogonal Decomposition (POD). The method identifies optimal coupled strain basis functions -or mechanical synergies- from simulation data, enabling the description of soft robot configurations with a minimal number of generalized coordinates. The reduced order model (ROM) achieves substantial dimensionality reduction while preserving accuracy. Rigorous testing demonstrates the interpolation and extrapolation capabilities of the ROM for soft manipulators under static and dynamic conditions. The approach is further validated on a snake-like hyper-redundant rigid manipulator and a closed-chain system with soft and rigid components, illustrating its broad applicability. Finally, the approach is leveraged for shape estimation of a real six-actuator soft manipulator using only two position markers, showcasing its practical utility. This POD-based ROM offers significant computational speed-ups, paving the way for real-time simulation and control of complex soft and hybrid robots.","sentences":["Soft robots offer remarkable adaptability and safety advantages over rigid robots, but modeling their complex, nonlinear dynamics remains challenging.","Strain-based models have recently emerged as a promising candidate to describe such systems, however, they tend to be high-dimensional and time consuming.","This paper presents a novel model order reduction approach for soft and hybrid robots by combining strain-based modeling with Proper Orthogonal Decomposition (POD).","The method identifies optimal coupled strain basis functions -or mechanical synergies- from simulation data, enabling the description of soft robot configurations with a minimal number of generalized coordinates.","The reduced order model (ROM) achieves substantial dimensionality reduction while preserving accuracy.","Rigorous testing demonstrates the interpolation and extrapolation capabilities of the ROM for soft manipulators under static and dynamic conditions.","The approach is further validated on a snake-like hyper-redundant rigid manipulator and a closed-chain system with soft and rigid components, illustrating its broad applicability.","Finally, the approach is leveraged for shape estimation of a real six-actuator soft manipulator using only two position markers, showcasing its practical utility.","This POD-based ROM offers significant computational speed-ups, paving the way for real-time simulation and control of complex soft and hybrid robots."],"url":"http://arxiv.org/abs/2405.12959v1"}
{"created":"2024-05-21 17:31:10","title":"Online Learning of Halfspaces with Massart Noise","abstract":"We study the task of online learning in the presence of Massart noise. Instead of assuming that the online adversary chooses an arbitrary sequence of labels, we assume that the context $\\mathbf{x}$ is selected adversarially but the label $y$ presented to the learner disagrees with the ground-truth label of $\\mathbf{x}$ with unknown probability at most $\\eta$. We study the fundamental class of $\\gamma$-margin linear classifiers and present a computationally efficient algorithm that achieves mistake bound $\\eta T + o(T)$. Our mistake bound is qualitatively tight for efficient algorithms: it is known that even in the offline setting achieving classification error better than $\\eta$ requires super-polynomial time in the SQ model.   We extend our online learning model to a $k$-arm contextual bandit setting where the rewards -- instead of satisfying commonly used realizability assumptions -- are consistent (in expectation) with some linear ranking function with weight vector $\\mathbf{w}^\\ast$. Given a list of contexts $\\mathbf{x}_1,\\ldots \\mathbf{x}_k$, if $\\mathbf{w}^*\\cdot \\mathbf{x}_i > \\mathbf{w}^* \\cdot \\mathbf{x}_j$, the expected reward of action $i$ must be larger than that of $j$ by at least $\\Delta$. We use our Massart online learner to design an efficient bandit algorithm that obtains expected reward at least $(1-1/k)~ \\Delta T - o(T)$ bigger than choosing a random action at every round.","sentences":["We study the task of online learning in the presence of Massart noise.","Instead of assuming that the online adversary chooses an arbitrary sequence of labels, we assume that the context $\\mathbf{x}$ is selected adversarially but the label $y$ presented to the learner disagrees with the ground-truth label of $\\mathbf{x}$ with unknown probability at most $\\eta$. We study the fundamental class of $\\gamma$-margin linear classifiers and present a computationally efficient algorithm that achieves mistake bound $\\eta T + o(T)$. Our mistake bound is qualitatively tight for efficient algorithms: it is known that even in the offline setting achieving classification error better than $\\eta$ requires super-polynomial time in the SQ model.   ","We extend our online learning model to a $k$-arm contextual bandit setting where the rewards -- instead of satisfying commonly used realizability assumptions -- are consistent (in expectation) with some linear ranking function with weight vector $\\mathbf{w}^\\ast$. Given a list of contexts $\\mathbf{x}_1,\\ldots \\mathbf{x}_k$, if $\\mathbf{w}^*\\cdot \\mathbf{x}_i > \\mathbf{w}^*","\\cdot \\mathbf{x}_j$, the expected reward of action $i$ must be larger than that of $j$ by at least $\\Delta$. We use our Massart online learner to design an efficient bandit algorithm that obtains expected reward at least $(1-1/k)~ \\Delta T - o(T)$ bigger than choosing a random action at every round."],"url":"http://arxiv.org/abs/2405.12958v1"}
{"created":"2024-05-21 17:28:06","title":"Truncated Variance Reduced Value Iteration","abstract":"We provide faster randomized algorithms for computing an $\\epsilon$-optimal policy in a discounted Markov decision process with $A_{\\text{tot}}$-state-action pairs, bounded rewards, and discount factor $\\gamma$. We provide an $\\tilde{O}(A_{\\text{tot}}[(1 - \\gamma)^{-3}\\epsilon^{-2} + (1 - \\gamma)^{-2}])$-time algorithm in the sampling setting, where the probability transition matrix is unknown but accessible through a generative model which can be queried in $\\tilde{O}(1)$-time, and an $\\tilde{O}(s + (1-\\gamma)^{-2})$-time algorithm in the offline setting where the probability transition matrix is known and $s$-sparse. These results improve upon the prior state-of-the-art which either ran in $\\tilde{O}(A_{\\text{tot}}[(1 - \\gamma)^{-3}\\epsilon^{-2} + (1 - \\gamma)^{-3}])$ time [Sidford, Wang, Wu, Ye 2018] in the sampling setting, $\\tilde{O}(s + A_{\\text{tot}} (1-\\gamma)^{-3})$ time [Sidford, Wang, Wu, Yang, Ye 2018] in the offline setting, or time at least quadratic in the number of states using interior point methods for linear programming. We achieve our results by building upon prior stochastic variance-reduced value iteration methods [Sidford, Wang, Wu, Yang, Ye 2018]. We provide a variant that carefully truncates the progress of its iterates to improve the variance of new variance-reduced sampling procedures that we introduce to implement the steps. Our method is essentially model-free and can be implemented in $\\tilde{O}(A_{\\text{tot}})$-space when given generative model access. Consequently, our results take a step in closing the sample-complexity gap between model-free and model-based methods.","sentences":["We provide faster randomized algorithms for computing an $\\epsilon$-optimal policy in a discounted Markov decision process with $A_{\\text{tot}}$-state-action pairs, bounded rewards, and discount factor $\\gamma$.","We provide an $\\tilde{O}(A_{\\text{tot}}[(1 - \\gamma)^{-3}\\epsilon^{-2} + (1 - \\gamma)^{-2}])$-time algorithm in the sampling setting, where the probability transition matrix is unknown but accessible through a generative model which can be queried in $\\tilde{O}(1)$-time, and an $\\tilde{O}(s + (1-\\gamma)^{-2})$-time algorithm in the offline setting where the probability transition matrix is known and $s$-sparse.","These results improve upon the prior state-of-the-art which either ran in $\\tilde{O}(A_{\\text{tot}}[(1 - \\gamma)^{-3}\\epsilon^{-2} + (1 - \\gamma)^{-3}])$ time","[Sidford, Wang, Wu, Ye 2018] in the sampling setting, $\\tilde{O}(s + A_{\\text{tot}} (1-\\gamma)^{-3})$ time [Sidford, Wang, Wu, Yang, Ye 2018] in the offline setting, or time at least quadratic in the number of states using interior point methods for linear programming.","We achieve our results by building upon prior stochastic variance-reduced value iteration methods [Sidford, Wang, Wu, Yang, Ye 2018].","We provide a variant that carefully truncates the progress of its iterates to improve the variance of new variance-reduced sampling procedures that we introduce to implement the steps.","Our method is essentially model-free and can be implemented in $\\tilde{O}(A_{\\text{tot}})$-space when given generative model access.","Consequently, our results take a step in closing the sample-complexity gap between model-free and model-based methods."],"url":"http://arxiv.org/abs/2405.12952v1"}
{"created":"2024-05-21 17:17:34","title":"Tutorly: Turning Programming Videos Into Apprenticeship Learning Environments with LLMs","abstract":"Online programming videos, including tutorials and streamcasts, are widely popular and contain a wealth of expert knowledge. However, effectively utilizing these resources to achieve targeted learning goals can be challenging. Unlike direct tutoring, video content lacks tailored guidance based on individual learning paces, personalized feedback, and interactive engagement necessary for support and monitoring. Our work transforms programming videos into one-on-one tutoring experiences using the cognitive apprenticeship framework. Tutorly, developed as a JupyterLab Plugin, allows learners to (1) set personalized learning goals, (2) engage in learning-by-doing through a conversational LLM-based mentor agent, (3) receive guidance and feedback based on a student model that steers the mentor moves. In a within-subject study with 16 participants learning exploratory data analysis from a streamcast, Tutorly significantly improved their performance from 61.9% to 76.6% based on a post-test questionnaire. Tutorly demonstrates the potential for enhancing programming video learning experiences with LLM and learner modeling.","sentences":["Online programming videos, including tutorials and streamcasts, are widely popular and contain a wealth of expert knowledge.","However, effectively utilizing these resources to achieve targeted learning goals can be challenging.","Unlike direct tutoring, video content lacks tailored guidance based on individual learning paces, personalized feedback, and interactive engagement necessary for support and monitoring.","Our work transforms programming videos into one-on-one tutoring experiences using the cognitive apprenticeship framework.","Tutorly, developed as a JupyterLab Plugin, allows learners to (1) set personalized learning goals, (2) engage in learning-by-doing through a conversational LLM-based mentor agent, (3) receive guidance and feedback based on a student model that steers the mentor moves.","In a within-subject study with 16 participants learning exploratory data analysis from a streamcast, Tutorly significantly improved their performance from 61.9% to 76.6% based on a post-test questionnaire.","Tutorly demonstrates the potential for enhancing programming video learning experiences with LLM and learner modeling."],"url":"http://arxiv.org/abs/2405.12946v1"}
{"created":"2024-05-21 17:17:17","title":"AMFD: Distillation via Adaptive Multimodal Fusion for Multispectral Pedestrian Detection","abstract":"Multispectral pedestrian detection has been shown to be effective in improving performance within complex illumination scenarios. However, prevalent double-stream networks in multispectral detection employ two separate feature extraction branches for multi-modal data, leading to nearly double the inference time compared to single-stream networks utilizing only one feature extraction branch. This increased inference time has hindered the widespread employment of multispectral pedestrian detection in embedded devices for autonomous systems. To address this limitation, various knowledge distillation methods have been proposed. However, traditional distillation methods focus only on the fusion features and ignore the large amount of information in the original multi-modal features, thereby restricting the student network's performance. To tackle the challenge, we introduce the Adaptive Modal Fusion Distillation (AMFD) framework, which can fully utilize the original modal features of the teacher network. Specifically, a Modal Extraction Alignment (MEA) module is utilized to derive learning weights for student networks, integrating focal and global attention mechanisms. This methodology enables the student network to acquire optimal fusion strategies independent from that of teacher network without necessitating an additional feature fusion module. Furthermore, we present the SMOD dataset, a well-aligned challenging multispectral dataset for detection. Extensive experiments on the challenging KAIST, LLVIP and SMOD datasets are conducted to validate the effectiveness of AMFD. The results demonstrate that our method outperforms existing state-of-the-art methods in both reducing log-average Miss Rate and improving mean Average Precision. The code is available at https://github.com/bigD233/AMFD.git.","sentences":["Multispectral pedestrian detection has been shown to be effective in improving performance within complex illumination scenarios.","However, prevalent double-stream networks in multispectral detection employ two separate feature extraction branches for multi-modal data, leading to nearly double the inference time compared to single-stream networks utilizing only one feature extraction branch.","This increased inference time has hindered the widespread employment of multispectral pedestrian detection in embedded devices for autonomous systems.","To address this limitation, various knowledge distillation methods have been proposed.","However, traditional distillation methods focus only on the fusion features and ignore the large amount of information in the original multi-modal features, thereby restricting the student network's performance.","To tackle the challenge, we introduce the Adaptive Modal Fusion Distillation (AMFD) framework, which can fully utilize the original modal features of the teacher network.","Specifically, a Modal Extraction Alignment (MEA) module is utilized to derive learning weights for student networks, integrating focal and global attention mechanisms.","This methodology enables the student network to acquire optimal fusion strategies independent from that of teacher network without necessitating an additional feature fusion module.","Furthermore, we present the SMOD dataset, a well-aligned challenging multispectral dataset for detection.","Extensive experiments on the challenging KAIST, LLVIP and SMOD datasets are conducted to validate the effectiveness of AMFD.","The results demonstrate that our method outperforms existing state-of-the-art methods in both reducing log-average Miss Rate and improving mean Average Precision.","The code is available at https://github.com/bigD233/AMFD.git."],"url":"http://arxiv.org/abs/2405.12944v1"}
{"created":"2024-05-21 17:05:02","title":"Address-Specific Sustainable Accommodation Choice Through Real-World Data Integration","abstract":"Consumers wish to choose sustainable accommodation for their travels, and in the case of corporations, may be required to do so. Yet accommodation marketplaces provide no meaningful capability for sustainable choice: typically CO2 estimates are provided that are identical for all accommodation of the same type across an entire country. We propose a decision support system that enables real choice of sustainable accommodation. We develop a data-driven address- specific metric called EcoGrade, which integrates government approved datasets and uses interpolation where data is sparse. We validate the metric on 10,000 UK addresses in 10 cities, showing the match of our interpolations to reality is statistically significant. We show how the metric has been embedded into a decision support system for a global accommodation marketplace and tested by real users over several months with positive user feedback. In the EU, forty percent of final energy consumption is from buildings. We need to encourage all building owners to make their accommodation more efficient. The rental sector is one area where change can occur rapidly, as rented accommodation is renovated frequently. We anticipate our decision support system using EcoGrade will encourage this positive change.","sentences":["Consumers wish to choose sustainable accommodation for their travels, and in the case of corporations, may be required to do so.","Yet accommodation marketplaces provide no meaningful capability for sustainable choice: typically CO2 estimates are provided that are identical for all accommodation of the same type across an entire country.","We propose a decision support system that enables real choice of sustainable accommodation.","We develop a data-driven address- specific metric called EcoGrade, which integrates government approved datasets and uses interpolation where data is sparse.","We validate the metric on 10,000 UK addresses in 10 cities, showing the match of our interpolations to reality is statistically significant.","We show how the metric has been embedded into a decision support system for a global accommodation marketplace and tested by real users over several months with positive user feedback.","In the EU, forty percent of final energy consumption is from buildings.","We need to encourage all building owners to make their accommodation more efficient.","The rental sector is one area where change can occur rapidly, as rented accommodation is renovated frequently.","We anticipate our decision support system using EcoGrade will encourage this positive change."],"url":"http://arxiv.org/abs/2405.12934v1"}
{"created":"2024-05-21 16:59:21","title":"Enabling Additive Manufacturing Part Inspection of Digital Twins via Collaborative Virtual Reality","abstract":"Digital twins (DTs) are an emerging capability in additive manufacturing (AM), set to revolutionize design optimization, inspection, in situ monitoring, and root cause analysis. AM DTs typically incorporate multimodal data streams, ranging from machine toolpaths and in-process imaging to X-ray CT scans and performance metrics. Despite the evolution of DT platforms, challenges remain in effectively inspecting them for actionable insights, either individually or in a multidisciplinary team setting. Quality assurance, manufacturing departments, pilot labs, and plant operations must collaborate closely to reliably produce parts at scale. This is particularly crucial in AM where complex structures require a collaborative and multidisciplinary approach. Additionally, the large-scale data originating from different modalities and their inherent 3D nature pose significant hurdles for traditional 2D desktop-based inspection methods. To address these challenges and increase the value proposition of DTs, we introduce a novel virtual reality (VR) framework to facilitate collaborative and real-time inspection of DTs in AM. This framework includes advanced features for intuitive alignment and visualization of multimodal data, visual occlusion management, streaming large-scale volumetric data, and collaborative tools, substantially improving the inspection of AM components and processes to fully exploit the potential of DTs in AM.","sentences":["Digital twins (DTs) are an emerging capability in additive manufacturing (AM), set to revolutionize design optimization, inspection, in situ monitoring, and root cause analysis.","AM DTs typically incorporate multimodal data streams, ranging from machine toolpaths and in-process imaging to X-ray CT scans and performance metrics.","Despite the evolution of DT platforms, challenges remain in effectively inspecting them for actionable insights, either individually or in a multidisciplinary team setting.","Quality assurance, manufacturing departments, pilot labs, and plant operations must collaborate closely to reliably produce parts at scale.","This is particularly crucial in AM where complex structures require a collaborative and multidisciplinary approach.","Additionally, the large-scale data originating from different modalities and their inherent 3D nature pose significant hurdles for traditional 2D desktop-based inspection methods.","To address these challenges and increase the value proposition of DTs, we introduce a novel virtual reality (VR) framework to facilitate collaborative and real-time inspection of DTs in AM.","This framework includes advanced features for intuitive alignment and visualization of multimodal data, visual occlusion management, streaming large-scale volumetric data, and collaborative tools, substantially improving the inspection of AM components and processes to fully exploit the potential of DTs in AM."],"url":"http://arxiv.org/abs/2405.12931v1"}
{"created":"2024-05-21 16:58:35","title":"Pytorch-Wildlife: A Collaborative Deep Learning Framework for Conservation","abstract":"The alarming decline in global biodiversity, driven by various factors, underscores the urgent need for large-scale wildlife monitoring. In response, scientists have turned to automated deep learning methods for data processing in wildlife monitoring. However, applying these advanced methods in real-world scenarios is challenging due to their complexity and the need for specialized knowledge, primarily because of technical challenges and interdisciplinary barriers.   To address these challenges, we introduce Pytorch-Wildlife, an open-source deep learning platform built on PyTorch. It is designed for creating, modifying, and sharing powerful AI models. This platform emphasizes usability and accessibility, making it accessible to individuals with limited or no technical background. It also offers a modular codebase to simplify feature expansion and further development. Pytorch-Wildlife offers an intuitive, user-friendly interface, accessible through local installation or Hugging Face, for animal detection and classification in images and videos. As two real-world applications, Pytorch-Wildlife has been utilized to train animal classification models for species recognition in the Amazon Rainforest and for invasive opossum recognition in the Galapagos Islands. The Opossum model achieves 98% accuracy, and the Amazon model has 92% recognition accuracy for 36 animals in 90% of the data. As Pytorch-Wildlife evolves, we aim to integrate more conservation tasks, addressing various environmental challenges. Pytorch-Wildlife is available at https://github.com/microsoft/CameraTraps.","sentences":["The alarming decline in global biodiversity, driven by various factors, underscores the urgent need for large-scale wildlife monitoring.","In response, scientists have turned to automated deep learning methods for data processing in wildlife monitoring.","However, applying these advanced methods in real-world scenarios is challenging due to their complexity and the need for specialized knowledge, primarily because of technical challenges and interdisciplinary barriers.   ","To address these challenges, we introduce Pytorch-Wildlife, an open-source deep learning platform built on PyTorch.","It is designed for creating, modifying, and sharing powerful AI models.","This platform emphasizes usability and accessibility, making it accessible to individuals with limited or no technical background.","It also offers a modular codebase to simplify feature expansion and further development.","Pytorch-Wildlife offers an intuitive, user-friendly interface, accessible through local installation or Hugging Face, for animal detection and classification in images and videos.","As two real-world applications, Pytorch-Wildlife has been utilized to train animal classification models for species recognition in the Amazon Rainforest and for invasive opossum recognition in the Galapagos Islands.","The Opossum model achieves 98% accuracy, and the Amazon model has 92% recognition accuracy for 36 animals in 90% of the data.","As Pytorch-Wildlife evolves, we aim to integrate more conservation tasks, addressing various environmental challenges.","Pytorch-Wildlife is available at https://github.com/microsoft/CameraTraps."],"url":"http://arxiv.org/abs/2405.12930v1"}
{"created":"2024-05-21 16:56:36","title":"Code-mixed Sentiment and Hate-speech Prediction","abstract":"Code-mixed discourse combines multiple languages in a single text. It is commonly used in informal discourse in countries with several official languages, but also in many other countries in combination with English or neighboring languages. As recently large language models have dominated most natural language processing tasks, we investigated their performance in code-mixed settings for relevant tasks. We first created four new bilingual pre-trained masked language models for English-Hindi and English-Slovene languages, specifically aimed to support informal language. Then we performed an evaluation of monolingual, bilingual, few-lingual, and massively multilingual models on several languages, using two tasks that frequently contain code-mixed text, in particular, sentiment analysis and offensive language detection in social media texts. The results show that the most successful classifiers are fine-tuned bilingual models and multilingual models, specialized for social media texts, followed by non-specialized massively multilingual and monolingual models, while huge generative models are not competitive. For our affective problems, the models mostly perform slightly better on code-mixed data compared to non-code-mixed data.","sentences":["Code-mixed discourse combines multiple languages in a single text.","It is commonly used in informal discourse in countries with several official languages, but also in many other countries in combination with English or neighboring languages.","As recently large language models have dominated most natural language processing tasks, we investigated their performance in code-mixed settings for relevant tasks.","We first created four new bilingual pre-trained masked language models for English-Hindi and English-Slovene languages, specifically aimed to support informal language.","Then we performed an evaluation of monolingual, bilingual, few-lingual, and massively multilingual models on several languages, using two tasks that frequently contain code-mixed text, in particular, sentiment analysis and offensive language detection in social media texts.","The results show that the most successful classifiers are fine-tuned bilingual models and multilingual models, specialized for social media texts, followed by non-specialized massively multilingual and monolingual models, while huge generative models are not competitive.","For our affective problems, the models mostly perform slightly better on code-mixed data compared to non-code-mixed data."],"url":"http://arxiv.org/abs/2405.12929v1"}
{"created":"2024-05-21 16:51:28","title":"Trusting Fair Data: Leveraging Quality in Fairness-Driven Data Removal Techniques","abstract":"In this paper, we deal with bias mitigation techniques that remove specific data points from the training set to aim for a fair representation of the population in that set. Machine learning models are trained on these pre-processed datasets, and their predictions are expected to be fair. However, such approaches may exclude relevant data, making the attained subsets less trustworthy for further usage. To enhance the trustworthiness of prior methods, we propose additional requirements and objectives that the subsets must fulfill in addition to fairness: (1) group coverage, and (2) minimal data loss. While removing entire groups may improve the measured fairness, this practice is very problematic as failing to represent every group cannot be considered fair. In our second concern, we advocate for the retention of data while minimizing discrimination. By introducing a multi-objective optimization problem that considers fairness and data loss, we propose a methodology to find Pareto-optimal solutions that balance these objectives. By identifying such solutions, users can make informed decisions about the trade-off between fairness and data quality and select the most suitable subset for their application.","sentences":["In this paper, we deal with bias mitigation techniques that remove specific data points from the training set to aim for a fair representation of the population in that set.","Machine learning models are trained on these pre-processed datasets, and their predictions are expected to be fair.","However, such approaches may exclude relevant data, making the attained subsets less trustworthy for further usage.","To enhance the trustworthiness of prior methods, we propose additional requirements and objectives that the subsets must fulfill in addition to fairness: (1) group coverage, and (2) minimal data loss.","While removing entire groups may improve the measured fairness, this practice is very problematic as failing to represent every group cannot be considered fair.","In our second concern, we advocate for the retention of data while minimizing discrimination.","By introducing a multi-objective optimization problem that considers fairness and data loss, we propose a methodology to find Pareto-optimal solutions that balance these objectives.","By identifying such solutions, users can make informed decisions about the trade-off between fairness and data quality and select the most suitable subset for their application."],"url":"http://arxiv.org/abs/2405.12926v1"}
{"created":"2024-05-21 16:42:02","title":"Streamlining Software Reviews: Efficient Predictive Modeling with Minimal Examples","abstract":"This paper proposes a new challenge problem for software analytics. In the process we shall call \"software review\", a panel of SMEs (subject matter experts) review examples of software behavior to recommend how to improve that's software's operation. SME time is usually extremely limited so, ideally, this panel can complete this optimization task after looking at just a small number of very informative, examples.   To support this review process, we explore methods that train a predictive model to guess if some oracle will like/dislike the next example. Such a predictive model can work with the SMEs to guide them in their exploration of all the examples. Also, after the panelists leave, that model can be used as an oracle in place of the panel (to handle new examples, while the panelists are busy, elsewhere).   In 31 case studies (ranging from from high-level decisions about software processes to low-level decisions about how to configure video encoding software), we show that such predictive models can be built using as few as 12 to 30 labels. To the best of our knowledge, this paper's success with only a handful of examples (and no large language model) is unprecedented.   In accordance with the principles of open science, we offer all our code and data at https://github.com/timm/ez/tree/Stable-EMSE-paper so that others can repeat/refute/improve these results.","sentences":["This paper proposes a new challenge problem for software analytics.","In the process we shall call \"software review\", a panel of SMEs (subject matter experts) review examples of software behavior to recommend how to improve that's software's operation.","SME time is usually extremely limited so, ideally, this panel can complete this optimization task after looking at just a small number of very informative, examples.   ","To support this review process, we explore methods that train a predictive model to guess if some oracle will like/dislike the next example.","Such a predictive model can work with the SMEs to guide them in their exploration of all the examples.","Also, after the panelists leave, that model can be used as an oracle in place of the panel (to handle new examples, while the panelists are busy, elsewhere).   ","In 31 case studies (ranging from from high-level decisions about software processes to low-level decisions about how to configure video encoding software), we show that such predictive models can be built using as few as 12 to 30 labels.","To the best of our knowledge, this paper's success with only a handful of examples (and no large language model) is unprecedented.   ","In accordance with the principles of open science, we offer all our code and data at https://github.com/timm/ez/tree/Stable-EMSE-paper so that others can repeat/refute/improve these results."],"url":"http://arxiv.org/abs/2405.12920v1"}
{"created":"2024-05-21 16:38:13","title":"G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation","abstract":"Large Language Models (LLMs) have demonstrated remarkable abilities in general scenarios. Instruction finetuning empowers them to align with humans in various tasks. Nevertheless, the Diversity and Quality of the instruction data remain two main challenges for instruction finetuning. With regard to this, in this paper, we propose a novel gradient-based method to automatically select high-quality and diverse instruction finetuning data for machine translation. Our key innovation centers around analyzing how individual training examples influence the model during training. Specifically, we select training examples that exert beneficial influences on the model as high-quality ones by means of Influence Function plus a small high-quality seed dataset. Moreover, to enhance the diversity of the training data we maximize the variety of influences they have on the model by clustering on their gradients and resampling. Extensive experiments on WMT22 and FLORES translation tasks demonstrate the superiority of our methods, and in-depth analysis further validates their effectiveness and generalization.","sentences":["Large Language Models (LLMs) have demonstrated remarkable abilities in general scenarios.","Instruction finetuning empowers them to align with humans in various tasks.","Nevertheless, the Diversity and Quality of the instruction data remain two main challenges for instruction finetuning.","With regard to this, in this paper, we propose a novel gradient-based method to automatically select high-quality and diverse instruction finetuning data for machine translation.","Our key innovation centers around analyzing how individual training examples influence the model during training.","Specifically, we select training examples that exert beneficial influences on the model as high-quality ones by means of Influence Function plus a small high-quality seed dataset.","Moreover, to enhance the diversity of the training data we maximize the variety of influences they have on the model by clustering on their gradients and resampling.","Extensive experiments on WMT22 and FLORES translation tasks demonstrate the superiority of our methods, and in-depth analysis further validates their effectiveness and generalization."],"url":"http://arxiv.org/abs/2405.12915v1"}
{"created":"2024-05-21 16:35:02","title":"An Empirical Study and Analysis of Text-to-Image Generation Using Large Language Model-Powered Textual Representation","abstract":"One critical prerequisite for faithful text-to-image generation is the accurate understanding of text inputs. Existing methods leverage the text encoder of the CLIP model to represent input prompts. However, the pre-trained CLIP model can merely encode English with a maximum token length of 77. Moreover, the model capacity of the text encoder from CLIP is relatively limited compared to Large Language Models (LLMs), which offer multilingual input, accommodate longer context, and achieve superior text representation. In this paper, we investigate LLMs as the text encoder to improve the language understanding in text-to-image generation. Unfortunately, training text-to-image generative model with LLMs from scratch demands significant computational resources and data. To this end, we introduce a three-stage training pipeline that effectively and efficiently integrates the existing text-to-image model with LLMs. Specifically, we propose a lightweight adapter that enables fast training of the text-to-image model using the textual representations from LLMs. Extensive experiments demonstrate that our model supports not only multilingual but also longer input context with superior image generation quality.","sentences":["One critical prerequisite for faithful text-to-image generation is the accurate understanding of text inputs.","Existing methods leverage the text encoder of the CLIP model to represent input prompts.","However, the pre-trained CLIP model can merely encode English with a maximum token length of 77.","Moreover, the model capacity of the text encoder from CLIP is relatively limited compared to Large Language Models (LLMs), which offer multilingual input, accommodate longer context, and achieve superior text representation.","In this paper, we investigate LLMs as the text encoder to improve the language understanding in text-to-image generation.","Unfortunately, training text-to-image generative model with LLMs from scratch demands significant computational resources and data.","To this end, we introduce a three-stage training pipeline that effectively and efficiently integrates the existing text-to-image model with LLMs.","Specifically, we propose a lightweight adapter that enables fast training of the text-to-image model using the textual representations from LLMs.","Extensive experiments demonstrate that our model supports not only multilingual but also longer input context with superior image generation quality."],"url":"http://arxiv.org/abs/2405.12914v1"}
{"created":"2024-05-21 16:22:06","title":"Exponential Steepest Ascent from Valued Constraint Graphs of Pathwidth Four","abstract":"We examine the complexity of maximising fitness via local search on valued constraint satisfaction problems (VCSPs). We consider two kinds of local ascents: (1) steepest ascents, where each step changes the domain that produces a maximal increase in fitness; and (2) $\\prec$-ordered ascents, where -- of the domains with available fitness increasing changes -- each step changes the $\\prec$-minimal domain. We provide a general padding argument to simulate any ordered ascent by a steepest ascent. We construct a VCSP that is a path of binary constraints between alternating 2-state and 3-state domains with exponentially long ordered ascents. We apply our padding argument to this VCSP to obtain a Boolean VCSP that has a constraint (hyper)graph of arity 5 and pathwidth 4 with exponential steepest ascents. This is an improvement on the previous best known construction for long steepest ascents, which had arity 8 and pathwidth 7.","sentences":["We examine the complexity of maximising fitness via local search on valued constraint satisfaction problems (VCSPs).","We consider two kinds of local ascents: (1) steepest ascents, where each step changes the domain that produces a maximal increase in fitness; and (2) $\\prec$-ordered ascents, where -- of the domains with available fitness increasing changes -- each step changes the $\\prec$-minimal domain.","We provide a general padding argument to simulate any ordered ascent by a steepest ascent.","We construct a VCSP that is a path of binary constraints between alternating 2-state and 3-state domains with exponentially long ordered ascents.","We apply our padding argument to this VCSP to obtain a Boolean VCSP that has a constraint (hyper)graph of arity 5 and pathwidth 4 with exponential steepest ascents.","This is an improvement on the previous best known construction for long steepest ascents, which had arity 8 and pathwidth 7."],"url":"http://arxiv.org/abs/2405.12906v1"}
{"created":"2024-05-21 16:14:55","title":"Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents","abstract":"Recent advancements in open-domain dialogue systems have been propelled by the emergence of high-quality large language models (LLMs) and various effective training methodologies. Nevertheless, the presence of toxicity within these models presents a significant challenge that can potentially diminish the user experience. In this study, we introduce an innovative training algorithm, an improvement upon direct preference optimization (DPO), called adversarial DPO (ADPO). The ADPO algorithm is designed to train models to assign higher probability distributions to preferred responses and lower distributions to unsafe responses, which are self-generated using the toxic control token. We demonstrate that ADPO enhances the model's resilience against harmful conversations while minimizing performance degradation. Furthermore, we illustrate that ADPO offers a more stable training procedure compared to the traditional DPO. To the best of our knowledge, this is the first adaptation of the DPO algorithm that directly incorporates harmful data into the generative model, thereby reducing the need to artificially create safe dialogue data.","sentences":["Recent advancements in open-domain dialogue systems have been propelled by the emergence of high-quality large language models (LLMs) and various effective training methodologies.","Nevertheless, the presence of toxicity within these models presents a significant challenge that can potentially diminish the user experience.","In this study, we introduce an innovative training algorithm, an improvement upon direct preference optimization (DPO), called adversarial DPO (ADPO).","The ADPO algorithm is designed to train models to assign higher probability distributions to preferred responses and lower distributions to unsafe responses, which are self-generated using the toxic control token.","We demonstrate that ADPO enhances the model's resilience against harmful conversations while minimizing performance degradation.","Furthermore, we illustrate that ADPO offers a more stable training procedure compared to the traditional DPO.","To the best of our knowledge, this is the first adaptation of the DPO algorithm that directly incorporates harmful data into the generative model, thereby reducing the need to artificially create safe dialogue data."],"url":"http://arxiv.org/abs/2405.12900v1"}
{"created":"2024-05-21 15:46:13","title":"Approximating TSP Variants Using a Bridge Lemma","abstract":"We give improved approximations for two metric \\textsc{Traveling Salesman Problem} (TSP) variants. In \\textsc{Ordered TSP} (OTSP) we are given a linear ordering on a subset of nodes $o_1, \\ldots, o_k$. The TSP solution must have that $o_{i+1}$ is visited at some point after $o_i$ for each $1 \\leq i < k$. This is the special case of \\textsc{Precedence-Constrained TSP} ($PTSP$) in which the precedence constraints are given by a single chain on a subset of nodes. In \\textsc{$k$-Person TSP Path} (k-TSPP), we are given pairs of nodes $(s_1,t_1), \\ldots, (s_k,t_k)$. The goal is to find an $s_i$-$t_i$ path with minimum total cost such that every node is visited by at least one path.   We obtain a $3/2 + e^{-1} < 1.878$ approximation for OTSP, the first improvement over a trivial $\\alpha+1$ approximation where $\\alpha$ is the current best TSP approximation. We also obtain a $1 + 2 \\cdot e^{-1/2} < 2.214$ approximation for k-TSPP, the first improvement over a trivial $3$-approximation.   These algorithms both use an adaptation of the Bridge Lemma that was initially used to obtain improved \\textsc{Steiner Tree} approximations [Byrka et al., 2013]. Roughly speaking, our variant states that the cost of a cheapest forest rooted at a given set of terminal nodes will decrease by a substantial amount if we randomly sample a set of non-terminal nodes to also become terminals such provided each non-terminal has a constant probability of being sampled. We believe this view of the Bridge Lemma will find further use for improved vehicle routing approximations beyond this paper.","sentences":["We give improved approximations for two metric \\textsc{Traveling Salesman Problem} (TSP) variants.","In \\textsc{Ordered TSP} (OTSP) we are given a linear ordering on a subset of nodes $o_1, \\ldots, o_k$.","The TSP solution must have that $o_{i+1}$ is visited at some point after $o_i$ for each $1 \\leq","i < k$.","This is the special case of \\textsc{Precedence-Constrained TSP} ($PTSP$) in which the precedence constraints are given by a single chain on a subset of nodes.","In \\textsc{$k$-Person TSP Path} (k-TSPP), we are given pairs of nodes $(s_1,t_1), \\ldots, (s_k,t_k)$. The goal is to find an $s_i$-$t_i$ path with minimum total cost such that every node is visited by at least one path.   ","We obtain a $3/2 + e^{-1} < 1.878$ approximation for OTSP, the first improvement over a trivial $\\alpha+1$ approximation where $\\alpha$ is the current best TSP approximation.","We also obtain a $1 + 2 \\cdot e^{-1/2} < 2.214$ approximation for k-TSPP, the first improvement over a trivial $3$-approximation.   ","These algorithms both use an adaptation of the Bridge Lemma that was initially used to obtain improved \\textsc{Steiner","Tree} approximations [Byrka et al., 2013].","Roughly speaking, our variant states that the cost of a cheapest forest rooted at a given set of terminal nodes will decrease by a substantial amount if we randomly sample a set of non-terminal nodes to also become terminals such provided each non-terminal has a constant probability of being sampled.","We believe this view of the Bridge Lemma will find further use for improved vehicle routing approximations beyond this paper."],"url":"http://arxiv.org/abs/2405.12876v1"}
{"created":"2024-05-21 15:39:11","title":"Efficient Influence Minimization via Node Blocking","abstract":"Given a graph G, a budget k and a misinformation seed set S, Influence Minimization (IMIN) via node blocking aims to find a set of k nodes to be blocked such that the expected spread of S is minimized. This problem finds important applications in suppressing the spread of misinformation and has been extensively studied in the literature. However, existing solutions for IMIN still incur significant computation overhead, especially when k becomes large. In addition, there is still no approximation solution with non-trivial theoretical guarantee for IMIN via node blocking prior to our work. In this paper, we conduct the first attempt to propose algorithms that yield data-dependent approximation guarantees. Based on the Sandwich framework, we first develop submodular and monotonic lower and upper bounds for our non-submodular objective function and prove the computation of proposed bounds is \\#P-hard. In addition, two advanced sampling methods are proposed to estimate the value of bounding functions. Moreover, we develop two novel martingale-based concentration bounds to reduce the sample complexity and design two non-trivial algorithms that provide (1-1/e-\\epsilon)-approximate solutions to our bounding functions. Comprehensive experiments on 9 real-world datasets are conducted to validate the efficiency and effectiveness of the proposed techniques. Compared with the state-of-the-art methods, our solutions can achieve up to two orders of magnitude speedup and provide theoretical guarantees for the quality of returned results.","sentences":["Given a graph G, a budget k and a misinformation seed set S, Influence Minimization (IMIN) via node blocking aims to find a set of k nodes to be blocked such that the expected spread of S is minimized.","This problem finds important applications in suppressing the spread of misinformation and has been extensively studied in the literature.","However, existing solutions for IMIN still incur significant computation overhead, especially when k becomes large.","In addition, there is still no approximation solution with non-trivial theoretical guarantee for IMIN via node blocking prior to our work.","In this paper, we conduct the first attempt to propose algorithms that yield data-dependent approximation guarantees.","Based on the Sandwich framework, we first develop submodular and monotonic lower and upper bounds for our non-submodular objective function and prove the computation of proposed bounds is \\#P-hard.","In addition, two advanced sampling methods are proposed to estimate the value of bounding functions.","Moreover, we develop two novel martingale-based concentration bounds to reduce the sample complexity and design two non-trivial algorithms that provide (1-1/e-\\epsilon)-approximate solutions to our bounding functions.","Comprehensive experiments on 9 real-world datasets are conducted to validate the efficiency and effectiveness of the proposed techniques.","Compared with the state-of-the-art methods, our solutions can achieve up to two orders of magnitude speedup and provide theoretical guarantees for the quality of returned results."],"url":"http://arxiv.org/abs/2405.12871v1"}
{"created":"2024-05-21 15:30:25","title":"Robust portfolio optimization model for electronic coupon allocation","abstract":"Currently, many e-commerce websites issue online/electronic coupons as an effective tool for promoting sales of various products and services. We focus on the problem of optimally allocating coupons to customers subject to a budget constraint on an e-commerce website. We apply a robust portfolio optimization model based on customer segmentation to the coupon allocation problem. We also validate the efficacy of our method through numerical experiments using actual data from randomly distributed coupons. Main contributions of our research are twofold. First, we handle six types of coupons, thereby making it extremely difficult to accurately estimate the difference in the effects of various coupons. Second, we demonstrate from detailed numerical results that the robust optimization model achieved larger uplifts of sales than did the commonly-used multiple-choice knapsack model and the conventional mean-variance optimization model. Our results open up great potential for robust portfolio optimization as an effective tool for practical coupon allocation.","sentences":["Currently, many e-commerce websites issue online/electronic coupons as an effective tool for promoting sales of various products and services.","We focus on the problem of optimally allocating coupons to customers subject to a budget constraint on an e-commerce website.","We apply a robust portfolio optimization model based on customer segmentation to the coupon allocation problem.","We also validate the efficacy of our method through numerical experiments using actual data from randomly distributed coupons.","Main contributions of our research are twofold.","First, we handle six types of coupons, thereby making it extremely difficult to accurately estimate the difference in the effects of various coupons.","Second, we demonstrate from detailed numerical results that the robust optimization model achieved larger uplifts of sales than did the commonly-used multiple-choice knapsack model and the conventional mean-variance optimization model.","Our results open up great potential for robust portfolio optimization as an effective tool for practical coupon allocation."],"url":"http://arxiv.org/abs/2405.12865v1"}
{"created":"2024-05-21 14:57:04","title":"A Dataset and Baselines for Measuring and Predicting the Music Piece Memorability","abstract":"Nowadays, humans are constantly exposed to music, whether through voluntary streaming services or incidental encounters during commercial breaks. Despite the abundance of music, certain pieces remain more memorable and often gain greater popularity. Inspired by this phenomenon, we focus on measuring and predicting music memorability. To achieve this, we collect a new music piece dataset with reliable memorability labels using a novel interactive experimental procedure. We then train baselines to predict and analyze music memorability, leveraging both interpretable features and audio mel-spectrograms as inputs. To the best of our knowledge, we are the first to explore music memorability using data-driven deep learning-based methods. Through a series of experiments and ablation studies, we demonstrate that while there is room for improvement, predicting music memorability with limited data is possible. Certain intrinsic elements, such as higher valence, arousal, and faster tempo, contribute to memorable music. As prediction techniques continue to evolve, real-life applications like music recommendation systems and music style transfer will undoubtedly benefit from this new area of research.","sentences":["Nowadays, humans are constantly exposed to music, whether through voluntary streaming services or incidental encounters during commercial breaks.","Despite the abundance of music, certain pieces remain more memorable and often gain greater popularity.","Inspired by this phenomenon, we focus on measuring and predicting music memorability.","To achieve this, we collect a new music piece dataset with reliable memorability labels using a novel interactive experimental procedure.","We then train baselines to predict and analyze music memorability, leveraging both interpretable features and audio mel-spectrograms as inputs.","To the best of our knowledge, we are the first to explore music memorability using data-driven deep learning-based methods.","Through a series of experiments and ablation studies, we demonstrate that while there is room for improvement, predicting music memorability with limited data is possible.","Certain intrinsic elements, such as higher valence, arousal, and faster tempo, contribute to memorable music.","As prediction techniques continue to evolve, real-life applications like music recommendation systems and music style transfer will undoubtedly benefit from this new area of research."],"url":"http://arxiv.org/abs/2405.12847v1"}
{"created":"2024-05-21 14:49:12","title":"SmartFlow: Robotic Process Automation using LLMs","abstract":"Robotic Process Automation (RPA) systems face challenges in handling complex processes and diverse screen layouts that require advanced human-like decision-making capabilities. These systems typically rely on pixel-level encoding through drag-and-drop or automation frameworks such as Selenium to create navigation workflows, rather than visual understanding of screen elements. In this context, we present SmartFlow, an AI-based RPA system that uses pre-trained large language models (LLMs) coupled with deep-learning based image understanding. Our system can adapt to new scenarios, including changes in the user interface and variations in input data, without the need for human intervention. SmartFlow uses computer vision and natural language processing to perceive visible elements on the graphical user interface (GUI) and convert them into a textual representation. This information is then utilized by LLMs to generate a sequence of actions that are executed by a scripting engine to complete an assigned task. To assess the effectiveness of SmartFlow, we have developed a dataset that includes a set of generic enterprise applications with diverse layouts, which we are releasing for research use. Our evaluations on this dataset demonstrate that SmartFlow exhibits robustness across different layouts and applications. SmartFlow can automate a wide range of business processes such as form filling, customer service, invoice processing, and back-office operations. SmartFlow can thus assist organizations in enhancing productivity by automating an even larger fraction of screen-based workflows. The demo-video and dataset are available at https://smartflow-4c5a0a.webflow.io/.","sentences":["Robotic Process Automation (RPA) systems face challenges in handling complex processes and diverse screen layouts that require advanced human-like decision-making capabilities.","These systems typically rely on pixel-level encoding through drag-and-drop or automation frameworks such as Selenium to create navigation workflows, rather than visual understanding of screen elements.","In this context, we present SmartFlow, an AI-based RPA system that uses pre-trained large language models (LLMs) coupled with deep-learning based image understanding.","Our system can adapt to new scenarios, including changes in the user interface and variations in input data, without the need for human intervention.","SmartFlow uses computer vision and natural language processing to perceive visible elements on the graphical user interface (GUI) and convert them into a textual representation.","This information is then utilized by LLMs to generate a sequence of actions that are executed by a scripting engine to complete an assigned task.","To assess the effectiveness of SmartFlow, we have developed a dataset that includes a set of generic enterprise applications with diverse layouts, which we are releasing for research use.","Our evaluations on this dataset demonstrate that SmartFlow exhibits robustness across different layouts and applications.","SmartFlow can automate a wide range of business processes such as form filling, customer service, invoice processing, and back-office operations.","SmartFlow can thus assist organizations in enhancing productivity by automating an even larger fraction of screen-based workflows.","The demo-video and dataset are available at https://smartflow-4c5a0a.webflow.io/."],"url":"http://arxiv.org/abs/2405.12842v1"}
{"created":"2024-05-21 14:37:35","title":"A Survey of Deep Learning-based Radiology Report Generation Using Multimodal Data","abstract":"Automatic radiology report generation can alleviate the workload for physicians and minimize regional disparities in medical resources, therefore becoming an important topic in the medical image analysis field. It is a challenging task, as the computational model needs to mimic physicians to obtain information from multi-modal input data (i.e., medical images, clinical information, medical knowledge, etc.), and produce comprehensive and accurate reports. Recently, numerous works emerged to address this issue using deep learning-based methods, such as transformers, contrastive learning, and knowledge-base construction. This survey summarizes the key techniques developed in the most recent works and proposes a general workflow for deep learning-based report generation with five main components, including multi-modality data acquisition, data preparation, feature learning, feature fusion/interaction, and report generation. The state-of-the-art methods for each of these components are highlighted. Additionally, training strategies, public datasets, evaluation methods, current challenges, and future directions in this field are summarized. We have also conducted a quantitative comparison between different methods under the same experimental setting. This is the most up-to-date survey that focuses on multi-modality inputs and data fusion for radiology report generation. The aim is to provide comprehensive and rich information for researchers interested in automatic clinical report generation and medical image analysis, especially when using multimodal inputs, and assist them in developing new algorithms to advance the field.","sentences":["Automatic radiology report generation can alleviate the workload for physicians and minimize regional disparities in medical resources, therefore becoming an important topic in the medical image analysis field.","It is a challenging task, as the computational model needs to mimic physicians to obtain information from multi-modal input data (i.e., medical images, clinical information, medical knowledge, etc.), and produce comprehensive and accurate reports.","Recently, numerous works emerged to address this issue using deep learning-based methods, such as transformers, contrastive learning, and knowledge-base construction.","This survey summarizes the key techniques developed in the most recent works and proposes a general workflow for deep learning-based report generation with five main components, including multi-modality data acquisition, data preparation, feature learning, feature fusion/interaction, and report generation.","The state-of-the-art methods for each of these components are highlighted.","Additionally, training strategies, public datasets, evaluation methods, current challenges, and future directions in this field are summarized.","We have also conducted a quantitative comparison between different methods under the same experimental setting.","This is the most up-to-date survey that focuses on multi-modality inputs and data fusion for radiology report generation.","The aim is to provide comprehensive and rich information for researchers interested in automatic clinical report generation and medical image analysis, especially when using multimodal inputs, and assist them in developing new algorithms to advance the field."],"url":"http://arxiv.org/abs/2405.12833v1"}
{"created":"2024-05-21 14:36:16","title":"Wav-KAN: Wavelet Kolmogorov-Arnold Networks","abstract":"In this paper , we introduce Wav-KAN, an innovative neural network architecture that leverages the Wavelet Kolmogorov-Arnold Networks (Wav-KAN) framework to enhance interpretability and performance. Traditional multilayer perceptrons (MLPs) and even recent advancements like Spl-KAN face challenges related to interpretability, training speed, robustness, computational efficiency, and performance. Wav-KAN addresses these limitations by incorporating wavelet functions into the Kolmogorov-Arnold network structure, enabling the network to capture both high-frequency and low-frequency components of the input data efficiently. Wavelet-based approximations employ orthogonal or semi-orthogonal basis and also maintains a balance between accurately representing the underlying data structure and avoiding overfitting to the noise. Analogous to how water conforms to the shape of its container, Wav-KAN adapts to the data structure, resulting in enhanced accuracy, faster training speeds, and increased robustness compared to Spl-KAN and MLPs. Our results highlight the potential of Wav-KAN as a powerful tool for developing interpretable and high-performance neural networks, with applications spanning various fields. This work sets the stage for further exploration and implementation of Wav-KAN in frameworks such as PyTorch, TensorFlow, and also it makes wavelet in KAN in wide-spread usage like nowadays activation functions like ReLU, sigmoid in universal approximation theory (UAT).","sentences":["In this paper , we introduce Wav-KAN, an innovative neural network architecture that leverages the Wavelet Kolmogorov-Arnold Networks (Wav-KAN) framework to enhance interpretability and performance.","Traditional multilayer perceptrons (MLPs) and even recent advancements like Spl-KAN face challenges related to interpretability, training speed, robustness, computational efficiency, and performance.","Wav-KAN addresses these limitations by incorporating wavelet functions into the Kolmogorov-Arnold network structure, enabling the network to capture both high-frequency and low-frequency components of the input data efficiently.","Wavelet-based approximations employ orthogonal or semi-orthogonal basis and also maintains a balance between accurately representing the underlying data structure and avoiding overfitting to the noise.","Analogous to how water conforms to the shape of its container, Wav-KAN adapts to the data structure, resulting in enhanced accuracy, faster training speeds, and increased robustness compared to Spl-KAN and MLPs.","Our results highlight the potential of Wav-KAN as a powerful tool for developing interpretable and high-performance neural networks, with applications spanning various fields.","This work sets the stage for further exploration and implementation of Wav-KAN in frameworks such as PyTorch, TensorFlow, and also it makes wavelet in KAN in wide-spread usage like nowadays activation functions like ReLU, sigmoid in universal approximation theory (UAT)."],"url":"http://arxiv.org/abs/2405.12832v1"}
{"created":"2024-05-21 13:53:58","title":"Stochastic Inference of Plate Bending from Heterogeneous Data: Physics-informed Gaussian Processes via Kirchhoff-Love Theory","abstract":"Advancements in machine learning and an abundance of structural monitoring data have inspired the integration of mechanical models with probabilistic models to identify a structure's state and quantify the uncertainty of its physical parameters and response. In this paper, we propose an inference methodology for classical Kirchhoff-Love plates via physics-informed Gaussian Processes (GP). A probabilistic model is formulated as a multi-output GP by placing a GP prior on the deflection and deriving the covariance function using the linear differential operators of the plate governing equations. The posteriors of the flexural rigidity, hyperparameters, and plate response are inferred in a Bayesian manner using Markov chain Monte Carlo (MCMC) sampling from noisy measurements. We demonstrate the applicability with two examples: a simply supported plate subjected to a sinusoidal load and a fixed plate subjected to a uniform load. The results illustrate how the proposed methodology can be employed to perform stochastic inference for plate rigidity and physical quantities by integrating measurements from various sensor types and qualities. Potential applications of the presented methodology are in structural health monitoring and uncertainty quantification of plate-like structures.","sentences":["Advancements in machine learning and an abundance of structural monitoring data have inspired the integration of mechanical models with probabilistic models to identify a structure's state and quantify the uncertainty of its physical parameters and response.","In this paper, we propose an inference methodology for classical Kirchhoff-Love plates via physics-informed Gaussian Processes (GP).","A probabilistic model is formulated as a multi-output GP by placing a GP prior on the deflection and deriving the covariance function using the linear differential operators of the plate governing equations.","The posteriors of the flexural rigidity, hyperparameters, and plate response are inferred in a Bayesian manner using Markov chain Monte Carlo (MCMC) sampling from noisy measurements.","We demonstrate the applicability with two examples: a simply supported plate subjected to a sinusoidal load and a fixed plate subjected to a uniform load.","The results illustrate how the proposed methodology can be employed to perform stochastic inference for plate rigidity and physical quantities by integrating measurements from various sensor types and qualities.","Potential applications of the presented methodology are in structural health monitoring and uncertainty quantification of plate-like structures."],"url":"http://arxiv.org/abs/2405.12802v1"}
{"created":"2024-05-21 13:51:47","title":"Deep Reinforcement Learning for Time-Critical Wilderness Search And Rescue Using Drones","abstract":"Traditional search and rescue methods in wilderness areas can be time-consuming and have limited coverage. Drones offer a faster and more flexible solution, but optimizing their search paths is crucial. This paper explores the use of deep reinforcement learning to create efficient search missions for drones in wilderness environments. Our approach leverages a priori data about the search area and the missing person in the form of a probability distribution map. This allows the deep reinforcement learning agent to learn optimal flight paths that maximize the probability of finding the missing person quickly. Experimental results show that our method achieves a significant improvement in search times compared to traditional coverage planning and search planning algorithms. In one comparison, deep reinforcement learning is found to outperform other algorithms by over $160\\%$, a difference that can mean life or death in real-world search operations. Additionally, unlike previous work, our approach incorporates a continuous action space enabled by cubature, allowing for more nuanced flight patterns.","sentences":["Traditional search and rescue methods in wilderness areas can be time-consuming and have limited coverage.","Drones offer a faster and more flexible solution, but optimizing their search paths is crucial.","This paper explores the use of deep reinforcement learning to create efficient search missions for drones in wilderness environments.","Our approach leverages a priori data about the search area and the missing person in the form of a probability distribution map.","This allows the deep reinforcement learning agent to learn optimal flight paths that maximize the probability of finding the missing person quickly.","Experimental results show that our method achieves a significant improvement in search times compared to traditional coverage planning and search planning algorithms.","In one comparison, deep reinforcement learning is found to outperform other algorithms by over $160\\%$, a difference that can mean life or death in real-world search operations.","Additionally, unlike previous work, our approach incorporates a continuous action space enabled by cubature, allowing for more nuanced flight patterns."],"url":"http://arxiv.org/abs/2405.12800v1"}
{"created":"2024-05-21 13:48:07","title":"Refined Graph Encoder Embedding via Self-Training and Latent Community Recovery","abstract":"This paper introduces a refined graph encoder embedding method, enhancing the original graph encoder embedding using linear transformation, self-training, and hidden community recovery within observed communities. We provide the theoretical rationale for the refinement procedure, demonstrating how and why our proposed method can effectively identify useful hidden communities via stochastic block models, and how the refinement method leads to improved vertex embedding and better decision boundaries for subsequent vertex classification. The efficacy of our approach is validated through a collection of simulated and real-world graph data.","sentences":["This paper introduces a refined graph encoder embedding method, enhancing the original graph encoder embedding using linear transformation, self-training, and hidden community recovery within observed communities.","We provide the theoretical rationale for the refinement procedure, demonstrating how and why our proposed method can effectively identify useful hidden communities via stochastic block models, and how the refinement method leads to improved vertex embedding and better decision boundaries for subsequent vertex classification.","The efficacy of our approach is validated through a collection of simulated and real-world graph data."],"url":"http://arxiv.org/abs/2405.12797v1"}
{"created":"2024-05-21 13:40:54","title":"A Novel Methodology for Autonomous Planetary Exploration Using Multi-Robot Teams","abstract":"One of the fundamental limiting factors in planetary exploration is the autonomous capabilities of planetary exploration rovers. This study proposes a novel methodology for trustworthy autonomous multi-robot teams which incorporates data from multiple sources (HiRISE orbiter imaging, probability distribution maps, and on-board rover sensors) to find efficient exploration routes in Jezero crater. A map is generated, consisting of a 3D terrain model, traversability analysis, and probability distribution map of points of scientific interest. A three-stage mission planner generates an efficient route, which maximises the accumulated probability of identifying points of interest. A 4D RRT* algorithm is used to determine smooth, flat paths, and prioritised planning is used to coordinate a safe set of paths. The above methodology is shown to coordinate safe and efficient rover paths, which ensure the rovers remain within their nominal pitch and roll limits throughout operation.","sentences":["One of the fundamental limiting factors in planetary exploration is the autonomous capabilities of planetary exploration rovers.","This study proposes a novel methodology for trustworthy autonomous multi-robot teams which incorporates data from multiple sources (HiRISE orbiter imaging, probability distribution maps, and on-board rover sensors) to find efficient exploration routes in Jezero crater.","A map is generated, consisting of a 3D terrain model, traversability analysis, and probability distribution map of points of scientific interest.","A three-stage mission planner generates an efficient route, which maximises the accumulated probability of identifying points of interest.","A 4D RRT* algorithm is used to determine smooth, flat paths, and prioritised planning is used to coordinate a safe set of paths.","The above methodology is shown to coordinate safe and efficient rover paths, which ensure the rovers remain within their nominal pitch and roll limits throughout operation."],"url":"http://arxiv.org/abs/2405.12790v1"}
{"created":"2024-05-21 13:40:30","title":"Anticipating Object State Changes","abstract":"Anticipating object state changes in images and videos is a challenging problem whose solution has important implications in vision-based scene understanding, automated monitoring systems, and action planning. In this work, we propose the first method for solving this problem. The proposed method predicts object state changes that will occur in the near future as a result of yet unseen human actions. To address this new problem, we propose a novel framework that integrates learnt visual features that represent the recent visual information, with natural language (NLP) features that represent past object state changes and actions. Leveraging the extensive and challenging Ego4D dataset which provides a large-scale collection of first-person perspective videos across numerous interaction scenarios, we introduce new curated annotation data for the object state change anticipation task (OSCA), noted as Ego4D-OSCA. An extensive experimental evaluation was conducted that demonstrates the efficacy of the proposed method in predicting object state changes in dynamic scenarios. The proposed work underscores the potential of integrating video and linguistic cues to enhance the predictive performance of video understanding systems. Moreover, it lays the groundwork for future research on the new task of object state change anticipation. The source code and the new annotation data (Ego4D-OSCA) will be made publicly available.","sentences":["Anticipating object state changes in images and videos is a challenging problem whose solution has important implications in vision-based scene understanding, automated monitoring systems, and action planning.","In this work, we propose the first method for solving this problem.","The proposed method predicts object state changes that will occur in the near future as a result of yet unseen human actions.","To address this new problem, we propose a novel framework that integrates learnt visual features that represent the recent visual information, with natural language (NLP) features that represent past object state changes and actions.","Leveraging the extensive and challenging Ego4D dataset which provides a large-scale collection of first-person perspective videos across numerous interaction scenarios, we introduce new curated annotation data for the object state change anticipation task (OSCA), noted as Ego4D-OSCA.","An extensive experimental evaluation was conducted that demonstrates the efficacy of the proposed method in predicting object state changes in dynamic scenarios.","The proposed work underscores the potential of integrating video and linguistic cues to enhance the predictive performance of video understanding systems.","Moreover, it lays the groundwork for future research on the new task of object state change anticipation.","The source code and the new annotation data (Ego4D-OSCA) will be made publicly available."],"url":"http://arxiv.org/abs/2405.12789v1"}
{"created":"2024-05-21 13:34:23","title":"Rethinking the Vulnerabilities of Face Recognition Systems:From a Practical Perspective","abstract":"Face Recognition Systems (FRS) have increasingly integrated into critical applications, including surveillance and user authentication, highlighting their pivotal role in modern security systems. Recent studies have revealed vulnerabilities in FRS to adversarial (e.g., adversarial patch attacks) and backdoor attacks (e.g., training data poisoning), raising significant concerns about their reliability and trustworthiness. Previous studies primarily focus on traditional adversarial or backdoor attacks, overlooking the resource-intensive or privileged-manipulation nature of such threats, thus limiting their practical generalization, stealthiness, universality and robustness. Correspondingly, in this paper, we delve into the inherent vulnerabilities in FRS through user studies and preliminary explorations. By exploiting these vulnerabilities, we identify a novel attack, facial identity backdoor attack dubbed FIBA, which unveils a potentially more devastating threat against FRS:an enrollment-stage backdoor attack. FIBA circumvents the limitations of traditional attacks, enabling broad-scale disruption by allowing any attacker donning a specific trigger to bypass these systems. This implies that after a single, poisoned example is inserted into the database, the corresponding trigger becomes a universal key for any attackers to spoof the FRS. This strategy essentially challenges the conventional attacks by initiating at the enrollment stage, dramatically transforming the threat landscape by poisoning the feature database rather than the training data.","sentences":["Face Recognition Systems (FRS) have increasingly integrated into critical applications, including surveillance and user authentication, highlighting their pivotal role in modern security systems.","Recent studies have revealed vulnerabilities in FRS to adversarial (e.g., adversarial patch attacks) and backdoor attacks (e.g., training data poisoning), raising significant concerns about their reliability and trustworthiness.","Previous studies primarily focus on traditional adversarial or backdoor attacks, overlooking the resource-intensive or privileged-manipulation nature of such threats, thus limiting their practical generalization, stealthiness, universality and robustness.","Correspondingly, in this paper, we delve into the inherent vulnerabilities in FRS through user studies and preliminary explorations.","By exploiting these vulnerabilities, we identify a novel attack, facial identity backdoor attack dubbed FIBA, which unveils a potentially more devastating threat against FRS:an enrollment-stage backdoor attack.","FIBA circumvents the limitations of traditional attacks, enabling broad-scale disruption by allowing any attacker donning a specific trigger to bypass these systems.","This implies that after a single, poisoned example is inserted into the database, the corresponding trigger becomes a universal key for any attackers to spoof the FRS.","This strategy essentially challenges the conventional attacks by initiating at the enrollment stage, dramatically transforming the threat landscape by poisoning the feature database rather than the training data."],"url":"http://arxiv.org/abs/2405.12786v1"}
{"created":"2024-05-21 13:32:46","title":"Artificial Intelligence Approaches for Predictive Maintenance in the Steel Industry: A Survey","abstract":"Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0, and became crucial for enhancing operational efficiency, allowing to minimize downtime, extend lifespan of equipment, and prevent failures. A wide range of PdM tasks can be performed using Artificial Intelligence (AI) methods, which often use data generated from industrial sensors. The steel industry, which is an important branch of the global economy, is one of the potential beneficiaries of this trend, given its large environmental footprint, the globalized nature of the market, and the demanding working conditions. This survey synthesizes the current state of knowledge in the field of AI-based PdM within the steel industry and is addressed to researchers and practitioners. We identified 219 articles related to this topic and formulated five research questions, allowing us to gain a global perspective on current trends and the main research gaps. We examined equipment and facilities subjected to PdM, determined common PdM approaches, and identified trends in the AI methods used to develop these solutions. We explored the characteristics of the data used in the surveyed articles and assessed the practical implications of the research presented there. Most of the research focuses on the blast furnace or hot rolling, using data from industrial sensors. Current trends show increasing interest in the domain, especially in the use of deep learning. The main challenges include implementing the proposed methods in a production environment, incorporating them into maintenance plans, and enhancing the accessibility and reproducibility of the research.","sentences":["Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0, and became crucial for enhancing operational efficiency, allowing to minimize downtime, extend lifespan of equipment, and prevent failures.","A wide range of PdM tasks can be performed using Artificial Intelligence (AI) methods, which often use data generated from industrial sensors.","The steel industry, which is an important branch of the global economy, is one of the potential beneficiaries of this trend, given its large environmental footprint, the globalized nature of the market, and the demanding working conditions.","This survey synthesizes the current state of knowledge in the field of AI-based PdM within the steel industry and is addressed to researchers and practitioners.","We identified 219 articles related to this topic and formulated five research questions, allowing us to gain a global perspective on current trends and the main research gaps.","We examined equipment and facilities subjected to PdM, determined common PdM approaches, and identified trends in the AI methods used to develop these solutions.","We explored the characteristics of the data used in the surveyed articles and assessed the practical implications of the research presented there.","Most of the research focuses on the blast furnace or hot rolling, using data from industrial sensors.","Current trends show increasing interest in the domain, especially in the use of deep learning.","The main challenges include implementing the proposed methods in a production environment, incorporating them into maintenance plans, and enhancing the accessibility and reproducibility of the research."],"url":"http://arxiv.org/abs/2405.12785v1"}
{"created":"2024-05-21 13:29:35","title":"Generalize Polyp Segmentation via Inpainting across Diverse Backgrounds and Pseudo-Mask Refinement","abstract":"Inpainting lesions within different normal backgrounds is a potential method of addressing the generalization problem, which is crucial for polyp segmentation models. However, seamlessly introducing polyps into complex endoscopic environments while simultaneously generating accurate pseudo-masks remains a challenge for current inpainting methods. To address these issues, we first leverage the pre-trained Stable Diffusion Inpaint and ControlNet, to introduce a robust generative model capable of inpainting polyps across different backgrounds. Secondly, we utilize the prior that synthetic polyps are confined to the inpainted region, to establish an inpainted region-guided pseudo-mask refinement network. We also propose a sample selection strategy that prioritizes well-aligned and hard synthetic cases for further model fine-tuning. Experiments demonstrate that our inpainting model outperformed baseline methods both qualitatively and quantitatively in inpainting quality. Moreover, our data augmentation strategy significantly enhances the performance of polyp segmentation models on external datasets, achieving or surpassing the level of fully supervised training benchmarks in that domain. Our code is available at https://github.com/497662892/PolypInpainter.","sentences":["Inpainting lesions within different normal backgrounds is a potential method of addressing the generalization problem, which is crucial for polyp segmentation models.","However, seamlessly introducing polyps into complex endoscopic environments while simultaneously generating accurate pseudo-masks remains a challenge for current inpainting methods.","To address these issues, we first leverage the pre-trained Stable Diffusion Inpaint and ControlNet, to introduce a robust generative model capable of inpainting polyps across different backgrounds.","Secondly, we utilize the prior that synthetic polyps are confined to the inpainted region, to establish an inpainted region-guided pseudo-mask refinement network.","We also propose a sample selection strategy that prioritizes well-aligned and hard synthetic cases for further model fine-tuning.","Experiments demonstrate that our inpainting model outperformed baseline methods both qualitatively and quantitatively in inpainting quality.","Moreover, our data augmentation strategy significantly enhances the performance of polyp segmentation models on external datasets, achieving or surpassing the level of fully supervised training benchmarks in that domain.","Our code is available at https://github.com/497662892/PolypInpainter."],"url":"http://arxiv.org/abs/2405.12784v1"}
{"created":"2024-05-21 13:28:32","title":"Self-Supervised Modality-Agnostic Pre-Training of Swin Transformers","abstract":"Unsupervised pre-training has emerged as a transformative paradigm, displaying remarkable advancements in various domains. However, the susceptibility to domain shift, where pre-training data distribution differs from fine-tuning, poses a significant obstacle. To address this, we augment the Swin Transformer to learn from different medical imaging modalities, enhancing downstream performance. Our model, dubbed SwinFUSE (Swin Multi-Modal Fusion for UnSupervised Enhancement), offers three key advantages: (i) it learns from both Computed Tomography (CT) and Magnetic Resonance Images (MRI) during pre-training, resulting in complementary feature representations; (ii) a domain-invariance module (DIM) that effectively highlights salient input regions, enhancing adaptability; (iii) exhibits remarkable generalizability, surpassing the confines of tasks it was initially pre-trained on. Our experiments on two publicly available 3D segmentation datasets show a modest 1-2% performance trade-off compared to single-modality models, yet significant out-performance of up to 27% on out-of-distribution modality. This substantial improvement underscores our proposed approach's practical relevance and real-world applicability. Code is available at: https://github.com/devalab/SwinFUSE","sentences":["Unsupervised pre-training has emerged as a transformative paradigm, displaying remarkable advancements in various domains.","However, the susceptibility to domain shift, where pre-training data distribution differs from fine-tuning, poses a significant obstacle.","To address this, we augment the Swin Transformer to learn from different medical imaging modalities, enhancing downstream performance.","Our model, dubbed SwinFUSE (Swin Multi-Modal Fusion for UnSupervised Enhancement), offers three key advantages: (i) it learns from both Computed Tomography (CT) and Magnetic Resonance Images (MRI) during pre-training, resulting in complementary feature representations; (ii) a domain-invariance module (DIM) that effectively highlights salient input regions, enhancing adaptability; (iii) exhibits remarkable generalizability, surpassing the confines of tasks it was initially pre-trained on.","Our experiments on two publicly available 3D segmentation datasets show a modest 1-2% performance trade-off compared to single-modality models, yet significant out-performance of up to 27% on out-of-distribution modality.","This substantial improvement underscores our proposed approach's practical relevance and real-world applicability.","Code is available at: https://github.com/devalab/SwinFUSE"],"url":"http://arxiv.org/abs/2405.12781v1"}
{"created":"2024-05-21 13:24:07","title":"Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances","abstract":"Discovering the semantics of multimodal utterances is essential for understanding human language and enhancing human-machine interactions. Existing methods manifest limitations in leveraging nonverbal information for discerning complex semantics in unsupervised scenarios. This paper introduces a novel unsupervised multimodal clustering method (UMC), making a pioneering contribution to this field. UMC introduces a unique approach to constructing augmentation views for multimodal data, which are then used to perform pre-training to establish well-initialized representations for subsequent clustering. An innovative strategy is proposed to dynamically select high-quality samples as guidance for representation learning, gauged by the density of each sample's nearest neighbors. Besides, it is equipped to automatically determine the optimal value for the top-$K$ parameter in each cluster to refine sample selection. Finally, both high- and low-quality samples are used to learn representations conducive to effective clustering. We build baselines on benchmark multimodal intent and dialogue act datasets. UMC shows remarkable improvements of 2-6\\% scores in clustering metrics over state-of-the-art methods, marking the first successful endeavor in this domain. The complete code and data are available at https://github.com/thuiar/UMC.","sentences":["Discovering the semantics of multimodal utterances is essential for understanding human language and enhancing human-machine interactions.","Existing methods manifest limitations in leveraging nonverbal information for discerning complex semantics in unsupervised scenarios.","This paper introduces a novel unsupervised multimodal clustering method (UMC), making a pioneering contribution to this field.","UMC introduces a unique approach to constructing augmentation views for multimodal data, which are then used to perform pre-training to establish well-initialized representations for subsequent clustering.","An innovative strategy is proposed to dynamically select high-quality samples as guidance for representation learning, gauged by the density of each sample's nearest neighbors.","Besides, it is equipped to automatically determine the optimal value for the top-$K$ parameter in each cluster to refine sample selection.","Finally, both high- and low-quality samples are used to learn representations conducive to effective clustering.","We build baselines on benchmark multimodal intent and dialogue act datasets.","UMC shows remarkable improvements of 2-6\\% scores in clustering metrics over state-of-the-art methods, marking the first successful endeavor in this domain.","The complete code and data are available at https://github.com/thuiar/UMC."],"url":"http://arxiv.org/abs/2405.12775v1"}
{"created":"2024-05-21 13:19:10","title":"Test Oracle Automation in the era of LLMs","abstract":"The effectiveness of a test suite in detecting faults highly depends on the correctness and completeness of its test oracles. Large Language Models (LLMs) have already demonstrated remarkable proficiency in tackling diverse software testing tasks, such as automated test generation and program repair. This paper aims to enable discussions on the potential of using LLMs for test oracle automation, along with the challenges that may emerge during the generation of various types of oracles. Additionally, our aim is to initiate discussions on the primary threats that SE researchers must consider when employing LLMs for oracle automation, encompassing concerns regarding oracle deficiencies and data leakages.","sentences":["The effectiveness of a test suite in detecting faults highly depends on the correctness and completeness of its test oracles.","Large Language Models (LLMs) have already demonstrated remarkable proficiency in tackling diverse software testing tasks, such as automated test generation and program repair.","This paper aims to enable discussions on the potential of using LLMs for test oracle automation, along with the challenges that may emerge during the generation of various types of oracles.","Additionally, our aim is to initiate discussions on the primary threats that SE researchers must consider when employing LLMs for oracle automation, encompassing concerns regarding oracle deficiencies and data leakages."],"url":"http://arxiv.org/abs/2405.12766v1"}
{"created":"2024-05-21 13:18:54","title":"Faster linear-sze And-Or path and adder circuits","abstract":"We consider the fundamental problem of constructing fast and small circuits for binary addition. We propose a new algorithm with running time $\\mathcal O(n \\log_2 n)$ for constructing linear-size $n$-bit adder circuits with a significantly better depth guarantee compared to previous approaches: Our circuits have a depth of at most $\\log_2 n + \\log_2 \\log_2 n + \\log_2 \\log_2 \\log_2 n + \\text{const}$, improving upon the previously best circuits by [12] with a depth of at most $\\log_2 n + 8 \\sqrt{\\log_2 n} + 6 \\log_2 \\log_2 n + \\text{const}$. Hence, we decrease the gap to the lower bound of $\\log_2 n + \\log_2 \\log_2 n + \\text{const}$ by [5] significantly from $\\mathcal O (\\sqrt{\\log_2 n})$ to $\\mathcal O(\\log_2 \\log_2 \\log_2 n)$.   Our core routine is a new algorithm for the construction of a circuit for a single carry bit, or, more generally, for an And-Or path, i.e., a Boolean function of type $t_0 \\lor ( t_1 \\land (t_2 \\lor ( \\dots t_{m-1}) \\dots ))$. We compute linear-size And-Or path circuits with a depth of at most $\\log_2 m + \\log_2 \\log_2 m + 0.65$ in time $\\mathcal O(m \\log_2 m)$. These are the first And-Or path circuits known that, up to an additive constant, match the lower bound by [5] and at the same time have a linear size. The previously fastest And-Or path circuits are only by an additive constant worse in depth, but have a much higher size in the order of $\\mathcal O (m \\log_2 m)$.","sentences":["We consider the fundamental problem of constructing fast and small circuits for binary addition.","We propose a new algorithm with running time $\\mathcal O(n \\log_2 n)$ for constructing linear-size $n$-bit adder circuits with a significantly better depth guarantee compared to previous approaches: Our circuits have a depth of at most $\\log_2 n + \\log_2 \\log_2 n + \\log_2 \\log_2 \\log_2 n + \\text{const}$, improving upon the previously best circuits by [12] with a depth of at most $\\log_2 n + 8 \\sqrt{\\log_2 n} + 6 \\log_2 \\log_2 n + \\text{const}$. Hence, we decrease the gap to the lower bound of $\\log_2 n + \\log_2 \\log_2 n + \\text{const}$ by [5] significantly from $\\mathcal O (\\sqrt{\\log_2 n})$ to $\\mathcal O(\\log_2 \\log_2 \\log_2 n)$.   Our core routine is a new algorithm for the construction of a circuit for a single carry bit, or, more generally, for an And-Or path, i.e., a Boolean function of type $t_0 \\lor ( t_1 \\land (t_2 \\lor ( \\dots t_{m-1}) \\dots ))","$.","We compute linear-size And-Or path circuits with a depth of at most $\\log_2 m + \\log_2 \\log_2 m + 0.65$ in time $\\mathcal O(m \\log_2 m)$.","These are the first And-Or path circuits known that, up to an additive constant, match the lower bound by [5] and at the same time have a linear size.","The previously fastest And-Or path circuits are only by an additive constant worse in depth, but have a much higher size in the order of $\\mathcal O (m \\log_2 m)$."],"url":"http://arxiv.org/abs/2405.12765v1"}
{"created":"2024-05-21 13:06:55","title":"Parallel Algorithm for Optimal Threshold Labeling of Ordinal Regression Methods","abstract":"Ordinal regression (OR) is classification of ordinal data in which the underlying categorical target variable has a natural ordinal relation for the underlying explanatory variable. For $K$-class OR tasks, threshold methods learn a one-dimensional transformation (1DT) of the explanatory variable so that 1DT values for observations of the explanatory variable preserve the order of label values $1,\\ldots,K$ for corresponding observations of the target variable well, and then assign a label prediction to the learned 1DT through threshold labeling, namely, according to the rank of an interval to which the 1DT belongs among intervals on the real line separated by $(K-1)$ threshold parameters. In this study, we propose a parallelizable algorithm to find the optimal threshold labeling, which was developed in previous research, and derive sufficient conditions for that algorithm to successfully output the optimal threshold labeling. In a numerical experiment we performed, the computation time taken for the whole learning process of a threshold method with the optimal threshold labeling could be reduced to approximately 60\\,\\% by using the proposed algorithm with parallel processing compared to using an existing algorithm based on dynamic programming.","sentences":["Ordinal regression (OR) is classification of ordinal data in which the underlying categorical target variable has a natural ordinal relation for the underlying explanatory variable.","For $K$-class OR tasks, threshold methods learn a one-dimensional transformation (1DT) of the explanatory variable so that 1DT values for observations of the explanatory variable preserve the order of label values $1,\\ldots,K$ for corresponding observations of the target variable well, and then assign a label prediction to the learned 1DT through threshold labeling, namely, according to the rank of an interval to which the 1DT belongs among intervals on the real line separated by $(K-1)$ threshold parameters.","In this study, we propose a parallelizable algorithm to find the optimal threshold labeling, which was developed in previous research, and derive sufficient conditions for that algorithm to successfully output the optimal threshold labeling.","In a numerical experiment we performed, the computation time taken for the whole learning process of a threshold method with the optimal threshold labeling could be reduced to approximately 60\\,\\% by using the proposed algorithm with parallel processing compared to using an existing algorithm based on dynamic programming."],"url":"http://arxiv.org/abs/2405.12756v1"}
{"created":"2024-05-21 13:04:10","title":"C3L: Content Correlated Vision-Language Instruction Tuning Data Generation via Contrastive Learning","abstract":"Vision-Language Instruction Tuning (VLIT) is a critical training phase for Large Vision-Language Models (LVLMs). With the improving capabilities of open-source LVLMs, researchers have increasingly turned to generate VLIT data by using open-source LVLMs and achieved significant progress. However, such data generation approaches are bottlenecked by the following challenges: 1) Since multi-modal models tend to be influenced by prior language knowledge, directly using LVLMs to generate VLIT data would inevitably lead to low content relevance between generated data and images. 2) To improve the ability of the models to generate VLIT data, previous methods have incorporated an additional training phase to boost the generative capacity. This process hurts the generalization of the models to unseen inputs (i.e., \"exposure bias\" problem). In this paper, we propose a new Content Correlated VLIT data generation via Contrastive Learning (C3L). Specifically, we design a new content relevance module which enhances the content relevance between VLIT data and images by computing Image Instruction Correspondence Scores S(I2C). Moreover, a contrastive learning module is introduced to further boost the VLIT data generation capability of the LVLMs. A large number of automatic measures on four benchmarks show the effectiveness of our method.","sentences":["Vision-Language Instruction Tuning (VLIT) is a critical training phase for Large Vision-Language Models (LVLMs).","With the improving capabilities of open-source LVLMs, researchers have increasingly turned to generate VLIT data by using open-source LVLMs and achieved significant progress.","However, such data generation approaches are bottlenecked by the following challenges: 1) Since multi-modal models tend to be influenced by prior language knowledge, directly using LVLMs to generate VLIT data would inevitably lead to low content relevance between generated data and images.","2) To improve the ability of the models to generate VLIT data, previous methods have incorporated an additional training phase to boost the generative capacity.","This process hurts the generalization of the models to unseen inputs (i.e., \"exposure bias\" problem).","In this paper, we propose a new Content Correlated VLIT data generation via Contrastive Learning (C3L).","Specifically, we design a new content relevance module which enhances the content relevance between VLIT data and images by computing Image Instruction Correspondence Scores S(I2C).","Moreover, a contrastive learning module is introduced to further boost the VLIT data generation capability of the LVLMs.","A large number of automatic measures on four benchmarks show the effectiveness of our method."],"url":"http://arxiv.org/abs/2405.12752v1"}
{"created":"2024-05-21 13:03:06","title":"A Stealthy Backdoor Attack for Without-Label-Sharing Split Learning","abstract":"As a novel privacy-preserving paradigm aimed at reducing client computational costs and achieving data utility, split learning has garnered extensive attention and proliferated widespread applications across various fields, including smart health and smart transportation, among others. While recent studies have primarily concentrated on addressing privacy leakage concerns in split learning, such as inference attacks and data reconstruction, the exploration of security issues (e.g., backdoor attacks) within the framework of split learning has been comparatively limited. Nonetheless, the security vulnerability within the context of split learning is highly posing a threat and can give rise to grave security implications, such as the illegal impersonation in the face recognition model. Therefore, in this paper, we propose a stealthy backdoor attack strategy (namely SBAT) tailored to the without-label-sharing split learning architecture, which unveils the inherent security vulnerability of split learning. We posit the existence of a potential attacker on the server side aiming to introduce a backdoor into the training model, while exploring two scenarios: one with known client network architecture and the other with unknown architecture. Diverging from traditional backdoor attack methods that manipulate the training data and labels, we constructively conduct the backdoor attack by injecting the trigger embedding into the server network. Specifically, our SBAT achieves a higher level of attack stealthiness by refraining from modifying any intermediate parameters (e.g., gradients) during training and instead executing all malicious operations post-training.","sentences":["As a novel privacy-preserving paradigm aimed at reducing client computational costs and achieving data utility, split learning has garnered extensive attention and proliferated widespread applications across various fields, including smart health and smart transportation, among others.","While recent studies have primarily concentrated on addressing privacy leakage concerns in split learning, such as inference attacks and data reconstruction, the exploration of security issues (e.g., backdoor attacks) within the framework of split learning has been comparatively limited.","Nonetheless, the security vulnerability within the context of split learning is highly posing a threat and can give rise to grave security implications, such as the illegal impersonation in the face recognition model.","Therefore, in this paper, we propose a stealthy backdoor attack strategy (namely SBAT) tailored to the without-label-sharing split learning architecture, which unveils the inherent security vulnerability of split learning.","We posit the existence of a potential attacker on the server side aiming to introduce a backdoor into the training model, while exploring two scenarios: one with known client network architecture and the other with unknown architecture.","Diverging from traditional backdoor attack methods that manipulate the training data and labels, we constructively conduct the backdoor attack by injecting the trigger embedding into the server network.","Specifically, our SBAT achieves a higher level of attack stealthiness by refraining from modifying any intermediate parameters (e.g., gradients) during training and instead executing all malicious operations post-training."],"url":"http://arxiv.org/abs/2405.12751v1"}
{"created":"2024-05-21 13:02:27","title":"Generative AI and Large Language Models for Cyber Security: All Insights You Need","abstract":"This paper provides a comprehensive review of the future of cybersecurity through Generative AI and Large Language Models (LLMs). We explore LLM applications across various domains, including hardware design security, intrusion detection, software engineering, design verification, cyber threat intelligence, malware detection, and phishing detection. We present an overview of LLM evolution and its current state, focusing on advancements in models such as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends to LLM vulnerabilities, such as prompt injection, insecure output handling, data poisoning, DDoS attacks, and adversarial instructions. We delve into mitigation strategies to protect these models, providing a comprehensive look at potential attack scenarios and prevention techniques. Furthermore, we evaluate the performance of 42 LLM models in cybersecurity knowledge and hardware security, highlighting their strengths and weaknesses. We thoroughly evaluate cybersecurity datasets for LLM training and testing, covering the lifecycle from data creation to usage and identifying gaps for future research. In addition, we review new strategies for leveraging LLMs, including techniques like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank Adapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim to enhance real-time cybersecurity defenses and improve the sophistication of LLM applications in threat detection and response. Our paper provides a foundational understanding and strategic direction for integrating LLMs into future cybersecurity frameworks, emphasizing innovation and robust model deployment to safeguard against evolving cyber threats.","sentences":["This paper provides a comprehensive review of the future of cybersecurity through Generative AI and Large Language Models (LLMs).","We explore LLM applications across various domains, including hardware design security, intrusion detection, software engineering, design verification, cyber threat intelligence, malware detection, and phishing detection.","We present an overview of LLM evolution and its current state, focusing on advancements in models such as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA.","Our analysis extends to LLM vulnerabilities, such as prompt injection, insecure output handling, data poisoning, DDoS attacks, and adversarial instructions.","We delve into mitigation strategies to protect these models, providing a comprehensive look at potential attack scenarios and prevention techniques.","Furthermore, we evaluate the performance of 42 LLM models in cybersecurity knowledge and hardware security, highlighting their strengths and weaknesses.","We thoroughly evaluate cybersecurity datasets for LLM training and testing, covering the lifecycle from data creation to usage and identifying gaps for future research.","In addition, we review new strategies for leveraging LLMs, including techniques like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank Adapters (QLoRA), and Retrieval-Augmented Generation (RAG).","These insights aim to enhance real-time cybersecurity defenses and improve the sophistication of LLM applications in threat detection and response.","Our paper provides a foundational understanding and strategic direction for integrating LLMs into future cybersecurity frameworks, emphasizing innovation and robust model deployment to safeguard against evolving cyber threats."],"url":"http://arxiv.org/abs/2405.12750v1"}
{"created":"2024-05-21 12:55:15","title":"The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM Fine-tuning","abstract":"Texts written in different languages reflect different culturally-dependent beliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are jointly trained on a concatenation of text in multiple languages, to encode different cultural values for each language. Yet, as the 'multilinguality' of these LMs is driven by cross-lingual sharing, we also have reason to belief that cultural values bleed over from one language into another. This limits the use of MLMs in practice, as apart from being proficient in generating text in multiple languages, creating language technology that can serve a community also requires the output of LMs to be sensitive to their biases (Naous et al., 2023). Yet, little is known about how cultural values emerge and evolve in MLMs (Hershcovich et al., 2022a). We are the first to study how languages can exert influence on the cultural values encoded for different test languages, by studying how such values are revised during fine-tuning. Focusing on the fine-tuning stage allows us to study the interplay between value shifts when exposed to new linguistic experience from different data sources and languages. Lastly, we use a training data attribution method to find patterns in the fine-tuning examples, and the languages that they come from, that tend to instigate value shifts.","sentences":["Texts written in different languages reflect different culturally-dependent beliefs of their writers.","Thus, we expect multilingual LMs (MLMs), that are jointly trained on a concatenation of text in multiple languages, to encode different cultural values for each language.","Yet, as the 'multilinguality' of these LMs is driven by cross-lingual sharing, we also have reason to belief that cultural values bleed over from one language into another.","This limits the use of MLMs in practice, as apart from being proficient in generating text in multiple languages, creating language technology that can serve a community also requires the output of LMs to be sensitive to their biases (Naous et al., 2023).","Yet, little is known about how cultural values emerge and evolve in MLMs (Hershcovich et al., 2022a).","We are the first to study how languages can exert influence on the cultural values encoded for different test languages, by studying how such values are revised during fine-tuning.","Focusing on the fine-tuning stage allows us to study the interplay between value shifts when exposed to new linguistic experience from different data sources and languages.","Lastly, we use a training data attribution method to find patterns in the fine-tuning examples, and the languages that they come from, that tend to instigate value shifts."],"url":"http://arxiv.org/abs/2405.12744v1"}
{"created":"2024-05-21 12:44:43","title":"Predicting the Influence of Adverse Weather on Pedestrian Detection with Automotive Radar and Lidar Sensors","abstract":"Pedestrians are among the most endangered traffic participants in road traffic. While pedestrian detection in nominal conditions is well established, the sensor and, therefore, the pedestrian detection performance degrades under adverse weather conditions. Understanding the influences of rain and fog on a specific radar and lidar sensor requires extensive testing, and if the sensors' specifications are altered, a retesting effort is required. These challenges are addressed in this paper, firstly by conducting comprehensive measurements collecting empirical data of pedestrian detection performance under varying rain and fog intensities in a controlled environment, and secondly, by introducing a dedicated \\textit{Weather Filter} (WF) model that predicts the effects of rain and fog on a user-specified radar and lidar on pedestrian detection performance. We use a state-of-the-art baseline model representing the physical relation of sensor specifications, which, however, lacks the representation of secondary weather effects, e.g., changes in pedestrian reflectivity or droplets on a sensor, and adjust it with empirical data to account for such. We find that our measurement results are in agreement with existent literature related to weather degredation and our WF outperforms the baseline model in predicting weather effects on pedestrian detection while only requiring a minimal testing effort.","sentences":["Pedestrians are among the most endangered traffic participants in road traffic.","While pedestrian detection in nominal conditions is well established, the sensor and, therefore, the pedestrian detection performance degrades under adverse weather conditions.","Understanding the influences of rain and fog on a specific radar and lidar sensor requires extensive testing, and if the sensors' specifications are altered, a retesting effort is required.","These challenges are addressed in this paper, firstly by conducting comprehensive measurements collecting empirical data of pedestrian detection performance under varying rain and fog intensities in a controlled environment, and secondly, by introducing a dedicated \\textit{Weather Filter} (WF) model that predicts the effects of rain and fog on a user-specified radar and lidar on pedestrian detection performance.","We use a state-of-the-art baseline model representing the physical relation of sensor specifications, which, however, lacks the representation of secondary weather effects, e.g., changes in pedestrian reflectivity or droplets on a sensor, and adjust it with empirical data to account for such.","We find that our measurement results are in agreement with existent literature related to weather degredation and our WF outperforms the baseline model in predicting weather effects on pedestrian detection while only requiring a minimal testing effort."],"url":"http://arxiv.org/abs/2405.12736v1"}
{"created":"2024-05-21 12:43:37","title":"Amplifying Academic Research through YouTube: Engagement Metrics as Predictors of Citation Impact","abstract":"This study explores the interplay between YouTube engagement metrics and the academic impact of cited publications within video descriptions, amid declining trust in traditional journalism and increased reliance on social media for information. By analyzing data from Altmetric.com and YouTube's API, it assesses how YouTube video features relate to citation impact. Initial results suggest that videos citing scientific publications and garnering high engagement-likes, comments, and references to other publications-may function as a filtering mechanism or even as a predictor of impactful research.","sentences":["This study explores the interplay between YouTube engagement metrics and the academic impact of cited publications within video descriptions, amid declining trust in traditional journalism and increased reliance on social media for information.","By analyzing data from Altmetric.com and YouTube's API, it assesses how YouTube video features relate to citation impact.","Initial results suggest that videos citing scientific publications and garnering high engagement-likes, comments, and references to other publications-may function as a filtering mechanism or even as a predictor of impactful research."],"url":"http://arxiv.org/abs/2405.12734v1"}
{"created":"2024-05-21 12:37:45","title":"Review on modeling the societal impact of infrastructure disruptions due to disasters","abstract":"Infrastructure systems play a critical role in providing essential products and services for the functioning of modern society; however, they are vulnerable to disasters and their service disruptions can cause severe societal impacts. To protect infrastructure from disasters and reduce potential impacts, great achievements have been made in modeling interdependent infrastructure systems in past decades. In recent years, scholars have gradually shifted their research focus to understanding and modeling societal impacts of disruptions considering the fact that infrastructure systems are critical because of their role in societal functioning, especially under situations of modern societies. Exploring how infrastructure disruptions impair society to enhance resilient city has become a key field of study. By comprehensively reviewing relevant studies, this paper demonstrated the definition and types of societal impact of infrastructure disruptions, and summarized the modeling approaches into four types: extended infrastructure modeling approaches, empirical approaches, agent-based approaches, and big data-driven approaches. For each approach, this paper organized relevant literature in terms of modeling ideas, advantages, and disadvantages. Furthermore, the four approaches were compared according to several criteria, including the input data, types of societal impact, and application scope. Finally, this paper illustrated the challenges and future research directions in the field.","sentences":["Infrastructure systems play a critical role in providing essential products and services for the functioning of modern society; however, they are vulnerable to disasters and their service disruptions can cause severe societal impacts.","To protect infrastructure from disasters and reduce potential impacts, great achievements have been made in modeling interdependent infrastructure systems in past decades.","In recent years, scholars have gradually shifted their research focus to understanding and modeling societal impacts of disruptions considering the fact that infrastructure systems are critical because of their role in societal functioning, especially under situations of modern societies.","Exploring how infrastructure disruptions impair society to enhance resilient city has become a key field of study.","By comprehensively reviewing relevant studies, this paper demonstrated the definition and types of societal impact of infrastructure disruptions, and summarized the modeling approaches into four types: extended infrastructure modeling approaches, empirical approaches, agent-based approaches, and big data-driven approaches.","For each approach, this paper organized relevant literature in terms of modeling ideas, advantages, and disadvantages.","Furthermore, the four approaches were compared according to several criteria, including the input data, types of societal impact, and application scope.","Finally, this paper illustrated the challenges and future research directions in the field."],"url":"http://arxiv.org/abs/2405.12732v1"}
{"created":"2024-05-21 12:20:19","title":"How to Train a Backdoor-Robust Model on a Poisoned Dataset without Auxiliary Data?","abstract":"Backdoor attacks have attracted wide attention from academia and industry due to their great security threat to deep neural networks (DNN). Most of the existing methods propose to conduct backdoor attacks by poisoning the training dataset with different strategies, so it's critical to identify the poisoned samples and then train a clean model on the unreliable dataset in the context of defending backdoor attacks. Although numerous backdoor countermeasure researches are proposed, their inherent weaknesses render them limited in practical scenarios, such as the requirement of enough clean samples, unstable defense performance under various attack conditions, poor defense performance against adaptive attacks, and so on.Therefore, in this paper, we are committed to overcome the above limitations and propose a more practical backdoor defense method. Concretely, we first explore the inherent relationship between the potential perturbations and the backdoor trigger, and the theoretical analysis and experimental results demonstrate that the poisoned samples perform more robustness to perturbation than the clean ones. Then, based on our key explorations, we introduce AdvrBD, an Adversarial perturbation-based and robust Backdoor Defense framework, which can effectively identify the poisoned samples and train a clean model on the poisoned dataset. Constructively, our AdvrBD eliminates the requirement for any clean samples or knowledge about the poisoned dataset (e.g., poisoning ratio), which significantly improves the practicality in real-world scenarios.","sentences":["Backdoor attacks have attracted wide attention from academia and industry due to their great security threat to deep neural networks (DNN).","Most of the existing methods propose to conduct backdoor attacks by poisoning the training dataset with different strategies, so it's critical to identify the poisoned samples and then train a clean model on the unreliable dataset in the context of defending backdoor attacks.","Although numerous backdoor countermeasure researches are proposed, their inherent weaknesses render them limited in practical scenarios, such as the requirement of enough clean samples, unstable defense performance under various attack conditions, poor defense performance against adaptive attacks, and so on.","Therefore, in this paper, we are committed to overcome the above limitations and propose a more practical backdoor defense method.","Concretely, we first explore the inherent relationship between the potential perturbations and the backdoor trigger, and the theoretical analysis and experimental results demonstrate that the poisoned samples perform more robustness to perturbation than the clean ones.","Then, based on our key explorations, we introduce AdvrBD, an Adversarial perturbation-based and robust Backdoor Defense framework, which can effectively identify the poisoned samples and train a clean model on the poisoned dataset.","Constructively, our AdvrBD eliminates the requirement for any clean samples or knowledge about the poisoned dataset (e.g., poisoning ratio), which significantly improves the practicality in real-world scenarios."],"url":"http://arxiv.org/abs/2405.12719v1"}
{"created":"2024-05-21 11:58:11","title":"Object-Centric Event Logs: Specifications, Comparative Analysis and Refinement","abstract":"Process mining aims to comprehend and enhance business processes by analyzing event logs. Recently, object-centric process mining has gained traction by considering multiple objects interacting with each other in a process. This object-centric approach offers advantages over traditional methods by avoiding dimension reduction issues. However, in contrast to traditional process mining where a standard event log format was quickly agreed upon with XES providing a common platform for further research and industry, various object-centric logging formats have been proposed, each addressing specific challenges such as object relations or dynamic attribute changes. This makes that interoperability of object-centric algorithms remains a challenge, hindering reproducibility and generalizability in research. Additionally, the object-centric process storage paradigm aligns well with a wide range of object-oriented databases storing process data.   This paper introduces a specifications framework from three perspectives originating from process mining (what should be analyzed), object-centric process modeling (how it should be modeled), and database storage (how it should be stored) perspectives in order to compare and evaluate object-centric log formats. By identifying commonalities and discrepancies among these formats, the study delves into unresolved issues and proposes potential solutions. Ultimately, this research contributes to advancing object-centric process mining by facilitating a deeper understanding of event log formats and promoting consistency and compatibility across methodologies.","sentences":["Process mining aims to comprehend and enhance business processes by analyzing event logs.","Recently, object-centric process mining has gained traction by considering multiple objects interacting with each other in a process.","This object-centric approach offers advantages over traditional methods by avoiding dimension reduction issues.","However, in contrast to traditional process mining where a standard event log format was quickly agreed upon with XES providing a common platform for further research and industry, various object-centric logging formats have been proposed, each addressing specific challenges such as object relations or dynamic attribute changes.","This makes that interoperability of object-centric algorithms remains a challenge, hindering reproducibility and generalizability in research.","Additionally, the object-centric process storage paradigm aligns well with a wide range of object-oriented databases storing process data.   ","This paper introduces a specifications framework from three perspectives originating from process mining (what should be analyzed), object-centric process modeling (how it should be modeled), and database storage (how it should be stored) perspectives in order to compare and evaluate object-centric log formats.","By identifying commonalities and discrepancies among these formats, the study delves into unresolved issues and proposes potential solutions.","Ultimately, this research contributes to advancing object-centric process mining by facilitating a deeper understanding of event log formats and promoting consistency and compatibility across methodologies."],"url":"http://arxiv.org/abs/2405.12709v1"}
{"created":"2024-05-21 11:49:07","title":"Getting Wiser from Multiple Data: Probabilistic Updating according to Jeffrey and Pearl","abstract":"In probabilistic updating one transforms a prior distribution in the light of given evidence into a posterior distribution, via what is called conditioning, updating, belief revision or inference. This is the essence of learning, as Bayesian updating. It will be illustrated via a physical model involving (adapted) water flows through pipes with different diameters.   Bayesian updating makes us wiser, in the sense that the posterior distribution makes the evidence more likely than the prior, since it incorporates the evidence. Things are less clear when one wishes to learn from multiple pieces of evidence / data. It turns out that there are (at least) two forms of updating for this, associated with Jeffrey and Pearl. The difference is not always clearly recognised.   This paper provides an introduction and an overview in the setting of discrete probability theory. It starts from an elementary question, involving multiple pieces of evidence, that has been sent to a small group academic specialists. Their answers show considerable differences. This is used as motivation and starting point to introduce the two forms of updating, of Jeffrey and Pearl, for multiple inputs and to elaborate their properties. In the end the account is related to so-called variational free energy (VFE) update in the cognitive theory of predictive processing. It is shown that both Jeffrey and Pearl outperform VFE updating and that VFE updating need not decrease divergence - that is correct errors - as it is supposed to do.","sentences":["In probabilistic updating one transforms a prior distribution in the light of given evidence into a posterior distribution, via what is called conditioning, updating, belief revision or inference.","This is the essence of learning, as Bayesian updating.","It will be illustrated via a physical model involving (adapted) water flows through pipes with different diameters.   ","Bayesian updating makes us wiser, in the sense that the posterior distribution makes the evidence more likely than the prior, since it incorporates the evidence.","Things are less clear when one wishes to learn from multiple pieces of evidence / data.","It turns out that there are (at least) two forms of updating for this, associated with Jeffrey and Pearl.","The difference is not always clearly recognised.   ","This paper provides an introduction and an overview in the setting of discrete probability theory.","It starts from an elementary question, involving multiple pieces of evidence, that has been sent to a small group academic specialists.","Their answers show considerable differences.","This is used as motivation and starting point to introduce the two forms of updating, of Jeffrey and Pearl, for multiple inputs and to elaborate their properties.","In the end the account is related to so-called variational free energy (VFE) update in the cognitive theory of predictive processing.","It is shown that both Jeffrey and Pearl outperform VFE updating and that VFE updating need not decrease divergence - that is correct errors - as it is supposed to do."],"url":"http://arxiv.org/abs/2405.12700v1"}
{"created":"2024-05-21 11:46:51","title":"GeckoGraph: A Visual Language for Polymorphic Types","abstract":"Polymorphic types are an important feature in most strongly typed programming languages. They allow functions to be written in a way that can be used with different data types, while still enforcing the relationship and constraints between the values. However, programmers often find polymorphic types difficult to use and understand and tend to reason using concrete types. We propose GeckoGraph, a graphical notation for types. GeckoGraph aims to accompany traditional text-based type notation and to make reading, understanding, and comparing types easier. We conducted a large-scale human study using GeckoGraph compared to text-based type notation. To our knowledge, this is the largest controlled user study on functional programming ever conducted. The results of the study show that GeckoGraph helps improve programmers' ability to succeed in the programming tasks we designed, especially for novice programmers.","sentences":["Polymorphic types are an important feature in most strongly typed programming languages.","They allow functions to be written in a way that can be used with different data types, while still enforcing the relationship and constraints between the values.","However, programmers often find polymorphic types difficult to use and understand and tend to reason using concrete types.","We propose GeckoGraph, a graphical notation for types.","GeckoGraph aims to accompany traditional text-based type notation and to make reading, understanding, and comparing types easier.","We conducted a large-scale human study using GeckoGraph compared to text-based type notation.","To our knowledge, this is the largest controlled user study on functional programming ever conducted.","The results of the study show that GeckoGraph helps improve programmers' ability to succeed in the programming tasks we designed, especially for novice programmers."],"url":"http://arxiv.org/abs/2405.12699v1"}
{"created":"2024-05-21 11:14:16","title":"A Multimodal Learning-based Approach for Autonomous Landing of UAV","abstract":"In the field of autonomous Unmanned Aerial Vehicles (UAVs) landing, conventional approaches fall short in delivering not only the required precision but also the resilience against environmental disturbances. Yet, learning-based algorithms can offer promising solutions by leveraging their ability to learn the intelligent behaviour from data. On one hand, this paper introduces a novel multimodal transformer-based Deep Learning detector, that can provide reliable positioning for precise autonomous landing. It surpasses standard approaches by addressing individual sensor limitations, achieving high reliability even in diverse weather and sensor failure conditions. It was rigorously validated across varying environments, achieving optimal true positive rates and average precisions of up to 90%. On the other hand, it is proposed a Reinforcement Learning (RL) decision-making model, based on a Deep Q-Network (DQN) rationale. Initially trained in sumlation, its adaptive behaviour is successfully transferred and validated in a real outdoor scenario. Furthermore, this approach demonstrates rapid inference times of approximately 5ms, validating its applicability on edge devices.","sentences":["In the field of autonomous Unmanned Aerial Vehicles (UAVs) landing, conventional approaches fall short in delivering not only the required precision but also the resilience against environmental disturbances.","Yet, learning-based algorithms can offer promising solutions by leveraging their ability to learn the intelligent behaviour from data.","On one hand, this paper introduces a novel multimodal transformer-based Deep Learning detector, that can provide reliable positioning for precise autonomous landing.","It surpasses standard approaches by addressing individual sensor limitations, achieving high reliability even in diverse weather and sensor failure conditions.","It was rigorously validated across varying environments, achieving optimal true positive rates and average precisions of up to 90%.","On the other hand, it is proposed a Reinforcement Learning (RL) decision-making model, based on a Deep Q-Network (DQN) rationale.","Initially trained in sumlation, its adaptive behaviour is successfully transferred and validated in a real outdoor scenario.","Furthermore, this approach demonstrates rapid inference times of approximately 5ms, validating its applicability on edge devices."],"url":"http://arxiv.org/abs/2405.12681v1"}
{"created":"2024-05-21 11:11:13","title":"Sorting in One and Two Rounds using $t$-Comparators","abstract":"We examine sorting algorithms for $n$ elements whose basic operation is comparing $t$ elements simultaneously (a $t$-comparator). We focus on algorithms that use only a single round or two rounds -- comparisons performed in the second round depend on the outcomes of the first round comparators.   We design deterministic and randomized algorithms. In the deterministic case, we show an interesting relation to design theory (namely, to 2-Steiner systems), which yields a single-round optimal algorithm for $n=t^{2^k}$ with any $k\\ge 1$ and a variety of possible values of $t$. For some values of $t$, however, no algorithm can reach the optimal (information-theoretic) bound on the number of comparators. For this case (and any other $n$ and $t$), we show an algorithm that uses at most three times as many comparators as the theoretical bound.   We also design a randomized Las-Vegas two-rounds sorting algorithm for any $n$ and $t$. Our algorithm uses an asymptotically optimal number of $O(\\max(\\frac{n^{3/2}}{t^2},\\frac{n}{t}))$ comparators, with high probability, i.e., with probability at least $1-1/n$. The analysis of this algorithm involves the gradual unveiling of randomness, using a novel technique which we coin the binary tree of deferred randomness.","sentences":["We examine sorting algorithms for $n$ elements whose basic operation is comparing $t$ elements simultaneously (a $t$-comparator).","We focus on algorithms that use only a single round or two rounds -- comparisons performed in the second round depend on the outcomes of the first round comparators.   ","We design deterministic and randomized algorithms.","In the deterministic case, we show an interesting relation to design theory (namely, to 2-Steiner systems), which yields a single-round optimal algorithm for $n=t^{2^k}$ with any $k\\ge 1$ and a variety of possible values of $t$. For some values of $t$, however, no algorithm can reach the optimal (information-theoretic) bound on the number of comparators.","For this case (and any other $n$ and $t$), we show an algorithm that uses at most three times as many comparators as the theoretical bound.   ","We also design a randomized Las-Vegas two-rounds sorting algorithm for any $n$ and $t$. Our algorithm uses an asymptotically optimal number of $O(\\max(\\frac{n^{3/2}}{t^2},\\frac{n}{t}))$ comparators, with high probability, i.e., with probability at least $1-1/n$. The analysis of this algorithm involves the gradual unveiling of randomness, using a novel technique which we coin the binary tree of deferred randomness."],"url":"http://arxiv.org/abs/2405.12678v1"}
{"created":"2024-05-21 10:14:50","title":"Mitigating Overconfidence in Out-of-Distribution Detection by Capturing Extreme Activations","abstract":"Detecting out-of-distribution (OOD) instances is crucial for the reliable deployment of machine learning models in real-world scenarios. OOD inputs are commonly expected to cause a more uncertain prediction in the primary task; however, there are OOD cases for which the model returns a highly confident prediction. This phenomenon, denoted as \"overconfidence\", presents a challenge to OOD detection. Specifically, theoretical evidence indicates that overconfidence is an intrinsic property of certain neural network architectures, leading to poor OOD detection. In this work, we address this issue by measuring extreme activation values in the penultimate layer of neural networks and then leverage this proxy of overconfidence to improve on several OOD detection baselines. We test our method on a wide array of experiments spanning synthetic data and real-world data, tabular and image datasets, multiple architectures such as ResNet and Transformer, different training loss functions, and include the scenarios examined in previous theoretical work. Compared to the baselines, our method often grants substantial improvements, with double-digit increases in OOD detection AUC, and it does not damage performance in any scenario.","sentences":["Detecting out-of-distribution (OOD) instances is crucial for the reliable deployment of machine learning models in real-world scenarios.","OOD inputs are commonly expected to cause a more uncertain prediction in the primary task; however, there are OOD cases for which the model returns a highly confident prediction.","This phenomenon, denoted as \"overconfidence\", presents a challenge to OOD detection.","Specifically, theoretical evidence indicates that overconfidence is an intrinsic property of certain neural network architectures, leading to poor OOD detection.","In this work, we address this issue by measuring extreme activation values in the penultimate layer of neural networks and then leverage this proxy of overconfidence to improve on several OOD detection baselines.","We test our method on a wide array of experiments spanning synthetic data and real-world data, tabular and image datasets, multiple architectures such as ResNet and Transformer, different training loss functions, and include the scenarios examined in previous theoretical work.","Compared to the baselines, our method often grants substantial improvements, with double-digit increases in OOD detection AUC, and it does not damage performance in any scenario."],"url":"http://arxiv.org/abs/2405.12658v1"}
{"created":"2024-05-21 10:10:56","title":"Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction","abstract":"Extrapolation in Large language models (LLMs) for open-ended inquiry encounters two pivotal issues: (1) hallucination and (2) expensive training costs. These issues present challenges for LLMs in specialized domains and personalized data, requiring truthful responses and low fine-tuning costs. Existing works attempt to tackle the problem by augmenting the input of a smaller language model with information from a knowledge graph (KG). However, they have two limitations: (1) failing to extract relevant information from a large one-hop neighborhood in KG and (2) applying the same augmentation strategy for KGs with different characteristics that may result in low performance. Moreover, open-ended inquiry typically yields multiple responses, further complicating extrapolation. We propose a new task, the extreme multi-label KG link prediction task, to enable a model to perform extrapolation with multiple responses using structured real-world knowledge. Our retriever identifies relevant one-hop neighbors by considering entity, relation, and textual data together. Our experiments demonstrate that (1) KGs with different characteristics require different augmenting strategies, and (2) augmenting the language model's input with textual data improves task performance significantly. By incorporating the retrieval-augmented framework with KG, our framework, with a small parameter size, is able to extrapolate based on a given KG. The code can be obtained on GitHub: https://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git","sentences":["Extrapolation in Large language models (LLMs) for open-ended inquiry encounters two pivotal issues: (1) hallucination and (2) expensive training costs.","These issues present challenges for LLMs in specialized domains and personalized data, requiring truthful responses and low fine-tuning costs.","Existing works attempt to tackle the problem by augmenting the input of a smaller language model with information from a knowledge graph (KG).","However, they have two limitations: (1) failing to extract relevant information from a large one-hop neighborhood in KG and (2) applying the same augmentation strategy for KGs with different characteristics that may result in low performance.","Moreover, open-ended inquiry typically yields multiple responses, further complicating extrapolation.","We propose a new task, the extreme multi-label KG link prediction task, to enable a model to perform extrapolation with multiple responses using structured real-world knowledge.","Our retriever identifies relevant one-hop neighbors by considering entity, relation, and textual data together.","Our experiments demonstrate that (1) KGs with different characteristics require different augmenting strategies, and (2) augmenting the language model's input with textual data improves task performance significantly.","By incorporating the retrieval-augmented framework with KG, our framework, with a small parameter size, is able to extrapolate based on a given KG.","The code can be obtained on GitHub: https://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git"],"url":"http://arxiv.org/abs/2405.12656v1"}
{"created":"2024-05-21 10:07:29","title":"Utilizing Description Logics for Global Explanations of Heterogeneous Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) are effective for node classification in graph-structured data, but they lack explainability, especially at the global level. Current research mainly utilizes subgraphs of the input as local explanations or generates new graphs as global explanations. However, these graph-based methods are limited in their ability to explain classes with multiple sufficient explanations. To provide more expressive explanations, we propose utilizing class expressions (CEs) from the field of description logic (DL). Our approach explains heterogeneous graphs with different types of nodes using CEs in the EL description logic. To identify the best explanation among multiple candidate explanations, we employ and compare two different scoring functions: (1) For a given CE, we construct multiple graphs, have the GNN make a prediction for each graph, and aggregate the predicted scores. (2) We score the CE in terms of fidelity, i.e., we compare the predictions of the GNN to the predictions by the CE on a separate validation set. Instead of subgraph-based explanations, we offer CE-based explanations.","sentences":["Graph Neural Networks (GNNs) are effective for node classification in graph-structured data, but they lack explainability, especially at the global level.","Current research mainly utilizes subgraphs of the input as local explanations or generates new graphs as global explanations.","However, these graph-based methods are limited in their ability to explain classes with multiple sufficient explanations.","To provide more expressive explanations, we propose utilizing class expressions (CEs) from the field of description logic (DL).","Our approach explains heterogeneous graphs with different types of nodes using CEs in the EL description logic.","To identify the best explanation among multiple candidate explanations, we employ and compare two different scoring functions: (1) For a given CE, we construct multiple graphs, have the GNN make a prediction for each graph, and aggregate the predicted scores.","(2) We score the CE in terms of fidelity, i.e., we compare the predictions of the GNN to the predictions by the CE on a separate validation set.","Instead of subgraph-based explanations, we offer CE-based explanations."],"url":"http://arxiv.org/abs/2405.12654v1"}
{"created":"2024-05-21 10:02:55","title":"Edge Information Hub-Empowered 6G NTN: Latency-Oriented Resource Orchestration and Configuration","abstract":"Quick response to disasters is crucial for saving lives and reducing loss. This requires low-latency uploading of situation information to the remote command center. Since terrestrial infrastructures are often damaged in disaster areas, non-terrestrial networks (NTNs) are preferable to provide network coverage, and mobile edge computing (MEC) could be integrated to improve the latency performance. Nevertheless, the communications and computing in MEC-enabled NTNs are strongly coupled, which complicates the system design. In this paper, an edge information hub (EIH) that incorporates communication, computing and storage capabilities is proposed to synergize communication and computing and enable systematic design. We first address the joint data scheduling and resource orchestration problem to minimize the latency for uploading sensing data. The problem is solved using an optimal resource orchestration algorithm. On that basis, we propose the principles for resource configuration of the EIH considering payload constraints on size, weight and energy supply. Simulation results demonstrate the superiority of our proposed scheme in reducing the overall upload latency, thus enabling quick emergency rescue.","sentences":["Quick response to disasters is crucial for saving lives and reducing loss.","This requires low-latency uploading of situation information to the remote command center.","Since terrestrial infrastructures are often damaged in disaster areas, non-terrestrial networks (NTNs) are preferable to provide network coverage, and mobile edge computing (MEC) could be integrated to improve the latency performance.","Nevertheless, the communications and computing in MEC-enabled NTNs are strongly coupled, which complicates the system design.","In this paper, an edge information hub (EIH) that incorporates communication, computing and storage capabilities is proposed to synergize communication and computing and enable systematic design.","We first address the joint data scheduling and resource orchestration problem to minimize the latency for uploading sensing data.","The problem is solved using an optimal resource orchestration algorithm.","On that basis, we propose the principles for resource configuration of the EIH considering payload constraints on size, weight and energy supply.","Simulation results demonstrate the superiority of our proposed scheme in reducing the overall upload latency, thus enabling quick emergency rescue."],"url":"http://arxiv.org/abs/2405.12652v1"}
{"created":"2024-05-21 09:51:15","title":"Combining Twitter and Mobile Phone Data to Observe Border-Rush: The Turkish-European Border Opening","abstract":"Following Turkey's 2020 decision to revoke border controls, many individuals journeyed towards the Greek, Bulgarian, and Turkish borders. However, the lack of verifiable statistics on irregular migration and discrepancies between media reports and actual migration patterns require further exploration. The objective of this study is to bridge this knowledge gap by harnessing novel data sources, specifically mobile phone and Twitter data, to construct estimators of cross-border mobility and to cultivate a qualitative comprehension of the unfolding events. By employing a migration diplomacy framework, we analyse emergent mobility patterns at the border. Our findings demonstrate the potential of mobile phone data for quantitative metrics and Twitter data for qualitative understanding. We underscore the ethical implications of leveraging Big Data, particularly considering the vulnerability of the population under study. This underscores the imperative for exhaustive research into the socio-political facets of human mobility, with the aim of discerning the potentialities, limitations, and risks inherent in these data sources and their integration. This scholarly endeavour contributes to a more nuanced understanding of migration dynamics and paves the way for the formulation of regulations that preclude misuse and oppressive surveillance, thereby ensuring a more accurate representation of migration realities.","sentences":["Following Turkey's 2020 decision to revoke border controls, many individuals journeyed towards the Greek, Bulgarian, and Turkish borders.","However, the lack of verifiable statistics on irregular migration and discrepancies between media reports and actual migration patterns require further exploration.","The objective of this study is to bridge this knowledge gap by harnessing novel data sources, specifically mobile phone and Twitter data, to construct estimators of cross-border mobility and to cultivate a qualitative comprehension of the unfolding events.","By employing a migration diplomacy framework, we analyse emergent mobility patterns at the border.","Our findings demonstrate the potential of mobile phone data for quantitative metrics and Twitter data for qualitative understanding.","We underscore the ethical implications of leveraging Big Data, particularly considering the vulnerability of the population under study.","This underscores the imperative for exhaustive research into the socio-political facets of human mobility, with the aim of discerning the potentialities, limitations, and risks inherent in these data sources and their integration.","This scholarly endeavour contributes to a more nuanced understanding of migration dynamics and paves the way for the formulation of regulations that preclude misuse and oppressive surveillance, thereby ensuring a more accurate representation of migration realities."],"url":"http://arxiv.org/abs/2405.12642v1"}
{"created":"2024-05-21 09:39:55","title":"TempoScale: A Cloud Workloads Prediction Approach Integrating Short-Term and Long-Term Information","abstract":"Cloud native solutions are widely applied in various fields, placing higher demands on the efficient management and utilization of resource platforms. To achieve the efficiency, load forecasting and elastic scaling have become crucial technologies for dynamically adjusting cloud resources to meet user demands and minimizing resource waste. However, existing prediction-based methods lack comprehensive analysis and integration of load characteristics across different time scales. For instance, long-term trend analysis helps reveal long-term changes in load and resource demand, thereby supporting proactive resource allocation over longer periods, while short-term volatility analysis can examine short-term fluctuations in load and resource demand, providing support for real-time scheduling and rapid response. In response to this, our research introduces TempoScale, which aims to enhance the comprehensive understanding of temporal variations in cloud workloads, enabling more intelligent and adaptive decision-making for elastic scaling. TempoScale utilizes the Complete Ensemble Empirical Mode Decomposition with Adaptive Noise algorithm to decompose time-series load data into multiple Intrinsic Mode Functions (IMF) and a Residual Component (RC). First, we integrate the IMF, which represents both long-term trends and short-term fluctuations, into the time series prediction model to obtain intermediate results. Then, these intermediate results, along with the RC, are transferred into a fully connected layer to obtain the final result. Finally, this result is fed into the resource management system based on Kubernetes for resource scaling. Our proposed approach can reduce the Mean Square Error by 5.80% to 30.43% compared to the baselines, and reduce the average response time by 5.58% to 31.15%.","sentences":["Cloud native solutions are widely applied in various fields, placing higher demands on the efficient management and utilization of resource platforms.","To achieve the efficiency, load forecasting and elastic scaling have become crucial technologies for dynamically adjusting cloud resources to meet user demands and minimizing resource waste.","However, existing prediction-based methods lack comprehensive analysis and integration of load characteristics across different time scales.","For instance, long-term trend analysis helps reveal long-term changes in load and resource demand, thereby supporting proactive resource allocation over longer periods, while short-term volatility analysis can examine short-term fluctuations in load and resource demand, providing support for real-time scheduling and rapid response.","In response to this, our research introduces TempoScale, which aims to enhance the comprehensive understanding of temporal variations in cloud workloads, enabling more intelligent and adaptive decision-making for elastic scaling.","TempoScale utilizes the Complete Ensemble Empirical Mode Decomposition with Adaptive Noise algorithm to decompose time-series load data into multiple Intrinsic Mode Functions (IMF) and a Residual Component (RC).","First, we integrate the IMF, which represents both long-term trends and short-term fluctuations, into the time series prediction model to obtain intermediate results.","Then, these intermediate results, along with the RC, are transferred into a fully connected layer to obtain the final result.","Finally, this result is fed into the resource management system based on Kubernetes for resource scaling.","Our proposed approach can reduce the Mean Square Error by 5.80% to 30.43% compared to the baselines, and reduce the average response time by 5.58% to 31.15%."],"url":"http://arxiv.org/abs/2405.12635v1"}
{"created":"2024-05-21 09:38:56","title":"Automating Attendance Management in Human Resources: A Design Science Approach Using Computer Vision and Facial Recognition","abstract":"Haar Cascade is a cost-effective and user-friendly machine learning-based algorithm for detecting objects in images and videos. Unlike Deep Learning algorithms, which typically require significant resources and expensive computing costs, it uses simple image processing techniques like edge detection and Haar features that are easy to comprehend and implement. By combining Haar Cascade with OpenCV2 on an embedded computer like the NVIDIA Jetson Nano, this system can accurately detect and match faces in a database for attendance tracking. This system aims to achieve several specific objectives that set it apart from existing solutions. It leverages Haar Cascade, enriched with carefully selected Haar features, such as Haar-like wavelets, and employs advanced edge detection techniques. These techniques enable precise face detection and matching in both images and videos, contributing to high accuracy and robust performance. By doing so, it minimizes manual intervention and reduces errors, thereby strengthening accountability. Additionally, the integration of OpenCV2 and the NVIDIA Jetson Nano optimizes processing efficiency, making it suitable for resource-constrained environments. This system caters to a diverse range of educational institutions, including schools, colleges, vocational training centers, and various workplace settings such as small businesses, offices, and factories. ... The system's affordability and efficiency democratize attendance management technology, making it accessible to a broader audience. Consequently, it has the potential to transform attendance tracking and management practices, ultimately leading to heightened productivity and accountability. In conclusion, this system represents a groundbreaking approach to attendance tracking and management...","sentences":["Haar Cascade is a cost-effective and user-friendly machine learning-based algorithm for detecting objects in images and videos.","Unlike Deep Learning algorithms, which typically require significant resources and expensive computing costs, it uses simple image processing techniques like edge detection and Haar features that are easy to comprehend and implement.","By combining Haar Cascade with OpenCV2 on an embedded computer like the NVIDIA Jetson Nano, this system can accurately detect and match faces in a database for attendance tracking.","This system aims to achieve several specific objectives that set it apart from existing solutions.","It leverages Haar Cascade, enriched with carefully selected Haar features, such as Haar-like wavelets, and employs advanced edge detection techniques.","These techniques enable precise face detection and matching in both images and videos, contributing to high accuracy and robust performance.","By doing so, it minimizes manual intervention and reduces errors, thereby strengthening accountability.","Additionally, the integration of OpenCV2 and the NVIDIA Jetson Nano optimizes processing efficiency, making it suitable for resource-constrained environments.","This system caters to a diverse range of educational institutions, including schools, colleges, vocational training centers, and various workplace settings such as small businesses, offices, and factories.","...","The system's affordability and efficiency democratize attendance management technology, making it accessible to a broader audience.","Consequently, it has the potential to transform attendance tracking and management practices, ultimately leading to heightened productivity and accountability.","In conclusion, this system represents a groundbreaking approach to attendance tracking and management..."],"url":"http://arxiv.org/abs/2405.12633v1"}
{"created":"2024-05-21 09:23:39","title":"Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition","abstract":"Recent work on dialogue-based collaborative plan acquisition (CPA) has suggested that Theory of Mind (ToM) modelling can improve missing knowledge prediction in settings with asymmetric skill-sets and knowledge. Although ToM was claimed to be important for effective collaboration, its real impact on this novel task remains under-explored. By representing plans as graphs and by exploiting task-specific constraints we show that, as performance on CPA nearly doubles when predicting one's own missing knowledge, the improvements due to ToM modelling diminish. This phenomenon persists even when evaluating existing baseline methods. To better understand the relevance of ToM for CPA, we report a principled performance comparison of models with and without ToM features. Results across different models and ablations consistently suggest that learned ToM features are indeed more likely to reflect latent patterns in the data with no perceivable link to ToM. This finding calls for a deeper understanding of the role of ToM in CPA and beyond, as well as new methods for modelling and evaluating mental states in computational collaborative agents.","sentences":["Recent work on dialogue-based collaborative plan acquisition (CPA) has suggested that Theory of Mind (ToM) modelling can improve missing knowledge prediction in settings with asymmetric skill-sets and knowledge.","Although ToM was claimed to be important for effective collaboration, its real impact on this novel task remains under-explored.","By representing plans as graphs and by exploiting task-specific constraints we show that, as performance on CPA nearly doubles when predicting one's own missing knowledge, the improvements due to ToM modelling diminish.","This phenomenon persists even when evaluating existing baseline methods.","To better understand the relevance of ToM for CPA, we report a principled performance comparison of models with and without ToM features.","Results across different models and ablations consistently suggest that learned ToM features are indeed more likely to reflect latent patterns in the data with no perceivable link to ToM.","This finding calls for a deeper understanding of the role of ToM in CPA and beyond, as well as new methods for modelling and evaluating mental states in computational collaborative agents."],"url":"http://arxiv.org/abs/2405.12621v1"}
{"created":"2024-05-21 09:16:38","title":"MentalQA: An Annotated Arabic Corpus for Questions and Answers of Mental Healthcare","abstract":"Mental health disorders significantly impact people globally, regardless of background, education, or socioeconomic status. However, access to adequate care remains a challenge, particularly for underserved communities with limited resources. Text mining tools offer immense potential to support mental healthcare by assisting professionals in diagnosing and treating patients. This study addresses the scarcity of Arabic mental health resources for developing such tools. We introduce MentalQA, a novel Arabic dataset featuring conversational-style question-and-answer (QA) interactions. To ensure data quality, we conducted a rigorous annotation process using a well-defined schema with quality control measures. Data was collected from a question-answering medical platform. The annotation schema for mental health questions and corresponding answers draws upon existing classification schemes with some modifications. Question types encompass six distinct categories: diagnosis, treatment, anatomy \\& physiology, epidemiology, healthy lifestyle, and provider choice. Answer strategies include information provision, direct guidance, and emotional support. Three experienced annotators collaboratively annotated the data to ensure consistency. Our findings demonstrate high inter-annotator agreement, with Fleiss' Kappa of $0.61$ for question types and $0.98$ for answer strategies. In-depth analysis revealed insightful patterns, including variations in question preferences across age groups and a strong correlation between question types and answer strategies. MentalQA offers a valuable foundation for developing Arabic text mining tools capable of supporting mental health professionals and individuals seeking information.","sentences":["Mental health disorders significantly impact people globally, regardless of background, education, or socioeconomic status.","However, access to adequate care remains a challenge, particularly for underserved communities with limited resources.","Text mining tools offer immense potential to support mental healthcare by assisting professionals in diagnosing and treating patients.","This study addresses the scarcity of Arabic mental health resources for developing such tools.","We introduce MentalQA, a novel Arabic dataset featuring conversational-style question-and-answer (QA) interactions.","To ensure data quality, we conducted a rigorous annotation process using a well-defined schema with quality control measures.","Data was collected from a question-answering medical platform.","The annotation schema for mental health questions and corresponding answers draws upon existing classification schemes with some modifications.","Question types encompass six distinct categories: diagnosis, treatment, anatomy \\& physiology, epidemiology, healthy lifestyle, and provider choice.","Answer strategies include information provision, direct guidance, and emotional support.","Three experienced annotators collaboratively annotated the data to ensure consistency.","Our findings demonstrate high inter-annotator agreement, with Fleiss' Kappa of $0.61$ for question types and $0.98$ for answer strategies.","In-depth analysis revealed insightful patterns, including variations in question preferences across age groups and a strong correlation between question types and answer strategies.","MentalQA offers a valuable foundation for developing Arabic text mining tools capable of supporting mental health professionals and individuals seeking information."],"url":"http://arxiv.org/abs/2405.12619v1"}
{"created":"2024-05-21 09:06:36","title":"Tagengo: A Multilingual Chat Dataset","abstract":"Open source large language models (LLMs) have shown great improvements in recent times. However, many of these models are focused solely on popular spoken languages. We present a high quality dataset of more than 70k prompt-response pairs in 74 languages which consist of human generated prompts and synthetic responses. We use this dataset to train a state-of-the-art open source English LLM to chat multilingually. We evaluate our model on MT-Bench chat benchmarks in 6 languages, finding that our multilingual model outperforms previous state-of-the-art open source LLMs across each language. We further find that training on more multilingual data is beneficial to the performance in a chosen target language (Japanese) compared to simply training on only data in that language. These results indicate the necessity of training on large amounts of high quality multilingual data to make a more accessible LLM.","sentences":["Open source large language models (LLMs) have shown great improvements in recent times.","However, many of these models are focused solely on popular spoken languages.","We present a high quality dataset of more than 70k prompt-response pairs in 74 languages which consist of human generated prompts and synthetic responses.","We use this dataset to train a state-of-the-art open source English LLM to chat multilingually.","We evaluate our model on MT-Bench chat benchmarks in 6 languages, finding that our multilingual model outperforms previous state-of-the-art open source LLMs across each language.","We further find that training on more multilingual data is beneficial to the performance in a chosen target language (Japanese) compared to simply training on only data in that language.","These results indicate the necessity of training on large amounts of high quality multilingual data to make a more accessible LLM."],"url":"http://arxiv.org/abs/2405.12612v1"}
{"created":"2024-05-21 08:35:10","title":"Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression","abstract":"Key-value~(KV) caching is an important technique to accelerate the inference of large language models~(LLMs), but incurs significant memory overhead. To compress the size of KV cache, existing methods often compromise precision or require extra data for calibration, limiting their practicality in LLM deployment. In this paper, we introduce \\textbf{DecoQuant}, a novel data-free low-bit quantization technique based on tensor decomposition methods, to effectively compress KV cache. Our core idea is to adjust the outlier distribution of the original matrix by performing tensor decomposition, so that the quantization difficulties are migrated from the matrix to decomposed local tensors. Specially, we find that outliers mainly concentrate on small local tensors, while large tensors tend to have a narrower value range. Based on this finding, we propose to apply low-bit quantization to the large tensor, while maintaining high-precision representation for the small tensor. Furthermore, we utilize the proposed quantization method to compress the KV cache of LLMs to accelerate the inference and develop an efficient dequantization kernel tailored specifically for DecoQuant. Through extensive experiments, DecoQuant demonstrates remarkable efficiency gains, showcasing up to a $\\sim$75\\% reduction in memory footprint while maintaining comparable generation quality.","sentences":["Key-value~(KV) caching is an important technique to accelerate the inference of large language models~(LLMs), but incurs significant memory overhead.","To compress the size of KV cache, existing methods often compromise precision or require extra data for calibration, limiting their practicality in LLM deployment.","In this paper, we introduce \\textbf{DecoQuant}, a novel data-free low-bit quantization technique based on tensor decomposition methods, to effectively compress KV cache.","Our core idea is to adjust the outlier distribution of the original matrix by performing tensor decomposition, so that the quantization difficulties are migrated from the matrix to decomposed local tensors.","Specially, we find that outliers mainly concentrate on small local tensors, while large tensors tend to have a narrower value range.","Based on this finding, we propose to apply low-bit quantization to the large tensor, while maintaining high-precision representation for the small tensor.","Furthermore, we utilize the proposed quantization method to compress the KV cache of LLMs to accelerate the inference and develop an efficient dequantization kernel tailored specifically for DecoQuant.","Through extensive experiments, DecoQuant demonstrates remarkable efficiency gains, showcasing up to a $\\sim$75\\% reduction in memory footprint while maintaining comparable generation quality."],"url":"http://arxiv.org/abs/2405.12591v1"}
{"created":"2024-05-21 08:34:39","title":"Maverick-Aware Shapley Valuation for Client Selection in Federated Learning","abstract":"Federated Learning (FL) allows clients to train a model collaboratively without sharing their private data. One key challenge in practical FL systems is data heterogeneity, particularly in handling clients with rare data, also referred to as Mavericks. These clients own one or more data classes exclusively, and the model performance becomes poor without their participation. Thus, utilizing Mavericks throughout training is crucial. In this paper, we first design a Maverick-aware Shapley valuation that fairly evaluates the contribution of Mavericks. The main idea is to compute the clients' Shapley values (SV) class-wise, i.e., per label. Next, we propose FedMS, a Maverick-Shapley client selection mechanism for FL that intelligently selects the clients that contribute the most in each round, by employing our Maverick-aware SV-based contribution score. We show that, compared to an extensive list of baselines, FedMS achieves better model performance and fairer Shapley Rewards distribution.","sentences":["Federated Learning (FL) allows clients to train a model collaboratively without sharing their private data.","One key challenge in practical FL systems is data heterogeneity, particularly in handling clients with rare data, also referred to as Mavericks.","These clients own one or more data classes exclusively, and the model performance becomes poor without their participation.","Thus, utilizing Mavericks throughout training is crucial.","In this paper, we first design a Maverick-aware Shapley valuation that fairly evaluates the contribution of Mavericks.","The main idea is to compute the clients' Shapley values (SV) class-wise, i.e., per label.","Next, we propose FedMS, a Maverick-Shapley client selection mechanism for FL that intelligently selects the clients that contribute the most in each round, by employing our Maverick-aware SV-based contribution score.","We show that, compared to an extensive list of baselines, FedMS achieves better model performance and fairer Shapley Rewards distribution."],"url":"http://arxiv.org/abs/2405.12590v1"}
{"created":"2024-05-21 08:23:54","title":"Mining the Explainability and Generalization: Fact Verification Based on Self-Instruction","abstract":"Fact-checking based on commercial LLMs has become mainstream. Although these methods offer high explainability, it falls short in accuracy compared to traditional fine-tuning approaches, and data security is also a significant concern. In this paper, we propose a self-instruction based fine-tuning approach for fact-checking that balances accuracy and explainability. Our method consists of Data Augmentation and Improved DPO fine-tuning. The former starts by instructing the model to generate both positive and negative explanations based on claim-evidence pairs and labels, then sampling the dataset according to our customized difficulty standards. The latter employs our proposed improved DPO to fine-tune the model using the generated samples. We fine-tune the smallest-scale LLaMA-7B model and evaluate it on the challenging fact-checking datasets FEVEROUS and HOVER, utilizing four fine-tuning methods and three few-shot learning methods for comparison. The experiments demonstrate that our approach not only retains accuracy comparable to, or even surpassing, traditional fine-tuning methods, but also generates fluent explanation text. Moreover, it also exhibit high generalization performance. Our method is the first to leverage self-supervised learning for fact-checking and innovatively combines contrastive learning and improved DPO in fine-tuning LLMs, as shown in the experiments.","sentences":["Fact-checking based on commercial LLMs has become mainstream.","Although these methods offer high explainability, it falls short in accuracy compared to traditional fine-tuning approaches, and data security is also a significant concern.","In this paper, we propose a self-instruction based fine-tuning approach for fact-checking that balances accuracy and explainability.","Our method consists of Data Augmentation and Improved DPO fine-tuning.","The former starts by instructing the model to generate both positive and negative explanations based on claim-evidence pairs and labels, then sampling the dataset according to our customized difficulty standards.","The latter employs our proposed improved DPO to fine-tune the model using the generated samples.","We fine-tune the smallest-scale LLaMA-7B model and evaluate it on the challenging fact-checking datasets FEVEROUS and HOVER, utilizing four fine-tuning methods and three few-shot learning methods for comparison.","The experiments demonstrate that our approach not only retains accuracy comparable to, or even surpassing, traditional fine-tuning methods, but also generates fluent explanation text.","Moreover, it also exhibit high generalization performance.","Our method is the first to leverage self-supervised learning for fact-checking and innovatively combines contrastive learning and improved DPO in fine-tuning LLMs, as shown in the experiments."],"url":"http://arxiv.org/abs/2405.12579v1"}
{"created":"2024-05-21 08:22:14","title":"Fast Estimation of Relative Transformation Based on Fusion of Odometry and UWB Ranging Data","abstract":"In this paper, we investigate the problem of estimating the 4-DOF (three-dimensional position and orientation) robot-robot relative frame transformation using odometers and distance measurements between robots. Firstly, we apply a two-step estimation method based on maximum likelihood estimation. Specifically, a good initial value is obtained through unconstrained least squares and projection, followed by a more accurate estimate achieved through one-step Gauss-Newton iteration. Additionally, the optimal installation positions of Ultra-Wideband (UWB) are provided, and the minimum operating time under different quantities of UWB devices is determined. Simulation demonstrates that the two-step approach offers faster computation with guaranteed accuracy while effectively addressing the relative transformation estimation problem within limited space constraints. Furthermore, this method can be applied to real-time relative transformation estimation when a specific number of UWB devices are installed.","sentences":["In this paper, we investigate the problem of estimating the 4-DOF (three-dimensional position and orientation) robot-robot relative frame transformation using odometers and distance measurements between robots.","Firstly, we apply a two-step estimation method based on maximum likelihood estimation.","Specifically, a good initial value is obtained through unconstrained least squares and projection, followed by a more accurate estimate achieved through one-step Gauss-Newton iteration.","Additionally, the optimal installation positions of Ultra-Wideband (UWB) are provided, and the minimum operating time under different quantities of UWB devices is determined.","Simulation demonstrates that the two-step approach offers faster computation with guaranteed accuracy while effectively addressing the relative transformation estimation problem within limited space constraints.","Furthermore, this method can be applied to real-time relative transformation estimation when a specific number of UWB devices are installed."],"url":"http://arxiv.org/abs/2405.12577v1"}
{"created":"2024-05-21 08:18:28","title":"EchoPT: A Pretrained Transformer Architecture that Predicts 2D In-Air Sonar Images for Mobile Robotics","abstract":"The predictive brain hypothesis suggests that perception can be interpreted as the process of minimizing the error between predicted perception tokens generated by an internal world model and actual sensory input tokens. When implementing working examples of this hypothesis in the context of in-air sonar, significant difficulties arise due to the sparse nature of the reflection model that governs ultrasonic sensing. Despite these challenges, creating consistent world models using sonar data is crucial for implementing predictive processing of ultrasound data in robotics. In an effort to enable robust robot behavior using ultrasound as the sole exteroceptive sensor modality, this paper introduces EchoPT, a pretrained transformer architecture designed to predict 2D sonar images from previous sensory data and robot ego-motion information. We detail the transformer architecture that drives EchoPT and compare the performance of our model to several state-of-the-art techniques. In addition to presenting and evaluating our EchoPT model, we demonstrate the effectiveness of this predictive perception approach in two robotic tasks.","sentences":["The predictive brain hypothesis suggests that perception can be interpreted as the process of minimizing the error between predicted perception tokens generated by an internal world model and actual sensory input tokens.","When implementing working examples of this hypothesis in the context of in-air sonar, significant difficulties arise due to the sparse nature of the reflection model that governs ultrasonic sensing.","Despite these challenges, creating consistent world models using sonar data is crucial for implementing predictive processing of ultrasound data in robotics.","In an effort to enable robust robot behavior using ultrasound as the sole exteroceptive sensor modality, this paper introduces EchoPT, a pretrained transformer architecture designed to predict 2D sonar images from previous sensory data and robot ego-motion information.","We detail the transformer architecture that drives EchoPT and compare the performance of our model to several state-of-the-art techniques.","In addition to presenting and evaluating our EchoPT model, we demonstrate the effectiveness of this predictive perception approach in two robotic tasks."],"url":"http://arxiv.org/abs/2405.12573v1"}
{"created":"2024-05-21 08:15:17","title":"iHERO: Interactive Human-oriented Exploration and Supervision Under Scarce Communication","abstract":"Exploration of unknown scenes before human entry is essential for safety and efficiency in numerous scenarios, e.g., subterranean exploration, reconnaissance, search and rescue missions. Fleets of autonomous robots are particularly suitable for this task, via concurrent exploration, multi-sensory perception and autonomous navigation. Communication however among the robots can be severely restricted to only close- range exchange via ad-hoc networks. Although some recent works have addressed the problem of collaborative exploration under restricted communication, the crucial role of the human operator has been mostly neglected. Indeed, the operator may: (i) require timely update regarding the exploration progress and fleet status; (ii) prioritize certain regions; and (iii) dynamically move within the explored area; To facilitate these requests, this work proposes an interactive human-oriented online coordination framework for collaborative exploration and supervision under scarce communication (iHERO). The robots switch smoothly and optimally among fast exploration, intermittent exchange of map and sensory data, and return to the operator for status update. It is ensured that these requests are fulfilled online interactively with a pre-specified latency. Extensive large-scale human-in- the-loop simulations and hardware experiments are performed over numerous challenging scenes, which signify its performance such as explored area and efficiency, and validate its potential applicability to real-world scenarios.","sentences":["Exploration of unknown scenes before human entry is essential for safety and efficiency in numerous scenarios, e.g., subterranean exploration, reconnaissance, search and rescue missions.","Fleets of autonomous robots are particularly suitable for this task, via concurrent exploration, multi-sensory perception and autonomous navigation.","Communication however among the robots can be severely restricted to only close- range exchange via ad-hoc networks.","Although some recent works have addressed the problem of collaborative exploration under restricted communication, the crucial role of the human operator has been mostly neglected.","Indeed, the operator may: (i) require timely update regarding the exploration progress and fleet status; (ii) prioritize certain regions; and (iii) dynamically move within the explored area; To facilitate these requests, this work proposes an interactive human-oriented online coordination framework for collaborative exploration and supervision under scarce communication (iHERO).","The robots switch smoothly and optimally among fast exploration, intermittent exchange of map and sensory data, and return to the operator for status update.","It is ensured that these requests are fulfilled online interactively with a pre-specified latency.","Extensive large-scale human-in- the-loop simulations and hardware experiments are performed over numerous challenging scenes, which signify its performance such as explored area and efficiency, and validate its potential applicability to real-world scenarios."],"url":"http://arxiv.org/abs/2405.12571v1"}
{"created":"2024-05-21 07:51:01","title":"Online Signature Recognition: A Biologically Inspired Feature Vector Splitting Approach","abstract":"This research introduces an innovative approach to explore the cognitive and biologically inspired underpinnings of feature vector splitting for analyzing the significance of different attributes in e-security biometric signature recognition applications. Departing from traditional methods of concatenating features into an extended set, we employ multiple splitting strategies, aligning with cognitive principles, to preserve control over the relative importance of each feature subset. Our methodology is applied to three diverse databases (MCYT100, MCYT300,and SVC) using two classifiers (vector quantization and dynamic time warping with one and five training samples). Experimentation demonstrates that the fusion of pressure data with spatial coordinates (x and y) consistently enhances performance. However, the inclusion of pen-tip angles in the same feature set yields mixed results, with performance improvements observed in select cases. This work delves into the cognitive aspects of feature fusion,shedding light on the cognitive relevance of feature vector splitting in e-security biometric applications.","sentences":["This research introduces an innovative approach to explore the cognitive and biologically inspired underpinnings of feature vector splitting for analyzing the significance of different attributes in e-security biometric signature recognition applications.","Departing from traditional methods of concatenating features into an extended set, we employ multiple splitting strategies, aligning with cognitive principles, to preserve control over the relative importance of each feature subset.","Our methodology is applied to three diverse databases (MCYT100, MCYT300,and SVC) using two classifiers (vector quantization and dynamic time warping with one and five training samples).","Experimentation demonstrates that the fusion of pressure data with spatial coordinates (x and y) consistently enhances performance.","However, the inclusion of pen-tip angles in the same feature set yields mixed results, with performance improvements observed in select cases.","This work delves into the cognitive aspects of feature fusion,shedding light on the cognitive relevance of feature vector splitting in e-security biometric applications."],"url":"http://arxiv.org/abs/2405.12556v1"}
{"created":"2024-05-21 07:37:31","title":"RA: A machine based rational agent, Part 1","abstract":"RA is a software package that couples machine learning with formal reasoning in an attempt to find the laws that generate the empirical data that it has been given access to. A brief outline of RA in its initial stage of development is presented. Particular emphasis is given to current design strategies that aim to endow RA with the ability to construct its own conjectures of which it constructs proofs.","sentences":["RA is a software package that couples machine learning with formal reasoning in an attempt to find the laws that generate the empirical data that it has been given access to.","A brief outline of RA in its initial stage of development is presented.","Particular emphasis is given to current design strategies that aim to endow RA with the ability to construct its own conjectures of which it constructs proofs."],"url":"http://arxiv.org/abs/2405.12551v1"}
{"created":"2024-05-21 07:16:12","title":"DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge","abstract":"Large language models (LLMs) have the potential to transform digital healthcare, as evidenced by recent advances in LLM-based virtual doctors. However, current approaches rely on patient's subjective descriptions of symptoms, causing increased misdiagnosis. Recognizing the value of daily data from smart devices, we introduce a novel LLM-based multi-turn consultation virtual doctor system, DrHouse, which incorporates three significant contributions: 1) It utilizes sensor data from smart devices in the diagnosis process, enhancing accuracy and reliability. 2) DrHouse leverages continuously updating medical databases such as Up-to-Date and PubMed to ensure our model remains at diagnostic standard's forefront. 3) DrHouse introduces a novel diagnostic algorithm that concurrently evaluates potential diseases and their likelihood, facilitating more nuanced and informed medical assessments. Through multi-turn interactions, DrHouse determines the next steps, such as accessing daily data from smart devices or requesting in-lab tests, and progressively refines its diagnoses. Evaluations on three public datasets and our self-collected datasets show that DrHouse can achieve up to an 18.8% increase in diagnosis accuracy over the state-of-the-art baselines. The results of a 32-participant user study show that 75% medical experts and 91.7% patients are willing to use DrHouse.","sentences":["Large language models (LLMs) have the potential to transform digital healthcare, as evidenced by recent advances in LLM-based virtual doctors.","However, current approaches rely on patient's subjective descriptions of symptoms, causing increased misdiagnosis.","Recognizing the value of daily data from smart devices, we introduce a novel LLM-based multi-turn consultation virtual doctor system, DrHouse, which incorporates three significant contributions: 1) It utilizes sensor data from smart devices in the diagnosis process, enhancing accuracy and reliability.","2) DrHouse leverages continuously updating medical databases such as Up-to-Date and PubMed to ensure our model remains at diagnostic standard's forefront.","3) DrHouse introduces a novel diagnostic algorithm that concurrently evaluates potential diseases and their likelihood, facilitating more nuanced and informed medical assessments.","Through multi-turn interactions, DrHouse determines the next steps, such as accessing daily data from smart devices or requesting in-lab tests, and progressively refines its diagnoses.","Evaluations on three public datasets and our self-collected datasets show that DrHouse can achieve up to an 18.8% increase in diagnosis accuracy over the state-of-the-art baselines.","The results of a 32-participant user study show that 75% medical experts and 91.7% patients are willing to use DrHouse."],"url":"http://arxiv.org/abs/2405.12541v1"}
{"created":"2024-05-21 07:07:44","title":"Bridging the Intent Gap: Knowledge-Enhanced Visual Generation","abstract":"For visual content generation, discrepancies between user intentions and the generated content have been a longstanding problem. This discrepancy arises from two main factors. First, user intentions are inherently complex, with subtle details not fully captured by input prompts. The absence of such details makes it challenging for generative models to accurately reflect the intended meaning, leading to a mismatch between the desired and generated output. Second, generative models trained on visual-label pairs lack the comprehensive knowledge to accurately represent all aspects of the input data in their generated outputs. To address these challenges, we propose a knowledge-enhanced iterative refinement framework for visual content generation. We begin by analyzing and identifying the key challenges faced by existing generative models. Then, we introduce various knowledge sources, including human insights, pre-trained models, logic rules, and world knowledge, which can be leveraged to address these challenges. Furthermore, we propose a novel visual generation framework that incorporates a knowledge-based feedback module to iteratively refine the generation process. This module gradually improves the alignment between the generated content and user intentions. We demonstrate the efficacy of the proposed framework through preliminary results, highlighting the potential of knowledge-enhanced generative models for intention-aligned content generation.","sentences":["For visual content generation, discrepancies between user intentions and the generated content have been a longstanding problem.","This discrepancy arises from two main factors.","First, user intentions are inherently complex, with subtle details not fully captured by input prompts.","The absence of such details makes it challenging for generative models to accurately reflect the intended meaning, leading to a mismatch between the desired and generated output.","Second, generative models trained on visual-label pairs lack the comprehensive knowledge to accurately represent all aspects of the input data in their generated outputs.","To address these challenges, we propose a knowledge-enhanced iterative refinement framework for visual content generation.","We begin by analyzing and identifying the key challenges faced by existing generative models.","Then, we introduce various knowledge sources, including human insights, pre-trained models, logic rules, and world knowledge, which can be leveraged to address these challenges.","Furthermore, we propose a novel visual generation framework that incorporates a knowledge-based feedback module to iteratively refine the generation process.","This module gradually improves the alignment between the generated content and user intentions.","We demonstrate the efficacy of the proposed framework through preliminary results, highlighting the potential of knowledge-enhanced generative models for intention-aligned content generation."],"url":"http://arxiv.org/abs/2405.12538v1"}
{"created":"2024-05-21 06:48:26","title":"Dataset and Benchmark for Urdu Natural Scenes Text Detection, Recognition and Visual Question Answering","abstract":"The development of Urdu scene text detection, recognition, and Visual Question Answering (VQA) technologies is crucial for advancing accessibility, information retrieval, and linguistic diversity in digital content, facilitating better understanding and interaction with Urdu-language visual data. This initiative seeks to bridge the gap between textual and visual comprehension. We propose a new multi-task Urdu scene text dataset comprising over 1000 natural scene images, which can be used for text detection, recognition, and VQA tasks. We provide fine-grained annotations for text instances, addressing the limitations of previous datasets for facing arbitrary-shaped texts. By incorporating additional annotation points, this dataset facilitates the development and assessment of methods that can handle diverse text layouts, intricate shapes, and non-standard orientations commonly encountered in real-world scenarios. Besides, the VQA annotations make it the first benchmark for the Urdu Text VQA method, which can prompt the development of Urdu scene text understanding. The proposed dataset is available at: https://github.com/Hiba-MeiRuan/Urdu-VQA-Dataset-/tree/main","sentences":["The development of Urdu scene text detection, recognition, and Visual Question Answering (VQA) technologies is crucial for advancing accessibility, information retrieval, and linguistic diversity in digital content, facilitating better understanding and interaction with Urdu-language visual data.","This initiative seeks to bridge the gap between textual and visual comprehension.","We propose a new multi-task Urdu scene text dataset comprising over 1000 natural scene images, which can be used for text detection, recognition, and VQA tasks.","We provide fine-grained annotations for text instances, addressing the limitations of previous datasets for facing arbitrary-shaped texts.","By incorporating additional annotation points, this dataset facilitates the development and assessment of methods that can handle diverse text layouts, intricate shapes, and non-standard orientations commonly encountered in real-world scenarios.","Besides, the VQA annotations make it the first benchmark for the Urdu Text VQA method, which can prompt the development of Urdu scene text understanding.","The proposed dataset is available at: https://github.com/Hiba-MeiRuan/Urdu-VQA-Dataset-/tree/main"],"url":"http://arxiv.org/abs/2405.12533v1"}
{"created":"2024-05-21 06:41:24","title":"Multi-hop Multi-RIS Wireless Communication Systems: Multi-reflection Path Scheduling and Beamforming","abstract":"Reconfigurable intelligent surface (RIS) provides a promising way to proactively augment propagation environments for better transmission performance in wireless communications. Existing multi-RIS works mainly focus on link-level optimization with predetermined transmission paths, which cannot be directly extended to system-level management, since they neither consider the interference caused by undesired scattering of RISs, nor the performance balancing between different transmission paths. To address this, we study an innovative multi-hop multi-RIS communication system, where a base station (BS) transmits information to a set of distributed users over multi-RIS configuration space in a multi-hop manner. The signals for each user are subsequently reflected by the selected RISs via multi-reflection line-of-sight (LoS) links. To ensure that all users have fair access to the system to avoid excessive number of RISs serving one user, we aim to find the optimal beam reflecting path for each user, while judiciously determining the path scheduling strategies with the corresponding beamforming design to ensure the fairness. Due to the presence of interference caused by undesired scattering of RISs, it is highly challenging to solve the formulated multi-RIS multi-path beamforming optimization problem. To solve it, we first derive the optimal RISs' phase shifts and the corresponding reflecting path selection for each user based on its practical deployment location. With the optimized multi-reflection paths, we obtain a feasible user grouping pattern for effective interference mitigation by constructing the maximum independent sets (MISs). Finally, we propose a joint heuristic algorithm to iteratively update the beamforming vectors and the group scheduling policies to maximize the minimum equivalent data rate of all users.","sentences":["Reconfigurable intelligent surface (RIS) provides a promising way to proactively augment propagation environments for better transmission performance in wireless communications.","Existing multi-RIS works mainly focus on link-level optimization with predetermined transmission paths, which cannot be directly extended to system-level management, since they neither consider the interference caused by undesired scattering of RISs, nor the performance balancing between different transmission paths.","To address this, we study an innovative multi-hop multi-RIS communication system, where a base station (BS) transmits information to a set of distributed users over multi-RIS configuration space in a multi-hop manner.","The signals for each user are subsequently reflected by the selected RISs via multi-reflection line-of-sight (LoS) links.","To ensure that all users have fair access to the system to avoid excessive number of RISs serving one user, we aim to find the optimal beam reflecting path for each user, while judiciously determining the path scheduling strategies with the corresponding beamforming design to ensure the fairness.","Due to the presence of interference caused by undesired scattering of RISs, it is highly challenging to solve the formulated multi-RIS multi-path beamforming optimization problem.","To solve it, we first derive the optimal RISs' phase shifts and the corresponding reflecting path selection for each user based on its practical deployment location.","With the optimized multi-reflection paths, we obtain a feasible user grouping pattern for effective interference mitigation by constructing the maximum independent sets (MISs).","Finally, we propose a joint heuristic algorithm to iteratively update the beamforming vectors and the group scheduling policies to maximize the minimum equivalent data rate of all users."],"url":"http://arxiv.org/abs/2405.12530v1"}
{"created":"2024-05-21 06:37:03","title":"SirLLM: Streaming Infinite Retentive LLM","abstract":"As Large Language Models (LLMs) become increasingly prevalent in various domains, their ability to process inputs of any length and maintain a degree of memory becomes essential. However, the one-off input of overly long texts is limited, as studies have shown that when input lengths exceed the LLMs' pre-trained text length, there is a dramatic decline in text generation capabilities. Moreover, simply extending the length of pre-training texts is impractical due to the difficulty in obtaining long text data and the substantial memory consumption costs this would entail for LLMs. Recent efforts have employed streaming inputs to alleviate the pressure of excessively long text inputs, but this approach can significantly impair the model's long-term memory capabilities.   Motivated by this challenge, we introduce Streaming Infinite Retentive LLM (SirLLM), which allows LLMs to maintain longer memory during infinite-length dialogues without the need for fine-tuning. SirLLM utilizes the Token Entropy metric and a memory decay mechanism to filter key phrases, endowing LLMs with both long-lasting and flexible memory. We designed three distinct tasks and constructed three datasets to measure the effectiveness of SirLLM from various angles: (1) DailyDialog; (2) Grocery Shopping; (3) Rock-Paper-Scissors. Our experimental results robustly demonstrate that SirLLM can achieve stable and significant improvements across different LLMs and tasks, compellingly proving its effectiveness. When having a coversation, \"A sir could forget himself,\" but SirLLM never does! Our code is publicly available at https://github.com/Zoeyyao27/SirLLM","sentences":["As Large Language Models (LLMs) become increasingly prevalent in various domains, their ability to process inputs of any length and maintain a degree of memory becomes essential.","However, the one-off input of overly long texts is limited, as studies have shown that when input lengths exceed the LLMs' pre-trained text length, there is a dramatic decline in text generation capabilities.","Moreover, simply extending the length of pre-training texts is impractical due to the difficulty in obtaining long text data and the substantial memory consumption costs this would entail for LLMs.","Recent efforts have employed streaming inputs to alleviate the pressure of excessively long text inputs, but this approach can significantly impair the model's long-term memory capabilities.   ","Motivated by this challenge, we introduce Streaming Infinite Retentive LLM (SirLLM), which allows LLMs to maintain longer memory during infinite-length dialogues without the need for fine-tuning.","SirLLM utilizes the Token Entropy metric and a memory decay mechanism to filter key phrases, endowing LLMs with both long-lasting and flexible memory.","We designed three distinct tasks and constructed three datasets to measure the effectiveness of SirLLM from various angles: (1) DailyDialog; (2) Grocery Shopping; (3) Rock-Paper-Scissors.","Our experimental results robustly demonstrate that SirLLM can achieve stable and significant improvements across different LLMs and tasks, compellingly proving its effectiveness.","When having a coversation, \"A sir could forget himself,\" but SirLLM never does!","Our code is publicly available at https://github.com/Zoeyyao27/SirLLM"],"url":"http://arxiv.org/abs/2405.12528v1"}
{"created":"2024-05-21 06:30:00","title":"Cache Blocking of Distributed-Memory Parallel Matrix Power Kernels","abstract":"Sparse matrix-vector products (SpMVs) are a bottleneck in many scientific codes. Due to the heavy strain on the main memory interface from loading the sparse matrix and the possibly irregular memory access pattern, SpMV typically exhibits low arithmetic intensity. Repeating these products multiple times with the same matrix is required in many algorithms. This so-called matrix power kernel (MPK) provides an opportunity for data reuse since the same matrix data is loaded from main memory multiple times, an opportunity that has only recently been exploited successfully with the Recursive Algebraic Coloring Engine (RACE). Using RACE, one considers a graph based formulation of the SpMV and employs s level-based implementation of SpMV for reuse of relevant matrix data. However, the underlying data dependencies have restricted the use of this concept to shared memory parallelization and thus to single compute nodes. Enabling cache blocking for distributed-memory parallelization of MPK is challenging due to the need for explicit communication and synchronization of data in neighboring levels. In this work, we propose and implement a flexible method that interleaves the cache-blocking capabilities of RACE with an MPI communication scheme that fulfills all data dependencies among processes. Compared to a \"traditional\" distributed memory parallel MPK, our new Distributed Level-Blocked MPK yields substantial speed-ups on modern Intel and AMD architectures across a wide range of sparse matrices from various scientific applications. Finally, we address a modern quantum physics problem to demonstrate the applicability of our method, achieving a speed-up of up to 4x on 832 cores of an Intel Sapphire Rapids cluster.","sentences":["Sparse matrix-vector products (SpMVs) are a bottleneck in many scientific codes.","Due to the heavy strain on the main memory interface from loading the sparse matrix and the possibly irregular memory access pattern, SpMV typically exhibits low arithmetic intensity.","Repeating these products multiple times with the same matrix is required in many algorithms.","This so-called matrix power kernel (MPK) provides an opportunity for data reuse since the same matrix data is loaded from main memory multiple times, an opportunity that has only recently been exploited successfully with the Recursive Algebraic Coloring Engine (RACE).","Using RACE, one considers a graph based formulation of the SpMV and employs s level-based implementation of SpMV for reuse of relevant matrix data.","However, the underlying data dependencies have restricted the use of this concept to shared memory parallelization and thus to single compute nodes.","Enabling cache blocking for distributed-memory parallelization of MPK is challenging due to the need for explicit communication and synchronization of data in neighboring levels.","In this work, we propose and implement a flexible method that interleaves the cache-blocking capabilities of RACE with an MPI communication scheme that fulfills all data dependencies among processes.","Compared to a \"traditional\" distributed memory parallel MPK, our new Distributed Level-Blocked MPK yields substantial speed-ups on modern Intel and AMD architectures across a wide range of sparse matrices from various scientific applications.","Finally, we address a modern quantum physics problem to demonstrate the applicability of our method, achieving a speed-up of up to 4x on 832 cores of an Intel Sapphire Rapids cluster."],"url":"http://arxiv.org/abs/2405.12525v1"}
{"created":"2024-05-21 06:27:12","title":"Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models","abstract":"Machine unlearning empowers individuals with the `right to be forgotten' by removing their private or sensitive information encoded in machine learning models. However, it remains uncertain whether MU can be effectively applied to Multimodal Large Language Models (MLLMs), particularly in scenarios of forgetting the leaked visual data of concepts. To overcome the challenge, we propose an efficient method, Single Image Unlearning (SIU), to unlearn the visual recognition of a concept by fine-tuning a single associated image for few steps. SIU consists of two key aspects: (i) Constructing Multifaceted fine-tuning data. We introduce four targets, based on which we construct fine-tuning data for the concepts to be forgotten; (ii) Jointly training loss. To synchronously forget the visual recognition of concepts and preserve the utility of MLLMs, we fine-tune MLLMs through a novel Dual Masked KL-divergence Loss combined with Cross Entropy loss. Alongside our method, we establish MMUBench, a new benchmark for MU in MLLMs and introduce a collection of metrics for its evaluation. Experimental results on MMUBench show that SIU completely surpasses the performance of existing methods. Furthermore, we surprisingly find that SIU can avoid invasive membership inference attacks and jailbreak attacks. To the best of our knowledge, we are the first to explore MU in MLLMs. We will release the code and benchmark in the near future.","sentences":["Machine unlearning empowers individuals with the `right to be forgotten' by removing their private or sensitive information encoded in machine learning models.","However, it remains uncertain whether MU can be effectively applied to Multimodal Large Language Models (MLLMs), particularly in scenarios of forgetting the leaked visual data of concepts.","To overcome the challenge, we propose an efficient method, Single Image Unlearning (SIU), to unlearn the visual recognition of a concept by fine-tuning a single associated image for few steps.","SIU consists of two key aspects: (i) Constructing Multifaceted fine-tuning data.","We introduce four targets, based on which we construct fine-tuning data for the concepts to be forgotten; (ii) Jointly training loss.","To synchronously forget the visual recognition of concepts and preserve the utility of MLLMs, we fine-tune MLLMs through a novel Dual Masked KL-divergence Loss combined with Cross Entropy loss.","Alongside our method, we establish MMUBench, a new benchmark for MU in MLLMs and introduce a collection of metrics for its evaluation.","Experimental results on MMUBench show that SIU completely surpasses the performance of existing methods.","Furthermore, we surprisingly find that SIU can avoid invasive membership inference attacks and jailbreak attacks.","To the best of our knowledge, we are the first to explore MU in MLLMs.","We will release the code and benchmark in the near future."],"url":"http://arxiv.org/abs/2405.12523v1"}
{"created":"2024-05-21 06:23:47","title":"Unleash Graph Neural Networks from Heavy Tuning","abstract":"Graph Neural Networks (GNNs) are deep-learning architectures designed for graph-type data, where understanding relationships among individual observations is crucial. However, achieving promising GNN performance, especially on unseen data, requires comprehensive hyperparameter tuning and meticulous training. Unfortunately, these processes come with high computational costs and significant human effort. Additionally, conventional searching algorithms such as grid search may result in overfitting on validation data, diminishing generalization accuracy. To tackle these challenges, we propose a graph conditional latent diffusion framework (GNN-Diff) to generate high-performing GNNs directly by learning from checkpoints saved during a light-tuning coarse search. Our method: (1) unleashes GNN training from heavy tuning and complex search space design; (2) produces GNN parameters that outperform those obtained through comprehensive grid search; and (3) establishes higher-quality generation for GNNs compared to diffusion frameworks designed for general neural networks.","sentences":["Graph Neural Networks (GNNs) are deep-learning architectures designed for graph-type data, where understanding relationships among individual observations is crucial.","However, achieving promising GNN performance, especially on unseen data, requires comprehensive hyperparameter tuning and meticulous training.","Unfortunately, these processes come with high computational costs and significant human effort.","Additionally, conventional searching algorithms such as grid search may result in overfitting on validation data, diminishing generalization accuracy.","To tackle these challenges, we propose a graph conditional latent diffusion framework (GNN-Diff) to generate high-performing GNNs directly by learning from checkpoints saved during a light-tuning coarse search.","Our method: (1) unleashes GNN training from heavy tuning and complex search space design; (2) produces GNN parameters that outperform those obtained through comprehensive grid search; and (3) establishes higher-quality generation for GNNs compared to diffusion frameworks designed for general neural networks."],"url":"http://arxiv.org/abs/2405.12521v1"}
{"created":"2024-05-21 06:16:42","title":"MOSS: A Large-scale Open Microscopic Traffic Simulation System","abstract":"In the research of Intelligent Transportation Systems (ITS), traffic simulation is a key procedure for the evaluation of new methods and optimization of strategies. However, existing traffic simulation systems face two challenges. First, how to balance simulation scale with realism is a dilemma. Second, it is hard to simulate realistic results, which requires realistic travel demand data and simulator. These problems limit computer-aided optimization of traffic management strategies for large-scale road networks and reduce the usability of traffic simulations in areas where real-world travel demand data are lacking. To address these problems, we design and implement MObility Simulation System (MOSS). MOSS adopts GPU acceleration to significantly improve the efficiency and scale of microscopic traffic simulation, which enables realistic and fast simulations for large-scale road networks. It provides realistic travel Origin-Destination (OD) matrices generation through a pre-trained generative neural network model based on publicly available data on a global scale, such as satellite imagery, to help researchers build meaningful travel demand data. It also provides a complete open toolchain to help users with road network construction, demand generation, simulation, and result analysis. The whole toolchain including the simulator can be accessed at https://moss.fiblab.net and the codes are open-source for community collaboration.","sentences":["In the research of Intelligent Transportation Systems (ITS), traffic simulation is a key procedure for the evaluation of new methods and optimization of strategies.","However, existing traffic simulation systems face two challenges.","First, how to balance simulation scale with realism is a dilemma.","Second, it is hard to simulate realistic results, which requires realistic travel demand data and simulator.","These problems limit computer-aided optimization of traffic management strategies for large-scale road networks and reduce the usability of traffic simulations in areas where real-world travel demand data are lacking.","To address these problems, we design and implement MObility Simulation System (MOSS).","MOSS adopts GPU acceleration to significantly improve the efficiency and scale of microscopic traffic simulation, which enables realistic and fast simulations for large-scale road networks.","It provides realistic travel Origin-Destination (OD) matrices generation through a pre-trained generative neural network model based on publicly available data on a global scale, such as satellite imagery, to help researchers build meaningful travel demand data.","It also provides a complete open toolchain to help users with road network construction, demand generation, simulation, and result analysis.","The whole toolchain including the simulator can be accessed at https://moss.fiblab.net and the codes are open-source for community collaboration."],"url":"http://arxiv.org/abs/2405.12520v1"}
{"created":"2024-05-21 05:34:34","title":"Compiler support for semi-manual AoS-to-SoA conversions with data views","abstract":"The C programming language and its cousins such as C++ stipulate the static storage of sets of structured data: Developers have to commit to one, invariant data model -- typically a structure-of-arrays (SoA) or an array-of-structs (AoS) -- unless they manually rearrange, i.e.~convert it throughout the computation. Whether AoS or SoA is favourable depends on the execution context and algorithm step. We propose a language extension based upon C++ attributes through which developers can guide the compiler what memory arrangements are to be used. The compiler can then automatically convert (parts of) the data into the format of choice prior to a calculation and convert results back afterwards. As all conversions are merely annotations, it is straightforward for the developer to experiment with different storage formats and to pick subsets of data that are subject to memory rearrangements. Our work implements the annotations within Clang and demonstrates their potential impact through a smoothed particle hydrodynamics (SPH) code.","sentences":["The C programming language and its cousins such as C++ stipulate the static storage of sets of structured data: Developers have to commit to one, invariant data model -- typically a structure-of-arrays (SoA) or an array-of-structs (AoS) -- unless they manually rearrange, i.e.~convert it throughout the computation.","Whether AoS or SoA is favourable depends on the execution context and algorithm step.","We propose a language extension based upon C++ attributes through which developers can guide the compiler what memory arrangements are to be used.","The compiler can then automatically convert (parts of) the data into the format of choice prior to a calculation and convert results back afterwards.","As all conversions are merely annotations, it is straightforward for the developer to experiment with different storage formats and to pick subsets of data that are subject to memory rearrangements.","Our work implements the annotations within Clang and demonstrates their potential impact through a smoothed particle hydrodynamics (SPH) code."],"url":"http://arxiv.org/abs/2405.12507v1"}
{"created":"2024-05-21 05:31:03","title":"NOVA-3D: Non-overlapped Views for 3D Anime Character Reconstruction","abstract":"In the animation industry, 3D modelers typically rely on front and back non-overlapped concept designs to guide the 3D modeling of anime characters. However, there is currently a lack of automated approaches for generating anime characters directly from these 2D designs. In light of this, we explore a novel task of reconstructing anime characters from non-overlapped views. This presents two main challenges: existing multi-view approaches cannot be directly applied due to the absence of overlapping regions, and there is a scarcity of full-body anime character data and standard benchmarks. To bridge the gap, we present Non-Overlapped Views for 3D \\textbf{A}nime Character Reconstruction (NOVA-3D), a new framework that implements a method for view-aware feature fusion to learn 3D-consistent features effectively and synthesizes full-body anime characters from non-overlapped front and back views directly. To facilitate this line of research, we collected the NOVA-Human dataset, which comprises multi-view images and accurate camera parameters for 3D anime characters. Extensive experiments demonstrate that the proposed method outperforms baseline approaches, achieving superior reconstruction of anime characters with exceptional detail fidelity. In addition, to further verify the effectiveness of our method, we applied it to the animation head reconstruction task and improved the state-of-the-art baseline to 94.453 in SSIM, 7.726 in LPIPS, and 19.575 in PSNR on average. Codes and datasets are available at https://wanghongsheng01.github.io/NOVA-3D/.","sentences":["In the animation industry, 3D modelers typically rely on front and back non-overlapped concept designs to guide the 3D modeling of anime characters.","However, there is currently a lack of automated approaches for generating anime characters directly from these 2D designs.","In light of this, we explore a novel task of reconstructing anime characters from non-overlapped views.","This presents two main challenges: existing multi-view approaches cannot be directly applied due to the absence of overlapping regions, and there is a scarcity of full-body anime character data and standard benchmarks.","To bridge the gap, we present Non-Overlapped Views for 3D \\textbf{A}nime Character Reconstruction (NOVA-3D), a new framework that implements a method for view-aware feature fusion to learn 3D-consistent features effectively and synthesizes full-body anime characters from non-overlapped front and back views directly.","To facilitate this line of research, we collected the NOVA-Human dataset, which comprises multi-view images and accurate camera parameters for 3D anime characters.","Extensive experiments demonstrate that the proposed method outperforms baseline approaches, achieving superior reconstruction of anime characters with exceptional detail fidelity.","In addition, to further verify the effectiveness of our method, we applied it to the animation head reconstruction task and improved the state-of-the-art baseline to 94.453 in SSIM, 7.726 in LPIPS, and 19.575 in PSNR on average.","Codes and datasets are available at https://wanghongsheng01.github.io/NOVA-3D/."],"url":"http://arxiv.org/abs/2405.12505v1"}
{"created":"2024-05-21 05:17:43","title":"EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy","abstract":"Unsupervised Outlier Detection (UOD) is an important data mining task. With the advance of deep learning, deep Outlier Detection (OD) has received broad interest. Most deep UOD models are trained exclusively on clean datasets to learn the distribution of the normal data, which requires huge manual efforts to clean the real-world data if possible. Instead of relying on clean datasets, some approaches directly train and detect on unlabeled contaminated datasets, leading to the need for methods that are robust to such conditions. Ensemble methods emerged as a superior solution to enhance model robustness against contaminated training sets. However, the training time is greatly increased by the ensemble.   In this study, we investigate the impact of outliers on the training phase, aiming to halt training on unlabeled contaminated datasets before performance degradation. Initially, we noted that blending normal and anomalous data causes AUC fluctuations, a label-dependent measure of detection accuracy. To circumvent the need for labels, we propose a zero-label entropy metric named Loss Entropy for loss distribution, enabling us to infer optimal stopping points for training without labels. Meanwhile, we theoretically demonstrate negative correlation between entropy metric and the label-based AUC. Based on this, we develop an automated early-stopping algorithm, EntropyStop, which halts training when loss entropy suggests the maximum model detection capability. We conduct extensive experiments on ADBench (including 47 real datasets), and the overall results indicate that AutoEncoder (AE) enhanced by our approach not only achieves better performance than ensemble AEs but also requires under 1\\% of training time. Lastly, our proposed metric and early-stopping approach are evaluated on other deep OD models, exhibiting their broad potential applicability.","sentences":["Unsupervised Outlier Detection (UOD) is an important data mining task.","With the advance of deep learning, deep Outlier Detection (OD) has received broad interest.","Most deep UOD models are trained exclusively on clean datasets to learn the distribution of the normal data, which requires huge manual efforts to clean the real-world data if possible.","Instead of relying on clean datasets, some approaches directly train and detect on unlabeled contaminated datasets, leading to the need for methods that are robust to such conditions.","Ensemble methods emerged as a superior solution to enhance model robustness against contaminated training sets.","However, the training time is greatly increased by the ensemble.   ","In this study, we investigate the impact of outliers on the training phase, aiming to halt training on unlabeled contaminated datasets before performance degradation.","Initially, we noted that blending normal and anomalous data causes AUC fluctuations, a label-dependent measure of detection accuracy.","To circumvent the need for labels, we propose a zero-label entropy metric named Loss Entropy for loss distribution, enabling us to infer optimal stopping points for training without labels.","Meanwhile, we theoretically demonstrate negative correlation between entropy metric and the label-based AUC.","Based on this, we develop an automated early-stopping algorithm, EntropyStop, which halts training when loss entropy suggests the maximum model detection capability.","We conduct extensive experiments on ADBench (including 47 real datasets), and the overall results indicate that AutoEncoder (AE) enhanced by our approach not only achieves better performance than ensemble AEs but also requires under 1\\% of training time.","Lastly, our proposed metric and early-stopping approach are evaluated on other deep OD models, exhibiting their broad potential applicability."],"url":"http://arxiv.org/abs/2405.12502v1"}
{"created":"2024-05-21 05:00:30","title":"Entropic associative memory for real world images","abstract":"The entropic associative memory (EAM) is a computational model of natural memory incorporating some of its putative properties of being associative, distributed, declarative, abstractive and constructive. Previous experiments satisfactorily tested the model on structured, homogeneous and conventional data: images of manuscripts digits and letters, images of clothing, and phone representations. In this work we show that EAM appropriately stores, recognizes and retrieves complex and unconventional images of animals and vehicles. Additionally, the memory system generates meaningful retrieval association chains for such complex images. The retrieved objects can be seen as proper memories, associated recollections or products of imagination.","sentences":["The entropic associative memory (EAM) is a computational model of natural memory incorporating some of its putative properties of being associative, distributed, declarative, abstractive and constructive.","Previous experiments satisfactorily tested the model on structured, homogeneous and conventional data: images of manuscripts digits and letters, images of clothing, and phone representations.","In this work we show that EAM appropriately stores, recognizes and retrieves complex and unconventional images of animals and vehicles.","Additionally, the memory system generates meaningful retrieval association chains for such complex images.","The retrieved objects can be seen as proper memories, associated recollections or products of imagination."],"url":"http://arxiv.org/abs/2405.12500v1"}
{"created":"2024-05-21 04:55:04","title":"RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error Bound for Approximate Nearest Neighbor Search","abstract":"Searching for approximate nearest neighbors (ANN) in the high-dimensional Euclidean space is a pivotal problem. Recently, with the help of fast SIMD-based implementations, Product Quantization (PQ) and its variants can often efficiently and accurately estimate the distances between the vectors and have achieved great success in the in-memory ANN search. Despite their empirical success, we note that these methods do not have a theoretical error bound and are observed to fail disastrously on some real-world datasets. Motivated by this, we propose a new randomized quantization method named RaBitQ, which quantizes $D$-dimensional vectors into $D$-bit strings. RaBitQ guarantees a sharp theoretical error bound and provides good empirical accuracy at the same time. In addition, we introduce efficient implementations of RaBitQ, supporting to estimate the distances with bitwise operations or SIMD-based operations. Extensive experiments on real-world datasets confirm that (1) our method outperforms PQ and its variants in terms of accuracy-efficiency trade-off by a clear margin and (2) its empirical performance is well-aligned with our theoretical analysis.","sentences":["Searching for approximate nearest neighbors (ANN) in the high-dimensional Euclidean space is a pivotal problem.","Recently, with the help of fast SIMD-based implementations, Product Quantization (PQ) and its variants can often efficiently and accurately estimate the distances between the vectors and have achieved great success in the in-memory ANN search.","Despite their empirical success, we note that these methods do not have a theoretical error bound and are observed to fail disastrously on some real-world datasets.","Motivated by this, we propose a new randomized quantization method named RaBitQ, which quantizes $D$-dimensional vectors into $D$-bit strings.","RaBitQ guarantees a sharp theoretical error bound and provides good empirical accuracy at the same time.","In addition, we introduce efficient implementations of RaBitQ, supporting to estimate the distances with bitwise operations or SIMD-based operations.","Extensive experiments on real-world datasets confirm that (1) our method outperforms PQ and its variants in terms of accuracy-efficiency trade-off by a clear margin and (2) its empirical performance is well-aligned with our theoretical analysis."],"url":"http://arxiv.org/abs/2405.12497v1"}
{"created":"2024-05-21 04:37:23","title":"Phishing Email Detection Using Inputs From Artificial Intelligence","abstract":"Enterprise security is increasingly being threatened by social engineering attacks, such as phishing, which deceive employees into giving access to enterprise data. To protect both the users themselves and enterprise data, more and more organizations provide cyber security training that seeks to teach employees/customers to identify and report suspicious content. By its very nature, such training seeks to focus on signals that are likely to persist across a wide range of attacks. Further, it expects the user to apply the learnings from these training on e-mail messages that were not filtered by existing, automatic enterprise security (e.g., spam filters and commercial phishing detection software). However, relying on such training now shifts the detection of phishing from an automatic process to a human driven one which is fallible especially when a user errs due to distraction, forgetfulness, etc. In this work we explore treating this type of detection as a natural language processing task and modifying training pipelines accordingly. We present a dataset with annotated labels where these labels are created from the classes of signals that users are typically asked to identify in such training. We also present baseline classifier models trained on these classes of labels. With a comparative analysis of performance between human annotators and the models on these labels, we provide insights which can contribute to the improvement of the respective curricula for both machine and human training.","sentences":["Enterprise security is increasingly being threatened by social engineering attacks, such as phishing, which deceive employees into giving access to enterprise data.","To protect both the users themselves and enterprise data, more and more organizations provide cyber security training that seeks to teach employees/customers to identify and report suspicious content.","By its very nature, such training seeks to focus on signals that are likely to persist across a wide range of attacks.","Further, it expects the user to apply the learnings from these training on e-mail messages that were not filtered by existing, automatic enterprise security (e.g., spam filters and commercial phishing detection software).","However, relying on such training now shifts the detection of phishing from an automatic process to a human driven one which is fallible especially when a user errs due to distraction, forgetfulness, etc.","In this work we explore treating this type of detection as a natural language processing task and modifying training pipelines accordingly.","We present a dataset with annotated labels where these labels are created from the classes of signals that users are typically asked to identify in such training.","We also present baseline classifier models trained on these classes of labels.","With a comparative analysis of performance between human annotators and the models on these labels, we provide insights which can contribute to the improvement of the respective curricula for both machine and human training."],"url":"http://arxiv.org/abs/2405.12494v1"}
{"created":"2024-05-21 04:24:47","title":"Bridging the Gap Between Domain-specific Frameworks and Multiple Hardware Devices","abstract":"The rapid development of domain-specific frameworks has presented us with a significant challenge: The current approach of implementing solutions on a case-by-case basis incurs a theoretical complexity of O(M*N), thereby increasing the cost of porting applications to different hardware platforms. To address these challenges, we propose a systematic methodology that effectively bridges the gap between domain-specific frameworks and multiple hardware devices, reducing porting complexity to O(M+N). The approach utilizes multi-layer abstractions. Different domain-specific abstractions are employed to represent applications from various domains. These abstractions are then transformed into a unified abstraction, which is subsequently translated into combinations of primitive operators. Finally, these operators are mapped to multiple hardware platforms. The implemented unified framework supports deep learning, classical machine learning, and data analysis across X86, ARM, RISC-V, IoT devices, and GPU. It outperforms existing solutions like scikit-learn, hummingbird, Spark, and pandas, achieving impressive speedups: 1.1x to 3.83x on X86 servers, 1.06x to 4.33x on ARM IoT devices, 1.25x to 3.72x on RISC-V IoT devices, and 1.93x on GPU. The source code is available at https://github.com/BenchCouncil/bridger.git.","sentences":["The rapid development of domain-specific frameworks has presented us with a significant challenge: The current approach of implementing solutions on a case-by-case basis incurs a theoretical complexity of O(M*N), thereby increasing the cost of porting applications to different hardware platforms.","To address these challenges, we propose a systematic methodology that effectively bridges the gap between domain-specific frameworks and multiple hardware devices, reducing porting complexity to O(M+N).","The approach utilizes multi-layer abstractions.","Different domain-specific abstractions are employed to represent applications from various domains.","These abstractions are then transformed into a unified abstraction, which is subsequently translated into combinations of primitive operators.","Finally, these operators are mapped to multiple hardware platforms.","The implemented unified framework supports deep learning, classical machine learning, and data analysis across X86, ARM, RISC-V, IoT devices, and GPU.","It outperforms existing solutions like scikit-learn, hummingbird, Spark, and pandas, achieving impressive speedups: 1.1x to 3.83x on X86 servers, 1.06x to 4.33x on ARM IoT devices, 1.25x to 3.72x on RISC-V IoT devices, and 1.93x on GPU.","The source code is available at https://github.com/BenchCouncil/bridger.git."],"url":"http://arxiv.org/abs/2405.12491v1"}
{"created":"2024-05-21 04:21:35","title":"Customize Your Own Paired Data via Few-shot Way","abstract":"Existing solutions to image editing tasks suffer from several issues. Though achieving remarkably satisfying generated results, some supervised methods require huge amounts of paired training data, which greatly limits their usages. The other unsupervised methods take full advantage of large-scale pre-trained priors, thus being strictly restricted to the domains where the priors are trained on and behaving badly in out-of-distribution cases. The task we focus on is how to enable the users to customize their desired effects through only few image pairs. In our proposed framework, a novel few-shot learning mechanism based on the directional transformations among samples is introduced and expands the learnable space exponentially. Adopting a diffusion model pipeline, we redesign the condition calculating modules in our model and apply several technical improvements. Experimental results demonstrate the capabilities of our method in various cases.","sentences":["Existing solutions to image editing tasks suffer from several issues.","Though achieving remarkably satisfying generated results, some supervised methods require huge amounts of paired training data, which greatly limits their usages.","The other unsupervised methods take full advantage of large-scale pre-trained priors, thus being strictly restricted to the domains where the priors are trained on and behaving badly in out-of-distribution cases.","The task we focus on is how to enable the users to customize their desired effects through only few image pairs.","In our proposed framework, a novel few-shot learning mechanism based on the directional transformations among samples is introduced and expands the learnable space exponentially.","Adopting a diffusion model pipeline, we redesign the condition calculating modules in our model and apply several technical improvements.","Experimental results demonstrate the capabilities of our method in various cases."],"url":"http://arxiv.org/abs/2405.12490v1"}
{"created":"2024-05-21 04:08:07","title":"Time Matters: Enhancing Pre-trained News Recommendation Models with Robust User Dwell Time Injection","abstract":"Large Language Models (LLMs) have revolutionized text comprehension, leading to State-of-the-Art (SOTA) news recommendation models that utilize LLMs for in-depth news understanding. Despite this, accurately modeling user preferences remains challenging due to the inherent uncertainty of click behaviors. Techniques like multi-head attention in Transformers seek to alleviate this by capturing interactions among clicks, yet they fall short in integrating explicit feedback signals. User Dwell Time emerges as a powerful indicator, offering the potential to enhance the weak signals emanating from clicks. Nonetheless, its real-world applicability is questionable, especially when dwell time data collection is subject to delays. To bridge this gap, this paper proposes two novel and robust dwell time injection strategies, namely Dwell time Weight (DweW) and Dwell time Aware (DweA). Dwe} concentrates on refining Effective User Clicks through detailed analysis of dwell time, integrating with initial behavioral inputs to construct a more robust user preference. DweA empowers the model with awareness of dwell time information, thereby facilitating autonomous adjustment of attention values in user modeling. This enhancement sharpens the model's ability to accurately identify user preferences. In our experiment using the real-world news dataset from MSN website, we validated that our two strategies significantly improve recommendation performance, favoring high-quality news. Crucially, our approaches exhibit robustness to user dwell time information, maintaining their ability to recommend high-quality content even in extreme cases where dwell time data is entirely missing.","sentences":["Large Language Models (LLMs) have revolutionized text comprehension, leading to State-of-the-Art (SOTA) news recommendation models that utilize LLMs for in-depth news understanding.","Despite this, accurately modeling user preferences remains challenging due to the inherent uncertainty of click behaviors.","Techniques like multi-head attention in Transformers seek to alleviate this by capturing interactions among clicks, yet they fall short in integrating explicit feedback signals.","User Dwell Time emerges as a powerful indicator, offering the potential to enhance the weak signals emanating from clicks.","Nonetheless, its real-world applicability is questionable, especially when dwell time data collection is subject to delays.","To bridge this gap, this paper proposes two novel and robust dwell time injection strategies, namely Dwell time Weight (DweW) and Dwell time Aware (DweA).","Dwe} concentrates on refining Effective User Clicks through detailed analysis of dwell time, integrating with initial behavioral inputs to construct a more robust user preference.","DweA empowers the model with awareness of dwell time information, thereby facilitating autonomous adjustment of attention values in user modeling.","This enhancement sharpens the model's ability to accurately identify user preferences.","In our experiment using the real-world news dataset from MSN website, we validated that our two strategies significantly improve recommendation performance, favoring high-quality news.","Crucially, our approaches exhibit robustness to user dwell time information, maintaining their ability to recommend high-quality content even in extreme cases where dwell time data is entirely missing."],"url":"http://arxiv.org/abs/2405.12486v1"}
{"created":"2024-05-21 03:12:50","title":"Optimizing Generative AI Networking: A Dual Perspective with Multi-Agent Systems and Mixture of Experts","abstract":"In the continued development of next-generation networking and artificial intelligence content generation (AIGC) services, the integration of multi-agent systems (MAS) and the mixture of experts (MoE) frameworks is becoming increasingly important. Motivated by this, this article studies the contrasting and converging of MAS and MoE in AIGC-enabled networking. First, we discuss the architectural designs, operational procedures, and inherent advantages of using MAS and MoE in generative AI to explore its functionality and applications fully. Next, we review the applications of MAS and MoE frameworks in content generation and resource allocation, emphasizing their impact on networking operations. Subsequently, we propose a novel multi-agent-enabled MoE-proximal policy optimization (MoE-PPO) framework for 3D object generation and data transfer scenarios. The framework uses MAS for dynamic task coordination of each network service provider agent and MoE for expert-driven execution of respective tasks, thereby improving overall system efficiency and adaptability. The simulation results demonstrate the effectiveness of our proposed framework and significantly improve the performance indicators under different network conditions. Finally, we outline potential future research directions.","sentences":["In the continued development of next-generation networking and artificial intelligence content generation (AIGC) services, the integration of multi-agent systems (MAS) and the mixture of experts (MoE) frameworks is becoming increasingly important.","Motivated by this, this article studies the contrasting and converging of MAS and MoE in AIGC-enabled networking.","First, we discuss the architectural designs, operational procedures, and inherent advantages of using MAS and MoE in generative AI to explore its functionality and applications fully.","Next, we review the applications of MAS and MoE frameworks in content generation and resource allocation, emphasizing their impact on networking operations.","Subsequently, we propose a novel multi-agent-enabled MoE-proximal policy optimization (MoE-PPO) framework for 3D object generation and data transfer scenarios.","The framework uses MAS for dynamic task coordination of each network service provider agent and MoE for expert-driven execution of respective tasks, thereby improving overall system efficiency and adaptability.","The simulation results demonstrate the effectiveness of our proposed framework and significantly improve the performance indicators under different network conditions.","Finally, we outline potential future research directions."],"url":"http://arxiv.org/abs/2405.12472v1"}
{"created":"2024-05-21 03:04:14","title":"Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue State Tracking","abstract":"This work demonstrates that substantial gains in zero-shot dialogue state tracking (DST) accuracy can be achieved by increasing the diversity of training data using synthetic data generation techniques. Current DST training resources are severely limited in the number of application domains and slot types they cover due to the high costs of data collection, resulting in limited adaptability to new domains. The presented work overcomes this challenge using a novel, fully automatic data generation approach to create synthetic zero-shot DST training resources. Unlike previous approaches for generating DST data, the presented approach generates entirely new application domains to generate dialogues, complete with silver dialogue state annotations and slot descriptions. This approach is used to create the D0T dataset for training zero-shot DST models, which covers an unprecedented 1,000+ domains. Experiments performed on the MultiWOZ benchmark indicate that training models on diverse synthetic data yields a performance improvement of +6.7% Joint Goal Accuracy, achieving results competitive with much larger models.","sentences":["This work demonstrates that substantial gains in zero-shot dialogue state tracking (DST) accuracy can be achieved by increasing the diversity of training data using synthetic data generation techniques.","Current DST training resources are severely limited in the number of application domains and slot types they cover due to the high costs of data collection, resulting in limited adaptability to new domains.","The presented work overcomes this challenge using a novel, fully automatic data generation approach to create synthetic zero-shot DST training resources.","Unlike previous approaches for generating DST data, the presented approach generates entirely new application domains to generate dialogues, complete with silver dialogue state annotations and slot descriptions.","This approach is used to create the D0T dataset for training zero-shot DST models, which covers an unprecedented 1,000+ domains.","Experiments performed on the MultiWOZ benchmark indicate that training models on diverse synthetic data yields a performance improvement of +6.7% Joint Goal Accuracy, achieving results competitive with much larger models."],"url":"http://arxiv.org/abs/2405.12468v1"}
{"created":"2024-05-21 02:41:40","title":"A finite element-based physics-informed operator learning framework for spatiotemporal partial differential equations on arbitrary domains","abstract":"We propose a novel finite element-based physics-informed operator learning framework that allows for predicting spatiotemporal dynamics governed by partial differential equations (PDEs). The proposed framework employs a loss function inspired by the finite element method (FEM) with the implicit Euler time integration scheme. A transient thermal conduction problem is considered to benchmark the performance. The proposed operator learning framework takes a temperature field at the current time step as input and predicts a temperature field at the next time step. The Galerkin discretized weak formulation of the heat equation is employed to incorporate physics into the loss function, which is coined finite operator learning (FOL). Upon training, the networks successfully predict the temperature evolution over time for any initial temperature field at high accuracy compared to the FEM solution. The framework is also confirmed to be applicable to a heterogeneous thermal conductivity and arbitrary geometry. The advantages of FOL can be summarized as follows: First, the training is performed in an unsupervised manner, avoiding the need for a large data set prepared from costly simulations or experiments. Instead, random temperature patterns generated by the Gaussian random process and the Fourier series, combined with constant temperature fields, are used as training data to cover possible temperature cases. Second, shape functions and backward difference approximation are exploited for the domain discretization, resulting in a purely algebraic equation. This enhances training efficiency, as one avoids time-consuming automatic differentiation when optimizing weights and biases while accepting possible discretization errors. Finally, thanks to the interpolation power of FEM, any arbitrary geometry can be handled with FOL, which is crucial to addressing various engineering application scenarios.","sentences":["We propose a novel finite element-based physics-informed operator learning framework that allows for predicting spatiotemporal dynamics governed by partial differential equations (PDEs).","The proposed framework employs a loss function inspired by the finite element method (FEM) with the implicit Euler time integration scheme.","A transient thermal conduction problem is considered to benchmark the performance.","The proposed operator learning framework takes a temperature field at the current time step as input and predicts a temperature field at the next time step.","The Galerkin discretized weak formulation of the heat equation is employed to incorporate physics into the loss function, which is coined finite operator learning (FOL).","Upon training, the networks successfully predict the temperature evolution over time for any initial temperature field at high accuracy compared to the FEM solution.","The framework is also confirmed to be applicable to a heterogeneous thermal conductivity and arbitrary geometry.","The advantages of FOL can be summarized as follows:","First, the training is performed in an unsupervised manner, avoiding the need for a large data set prepared from costly simulations or experiments.","Instead, random temperature patterns generated by the Gaussian random process and the Fourier series, combined with constant temperature fields, are used as training data to cover possible temperature cases.","Second, shape functions and backward difference approximation are exploited for the domain discretization, resulting in a purely algebraic equation.","This enhances training efficiency, as one avoids time-consuming automatic differentiation when optimizing weights and biases while accepting possible discretization errors.","Finally, thanks to the interpolation power of FEM, any arbitrary geometry can be handled with FOL, which is crucial to addressing various engineering application scenarios."],"url":"http://arxiv.org/abs/2405.12465v1"}
{"created":"2024-05-21 02:36:37","title":"Physics-based Scene Layout Generation from Human Motion","abstract":"Creating scenes for captured motions that achieve realistic human-scene interaction is crucial for 3D animation in movies or video games. As character motion is often captured in a blue-screened studio without real furniture or objects in place, there may be a discrepancy between the planned motion and the captured one. This gives rise to the need for automatic scene layout generation to relieve the burdens of selecting and positioning furniture and objects. Previous approaches cannot avoid artifacts like penetration and floating due to the lack of physical constraints. Furthermore, some heavily rely on specific data to learn the contact affordances, restricting the generalization ability to different motions. In this work, we present a physics-based approach that simultaneously optimizes a scene layout generator and simulates a moving human in a physics simulator. To attain plausible and realistic interaction motions, our method explicitly introduces physical constraints. To automatically recover and generate the scene layout, we minimize the motion tracking errors to identify the objects that can afford interaction. We use reinforcement learning to perform a dual-optimization of both the character motion imitation controller and the scene layout generator. To facilitate the optimization, we reshape the tracking rewards and devise pose prior guidance obtained from our estimated pseudo-contact labels. We evaluate our method using motions from SAMP and PROX, and demonstrate physically plausible scene layout reconstruction compared with the previous kinematics-based method.","sentences":["Creating scenes for captured motions that achieve realistic human-scene interaction is crucial for 3D animation in movies or video games.","As character motion is often captured in a blue-screened studio without real furniture or objects in place, there may be a discrepancy between the planned motion and the captured one.","This gives rise to the need for automatic scene layout generation to relieve the burdens of selecting and positioning furniture and objects.","Previous approaches cannot avoid artifacts like penetration and floating due to the lack of physical constraints.","Furthermore, some heavily rely on specific data to learn the contact affordances, restricting the generalization ability to different motions.","In this work, we present a physics-based approach that simultaneously optimizes a scene layout generator and simulates a moving human in a physics simulator.","To attain plausible and realistic interaction motions, our method explicitly introduces physical constraints.","To automatically recover and generate the scene layout, we minimize the motion tracking errors to identify the objects that can afford interaction.","We use reinforcement learning to perform a dual-optimization of both the character motion imitation controller and the scene layout generator.","To facilitate the optimization, we reshape the tracking rewards and devise pose prior guidance obtained from our estimated pseudo-contact labels.","We evaluate our method using motions from SAMP and PROX, and demonstrate physically plausible scene layout reconstruction compared with the previous kinematics-based method."],"url":"http://arxiv.org/abs/2405.12460v1"}
{"created":"2024-05-21 02:33:17","title":"PLM4Traj: Cognizing Movement Patterns and Travel Purposes from Trajectories with Pre-trained Language Models","abstract":"Spatio-temporal trajectories play a vital role in various spatio-temporal data mining tasks. Developing a versatile trajectory learning approach that can adapt to different tasks while ensuring high accuracy is crucial. This requires effectively extracting movement patterns and travel purposes embedded in trajectories. However, this task is challenging due to limitations in the size and quality of available trajectory datasets. On the other hand, pre-trained language models (PLMs) have shown great success in adapting to different tasks by training on large-scale, high-quality corpus datasets. Given the similarities between trajectories and sentences, there is potential in leveraging PLMs to enhance the development of a versatile and effective trajectory learning method. Nevertheless, vanilla PLMs are not tailored to handle the unique spatio-temporal features present in trajectories and lack the capability to extract movement patterns and travel purposes from them.   To overcome these obstacles, we propose a model called PLM4Traj that effectively utilizes PLMs to model trajectories. PLM4Traj leverages the strengths of PLMs to create a versatile trajectory learning approach while addressing the limitations of vanilla PLMs in modeling trajectories. Firstly, PLM4Traj incorporates a novel trajectory semantic embedder that enables PLMs to process spatio-temporal features in trajectories and extract movement patterns and travel purposes from them. Secondly, PLM4Traj introduces a novel trajectory prompt that integrates movement patterns and travel purposes into PLMs, while also allowing the model to adapt to various tasks. Extensive experiments conducted on two real-world datasets and two representative tasks demonstrate that PLM4Traj successfully achieves its design goals. Codes are available at https://github.com/Zeru19/PLM4Traj.","sentences":["Spatio-temporal trajectories play a vital role in various spatio-temporal data mining tasks.","Developing a versatile trajectory learning approach that can adapt to different tasks while ensuring high accuracy is crucial.","This requires effectively extracting movement patterns and travel purposes embedded in trajectories.","However, this task is challenging due to limitations in the size and quality of available trajectory datasets.","On the other hand, pre-trained language models (PLMs) have shown great success in adapting to different tasks by training on large-scale, high-quality corpus datasets.","Given the similarities between trajectories and sentences, there is potential in leveraging PLMs to enhance the development of a versatile and effective trajectory learning method.","Nevertheless, vanilla PLMs are not tailored to handle the unique spatio-temporal features present in trajectories and lack the capability to extract movement patterns and travel purposes from them.   ","To overcome these obstacles, we propose a model called PLM4Traj that effectively utilizes PLMs to model trajectories.","PLM4Traj leverages the strengths of PLMs to create a versatile trajectory learning approach while addressing the limitations of vanilla PLMs in modeling trajectories.","Firstly, PLM4Traj incorporates a novel trajectory semantic embedder that enables PLMs to process spatio-temporal features in trajectories and extract movement patterns and travel purposes from them.","Secondly, PLM4Traj introduces a novel trajectory prompt that integrates movement patterns and travel purposes into PLMs, while also allowing the model to adapt to various tasks.","Extensive experiments conducted on two real-world datasets and two representative tasks demonstrate that PLM4Traj successfully achieves its design goals.","Codes are available at https://github.com/Zeru19/PLM4Traj."],"url":"http://arxiv.org/abs/2405.12459v1"}
{"created":"2024-05-21 02:06:40","title":"Prompt-Enhanced Spatio-Temporal Graph Transfer Learning","abstract":"Spatio-temporal graph neural networks have demonstrated efficacy in capturing complex dependencies for urban computing tasks such as forecasting and kriging. However, their performance is constrained by the reliance on extensive data for training on specific tasks, which limits their adaptability to new urban domains with varied demands. Although transfer learning has been proposed to address this problem by leveraging knowledge across domains, cross-task generalization remains underexplored in spatio-temporal graph transfer learning methods due to the absence of a unified framework. To bridge this gap, we propose Spatio-Temporal Graph Prompting (STGP), a prompt-enhanced transfer learning framework capable of adapting to diverse tasks in data-scarce domains. Specifically, we first unify different tasks into a single template and introduce a task-agnostic network architecture that aligns with this template. This approach enables the capture of spatio-temporal dependencies shared across tasks. Furthermore, we employ learnable prompts to achieve domain and task transfer in a two-stage prompting pipeline, enabling the prompts to effectively capture domain knowledge and task-specific properties at each stage. Extensive experiments demonstrate that STGP outperforms state-of-the-art baselines in three downstream tasks forecasting, kriging, and extrapolation by a notable margin.","sentences":["Spatio-temporal graph neural networks have demonstrated efficacy in capturing complex dependencies for urban computing tasks such as forecasting and kriging.","However, their performance is constrained by the reliance on extensive data for training on specific tasks, which limits their adaptability to new urban domains with varied demands.","Although transfer learning has been proposed to address this problem by leveraging knowledge across domains, cross-task generalization remains underexplored in spatio-temporal graph transfer learning methods due to the absence of a unified framework.","To bridge this gap, we propose Spatio-Temporal Graph Prompting (STGP), a prompt-enhanced transfer learning framework capable of adapting to diverse tasks in data-scarce domains.","Specifically, we first unify different tasks into a single template and introduce a task-agnostic network architecture that aligns with this template.","This approach enables the capture of spatio-temporal dependencies shared across tasks.","Furthermore, we employ learnable prompts to achieve domain and task transfer in a two-stage prompting pipeline, enabling the prompts to effectively capture domain knowledge and task-specific properties at each stage.","Extensive experiments demonstrate that STGP outperforms state-of-the-art baselines in three downstream tasks forecasting, kriging, and extrapolation by a notable margin."],"url":"http://arxiv.org/abs/2405.12452v1"}
{"created":"2024-05-21 01:39:11","title":"FFCL: Forward-Forward Net with Cortical Loops, Training and Inference on Edge Without Backpropagation","abstract":"The Forward-Forward Learning (FFL) algorithm is a recently proposed solution for training neural networks without needing memory-intensive backpropagation. During training, labels accompany input data, classifying them as positive or negative inputs. Each layer learns its response to these inputs independently. In this study, we enhance the FFL with the following contributions: 1) We optimize label processing by segregating label and feature forwarding between layers, enhancing learning performance. 2) By revising label integration, we enhance the inference process, reduce computational complexity, and improve performance. 3) We introduce feedback loops akin to cortical loops in the brain, where information cycles through and returns to earlier neurons, enabling layers to combine complex features from previous layers with lower-level features, enhancing learning efficiency.","sentences":["The Forward-Forward Learning (FFL) algorithm is a recently proposed solution for training neural networks without needing memory-intensive backpropagation.","During training, labels accompany input data, classifying them as positive or negative inputs.","Each layer learns its response to these inputs independently.","In this study, we enhance the FFL with the following contributions: 1) We optimize label processing by segregating label and feature forwarding between layers, enhancing learning performance.","2) By revising label integration, we enhance the inference process, reduce computational complexity, and improve performance.","3) We introduce feedback loops akin to cortical loops in the brain, where information cycles through and returns to earlier neurons, enabling layers to combine complex features from previous layers with lower-level features, enhancing learning efficiency."],"url":"http://arxiv.org/abs/2405.12443v1"}
{"created":"2024-05-21 01:31:44","title":"No-Regret M${}^{\\natural}$-Concave Function Maximization: Stochastic Bandit Algorithms and NP-Hardness of Adversarial Full-Information Setting","abstract":"M${}^{\\natural}$-concave functions, a.k.a. gross substitute valuation functions, play a fundamental role in many fields, including discrete mathematics and economics. In practice, perfect knowledge of M${}^{\\natural}$-concave functions is often unavailable a priori, and we can optimize them only interactively based on some feedback. Motivated by such situations, we study online M${}^{\\natural}$-concave function maximization problems, which are interactive versions of the problem studied by Murota and Shioura (1999). For the stochastic bandit setting, we present $O(T^{-1/2})$-simple regret and $O(T^{2/3})$-regret algorithms under $T$ times access to unbiased noisy value oracles of M${}^{\\natural}$-concave functions. A key to proving these results is the robustness of the greedy algorithm to local errors in M${}^{\\natural}$-concave function maximization, which is one of our main technical results. While we obtain those positive results for the stochastic setting, another main result of our work is an impossibility in the adversarial setting. We prove that, even with full-information feedback, no algorithms that run in polynomial time per round can achieve $O(T^{1-c})$ regret for any constant $c > 0$ unless $\\mathsf{P} = \\mathsf{NP}$. Our proof is based on a reduction from the matroid intersection problem for three matroids, which would be a novel idea in the context of online learning.","sentences":["M${}^{\\natural}$-concave functions, a.k.a. gross substitute valuation functions, play a fundamental role in many fields, including discrete mathematics and economics.","In practice, perfect knowledge of M${}^{\\natural}$-concave functions is often unavailable a priori, and we can optimize them only interactively based on some feedback.","Motivated by such situations, we study online M${}^{\\natural}$-concave function maximization problems, which are interactive versions of the problem studied by Murota and Shioura (1999).","For the stochastic bandit setting, we present $O(T^{-1/2})$-simple regret and $O(T^{2/3})$-regret algorithms under $T$ times access to unbiased noisy value oracles of M${}^{\\natural}$-concave functions.","A key to proving these results is the robustness of the greedy algorithm to local errors in M${}^{\\natural}$-concave function maximization, which is one of our main technical results.","While we obtain those positive results for the stochastic setting, another main result of our work is an impossibility in the adversarial setting.","We prove that, even with full-information feedback, no algorithms that run in polynomial time per round can achieve $O(T^{1-c})$ regret for any constant $c > 0$ unless $\\mathsf{P} =","\\mathsf{NP}$. Our proof is based on a reduction from the matroid intersection problem for three matroids, which would be a novel idea in the context of online learning."],"url":"http://arxiv.org/abs/2405.12439v1"}
{"created":"2024-05-21 01:14:33","title":"Data Sharing at the Edge of the Network: A Disturbance Resilient Multi-modal ITS","abstract":"Mobility-as-a-Service (MaaS) is a paradigm that encourages the shift from private cars to more sustainable alternative mobility services. MaaS provides services that enhances and enables multiple modes of transport to operate seamlessly and bringing Multimodal Intelligent Transport Systems (M-ITS) closer to reality. This requires sharing and integration of data collected from multiple sources including modes of transports, sensors, and end-users' devices to allow a seamless and integrated services especially during unprecedented disturbances. This paper discusses the interactions among transportation modes, networks, potential disturbance scenarios, and adaptation strategies to mitigate their impact on MaaS. We particularly discuss the need to share data between the modes of transport and relevant entities that are at the vicinity of each other, taking advantage of edge computing technology to avoid any latency due to communication to the cloud and privacy concerns. However, when sharing at the edge, bandwidth, storage, and computational limitations must be considered.","sentences":["Mobility-as-a-Service (MaaS) is a paradigm that encourages the shift from private cars to more sustainable alternative mobility services.","MaaS provides services that enhances and enables multiple modes of transport to operate seamlessly and bringing Multimodal Intelligent Transport Systems (M-ITS) closer to reality.","This requires sharing and integration of data collected from multiple sources including modes of transports, sensors, and end-users' devices to allow a seamless and integrated services especially during unprecedented disturbances.","This paper discusses the interactions among transportation modes, networks, potential disturbance scenarios, and adaptation strategies to mitigate their impact on MaaS. We particularly discuss the need to share data between the modes of transport and relevant entities that are at the vicinity of each other, taking advantage of edge computing technology to avoid any latency due to communication to the cloud and privacy concerns.","However, when sharing at the edge, bandwidth, storage, and computational limitations must be considered."],"url":"http://arxiv.org/abs/2405.12431v1"}
{"created":"2024-05-20 23:59:26","title":"A Unified Linear Programming Framework for Offline Reward Learning from Human Demonstrations and Feedback","abstract":"Inverse Reinforcement Learning (IRL) and Reinforcement Learning from Human Feedback (RLHF) are pivotal methodologies in reward learning, which involve inferring and shaping the underlying reward function of sequential decision-making problems based on observed human demonstrations and feedback. Most prior work in reward learning has relied on prior knowledge or assumptions about decision or preference models, potentially leading to robustness issues. In response, this paper introduces a novel linear programming (LP) framework tailored for offline reward learning. Utilizing pre-collected trajectories without online exploration, this framework estimates a feasible reward set from the primal-dual optimality conditions of a suitably designed LP, and offers an optimality guarantee with provable sample efficiency. Our LP framework also enables aligning the reward functions with human feedback, such as pairwise trajectory comparison data, while maintaining computational tractability and sample efficiency. We demonstrate that our framework potentially achieves better performance compared to the conventional maximum likelihood estimation (MLE) approach through analytical examples and numerical experiments.","sentences":["Inverse Reinforcement Learning (IRL) and Reinforcement Learning from Human Feedback (RLHF) are pivotal methodologies in reward learning, which involve inferring and shaping the underlying reward function of sequential decision-making problems based on observed human demonstrations and feedback.","Most prior work in reward learning has relied on prior knowledge or assumptions about decision or preference models, potentially leading to robustness issues.","In response, this paper introduces a novel linear programming (LP) framework tailored for offline reward learning.","Utilizing pre-collected trajectories without online exploration, this framework estimates a feasible reward set from the primal-dual optimality conditions of a suitably designed LP, and offers an optimality guarantee with provable sample efficiency.","Our LP framework also enables aligning the reward functions with human feedback, such as pairwise trajectory comparison data, while maintaining computational tractability and sample efficiency.","We demonstrate that our framework potentially achieves better performance compared to the conventional maximum likelihood estimation (MLE) approach through analytical examples and numerical experiments."],"url":"http://arxiv.org/abs/2405.12421v1"}
{"created":"2024-05-20 23:53:42","title":"GeoMask3D: Geometrically Informed Mask Selection for Self-Supervised Point Cloud Learning in 3D","abstract":"We introduce a pioneering approach to self-supervised learning for point clouds, employing a geometrically informed mask selection strategy called GeoMask3D (GM3D) to boost the efficiency of Masked Auto Encoders (MAE). Unlike the conventional method of random masking, our technique utilizes a teacher-student model to focus on intricate areas within the data, guiding the model's focus toward regions with higher geometric complexity. This strategy is grounded in the hypothesis that concentrating on harder patches yields a more robust feature representation, as evidenced by the improved performance on downstream tasks. Our method also presents a complete-to-partial feature-level knowledge distillation technique designed to guide the prediction of geometric complexity utilizing a comprehensive context from feature-level information. Extensive experiments confirm our method's superiority over State-Of-The-Art (SOTA) baselines, demonstrating marked improvements in classification, and few-shot tasks.","sentences":["We introduce a pioneering approach to self-supervised learning for point clouds, employing a geometrically informed mask selection strategy called GeoMask3D (GM3D) to boost the efficiency of Masked Auto Encoders (MAE).","Unlike the conventional method of random masking, our technique utilizes a teacher-student model to focus on intricate areas within the data, guiding the model's focus toward regions with higher geometric complexity.","This strategy is grounded in the hypothesis that concentrating on harder patches yields a more robust feature representation, as evidenced by the improved performance on downstream tasks.","Our method also presents a complete-to-partial feature-level knowledge distillation technique designed to guide the prediction of geometric complexity utilizing a comprehensive context from feature-level information.","Extensive experiments confirm our method's superiority over State-Of-The-Art (SOTA) baselines, demonstrating marked improvements in classification, and few-shot tasks."],"url":"http://arxiv.org/abs/2405.12419v1"}
{"created":"2024-05-20 23:39:30","title":"The Power of Two in Token Systems","abstract":"In economies without monetary transfers, token systems serve as an alternative to sustain cooperation, alleviate free riding, and increase efficiency. This paper studies whether a token-based economy can be effective in marketplaces with thin exogenous supply. We consider a marketplace in which at each time period one agent requests a service, one agent provides the service, and one token (artificial currency) is used to pay for service provision. The number of tokens each agent has represents the difference between the amount of service provisions and service requests by the agent. We are interested in the behavior of this economy when very few agents are available to provide the requested service. Since balancing the number of tokens across agents is key to sustain cooperation, the agent with the minimum amount of tokens is selected to provide service among the available agents. When exactly one random agent is available to provide service, we show that the token distribution is unstable. However, already when just two random agents are available to provide service, the token distribution is stable, in the sense that agents' token balance is unlikely to deviate much from their initial endowment, and agents return to their initial endowment in finite expected time. Our results mirror the power of two choices paradigm in load balancing problems. Supported by numerical simulations using kidney exchange data, our findings suggest that token systems may generate efficient outcomes in kidney exchange marketplaces by sustaining cooperation between hospitals.","sentences":["In economies without monetary transfers, token systems serve as an alternative to sustain cooperation, alleviate free riding, and increase efficiency.","This paper studies whether a token-based economy can be effective in marketplaces with thin exogenous supply.","We consider a marketplace in which at each time period one agent requests a service, one agent provides the service, and one token (artificial currency) is used to pay for service provision.","The number of tokens each agent has represents the difference between the amount of service provisions and service requests by the agent.","We are interested in the behavior of this economy when very few agents are available to provide the requested service.","Since balancing the number of tokens across agents is key to sustain cooperation, the agent with the minimum amount of tokens is selected to provide service among the available agents.","When exactly one random agent is available to provide service, we show that the token distribution is unstable.","However, already when just two random agents are available to provide service, the token distribution is stable, in the sense that agents' token balance is unlikely to deviate much from their initial endowment, and agents return to their initial endowment in finite expected time.","Our results mirror the power of two choices paradigm in load balancing problems.","Supported by numerical simulations using kidney exchange data, our findings suggest that token systems may generate efficient outcomes in kidney exchange marketplaces by sustaining cooperation between hospitals."],"url":"http://arxiv.org/abs/2405.12414v1"}
{"created":"2024-05-20 23:30:07","title":"On Measuring Calibration of Discrete Probabilistic Neural Networks","abstract":"As machine learning systems become increasingly integrated into real-world applications, accurately representing uncertainty is crucial for enhancing their safety, robustness, and reliability. Training neural networks to fit high-dimensional probability distributions via maximum likelihood has become an effective method for uncertainty quantification. However, such models often exhibit poor calibration, leading to overconfident predictions. Traditional metrics like Expected Calibration Error (ECE) and Negative Log Likelihood (NLL) have limitations, including biases and parametric assumptions. This paper proposes a new approach using conditional kernel mean embeddings to measure calibration discrepancies without these biases and assumptions. Preliminary experiments on synthetic data demonstrate the method's potential, with future work planned for more complex applications.","sentences":["As machine learning systems become increasingly integrated into real-world applications, accurately representing uncertainty is crucial for enhancing their safety, robustness, and reliability.","Training neural networks to fit high-dimensional probability distributions via maximum likelihood has become an effective method for uncertainty quantification.","However, such models often exhibit poor calibration, leading to overconfident predictions.","Traditional metrics like Expected Calibration Error (ECE) and Negative Log Likelihood (NLL) have limitations, including biases and parametric assumptions.","This paper proposes a new approach using conditional kernel mean embeddings to measure calibration discrepancies without these biases and assumptions.","Preliminary experiments on synthetic data demonstrate the method's potential, with future work planned for more complex applications."],"url":"http://arxiv.org/abs/2405.12412v1"}
{"created":"2024-05-20 23:28:38","title":"Local search for valued constraint satisfaction parameterized by treedepth","abstract":"Sometimes local search algorithms cannot efficiently find even local peaks. To understand why, I look at the structure of ascents in fitness landscapes from valued constraint satisfaction problems (VCSPs). Given a VCSP with a constraint graph of treedepth $d$, I prove that from any initial assignment there always exists an ascent of length $2^{d + 1} \\cdot n$ to a local peak. This means that short ascents always exist in fitness landscapes from constraint graphs of logarithmic treedepth, and thus also for all VCSPs of bounded treewidth. But this does not mean that local search algorithms will always find and follow such short ascents in sparse VCSPs. I show that with loglog treedepth, superpolynomial ascents exist; and for polylog treedepth, there are initial assignments from which all ascents are superpolynomial. Together, these results suggest that the study of sparse VCSPs can help us better understand the barriers to efficient local search.","sentences":["Sometimes local search algorithms cannot efficiently find even local peaks.","To understand why, I look at the structure of ascents in fitness landscapes from valued constraint satisfaction problems (VCSPs).","Given a VCSP with a constraint graph of treedepth $d$, I prove that from any initial assignment there always exists an ascent of length $2^{d + 1} \\cdot n$ to a local peak.","This means that short ascents always exist in fitness landscapes from constraint graphs of logarithmic treedepth, and thus also for all VCSPs of bounded treewidth.","But this does not mean that local search algorithms will always find and follow such short ascents in sparse VCSPs.","I show that with loglog treedepth, superpolynomial ascents exist; and for polylog treedepth, there are initial assignments from which all ascents are superpolynomial.","Together, these results suggest that the study of sparse VCSPs can help us better understand the barriers to efficient local search."],"url":"http://arxiv.org/abs/2405.12410v1"}
{"created":"2024-05-20 22:35:34","title":"ASMR: Activation-sharing Multi-resolution Coordinate Networks For Efficient Inference","abstract":"Coordinate network or implicit neural representation (INR) is a fast-emerging method for encoding natural signals (such as images and videos) with the benefits of a compact neural representation. While numerous methods have been proposed to increase the encoding capabilities of an INR, an often overlooked aspect is the inference efficiency, usually measured in multiply-accumulate (MAC) count. This is particularly critical in use cases where inference throughput is greatly limited by hardware constraints. To this end, we propose the Activation-Sharing Multi-Resolution (ASMR) coordinate network that combines multi-resolution coordinate decomposition with hierarchical modulations. Specifically, an ASMR model enables the sharing of activations across grids of the data. This largely decouples its inference cost from its depth which is directly correlated to its reconstruction capability, and renders a near O(1) inference complexity irrespective of the number of layers. Experiments show that ASMR can reduce the MAC of a vanilla SIREN model by up to 500x while achieving an even higher reconstruction quality than its SIREN baseline.","sentences":["Coordinate network or implicit neural representation (INR) is a fast-emerging method for encoding natural signals (such as images and videos) with the benefits of a compact neural representation.","While numerous methods have been proposed to increase the encoding capabilities of an INR, an often overlooked aspect is the inference efficiency, usually measured in multiply-accumulate (MAC) count.","This is particularly critical in use cases where inference throughput is greatly limited by hardware constraints.","To this end, we propose the Activation-Sharing Multi-Resolution (ASMR) coordinate network that combines multi-resolution coordinate decomposition with hierarchical modulations.","Specifically, an ASMR model enables the sharing of activations across grids of the data.","This largely decouples its inference cost from its depth which is directly correlated to its reconstruction capability, and renders a near O(1) inference complexity irrespective of the number of layers.","Experiments show that ASMR can reduce the MAC of a vanilla SIREN model by up to 500x while achieving an even higher reconstruction quality than its SIREN baseline."],"url":"http://arxiv.org/abs/2405.12398v1"}
{"created":"2024-05-20 21:43:43","title":"Conformal Counterfactual Inference under Hidden Confounding","abstract":"Personalized decision making requires the knowledge of potential outcomes under different treatments, and confidence intervals about the potential outcomes further enrich this decision-making process and improve its reliability in high-stakes scenarios. Predicting potential outcomes along with its uncertainty in a counterfactual world poses the foundamental challenge in causal inference. Existing methods that construct confidence intervals for counterfactuals either rely on the assumption of strong ignorability, or need access to un-identifiable lower and upper bounds that characterize the difference between observational and interventional distributions. To overcome these limitations, we first propose a novel approach wTCP-DR based on transductive weighted conformal prediction, which provides confidence intervals for counterfactual outcomes with marginal converage guarantees, even under hidden confounding. With less restrictive assumptions, our approach requires access to a fraction of interventional data (from randomized controlled trials) to account for the covariate shift from observational distributoin to interventional distribution. Theoretical results explicitly demonstrate the conditions under which our algorithm is strictly advantageous to the naive method that only uses interventional data. After ensuring valid intervals on counterfactuals, it is straightforward to construct intervals for individual treatment effects (ITEs). We demonstrate our method across synthetic and real-world data, including recommendation systems, to verify the superiority of our methods compared against state-of-the-art baselines in terms of both coverage and efficiency","sentences":["Personalized decision making requires the knowledge of potential outcomes under different treatments, and confidence intervals about the potential outcomes further enrich this decision-making process and improve its reliability in high-stakes scenarios.","Predicting potential outcomes along with its uncertainty in a counterfactual world poses the foundamental challenge in causal inference.","Existing methods that construct confidence intervals for counterfactuals either rely on the assumption of strong ignorability, or need access to un-identifiable lower and upper bounds that characterize the difference between observational and interventional distributions.","To overcome these limitations, we first propose a novel approach wTCP-DR based on transductive weighted conformal prediction, which provides confidence intervals for counterfactual outcomes with marginal converage guarantees, even under hidden confounding.","With less restrictive assumptions, our approach requires access to a fraction of interventional data (from randomized controlled trials) to account for the covariate shift from observational distributoin to interventional distribution.","Theoretical results explicitly demonstrate the conditions under which our algorithm is strictly advantageous to the naive method that only uses interventional data.","After ensuring valid intervals on counterfactuals, it is straightforward to construct intervals for individual treatment effects (ITEs).","We demonstrate our method across synthetic and real-world data, including recommendation systems, to verify the superiority of our methods compared against state-of-the-art baselines in terms of both coverage and efficiency"],"url":"http://arxiv.org/abs/2405.12387v1"}
{"created":"2024-05-20 21:40:08","title":"SciJava Ops: An Improved Algorithms Framework for Fiji and Beyond","abstract":"Many scientific software platforms provide plugin mechanisms that simplify the integration, deployment, and execution of externally developed functionality. One of the most widely used platforms in the imaging space is Fiji, a popular open-source application for scientific image analysis. Fiji incorporates and builds on the ImageJ and ImageJ2 platforms, which provide a powerful plugin architecture used by thousands of plugins to solve a wide variety of problems. This capability is a major part of Fiji's success, and it has become a widely used biological image analysis tool and a target for new functionality. However, a plugin-based software architecture cannot unify disparate platforms operating on incompatible data structures; interoperability necessitates the creation of adaptation or \"bridge\" layers to translate data and invoke functionality. As a result, while platforms like Fiji enable a high degree of interconnectivity and extensibility, they were not fundamentally designed to integrate across the many data types, programming languages, and architectural differences of various software platforms.To help address this challenge, we present SciJava Ops, a foundational software library for expressing algorithms as plugins in a unified and extensible way. Continuing the evolution of Fiji's SciJava plugin mechanism, SciJava Ops enables users to harness algorithms from various software platforms within a central execution environment. In addition, SciJava Ops automatically adapts data into the most appropriate structure for each algorithm, allowing users to freely and transparently combine algorithms from otherwise incompatible tools. While SciJava Ops is initially distributed as a Fiji update site, the framework does not require Fiji, ImageJ, or ImageJ2, and would be suitable for integration with additional image analysis platforms.","sentences":["Many scientific software platforms provide plugin mechanisms that simplify the integration, deployment, and execution of externally developed functionality.","One of the most widely used platforms in the imaging space is Fiji, a popular open-source application for scientific image analysis.","Fiji incorporates and builds on the ImageJ and ImageJ2 platforms, which provide a powerful plugin architecture used by thousands of plugins to solve a wide variety of problems.","This capability is a major part of Fiji's success, and it has become a widely used biological image analysis tool and a target for new functionality.","However, a plugin-based software architecture cannot unify disparate platforms operating on incompatible data structures; interoperability necessitates the creation of adaptation or \"bridge\" layers to translate data and invoke functionality.","As a result, while platforms like Fiji enable a high degree of interconnectivity and extensibility, they were not fundamentally designed to integrate across the many data types, programming languages, and architectural differences of various software platforms.","To help address this challenge, we present SciJava Ops, a foundational software library for expressing algorithms as plugins in a unified and extensible way.","Continuing the evolution of Fiji's SciJava plugin mechanism, SciJava Ops enables users to harness algorithms from various software platforms within a central execution environment.","In addition, SciJava Ops automatically adapts data into the most appropriate structure for each algorithm, allowing users to freely and transparently combine algorithms from otherwise incompatible tools.","While SciJava Ops is initially distributed as a Fiji update site, the framework does not require Fiji, ImageJ, or ImageJ2, and would be suitable for integration with additional image analysis platforms."],"url":"http://arxiv.org/abs/2405.12385v1"}
{"created":"2024-05-20 21:39:19","title":"Vulnerability Detection with Deep Learning","abstract":"Deep learning has been shown to be a promising tool in detecting software vulnerabilities. In this work, we train neural networks with program slices extracted from the source code of C/C++ programs to detect software vulnerabilities. The program slices capture the syntax and semantic characteristics of vulnerability-related program constructs, including API function call, array usage, pointer usage, and arithmetic expression. To achieve a strong prediction model for both vulnerable code and non-vulnerable code, we compare different types of training data, different optimizers, and different types of neural networks. Our result shows that combining different types of characteristics of source code and using a balanced number of vulnerable program slices and non-vulnerable program slices produce a balanced accuracy in predicting both vulnerable code and non-vulnerable code. Among different neural networks, BGRU with the ADAM optimizer performs the best in detecting software vulnerabilities with an accuracy of 92.49%.","sentences":["Deep learning has been shown to be a promising tool in detecting software vulnerabilities.","In this work, we train neural networks with program slices extracted from the source code of C/C++ programs to detect software vulnerabilities.","The program slices capture the syntax and semantic characteristics of vulnerability-related program constructs, including API function call, array usage, pointer usage, and arithmetic expression.","To achieve a strong prediction model for both vulnerable code and non-vulnerable code, we compare different types of training data, different optimizers, and different types of neural networks.","Our result shows that combining different types of characteristics of source code and using a balanced number of vulnerable program slices and non-vulnerable program slices produce a balanced accuracy in predicting both vulnerable code and non-vulnerable code.","Among different neural networks, BGRU with the ADAM optimizer performs the best in detecting software vulnerabilities with an accuracy of 92.49%."],"url":"http://arxiv.org/abs/2405.12384v1"}
{"created":"2024-05-20 20:52:11","title":"Algorithms for Generating Small Random Samples","abstract":"This report presents algorithms for generating small random samples without replacement. It considers two cases. It presents an algorithm for sampling a pair of distinct integers, and an algorithm for sampling a triple of distinct integers. The worst case runtime of both algorithms is constant, while the worst case runtime of common algorithms for the general case of sampling $k$ elements from a set of $n$ are linear in $n$. Java implementations of both algorithms are included in the open source library $\\rho\\mu$.","sentences":["This report presents algorithms for generating small random samples without replacement.","It considers two cases.","It presents an algorithm for sampling a pair of distinct integers, and an algorithm for sampling a triple of distinct integers.","The worst case runtime of both algorithms is constant, while the worst case runtime of common algorithms for the general case of sampling $k$ elements from a set of $n$ are linear in $n$. Java implementations of both algorithms are included in the open source library $\\rho\\mu$."],"url":"http://arxiv.org/abs/2405.12371v1"}
{"created":"2024-05-20 20:37:44","title":"Layout Agnostic Human Activity Recognition in Smart Homes through Textual Descriptions Of Sensor Triggers (TDOST)","abstract":"Human activity recognition (HAR) using ambient sensors in smart homes has numerous applications for human healthcare and wellness. However, building general-purpose HAR models that can be deployed to new smart home environments requires a significant amount of annotated sensor data and training overhead. Most smart homes vary significantly in their layouts, i.e., floor plans and the specifics of sensors embedded, resulting in low generalizability of HAR models trained for specific homes. We address this limitation by introducing a novel, layout-agnostic modeling approach for HAR systems in smart homes that utilizes the transferrable representational capacity of natural language descriptions of raw sensor data. To this end, we generate Textual Descriptions Of Sensor Triggers (TDOST) that encapsulate the surrounding trigger conditions and provide cues for underlying activities to the activity recognition models. Leveraging textual embeddings, rather than raw sensor data, we create activity recognition systems that predict standard activities across homes without either (re-)training or adaptation on target homes. Through an extensive evaluation, we demonstrate the effectiveness of TDOST-based models in unseen smart homes through experiments on benchmarked CASAS datasets. Furthermore, we conduct a detailed analysis of how the individual components of our approach affect downstream activity recognition performance.","sentences":["Human activity recognition (HAR) using ambient sensors in smart homes has numerous applications for human healthcare and wellness.","However, building general-purpose HAR models that can be deployed to new smart home environments requires a significant amount of annotated sensor data and training overhead.","Most smart homes vary significantly in their layouts, i.e., floor plans and the specifics of sensors embedded, resulting in low generalizability of HAR models trained for specific homes.","We address this limitation by introducing a novel, layout-agnostic modeling approach for HAR systems in smart homes that utilizes the transferrable representational capacity of natural language descriptions of raw sensor data.","To this end, we generate Textual Descriptions Of Sensor Triggers (TDOST) that encapsulate the surrounding trigger conditions and provide cues for underlying activities to the activity recognition models.","Leveraging textual embeddings, rather than raw sensor data, we create activity recognition systems that predict standard activities across homes without either (re-)training or adaptation on target homes.","Through an extensive evaluation, we demonstrate the effectiveness of TDOST-based models in unseen smart homes through experiments on benchmarked CASAS datasets.","Furthermore, we conduct a detailed analysis of how the individual components of our approach affect downstream activity recognition performance."],"url":"http://arxiv.org/abs/2405.12368v1"}
{"created":"2024-05-20 20:03:51","title":"TinyM$^2$Net-V3: Memory-Aware Compressed Multimodal Deep Neural Networks for Sustainable Edge Deployment","abstract":"The advancement of sophisticated artificial intelligence (AI) algorithms has led to a notable increase in energy usage and carbon dioxide emissions, intensifying concerns about climate change. This growing problem has brought the environmental sustainability of AI technologies to the forefront, especially as they expand across various sectors. In response to these challenges, there is an urgent need for the development of sustainable AI solutions. These solutions must focus on energy-efficient embedded systems that are capable of handling diverse data types even in environments with limited resources, thereby ensuring both technological progress and environmental responsibility. Integrating complementary multimodal data into tiny machine learning models for edge devices is challenging due to increased complexity, latency, and power consumption. This work introduces TinyM$^2$Net-V3, a system that processes different modalities of complementary data, designs deep neural network (DNN) models, and employs model compression techniques including knowledge distillation and low bit-width quantization with memory-aware considerations to fit models within lower memory hierarchy levels, reducing latency and enhancing energy efficiency on resource-constrained devices. We evaluated TinyM$^2$Net-V3 in two multimodal case studies: COVID-19 detection using cough, speech, and breathing audios, and pose classification from depth and thermal images. With tiny inference models (6 KB and 58 KB), we achieved 92.95% and 90.7% accuracies, respectively. Our tiny machine learning models, deployed on resource limited hardware, demonstrated low latencies within milliseconds and very high power efficiency.","sentences":["The advancement of sophisticated artificial intelligence (AI) algorithms has led to a notable increase in energy usage and carbon dioxide emissions, intensifying concerns about climate change.","This growing problem has brought the environmental sustainability of AI technologies to the forefront, especially as they expand across various sectors.","In response to these challenges, there is an urgent need for the development of sustainable AI solutions.","These solutions must focus on energy-efficient embedded systems that are capable of handling diverse data types even in environments with limited resources, thereby ensuring both technological progress and environmental responsibility.","Integrating complementary multimodal data into tiny machine learning models for edge devices is challenging due to increased complexity, latency, and power consumption.","This work introduces TinyM$^2$Net-V3, a system that processes different modalities of complementary data, designs deep neural network (DNN) models, and employs model compression techniques including knowledge distillation and low bit-width quantization with memory-aware considerations to fit models within lower memory hierarchy levels, reducing latency and enhancing energy efficiency on resource-constrained devices.","We evaluated TinyM$^2$Net-V3 in two multimodal case studies: COVID-19 detection using cough, speech, and breathing audios, and pose classification from depth and thermal images.","With tiny inference models (6 KB and 58 KB), we achieved 92.95% and 90.7% accuracies, respectively.","Our tiny machine learning models, deployed on resource limited hardware, demonstrated low latencies within milliseconds and very high power efficiency."],"url":"http://arxiv.org/abs/2405.12353v1"}
{"created":"2024-05-20 19:24:10","title":"Cascade-based Randomization for Inferring Causal Effects under Diffusion Interference","abstract":"The presence of interference, where the outcome of an individual may depend on the treatment assignment and behavior of neighboring nodes, can lead to biased causal effect estimation. Current approaches to network experiment design focus on limiting interference through cluster-based randomization, in which clusters are identified using graph clustering, and cluster randomization dictates the node assignment to treatment and control. However, cluster-based randomization approaches perform poorly when interference propagates in cascades, whereby the response of individuals to treatment propagates to their multi-hop neighbors. When we have knowledge of the cascade seed nodes, we can leverage this interference structure to mitigate the resulting causal effect estimation bias. With this goal, we propose a cascade-based network experiment design that initiates treatment assignment from the cascade seed node and propagates the assignment to their multi-hop neighbors to limit interference during cascade growth and thereby reduce the overall causal effect estimation error. Our extensive experiments on real-world and synthetic datasets demonstrate that our proposed framework outperforms the existing state-of-the-art approaches in estimating causal effects in network data.","sentences":["The presence of interference, where the outcome of an individual may depend on the treatment assignment and behavior of neighboring nodes, can lead to biased causal effect estimation.","Current approaches to network experiment design focus on limiting interference through cluster-based randomization, in which clusters are identified using graph clustering, and cluster randomization dictates the node assignment to treatment and control.","However, cluster-based randomization approaches perform poorly when interference propagates in cascades, whereby the response of individuals to treatment propagates to their multi-hop neighbors.","When we have knowledge of the cascade seed nodes, we can leverage this interference structure to mitigate the resulting causal effect estimation bias.","With this goal, we propose a cascade-based network experiment design that initiates treatment assignment from the cascade seed node and propagates the assignment to their multi-hop neighbors to limit interference during cascade growth and thereby reduce the overall causal effect estimation error.","Our extensive experiments on real-world and synthetic datasets demonstrate that our proposed framework outperforms the existing state-of-the-art approaches in estimating causal effects in network data."],"url":"http://arxiv.org/abs/2405.12340v1"}
{"created":"2024-05-20 18:51:42","title":"Overlap Number of Balls Model-Agnostic CounterFactuals (ONB-MACF): A Data-Morphology-based Counterfactual Generation Method for Trustworthy Artificial Intelligence","abstract":"Explainable Artificial Intelligence (XAI) is a pivotal research domain aimed at understanding the operational mechanisms of AI systems, particularly those considered ``black boxes'' due to their complex, opaque nature. XAI seeks to make these AI systems more understandable and trustworthy, providing insight into their decision-making processes. By producing clear and comprehensible explanations, XAI enables users, practitioners, and stakeholders to trust a model's decisions. This work analyses the value of data morphology strategies in generating counterfactual explanations. It introduces the Overlap Number of Balls Model-Agnostic CounterFactuals (ONB-MACF) method, a model-agnostic counterfactual generator that leverages data morphology to estimate a model's decision boundaries. The ONB-MACF method constructs hyperspheres in the data space whose covered points share a class, mapping the decision boundary. Counterfactuals are then generated by incrementally adjusting an instance's attributes towards the nearest alternate-class hypersphere, crossing the decision boundary with minimal modifications. By design, the ONB-MACF method generates feasible and sparse counterfactuals that follow the data distribution. Our comprehensive benchmark from a double perspective (quantitative and qualitative) shows that the ONB-MACF method outperforms existing state-of-the-art counterfactual generation methods across multiple quality metrics on diverse tabular datasets. This supports our hypothesis, showcasing the potential of data-morphology-based explainability strategies for trustworthy AI.","sentences":["Explainable Artificial Intelligence (XAI) is a pivotal research domain aimed at understanding the operational mechanisms of AI systems, particularly those considered ``black boxes'' due to their complex, opaque nature.","XAI seeks to make these AI systems more understandable and trustworthy, providing insight into their decision-making processes.","By producing clear and comprehensible explanations, XAI enables users, practitioners, and stakeholders to trust a model's decisions.","This work analyses the value of data morphology strategies in generating counterfactual explanations.","It introduces the Overlap Number of Balls Model-Agnostic CounterFactuals (ONB-MACF) method, a model-agnostic counterfactual generator that leverages data morphology to estimate a model's decision boundaries.","The ONB-MACF method constructs hyperspheres in the data space whose covered points share a class, mapping the decision boundary.","Counterfactuals are then generated by incrementally adjusting an instance's attributes towards the nearest alternate-class hypersphere, crossing the decision boundary with minimal modifications.","By design, the ONB-MACF method generates feasible and sparse counterfactuals that follow the data distribution.","Our comprehensive benchmark from a double perspective (quantitative and qualitative) shows that the ONB-MACF method outperforms existing state-of-the-art counterfactual generation methods across multiple quality metrics on diverse tabular datasets.","This supports our hypothesis, showcasing the potential of data-morphology-based explainability strategies for trustworthy AI."],"url":"http://arxiv.org/abs/2405.12326v1"}
{"created":"2024-05-20 18:29:53","title":"Dynamic Line Rating using Hyper-local Weather Predictions: A Machine Learning Approach","abstract":"Dynamic Line Rating (DLR) systems are crucial for renewable energy integration in transmission networks. However, traditional methods relying on sensor data face challenges due to the impracticality of installing sensors on every pole or span. Additionally, sensor-based approaches may struggle predicting DLR in rapidly changing weather conditions. This paper proposes a novel approach, leveraging machine learning (ML) techniques alongside hyper-local weather forecast data. Unlike conventional methods, which solely rely on sensor data, this approach utilizes ML models trained to predict hyper-local weather parameters on a full network scale. Integrating topographical data enhances prediction accuracy by accounting for landscape features and obstacles around overhead lines. The paper introduces confidence intervals for DLR assessments to mitigate risks associated with uncertainties. A case study from Estonia demonstrates the practical implementation of the proposed methodology, highlighting its effectiveness in real-world scenarios. By addressing limitations of sensor-based approaches, this research contributes to the discourse of renewable energy integration in transmission systems, advancing efficiency and reliability in the power grid.","sentences":["Dynamic Line Rating (DLR) systems are crucial for renewable energy integration in transmission networks.","However, traditional methods relying on sensor data face challenges due to the impracticality of installing sensors on every pole or span.","Additionally, sensor-based approaches may struggle predicting DLR in rapidly changing weather conditions.","This paper proposes a novel approach, leveraging machine learning (ML) techniques alongside hyper-local weather forecast data.","Unlike conventional methods, which solely rely on sensor data, this approach utilizes ML models trained to predict hyper-local weather parameters on a full network scale.","Integrating topographical data enhances prediction accuracy by accounting for landscape features and obstacles around overhead lines.","The paper introduces confidence intervals for DLR assessments to mitigate risks associated with uncertainties.","A case study from Estonia demonstrates the practical implementation of the proposed methodology, highlighting its effectiveness in real-world scenarios.","By addressing limitations of sensor-based approaches, this research contributes to the discourse of renewable energy integration in transmission systems, advancing efficiency and reliability in the power grid."],"url":"http://arxiv.org/abs/2405.12319v1"}
{"created":"2024-05-20 18:15:20","title":"Deep learning-based hyperspectral image reconstruction for quality assessment of agro-product","abstract":"Hyperspectral imaging (HSI) has recently emerged as a promising tool for many agricultural applications; however, the technology cannot be directly used in a real-time system due to the extensive time needed to process large volumes of data. Consequently, the development of a simple, compact, and cost-effective imaging system is not possible with the current HSI systems. Therefore, the overall goal of this study was to reconstruct hyperspectral images from RGB images through deep learning for agricultural applications. Specifically, this study used Hyperspectral Convolutional Neural Network - Dense (HSCNN-D) to reconstruct hyperspectral images from RGB images for predicting soluble solid content (SSC) in sweet potatoes. The algorithm accurately reconstructed the hyperspectral images from RGB images, with the resulting spectra closely matching the ground-truth. The partial least squares regression (PLSR) model based on reconstructed spectra outperformed the model using the full spectral range, demonstrating its potential for SSC prediction in sweet potatoes. These findings highlight the potential of deep learning-based hyperspectral image reconstruction as a low-cost, efficient tool for various agricultural uses.","sentences":["Hyperspectral imaging (HSI) has recently emerged as a promising tool for many agricultural applications; however, the technology cannot be directly used in a real-time system due to the extensive time needed to process large volumes of data.","Consequently, the development of a simple, compact, and cost-effective imaging system is not possible with the current HSI systems.","Therefore, the overall goal of this study was to reconstruct hyperspectral images from RGB images through deep learning for agricultural applications.","Specifically, this study used Hyperspectral Convolutional Neural Network - Dense (HSCNN-D) to reconstruct hyperspectral images from RGB images for predicting soluble solid content (SSC) in sweet potatoes.","The algorithm accurately reconstructed the hyperspectral images from RGB images, with the resulting spectra closely matching the ground-truth.","The partial least squares regression (PLSR) model based on reconstructed spectra outperformed the model using the full spectral range, demonstrating its potential for SSC prediction in sweet potatoes.","These findings highlight the potential of deep learning-based hyperspectral image reconstruction as a low-cost, efficient tool for various agricultural uses."],"url":"http://arxiv.org/abs/2405.12313v1"}
{"created":"2024-05-20 18:14:33","title":"A Principled Approach for a New Bias Measure","abstract":"The widespread use of machine learning and data-driven algorithms for decision making has been steadily increasing over many years. The areas in which this is happening are diverse: healthcare, employment, finance, education, the legal system to name a few; and the associated negative side effects are being increasingly harmful for society. Negative data \\emph{bias} is one of those, which tends to result in harmful consequences for specific groups of people. Any mitigation strategy or effective policy that addresses the negative consequences of bias must start with awareness that bias exists, together with a way to understand and quantify it. However, there is a lack of consensus on how to measure data bias and oftentimes the intended meaning is context dependent and not uniform within the research community. The main contributions of our work are: (1) a general algorithmic framework for defining and efficiently quantifying the bias level of a dataset with respect to a protected group; and (2) the definition of a new bias measure. Our results are experimentally validated using nine publicly available datasets and theoretically analyzed, which provide novel insights about the problem. Based on our approach, we also derive a bias mitigation algorithm that might be useful to policymakers.","sentences":["The widespread use of machine learning and data-driven algorithms for decision making has been steadily increasing over many years.","The areas in which this is happening are diverse: healthcare, employment, finance, education, the legal system to name a few; and the associated negative side effects are being increasingly harmful for society.","Negative data \\emph{bias} is one of those, which tends to result in harmful consequences for specific groups of people.","Any mitigation strategy or effective policy that addresses the negative consequences of bias must start with awareness that bias exists, together with a way to understand and quantify it.","However, there is a lack of consensus on how to measure data bias and oftentimes the intended meaning is context dependent and not uniform within the research community.","The main contributions of our work are: (1) a general algorithmic framework for defining and efficiently quantifying the bias level of a dataset with respect to a protected group; and (2) the definition of a new bias measure.","Our results are experimentally validated using nine publicly available datasets and theoretically analyzed, which provide novel insights about the problem.","Based on our approach, we also derive a bias mitigation algorithm that might be useful to policymakers."],"url":"http://arxiv.org/abs/2405.12312v1"}
{"created":"2024-05-20 18:11:45","title":"Automatic Hardware Pragma Insertion in High-Level Synthesis: A Non-Linear Programming Approach","abstract":"High-level synthesis, source-to-source compilers, and various Design Space Exploration techniques for pragma insertion have significantly improved the Quality of Results of generated designs. These tools offer benefits such as reduced development time and enhanced performance. However, achieving high-quality results often requires additional manual code transformations and tiling selections, which are typically performed separately or as pre-processing steps. Although DSE techniques enable code transformation upfront, the vastness of the search space often limits the exploration of all possible code transformations, making it challenging to determine which transformations are necessary. Additionally, ensuring correctness remains challenging, especially for complex transformations and optimizations.   To tackle this obstacle, we first propose a comprehensive framework leveraging HLS compilers. Our system streamlines code transformation, pragma insertion, and tiles size selection for on-chip data caching through a unified optimization problem, aiming to enhance parallelization, particularly beneficial for computation-bound kernels. Them employing a novel Non-Linear Programming (NLP) approach, we simultaneously ascertain transformations, pragmas, and tile sizes, focusing on regular loop-based kernels. Our evaluation demonstrates that our framework adeptly identifies the appropriate transformations, including scenarios where no transformation is necessary, and inserts pragmas to achieve a favorable Quality of Results.","sentences":["High-level synthesis, source-to-source compilers, and various Design Space Exploration techniques for pragma insertion have significantly improved the Quality of Results of generated designs.","These tools offer benefits such as reduced development time and enhanced performance.","However, achieving high-quality results often requires additional manual code transformations and tiling selections, which are typically performed separately or as pre-processing steps.","Although DSE techniques enable code transformation upfront, the vastness of the search space often limits the exploration of all possible code transformations, making it challenging to determine which transformations are necessary.","Additionally, ensuring correctness remains challenging, especially for complex transformations and optimizations.   ","To tackle this obstacle, we first propose a comprehensive framework leveraging HLS compilers.","Our system streamlines code transformation, pragma insertion, and tiles size selection for on-chip data caching through a unified optimization problem, aiming to enhance parallelization, particularly beneficial for computation-bound kernels.","Them employing a novel Non-Linear Programming (NLP) approach, we simultaneously ascertain transformations, pragmas, and tile sizes, focusing on regular loop-based kernels.","Our evaluation demonstrates that our framework adeptly identifies the appropriate transformations, including scenarios where no transformation is necessary, and inserts pragmas to achieve a favorable Quality of Results."],"url":"http://arxiv.org/abs/2405.12304v1"}
{"created":"2024-05-20 18:04:59","title":"Perturbing the Gradient for Alleviating Meta Overfitting","abstract":"The reason for Meta Overfitting can be attributed to two factors: Mutual Non-exclusivity and the Lack of diversity, consequent to which a single global function can fit the support set data of all the meta-training tasks and fail to generalize to new unseen tasks. This issue is evidenced by low error rates on the meta-training tasks, but high error rates on new tasks. However, there can be a number of novel solutions to this problem keeping in mind any of the two objectives to be attained, i.e. to increase diversity in the tasks and to reduce the confidence of the model for some of the tasks. In light of the above, this paper proposes a number of solutions to tackle meta-overfitting on few-shot learning settings, such as few-shot sinusoid regression and few shot classification. Our proposed approaches demonstrate improved generalization performance compared to state-of-the-art baselines for learning in a non-mutually exclusive task setting. Overall, this paper aims to provide insights into tackling overfitting in meta-learning and to advance the field towards more robust and generalizable models.","sentences":["The reason for Meta Overfitting can be attributed to two factors: Mutual Non-exclusivity and the Lack of diversity, consequent to which a single global function can fit the support set data of all the meta-training tasks and fail to generalize to new unseen tasks.","This issue is evidenced by low error rates on the meta-training tasks, but high error rates on new tasks.","However, there can be a number of novel solutions to this problem keeping in mind any of the two objectives to be attained, i.e. to increase diversity in the tasks and to reduce the confidence of the model for some of the tasks.","In light of the above, this paper proposes a number of solutions to tackle meta-overfitting on few-shot learning settings, such as few-shot sinusoid regression and few shot classification.","Our proposed approaches demonstrate improved generalization performance compared to state-of-the-art baselines for learning in a non-mutually exclusive task setting.","Overall, this paper aims to provide insights into tackling overfitting in meta-learning and to advance the field towards more robust and generalizable models."],"url":"http://arxiv.org/abs/2405.12299v1"}
{"created":"2024-05-20 18:01:15","title":"Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) are recognized as potent tools for processing real-world data organized in graph structures. Especially inductive GNNs, which enable the processing of graph-structured data without relying on predefined graph structures, are gaining importance in an increasingly wide variety of applications. As these networks demonstrate proficiency across a range of tasks, they become lucrative targets for model-stealing attacks where an adversary seeks to replicate the functionality of the targeted network. A large effort has been made to develop model-stealing attacks that focus on models trained with images and texts. However, little attention has been paid to GNNs trained on graph data. This paper introduces a novel method for unsupervised model-stealing attacks against inductive GNNs, based on graph contrasting learning and spectral graph augmentations to efficiently extract information from the target model. The proposed attack is thoroughly evaluated on six datasets. The results show that this approach demonstrates a higher level of efficiency compared to existing stealing attacks. More concretely, our attack outperforms the baseline on all benchmarks achieving higher fidelity and downstream accuracy of the stolen model while requiring fewer queries sent to the target model.","sentences":["Graph Neural Networks (GNNs) are recognized as potent tools for processing real-world data organized in graph structures.","Especially inductive GNNs, which enable the processing of graph-structured data without relying on predefined graph structures, are gaining importance in an increasingly wide variety of applications.","As these networks demonstrate proficiency across a range of tasks, they become lucrative targets for model-stealing attacks where an adversary seeks to replicate the functionality of the targeted network.","A large effort has been made to develop model-stealing attacks that focus on models trained with images and texts.","However, little attention has been paid to GNNs trained on graph data.","This paper introduces a novel method for unsupervised model-stealing attacks against inductive GNNs, based on graph contrasting learning and spectral graph augmentations to efficiently extract information from the target model.","The proposed attack is thoroughly evaluated on six datasets.","The results show that this approach demonstrates a higher level of efficiency compared to existing stealing attacks.","More concretely, our attack outperforms the baseline on all benchmarks achieving higher fidelity and downstream accuracy of the stolen model while requiring fewer queries sent to the target model."],"url":"http://arxiv.org/abs/2405.12295v1"}
{"created":"2024-05-20 18:01:11","title":"Exact Random Graph Matching with Multiple Graphs","abstract":"This work studies fundamental limits for recovering the underlying correspondence among multiple correlated random graphs. We identify a necessary condition for any algorithm to correctly match all nodes across all graphs, and propose two algorithms for which the same condition is also sufficient. The first algorithm employs global information to simultaneously match all the graphs, whereas the second algorithm first partially matches the graphs pairwise and then combines the partial matchings by transitivity. Both algorithms work down to the information theoretic threshold. Our analysis reveals a scenario where exact matching between two graphs alone is impossible, but leveraging more than two graphs allows exact matching among all the graphs. Along the way, we derive independent results about the k-core of Erdos-Renyi graphs.","sentences":["This work studies fundamental limits for recovering the underlying correspondence among multiple correlated random graphs.","We identify a necessary condition for any algorithm to correctly match all nodes across all graphs, and propose two algorithms for which the same condition is also sufficient.","The first algorithm employs global information to simultaneously match all the graphs, whereas the second algorithm first partially matches the graphs pairwise and then combines the partial matchings by transitivity.","Both algorithms work down to the information theoretic threshold.","Our analysis reveals a scenario where exact matching between two graphs alone is impossible, but leveraging more than two graphs allows exact matching among all the graphs.","Along the way, we derive independent results about the k-core of Erdos-Renyi graphs."],"url":"http://arxiv.org/abs/2405.12293v1"}
