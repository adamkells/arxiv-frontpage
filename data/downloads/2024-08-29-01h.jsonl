{"created":"2024-08-27 17:59:55","title":"Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty","abstract":"Robust and realistic rendering for large-scale road scenes is essential in autonomous driving simulation. Recently, 3D Gaussian Splatting (3D-GS) has made groundbreaking progress in neural rendering, but the general fidelity of large-scale road scene renderings is often limited by the input imagery, which usually has a narrow field of view and focuses mainly on the street-level local area. Intuitively, the data from the drone's perspective can provide a complementary viewpoint for the data from the ground vehicle's perspective, enhancing the completeness of scene reconstruction and rendering. However, training naively with aerial and ground images, which exhibit large view disparity, poses a significant convergence challenge for 3D-GS, and does not demonstrate remarkable improvements in performance on road views. In order to enhance the novel view synthesis of road views and to effectively use the aerial information, we design an uncertainty-aware training method that allows aerial images to assist in the synthesis of areas where ground images have poor learning outcomes instead of weighting all pixels equally in 3D-GS training like prior work did. We are the first to introduce the cross-view uncertainty to 3D-GS by matching the car-view ensemble-based rendering uncertainty to aerial images, weighting the contribution of each pixel to the training process. Additionally, to systematically quantify evaluation metrics, we assemble a high-quality synthesized dataset comprising both aerial and ground images for road scenes.","sentences":["Robust and realistic rendering for large-scale road scenes is essential in autonomous driving simulation.","Recently, 3D Gaussian Splatting (3D-GS) has made groundbreaking progress in neural rendering, but the general fidelity of large-scale road scene renderings is often limited by the input imagery, which usually has a narrow field of view and focuses mainly on the street-level local area.","Intuitively, the data from the drone's perspective can provide a complementary viewpoint for the data from the ground vehicle's perspective, enhancing the completeness of scene reconstruction and rendering.","However, training naively with aerial and ground images, which exhibit large view disparity, poses a significant convergence challenge for 3D-GS, and does not demonstrate remarkable improvements in performance on road views.","In order to enhance the novel view synthesis of road views and to effectively use the aerial information, we design an uncertainty-aware training method that allows aerial images to assist in the synthesis of areas where ground images have poor learning outcomes instead of weighting all pixels equally in 3D-GS training like prior work did.","We are the first to introduce the cross-view uncertainty to 3D-GS by matching the car-view ensemble-based rendering uncertainty to aerial images, weighting the contribution of each pixel to the training process.","Additionally, to systematically quantify evaluation metrics, we assemble a high-quality synthesized dataset comprising both aerial and ground images for road scenes."],"url":"http://arxiv.org/abs/2408.15242v1"}
{"created":"2024-08-27 17:48:29","title":"DCT-CryptoNets: Scaling Private Inference in the Frequency Domain","abstract":"The convergence of fully homomorphic encryption (FHE) and machine learning offers unprecedented opportunities for private inference of sensitive data. FHE enables computation directly on encrypted data, safeguarding the entire machine learning pipeline, including data and model confidentiality. However, existing FHE-based implementations for deep neural networks face significant challenges in computational cost, latency, and scalability, limiting their practical deployment. This paper introduces DCT-CryptoNets, a novel approach that leverages frequency-domain learning to tackle these issues. Our method operates directly in the frequency domain, utilizing the discrete cosine transform (DCT) commonly employed in JPEG compression. This approach is inherently compatible with remote computing services, where images are usually transmitted and stored in compressed formats. DCT-CryptoNets reduces the computational burden of homomorphic operations by focusing on perceptually relevant low-frequency components. This is demonstrated by substantial latency reduction of up to 5.3$\\times$ compared to prior work on image classification tasks, including a novel demonstration of ImageNet inference within 2.5 hours, down from 12.5 hours compared to prior work on equivalent compute resources. Moreover, DCT-CryptoNets improves the reliability of encrypted accuracy by reducing variability (e.g., from $\\pm$2.5\\% to $\\pm$1.0\\% on ImageNet). This study demonstrates a promising avenue for achieving efficient and practical privacy-preserving deep learning on high resolution images seen in real-world applications.","sentences":["The convergence of fully homomorphic encryption (FHE) and machine learning offers unprecedented opportunities for private inference of sensitive data.","FHE enables computation directly on encrypted data, safeguarding the entire machine learning pipeline, including data and model confidentiality.","However, existing FHE-based implementations for deep neural networks face significant challenges in computational cost, latency, and scalability, limiting their practical deployment.","This paper introduces DCT-CryptoNets, a novel approach that leverages frequency-domain learning to tackle these issues.","Our method operates directly in the frequency domain, utilizing the discrete cosine transform (DCT) commonly employed in JPEG compression.","This approach is inherently compatible with remote computing services, where images are usually transmitted and stored in compressed formats.","DCT-CryptoNets reduces the computational burden of homomorphic operations by focusing on perceptually relevant low-frequency components.","This is demonstrated by substantial latency reduction of up to 5.3$\\times$ compared to prior work on image classification tasks, including a novel demonstration of ImageNet inference within 2.5 hours, down from 12.5 hours compared to prior work on equivalent compute resources.","Moreover, DCT-CryptoNets improves the reliability of encrypted accuracy by reducing variability (e.g., from $\\pm$2.5\\% to $\\pm$1.0\\% on ImageNet).","This study demonstrates a promising avenue for achieving efficient and practical privacy-preserving deep learning on high resolution images seen in real-world applications."],"url":"http://arxiv.org/abs/2408.15231v1"}
{"created":"2024-08-27 17:19:57","title":"Classifying populist language in American presidential and governor speeches using automatic text analysis","abstract":"Populism is a concept that is often used but notoriously difficult to measure. Common qualitative measurements like holistic grading or content analysis require great amounts of time and labour, making it difficult to quickly scope out which politicians should be classified as populist and which should not, while quantitative methods show mixed results when it comes to classifying populist rhetoric. In this paper, we develop a pipeline to train and validate an automated classification model to estimate the use of populist language. We train models based on sentences that were identified as populist and pluralist in 300 US governors' speeches from 2010 to 2018 and in 45 speeches of presidential candidates in 2016. We find that these models classify most speeches correctly, including 84% of governor speeches and 89% of presidential speeches. These results extend to different time periods (with 92% accuracy on more recent American governors), different amounts of data (with as few as 70 training sentences per category achieving similar results), and when classifying politicians instead of individual speeches. This pipeline is thus an effective tool that can optimise the systematic and swift classification of the use of populist language in politicians' speeches.","sentences":["Populism is a concept that is often used but notoriously difficult to measure.","Common qualitative measurements like holistic grading or content analysis require great amounts of time and labour, making it difficult to quickly scope out which politicians should be classified as populist and which should not, while quantitative methods show mixed results when it comes to classifying populist rhetoric.","In this paper, we develop a pipeline to train and validate an automated classification model to estimate the use of populist language.","We train models based on sentences that were identified as populist and pluralist in 300 US governors' speeches from 2010 to 2018 and in 45 speeches of presidential candidates in 2016.","We find that these models classify most speeches correctly, including 84% of governor speeches and 89% of presidential speeches.","These results extend to different time periods (with 92% accuracy on more recent American governors), different amounts of data (with as few as 70 training sentences per category achieving similar results), and when classifying politicians instead of individual speeches.","This pipeline is thus an effective tool that can optimise the systematic and swift classification of the use of populist language in politicians' speeches."],"url":"http://arxiv.org/abs/2408.15213v1"}
{"created":"2024-08-27 17:03:18","title":"Can Unconfident LLM Annotations Be Used for Confident Conclusions?","abstract":"Large language models (LLMs) have shown high agreement with human raters across a variety of tasks, demonstrating potential to ease the challenges of human data collection. In computational social science (CSS), researchers are increasingly leveraging LLM annotations to complement slow and expensive human annotations. Still, guidelines for collecting and using LLM annotations, without compromising the validity of downstream conclusions, remain limited. We introduce Confidence-Driven Inference: a method that combines LLM annotations and LLM confidence indicators to strategically select which human annotations should be collected, with the goal of producing accurate statistical estimates and provably valid confidence intervals while reducing the number of human annotations needed. Our approach comes with safeguards against LLM annotations of poor quality, guaranteeing that the conclusions will be both valid and no less accurate than if we only relied on human annotations. We demonstrate the effectiveness of Confidence-Driven Inference over baselines in statistical estimation tasks across three CSS settings--text politeness, stance, and bias--reducing the needed number of human annotations by over 25% in each. Although we use CSS settings for demonstration, Confidence-Driven Inference can be used to estimate most standard quantities across a broad range of NLP problems.","sentences":["Large language models (LLMs) have shown high agreement with human raters across a variety of tasks, demonstrating potential to ease the challenges of human data collection.","In computational social science (CSS), researchers are increasingly leveraging LLM annotations to complement slow and expensive human annotations.","Still, guidelines for collecting and using LLM annotations, without compromising the validity of downstream conclusions, remain limited.","We introduce Confidence-Driven Inference: a method that combines LLM annotations and LLM confidence indicators to strategically select which human annotations should be collected, with the goal of producing accurate statistical estimates and provably valid confidence intervals while reducing the number of human annotations needed.","Our approach comes with safeguards against LLM annotations of poor quality, guaranteeing that the conclusions will be both valid and no less accurate than if we only relied on human annotations.","We demonstrate the effectiveness of Confidence-Driven Inference over baselines in statistical estimation tasks across three CSS settings--text politeness, stance, and bias--reducing the needed number of human annotations by over 25% in each.","Although we use CSS settings for demonstration, Confidence-Driven Inference can be used to estimate most standard quantities across a broad range of NLP problems."],"url":"http://arxiv.org/abs/2408.15204v1"}
{"created":"2024-08-27 17:03:10","title":"On the Encoding Process in Decentralized Systems","abstract":"We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation. The system involves K source processors, each holding some data modeled as a vector over a finite field. The remaining R processors are sinks, and each of which requires a linear combination of all data vectors. These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code. To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds. In every round, every processor sends and receives one message through each one of its p ports. Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data. We propose a framework that addresses the decentralized encoding problem on two levels. On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code. On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems. Our solutions are based on a newly-defined collective communication operation we call all-to-all encode.","sentences":["We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation.","The system involves K source processors, each holding some data modeled as a vector over a finite field.","The remaining R processors are sinks, and each of which requires a linear combination of all data vectors.","These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code.","To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds.","In every round, every processor sends and receives one message through each one of its p ports.","Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data.","We propose a framework that addresses the decentralized encoding problem on two levels.","On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code.","On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems.","Our solutions are based on a newly-defined collective communication operation we call all-to-all encode."],"url":"http://arxiv.org/abs/2408.15203v1"}
{"created":"2024-08-27 16:41:13","title":"Easy-access online social media metrics can effectively identify misinformation sharing users","abstract":"Misinformation poses a significant challenge studied extensively by researchers, yet acquiring data to identify primary sharers is costly and challenging. To address this, we propose a low-barrier approach to differentiate social media users who are more likely to share misinformation from those who are less likely. Leveraging insights from previous studies, we demonstrate that easy-access online social network metrics -- average daily tweet count, and account age -- can be leveraged to help identify potential low factuality content spreaders on X (previously known as Twitter). We find that higher tweet frequency is positively associated with low factuality in shared content, while account age is negatively associated with it. We also find that some of the effects, namely the effect of the number of accounts followed and the number of tweets produced, differ depending on the number of followers a user has. Our findings show that relying on these easy-access social network metrics could serve as a low-barrier approach for initial identification of users who are more likely to spread misinformation, and therefore contribute to combating misinformation effectively on social media platforms.","sentences":["Misinformation poses a significant challenge studied extensively by researchers, yet acquiring data to identify primary sharers is costly and challenging.","To address this, we propose a low-barrier approach to differentiate social media users who are more likely to share misinformation from those who are less likely.","Leveraging insights from previous studies, we demonstrate that easy-access online social network metrics -- average daily tweet count, and account age -- can be leveraged to help identify potential low factuality content spreaders on X (previously known as Twitter).","We find that higher tweet frequency is positively associated with low factuality in shared content, while account age is negatively associated with it.","We also find that some of the effects, namely the effect of the number of accounts followed and the number of tweets produced, differ depending on the number of followers a user has.","Our findings show that relying on these easy-access social network metrics could serve as a low-barrier approach for initial identification of users who are more likely to spread misinformation, and therefore contribute to combating misinformation effectively on social media platforms."],"url":"http://arxiv.org/abs/2408.15186v1"}
{"created":"2024-08-27 16:40:14","title":"PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization","abstract":"Video Anomaly Detection (VAD) presents a significant challenge in computer vision, particularly due to the unpredictable and infrequent nature of anomalous events, coupled with the diverse and dynamic environments in which they occur. Human-centric VAD, a specialized area within this domain, faces additional complexities, including variations in human behavior, potential biases in data, and substantial privacy concerns related to human subjects. These issues complicate the development of models that are both robust and generalizable. To address these challenges, recent advancements have focused on pose-based VAD, which leverages human pose as a high-level feature to mitigate privacy concerns, reduce appearance biases, and minimize background interference. In this paper, we introduce PoseWatch, a novel transformer-based architecture designed specifically for human-centric pose-based VAD. PoseWatch features an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP) tokenization method that enhances the representation of human motion over time, which is also beneficial for broader human behavior analysis tasks. The architecture's core, a Unified Encoder Twin Decoders (UETD) transformer, significantly improves the detection of anomalous behaviors in video data. Extensive evaluations across multiple benchmark datasets demonstrate that PoseWatch consistently outperforms existing methods, establishing a new state-of-the-art in pose-based VAD. This work not only demonstrates the efficacy of PoseWatch but also highlights the potential of integrating Natural Language Processing techniques with computer vision to advance human behavior analysis.","sentences":["Video Anomaly Detection (VAD) presents a significant challenge in computer vision, particularly due to the unpredictable and infrequent nature of anomalous events, coupled with the diverse and dynamic environments in which they occur.","Human-centric VAD, a specialized area within this domain, faces additional complexities, including variations in human behavior, potential biases in data, and substantial privacy concerns related to human subjects.","These issues complicate the development of models that are both robust and generalizable.","To address these challenges, recent advancements have focused on pose-based VAD, which leverages human pose as a high-level feature to mitigate privacy concerns, reduce appearance biases, and minimize background interference.","In this paper, we introduce PoseWatch, a novel transformer-based architecture designed specifically for human-centric pose-based VAD.","PoseWatch features an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP) tokenization method that enhances the representation of human motion over time, which is also beneficial for broader human behavior analysis tasks.","The architecture's core, a Unified Encoder Twin Decoders (UETD) transformer, significantly improves the detection of anomalous behaviors in video data.","Extensive evaluations across multiple benchmark datasets demonstrate that PoseWatch consistently outperforms existing methods, establishing a new state-of-the-art in pose-based VAD.","This work not only demonstrates the efficacy of PoseWatch but also highlights the potential of integrating Natural Language Processing techniques with computer vision to advance human behavior analysis."],"url":"http://arxiv.org/abs/2408.15185v1"}
{"created":"2024-08-27 16:33:37","title":"On the parameterized complexity of computing good edge-labelings","abstract":"A good edge-labeling (gel for short) of a graph $G$ is a function $\\lambda: E(G) \\to \\mathbb{R}$ such that, for any ordered pair of vertices $(x, y)$ of $G$, there do not exist two distinct increasing paths from $x$ to $y$, where ``increasing'' means that the sequence of labels is non-decreasing. This notion was introduced by Bermond et al. [Theor. Comput. Sci. 2013] motivated by practical applications arising from routing and wavelength assignment problems in optical networks. Prompted by the lack of algorithmic results about the problem of deciding whether an input graph admits a gel, called GEL, we initiate its study from the viewpoint of parameterized complexity. We first introduce the natural version of GEL where one wants to use at most $c$ distinct labels, which we call $c$-GEL, and we prove that it is NP-complete for every $c \\geq 2$ on very restricted instances. We then provide several positive results, starting with simple polynomial kernels for GEL and $c$-\\GEL parameterized by neighborhood diversity or vertex cover. As one of our main technical contributions, we present an FPT algorithm for GEL parameterized by the size of a modulator to a forest of stars, based on a novel approach via a 2-SAT formulation which we believe to be of independent interest. We also present FPT algorithms based on dynamic programming for $c$-GEL parameterized by treewidth and $c$, and for GEL parameterized by treewidth and the maximum degree. Finally, we answer positively a question of Bermond et al. [Theor. Comput. Sci. 2013] by proving the NP-completeness of a problem strongly related to GEL, namely that of deciding whether an input graph admits a so-called UPP-orientation.","sentences":["A good edge-labeling (gel for short) of a graph $G$ is a function $\\lambda: E(G) \\to \\mathbb{R}$ such that, for any ordered pair of vertices $(x, y)$ of $G$, there do not exist two distinct increasing paths from $x$ to $y$, where ``increasing'' means that the sequence of labels is non-decreasing.","This notion was introduced by Bermond et al.","[Theor.","Comput.","Sci. 2013] motivated by practical applications arising from routing and wavelength assignment problems in optical networks.","Prompted by the lack of algorithmic results about the problem of deciding whether an input graph admits a gel, called GEL, we initiate its study from the viewpoint of parameterized complexity.","We first introduce the natural version of GEL where one wants to use at most $c$ distinct labels, which we call $c$-GEL, and we prove that it is NP-complete for every $c \\geq 2$ on very restricted instances.","We then provide several positive results, starting with simple polynomial kernels for GEL and $c$-\\GEL parameterized by neighborhood diversity or vertex cover.","As one of our main technical contributions, we present an FPT algorithm for GEL parameterized by the size of a modulator to a forest of stars, based on a novel approach via a 2-SAT formulation which we believe to be of independent interest.","We also present FPT algorithms based on dynamic programming for $c$-GEL parameterized by treewidth and $c$, and for GEL parameterized by treewidth and the maximum degree.","Finally, we answer positively a question of Bermond et al.","[Theor.","Comput.","Sci. 2013]","by proving the NP-completeness of a problem strongly related to GEL, namely that of deciding whether an input graph admits a so-called UPP-orientation."],"url":"http://arxiv.org/abs/2408.15181v1"}
{"created":"2024-08-27 16:21:29","title":"Regaining Trust: Impact of Transparent User Interface Design on Acceptance of Camera-Based In-Car Health Monitoring Systems","abstract":"Introducing in-car health monitoring systems offers substantial potential to improve driver safety. However, camera-based sensing technologies introduce significant privacy concerns. This study investigates the impact of transparent user interface design on user acceptance of these systems. We conducted an online study with 42 participants using prototypes varying in transparency, choice, and deception levels. The prototypes included three onboarding designs: (1) a traditional Terms and Conditions text, (2) a Business Nudge design that subtly encouraged users to accept default data-sharing options, and (3) a Transparent Walk-Through that provided clear, step-by-step explanations of data use and privacy policies. Our findings indicate that transparent design significantly affects user experience measures, including perceived creepiness, trust in data use, and trustworthiness of content. Transparent onboarding processes enhanced user experience and trust without significantly increasing onboarding time. These findings offer practical guidance for designing user-friendly and privacy-respecting in-car health monitoring systems.","sentences":["Introducing in-car health monitoring systems offers substantial potential to improve driver safety.","However, camera-based sensing technologies introduce significant privacy concerns.","This study investigates the impact of transparent user interface design on user acceptance of these systems.","We conducted an online study with 42 participants using prototypes varying in transparency, choice, and deception levels.","The prototypes included three onboarding designs: (1) a traditional Terms and Conditions text, (2) a Business Nudge design that subtly encouraged users to accept default data-sharing options, and (3) a Transparent Walk-Through that provided clear, step-by-step explanations of data use and privacy policies.","Our findings indicate that transparent design significantly affects user experience measures, including perceived creepiness, trust in data use, and trustworthiness of content.","Transparent onboarding processes enhanced user experience and trust without significantly increasing onboarding time.","These findings offer practical guidance for designing user-friendly and privacy-respecting in-car health monitoring systems."],"url":"http://arxiv.org/abs/2408.15177v1"}
{"created":"2024-08-27 15:52:52","title":"Delay as Payoff in MAB","abstract":"In this paper, we investigate a variant of the classical stochastic Multi-armed Bandit (MAB) problem, where the payoff received by an agent (either cost or reward) is both delayed, and directly corresponds to the magnitude of the delay. This setting models faithfully many real world scenarios such as the time it takes for a data packet to traverse a network given a choice of route (where delay serves as the agent's cost); or a user's time spent on a web page given a choice of content (where delay serves as the agent's reward).   Our main contributions are tight upper and lower bounds for both the cost and reward settings. For the case that delays serve as costs, which we are the first to consider, we prove optimal regret that scales as $\\sum_{i:\\Delta_i > 0}\\frac{\\log T}{\\Delta_i} + d^*$, where $T$ is the maximal number of steps, $\\Delta_i$ are the sub-optimality gaps and $d^*$ is the minimal expected delay amongst arms. For the case that delays serves as rewards, we show optimal regret of $\\sum_{i:\\Delta_i > 0}\\frac{\\log T}{\\Delta_i} + \\bar{d}$, where $\\bar d$ is the second maximal expected delay. These improve over the regret in the general delay-dependent payoff setting, which scales as $\\sum_{i:\\Delta_i > 0}\\frac{\\log T}{\\Delta_i} + D$, where $D$ is the maximum possible delay. Our regret bounds highlight the difference between the cost and reward scenarios, showing that the improvement in the cost scenario is more significant than for the reward. Finally, we accompany our theoretical results with an empirical evaluation.","sentences":["In this paper, we investigate a variant of the classical stochastic Multi-armed Bandit (MAB) problem, where the payoff received by an agent (either cost or reward) is both delayed, and directly corresponds to the magnitude of the delay.","This setting models faithfully many real world scenarios such as the time it takes for a data packet to traverse a network given a choice of route (where delay serves as the agent's cost); or a user's time spent on a web page given a choice of content (where delay serves as the agent's reward).   ","Our main contributions are tight upper and lower bounds for both the cost and reward settings.","For the case that delays serve as costs, which we are the first to consider, we prove optimal regret that scales as $\\sum_{i:\\Delta_i > 0}\\frac{\\log","T}{\\Delta_i} + d^*$, where $T$ is the maximal number of steps, $\\Delta_i$ are the sub-optimality gaps and $d^*$ is the minimal expected delay amongst arms.","For the case that delays serves as rewards, we show optimal regret of $\\sum_{i:\\Delta_i > 0}\\frac{\\log T}{\\Delta_i} + \\bar{d}$, where $\\bar d$ is the second maximal expected delay.","These improve over the regret in the general delay-dependent payoff setting, which scales as $\\sum_{i:\\Delta_i > 0}\\frac{\\log T}{\\Delta_i} + D$, where $D$ is the maximum possible delay.","Our regret bounds highlight the difference between the cost and reward scenarios, showing that the improvement in the cost scenario is more significant than for the reward.","Finally, we accompany our theoretical results with an empirical evaluation."],"url":"http://arxiv.org/abs/2408.15158v1"}
{"created":"2024-08-27 15:23:09","title":"How transformers learn structured data: insights from hierarchical filtering","abstract":"We introduce a hierarchical filtering procedure for generative models of sequences on trees, enabling control over the range of positional correlations in the data. Leveraging this controlled setting, we provide evidence that vanilla encoder-only transformer architectures can implement the optimal Belief Propagation algorithm on both root classification and masked language modeling tasks. Correlations at larger distances corresponding to increasing layers of the hierarchy are sequentially included as the network is trained. We analyze how the transformer layers succeed by focusing on attention maps from models trained with varying degrees of filtering. These attention maps show clear evidence for iterative hierarchical reconstruction of correlations, and we can relate these observations to a plausible implementation of the exact inference algorithm for the network sizes considered.","sentences":["We introduce a hierarchical filtering procedure for generative models of sequences on trees, enabling control over the range of positional correlations in the data.","Leveraging this controlled setting, we provide evidence that vanilla encoder-only transformer architectures can implement the optimal Belief Propagation algorithm on both root classification and masked language modeling tasks.","Correlations at larger distances corresponding to increasing layers of the hierarchy are sequentially included as the network is trained.","We analyze how the transformer layers succeed by focusing on attention maps from models trained with varying degrees of filtering.","These attention maps show clear evidence for iterative hierarchical reconstruction of correlations, and we can relate these observations to a plausible implementation of the exact inference algorithm for the network sizes considered."],"url":"http://arxiv.org/abs/2408.15138v1"}
{"created":"2024-08-27 15:13:06","title":"Using LLMs for Explaining Sets of Counterfactual Examples to Final Users","abstract":"Causality is vital for understanding true cause-and-effect relationships between variables within predictive models, rather than relying on mere correlations, making it highly relevant in the field of Explainable AI. In an automated decision-making scenario, causal inference methods can analyze the underlying data-generation process, enabling explanations of a model's decision by manipulating features and creating counterfactual examples. These counterfactuals explore hypothetical scenarios where a minimal number of factors are altered, providing end-users with valuable information on how to change their situation. However, interpreting a set of multiple counterfactuals can be challenging for end-users who are not used to analyzing raw data records. In our work, we propose a novel multi-step pipeline that uses counterfactuals to generate natural language explanations of actions that will lead to a change in outcome in classifiers of tabular data using LLMs. This pipeline is designed to guide the LLM through smaller tasks that mimic human reasoning when explaining a decision based on counterfactual cases. We conducted various experiments using a public dataset and proposed a method of closed-loop evaluation to assess the coherence of the final explanation with the counterfactuals, as well as the quality of the content. Results are promising, although further experiments with other datasets and human evaluations should be carried out.","sentences":["Causality is vital for understanding true cause-and-effect relationships between variables within predictive models, rather than relying on mere correlations, making it highly relevant in the field of Explainable AI.","In an automated decision-making scenario, causal inference methods can analyze the underlying data-generation process, enabling explanations of a model's decision by manipulating features and creating counterfactual examples.","These counterfactuals explore hypothetical scenarios where a minimal number of factors are altered, providing end-users with valuable information on how to change their situation.","However, interpreting a set of multiple counterfactuals can be challenging for end-users who are not used to analyzing raw data records.","In our work, we propose a novel multi-step pipeline that uses counterfactuals to generate natural language explanations of actions that will lead to a change in outcome in classifiers of tabular data using LLMs.","This pipeline is designed to guide the LLM through smaller tasks that mimic human reasoning when explaining a decision based on counterfactual cases.","We conducted various experiments using a public dataset and proposed a method of closed-loop evaluation to assess the coherence of the final explanation with the counterfactuals, as well as the quality of the content.","Results are promising, although further experiments with other datasets and human evaluations should be carried out."],"url":"http://arxiv.org/abs/2408.15133v1"}
{"created":"2024-08-27 15:12:21","title":"Faster Cycle Detection in the Congested Clique","abstract":"We provide a fast distributed algorithm for detecting $h$-cycles in the \\textsf{Congested Clique} model, whose running time decreases as the number of $h$-cycles in the graph increases. In undirected graphs, constant-round algorithms are known for cycles of even length. Our algorithm greatly improves upon the state of the art for odd values of $h$. Moreover, our running time applies also to directed graphs, in which case the improvement is for all values of $h$. Further, our techniques allow us to obtain a triangle detection algorithm in the quantum variant of this model, which is faster than prior work.   A key technical contribution we develop to obtain our fast cycle detection algorithm is a new algorithm for computing the product of many pairs of small matrices in parallel, which may be of independent interest.","sentences":["We provide a fast distributed algorithm for detecting $h$-cycles in the \\textsf{Congested Clique} model, whose running time decreases as the number of $h$-cycles in the graph increases.","In undirected graphs, constant-round algorithms are known for cycles of even length.","Our algorithm greatly improves upon the state of the art for odd values of $h$. Moreover, our running time applies also to directed graphs, in which case the improvement is for all values of $h$. Further, our techniques allow us to obtain a triangle detection algorithm in the quantum variant of this model, which is faster than prior work.   ","A key technical contribution we develop to obtain our fast cycle detection algorithm is a new algorithm for computing the product of many pairs of small matrices in parallel, which may be of independent interest."],"url":"http://arxiv.org/abs/2408.15132v1"}
{"created":"2024-08-27 14:58:13","title":"Urdu Digital Text Word Optical Character Recognition Using Permuted Auto Regressive Sequence Modeling","abstract":"This research paper presents a novel word-level Optical Character Recognition (OCR) model developed specifically for digital Urdu text. The model utilizes transformer-based architectures and attention mechanisms to address the unique challenges of recognizing Urdu script, which includes handling a diverse range of text styles, fonts, and variations. Trained on a comprehensive dataset of approximately 160,000 Urdu text images, the model incorporates a permuted autoregressive sequence (PARSeq) architecture. This design enables context-aware inference and iterative refinement by leveraging bidirectional context information, significantly enhancing its ability to accurately recognize Urdu characters. The model achieves a character error rate (CER) of 0.178, highlighting its effectiveness and precision in real-world applications. However, the model has some limitations, such as difficulties with blurred images, non-horizontal orientations, and the presence of trailing punctuation marks, which can introduce noise into the recognition process. Addressing these challenges will be a key focus of future work. Future research will aim to further refine the model through advanced data augmentation techniques, optimization of hyperparameters, and the integration of context-aware language models, ultimately enhancing the model's performance and robustness in Urdu text recognition.","sentences":["This research paper presents a novel word-level Optical Character Recognition (OCR) model developed specifically for digital Urdu text.","The model utilizes transformer-based architectures and attention mechanisms to address the unique challenges of recognizing Urdu script, which includes handling a diverse range of text styles, fonts, and variations.","Trained on a comprehensive dataset of approximately 160,000 Urdu text images, the model incorporates a permuted autoregressive sequence (PARSeq) architecture.","This design enables context-aware inference and iterative refinement by leveraging bidirectional context information, significantly enhancing its ability to accurately recognize Urdu characters.","The model achieves a character error rate (CER) of 0.178, highlighting its effectiveness and precision in real-world applications.","However, the model has some limitations, such as difficulties with blurred images, non-horizontal orientations, and the presence of trailing punctuation marks, which can introduce noise into the recognition process.","Addressing these challenges will be a key focus of future work.","Future research will aim to further refine the model through advanced data augmentation techniques, optimization of hyperparameters, and the integration of context-aware language models, ultimately enhancing the model's performance and robustness in Urdu text recognition."],"url":"http://arxiv.org/abs/2408.15119v2"}
{"created":"2024-08-27 14:54:33","title":"Few-Shot Unsupervised Implicit Neural Shape Representation Learning with Spatial Adversaries","abstract":"Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities, encompassing a wide range from 3D shapes to images and audio. Within the realm of 3D shape representation, Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry. However, learning SDFs from sparse 3D point clouds in the absence of ground truth supervision remains a very challenging task. While recent methods rely on smoothness priors to regularize the learning, our method introduces a regularization term that leverages adversarial samples around the shape to improve the learned SDFs. Through extensive experiments and evaluations, we illustrate the efficacy of our proposed method, highlighting its capacity to improve SDF learning with respect to baselines and the state-of-the-art using synthetic and real data.","sentences":["Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities, encompassing a wide range from 3D shapes to images and audio.","Within the realm of 3D shape representation, Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry.","However, learning SDFs from sparse 3D point clouds in the absence of ground truth supervision remains a very challenging task.","While recent methods rely on smoothness priors to regularize the learning, our method introduces a regularization term that leverages adversarial samples around the shape to improve the learned SDFs.","Through extensive experiments and evaluations, we illustrate the efficacy of our proposed method, highlighting its capacity to improve SDF learning with respect to baselines and the state-of-the-art using synthetic and real data."],"url":"http://arxiv.org/abs/2408.15114v1"}
{"created":"2024-08-27 14:31:54","title":"No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery","abstract":"What data or environments to use for training to improve downstream performance is a longstanding and very topical question in reinforcement learning. In particular, Unsupervised Environment Design (UED) methods have gained recent attention as their adaptive curricula enable agents to be robust to in- and out-of-distribution tasks. We ask to what extent these methods are themselves robust when applied to a novel setting, closely inspired by a real-world robotics problem. Surprisingly, we find that the state-of-the-art UED methods either do not improve upon the na\\\"{i}ve baseline of Domain Randomisation (DR), or require substantial hyperparameter tuning to do so. Our analysis shows that this is due to their underlying scoring functions failing to predict intuitive measures of ``learnability'', i.e., in finding the settings that the agent sometimes solves, but not always. Based on this, we instead directly train on levels with high learnability and find that this simple and intuitive approach outperforms UED methods and DR in several binary-outcome environments, including on our domain and the standard UED domain of Minigrid. We further introduce a new adversarial evaluation procedure for directly measuring robustness, closely mirroring the conditional value at risk (CVaR). We open-source all our code and present visualisations of final policies here: https://github.com/amacrutherford/sampling-for-learnability.","sentences":["What data or environments to use for training to improve downstream performance is a longstanding and very topical question in reinforcement learning.","In particular, Unsupervised Environment Design (UED) methods have gained recent attention as their adaptive curricula enable agents to be robust to in- and out-of-distribution tasks.","We ask to what extent these methods are themselves robust when applied to a novel setting, closely inspired by a real-world robotics problem.","Surprisingly, we find that the state-of-the-art UED methods either do not improve upon the na\\\"{i}ve baseline of Domain Randomisation (DR), or require substantial hyperparameter tuning to do so.","Our analysis shows that this is due to their underlying scoring functions failing to predict intuitive measures of ``learnability'', i.e., in finding the settings that the agent sometimes solves, but not always.","Based on this, we instead directly train on levels with high learnability and find that this simple and intuitive approach outperforms UED methods and DR in several binary-outcome environments, including on our domain and the standard UED domain of Minigrid.","We further introduce a new adversarial evaluation procedure for directly measuring robustness, closely mirroring the conditional value at risk (CVaR).","We open-source all our code and present visualisations of final policies here: https://github.com/amacrutherford/sampling-for-learnability."],"url":"http://arxiv.org/abs/2408.15099v1"}
{"created":"2024-08-27 14:30:06","title":"Data-Driven Nonlinear Deformation Design of 3D-Printable Shells","abstract":"Designing and fabricating structures with specific mechanical properties requires understanding the intricate relationship between design parameters and performance. Understanding the design-performance relationship becomes increasingly complicated for nonlinear deformations. Though successful at modeling elastic deformations, simulation-based techniques struggle to model large elastoplastic deformations exhibiting plasticity and densification. We propose a neural network trained on experimental data to learn the design-performance relationship between 3D-printable shells and their compressive force-displacement behavior. Trained on thousands of physical experiments, our network aids in both forward and inverse design to generate shells exhibiting desired elastoplastic and hyperelastic deformations. We validate a subset of generated designs through fabrication and testing. Furthermore, we demonstrate the network's inverse design efficacy in generating custom shells for several applications.","sentences":["Designing and fabricating structures with specific mechanical properties requires understanding the intricate relationship between design parameters and performance.","Understanding the design-performance relationship becomes increasingly complicated for nonlinear deformations.","Though successful at modeling elastic deformations, simulation-based techniques struggle to model large elastoplastic deformations exhibiting plasticity and densification.","We propose a neural network trained on experimental data to learn the design-performance relationship between 3D-printable shells and their compressive force-displacement behavior.","Trained on thousands of physical experiments, our network aids in both forward and inverse design to generate shells exhibiting desired elastoplastic and hyperelastic deformations.","We validate a subset of generated designs through fabrication and testing.","Furthermore, we demonstrate the network's inverse design efficacy in generating custom shells for several applications."],"url":"http://arxiv.org/abs/2408.15097v1"}
{"created":"2024-08-27 14:25:42","title":"Constrained Diffusion Models via Dual Training","abstract":"Diffusion models have attained prominence for their ability to synthesize a probability distribution for a given dataset via a diffusion process, enabling the generation of new data points with high fidelity. However, diffusion processes are prone to generating biased data based on the training dataset. To address this issue, we develop constrained diffusion models by imposing diffusion constraints based on desired distributions that are informed by requirements. Specifically, we cast the training of diffusion models under requirements as a constrained distribution optimization problem that aims to reduce the distribution difference between original and generated data while obeying constraints on the distribution of generated data. We show that our constrained diffusion models generate new data from a mixture data distribution that achieves the optimal trade-off among objective and constraints. To train constrained diffusion models, we develop a dual training algorithm and characterize the optimality of the trained constrained diffusion model. We empirically demonstrate the effectiveness of our constrained models in two constrained generation tasks: (i) we consider a dataset with one or more underrepresented classes where we train the model with constraints to ensure fairly sampling from all classes during inference; (ii) we fine-tune a pre-trained diffusion model to sample from a new dataset while avoiding overfitting.","sentences":["Diffusion models have attained prominence for their ability to synthesize a probability distribution for a given dataset via a diffusion process, enabling the generation of new data points with high fidelity.","However, diffusion processes are prone to generating biased data based on the training dataset.","To address this issue, we develop constrained diffusion models by imposing diffusion constraints based on desired distributions that are informed by requirements.","Specifically, we cast the training of diffusion models under requirements as a constrained distribution optimization problem that aims to reduce the distribution difference between original and generated data while obeying constraints on the distribution of generated data.","We show that our constrained diffusion models generate new data from a mixture data distribution that achieves the optimal trade-off among objective and constraints.","To train constrained diffusion models, we develop a dual training algorithm and characterize the optimality of the trained constrained diffusion model.","We empirically demonstrate the effectiveness of our constrained models in two constrained generation tasks: (i) we consider a dataset with one or more underrepresented classes where we train the model with constraints to ensure fairly sampling from all classes during inference; (ii) we fine-tune a pre-trained diffusion model to sample from a new dataset while avoiding overfitting."],"url":"http://arxiv.org/abs/2408.15094v1"}
{"created":"2024-08-27 14:20:21","title":"SiHGNN: Leveraging Properties of Semantic Graphs for Efficient HGNN Acceleration","abstract":"Heterogeneous Graph Neural Networks (HGNNs) have expanded graph representation learning to heterogeneous graph fields. Recent studies have demonstrated their superior performance across various applications, including medical analysis and recommendation systems, often surpassing existing methods. However, GPUs often experience inefficiencies when executing HGNNs due to their unique and complex execution patterns. Compared to traditional Graph Neural Networks, these patterns further exacerbate irregularities in memory access. To tackle these challenges, recent studies have focused on developing domain-specific accelerators for HGNNs. Nonetheless, most of these efforts have concentrated on optimizing the datapath or scheduling data accesses, while largely overlooking the potential benefits that could be gained from leveraging the inherent properties of the semantic graph, such as its topology, layout, and generation.   In this work, we focus on leveraging the properties of semantic graphs to enhance HGNN performance. First, we analyze the Semantic Graph Build (SGB) stage and identify significant opportunities for data reuse during semantic graph generation. Next, we uncover the phenomenon of buffer thrashing during the Graph Feature Processing (GFP) stage, revealing potential optimization opportunities in semantic graph layout. Furthermore, we propose a lightweight hardware accelerator frontend for HGNNs, called SiHGNN. This accelerator frontend incorporates a tree-based Semantic Graph Builder for efficient semantic graph generation and features a novel Graph Restructurer for optimizing semantic graph layouts. Experimental results show that SiHGNN enables the state-of-the-art HGNN accelerator to achieve an average performance improvement of 2.95$\\times$.","sentences":["Heterogeneous Graph Neural Networks (HGNNs) have expanded graph representation learning to heterogeneous graph fields.","Recent studies have demonstrated their superior performance across various applications, including medical analysis and recommendation systems, often surpassing existing methods.","However, GPUs often experience inefficiencies when executing HGNNs due to their unique and complex execution patterns.","Compared to traditional Graph Neural Networks, these patterns further exacerbate irregularities in memory access.","To tackle these challenges, recent studies have focused on developing domain-specific accelerators for HGNNs.","Nonetheless, most of these efforts have concentrated on optimizing the datapath or scheduling data accesses, while largely overlooking the potential benefits that could be gained from leveraging the inherent properties of the semantic graph, such as its topology, layout, and generation.   ","In this work, we focus on leveraging the properties of semantic graphs to enhance HGNN performance.","First, we analyze the Semantic Graph Build (SGB) stage and identify significant opportunities for data reuse during semantic graph generation.","Next, we uncover the phenomenon of buffer thrashing during the Graph Feature Processing (GFP) stage, revealing potential optimization opportunities in semantic graph layout.","Furthermore, we propose a lightweight hardware accelerator frontend for HGNNs, called SiHGNN.","This accelerator frontend incorporates a tree-based Semantic Graph Builder for efficient semantic graph generation and features a novel Graph Restructurer for optimizing semantic graph layouts.","Experimental results show that SiHGNN enables the state-of-the-art HGNN accelerator to achieve an average performance improvement of 2.95$\\times$."],"url":"http://arxiv.org/abs/2408.15089v1"}
{"created":"2024-08-27 14:08:23","title":"BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline","abstract":"The general capabilities of Large Language Models (LLM) highly rely on the composition and selection on extensive pretraining datasets, treated as commercial secrets by several institutions. To mitigate this issue, we open-source the details of a universally applicable data processing pipeline and validate its effectiveness and potential by introducing a competitive LLM baseline. Specifically, the data processing pipeline consists of broad collection to scale up and reweighting to improve quality. We then pretrain a 7B model BaichuanSEED with 3T tokens processed by our pipeline without any deliberate downstream task-related optimization, followed by an easy but effective supervised fine-tuning stage. BaichuanSEED demonstrates consistency and predictability throughout training and achieves comparable performance on comprehensive benchmarks with several commercial advanced large language models, such as Qwen1.5 and Llama3. We also conduct several heuristic experiments to discuss the potential for further optimization of downstream tasks, such as mathematics and coding.","sentences":["The general capabilities of Large Language Models (LLM) highly rely on the composition and selection on extensive pretraining datasets, treated as commercial secrets by several institutions.","To mitigate this issue, we open-source the details of a universally applicable data processing pipeline and validate its effectiveness and potential by introducing a competitive LLM baseline.","Specifically, the data processing pipeline consists of broad collection to scale up and reweighting to improve quality.","We then pretrain a 7B model BaichuanSEED with 3T tokens processed by our pipeline without any deliberate downstream task-related optimization, followed by an easy but effective supervised fine-tuning stage.","BaichuanSEED demonstrates consistency and predictability throughout training and achieves comparable performance on comprehensive benchmarks with several commercial advanced large language models, such as Qwen1.5 and Llama3.","We also conduct several heuristic experiments to discuss the potential for further optimization of downstream tasks, such as mathematics and coding."],"url":"http://arxiv.org/abs/2408.15079v1"}
{"created":"2024-08-27 14:05:48","title":"MMASD+: A Novel Dataset for Privacy-Preserving Behavior Analysis of Children with Autism Spectrum Disorder","abstract":"Autism spectrum disorder (ASD) is characterized by significant challenges in social interaction and comprehending communication signals. Recently, therapeutic interventions for ASD have increasingly utilized Deep learning powered-computer vision techniques to monitor individual progress over time. These models are trained on private, non-public datasets from the autism community, creating challenges in comparing results across different models due to privacy-preserving data-sharing issues. This work introduces MMASD+. MMASD+ consists of diverse data modalities, including 3D-Skeleton, 3D Body Mesh, and Optical Flow data. It integrates the capabilities of Yolov8 and Deep SORT algorithms to distinguish between the therapist and children, addressing a significant barrier in the original dataset. Additionally, a Multimodal Transformer framework is proposed to predict 11 action types and the presence of ASD. This framework achieves an accuracy of 95.03% for predicting action types and 96.42% for predicting ASD presence, demonstrating over a 10% improvement compared to models trained on single data modalities. These findings highlight the advantages of integrating multiple data modalities within the Multimodal Transformer framework.","sentences":["Autism spectrum disorder (ASD) is characterized by significant challenges in social interaction and comprehending communication signals.","Recently, therapeutic interventions for ASD have increasingly utilized Deep learning powered-computer vision techniques to monitor individual progress over time.","These models are trained on private, non-public datasets from the autism community, creating challenges in comparing results across different models due to privacy-preserving data-sharing issues.","This work introduces MMASD+.","MMASD+ consists of diverse data modalities, including 3D-Skeleton, 3D Body Mesh, and Optical Flow data.","It integrates the capabilities of Yolov8 and Deep SORT algorithms to distinguish between the therapist and children, addressing a significant barrier in the original dataset.","Additionally, a Multimodal Transformer framework is proposed to predict 11 action types and the presence of ASD.","This framework achieves an accuracy of 95.03% for predicting action types and 96.42% for predicting ASD presence, demonstrating over a 10% improvement compared to models trained on single data modalities.","These findings highlight the advantages of integrating multiple data modalities within the Multimodal Transformer framework."],"url":"http://arxiv.org/abs/2408.15077v1"}
{"created":"2024-08-27 14:04:04","title":"MiWaves Reinforcement Learning Algorithm","abstract":"The escalating prevalence of cannabis use poses a significant public health challenge globally. In the U.S., cannabis use is more prevalent among emerging adults (EAs) (ages 18-25) than any other age group, with legalization in the multiple states contributing to a public perception that cannabis is less risky than in prior decades. To address this growing concern, we developed MiWaves, a reinforcement learning (RL) algorithm designed to optimize the delivery of personalized intervention prompts to reduce cannabis use among EAs. MiWaves leverages domain expertise and prior data to tailor the likelihood of delivery of intervention messages. This paper presents a comprehensive overview of the algorithm's design, including key decisions and experimental outcomes. The finalized MiWaves RL algorithm was deployed in a clinical trial from March to May 2024.","sentences":["The escalating prevalence of cannabis use poses a significant public health challenge globally.","In the U.S., cannabis use is more prevalent among emerging adults (EAs) (ages 18-25) than any other age group, with legalization in the multiple states contributing to a public perception that cannabis is less risky than in prior decades.","To address this growing concern, we developed MiWaves, a reinforcement learning (RL) algorithm designed to optimize the delivery of personalized intervention prompts to reduce cannabis use among EAs.","MiWaves leverages domain expertise and prior data to tailor the likelihood of delivery of intervention messages.","This paper presents a comprehensive overview of the algorithm's design, including key decisions and experimental outcomes.","The finalized MiWaves RL algorithm was deployed in a clinical trial from March to May 2024."],"url":"http://arxiv.org/abs/2408.15076v1"}
{"created":"2024-08-27 14:02:21","title":"Interactive dense pixel visualizations for time series and model attribution explanations","abstract":"The field of Explainable Artificial Intelligence (XAI) for Deep Neural Network models has developed significantly, offering numerous techniques to extract explanations from models. However, evaluating explanations is often not trivial, and differences in applied metrics can be subtle, especially with non-intelligible data. Thus, there is a need for visualizations tailored to explore explanations for domains with such data, e.g., time series. We propose DAVOTS, an interactive visual analytics approach to explore raw time series data, activations of neural networks, and attributions in a dense-pixel visualization to gain insights into the data, models' decisions, and explanations. To further support users in exploring large datasets, we apply clustering approaches to the visualized data domains to highlight groups and present ordering strategies for individual and combined data exploration to facilitate finding patterns. We visualize a CNN trained on the FordA dataset to demonstrate the approach.","sentences":["The field of Explainable Artificial Intelligence (XAI) for Deep Neural Network models has developed significantly, offering numerous techniques to extract explanations from models.","However, evaluating explanations is often not trivial, and differences in applied metrics can be subtle, especially with non-intelligible data.","Thus, there is a need for visualizations tailored to explore explanations for domains with such data, e.g., time series.","We propose DAVOTS, an interactive visual analytics approach to explore raw time series data, activations of neural networks, and attributions in a dense-pixel visualization to gain insights into the data, models' decisions, and explanations.","To further support users in exploring large datasets, we apply clustering approaches to the visualized data domains to highlight groups and present ordering strategies for individual and combined data exploration to facilitate finding patterns.","We visualize a CNN trained on the FordA dataset to demonstrate the approach."],"url":"http://arxiv.org/abs/2408.15073v1"}
{"created":"2024-08-27 13:52:10","title":"On Controlling Knockout Tournaments Without Perfect Information","abstract":"Over the last decade, extensive research has been conducted on the algorithmic aspects of designing single-elimination (SE) tournaments. Addressing natural questions of algorithmic tractability, we identify key properties of input instances that enable the tournament designer to efficiently schedule the tournament in a way that maximizes the chances of a preferred player winning. Much of the prior algorithmic work on this topic focuses on the perfect (complete and deterministic) information scenario, especially in the context of fixed-parameter algorithm design. Our contributions constitute the first fixed-parameter tractability results applicable to more general settings of SE tournament design with potential imperfect information.","sentences":["Over the last decade, extensive research has been conducted on the algorithmic aspects of designing single-elimination (SE) tournaments.","Addressing natural questions of algorithmic tractability, we identify key properties of input instances that enable the tournament designer to efficiently schedule the tournament in a way that maximizes the chances of a preferred player winning.","Much of the prior algorithmic work on this topic focuses on the perfect (complete and deterministic) information scenario, especially in the context of fixed-parameter algorithm design.","Our contributions constitute the first fixed-parameter tractability results applicable to more general settings of SE tournament design with potential imperfect information."],"url":"http://arxiv.org/abs/2408.15068v1"}
{"created":"2024-08-27 13:47:31","title":"Adapting Segment Anything Model to Multi-modal Salient Object Detection with Semantic Feature Fusion Guidance","abstract":"Although most existing multi-modal salient object detection (SOD) methods demonstrate effectiveness through training models from scratch, the limited multi-modal data hinders these methods from reaching optimality. In this paper, we propose a novel framework to explore and exploit the powerful feature representation and zero-shot generalization ability of the pre-trained Segment Anything Model (SAM) for multi-modal SOD. Despite serving as a recent vision fundamental model, driving the class-agnostic SAM to comprehend and detect salient objects accurately is non-trivial, especially in challenging scenes. To this end, we develop \\underline{SAM} with se\\underline{m}antic f\\underline{e}ature fu\\underline{s}ion guidanc\\underline{e} (Sammese), which incorporates multi-modal saliency-specific knowledge into SAM to adapt SAM to multi-modal SOD tasks. However, it is difficult for SAM trained on single-modal data to directly mine the complementary benefits of multi-modal inputs and comprehensively utilize them to achieve accurate saliency prediction.To address these issues, we first design a multi-modal complementary fusion module to extract robust multi-modal semantic features by integrating information from visible and thermal or depth image pairs. Then, we feed the extracted multi-modal semantic features into both the SAM image encoder and mask decoder for fine-tuning and prompting, respectively. Specifically, in the image encoder, a multi-modal adapter is proposed to adapt the single-modal SAM to multi-modal information. In the mask decoder, a semantic-geometric prompt generation strategy is proposed to produce corresponding embeddings with various saliency cues. Extensive experiments on both RGB-D and RGB-T SOD benchmarks show the effectiveness of the proposed framework.","sentences":["Although most existing multi-modal salient object detection (SOD) methods demonstrate effectiveness through training models from scratch, the limited multi-modal data hinders these methods from reaching optimality.","In this paper, we propose a novel framework to explore and exploit the powerful feature representation and zero-shot generalization ability of the pre-trained Segment Anything Model (SAM) for multi-modal SOD.","Despite serving as a recent vision fundamental model, driving the class-agnostic SAM to comprehend and detect salient objects accurately is non-trivial, especially in challenging scenes.","To this end, we develop \\underline{SAM} with se\\underline{m}antic f\\underline{e}ature fu\\underline{s}ion guidanc\\underline{e} (Sammese), which incorporates multi-modal saliency-specific knowledge into SAM to adapt SAM to multi-modal SOD tasks.","However, it is difficult for SAM trained on single-modal data to directly mine the complementary benefits of multi-modal inputs and comprehensively utilize them to achieve accurate saliency prediction.","To address these issues, we first design a multi-modal complementary fusion module to extract robust multi-modal semantic features by integrating information from visible and thermal or depth image pairs.","Then, we feed the extracted multi-modal semantic features into both the SAM image encoder and mask decoder for fine-tuning and prompting, respectively.","Specifically, in the image encoder, a multi-modal adapter is proposed to adapt the single-modal SAM to multi-modal information.","In the mask decoder, a semantic-geometric prompt generation strategy is proposed to produce corresponding embeddings with various saliency cues.","Extensive experiments on both RGB-D and RGB-T SOD benchmarks show the effectiveness of the proposed framework."],"url":"http://arxiv.org/abs/2408.15063v2"}
{"created":"2024-08-27 13:40:15","title":"Subgroup Analysis via Model-based Rule Forest","abstract":"Machine learning models are often criticized for their black-box nature, raising concerns about their applicability in critical decision-making scenarios. Consequently, there is a growing demand for interpretable models in such contexts. In this study, we introduce Model-based Deep Rule Forests (mobDRF), an interpretable representation learning algorithm designed to extract transparent models from data. By leveraging IF-THEN rules with multi-level logic expressions, mobDRF enhances the interpretability of existing models without compromising accuracy. We apply mobDRF to identify key risk factors for cognitive decline in an elderly population, demonstrating its effectiveness in subgroup analysis and local model optimization. Our method offers a promising solution for developing trustworthy and interpretable machine learning models, particularly valuable in fields like healthcare, where understanding differential effects across patient subgroups can lead to more personalized and effective treatments.","sentences":["Machine learning models are often criticized for their black-box nature, raising concerns about their applicability in critical decision-making scenarios.","Consequently, there is a growing demand for interpretable models in such contexts.","In this study, we introduce Model-based Deep Rule Forests (mobDRF), an interpretable representation learning algorithm designed to extract transparent models from data.","By leveraging IF-THEN rules with multi-level logic expressions, mobDRF enhances the interpretability of existing models without compromising accuracy.","We apply mobDRF to identify key risk factors for cognitive decline in an elderly population, demonstrating its effectiveness in subgroup analysis and local model optimization.","Our method offers a promising solution for developing trustworthy and interpretable machine learning models, particularly valuable in fields like healthcare, where understanding differential effects across patient subgroups can lead to more personalized and effective treatments."],"url":"http://arxiv.org/abs/2408.15057v1"}
{"created":"2024-08-27 13:32:31","title":"Causal Rule Forest: Toward Interpretable and Precise Treatment Effect Estimation","abstract":"Understanding and inferencing Heterogeneous Treatment Effects (HTE) and Conditional Average Treatment Effects (CATE) are vital for developing personalized treatment recommendations. Many state-of-the-art approaches achieve inspiring performance in estimating HTE on benchmark datasets or simulation studies. However, the indirect predicting manner and complex model architecture reduce the interpretability of these approaches. To mitigate the gap between predictive performance and heterogeneity interpretability, we introduce the Causal Rule Forest (CRF), a novel approach to learning hidden patterns from data and transforming the patterns into interpretable multi-level Boolean rules. By training the other interpretable causal inference models with data representation learned by CRF, we can reduce the predictive errors of these models in estimating HTE and CATE, while keeping their interpretability for identifying subgroups that a treatment is more effective. Our experiments underscore the potential of CRF to advance personalized interventions and policies, paving the way for future research to enhance its scalability and application across complex causal inference challenges.","sentences":["Understanding and inferencing Heterogeneous Treatment Effects (HTE) and Conditional Average Treatment Effects (CATE) are vital for developing personalized treatment recommendations.","Many state-of-the-art approaches achieve inspiring performance in estimating HTE on benchmark datasets or simulation studies.","However, the indirect predicting manner and complex model architecture reduce the interpretability of these approaches.","To mitigate the gap between predictive performance and heterogeneity interpretability, we introduce the Causal Rule Forest (CRF), a novel approach to learning hidden patterns from data and transforming the patterns into interpretable multi-level Boolean rules.","By training the other interpretable causal inference models with data representation learned by CRF, we can reduce the predictive errors of these models in estimating HTE and CATE, while keeping their interpretability for identifying subgroups that a treatment is more effective.","Our experiments underscore the potential of CRF to advance personalized interventions and policies, paving the way for future research to enhance its scalability and application across complex causal inference challenges."],"url":"http://arxiv.org/abs/2408.15055v1"}
{"created":"2024-08-27 13:10:05","title":"A Survey of Large Language Models for European Languages","abstract":"Large Language Models (LLMs) have gained significant attention due to their high performance on a wide range of natural language tasks since the release of ChatGPT. The LLMs learn to understand and generate language by training billions of model parameters on vast volumes of text data. Despite being a relatively new field, LLM research is rapidly advancing in various directions. In this paper, we present an overview of LLM families, including LLaMA, PaLM, GPT, and MoE, and the methods developed to create and enhance LLMs for official European Union (EU) languages. We provide a comprehensive summary of common monolingual and multilingual datasets used for pretraining large language models.","sentences":["Large Language Models (LLMs) have gained significant attention due to their high performance on a wide range of natural language tasks since the release of ChatGPT.","The LLMs learn to understand and generate language by training billions of model parameters on vast volumes of text data.","Despite being a relatively new field, LLM research is rapidly advancing in various directions.","In this paper, we present an overview of LLM families, including LLaMA, PaLM, GPT, and MoE, and the methods developed to create and enhance LLMs for official European Union (EU) languages.","We provide a comprehensive summary of common monolingual and multilingual datasets used for pretraining large language models."],"url":"http://arxiv.org/abs/2408.15040v2"}
{"created":"2024-08-27 13:07:09","title":"Interactive Occlusion Boundary Estimation through Exploitation of Synthetic Data","abstract":"Occlusion boundaries (OBs) geometrically localize the occlusion events in a 2D image, and contain useful information for addressing various scene understanding problems. To advance their study, we have led the investigation in the following three aspects. Firstly, we have studied interactive estimation of OBs, which is the first in the literature, and proposed an efficient deep-network-based method using multiple-scribble intervention, named DNMMSI, which significantly improves the performance over the state-of-the-art fully-automatic methods. Secondly, we propose to exploit the synthetic benchmark for the training process, thanks to the particularity that OBs are determined geometrically and unambiguously from the 3D scene. To this end, we have developed an efficient tool, named Mesh2OB, for the automatic generation of 2D images together with their ground-truth OBs, using which we have constructed a synthetic benchmark, named OB-FUTURE. Abundant experimental results demonstrate that leveraging such a synthetic benchmark for training achieves promising performance, even without the use of domain adaptation techniques. Finally, to achieve a more compelling and robust evaluation in OB-related research, we have created a real benchmark, named OB-LabName, consisting of 120 high-resolution images together with their ground-truth OBs, with precision surpassing that of previous benchmarks. We will release DNMMSI with pre-trained parameters, Mesh2OB, OB-FUTURE, and OB-LabName to support further research.","sentences":["Occlusion boundaries (OBs) geometrically localize the occlusion events in a 2D image, and contain useful information for addressing various scene understanding problems.","To advance their study, we have led the investigation in the following three aspects.","Firstly, we have studied interactive estimation of OBs, which is the first in the literature, and proposed an efficient deep-network-based method using multiple-scribble intervention, named DNMMSI, which significantly improves the performance over the state-of-the-art fully-automatic methods.","Secondly, we propose to exploit the synthetic benchmark for the training process, thanks to the particularity that OBs are determined geometrically and unambiguously from the 3D scene.","To this end, we have developed an efficient tool, named Mesh2OB, for the automatic generation of 2D images together with their ground-truth OBs, using which we have constructed a synthetic benchmark, named OB-FUTURE.","Abundant experimental results demonstrate that leveraging such a synthetic benchmark for training achieves promising performance, even without the use of domain adaptation techniques.","Finally, to achieve a more compelling and robust evaluation in OB-related research, we have created a real benchmark, named OB-LabName, consisting of 120 high-resolution images together with their ground-truth OBs, with precision surpassing that of previous benchmarks.","We will release DNMMSI with pre-trained parameters, Mesh2OB, OB-FUTURE, and OB-LabName to support further research."],"url":"http://arxiv.org/abs/2408.15038v1"}
{"created":"2024-08-27 12:55:54","title":"Sequence-aware Pre-training for Echocardiography Probe Guidance","abstract":"Cardiac ultrasound probe guidance aims to help novices adjust the 6-DOF probe pose to obtain high-quality sectional images. Cardiac ultrasound faces two major challenges: (1) the inherently complex structure of the heart, and (2) significant individual variations. Previous works have only learned the population-averaged 2D and 3D structures of the heart rather than personalized cardiac structural features, leading to a performance bottleneck. Clinically, we observed that sonographers adjust their understanding of a patient's cardiac structure based on prior scanning sequences, thereby modifying their scanning strategies. Inspired by this, we propose a sequence-aware self-supervised pre-training method. Specifically, our approach learns personalized 2D and 3D cardiac structural features by predicting the masked-out images and actions in a scanning sequence. We hypothesize that if the model can predict the missing content it has acquired a good understanding of the personalized cardiac structure. In the downstream probe guidance task, we also introduced a sequence modeling approach that models individual cardiac structural information based on the images and actions from historical scan data, enabling more accurate navigation decisions. Experiments on a large-scale dataset with 1.36 million samples demonstrated that our proposed sequence-aware paradigm can significantly reduce navigation errors, with translation errors decreasing by 15.90% to 36.87% and rotation errors decreasing by 11.13% to 20.77%, compared to state-of-the-art methods.","sentences":["Cardiac ultrasound probe guidance aims to help novices adjust the 6-DOF probe pose to obtain high-quality sectional images.","Cardiac ultrasound faces two major challenges: (1) the inherently complex structure of the heart, and (2) significant individual variations.","Previous works have only learned the population-averaged 2D and 3D structures of the heart rather than personalized cardiac structural features, leading to a performance bottleneck.","Clinically, we observed that sonographers adjust their understanding of a patient's cardiac structure based on prior scanning sequences, thereby modifying their scanning strategies.","Inspired by this, we propose a sequence-aware self-supervised pre-training method.","Specifically, our approach learns personalized 2D and 3D cardiac structural features by predicting the masked-out images and actions in a scanning sequence.","We hypothesize that if the model can predict the missing content it has acquired a good understanding of the personalized cardiac structure.","In the downstream probe guidance task, we also introduced a sequence modeling approach that models individual cardiac structural information based on the images and actions from historical scan data, enabling more accurate navigation decisions.","Experiments on a large-scale dataset with 1.36 million samples demonstrated that our proposed sequence-aware paradigm can significantly reduce navigation errors, with translation errors decreasing by 15.90% to 36.87% and rotation errors decreasing by 11.13% to 20.77%, compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2408.15026v1"}
{"created":"2024-08-27 12:48:46","title":"Pre-training Everywhere: Parameter-Efficient Fine-Tuning for Medical Image Analysis via Target Parameter Pre-training","abstract":"Parameter-efficient fine-tuning (PEFT) techniques have emerged to address issues of overfitting and high computational costs associated with fully fine-tuning in the paradigm of self-supervised learning. Mainstream methods based on PEFT involve adding a few trainable parameters while keeping the pre-trained parameters of the backbone fixed. These methods achieve comparative, and often superior, performance to fully fine-tuning, demonstrating the powerful representation ability of the pre-trained backbone. Despite its success, these methods typically ignore the initialization of the new parameters, often relying solely on random initialization. We argue that if pre-training is significantly beneficial, it should be applied to all parameters requiring representational capacity. Motivated by this insight, we propose a simple yet effective fine-tuning framework based on Target Parameter Pre-training (TPP). The target parameters refer to the new parameters introduced during fine-tuning. TPP includes an additional stage before PEFT to pre-train these target parameters. During this stage, the pre-trained backbone parameters are frozen, and only the target parameters are trainable. A defined pre-text task is used to encourage the target parameters to learn specific representations of downstream data. When PEFT is subsequently employed, the pre-trained target parameters are loaded to enhance fine-tuning efficiency. The proposed TPP framework is versatile, allowing for the integration of various pretext tasks for pre-training and supporting different PEFT methods as backbones. We evaluated the fine-tining performance of our method using five public datasets, including three modalities and two task types. The results demonstrate that the proposed TPP can be easily integrated into existing PEFT methods, significantly improving performance.","sentences":["Parameter-efficient fine-tuning (PEFT) techniques have emerged to address issues of overfitting and high computational costs associated with fully fine-tuning in the paradigm of self-supervised learning.","Mainstream methods based on PEFT involve adding a few trainable parameters while keeping the pre-trained parameters of the backbone fixed.","These methods achieve comparative, and often superior, performance to fully fine-tuning, demonstrating the powerful representation ability of the pre-trained backbone.","Despite its success, these methods typically ignore the initialization of the new parameters, often relying solely on random initialization.","We argue that if pre-training is significantly beneficial, it should be applied to all parameters requiring representational capacity.","Motivated by this insight, we propose a simple yet effective fine-tuning framework based on Target Parameter Pre-training (TPP).","The target parameters refer to the new parameters introduced during fine-tuning.","TPP includes an additional stage before PEFT to pre-train these target parameters.","During this stage, the pre-trained backbone parameters are frozen, and only the target parameters are trainable.","A defined pre-text task is used to encourage the target parameters to learn specific representations of downstream data.","When PEFT is subsequently employed, the pre-trained target parameters are loaded to enhance fine-tuning efficiency.","The proposed TPP framework is versatile, allowing for the integration of various pretext tasks for pre-training and supporting different PEFT methods as backbones.","We evaluated the fine-tining performance of our method using five public datasets, including three modalities and two task types.","The results demonstrate that the proposed TPP can be easily integrated into existing PEFT methods, significantly improving performance."],"url":"http://arxiv.org/abs/2408.15011v1"}
{"created":"2024-08-27 12:41:37","title":"Measuring publication relatedness using controlled vocabularies","abstract":"Measuring the relatedness between scientific publications has important applications in many areas of bibliometrics and science policy. Controlled vocabularies provide a promising basis for measuring relatedness because they address issues that arise when using citation or textual similarity to measure relatedness. While several controlled-vocabulary-based relatedness measures have been developed, there exists no comprehensive and direct test of their accuracy and suitability for different types of research questions. This paper reviews existing measures, develops a new measure, and benchmarks the measures using TREC Genomics data as a ground truth of topics. The benchmark test show that the new measure and the measure proposed by Ahlgren et al. (2020) have differing strengths and weaknesses. These results inform a discussion of which method to choose when studying interdisciplinarity, information retrieval, clustering of science, and researcher topic switching.","sentences":["Measuring the relatedness between scientific publications has important applications in many areas of bibliometrics and science policy.","Controlled vocabularies provide a promising basis for measuring relatedness because they address issues that arise when using citation or textual similarity to measure relatedness.","While several controlled-vocabulary-based relatedness measures have been developed, there exists no comprehensive and direct test of their accuracy and suitability for different types of research questions.","This paper reviews existing measures, develops a new measure, and benchmarks the measures using TREC Genomics data as a ground truth of topics.","The benchmark test show that the new measure and the measure proposed by Ahlgren et al. (2020) have differing strengths and weaknesses.","These results inform a discussion of which method to choose when studying interdisciplinarity, information retrieval, clustering of science, and researcher topic switching."],"url":"http://arxiv.org/abs/2408.15004v1"}
{"created":"2024-08-27 12:34:03","title":"PaceMaker: A Practical Tool for Pacing Video Games","abstract":"Designing pacing for video games presents a unique set of challenges. Due to their interactivity, non-linearity, and narrative nature, many aspects must be coordinated and considered simultaneously. In addition, games are often developed in an iterative workflow, making revisions to previous designs difficult and time-consuming. In this paper, we present PaceMaker, a toolkit designed to enable common design workflows for pacing while addressing the challenges above. We conducted initial research on pacing and then implemented our findings in a platform-independent application that allows the user to define simple state diagrams to deal with the possibility space of games. The user can select paths on the directed graph to visualize a node's data in diagrams dedicated to intensity and gameplay category. After implementation, we created a demonstration of the tool and conducted qualitative interviews. While the interviews raised some concerns about the efficiency of PaceMaker, the results https://info.arxiv.org/help/prep#commentsdemonstrate the expressiveness of the toolkit and support the need for such a tool.","sentences":["Designing pacing for video games presents a unique set of challenges.","Due to their interactivity, non-linearity, and narrative nature, many aspects must be coordinated and considered simultaneously.","In addition, games are often developed in an iterative workflow, making revisions to previous designs difficult and time-consuming.","In this paper, we present PaceMaker, a toolkit designed to enable common design workflows for pacing while addressing the challenges above.","We conducted initial research on pacing and then implemented our findings in a platform-independent application that allows the user to define simple state diagrams to deal with the possibility space of games.","The user can select paths on the directed graph to visualize a node's data in diagrams dedicated to intensity and gameplay category.","After implementation, we created a demonstration of the tool and conducted qualitative interviews.","While the interviews raised some concerns about the efficiency of PaceMaker, the results https://info.arxiv.org/help/prep#commentsdemonstrate the expressiveness of the toolkit and support the need for such a tool."],"url":"http://arxiv.org/abs/2408.15001v1"}
{"created":"2024-08-27 12:25:12","title":"Depth Restoration of Hand-Held Transparent Objects for Human-to-Robot Handover","abstract":"Transparent objects are common in daily life, while their unique optical properties pose challenges for RGB-D cameras, which struggle to capture accurate depth information. For assistant robots, accurately perceiving transparent objects held by humans is essential for effective human-robot interaction. This paper presents a Hand-Aware Depth Restoration (HADR) method for hand-held transparent objects based on creating an implicit neural representation function from a single RGB-D image. The proposed method introduces the hand posture as an important guidance to leverage semantic and geometric information. To train and evaluate the proposed method, we create a high-fidelity synthetic dataset called TransHand-14K with a real-to-sim data generation scheme. Experiments show that our method has a better performance and generalization ability compared with existing methods. We further develop a real-world human-to-robot handover system based on the proposed depth restoration method, demonstrating its application value in human-robot interaction.","sentences":["Transparent objects are common in daily life, while their unique optical properties pose challenges for RGB-D cameras, which struggle to capture accurate depth information.","For assistant robots, accurately perceiving transparent objects held by humans is essential for effective human-robot interaction.","This paper presents a Hand-Aware Depth Restoration (HADR) method for hand-held transparent objects based on creating an implicit neural representation function from a single RGB-D image.","The proposed method introduces the hand posture as an important guidance to leverage semantic and geometric information.","To train and evaluate the proposed method, we create a high-fidelity synthetic dataset called TransHand-14K with a real-to-sim data generation scheme.","Experiments show that our method has a better performance and generalization ability compared with existing methods.","We further develop a real-world human-to-robot handover system based on the proposed depth restoration method, demonstrating its application value in human-robot interaction."],"url":"http://arxiv.org/abs/2408.14997v1"}
{"created":"2024-08-27 11:38:01","title":"Prior-free Balanced Replay: Uncertainty-guided Reservoir Sampling for Long-Tailed Continual Learning","abstract":"Even in the era of large models, one of the well-known issues in continual learning (CL) is catastrophic forgetting, which is significantly challenging when the continual data stream exhibits a long-tailed distribution, termed as Long-Tailed Continual Learning (LTCL). Existing LTCL solutions generally require the label distribution of the data stream to achieve re-balance training. However, obtaining such prior information is often infeasible in real scenarios since the model should learn without pre-identifying the majority and minority classes. To this end, we propose a novel Prior-free Balanced Replay (PBR) framework to learn from long-tailed data stream with less forgetting. Concretely, motivated by our experimental finding that the minority classes are more likely to be forgotten due to the higher uncertainty, we newly design an uncertainty-guided reservoir sampling strategy to prioritize rehearsing minority data without using any prior information, which is based on the mutual dependence between the model and samples. Additionally, we incorporate two prior-free components to further reduce the forgetting issue: (1) Boundary constraint is to preserve uncertain boundary supporting samples for continually re-estimating task boundaries. (2) Prototype constraint is to maintain the consistency of learned class prototypes along with training. Our approach is evaluated on three standard long-tailed benchmarks, demonstrating superior performance to existing CL methods and previous SOTA LTCL approach in both task- and class-incremental learning settings, as well as ordered- and shuffled-LTCL settings.","sentences":["Even in the era of large models, one of the well-known issues in continual learning (CL) is catastrophic forgetting, which is significantly challenging when the continual data stream exhibits a long-tailed distribution, termed as Long-Tailed Continual Learning (LTCL).","Existing LTCL solutions generally require the label distribution of the data stream to achieve re-balance training.","However, obtaining such prior information is often infeasible in real scenarios since the model should learn without pre-identifying the majority and minority classes.","To this end, we propose a novel Prior-free Balanced Replay (PBR) framework to learn from long-tailed data stream with less forgetting.","Concretely, motivated by our experimental finding that the minority classes are more likely to be forgotten due to the higher uncertainty, we newly design an uncertainty-guided reservoir sampling strategy to prioritize rehearsing minority data without using any prior information, which is based on the mutual dependence between the model and samples.","Additionally, we incorporate two prior-free components to further reduce the forgetting issue: (1) Boundary constraint is to preserve uncertain boundary supporting samples for continually re-estimating task boundaries.","(2) Prototype constraint is to maintain the consistency of learned class prototypes along with training.","Our approach is evaluated on three standard long-tailed benchmarks, demonstrating superior performance to existing CL methods and previous SOTA LTCL approach in both task- and class-incremental learning settings, as well as ordered- and shuffled-LTCL settings."],"url":"http://arxiv.org/abs/2408.14976v1"}
{"created":"2024-08-27 11:29:08","title":"Finding Convincing Views to Endorse a Claim","abstract":"Recent studies investigated the challenge of assessing the strength of a given claim extracted from a dataset, particularly the claim's potential of being misleading and cherry-picked. We focus on claims that compare answers to an aggregate query posed on a view that selects tuples. The strength of a claim amounts to the question of how likely it is that the view is carefully chosen to support the claim, whereas less careful choices would lead to contradictory claims. We embark on the study of the reverse task that offers a complementary angle in the critical assessment of data-based claims: given a claim, find useful supporting views. The goal of this task is twofold. On the one hand, we aim to assist users in finding significant evidence of phenomena of interest. On the other hand, we wish to provide them with machinery to criticize or counter given claims by extracting evidence of opposing statements.   To be effective, the supporting sub-population should be significant and defined by a ``natural'' view. We discuss several measures of naturalness and propose ways of extracting the best views under each measure (and combinations thereof). The main challenge is the computational cost, as na\\\"ive search is infeasible. We devise anytime algorithms that deploy two main steps: (1) a preliminary construction of a ranked list of attribute combinations that are assessed using fast-to-compute features, and (2) an efficient search for the actual views based on each attribute combination. We present a thorough experimental study that shows the effectiveness of our algorithms in terms of quality and execution cost. We also present a user study to assess the usefulness of the naturalness measures.","sentences":["Recent studies investigated the challenge of assessing the strength of a given claim extracted from a dataset, particularly the claim's potential of being misleading and cherry-picked.","We focus on claims that compare answers to an aggregate query posed on a view that selects tuples.","The strength of a claim amounts to the question of how likely it is that the view is carefully chosen to support the claim, whereas less careful choices would lead to contradictory claims.","We embark on the study of the reverse task that offers a complementary angle in the critical assessment of data-based claims: given a claim, find useful supporting views.","The goal of this task is twofold.","On the one hand, we aim to assist users in finding significant evidence of phenomena of interest.","On the other hand, we wish to provide them with machinery to criticize or counter given claims by extracting evidence of opposing statements.   ","To be effective, the supporting sub-population should be significant and defined by a ``natural'' view.","We discuss several measures of naturalness and propose ways of extracting the best views under each measure (and combinations thereof).","The main challenge is the computational cost, as na\\\"ive search is infeasible.","We devise anytime algorithms that deploy two main steps: (1) a preliminary construction of a ranked list of attribute combinations that are assessed using fast-to-compute features, and (2) an efficient search for the actual views based on each attribute combination.","We present a thorough experimental study that shows the effectiveness of our algorithms in terms of quality and execution cost.","We also present a user study to assess the usefulness of the naturalness measures."],"url":"http://arxiv.org/abs/2408.14974v1"}
{"created":"2024-08-27 11:21:19","title":"MRSE: An Efficient Multi-modality Retrieval System for Large Scale E-commerce","abstract":"Providing high-quality item recall for text queries is crucial in large-scale e-commerce search systems. Current Embedding-based Retrieval Systems (ERS) embed queries and items into a shared low-dimensional space, but uni-modality ERS rely too heavily on textual features, making them unreliable in complex contexts. While multi-modality ERS incorporate various data sources, they often overlook individual preferences for different modalities, leading to suboptimal results. To address these issues, we propose MRSE, a Multi-modality Retrieval System that integrates text, item images, and user preferences through lightweight mixture-of-expert (LMoE) modules to better align features across and within modalities. MRSE also builds user profiles at a multi-modality level and introduces a novel hybrid loss function that enhances consistency and robustness using hard negative sampling. Experiments on a large-scale dataset from Shopee and online A/B testing show that MRSE achieves an 18.9% improvement in offline relevance and a 3.7% gain in online core metrics compared to Shopee's state-of-the-art uni-modality system.","sentences":["Providing high-quality item recall for text queries is crucial in large-scale e-commerce search systems.","Current Embedding-based Retrieval Systems (ERS) embed queries and items into a shared low-dimensional space, but uni-modality ERS rely too heavily on textual features, making them unreliable in complex contexts.","While multi-modality ERS incorporate various data sources, they often overlook individual preferences for different modalities, leading to suboptimal results.","To address these issues, we propose MRSE, a Multi-modality Retrieval System that integrates text, item images, and user preferences through lightweight mixture-of-expert (LMoE) modules to better align features across and within modalities.","MRSE also builds user profiles at a multi-modality level and introduces a novel hybrid loss function that enhances consistency and robustness using hard negative sampling.","Experiments on a large-scale dataset from Shopee and online A/B testing show that MRSE achieves an 18.9% improvement in offline relevance and a 3.7% gain in online core metrics compared to Shopee's state-of-the-art uni-modality system."],"url":"http://arxiv.org/abs/2408.14968v1"}
{"created":"2024-08-27 11:10:39","title":"Cross-Modal Learning for Chemistry Property Prediction: Large Language Models Meet Graph Machine Learning","abstract":"In the field of chemistry, the objective is to create novel molecules with desired properties, facilitating accurate property predictions for applications such as material design and drug screening. However, existing graph deep learning methods face limitations that curb their expressive power. To address this, we explore the integration of vast molecular domain knowledge from Large Language Models (LLMs) with the complementary strengths of Graph Neural Networks (GNNs) to enhance performance in property prediction tasks. We introduce a Multi-Modal Fusion (MMF) framework that synergistically harnesses the analytical prowess of GNNs and the linguistic generative and predictive abilities of LLMs, thereby improving accuracy and robustness in predicting molecular properties. Our framework combines the effectiveness of GNNs in modeling graph-structured data with the zero-shot and few-shot learning capabilities of LLMs, enabling improved predictions while reducing the risk of overfitting. Furthermore, our approach effectively addresses distributional shifts, a common challenge in real-world applications, and showcases the efficacy of learning cross-modal representations, surpassing state-of-the-art baselines on benchmark datasets for property prediction tasks.","sentences":["In the field of chemistry, the objective is to create novel molecules with desired properties, facilitating accurate property predictions for applications such as material design and drug screening.","However, existing graph deep learning methods face limitations that curb their expressive power.","To address this, we explore the integration of vast molecular domain knowledge from Large Language Models (LLMs) with the complementary strengths of Graph Neural Networks (GNNs) to enhance performance in property prediction tasks.","We introduce a Multi-Modal Fusion (MMF) framework that synergistically harnesses the analytical prowess of GNNs and the linguistic generative and predictive abilities of LLMs, thereby improving accuracy and robustness in predicting molecular properties.","Our framework combines the effectiveness of GNNs in modeling graph-structured data with the zero-shot and few-shot learning capabilities of LLMs, enabling improved predictions while reducing the risk of overfitting.","Furthermore, our approach effectively addresses distributional shifts, a common challenge in real-world applications, and showcases the efficacy of learning cross-modal representations, surpassing state-of-the-art baselines on benchmark datasets for property prediction tasks."],"url":"http://arxiv.org/abs/2408.14964v1"}
{"created":"2024-08-27 11:09:34","title":"Deep Learning-based Average Shear Wave Velocity Prediction using Accelerometer Records","abstract":"Assessing seismic hazards and thereby designing earthquake-resilient structures or evaluating structural damage that has been incurred after an earthquake are important objectives in earthquake engineering. Both tasks require critical evaluation of strong ground motion records, and the knowledge of site conditions at the earthquake stations plays a major role in achieving the aforementioned objectives. Site conditions are generally represented by the time-averaged shear wave velocity in the upper 30 meters of the geological materials (Vs30). Several strong motion stations lack Vs30 measurements resulting in potentially inaccurate assessment of seismic hazards and evaluation of ground motion records. In this study, we present a deep learning-based approach for predicting Vs30 at strong motion station locations using three-channel earthquake records. For this purpose, Convolutional Neural Networks (CNNs) with dilated and causal convolutional layers are used to extract deep features from accelerometer records collected from over 700 stations located in Turkey. In order to overcome the limited availability of labeled data, we propose a two-phase training approach. In the first phase, a CNN is trained to estimate the epicenters, for which ground truth is available for all records. After the CNN is trained, the pre-trained encoder is fine-tuned based on the Vs30 ground truth. The performance of the proposed method is compared with machine learning models that utilize hand-crafted features. The results demonstrate that the deep convolutional encoder based Vs30 prediction model outperforms the machine learning models that rely on hand-crafted features.","sentences":["Assessing seismic hazards and thereby designing earthquake-resilient structures or evaluating structural damage that has been incurred after an earthquake are important objectives in earthquake engineering.","Both tasks require critical evaluation of strong ground motion records, and the knowledge of site conditions at the earthquake stations plays a major role in achieving the aforementioned objectives.","Site conditions are generally represented by the time-averaged shear wave velocity in the upper 30 meters of the geological materials (Vs30).","Several strong motion stations lack Vs30 measurements resulting in potentially inaccurate assessment of seismic hazards and evaluation of ground motion records.","In this study, we present a deep learning-based approach for predicting Vs30 at strong motion station locations using three-channel earthquake records.","For this purpose, Convolutional Neural Networks (CNNs) with dilated and causal convolutional layers are used to extract deep features from accelerometer records collected from over 700 stations located in Turkey.","In order to overcome the limited availability of labeled data, we propose a two-phase training approach.","In the first phase, a CNN is trained to estimate the epicenters, for which ground truth is available for all records.","After the CNN is trained, the pre-trained encoder is fine-tuned based on the Vs30 ground truth.","The performance of the proposed method is compared with machine learning models that utilize hand-crafted features.","The results demonstrate that the deep convolutional encoder based Vs30 prediction model outperforms the machine learning models that rely on hand-crafted features."],"url":"http://arxiv.org/abs/2408.14962v1"}
{"created":"2024-08-27 11:07:15","title":"Multilingual Arbitrage: Optimizing Data Pools to Accelerate Multilingual Progress","abstract":"The use of synthetic data has played a critical role in recent state-of-art breakthroughs. However, overly relying on a single oracle teacher model to generate data has been shown to lead to model collapse and invite propagation of biases. These limitations are particularly evident in multilingual settings, where the absence of a universally effective teacher model that excels across all languages presents significant challenges. In this work, we address these extreme difference by introducing \"multilingual arbitrage\", which capitalizes on performance variations between multiple models for a given language. To do so, we strategically route samples through a diverse pool of models, each with unique strengths in different languages. Across exhaustive experiments on state-of-art models, our work suggests that arbitrage techniques allow for spectacular gains in performance that far outperform relying on a single teacher. In particular, compared to the best single teacher, we observe gains of up to 56.5% improvement in win rates averaged across all languages when switching to multilingual arbitrage. We observe the most significant gains for the least resourced languages in our pool.","sentences":["The use of synthetic data has played a critical role in recent state-of-art breakthroughs.","However, overly relying on a single oracle teacher model to generate data has been shown to lead to model collapse and invite propagation of biases.","These limitations are particularly evident in multilingual settings, where the absence of a universally effective teacher model that excels across all languages presents significant challenges.","In this work, we address these extreme difference by introducing \"multilingual arbitrage\", which capitalizes on performance variations between multiple models for a given language.","To do so, we strategically route samples through a diverse pool of models, each with unique strengths in different languages.","Across exhaustive experiments on state-of-art models, our work suggests that arbitrage techniques allow for spectacular gains in performance that far outperform relying on a single teacher.","In particular, compared to the best single teacher, we observe gains of up to 56.5% improvement in win rates averaged across all languages when switching to multilingual arbitrage.","We observe the most significant gains for the least resourced languages in our pool."],"url":"http://arxiv.org/abs/2408.14960v1"}
{"created":"2024-08-27 10:54:37","title":"NeuralOOD: Improving Out-of-Distribution Generalization Performance with Brain-machine Fusion Learning Framework","abstract":"Deep Neural Networks (DNNs) have demonstrated exceptional recognition capabilities in traditional computer vision (CV) tasks. However, existing CV models often suffer a significant decrease in accuracy when confronted with out-of-distribution (OOD) data. In contrast to these DNN models, human can maintain a consistently low error rate when facing OOD scenes, partly attributed to the rich prior cognitive knowledge stored in the human brain. Previous OOD generalization researches only focus on the single modal, overlooking the advantages of multimodal learning method. In this paper, we utilize the multimodal learning method to improve the OOD generalization and propose a novel Brain-machine Fusion Learning (BMFL) framework. We adopt the cross-attention mechanism to fuse the visual knowledge from CV model and prior cognitive knowledge from the human brain. Specially, we employ a pre-trained visual neural encoding model to predict the functional Magnetic Resonance Imaging (fMRI) from visual features which eliminates the need for the fMRI data collection and pre-processing, effectively reduces the workload associated with conventional BMFL methods. Furthermore, we construct a brain transformer to facilitate the extraction of knowledge inside the fMRI data. Moreover, we introduce the Pearson correlation coefficient maximization regularization method into the training process, which improves the fusion capability with better constrains. Our model outperforms the DINOv2 and baseline models on the ImageNet-1k validation dataset as well as six curated OOD datasets, showcasing its superior performance in diverse scenarios.","sentences":["Deep Neural Networks (DNNs) have demonstrated exceptional recognition capabilities in traditional computer vision (CV) tasks.","However, existing CV models often suffer a significant decrease in accuracy when confronted with out-of-distribution (OOD) data.","In contrast to these DNN models, human can maintain a consistently low error rate when facing OOD scenes, partly attributed to the rich prior cognitive knowledge stored in the human brain.","Previous OOD generalization researches only focus on the single modal, overlooking the advantages of multimodal learning method.","In this paper, we utilize the multimodal learning method to improve the OOD generalization and propose a novel Brain-machine Fusion Learning (BMFL) framework.","We adopt the cross-attention mechanism to fuse the visual knowledge from CV model and prior cognitive knowledge from the human brain.","Specially, we employ a pre-trained visual neural encoding model to predict the functional Magnetic Resonance Imaging (fMRI) from visual features which eliminates the need for the fMRI data collection and pre-processing, effectively reduces the workload associated with conventional BMFL methods.","Furthermore, we construct a brain transformer to facilitate the extraction of knowledge inside the fMRI data.","Moreover, we introduce the Pearson correlation coefficient maximization regularization method into the training process, which improves the fusion capability with better constrains.","Our model outperforms the DINOv2 and baseline models on the ImageNet-1k validation dataset as well as six curated OOD datasets, showcasing its superior performance in diverse scenarios."],"url":"http://arxiv.org/abs/2408.14950v1"}
{"created":"2024-08-27 10:26:05","title":"BOX3D: Lightweight Camera-LiDAR Fusion for 3D Object Detection and Localization","abstract":"Object detection and global localization play a crucial role in robotics, spanning across a great spectrum of applications from autonomous cars to multi-layered 3D Scene Graphs for semantic scene understanding. This article proposes BOX3D, a novel multi-modal and lightweight scheme for localizing objects of interest by fusing the information from RGB camera and 3D LiDAR. BOX3D is structured around a three-layered architecture, building up from the local perception of the incoming sequential sensor data to the global perception refinement that covers for outliers and the general consistency of each object's observation. More specifically, the first layer handles the low-level fusion of camera and LiDAR data for initial 3D bounding box extraction. The second layer converts each LiDAR's scan 3D bounding boxes to the world coordinate frame and applies a spatial pairing and merging mechanism to maintain the uniqueness of objects observed from different viewpoints. Finally, BOX3D integrates the third layer that supervises the consistency of the results on the global map iteratively, using a point-to-voxel comparison for identifying all points in the global map that belong to the object. Benchmarking results of the proposed novel architecture are showcased in multiple experimental trials on public state-of-the-art large-scale dataset of urban environments.","sentences":["Object detection and global localization play a crucial role in robotics, spanning across a great spectrum of applications from autonomous cars to multi-layered 3D Scene Graphs for semantic scene understanding.","This article proposes BOX3D, a novel multi-modal and lightweight scheme for localizing objects of interest by fusing the information from RGB camera and 3D LiDAR.","BOX3D is structured around a three-layered architecture, building up from the local perception of the incoming sequential sensor data to the global perception refinement that covers for outliers and the general consistency of each object's observation.","More specifically, the first layer handles the low-level fusion of camera and LiDAR data for initial 3D bounding box extraction.","The second layer converts each LiDAR's scan 3D bounding boxes to the world coordinate frame and applies a spatial pairing and merging mechanism to maintain the uniqueness of objects observed from different viewpoints.","Finally, BOX3D integrates the third layer that supervises the consistency of the results on the global map iteratively, using a point-to-voxel comparison for identifying all points in the global map that belong to the object.","Benchmarking results of the proposed novel architecture are showcased in multiple experimental trials on public state-of-the-art large-scale dataset of urban environments."],"url":"http://arxiv.org/abs/2408.14941v1"}
{"created":"2024-08-27 10:17:22","title":"Quotient Normalized Maximum Likelihood Criterion for Learning Bayesian Network Structures","abstract":"We introduce an information theoretic criterion for Bayesian network structure learning which we call quotient normalized maximum likelihood (qNML). In contrast to the closely related factorized normalized maximum likelihood criterion, qNML satisfies the property of score equivalence. It is also decomposable and completely free of adjustable hyperparameters. For practical computations, we identify a remarkably accurate approximation proposed earlier by Szpankowski and Weinberger. Experiments on both simulated and real data demonstrate that the new criterion leads to parsimonious models with good predictive accuracy.","sentences":["We introduce an information theoretic criterion for Bayesian network structure learning which we call quotient normalized maximum likelihood (qNML).","In contrast to the closely related factorized normalized maximum likelihood criterion, qNML satisfies the property of score equivalence.","It is also decomposable and completely free of adjustable hyperparameters.","For practical computations, we identify a remarkably accurate approximation proposed earlier by Szpankowski and Weinberger.","Experiments on both simulated and real data demonstrate that the new criterion leads to parsimonious models with good predictive accuracy."],"url":"http://arxiv.org/abs/2408.14935v1"}
{"created":"2024-08-27 10:09:17","title":"CMTA: Cross-Modal Temporal Alignment for Event-guided Video Deblurring","abstract":"Video deblurring aims to enhance the quality of restored results in motion-blurred videos by effectively gathering information from adjacent video frames to compensate for the insufficient data in a single blurred frame. However, when faced with consecutively severe motion blur situations, frame-based video deblurring methods often fail to find accurate temporal correspondence among neighboring video frames, leading to diminished performance. To address this limitation, we aim to solve the video deblurring task by leveraging an event camera with micro-second temporal resolution. To fully exploit the dense temporal resolution of the event camera, we propose two modules: 1) Intra-frame feature enhancement operates within the exposure time of a single blurred frame, iteratively enhancing cross-modality features in a recurrent manner to better utilize the rich temporal information of events, 2) Inter-frame temporal feature alignment gathers valuable long-range temporal information to target frames, aggregating sharp features leveraging the advantages of the events. In addition, we present a novel dataset composed of real-world blurred RGB videos, corresponding sharp videos, and event data. This dataset serves as a valuable resource for evaluating event-guided deblurring methods. We demonstrate that our proposed methods outperform state-of-the-art frame-based and event-based motion deblurring methods through extensive experiments conducted on both synthetic and real-world deblurring datasets. The code and dataset are available at https://github.com/intelpro/CMTA.","sentences":["Video deblurring aims to enhance the quality of restored results in motion-blurred videos by effectively gathering information from adjacent video frames to compensate for the insufficient data in a single blurred frame.","However, when faced with consecutively severe motion blur situations, frame-based video deblurring methods often fail to find accurate temporal correspondence among neighboring video frames, leading to diminished performance.","To address this limitation, we aim to solve the video deblurring task by leveraging an event camera with micro-second temporal resolution.","To fully exploit the dense temporal resolution of the event camera, we propose two modules: 1) Intra-frame feature enhancement operates within the exposure time of a single blurred frame, iteratively enhancing cross-modality features in a recurrent manner to better utilize the rich temporal information of events, 2) Inter-frame temporal feature alignment gathers valuable long-range temporal information to target frames, aggregating sharp features leveraging the advantages of the events.","In addition, we present a novel dataset composed of real-world blurred RGB videos, corresponding sharp videos, and event data.","This dataset serves as a valuable resource for evaluating event-guided deblurring methods.","We demonstrate that our proposed methods outperform state-of-the-art frame-based and event-based motion deblurring methods through extensive experiments conducted on both synthetic and real-world deblurring datasets.","The code and dataset are available at https://github.com/intelpro/CMTA."],"url":"http://arxiv.org/abs/2408.14930v2"}
{"created":"2024-08-27 09:59:32","title":"Unraveling the Airalo Ecosystem","abstract":"In recent years, we have witnessed myriad flavours of Mobile Network Aggregators (MNAs) which exploit the coverage footprint of a handful of base operators to provide global mobile connectivity. Under the MNA model, emerging operators reap the benefits of network softwarization and virtualization, including eSIM technology or control/data-plane separation. This paper investigates an emergent MNA type - a thick MNA - that relies on multiple (core) base operators from different economies to provision eSIM profiles, while employing gateway functions to the public internet located outside the respective base operators' home country. Specifically, our work is the first to capture the intricacies of Airalo - a thick MNA that operates in 219 countries. Unlike other MNAs that our community scrutinized, we show that Airalo often decouples the geographical location of the public internet gateway from the native country of the base operator via IPX Hub Breakout (IHBO). To map Airalo's underlying infrastructure, we ran web-based measurements that 14 volunteers performed while traveling and using an Airalo eSIM on their personal devices. We further dive into Airalo's performance by running device-based measurements (speedtest, traceroute, video streaming, etc.) in 10 countries with rooted Android devices. Finally, we examine Airalo's pricing by monitoring its marketplace.","sentences":["In recent years, we have witnessed myriad flavours of Mobile Network Aggregators (MNAs) which exploit the coverage footprint of a handful of base operators to provide global mobile connectivity.","Under the MNA model, emerging operators reap the benefits of network softwarization and virtualization, including eSIM technology or control/data-plane separation.","This paper investigates an emergent MNA type - a thick MNA - that relies on multiple (core) base operators from different economies to provision eSIM profiles, while employing gateway functions to the public internet located outside the respective base operators' home country.","Specifically, our work is the first to capture the intricacies of Airalo - a thick MNA that operates in 219 countries.","Unlike other MNAs that our community scrutinized, we show that Airalo often decouples the geographical location of the public internet gateway from the native country of the base operator via IPX Hub Breakout (IHBO).","To map Airalo's underlying infrastructure, we ran web-based measurements that 14 volunteers performed while traveling and using an Airalo eSIM on their personal devices.","We further dive into Airalo's performance by running device-based measurements (speedtest, traceroute, video streaming, etc.) in 10 countries with rooted Android devices.","Finally, we examine Airalo's pricing by monitoring its marketplace."],"url":"http://arxiv.org/abs/2408.14923v1"}
{"created":"2024-08-27 09:44:01","title":"Can Transformers Do Enumerative Geometry?","abstract":"How can Transformers model and learn enumerative geometry? What is a robust procedure for using Transformers in abductive knowledge discovery within a mathematician-machine collaboration? In this work, we introduce a new paradigm in computational enumerative geometry in analyzing the $\\psi$-class intersection numbers on the moduli space of curves. By formulating the enumerative problem as a continuous optimization task, we develop a Transformer-based model for computing $\\psi$-class intersection numbers based on the underlying quantum Airy structure. For a finite range of genera, our model is capable of regressing intersection numbers that span an extremely wide range of values, from $10^{-45}$ to $10^{45}$. To provide a proper inductive bias for capturing the recursive behavior of intersection numbers, we propose a new activation function, Dynamic Range Activator (DRA). Moreover, given the severe heteroscedasticity of $\\psi$-class intersections and the required precision, we quantify the uncertainty of the predictions using Conformal Prediction with a dynamic sliding window that is aware of the number of marked points. Next, we go beyond merely computing intersection numbers and explore the enumerative \"world-model\" of the Transformers. Through a series of causal inference and correlational interpretability analyses, we demonstrate that Transformers are actually modeling Virasoro constraints in a purely data-driven manner. Additionally, we provide evidence for the comprehension of several values appearing in the large genus asymptotic of $\\psi$-class intersection numbers through abductive hypothesis testing.","sentences":["How can Transformers model and learn enumerative geometry?","What is a robust procedure for using Transformers in abductive knowledge discovery within a mathematician-machine collaboration?","In this work, we introduce a new paradigm in computational enumerative geometry in analyzing the $\\psi$-class intersection numbers on the moduli space of curves.","By formulating the enumerative problem as a continuous optimization task, we develop a Transformer-based model for computing $\\psi$-class intersection numbers based on the underlying quantum Airy structure.","For a finite range of genera, our model is capable of regressing intersection numbers that span an extremely wide range of values, from $10^{-45}$ to $10^{45}$. To provide a proper inductive bias for capturing the recursive behavior of intersection numbers, we propose a new activation function, Dynamic Range Activator (DRA).","Moreover, given the severe heteroscedasticity of $\\psi$-class intersections and the required precision, we quantify the uncertainty of the predictions using Conformal Prediction with a dynamic sliding window that is aware of the number of marked points.","Next, we go beyond merely computing intersection numbers and explore the enumerative \"world-model\" of the Transformers.","Through a series of causal inference and correlational interpretability analyses, we demonstrate that Transformers are actually modeling Virasoro constraints in a purely data-driven manner.","Additionally, we provide evidence for the comprehension of several values appearing in the large genus asymptotic of $\\psi$-class intersection numbers through abductive hypothesis testing."],"url":"http://arxiv.org/abs/2408.14915v1"}
{"created":"2024-08-27 09:37:19","title":"Deep learning classification system for coconut maturity levels based on acoustic signals","abstract":"The advancement of computer image processing, pattern recognition, signal processing, and other technologies has gradually replaced the manual methods of classifying fruit with computer and mechanical methods. In the field of agriculture, the intelligent classification of post-harvested fruit has enabled the use of smart devices that creates a direct impact on farmers, especially on export products. For coconut classification, it remains to be traditional in process. This study presents a classification of the coconut dataset based on acoustic signals. To address the imbalanced dataset, a data augmentation technique was conducted through audiomentation and procedural audio generation methods. Audio signals under premature, mature, and overmature now have 4,050, 4,050, and 5,850 audio signals, respectively. To address the updation of the classification system and the classification accuracy performance, deep learning models were utilized for classifying the generated audio signals from data generation. Specifically, RNN and LSTM models were trained and tested, and their performances were compared with each other and the machine learning methods used by Caladcad et al. (2020). The two DL models showed impressive performance with both having an accuracy of 97.42% and neither of them outperformed the other since there are no significant differences in their classification performance.","sentences":["The advancement of computer image processing, pattern recognition, signal processing, and other technologies has gradually replaced the manual methods of classifying fruit with computer and mechanical methods.","In the field of agriculture, the intelligent classification of post-harvested fruit has enabled the use of smart devices that creates a direct impact on farmers, especially on export products.","For coconut classification, it remains to be traditional in process.","This study presents a classification of the coconut dataset based on acoustic signals.","To address the imbalanced dataset, a data augmentation technique was conducted through audiomentation and procedural audio generation methods.","Audio signals under premature, mature, and overmature now have 4,050, 4,050, and 5,850 audio signals, respectively.","To address the updation of the classification system and the classification accuracy performance, deep learning models were utilized for classifying the generated audio signals from data generation.","Specifically, RNN and LSTM models were trained and tested, and their performances were compared with each other and the machine learning methods used by Caladcad et al.","(2020).","The two DL models showed impressive performance with both having an accuracy of 97.42% and neither of them outperformed the other since there are no significant differences in their classification performance."],"url":"http://arxiv.org/abs/2408.14910v1"}
{"created":"2024-08-27 09:18:57","title":"VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities","abstract":"Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data (e.g., images and videos) into symbols, have attracted attention as resources enabling knowledge processing and machine learning across modalities. However, the construction of MMKGs for videos consisting of multiple events, such as daily activities, is still in the early stages. In this paper, we construct an MMKG based on synchronized multi-view simulated videos of daily activities. Besides representing the content of daily life videos as event-centric knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as bounding boxes within video frames. In addition, we provide support tools for querying our MMKG. As an application example, we demonstrate that our MMKG facilitates benchmarking vision-language models by providing the necessary vision-language datasets for a tailored task.","sentences":["Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data (e.g., images and videos) into symbols, have attracted attention as resources enabling knowledge processing and machine learning across modalities.","However, the construction of MMKGs for videos consisting of multiple events, such as daily activities, is still in the early stages.","In this paper, we construct an MMKG based on synchronized multi-view simulated videos of daily activities.","Besides representing the content of daily life videos as event-centric knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as bounding boxes within video frames.","In addition, we provide support tools for querying our MMKG.","As an application example, we demonstrate that our MMKG facilitates benchmarking vision-language models by providing the necessary vision-language datasets for a tailored task."],"url":"http://arxiv.org/abs/2408.14895v2"}
{"created":"2024-08-27 08:57:31","title":"The VoxCeleb Speaker Recognition Challenge: A Retrospective","abstract":"The VoxCeleb Speaker Recognition Challenges (VoxSRC) were a series of challenges and workshops that ran annually from 2019 to 2023. The challenges primarily evaluated the tasks of speaker recognition and diarisation under various settings including: closed and open training data; as well as supervised, self-supervised, and semi-supervised training for domain adaptation. The challenges also provided publicly available training and evaluation datasets for each task and setting, with new test sets released each year. In this paper, we provide a review of these challenges that covers: what they explored; the methods developed by the challenge participants and how these evolved; and also the current state of the field for speaker verification and diarisation. We chart the progress in performance over the five installments of the challenge on a common evaluation dataset and provide a detailed analysis of how each year's special focus affected participants' performance. This paper is aimed both at researchers who want an overview of the speaker recognition and diarisation field, and also at challenge organisers who want to benefit from the successes and avoid the mistakes of the VoxSRC challenges. We end with a discussion of the current strengths of the field and open challenges. Project page : https://mm.kaist.ac.kr/datasets/voxceleb/voxsrc/workshop.html","sentences":["The VoxCeleb Speaker Recognition Challenges (VoxSRC) were a series of challenges and workshops that ran annually from 2019 to 2023.","The challenges primarily evaluated the tasks of speaker recognition and diarisation under various settings including: closed and open training data; as well as supervised, self-supervised, and semi-supervised training for domain adaptation.","The challenges also provided publicly available training and evaluation datasets for each task and setting, with new test sets released each year.","In this paper, we provide a review of these challenges that covers: what they explored; the methods developed by the challenge participants and how these evolved; and also the current state of the field for speaker verification and diarisation.","We chart the progress in performance over the five installments of the challenge on a common evaluation dataset and provide a detailed analysis of how each year's special focus affected participants' performance.","This paper is aimed both at researchers who want an overview of the speaker recognition and diarisation field, and also at challenge organisers who want to benefit from the successes and avoid the mistakes of the VoxSRC challenges.","We end with a discussion of the current strengths of the field and open challenges.","Project page : https://mm.kaist.ac.kr/datasets/voxceleb/voxsrc/workshop.html"],"url":"http://arxiv.org/abs/2408.14886v1"}
{"created":"2024-08-27 08:55:41","title":"User-level Social Multimedia Traffic Anomaly Detection with Meta-Learning","abstract":"Accuracy anomaly detection in user-level social multimedia traffic is crucial for privacy security. Compared with existing models that passively detect specific anomaly classes with large labeled training samples, user-level social multimedia traffic contains sizeable new anomaly classes with few labeled samples and has an imbalance, self-similar, and data-hungry nature. Recent advances, such as Generative Adversarial Networks (GAN), solve it by learning a sample generator only from seen class samples to synthesize new samples. However, if we detect many new classes, the number of synthesizing samples would be unfeasibly estimated, and this operation will drastically increase computational complexity and energy consumption. Motivation on these limitations, in this paper, we propose \\textit{Meta-UAD}, a Meta-learning scheme for User-level social multimedia traffic Anomaly Detection. This scheme relies on the episodic training paradigm and learns from the collection of K-way-M-shot classification tasks, which can use the pre-trained model to adapt any new class with few samples by going through few iteration steps. Since user-level social multimedia traffic emerges from a complex interaction process of users and social applications, we further develop a feature extractor to improve scheme performance. It extracts statistical features using cumulative importance ranking and time-series features using an LSTM-based AutoEncoder. We evaluate our scheme on two public datasets and the results further demonstrate the superiority of Meta-UAD.","sentences":["Accuracy anomaly detection in user-level social multimedia traffic is crucial for privacy security.","Compared with existing models that passively detect specific anomaly classes with large labeled training samples, user-level social multimedia traffic contains sizeable new anomaly classes with few labeled samples and has an imbalance, self-similar, and data-hungry nature.","Recent advances, such as Generative Adversarial Networks (GAN), solve it by learning a sample generator only from seen class samples to synthesize new samples.","However, if we detect many new classes, the number of synthesizing samples would be unfeasibly estimated, and this operation will drastically increase computational complexity and energy consumption.","Motivation on these limitations, in this paper, we propose \\textit{Meta-UAD}, a Meta-learning scheme for User-level social multimedia traffic Anomaly Detection.","This scheme relies on the episodic training paradigm and learns from the collection of K-way-M-shot classification tasks, which can use the pre-trained model to adapt any new class with few samples by going through few iteration steps.","Since user-level social multimedia traffic emerges from a complex interaction process of users and social applications, we further develop a feature extractor to improve scheme performance.","It extracts statistical features using cumulative importance ranking and time-series features using an LSTM-based AutoEncoder.","We evaluate our scheme on two public datasets and the results further demonstrate the superiority of Meta-UAD."],"url":"http://arxiv.org/abs/2408.14884v2"}
{"created":"2024-08-27 08:44:31","title":"Adversarial Attacks and Defenses in Multivariate Time-Series Forecasting for Smart and Connected Infrastructures","abstract":"The emergence of deep learning models has revolutionized various industries over the last decade, leading to a surge in connected devices and infrastructures. However, these models can be tricked into making incorrect predictions with high confidence, leading to disastrous failures and security concerns. To this end, we explore the impact of adversarial attacks on multivariate time-series forecasting and investigate methods to counter them. Specifically, we employ untargeted white-box attacks, namely the Fast Gradient Sign Method (FGSM) and the Basic Iterative Method (BIM), to poison the inputs to the training process, effectively misleading the model. We also illustrate the subtle modifications to the inputs after the attack, which makes detecting the attack using the naked eye quite difficult. Having demonstrated the feasibility of these attacks, we develop robust models through adversarial training and model hardening. We are among the first to showcase the transferability of these attacks and defenses by extrapolating our work from the benchmark electricity data to a larger, 10-year real-world data used for predicting the time-to-failure of hard disks. Our experimental results confirm that the attacks and defenses achieve the desired security thresholds, leading to a 72.41% and 94.81% decrease in RMSE for the electricity and hard disk datasets respectively after implementing the adversarial defenses.","sentences":["The emergence of deep learning models has revolutionized various industries over the last decade, leading to a surge in connected devices and infrastructures.","However, these models can be tricked into making incorrect predictions with high confidence, leading to disastrous failures and security concerns.","To this end, we explore the impact of adversarial attacks on multivariate time-series forecasting and investigate methods to counter them.","Specifically, we employ untargeted white-box attacks, namely the Fast Gradient Sign Method (FGSM) and the Basic Iterative Method (BIM), to poison the inputs to the training process, effectively misleading the model.","We also illustrate the subtle modifications to the inputs after the attack, which makes detecting the attack using the naked eye quite difficult.","Having demonstrated the feasibility of these attacks, we develop robust models through adversarial training and model hardening.","We are among the first to showcase the transferability of these attacks and defenses by extrapolating our work from the benchmark electricity data to a larger, 10-year real-world data used for predicting the time-to-failure of hard disks.","Our experimental results confirm that the attacks and defenses achieve the desired security thresholds, leading to a 72.41% and 94.81% decrease in RMSE for the electricity and hard disk datasets respectively after implementing the adversarial defenses."],"url":"http://arxiv.org/abs/2408.14875v1"}
{"created":"2024-08-27 08:43:32","title":"Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data","abstract":"Reinforcement Learning from Human Feedback (RLHF) has proven effective in aligning large language models with human intentions, yet it often relies on complex methodologies like Proximal Policy Optimization (PPO) that require extensive hyper-parameter tuning and present challenges in sample efficiency and stability. In this paper, we introduce Inverse-Q*, an innovative framework that transcends traditional RL methods by optimizing token-level reinforcement learning without the need for additional reward or value models. Inverse-Q* leverages direct preference optimization techniques but extends them by estimating the conditionally optimal policy directly from the model's responses, facilitating more granular and flexible policy shaping. Our approach reduces reliance on human annotation and external supervision, making it especially suitable for low-resource settings. We present extensive experimental results demonstrating that Inverse-Q* not only matches but potentially exceeds the effectiveness of PPO in terms of convergence speed and the alignment of model responses with human preferences. Our findings suggest that Inverse-Q* offers a practical and robust alternative to conventional RLHF approaches, paving the way for more efficient and adaptable model training approaches.","sentences":["Reinforcement Learning from Human Feedback (RLHF) has proven effective in aligning large language models with human intentions, yet it often relies on complex methodologies like Proximal Policy Optimization (PPO) that require extensive hyper-parameter tuning and present challenges in sample efficiency and stability.","In this paper, we introduce Inverse-Q*, an innovative framework that transcends traditional RL methods by optimizing token-level reinforcement learning without the need for additional reward or value models.","Inverse-Q* leverages direct preference optimization techniques but extends them by estimating the conditionally optimal policy directly from the model's responses, facilitating more granular and flexible policy shaping.","Our approach reduces reliance on human annotation and external supervision, making it especially suitable for low-resource settings.","We present extensive experimental results demonstrating that Inverse-Q* not only matches but potentially exceeds the effectiveness of PPO in terms of convergence speed and the alignment of model responses with human preferences.","Our findings suggest that Inverse-Q* offers a practical and robust alternative to conventional RLHF approaches, paving the way for more efficient and adaptable model training approaches."],"url":"http://arxiv.org/abs/2408.14874v1"}
{"created":"2024-08-27 08:38:48","title":"Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models","abstract":"Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy Coordinate Gradient (GCG). However, GCG struggles with computational inefficiency, limiting further investigations regarding suffix transferability and scalability across models and data. In this work, we bridge the connection between search efficiency and suffix transferability. We propose a two-stage transfer learning framework, DeGCG, which decouples the search process into behavior-agnostic pre-searching and behavior-relevant post-searching. Specifically, we employ direct first target token optimization in pre-searching to facilitate the search process. We apply our approach to cross-model, cross-data, and self-transfer scenarios. Furthermore, we introduce an interleaved variant of our approach, i-DeGCG, which iteratively leverages self-transferability to accelerate the search process. Experiments on HarmBench demonstrate the efficiency of our approach across various models and domains. Notably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of $43.9$ ($+22.2$) and $39.0$ ($+19.5$) on valid and test sets, respectively. Further analysis on cross-model transfer indicates the pivotal role of first target token optimization in leveraging suffix transferability for efficient searching.","sentences":["Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users.","Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy Coordinate Gradient (GCG).","However, GCG struggles with computational inefficiency, limiting further investigations regarding suffix transferability and scalability across models and data.","In this work, we bridge the connection between search efficiency and suffix transferability.","We propose a two-stage transfer learning framework, DeGCG, which decouples the search process into behavior-agnostic pre-searching and behavior-relevant post-searching.","Specifically, we employ direct first target token optimization in pre-searching to facilitate the search process.","We apply our approach to cross-model, cross-data, and self-transfer scenarios.","Furthermore, we introduce an interleaved variant of our approach, i-DeGCG, which iteratively leverages self-transferability to accelerate the search process.","Experiments on HarmBench demonstrate the efficiency of our approach across various models and domains.","Notably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of $43.9$ ($+22.2$) and $39.0$ ($+19.5$) on valid and test sets, respectively.","Further analysis on cross-model transfer indicates the pivotal role of first target token optimization in leveraging suffix transferability for efficient searching."],"url":"http://arxiv.org/abs/2408.14866v1"}
{"created":"2024-08-27 08:33:26","title":"Leveraging Self-supervised Audio Representations for Data-Efficient Acoustic Scene Classification","abstract":"Acoustic scene classification (ASC) predominantly relies on supervised approaches. However, acquiring labeled data for training ASC models is often costly and time-consuming. Recently, self-supervised learning (SSL) has emerged as a powerful method for extracting features from unlabeled audio data, benefiting many downstream audio tasks. This paper proposes a data-efficient and low-complexity ASC system by leveraging self-supervised audio representations extracted from general-purpose audio datasets. We introduce BEATs, an audio SSL pre-trained model, to extract the general representations from AudioSet. Through extensive experiments, it has been demonstrated that the self-supervised audio representations can help to achieve high ASC accuracy with limited labeled fine-tuning data. Furthermore, we find that ensembling the SSL models fine-tuned with different strategies contributes to a further performance improvement. To meet low-complexity requirements, we use knowledge distillation to transfer the self-supervised knowledge from large teacher models to an efficient student model. The experimental results suggest that the self-supervised teachers effectively improve the classification accuracy of the student model. Our best-performing system obtains an average accuracy of 56.7%.","sentences":["Acoustic scene classification (ASC) predominantly relies on supervised approaches.","However, acquiring labeled data for training ASC models is often costly and time-consuming.","Recently, self-supervised learning (SSL) has emerged as a powerful method for extracting features from unlabeled audio data, benefiting many downstream audio tasks.","This paper proposes a data-efficient and low-complexity ASC system by leveraging self-supervised audio representations extracted from general-purpose audio datasets.","We introduce BEATs, an audio SSL pre-trained model, to extract the general representations from AudioSet.","Through extensive experiments, it has been demonstrated that the self-supervised audio representations can help to achieve high ASC accuracy with limited labeled fine-tuning data.","Furthermore, we find that ensembling the SSL models fine-tuned with different strategies contributes to a further performance improvement.","To meet low-complexity requirements, we use knowledge distillation to transfer the self-supervised knowledge from large teacher models to an efficient student model.","The experimental results suggest that the self-supervised teachers effectively improve the classification accuracy of the student model.","Our best-performing system obtains an average accuracy of 56.7%."],"url":"http://arxiv.org/abs/2408.14862v1"}
{"created":"2024-08-27 07:57:58","title":"Diffusion-Occ: 3D Point Cloud Completion via Occupancy Diffusion","abstract":"Point clouds are crucial for capturing three-dimensional data but often suffer from incompleteness due to limitations such as resolution and occlusion. Traditional methods typically rely on point-based approaches within discriminative frameworks for point cloud completion. In this paper, we introduce \\textbf{Diffusion-Occ}, a novel framework for Diffusion Point Cloud Completion. Diffusion-Occ utilizes a two-stage coarse-to-fine approach. In the first stage, the Coarse Density Voxel Prediction Network (CDNet) processes partial points to predict coarse density voxels, streamlining global feature extraction through voxel classification, as opposed to previous regression-based methods. In the second stage, we introduce the Occupancy Generation Network (OccGen), a conditional occupancy diffusion model based on a transformer architecture and enhanced by our Point-Voxel Fuse (PVF) block. This block integrates coarse density voxels with partial points to leverage both global and local features for comprehensive completion. By thresholding the occupancy field, we convert it into a complete point cloud. Additionally, our method employs diverse training mixtures and efficient diffusion parameterization to enable effective one-step sampling during both training and inference. Experimental results demonstrate that Diffusion-Occ outperforms existing discriminative and generative methods.","sentences":["Point clouds are crucial for capturing three-dimensional data but often suffer from incompleteness due to limitations such as resolution and occlusion.","Traditional methods typically rely on point-based approaches within discriminative frameworks for point cloud completion.","In this paper, we introduce \\textbf{Diffusion-Occ}, a novel framework for Diffusion Point Cloud Completion.","Diffusion-Occ utilizes a two-stage coarse-to-fine approach.","In the first stage, the Coarse Density Voxel Prediction Network (CDNet) processes partial points to predict coarse density voxels, streamlining global feature extraction through voxel classification, as opposed to previous regression-based methods.","In the second stage, we introduce the Occupancy Generation Network (OccGen), a conditional occupancy diffusion model based on a transformer architecture and enhanced by our Point-Voxel Fuse (PVF) block.","This block integrates coarse density voxels with partial points to leverage both global and local features for comprehensive completion.","By thresholding the occupancy field, we convert it into a complete point cloud.","Additionally, our method employs diverse training mixtures and efficient diffusion parameterization to enable effective one-step sampling during both training and inference.","Experimental results demonstrate that Diffusion-Occ outperforms existing discriminative and generative methods."],"url":"http://arxiv.org/abs/2408.14846v1"}
{"created":"2024-08-27 07:28:05","title":"DRL-Based Federated Self-Supervised Learning for Task Offloading and Resource Allocation in ISAC-Enabled Vehicle Edge Computing","abstract":"Intelligent Transportation Systems (ITS) leverage Integrated Sensing and Communications (ISAC) to enhance data exchange between vehicles and infrastructure in the Internet of Vehicles (IoV). This integration inevitably increases computing demands, risking real-time system stability. Vehicle Edge Computing (VEC) addresses this by offloading tasks to Road Side Unit (RSU), ensuring timely services. Our previous work FLSimCo algorithm, which uses local resources for Federated Self-Supervised Learning (SSL), though vehicles often can't complete all iterations task. Our improved algorithm offloads partial task to RSU and optimizes energy consumption by adjusting transmission power, CPU frequency, and task assignment ratios, balancing local and RSU-based training. Meanwhile, setting an offloading threshold further prevents inefficiencies. Simulation results show that the enhanced algorithm reduces energy consumption, improves offloading efficiency and the accuracy of Federated SSL.","sentences":["Intelligent Transportation Systems (ITS) leverage Integrated Sensing and Communications (ISAC) to enhance data exchange between vehicles and infrastructure in the Internet of Vehicles (IoV).","This integration inevitably increases computing demands, risking real-time system stability.","Vehicle Edge Computing (VEC) addresses this by offloading tasks to Road Side Unit (RSU), ensuring timely services.","Our previous work FLSimCo algorithm, which uses local resources for Federated Self-Supervised Learning (SSL), though vehicles often can't complete all iterations task.","Our improved algorithm offloads partial task to RSU and optimizes energy consumption by adjusting transmission power, CPU frequency, and task assignment ratios, balancing local and RSU-based training.","Meanwhile, setting an offloading threshold further prevents inefficiencies.","Simulation results show that the enhanced algorithm reduces energy consumption, improves offloading efficiency and the accuracy of Federated SSL."],"url":"http://arxiv.org/abs/2408.14831v1"}
{"created":"2024-08-27 07:27:16","title":"PolicyLR: A Logic Representation For Privacy Policies","abstract":"Privacy policies are crucial in the online ecosystem, defining how services handle user data and adhere to regulations such as GDPR and CCPA. However, their complexity and frequent updates often make them difficult for stakeholders to understand and analyze. Current automated analysis methods, which utilize natural language processing, have limitations. They typically focus on individual tasks and fail to capture the full context of the policies. We propose PolicyLR, a new paradigm that offers a comprehensive machine-readable representation of privacy policies, serving as an all-in-one solution for multiple downstream tasks. PolicyLR converts privacy policies into a machine-readable format using valuations of atomic formulae, allowing for formal definitions of tasks like compliance and consistency. We have developed a compiler that transforms unstructured policy text into this format using off-the-shelf Large Language Models (LLMs). This compiler breaks down the transformation task into a two-stage translation and entailment procedure. This procedure considers the full context of the privacy policy to infer a complex formula, where each formula consists of simpler atomic formulae. The advantage of this model is that PolicyLR is interpretable by design and grounded in segments of the privacy policy. We evaluated the compiler using ToS;DR, a community-annotated privacy policy entailment dataset. Utilizing open-source LLMs, our compiler achieves precision and recall values of 0.91 and 0.88, respectively. Finally, we demonstrate the utility of PolicyLR in three privacy tasks: Policy Compliance, Inconsistency Detection, and Privacy Comparison Shopping.","sentences":["Privacy policies are crucial in the online ecosystem, defining how services handle user data and adhere to regulations such as GDPR and CCPA.","However, their complexity and frequent updates often make them difficult for stakeholders to understand and analyze.","Current automated analysis methods, which utilize natural language processing, have limitations.","They typically focus on individual tasks and fail to capture the full context of the policies.","We propose PolicyLR, a new paradigm that offers a comprehensive machine-readable representation of privacy policies, serving as an all-in-one solution for multiple downstream tasks.","PolicyLR","converts privacy policies into a machine-readable format using valuations of atomic formulae, allowing for formal definitions of tasks like compliance and consistency.","We have developed a compiler that transforms unstructured policy text into this format using off-the-shelf Large Language Models (LLMs).","This compiler breaks down the transformation task into a two-stage translation and entailment procedure.","This procedure considers the full context of the privacy policy to infer a complex formula, where each formula consists of simpler atomic formulae.","The advantage of this model is that PolicyLR is interpretable by design and grounded in segments of the privacy policy.","We evaluated the compiler using ToS;DR, a community-annotated privacy policy entailment dataset.","Utilizing open-source LLMs, our compiler achieves precision and recall values of 0.91 and 0.88, respectively.","Finally, we demonstrate the utility of PolicyLR in three privacy tasks: Policy Compliance, Inconsistency Detection, and Privacy Comparison Shopping."],"url":"http://arxiv.org/abs/2408.14830v1"}
{"created":"2024-08-27 07:15:05","title":"Generative-AI for AI/ML Model Adaptive Retraining in Beyond 5G Networks","abstract":"Beyond fifth-generation (B5G) networks aim to support high data rates, low-latency applications, and massive machine communications. Artificial Intelligence/Machine Learning (AI/ML) can help to improve B5G network performance and efficiency. However, dynamic service demands of B5G use cases cause AI/ML model performance degradation, resulting in Service Level Agreements (SLA) violations, over- or under-provisioning of resources, etc. Retraining is essential to address the performance degradation of the AI/ML models. Existing threshold and periodic retraining approaches have potential disadvantages, such as SLA violations and inefficient resource utilization for setting a threshold parameter in a dynamic environment. This paper proposes a novel approach that predicts when to retrain AI/ML models using Generative Artificial Intelligence. The proposed predictive approach is evaluated for a Quality of Service Prediction use case on the Open Radio Access Network (O-RAN) Software Community platform and compared to the predictive approach based on the classifier and a threshold approach. Also, a realtime dataset from the Colosseum testbed is considered to evaluate Network Slicing (NS) use case with the proposed predictive approach. The results show that the proposed predictive approach outperforms both the classifier-based predictive and threshold approaches.","sentences":["Beyond fifth-generation (B5G) networks aim to support high data rates, low-latency applications, and massive machine communications.","Artificial Intelligence/Machine Learning (AI/ML) can help to improve B5G network performance and efficiency.","However, dynamic service demands of B5G use cases cause AI/ML model performance degradation, resulting in Service Level Agreements (SLA) violations, over- or under-provisioning of resources, etc.","Retraining is essential to address the performance degradation of the AI/ML models.","Existing threshold and periodic retraining approaches have potential disadvantages, such as SLA violations and inefficient resource utilization for setting a threshold parameter in a dynamic environment.","This paper proposes a novel approach that predicts when to retrain AI/ML models using Generative Artificial Intelligence.","The proposed predictive approach is evaluated for a Quality of Service Prediction use case on the Open Radio Access Network (O-RAN) Software Community platform and compared to the predictive approach based on the classifier and a threshold approach.","Also, a realtime dataset from the Colosseum testbed is considered to evaluate Network Slicing (NS) use case with the proposed predictive approach.","The results show that the proposed predictive approach outperforms both the classifier-based predictive and threshold approaches."],"url":"http://arxiv.org/abs/2408.14827v1"}
{"created":"2024-08-27 07:13:44","title":"Alfie: Democratising RGBA Image Generation With No $$$","abstract":"Designs and artworks are ubiquitous across various creative fields, requiring graphic design skills and dedicated software to create compositions that include many graphical elements, such as logos, icons, symbols, and art scenes, which are integral to visual storytelling. Automating the generation of such visual elements improves graphic designers' productivity, democratizes and innovates the creative industry, and helps generate more realistic synthetic data for related tasks. These illustration elements are mostly RGBA images with irregular shapes and cutouts, facilitating blending and scene composition. However, most image generation models are incapable of generating such images and achieving this capability requires expensive computational resources, specific training recipes, or post-processing solutions. In this work, we propose a fully-automated approach for obtaining RGBA illustrations by modifying the inference-time behavior of a pre-trained Diffusion Transformer model, exploiting the prompt-guided controllability and visual quality offered by such models with no additional computational cost. We force the generation of entire subjects without sharp croppings, whose background is easily removed for seamless integration into design projects or artistic scenes. We show with a user study that, in most cases, users prefer our solution over generating and then matting an image, and we show that our generated illustrations yield good results when used as inputs for composite scene generation pipelines. We release the code at https://github.com/aimagelab/Alfie.","sentences":["Designs and artworks are ubiquitous across various creative fields, requiring graphic design skills and dedicated software to create compositions that include many graphical elements, such as logos, icons, symbols, and art scenes, which are integral to visual storytelling.","Automating the generation of such visual elements improves graphic designers' productivity, democratizes and innovates the creative industry, and helps generate more realistic synthetic data for related tasks.","These illustration elements are mostly RGBA images with irregular shapes and cutouts, facilitating blending and scene composition.","However, most image generation models are incapable of generating such images and achieving this capability requires expensive computational resources, specific training recipes, or post-processing solutions.","In this work, we propose a fully-automated approach for obtaining RGBA illustrations by modifying the inference-time behavior of a pre-trained Diffusion Transformer model, exploiting the prompt-guided controllability and visual quality offered by such models with no additional computational cost.","We force the generation of entire subjects without sharp croppings, whose background is easily removed for seamless integration into design projects or artistic scenes.","We show with a user study that, in most cases, users prefer our solution over generating and then matting an image, and we show that our generated illustrations yield good results when used as inputs for composite scene generation pipelines.","We release the code at https://github.com/aimagelab/Alfie."],"url":"http://arxiv.org/abs/2408.14826v1"}
{"created":"2024-08-27 07:03:51","title":"Data-driven Effective Modeling of Multiscale Stochastic Dynamical Systems","abstract":"We present a numerical method for learning the dynamics of slow components of unknown multiscale stochastic dynamical systems. While the governing equations of the systems are unknown, bursts of observation data of the slow variables are available. By utilizing the observation data, our proposed method is capable of constructing a generative stochastic model that can accurately capture the effective dynamics of the slow variables in distribution. We present a comprehensive set of numerical examples to demonstrate the performance of the proposed method.","sentences":["We present a numerical method for learning the dynamics of slow components of unknown multiscale stochastic dynamical systems.","While the governing equations of the systems are unknown, bursts of observation data of the slow variables are available.","By utilizing the observation data, our proposed method is capable of constructing a generative stochastic model that can accurately capture the effective dynamics of the slow variables in distribution.","We present a comprehensive set of numerical examples to demonstrate the performance of the proposed method."],"url":"http://arxiv.org/abs/2408.14821v1"}
{"created":"2024-08-27 06:28:35","title":"Poly2Vec: Polymorphic Encoding of Geospatial Objects for Spatial Reasoning with Deep Neural Networks","abstract":"Encoding geospatial data is crucial for enabling machine learning (ML) models to perform tasks that require spatial reasoning, such as identifying the topological relationships between two different geospatial objects. However, existing encoding methods are limited as they are typically customized to handle only specific types of spatial data, which impedes their applicability across different downstream tasks where multiple data types coexist. To address this, we introduce Poly2Vec, an encoding framework that unifies the modeling of different geospatial objects, including 2D points, polylines, and polygons, irrespective of the downstream task. We leverage the power of the 2D Fourier transform to encode useful spatial properties, such as shape and location, from geospatial objects into fixed-length vectors. These vectors are then inputted into neural network models for spatial reasoning tasks.This unified approach eliminates the need to develop and train separate models for each distinct spatial type. We evaluate Poly2Vec on both synthetic and real datasets of mixed geometry types and verify its consistent performance across several downstream spatial reasoning tasks.","sentences":["Encoding geospatial data is crucial for enabling machine learning (ML) models to perform tasks that require spatial reasoning, such as identifying the topological relationships between two different geospatial objects.","However, existing encoding methods are limited as they are typically customized to handle only specific types of spatial data, which impedes their applicability across different downstream tasks where multiple data types coexist.","To address this, we introduce Poly2Vec, an encoding framework that unifies the modeling of different geospatial objects, including 2D points, polylines, and polygons, irrespective of the downstream task.","We leverage the power of the 2D Fourier transform to encode useful spatial properties, such as shape and location, from geospatial objects into fixed-length vectors.","These vectors are then inputted into neural network models for spatial reasoning tasks.","This unified approach eliminates the need to develop and train separate models for each distinct spatial type.","We evaluate Poly2Vec on both synthetic and real datasets of mixed geometry types and verify its consistent performance across several downstream spatial reasoning tasks."],"url":"http://arxiv.org/abs/2408.14806v1"}
{"created":"2024-08-27 06:24:51","title":"Platypus: A Generalized Specialist Model for Reading Text in Various Forms","abstract":"Reading text from images (either natural scenes or documents) has been a long-standing research topic for decades, due to the high technical challenge and wide application range. Previously, individual specialist models are developed to tackle the sub-tasks of text reading (e.g., scene text recognition, handwritten text recognition and mathematical expression recognition). However, such specialist models usually cannot effectively generalize across different sub-tasks. Recently, generalist models (such as GPT-4V), trained on tremendous data in a unified way, have shown enormous potential in reading text in various scenarios, but with the drawbacks of limited accuracy and low efficiency. In this work, we propose Platypus, a generalized specialist model for text reading. Specifically, Platypus combines the best of both worlds: being able to recognize text of various forms with a single unified architecture, while achieving excellent accuracy and high efficiency. To better exploit the advantage of Platypus, we also construct a text reading dataset (called Worms), the images of which are curated from previous datasets and partially re-labeled. Experiments on standard benchmarks demonstrate the effectiveness and superiority of the proposed Platypus model. Model and data will be made publicly available at https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/Platypus.","sentences":["Reading text from images (either natural scenes or documents) has been a long-standing research topic for decades, due to the high technical challenge and wide application range.","Previously, individual specialist models are developed to tackle the sub-tasks of text reading (e.g., scene text recognition, handwritten text recognition and mathematical expression recognition).","However, such specialist models usually cannot effectively generalize across different sub-tasks.","Recently, generalist models (such as GPT-4V), trained on tremendous data in a unified way, have shown enormous potential in reading text in various scenarios, but with the drawbacks of limited accuracy and low efficiency.","In this work, we propose Platypus, a generalized specialist model for text reading.","Specifically, Platypus combines the best of both worlds: being able to recognize text of various forms with a single unified architecture, while achieving excellent accuracy and high efficiency.","To better exploit the advantage of Platypus, we also construct a text reading dataset (called Worms), the images of which are curated from previous datasets and partially re-labeled.","Experiments on standard benchmarks demonstrate the effectiveness and superiority of the proposed Platypus model.","Model and data will be made publicly available at https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/Platypus."],"url":"http://arxiv.org/abs/2408.14805v1"}
{"created":"2024-08-27 06:14:54","title":"RAW-Adapter: Adapting Pre-trained Visual Model to Camera RAW Images","abstract":"sRGB images are now the predominant choice for pre-training visual models in computer vision research, owing to their ease of acquisition and efficient storage. Meanwhile, the advantage of RAW images lies in their rich physical information under variable real-world challenging lighting conditions. For computer vision tasks directly based on camera RAW data, most existing studies adopt methods of integrating image signal processor (ISP) with backend networks, yet often overlook the interaction capabilities between the ISP stages and subsequent networks. Drawing inspiration from ongoing adapter research in NLP and CV areas, we introduce RAW-Adapter, a novel approach aimed at adapting sRGB pre-trained models to camera RAW data. RAW-Adapter comprises input-level adapters that employ learnable ISP stages to adjust RAW inputs, as well as model-level adapters to build connections between ISP stages and subsequent high-level networks. Additionally, RAW-Adapter is a general framework that could be used in various computer vision frameworks. Abundant experiments under different lighting conditions have shown our algorithm's state-of-the-art (SOTA) performance, demonstrating its effectiveness and efficiency across a range of real-world and synthetic datasets.","sentences":["sRGB images are now the predominant choice for pre-training visual models in computer vision research, owing to their ease of acquisition and efficient storage.","Meanwhile, the advantage of RAW images lies in their rich physical information under variable real-world challenging lighting conditions.","For computer vision tasks directly based on camera RAW data, most existing studies adopt methods of integrating image signal processor (ISP) with backend networks, yet often overlook the interaction capabilities between the ISP stages and subsequent networks.","Drawing inspiration from ongoing adapter research in NLP and CV areas, we introduce RAW-Adapter, a novel approach aimed at adapting sRGB pre-trained models to camera RAW data.","RAW-Adapter comprises input-level adapters that employ learnable ISP stages to adjust RAW inputs, as well as model-level adapters to build connections between ISP stages and subsequent high-level networks.","Additionally, RAW-Adapter is a general framework that could be used in various computer vision frameworks.","Abundant experiments under different lighting conditions have shown our algorithm's state-of-the-art (SOTA) performance, demonstrating its effectiveness and efficiency across a range of real-world and synthetic datasets."],"url":"http://arxiv.org/abs/2408.14802v1"}
{"created":"2024-08-27 05:53:02","title":"Optimizing Structured Data Processing through Robotic Process Automation","abstract":"Robotic Process Automation (RPA) has emerged as a game-changing technology in data extraction, revolutionizing the way organizations process and analyze large volumes of documents such as invoices, purchase orders, and payment advices. This study investigates the use of RPA for structured data extraction and evaluates its advantages over manual processes. By comparing human-performed tasks with those executed by RPA software bots, we assess efficiency and accuracy in data extraction from invoices, focusing on the effectiveness of the RPA system. Through four distinct scenarios involving varying numbers of invoices, we measure efficiency in terms of time and effort required for task completion, as well as accuracy by comparing error rates between manual and RPA processes. Our findings highlight the significant efficiency gains achieved by RPA, with bots completing tasks in significantly less time compared to manual efforts across all cases. Moreover, the RPA system consistently achieves perfect accuracy, mitigating the risk of errors and enhancing process reliability. These results underscore the transformative potential of RPA in optimizing operational efficiency, reducing human labor costs, and improving overall business performance.","sentences":["Robotic Process Automation (RPA) has emerged as a game-changing technology in data extraction, revolutionizing the way organizations process and analyze large volumes of documents such as invoices, purchase orders, and payment advices.","This study investigates the use of RPA for structured data extraction and evaluates its advantages over manual processes.","By comparing human-performed tasks with those executed by RPA software bots, we assess efficiency and accuracy in data extraction from invoices, focusing on the effectiveness of the RPA system.","Through four distinct scenarios involving varying numbers of invoices, we measure efficiency in terms of time and effort required for task completion, as well as accuracy by comparing error rates between manual and RPA processes.","Our findings highlight the significant efficiency gains achieved by RPA, with bots completing tasks in significantly less time compared to manual efforts across all cases.","Moreover, the RPA system consistently achieves perfect accuracy, mitigating the risk of errors and enhancing process reliability.","These results underscore the transformative potential of RPA in optimizing operational efficiency, reducing human labor costs, and improving overall business performance."],"url":"http://arxiv.org/abs/2408.14791v1"}
{"created":"2024-08-27 05:31:30","title":"Revisiting Surgical Instrument Segmentation Without Human Intervention: A Graph Partitioning View","abstract":"Surgical instrument segmentation (SIS) on endoscopic images stands as a long-standing and essential task in the context of computer-assisted interventions for boosting minimally invasive surgery. Given the recent surge of deep learning methodologies and their data-hungry nature, training a neural predictive model based on massive expert-curated annotations has been dominating and served as an off-the-shelf approach in the field, which could, however, impose prohibitive burden to clinicians for preparing fine-grained pixel-wise labels corresponding to the collected surgical video frames. In this work, we propose an unsupervised method by reframing the video frame segmentation as a graph partitioning problem and regarding image pixels as graph nodes, which is significantly different from the previous efforts. A self-supervised pre-trained model is firstly leveraged as a feature extractor to capture high-level semantic features. Then, Laplacian matrixs are computed from the features and are eigendecomposed for graph partitioning. On the \"deep\" eigenvectors, a surgical video frame is meaningfully segmented into different modules such as tools and tissues, providing distinguishable semantic information like locations, classes, and relations. The segmentation problem can then be naturally tackled by applying clustering or threshold on the eigenvectors. Extensive experiments are conducted on various datasets (e.g., EndoVis2017, EndoVis2018, UCL, etc.) for different clinical endpoints. Across all the challenging scenarios, our method demonstrates outstanding performance and robustness higher than unsupervised state-of-the-art (SOTA) methods. The code is released at https://github.com/MingyuShengSMY/GraphClusteringSIS.git.","sentences":["Surgical instrument segmentation (SIS) on endoscopic images stands as a long-standing and essential task in the context of computer-assisted interventions for boosting minimally invasive surgery.","Given the recent surge of deep learning methodologies and their data-hungry nature, training a neural predictive model based on massive expert-curated annotations has been dominating and served as an off-the-shelf approach in the field, which could, however, impose prohibitive burden to clinicians for preparing fine-grained pixel-wise labels corresponding to the collected surgical video frames.","In this work, we propose an unsupervised method by reframing the video frame segmentation as a graph partitioning problem and regarding image pixels as graph nodes, which is significantly different from the previous efforts.","A self-supervised pre-trained model is firstly leveraged as a feature extractor to capture high-level semantic features.","Then, Laplacian matrixs are computed from the features and are eigendecomposed for graph partitioning.","On the \"deep\" eigenvectors, a surgical video frame is meaningfully segmented into different modules such as tools and tissues, providing distinguishable semantic information like locations, classes, and relations.","The segmentation problem can then be naturally tackled by applying clustering or threshold on the eigenvectors.","Extensive experiments are conducted on various datasets (e.g., EndoVis2017, EndoVis2018, UCL, etc.) for different clinical endpoints.","Across all the challenging scenarios, our method demonstrates outstanding performance and robustness higher than unsupervised state-of-the-art (SOTA) methods.","The code is released at https://github.com/MingyuShengSMY/GraphClusteringSIS.git."],"url":"http://arxiv.org/abs/2408.14789v1"}
{"created":"2024-08-27 05:28:52","title":"Learning from Complementary Features","abstract":"While precise data observation is essential for the learning processes of predictive models, it can be challenging owing to factors such as insufficient observation accuracy, high collection costs, and privacy constraints. In this paper, we examines cases where some qualitative features are unavailable as precise information indicating \"what it is,\" but rather as complementary information indicating \"what it is not.\" We refer to features defined by precise information as ordinary features (OFs) and those defined by complementary information as complementary features (CFs). We then formulate a new learning scenario termed Complementary Feature Learning (CFL), where predictive models are constructed using instances consisting of OFs and CFs. The simplest formalization of CFL applies conventional supervised learning directly using the observed values of CFs. However, this approach does not resolve the ambiguity associated with CFs, making learning challenging and complicating the interpretation of the predictive model's specific predictions. Therefore, we derive an objective function from an information-theoretic perspective to estimate the OF values corresponding to CFs and to predict output labels based on these estimations. Based on this objective function, we propose a theoretically guaranteed graph-based estimation method along with its practical approximation, for estimating OF values corresponding to CFs. The results of numerical experiments conducted with real-world data demonstrate that our proposed method effectively estimates OF values corresponding to CFs and predicts output labels.","sentences":["While precise data observation is essential for the learning processes of predictive models, it can be challenging owing to factors such as insufficient observation accuracy, high collection costs, and privacy constraints.","In this paper, we examines cases where some qualitative features are unavailable as precise information indicating \"what it is,\" but rather as complementary information indicating \"what it is not.\"","We refer to features defined by precise information as ordinary features (OFs) and those defined by complementary information as complementary features (CFs).","We then formulate a new learning scenario termed Complementary Feature Learning (CFL), where predictive models are constructed using instances consisting of OFs and CFs.","The simplest formalization of CFL applies conventional supervised learning directly using the observed values of CFs.","However, this approach does not resolve the ambiguity associated with CFs, making learning challenging and complicating the interpretation of the predictive model's specific predictions.","Therefore, we derive an objective function from an information-theoretic perspective to estimate the OF values corresponding to CFs and to predict output labels based on these estimations.","Based on this objective function, we propose a theoretically guaranteed graph-based estimation method along with its practical approximation, for estimating OF values corresponding to CFs.","The results of numerical experiments conducted with real-world data demonstrate that our proposed method effectively estimates OF values corresponding to CFs and predicts output labels."],"url":"http://arxiv.org/abs/2408.14788v1"}
{"created":"2024-08-27 05:23:45","title":"Unsupervised-to-Online Reinforcement Learning","abstract":"Offline-to-online reinforcement learning (RL), a framework that trains a policy with offline RL and then further fine-tunes it with online RL, has been considered a promising recipe for data-driven decision-making. While sensible, this framework has drawbacks: it requires domain-specific offline RL pre-training for each task, and is often brittle in practice. In this work, we propose unsupervised-to-online RL (U2O RL), which replaces domain-specific supervised offline RL with unsupervised offline RL, as a better alternative to offline-to-online RL. U2O RL not only enables reusing a single pre-trained model for multiple downstream tasks, but also learns better representations, which often result in even better performance and stability than supervised offline-to-online RL. To instantiate U2O RL in practice, we propose a general recipe for U2O RL to bridge task-agnostic unsupervised offline skill-based policy pre-training and supervised online fine-tuning. Throughout our experiments in nine state-based and pixel-based environments, we empirically demonstrate that U2O RL achieves strong performance that matches or even outperforms previous offline-to-online RL approaches, while being able to reuse a single pre-trained model for a number of different downstream tasks.","sentences":["Offline-to-online reinforcement learning (RL), a framework that trains a policy with offline RL and then further fine-tunes it with online RL, has been considered a promising recipe for data-driven decision-making.","While sensible, this framework has drawbacks: it requires domain-specific offline RL pre-training for each task, and is often brittle in practice.","In this work, we propose unsupervised-to-online RL (U2O RL), which replaces domain-specific supervised offline RL with unsupervised offline RL, as a better alternative to offline-to-online RL.","U2O RL not only enables reusing a single pre-trained model for multiple downstream tasks, but also learns better representations, which often result in even better performance and stability than supervised offline-to-online RL.","To instantiate U2O RL in practice, we propose a general recipe for U2O RL to bridge task-agnostic unsupervised offline skill-based policy pre-training and supervised online fine-tuning.","Throughout our experiments in nine state-based and pixel-based environments, we empirically demonstrate that U2O RL achieves strong performance that matches or even outperforms previous offline-to-online RL approaches, while being able to reuse a single pre-trained model for a number of different downstream tasks."],"url":"http://arxiv.org/abs/2408.14785v1"}
{"created":"2024-08-27 04:31:58","title":"Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning","abstract":"We introduce Instruct-SkillMix, an automated approach for creating diverse, high quality SFT data. The Instruct-SkillMix pipeline involves two stages, each leveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to extract core \"skills\" for instruction-following, either from existing datasets, or by directly prompting the model; (2) Data generation: uses the powerful LLM to generate (instruction, response) data that exhibit a randomly chosen pair of these skills. Here, the use of random skill combinations promotes diversity and difficulty.   Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from Instruct-SkillMix leads to strong gains on instruction following benchmarks such as AlpacaEval 2.0, MT-Bench, and WildBench. With just $4$K examples, LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0. To our knowledge, this achieves state-of-the-art performance among all models that have only undergone SFT (no RL methods) and competes with proprietary models such as Claude 3 Opus and LLaMA-3.1-405B-Instruct.   Ablation studies also suggest plausible reasons for why creating open instruction-tuning datasets via naive crowd-sourcing has proved difficult. Introducing low quality answers (\"shirkers\") in $20\\%$ of Instruct-SkillMix examples causes performance to plummet, sometimes catastrophically.   The Instruct-SkillMix pipeline is flexible and is adaptable to other settings.","sentences":["We introduce Instruct-SkillMix, an automated approach for creating diverse, high quality SFT data.","The Instruct-SkillMix pipeline involves two stages, each leveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to extract core \"skills\" for instruction-following, either from existing datasets, or by directly prompting the model; (2) Data generation: uses the powerful LLM to generate (instruction, response) data that exhibit a randomly chosen pair of these skills.","Here, the use of random skill combinations promotes diversity and difficulty.   ","Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from Instruct-SkillMix leads to strong gains on instruction following benchmarks such as AlpacaEval 2.0, MT-Bench, and WildBench.","With just $4$K examples, LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0.","To our knowledge, this achieves state-of-the-art performance among all models that have only undergone SFT (no RL methods) and competes with proprietary models such as Claude 3 Opus and LLaMA-3.1-405B-Instruct.   ","Ablation studies also suggest plausible reasons for why creating open instruction-tuning datasets via naive crowd-sourcing has proved difficult.","Introducing low quality answers (\"shirkers\") in $20\\%$ of Instruct-SkillMix examples causes performance to plummet, sometimes catastrophically.   ","The Instruct-SkillMix pipeline is flexible and is adaptable to other settings."],"url":"http://arxiv.org/abs/2408.14774v1"}
{"created":"2024-08-27 04:18:18","title":"Text-guided Foundation Model Adaptation for Long-Tailed Medical Image Classification","abstract":"In medical contexts, the imbalanced data distribution in long-tailed datasets, due to scarce labels for rare diseases, greatly impairs the diagnostic accuracy of deep learning models. Recent multimodal text-image supervised foundation models offer new solutions to data scarcity through effective representation learning. However, their limited medical-specific pretraining hinders their performance in medical image classification relative to natural images. To address this issue, we propose a novel Text-guided Foundation model Adaptation for Long-Tailed medical image classification (TFA-LT). We adopt a two-stage training strategy, integrating representations from the foundation model using just two linear adapters and a single ensembler for balanced outcomes. Experimental results on two long-tailed medical image datasets validate the simplicity, lightweight and efficiency of our approach: requiring only 6.1% GPU memory usage of the current best-performing algorithm, our method achieves an accuracy improvement of up to 27.1%, highlighting the substantial potential of foundation model adaptation in this area.","sentences":["In medical contexts, the imbalanced data distribution in long-tailed datasets, due to scarce labels for rare diseases, greatly impairs the diagnostic accuracy of deep learning models.","Recent multimodal text-image supervised foundation models offer new solutions to data scarcity through effective representation learning.","However, their limited medical-specific pretraining hinders their performance in medical image classification relative to natural images.","To address this issue, we propose a novel Text-guided Foundation model Adaptation for Long-Tailed medical image classification (TFA-LT).","We adopt a two-stage training strategy, integrating representations from the foundation model using just two linear adapters and a single ensembler for balanced outcomes.","Experimental results on two long-tailed medical image datasets validate the simplicity, lightweight and efficiency of our approach: requiring only 6.1% GPU memory usage of the current best-performing algorithm, our method achieves an accuracy improvement of up to 27.1%, highlighting the substantial potential of foundation model adaptation in this area."],"url":"http://arxiv.org/abs/2408.14770v1"}
{"created":"2024-08-27 04:10:22","title":"Points2Plans: From Point Clouds to Long-Horizon Plans with Composable Relational Dynamics","abstract":"We present Points2Plans, a framework for composable planning with a relational dynamics model that enables robots to solve long-horizon manipulation tasks from partial-view point clouds. Given a language instruction and a point cloud of the scene, our framework initiates a hierarchical planning procedure, whereby a language model generates a high-level plan and a sampling-based planner produces constraint-satisfying continuous parameters for manipulation primitives sequenced according to the high-level plan. Key to our approach is the use of a relational dynamics model as a unifying interface between the continuous and symbolic representations of states and actions, thus facilitating language-driven planning from high-dimensional perceptual input such as point clouds. Whereas previous relational dynamics models require training on datasets of multi-step manipulation scenarios that align with the intended test scenarios, Points2Plans uses only single-step simulated training data while generalizing zero-shot to a variable number of steps during real-world evaluations. We evaluate our approach on tasks involving geometric reasoning, multi-object interactions, and occluded object reasoning in both simulated and real-world settings. Results demonstrate that Points2Plans offers strong generalization to unseen long-horizon tasks in the real world, where it solves over 85% of evaluated tasks while the next best baseline solves only 50%. Qualitative demonstrations of our approach operating on a mobile manipulator platform are made available at sites.google.com/stanford.edu/points2plans.","sentences":["We present Points2Plans, a framework for composable planning with a relational dynamics model that enables robots to solve long-horizon manipulation tasks from partial-view point clouds.","Given a language instruction and a point cloud of the scene, our framework initiates a hierarchical planning procedure, whereby a language model generates a high-level plan and a sampling-based planner produces constraint-satisfying continuous parameters for manipulation primitives sequenced according to the high-level plan.","Key to our approach is the use of a relational dynamics model as a unifying interface between the continuous and symbolic representations of states and actions, thus facilitating language-driven planning from high-dimensional perceptual input such as point clouds.","Whereas previous relational dynamics models require training on datasets of multi-step manipulation scenarios that align with the intended test scenarios, Points2Plans uses only single-step simulated training data while generalizing zero-shot to a variable number of steps during real-world evaluations.","We evaluate our approach on tasks involving geometric reasoning, multi-object interactions, and occluded object reasoning in both simulated and real-world settings.","Results demonstrate that Points2Plans offers strong generalization to unseen long-horizon tasks in the real world, where it solves over 85% of evaluated tasks while the next best baseline solves only 50%.","Qualitative demonstrations of our approach operating on a mobile manipulator platform are made available at sites.google.com/stanford.edu/points2plans."],"url":"http://arxiv.org/abs/2408.14769v1"}
{"created":"2024-08-27 03:41:44","title":"CrossViewDiff: A Cross-View Diffusion Model for Satellite-to-Street View Synthesis","abstract":"Satellite-to-street view synthesis aims at generating a realistic street-view image from its corresponding satellite-view image. Although stable diffusion models have exhibit remarkable performance in a variety of image generation applications, their reliance on similar-view inputs to control the generated structure or texture restricts their application to the challenging cross-view synthesis task. In this work, we propose CrossViewDiff, a cross-view diffusion model for satellite-to-street view synthesis. To address the challenges posed by the large discrepancy across views, we design the satellite scene structure estimation and cross-view texture mapping modules to construct the structural and textural controls for street-view image synthesis. We further design a cross-view control guided denoising process that incorporates the above controls via an enhanced cross-view attention module. To achieve a more comprehensive evaluation of the synthesis results, we additionally design a GPT-based scoring method as a supplement to standard evaluation metrics. We also explore the effect of different data sources (e.g., text, maps, building heights, and multi-temporal satellite imagery) on this task. Results on three public cross-view datasets show that CrossViewDiff outperforms current state-of-the-art on both standard and GPT-based evaluation metrics, generating high-quality street-view panoramas with more realistic structures and textures across rural, suburban, and urban scenes. The code and models of this work will be released at https://opendatalab.github.io/CrossViewDiff/.","sentences":["Satellite-to-street view synthesis aims at generating a realistic street-view image from its corresponding satellite-view image.","Although stable diffusion models have exhibit remarkable performance in a variety of image generation applications, their reliance on similar-view inputs to control the generated structure or texture restricts their application to the challenging cross-view synthesis task.","In this work, we propose CrossViewDiff, a cross-view diffusion model for satellite-to-street view synthesis.","To address the challenges posed by the large discrepancy across views, we design the satellite scene structure estimation and cross-view texture mapping modules to construct the structural and textural controls for street-view image synthesis.","We further design a cross-view control guided denoising process that incorporates the above controls via an enhanced cross-view attention module.","To achieve a more comprehensive evaluation of the synthesis results, we additionally design a GPT-based scoring method as a supplement to standard evaluation metrics.","We also explore the effect of different data sources (e.g., text, maps, building heights, and multi-temporal satellite imagery) on this task.","Results on three public cross-view datasets show that CrossViewDiff outperforms current state-of-the-art on both standard and GPT-based evaluation metrics, generating high-quality street-view panoramas with more realistic structures and textures across rural, suburban, and urban scenes.","The code and models of this work will be released at https://opendatalab.github.io/CrossViewDiff/."],"url":"http://arxiv.org/abs/2408.14765v1"}
{"created":"2024-08-27 03:31:24","title":"SynthDoc: Bilingual Documents Synthesis for Visual Document Understanding","abstract":"This paper introduces SynthDoc, a novel synthetic document generation pipeline designed to enhance Visual Document Understanding (VDU) by generating high-quality, diverse datasets that include text, images, tables, and charts. Addressing the challenges of data acquisition and the limitations of existing datasets, SynthDoc leverages publicly available corpora and advanced rendering tools to create a comprehensive and versatile dataset. Our experiments, conducted using the Donut model, demonstrate that models trained with SynthDoc's data achieve superior performance in pre-training read tasks and maintain robustness in downstream tasks, despite language inconsistencies. The release of a benchmark dataset comprising 5,000 image-text pairs not only showcases the pipeline's capabilities but also provides a valuable resource for the VDU community to advance research and development in document image recognition. This work significantly contributes to the field by offering a scalable solution to data scarcity and by validating the efficacy of end-to-end models in parsing complex, real-world documents.","sentences":["This paper introduces SynthDoc, a novel synthetic document generation pipeline designed to enhance Visual Document Understanding (VDU) by generating high-quality, diverse datasets that include text, images, tables, and charts.","Addressing the challenges of data acquisition and the limitations of existing datasets, SynthDoc leverages publicly available corpora and advanced rendering tools to create a comprehensive and versatile dataset.","Our experiments, conducted using the Donut model, demonstrate that models trained with SynthDoc's data achieve superior performance in pre-training read tasks and maintain robustness in downstream tasks, despite language inconsistencies.","The release of a benchmark dataset comprising 5,000 image-text pairs not only showcases the pipeline's capabilities but also provides a valuable resource for the VDU community to advance research and development in document image recognition.","This work significantly contributes to the field by offering a scalable solution to data scarcity and by validating the efficacy of end-to-end models in parsing complex, real-world documents."],"url":"http://arxiv.org/abs/2408.14764v1"}
{"created":"2024-08-27 03:30:18","title":"Channel-wise Influence: Estimating Data Influence for Multivariate Time Series","abstract":"The influence function, a technique from robust statistics, measures the impact on model parameters or related functions when training data is removed or modified. This effective and valuable post-hoc method allows for studying the interpretability of machine learning models without requiring costly model retraining. It would provide extensions like increasing model performance, improving model generalization, and offering interpretability. Recently, Multivariate Time Series (MTS) analysis has become an important yet challenging task, attracting significant attention. However, there is no preceding research on the influence functions of MTS to shed light on the effects of modifying the channel of training MTS. Given that each channel in an MTS plays a crucial role in its analysis, it is essential to characterize the influence of different channels. To fill this gap, we propose a channel-wise influence function, which is the first method that can estimate the influence of different channels in MTS, utilizing a first-order gradient approximation that leverages the more informative average gradient of the data set. Additionally, we demonstrate how this influence function can be used to estimate the impact of a channel in MTS. Finally, we validated the accuracy and effectiveness of our influence estimation function in critical MTS analysis tasks, such as MTS anomaly detection and MTS forecasting. According to abundant experiments on real-world dataset, the original influence function performs worse than our method and even fail for the channel pruning problem, which demonstrate the superiority and necessity of channel-wise influence function in MTS analysis tasks.","sentences":["The influence function, a technique from robust statistics, measures the impact on model parameters or related functions when training data is removed or modified.","This effective and valuable post-hoc method allows for studying the interpretability of machine learning models without requiring costly model retraining.","It would provide extensions like increasing model performance, improving model generalization, and offering interpretability.","Recently, Multivariate Time Series (MTS) analysis has become an important yet challenging task, attracting significant attention.","However, there is no preceding research on the influence functions of MTS to shed light on the effects of modifying the channel of training MTS.","Given that each channel in an MTS plays a crucial role in its analysis, it is essential to characterize the influence of different channels.","To fill this gap, we propose a channel-wise influence function, which is the first method that can estimate the influence of different channels in MTS, utilizing a first-order gradient approximation that leverages the more informative average gradient of the data set.","Additionally, we demonstrate how this influence function can be used to estimate the impact of a channel in MTS.","Finally, we validated the accuracy and effectiveness of our influence estimation function in critical MTS analysis tasks, such as MTS anomaly detection and MTS forecasting.","According to abundant experiments on real-world dataset, the original influence function performs worse than our method and even fail for the channel pruning problem, which demonstrate the superiority and necessity of channel-wise influence function in MTS analysis tasks."],"url":"http://arxiv.org/abs/2408.14763v1"}
{"created":"2024-08-27 03:30:01","title":"Explainable Hierarchical Urban Representation Learning for Commuting Flow Prediction","abstract":"Commuting flow prediction is an essential task for municipal operations in the real world. Previous studies have revealed that it is feasible to estimate the commuting origin-destination (OD) demand within a city using multiple auxiliary data. However, most existing methods are not suitable to deal with a similar task at a large scale, namely within a prefecture or the whole nation, owing to the increased number of geographical units that need to be maintained. In addition, region representation learning is a universal approach for gaining urban knowledge for diverse metropolitan downstream tasks. Although many researchers have developed comprehensive frameworks to describe urban units from multi-source data, they have not clarified the relationship between the selected geographical elements. Furthermore, metropolitan areas naturally preserve ranked structures, like cities and their inclusive districts, which makes elucidating relations between cross-level urban units necessary. Therefore, we develop a heterogeneous graph-based model to generate meaningful region embeddings at multiple spatial resolutions for predicting different types of inter-level OD flows. To demonstrate the effectiveness of the proposed method, extensive experiments were conducted using real-world aggregated mobile phone datasets collected from Shizuoka Prefecture, Japan. The results indicate that our proposed model outperforms existing models in terms of a uniform urban structure. We extend the understanding of predicted results using reasonable explanations to enhance the credibility of the model.","sentences":["Commuting flow prediction is an essential task for municipal operations in the real world.","Previous studies have revealed that it is feasible to estimate the commuting origin-destination (OD) demand within a city using multiple auxiliary data.","However, most existing methods are not suitable to deal with a similar task at a large scale, namely within a prefecture or the whole nation, owing to the increased number of geographical units that need to be maintained.","In addition, region representation learning is a universal approach for gaining urban knowledge for diverse metropolitan downstream tasks.","Although many researchers have developed comprehensive frameworks to describe urban units from multi-source data, they have not clarified the relationship between the selected geographical elements.","Furthermore, metropolitan areas naturally preserve ranked structures, like cities and their inclusive districts, which makes elucidating relations between cross-level urban units necessary.","Therefore, we develop a heterogeneous graph-based model to generate meaningful region embeddings at multiple spatial resolutions for predicting different types of inter-level OD flows.","To demonstrate the effectiveness of the proposed method, extensive experiments were conducted using real-world aggregated mobile phone datasets collected from Shizuoka Prefecture, Japan.","The results indicate that our proposed model outperforms existing models in terms of a uniform urban structure.","We extend the understanding of predicted results using reasonable explanations to enhance the credibility of the model."],"url":"http://arxiv.org/abs/2408.14762v1"}
{"created":"2024-08-27 03:12:08","title":"Training-Free Time-Series Anomaly Detection: Leveraging Image Foundation Models","abstract":"Recent advancements in time-series anomaly detection have relied on deep learning models to handle the diverse behaviors of time-series data. However, these models often suffer from unstable training and require extensive hyperparameter tuning, leading to practical limitations. Although foundation models present a potential solution, their use in time series is limited. To overcome these issues, we propose an innovative image-based, training-free time-series anomaly detection (ITF-TAD) approach. ITF-TAD converts time-series data into images using wavelet transform and compresses them into a single representation, leveraging image foundation models for anomaly detection. This approach achieves high-performance anomaly detection without unstable neural network training or hyperparameter tuning. Furthermore, ITF-TAD identifies anomalies across different frequencies, providing users with a detailed visualization of anomalies and their corresponding frequencies. Comprehensive experiments on five benchmark datasets, including univariate and multivariate time series, demonstrate that ITF-TAD offers a practical and effective solution with performance exceeding or comparable to that of deep models.","sentences":["Recent advancements in time-series anomaly detection have relied on deep learning models to handle the diverse behaviors of time-series data.","However, these models often suffer from unstable training and require extensive hyperparameter tuning, leading to practical limitations.","Although foundation models present a potential solution, their use in time series is limited.","To overcome these issues, we propose an innovative image-based, training-free time-series anomaly detection (ITF-TAD) approach.","ITF-TAD converts time-series data into images using wavelet transform and compresses them into a single representation, leveraging image foundation models for anomaly detection.","This approach achieves high-performance anomaly detection without unstable neural network training or hyperparameter tuning.","Furthermore, ITF-TAD identifies anomalies across different frequencies, providing users with a detailed visualization of anomalies and their corresponding frequencies.","Comprehensive experiments on five benchmark datasets, including univariate and multivariate time series, demonstrate that ITF-TAD offers a practical and effective solution with performance exceeding or comparable to that of deep models."],"url":"http://arxiv.org/abs/2408.14756v1"}
{"created":"2024-08-27 03:07:03","title":"CoopASD: Cooperative Machine Anomalous Sound Detection with Privacy Concerns","abstract":"Machine anomalous sound detection (ASD) has emerged as one of the most promising applications in the Industrial Internet of Things (IIoT) due to its unprecedented efficacy in mitigating risks of malfunctions and promoting production efficiency. Previous works mainly investigated the machine ASD task under centralized settings. However, developing the ASD system under decentralized settings is crucial in practice, since the machine data are dispersed in various factories and the data should not be explicitly shared due to privacy concerns. To enable these factories to cooperatively develop a scalable ASD model while preserving their privacy, we propose a novel framework named CoopASD, where each factory trains an ASD model on its local dataset, and a central server aggregates these local models periodically. We employ a pre-trained model as the backbone of the ASD model to improve its robustness and develop specialized techniques to stabilize the model under a completely non-iid and domain shift setting. Compared with previous state-of-the-art (SOTA) models trained in centralized settings, CoopASD showcases competitive results with negligible degradation of 0.08%. We also conduct extensive ablation studies to demonstrate the effectiveness of CoopASD.","sentences":["Machine anomalous sound detection (ASD) has emerged as one of the most promising applications in the Industrial Internet of Things (IIoT) due to its unprecedented efficacy in mitigating risks of malfunctions and promoting production efficiency.","Previous works mainly investigated the machine ASD task under centralized settings.","However, developing the ASD system under decentralized settings is crucial in practice, since the machine data are dispersed in various factories and the data should not be explicitly shared due to privacy concerns.","To enable these factories to cooperatively develop a scalable ASD model while preserving their privacy, we propose a novel framework named CoopASD, where each factory trains an ASD model on its local dataset, and a central server aggregates these local models periodically.","We employ a pre-trained model as the backbone of the ASD model to improve its robustness and develop specialized techniques to stabilize the model under a completely non-iid and domain shift setting.","Compared with previous state-of-the-art (SOTA) models trained in centralized settings, CoopASD showcases competitive results with negligible degradation of 0.08%.","We also conduct extensive ablation studies to demonstrate the effectiveness of CoopASD."],"url":"http://arxiv.org/abs/2408.14753v1"}
{"created":"2024-08-27 03:01:48","title":"LyCon: Lyrics Reconstruction from the Bag-of-Words Using Large Language Models","abstract":"This paper addresses the unique challenge of conducting research in lyric studies, where direct use of lyrics is often restricted due to copyright concerns. Unlike typical data, internet-sourced lyrics are frequently protected under copyright law, necessitating alternative approaches. Our study introduces a novel method for generating copyright-free lyrics from publicly available Bag-of-Words (BoW) datasets, which contain the vocabulary of lyrics but not the lyrics themselves. Utilizing metadata associated with BoW datasets and large language models, we successfully reconstructed lyrics. We have compiled and made available a dataset of reconstructed lyrics, LyCon, aligned with metadata from renowned sources including the Million Song Dataset, Deezer Mood Detection Dataset, and AllMusic Genre Dataset, available for public access. We believe that the integration of metadata such as mood annotations or genres enables a variety of academic experiments on lyrics, such as conditional lyric generation.","sentences":["This paper addresses the unique challenge of conducting research in lyric studies, where direct use of lyrics is often restricted due to copyright concerns.","Unlike typical data, internet-sourced lyrics are frequently protected under copyright law, necessitating alternative approaches.","Our study introduces a novel method for generating copyright-free lyrics from publicly available Bag-of-Words (BoW) datasets, which contain the vocabulary of lyrics but not the lyrics themselves.","Utilizing metadata associated with BoW datasets and large language models, we successfully reconstructed lyrics.","We have compiled and made available a dataset of reconstructed lyrics, LyCon, aligned with metadata from renowned sources including the Million Song Dataset, Deezer Mood Detection Dataset, and AllMusic Genre Dataset, available for public access.","We believe that the integration of metadata such as mood annotations or genres enables a variety of academic experiments on lyrics, such as conditional lyric generation."],"url":"http://arxiv.org/abs/2408.14750v1"}
{"created":"2024-08-27 02:45:26","title":"RSTeller: Scaling Up Visual Language Modeling in Remote Sensing with Rich Linguistic Semantics from Openly Available Data and Large Language Models","abstract":"Abundant, well-annotated multimodal data in remote sensing are pivotal for aligning complex visual remote sensing (RS) scenes with human language, enabling the development of specialized vision language models across diverse RS interpretation tasks. However, annotating RS images with rich linguistic semantics at scale demands expertise in RS and substantial human labor, making it costly and often impractical. In this study, we propose a workflow that leverages large language models (LLMs) to generate multimodal datasets with semantically rich captions at scale from plain OpenStreetMap (OSM) data for images sourced from the Google Earth Engine (GEE) platform. This approach facilitates the generation of paired remote sensing data and can be readily scaled up using openly available data. Within this framework, we present RSTeller, a multimodal dataset comprising over 1 million RS images, each accompanied by multiple descriptive captions. Extensive experiments demonstrate that RSTeller enhances the performance of multiple existing vision language models for RS scene understanding through continual pre-training. Our methodology significantly reduces the manual effort and expertise needed for annotating remote sensing imagery while democratizing access to high-quality annotated data. This advancement fosters progress in visual language modeling and encourages broader participation in remote sensing research and applications. The RSTeller dataset is available at https://github.com/SlytherinGe/RSTeller.","sentences":["Abundant, well-annotated multimodal data in remote sensing are pivotal for aligning complex visual remote sensing (RS) scenes with human language, enabling the development of specialized vision language models across diverse RS interpretation tasks.","However, annotating RS images with rich linguistic semantics at scale demands expertise in RS and substantial human labor, making it costly and often impractical.","In this study, we propose a workflow that leverages large language models (LLMs) to generate multimodal datasets with semantically rich captions at scale from plain OpenStreetMap (OSM) data for images sourced from the Google Earth Engine (GEE) platform.","This approach facilitates the generation of paired remote sensing data and can be readily scaled up using openly available data.","Within this framework, we present RSTeller, a multimodal dataset comprising over 1 million RS images, each accompanied by multiple descriptive captions.","Extensive experiments demonstrate that RSTeller enhances the performance of multiple existing vision language models for RS scene understanding through continual pre-training.","Our methodology significantly reduces the manual effort and expertise needed for annotating remote sensing imagery while democratizing access to high-quality annotated data.","This advancement fosters progress in visual language modeling and encourages broader participation in remote sensing research and applications.","The RSTeller dataset is available at https://github.com/SlytherinGe/RSTeller."],"url":"http://arxiv.org/abs/2408.14744v1"}
{"created":"2024-08-27 02:43:40","title":"Personalized Video Summarization using Text-Based Queries and Conditional Modeling","abstract":"The proliferation of video content on platforms like YouTube and Vimeo presents significant challenges in efficiently locating relevant information. Automatic video summarization aims to address this by extracting and presenting key content in a condensed form. This thesis explores enhancing video summarization by integrating text-based queries and conditional modeling to tailor summaries to user needs. Traditional methods often produce fixed summaries that may not align with individual requirements. To overcome this, we propose a multi-modal deep learning approach that incorporates both textual queries and visual information, fusing them at different levels of the model architecture. Evaluation metrics such as accuracy and F1-score assess the quality of the generated summaries. The thesis also investigates improving text-based query representations using contextualized word embeddings and specialized attention networks. This enhances the semantic understanding of queries, leading to better video summaries. To emulate human-like summarization, which accounts for both visual coherence and abstract factors like storyline consistency, we introduce a conditional modeling approach. This method uses multiple random variables and joint distributions to capture key summarization components, resulting in more human-like and explainable summaries. Addressing data scarcity in fully supervised learning, the thesis proposes a segment-level pseudo-labeling approach. This self-supervised method generates additional data, improving model performance even with limited human-labeled datasets. In summary, this research aims to enhance automatic video summarization by incorporating text-based queries, improving query representations, introducing conditional modeling, and addressing data scarcity, thereby creating more effective and personalized video summaries.","sentences":["The proliferation of video content on platforms like YouTube and Vimeo presents significant challenges in efficiently locating relevant information.","Automatic video summarization aims to address this by extracting and presenting key content in a condensed form.","This thesis explores enhancing video summarization by integrating text-based queries and conditional modeling to tailor summaries to user needs.","Traditional methods often produce fixed summaries that may not align with individual requirements.","To overcome this, we propose a multi-modal deep learning approach that incorporates both textual queries and visual information, fusing them at different levels of the model architecture.","Evaluation metrics such as accuracy and F1-score assess the quality of the generated summaries.","The thesis also investigates improving text-based query representations using contextualized word embeddings and specialized attention networks.","This enhances the semantic understanding of queries, leading to better video summaries.","To emulate human-like summarization, which accounts for both visual coherence and abstract factors like storyline consistency, we introduce a conditional modeling approach.","This method uses multiple random variables and joint distributions to capture key summarization components, resulting in more human-like and explainable summaries.","Addressing data scarcity in fully supervised learning, the thesis proposes a segment-level pseudo-labeling approach.","This self-supervised method generates additional data, improving model performance even with limited human-labeled datasets.","In summary, this research aims to enhance automatic video summarization by incorporating text-based queries, improving query representations, introducing conditional modeling, and addressing data scarcity, thereby creating more effective and personalized video summaries."],"url":"http://arxiv.org/abs/2408.14743v1"}
{"created":"2024-08-27 02:34:41","title":"Properties of Effective Information Anonymity Regulations","abstract":"A firm seeks to analyze a dataset and to release the results. The dataset contains information about individual people, and the firm is subject to some regulation that forbids the release of the dataset itself. The regulation also imposes conditions on the release of the results. What properties should the regulation satisfy? We restrict our attention to regulations tailored to controlling the downstream effects of the release specifically on the individuals to whom the data relate. A particular example of interest is an anonymization rule, where a data protection regulation limiting the disclosure of personally identifiable information does not restrict the distribution of data that has been sufficiently anonymized.   In this paper, we develop a set of technical requirements for anonymization rules and related regulations. The requirements are derived by situating within a simple abstract model of data processing a set of guiding general principles put forth in prior work. We describe an approach to evaluating such regulations using these requirements -- thus enabling the application of the general principles for the design of mechanisms. As an exemplar, we evaluate competing interpretations of regulatory requirements from the EU's General Data Protection Regulation.","sentences":["A firm seeks to analyze a dataset and to release the results.","The dataset contains information about individual people, and the firm is subject to some regulation that forbids the release of the dataset itself.","The regulation also imposes conditions on the release of the results.","What properties should the regulation satisfy?","We restrict our attention to regulations tailored to controlling the downstream effects of the release specifically on the individuals to whom the data relate.","A particular example of interest is an anonymization rule, where a data protection regulation limiting the disclosure of personally identifiable information does not restrict the distribution of data that has been sufficiently anonymized.   ","In this paper, we develop a set of technical requirements for anonymization rules and related regulations.","The requirements are derived by situating within a simple abstract model of data processing a set of guiding general principles put forth in prior work.","We describe an approach to evaluating such regulations using these requirements -- thus enabling the application of the general principles for the design of mechanisms.","As an exemplar, we evaluate competing interpretations of regulatory requirements from the EU's General Data Protection Regulation."],"url":"http://arxiv.org/abs/2408.14740v1"}
{"created":"2024-08-27 02:29:29","title":"Learning Differentially Private Diffusion Models via Stochastic Adversarial Distillation","abstract":"While the success of deep learning relies on large amounts of training datasets, data is often limited in privacy-sensitive domains. To address this challenge, generative model learning with differential privacy has emerged as a solution to train private generative models for desensitized data generation. However, the quality of the images generated by existing methods is limited due to the complexity of modeling data distribution. We build on the success of diffusion models and introduce DP-SAD, which trains a private diffusion model by a stochastic adversarial distillation method. Specifically, we first train a diffusion model as a teacher and then train a student by distillation, in which we achieve differential privacy by adding noise to the gradients from other models to the student. For better generation quality, we introduce a discriminator to distinguish whether an image is from the teacher or the student, which forms the adversarial training. Extensive experiments and analysis clearly demonstrate the effectiveness of our proposed method.","sentences":["While the success of deep learning relies on large amounts of training datasets, data is often limited in privacy-sensitive domains.","To address this challenge, generative model learning with differential privacy has emerged as a solution to train private generative models for desensitized data generation.","However, the quality of the images generated by existing methods is limited due to the complexity of modeling data distribution.","We build on the success of diffusion models and introduce DP-SAD, which trains a private diffusion model by a stochastic adversarial distillation method.","Specifically, we first train a diffusion model as a teacher and then train a student by distillation, in which we achieve differential privacy by adding noise to the gradients from other models to the student.","For better generation quality, we introduce a discriminator to distinguish whether an image is from the teacher or the student, which forms the adversarial training.","Extensive experiments and analysis clearly demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2408.14738v1"}
{"created":"2024-08-27 02:28:27","title":"Bandwidth-Aware and Overlap-Weighted Compression for Communication-Efficient Federated Learning","abstract":"Current data compression methods, such as sparsification in Federated Averaging (FedAvg), effectively enhance the communication efficiency of Federated Learning (FL). However, these methods encounter challenges such as the straggler problem and diminished model performance due to heterogeneous bandwidth and non-IID (Independently and Identically Distributed) data. To address these issues, we introduce a bandwidth-aware compression framework for FL, aimed at improving communication efficiency while mitigating the problems associated with non-IID data. First, our strategy dynamically adjusts compression ratios according to bandwidth, enabling clients to upload their models at a close pace, thus exploiting the otherwise wasted time to transmit more data. Second, we identify the non-overlapped pattern of retained parameters after compression, which results in diminished client update signals due to uniformly averaged weights. Based on this finding, we propose a parameter mask to adjust the client-averaging coefficients at the parameter level, thereby more closely approximating the original updates, and improving the training convergence under heterogeneous environments. Our evaluations reveal that our method significantly boosts model accuracy, with a maximum improvement of 13% over the uncompressed FedAvg. Moreover, it achieves a $3.37\\times$ speedup in reaching the target accuracy compared to FedAvg with a Top-K compressor, demonstrating its effectiveness in accelerating convergence with compression. The integration of common compression techniques into our framework further establishes its potential as a versatile foundation for future cross-device, communication-efficient FL research, addressing critical challenges in FL and advancing the field of distributed machine learning.","sentences":["Current data compression methods, such as sparsification in Federated Averaging (FedAvg), effectively enhance the communication efficiency of Federated Learning (FL).","However, these methods encounter challenges such as the straggler problem and diminished model performance due to heterogeneous bandwidth and non-IID (Independently and Identically Distributed) data.","To address these issues, we introduce a bandwidth-aware compression framework for FL, aimed at improving communication efficiency while mitigating the problems associated with non-IID data.","First, our strategy dynamically adjusts compression ratios according to bandwidth, enabling clients to upload their models at a close pace, thus exploiting the otherwise wasted time to transmit more data.","Second, we identify the non-overlapped pattern of retained parameters after compression, which results in diminished client update signals due to uniformly averaged weights.","Based on this finding, we propose a parameter mask to adjust the client-averaging coefficients at the parameter level, thereby more closely approximating the original updates, and improving the training convergence under heterogeneous environments.","Our evaluations reveal that our method significantly boosts model accuracy, with a maximum improvement of 13% over the uncompressed FedAvg.","Moreover, it achieves a $3.37\\times$ speedup in reaching the target accuracy compared to FedAvg with a Top-K compressor, demonstrating its effectiveness in accelerating convergence with compression.","The integration of common compression techniques into our framework further establishes its potential as a versatile foundation for future cross-device, communication-efficient FL research, addressing critical challenges in FL and advancing the field of distributed machine learning."],"url":"http://arxiv.org/abs/2408.14736v1"}
{"created":"2024-08-27 01:54:00","title":"Physics-Informed Machine Learning For Sound Field Estimation","abstract":"The area of study concerning the estimation of spatial sound, i.e., the distribution of a physical quantity of sound such as acoustic pressure, is called sound field estimation, which is the basis for various applied technologies related to spatial audio processing. The sound field estimation problem is formulated as a function interpolation problem in machine learning in a simplified scenario. However, high estimation performance cannot be expected by simply applying general interpolation techniques that rely only on data. The physical properties of sound fields are useful a priori information, and it is considered extremely important to incorporate them into the estimation. In this article, we introduce the fundamentals of physics-informed machine learning (PIML) for sound field estimation and overview current PIML-based sound field estimation methods.","sentences":["The area of study concerning the estimation of spatial sound, i.e., the distribution of a physical quantity of sound such as acoustic pressure, is called sound field estimation, which is the basis for various applied technologies related to spatial audio processing.","The sound field estimation problem is formulated as a function interpolation problem in machine learning in a simplified scenario.","However, high estimation performance cannot be expected by simply applying general interpolation techniques that rely only on data.","The physical properties of sound fields are useful a priori information, and it is considered extremely important to incorporate them into the estimation.","In this article, we introduce the fundamentals of physics-informed machine learning (PIML) for sound field estimation and overview current PIML-based sound field estimation methods."],"url":"http://arxiv.org/abs/2408.14731v1"}
{"created":"2024-08-27 01:41:21","title":"TART: Boosting Clean Accuracy Through Tangent Direction Guided Adversarial Training","abstract":"Adversarial training has been shown to be successful in enhancing the robustness of deep neural networks against adversarial attacks. However, this robustness is accompanied by a significant decline in accuracy on clean data. In this paper, we propose a novel method, called Tangent Direction Guided Adversarial Training (TART), that leverages the tangent space of the data manifold to ameliorate the existing adversarial defense algorithms. We argue that training with adversarial examples having large normal components significantly alters the decision boundary and hurts accuracy. TART mitigates this issue by estimating the tangent direction of adversarial examples and allocating an adaptive perturbation limit according to the norm of their tangential component. To the best of our knowledge, our paper is the first work to consider the concept of tangent space and direction in the context of adversarial defense. We validate the effectiveness of TART through extensive experiments on both simulated and benchmark datasets. The results demonstrate that TART consistently boosts clean accuracy while retaining a high level of robustness against adversarial attacks. Our findings suggest that incorporating the geometric properties of data can lead to more effective and efficient adversarial training methods.","sentences":["Adversarial training has been shown to be successful in enhancing the robustness of deep neural networks against adversarial attacks.","However, this robustness is accompanied by a significant decline in accuracy on clean data.","In this paper, we propose a novel method, called Tangent Direction Guided Adversarial Training (TART), that leverages the tangent space of the data manifold to ameliorate the existing adversarial defense algorithms.","We argue that training with adversarial examples having large normal components significantly alters the decision boundary and hurts accuracy.","TART mitigates this issue by estimating the tangent direction of adversarial examples and allocating an adaptive perturbation limit according to the norm of their tangential component.","To the best of our knowledge, our paper is the first work to consider the concept of tangent space and direction in the context of adversarial defense.","We validate the effectiveness of TART through extensive experiments on both simulated and benchmark datasets.","The results demonstrate that TART consistently boosts clean accuracy while retaining a high level of robustness against adversarial attacks.","Our findings suggest that incorporating the geometric properties of data can lead to more effective and efficient adversarial training methods."],"url":"http://arxiv.org/abs/2408.14728v1"}
{"created":"2024-08-27 01:28:15","title":"GeoTransfer : Generalizable Few-Shot Multi-View Reconstruction via Transfer Learning","abstract":"This paper presents a novel approach for sparse 3D reconstruction by leveraging the expressive power of Neural Radiance Fields (NeRFs) and fast transfer of their features to learn accurate occupancy fields. Existing 3D reconstruction methods from sparse inputs still struggle with capturing intricate geometric details and can suffer from limitations in handling occluded regions. On the other hand, NeRFs excel in modeling complex scenes but do not offer means to extract meaningful geometry. Our proposed method offers the best of both worlds by transferring the information encoded in NeRF features to derive an accurate occupancy field representation. We utilize a pre-trained, generalizable state-of-the-art NeRF network to capture detailed scene radiance information, and rapidly transfer this knowledge to train a generalizable implicit occupancy network. This process helps in leveraging the knowledge of the scene geometry encoded in the generalizable NeRF prior and refining it to learn occupancy fields, facilitating a more precise generalizable representation of 3D space. The transfer learning approach leads to a dramatic reduction in training time, by orders of magnitude (i.e. from several days to 3.5 hrs), obviating the need to train generalizable sparse surface reconstruction methods from scratch. Additionally, we introduce a novel loss on volumetric rendering weights that helps in the learning of accurate occupancy fields, along with a normal loss that helps in global smoothing of the occupancy fields. We evaluate our approach on the DTU dataset and demonstrate state-of-the-art performance in terms of reconstruction accuracy, especially in challenging scenarios with sparse input data and occluded regions. We furthermore demonstrate the generalization capabilities of our method by showing qualitative results on the Blended MVS dataset without any retraining.","sentences":["This paper presents a novel approach for sparse 3D reconstruction by leveraging the expressive power of Neural Radiance Fields (NeRFs) and fast transfer of their features to learn accurate occupancy fields.","Existing 3D reconstruction methods from sparse inputs still struggle with capturing intricate geometric details and can suffer from limitations in handling occluded regions.","On the other hand, NeRFs excel in modeling complex scenes but do not offer means to extract meaningful geometry.","Our proposed method offers the best of both worlds by transferring the information encoded in NeRF features to derive an accurate occupancy field representation.","We utilize a pre-trained, generalizable state-of-the-art NeRF network to capture detailed scene radiance information, and rapidly transfer this knowledge to train a generalizable implicit occupancy network.","This process helps in leveraging the knowledge of the scene geometry encoded in the generalizable NeRF prior and refining it to learn occupancy fields, facilitating a more precise generalizable representation of 3D space.","The transfer learning approach leads to a dramatic reduction in training time, by orders of magnitude (i.e. from several days to 3.5 hrs), obviating the need to train generalizable sparse surface reconstruction methods from scratch.","Additionally, we introduce a novel loss on volumetric rendering weights that helps in the learning of accurate occupancy fields, along with a normal loss that helps in global smoothing of the occupancy fields.","We evaluate our approach on the DTU dataset and demonstrate state-of-the-art performance in terms of reconstruction accuracy, especially in challenging scenarios with sparse input data and occluded regions.","We furthermore demonstrate the generalization capabilities of our method by showing qualitative results on the Blended MVS dataset without any retraining."],"url":"http://arxiv.org/abs/2408.14724v1"}
{"created":"2024-08-27 00:58:32","title":"Residual-based Adaptive Huber Loss (RAHL) -- Design of an improved Huber loss for CQI prediction in 5G networks","abstract":"The Channel Quality Indicator (CQI) plays a pivotal role in 5G networks, optimizing infrastructure dynamically to ensure high Quality of Service (QoS). Recent research has focused on improving CQI estimation in 5G networks using machine learning. In this field, the selection of the proper loss function is critical for training an accurate model. Two commonly used loss functions are Mean Squared Error (MSE) and Mean Absolute Error (MAE). Roughly speaking, MSE put more weight on outliers, MAE on the majority. Here, we argue that the Huber loss function is more suitable for CQI prediction, since it combines the benefits of both MSE and MAE. To achieve this, the Huber loss transitions smoothly between MSE and MAE, controlled by a user-defined hyperparameter called delta. However, finding the right balance between sensitivity to small errors (MAE) and robustness to outliers (MSE) by manually choosing the optimal delta is challenging. To address this issue, we propose a novel loss function, named Residual-based Adaptive Huber Loss (RAHL). In RAHL, a learnable residual is added to the delta, enabling the model to adapt based on the distribution of errors in the data. Our approach effectively balances model robustness against outliers while preserving inlier data precision. The widely recognized Long Short-Term Memory (LSTM) model is employed in conjunction with RAHL, showcasing significantly improved results compared to the aforementioned loss functions. The obtained results affirm the superiority of RAHL, offering a promising avenue for enhanced CQI prediction in 5G networks.","sentences":["The Channel Quality Indicator (CQI) plays a pivotal role in 5G networks, optimizing infrastructure dynamically to ensure high Quality of Service (QoS).","Recent research has focused on improving CQI estimation in 5G networks using machine learning.","In this field, the selection of the proper loss function is critical for training an accurate model.","Two commonly used loss functions are Mean Squared Error (MSE) and Mean Absolute Error (MAE).","Roughly speaking, MSE put more weight on outliers, MAE on the majority.","Here, we argue that the Huber loss function is more suitable for CQI prediction, since it combines the benefits of both MSE and MAE.","To achieve this, the Huber loss transitions smoothly between MSE and MAE, controlled by a user-defined hyperparameter called delta.","However, finding the right balance between sensitivity to small errors (MAE) and robustness to outliers (MSE) by manually choosing the optimal delta is challenging.","To address this issue, we propose a novel loss function, named Residual-based Adaptive Huber Loss (RAHL).","In RAHL, a learnable residual is added to the delta, enabling the model to adapt based on the distribution of errors in the data.","Our approach effectively balances model robustness against outliers while preserving inlier data precision.","The widely recognized Long Short-Term Memory (LSTM) model is employed in conjunction with RAHL, showcasing significantly improved results compared to the aforementioned loss functions.","The obtained results affirm the superiority of RAHL, offering a promising avenue for enhanced CQI prediction in 5G networks."],"url":"http://arxiv.org/abs/2408.14718v1"}
{"created":"2024-08-27 00:50:14","title":"Text2SQL is Not Enough: Unifying AI and Databases with TAG","abstract":"AI systems that serve natural language questions over databases promise to unlock tremendous value. Such systems would allow users to leverage the powerful reasoning and knowledge capabilities of language models (LMs) alongside the scalable computational power of data management systems. These combined capabilities would empower users to ask arbitrary natural language questions over custom data sources. However, existing methods and benchmarks insufficiently explore this setting. Text2SQL methods focus solely on natural language questions that can be expressed in relational algebra, representing a small subset of the questions real users wish to ask. Likewise, Retrieval-Augmented Generation (RAG) considers the limited subset of queries that can be answered with point lookups to one or a few data records within the database. We propose Table-Augmented Generation (TAG), a unified and general-purpose paradigm for answering natural language questions over databases. The TAG model represents a wide range of interactions between the LM and database that have been previously unexplored and creates exciting research opportunities for leveraging the world knowledge and reasoning capabilities of LMs over data. We systematically develop benchmarks to study the TAG problem and find that standard methods answer no more than 20% of queries correctly, confirming the need for further research in this area. We release code for the benchmark at https://github.com/TAG-Research/TAG-Bench.","sentences":["AI systems that serve natural language questions over databases promise to unlock tremendous value.","Such systems would allow users to leverage the powerful reasoning and knowledge capabilities of language models (LMs) alongside the scalable computational power of data management systems.","These combined capabilities would empower users to ask arbitrary natural language questions over custom data sources.","However, existing methods and benchmarks insufficiently explore this setting.","Text2SQL methods focus solely on natural language questions that can be expressed in relational algebra, representing a small subset of the questions real users wish to ask.","Likewise, Retrieval-Augmented Generation (RAG) considers the limited subset of queries that can be answered with point lookups to one or a few data records within the database.","We propose Table-Augmented Generation (TAG), a unified and general-purpose paradigm for answering natural language questions over databases.","The TAG model represents a wide range of interactions between the LM and database that have been previously unexplored and creates exciting research opportunities for leveraging the world knowledge and reasoning capabilities of LMs over data.","We systematically develop benchmarks to study the TAG problem and find that standard methods answer no more than 20% of queries correctly, confirming the need for further research in this area.","We release code for the benchmark at https://github.com/TAG-Research/TAG-Bench."],"url":"http://arxiv.org/abs/2408.14717v1"}
{"created":"2024-08-27 00:21:26","title":"Galley: Modern Query Optimization for Sparse Tensor Programs","abstract":"The tensor programming abstraction has become the key . This framework allows users to write high performance programs for bulk computation via a high-level imperative interface. Recent work has extended this paradigm to sparse tensors (i.e. tensors where most entries are not explicitly represented) with the use of sparse tensor compilers. These systems excel at producing efficient code for computation over sparse tensors, which may be stored in a wide variety of formats. However, they require the user to manually choose the order of operations and the data formats at every step. Unfortunately, these decisions are both highly impactful and complicated, requiring significant effort to manually optimize. In this work, we present Galley, a system for declarative sparse tensor programming. Galley performs cost-based optimization to lower these programs to a logical plan then to a physical plan. It then leverages sparse tensor compilers to execute the physical plan efficiently. We show that Galley achieves high performance on a wide variety of problems including machine learning algorithms, subgraph counting, and iterative graph algorithms.","sentences":["The tensor programming abstraction has become the key .","This framework allows users to write high performance programs for bulk computation via a high-level imperative interface.","Recent work has extended this paradigm to sparse tensors (i.e. tensors where most entries are not explicitly represented) with the use of sparse tensor compilers.","These systems excel at producing efficient code for computation over sparse tensors, which may be stored in a wide variety of formats.","However, they require the user to manually choose the order of operations and the data formats at every step.","Unfortunately, these decisions are both highly impactful and complicated, requiring significant effort to manually optimize.","In this work, we present Galley, a system for declarative sparse tensor programming.","Galley performs cost-based optimization to lower these programs to a logical plan then to a physical plan.","It then leverages sparse tensor compilers to execute the physical plan efficiently.","We show that Galley achieves high performance on a wide variety of problems including machine learning algorithms, subgraph counting, and iterative graph algorithms."],"url":"http://arxiv.org/abs/2408.14706v1"}
{"created":"2024-08-26 23:29:03","title":"Federated User Preference Modeling for Privacy-Preserving Cross-Domain Recommendation","abstract":"Cross-domain recommendation (CDR) aims to address the data-sparsity problem by transferring knowledge across domains. Existing CDR methods generally assume that the user-item interaction data is shareable between domains, which leads to privacy leakage. Recently, some privacy-preserving CDR (PPCDR) models have been proposed to solve this problem. However, they primarily transfer simple representations learned only from user-item interaction histories, overlooking other useful side information, leading to inaccurate user preferences. Additionally, they transfer differentially private user-item interaction matrices or embeddings across domains to protect privacy. However, these methods offer limited privacy protection, as attackers may exploit external information to infer the original data. To address these challenges, we propose a novel Federated User Preference Modeling (FUPM) framework. In FUPM, first, a novel comprehensive preference exploration module is proposed to learn users' comprehensive preferences from both interaction data and additional data including review texts and potentially positive items. Next, a private preference transfer module is designed to first learn differentially private local and global prototypes, and then privately transfer the global prototypes using a federated learning strategy. These prototypes are generalized representations of user groups, making it difficult for attackers to infer individual information. Extensive experiments on four CDR tasks conducted on the Amazon and Douban datasets validate the superiority of FUPM over SOTA baselines. Code is available at https://github.com/Lili1013/FUPM.","sentences":["Cross-domain recommendation (CDR) aims to address the data-sparsity problem by transferring knowledge across domains.","Existing CDR methods generally assume that the user-item interaction data is shareable between domains, which leads to privacy leakage.","Recently, some privacy-preserving CDR (PPCDR) models have been proposed to solve this problem.","However, they primarily transfer simple representations learned only from user-item interaction histories, overlooking other useful side information, leading to inaccurate user preferences.","Additionally, they transfer differentially private user-item interaction matrices or embeddings across domains to protect privacy.","However, these methods offer limited privacy protection, as attackers may exploit external information to infer the original data.","To address these challenges, we propose a novel Federated User Preference Modeling (FUPM) framework.","In FUPM, first, a novel comprehensive preference exploration module is proposed to learn users' comprehensive preferences from both interaction data and additional data including review texts and potentially positive items.","Next, a private preference transfer module is designed to first learn differentially private local and global prototypes, and then privately transfer the global prototypes using a federated learning strategy.","These prototypes are generalized representations of user groups, making it difficult for attackers to infer individual information.","Extensive experiments on four CDR tasks conducted on the Amazon and Douban datasets validate the superiority of FUPM over SOTA baselines.","Code is available at https://github.com/Lili1013/FUPM."],"url":"http://arxiv.org/abs/2408.14689v1"}
{"created":"2024-08-26 23:24:31","title":"A Synthetic Benchmark to Explore Limitations of Localized Drift Detections","abstract":"Concept drift is a common phenomenon in data streams where the statistical properties of the target variable change over time. Traditionally, drift is assumed to occur globally, affecting the entire dataset uniformly. However, this assumption does not always hold true in real-world scenarios where only specific subpopulations within the data may experience drift. This paper explores the concept of localized drift and evaluates the performance of several drift detection techniques in identifying such localized changes. We introduce a synthetic dataset based on the Agrawal generator, where drift is induced in a randomly chosen subgroup. Our experiments demonstrate that commonly adopted drift detection methods may fail to detect drift when it is confined to a small subpopulation. We propose and test various drift detection approaches to quantify their effectiveness in this localized drift scenario. We make the source code for the generation of the synthetic benchmark available at https://github.com/fgiobergia/subgroup-agrawal-drift.","sentences":["Concept drift is a common phenomenon in data streams where the statistical properties of the target variable change over time.","Traditionally, drift is assumed to occur globally, affecting the entire dataset uniformly.","However, this assumption does not always hold true in real-world scenarios where only specific subpopulations within the data may experience drift.","This paper explores the concept of localized drift and evaluates the performance of several drift detection techniques in identifying such localized changes.","We introduce a synthetic dataset based on the Agrawal generator, where drift is induced in a randomly chosen subgroup.","Our experiments demonstrate that commonly adopted drift detection methods may fail to detect drift when it is confined to a small subpopulation.","We propose and test various drift detection approaches to quantify their effectiveness in this localized drift scenario.","We make the source code for the generation of the synthetic benchmark available at https://github.com/fgiobergia/subgroup-agrawal-drift."],"url":"http://arxiv.org/abs/2408.14687v1"}
{"created":"2024-08-26 23:13:38","title":"Detecting Interpretable Subgroup Drifts","abstract":"The ability to detect and adapt to changes in data distributions is crucial to maintain the accuracy and reliability of machine learning models. Detection is generally approached by observing the drift of model performance from a global point of view. However, drifts occurring in (fine-grained) data subgroups may go unnoticed when monitoring global drift. We take a different perspective, and introduce methods for observing drift at the finer granularity of subgroups. Relevant data subgroups are identified during training and monitored efficiently throughout the model's life. Performance drifts in any subgroup are detected, quantified and characterized so as to provide an interpretable summary of the model behavior over time. Experimental results confirm that our subgroup-level drift analysis identifies drifts that do not show at the (coarser) global dataset level. The proposed approach provides a valuable tool for monitoring model performance in dynamic real-world applications, offering insights into the evolving nature of data and ultimately contributing to more robust and adaptive models.","sentences":["The ability to detect and adapt to changes in data distributions is crucial to maintain the accuracy and reliability of machine learning models.","Detection is generally approached by observing the drift of model performance from a global point of view.","However, drifts occurring in (fine-grained) data subgroups may go unnoticed when monitoring global drift.","We take a different perspective, and introduce methods for observing drift at the finer granularity of subgroups.","Relevant data subgroups are identified during training and monitored efficiently throughout the model's life.","Performance drifts in any subgroup are detected, quantified and characterized so as to provide an interpretable summary of the model behavior over time.","Experimental results confirm that our subgroup-level drift analysis identifies drifts that do not show at the (coarser) global dataset level.","The proposed approach provides a valuable tool for monitoring model performance in dynamic real-world applications, offering insights into the evolving nature of data and ultimately contributing to more robust and adaptive models."],"url":"http://arxiv.org/abs/2408.14682v1"}
{"created":"2024-08-26 23:10:42","title":"Enhancing Neural Network Interpretability Through Conductance-Based Information Plane Analysis","abstract":"The Information Plane is a conceptual framework used to analyze the flow of information in neural networks, but traditional methods based on activations may not fully capture the dynamics of information processing. This paper introduces a new approach that uses layer conductance, a measure of sensitivity to input features, to enhance the Information Plane analysis. By incorporating gradient-based contributions, we provide a more precise characterization of information dynamics within the network. The proposed conductance-based Information Plane and a new Information Transformation Efficiency (ITE) metric are evaluated on pretrained ResNet50 and VGG16 models using the ImageNet dataset. Our results demonstrate the ability to identify critical hidden layers that contribute significantly to model performance and interpretability, giving insights into information compression, preservation, and utilization across layers. The conductance-based approach offers a granular perspective on feature attribution, enhancing our understanding of the decision-making processes within neural networks. Furthermore, our empirical findings challenge certain theoretical predictions of the Information Bottleneck theory, highlighting the complexities of information dynamics in real-world data scenarios. The proposed method not only advances our understanding of information dynamics in neural networks but also has the potential to significantly impact the broader field of Artificial Intelligence by enabling the development of more interpretable, efficient, and robust models.","sentences":["The Information Plane is a conceptual framework used to analyze the flow of information in neural networks, but traditional methods based on activations may not fully capture the dynamics of information processing.","This paper introduces a new approach that uses layer conductance, a measure of sensitivity to input features, to enhance the Information Plane analysis.","By incorporating gradient-based contributions, we provide a more precise characterization of information dynamics within the network.","The proposed conductance-based Information Plane and a new Information Transformation Efficiency (ITE) metric are evaluated on pretrained ResNet50 and VGG16 models using the ImageNet dataset.","Our results demonstrate the ability to identify critical hidden layers that contribute significantly to model performance and interpretability, giving insights into information compression, preservation, and utilization across layers.","The conductance-based approach offers a granular perspective on feature attribution, enhancing our understanding of the decision-making processes within neural networks.","Furthermore, our empirical findings challenge certain theoretical predictions of the Information Bottleneck theory, highlighting the complexities of information dynamics in real-world data scenarios.","The proposed method not only advances our understanding of information dynamics in neural networks but also has the potential to significantly impact the broader field of Artificial Intelligence by enabling the development of more interpretable, efficient, and robust models."],"url":"http://arxiv.org/abs/2408.14681v1"}
{"created":"2024-08-26 23:10:01","title":"On-Chip Learning with Memristor-Based Neural Networks: Assessing Accuracy and Efficiency Under Device Variations, Conductance Errors, and Input Noise","abstract":"This paper presents a memristor-based compute-in-memory hardware accelerator for on-chip training and inference, focusing on its accuracy and efficiency against device variations, conductance errors, and input noise. Utilizing realistic SPICE models of commercially available silver-based metal self-directed channel (M-SDC) memristors, the study incorporates inherent device non-idealities into the circuit simulations. The hardware, consisting of 30 memristors and 4 neurons, utilizes three different M-SDC structures with tungsten, chromium, and carbon media to perform binary image classification tasks. An on-chip training algorithm precisely tunes memristor conductance to achieve target weights. Results show that incorporating moderate noise (<15%) during training enhances robustness to device variations and noisy input data, achieving up to 97% accuracy despite conductance variations and input noises. The network tolerates a 10% conductance error without significant accuracy loss. Notably, omitting the initial memristor reset pulse during training considerably reduces training time and energy consumption. The hardware designed with chromium-based memristors exhibits superior performance, achieving a training time of 2.4 seconds and an energy consumption of 18.9 mJ. This research provides insights for developing robust and energy-efficient memristor-based neural networks for on-chip learning in edge applications.","sentences":["This paper presents a memristor-based compute-in-memory hardware accelerator for on-chip training and inference, focusing on its accuracy and efficiency against device variations, conductance errors, and input noise.","Utilizing realistic SPICE models of commercially available silver-based metal self-directed channel (M-SDC) memristors, the study incorporates inherent device non-idealities into the circuit simulations.","The hardware, consisting of 30 memristors and 4 neurons, utilizes three different M-SDC structures with tungsten, chromium, and carbon media to perform binary image classification tasks.","An on-chip training algorithm precisely tunes memristor conductance to achieve target weights.","Results show that incorporating moderate noise (<15%) during training enhances robustness to device variations and noisy input data, achieving up to 97% accuracy despite conductance variations and input noises.","The network tolerates a 10% conductance error without significant accuracy loss.","Notably, omitting the initial memristor reset pulse during training considerably reduces training time and energy consumption.","The hardware designed with chromium-based memristors exhibits superior performance, achieving a training time of 2.4 seconds and an energy consumption of 18.9 mJ. This research provides insights for developing robust and energy-efficient memristor-based neural networks for on-chip learning in edge applications."],"url":"http://arxiv.org/abs/2408.14680v1"}
{"created":"2024-08-26 23:01:48","title":"Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems","abstract":"Knowledge Distillation (KD) is a powerful approach for compressing a large model into a smaller, more efficient model, particularly beneficial for latency-sensitive applications like recommender systems. However, current KD research predominantly focuses on Computer Vision (CV) and NLP tasks, overlooking unique data characteristics and challenges inherent to recommender systems. This paper addresses these overlooked challenges, specifically: (1) mitigating data distribution shifts between teacher and student models, (2) efficiently identifying optimal teacher configurations within time and budgetary constraints, and (3) enabling computationally efficient and rapid sharing of teacher labels to support multiple students. We present a robust KD system developed and rigorously evaluated on multiple large-scale personalized video recommendation systems within Google. Our live experiment results demonstrate significant improvements in student model performance while ensuring consistent and reliable generation of high quality teacher labels from a continuous data stream of data.","sentences":["Knowledge Distillation (KD) is a powerful approach for compressing a large model into a smaller, more efficient model, particularly beneficial for latency-sensitive applications like recommender systems.","However, current KD research predominantly focuses on Computer Vision (CV) and NLP tasks, overlooking unique data characteristics and challenges inherent to recommender systems.","This paper addresses these overlooked challenges, specifically: (1) mitigating data distribution shifts between teacher and student models, (2) efficiently identifying optimal teacher configurations within time and budgetary constraints, and (3) enabling computationally efficient and rapid sharing of teacher labels to support multiple students.","We present a robust KD system developed and rigorously evaluated on multiple large-scale personalized video recommendation systems within Google.","Our live experiment results demonstrate significant improvements in student model performance while ensuring consistent and reliable generation of high quality teacher labels from a continuous data stream of data."],"url":"http://arxiv.org/abs/2408.14678v1"}
{"created":"2024-08-26 22:50:59","title":"gWaveNet: Classification of Gravity Waves from Noisy Satellite Data using Custom Kernel Integrated Deep Learning Method","abstract":"Atmospheric gravity waves occur in the Earths atmosphere caused by an interplay between gravity and buoyancy forces. These waves have profound impacts on various aspects of the atmosphere, including the patterns of precipitation, cloud formation, ozone distribution, aerosols, and pollutant dispersion. Therefore, understanding gravity waves is essential to comprehend and monitor changes in a wide range of atmospheric behaviors. Limited studies have been conducted to identify gravity waves from satellite data using machine learning techniques. Particularly, without applying noise removal techniques, it remains an underexplored area of research. This study presents a novel kernel design aimed at identifying gravity waves within satellite images. The proposed kernel is seamlessly integrated into a deep convolutional neural network, denoted as gWaveNet. Our proposed model exhibits impressive proficiency in detecting images containing gravity waves from noisy satellite data without any feature engineering. The empirical results show our model outperforms related approaches by achieving over 98% training accuracy and over 94% test accuracy which is known to be the best result for gravity waves detection up to the time of this work. We open sourced our code at https://rb.gy/qn68ku.","sentences":["Atmospheric gravity waves occur in the Earths atmosphere caused by an interplay between gravity and buoyancy forces.","These waves have profound impacts on various aspects of the atmosphere, including the patterns of precipitation, cloud formation, ozone distribution, aerosols, and pollutant dispersion.","Therefore, understanding gravity waves is essential to comprehend and monitor changes in a wide range of atmospheric behaviors.","Limited studies have been conducted to identify gravity waves from satellite data using machine learning techniques.","Particularly, without applying noise removal techniques, it remains an underexplored area of research.","This study presents a novel kernel design aimed at identifying gravity waves within satellite images.","The proposed kernel is seamlessly integrated into a deep convolutional neural network, denoted as gWaveNet.","Our proposed model exhibits impressive proficiency in detecting images containing gravity waves from noisy satellite data without any feature engineering.","The empirical results show our model outperforms related approaches by achieving over 98% training accuracy and over 94% test accuracy which is known to be the best result for gravity waves detection up to the time of this work.","We open sourced our code at https://rb.gy/qn68ku."],"url":"http://arxiv.org/abs/2408.14674v1"}
{"created":"2024-08-26 22:39:08","title":"Physically Feasible Semantic Segmentation","abstract":"State-of-the-art semantic segmentation models are typically optimized in a data-driven fashion, minimizing solely per-pixel classification objectives on their training data. This purely data-driven paradigm often leads to absurd segmentations, especially when the domain of input images is shifted from the one encountered during training. For instance, state-of-the-art models may assign the label ``road'' to a segment which is located above a segment that is respectively labeled as ``sky'', although our knowledge of the physical world dictates that such a configuration is not feasible for images captured by forward-facing upright cameras. Our method, Physically Feasible Semantic Segmentation (PhyFea), extracts explicit physical constraints that govern spatial class relations from the training sets of semantic segmentation datasets and enforces a differentiable loss function that penalizes violations of these constraints to promote prediction feasibility. PhyFea yields significant performance improvements in mIoU over each state-of-the-art network we use as baseline across ADE20K, Cityscapes and ACDC, notably a $1.5\\%$ improvement on ADE20K and a $2.1\\%$ improvement on ACDC.","sentences":["State-of-the-art semantic segmentation models are typically optimized in a data-driven fashion, minimizing solely per-pixel classification objectives on their training data.","This purely data-driven paradigm often leads to absurd segmentations, especially when the domain of input images is shifted from the one encountered during training.","For instance, state-of-the-art models may assign the label ``road'' to a segment which is located above a segment that is respectively labeled as ``sky'', although our knowledge of the physical world dictates that such a configuration is not feasible for images captured by forward-facing upright cameras.","Our method, Physically Feasible Semantic Segmentation (PhyFea), extracts explicit physical constraints that govern spatial class relations from the training sets of semantic segmentation datasets and enforces a differentiable loss function that penalizes violations of these constraints to promote prediction feasibility.","PhyFea yields significant performance improvements in mIoU over each state-of-the-art network we use as baseline across ADE20K, Cityscapes and ACDC, notably a $1.5\\%$ improvement on ADE20K and a $2.1\\%$ improvement on ACDC."],"url":"http://arxiv.org/abs/2408.14672v1"}
{"created":"2024-08-26 21:55:06","title":"Comparative Analysis: Violence Recognition from Videos using Transfer Learning","abstract":"Action recognition has become a hot topic in computer vision. However, the main applications of computer vision in video processing have focused on detection of relatively simple actions while complex events such as violence detection have been comparatively less investigated. This study focuses on the benchmarking of various deep learning techniques on a complex dataset. Next, a larger dataset is utilized to test the uplift from increasing volume of data. The dataset size increase from 500 to 1,600 videos resulted in a notable average accuracy improvement of 6% across four models.","sentences":["Action recognition has become a hot topic in computer vision.","However, the main applications of computer vision in video processing have focused on detection of relatively simple actions while complex events such as violence detection have been comparatively less investigated.","This study focuses on the benchmarking of various deep learning techniques on a complex dataset.","Next, a larger dataset is utilized to test the uplift from increasing volume of data.","The dataset size increase from 500 to 1,600 videos resulted in a notable average accuracy improvement of 6% across four models."],"url":"http://arxiv.org/abs/2408.14659v1"}
{"created":"2024-08-26 21:33:34","title":"Continuous Optimization for Decoding Errors","abstract":"Error-correcting codes are one of the most fundamental objects in pseudorandomness, with applications in communication, complexity theory, and beyond. Codes are useful because of their ability to support decoding, which is the task of recovering a codeword from its noisy copy. List decoding is a relaxation where the decoder is allowed to output a list of codewords, and has seen tremendous progress over the last 25 years. In this thesis, we prove new algorithmic and combinatorial results about list decoding.   We describe a list decoding framework that reduces the task of efficient decoding to proving distance in certain restricted proof systems. We then instantiate this framework for Tanner codes of Sipser and Spielman [IEEE Trans. Inf. Theory 1996] and Alon-Edmonds-Luby (AEL) distance amplification [FOCS 1995] of unique decodable base codes to get the first polynomial time list decoding algorithms for these codes. We also show extensions to the quantum version of AEL distance amplification to get polynomial-time list decodable quantum LDPC codes.   We next give an alternate viewpoint of the above framework based on abstract regularity lemmas. We show how to efficiently implement the regularity lemma for the case of Ta-Shma's explicit codes near the Gilbert-Varshamov bound [STOC 2017]. This leads to a near-linear time algorithm for unique decoding of Ta-Shma's code.   We also give new combinatorial results that improve known list sizes beyond the Johnson bound. Firstly, we adapt the AEL amplification to construct a new family of explicit codes that can be combinatorially list decoded to the optimal error correction radius. This is the first example of such a code that does not use significant algebraic ingredients. Secondly, we present list size improvements for Folded Reed-Solomon codes, improving the state of the art list size for explicit list decoding capacity achieving codes.","sentences":["Error-correcting codes are one of the most fundamental objects in pseudorandomness, with applications in communication, complexity theory, and beyond.","Codes are useful because of their ability to support decoding, which is the task of recovering a codeword from its noisy copy.","List decoding is a relaxation where the decoder is allowed to output a list of codewords, and has seen tremendous progress over the last 25 years.","In this thesis, we prove new algorithmic and combinatorial results about list decoding.   ","We describe a list decoding framework that reduces the task of efficient decoding to proving distance in certain restricted proof systems.","We then instantiate this framework for Tanner codes of Sipser and Spielman [IEEE Trans.","Inf.","Theory 1996] and Alon-Edmonds-Luby (AEL) distance amplification","[FOCS 1995] of unique decodable base codes to get the first polynomial time list decoding algorithms for these codes.","We also show extensions to the quantum version of AEL distance amplification to get polynomial-time list decodable quantum LDPC codes.   ","We next give an alternate viewpoint of the above framework based on abstract regularity lemmas.","We show how to efficiently implement the regularity lemma for the case of Ta-Shma's explicit codes near the Gilbert-Varshamov bound [STOC 2017].","This leads to a near-linear time algorithm for unique decoding of Ta-Shma's code.   ","We also give new combinatorial results that improve known list sizes beyond the Johnson bound.","Firstly, we adapt the AEL amplification to construct a new family of explicit codes that can be combinatorially list decoded to the optimal error correction radius.","This is the first example of such a code that does not use significant algebraic ingredients.","Secondly, we present list size improvements for Folded Reed-Solomon codes, improving the state of the art list size for explicit list decoding capacity achieving codes."],"url":"http://arxiv.org/abs/2408.14652v1"}
{"created":"2024-08-26 21:20:45","title":"Visions of Destruction: Exploring a Potential of Generative AI in Interactive Art","abstract":"This paper explores the potential of generative AI within interactive art, employing a practice-based research approach. It presents the interactive artwork \"Visions of Destruction\" as a detailed case study, highlighting its innovative use of generative AI to create a dynamic, audience-responsive experience. This artwork applies gaze-based interaction to dynamically alter digital landscapes, symbolizing the impact of human activities on the environment by generating contemporary collages created with AI, trained on data about human damage to nature, and guided by audience interaction. The transformation of pristine natural scenes into human-made and industrialized landscapes through viewer interaction serves as a stark reminder of environmental degradation. The paper thoroughly explores the technical challenges and artistic innovations involved in creating such an interactive art installation, emphasizing the potential of generative AI to revolutionize artistic expression, audience engagement, and especially the opportunities for the interactive art field. It offers insights into the conceptual framework behind the artwork, aiming to evoke a deeper understanding and reflection on the Anthropocene era and human-induced climate change. This study contributes significantly to the field of creative AI and interactive art, blending technology and environmental consciousness in a compelling, thought-provoking manner.","sentences":["This paper explores the potential of generative AI within interactive art, employing a practice-based research approach.","It presents the interactive artwork \"Visions of Destruction\" as a detailed case study, highlighting its innovative use of generative AI to create a dynamic, audience-responsive experience.","This artwork applies gaze-based interaction to dynamically alter digital landscapes, symbolizing the impact of human activities on the environment by generating contemporary collages created with AI, trained on data about human damage to nature, and guided by audience interaction.","The transformation of pristine natural scenes into human-made and industrialized landscapes through viewer interaction serves as a stark reminder of environmental degradation.","The paper thoroughly explores the technical challenges and artistic innovations involved in creating such an interactive art installation, emphasizing the potential of generative AI to revolutionize artistic expression, audience engagement, and especially the opportunities for the interactive art field.","It offers insights into the conceptual framework behind the artwork, aiming to evoke a deeper understanding and reflection on the Anthropocene era and human-induced climate change.","This study contributes significantly to the field of creative AI and interactive art, blending technology and environmental consciousness in a compelling, thought-provoking manner."],"url":"http://arxiv.org/abs/2408.14644v1"}
{"created":"2024-08-26 21:05:32","title":"New weighted additive spanners","abstract":"Ahmed, Bodwin, Sahneh, Kobourov, and Spence (WG 2020) introduced additive spanners for weighted graphs and constructed (i) a $+2W_{\\max}$ spanner with $O(n^{3/2})$ edges and (ii) a $+4W_{\\max}$ spanner with $\\tilde{O}(n^{7/5})$ edges, and (iii) a $+8W_{\\max}$ spanner with $O(n^{4/3})$ edges, for any weighted graph with $n$ vertices. Here $W_{\\max} = \\max_{e\\in E}w(e)$ is the maximum edge weight in the graph. Their results for $+2W_{\\max}$, $+4W_{\\max}$, and $+8W_{\\max}$ match the state-of-the-art bounds for the unweighted counterparts where $W_{\\max} = 1$. They left open the question of constructing a $+6W_{\\max}$ spanner with $O(n^{4/3})$ edges. Elkin, Gitlitz, and Neiman (DISC 2021) made significant progress on this problem by showing that there exists a $+(6+\\epsilon)W_{\\max}$ spanner with $O(n^{4/3}/\\epsilon)$ edges for any fixed constant $\\epsilon > 0$. Indeed, their result is stronger as the additive stretch is local: the stretch for any pair $u,v$ is $+(6+\\epsilon)W_{uv}$ where $W_{uv}$ is the maximum weight edge on the shortest path from $u$ to $v$.   In this work, we resolve the problem posted by Ahmed et al. (WG 2020) up to a poly-logarithmic factor in the number of edges: We construct a $+6W_{\\max}$ spanner with $\\tilde{O}(n^{4/3})$ edges. We extend the construction for $+6$-spanners of Woodruff (ICALP 2010), and our main contribution is an analysis tailoring to the weighted setting. The stretch of our spanner could also be made local, in the sense of Elkin, Gitlitz, and Neiman (DISC 2021). We also study the fast constructions of additive spanners with $+6W_{\\max}$ and $+4W_{\\max}$ stretches. We obtain, among other things, an algorithm for constructing a $+(6+\\epsilon)W_{\\max}$ spanner of $\\tilde{O}(\\frac{n^{4/3}}{\\epsilon})$ edges in $\\tilde{O}(n^2)$ time.","sentences":["Ahmed, Bodwin, Sahneh, Kobourov, and Spence (WG 2020) introduced additive spanners for weighted graphs and constructed (i) a $+2W_{\\max}$ spanner with $O(n^{3/2})$ edges and (ii) a $+4W_{\\max}$ spanner with $\\tilde{O}(n^{7/5})$ edges, and (iii) a $+8W_{\\max}$ spanner with $O(n^{4/3})$ edges, for any weighted graph with $n$ vertices.","Here $W_{\\max} = \\max_{e\\in E}w(e)$ is the maximum edge weight in the graph.","Their results for $+2W_{\\max}$, $+4W_{\\max}$, and $+8W_{\\max}$ match the state-of-the-art bounds for the unweighted counterparts where $W_{\\max} = 1$.","They left open the question of constructing a $+6W_{\\max}$ spanner with $O(n^{4/3})$ edges.","Elkin, Gitlitz, and Neiman (DISC 2021) made significant progress on this problem by showing that there exists a $+(6+\\epsilon)W_{\\max}$ spanner with $O(n^{4/3}/\\epsilon)$ edges for any fixed constant $\\epsilon > 0$.","Indeed, their result is stronger as the additive stretch is local: the stretch for any pair $u,v$ is $+(6+\\epsilon)W_{uv}$ where $W_{uv}$ is the maximum weight edge on the shortest path from $u$ to $v$.   In this work, we resolve the problem posted by Ahmed et al.","(WG 2020) up to a poly-logarithmic factor in the number of edges: We construct a $+6W_{\\max}$ spanner with $\\tilde{O}(n^{4/3})$ edges.","We extend the construction for $+6$-spanners of Woodruff (ICALP 2010), and our main contribution is an analysis tailoring to the weighted setting.","The stretch of our spanner could also be made local, in the sense of Elkin, Gitlitz, and Neiman (DISC 2021).","We also study the fast constructions of additive spanners with $+6W_{\\max}$ and $+4W_{\\max}$ stretches.","We obtain, among other things, an algorithm for constructing a $+(6+\\epsilon)W_{\\max}$ spanner of $\\tilde{O}(\\frac{n^{4/3}}{\\epsilon})$ edges in $\\tilde{O}(n^2)$ time."],"url":"http://arxiv.org/abs/2408.14638v1"}
{"created":"2024-08-26 20:57:36","title":"Channel allocation revisited through 1-extendability of graphs","abstract":"We revisit the classical problem of channel allocation for Wi-Fi access points (AP). Using mechanisms such as the CSMA/CA protocol, Wi-Fi access points which are in conflict within a same channel are still able to communicate to terminals. In graph theoretical terms, it means that it is not mandatory for the channel allocation to correspond to a proper coloring of the conflict graph. However, recent studies suggest that the structure -- rather than the number -- of conflicts plays a crucial role in the performance of each AP. More precisely, the graph induced by each channel must satisfy the so-called $1$-extendability property, which requires each vertex to be contained in an independent set of maximum cardinality. In this paper we introduce the 1-extendable chromatic number, which is the minimum size of a partition of the vertex set of a graph such that each part induces a 1-extendable graph. We study this parameter and the related optimization problem through different perspectives: algorithms and complexity, structure, and extremal properties. We first show how to compute this number using modular decompositions of graphs, and analyze the running time with respect to the modular width of the input graph. We also focus on the special case of cographs, and prove that the 1-extendable chromatic number can be computed in quasi-polynomial time in this class. Concerning extremal results, we show that the 1-extendable chromatic number of a graph with $n$ vertices is at most $2\\sqrt{n}$, whereas the classical chromatic number can be as large as $n$. We are also able to construct graphs whose 1-extendable chromatic number is at least logarithmic in the number of vertices.","sentences":["We revisit the classical problem of channel allocation for Wi-Fi access points (AP).","Using mechanisms such as the CSMA/CA protocol, Wi-Fi access points which are in conflict within a same channel are still able to communicate to terminals.","In graph theoretical terms, it means that it is not mandatory for the channel allocation to correspond to a proper coloring of the conflict graph.","However, recent studies suggest that the structure -- rather than the number -- of conflicts plays a crucial role in the performance of each AP.","More precisely, the graph induced by each channel must satisfy the so-called $1$-extendability property, which requires each vertex to be contained in an independent set of maximum cardinality.","In this paper we introduce the 1-extendable chromatic number, which is the minimum size of a partition of the vertex set of a graph such that each part induces a 1-extendable graph.","We study this parameter and the related optimization problem through different perspectives: algorithms and complexity, structure, and extremal properties.","We first show how to compute this number using modular decompositions of graphs, and analyze the running time with respect to the modular width of the input graph.","We also focus on the special case of cographs, and prove that the 1-extendable chromatic number can be computed in quasi-polynomial time in this class.","Concerning extremal results, we show that the 1-extendable chromatic number of a graph with $n$ vertices is at most $2\\sqrt{n}$, whereas the classical chromatic number can be as large as $n$. We are also able to construct graphs whose 1-extendable chromatic number is at least logarithmic in the number of vertices."],"url":"http://arxiv.org/abs/2408.14633v1"}
{"created":"2024-08-26 20:45:48","title":"Sustainable Data Democratization: A Multifaceted Investment for an Equitable Future","abstract":"The urgent need for data democratization in scientific research was the focal point of a panel discussion at SC23 in Denver, Colorado, from November 12 to 17, 2023. This article summarizes the outcomes of that discussion and subsequent conversations. We advocate for strategic investments in financial, human, and technological resources for sustainable data democratization. Emphasizing that data is central to scientific discovery and AI deployment, we highlight barriers such as limited access, inadequate financial incentives for cross-domain collaboration, and a shortage of workforce development initiatives. Our recommendations aim to guide decision-makers in fostering an inclusive research community, breaking down research silos, and developing a skilled workforce to advance scientific discovery.","sentences":["The urgent need for data democratization in scientific research was the focal point of a panel discussion at SC23 in Denver, Colorado, from November 12 to 17, 2023.","This article summarizes the outcomes of that discussion and subsequent conversations.","We advocate for strategic investments in financial, human, and technological resources for sustainable data democratization.","Emphasizing that data is central to scientific discovery and AI deployment, we highlight barriers such as limited access, inadequate financial incentives for cross-domain collaboration, and a shortage of workforce development initiatives.","Our recommendations aim to guide decision-makers in fostering an inclusive research community, breaking down research silos, and developing a skilled workforce to advance scientific discovery."],"url":"http://arxiv.org/abs/2408.14627v1"}
{"created":"2024-08-26 20:45:07","title":"Hybrid Deep Convolutional Neural Networks Combined with Autoencoders And Augmented Data To Predict The Look-Up Table 2006","abstract":"This study explores the development of a hybrid deep convolutional neural network (DCNN) model enhanced by autoencoders and data augmentation techniques to predict critical heat flux (CHF) with high accuracy. By augmenting the original input features using three different autoencoder configurations, the model's predictive capabilities were significantly improved. The hybrid models were trained and tested on a dataset of 7225 samples, with performance metrics including the coefficient of determination (R2), Nash-Sutcliffe efficiency (NSE), mean absolute error (MAE), and normalized root-mean-squared error (NRMSE) used for evaluation. Among the tested models, the DCNN_3F-A2 configuration demonstrated the highest accuracy, achieving an R2 of 0.9908 during training and 0.9826 during testing, outperforming the base model and other augmented versions. These results suggest that the proposed hybrid approach, combining deep learning with feature augmentation, offers a robust solution for CHF prediction, with the potential to generalize across a wider range of conditions.","sentences":["This study explores the development of a hybrid deep convolutional neural network (DCNN) model enhanced by autoencoders and data augmentation techniques to predict critical heat flux (CHF) with high accuracy.","By augmenting the original input features using three different autoencoder configurations, the model's predictive capabilities were significantly improved.","The hybrid models were trained and tested on a dataset of 7225 samples, with performance metrics including the coefficient of determination (R2), Nash-Sutcliffe efficiency (NSE), mean absolute error (MAE), and normalized root-mean-squared error (NRMSE) used for evaluation.","Among the tested models, the DCNN_3F-A2 configuration demonstrated the highest accuracy, achieving an R2 of 0.9908 during training and 0.9826 during testing, outperforming the base model and other augmented versions.","These results suggest that the proposed hybrid approach, combining deep learning with feature augmentation, offers a robust solution for CHF prediction, with the potential to generalize across a wider range of conditions."],"url":"http://arxiv.org/abs/2408.14626v1"}
{"created":"2024-08-26 20:23:02","title":"Dynamic Locality Sensitive Orderings in Doubling Metrics","abstract":"In their pioneering work, Chan, Har-Peled, and Jones (SICOMP 2020) introduced locality-sensitive ordering (LSO), and constructed an LSO with a constant number of orderings for point sets in the $d$-dimensional Euclidean space. Furthermore, their LSO could be made dynamic effortlessly under point insertions and deletions, taking $O(\\log{n})$ time per update by exploiting Euclidean geometry. Their LSO provides a powerful primitive to solve a host of geometric problems in both dynamic and static settings. Filtser and Le (STOC 2022) constructed the first LSO with a constant number of orderings in the more general setting of doubling metrics. However, their algorithm is inherently static since it relies on several sophisticated constructions in intermediate steps, none of which is known to have a dynamic version. Making their LSO dynamic would recover the full generality of LSO and provide a general tool to dynamize a vast number of static constructions in doubling metrics.   In this work, we give a dynamic algorithm that has $O(\\log{n})$ time per update to construct an LSO in doubling metrics under point insertions and deletions. We introduce a toolkit of several new data structures: a pairwise tree cover, a net tree cover, and a leaf tracker. A key technical is stabilizing the dynamic net tree of Cole and Gottlieb (STOC 2006), a central dynamic data structure in doubling metrics. Specifically, we show that every update to the dynamic net tree can be decomposed into a few simple updates to trees in the net tree cover. As stability is the key to any dynamic algorithm, our technique could be useful for other problems in doubling metrics.   We obtain several algorithmic applications from our dynamic LSO. The most notably is the first dynamic algorithm for maintaining an $k$-fault tolerant spanner in doubling metrics with optimal sparsity in optimal $O(\\log{n})$ time per update.","sentences":["In their pioneering work, Chan, Har-Peled, and Jones (SICOMP 2020) introduced locality-sensitive ordering (LSO), and constructed an LSO with a constant number of orderings for point sets in the $d$-dimensional Euclidean space.","Furthermore, their LSO could be made dynamic effortlessly under point insertions and deletions, taking $O(\\log{n})$ time per update by exploiting Euclidean geometry.","Their LSO provides a powerful primitive to solve a host of geometric problems in both dynamic and static settings.","Filtser and Le (STOC 2022) constructed the first LSO with a constant number of orderings in the more general setting of doubling metrics.","However, their algorithm is inherently static since it relies on several sophisticated constructions in intermediate steps, none of which is known to have a dynamic version.","Making their LSO dynamic would recover the full generality of LSO and provide a general tool to dynamize a vast number of static constructions in doubling metrics.   ","In this work, we give a dynamic algorithm that has $O(\\log{n})$ time per update to construct an LSO in doubling metrics under point insertions and deletions.","We introduce a toolkit of several new data structures: a pairwise tree cover, a net tree cover, and a leaf tracker.","A key technical is stabilizing the dynamic net tree of Cole and Gottlieb (STOC 2006), a central dynamic data structure in doubling metrics.","Specifically, we show that every update to the dynamic net tree can be decomposed into a few simple updates to trees in the net tree cover.","As stability is the key to any dynamic algorithm, our technique could be useful for other problems in doubling metrics.   ","We obtain several algorithmic applications from our dynamic LSO.","The most notably is the first dynamic algorithm for maintaining an $k$-fault tolerant spanner in doubling metrics with optimal sparsity in optimal $O(\\log{n})$ time per update."],"url":"http://arxiv.org/abs/2408.14617v1"}
{"created":"2024-08-26 20:22:13","title":"Automated model discovery of finite strain elastoplasticity from uniaxial experiments","abstract":"Constitutive modeling lies at the core of mechanics, allowing us to map strains onto stresses for a material in a given mechanical setting. Historically, researchers relied on phenomenological modeling where simple mathematical relationships were derived through experimentation and curve fitting. Recently, to automate the constitutive modeling process, data-driven approaches based on neural networks have been explored. While initial naive approaches violated established mechanical principles, recent efforts concentrate on designing neural network architectures that incorporate physics and mechanistic assumptions into machine-learning-based constitutive models. For history-dependent materials, these models have so far predominantly been restricted to small-strain formulations. In this work, we develop a finite strain plasticity formulation based on thermodynamic potentials to model mixed isotropic and kinematic hardening. We then leverage physics-augmented neural networks to automate the discovery of thermodynamically consistent constitutive models of finite strain elastoplasticity from uniaxial experiments. We apply the framework to both synthetic and experimental data, demonstrating its ability to capture complex material behavior under cyclic uniaxial loading. Furthermore, we show that the neural network enhanced model trains easier than traditional phenomenological models as it is less sensitive to varying initial seeds. our model's ability to generalize beyond the training set underscores its robustness and predictive power. By automating the discovery of hardening models, our approach eliminates user bias and ensures that the resulting constitutive model complies with thermodynamic principles, thus offering a more systematic and physics-informed framework.","sentences":["Constitutive modeling lies at the core of mechanics, allowing us to map strains onto stresses for a material in a given mechanical setting.","Historically, researchers relied on phenomenological modeling where simple mathematical relationships were derived through experimentation and curve fitting.","Recently, to automate the constitutive modeling process, data-driven approaches based on neural networks have been explored.","While initial naive approaches violated established mechanical principles, recent efforts concentrate on designing neural network architectures that incorporate physics and mechanistic assumptions into machine-learning-based constitutive models.","For history-dependent materials, these models have so far predominantly been restricted to small-strain formulations.","In this work, we develop a finite strain plasticity formulation based on thermodynamic potentials to model mixed isotropic and kinematic hardening.","We then leverage physics-augmented neural networks to automate the discovery of thermodynamically consistent constitutive models of finite strain elastoplasticity from uniaxial experiments.","We apply the framework to both synthetic and experimental data, demonstrating its ability to capture complex material behavior under cyclic uniaxial loading.","Furthermore, we show that the neural network enhanced model trains easier than traditional phenomenological models as it is less sensitive to varying initial seeds.","our model's ability to generalize beyond the training set underscores its robustness and predictive power.","By automating the discovery of hardening models, our approach eliminates user bias and ensures that the resulting constitutive model complies with thermodynamic principles, thus offering a more systematic and physics-informed framework."],"url":"http://arxiv.org/abs/2408.14615v1"}
{"created":"2024-08-26 20:20:36","title":"Security Concerns in IoT Light Bulbs: Investigating Covert Channels","abstract":"The proliferation of Internet of Things (IoT) devices has raised significant concerns regarding their security vulnerabilities. This paper explores the security risks associated with smart light systems, focusing on covert communication channels. Drawing upon previous re-search highlighting vulnerabilities in communication protocols and en-cryption flaws, the study investigates the potential for exploiting smart light systems for covert data transmission. Specifically, the paper repli-cates and analyzes an attack method introduced by Ronen and Shamir, which utilizes the Philips Hue White lighting system to create a covert channel through visible light communication (VLC). Experimental re-sults demonstrate the feasibility of transmitting data covertly through subtle variations in brightness levels, leveraging the inherent functional-ity of smart light bulbs. Despite limit. ations imposed by device constraints and communication protocols, the study underscores the need for heightened awareness and security measures in IoT environment. Ultimately, the findings emphasize the importance of implementing robust security practices and exercising caution when deploying networked IoT devices in sensitive environment.","sentences":["The proliferation of Internet of Things (IoT) devices has raised significant concerns regarding their security vulnerabilities.","This paper explores the security risks associated with smart light systems, focusing on covert communication channels.","Drawing upon previous re-search highlighting vulnerabilities in communication protocols and en-cryption flaws, the study investigates the potential for exploiting smart light systems for covert data transmission.","Specifically, the paper repli-cates and analyzes an attack method introduced by Ronen and Shamir, which utilizes the Philips Hue White lighting system to create a covert channel through visible light communication (VLC).","Experimental re-sults demonstrate the feasibility of transmitting data covertly through subtle variations in brightness levels, leveraging the inherent functional-ity of smart light bulbs.","Despite limit.","ations imposed by device constraints and communication protocols, the study underscores the need for heightened awareness and security measures in IoT environment.","Ultimately, the findings emphasize the importance of implementing robust security practices and exercising caution when deploying networked IoT devices in sensitive environment."],"url":"http://arxiv.org/abs/2408.14613v1"}
