{"created":"2025-01-08 18:59:01","title":"ConceptMaster: Multi-Concept Video Customization on Diffusion Transformer Models Without Test-Time Tuning","abstract":"Text-to-video generation has made remarkable advancements through diffusion models. However, Multi-Concept Video Customization (MCVC) remains a significant challenge. We identify two key challenges in this task: 1) the identity decoupling problem, where directly adopting existing customization methods inevitably mix attributes when handling multiple concepts simultaneously, and 2) the scarcity of high-quality video-entity pairs, which is crucial for training such a model that represents and decouples various concepts well. To address these challenges, we introduce ConceptMaster, an innovative framework that effectively tackles the critical issues of identity decoupling while maintaining concept fidelity in customized videos. Specifically, we introduce a novel strategy of learning decoupled multi-concept embeddings that are injected into the diffusion models in a standalone manner, which effectively guarantees the quality of customized videos with multiple identities, even for highly similar visual concepts. To further overcome the scarcity of high-quality MCVC data, we carefully establish a data construction pipeline, which enables systematic collection of precise multi-concept video-entity data across diverse concepts. A comprehensive benchmark is designed to validate the effectiveness of our model from three critical dimensions: concept fidelity, identity decoupling ability, and video generation quality across six different concept composition scenarios. Extensive experiments demonstrate that our ConceptMaster significantly outperforms previous approaches for this task, paving the way for generating personalized and semantically accurate videos across multiple concepts.","sentences":["Text-to-video generation has made remarkable advancements through diffusion models.","However, Multi-Concept Video Customization (MCVC) remains a significant challenge.","We identify two key challenges in this task: 1) the identity decoupling problem, where directly adopting existing customization methods inevitably mix attributes when handling multiple concepts simultaneously, and 2) the scarcity of high-quality video-entity pairs, which is crucial for training such a model that represents and decouples various concepts well.","To address these challenges, we introduce ConceptMaster, an innovative framework that effectively tackles the critical issues of identity decoupling while maintaining concept fidelity in customized videos.","Specifically, we introduce a novel strategy of learning decoupled multi-concept embeddings that are injected into the diffusion models in a standalone manner, which effectively guarantees the quality of customized videos with multiple identities, even for highly similar visual concepts.","To further overcome the scarcity of high-quality MCVC data, we carefully establish a data construction pipeline, which enables systematic collection of precise multi-concept video-entity data across diverse concepts.","A comprehensive benchmark is designed to validate the effectiveness of our model from three critical dimensions: concept fidelity, identity decoupling ability, and video generation quality across six different concept composition scenarios.","Extensive experiments demonstrate that our ConceptMaster significantly outperforms previous approaches for this task, paving the way for generating personalized and semantically accurate videos across multiple concepts."],"url":"http://arxiv.org/abs/2501.04698v1"}
{"created":"2025-01-08 18:58:22","title":"Re-ranking the Context for Multimodal Retrieval Augmented Generation","abstract":"Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge to generate a response within a context with improved accuracy and reduced hallucinations. However, multi-modal RAG systems face unique challenges: (i) the retrieval process may select irrelevant entries to user query (e.g., images, documents), and (ii) vision-language models or multi-modal language models like GPT-4o may hallucinate when processing these entries to generate RAG output. In this paper, we aim to address the first challenge, i.e, improving the selection of relevant context from the knowledge-base in retrieval phase of the multi-modal RAG. Specifically, we leverage the relevancy score (RS) measure designed in our previous work for evaluating the RAG performance to select more relevant entries in retrieval process. The retrieval based on embeddings, say CLIP-based embedding, and cosine similarity usually perform poorly particularly for multi-modal data. We show that by using a more advanced relevancy measure, one can enhance the retrieval process by selecting more relevant pieces from the knowledge-base and eliminate the irrelevant pieces from the context by adaptively selecting up-to-$k$ entries instead of fixed number of entries. Our evaluation using COCO dataset demonstrates significant enhancement in selecting relevant context and accuracy of the generated response.","sentences":["Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge to generate a response within a context with improved accuracy and reduced hallucinations.","However, multi-modal RAG systems face unique challenges: (i) the retrieval process may select irrelevant entries to user query (e.g., images, documents), and (ii) vision-language models or multi-modal language models like GPT-4o may hallucinate when processing these entries to generate RAG output.","In this paper, we aim to address the first challenge, i.e, improving the selection of relevant context from the knowledge-base in retrieval phase of the multi-modal RAG.","Specifically, we leverage the relevancy score (RS) measure designed in our previous work for evaluating the RAG performance to select more relevant entries in retrieval process.","The retrieval based on embeddings, say CLIP-based embedding, and cosine similarity usually perform poorly particularly for multi-modal data.","We show that by using a more advanced relevancy measure, one can enhance the retrieval process by selecting more relevant pieces from the knowledge-base and eliminate the irrelevant pieces from the context by adaptively selecting up-to-$k$ entries instead of fixed number of entries.","Our evaluation using COCO dataset demonstrates significant enhancement in selecting relevant context and accuracy of the generated response."],"url":"http://arxiv.org/abs/2501.04695v1"}
{"created":"2025-01-08 18:58:15","title":"EpiCoder: Encompassing Diversity and Complexity in Code Generation","abstract":"Effective instruction tuning is indispensable for optimizing code LLMs, aligning model behavior with user expectations and enhancing model performance in real-world applications. However, most existing methods focus on code snippets, which are limited to specific functionalities and rigid structures, restricting the complexity and diversity of the synthesized data. To address these limitations, we introduce a novel feature tree-based synthesis framework inspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntactic structure of code, our framework models semantic relationships between code elements, enabling the generation of more nuanced and diverse data. The feature tree is constructed from raw data and refined iteratively to increase the quantity and diversity of the extracted features. This process enables the identification of more complex patterns and relationships within the code. By sampling subtrees with controlled depth and breadth, our framework allows precise adjustments to the complexity of the generated code, supporting a wide range of tasks from simple function-level operations to intricate multi-file scenarios. We fine-tuned widely-used base models to create the EpiCoder series, achieving state-of-the-art performance at both the function and file levels across multiple benchmarks. Notably, empirical evidence indicates that our approach shows significant potential in synthesizing highly complex repository-level code data. Further analysis elucidates the merits of this approach by rigorously assessing data complexity and diversity through software engineering principles and LLM-as-a-judge method.","sentences":["Effective instruction tuning is indispensable for optimizing code LLMs, aligning model behavior with user expectations and enhancing model performance in real-world applications.","However, most existing methods focus on code snippets, which are limited to specific functionalities and rigid structures, restricting the complexity and diversity of the synthesized data.","To address these limitations, we introduce a novel feature tree-based synthesis framework inspired by Abstract Syntax Trees (AST).","Unlike AST, which captures syntactic structure of code, our framework models semantic relationships between code elements, enabling the generation of more nuanced and diverse data.","The feature tree is constructed from raw data and refined iteratively to increase the quantity and diversity of the extracted features.","This process enables the identification of more complex patterns and relationships within the code.","By sampling subtrees with controlled depth and breadth, our framework allows precise adjustments to the complexity of the generated code, supporting a wide range of tasks from simple function-level operations to intricate multi-file scenarios.","We fine-tuned widely-used base models to create the EpiCoder series, achieving state-of-the-art performance at both the function and file levels across multiple benchmarks.","Notably, empirical evidence indicates that our approach shows significant potential in synthesizing highly complex repository-level code data.","Further analysis elucidates the merits of this approach by rigorously assessing data complexity and diversity through software engineering principles and LLM-as-a-judge method."],"url":"http://arxiv.org/abs/2501.04694v1"}
{"created":"2025-01-08 18:53:50","title":"Comparative Analysis of Quantum and Classical Support Vector Classifiers for Software Bug Prediction: An Exploratory Study","abstract":"Purpose: Quantum computing promises to transform problem-solving across various domains with rapid and practical solutions. Within Software Evolution and Maintenance, Quantum Machine Learning (QML) remains mostly an underexplored domain, particularly in addressing challenges such as detecting buggy software commits from code repositories. Methods: In this study, we investigate the practical application of Quantum Support Vector Classifiers (QSVC) for detecting buggy software commits across 14 open-source software projects with diverse dataset sizes encompassing 30,924 data instances. We compare the QML algorithm PQSVC (Pegasos QSVC) and QSVC against the classical Support Vector Classifier (SVC). Our technique addresses large datasets in QSVC algorithms by dividing them into smaller subsets. We propose and evaluate an aggregation method to combine predictions from these models to detect the entire test dataset. We also introduce an incremental testing methodology to overcome the difficulties of quantum feature mapping during the testing approach. Results: The study shows the effectiveness of QSVC and PQSVC in detecting buggy software commits. The aggregation technique successfully combines predictions from smaller data subsets, enhancing the overall detection accuracy for the entire test dataset. The incremental testing methodology effectively manages the challenges associated with quantum feature mapping during the testing process. Conclusion: We contribute to the advancement of QML algorithms in defect prediction, unveiling the potential for further research in this domain. The specific scenario of the Short-Term Activity Frame (STAF) highlights the early detection of buggy software commits during the initial developmental phases of software systems, particularly when dataset sizes remain insufficient to train machine learning models.","sentences":["Purpose:","Quantum computing promises to transform problem-solving across various domains with rapid and practical solutions.","Within Software Evolution and Maintenance, Quantum Machine Learning (QML) remains mostly an underexplored domain, particularly in addressing challenges such as detecting buggy software commits from code repositories.","Methods: In this study, we investigate the practical application of Quantum Support Vector Classifiers (QSVC) for detecting buggy software commits across 14 open-source software projects with diverse dataset sizes encompassing 30,924 data instances.","We compare the QML algorithm PQSVC (Pegasos QSVC) and QSVC against the classical Support Vector Classifier (SVC).","Our technique addresses large datasets in QSVC algorithms by dividing them into smaller subsets.","We propose and evaluate an aggregation method to combine predictions from these models to detect the entire test dataset.","We also introduce an incremental testing methodology to overcome the difficulties of quantum feature mapping during the testing approach.","Results:","The study shows the effectiveness of QSVC and PQSVC in detecting buggy software commits.","The aggregation technique successfully combines predictions from smaller data subsets, enhancing the overall detection accuracy for the entire test dataset.","The incremental testing methodology effectively manages the challenges associated with quantum feature mapping during the testing process.","Conclusion: We contribute to the advancement of QML algorithms in defect prediction, unveiling the potential for further research in this domain.","The specific scenario of the Short-Term Activity Frame (STAF) highlights the early detection of buggy software commits during the initial developmental phases of software systems, particularly when dataset sizes remain insufficient to train machine learning models."],"url":"http://arxiv.org/abs/2501.04690v1"}
{"created":"2025-01-08 18:49:41","title":"URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics","abstract":"Chain-of-thought (CoT) reasoning has been widely applied in the mathematical reasoning of Large Language Models (LLMs). Recently, the introduction of derivative process supervision on CoT trajectories has sparked discussions on enhancing scaling capabilities during test time, thereby boosting the potential of these models. However, in multimodal mathematical reasoning, the scarcity of high-quality CoT training data has hindered existing models from achieving high-precision CoT reasoning and has limited the realization of reasoning potential during test time. In this work, we propose a three-module synthesis strategy that integrates CoT distillation, trajectory-format rewriting, and format unification. It results in a high-quality CoT reasoning instruction fine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively validate the state-of-the-art (SOTA) performance of the trained URSA-7B model on multiple multimodal mathematical benchmarks. For test-time scaling, we introduce a data synthesis strategy that automatically generates process annotation datasets, known as DualMath-1.1M, focusing on both interpretation and logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT reasoning capabilities to robust supervision abilities. The trained URSA-RM-7B acts as a verifier, effectively enhancing the performance of URSA-7B at test time. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD) verifying capabilities, showcasing its generalization. Model weights, training data and code will be open-sourced.","sentences":["Chain-of-thought (CoT) reasoning has been widely applied in the mathematical reasoning of Large Language Models (LLMs).","Recently, the introduction of derivative process supervision on CoT trajectories has sparked discussions on enhancing scaling capabilities during test time, thereby boosting the potential of these models.","However, in multimodal mathematical reasoning, the scarcity of high-quality CoT training data has hindered existing models from achieving high-precision CoT reasoning and has limited the realization of reasoning potential during test time.","In this work, we propose a three-module synthesis strategy that integrates CoT distillation, trajectory-format rewriting, and format unification.","It results in a high-quality CoT reasoning instruction fine-tuning dataset in multimodal mathematics, MMathCoT-1M.","We comprehensively validate the state-of-the-art (SOTA) performance of the trained URSA-7B model on multiple multimodal mathematical benchmarks.","For test-time scaling, we introduce a data synthesis strategy that automatically generates process annotation datasets, known as DualMath-1.1M, focusing on both interpretation and logic.","By further training URSA-7B on DualMath-1.1M, we transition from CoT reasoning capabilities to robust supervision abilities.","The trained URSA-RM-7B acts as a verifier, effectively enhancing the performance of URSA-7B at test time.","URSA-RM-7B also demonstrates excellent out-of-distribution (OOD) verifying capabilities, showcasing its generalization.","Model weights, training data and code will be open-sourced."],"url":"http://arxiv.org/abs/2501.04686v1"}
{"created":"2025-01-08 18:42:48","title":"Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought","abstract":"We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms. Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training. Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms. This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.","sentences":["We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms.","Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training.","Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms.","This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence."],"url":"http://arxiv.org/abs/2501.04682v1"}
{"created":"2025-01-08 18:33:17","title":"Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations","abstract":"Chart interpretation is crucial for visual data analysis, but accurately extracting information from charts poses significant challenges for automated models. This study investigates the fine-tuning of DEPLOT, a modality conversion module that translates the image of a plot or chart to a linearized table, on a custom dataset of 50,000 bar charts. The dataset comprises simple, stacked, and grouped bar charts, targeting the unique structural features of these visualizations. The finetuned DEPLOT model is evaluated against its base version using a test set of 1,000 images and two metrics: Relative Mapping Similarity (RMS), which measures categorical mapping accuracy, and Relative Number Set Similarity (RNSS), which evaluates numerical interpretation accuracy. To further explore the reasoning capabilities of large language models (LLMs), we curate an additional set of 100 bar chart images paired with question answer sets. Our findings demonstrate that providing a structured intermediate table alongside the image significantly enhances LLM reasoning performance compared to direct image queries.","sentences":["Chart interpretation is crucial for visual data analysis, but accurately extracting information from charts poses significant challenges for automated models.","This study investigates the fine-tuning of DEPLOT, a modality conversion module that translates the image of a plot or chart to a linearized table, on a custom dataset of 50,000 bar charts.","The dataset comprises simple, stacked, and grouped bar charts, targeting the unique structural features of these visualizations.","The finetuned DEPLOT model is evaluated against its base version using a test set of 1,000 images and two metrics: Relative Mapping Similarity (RMS), which measures categorical mapping accuracy, and Relative Number Set Similarity (RNSS), which evaluates numerical interpretation accuracy.","To further explore the reasoning capabilities of large language models (LLMs), we curate an additional set of 100 bar chart images paired with question answer sets.","Our findings demonstrate that providing a structured intermediate table alongside the image significantly enhances LLM reasoning performance compared to direct image queries."],"url":"http://arxiv.org/abs/2501.04675v1"}
{"created":"2025-01-08 18:31:16","title":"DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests","abstract":"Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning. However, due to the modality gap between textual and visual data, they often face significant challenges, such as over-reliance on text priors, hallucinations, and limited capacity for complex visual reasoning. Existing benchmarks to evaluate visual reasoning in LVLMs often rely on schematic or synthetic images and on imprecise machine-generated explanations. To bridge the modality gap, we present DrivingVQA, a new benchmark derived from driving theory tests to evaluate visual chain-of-thought reasoning in complex real-world scenarios. It offers 3,931 expert-crafted multiple-choice problems and interleaved explanations grounded with entities relevant to the reasoning process. We leverage this dataset to perform an extensive study of LVLMs' ability to reason about complex visual scenarios. Our experiments reveal that open-source and proprietary LVLMs struggle with visual chain-of-thought reasoning under zero-shot settings. We investigate training strategies that leverage relevant entities to improve visual reasoning. Notably, we observe a performance boost of up to 7\\% when reasoning over image tokens of cropped regions tied to these entities.","sentences":["Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning.","However, due to the modality gap between textual and visual data, they often face significant challenges, such as over-reliance on text priors, hallucinations, and limited capacity for complex visual reasoning.","Existing benchmarks to evaluate visual reasoning in LVLMs often rely on schematic or synthetic images and on imprecise machine-generated explanations.","To bridge the modality gap, we present DrivingVQA, a new benchmark derived from driving theory tests to evaluate visual chain-of-thought reasoning in complex real-world scenarios.","It offers 3,931 expert-crafted multiple-choice problems and interleaved explanations grounded with entities relevant to the reasoning process.","We leverage this dataset to perform an extensive study of LVLMs' ability to reason about complex visual scenarios.","Our experiments reveal that open-source and proprietary LVLMs struggle with visual chain-of-thought reasoning under zero-shot settings.","We investigate training strategies that leverage relevant entities to improve visual reasoning.","Notably, we observe a performance boost of up to 7\\% when reasoning over image tokens of cropped regions tied to these entities."],"url":"http://arxiv.org/abs/2501.04671v1"}
{"created":"2025-01-08 18:30:53","title":"Are They the Same? Exploring Visual Correspondence Shortcomings of Multimodal LLMs","abstract":"Recent advancements in multimodal models have shown a strong ability in visual perception, reasoning abilities, and vision-language understanding. However, studies on visual matching ability are missing, where finding the visual correspondence of objects is essential in vision research. Our research reveals that the matching capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings, even with current strong MLLMs models, GPT-4o. In particular, we construct a Multimodal Visual Matching (MMVM) benchmark to fairly benchmark over 30 different MLLMs. The MMVM benchmark is built from 15 open-source datasets and Internet videos with manual annotation. We categorize the data samples of MMVM benchmark into eight aspects based on the required cues and capabilities to more comprehensively evaluate and analyze current MLLMs. In addition, we have designed an automatic annotation pipeline to generate the MMVM SFT dataset, including 220K visual matching data with reasoning annotation. Finally, we present CoLVA, a novel contrastive MLLM with two novel technical designs: fine-grained vision expert with object-level contrastive learning and instruction augmentation strategy. CoLVA achieves 51.06\\% overall accuracy (OA) on the MMVM benchmark, surpassing GPT-4o and baseline by 8.41\\% and 23.58\\% OA, respectively. The results show the effectiveness of our MMVM SFT dataset and our novel technical designs. Code, benchmark, dataset, and models are available at https://github.com/zhouyiks/CoLVA.","sentences":["Recent advancements in multimodal models have shown a strong ability in visual perception, reasoning abilities, and vision-language understanding.","However, studies on visual matching ability are missing, where finding the visual correspondence of objects is essential in vision research.","Our research reveals that the matching capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings, even with current strong MLLMs models, GPT-4o.","In particular, we construct a Multimodal Visual Matching (MMVM) benchmark to fairly benchmark over 30 different MLLMs.","The MMVM benchmark is built from 15 open-source datasets and Internet videos with manual annotation.","We categorize the data samples of MMVM benchmark into eight aspects based on the required cues and capabilities to more comprehensively evaluate and analyze current MLLMs.","In addition, we have designed an automatic annotation pipeline to generate the MMVM SFT dataset, including 220K visual matching data with reasoning annotation.","Finally, we present CoLVA, a novel contrastive MLLM with two novel technical designs: fine-grained vision expert with object-level contrastive learning and instruction augmentation strategy.","CoLVA achieves 51.06\\% overall accuracy (OA) on the MMVM benchmark, surpassing GPT-4o and baseline by 8.41\\% and 23.58\\% OA, respectively.","The results show the effectiveness of our MMVM SFT dataset and our novel technical designs.","Code, benchmark, dataset, and models are available at https://github.com/zhouyiks/CoLVA."],"url":"http://arxiv.org/abs/2501.04670v1"}
{"created":"2025-01-08 18:25:50","title":"Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling","abstract":"Given an isolated garment image in a canonical product view and a separate image of a person, the virtual try-on task aims to generate a new image of the person wearing the target garment. Prior virtual try-on works face two major challenges in achieving this goal: a) the paired (human, garment) training data has limited availability; b) generating textures on the human that perfectly match that of the prompted garment is difficult, often resulting in distorted text and faded textures. Our work explores ways to tackle these issues through both synthetic data as well as model refinement. We introduce a garment extraction model that generates (human, synthetic garment) pairs from a single image of a clothed individual. The synthetic pairs can then be used to augment the training of virtual try-on. We also propose an Error-Aware Refinement-based Schr\\\"odinger Bridge (EARSB) that surgically targets localized generation errors for correcting the output of a base virtual try-on model. To identify likely errors, we propose a weakly-supervised error classifier that localizes regions for refinement, subsequently augmenting the Schr\\\"odinger Bridge's noise schedule with its confidence heatmap. Experiments on VITON-HD and DressCode-Upper demonstrate that our synthetic data augmentation enhances the performance of prior work, while EARSB improves the overall image quality. In user studies, our model is preferred by the users in an average of 59% of cases.","sentences":["Given an isolated garment image in a canonical product view and a separate image of a person, the virtual try-on task aims to generate a new image of the person wearing the target garment.","Prior virtual try-on works face two major challenges in achieving this goal: a) the paired (human, garment) training data has limited availability; b) generating textures on the human that perfectly match that of the prompted garment is difficult, often resulting in distorted text and faded textures.","Our work explores ways to tackle these issues through both synthetic data as well as model refinement.","We introduce a garment extraction model that generates (human, synthetic garment) pairs from a single image of a clothed individual.","The synthetic pairs can then be used to augment the training of virtual try-on.","We also propose an Error-Aware Refinement-based Schr\\\"odinger Bridge (EARSB) that surgically targets localized generation errors for correcting the output of a base virtual try-on model.","To identify likely errors, we propose a weakly-supervised error classifier that localizes regions for refinement, subsequently augmenting the Schr\\\"odinger Bridge's noise schedule with its confidence heatmap.","Experiments on VITON-HD and DressCode-Upper demonstrate that our synthetic data augmentation enhances the performance of prior work, while EARSB improves the overall image quality.","In user studies, our model is preferred by the users in an average of 59% of cases."],"url":"http://arxiv.org/abs/2501.04666v1"}
{"created":"2025-01-08 18:15:47","title":"On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena","abstract":"Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages. In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by analyzing several contributing factors, including the representation of entities in pre-training data and the impact of variations in linguistic phenomena across languages. We introduce CAMeL-2, a parallel Arabic-English benchmark of 58,086 entities associated with Arab and Western cultures and 367 masked natural contexts for entities. Our evaluations using CAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in English compared to Arabic. We find that LMs struggle in Arabic with entities that appear at high frequencies in pre-training, where entities can hold multiple word senses. This also extends to entities that exhibit high lexical overlap with languages that are not Arabic but use the Arabic script. Further, we show how frequency-based tokenization leads to this issue in LMs, which gets worse with larger Arabic vocabularies. We will make CAMeL-2 available at: https://github.com/tareknaous/camel2","sentences":["Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages.","In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by analyzing several contributing factors, including the representation of entities in pre-training data and the impact of variations in linguistic phenomena across languages.","We introduce CAMeL-2, a parallel Arabic-English benchmark of 58,086 entities associated with Arab and Western cultures and 367 masked natural contexts for entities.","Our evaluations using CAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in English compared to Arabic.","We find that LMs struggle in Arabic with entities that appear at high frequencies in pre-training, where entities can hold multiple word senses.","This also extends to entities that exhibit high lexical overlap with languages that are not Arabic but use the Arabic script.","Further, we show how frequency-based tokenization leads to this issue in LMs, which gets worse with larger Arabic vocabularies.","We will make CAMeL-2 available at: https://github.com/tareknaous/camel2"],"url":"http://arxiv.org/abs/2501.04662v1"}
{"created":"2025-01-08 18:15:10","title":"Assessing Language Comprehension in Large Language Models Using Construction Grammar","abstract":"Large Language Models, despite their significant capabilities, are known to fail in surprising and unpredictable ways. Evaluating their true `understanding' of language is particularly challenging due to the extensive web-scale data they are trained on. Therefore, we construct an evaluation to systematically assess natural language understanding (NLU) in LLMs by leveraging Construction Grammar (CxG), which provides insights into the meaning captured by linguistic elements known as constructions (Cxns). CxG is well-suited for this purpose because provides a theoretical basis to construct targeted evaluation sets. These datasets are carefully constructed to include examples which are unlikely to appear in pre-training data, yet intuitive and easy for humans to understand, enabling a more targeted and reliable assessment. Our experiments focus on downstream natural language inference and reasoning tasks by comparing LLMs' understanding of the underlying meanings communicated through 8 unique Cxns with that of humans. The results show that while LLMs demonstrate some knowledge of constructional information, even the latest models including GPT-o1 struggle with abstract meanings conveyed by these Cxns, as demonstrated in cases where test sentences are dissimilar to their pre-training data. We argue that such cases provide a more accurate test of true language understanding, highlighting key limitations in LLMs' semantic capabilities. We make our novel dataset and associated experimental data including prompts and model responses publicly available.","sentences":["Large Language Models, despite their significant capabilities, are known to fail in surprising and unpredictable ways.","Evaluating their true `understanding' of language is particularly challenging due to the extensive web-scale data they are trained on.","Therefore, we construct an evaluation to systematically assess natural language understanding (NLU) in LLMs by leveraging Construction Grammar (CxG), which provides insights into the meaning captured by linguistic elements known as constructions (Cxns).","CxG is well-suited for this purpose because provides a theoretical basis to construct targeted evaluation sets.","These datasets are carefully constructed to include examples which are unlikely to appear in pre-training data, yet intuitive and easy for humans to understand, enabling a more targeted and reliable assessment.","Our experiments focus on downstream natural language inference and reasoning tasks by comparing LLMs' understanding of the underlying meanings communicated through 8 unique Cxns with that of humans.","The results show that while LLMs demonstrate some knowledge of constructional information, even the latest models including GPT-o1 struggle with abstract meanings conveyed by these Cxns, as demonstrated in cases where test sentences are dissimilar to their pre-training data.","We argue that such cases provide a more accurate test of true language understanding, highlighting key limitations in LLMs' semantic capabilities.","We make our novel dataset and associated experimental data including prompts and model responses publicly available."],"url":"http://arxiv.org/abs/2501.04661v1"}
{"created":"2025-01-08 18:07:12","title":"Recorder: Comprehensive Parallel I/O Tracing and Analysis","abstract":"This paper presents Recorder, a parallel I/O tracing tool designed to capture comprehensive I/O information on HPC applications. Recorder traces I/O calls across various I/O layers, storing all function parameters for each captured call. The volume of stored information scales linearly the application's execution scale. To address this, we present a sophisticated pattern-recognition-based compression algorithm. This algorithm identifies and compresses recurring I/O patterns both within individual processes and across multiple processes, significantly reducing space and time overheads. We evaluate the proposed compression algorithm using I/O benchmarks and real-world applications, demonstrating that Recorder can store more information while requiring approximately 12x less storage space compared to its predecessor. Notably, for applications with typical parallel I/O patterns, Recorder achieves a constant trace size regardless of execution scale. Additionally, a comparison with the profiling tool Darshan shows that Recorder captures detailed I/O information without incurring substantial overhead. The richer data collected by Recorder enables new insights and facilitates more in-depth I/O studies, offering valuable contributions to the I/O research community.","sentences":["This paper presents Recorder, a parallel I/O tracing tool designed to capture comprehensive I/O information on HPC applications.","Recorder traces I/O calls across various I/O layers, storing all function parameters for each captured call.","The volume of stored information scales linearly the application's execution scale.","To address this, we present a sophisticated pattern-recognition-based compression algorithm.","This algorithm identifies and compresses recurring I/O patterns both within individual processes and across multiple processes, significantly reducing space and time overheads.","We evaluate the proposed compression algorithm using I/O benchmarks and real-world applications, demonstrating that Recorder can store more information while requiring approximately 12x less storage space compared to its predecessor.","Notably, for applications with typical parallel I/O patterns, Recorder achieves a constant trace size regardless of execution scale.","Additionally, a comparison with the profiling tool Darshan shows that Recorder captures detailed I/O information without incurring substantial overhead.","The richer data collected by Recorder enables new insights and facilitates more in-depth I/O studies, offering valuable contributions to the I/O research community."],"url":"http://arxiv.org/abs/2501.04654v1"}
{"created":"2025-01-08 18:05:30","title":"Multi-task retriever fine-tuning for domain-specific and efficient RAG","abstract":"Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying Large Language Models (LLMs), as it can address typical limitations such as generating hallucinated or outdated information. However, when building real-world RAG applications, practical issues arise. First, the retrieved information is generally domain-specific. Since it is computationally expensive to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve the quality of the data included in the LLM input. Second, as more applications are deployed in the same real-world system, one cannot afford to deploy separate retrievers. Moreover, these RAG applications normally retrieve different kinds of data. Our solution is to instruction fine-tune a small retriever encoder on a variety of domain-specific tasks to allow us to deploy one encoder that can serve many use cases, thereby achieving low-cost, scalability, and speed. We show how this encoder generalizes to out-of-domain settings as well as to an unseen retrieval task on real-world enterprise use cases.","sentences":["Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying Large Language Models (LLMs), as it can address typical limitations such as generating hallucinated or outdated information.","However, when building real-world RAG applications, practical issues arise.","First, the retrieved information is generally domain-specific.","Since it is computationally expensive to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve the quality of the data included in the LLM input.","Second, as more applications are deployed in the same real-world system, one cannot afford to deploy separate retrievers.","Moreover, these RAG applications normally retrieve different kinds of data.","Our solution is to instruction fine-tune a small retriever encoder on a variety of domain-specific tasks to allow us to deploy one encoder that can serve many use cases, thereby achieving low-cost, scalability, and speed.","We show how this encoder generalizes to out-of-domain settings as well as to an unseen retrieval task on real-world enterprise use cases."],"url":"http://arxiv.org/abs/2501.04652v1"}
{"created":"2025-01-08 18:01:49","title":"FlairGPT: Repurposing LLMs for Interior Designs","abstract":"Interior design involves the careful selection and arrangement of objects to create an aesthetically pleasing, functional, and harmonized space that aligns with the client's design brief. This task is particularly challenging, as a successful design must not only incorporate all the necessary objects in a cohesive style, but also ensure they are arranged in a way that maximizes accessibility, while adhering to a variety of affordability and usage considerations. Data-driven solutions have been proposed, but these are typically room- or domain-specific and lack explainability in their design design considerations used in producing the final layout. In this paper, we investigate if large language models (LLMs) can be directly utilized for interior design. While we find that LLMs are not yet capable of generating complete layouts, they can be effectively leveraged in a structured manner, inspired by the workflow of interior designers. By systematically probing LLMs, we can reliably generate a list of objects along with relevant constraints that guide their placement. We translate this information into a design layout graph, which is then solved using an off-the-shelf constrained optimization setup to generate the final layouts. We benchmark our algorithm in various design configurations against existing LLM-based methods and human designs, and evaluate the results using a variety of quantitative and qualitative metrics along with user studies. In summary, we demonstrate that LLMs, when used in a structured manner, can effectively generate diverse high-quality layouts, making them a viable solution for creating large-scale virtual scenes. Project webpage at https://flairgpt.github.io/","sentences":["Interior design involves the careful selection and arrangement of objects to create an aesthetically pleasing, functional, and harmonized space that aligns with the client's design brief.","This task is particularly challenging, as a successful design must not only incorporate all the necessary objects in a cohesive style, but also ensure they are arranged in a way that maximizes accessibility, while adhering to a variety of affordability and usage considerations.","Data-driven solutions have been proposed, but these are typically room- or domain-specific and lack explainability in their design design considerations used in producing the final layout.","In this paper, we investigate if large language models (LLMs) can be directly utilized for interior design.","While we find that LLMs are not yet capable of generating complete layouts, they can be effectively leveraged in a structured manner, inspired by the workflow of interior designers.","By systematically probing LLMs, we can reliably generate a list of objects along with relevant constraints that guide their placement.","We translate this information into a design layout graph, which is then solved using an off-the-shelf constrained optimization setup to generate the final layouts.","We benchmark our algorithm in various design configurations against existing LLM-based methods and human designs, and evaluate the results using a variety of quantitative and qualitative metrics along with user studies.","In summary, we demonstrate that LLMs, when used in a structured manner, can effectively generate diverse high-quality layouts, making them a viable solution for creating large-scale virtual scenes.","Project webpage at https://flairgpt.github.io/"],"url":"http://arxiv.org/abs/2501.04648v1"}
{"created":"2025-01-08 17:29:46","title":"Knowledge Retrieval Based on Generative AI","abstract":"This study develops a question-answering system based on Retrieval-Augmented Generation (RAG) using Chinese Wikipedia and Lawbank as retrieval sources. Using TTQA and TMMLU+ as evaluation datasets, the system employs BGE-M3 for dense vector retrieval to obtain highly relevant search results and BGE-reranker to reorder these results based on query relevance. The most pertinent retrieval outcomes serve as reference knowledge for a Large Language Model (LLM), enhancing its ability to answer questions and establishing a knowledge retrieval system grounded in generative AI.   The system's effectiveness is assessed through a two-stage evaluation: automatic and assisted performance evaluations. The automatic evaluation calculates accuracy by comparing the model's auto-generated labels with ground truth answers, measuring performance under standardized conditions without human intervention. The assisted performance evaluation involves 20 finance-related multiple-choice questions answered by 20 participants without financial backgrounds. Initially, participants answer independently. Later, they receive system-generated reference information to assist in answering, examining whether the system improves accuracy when assistance is provided.   The main contributions of this research are: (1) Enhanced LLM Capability: By integrating BGE-M3 and BGE-reranker, the system retrieves and reorders highly relevant results, reduces hallucinations, and dynamically accesses authorized or public knowledge sources. (2) Improved Data Privacy: A customized RAG architecture enables local operation of the LLM, eliminating the need to send private data to external servers. This approach enhances data security, reduces reliance on commercial services, lowers operational costs, and mitigates privacy risks.","sentences":["This study develops a question-answering system based on Retrieval-Augmented Generation (RAG) using Chinese Wikipedia and Lawbank as retrieval sources.","Using TTQA and TMMLU+ as evaluation datasets, the system employs BGE-M3 for dense vector retrieval to obtain highly relevant search results and BGE-reranker to reorder these results based on query relevance.","The most pertinent retrieval outcomes serve as reference knowledge for a Large Language Model (LLM), enhancing its ability to answer questions and establishing a knowledge retrieval system grounded in generative AI.   ","The system's effectiveness is assessed through a two-stage evaluation: automatic and assisted performance evaluations.","The automatic evaluation calculates accuracy by comparing the model's auto-generated labels with ground truth answers, measuring performance under standardized conditions without human intervention.","The assisted performance evaluation involves 20 finance-related multiple-choice questions answered by 20 participants without financial backgrounds.","Initially, participants answer independently.","Later, they receive system-generated reference information to assist in answering, examining whether the system improves accuracy when assistance is provided.   ","The main contributions of this research are: (1) Enhanced LLM Capability:","By integrating BGE-M3 and BGE-reranker, the system retrieves and reorders highly relevant results, reduces hallucinations, and dynamically accesses authorized or public knowledge sources.","(2) Improved Data Privacy: A customized RAG architecture enables local operation of the LLM, eliminating the need to send private data to external servers.","This approach enhances data security, reduces reliance on commercial services, lowers operational costs, and mitigates privacy risks."],"url":"http://arxiv.org/abs/2501.04635v1"}
{"created":"2025-01-08 17:22:03","title":"Evaluating Interval-based Tokenization for Pitch Representation in Symbolic Music Analysis","abstract":"Symbolic music analysis tasks are often performed by models originally developed for Natural Language Processing, such as Transformers. Such models require the input data to be represented as sequences, which is achieved through a process of tokenization. Tokenization strategies for symbolic music often rely on absolute MIDI values to represent pitch information. However, music research largely promotes the benefit of higher-level representations such as melodic contour and harmonic relations for which pitch intervals turn out to be more expressive than absolute pitches. In this work, we introduce a general framework for building interval-based tokenizations. By evaluating these tokenizations on three music analysis tasks, we show that such interval-based tokenizations improve model performances and facilitate their explainability.","sentences":["Symbolic music analysis tasks are often performed by models originally developed for Natural Language Processing, such as Transformers.","Such models require the input data to be represented as sequences, which is achieved through a process of tokenization.","Tokenization strategies for symbolic music often rely on absolute MIDI values to represent pitch information.","However, music research largely promotes the benefit of higher-level representations such as melodic contour and harmonic relations for which pitch intervals turn out to be more expressive than absolute pitches.","In this work, we introduce a general framework for building interval-based tokenizations.","By evaluating these tokenizations on three music analysis tasks, we show that such interval-based tokenizations improve model performances and facilitate their explainability."],"url":"http://arxiv.org/abs/2501.04630v1"}
{"created":"2025-01-08 17:10:18","title":"Framework for Integrating Machine Learning Methods for Path-Aware Source Routing","abstract":"Since the advent of software-defined networking (SDN), Traffic Engineering (TE) has been highlighted as one of the key applications that can be achieved through software-controlled protocols (e.g. PCEP and MPLS). Being one of the most complex challenges in networking, TE problems involve difficult decisions such as allocating flows, either via splitting them among multiple paths or by using a reservation system, to minimize congestion. However, creating an optimized solution is cumbersome and difficult as traffic patterns vary and change with network scale, capacity, and demand. AI methods can help alleviate this by finding optimized TE solutions for the best network performance. SDN-based TE tools such as Teal, Hecate and more, use classification techniques or deep reinforcement learning to find optimal network TE solutions that are demonstrated in simulation. Routing control conducted via source routing tools, e.g., PolKA, can help dynamically divert network flows. In this paper, we propose a novel framework that leverages Hecate to practically demonstrate TE on a real network, collaborating with PolKA, a source routing tool. With real-time traffic statistics, Hecate uses this data to compute optimal paths that are then communicated to PolKA to allocate flows. Several contributions are made to show a practical implementation of how this framework is tested using an emulated ecosystem mimicking a real P4 testbed scenario. This work proves valuable for truly engineered self-driving networks helping translate theory to practice.","sentences":["Since the advent of software-defined networking (SDN), Traffic Engineering (TE) has been highlighted as one of the key applications that can be achieved through software-controlled protocols (e.g. PCEP and MPLS).","Being one of the most complex challenges in networking, TE problems involve difficult decisions such as allocating flows, either via splitting them among multiple paths or by using a reservation system, to minimize congestion.","However, creating an optimized solution is cumbersome and difficult as traffic patterns vary and change with network scale, capacity, and demand.","AI methods can help alleviate this by finding optimized TE solutions for the best network performance.","SDN-based TE tools such as Teal, Hecate and more, use classification techniques or deep reinforcement learning to find optimal network TE solutions that are demonstrated in simulation.","Routing control conducted via source routing tools, e.g., PolKA, can help dynamically divert network flows.","In this paper, we propose a novel framework that leverages Hecate to practically demonstrate TE on a real network, collaborating with PolKA, a source routing tool.","With real-time traffic statistics, Hecate uses this data to compute optimal paths that are then communicated to PolKA to allocate flows.","Several contributions are made to show a practical implementation of how this framework is tested using an emulated ecosystem mimicking a real P4 testbed scenario.","This work proves valuable for truly engineered self-driving networks helping translate theory to practice."],"url":"http://arxiv.org/abs/2501.04624v1"}
{"created":"2025-01-08 16:53:56","title":"MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation","abstract":"Artificial Intelligence is revolutionizing medical practice, enhancing diagnostic accuracy and healthcare delivery. However, its adaptation in medical settings still faces significant challenges, related to data availability and privacy constraints. Synthetic data has emerged as a promising solution to mitigate these issues, addressing data scarcity while preserving privacy. Recently, Latent Diffusion Models have emerged as a powerful tool for generating high-quality synthetic data. Meanwhile, the integration of different modalities has gained interest, emphasizing the need of models capable of handle multimodal medical data. Existing approaches struggle to integrate complementary information and lack the ability to generate modalities simultaneously. To address this challenge, we present MedCoDi-M, a 6.77-billion-parameter model, designed for multimodal medical data generation, that, following Foundation Model paradigm, exploits contrastive learning and large quantity of data to build a shared latent space which capture the relationships between different data modalities. Further, we introduce the Multi-Prompt training technique, which significantly boosts MedCoDi-M's generation under different settings. We extensively validate MedCoDi-M: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for Chest X-ray and radiological report generation. Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios. Finally, we assess the utility of MedCoDi-M in addressing key challenges in the medical field, such as anonymization, data scarcity and imbalance learning. The results are promising, demonstrating the applicability of MedCoDi-M in medical contexts. Project page is at https://cosbidev.github.io/MedCoDi-M/.","sentences":["Artificial Intelligence is revolutionizing medical practice, enhancing diagnostic accuracy and healthcare delivery.","However, its adaptation in medical settings still faces significant challenges, related to data availability and privacy constraints.","Synthetic data has emerged as a promising solution to mitigate these issues, addressing data scarcity while preserving privacy.","Recently, Latent Diffusion Models have emerged as a powerful tool for generating high-quality synthetic data.","Meanwhile, the integration of different modalities has gained interest, emphasizing the need of models capable of handle multimodal medical data.","Existing approaches struggle to integrate complementary information and lack the ability to generate modalities simultaneously.","To address this challenge, we present MedCoDi-M, a 6.77-billion-parameter model, designed for multimodal medical data generation, that, following Foundation Model paradigm, exploits contrastive learning and large quantity of data to build a shared latent space which capture the relationships between different data modalities.","Further, we introduce the Multi-Prompt training technique, which significantly boosts MedCoDi-M's generation under different settings.","We extensively validate MedCoDi-M: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for Chest X-ray and radiological report generation.","Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios.","Finally, we assess the utility of MedCoDi-M in addressing key challenges in the medical field, such as anonymization, data scarcity and imbalance learning.","The results are promising, demonstrating the applicability of MedCoDi-M in medical contexts.","Project page is at https://cosbidev.github.io/MedCoDi-M/."],"url":"http://arxiv.org/abs/2501.04614v2"}
{"created":"2025-01-08 16:47:45","title":"Resilient Peer-to-peer Learning based on Adaptive Aggregation","abstract":"Collaborative learning in peer-to-peer networks offers the benefits of distributed learning while mitigating the risks associated with single points of failure inherent in centralized servers. However, adversarial workers pose potential threats by attempting to inject malicious information into the network. Thus, ensuring the resilience of peer-to-peer learning emerges as a pivotal research objective. The challenge is exacerbated in the presence of non-convex loss functions and non-iid data distributions. This paper introduces a resilient aggregation technique tailored for such scenarios, aimed at fostering similarity among peers' learning processes. The aggregation weights are determined through an optimization procedure, and use the loss function computed using the neighbor's models and individual private data, thereby addressing concerns regarding data privacy in distributed machine learning. Theoretical analysis demonstrates convergence of parameters with non-convex loss functions and non-iid data distributions. Empirical evaluations across three distinct machine learning tasks support the claims. The empirical findings, which encompass a range of diverse attack models, also demonstrate improved accuracy when compared to existing methodologies.","sentences":["Collaborative learning in peer-to-peer networks offers the benefits of distributed learning while mitigating the risks associated with single points of failure inherent in centralized servers.","However, adversarial workers pose potential threats by attempting to inject malicious information into the network.","Thus, ensuring the resilience of peer-to-peer learning emerges as a pivotal research objective.","The challenge is exacerbated in the presence of non-convex loss functions and non-iid data distributions.","This paper introduces a resilient aggregation technique tailored for such scenarios, aimed at fostering similarity among peers' learning processes.","The aggregation weights are determined through an optimization procedure, and use the loss function computed using the neighbor's models and individual private data, thereby addressing concerns regarding data privacy in distributed machine learning.","Theoretical analysis demonstrates convergence of parameters with non-convex loss functions and non-iid data distributions.","Empirical evaluations across three distinct machine learning tasks support the claims.","The empirical findings, which encompass a range of diverse attack models, also demonstrate improved accuracy when compared to existing methodologies."],"url":"http://arxiv.org/abs/2501.04610v1"}
{"created":"2025-01-08 16:25:32","title":"FrontierNet: Learning Visual Cues to Explore","abstract":"Exploration of unknown environments is crucial for autonomous robots; it allows them to actively reason and decide on what new data to acquire for tasks such as mapping, object discovery, and environmental assessment. Existing methods, such as frontier-based methods, rely heavily on 3D map operations, which are limited by map quality and often overlook valuable context from visual cues. This work aims at leveraging 2D visual cues for efficient autonomous exploration, addressing the limitations of extracting goal poses from a 3D map. We propose a image-only frontier-based exploration system, with FrontierNet as a core component developed in this work. FrontierNet is a learning-based model that (i) detects frontiers, and (ii) predicts their information gain, from posed RGB images enhanced by monocular depth priors. Our approach provides an alternative to existing 3D-dependent exploration systems, achieving a 16% improvement in early-stage exploration efficiency, as validated through extensive simulations and real-world experiments.","sentences":["Exploration of unknown environments is crucial for autonomous robots; it allows them to actively reason and decide on what new data to acquire for tasks such as mapping, object discovery, and environmental assessment.","Existing methods, such as frontier-based methods, rely heavily on 3D map operations, which are limited by map quality and often overlook valuable context from visual cues.","This work aims at leveraging 2D visual cues for efficient autonomous exploration, addressing the limitations of extracting goal poses from a 3D map.","We propose a image-only frontier-based exploration system, with FrontierNet as a core component developed in this work.","FrontierNet is a learning-based model that (i) detects frontiers, and (ii) predicts their information gain, from posed RGB images enhanced by monocular depth priors.","Our approach provides an alternative to existing 3D-dependent exploration systems, achieving a 16% improvement in early-stage exploration efficiency, as validated through extensive simulations and real-world experiments."],"url":"http://arxiv.org/abs/2501.04597v1"}
{"created":"2025-01-08 16:23:56","title":"MobileH2R: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic Data","abstract":"This paper introduces MobileH2R, a framework for learning generalizable vision-based human-to-mobile-robot (H2MR) handover skills. Unlike traditional fixed-base handovers, this task requires a mobile robot to reliably receive objects in a large workspace enabled by its mobility. Our key insight is that generalizable handover skills can be developed in simulators using high-quality synthetic data, without the need for real-world demonstrations. To achieve this, we propose a scalable pipeline for generating diverse synthetic full-body human motion data, an automated method for creating safe and imitation-friendly demonstrations, and an efficient 4D imitation learning method for distilling large-scale demonstrations into closed-loop policies with base-arm coordination. Experimental evaluations in both simulators and the real world show significant improvements (at least +15% success rate) over baseline methods in all cases. Experiments also validate that large-scale and diverse synthetic data greatly enhances robot learning, highlighting our scalable framework.","sentences":["This paper introduces MobileH2R, a framework for learning generalizable vision-based human-to-mobile-robot (H2MR) handover skills.","Unlike traditional fixed-base handovers, this task requires a mobile robot to reliably receive objects in a large workspace enabled by its mobility.","Our key insight is that generalizable handover skills can be developed in simulators using high-quality synthetic data, without the need for real-world demonstrations.","To achieve this, we propose a scalable pipeline for generating diverse synthetic full-body human motion data, an automated method for creating safe and imitation-friendly demonstrations, and an efficient 4D imitation learning method for distilling large-scale demonstrations into closed-loop policies with base-arm coordination.","Experimental evaluations in both simulators and the real world show significant improvements (at least +15% success rate) over baseline methods in all cases.","Experiments also validate that large-scale and diverse synthetic data greatly enhances robot learning, highlighting our scalable framework."],"url":"http://arxiv.org/abs/2501.04595v2"}
{"created":"2025-01-08 16:11:31","title":"Quantum-inspired Embeddings Projection and Similarity Metrics for Representation Learning","abstract":"Over the last decade, representation learning, which embeds complex information extracted from large amounts of data into dense vector spaces, has emerged as a key technique in machine learning. Among other applications, it has been a key building block for large language models and advanced computer vision systems based on contrastive learning. A core component of representation learning systems is the projection head, which maps the original embeddings into different, often compressed spaces, while preserving the similarity relationship between vectors.   In this paper, we propose a quantum-inspired projection head that includes a corresponding quantum-inspired similarity metric. Specifically, we map classical embeddings onto quantum states in Hilbert space and introduce a quantum circuit-based projection head to reduce embedding dimensionality. To evaluate the effectiveness of this approach, we extended the BERT language model by integrating our projection head for embedding compression. We compared the performance of embeddings, which were compressed using our quantum-inspired projection head, with those compressed using a classical projection head on information retrieval tasks using the TREC 2019 and TREC 2020 Deep Learning benchmarks. The results demonstrate that our quantum-inspired method achieves competitive performance relative to the classical method while utilizing 32 times fewer parameters. Furthermore, when trained from scratch, it notably excels, particularly on smaller datasets. This work not only highlights the effectiveness of the quantum-inspired approach but also emphasizes the utility of efficient, ad hoc low-entanglement circuit simulations within neural networks as a powerful quantum-inspired technique.","sentences":["Over the last decade, representation learning, which embeds complex information extracted from large amounts of data into dense vector spaces, has emerged as a key technique in machine learning.","Among other applications, it has been a key building block for large language models and advanced computer vision systems based on contrastive learning.","A core component of representation learning systems is the projection head, which maps the original embeddings into different, often compressed spaces, while preserving the similarity relationship between vectors.   ","In this paper, we propose a quantum-inspired projection head that includes a corresponding quantum-inspired similarity metric.","Specifically, we map classical embeddings onto quantum states in Hilbert space and introduce a quantum circuit-based projection head to reduce embedding dimensionality.","To evaluate the effectiveness of this approach, we extended the BERT language model by integrating our projection head for embedding compression.","We compared the performance of embeddings, which were compressed using our quantum-inspired projection head, with those compressed using a classical projection head on information retrieval tasks using the TREC 2019 and TREC 2020","Deep Learning benchmarks.","The results demonstrate that our quantum-inspired method achieves competitive performance relative to the classical method while utilizing 32 times fewer parameters.","Furthermore, when trained from scratch, it notably excels, particularly on smaller datasets.","This work not only highlights the effectiveness of the quantum-inspired approach but also emphasizes the utility of efficient, ad hoc low-entanglement circuit simulations within neural networks as a powerful quantum-inspired technique."],"url":"http://arxiv.org/abs/2501.04591v1"}
{"created":"2025-01-08 16:06:39","title":"Federated-Continual Dynamic Segmentation of Histopathology guided by Barlow Continuity","abstract":"Federated- and Continual Learning have been established as approaches to enable privacy-aware learning on continuously changing data, as required for deploying AI systems in histopathology images. However, data shifts can occur in a dynamic world, spatially between institutions and temporally, due to changing data over time. This leads to two issues: Client Drift, where the central model degrades from aggregating data from clients trained on shifted data, and Catastrophic Forgetting, from temporal shifts such as changes in patient populations. Both tend to degrade the model's performance of previously seen data or spatially distributed training. Despite both problems arising from the same underlying problem of data shifts, existing research addresses them only individually. In this work, we introduce a method that can jointly alleviate Client Drift and Catastrophic Forgetting by using our proposed Dynamic Barlow Continuity that evaluates client updates on a public reference dataset and uses this to guide the training process to a spatially and temporally shift-invariant model. We evaluate our approach on the histopathology datasets BCSS and Semicol and prove our method to be highly effective by jointly improving the dice score as much as from 15.8% to 71.6% in Client Drift and from 42.5% to 62.8% in Catastrophic Forgetting. This enables Dynamic Learning by establishing spatio-temporal shift-invariance.","sentences":["Federated- and Continual Learning have been established as approaches to enable privacy-aware learning on continuously changing data, as required for deploying AI systems in histopathology images.","However, data shifts can occur in a dynamic world, spatially between institutions and temporally, due to changing data over time.","This leads to two issues: Client Drift, where the central model degrades from aggregating data from clients trained on shifted data, and Catastrophic Forgetting, from temporal shifts such as changes in patient populations.","Both tend to degrade the model's performance of previously seen data or spatially distributed training.","Despite both problems arising from the same underlying problem of data shifts, existing research addresses them only individually.","In this work, we introduce a method that can jointly alleviate Client Drift and Catastrophic Forgetting by using our proposed Dynamic Barlow Continuity that evaluates client updates on a public reference dataset and uses this to guide the training process to a spatially and temporally shift-invariant model.","We evaluate our approach on the histopathology datasets BCSS and Semicol and prove our method to be highly effective by jointly improving the dice score as much as from 15.8% to 71.6% in Client Drift and from 42.5% to 62.8% in Catastrophic Forgetting.","This enables Dynamic Learning by establishing spatio-temporal shift-invariance."],"url":"http://arxiv.org/abs/2501.04588v1"}
{"created":"2025-01-08 15:45:21","title":"InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection","abstract":"Graphical User Interface (GUI) Agents, powered by multimodal large language models (MLLMs), have shown great potential for task automation on computing devices such as computers and mobile phones. However, existing agents face challenges in multi-step reasoning and reliance on textual annotations, limiting their effectiveness. We introduce \\textit{InfiGUIAgent}, an MLLM-based GUI Agent trained with a two-stage supervised fine-tuning pipeline. Stage 1 enhances fundamental skills such as GUI understanding and grounding, while Stage 2 integrates hierarchical reasoning and expectation-reflection reasoning skills using synthesized data to enable native reasoning abilities of the agents. \\textit{InfiGUIAgent} achieves competitive performance on several GUI benchmarks, highlighting the impact of native reasoning skills in enhancing GUI interaction for automation tasks. Resources are available at \\url{https://github.com/Reallm-Labs/InfiGUIAgent}.","sentences":["Graphical User Interface (GUI) Agents, powered by multimodal large language models (MLLMs), have shown great potential for task automation on computing devices such as computers and mobile phones.","However, existing agents face challenges in multi-step reasoning and reliance on textual annotations, limiting their effectiveness.","We introduce \\textit{InfiGUIAgent}, an MLLM-based GUI Agent trained with a two-stage supervised fine-tuning pipeline.","Stage 1 enhances fundamental skills such as GUI understanding and grounding, while Stage 2 integrates hierarchical reasoning and expectation-reflection reasoning skills using synthesized data to enable native reasoning abilities of the agents.","\\textit{InfiGUIAgent} achieves competitive performance on several GUI benchmarks, highlighting the impact of native reasoning skills in enhancing GUI interaction for automation tasks.","Resources are available at \\url{https://github.com/Reallm-Labs/InfiGUIAgent}."],"url":"http://arxiv.org/abs/2501.04575v1"}
{"created":"2025-01-08 15:40:22","title":"Scalable Data Notarization Leveraging Hybrid DLTs","abstract":"Notarization is a procedure that enhance data management by ensuring the authentication of data during audits, thereby increasing trust in the audited data. Blockchain is frequently used as a secure, immutable, and transparent storage, contributing to make data notarization procedures more effective and trustable. Several blockchain-based data notarization protocols have been proposed in literature and commercial solutions. However, these implementations, whether on public or private blockchains, face inherent challenges: high fees on public blockchains and trust issues on private platforms, limiting the adoption of blockchains for data notarization or forcing several trade-offs. In this paper, we explore the use of hybrid blockchain architectures for data notarization, with a focus on scalability issues. Through the analysis of a real-world use case, the data notarization of product passports in supply chains, we propose a novel approach utilizing a data structure designed to efficiently manage the trade-offs in terms of storage occupation and costs involved in notarizing a large collection of data.","sentences":["Notarization is a procedure that enhance data management by ensuring the authentication of data during audits, thereby increasing trust in the audited data.","Blockchain is frequently used as a secure, immutable, and transparent storage, contributing to make data notarization procedures more effective and trustable.","Several blockchain-based data notarization protocols have been proposed in literature and commercial solutions.","However, these implementations, whether on public or private blockchains, face inherent challenges: high fees on public blockchains and trust issues on private platforms, limiting the adoption of blockchains for data notarization or forcing several trade-offs.","In this paper, we explore the use of hybrid blockchain architectures for data notarization, with a focus on scalability issues.","Through the analysis of a real-world use case, the data notarization of product passports in supply chains, we propose a novel approach utilizing a data structure designed to efficiently manage the trade-offs in terms of storage occupation and costs involved in notarizing a large collection of data."],"url":"http://arxiv.org/abs/2501.04571v1"}
{"created":"2025-01-08 15:32:12","title":"Supervision-free Vision-Language Alignment","abstract":"Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation of these image-text pairs is both time-consuming and computationally expensive. To address this challenge, we introduce SVP (Supervision-free Visual Projection), a novel framework that enhances vision-language alignment without relying on curated data or preference annotation. SVP leverages self-captioning and a pre-trained grounding model as a feedback mechanism to elicit latent information in VLMs. We evaluate our approach across six key areas: captioning, referring, visual question answering, multitasking, hallucination control, and object recall. Results demonstrate significant improvements, including a 14% average improvement in captioning tasks, up to 12% increase in object recall, and substantial reduction in hallucination rates. Notably, a small VLM using SVP achieves hallucination reductions comparable to a model five times larger, while a VLM with initially poor referring capabilities more than doubles its performance, approaching parity with a model twice its size.","sentences":["Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data.","Curation of these image-text pairs is both time-consuming and computationally expensive.","To address this challenge, we introduce SVP (Supervision-free Visual Projection), a novel framework that enhances vision-language alignment without relying on curated data or preference annotation.","SVP leverages self-captioning and a pre-trained grounding model as a feedback mechanism to elicit latent information in VLMs.","We evaluate our approach across six key areas: captioning, referring, visual question answering, multitasking, hallucination control, and object recall.","Results demonstrate significant improvements, including a 14% average improvement in captioning tasks, up to 12% increase in object recall, and substantial reduction in hallucination rates.","Notably, a small VLM using SVP achieves hallucination reductions comparable to a model five times larger, while a VLM with initially poor referring capabilities more than doubles its performance, approaching parity with a model twice its size."],"url":"http://arxiv.org/abs/2501.04568v1"}
{"created":"2025-01-08 15:25:19","title":"Learnable Scaled Gradient Descent for Guaranteed Robust Tensor PCA","abstract":"Robust tensor principal component analysis (RTPCA) aims to separate the low-rank and sparse components from multi-dimensional data, making it an essential technique in the signal processing and computer vision fields. Recently emerging tensor singular value decomposition (t-SVD) has gained considerable attention for its ability to better capture the low-rank structure of tensors compared to traditional matrix SVD. However, existing methods often rely on the computationally expensive tensor nuclear norm (TNN), which limits their scalability for real-world tensors. To address this issue, we explore an efficient scaled gradient descent (SGD) approach within the t-SVD framework for the first time, and propose the RTPCA-SGD method. Theoretically, we rigorously establish the recovery guarantees of RTPCA-SGD under mild assumptions, demonstrating that with appropriate parameter selection, it achieves linear convergence to the true low-rank tensor at a constant rate, independent of the condition number. To enhance its practical applicability, we further propose a learnable self-supervised deep unfolding model, which enables effective parameter learning. Numerical experiments on both synthetic and real-world datasets demonstrate the superior performance of the proposed methods while maintaining competitive computational efficiency, especially consuming less time than RTPCA-TNN.","sentences":["Robust tensor principal component analysis (RTPCA) aims to separate the low-rank and sparse components from multi-dimensional data, making it an essential technique in the signal processing and computer vision fields.","Recently emerging tensor singular value decomposition (t-SVD) has gained considerable attention for its ability to better capture the low-rank structure of tensors compared to traditional matrix SVD.","However, existing methods often rely on the computationally expensive tensor nuclear norm (TNN), which limits their scalability for real-world tensors.","To address this issue, we explore an efficient scaled gradient descent (SGD) approach within the t-SVD framework for the first time, and propose the RTPCA-SGD method.","Theoretically, we rigorously establish the recovery guarantees of RTPCA-SGD under mild assumptions, demonstrating that with appropriate parameter selection, it achieves linear convergence to the true low-rank tensor at a constant rate, independent of the condition number.","To enhance its practical applicability, we further propose a learnable self-supervised deep unfolding model, which enables effective parameter learning.","Numerical experiments on both synthetic and real-world datasets demonstrate the superior performance of the proposed methods while maintaining competitive computational efficiency, especially consuming less time than RTPCA-TNN."],"url":"http://arxiv.org/abs/2501.04565v1"}
{"created":"2025-01-08 14:51:36","title":"Medical artificial intelligence toolbox (MAIT): an explainable machine learning framework for binary classification, survival modelling, and regression analyses","abstract":"While machine learning offers diverse techniques suitable for exploring various medical research questions, a cohesive synergistic framework can facilitate the integration and understanding of new approaches within unified model development and interpretation. We therefore introduce the Medical Artificial Intelligence Toolbox (MAIT), an explainable, open-source Python pipeline for developing and evaluating binary classification, regression, and survival models on tabular datasets. MAIT addresses key challenges (e.g., high dimensionality, class imbalance, mixed variable types, and missingness) while promoting transparency in reporting (TRIPOD+AI compliant). Offering automated configurations for beginners and customizable source code for experts, MAIT streamlines two primary use cases: Discovery (feature importance via unified scoring, e.g., SHapley Additive exPlanations - SHAP) and Prediction (model development and deployment with optimized solutions). Moreover, MAIT proposes new techniques including fine-tuning of probability threshold in binary classification, translation of cumulative hazard curves to binary classification, enhanced visualizations for model interpretation for mixed data types, and handling censoring through semi-supervised learning, to adapt to a wide set of data constraints and study designs. We provide detailed tutorials on GitHub, using four open-access data sets, to demonstrate how MAIT can be used to improve implementation and interpretation of ML models in medical research.","sentences":["While machine learning offers diverse techniques suitable for exploring various medical research questions, a cohesive synergistic framework can facilitate the integration and understanding of new approaches within unified model development and interpretation.","We therefore introduce the Medical Artificial Intelligence Toolbox (MAIT), an explainable, open-source Python pipeline for developing and evaluating binary classification, regression, and survival models on tabular datasets.","MAIT addresses key challenges (e.g., high dimensionality, class imbalance, mixed variable types, and missingness) while promoting transparency in reporting (TRIPOD+AI compliant).","Offering automated configurations for beginners and customizable source code for experts, MAIT streamlines two primary use cases: Discovery (feature importance via unified scoring, e.g., SHapley Additive exPlanations - SHAP) and Prediction (model development and deployment with optimized solutions).","Moreover, MAIT proposes new techniques including fine-tuning of probability threshold in binary classification, translation of cumulative hazard curves to binary classification, enhanced visualizations for model interpretation for mixed data types, and handling censoring through semi-supervised learning, to adapt to a wide set of data constraints and study designs.","We provide detailed tutorials on GitHub, using four open-access data sets, to demonstrate how MAIT can be used to improve implementation and interpretation of ML models in medical research."],"url":"http://arxiv.org/abs/2501.04547v1"}
{"created":"2025-01-08 14:40:00","title":"Protecting the Connectivity of a Graph Under Non-Uniform Edge Failures","abstract":"We study the problem of guaranteeing the connectivity of a given graph by protecting or strengthening edges. Herein, a protected edge is assumed to be robust and will not fail, which features a non-uniform failure model. We introduce the $(p,q)$-Steiner-Connectivity Preservation problem where we protect a minimum-cost set of edges such that the underlying graph maintains $p$-edge-connectivity between given terminal pairs against edge failures, assuming at most $q$ unprotected edges can fail. We design polynomial-time exact algorithms for the cases where $p$ and $q$ are small and approximation algorithms for general values of $p$ and $q$. Additionally, we show that when both $p$ and $q$ are part of the input, even deciding whether a given solution is feasible is NP-complete. This hardness also carries over to Flexible Network Design, a research direction that has gained significant attention. In particular, previous work focuses on problem settings where either $p$ or $q$ is constant, for which our new hardness result now provides justification.","sentences":["We study the problem of guaranteeing the connectivity of a given graph by protecting or strengthening edges.","Herein, a protected edge is assumed to be robust and will not fail, which features a non-uniform failure model.","We introduce the $(p,q)$-Steiner-Connectivity Preservation problem where we protect a minimum-cost set of edges such that the underlying graph maintains $p$-edge-connectivity between given terminal pairs against edge failures, assuming at most $q$ unprotected edges can fail.","We design polynomial-time exact algorithms for the cases where $p$ and $q$ are small and approximation algorithms for general values of $p$ and $q$. Additionally, we show that when both $p$ and $q$ are part of the input, even deciding whether a given solution is feasible is NP-complete.","This hardness also carries over to Flexible Network Design, a research direction that has gained significant attention.","In particular, previous work focuses on problem settings where either $p$ or $q$ is constant, for which our new hardness result now provides justification."],"url":"http://arxiv.org/abs/2501.04540v1"}
{"created":"2025-01-08 14:21:03","title":"A Plug-and-Play Bregman ADMM Module for Inferring Event Branches in Temporal Point Processes","abstract":"An event sequence generated by a temporal point process is often associated with a hidden and structured event branching process that captures the triggering relations between its historical and current events. In this study, we design a new plug-and-play module based on the Bregman ADMM (BADMM) algorithm, which infers event branches associated with event sequences in the maximum likelihood estimation framework of temporal point processes (TPPs). Specifically, we formulate the inference of event branches as an optimization problem for the event transition matrix under sparse and low-rank constraints, which is embedded in existing TPP models or their learning paradigms. We can implement this optimization problem based on subspace clustering and sparse group-lasso, respectively, and solve it using the Bregman ADMM algorithm, whose unrolling leads to the proposed BADMM module. When learning a classic TPP (e.g., Hawkes process) by the expectation-maximization algorithm, the BADMM module helps derive structured responsibility matrices in the E-step. Similarly, the BADMM module helps derive low-rank and sparse attention maps for the neural TPPs with self-attention layers. The structured responsibility matrices and attention maps, which work as learned event transition matrices, indicate event branches, e.g., inferring isolated events and those key events triggering many subsequent events. Experiments on both synthetic and real-world data show that plugging our BADMM module into existing TPP models and learning paradigms can improve model performance and provide us with interpretable structured event branches. The code is available at \\url{https://github.com/qingmeiwangdaily/BADMM_TPP}.","sentences":["An event sequence generated by a temporal point process is often associated with a hidden and structured event branching process that captures the triggering relations between its historical and current events.","In this study, we design a new plug-and-play module based on the Bregman ADMM (BADMM) algorithm, which infers event branches associated with event sequences in the maximum likelihood estimation framework of temporal point processes (TPPs).","Specifically, we formulate the inference of event branches as an optimization problem for the event transition matrix under sparse and low-rank constraints, which is embedded in existing TPP models or their learning paradigms.","We can implement this optimization problem based on subspace clustering and sparse group-lasso, respectively, and solve it using the Bregman ADMM algorithm, whose unrolling leads to the proposed BADMM module.","When learning a classic TPP (e.g., Hawkes process) by the expectation-maximization algorithm, the BADMM module helps derive structured responsibility matrices in the E-step.","Similarly, the BADMM module helps derive low-rank and sparse attention maps for the neural TPPs with self-attention layers.","The structured responsibility matrices and attention maps, which work as learned event transition matrices, indicate event branches, e.g., inferring isolated events and those key events triggering many subsequent events.","Experiments on both synthetic and real-world data show that plugging our BADMM module into existing TPP models and learning paradigms can improve model performance and provide us with interpretable structured event branches.","The code is available at \\url{https://github.com/qingmeiwangdaily/BADMM_TPP}."],"url":"http://arxiv.org/abs/2501.04529v1"}
{"created":"2025-01-08 14:19:54","title":"Towards a Problem-Oriented Domain Adaptation Framework for Machine Learning","abstract":"Domain adaptation is a sub-field of machine learning that involves transferring knowledge from a source domain to perform the same task in the target domain. It is a typical challenge in machine learning that arises, e.g., when data is obtained from various sources or when using a data basis that changes over time. Recent advances in the field offer promising methods, but it is still challenging for researchers and practitioners to determine if domain adaptation is suitable for a given problem -- and, subsequently, to select the appropriate approach. This article employs design science research to develop a problem-oriented framework for domain adaptation, which is matured in three evaluation episodes. We describe a framework that distinguishes between five domain adaptation scenarios, provides recommendations for addressing each scenario, and offers guidelines for determining if a problem falls into one of these scenarios. During the multiple evaluation episodes, the framework is tested on artificial and real-world datasets and an experimental study involving 100 participants. The evaluation demonstrates that the framework has the explanatory power to capture any domain adaptation problem effectively. In summary, we provide clear guidance for researchers and practitioners who want to employ domain adaptation but lack in-depth knowledge of the possibilities.","sentences":["Domain adaptation is a sub-field of machine learning that involves transferring knowledge from a source domain to perform the same task in the target domain.","It is a typical challenge in machine learning that arises, e.g., when data is obtained from various sources or when using a data basis that changes over time.","Recent advances in the field offer promising methods, but it is still challenging for researchers and practitioners to determine if domain adaptation is suitable for a given problem -- and, subsequently, to select the appropriate approach.","This article employs design science research to develop a problem-oriented framework for domain adaptation, which is matured in three evaluation episodes.","We describe a framework that distinguishes between five domain adaptation scenarios, provides recommendations for addressing each scenario, and offers guidelines for determining if a problem falls into one of these scenarios.","During the multiple evaluation episodes, the framework is tested on artificial and real-world datasets and an experimental study involving 100 participants.","The evaluation demonstrates that the framework has the explanatory power to capture any domain adaptation problem effectively.","In summary, we provide clear guidance for researchers and practitioners who want to employ domain adaptation but lack in-depth knowledge of the possibilities."],"url":"http://arxiv.org/abs/2501.04528v1"}
{"created":"2025-01-08 14:14:19","title":"Right Label Context in End-to-End Training of Time-Synchronous ASR Models","abstract":"Current time-synchronous sequence-to-sequence automatic speech recognition (ASR) models are trained by using sequence level cross-entropy that sums over all alignments. Due to the discriminative formulation, incorporating the right label context into the training criterion's gradient causes normalization problems and is not mathematically well-defined. The classic hybrid neural network hidden Markov model (NN-HMM) with its inherent generative formulation enables conditioning on the right label context. However, due to the HMM state-tying the identity of the right label context is never modeled explicitly. In this work, we propose a factored loss with auxiliary left and right label contexts that sums over all alignments. We show that the inclusion of the right label context is particularly beneficial when training data resources are limited. Moreover, we also show that it is possible to build a factored hybrid HMM system by relying exclusively on the full-sum criterion. Experiments were conducted on Switchboard 300h and LibriSpeech 960h.","sentences":["Current time-synchronous sequence-to-sequence automatic speech recognition (ASR) models are trained by using sequence level cross-entropy that sums over all alignments.","Due to the discriminative formulation, incorporating the right label context into the training criterion's gradient causes normalization problems and is not mathematically well-defined.","The classic hybrid neural network hidden Markov model (NN-HMM) with its inherent generative formulation enables conditioning on the right label context.","However, due to the HMM state-tying the identity of the right label context is never modeled explicitly.","In this work, we propose a factored loss with auxiliary left and right label contexts that sums over all alignments.","We show that the inclusion of the right label context is particularly beneficial when training data resources are limited.","Moreover, we also show that it is possible to build a factored hybrid HMM system by relying exclusively on the full-sum criterion.","Experiments were conducted on Switchboard 300h and LibriSpeech 960h."],"url":"http://arxiv.org/abs/2501.04521v2"}
{"created":"2025-01-08 14:12:57","title":"rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking","abstract":"We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models. rStar-Math achieves this by exercising \"deep thinking\" through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model. rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data sythesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na\\\"ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities. Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels. On the MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, surpassing o1-preview by +4.5% and +0.9%. On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% the brightest high school math students. Code and data will be available at https://github.com/microsoft/rStar.","sentences":["We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models.","rStar-Math achieves this by exercising \"deep thinking\" through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model.","rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data sythesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na\\\"ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities.","Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels.","On the MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, surpassing o1-preview by +4.5% and +0.9%.","On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% the brightest high school math students.","Code and data will be available at https://github.com/microsoft/rStar."],"url":"http://arxiv.org/abs/2501.04519v1"}
{"created":"2025-01-08 14:06:07","title":"Histogram-Equalized Quantization for logic-gated Residual Neural Networks","abstract":"Adjusting the quantization according to the data or to the model loss seems mandatory to enable a high accuracy in the context of quantized neural networks. This work presents Histogram-Equalized Quantization (HEQ), an adaptive framework for linear symmetric quantization. HEQ automatically adapts the quantization thresholds using a unique step size optimization. We empirically show that HEQ achieves state-of-the-art performances on CIFAR-10. Experiments on the STL-10 dataset even show that HEQ enables a proper training of our proposed logic-gated (OR, MUX) residual networks with a higher accuracy at a lower hardware complexity than previous work.","sentences":["Adjusting the quantization according to the data or to the model loss seems mandatory to enable a high accuracy in the context of quantized neural networks.","This work presents Histogram-Equalized Quantization (HEQ), an adaptive framework for linear symmetric quantization.","HEQ automatically adapts the quantization thresholds using a unique step size optimization.","We empirically show that HEQ achieves state-of-the-art performances on CIFAR-10.","Experiments on the STL-10 dataset even show that HEQ enables a proper training of our proposed logic-gated (OR, MUX) residual networks with a higher accuracy at a lower hardware complexity than previous work."],"url":"http://arxiv.org/abs/2501.04517v2"}
{"created":"2025-01-08 14:00:07","title":"Improving Image Captioning by Mimicking Human Reformulation Feedback at Inference-time","abstract":"Incorporating automatically predicted human feedback into the process of training generative models has attracted substantial recent interest, while feedback at inference time has received less attention. The typical feedback at training time, i.e., preferences of choice given two samples, does not naturally transfer to the inference phase. We introduce a novel type of feedback -- caption reformulations -- and train models to mimic reformulation feedback based on human annotations. Our method does not require training the image captioning model itself, thereby demanding substantially less computational effort. We experiment with two types of reformulation feedback: first, we collect a dataset of human reformulations that correct errors in the generated captions. We find that incorporating reformulation models trained on this data into the inference phase of existing image captioning models results in improved captions, especially when the original captions are of low quality. We apply our method to non-English image captioning, a domain where robust models are less prevalent, and gain substantial improvement. Second, we apply reformulations to style transfer. Quantitative evaluations reveal state-of-the-art performance on German image captioning and English style transfer, while human validation with a detailed comparative framework exposes the specific axes of improvement.","sentences":["Incorporating automatically predicted human feedback into the process of training generative models has attracted substantial recent interest, while feedback at inference time has received less attention.","The typical feedback at training time, i.e., preferences of choice given two samples, does not naturally transfer to the inference phase.","We introduce a novel type of feedback -- caption reformulations -- and train models to mimic reformulation feedback based on human annotations.","Our method does not require training the image captioning model itself, thereby demanding substantially less computational effort.","We experiment with two types of reformulation feedback: first, we collect a dataset of human reformulations that correct errors in the generated captions.","We find that incorporating reformulation models trained on this data into the inference phase of existing image captioning models results in improved captions, especially when the original captions are of low quality.","We apply our method to non-English image captioning, a domain where robust models are less prevalent, and gain substantial improvement.","Second, we apply reformulations to style transfer.","Quantitative evaluations reveal state-of-the-art performance on German image captioning and English style transfer, while human validation with a detailed comparative framework exposes the specific axes of improvement."],"url":"http://arxiv.org/abs/2501.04513v1"}
{"created":"2025-01-08 13:14:05","title":"Integrating remote sensing data assimilation, deep learning and large language model for interactive wheat breeding yield prediction","abstract":"Yield is one of the core goals of crop breeding. By predicting the potential yield of different breeding materials, breeders can screen these materials at various growth stages to select the best performing. Based on unmanned aerial vehicle remote sensing technology, high-throughput crop phenotyping data in breeding areas is collected to provide data support for the breeding decisions of breeders. However, the accuracy of current yield predictions still requires improvement, and the usability and user-friendliness of yield forecasting tools remain suboptimal. To address these challenges, this study introduces a hybrid method and tool for crop yield prediction, designed to allow breeders to interactively and accurately predict wheat yield by chatting with a large language model (LLM). First, the newly designed data assimilation algorithm is used to assimilate the leaf area index into the WOFOST model. Then, selected outputs from the assimilation process, along with remote sensing inversion results, are used to drive the time-series temporal fusion transformer model for wheat yield prediction. Finally, based on this hybrid method and leveraging an LLM with retrieval augmented generation technology, we developed an interactive yield prediction Web tool that is user-friendly and supports sustainable data updates. This tool integrates multi-source data to assist breeding decision-making. This study aims to accelerate the identification of high-yield materials in the breeding process, enhance breeding efficiency, and enable more scientific and smart breeding decisions.","sentences":["Yield is one of the core goals of crop breeding.","By predicting the potential yield of different breeding materials, breeders can screen these materials at various growth stages to select the best performing.","Based on unmanned aerial vehicle remote sensing technology, high-throughput crop phenotyping data in breeding areas is collected to provide data support for the breeding decisions of breeders.","However, the accuracy of current yield predictions still requires improvement, and the usability and user-friendliness of yield forecasting tools remain suboptimal.","To address these challenges, this study introduces a hybrid method and tool for crop yield prediction, designed to allow breeders to interactively and accurately predict wheat yield by chatting with a large language model (LLM).","First, the newly designed data assimilation algorithm is used to assimilate the leaf area index into the WOFOST model.","Then, selected outputs from the assimilation process, along with remote sensing inversion results, are used to drive the time-series temporal fusion transformer model for wheat yield prediction.","Finally, based on this hybrid method and leveraging an LLM with retrieval augmented generation technology, we developed an interactive yield prediction Web tool that is user-friendly and supports sustainable data updates.","This tool integrates multi-source data to assist breeding decision-making.","This study aims to accelerate the identification of high-yield materials in the breeding process, enhance breeding efficiency, and enable more scientific and smart breeding decisions."],"url":"http://arxiv.org/abs/2501.04487v1"}
{"created":"2025-01-08 13:04:08","title":"Safe Reinforcement Learning with Minimal Supervision","abstract":"Reinforcement learning (RL) in the real world necessitates the development of procedures that enable agents to explore without causing harm to themselves or others. The most successful solutions to the problem of safe RL leverage offline data to learn a safe-set, enabling safe online exploration. However, this approach to safe-learning is often constrained by the demonstrations that are available for learning.   In this paper we investigate the influence of the quantity and quality of data used to train the initial safe learning problem offline on the ability to learn safe-RL policies online. Specifically, we focus on tasks with spatially extended goal states where we have few or no demonstrations available. Classically this problem is addressed either by using hand-designed controllers to generate data or by collecting user-generated demonstrations. However, these methods are often expensive and do not scale to more complex tasks and environments. To address this limitation we propose an unsupervised RL-based offline data collection procedure, to learn complex and scalable policies without the need for hand-designed controllers or user demonstrations. Our research demonstrates the significance of providing sufficient demonstrations for agents to learn optimal safe-RL policies online, and as a result, we propose optimistic forgetting, a novel online safe-RL approach that is practical for scenarios with limited data. Further, our unsupervised data collection approach highlights the need to balance diversity and optimality for safe online exploration.","sentences":["Reinforcement learning (RL) in the real world necessitates the development of procedures that enable agents to explore without causing harm to themselves or others.","The most successful solutions to the problem of safe RL leverage offline data to learn a safe-set, enabling safe online exploration.","However, this approach to safe-learning is often constrained by the demonstrations that are available for learning.   ","In this paper we investigate the influence of the quantity and quality of data used to train the initial safe learning problem offline on the ability to learn safe-RL policies online.","Specifically, we focus on tasks with spatially extended goal states where we have few or no demonstrations available.","Classically this problem is addressed either by using hand-designed controllers to generate data or by collecting user-generated demonstrations.","However, these methods are often expensive and do not scale to more complex tasks and environments.","To address this limitation we propose an unsupervised RL-based offline data collection procedure, to learn complex and scalable policies without the need for hand-designed controllers or user demonstrations.","Our research demonstrates the significance of providing sufficient demonstrations for agents to learn optimal safe-RL policies online, and as a result, we propose optimistic forgetting, a novel online safe-RL approach that is practical for scenarios with limited data.","Further, our unsupervised data collection approach highlights the need to balance diversity and optimality for safe online exploration."],"url":"http://arxiv.org/abs/2501.04481v1"}
{"created":"2025-01-08 12:54:05","title":"When LLMs Struggle: Reference-less Translation Evaluation for Low-resource Languages","abstract":"This paper investigates the reference-less evaluation of machine translation for low-resource language pairs, known as quality estimation (QE). Segment-level QE is a challenging cross-lingual language understanding task that provides a quality score (0-100) to the translated output. We comprehensively evaluate large language models (LLMs) in zero/few-shot scenarios and perform instruction fine-tuning using a novel prompt based on annotation guidelines. Our results indicate that prompt-based approaches are outperformed by the encoder-based fine-tuned QE models. Our error analysis reveals tokenization issues, along with errors due to transliteration and named entities, and argues for refinement in LLM pre-training for cross-lingual tasks. We release the data, and models trained publicly for further research.","sentences":["This paper investigates the reference-less evaluation of machine translation for low-resource language pairs, known as quality estimation (QE).","Segment-level QE is a challenging cross-lingual language understanding task that provides a quality score (0-100) to the translated output.","We comprehensively evaluate large language models (LLMs) in zero/few-shot scenarios and perform instruction fine-tuning using a novel prompt based on annotation guidelines.","Our results indicate that prompt-based approaches are outperformed by the encoder-based fine-tuned QE models.","Our error analysis reveals tokenization issues, along with errors due to transliteration and named entities, and argues for refinement in LLM pre-training for cross-lingual tasks.","We release the data, and models trained publicly for further research."],"url":"http://arxiv.org/abs/2501.04473v1"}
{"created":"2025-01-08 12:41:42","title":"A Histologic Dataset of Normal and Atypical Mitotic Figures on Human Breast Cancer (AMi-Br)","abstract":"Assessment of the density of mitotic figures (MFs) in histologic tumor sections is an important prognostic marker for many tumor types, including breast cancer. Recently, it has been reported in multiple works that the quantity of MFs with an atypical morphology (atypical MFs, AMFs) might be an independent prognostic criterion for breast cancer. AMFs are an indicator of mutations in the genes regulating the cell cycle and can lead to aberrant chromosome constitution (aneuploidy) of the tumor cells. To facilitate further research on this topic using pattern recognition, we present the first ever publicly available dataset of atypical and normal MFs (AMi-Br). For this, we utilized two of the most popular MF datasets (MIDOG 2021 and TUPAC) and subclassified all MFs using a three expert majority vote. Our final dataset consists of 3,720 MFs, split into 832 AMFs (22.4%) and 2,888 normal MFs (77.6%) across all 223 tumor cases in the combined set. We provide baseline classification experiments to investigate the consistency of the dataset, using a Monte Carlo cross-validation and different strategies to combat class imbalance. We found an averaged balanced accuracy of up to 0.806 when using a patch-level data set split, and up to 0.713 when using a patient-level split.","sentences":["Assessment of the density of mitotic figures (MFs) in histologic tumor sections is an important prognostic marker for many tumor types, including breast cancer.","Recently, it has been reported in multiple works that the quantity of MFs with an atypical morphology (atypical MFs, AMFs) might be an independent prognostic criterion for breast cancer.","AMFs are an indicator of mutations in the genes regulating the cell cycle and can lead to aberrant chromosome constitution (aneuploidy) of the tumor cells.","To facilitate further research on this topic using pattern recognition, we present the first ever publicly available dataset of atypical and normal MFs (AMi-Br).","For this, we utilized two of the most popular MF datasets (MIDOG 2021 and TUPAC) and subclassified all MFs using a three expert majority vote.","Our final dataset consists of 3,720 MFs, split into 832 AMFs (22.4%) and 2,888 normal MFs (77.6%) across all 223 tumor cases in the combined set.","We provide baseline classification experiments to investigate the consistency of the dataset, using a Monte Carlo cross-validation and different strategies to combat class imbalance.","We found an averaged balanced accuracy of up to 0.806 when using a patch-level data set split, and up to 0.713 when using a patient-level split."],"url":"http://arxiv.org/abs/2501.04467v1"}
{"created":"2025-01-08 12:18:11","title":"Hidden Entity Detection from GitHub Leveraging Large Language Models","abstract":"Named entity recognition is an important task when constructing knowledge bases from unstructured data sources. Whereas entity detection methods mostly rely on extensive training data, Large Language Models (LLMs) have paved the way towards approaches that rely on zero-shot learning (ZSL) or few-shot learning (FSL) by taking advantage of the capabilities LLMs acquired during pretraining. Specifically, in very specialized scenarios where large-scale training data is not available, ZSL / FSL opens new opportunities. This paper follows this recent trend and investigates the potential of leveraging Large Language Models (LLMs) in such scenarios to automatically detect datasets and software within textual content from GitHub repositories. While existing methods focused solely on named entities, this study aims to broaden the scope by incorporating resources such as repositories and online hubs where entities are also represented by URLs. The study explores different FSL prompt learning approaches to enhance the LLMs' ability to identify dataset and software mentions within repository texts. Through analyses of LLM effectiveness and learning strategies, this paper offers insights into the potential of advanced language models for automated entity detection.","sentences":["Named entity recognition is an important task when constructing knowledge bases from unstructured data sources.","Whereas entity detection methods mostly rely on extensive training data, Large Language Models (LLMs) have paved the way towards approaches that rely on zero-shot learning (ZSL) or few-shot learning (FSL) by taking advantage of the capabilities LLMs acquired during pretraining.","Specifically, in very specialized scenarios where large-scale training data is not available, ZSL / FSL opens new opportunities.","This paper follows this recent trend and investigates the potential of leveraging Large Language Models (LLMs) in such scenarios to automatically detect datasets and software within textual content from GitHub repositories.","While existing methods focused solely on named entities, this study aims to broaden the scope by incorporating resources such as repositories and online hubs where entities are also represented by URLs.","The study explores different FSL prompt learning approaches to enhance the LLMs' ability to identify dataset and software mentions within repository texts.","Through analyses of LLM effectiveness and learning strategies, this paper offers insights into the potential of advanced language models for automated entity detection."],"url":"http://arxiv.org/abs/2501.04455v1"}
{"created":"2025-01-08 12:14:00","title":"Gradient Purification: Defense Against Poisoning Attack in Decentralized Federated Learning","abstract":"Decentralized federated learning (DFL) is inherently vulnerable to poisoning attacks, as malicious clients can transmit manipulated model gradients to neighboring clients. Existing defense methods either reject suspicious gradients per iteration or restart DFL aggregation after detecting all malicious clients. They overlook the potential accuracy benefit from the discarded malicious gradients. In this paper, we propose a novel gradient purification defense, named GPD, that integrates seamlessly with existing DFL aggregation to defend against poisoning attacks. It aims to mitigate the harm in model gradients while retaining the benefit in model weights for enhancing accuracy. For each benign client in GPD, a recording variable is designed to track the historically aggregated gradients from one of its neighbors. It allows benign clients to precisely detect malicious neighbors and swiftly mitigate aggregated malicious gradients via historical consistency checks. Upon mitigation, GPD optimizes model weights via aggregating gradients solely from benign clients. This retains the previously beneficial portions from malicious clients and exploits the contributions from benign clients, thereby significantly enhancing the model accuracy. We analyze the convergence of GPD, as well as its ability to harvest high accuracy. Extensive experiments over three datasets demonstrate that, GPD is capable of mitigating poisoning attacks under both iid and non-iid data distributions. It significantly outperforms state-of-the-art defenses in terms of accuracy against various poisoning attacks.","sentences":["Decentralized federated learning (DFL) is inherently vulnerable to poisoning attacks, as malicious clients can transmit manipulated model gradients to neighboring clients.","Existing defense methods either reject suspicious gradients per iteration or restart DFL aggregation after detecting all malicious clients.","They overlook the potential accuracy benefit from the discarded malicious gradients.","In this paper, we propose a novel gradient purification defense, named GPD, that integrates seamlessly with existing DFL aggregation to defend against poisoning attacks.","It aims to mitigate the harm in model gradients while retaining the benefit in model weights for enhancing accuracy.","For each benign client in GPD, a recording variable is designed to track the historically aggregated gradients from one of its neighbors.","It allows benign clients to precisely detect malicious neighbors and swiftly mitigate aggregated malicious gradients via historical consistency checks.","Upon mitigation, GPD optimizes model weights via aggregating gradients solely from benign clients.","This retains the previously beneficial portions from malicious clients and exploits the contributions from benign clients, thereby significantly enhancing the model accuracy.","We analyze the convergence of GPD, as well as its ability to harvest high accuracy.","Extensive experiments over three datasets demonstrate that, GPD is capable of mitigating poisoning attacks under both iid and non-iid data distributions.","It significantly outperforms state-of-the-art defenses in terms of accuracy against various poisoning attacks."],"url":"http://arxiv.org/abs/2501.04453v1"}
{"created":"2025-01-08 11:53:30","title":"A novel Facial Recognition technique with Focusing on Masked Faces","abstract":"Recognizing the same faces with and without masks is important for ensuring consistent identification in security, access control, and public safety. This capability is crucial in scenarios like law enforcement, healthcare, and surveillance, where accurate recognition must be maintained despite facial occlusion. This research focuses on the challenge of recognizing the same faces with and without masks by employing cosine similarity as the primary technique. With the increased use of masks, traditional facial recognition systems face significant accuracy issues, making it crucial to develop methods that can reliably identify individuals in masked conditions. For that reason, this study proposed Masked-Unmasked Face Matching Model (MUFM). This model employs transfer learning using the Visual Geometry Group (VGG16) model to extract significant facial features, which are subsequently classified utilizing the K-Nearest Neighbors (K-NN) algorithm. The cosine similarity metric is employed to compare masked and unmasked faces of the same individuals. This approach represents a novel contribution, as the task of recognizing the same individual with and without a mask using cosine similarity has not been previously addressed. By integrating these advanced methodologies, the research demonstrates effective identification of individuals despite the presence of masks, addressing a significant limitation in traditional systems. Using data is another essential part of this work, by collecting and preparing an image dataset from three different sources especially some of those data are real provided a comprehensive power of this research. The image dataset used were already collected in three different datasets of masked and unmasked for the same faces.","sentences":["Recognizing the same faces with and without masks is important for ensuring consistent identification in security, access control, and public safety.","This capability is crucial in scenarios like law enforcement, healthcare, and surveillance, where accurate recognition must be maintained despite facial occlusion.","This research focuses on the challenge of recognizing the same faces with and without masks by employing cosine similarity as the primary technique.","With the increased use of masks, traditional facial recognition systems face significant accuracy issues, making it crucial to develop methods that can reliably identify individuals in masked conditions.","For that reason, this study proposed Masked-Unmasked Face Matching Model (MUFM).","This model employs transfer learning using the Visual Geometry Group (VGG16) model to extract significant facial features, which are subsequently classified utilizing the K-Nearest Neighbors (K-NN) algorithm.","The cosine similarity metric is employed to compare masked and unmasked faces of the same individuals.","This approach represents a novel contribution, as the task of recognizing the same individual with and without a mask using cosine similarity has not been previously addressed.","By integrating these advanced methodologies, the research demonstrates effective identification of individuals despite the presence of masks, addressing a significant limitation in traditional systems.","Using data is another essential part of this work, by collecting and preparing an image dataset from three different sources especially some of those data are real provided a comprehensive power of this research.","The image dataset used were already collected in three different datasets of masked and unmasked for the same faces."],"url":"http://arxiv.org/abs/2501.04444v1"}
{"created":"2025-01-08 11:45:50","title":"Motif Discovery Framework for Psychiatric EEG Data Classification","abstract":"In current medical practice, patients undergoing depression treatment must wait four to six weeks before a clinician can assess medication response due to the delayed noticeable effects of antidepressants. Identification of a treatment response at any earlier stage is of great importance, since it can reduce the emotional and economic burden connected with the treatment. We approach the prediction of a patient response to a treatment as a classification problem, by utilizing the dynamic properties of EEG recordings on the 7th day of the treatment. We present a novel framework that applies motif discovery to extract meaningful features from EEG data distinguishing between depression treatment responders and non-responders. We applied our framework also to classification tasks in other psychiatric EEG datasets, namely to patients with symptoms of schizophrenia, pediatric patients with intractable seizures, and Alzheimer disease and dementia. We achieved high classification precision in all data sets. The results demonstrate that the dynamic properties of the EEGs may support clinicians in decision making both in diagnosis and in the prediction depression treatment response as early as on the 7th day of the treatment. To our best knowledge, our work is the first one using motifs in the depression diagnostics in general.","sentences":["In current medical practice, patients undergoing depression treatment must wait four to six weeks before a clinician can assess medication response due to the delayed noticeable effects of antidepressants.","Identification of a treatment response at any earlier stage is of great importance, since it can reduce the emotional and economic burden connected with the treatment.","We approach the prediction of a patient response to a treatment as a classification problem, by utilizing the dynamic properties of EEG recordings on the 7th day of the treatment.","We present a novel framework that applies motif discovery to extract meaningful features from EEG data distinguishing between depression treatment responders and non-responders.","We applied our framework also to classification tasks in other psychiatric EEG datasets, namely to patients with symptoms of schizophrenia, pediatric patients with intractable seizures, and Alzheimer disease and dementia.","We achieved high classification precision in all data sets.","The results demonstrate that the dynamic properties of the EEGs may support clinicians in decision making both in diagnosis and in the prediction depression treatment response as early as on the 7th day of the treatment.","To our best knowledge, our work is the first one using motifs in the depression diagnostics in general."],"url":"http://arxiv.org/abs/2501.04441v1"}
{"created":"2025-01-08 11:39:28","title":"Effect of Information Technology on Job Creation to Support Economic: Case Studies of Graduates in Universities (2023-2024) of the KRG of Iraq","abstract":"The aim of this study is to assess the impact of information technology (IT) on university graduates in terms of employment development, which will aid in economic issues. This study uses a descriptive research methodology and a quantitative approach to understand variables. The focus of this study is to ascertain how graduates of Kurdistan regional universities might use IT to secure employment and significantly contribute to the nation's economic revival. The sample size was established by the use of judgmental sampling procedure and consisted of 314 people. The researcher prepared the questionnaire to collect data, and then SPSS statistical software, version 22, and Excel 2010 were used to modify, compile, and tabulate the results. The study's outcome showed that information technology is incredibly inventive, has a promising future, and makes life much easier for everyone. It also proved that a deep academic understanding of information technology and its constituent parts helps graduates of Kurdistan Regional University find suitable careers. More importantly, though, anyone looking for work or a means of support will find great benefit from possessing credentials and understanding of IT. The study's final finding was that information technology has actively advanced the country's economy. Not only is IT helping to boost youth employment, but it is also turning into a worthwhile investment for economic growth.","sentences":["The aim of this study is to assess the impact of information technology (IT) on university graduates in terms of employment development, which will aid in economic issues.","This study uses a descriptive research methodology and a quantitative approach to understand variables.","The focus of this study is to ascertain how graduates of Kurdistan regional universities might use IT to secure employment and significantly contribute to the nation's economic revival.","The sample size was established by the use of judgmental sampling procedure and consisted of 314 people.","The researcher prepared the questionnaire to collect data, and then SPSS statistical software, version 22, and Excel 2010 were used to modify, compile, and tabulate the results.","The study's outcome showed that information technology is incredibly inventive, has a promising future, and makes life much easier for everyone.","It also proved that a deep academic understanding of information technology and its constituent parts helps graduates of Kurdistan Regional University find suitable careers.","More importantly, though, anyone looking for work or a means of support will find great benefit from possessing credentials and understanding of IT.","The study's final finding was that information technology has actively advanced the country's economy.","Not only is IT helping to boost youth employment, but it is also turning into a worthwhile investment for economic growth."],"url":"http://arxiv.org/abs/2501.04438v1"}
{"created":"2025-01-08 11:37:06","title":"Federated Fine-Tuning of LLMs: Framework Comparison and Research Directions","abstract":"Federated learning (FL) provides a privacy-preserving solution for fine-tuning pre-trained large language models (LLMs) using distributed private datasets, enabling task-specific adaptation while preserving data privacy. However, fine-tuning the extensive parameters in LLMs is particularly challenging in resource-constrained federated scenarios due to the significant communication and computational costs. To gain a deeper understanding of how these challenges can be addressed, this article conducts a comparative analysis three advanced federated LLM (FedLLM) frameworks that integrate knowledge distillation (KD) and split learning (SL) to mitigate these issues: 1) FedLLMs, where clients upload model parameters or gradients to enable straightforward and effective fine-tuning; 2) KD-FedLLMs, which leverage KD for efficient knowledge sharing via logits; and 3) Split-FedLLMs, which split the LLMs into two parts, with one part executed on the client and the other one on the server, to balance the computational load. Each framework is evaluated based on key performance metrics, including model accuracy, communication overhead, and client-side computational load, offering insights into their effectiveness for various federated fine-tuning scenarios. Through this analysis, we identify framework-specific optimization opportunities to enhance the efficiency of FedLLMs and discuss broader research directions, highlighting open opportunities to better adapt FedLLMs for real-world applications. A use case is presented to demonstrate the performance comparison of these three frameworks under varying configurations and settings.","sentences":["Federated learning (FL) provides a privacy-preserving solution for fine-tuning pre-trained large language models (LLMs) using distributed private datasets, enabling task-specific adaptation while preserving data privacy.","However, fine-tuning the extensive parameters in LLMs is particularly challenging in resource-constrained federated scenarios due to the significant communication and computational costs.","To gain a deeper understanding of how these challenges can be addressed, this article conducts a comparative analysis three advanced federated LLM (FedLLM) frameworks that integrate knowledge distillation (KD) and split learning (SL) to mitigate these issues: 1) FedLLMs, where clients upload model parameters or gradients to enable straightforward and effective fine-tuning; 2) KD-FedLLMs, which leverage KD for efficient knowledge sharing via logits; and 3) Split-FedLLMs, which split the LLMs into two parts, with one part executed on the client and the other one on the server, to balance the computational load.","Each framework is evaluated based on key performance metrics, including model accuracy, communication overhead, and client-side computational load, offering insights into their effectiveness for various federated fine-tuning scenarios.","Through this analysis, we identify framework-specific optimization opportunities to enhance the efficiency of FedLLMs and discuss broader research directions, highlighting open opportunities to better adapt FedLLMs for real-world applications.","A use case is presented to demonstrate the performance comparison of these three frameworks under varying configurations and settings."],"url":"http://arxiv.org/abs/2501.04436v1"}
{"created":"2025-01-08 11:31:39","title":"A Digital Shadow for Modeling, Studying and Preventing Urban Crime","abstract":"Crime is one of the greatest threats to urban security. Around 80 percent of the world's population lives in countries with high levels of criminality. Most of the crimes committed in the cities take place in their urban environments. This paper presents the development and validation of a digital shadow platform for modeling and simulating urban crime. This digital shadow has been constructed using data-driven agent-based modeling and simulation techniques, which are suitable for capturing dynamic interactions among individuals and with their environment. Our approach transforms and integrates well-known criminological theories and the expert knowledge of law enforcement agencies (LEA), policy makers, and other stakeholders under a theoretical model, which is in turn combined with real crime, spatial (cartographic) and socio-economic data into an urban model characterizing the daily behavior of citizens. The digital shadow has also been instantiated for the city of Malaga, for which we had over 300,000 complaints available. This instance has been calibrated with those complaints and other geographic and socio-economic information of the city. To the best of our knowledge, our digital shadow is the first for large urban areas that has been calibrated with a large dataset of real crime reports and with an accurate representation of the urban environment. The performance indicators of the model after being calibrated, in terms of the metrics widely used in predictive policing, suggest that our simulated crime generation matches the general pattern of crime in the city according to historical data. Our digital shadow platform could be an interesting tool for modeling and predicting criminal behavior in an urban environment on a daily basis and, thus, a useful tool for policy makers, criminologists, sociologists, LEAs, etc. to study and prevent urban crime.","sentences":["Crime is one of the greatest threats to urban security.","Around 80 percent of the world's population lives in countries with high levels of criminality.","Most of the crimes committed in the cities take place in their urban environments.","This paper presents the development and validation of a digital shadow platform for modeling and simulating urban crime.","This digital shadow has been constructed using data-driven agent-based modeling and simulation techniques, which are suitable for capturing dynamic interactions among individuals and with their environment.","Our approach transforms and integrates well-known criminological theories and the expert knowledge of law enforcement agencies (LEA), policy makers, and other stakeholders under a theoretical model, which is in turn combined with real crime, spatial (cartographic) and socio-economic data into an urban model characterizing the daily behavior of citizens.","The digital shadow has also been instantiated for the city of Malaga, for which we had over 300,000 complaints available.","This instance has been calibrated with those complaints and other geographic and socio-economic information of the city.","To the best of our knowledge, our digital shadow is the first for large urban areas that has been calibrated with a large dataset of real crime reports and with an accurate representation of the urban environment.","The performance indicators of the model after being calibrated, in terms of the metrics widely used in predictive policing, suggest that our simulated crime generation matches the general pattern of crime in the city according to historical data.","Our digital shadow platform could be an interesting tool for modeling and predicting criminal behavior in an urban environment on a daily basis and, thus, a useful tool for policy makers, criminologists, sociologists, LEAs, etc. to study and prevent urban crime."],"url":"http://arxiv.org/abs/2501.04435v1"}
{"created":"2025-01-08 11:17:40","title":"NSA: Neuro-symbolic ARC Challenge","abstract":"The Abstraction and Reasoning Corpus (ARC) evaluates general reasoning capabilities that are difficult for both machine learning models and combinatorial search methods. We propose a neuro-symbolic approach that combines a transformer for proposal generation with combinatorial search using a domain-specific language. The transformer narrows the search space by proposing promising search directions, which allows the combinatorial search to find the actual solution in short time. We pre-train the trainsformer with synthetically generated data. During test-time we generate additional task-specific training tasks and fine-tune our model. Our results surpass comparable state of the art on the ARC evaluation set by 27% and compare favourably on the ARC train set. We make our code and dataset publicly available at https://github.com/Batorskq/NSA.","sentences":["The Abstraction and Reasoning Corpus (ARC) evaluates general reasoning capabilities that are difficult for both machine learning models and combinatorial search methods.","We propose a neuro-symbolic approach that combines a transformer for proposal generation with combinatorial search using a domain-specific language.","The transformer narrows the search space by proposing promising search directions, which allows the combinatorial search to find the actual solution in short time.","We pre-train the trainsformer with synthetically generated data.","During test-time we generate additional task-specific training tasks and fine-tune our model.","Our results surpass comparable state of the art on the ARC evaluation set by 27% and compare favourably on the ARC train set.","We make our code and dataset publicly available at https://github.com/Batorskq/NSA."],"url":"http://arxiv.org/abs/2501.04424v1"}
{"created":"2025-01-08 11:08:58","title":"A Closer Look on Gender Stereotypes in Movie Recommender Systems and Their Implications with Privacy","abstract":"The movie recommender system typically leverages user feedback to provide personalized recommendations that align with user preferences and increase business revenue. This study investigates the impact of gender stereotypes on such systems through a specific attack scenario. In this scenario, an attacker determines users' gender, a private attribute, by exploiting gender stereotypes about movie preferences and analyzing users' feedback data, which is either publicly available or observed within the system. The study consists of two phases. In the first phase, a user study involving 630 participants identified gender stereotypes associated with movie genres, which often influence viewing choices. In the second phase, four inference algorithms were applied to detect gender stereotypes by combining the findings from the first phase with users' feedback data. Results showed that these algorithms performed more effectively than relying solely on feedback data for gender inference. Additionally, we quantified the extent of gender stereotypes to evaluate their broader impact on digital computational science. The latter part of the study utilized two major movie recommender datasets: MovieLens 1M and Yahoo!Movie. Detailed experimental information is available on our GitHub repository: https://github.com/fr-iit/GSMRS","sentences":["The movie recommender system typically leverages user feedback to provide personalized recommendations that align with user preferences and increase business revenue.","This study investigates the impact of gender stereotypes on such systems through a specific attack scenario.","In this scenario, an attacker determines users' gender, a private attribute, by exploiting gender stereotypes about movie preferences and analyzing users' feedback data, which is either publicly available or observed within the system.","The study consists of two phases.","In the first phase, a user study involving 630 participants identified gender stereotypes associated with movie genres, which often influence viewing choices.","In the second phase, four inference algorithms were applied to detect gender stereotypes by combining the findings from the first phase with users' feedback data.","Results showed that these algorithms performed more effectively than relying solely on feedback data for gender inference.","Additionally, we quantified the extent of gender stereotypes to evaluate their broader impact on digital computational science.","The latter part of the study utilized two major movie recommender datasets: MovieLens 1M and Yahoo!Movie.","Detailed experimental information is available on our GitHub repository: https://github.com/fr-iit/GSMRS"],"url":"http://arxiv.org/abs/2501.04420v1"}
{"created":"2025-01-08 11:07:43","title":"Not All Bonds Are Created Equal: Dyadic Latent Class Models for Relational Event Data","abstract":"Dynamic social networks can be conceptualized as sequences of dyadic interactions between individuals over time. The relational event model has been the workhorse to analyze such interaction sequences in empirical social network research. When addressing possible unobserved heterogeneity in the interaction mechanisms, standard approaches, such as the stochastic block model, aim to cluster the variation at the actor level. Though useful, the implied latent structure of the adjacency matrix is restrictive which may lead to biased interpretations and insights. To address this shortcoming, we introduce a more flexible dyadic latent class relational event model (DLC-REM) that captures the unobserved heterogeneity at the dyadic level. Through numerical simulations, we provide a proof of concept demonstrating that this approach is more general than latent actor-level approaches. To illustrate the applicability of the model, we apply it to a dataset of militarized interstate conflicts between countries.","sentences":["Dynamic social networks can be conceptualized as sequences of dyadic interactions between individuals over time.","The relational event model has been the workhorse to analyze such interaction sequences in empirical social network research.","When addressing possible unobserved heterogeneity in the interaction mechanisms, standard approaches, such as the stochastic block model, aim to cluster the variation at the actor level.","Though useful, the implied latent structure of the adjacency matrix is restrictive which may lead to biased interpretations and insights.","To address this shortcoming, we introduce a more flexible dyadic latent class relational event model (DLC-REM) that captures the unobserved heterogeneity at the dyadic level.","Through numerical simulations, we provide a proof of concept demonstrating that this approach is more general than latent actor-level approaches.","To illustrate the applicability of the model, we apply it to a dataset of militarized interstate conflicts between countries."],"url":"http://arxiv.org/abs/2501.04418v1"}
{"created":"2025-01-08 10:49:13","title":"User Simulation in the Era of Generative AI: User Modeling, Synthetic Data Generation, and System Evaluation","abstract":"User simulation is an emerging interdisciplinary topic with multiple critical applications in the era of Generative AI. It involves creating an intelligent agent that mimics the actions of a human user interacting with an AI system, enabling researchers to model and analyze user behaviour, generate synthetic data for training, and evaluate interactive AI systems in a controlled and reproducible manner. User simulation has profound implications for diverse fields and plays a vital role in the pursuit of Artificial General Intelligence. This paper provides an overview of user simulation, highlighting its key applications, connections to various disciplines, and outlining future research directions to advance this increasingly important technology.","sentences":["User simulation is an emerging interdisciplinary topic with multiple critical applications in the era of Generative AI.","It involves creating an intelligent agent that mimics the actions of a human user interacting with an AI system, enabling researchers to model and analyze user behaviour, generate synthetic data for training, and evaluate interactive AI systems in a controlled and reproducible manner.","User simulation has profound implications for diverse fields and plays a vital role in the pursuit of Artificial General Intelligence.","This paper provides an overview of user simulation, highlighting its key applications, connections to various disciplines, and outlining future research directions to advance this increasingly important technology."],"url":"http://arxiv.org/abs/2501.04410v1"}
{"created":"2025-01-08 10:49:06","title":"Lossless Privacy-Preserving Aggregation for Decentralized Federated Learning","abstract":"Privacy concerns arise as sensitive data proliferate. Despite decentralized federated learning (DFL) aggregating gradients from neighbors to avoid direct data transmission, it still poses indirect data leaks from the transmitted gradients. Existing privacy-preserving methods for DFL add noise to gradients. They either diminish the model predictive accuracy or suffer from ineffective gradient protection. In this paper, we propose a novel lossless privacy-preserving aggregation rule named LPPA to enhance gradient protection as much as possible but without loss of DFL model predictive accuracy. LPPA subtly injects the noise difference between the sent and received noise into transmitted gradients for gradient protection. The noise difference incorporates neighbors' randomness for each client, effectively safeguarding against data leaks. LPPA employs the noise flow conservation theory to ensure that the noise impact can be globally eliminated. The global sum of all noise differences remains zero, ensuring that accurate gradient aggregation is unaffected and the model accuracy remains intact. We theoretically prove that the privacy-preserving capacity of LPPA is \\sqrt{2} times greater than that of noise addition, while maintaining comparable model accuracy to the standard DFL aggregation without noise injection. Experimental results verify the theoretical findings and show that LPPA achieves a 13% mean improvement in accuracy over noise addition. We also demonstrate the effectiveness of LPPA in protecting raw data and guaranteeing lossless model accuracy.","sentences":["Privacy concerns arise as sensitive data proliferate.","Despite decentralized federated learning (DFL) aggregating gradients from neighbors to avoid direct data transmission, it still poses indirect data leaks from the transmitted gradients.","Existing privacy-preserving methods for DFL add noise to gradients.","They either diminish the model predictive accuracy or suffer from ineffective gradient protection.","In this paper, we propose a novel lossless privacy-preserving aggregation rule named LPPA to enhance gradient protection as much as possible but without loss of DFL model predictive accuracy.","LPPA subtly injects the noise difference between the sent and received noise into transmitted gradients for gradient protection.","The noise difference incorporates neighbors' randomness for each client, effectively safeguarding against data leaks.","LPPA employs the noise flow conservation theory to ensure that the noise impact can be globally eliminated.","The global sum of all noise differences remains zero, ensuring that accurate gradient aggregation is unaffected and the model accuracy remains intact.","We theoretically prove that the privacy-preserving capacity of LPPA is \\sqrt{2} times greater than that of noise addition, while maintaining comparable model accuracy to the standard DFL aggregation without noise injection.","Experimental results verify the theoretical findings and show that LPPA achieves a 13% mean improvement in accuracy over noise addition.","We also demonstrate the effectiveness of LPPA in protecting raw data and guaranteeing lossless model accuracy."],"url":"http://arxiv.org/abs/2501.04409v1"}
{"created":"2025-01-08 10:42:48","title":"Resource Allocation for the Training of Image Semantic Communication Networks","abstract":"Semantic communication is a new paradigm that aims at providing more efficient communication for the next-generation wireless network. It focuses on transmitting extracted, meaningful information instead of the raw data. However, deep learning-enabled image semantic communication models often require a significant amount of time and energy for training, which is unacceptable, especially for mobile devices. To solve this challenge, our paper first introduces a distributed image semantic communication system where the base station and local devices will collaboratively train the models for uplink communication. Furthermore, we formulate a joint optimization problem to balance time and energy consumption on the local devices during training while ensuring effective model performance. An adaptable resource allocation algorithm is proposed to meet requirements under different scenarios, and its time complexity, solution quality, and convergence are thoroughly analyzed. Experimental results demonstrate the superiority of our algorithm in resource allocation optimization against existing benchmarks and discuss its impact on the performance of image semantic communication systems.","sentences":["Semantic communication is a new paradigm that aims at providing more efficient communication for the next-generation wireless network.","It focuses on transmitting extracted, meaningful information instead of the raw data.","However, deep learning-enabled image semantic communication models often require a significant amount of time and energy for training, which is unacceptable, especially for mobile devices.","To solve this challenge, our paper first introduces a distributed image semantic communication system where the base station and local devices will collaboratively train the models for uplink communication.","Furthermore, we formulate a joint optimization problem to balance time and energy consumption on the local devices during training while ensuring effective model performance.","An adaptable resource allocation algorithm is proposed to meet requirements under different scenarios, and its time complexity, solution quality, and convergence are thoroughly analyzed.","Experimental results demonstrate the superiority of our algorithm in resource allocation optimization against existing benchmarks and discuss its impact on the performance of image semantic communication systems."],"url":"http://arxiv.org/abs/2501.04408v1"}
{"created":"2025-01-08 10:29:35","title":"Tracking UWB Devices Through Radio Frequency Fingerprinting Is Possible","abstract":"Ultra-wideband (UWB) is a state-of-the-art technology designed for applications requiring centimeter-level localization. Its widespread adoption by smartphone manufacturer naturally raises security and privacy concerns. Successfully implementing Radio Frequency Fingerprinting (RFF) to UWB could enable physical layer security, but might also allow undesired tracking of the devices. The scope of this paper is to explore the feasibility of applying RFF to UWB and investigates how well this technique generalizes across different environments. We collected a realistic dataset using off-the-shelf UWB devices with controlled variation in device positioning. Moreover, we developed an improved deep learning pipeline to extract the hardware signature from the signal data. In stable conditions, the extracted RFF achieves over 99% accuracy. While the accuracy decreases in more changing environments, we still obtain up to 76% accuracy in untrained locations.","sentences":["Ultra-wideband (UWB) is a state-of-the-art technology designed for applications requiring centimeter-level localization.","Its widespread adoption by smartphone manufacturer naturally raises security and privacy concerns.","Successfully implementing Radio Frequency Fingerprinting (RFF) to UWB could enable physical layer security, but might also allow undesired tracking of the devices.","The scope of this paper is to explore the feasibility of applying RFF to UWB and investigates how well this technique generalizes across different environments.","We collected a realistic dataset using off-the-shelf UWB devices with controlled variation in device positioning.","Moreover, we developed an improved deep learning pipeline to extract the hardware signature from the signal data.","In stable conditions, the extracted RFF achieves over 99% accuracy.","While the accuracy decreases in more changing environments, we still obtain up to 76% accuracy in untrained locations."],"url":"http://arxiv.org/abs/2501.04401v1"}
{"created":"2025-01-08 10:22:22","title":"Implementation Of Wildlife Observation System","abstract":"By entering the habitats of wild animals, wildlife watchers can engage closely with them. There are some wild animals that are not always safe to approach. Therefore, we suggest this system for observing wildlife. Android phones can be used by users to see live events. Wildlife observers can thus get a close-up view of wild animals by employing this robotic vehicle. The commands are delivered to the system via a Wi-Fi module. As we developed the technology to enable our robot to deal with the challenges of maintaining continuous surveillance of a target, we found that our robot needed to be able to move silently and purposefully when monitoring a natural target without being noticed. After processing the data, the computer sends commands to the motors to turn on. The driver motors, which deliver the essential signal outputs to drive the vehicle movement, are now in charge of driving the motors.","sentences":["By entering the habitats of wild animals, wildlife watchers can engage closely with them.","There are some wild animals that are not always safe to approach.","Therefore, we suggest this system for observing wildlife.","Android phones can be used by users to see live events.","Wildlife observers can thus get a close-up view of wild animals by employing this robotic vehicle.","The commands are delivered to the system via a Wi-Fi module.","As we developed the technology to enable our robot to deal with the challenges of maintaining continuous surveillance of a target, we found that our robot needed to be able to move silently and purposefully when monitoring a natural target without being noticed.","After processing the data, the computer sends commands to the motors to turn on.","The driver motors, which deliver the essential signal outputs to drive the vehicle movement, are now in charge of driving the motors."],"url":"http://arxiv.org/abs/2501.04398v1"}
{"created":"2025-01-08 10:10:29","title":"SEO: Stochastic Experience Optimization for Large Language Models","abstract":"Large Language Models (LLMs) can benefit from useful experiences to improve their performance on specific tasks. However, finding helpful experiences for different LLMs is not obvious, since it is unclear what experiences suit specific LLMs. Previous studies intended to automatically find useful experiences using LLMs, while it is difficult to ensure the effectiveness of the obtained experience. In this paper, we propose Stochastic Experience Optimization (SEO), an iterative approach that finds optimized model-specific experience without modifying model parameters through experience update in natural language. In SEO, we propose a stochastic validation method to ensure the update direction of experience, avoiding unavailing updates. Experimental results on three tasks for three LLMs demonstrate that experiences optimized by SEO can achieve consistently improved performance. Further analysis indicates that SEO-optimized experience can generalize to out-of-distribution data, boosting the performance of LLMs on similar tasks.","sentences":["Large Language Models (LLMs) can benefit from useful experiences to improve their performance on specific tasks.","However, finding helpful experiences for different LLMs is not obvious, since it is unclear what experiences suit specific LLMs.","Previous studies intended to automatically find useful experiences using LLMs, while it is difficult to ensure the effectiveness of the obtained experience.","In this paper, we propose Stochastic Experience Optimization (SEO), an iterative approach that finds optimized model-specific experience without modifying model parameters through experience update in natural language.","In SEO, we propose a stochastic validation method to ensure the update direction of experience, avoiding unavailing updates.","Experimental results on three tasks for three LLMs demonstrate that experiences optimized by SEO can achieve consistently improved performance.","Further analysis indicates that SEO-optimized experience can generalize to out-of-distribution data, boosting the performance of LLMs on similar tasks."],"url":"http://arxiv.org/abs/2501.04393v1"}
{"created":"2025-01-08 09:58:29","title":"Evidence-based multimodal fusion on structured EHRs and free-text notes for ICU outcome prediction","abstract":"Objective: Accurate Intensive Care Unit (ICU) outcome prediction is critical for improving patient treatment quality and ICU resource allocation. Existing research mainly focuses on structured data and lacks effective frameworks to integrate clinical notes from heterogeneous electronic health records (EHRs). This study aims to explore a multimodal framework based on evidence theory that can effectively combine heterogeneous structured EHRs and free-text notes for accurate and reliable ICU outcome prediction. Materials and Methods: We proposed an evidence-based multimodal fusion framework to predict ICU outcomes, including mortality and prolonged length of stay (PLOS), by utilizing both structured EHR data and free-text notes from the MIMIC-III database. We compare the performance against baseline models that use only structured EHRs, free-text notes, or existing multimodal approaches. Results: The results demonstrate that the evidence-based multimodal fusion model achieved both accurate and reliable prediction. Specifically, it outperformed the best baseline by 1.05%/1.02% in BACC, 9.74%/6.04% in F1 score, 1.28%/0.9% in AUROC, and 6.21%/2.68% in AUPRC for predicting mortality and PLOS, respectively. Additionally, it improved the reliability of the predictions with a 26.8%/15.1% reduction in the Brier score and a 25.0%/13.3% reduction in negative log-likelihood. Conclusion: This study demonstrates that the evidence-based multimodal fusion framework can serve as a strong baseline for predictions using structured EHRs and free-text notes. It effectively reduces false positives, which can help improve the allocation of medical resources in the ICU. This framework can be further applied to analyze multimodal EHRs for other clinical tasks.","sentences":["Objective: Accurate Intensive Care Unit (ICU) outcome prediction is critical for improving patient treatment quality and ICU resource allocation.","Existing research mainly focuses on structured data and lacks effective frameworks to integrate clinical notes from heterogeneous electronic health records (EHRs).","This study aims to explore a multimodal framework based on evidence theory that can effectively combine heterogeneous structured EHRs and free-text notes for accurate and reliable ICU outcome prediction.","Materials and Methods: We proposed an evidence-based multimodal fusion framework to predict ICU outcomes, including mortality and prolonged length of stay (PLOS), by utilizing both structured EHR data and free-text notes from the MIMIC-III database.","We compare the performance against baseline models that use only structured EHRs, free-text notes, or existing multimodal approaches.","Results:","The results demonstrate that the evidence-based multimodal fusion model achieved both accurate and reliable prediction.","Specifically, it outperformed the best baseline by 1.05%/1.02% in BACC, 9.74%/6.04% in F1 score, 1.28%/0.9% in AUROC, and 6.21%/2.68% in AUPRC for predicting mortality and PLOS, respectively.","Additionally, it improved the reliability of the predictions with a 26.8%/15.1% reduction in the Brier score and a 25.0%/13.3% reduction in negative log-likelihood.","Conclusion: This study demonstrates that the evidence-based multimodal fusion framework can serve as a strong baseline for predictions using structured EHRs and free-text notes.","It effectively reduces false positives, which can help improve the allocation of medical resources in the ICU.","This framework can be further applied to analyze multimodal EHRs for other clinical tasks."],"url":"http://arxiv.org/abs/2501.04389v1"}
{"created":"2025-01-08 09:28:25","title":"Instructive3D: Editing Large Reconstruction Models with Text Instructions","abstract":"Transformer based methods have enabled users to create, modify, and comprehend text and image data. Recently proposed Large Reconstruction Models (LRMs) further extend this by providing the ability to generate high-quality 3D models with the help of a single object image. These models, however, lack the ability to manipulate or edit the finer details, such as adding standard design patterns or changing the color and reflectance of the generated objects, thus lacking fine-grained control that may be very helpful in domains such as augmented reality, animation and gaming. Naively training LRMs for this purpose would require generating precisely edited images and 3D object pairs, which is computationally expensive. In this paper, we propose Instructive3D, a novel LRM based model that integrates generation and fine-grained editing, through user text prompts, of 3D objects into a single model. We accomplish this by adding an adapter that performs a diffusion process conditioned on a text prompt specifying edits in the triplane latent space representation of 3D object models. Our method does not require the generation of edited 3D objects. Additionally, Instructive3D allows us to perform geometrically consistent modifications, as the edits done through user-defined text prompts are applied to the triplane latent representation thus enhancing the versatility and precision of 3D objects generated. We compare the objects generated by Instructive3D and a baseline that first generates the 3D object meshes using a standard LRM model and then edits these 3D objects using text prompts when images are provided from the Objaverse LVIS dataset. We find that Instructive3D produces qualitatively superior 3D objects with the properties specified by the edit prompts.","sentences":["Transformer based methods have enabled users to create, modify, and comprehend text and image data.","Recently proposed Large Reconstruction Models (LRMs) further extend this by providing the ability to generate high-quality 3D models with the help of a single object image.","These models, however, lack the ability to manipulate or edit the finer details, such as adding standard design patterns or changing the color and reflectance of the generated objects, thus lacking fine-grained control that may be very helpful in domains such as augmented reality, animation and gaming.","Naively training LRMs for this purpose would require generating precisely edited images and 3D object pairs, which is computationally expensive.","In this paper, we propose Instructive3D, a novel LRM based model that integrates generation and fine-grained editing, through user text prompts, of 3D objects into a single model.","We accomplish this by adding an adapter that performs a diffusion process conditioned on a text prompt specifying edits in the triplane latent space representation of 3D object models.","Our method does not require the generation of edited 3D objects.","Additionally, Instructive3D allows us to perform geometrically consistent modifications, as the edits done through user-defined text prompts are applied to the triplane latent representation thus enhancing the versatility and precision of 3D objects generated.","We compare the objects generated by Instructive3D and a baseline that first generates the 3D object meshes using a standard LRM model and then edits these 3D objects using text prompts when images are provided from the Objaverse LVIS dataset.","We find that Instructive3D produces qualitatively superior 3D objects with the properties specified by the edit prompts."],"url":"http://arxiv.org/abs/2501.04374v1"}
{"created":"2025-01-08 09:03:16","title":"An innovative data collection method to eliminate the preprocessing phase in web usage mining","abstract":"The underlying data source for web usage mining (WUM) is commonly thought to be server logs. However, access log files ensure quite limited data about the clients. Identifying sessions from this messy data takes a considerable effort, and operations performed for this purpose do not always yield excellent results. Also, this data cannot be used for web analytics efficiently. This study proposes an innovative method for user tracking, session management, and collecting web usage data. The method is mainly based on a new approach for using collected data for web analytics extraction as the data source in web usage mining. An application-based API has been developed with a different strategy from conventional client-side methods to obtain and process log data. The log data has been successfully gathered by integrating the technique into an enterprise web application. The results reveal that the homogeneous structured data collected and stored with this method is more convenient to browse, filter, and process than web server logs. This data stored on a relational database can be used effortlessly as a reliable data source for high-performance web usage mining activity, real-time web analytics, or a functional recommendation system.","sentences":["The underlying data source for web usage mining (WUM) is commonly thought to be server logs.","However, access log files ensure quite limited data about the clients.","Identifying sessions from this messy data takes a considerable effort, and operations performed for this purpose do not always yield excellent results.","Also, this data cannot be used for web analytics efficiently.","This study proposes an innovative method for user tracking, session management, and collecting web usage data.","The method is mainly based on a new approach for using collected data for web analytics extraction as the data source in web usage mining.","An application-based API has been developed with a different strategy from conventional client-side methods to obtain and process log data.","The log data has been successfully gathered by integrating the technique into an enterprise web application.","The results reveal that the homogeneous structured data collected and stored with this method is more convenient to browse, filter, and process than web server logs.","This data stored on a relational database can be used effortlessly as a reliable data source for high-performance web usage mining activity, real-time web analytics, or a functional recommendation system."],"url":"http://arxiv.org/abs/2501.04364v1"}
{"created":"2025-01-08 09:01:17","title":"Neighborhood Disparities in Smart City Service Adoption","abstract":"While local governments have invested heavily in smart city infrastructure, significant disparities in adopting these services remain in urban areas. The success of many user-facing smart city technologies requires understanding barriers to adoption, including persistent inequalities in urban areas. An analysis of a random sample telephone survey (n=489) in four neighborhoods of Tel Aviv merged with digital municipal services usage data found that neighborhood residency influences the reasons why residents adopt resident-facing smart city services, as well as individual-level factors. Structured Equation Modeling shows that neighborhood residency is related to digital proficiency and privacy perceptions beyond demographic factors and that those influence the adoption of smart-city services. We summarize the paper by discussing why and how place effects must be considered in further research in smart cities and the study and mitigation of digital inequality.","sentences":["While local governments have invested heavily in smart city infrastructure, significant disparities in adopting these services remain in urban areas.","The success of many user-facing smart city technologies requires understanding barriers to adoption, including persistent inequalities in urban areas.","An analysis of a random sample telephone survey (n=489) in four neighborhoods of Tel Aviv merged with digital municipal services usage data found that neighborhood residency influences the reasons why residents adopt resident-facing smart city services, as well as individual-level factors.","Structured Equation Modeling shows that neighborhood residency is related to digital proficiency and privacy perceptions beyond demographic factors and that those influence the adoption of smart-city services.","We summarize the paper by discussing why and how place effects must be considered in further research in smart cities and the study and mitigation of digital inequality."],"url":"http://arxiv.org/abs/2501.04363v1"}
{"created":"2025-01-08 08:49:52","title":"Online Gaussian Test-Time Adaptation of Vision-Language Models","abstract":"Online test-time adaptation (OTTA) of vision-language models (VLMs) has recently garnered increased attention to take advantage of data observed along a stream to improve future predictions. Unfortunately, existing methods rely on dataset-specific hyperparameters, significantly limiting their adaptability to unseen tasks. In response, we propose Online Gaussian Adaptation (OGA), a novel method that models the likelihoods of visual features using Gaussian distributions and incorporates zero-shot priors into an interpretable Maximum A Posteriori (MAP) estimation framework with fixed hyper-parameters across all datasets. We demonstrate that OGA outperforms state-of-the-art methods on most datasets and runs. Additionally, we show that combining OTTA with popular few-shot techniques (a practical yet overlooked setting in prior research) is highly beneficial. Furthermore, our experimental study reveals that common OTTA evaluation protocols, which average performance over at most three runs per dataset, are inadequate due to the substantial variability observed across runs for all OTTA methods. Therefore, we advocate for more rigorous evaluation practices, including increasing the number of runs and considering additional quantitative metrics, such as our proposed Expected Tail Accuracy (ETA), calculated as the average accuracy in the worst 10% of runs. We hope these contributions will encourage more rigorous and diverse evaluation practices in the OTTA community. Code is available at https://github.com/cfuchs2023/OGA .","sentences":["Online test-time adaptation (OTTA) of vision-language models (VLMs) has recently garnered increased attention to take advantage of data observed along a stream to improve future predictions.","Unfortunately, existing methods rely on dataset-specific hyperparameters, significantly limiting their adaptability to unseen tasks.","In response, we propose Online Gaussian Adaptation (OGA), a novel method that models the likelihoods of visual features using Gaussian distributions and incorporates zero-shot priors into an interpretable Maximum A Posteriori (MAP) estimation framework with fixed hyper-parameters across all datasets.","We demonstrate that OGA outperforms state-of-the-art methods on most datasets and runs.","Additionally, we show that combining OTTA with popular few-shot techniques (a practical yet overlooked setting in prior research) is highly beneficial.","Furthermore, our experimental study reveals that common OTTA evaluation protocols, which average performance over at most three runs per dataset, are inadequate due to the substantial variability observed across runs for all OTTA methods.","Therefore, we advocate for more rigorous evaluation practices, including increasing the number of runs and considering additional quantitative metrics, such as our proposed Expected Tail Accuracy (ETA), calculated as the average accuracy in the worst 10% of runs.","We hope these contributions will encourage more rigorous and diverse evaluation practices in the OTTA community.","Code is available at https://github.com/cfuchs2023/OGA ."],"url":"http://arxiv.org/abs/2501.04352v1"}
{"created":"2025-01-08 08:42:51","title":"Keyword Search in the Deep Web","abstract":"The Deep Web is constituted by data that are accessible through Web pages, but not readily indexable by search engines as they are returned in dynamic pages. In this paper we propose a conceptual framework for answering keyword queries on Deep Web sources represented as relational tables with so-called access limitations. We formalize the notion of optimal answer, characterize queries for which an answer can be found, and present a method for query processing based on the construction of a query plan that minimizes the accesses to the data sources.","sentences":["The Deep Web is constituted by data that are accessible through Web pages, but not readily indexable by search engines as they are returned in dynamic pages.","In this paper we propose a conceptual framework for answering keyword queries on Deep Web sources represented as relational tables with so-called access limitations.","We formalize the notion of optimal answer, characterize queries for which an answer can be found, and present a method for query processing based on the construction of a query plan that minimizes the accesses to the data sources."],"url":"http://arxiv.org/abs/2501.04347v1"}
{"created":"2025-01-08 07:47:43","title":"Navigating the Designs of Privacy-Preserving Fine-tuning for Large Language Models","abstract":"Instruction tuning has proven effective in enhancing Large Language Models' (LLMs) performance on downstream tasks. However, real-world fine-tuning faces inherent conflicts between model providers' intellectual property protection, clients' data privacy requirements, and tuning costs. While recent approaches like split learning and offsite tuning demonstrate promising architectures for privacy-preserving fine-tuning, there is a gap in systematically addressing the multidimensional trade-offs required for diverse real-world deployments. We propose several indicative evaluation metrics to guide design trade-offs for privacy-preserving fine-tuning and a series of example designs, collectively named GuardedTuning; they result from novel combinations of system architectures with adapted privacy-enhancement methods and emerging computation techniques. Each design represents distinct trade-offs across model utility, privacy guarantees, and costs. Experimental results demonstrate that these designs protect against data reconstruction attacks while maintaining competitive fine-tuning performance.","sentences":["Instruction tuning has proven effective in enhancing Large Language Models' (LLMs) performance on downstream tasks.","However, real-world fine-tuning faces inherent conflicts between model providers' intellectual property protection, clients' data privacy requirements, and tuning costs.","While recent approaches like split learning and offsite tuning demonstrate promising architectures for privacy-preserving fine-tuning, there is a gap in systematically addressing the multidimensional trade-offs required for diverse real-world deployments.","We propose several indicative evaluation metrics to guide design trade-offs for privacy-preserving fine-tuning and a series of example designs, collectively named GuardedTuning; they result from novel combinations of system architectures with adapted privacy-enhancement methods and emerging computation techniques.","Each design represents distinct trade-offs across model utility, privacy guarantees, and costs.","Experimental results demonstrate that these designs protect against data reconstruction attacks while maintaining competitive fine-tuning performance."],"url":"http://arxiv.org/abs/2501.04323v2"}
{"created":"2025-01-08 07:42:54","title":"Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts","abstract":"Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes. Running VLMs on edge devices has become a challenge for their widespread application. There are several efficient VLM efforts, but they often sacrifice linguistic capabilities to enhance multimodal abilities, or require extensive training. To address this quandary,we introduce the innovative framework of Efficient Vision Language Models with Elastic Visual Experts (Eve). By strategically incorporating adaptable visual expertise at multiple stages of training, Eve strikes a balance between preserving linguistic abilities and augmenting multimodal capabilities. This balanced approach results in a versatile model with only 1.8B parameters that delivers significant improvements in both multimodal and linguistic tasks. Notably, in configurations below 3B parameters, Eve distinctly outperforms in language benchmarks and achieves state-of-the-art results 68.87% in VLM Benchmarks. Additionally, its multimodal accuracy outstrips that of the larger 7B LLaVA-1.5 model.","sentences":["Multimodal vision language models (VLMs) have made significant progress with the support of continuously increasing model sizes and data volumes.","Running VLMs on edge devices has become a challenge for their widespread application.","There are several efficient VLM efforts, but they often sacrifice linguistic capabilities to enhance multimodal abilities, or require extensive training.","To address this quandary,we introduce the innovative framework of Efficient Vision Language Models with Elastic Visual Experts (Eve).","By strategically incorporating adaptable visual expertise at multiple stages of training, Eve strikes a balance between preserving linguistic abilities and augmenting multimodal capabilities.","This balanced approach results in a versatile model with only 1.8B parameters that delivers significant improvements in both multimodal and linguistic tasks.","Notably, in configurations below 3B parameters, Eve distinctly outperforms in language benchmarks and achieves state-of-the-art results 68.87% in VLM Benchmarks.","Additionally, its multimodal accuracy outstrips that of the larger 7B LLaVA-1.5 model."],"url":"http://arxiv.org/abs/2501.04322v1"}
{"created":"2025-01-08 07:32:54","title":"VerifBFL: Leveraging zk-SNARKs for A Verifiable Blockchained Federated Learning","abstract":"Blockchain-based Federated Learning (FL) is an emerging decentralized machine learning paradigm that enables model training without relying on a central server. Although some BFL frameworks are considered privacy-preserving, they are still vulnerable to various attacks, including inference and model poisoning. Additionally, most of these solutions employ strong trust assumptions among all participating entities or introduce incentive mechanisms to encourage collaboration, making them susceptible to multiple security flaws. This work presents VerifBFL, a trustless, privacy-preserving, and verifiable federated learning framework that integrates blockchain technology and cryptographic protocols. By employing zero-knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARKs) and incrementally verifiable computation (IVC), VerifBFL ensures the verifiability of both local training and aggregation processes. The proofs of training and aggregation are verified on-chain, guaranteeing the integrity and auditability of each participant's contributions. To protect training data from inference attacks, VerifBFL leverages differential privacy. Finally, to demonstrate the efficiency of the proposed protocols, we built a proof of concept using emerging tools. The results show that generating proofs for local training and aggregation in VerifBFL takes less than 81s and 2s, respectively, while verifying them on-chain takes less than 0.6s.","sentences":["Blockchain-based Federated Learning (FL) is an emerging decentralized machine learning paradigm that enables model training without relying on a central server.","Although some BFL frameworks are considered privacy-preserving, they are still vulnerable to various attacks, including inference and model poisoning.","Additionally, most of these solutions employ strong trust assumptions among all participating entities or introduce incentive mechanisms to encourage collaboration, making them susceptible to multiple security flaws.","This work presents VerifBFL, a trustless, privacy-preserving, and verifiable federated learning framework that integrates blockchain technology and cryptographic protocols.","By employing zero-knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARKs) and incrementally verifiable computation (IVC), VerifBFL ensures the verifiability of both local training and aggregation processes.","The proofs of training and aggregation are verified on-chain, guaranteeing the integrity and auditability of each participant's contributions.","To protect training data from inference attacks, VerifBFL leverages differential privacy.","Finally, to demonstrate the efficiency of the proposed protocols, we built a proof of concept using emerging tools.","The results show that generating proofs for local training and aggregation in VerifBFL takes less than 81s and 2s, respectively, while verifying them on-chain takes less than 0.6s."],"url":"http://arxiv.org/abs/2501.04319v1"}
{"created":"2025-01-08 07:10:50","title":"Molecular HDD Logic for Encrypted Massive Data Storage","abstract":"Organic memories, with small dimension, fast speed and long retention features, are considered as promising candidates for massive data archiving. In order to satisfy the re-quirements for ultra-low power and high-security information storage, we design a concep-tual molecular hard-disk (HDD) logic scheme that is capable to execute in-situ encryption of massive data in pW/bit power-consumption range. Beneficial from the coupled mechanism of counter-balanced redox reaction and local ion drifting, the basic HDD unit consisting of ~ 200 self-assembled RuXLPH molecules in a monolayer (SAM) configuration undergoes unique conductance modulation with continuous, symmetric and low-power switching char-acteristics. 96-state memory performance, which allows 6-bit data storage and single-unit one-step XOR operation, is realized in the RuXLPH SAM sample. Through single-unit XOR manipulation of the pixel information, in-situ bitwise encryption of the Mogao Grottoes mural images stored in the molecular HDD is demonstrated.","sentences":["Organic memories, with small dimension, fast speed and long retention features, are considered as promising candidates for massive data archiving.","In order to satisfy the re-quirements for ultra-low power and high-security information storage, we design a concep-tual molecular hard-disk (HDD) logic scheme that is capable to execute in-situ encryption of massive data in pW/bit power-consumption range.","Beneficial from the coupled mechanism of counter-balanced redox reaction and local ion drifting, the basic HDD unit consisting of ~ 200 self-assembled RuXLPH molecules in a monolayer (SAM) configuration undergoes unique conductance modulation with continuous, symmetric and low-power switching char-acteristics.","96-state memory performance, which allows 6-bit data storage and single-unit one-step XOR operation, is realized in the RuXLPH SAM sample.","Through single-unit XOR manipulation of the pixel information, in-situ bitwise encryption of the Mogao Grottoes mural images stored in the molecular HDD is demonstrated."],"url":"http://arxiv.org/abs/2501.04314v1"}
{"created":"2025-01-08 06:34:32","title":"Physics-Informed Super-Resolution Diffusion for 6D Phase Space Diagnostics","abstract":"Adaptive physics-informed super-resolution diffusion is developed for non-invasive virtual diagnostics of the 6D phase space density of charged particle beams. An adaptive variational autoencoder (VAE) embeds initial beam condition images and scalar measurements to a low-dimensional latent space from which a 326 pixel 6D tensor representation of the beam's 6D phase space density is generated. Projecting from a 6D tensor generates physically consistent 2D projections. Physics-guided super-resolution diffusion transforms low-resolution images of the 6D density to high resolution 256x256 pixel images. Un-supervised adaptive latent space tuning enables tracking of time-varying beams without knowledge of time-varying initial conditions. The method is demonstrated with experimental data and multi-particle simulations at the HiRES UED. The general approach is applicable to a wide range of complex dynamic systems evolving in high-dimensional phase space. The method is shown to be robust to distribution shift without re-training.","sentences":["Adaptive physics-informed super-resolution diffusion is developed for non-invasive virtual diagnostics of the 6D phase space density of charged particle beams.","An adaptive variational autoencoder (VAE) embeds initial beam condition images and scalar measurements to a low-dimensional latent space from which a 326 pixel 6D tensor representation of the beam's 6D phase space density is generated.","Projecting from a 6D tensor generates physically consistent 2D projections.","Physics-guided super-resolution diffusion transforms low-resolution images of the 6D density to high resolution 256x256 pixel images.","Un-supervised adaptive latent space tuning enables tracking of time-varying beams without knowledge of time-varying initial conditions.","The method is demonstrated with experimental data and multi-particle simulations at the HiRES UED.","The general approach is applicable to a wide range of complex dynamic systems evolving in high-dimensional phase space.","The method is shown to be robust to distribution shift without re-training."],"url":"http://arxiv.org/abs/2501.04305v1"}
{"created":"2025-01-08 06:27:07","title":"Multimodal Graph Constrastive Learning and Prompt for ChartQA","abstract":"ChartQA presents significant challenges due to the complex distribution of chart elements and the implicit patterns embedded within the underlying data. In this chapter, we have developed a joint multimodal scene graph for charts, explicitly representing the relationships between chart elements and their associated patterns.   Our proposed multimodal scene graph consists of two components: a visual graph and a textual graph, each designed to capture the structural and semantic information within the chart. To unify representations across these different modalities, we introduce a multimodal graph contrastive learning approach that learns unified representations by maximizing similarity between nodes representing the same object across multimodal graphs. The learned graph representations can be seamlessly incorporated into a transformer decoder as a soft prompt.   Additionally, given the growing need for Multimodal Large Language Models (MLLMs) in zero-shot scenarios, we have designed Chain-of-Thought (CoT) prompts for MLLMs to reduce hallucinations. We tested both methods on public benchmarks such as ChartQA, OpenCQA, and ChartX, demonstrating improved performance and validating the effectiveness of our proposed methods.","sentences":["ChartQA presents significant challenges due to the complex distribution of chart elements and the implicit patterns embedded within the underlying data.","In this chapter, we have developed a joint multimodal scene graph for charts, explicitly representing the relationships between chart elements and their associated patterns.   ","Our proposed multimodal scene graph consists of two components: a visual graph and a textual graph, each designed to capture the structural and semantic information within the chart.","To unify representations across these different modalities, we introduce a multimodal graph contrastive learning approach that learns unified representations by maximizing similarity between nodes representing the same object across multimodal graphs.","The learned graph representations can be seamlessly incorporated into a transformer decoder as a soft prompt.   ","Additionally, given the growing need for Multimodal Large Language Models (MLLMs) in zero-shot scenarios, we have designed Chain-of-Thought (CoT) prompts for MLLMs to reduce hallucinations.","We tested both methods on public benchmarks such as ChartQA, OpenCQA, and ChartX, demonstrating improved performance and validating the effectiveness of our proposed methods."],"url":"http://arxiv.org/abs/2501.04303v1"}
{"created":"2025-01-08 06:18:32","title":"Handling Incomplete Heterogeneous Data using a Data-Dependent Kernel","abstract":"Handling incomplete data in real-world applications is a critical challenge due to two key limitations of existing methods: (i) they are primarily designed for numeric data and struggle with categorical or heterogeneous/mixed datasets; (ii) they assume that data is missing completely at random, which is often not the case in practice -- in reality, data is missing in patterns, leading to biased results if these patterns are not accounted for. To address these two limitations, this paper presents a novel approach to handling missing values using the Probability Mass Similarity Kernel (PMK), a data-dependent kernel, which does not make any assumptions about data types and missing mechanisms. It eliminates the need for prior knowledge or extensive pre-processing steps and instead leverages the distribution of observed data. Our method unifies the representation of diverse data types by capturing more meaningful pairwise similarities and enhancing downstream performance. We evaluated our approach across over 10 datasets with numerical-only, categorical-only, and mixed features under different missing mechanisms and rates. Across both classification and clustering tasks, our approach consistently outperformed existing techniques, demonstrating its robustness and effectiveness in managing incomplete heterogeneous data.","sentences":["Handling incomplete data in real-world applications is a critical challenge due to two key limitations of existing methods: (i) they are primarily designed for numeric data and struggle with categorical or heterogeneous/mixed datasets; (ii) they assume that data is missing completely at random, which is often not the case in practice -- in reality, data is missing in patterns, leading to biased results if these patterns are not accounted for.","To address these two limitations, this paper presents a novel approach to handling missing values using the Probability Mass Similarity Kernel (PMK), a data-dependent kernel, which does not make any assumptions about data types and missing mechanisms.","It eliminates the need for prior knowledge or extensive pre-processing steps and instead leverages the distribution of observed data.","Our method unifies the representation of diverse data types by capturing more meaningful pairwise similarities and enhancing downstream performance.","We evaluated our approach across over 10 datasets with numerical-only, categorical-only, and mixed features under different missing mechanisms and rates.","Across both classification and clustering tasks, our approach consistently outperformed existing techniques, demonstrating its robustness and effectiveness in managing incomplete heterogeneous data."],"url":"http://arxiv.org/abs/2501.04300v1"}
{"created":"2025-01-08 05:27:16","title":"An Analysis of Model Robustness across Concurrent Distribution Shifts","abstract":"Machine learning models, meticulously optimized for source data, often fail to predict target data when faced with distribution shifts (DSs). Previous benchmarking studies, though extensive, have mainly focused on simple DSs. Recognizing that DSs often occur in more complex forms in real-world scenarios, we broadened our study to include multiple concurrent shifts, such as unseen domain shifts combined with spurious correlations. We evaluated 26 algorithms that range from simple heuristic augmentations to zero-shot inference using foundation models, across 168 source-target pairs from eight datasets. Our analysis of over 100K models reveals that (i) concurrent DSs typically worsen performance compared to a single shift, with certain exceptions, (ii) if a model improves generalization for one distribution shift, it tends to be effective for others, and (iii) heuristic data augmentations achieve the best overall performance on both synthetic and real-world datasets.","sentences":["Machine learning models, meticulously optimized for source data, often fail to predict target data when faced with distribution shifts (DSs).","Previous benchmarking studies, though extensive, have mainly focused on simple DSs.","Recognizing that DSs often occur in more complex forms in real-world scenarios, we broadened our study to include multiple concurrent shifts, such as unseen domain shifts combined with spurious correlations.","We evaluated 26 algorithms that range from simple heuristic augmentations to zero-shot inference using foundation models, across 168 source-target pairs from eight datasets.","Our analysis of over 100K models reveals that (i) concurrent DSs typically worsen performance compared to a single shift, with certain exceptions, (ii) if a model improves generalization for one distribution shift, it tends to be effective for others, and (iii) heuristic data augmentations achieve the best overall performance on both synthetic and real-world datasets."],"url":"http://arxiv.org/abs/2501.04288v1"}
{"created":"2025-01-08 05:15:43","title":"ContextMRI: Enhancing Compressed Sensing MRI through Metadata Conditioning","abstract":"Compressed sensing MRI seeks to accelerate MRI acquisition processes by sampling fewer k-space measurements and then reconstructing the missing data algorithmically. The success of these approaches often relies on strong priors or learned statistical models. While recent diffusion model-based priors have shown great potential, previous methods typically ignore clinically available metadata (e.g. patient demographics, imaging parameters, slice-specific information). In practice, metadata contains meaningful cues about the anatomy and acquisition protocol, suggesting it could further constrain the reconstruction problem. In this work, we propose ContextMRI, a text-conditioned diffusion model for MRI that integrates granular metadata into the reconstruction process. We train a pixel-space diffusion model directly on minimally processed, complex-valued MRI images. During inference, metadata is converted into a structured text prompt and fed to the model via CLIP text embeddings. By conditioning the prior on metadata, we unlock more accurate reconstructions and show consistent gains across multiple datasets, acceleration factors, and undersampling patterns. Our experiments demonstrate that increasing the fidelity of metadata, ranging from slice location and contrast to patient age, sex, and pathology, systematically boosts reconstruction performance. This work highlights the untapped potential of leveraging clinical context for inverse problems and opens a new direction for metadata-driven MRI reconstruction.","sentences":["Compressed sensing MRI seeks to accelerate MRI acquisition processes by sampling fewer k-space measurements and then reconstructing the missing data algorithmically.","The success of these approaches often relies on strong priors or learned statistical models.","While recent diffusion model-based priors have shown great potential, previous methods typically ignore clinically available metadata (e.g. patient demographics, imaging parameters, slice-specific information).","In practice, metadata contains meaningful cues about the anatomy and acquisition protocol, suggesting it could further constrain the reconstruction problem.","In this work, we propose ContextMRI, a text-conditioned diffusion model for MRI that integrates granular metadata into the reconstruction process.","We train a pixel-space diffusion model directly on minimally processed, complex-valued MRI images.","During inference, metadata is converted into a structured text prompt and fed to the model via CLIP text embeddings.","By conditioning the prior on metadata, we unlock more accurate reconstructions and show consistent gains across multiple datasets, acceleration factors, and undersampling patterns.","Our experiments demonstrate that increasing the fidelity of metadata, ranging from slice location and contrast to patient age, sex, and pathology, systematically boosts reconstruction performance.","This work highlights the untapped potential of leveraging clinical context for inverse problems and opens a new direction for metadata-driven MRI reconstruction."],"url":"http://arxiv.org/abs/2501.04284v2"}
{"created":"2025-01-08 05:14:36","title":"Enhancing Scene Classification in Cloudy Image Scenarios: A Collaborative Transfer Method with Information Regulation Mechanism using Optical Cloud-Covered and SAR Remote Sensing Images","abstract":"In remote sensing scene classification, leveraging the transfer methods with well-trained optical models is an efficient way to overcome label scarcity. However, cloud contamination leads to optical information loss and significant impacts on feature distribution, challenging the reliability and stability of transferred target models. Common solutions include cloud removal for optical data or directly using Synthetic aperture radar (SAR) data in the target domain. However, cloud removal requires substantial auxiliary data for support and pre-training, while directly using SAR disregards the unobstructed portions of optical data. This study presents a scene classification transfer method that synergistically combines multi-modality data, which aims to transfer the source domain model trained on cloudfree optical data to the target domain that includes both cloudy optical and SAR data at low cost. Specifically, the framework incorporates two parts: (1) the collaborative transfer strategy, based on knowledge distillation, enables the efficient prior knowledge transfer across heterogeneous data; (2) the information regulation mechanism (IRM) is proposed to address the modality imbalance issue during transfer. It employs auxiliary models to measure the contribution discrepancy of each modality, and automatically balances the information utilization of modalities during the target model learning process at the sample-level. The transfer experiments were conducted on simulated and real cloud datasets, demonstrating the superior performance of the proposed method compared to other solutions in cloud-covered scenarios. We also verified the importance and limitations of IRM, and further discussed and visualized the modality imbalance problem during the model transfer. Codes are available at https://github.com/wangyuze-csu/ESCCS","sentences":["In remote sensing scene classification, leveraging the transfer methods with well-trained optical models is an efficient way to overcome label scarcity.","However, cloud contamination leads to optical information loss and significant impacts on feature distribution, challenging the reliability and stability of transferred target models.","Common solutions include cloud removal for optical data or directly using Synthetic aperture radar (SAR) data in the target domain.","However, cloud removal requires substantial auxiliary data for support and pre-training, while directly using SAR disregards the unobstructed portions of optical data.","This study presents a scene classification transfer method that synergistically combines multi-modality data, which aims to transfer the source domain model trained on cloudfree optical data to the target domain that includes both cloudy optical and SAR data at low cost.","Specifically, the framework incorporates two parts: (1) the collaborative transfer strategy, based on knowledge distillation, enables the efficient prior knowledge transfer across heterogeneous data; (2) the information regulation mechanism (IRM) is proposed to address the modality imbalance issue during transfer.","It employs auxiliary models to measure the contribution discrepancy of each modality, and automatically balances the information utilization of modalities during the target model learning process at the sample-level.","The transfer experiments were conducted on simulated and real cloud datasets, demonstrating the superior performance of the proposed method compared to other solutions in cloud-covered scenarios.","We also verified the importance and limitations of IRM, and further discussed and visualized the modality imbalance problem during the model transfer.","Codes are available at https://github.com/wangyuze-csu/ESCCS"],"url":"http://arxiv.org/abs/2501.04283v1"}
{"created":"2025-01-08 04:37:36","title":"Open set label noise learning with robust sample selection and margin-guided module","abstract":"In recent years, the remarkable success of deep neural networks (DNNs) in computer vision is largely due to large-scale, high-quality labeled datasets. Training directly on real-world datasets with label noise may result in overfitting. The traditional method is limited to deal with closed set label noise, where noisy training data has true class labels within the known label space. However, there are some real-world datasets containing open set label noise, which means that some samples belong to an unknown class outside the known label space. To address the open set label noise problem, we introduce a method based on Robust Sample Selection and Margin-Guided Module (RSS-MGM). Firstly, unlike the prior clean sample selection approach, which only select a limited number of clean samples, a robust sample selection module combines small loss selection or high-confidence sample selection to obtain more clean samples. Secondly, to efficiently distinguish open set label noise and closed set ones, margin functions are designed to filter open-set data and closed set data. Thirdly, different processing methods are selected for different types of samples in order to fully utilize the data's prior information and optimize the whole model. Furthermore, extensive experimental results with noisy labeled data from benchmark datasets and real-world datasets, such as CIFAR-100N-C, CIFAR80N-O, WebFG-469, and Food101N, indicate that our approach outperforms many state-of-the-art label noise learning methods. Especially, it can more accurately divide open set label noise samples and closed set ones.","sentences":["In recent years, the remarkable success of deep neural networks (DNNs) in computer vision is largely due to large-scale, high-quality labeled datasets.","Training directly on real-world datasets with label noise may result in overfitting.","The traditional method is limited to deal with closed set label noise, where noisy training data has true class labels within the known label space.","However, there are some real-world datasets containing open set label noise, which means that some samples belong to an unknown class outside the known label space.","To address the open set label noise problem, we introduce a method based on Robust Sample Selection and Margin-Guided Module (RSS-MGM).","Firstly, unlike the prior clean sample selection approach, which only select a limited number of clean samples, a robust sample selection module combines small loss selection or high-confidence sample selection to obtain more clean samples.","Secondly, to efficiently distinguish open set label noise and closed set ones, margin functions are designed to filter open-set data and closed set data.","Thirdly, different processing methods are selected for different types of samples in order to fully utilize the data's prior information and optimize the whole model.","Furthermore, extensive experimental results with noisy labeled data from benchmark datasets and real-world datasets, such as CIFAR-100N-C, CIFAR80N-O, WebFG-469, and Food101N, indicate that our approach outperforms many state-of-the-art label noise learning methods.","Especially, it can more accurately divide open set label noise samples and closed set ones."],"url":"http://arxiv.org/abs/2501.04269v1"}
{"created":"2025-01-08 04:30:45","title":"Robotic Programmer: Video Instructed Policy Code Generation for Robotic Manipulation","abstract":"Zero-shot generalization across various robots, tasks and environments remains a significant challenge in robotic manipulation. Policy code generation methods use executable code to connect high-level task descriptions and low-level action sequences, leveraging the generalization capabilities of large language models and atomic skill libraries. In this work, we propose Robotic Programmer (RoboPro), a robotic foundation model, enabling the capability of perceiving visual information and following free-form instructions to perform robotic manipulation with policy code in a zero-shot manner. To address low efficiency and high cost in collecting runtime code data for robotic tasks, we devise Video2Code to synthesize executable code from extensive videos in-the-wild with off-the-shelf vision-language model and code-domain large language model. Extensive experiments show that RoboPro achieves the state-of-the-art zero-shot performance on robotic manipulation in both simulators and real-world environments. Specifically, the zero-shot success rate of RoboPro on RLBench surpasses the state-of-the-art model GPT-4o by 11.6%, which is even comparable to a strong supervised training baseline. Furthermore, RoboPro is robust to variations on API formats and skill sets.","sentences":["Zero-shot generalization across various robots, tasks and environments remains a significant challenge in robotic manipulation.","Policy code generation methods use executable code to connect high-level task descriptions and low-level action sequences, leveraging the generalization capabilities of large language models and atomic skill libraries.","In this work, we propose Robotic Programmer (RoboPro), a robotic foundation model, enabling the capability of perceiving visual information and following free-form instructions to perform robotic manipulation with policy code in a zero-shot manner.","To address low efficiency and high cost in collecting runtime code data for robotic tasks, we devise Video2Code to synthesize executable code from extensive videos in-the-wild with off-the-shelf vision-language model and code-domain large language model.","Extensive experiments show that RoboPro achieves the state-of-the-art zero-shot performance on robotic manipulation in both simulators and real-world environments.","Specifically, the zero-shot success rate of RoboPro on RLBench surpasses the state-of-the-art model GPT-4o by 11.6%, which is even comparable to a strong supervised training baseline.","Furthermore, RoboPro is robust to variations on API formats and skill sets."],"url":"http://arxiv.org/abs/2501.04268v1"}
{"created":"2025-01-08 04:14:09","title":"KN-LIO: Geometric Kinematics and Neural Field Coupled LiDAR-Inertial Odometry","abstract":"Recent advancements in LiDAR-Inertial Odometry (LIO) have boosted a large amount of applications. However, traditional LIO systems tend to focus more on localization rather than mapping, with maps consisting mostly of sparse geometric elements, which is not ideal for downstream tasks. Recent emerging neural field technology has great potential in dense mapping, but pure LiDAR mapping is difficult to work on high-dynamic vehicles. To mitigate this challenge, we present a new solution that tightly couples geometric kinematics with neural fields to enhance simultaneous state estimation and dense mapping capabilities. We propose both semi-coupled and tightly coupled Kinematic-Neural LIO (KN-LIO) systems that leverage online SDF decoding and iterated error-state Kalman filtering to fuse laser and inertial data. Our KN-LIO minimizes information loss and improves accuracy in state estimation, while also accommodating asynchronous multi-LiDAR inputs. Evaluations on diverse high-dynamic datasets demonstrate that our KN-LIO achieves performance on par with or superior to existing state-of-the-art solutions in pose estimation and offers improved dense mapping accuracy over pure LiDAR-based methods. The relevant code and datasets will be made available at https://**.","sentences":["Recent advancements in LiDAR-Inertial Odometry (LIO) have boosted a large amount of applications.","However, traditional LIO systems tend to focus more on localization rather than mapping, with maps consisting mostly of sparse geometric elements, which is not ideal for downstream tasks.","Recent emerging neural field technology has great potential in dense mapping, but pure LiDAR mapping is difficult to work on high-dynamic vehicles.","To mitigate this challenge, we present a new solution that tightly couples geometric kinematics with neural fields to enhance simultaneous state estimation and dense mapping capabilities.","We propose both semi-coupled and tightly coupled Kinematic-Neural LIO (KN-LIO) systems that leverage online SDF decoding and iterated error-state Kalman filtering to fuse laser and inertial data.","Our KN-LIO minimizes information loss and improves accuracy in state estimation, while also accommodating asynchronous multi-LiDAR inputs.","Evaluations on diverse high-dynamic datasets demonstrate that our KN-LIO achieves performance on par with or superior to existing state-of-the-art solutions in pose estimation and offers improved dense mapping accuracy over pure LiDAR-based methods.","The relevant code and datasets will be made available at https://**."],"url":"http://arxiv.org/abs/2501.04263v1"}
{"created":"2025-01-08 03:50:15","title":"Stable Derivative Free Gaussian Mixture Variational Inference for Bayesian Inverse Problems","abstract":"This paper is concerned with the approximation of probability distributions known up to normalization constants, with a focus on Bayesian inference for large-scale inverse problems in scientific computing. In this context, key challenges include costly repeated evaluations of forward models, multimodality, and inaccessible gradients for the forward model. To address them, we develop a variational inference framework that combines Fisher-Rao natural gradient with specialized quadrature rules to enable derivative free updates of Gaussian mixture variational families. The resulting method, termed Derivative Free Gaussian Mixture Variational Inference (DF-GMVI), guarantees covariance positivity and affine invariance, offering a stable and efficient framework for approximating complex posterior distributions. The effectiveness of DF-GMVI is demonstrated through numerical experiments on challenging scenarios, including distributions with multiple modes, infinitely many modes, and curved modes in spaces with up to hundreds of dimensions. The method's practicality is further demonstrated in a large-scale application, where it successfully recovers the initial conditions of the Navier-Stokes equations from solution data at positive times.","sentences":["This paper is concerned with the approximation of probability distributions known up to normalization constants, with a focus on Bayesian inference for large-scale inverse problems in scientific computing.","In this context, key challenges include costly repeated evaluations of forward models, multimodality, and inaccessible gradients for the forward model.","To address them, we develop a variational inference framework that combines Fisher-Rao natural gradient with specialized quadrature rules to enable derivative free updates of Gaussian mixture variational families.","The resulting method, termed Derivative Free Gaussian Mixture Variational Inference (DF-GMVI), guarantees covariance positivity and affine invariance, offering a stable and efficient framework for approximating complex posterior distributions.","The effectiveness of DF-GMVI is demonstrated through numerical experiments on challenging scenarios, including distributions with multiple modes, infinitely many modes, and curved modes in spaces with up to hundreds of dimensions.","The method's practicality is further demonstrated in a large-scale application, where it successfully recovers the initial conditions of the Navier-Stokes equations from solution data at positive times."],"url":"http://arxiv.org/abs/2501.04259v1"}
{"created":"2025-01-08 03:18:41","title":"Publish on Ping: A Better Way to Publish Reservations in Memory Reclamation for Concurrent Data Structures","abstract":"Safe memory reclamation techniques that utilize per read reservations, such as hazard pointers, often cause significant overhead in traversals of linked concurrent data structures. This is primarily due to the need to announce a reservation, and fence to enforce appropriate ordering, before each read. In read-intensive workloads, this overhead is amplified because, even if relatively little memory reclamation actually occurs, the full overhead of reserving records is still incurred while traversing data structures.   In this paper, we propose a novel memory reclamation technique by combining POSIX signals and delayed reclamation, introducing a publish-on-ping approach. This method eliminates the need to make reservations globally visible before use. Instead, threads privately track which records they are accessing, and share this information on demand with threads that intend to reclaim memory. The approach can serve as a drop-in replacement for hazard pointers and hazard eras. Furthermore, the capability to retain reservations during traversals in data structure operations and publish them on demand facilitates the construction of a variant of hazard pointers (EpochPOP). This variant uses epochs to approach the performance of epoch-based reclamation in the common case where threads are not frequently delayed (while retaining the robustness of hazard pointers).   Our publish-on-ping implementations based on hazard pointers (HP) and hazard eras, when applied to various data structures, exhibit significant performance improvements. The improvements across various workloads and data structures range from 1.2X to 4X over the original HP, up to 20% compared to a heavily optimized HP implementation similar to the one in the Folly open-source library, and up to 3X faster than hazard eras. EpochPOP delivers performance similar to epoch-based reclamation while providing stronger guarantees.","sentences":["Safe memory reclamation techniques that utilize per read reservations, such as hazard pointers, often cause significant overhead in traversals of linked concurrent data structures.","This is primarily due to the need to announce a reservation, and fence to enforce appropriate ordering, before each read.","In read-intensive workloads, this overhead is amplified because, even if relatively little memory reclamation actually occurs, the full overhead of reserving records is still incurred while traversing data structures.   ","In this paper, we propose a novel memory reclamation technique by combining POSIX signals and delayed reclamation, introducing a publish-on-ping approach.","This method eliminates the need to make reservations globally visible before use.","Instead, threads privately track which records they are accessing, and share this information on demand with threads that intend to reclaim memory.","The approach can serve as a drop-in replacement for hazard pointers and hazard eras.","Furthermore, the capability to retain reservations during traversals in data structure operations and publish them on demand facilitates the construction of a variant of hazard pointers (EpochPOP).","This variant uses epochs to approach the performance of epoch-based reclamation in the common case where threads are not frequently delayed (while retaining the robustness of hazard pointers).   ","Our publish-on-ping implementations based on hazard pointers (HP) and hazard eras, when applied to various data structures, exhibit significant performance improvements.","The improvements across various workloads and data structures range from 1.2X to 4X over the original HP, up to 20% compared to a heavily optimized HP implementation similar to the one in the Folly open-source library, and up to 3X faster than hazard eras.","EpochPOP delivers performance similar to epoch-based reclamation while providing stronger guarantees."],"url":"http://arxiv.org/abs/2501.04250v1"}
{"created":"2025-01-08 03:10:30","title":"Drift-oriented Self-evolving Encrypted Traffic Application Classification for Actual Network Environment","abstract":"Encrypted traffic classification technology is a crucial decision-making information source for network management and security protection. It has the advantages of excellent response timeliness, large-scale data bearing, and cross-time-and-space analysis. The existing research on encrypted traffic classification has gradually transitioned from the closed world to the open world, and many classifier optimization and feature engineering schemes have been proposed. However, encrypted traffic classification has yet to be effectively applied to the actual network environment. The main reason is that applications on the Internet are constantly updated, including function adjustment and version change, which brings severe feature concept drift, resulting in rapid failure of the classifier. Hence, the entire model must be retrained only past very fast time, with unacceptable labeled sample constructing and model training cost. To solve this problem, we deeply study the characteristics of Internet application updates, associate them with feature concept drift, and then propose self-evolving encrypted traffic classification. We propose a feature concept drift determination method and a drift-oriented self-evolving fine-tuning method based on the Laida criterion to adapt to all applications that are likely to be updated. In the case of no exact label samples, the classifier evolves through fully fine-tuning continuously, and the time interval between two necessary retraining is greatly extended to be applied to the actual network environment. Experiments show that our approach significantly improves the classification performance of the original classifier on the following stage dataset of the following months (9\\% improvement on F1-score) without any hard-to-acquire labeled sample. Under the current experimental environment, the life of the classifier is extended to more than eight months.","sentences":["Encrypted traffic classification technology is a crucial decision-making information source for network management and security protection.","It has the advantages of excellent response timeliness, large-scale data bearing, and cross-time-and-space analysis.","The existing research on encrypted traffic classification has gradually transitioned from the closed world to the open world, and many classifier optimization and feature engineering schemes have been proposed.","However, encrypted traffic classification has yet to be effectively applied to the actual network environment.","The main reason is that applications on the Internet are constantly updated, including function adjustment and version change, which brings severe feature concept drift, resulting in rapid failure of the classifier.","Hence, the entire model must be retrained only past very fast time, with unacceptable labeled sample constructing and model training cost.","To solve this problem, we deeply study the characteristics of Internet application updates, associate them with feature concept drift, and then propose self-evolving encrypted traffic classification.","We propose a feature concept drift determination method and a drift-oriented self-evolving fine-tuning method based on the Laida criterion to adapt to all applications that are likely to be updated.","In the case of no exact label samples, the classifier evolves through fully fine-tuning continuously, and the time interval between two necessary retraining is greatly extended to be applied to the actual network environment.","Experiments show that our approach significantly improves the classification performance of the original classifier on the following stage dataset of the following months (9\\% improvement on F1-score) without any hard-to-acquire labeled sample.","Under the current experimental environment, the life of the classifier is extended to more than eight months."],"url":"http://arxiv.org/abs/2501.04246v1"}
{"created":"2025-01-08 02:32:48","title":"Dynamic Localisation of Spatial-Temporal Graph Neural Network","abstract":"Spatial-temporal data, fundamental to many intelligent applications, reveals dependencies indicating causal links between present measurements at specific locations and historical data at the same or other locations. Within this context, adaptive spatial-temporal graph neural networks (ASTGNNs) have emerged as valuable tools for modelling these dependencies, especially through a data-driven approach rather than pre-defined spatial graphs. While this approach offers higher accuracy, it presents increased computational demands. Addressing this challenge, this paper delves into the concept of localisation within ASTGNNs, introducing an innovative perspective that spatial dependencies should be dynamically evolving over time. We introduce \\textit{DynAGS}, a localised ASTGNN framework aimed at maximising efficiency and accuracy in distributed deployment. This framework integrates dynamic localisation, time-evolving spatial graphs, and personalised localisation, all orchestrated around the Dynamic Graph Generator, a light-weighted central module leveraging cross attention. The central module can integrate historical information in a node-independent manner to enhance the feature representation of nodes at the current moment. This improved feature representation is then used to generate a dynamic sparse graph without the need for costly data exchanges, and it supports personalised localisation. Performance assessments across two core ASTGNN architectures and nine real-world datasets from various applications reveal that \\textit{DynAGS} outshines current benchmarks, underscoring that the dynamic modelling of spatial dependencies can drastically improve model expressibility, flexibility, and system efficiency, especially in distributed settings.","sentences":["Spatial-temporal data, fundamental to many intelligent applications, reveals dependencies indicating causal links between present measurements at specific locations and historical data at the same or other locations.","Within this context, adaptive spatial-temporal graph neural networks (ASTGNNs) have emerged as valuable tools for modelling these dependencies, especially through a data-driven approach rather than pre-defined spatial graphs.","While this approach offers higher accuracy, it presents increased computational demands.","Addressing this challenge, this paper delves into the concept of localisation within ASTGNNs, introducing an innovative perspective that spatial dependencies should be dynamically evolving over time.","We introduce \\textit{DynAGS}, a localised ASTGNN framework aimed at maximising efficiency and accuracy in distributed deployment.","This framework integrates dynamic localisation, time-evolving spatial graphs, and personalised localisation, all orchestrated around the Dynamic Graph Generator, a light-weighted central module leveraging cross attention.","The central module can integrate historical information in a node-independent manner to enhance the feature representation of nodes at the current moment.","This improved feature representation is then used to generate a dynamic sparse graph without the need for costly data exchanges, and it supports personalised localisation.","Performance assessments across two core ASTGNN architectures and nine real-world datasets from various applications reveal that \\textit{DynAGS} outshines current benchmarks, underscoring that the dynamic modelling of spatial dependencies can drastically improve model expressibility, flexibility, and system efficiency, especially in distributed settings."],"url":"http://arxiv.org/abs/2501.04239v2"}
{"created":"2025-01-08 02:04:09","title":"Computation and Communication Co-scheduling for Timely Multi-Task Inference at the Wireless Edge","abstract":"In multi-task remote inference systems, an intelligent receiver (e.g., command center) performs multiple inference tasks (e.g., target detection) using data features received from several remote sources (e.g., edge sensors). Key challenges to facilitating timely inference in these systems arise from (i) limited computational power of the sources to produce features from their inputs, and (ii) limited communication resources of the channels to carry simultaneous feature transmissions to the receiver. We develop a novel computation and communication co-scheduling methodology which determines feature generation and transmission scheduling to minimize inference errors subject to these resource constraints. Specifically, we formulate the co-scheduling problem as a weakly-coupled Markov decision process with Age of Information (AoI)-based timeliness gauging the inference errors. To overcome its PSPACE-hard complexity, we analyze a Lagrangian relaxation of the problem, which yields gain indices assessing the improvement in inference error for each potential feature generation-transmission scheduling action. Based on this, we develop a maximum gain first (MGF) policy which we show is asymptotically optimal for the original problem as the number of inference tasks increases. Experiments demonstrate that MGF obtains significant improvements over baseline policies for varying tasks, channels, and sources.","sentences":["In multi-task remote inference systems, an intelligent receiver (e.g., command center) performs multiple inference tasks (e.g., target detection) using data features received from several remote sources (e.g., edge sensors).","Key challenges to facilitating timely inference in these systems arise from (i) limited computational power of the sources to produce features from their inputs, and (ii) limited communication resources of the channels to carry simultaneous feature transmissions to the receiver.","We develop a novel computation and communication co-scheduling methodology which determines feature generation and transmission scheduling to minimize inference errors subject to these resource constraints.","Specifically, we formulate the co-scheduling problem as a weakly-coupled Markov decision process with Age of Information (AoI)-based timeliness gauging the inference errors.","To overcome its PSPACE-hard complexity, we analyze a Lagrangian relaxation of the problem, which yields gain indices assessing the improvement in inference error for each potential feature generation-transmission scheduling action.","Based on this, we develop a maximum gain first (MGF) policy which we show is asymptotically optimal for the original problem as the number of inference tasks increases.","Experiments demonstrate that MGF obtains significant improvements over baseline policies for varying tasks, channels, and sources."],"url":"http://arxiv.org/abs/2501.04231v1"}
{"created":"2025-01-08 01:27:35","title":"Continual Self-supervised Learning Considering Medical Domain Knowledge in Chest CT Images","abstract":"We propose a novel continual self-supervised learning method (CSSL) considering medical domain knowledge in chest CT images. Our approach addresses the challenge of sequential learning by effectively capturing the relationship between previously learned knowledge and new information at different stages. By incorporating an enhanced DER into CSSL and maintaining both diversity and representativeness within the rehearsal buffer of DER, the risk of data interference during pretraining is reduced, enabling the model to learn more richer and robust feature representations. In addition, we incorporate a mixup strategy and feature distillation to further enhance the model's ability to learn meaningful representations. We validate our method using chest CT images obtained under two different imaging conditions, demonstrating superior performance compared to state-of-the-art methods.","sentences":["We propose a novel continual self-supervised learning method (CSSL) considering medical domain knowledge in chest CT images.","Our approach addresses the challenge of sequential learning by effectively capturing the relationship between previously learned knowledge and new information at different stages.","By incorporating an enhanced DER into CSSL and maintaining both diversity and representativeness within the rehearsal buffer of DER, the risk of data interference during pretraining is reduced, enabling the model to learn more richer and robust feature representations.","In addition, we incorporate a mixup strategy and feature distillation to further enhance the model's ability to learn meaningful representations.","We validate our method using chest CT images obtained under two different imaging conditions, demonstrating superior performance compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2501.04217v1"}
{"created":"2025-01-08 01:23:29","title":"Optimal Oblivious Algorithms for Multi-way Joins","abstract":"In cloud databases, cloud computation over sensitive data uploaded by clients inevitably causes concern about data security and privacy. Even when encryption primitives and trusted computing environments are integrated into query processing to safeguard the actual contents of the data, access patterns of algorithms can still leak private information about the data. Oblivious Random Access Memory (ORAM) and circuits are two generic approaches to address this issue, ensuring that access patterns of algorithms remain oblivious to the data. However, deploying these methods on insecure algorithms, particularly for multi-way join processing, is computationally expensive and inherently challenging.   In this paper, we propose a novel sorting-based algorithm for multi-way join processing that operates without relying on ORAM simulations or other security assumptions. Our algorithm is a non-trivial, provably oblivious composition of basic primitives, with time complexity matching the insecure worst-case optimal join algorithm, up to a logarithmic factor. Furthermore, it is cache-agnostic, with cache complexity matching the insecure lower bound, also up to a logarithmic factor. This clean and straightforward approach has the potential to be extended to other security settings and implemented in practical database systems.","sentences":["In cloud databases, cloud computation over sensitive data uploaded by clients inevitably causes concern about data security and privacy.","Even when encryption primitives and trusted computing environments are integrated into query processing to safeguard the actual contents of the data, access patterns of algorithms can still leak private information about the data.","Oblivious Random Access Memory (ORAM) and circuits are two generic approaches to address this issue, ensuring that access patterns of algorithms remain oblivious to the data.","However, deploying these methods on insecure algorithms, particularly for multi-way join processing, is computationally expensive and inherently challenging.   ","In this paper, we propose a novel sorting-based algorithm for multi-way join processing that operates without relying on ORAM simulations or other security assumptions.","Our algorithm is a non-trivial, provably oblivious composition of basic primitives, with time complexity matching the insecure worst-case optimal join algorithm, up to a logarithmic factor.","Furthermore, it is cache-agnostic, with cache complexity matching the insecure lower bound, also up to a logarithmic factor.","This clean and straightforward approach has the potential to be extended to other security settings and implemented in practical database systems."],"url":"http://arxiv.org/abs/2501.04216v2"}
{"created":"2025-01-08 00:52:19","title":"LipGen: Viseme-Guided Lip Video Generation for Enhancing Visual Speech Recognition","abstract":"Visual speech recognition (VSR), commonly known as lip reading, has garnered significant attention due to its wide-ranging practical applications. The advent of deep learning techniques and advancements in hardware capabilities have significantly enhanced the performance of lip reading models. Despite these advancements, existing datasets predominantly feature stable video recordings with limited variability in lip movements. This limitation results in models that are highly sensitive to variations encountered in real-world scenarios. To address this issue, we propose a novel framework, LipGen, which aims to improve model robustness by leveraging speech-driven synthetic visual data, thereby mitigating the constraints of current datasets. Additionally, we introduce an auxiliary task that incorporates viseme classification alongside attention mechanisms. This approach facilitates the efficient integration of temporal information, directing the model's focus toward the relevant segments of speech, thereby enhancing discriminative capabilities. Our method demonstrates superior performance compared to the current state-of-the-art on the lip reading in the wild (LRW) dataset and exhibits even more pronounced advantages under challenging conditions.","sentences":["Visual speech recognition (VSR), commonly known as lip reading, has garnered significant attention due to its wide-ranging practical applications.","The advent of deep learning techniques and advancements in hardware capabilities have significantly enhanced the performance of lip reading models.","Despite these advancements, existing datasets predominantly feature stable video recordings with limited variability in lip movements.","This limitation results in models that are highly sensitive to variations encountered in real-world scenarios.","To address this issue, we propose a novel framework, LipGen, which aims to improve model robustness by leveraging speech-driven synthetic visual data, thereby mitigating the constraints of current datasets.","Additionally, we introduce an auxiliary task that incorporates viseme classification alongside attention mechanisms.","This approach facilitates the efficient integration of temporal information, directing the model's focus toward the relevant segments of speech, thereby enhancing discriminative capabilities.","Our method demonstrates superior performance compared to the current state-of-the-art on the lip reading in the wild (LRW) dataset and exhibits even more pronounced advantages under challenging conditions."],"url":"http://arxiv.org/abs/2501.04204v1"}
{"created":"2025-01-08 00:43:31","title":"Generative Dataset Distillation Based on Self-knowledge Distillation","abstract":"Dataset distillation is an effective technique for reducing the cost and complexity of model training while maintaining performance by compressing large datasets into smaller, more efficient versions. In this paper, we present a novel generative dataset distillation method that can improve the accuracy of aligning prediction logits. Our approach integrates self-knowledge distillation to achieve more precise distribution matching between the synthetic and original data, thereby capturing the overall structure and relationships within the data. To further improve the accuracy of alignment, we introduce a standardization step on the logits before performing distribution matching, ensuring consistency in the range of logits. Through extensive experiments, we demonstrate that our method outperforms existing state-of-the-art methods, resulting in superior distillation performance.","sentences":["Dataset distillation is an effective technique for reducing the cost and complexity of model training while maintaining performance by compressing large datasets into smaller, more efficient versions.","In this paper, we present a novel generative dataset distillation method that can improve the accuracy of aligning prediction logits.","Our approach integrates self-knowledge distillation to achieve more precise distribution matching between the synthetic and original data, thereby capturing the overall structure and relationships within the data.","To further improve the accuracy of alignment, we introduce a standardization step on the logits before performing distribution matching, ensuring consistency in the range of logits.","Through extensive experiments, we demonstrate that our method outperforms existing state-of-the-art methods, resulting in superior distillation performance."],"url":"http://arxiv.org/abs/2501.04202v1"}
{"created":"2025-01-08 00:06:38","title":"GNN-based Decentralized Perception in Multirobot Systems for Predicting Worker Actions","abstract":"In industrial environments, predicting human actions is essential for ensuring safe and effective collaboration between humans and robots. This paper introduces a perception framework that enables mobile robots to understand and share information about human actions in a decentralized way. The framework first allows each robot to build a spatial graph representing its surroundings, which it then shares with other robots. This shared spatial data is combined with temporal information to track human behavior over time. A swarm-inspired decision-making process is used to ensure all robots agree on a unified interpretation of the human's actions. Results show that adding more robots and incorporating longer time sequences improve prediction accuracy. Additionally, the consensus mechanism increases system resilience, making the multi-robot setup more reliable in dynamic industrial settings.","sentences":["In industrial environments, predicting human actions is essential for ensuring safe and effective collaboration between humans and robots.","This paper introduces a perception framework that enables mobile robots to understand and share information about human actions in a decentralized way.","The framework first allows each robot to build a spatial graph representing its surroundings, which it then shares with other robots.","This shared spatial data is combined with temporal information to track human behavior over time.","A swarm-inspired decision-making process is used to ensure all robots agree on a unified interpretation of the human's actions.","Results show that adding more robots and incorporating longer time sequences improve prediction accuracy.","Additionally, the consensus mechanism increases system resilience, making the multi-robot setup more reliable in dynamic industrial settings."],"url":"http://arxiv.org/abs/2501.04193v1"}
{"created":"2025-01-07 23:32:05","title":"MedicalNarratives: Connecting Medical Vision and Language with Localized Narratives","abstract":"We propose MedicalNarratives, a dataset curated from medical pedagogical videos similar in nature to data collected in Think-Aloud studies and inspired by Localized Narratives, which collects grounded image-text data by curating instructors' speech and mouse cursor movements synchronized in time. MedicalNarratives enables pretraining of both semantic and dense objectives, alleviating the need to train medical semantic and dense tasks disparately due to the lack of reasonably sized datasets. Our dataset contains 4.7M image-text pairs from videos and articles, with 1M samples containing dense annotations in the form of traces and bounding boxes. To evaluate the utility of MedicalNarratives, we train GenMedClip based on the CLIP architecture using our dataset spanning 12 medical domains and demonstrate that it outperforms previous state-of-the-art models on a newly constructed medical imaging benchmark that comprehensively evaluates performance across all modalities. Data, demo, code and models available at https://medical-narratives.github.io","sentences":["We propose MedicalNarratives, a dataset curated from medical pedagogical videos similar in nature to data collected in Think-Aloud studies and inspired by Localized Narratives, which collects grounded image-text data by curating instructors' speech and mouse cursor movements synchronized in time.","MedicalNarratives enables pretraining of both semantic and dense objectives, alleviating the need to train medical semantic and dense tasks disparately due to the lack of reasonably sized datasets.","Our dataset contains 4.7M image-text pairs from videos and articles, with 1M samples containing dense annotations in the form of traces and bounding boxes.","To evaluate the utility of MedicalNarratives, we train GenMedClip based on the CLIP architecture using our dataset spanning 12 medical domains and demonstrate that it outperforms previous state-of-the-art models on a newly constructed medical imaging benchmark that comprehensively evaluates performance across all modalities.","Data, demo, code and models available at https://medical-narratives.github.io"],"url":"http://arxiv.org/abs/2501.04184v1"}
{"created":"2025-01-07 22:40:37","title":"A Bayesian Modeling Framework for Estimation and Ground Segmentation of Cluttered Staircases","abstract":"Autonomous robot navigation in complex environments requires robust perception as well as high-level scene understanding due to perceptual challenges, such as occlusions, and uncertainty introduced by robot movement. For example, a robot climbing a cluttered staircase can misinterpret clutter as a step, misrepresenting the state and compromising safety. This requires robust state estimation methods capable of inferring the underlying structure of the environment even from incomplete sensor data. In this paper, we introduce a novel method for robust state estimation of staircases. To address the challenge of perceiving occluded staircases extending beyond the robot's field-of-view, our approach combines an infinite-width staircase representation with a finite endpoint state to capture the overall staircase structure. This representation is integrated into a Bayesian inference framework to fuse noisy measurements enabling accurate estimation of staircase location even with partial observations and occlusions. Additionally, we present a segmentation algorithm that works in conjunction with the staircase estimation pipeline to accurately identify clutter-free regions on a staircase. Our method is extensively evaluated on real robot across diverse staircases, demonstrating significant improvements in estimation accuracy and segmentation performance compared to baseline approaches.","sentences":["Autonomous robot navigation in complex environments requires robust perception as well as high-level scene understanding due to perceptual challenges, such as occlusions, and uncertainty introduced by robot movement.","For example, a robot climbing a cluttered staircase can misinterpret clutter as a step, misrepresenting the state and compromising safety.","This requires robust state estimation methods capable of inferring the underlying structure of the environment even from incomplete sensor data.","In this paper, we introduce a novel method for robust state estimation of staircases.","To address the challenge of perceiving occluded staircases extending beyond the robot's field-of-view, our approach combines an infinite-width staircase representation with a finite endpoint state to capture the overall staircase structure.","This representation is integrated into a Bayesian inference framework to fuse noisy measurements enabling accurate estimation of staircase location even with partial observations and occlusions.","Additionally, we present a segmentation algorithm that works in conjunction with the staircase estimation pipeline to accurately identify clutter-free regions on a staircase.","Our method is extensively evaluated on real robot across diverse staircases, demonstrating significant improvements in estimation accuracy and segmentation performance compared to baseline approaches."],"url":"http://arxiv.org/abs/2501.04170v1"}
{"created":"2025-01-07 22:33:47","title":"Learning to Transfer Human Hand Skills for Robot Manipulations","abstract":"We present a method for teaching dexterous manipulation tasks to robots from human hand motion demonstrations. Unlike existing approaches that solely rely on kinematics information without taking into account the plausibility of robot and object interaction, our method directly infers plausible robot manipulation actions from human motion demonstrations. To address the embodiment gap between the human hand and the robot system, our approach learns a joint motion manifold that maps human hand movements, robot hand actions, and object movements in 3D, enabling us to infer one motion component from others. Our key idea is the generation of pseudo-supervision triplets, which pair human, object, and robot motion trajectories synthetically. Through real-world experiments with robot hand manipulation, we demonstrate that our data-driven retargeting method significantly outperforms conventional retargeting techniques, effectively bridging the embodiment gap between human and robotic hands. Website at https://rureadyo.github.io/MocapRobot/.","sentences":["We present a method for teaching dexterous manipulation tasks to robots from human hand motion demonstrations.","Unlike existing approaches that solely rely on kinematics information without taking into account the plausibility of robot and object interaction, our method directly infers plausible robot manipulation actions from human motion demonstrations.","To address the embodiment gap between the human hand and the robot system, our approach learns a joint motion manifold that maps human hand movements, robot hand actions, and object movements in 3D, enabling us to infer one motion component from others.","Our key idea is the generation of pseudo-supervision triplets, which pair human, object, and robot motion trajectories synthetically.","Through real-world experiments with robot hand manipulation, we demonstrate that our data-driven retargeting method significantly outperforms conventional retargeting techniques, effectively bridging the embodiment gap between human and robotic hands.","Website at https://rureadyo.github.io/MocapRobot/."],"url":"http://arxiv.org/abs/2501.04169v1"}
{"created":"2025-01-07 22:29:08","title":"Reasoning-Enhanced Self-Training for Long-Form Personalized Text Generation","abstract":"Personalized text generation requires a unique ability of large language models (LLMs) to learn from context that they often do not encounter during their standard training. One way to encourage LLMs to better use personalized context for generating outputs that better align with the user's expectations is to instruct them to reason over the user's past preferences, background knowledge, or writing style. To achieve this, we propose Reasoning-Enhanced Self-Training for Personalized Text Generation (REST-PG), a framework that trains LLMs to reason over personal data during response generation. REST-PG first generates reasoning paths to train the LLM's reasoning abilities and then employs Expectation-Maximization Reinforced Self-Training to iteratively train the LLM based on its own high-reward outputs. We evaluate REST-PG on the LongLaMP benchmark, consisting of four diverse personalized long-form text generation tasks. Our experiments demonstrate that REST-PG achieves significant improvements over state-of-the-art baselines, with an average relative performance gain of 14.5% on the benchmark.","sentences":["Personalized text generation requires a unique ability of large language models (LLMs) to learn from context that they often do not encounter during their standard training.","One way to encourage LLMs to better use personalized context for generating outputs that better align with the user's expectations is to instruct them to reason over the user's past preferences, background knowledge, or writing style.","To achieve this, we propose Reasoning-Enhanced Self-Training for Personalized Text Generation (REST-PG), a framework that trains LLMs to reason over personal data during response generation.","REST-PG first generates reasoning paths to train the LLM's reasoning abilities and then employs Expectation-Maximization Reinforced Self-Training to iteratively train the LLM based on its own high-reward outputs.","We evaluate REST-PG on the LongLaMP benchmark, consisting of four diverse personalized long-form text generation tasks.","Our experiments demonstrate that REST-PG achieves significant improvements over state-of-the-art baselines, with an average relative performance gain of 14.5% on the benchmark."],"url":"http://arxiv.org/abs/2501.04167v1"}
{"created":"2025-01-07 22:19:15","title":"KGIF: Optimizing Relation-Aware Recommendations with Knowledge Graph Information Fusion","abstract":"While deep-learning-enabled recommender systems demonstrate strong performance benchmarks, many struggle to adapt effectively in real-world environments due to limited use of user-item relationship data and insufficient transparency in recommendation generation. Traditional collaborative filtering approaches fail to integrate multifaceted item attributes, and although Factorization Machines account for item-specific details, they overlook broader relational patterns. Collaborative knowledge graph-based models have progressed by embedding user-item interactions with item-attribute relationships, offering a holistic perspective on interconnected entities. However, these models frequently aggregate attribute and interaction data in an implicit manner, leaving valuable relational nuances underutilized.   This study introduces the Knowledge Graph Attention Network with Information Fusion (KGIF), a specialized framework designed to merge entity and relation embeddings explicitly through a tailored self-attention mechanism. The KGIF framework integrates reparameterization via dynamic projection vectors, enabling embeddings to adaptively represent intricate relationships within knowledge graphs. This explicit fusion enhances the interplay between user-item interactions and item-attribute relationships, providing a nuanced balance between user-centric and item-centric representations. An attentive propagation mechanism further optimizes knowledge graph embeddings, capturing multi-layered interaction patterns. The contributions of this work include an innovative method for explicit information fusion, improved robustness for sparse knowledge graphs, and the ability to generate explainable recommendations through interpretable path visualization.","sentences":["While deep-learning-enabled recommender systems demonstrate strong performance benchmarks, many struggle to adapt effectively in real-world environments due to limited use of user-item relationship data and insufficient transparency in recommendation generation.","Traditional collaborative filtering approaches fail to integrate multifaceted item attributes, and although Factorization Machines account for item-specific details, they overlook broader relational patterns.","Collaborative knowledge graph-based models have progressed by embedding user-item interactions with item-attribute relationships, offering a holistic perspective on interconnected entities.","However, these models frequently aggregate attribute and interaction data in an implicit manner, leaving valuable relational nuances underutilized.   ","This study introduces the Knowledge Graph Attention Network with Information Fusion (KGIF), a specialized framework designed to merge entity and relation embeddings explicitly through a tailored self-attention mechanism.","The KGIF framework integrates reparameterization via dynamic projection vectors, enabling embeddings to adaptively represent intricate relationships within knowledge graphs.","This explicit fusion enhances the interplay between user-item interactions and item-attribute relationships, providing a nuanced balance between user-centric and item-centric representations.","An attentive propagation mechanism further optimizes knowledge graph embeddings, capturing multi-layered interaction patterns.","The contributions of this work include an innovative method for explicit information fusion, improved robustness for sparse knowledge graphs, and the ability to generate explainable recommendations through interpretable path visualization."],"url":"http://arxiv.org/abs/2501.04161v1"}
{"created":"2025-01-07 21:57:51","title":"AdaptiveCoPilot: Design and Testing of a NeuroAdaptive LLM Cockpit Guidance System in both Novice and Expert Pilots","abstract":"Pilots operating modern cockpits often face high cognitive demands due to complex interfaces and multitasking requirements, which can lead to overload and decreased performance. This study introduces AdaptiveCoPilot, a neuroadaptive guidance system that adapts visual, auditory, and textual cues in real time based on the pilot's cognitive workload, measured via functional Near-Infrared Spectroscopy (fNIRS). A formative study with expert pilots (N=3) identified adaptive rules for modality switching and information load adjustments during preflight tasks. These insights informed the design of AdaptiveCoPilot, which integrates cognitive state assessments, behavioral data, and adaptive strategies within a context-aware Large Language Model (LLM). The system was evaluated in a virtual reality (VR) simulated cockpit with licensed pilots (N=8), comparing its performance against baseline and random feedback conditions. The results indicate that the pilots using AdaptiveCoPilot exhibited higher rates of optimal cognitive load states on the facets of working memory and perception, along with reduced task completion times. Based on the formative study, experimental findings, qualitative interviews, we propose a set of strategies for future development of neuroadaptive pilot guidance systems and highlight the potential of neuroadaptive systems to enhance pilot performance and safety in aviation environments.","sentences":["Pilots operating modern cockpits often face high cognitive demands due to complex interfaces and multitasking requirements, which can lead to overload and decreased performance.","This study introduces AdaptiveCoPilot, a neuroadaptive guidance system that adapts visual, auditory, and textual cues in real time based on the pilot's cognitive workload, measured via functional Near-Infrared Spectroscopy (fNIRS).","A formative study with expert pilots (N=3) identified adaptive rules for modality switching and information load adjustments during preflight tasks.","These insights informed the design of AdaptiveCoPilot, which integrates cognitive state assessments, behavioral data, and adaptive strategies within a context-aware Large Language Model (LLM).","The system was evaluated in a virtual reality (VR) simulated cockpit with licensed pilots (N=8), comparing its performance against baseline and random feedback conditions.","The results indicate that the pilots using AdaptiveCoPilot exhibited higher rates of optimal cognitive load states on the facets of working memory and perception, along with reduced task completion times.","Based on the formative study, experimental findings, qualitative interviews, we propose a set of strategies for future development of neuroadaptive pilot guidance systems and highlight the potential of neuroadaptive systems to enhance pilot performance and safety in aviation environments."],"url":"http://arxiv.org/abs/2501.04156v1"}
{"created":"2025-01-07 21:55:56","title":"MM-GEN: Enhancing Task Performance Through Targeted Multimodal Data Curation","abstract":"Vision-language models (VLMs) are highly effective but often underperform on specialized tasks; for example, Llava-1.5 struggles with chart and diagram understanding due to scarce task-specific training data. Existing training data, sourced from general-purpose datasets, fails to capture the nuanced details needed for these tasks. We introduce MM-Gen, a scalable method that generates task-specific, high-quality synthetic text for candidate images by leveraging stronger models. MM-Gen employs a three-stage targeted process: partitioning data into subgroups, generating targeted text based on task descriptions, and filtering out redundant and outlier data. Fine-tuning VLMs with data generated by MM-Gen leads to significant performance gains, including 29% on spatial reasoning and 15% on diagram understanding for Llava-1.5 (7B). Compared to human-curated caption data, MM-Gen achieves up to 1.6x better improvements for the original models, proving its effectiveness in enhancing task-specific VLM performance and bridging the gap between general-purpose datasets and specialized requirements. Code available at https://github.com/sjoshi804/MM-Gen.","sentences":["Vision-language models (VLMs) are highly effective but often underperform on specialized tasks; for example, Llava-1.5 struggles with chart and diagram understanding due to scarce task-specific training data.","Existing training data, sourced from general-purpose datasets, fails to capture the nuanced details needed for these tasks.","We introduce MM-Gen, a scalable method that generates task-specific, high-quality synthetic text for candidate images by leveraging stronger models.","MM-Gen employs a three-stage targeted process: partitioning data into subgroups, generating targeted text based on task descriptions, and filtering out redundant and outlier data.","Fine-tuning VLMs with data generated by MM-Gen leads to significant performance gains, including 29% on spatial reasoning and 15% on diagram understanding for Llava-1.5 (7B).","Compared to human-curated caption data, MM-Gen achieves up to 1.6x better improvements for the original models, proving its effectiveness in enhancing task-specific VLM performance and bridging the gap between general-purpose datasets and specialized requirements.","Code available at https://github.com/sjoshi804/MM-Gen."],"url":"http://arxiv.org/abs/2501.04155v1"}
{"created":"2025-01-07 21:43:09","title":"Multilingual Open QA on the MIA Shared Task","abstract":"Cross-lingual information retrieval (CLIR) ~\\cite{shi2021cross, asai2021one, jiang2020cross} for example, can find relevant text in any language such as English(high resource) or Telugu (low resource) even when the query is posed in a different, possibly low-resource, language. In this work, we aim to develop useful CLIR models for this constrained, yet important, setting where we do not require any kind of additional supervision or labelled data for retrieval task and hence can work effectively for low-resource languages.   \\par We propose a simple and effective re-ranking method for improving passage retrieval in open question answering. The re-ranker re-scores retrieved passages with a zero-shot multilingual question generation model, which is a pre-trained language model, to compute the probability of the input question in the target language conditioned on a retrieved passage, which can be possibly in a different language. We evaluate our method in a completely zero shot setting and doesn't require any training. Thus the main advantage of our method is that our approach can be used to re-rank results obtained by any sparse retrieval methods like BM-25. This eliminates the need for obtaining expensive labelled corpus required for the retrieval tasks and hence can be used for low resource languages.","sentences":["Cross-lingual information retrieval (CLIR) ~\\cite{shi2021cross, asai2021one, jiang2020cross} for example, can find relevant text in any language such as English(high resource) or Telugu (low resource) even when the query is posed in a different, possibly low-resource, language.","In this work, we aim to develop useful CLIR models for this constrained, yet important, setting where we do not require any kind of additional supervision or labelled data for retrieval task and hence can work effectively for low-resource languages.   ","\\par","We propose a simple and effective re-ranking method for improving passage retrieval in open question answering.","The re-ranker re-scores retrieved passages with a zero-shot multilingual question generation model, which is a pre-trained language model, to compute the probability of the input question in the target language conditioned on a retrieved passage, which can be possibly in a different language.","We evaluate our method in a completely zero shot setting and doesn't require any training.","Thus the main advantage of our method is that our approach can be used to re-rank results obtained by any sparse retrieval methods like BM-25.","This eliminates the need for obtaining expensive labelled corpus required for the retrieval tasks and hence can be used for low resource languages."],"url":"http://arxiv.org/abs/2501.04153v1"}
{"created":"2025-01-07 21:10:16","title":"BiasGuard: Guardrailing Fairness in Machine Learning Production Systems","abstract":"As machine learning (ML) systems increasingly impact critical sectors such as hiring, financial risk assessments, and criminal justice, the imperative to ensure fairness has intensified due to potential negative implications. While much ML fairness research has focused on enhancing training data and processes, addressing the outputs of already deployed systems has received less attention. This paper introduces 'BiasGuard', a novel approach designed to act as a fairness guardrail in production ML systems. BiasGuard leverages Test-Time Augmentation (TTA) powered by Conditional Generative Adversarial Network (CTGAN), a cutting-edge generative AI model, to synthesize data samples conditioned on inverted protected attribute values, thereby promoting equitable outcomes across diverse groups. This method aims to provide equal opportunities for both privileged and unprivileged groups while significantly enhancing the fairness metrics of deployed systems without the need for retraining. Our comprehensive experimental analysis across diverse datasets reveals that BiasGuard enhances fairness by 31% while only reducing accuracy by 0.09% compared to non-mitigated benchmarks. Additionally, BiasGuard outperforms existing post-processing methods in improving fairness, positioning it as an effective tool to safeguard against biases when retraining the model is impractical.","sentences":["As machine learning (ML) systems increasingly impact critical sectors such as hiring, financial risk assessments, and criminal justice, the imperative to ensure fairness has intensified due to potential negative implications.","While much ML fairness research has focused on enhancing training data and processes, addressing the outputs of already deployed systems has received less attention.","This paper introduces 'BiasGuard', a novel approach designed to act as a fairness guardrail in production ML systems.","BiasGuard leverages Test-Time Augmentation (TTA) powered by Conditional Generative Adversarial Network (CTGAN), a cutting-edge generative AI model, to synthesize data samples conditioned on inverted protected attribute values, thereby promoting equitable outcomes across diverse groups.","This method aims to provide equal opportunities for both privileged and unprivileged groups while significantly enhancing the fairness metrics of deployed systems without the need for retraining.","Our comprehensive experimental analysis across diverse datasets reveals that BiasGuard enhances fairness by 31% while only reducing accuracy by 0.09% compared to non-mitigated benchmarks.","Additionally, BiasGuard outperforms existing post-processing methods in improving fairness, positioning it as an effective tool to safeguard against biases when retraining the model is impractical."],"url":"http://arxiv.org/abs/2501.04142v1"}
{"created":"2025-01-07 19:35:19","title":"TrojanDec: Data-free Detection of Trojan Inputs in Self-supervised Learning","abstract":"An image encoder pre-trained by self-supervised learning can be used as a general-purpose feature extractor to build downstream classifiers for various downstream tasks. However, many studies showed that an attacker can embed a trojan into an encoder such that multiple downstream classifiers built based on the trojaned encoder simultaneously inherit the trojan behavior. In this work, we propose TrojanDec, the first data-free method to identify and recover a test input embedded with a trigger. Given a (trojaned or clean) encoder and a test input, TrojanDec first predicts whether the test input is trojaned. If not, the test input is processed in a normal way to maintain the utility. Otherwise, the test input will be further restored to remove the trigger. Our extensive evaluation shows that TrojanDec can effectively identify the trojan (if any) from a given test input and recover it under state-of-the-art trojan attacks. We further demonstrate by experiments that our TrojanDec outperforms the state-of-the-art defenses.","sentences":["An image encoder pre-trained by self-supervised learning can be used as a general-purpose feature extractor to build downstream classifiers for various downstream tasks.","However, many studies showed that an attacker can embed a trojan into an encoder such that multiple downstream classifiers built based on the trojaned encoder simultaneously inherit the trojan behavior.","In this work, we propose TrojanDec, the first data-free method to identify and recover a test input embedded with a trigger.","Given a (trojaned or clean) encoder and a test input, TrojanDec first predicts whether the test input is trojaned.","If not, the test input is processed in a normal way to maintain the utility.","Otherwise, the test input will be further restored to remove the trigger.","Our extensive evaluation shows that TrojanDec can effectively identify the trojan (if any) from a given test input and recover it under state-of-the-art trojan attacks.","We further demonstrate by experiments that our TrojanDec outperforms the state-of-the-art defenses."],"url":"http://arxiv.org/abs/2501.04108v1"}
{"created":"2025-01-07 19:29:10","title":"DeepVIVONet: Using deep neural operators to optimize sensor locations with application to vortex-induced vibrations","abstract":"We introduce DeepVIVONet, a new framework for optimal dynamic reconstruction and forecasting of the vortex-induced vibrations (VIV) of a marine riser, using field data. We demonstrate the effectiveness of DeepVIVONet in accurately reconstructing the motion of an off--shore marine riser by using sparse spatio-temporal measurements. We also show the generalization of our model in extrapolating to other flow conditions via transfer learning, underscoring its potential to streamline operational efficiency and enhance predictive accuracy. The trained DeepVIVONet serves as a fast and accurate surrogate model for the marine riser, which we use in an outer--loop optimization algorithm to obtain the optimal locations for placing the sensors. Furthermore, we employ an existing sensor placement method based on proper orthogonal decomposition (POD) to compare with our data-driven approach. We find that that while POD offers a good approach for initial sensor placement, DeepVIVONet's adaptive capabilities yield more precise and cost-effective configurations.","sentences":["We introduce DeepVIVONet, a new framework for optimal dynamic reconstruction and forecasting of the vortex-induced vibrations (VIV) of a marine riser, using field data.","We demonstrate the effectiveness of DeepVIVONet in accurately reconstructing the motion of an off--shore marine riser by using sparse spatio-temporal measurements.","We also show the generalization of our model in extrapolating to other flow conditions via transfer learning, underscoring its potential to streamline operational efficiency and enhance predictive accuracy.","The trained DeepVIVONet serves as a fast and accurate surrogate model for the marine riser, which we use in an outer--loop optimization algorithm to obtain the optimal locations for placing the sensors.","Furthermore, we employ an existing sensor placement method based on proper orthogonal decomposition (POD) to compare with our data-driven approach.","We find that that while POD offers a good approach for initial sensor placement, DeepVIVONet's adaptive capabilities yield more precise and cost-effective configurations."],"url":"http://arxiv.org/abs/2501.04105v1"}
{"created":"2025-01-07 19:19:22","title":"Enhancing Distribution and Label Consistency for Graph Out-of-Distribution Generalization","abstract":"To deal with distribution shifts in graph data, various graph out-of-distribution (OOD) generalization techniques have been recently proposed. These methods often employ a two-step strategy that first creates augmented environments and subsequently identifies invariant subgraphs to improve generalizability. Nevertheless, this approach could be suboptimal from the perspective of consistency. First, the process of augmenting environments by altering the graphs while preserving labels may lead to graphs that are not realistic or meaningfully related to the origin distribution, thus lacking distribution consistency. Second, the extracted subgraphs are obtained from directly modifying graphs, and may not necessarily maintain a consistent predictive relationship with their labels, thereby impacting label consistency. In response to these challenges, we introduce an innovative approach that aims to enhance these two types of consistency for graph OOD generalization. We propose a modifier to obtain both augmented and invariant graphs in a unified manner. With the augmented graphs, we enrich the training data without compromising the integrity of label-graph relationships. The label consistency enhancement in our framework further preserves the supervision information in the invariant graph. We conduct extensive experiments on real-world datasets to demonstrate the superiority of our framework over other state-of-the-art baselines.","sentences":["To deal with distribution shifts in graph data, various graph out-of-distribution (OOD) generalization techniques have been recently proposed.","These methods often employ a two-step strategy that first creates augmented environments and subsequently identifies invariant subgraphs to improve generalizability.","Nevertheless, this approach could be suboptimal from the perspective of consistency.","First, the process of augmenting environments by altering the graphs while preserving labels may lead to graphs that are not realistic or meaningfully related to the origin distribution, thus lacking distribution consistency.","Second, the extracted subgraphs are obtained from directly modifying graphs, and may not necessarily maintain a consistent predictive relationship with their labels, thereby impacting label consistency.","In response to these challenges, we introduce an innovative approach that aims to enhance these two types of consistency for graph OOD generalization.","We propose a modifier to obtain both augmented and invariant graphs in a unified manner.","With the augmented graphs, we enrich the training data without compromising the integrity of label-graph relationships.","The label consistency enhancement in our framework further preserves the supervision information in the invariant graph.","We conduct extensive experiments on real-world datasets to demonstrate the superiority of our framework over other state-of-the-art baselines."],"url":"http://arxiv.org/abs/2501.04102v1"}
{"created":"2025-01-07 19:15:00","title":"Neighbor displacement-based enhanced synthetic oversampling for multiclass imbalanced data","abstract":"Imbalanced multiclass datasets pose challenges for machine learning algorithms. These datasets often contain minority classes that are important for accurate prediction. Existing methods still suffer from sparse data and may not accurately represent the original data patterns, leading to noise and poor model performance. A hybrid method called Neighbor Displacement-based Enhanced Synthetic Oversampling (NDESO) is proposed in this paper. This approach uses a displacement strategy for noisy data points, computing the average distance to their neighbors and moving them closer to their centroids. Random oversampling is then performed to achieve dataset balance. Extensive evaluations compare 14 alternatives on nine classifiers across synthetic and 20 real-world datasets with varying imbalance ratios. The results show that our method outperforms its competitors regarding average G-mean score and achieves the lowest statistical mean rank. This highlights its superiority and suitability for addressing data imbalance in practical applications.","sentences":["Imbalanced multiclass datasets pose challenges for machine learning algorithms.","These datasets often contain minority classes that are important for accurate prediction.","Existing methods still suffer from sparse data and may not accurately represent the original data patterns, leading to noise and poor model performance.","A hybrid method called Neighbor Displacement-based Enhanced Synthetic Oversampling (NDESO) is proposed in this paper.","This approach uses a displacement strategy for noisy data points, computing the average distance to their neighbors and moving them closer to their centroids.","Random oversampling is then performed to achieve dataset balance.","Extensive evaluations compare 14 alternatives on nine classifiers across synthetic and 20 real-world datasets with varying imbalance ratios.","The results show that our method outperforms its competitors regarding average G-mean score and achieves the lowest statistical mean rank.","This highlights its superiority and suitability for addressing data imbalance in practical applications."],"url":"http://arxiv.org/abs/2501.04099v1"}
