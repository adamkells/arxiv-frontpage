{"created":"2024-08-07 17:51:42","title":"Lower Bounds for Approximate (& Exact) k-Disjoint-Shortest-Paths","abstract":"Given a graph $G=(V,E)$ and a set $T=\\{ (s_i, t_i) : 1\\leq i\\leq k \\}\\subseteq V\\times V$ of $k$ pairs, the $k$-vertex-disjoint-paths (resp. $k$-edge-disjoint-paths) problem asks to determine whether there exist~$k$ pairwise vertex-disjoint (resp. edge-disjoint) paths $P_1, P_2, ..., P_k$ in $G$ such that, for each $1\\leq i\\leq k$, $P_i$ connects $s_i$ to $t_i$. Both the edge-disjoint and vertex-disjoint versions in undirected graphs are famously known to be FPT (parameterized by $k$) due to the Graph Minor Theory of Robertson and Seymour. Eilam-Tzoreff [DAM `98] introduced a variant, known as the $k$-disjoint-shortest-paths problem, where each individual path is further required to be a shortest path connecting its pair. They showed that the $k$-disjoint-shortest-paths problem is NP-complete on both directed and undirected graphs; this holds even if the graphs are planar and have unit edge lengths. We focus on four versions of the problem, corresponding to considering edge/vertex disjointness, and to considering directed/undirected graphs. Building on the reduction of Chitnis [SIDMA `23] for $k$-edge-disjoint-paths on planar DAGs, we obtain the following inapproximability lower bound for each of the four versions of $k$-disjoint-shortest-paths on $n$-vertex graphs: - Under Gap-ETH, there exists a constant $\\delta>0$ such that for any constant $0<\\epsilon\\leq \\frac{1}{2}$ and any computable function $f$, there is no $(\\frac{1}{2}+\\epsilon)$-approx in $f(k)\\cdot n^{\\delta\\cdot k}$ time. We further strengthen our results as follows: Directed: Inapprox lower bound for edge-disjoint (resp. vertex-disjoint) paths holds even if the input graph is a planar (resp. 1-planar) DAG with max in-degree and max out-degree at most $2$. Undirected: Inapprox lower bound for edge-disjoint (resp. vertex-disjoint) paths hold even if the input graph is planar (resp. 1-planar) and has max degree $4$.","sentences":["Given a graph $G=(V,E)$ and a set $T=\\{ (s_i, t_i) : 1\\leq i\\leq k \\}\\subseteq V\\times V$ of $k$ pairs, the $k$-vertex-disjoint-paths (resp.","$k$-edge-disjoint-paths) problem asks to determine whether there exist~$k$ pairwise vertex-disjoint (resp.","edge-disjoint) paths $P_1, P_2, ...,","P_k$ in $G$ such that, for each $1\\leq i\\leq k$, $P_i$ connects $s_i$ to $t_i$. Both the edge-disjoint and vertex-disjoint versions in undirected graphs are famously known to be FPT (parameterized by $k$) due to the Graph Minor Theory of Robertson and Seymour.","Eilam-Tzoreff [DAM `98] introduced a variant, known as the $k$-disjoint-shortest-paths problem, where each individual path is further required to be a shortest path connecting its pair.","They showed that the $k$-disjoint-shortest-paths problem is NP-complete on both directed and undirected graphs; this holds even if the graphs are planar and have unit edge lengths.","We focus on four versions of the problem, corresponding to considering edge/vertex disjointness, and to considering directed/undirected graphs.","Building on the reduction of Chitnis [SIDMA `23] for $k$-edge-disjoint-paths on planar DAGs, we obtain the following inapproximability lower bound for each of the four versions of $k$-disjoint-shortest-paths on $n$-vertex graphs: - Under Gap-ETH, there exists a constant $\\delta>0$ such that for any constant $0<\\epsilon\\leq \\frac{1}{2}$ and any computable function $f$, there is no $(\\frac{1}{2}+\\epsilon)$-approx in $f(k)\\cdot n^{\\delta\\cdot k}$ time.","We further strengthen our results as follows: Directed: Inapprox lower bound for edge-disjoint (resp. vertex-disjoint) paths holds even if the input graph is a planar (resp.","1-planar) DAG with max in-degree and max out-degree at most $2$. Undirected: Inapprox lower bound for edge-disjoint (resp.","vertex-disjoint) paths hold even if the input graph is planar (resp.","1-planar) and has max degree $4$."],"url":"http://arxiv.org/abs/2408.03933v1"}
{"created":"2024-08-07 17:19:15","title":"AdapMTL: Adaptive Pruning Framework for Multitask Learning Model","abstract":"In the domain of multimedia and multimodal processing, the efficient handling of diverse data streams such as images, video, and sensor data is paramount. Model compression and multitask learning (MTL) are crucial in this field, offering the potential to address the resource-intensive demands of processing and interpreting multiple forms of media simultaneously. However, effectively compressing a multitask model presents significant challenges due to the complexities of balancing sparsity allocation and accuracy performance across multiple tasks. To tackle these challenges, we propose AdapMTL, an adaptive pruning framework for MTL models. AdapMTL leverages multiple learnable soft thresholds independently assigned to the shared backbone and the task-specific heads to capture the nuances in different components' sensitivity to pruning. During training, it co-optimizes the soft thresholds and MTL model weights to automatically determine the suitable sparsity level at each component to achieve both high task accuracy and high overall sparsity. It further incorporates an adaptive weighting mechanism that dynamically adjusts the importance of task-specific losses based on each task's robustness to pruning. We demonstrate the effectiveness of AdapMTL through comprehensive experiments on popular multitask datasets, namely NYU-v2 and Tiny-Taskonomy, with different architectures, showcasing superior performance compared to state-of-the-art pruning methods.","sentences":["In the domain of multimedia and multimodal processing, the efficient handling of diverse data streams such as images, video, and sensor data is paramount.","Model compression and multitask learning (MTL) are crucial in this field, offering the potential to address the resource-intensive demands of processing and interpreting multiple forms of media simultaneously.","However, effectively compressing a multitask model presents significant challenges due to the complexities of balancing sparsity allocation and accuracy performance across multiple tasks.","To tackle these challenges, we propose AdapMTL, an adaptive pruning framework for MTL models.","AdapMTL leverages multiple learnable soft thresholds independently assigned to the shared backbone and the task-specific heads to capture the nuances in different components' sensitivity to pruning.","During training, it co-optimizes the soft thresholds and MTL model weights to automatically determine the suitable sparsity level at each component to achieve both high task accuracy and high overall sparsity.","It further incorporates an adaptive weighting mechanism that dynamically adjusts the importance of task-specific losses based on each task's robustness to pruning.","We demonstrate the effectiveness of AdapMTL through comprehensive experiments on popular multitask datasets, namely NYU-v2 and Tiny-Taskonomy, with different architectures, showcasing superior performance compared to state-of-the-art pruning methods."],"url":"http://arxiv.org/abs/2408.03913v1"}
{"created":"2024-08-07 17:13:46","title":"LaFA: Latent Feature Attacks on Non-negative Matrix Factorization","abstract":"As Machine Learning (ML) applications rapidly grow, concerns about adversarial attacks compromising their reliability have gained significant attention. One unsupervised ML method known for its resilience to such attacks is Non-negative Matrix Factorization (NMF), an algorithm that decomposes input data into lower-dimensional latent features. However, the introduction of powerful computational tools such as Pytorch enables the computation of gradients of the latent features with respect to the original data, raising concerns about NMF's reliability. Interestingly, naively deriving the adversarial loss for NMF as in the case of ML would result in the reconstruction loss, which can be shown theoretically to be an ineffective attacking objective. In this work, we introduce a novel class of attacks in NMF termed Latent Feature Attacks (LaFA), which aim to manipulate the latent features produced by the NMF process. Our method utilizes the Feature Error (FE) loss directly on the latent features. By employing FE loss, we generate perturbations in the original data that significantly affect the extracted latent features, revealing vulnerabilities akin to those found in other ML techniques. To handle large peak-memory overhead from gradient back-propagation in FE attacks, we develop a method based on implicit differentiation which enables their scaling to larger datasets. We validate NMF vulnerabilities and FE attacks effectiveness through extensive experiments on synthetic and real-world data.","sentences":["As Machine Learning (ML) applications rapidly grow, concerns about adversarial attacks compromising their reliability have gained significant attention.","One unsupervised ML method known for its resilience to such attacks is Non-negative Matrix Factorization (NMF), an algorithm that decomposes input data into lower-dimensional latent features.","However, the introduction of powerful computational tools such as Pytorch enables the computation of gradients of the latent features with respect to the original data, raising concerns about NMF's reliability.","Interestingly, naively deriving the adversarial loss for NMF as in the case of ML would result in the reconstruction loss, which can be shown theoretically to be an ineffective attacking objective.","In this work, we introduce a novel class of attacks in NMF termed Latent Feature Attacks (LaFA), which aim to manipulate the latent features produced by the NMF process.","Our method utilizes the Feature Error (FE) loss directly on the latent features.","By employing FE loss, we generate perturbations in the original data that significantly affect the extracted latent features, revealing vulnerabilities akin to those found in other ML techniques.","To handle large peak-memory overhead from gradient back-propagation in FE attacks, we develop a method based on implicit differentiation which enables their scaling to larger datasets.","We validate NMF vulnerabilities and FE attacks effectiveness through extensive experiments on synthetic and real-world data."],"url":"http://arxiv.org/abs/2408.03909v1"}
{"created":"2024-08-07 16:40:03","title":"The State of Reproducibility Stamps for Visualization Research Papers","abstract":"I analyze the evolution of papers certified by the Graphics Replicability Stamp Initiative (GRSI) to be reproducible, with a specific focus on the subset of publications that address visualization-related topics. With this analysis I show that, while the number of papers is increasing overall and within the visualization field, we still have to improve quite a bit to escape the replication crisis. I base my analysis on the data published by the GRSI as well as publication data for the different venues in visualization and lists of journal papers that have been presented at visualization-focused conferences. I also analyze the differences between the involved journals as well as the percentage of reproducible papers in the different presentation venues. Furthermore, I look at the authors of the publications and, in particular, their affiliation countries to see where most reproducible papers come from. Finally, I discuss potential reasons for the low reproducibility numbers and suggest possible ways to overcome these obstacles. This paper is reproducible itself, with source code and data available from github.com/tobiasisenberg/Visualization-Reproducibility as well as a free paper copy and all supplemental materials at osf.io/mvnbj.","sentences":["I analyze the evolution of papers certified by the Graphics Replicability Stamp Initiative (GRSI) to be reproducible, with a specific focus on the subset of publications that address visualization-related topics.","With this analysis I show that, while the number of papers is increasing overall and within the visualization field, we still have to improve quite a bit to escape the replication crisis.","I base my analysis on the data published by the GRSI as well as publication data for the different venues in visualization and lists of journal papers that have been presented at visualization-focused conferences.","I also analyze the differences between the involved journals as well as the percentage of reproducible papers in the different presentation venues.","Furthermore, I look at the authors of the publications and, in particular, their affiliation countries to see where most reproducible papers come from.","Finally, I discuss potential reasons for the low reproducibility numbers and suggest possible ways to overcome these obstacles.","This paper is reproducible itself, with source code and data available from github.com/tobiasisenberg/Visualization-Reproducibility as well as a free paper copy and all supplemental materials at osf.io/mvnbj."],"url":"http://arxiv.org/abs/2408.03889v1"}
{"created":"2024-08-07 16:35:10","title":"Retrieval Augmentation via User Interest Clustering","abstract":"Many existing industrial recommender systems are sensitive to the patterns of user-item engagement. Light users, who interact less frequently, correspond to a data sparsity problem, making it difficult for the system to accurately learn and represent their preferences. On the other hand, heavy users with rich interaction history often demonstrate a variety of niche interests that are hard to be precisely captured under the standard \"user-item\" similarity measurement. Moreover, implementing these systems in an industrial environment necessitates that they are resource-efficient and scalable to process web-scale data under strict latency constraints. In this paper, we address these challenges by introducing an intermediate \"interest\" layer between users and items. We propose a novel approach that efficiently constructs user interest and facilitates low computational cost inference by clustering engagement graphs and incorporating user-interest attention. This method enhances the understanding of light users' preferences by linking them with heavy users. By integrating user-interest attention, our approach allows a more personalized similarity metric, adept at capturing the complex dynamics of user-item interactions. The use of interest as an intermediary layer fosters a balance between scalability and expressiveness in the model. Evaluations on two public datasets reveal that our method not only achieves improved recommendation performance but also demonstrates enhanced computational efficiency compared to item-level attention models. Our approach has also been deployed in multiple products at Meta, facilitating short-form video related recommendation.","sentences":["Many existing industrial recommender systems are sensitive to the patterns of user-item engagement.","Light users, who interact less frequently, correspond to a data sparsity problem, making it difficult for the system to accurately learn and represent their preferences.","On the other hand, heavy users with rich interaction history often demonstrate a variety of niche interests that are hard to be precisely captured under the standard \"user-item\" similarity measurement.","Moreover, implementing these systems in an industrial environment necessitates that they are resource-efficient and scalable to process web-scale data under strict latency constraints.","In this paper, we address these challenges by introducing an intermediate \"interest\" layer between users and items.","We propose a novel approach that efficiently constructs user interest and facilitates low computational cost inference by clustering engagement graphs and incorporating user-interest attention.","This method enhances the understanding of light users' preferences by linking them with heavy users.","By integrating user-interest attention, our approach allows a more personalized similarity metric, adept at capturing the complex dynamics of user-item interactions.","The use of interest as an intermediary layer fosters a balance between scalability and expressiveness in the model.","Evaluations on two public datasets reveal that our method not only achieves improved recommendation performance but also demonstrates enhanced computational efficiency compared to item-level attention models.","Our approach has also been deployed in multiple products at Meta, facilitating short-form video related recommendation."],"url":"http://arxiv.org/abs/2408.03886v1"}
{"created":"2024-08-07 16:34:32","title":"Global-Local Progressive Integration Network for Blind Image Quality Assessment","abstract":"Vision transformers (ViTs) excel in computer vision for modeling long-term dependencies, yet face two key challenges for image quality assessment (IQA): discarding fine details during patch embedding, and requiring extensive training data due to lack of inductive biases. In this study, we propose a Global-Local progressive INTegration network for IQA, called GlintIQA, to address these issues through three key components: 1) Hybrid feature extraction combines ViT-based global feature extractor (VGFE) and convolutional neural networks (CNNs)-based local feature extractor (CLFE) to capture global coarse-grained features and local fine-grained features, respectively. The incorporation of CNNs mitigates the patch-level information loss and inductive bias constraints inherent to ViT architectures. 2) Progressive feature integration leverages diverse kernel sizes in embedding to spatially align coarse- and fine-grained features, and progressively aggregate these features by interactively stacking channel-wise attention and spatial enhancement modules to build effective quality-aware representations. 3) Content similarity-based labeling approach is proposed that automatically assigns quality labels to images with diverse content based on subjective quality scores. This addresses the scarcity of labeled training data in synthetic datasets and bolsters model generalization. The experimental results demonstrate the efficacy of our approach, yielding 5.04% average SROCC gains on cross-authentic dataset evaluations. Moreover, our model and its counterpart pre-trained on the proposed dataset respectively exhibited 5.40% and 13.23% improvements on across-synthetic datasets evaluation. The codes and proposed dataset will be released at https://github.com/XiaoqiWang/GlintIQA.","sentences":["Vision transformers (ViTs) excel in computer vision for modeling long-term dependencies, yet face two key challenges for image quality assessment (IQA): discarding fine details during patch embedding, and requiring extensive training data due to lack of inductive biases.","In this study, we propose a Global-Local progressive INTegration network for IQA, called GlintIQA, to address these issues through three key components: 1) Hybrid feature extraction combines ViT-based global feature extractor (VGFE) and convolutional neural networks (CNNs)-based local feature extractor (CLFE) to capture global coarse-grained features and local fine-grained features, respectively.","The incorporation of CNNs mitigates the patch-level information loss and inductive bias constraints inherent to ViT architectures.","2) Progressive feature integration leverages diverse kernel sizes in embedding to spatially align coarse- and fine-grained features, and progressively aggregate these features by interactively stacking channel-wise attention and spatial enhancement modules to build effective quality-aware representations.","3) Content similarity-based labeling approach is proposed that automatically assigns quality labels to images with diverse content based on subjective quality scores.","This addresses the scarcity of labeled training data in synthetic datasets and bolsters model generalization.","The experimental results demonstrate the efficacy of our approach, yielding 5.04% average SROCC gains on cross-authentic dataset evaluations.","Moreover, our model and its counterpart pre-trained on the proposed dataset respectively exhibited 5.40% and 13.23% improvements on across-synthetic datasets evaluation.","The codes and proposed dataset will be released at https://github.com/XiaoqiWang/GlintIQA."],"url":"http://arxiv.org/abs/2408.03885v1"}
{"created":"2024-08-07 16:25:39","title":"From Data to Story: Towards Automatic Animated Data Video Creation with LLM-based Multi-Agent Systems","abstract":"Creating data stories from raw data is challenging due to humans' limited attention spans and the need for specialized skills. Recent advancements in large language models (LLMs) offer great opportunities to develop systems with autonomous agents to streamline the data storytelling workflow. Though multi-agent systems have benefits such as fully realizing LLM potentials with decomposed tasks for individual agents, designing such systems also faces challenges in task decomposition, performance optimization for sub-tasks, and workflow design. To better understand these issues, we develop Data Director, an LLM-based multi-agent system designed to automate the creation of animated data videos, a representative genre of data stories. Data Director interprets raw data, breaks down tasks, designs agent roles to make informed decisions automatically, and seamlessly integrates diverse components of data videos. A case study demonstrates Data Director's effectiveness in generating data videos. Throughout development, we have derived lessons learned from addressing challenges, guiding further advancements in autonomous agents for data storytelling. We also shed light on future directions for global optimization, human-in-the-loop design, and the application of advanced multi-modal LLMs.","sentences":["Creating data stories from raw data is challenging due to humans' limited attention spans and the need for specialized skills.","Recent advancements in large language models (LLMs) offer great opportunities to develop systems with autonomous agents to streamline the data storytelling workflow.","Though multi-agent systems have benefits such as fully realizing LLM potentials with decomposed tasks for individual agents, designing such systems also faces challenges in task decomposition, performance optimization for sub-tasks, and workflow design.","To better understand these issues, we develop Data Director, an LLM-based multi-agent system designed to automate the creation of animated data videos, a representative genre of data stories.","Data Director interprets raw data, breaks down tasks, designs agent roles to make informed decisions automatically, and seamlessly integrates diverse components of data videos.","A case study demonstrates Data Director's effectiveness in generating data videos.","Throughout development, we have derived lessons learned from addressing challenges, guiding further advancements in autonomous agents for data storytelling.","We also shed light on future directions for global optimization, human-in-the-loop design, and the application of advanced multi-modal LLMs."],"url":"http://arxiv.org/abs/2408.03876v1"}
{"created":"2024-08-07 16:23:29","title":"A Reproducible Analysis of Sequential Recommender Systems","abstract":"Sequential Recommender Systems (SRSs) have emerged as a highly efficient approach to recommendation systems. By leveraging sequential data, SRSs can identify temporal patterns in user behaviour, significantly improving recommendation accuracy and relevance.Ensuring the reproducibility of these models is paramount for advancing research and facilitating comparisons between them. Existing works exhibit shortcomings in reproducibility and replicability of results, leading to inconsistent statements across papers. Our work fills these gaps by standardising data pre-processing and model implementations, providing a comprehensive code resource, including a framework for developing SRSs and establishing a foundation for consistent and reproducible experimentation. We conduct extensive experiments on several benchmark datasets, comparing various SRSs implemented in our resource. We challenge prevailing performance benchmarks, offering new insights into the SR domain. For instance, SASRec does not consistently outperform GRU4Rec. On the contrary, when the number of model parameters becomes substantial, SASRec starts to clearly dominate all the other SRSs. This discrepancy underscores the significant impact that experimental configuration has on the outcomes and the importance of setting it up to ensure precise and comprehensive results. Failure to do so can lead to significantly flawed conclusions, highlighting the need for rigorous experimental design and analysis in SRS research. Our code is available at https://github.com/antoniopurificato/recsys_repro_conf.","sentences":["Sequential Recommender Systems (SRSs) have emerged as a highly efficient approach to recommendation systems.","By leveraging sequential data, SRSs can identify temporal patterns in user behaviour, significantly improving recommendation accuracy and relevance.","Ensuring the reproducibility of these models is paramount for advancing research and facilitating comparisons between them.","Existing works exhibit shortcomings in reproducibility and replicability of results, leading to inconsistent statements across papers.","Our work fills these gaps by standardising data pre-processing and model implementations, providing a comprehensive code resource, including a framework for developing SRSs and establishing a foundation for consistent and reproducible experimentation.","We conduct extensive experiments on several benchmark datasets, comparing various SRSs implemented in our resource.","We challenge prevailing performance benchmarks, offering new insights into the SR domain.","For instance, SASRec does not consistently outperform GRU4Rec.","On the contrary, when the number of model parameters becomes substantial, SASRec starts to clearly dominate all the other SRSs.","This discrepancy underscores the significant impact that experimental configuration has on the outcomes and the importance of setting it up to ensure precise and comprehensive results.","Failure to do so can lead to significantly flawed conclusions, highlighting the need for rigorous experimental design and analysis in SRS research.","Our code is available at https://github.com/antoniopurificato/recsys_repro_conf."],"url":"http://arxiv.org/abs/2408.03873v1"}
{"created":"2024-08-07 16:21:41","title":"BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability","abstract":"In this system report, we describe the models and methods we used for our participation in the PLABA2023 task on biomedical abstract simplification, part of the TAC 2023 tracks. The system outputs we submitted come from the following three categories: 1) domain fine-tuned T5-like models including Biomedical-T5 and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes (via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we carried out for this task on BioGPT finetuning. In the official automatic evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model LaySciFive ranks 3rd among all 13 evaluated systems. In the official human evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score 92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It also produced a high score 91.57 on Fluency in comparison to the highest score 93.53. In the second round of submissions, our team using ChatGPT-prompting ranks the 2nd in several categories including simplified term accuracy score 92.26 and completeness score 96.58, and a very similar score on faithfulness score 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our codes, fine-tuned models, prompts, and data splits from the system development stage will be available at https://github.com/ HECTA-UoM/PLABA-MU","sentences":["In this system report, we describe the models and methods we used for our participation in the PLABA2023 task on biomedical abstract simplification, part of the TAC 2023 tracks.","The system outputs we submitted come from the following three categories: 1) domain fine-tuned T5-like models including Biomedical-T5 and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes (via tokens) BART-w-CTs; 3) ChatGPTprompting.","We also present the work we carried out for this task on BioGPT finetuning.","In the official automatic evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model LaySciFive ranks 3rd among all 13 evaluated systems.","In the official human evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score 92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It also produced a high score 91.57 on Fluency in comparison to the highest score 93.53.","In the second round of submissions, our team using ChatGPT-prompting ranks the 2nd in several categories including simplified term accuracy score 92.26 and completeness score 96.58, and a very similar score on faithfulness score 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations.","Our codes, fine-tuned models, prompts, and data splits from the system development stage will be available at https://github.com/ HECTA-UoM/PLABA-MU"],"url":"http://arxiv.org/abs/2408.03871v1"}
{"created":"2024-08-07 16:18:38","title":"'Intelligence Studies Network': A human-curated database for indexing resources with open-source tools","abstract":"The Intelligence Studies Network is a comprehensive resource database for publications, events, conferences, and calls for papers in the field of intelligence studies. It offers a novel solution for monitoring, indexing, and visualising resources. Sources are automatically monitored and added to a manually curated database, ensuring the relevance of items to intelligence studies. Curated outputs are stored in a group library on Zotero, an open-source reference management tool. The metadata of items in Zotero is enriched with OpenAlex, an open access bibliographic database. Finally, outputs are listed and visualised on a Streamlit app, an open-source Python framework for building apps. This paper aims to explain the Intelligence Studies Network database and provide a detailed guide on data sources and the workflow. This study demonstrates that it is possible to create a specialised academic database by using open source tools.","sentences":["The Intelligence Studies Network is a comprehensive resource database for publications, events, conferences, and calls for papers in the field of intelligence studies.","It offers a novel solution for monitoring, indexing, and visualising resources.","Sources are automatically monitored and added to a manually curated database, ensuring the relevance of items to intelligence studies.","Curated outputs are stored in a group library on Zotero, an open-source reference management tool.","The metadata of items in Zotero is enriched with OpenAlex, an open access bibliographic database.","Finally, outputs are listed and visualised on a Streamlit app, an open-source Python framework for building apps.","This paper aims to explain the Intelligence Studies Network database and provide a detailed guide on data sources and the workflow.","This study demonstrates that it is possible to create a specialised academic database by using open source tools."],"url":"http://arxiv.org/abs/2408.03868v1"}
{"created":"2024-08-07 15:46:45","title":"Hate Speech Detection and Classification in Amharic Text with Deep Learning","abstract":"Hate speech is a growing problem on social media. It can seriously impact society, especially in countries like Ethiopia, where it can trigger conflicts among diverse ethnic and religious groups. While hate speech detection in resource rich languages are progressing, for low resource languages such as Amharic are lacking. To address this gap, we develop Amharic hate speech data and SBi-LSTM deep learning model that can detect and classify text into four categories of hate speech: racial, religious, gender, and non-hate speech. We have annotated 5k Amharic social media post and comment data into four categories. The data is annotated using a custom annotation tool by a total of 100 native Amharic speakers. The model achieves a 94.8 F1-score performance. Future improvements will include expanding the dataset and develop state-of-the art models.   Keywords: Amharic hate speech detection, classification, Amharic dataset, Deep Learning, SBi-LSTM","sentences":["Hate speech is a growing problem on social media.","It can seriously impact society, especially in countries like Ethiopia, where it can trigger conflicts among diverse ethnic and religious groups.","While hate speech detection in resource rich languages are progressing, for low resource languages such as Amharic are lacking.","To address this gap, we develop Amharic hate speech data and SBi-LSTM deep learning model that can detect and classify text into four categories of hate speech: racial, religious, gender, and non-hate speech.","We have annotated 5k Amharic social media post and comment data into four categories.","The data is annotated using a custom annotation tool by a total of 100 native Amharic speakers.","The model achieves a 94.8 F1-score performance.","Future improvements will include expanding the dataset and develop state-of-the art models.   ","Keywords:","Amharic hate speech detection, classification, Amharic dataset, Deep Learning, SBi-LSTM"],"url":"http://arxiv.org/abs/2408.03849v1"}
{"created":"2024-08-07 15:35:25","title":"Bi-Level Spatial and Channel-aware Transformer for Learned Image Compression","abstract":"Recent advancements in learned image compression (LIC) methods have demonstrated superior performance over traditional hand-crafted codecs. These learning-based methods often employ convolutional neural networks (CNNs) or Transformer-based architectures. However, these nonlinear approaches frequently overlook the frequency characteristics of images, which limits their compression efficiency. To address this issue, we propose a novel Transformer-based image compression method that enhances the transformation stage by considering frequency components within the feature map. Our method integrates a novel Hybrid Spatial-Channel Attention Transformer Block (HSCATB), where a spatial-based branch independently handles high and low frequencies at the attention layer, and a Channel-aware Self-Attention (CaSA) module captures information across channels, significantly improving compression performance. Additionally, we introduce a Mixed Local-Global Feed Forward Network (MLGFFN) within the Transformer block to enhance the extraction of diverse and rich information, which is crucial for effective compression. These innovations collectively improve the transformation's ability to project data into a more decorrelated latent space, thereby boosting overall compression efficiency. Experimental results demonstrate that our framework surpasses state-of-the-art LIC methods in rate-distortion performance.","sentences":["Recent advancements in learned image compression (LIC) methods have demonstrated superior performance over traditional hand-crafted codecs.","These learning-based methods often employ convolutional neural networks (CNNs) or Transformer-based architectures.","However, these nonlinear approaches frequently overlook the frequency characteristics of images, which limits their compression efficiency.","To address this issue, we propose a novel Transformer-based image compression method that enhances the transformation stage by considering frequency components within the feature map.","Our method integrates a novel Hybrid Spatial-Channel Attention Transformer Block (HSCATB), where a spatial-based branch independently handles high and low frequencies at the attention layer, and a Channel-aware Self-Attention (CaSA) module captures information across channels, significantly improving compression performance.","Additionally, we introduce a Mixed Local-Global Feed Forward Network (MLGFFN) within the Transformer block to enhance the extraction of diverse and rich information, which is crucial for effective compression.","These innovations collectively improve the transformation's ability to project data into a more decorrelated latent space, thereby boosting overall compression efficiency.","Experimental results demonstrate that our framework surpasses state-of-the-art LIC methods in rate-distortion performance."],"url":"http://arxiv.org/abs/2408.03842v1"}
{"created":"2024-08-07 15:25:50","title":"On Fast SC-based Polar Decoders: Metric Polarization and a Pruning Technique","abstract":"Short- to medium-block-length polar-like and polarization-adjusted convolutional (PAC) codes have demonstrated exceptional error-correction performance through sequential decoding. Successive cancellation list (SCL) decoding of polar-like and PAC codes can potentially match the performance of sequential decoding though a relatively large list size is often required. By benefiting from an optimal metric function, sequential decoding can find the correct path corresponding to the transmitted data by following almost one path on average at high Eb/N0 regimes. When considering a large number of paths in SCL decoding, a main bottleneck emerges that is the need for a rather expensive sorting operation at each level of decoding of data bits. In this paper, we propose a method to obtain the optimal metric function for each depth of the polarization tree through a process that we call polarization of the metric function. One of the major advantages of the proposed metric function is that it can be utilized in fast SC-based (FSC) and SCL-based (FSCL) decoders, i.e., decoders that opt to skip the so-called rate-1 and rate-0 nodes in the binary tree representation for significantly more efficient implementation. Furthermore, based on the average value of the polarized metric function of FSC-based decoders, we introduce a pruning technique that keeps only the paths whose metric values are close to the average value. As a result, our proposed technique significantly reduces the number of required sorting operations for FSCL-based decoding algorithms. For instance, for a high-rate PAC(128,99) code, SCL decoding with a list size of 32 achieves error-correction performance comparable to the Fano algorithm. Our method reduces the number of sorting operations of FSCL decoding to 33%, further decreasing latency.","sentences":["Short- to medium-block-length polar-like and polarization-adjusted convolutional (PAC) codes have demonstrated exceptional error-correction performance through sequential decoding.","Successive cancellation list (SCL) decoding of polar-like and PAC codes can potentially match the performance of sequential decoding though a relatively large list size is often required.","By benefiting from an optimal metric function, sequential decoding can find the correct path corresponding to the transmitted data by following almost one path on average at high Eb/N0 regimes.","When considering a large number of paths in SCL decoding, a main bottleneck emerges that is the need for a rather expensive sorting operation at each level of decoding of data bits.","In this paper, we propose a method to obtain the optimal metric function for each depth of the polarization tree through a process that we call polarization of the metric function.","One of the major advantages of the proposed metric function is that it can be utilized in fast SC-based (FSC) and SCL-based (FSCL) decoders, i.e., decoders that opt to skip the so-called rate-1 and rate-0 nodes in the binary tree representation for significantly more efficient implementation.","Furthermore, based on the average value of the polarized metric function of FSC-based decoders, we introduce a pruning technique that keeps only the paths whose metric values are close to the average value.","As a result, our proposed technique significantly reduces the number of required sorting operations for FSCL-based decoding algorithms.","For instance, for a high-rate PAC(128,99) code, SCL decoding with a list size of 32 achieves error-correction performance comparable to the Fano algorithm.","Our method reduces the number of sorting operations of FSCL decoding to 33%, further decreasing latency."],"url":"http://arxiv.org/abs/2408.03840v1"}
{"created":"2024-08-07 15:24:25","title":"Using a Distance Sensor to Detect Deviations in a Planar Surface","abstract":"We investigate methods for determining if a planar surface contains geometric deviations (e.g., protrusions, objects, divots, or cliffs) using only an instantaneous measurement from a miniature optical time-of-flight sensor. The key to our method is to utilize the entirety of information encoded in raw time-of-flight data captured by off-the-shelf distance sensors. We provide an analysis of the problem in which we identify the key ambiguity between geometry and surface photometrics. To overcome this challenging ambiguity, we fit a Gaussian mixture model to a small dataset of planar surface measurements. This model implicitly captures the expected geometry and distribution of photometrics of the planar surface and is used to identify measurements that are likely to contain deviations. We characterize our method on a variety of surfaces and planar deviations across a range of scenarios. We find that our method utilizing raw time-of-flight data outperforms baselines which use only derived distance estimates. We build an example application in which our method enables mobile robot obstacle and cliff avoidance over a wide field-of-view.","sentences":["We investigate methods for determining if a planar surface contains geometric deviations (e.g., protrusions, objects, divots, or cliffs) using only an instantaneous measurement from a miniature optical time-of-flight sensor.","The key to our method is to utilize the entirety of information encoded in raw time-of-flight data captured by off-the-shelf distance sensors.","We provide an analysis of the problem in which we identify the key ambiguity between geometry and surface photometrics.","To overcome this challenging ambiguity, we fit a Gaussian mixture model to a small dataset of planar surface measurements.","This model implicitly captures the expected geometry and distribution of photometrics of the planar surface and is used to identify measurements that are likely to contain deviations.","We characterize our method on a variety of surfaces and planar deviations across a range of scenarios.","We find that our method utilizing raw time-of-flight data outperforms baselines which use only derived distance estimates.","We build an example application in which our method enables mobile robot obstacle and cliff avoidance over a wide field-of-view."],"url":"http://arxiv.org/abs/2408.03838v1"}
{"created":"2024-08-07 15:06:51","title":"More than 'Left and Right': Revealing Multilevel Online Political Selective Exposure","abstract":"Selective exposure, individuals' inclination to seek out information that supports their beliefs while avoiding information that contradicts them, plays an important role in the emergence of polarization. In the political domain, selective exposure is usually measured on a left-right ideology scale, ignoring finer details. Here, we combine survey and Twitter data collected during the 2022 Brazilian Presidential Election and investigate selective exposure patterns between the survey respondents and political influencers. We analyze the followship network between survey respondents and political influencers and find a multilevel community structure that reveals a hierarchical organization more complex than a simple split between left and right. Moreover, depending on the level we consider, we find different associations between network indices of exposure patterns and 189 individual attributes of the survey respondents. For example, at finer levels, the number of influencer communities a survey respondent follows is associated with several factors, such as demographics, news consumption frequency, and incivility perception. In comparison, only their political ideology is a significant factor at coarser levels. Our work demonstrates that measuring selective exposure at a single level, such as left and right, misses important information necessary to capture this phenomenon correctly.","sentences":["Selective exposure, individuals' inclination to seek out information that supports their beliefs while avoiding information that contradicts them, plays an important role in the emergence of polarization.","In the political domain, selective exposure is usually measured on a left-right ideology scale, ignoring finer details.","Here, we combine survey and Twitter data collected during the 2022 Brazilian Presidential Election and investigate selective exposure patterns between the survey respondents and political influencers.","We analyze the followship network between survey respondents and political influencers and find a multilevel community structure that reveals a hierarchical organization more complex than a simple split between left and right.","Moreover, depending on the level we consider, we find different associations between network indices of exposure patterns and 189 individual attributes of the survey respondents.","For example, at finer levels, the number of influencer communities a survey respondent follows is associated with several factors, such as demographics, news consumption frequency, and incivility perception.","In comparison, only their political ideology is a significant factor at coarser levels.","Our work demonstrates that measuring selective exposure at a single level, such as left and right, misses important information necessary to capture this phenomenon correctly."],"url":"http://arxiv.org/abs/2408.03828v1"}
{"created":"2024-08-07 14:55:04","title":"Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning","abstract":"Active Learning (AL) allows models to learn interactively from user feedback. This paper introduces a counterfactual data augmentation approach to AL, particularly addressing the selection of datapoints for user querying, a pivotal concern in enhancing data efficiency. Our approach is inspired by Variation Theory, a theory of human concept learning that emphasizes the essential features of a concept by focusing on what stays the same and what changes. Instead of just querying with existing datapoints, our approach synthesizes artificial datapoints that highlight potential key similarities and differences among labels using a neuro-symbolic pipeline combining large language models (LLMs) and rule-based models. Through an experiment in the example domain of text classification, we show that our approach achieves significantly higher performance when there are fewer annotated data. As the annotated training data gets larger the impact of the generated data starts to diminish showing its capability to address the cold start problem in AL. This research sheds light on integrating theories of human learning into the optimization of AL.","sentences":["Active Learning (AL) allows models to learn interactively from user feedback.","This paper introduces a counterfactual data augmentation approach to AL, particularly addressing the selection of datapoints for user querying, a pivotal concern in enhancing data efficiency.","Our approach is inspired by Variation Theory, a theory of human concept learning that emphasizes the essential features of a concept by focusing on what stays the same and what changes.","Instead of just querying with existing datapoints, our approach synthesizes artificial datapoints that highlight potential key similarities and differences among labels using a neuro-symbolic pipeline combining large language models (LLMs) and rule-based models.","Through an experiment in the example domain of text classification, we show that our approach achieves significantly higher performance when there are fewer annotated data.","As the annotated training data gets larger the impact of the generated data starts to diminish showing its capability to address the cold start problem in AL.","This research sheds light on integrating theories of human learning into the optimization of AL."],"url":"http://arxiv.org/abs/2408.03819v1"}
{"created":"2024-08-07 14:54:04","title":"Interactive Visual Analysis of Spatial Sensitivities","abstract":"Sensitivity analyses of simulation ensembles determine how simulation parameters influence the simulation's outcome. Commonly, one global numerical sensitivity value is computed per simulation parameter. However, when considering 3D spatial simulations, the analysis of localized sensitivities in different spatial regions is of importance in many applications. For analyzing the spatial variation of parameter sensitivity, one needs to compute a spatial sensitivity scalar field per simulation parameter. Given $n$ simulation parameters, we obtain multi-field data consisting of $n$ scalar fields when considering all simulation parameters. We propose an interactive visual analytics solution to analyze the multi-field sensitivity data. It supports the investigation of how strongly and in what way individual parameters influence the simulation outcome, in which spatial regions this is happening, and what the interplay of the simulation parameters is. Its central component is an overview visualization of all sensitivity fields that avoids 3D occlusions by linearizing the data using an adapted scheme of data-driven space-filling curves. The spatial sensitivity values are visualized in a combination of a Horizon Graph and a line chart. We validate our approach by applying it to synthetic and real-world ensemble data.","sentences":["Sensitivity analyses of simulation ensembles determine how simulation parameters influence the simulation's outcome.","Commonly, one global numerical sensitivity value is computed per simulation parameter.","However, when considering 3D spatial simulations, the analysis of localized sensitivities in different spatial regions is of importance in many applications.","For analyzing the spatial variation of parameter sensitivity, one needs to compute a spatial sensitivity scalar field per simulation parameter.","Given $n$ simulation parameters, we obtain multi-field data consisting of $n$ scalar fields when considering all simulation parameters.","We propose an interactive visual analytics solution to analyze the multi-field sensitivity data.","It supports the investigation of how strongly and in what way individual parameters influence the simulation outcome, in which spatial regions this is happening, and what the interplay of the simulation parameters is.","Its central component is an overview visualization of all sensitivity fields that avoids 3D occlusions by linearizing the data using an adapted scheme of data-driven space-filling curves.","The spatial sensitivity values are visualized in a combination of a Horizon Graph and a line chart.","We validate our approach by applying it to synthetic and real-world ensemble data."],"url":"http://arxiv.org/abs/2408.03817v1"}
{"created":"2024-08-07 14:52:06","title":"Early Prediction of Causes (not Effects) in Healthcare by Long-Term Clinical Time Series Forecasting","abstract":"Machine learning for early syndrome diagnosis aims to solve the intricate task of predicting a ground truth label that most often is the outcome (effect) of a medical consensus definition applied to observed clinical measurements (causes), given clinical measurements observed several hours before. Instead of focusing on the prediction of the future effect, we propose to directly predict the causes via time series forecasting (TSF) of clinical variables and determine the effect by applying the gold standard consensus definition to the forecasted values. This method has the invaluable advantage of being straightforwardly interpretable to clinical practitioners, and because model training does not rely on a particular label anymore, the forecasted data can be used to predict any consensus-based label. We exemplify our method by means of long-term TSF with Transformer models, with a focus on accurate prediction of sparse clinical variables involved in the SOFA-based Sepsis-3 definition and the new Simplified Acute Physiology Score (SAPS-II) definition. Our experiments are conducted on two datasets and show that contrary to recent proposals which advocate set function encoders for time series and direct multi-step decoders, best results are achieved by a combination of standard dense encoders with iterative multi-step decoders. The key for success of iterative multi-step decoding can be attributed to its ability to capture cross-variate dependencies and to a student forcing training strategy that teaches the model to rely on its own previous time step predictions for the next time step prediction.","sentences":["Machine learning for early syndrome diagnosis aims to solve the intricate task of predicting a ground truth label that most often is the outcome (effect) of a medical consensus definition applied to observed clinical measurements (causes), given clinical measurements observed several hours before.","Instead of focusing on the prediction of the future effect, we propose to directly predict the causes via time series forecasting (TSF) of clinical variables and determine the effect by applying the gold standard consensus definition to the forecasted values.","This method has the invaluable advantage of being straightforwardly interpretable to clinical practitioners, and because model training does not rely on a particular label anymore, the forecasted data can be used to predict any consensus-based label.","We exemplify our method by means of long-term TSF with Transformer models, with a focus on accurate prediction of sparse clinical variables involved in the SOFA-based Sepsis-3 definition and the new Simplified Acute Physiology Score (SAPS-II) definition.","Our experiments are conducted on two datasets and show that contrary to recent proposals which advocate set function encoders for time series and direct multi-step decoders, best results are achieved by a combination of standard dense encoders with iterative multi-step decoders.","The key for success of iterative multi-step decoding can be attributed to its ability to capture cross-variate dependencies and to a student forcing training strategy that teaches the model to rely on its own previous time step predictions for the next time step prediction."],"url":"http://arxiv.org/abs/2408.03816v1"}
{"created":"2024-08-07 14:48:49","title":"Talk to the Wall: The Role of Speech Interaction in Collaborative Visual Analytics","abstract":"We present the results of an exploratory study on how pairs interact with speech commands and touch gestures on a wall-sized display during a collaborative sensemaking task. Previous work has shown that speech commands, alone or in combination with other input modalities, can support visual data exploration by individuals. However, it is still unknown whether and how speech commands can be used in collaboration, and for what tasks. To answer these questions, we developed a functioning prototype that we used as a technology probe. We conducted an in-depth exploratory study with 10 participant pairs to analyze their interaction choices, the interplay between the input modalities, and their collaboration. While touch was the most used modality, we found that participants preferred speech commands for global operations, used them for distant interaction, and that speech interaction contributed to the awareness of the partner's actions. Furthermore, the likelihood of using speech commands during collaboration was related to the personality trait of agreeableness. Regarding collaboration styles, participants interacted with speech equally often whether they were in loosely or closely coupled collaboration. While the partners stood closer to each other during close collaboration, they did not distance themselves to use speech commands. From our findings, we derive and contribute a set of design considerations for collaborative and multimodal interactive data analysis systems. All supplemental materials are available at https://osf.io/8gpv2","sentences":["We present the results of an exploratory study on how pairs interact with speech commands and touch gestures on a wall-sized display during a collaborative sensemaking task.","Previous work has shown that speech commands, alone or in combination with other input modalities, can support visual data exploration by individuals.","However, it is still unknown whether and how speech commands can be used in collaboration, and for what tasks.","To answer these questions, we developed a functioning prototype that we used as a technology probe.","We conducted an in-depth exploratory study with 10 participant pairs to analyze their interaction choices, the interplay between the input modalities, and their collaboration.","While touch was the most used modality, we found that participants preferred speech commands for global operations, used them for distant interaction, and that speech interaction contributed to the awareness of the partner's actions.","Furthermore, the likelihood of using speech commands during collaboration was related to the personality trait of agreeableness.","Regarding collaboration styles, participants interacted with speech equally often whether they were in loosely or closely coupled collaboration.","While the partners stood closer to each other during close collaboration, they did not distance themselves to use speech commands.","From our findings, we derive and contribute a set of design considerations for collaborative and multimodal interactive data analysis systems.","All supplemental materials are available at https://osf.io/8gpv2"],"url":"http://arxiv.org/abs/2408.03813v1"}
{"created":"2024-08-07 14:25:18","title":"Building and Eroding: Exogenous and Endogenous Factors that Influence Subjective Trust in Visualization","abstract":"Trust is a subjective yet fundamental component of human-computer interaction, and is a determining factor in shaping the efficacy of data visualizations. Prior research has identified five dimensions of trust assessment in visualizations (credibility, clarity, reliability, familiarity, and confidence), and observed that these dimensions tend to vary predictably along with certain features of the visualization being evaluated. This raises a further question: how do the design features driving viewers trust assessment vary with the characteristics of the viewers themselves? By reanalyzing data from these studies through the lens of individual differences, we build a more detailed map of the relationships between design features, individual characteristics, and trust behaviors. In particular, we model the distinct contributions of endogenous design features (such as visualization type, or the use of color) and exogenous user characteristics (such as visualization literacy), as well as the interactions between them. We then use these findings to make recommendations for individualized and adaptive visualization design.","sentences":["Trust is a subjective yet fundamental component of human-computer interaction, and is a determining factor in shaping the efficacy of data visualizations.","Prior research has identified five dimensions of trust assessment in visualizations (credibility, clarity, reliability, familiarity, and confidence), and observed that these dimensions tend to vary predictably along with certain features of the visualization being evaluated.","This raises a further question: how do the design features driving viewers trust assessment vary with the characteristics of the viewers themselves?","By reanalyzing data from these studies through the lens of individual differences, we build a more detailed map of the relationships between design features, individual characteristics, and trust behaviors.","In particular, we model the distinct contributions of endogenous design features (such as visualization type, or the use of color) and exogenous user characteristics (such as visualization literacy), as well as the interactions between them.","We then use these findings to make recommendations for individualized and adaptive visualization design."],"url":"http://arxiv.org/abs/2408.03800v1"}
{"created":"2024-08-07 14:14:53","title":"Vision-Language Guidance for LiDAR-based Unsupervised 3D Object Detection","abstract":"Accurate 3D object detection in LiDAR point clouds is crucial for autonomous driving systems. To achieve state-of-the-art performance, the supervised training of detectors requires large amounts of human-annotated data, which is expensive to obtain and restricted to predefined object categories. To mitigate manual labeling efforts, recent unsupervised object detection approaches generate class-agnostic pseudo-labels for moving objects, subsequently serving as supervision signal to bootstrap a detector. Despite promising results, these approaches do not provide class labels or generalize well to static objects. Furthermore, they are mostly restricted to data containing multiple drives from the same scene or images from a precisely calibrated and synchronized camera setup. To overcome these limitations, we propose a vision-language-guided unsupervised 3D detection approach that operates exclusively on LiDAR point clouds. We transfer CLIP knowledge to classify point clusters of static and moving objects, which we discover by exploiting the inherent spatio-temporal information of LiDAR point clouds for clustering, tracking, as well as box and label refinement. Our approach outperforms state-of-the-art unsupervised 3D object detectors on the Waymo Open Dataset ($+23~\\text{AP}_{3D}$) and Argoverse 2 ($+7.9~\\text{AP}_{3D}$) and provides class labels not solely based on object size assumptions, marking a significant advancement in the field.","sentences":["Accurate 3D object detection in LiDAR point clouds is crucial for autonomous driving systems.","To achieve state-of-the-art performance, the supervised training of detectors requires large amounts of human-annotated data, which is expensive to obtain and restricted to predefined object categories.","To mitigate manual labeling efforts, recent unsupervised object detection approaches generate class-agnostic pseudo-labels for moving objects, subsequently serving as supervision signal to bootstrap a detector.","Despite promising results, these approaches do not provide class labels or generalize well to static objects.","Furthermore, they are mostly restricted to data containing multiple drives from the same scene or images from a precisely calibrated and synchronized camera setup.","To overcome these limitations, we propose a vision-language-guided unsupervised 3D detection approach that operates exclusively on LiDAR point clouds.","We transfer CLIP knowledge to classify point clusters of static and moving objects, which we discover by exploiting the inherent spatio-temporal information of LiDAR point clouds for clustering, tracking, as well as box and label refinement.","Our approach outperforms state-of-the-art unsupervised 3D object detectors on the Waymo Open Dataset ($+23~\\text{AP}_{3D}$) and Argoverse 2 ($+7.9~\\text{AP}_{3D}$) and provides class labels not solely based on object size assumptions, marking a significant advancement in the field."],"url":"http://arxiv.org/abs/2408.03790v1"}
{"created":"2024-08-07 13:36:03","title":"Reliable Node Similarity Matrix Guided Contrastive Graph Clustering","abstract":"Graph clustering, which involves the partitioning of nodes within a graph into disjoint clusters, holds significant importance for numerous subsequent applications. Recently, contrastive learning, known for utilizing supervisory information, has demonstrated encouraging results in deep graph clustering. This methodology facilitates the learning of favorable node representations for clustering by attracting positively correlated node pairs and distancing negatively correlated pairs within the representation space. Nevertheless, a significant limitation of existing methods is their inadequacy in thoroughly exploring node-wise similarity. For instance, some hypothesize that the node similarity matrix within the representation space is identical, ignoring the inherent semantic relationships among nodes. Given the fundamental role of instance similarity in clustering, our research investigates contrastive graph clustering from the perspective of the node similarity matrix. We argue that an ideal node similarity matrix within the representation space should accurately reflect the inherent semantic relationships among nodes, ensuring the preservation of semantic similarities in the learned representations. In response to this, we introduce a new framework, Reliable Node Similarity Matrix Guided Contrastive Graph Clustering (NS4GC), which estimates an approximately ideal node similarity matrix within the representation space to guide representation learning. Our method introduces node-neighbor alignment and semantic-aware sparsification, ensuring the node similarity matrix is both accurate and efficiently sparse. Comprehensive experiments conducted on $8$ real-world datasets affirm the efficacy of learning the node similarity matrix and the superior performance of NS4GC.","sentences":["Graph clustering, which involves the partitioning of nodes within a graph into disjoint clusters, holds significant importance for numerous subsequent applications.","Recently, contrastive learning, known for utilizing supervisory information, has demonstrated encouraging results in deep graph clustering.","This methodology facilitates the learning of favorable node representations for clustering by attracting positively correlated node pairs and distancing negatively correlated pairs within the representation space.","Nevertheless, a significant limitation of existing methods is their inadequacy in thoroughly exploring node-wise similarity.","For instance, some hypothesize that the node similarity matrix within the representation space is identical, ignoring the inherent semantic relationships among nodes.","Given the fundamental role of instance similarity in clustering, our research investigates contrastive graph clustering from the perspective of the node similarity matrix.","We argue that an ideal node similarity matrix within the representation space should accurately reflect the inherent semantic relationships among nodes, ensuring the preservation of semantic similarities in the learned representations.","In response to this, we introduce a new framework, Reliable Node Similarity Matrix Guided Contrastive Graph Clustering (NS4GC), which estimates an approximately ideal node similarity matrix within the representation space to guide representation learning.","Our method introduces node-neighbor alignment and semantic-aware sparsification, ensuring the node similarity matrix is both accurate and efficiently sparse.","Comprehensive experiments conducted on $8$ real-world datasets affirm the efficacy of learning the node similarity matrix and the superior performance of NS4GC."],"url":"http://arxiv.org/abs/2408.03765v1"}
{"created":"2024-08-07 13:09:57","title":"A Soft Robotic System Automatically Learns Precise Agile Motions Without Model Information","abstract":"Many application domains, e.g., in medicine and manufacturing, can greatly benefit from pneumatic Soft Robots (SRs). However, the accurate control of SRs has remained a significant challenge to date, mainly due to their nonlinear dynamics and viscoelastic material properties. Conventional control design methods often rely on either complex system modeling or time-intensive manual tuning, both of which require significant amounts of human expertise and thus limit their practicality. In recent works, the data-driven method, Automatic Neural ODE Control (ANODEC) has been successfully used to -- fully automatically and utilizing only input-output data -- design controllers for various nonlinear systems in silico, and without requiring prior model knowledge or extensive manual tuning. In this work, we successfully apply ANODEC to automatically learn to perform agile, non-repetitive reference tracking motion tasks in a real-world SR and within a finite time horizon. To the best of the authors' knowledge, ANODEC achieves, for the first time, performant control of a SR with hysteresis effects from only 30 seconds of input-output data and without any prior model knowledge. We show that for multiple, qualitatively different and even out-of-training-distribution reference signals, a single feedback controller designed by ANODEC outperforms a manually tuned PID baseline consistently. Overall, this contribution not only further strengthens the validity of ANODEC, but it marks an important step towards more practical, easy-to-use SRs that can automatically learn to perform agile motions from minimal experimental interaction time.","sentences":["Many application domains, e.g., in medicine and manufacturing, can greatly benefit from pneumatic Soft Robots (SRs).","However, the accurate control of SRs has remained a significant challenge to date, mainly due to their nonlinear dynamics and viscoelastic material properties.","Conventional control design methods often rely on either complex system modeling or time-intensive manual tuning, both of which require significant amounts of human expertise and thus limit their practicality.","In recent works, the data-driven method, Automatic Neural ODE Control (ANODEC) has been successfully used to -- fully automatically and utilizing only input-output data -- design controllers for various nonlinear systems in silico, and without requiring prior model knowledge or extensive manual tuning.","In this work, we successfully apply ANODEC to automatically learn to perform agile, non-repetitive reference tracking motion tasks in a real-world SR and within a finite time horizon.","To the best of the authors' knowledge, ANODEC achieves, for the first time, performant control of a SR with hysteresis effects from only 30 seconds of input-output data and without any prior model knowledge.","We show that for multiple, qualitatively different and even out-of-training-distribution reference signals, a single feedback controller designed by ANODEC outperforms a manually tuned PID baseline consistently.","Overall, this contribution not only further strengthens the validity of ANODEC, but it marks an important step towards more practical, easy-to-use SRs that can automatically learn to perform agile motions from minimal experimental interaction time."],"url":"http://arxiv.org/abs/2408.03754v1"}
{"created":"2024-08-07 13:01:10","title":"Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions","abstract":"Time-series anomaly detection plays an important role in engineering processes, like development, manufacturing and other operations involving dynamic systems. These processes can greatly benefit from advances in the field, as state-of-the-art approaches may aid in cases involving, for example, highly dimensional data. To provide the reader with understanding of the terminology, this survey introduces a novel taxonomy where a distinction between online and offline, and training and inference is made. Additionally, it presents the most popular data sets and evaluation metrics used in the literature, as well as a detailed analysis. Furthermore, this survey provides an extensive overview of the state-of-the-art model-based online semi- and unsupervised anomaly detection approaches for multivariate time-series data, categorising them into different model families and other properties. The biggest research challenge revolves around benchmarking, as currently there is no reliable way to compare different approaches against one another. This problem is two-fold: on the one hand, public data sets suffers from at least one fundamental flaw, while on the other hand, there is a lack of intuitive and representative evaluation metrics in the field. Moreover, the way most publications choose a detection threshold disregards real-world conditions, which hinders the application in the real world. To allow for tangible advances in the field, these issues must be addressed in future work.","sentences":["Time-series anomaly detection plays an important role in engineering processes, like development, manufacturing and other operations involving dynamic systems.","These processes can greatly benefit from advances in the field, as state-of-the-art approaches may aid in cases involving, for example, highly dimensional data.","To provide the reader with understanding of the terminology, this survey introduces a novel taxonomy where a distinction between online and offline, and training and inference is made.","Additionally, it presents the most popular data sets and evaluation metrics used in the literature, as well as a detailed analysis.","Furthermore, this survey provides an extensive overview of the state-of-the-art model-based online semi- and unsupervised anomaly detection approaches for multivariate time-series data, categorising them into different model families and other properties.","The biggest research challenge revolves around benchmarking, as currently there is no reliable way to compare different approaches against one another.","This problem is two-fold: on the one hand, public data sets suffers from at least one fundamental flaw, while on the other hand, there is a lack of intuitive and representative evaluation metrics in the field.","Moreover, the way most publications choose a detection threshold disregards real-world conditions, which hinders the application in the real world.","To allow for tangible advances in the field, these issues must be addressed in future work."],"url":"http://arxiv.org/abs/2408.03747v1"}
{"created":"2024-08-07 13:01:10","title":"Data Generation Scheme for Thermal Modality with Edge-Guided Adversarial Conditional Diffusion Model","abstract":"In challenging low light and adverse weather conditions,thermal vision algorithms,especially object detection,have exhibited remarkable potential,contrasting with the frequent struggles encountered by visible vision algorithms. Nevertheless,the efficacy of thermal vision algorithms driven by deep learning models remains constrained by the paucity of available training data samples. To this end,this paper introduces a novel approach termed the edge guided conditional diffusion model. This framework aims to produce meticulously aligned pseudo thermal images at the pixel level,leveraging edge information extracted from visible images. By utilizing edges as contextual cues from the visible domain,the diffusion model achieves meticulous control over the delineation of objects within the generated images. To alleviate the impacts of those visible-specific edge information that should not appear in the thermal domain,a two-stage modality adversarial training strategy is proposed to filter them out from the generated images by differentiating the visible and thermal modality. Extensive experiments on LLVIP demonstrate ECDM s superiority over existing state-of-the-art approaches in terms of image generation quality.","sentences":["In challenging low light and adverse weather conditions,thermal vision algorithms,especially object detection,have exhibited remarkable potential,contrasting with the frequent struggles encountered by visible vision algorithms.","Nevertheless,the efficacy of thermal vision algorithms driven by deep learning models remains constrained by the paucity of available training data samples.","To this end,this paper introduces a novel approach termed the edge guided conditional diffusion model.","This framework aims to produce meticulously aligned pseudo thermal images at the pixel level,leveraging edge information extracted from visible images.","By utilizing edges as contextual cues from the visible domain,the diffusion model achieves meticulous control over the delineation of objects within the generated images.","To alleviate the impacts of those visible-specific edge information that should not appear in the thermal domain,a two-stage modality adversarial training strategy is proposed to filter them out from the generated images by differentiating the visible and thermal modality.","Extensive experiments on LLVIP demonstrate ECDM s superiority over existing state-of-the-art approaches in terms of image generation quality."],"url":"http://arxiv.org/abs/2408.03748v1"}
{"created":"2024-08-07 12:58:39","title":"Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification","abstract":"The interpretability of machine learning models is critical, as users may be reluctant to rely on their inferences. Intuitionistic FCMs (iFCMs) have been proposed as an extension of FCMs offering a natural mechanism to assess the quality of their output through the estimation of hesitancy, a concept resembling to human hesitation in decision making. To address the challenge of interpretable image classification, this paper introduces a novel framework, named Interpretable Intuitionistic FCM (I2FCM) which is domain-independent, simple to implement, and can be applied on Convolutional Neural Network (CNN) models, rendering them interpretable. To the best of our knowledge this is the first time iFCMs are applied for image classification. Further novel contributions include: a feature extraction process focusing on the most informative image regions; a learning algorithm for data-driven determination of the intuitionistic fuzzy interconnections of the iFCM; an inherently interpretable classification approach based on image contents. In the context of image classification, hesitancy is considered as a degree of inconfidence with which an image is categorized to a class. The constructed iFCM model distinguishes the most representative image semantics and analyses them utilizing cause-and-effect relations. The effectiveness of the introduced framework is evaluated on publicly available datasets, and the experimental results confirm that it can provide enhanced classification performance, while providing interpretable inferences.","sentences":["The interpretability of machine learning models is critical, as users may be reluctant to rely on their inferences.","Intuitionistic FCMs (iFCMs) have been proposed as an extension of FCMs offering a natural mechanism to assess the quality of their output through the estimation of hesitancy, a concept resembling to human hesitation in decision making.","To address the challenge of interpretable image classification, this paper introduces a novel framework, named Interpretable Intuitionistic FCM (I2FCM) which is domain-independent, simple to implement, and can be applied on Convolutional Neural Network (CNN) models, rendering them interpretable.","To the best of our knowledge this is the first time iFCMs are applied for image classification.","Further novel contributions include: a feature extraction process focusing on the most informative image regions; a learning algorithm for data-driven determination of the intuitionistic fuzzy interconnections of the iFCM; an inherently interpretable classification approach based on image contents.","In the context of image classification, hesitancy is considered as a degree of inconfidence with which an image is categorized to a class.","The constructed iFCM model distinguishes the most representative image semantics and analyses them utilizing cause-and-effect relations.","The effectiveness of the introduced framework is evaluated on publicly available datasets, and the experimental results confirm that it can provide enhanced classification performance, while providing interpretable inferences."],"url":"http://arxiv.org/abs/2408.03745v1"}
{"created":"2024-08-07 12:42:09","title":"Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation","abstract":"This paper presents the first study to explore the potential of parameter quantization for multimodal large language models to alleviate the significant resource constraint encountered during vision-language instruction tuning. We introduce a Quantization-aware Scale LeArning method based on multimodal Warmup, termed QSLAW. This method is grounded in two key innovations: (1) The learning of group-wise scale factors for quantized LLM weights to mitigate the quantization error arising from activation outliers and achieve more effective vision-language instruction tuning; (2) The implementation of a multimodal warmup that progressively integrates linguistic and multimodal training samples, thereby preventing overfitting of the quantized model to multimodal data while ensuring stable adaptation of multimodal large language models to downstream vision-language tasks. Extensive experiments demonstrate that models quantized by QSLAW perform on par with, or even surpass, their full-precision counterparts, while facilitating up to 1.4 times reduction in VL tuning time and GPU consumption. Our code is released at https://github.com/xjjxmu/QSLAW.","sentences":["This paper presents the first study to explore the potential of parameter quantization for multimodal large language models to alleviate the significant resource constraint encountered during vision-language instruction tuning.","We introduce a Quantization-aware Scale LeArning method based on multimodal Warmup, termed QSLAW.","This method is grounded in two key innovations: (1) The learning of group-wise scale factors for quantized LLM weights to mitigate the quantization error arising from activation outliers and achieve more effective vision-language instruction tuning; (2) The implementation of a multimodal warmup that progressively integrates linguistic and multimodal training samples, thereby preventing overfitting of the quantized model to multimodal data while ensuring stable adaptation of multimodal large language models to downstream vision-language tasks.","Extensive experiments demonstrate that models quantized by QSLAW perform on par with, or even surpass, their full-precision counterparts, while facilitating up to 1.4 times reduction in VL tuning time and GPU consumption.","Our code is released at https://github.com/xjjxmu/QSLAW."],"url":"http://arxiv.org/abs/2408.03735v1"}
{"created":"2024-08-07 12:24:23","title":"MS-Mapping: An Uncertainty-Aware Large-Scale Multi-Session LiDAR Mapping System","abstract":"Large-scale multi-session LiDAR mapping is essential for a wide range of applications, including surveying, autonomous driving, crowdsourced mapping, and multi-agent navigation. However, existing approaches often struggle with data redundancy, robustness, and accuracy in complex environments. To address these challenges, we present MS-Mapping, an novel multi-session LiDAR mapping system that employs an incremental mapping scheme for robust and accurate map assembly in large-scale environments. Our approach introduces three key innovations: 1) A distribution-aware keyframe selection method that captures the subtle contributions of each point cloud frame to the map by analyzing the similarity of map distributions. This method effectively reduces data redundancy and pose graph size, while enhancing graph optimization speed; 2) An uncertainty model that automatically performs least-squares adjustments according to the covariance matrix during graph optimization, improving mapping precision, robustness, and flexibility without the need for scene-specific parameter tuning. This uncertainty model enables our system to monitor pose uncertainty and avoid ill-posed optimizations, thereby increasing adaptability to diverse and challenging environments. 3) To ensure fair evaluation, we redesign baseline comparisons and the evaluation benchmark. Direct assessment of map accuracy demonstrates the superiority of the proposed MS-Mapping algorithm compared to state-of-the-art methods. In addition to employing public datasets such as Urban-Nav, FusionPortable, and Newer College, we conducted extensive experiments on such a large \\SI{855}{m}$\\times$\\SI{636}{m} ground truth map, collecting over \\SI{20}{km} of indoor and outdoor data across more than ten sequences...","sentences":["Large-scale multi-session LiDAR mapping is essential for a wide range of applications, including surveying, autonomous driving, crowdsourced mapping, and multi-agent navigation.","However, existing approaches often struggle with data redundancy, robustness, and accuracy in complex environments.","To address these challenges, we present MS-Mapping, an novel multi-session LiDAR mapping system that employs an incremental mapping scheme for robust and accurate map assembly in large-scale environments.","Our approach introduces three key innovations: 1) A distribution-aware keyframe selection method that captures the subtle contributions of each point cloud frame to the map by analyzing the similarity of map distributions.","This method effectively reduces data redundancy and pose graph size, while enhancing graph optimization speed; 2) An uncertainty model that automatically performs least-squares adjustments according to the covariance matrix during graph optimization, improving mapping precision, robustness, and flexibility without the need for scene-specific parameter tuning.","This uncertainty model enables our system to monitor pose uncertainty and avoid ill-posed optimizations, thereby increasing adaptability to diverse and challenging environments.","3) To ensure fair evaluation, we redesign baseline comparisons and the evaluation benchmark.","Direct assessment of map accuracy demonstrates the superiority of the proposed MS-Mapping algorithm compared to state-of-the-art methods.","In addition to employing public datasets such as Urban-Nav, FusionPortable, and Newer College, we conducted extensive experiments on such a large \\SI{855}{m}$\\times$\\SI{636}{m} ground truth map, collecting over \\SI{20}{km} of indoor and outdoor data across more than ten sequences..."],"url":"http://arxiv.org/abs/2408.03723v1"}
{"created":"2024-08-07 12:19:28","title":"Improving the Intelligent Driver Model by Incorporating Vehicle Dynamics: Microscopic Calibration and Macroscopic Validation","abstract":"Microscopic traffic simulations are used to evaluate the impact of infrastructure modifications and evolving vehicle technologies, such as connected and automated driving. Simulated vehicles are controlled via car-following, lane-changing and junction models, which are designed to imitate human driving behavior. However, physics-based car-following models (CFMs) cannot fully replicate measured vehicle trajectories. Therefore, we present model extensions for the Intelligent Driver Model (IDM), of which some are already included in the Extended Intelligent Driver Model (EIDM), to improve calibration and validation results. They consist of equations based on vehicle dynamics and drive off procedures. In addition, parameter selection plays a decisive role. Thus, we introduce a framework to calibrate CFMs using drone data captured at a signalized intersection in Stuttgart, Germany. We compare the calibration error of the Krauss Model with the IDM and EIDM. In this setup, the EIDM achieves a 17.78 % lower mean error than the IDM, based on the distance difference between real world and simulated vehicles. Adding vehicle dynamics equations to the EIDM further improves the results by an additional 18.97 %. The calibrated vehicle-driver combinations are then investigated by simulating the traffic in three different scenarios: at the original intersection, in a closed loop and in a stop-and-go wave. The data shows that the improved calibration process of individual vehicles, openly available at https://www.github.com/stepeos/pycarmodel_calibration, also provides more accurate macroscopic results.","sentences":["Microscopic traffic simulations are used to evaluate the impact of infrastructure modifications and evolving vehicle technologies, such as connected and automated driving.","Simulated vehicles are controlled via car-following, lane-changing and junction models, which are designed to imitate human driving behavior.","However, physics-based car-following models (CFMs) cannot fully replicate measured vehicle trajectories.","Therefore, we present model extensions for the Intelligent Driver Model (IDM), of which some are already included in the Extended Intelligent Driver Model (EIDM), to improve calibration and validation results.","They consist of equations based on vehicle dynamics and drive off procedures.","In addition, parameter selection plays a decisive role.","Thus, we introduce a framework to calibrate CFMs using drone data captured at a signalized intersection in Stuttgart, Germany.","We compare the calibration error of the Krauss Model with the IDM and EIDM.","In this setup, the EIDM achieves a 17.78 % lower mean error than the IDM, based on the distance difference between real world and simulated vehicles.","Adding vehicle dynamics equations to the EIDM further improves the results by an additional 18.97 %.","The calibrated vehicle-driver combinations are then investigated by simulating the traffic in three different scenarios: at the original intersection, in a closed loop and in a stop-and-go wave.","The data shows that the improved calibration process of individual vehicles, openly available at https://www.github.com/stepeos/pycarmodel_calibration, also provides more accurate macroscopic results."],"url":"http://arxiv.org/abs/2408.03722v1"}
{"created":"2024-08-07 12:02:13","title":"Centralized Defense: Logging and Mitigation of Kubernetes Misconfigurations with Open Source Tools","abstract":"Kubernetes, an open-source platform for automating the deployment, scaling, and management of containerized applications, is widely used for its efficiency and scalability. However, its complexity and extensive configuration options often lead to security vulnerabilities if not managed properly. This paper presents a detailed analysis of misconfigurations in Kubernetes environments and their significant impact on system reliability and security. A centralized logging solution was developed to detect such misconfigurations, detailing the integration process with a Kubernetes cluster and the implementation of role-based access control. Utilizing a combination of open-source tools, the solution systematically identifies misconfigurations and aggregates diagnostic data into a central repository. The effectiveness of the solution was evaluated using specific metrics, such as the total cycle time for running the central logging solution against the individual open source tools.","sentences":["Kubernetes, an open-source platform for automating the deployment, scaling, and management of containerized applications, is widely used for its efficiency and scalability.","However, its complexity and extensive configuration options often lead to security vulnerabilities if not managed properly.","This paper presents a detailed analysis of misconfigurations in Kubernetes environments and their significant impact on system reliability and security.","A centralized logging solution was developed to detect such misconfigurations, detailing the integration process with a Kubernetes cluster and the implementation of role-based access control.","Utilizing a combination of open-source tools, the solution systematically identifies misconfigurations and aggregates diagnostic data into a central repository.","The effectiveness of the solution was evaluated using specific metrics, such as the total cycle time for running the central logging solution against the individual open source tools."],"url":"http://arxiv.org/abs/2408.03714v1"}
{"created":"2024-08-07 11:44:58","title":"Home Energy Management Systems: Challenges, Heterogeneity & Integration Architecture Towards A Smart City Ecosystem","abstract":"The contemporary era is marked by rapid urban growth and increasing population. A significant, and constantly growing, portion of the global population now resides in major cities, leading to escalating energy demands in urban centers. As urban population is expected to keep on expanding in the near future, the same is also expected to happen with the associated energy requirements. The situation with the continuously increasing energy demand, along with the emergence of smart grids and the capabilities that are already -- or can be -- offered by Home Energy Management System (HEMS), has created a lot of opportunities towards a more sustainable future, with optimized energy consumption and demand response, which leads to economic and environmental benefits, based on the actual needs of the consumers. In this paper, we begin by providing an analytical exploration of the challenges faced at both the development and deployment levels. We proceed with a thorough analysis and comparison between the abundance of devices, smart home technologies, and protocols currently used by various products. Following, aiming to blunt the currently existing challenges, we propose a reliable, flexible, and extendable architectural schema. Finally, we analyze a number of potential ways in which the data deriving from such implementations can be analyzed and leveraged, in order to produce services that offer useful insights and smart solutions towards enhanced energy efficiency.","sentences":["The contemporary era is marked by rapid urban growth and increasing population.","A significant, and constantly growing, portion of the global population now resides in major cities, leading to escalating energy demands in urban centers.","As urban population is expected to keep on expanding in the near future, the same is also expected to happen with the associated energy requirements.","The situation with the continuously increasing energy demand, along with the emergence of smart grids and the capabilities that are already -- or can be -- offered by Home Energy Management System (HEMS), has created a lot of opportunities towards a more sustainable future, with optimized energy consumption and demand response, which leads to economic and environmental benefits, based on the actual needs of the consumers.","In this paper, we begin by providing an analytical exploration of the challenges faced at both the development and deployment levels.","We proceed with a thorough analysis and comparison between the abundance of devices, smart home technologies, and protocols currently used by various products.","Following, aiming to blunt the currently existing challenges, we propose a reliable, flexible, and extendable architectural schema.","Finally, we analyze a number of potential ways in which the data deriving from such implementations can be analyzed and leveraged, in order to produce services that offer useful insights and smart solutions towards enhanced energy efficiency."],"url":"http://arxiv.org/abs/2408.03707v1"}
{"created":"2024-08-07 11:37:02","title":"BioDeepHash: Mapping Biometrics into a Stable Code","abstract":"With the wide application of biometrics, more and more attention has been paid to the security of biometric templates. However most of existing biometric template protection (BTP) methods have some security problems, e.g. the problem that protected templates leak part of the original biometric data (exists in Cancelable Biometrics (CB)), the use of error-correcting codes (ECC) leads to decodable attack, statistical attack (exists in Biometric Cryptosystems (BCS)), the inability to achieve revocability (exists in methods using Neural Network (NN) to learn pre-defined templates), the inability to use cryptographic hash to guarantee strong security (exists in CB and methods using NN to learn latent templates). In this paper, we propose a framework called BioDeepHash based on deep hashing and cryptographic hashing to address the above four problems, where different biometric data of the same user are mapped to a stable code using deep hashing instead of predefined binary codes thus avoiding the use of ECC. An application-specific binary string is employed to achieve revocability. Then cryptographic hashing is used to get the final protected template to ensure strong security. Ultimately our framework achieves not storing any data that would leak part of the original biometric data. We also conduct extensive experiments on facial and iris datasets. Our method achieves an improvement of 10.12$\\%$ on the average Genuine Acceptance Rate (GAR) for iris data and 3.12$\\%$ for facial data compared to existing methods. In addition, BioDeepHash achieves extremely low False Acceptance Rate (FAR), i.e. 0$\\%$ FAR on the iris dataset and the highest FAR on the facial dataset is only 0.0002$\\%$.","sentences":["With the wide application of biometrics, more and more attention has been paid to the security of biometric templates.","However most of existing biometric template protection (BTP) methods have some security problems, e.g. the problem that protected templates leak part of the original biometric data (exists in Cancelable Biometrics (CB)), the use of error-correcting codes (ECC) leads to decodable attack, statistical attack (exists in Biometric Cryptosystems (BCS)), the inability to achieve revocability (exists in methods using Neural Network (NN) to learn pre-defined templates), the inability to use cryptographic hash to guarantee strong security (exists in CB and methods using NN to learn latent templates).","In this paper, we propose a framework called BioDeepHash based on deep hashing and cryptographic hashing to address the above four problems, where different biometric data of the same user are mapped to a stable code using deep hashing instead of predefined binary codes thus avoiding the use of ECC.","An application-specific binary string is employed to achieve revocability.","Then cryptographic hashing is used to get the final protected template to ensure strong security.","Ultimately our framework achieves not storing any data that would leak part of the original biometric data.","We also conduct extensive experiments on facial and iris datasets.","Our method achieves an improvement of 10.12$\\%$ on the average Genuine Acceptance Rate (GAR) for iris data and 3.12$\\%$ for facial data compared to existing methods.","In addition, BioDeepHash achieves extremely low False Acceptance Rate (FAR), i.e. 0$\\%$ FAR on the iris dataset and the highest FAR on the facial dataset is only 0.0002$\\%$."],"url":"http://arxiv.org/abs/2408.03704v1"}
{"created":"2024-08-07 11:28:55","title":"Finding longer cycles via shortest colourful cycle","abstract":"We consider the parameterised $k,e$-Long Cycle problem, in which you are given an $n$-vertex undirected graph $G$, a specified edge $e$ in $G$, and a positive integer $k$, and are asked to decide if the graph $G$ has a simple cycle through $e$ of length at least $k$. We show that the problem can be solved in $1.731^k\\operatorname{poly}(n)$ time, improving over the previously best known $2^k\\operatorname{poly}(n)$ time algorithm and solving an open problem [Fomin et al., TALG 2024]. When the graph is bipartite, we can solve the problem in $2^{k/2}\\operatorname{poly}(n)$ time, matching the fastest known algorithm for finding a cycle of length exactly $k$ in an undirected bipartite graph [Bj\\\"orklund et al., JCSS 2017].   Our results follow the approach taken by [Fomin et al., TALG 2024], which describes an efficient algorithm for finding cycles using many colours in a vertex-coloured undirected graph. Our contribution is twofold. First, we describe a new algorithm and analysis for the central colourful cycle problem, with the aim of providing a comparatively short and self-contained proof of correctness. Second, we give tighter reductions from $k,e$-Long Cycle to the colourful cycle problem, which lead to our improved running times.","sentences":["We consider the parameterised $k,e$-Long","Cycle problem, in which you are given an $n$-vertex undirected graph $G$, a specified edge $e$ in $G$, and a positive integer $k$, and are asked to decide if the graph $G$ has a simple cycle through $e$ of length at least $k$.","We show that the problem can be solved in $1.731^k\\operatorname{poly}(n)$ time, improving over the previously best known $2^k\\operatorname{poly}(n)$ time algorithm and solving an open problem","[Fomin et al., TALG 2024].","When the graph is bipartite, we can solve the problem in $2^{k/2}\\operatorname{poly}(n)$ time, matching the fastest known algorithm for finding a cycle of length exactly $k$ in an undirected bipartite graph [Bj\\\"orklund et al., JCSS 2017].   ","Our results follow the approach taken by [Fomin et al., TALG 2024], which describes an efficient algorithm for finding cycles using many colours in a vertex-coloured undirected graph.","Our contribution is twofold.","First, we describe a new algorithm and analysis for the central colourful cycle problem, with the aim of providing a comparatively short and self-contained proof of correctness.","Second, we give tighter reductions from $k,e$-Long","Cycle to the colourful cycle problem, which lead to our improved running times."],"url":"http://arxiv.org/abs/2408.03699v1"}
{"created":"2024-08-07 11:14:18","title":"A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework","abstract":"The metaverse, envisioned as the next digital frontier for avatar-based virtual interaction, involves high-performance models. In this dynamic environment, users' tasks frequently shift, requiring fast model personalization despite limited data. This evolution consumes extensive resources and requires vast data volumes. To address this, meta-learning emerges as an invaluable tool for metaverse users, with federated meta-learning (FML), offering even more tailored solutions owing to its adaptive capabilities. However, the metaverse is characterized by users heterogeneity with diverse data structures, varied tasks, and uneven sample sizes, potentially undermining global training outcomes due to statistical difference. Given this, an urgent need arises for smart coalition formation that accounts for these disparities. This paper introduces a dual game-theoretic framework for metaverse services involving meta-learners as workers to manage FML. A blockchain-based cooperative coalition formation game is crafted, grounded on a reputation metric, user similarity, and incentives. We also introduce a novel reputation system based on users' historical contributions and potential contributions to present tasks, leveraging correlations between past and new tasks. Finally, a Stackelberg game-based incentive mechanism is presented to attract reliable workers to participate in meta-learning, minimizing users' energy costs, increasing payoffs, boosting FML efficacy, and improving metaverse utility. Results show that our dual game framework outperforms best-effort, random, and non-uniform clustering schemes - improving training performance by up to 10%, cutting completion times by as much as 30%, enhancing metaverse utility by more than 25%, and offering up to 5% boost in training efficiency over non-blockchain systems, effectively countering misbehaving users.","sentences":["The metaverse, envisioned as the next digital frontier for avatar-based virtual interaction, involves high-performance models.","In this dynamic environment, users' tasks frequently shift, requiring fast model personalization despite limited data.","This evolution consumes extensive resources and requires vast data volumes.","To address this, meta-learning emerges as an invaluable tool for metaverse users, with federated meta-learning (FML), offering even more tailored solutions owing to its adaptive capabilities.","However, the metaverse is characterized by users heterogeneity with diverse data structures, varied tasks, and uneven sample sizes, potentially undermining global training outcomes due to statistical difference.","Given this, an urgent need arises for smart coalition formation that accounts for these disparities.","This paper introduces a dual game-theoretic framework for metaverse services involving meta-learners as workers to manage FML.","A blockchain-based cooperative coalition formation game is crafted, grounded on a reputation metric, user similarity, and incentives.","We also introduce a novel reputation system based on users' historical contributions and potential contributions to present tasks, leveraging correlations between past and new tasks.","Finally, a Stackelberg game-based incentive mechanism is presented to attract reliable workers to participate in meta-learning, minimizing users' energy costs, increasing payoffs, boosting FML efficacy, and improving metaverse utility.","Results show that our dual game framework outperforms best-effort, random, and non-uniform clustering schemes - improving training performance by up to 10%, cutting completion times by as much as 30%, enhancing metaverse utility by more than 25%, and offering up to 5% boost in training efficiency over non-blockchain systems, effectively countering misbehaving users."],"url":"http://arxiv.org/abs/2408.03694v1"}
{"created":"2024-08-07 11:13:19","title":"Generative Design of Periodic Orbits in the Restricted Three-Body Problem","abstract":"The Three-Body Problem has fascinated scientists for centuries and it has been crucial in the design of modern space missions. Recent developments in Generative Artificial Intelligence hold transformative promise for addressing this longstanding problem. This work investigates the use of Variational Autoencoder (VAE) and its internal representation to generate periodic orbits. We utilize a comprehensive dataset of periodic orbits in the Circular Restricted Three-Body Problem (CR3BP) to train deep-learning architectures that capture key orbital characteristics, and we set up physical evaluation metrics for the generated trajectories. Through this investigation, we seek to enhance the understanding of how Generative AI can improve space mission planning and astrodynamics research, leading to novel, data-driven approaches in the field.","sentences":["The Three-Body Problem has fascinated scientists for centuries and it has been crucial in the design of modern space missions.","Recent developments in Generative Artificial Intelligence hold transformative promise for addressing this longstanding problem.","This work investigates the use of Variational Autoencoder (VAE) and its internal representation to generate periodic orbits.","We utilize a comprehensive dataset of periodic orbits in the Circular Restricted Three-Body Problem (CR3BP) to train deep-learning architectures that capture key orbital characteristics, and we set up physical evaluation metrics for the generated trajectories.","Through this investigation, we seek to enhance the understanding of how Generative AI can improve space mission planning and astrodynamics research, leading to novel, data-driven approaches in the field."],"url":"http://arxiv.org/abs/2408.03691v1"}
{"created":"2024-08-07 10:53:07","title":"RL-ADN: A High-Performance Deep Reinforcement Learning Environment for Optimal Energy Storage Systems Dispatch in Active Distribution Networks","abstract":"Deep Reinforcement Learning (DRL) presents a promising avenue for optimizing Energy Storage Systems (ESSs) dispatch in distribution networks. This paper introduces RL-ADN, an innovative open-source library specifically designed for solving the optimal ESSs dispatch in active distribution networks. RL-ADN offers unparalleled flexibility in modeling distribution networks, and ESSs, accommodating a wide range of research goals. A standout feature of RL-ADN is its data augmentation module, based on Gaussian Mixture Model and Copula (GMC) functions, which elevates the performance ceiling of DRL agents. Additionally, RL-ADN incorporates the Laurent power flow solver, significantly reducing the computational burden of power flow calculations during training without sacrificing accuracy. The effectiveness of RL-ADN is demonstrated using in different sizes of distribution networks, showing marked performance improvements in the adaptability of DRL algorithms for ESS dispatch tasks. This enhancement is particularly beneficial from the increased diversity of training scenarios. Furthermore, RL-ADN achieves a tenfold increase in computational efficiency during training, making it highly suitable for large-scale network applications. The library sets a new benchmark in DRL-based ESSs dispatch in distribution networks and it is poised to advance DRL applications in distribution network operations significantly. RL-ADN is available at: https://github.com/ShengrenHou/RL-ADN and https://github.com/distributionnetworksTUDelft/RL-ADN.","sentences":["Deep Reinforcement Learning (DRL) presents a promising avenue for optimizing Energy Storage Systems (ESSs) dispatch in distribution networks.","This paper introduces RL-ADN, an innovative open-source library specifically designed for solving the optimal ESSs dispatch in active distribution networks.","RL-ADN offers unparalleled flexibility in modeling distribution networks, and ESSs, accommodating a wide range of research goals.","A standout feature of RL-ADN is its data augmentation module, based on Gaussian Mixture Model and Copula (GMC) functions, which elevates the performance ceiling of DRL agents.","Additionally, RL-ADN incorporates the Laurent power flow solver, significantly reducing the computational burden of power flow calculations during training without sacrificing accuracy.","The effectiveness of RL-ADN is demonstrated using in different sizes of distribution networks, showing marked performance improvements in the adaptability of DRL algorithms for ESS dispatch tasks.","This enhancement is particularly beneficial from the increased diversity of training scenarios.","Furthermore, RL-ADN achieves a tenfold increase in computational efficiency during training, making it highly suitable for large-scale network applications.","The library sets a new benchmark in DRL-based ESSs dispatch in distribution networks and it is poised to advance DRL applications in distribution network operations significantly.","RL-ADN is available at: https://github.com/ShengrenHou/RL-ADN and https://github.com/distributionnetworksTUDelft/RL-ADN."],"url":"http://arxiv.org/abs/2408.03685v2"}
{"created":"2024-08-07 10:49:12","title":"Path-based Design Model for Constructing and Exploring Alternative Visualisations","abstract":"We present a path-based design model and system for designing and creating visualisations. Our model represents a systematic approach to constructing visual representations of data or concepts following a predefined sequence of steps. The initial step involves outlining the overall appearance of the visualisation by creating a skeleton structure, referred to as a flowpath. Subsequently, we specify objects, visual marks, properties, and appearance, storing them in a gene. Lastly, we map data onto the flowpath, ensuring suitable morphisms. Alternative designs are created by exchanging values in the gene. For example, designs that share similar traits, are created by making small incremental changes to the gene. Our design methodology fosters the generation of diverse creative concepts, space-filling visualisations, and traditional formats like bar charts, circular plots and pie charts. Through our implementation we showcase the model in action. As an example application, we integrate the output visualisations onto a smartwatch and visualisation dashboards. In this article we (1) introduce, define and explain the path model and discuss possibilities for its use, (2) present our implementation, results, and evaluation, and (3) demonstrate and evaluate an application of its use on a mobile watch.","sentences":["We present a path-based design model and system for designing and creating visualisations.","Our model represents a systematic approach to constructing visual representations of data or concepts following a predefined sequence of steps.","The initial step involves outlining the overall appearance of the visualisation by creating a skeleton structure, referred to as a flowpath.","Subsequently, we specify objects, visual marks, properties, and appearance, storing them in a gene.","Lastly, we map data onto the flowpath, ensuring suitable morphisms.","Alternative designs are created by exchanging values in the gene.","For example, designs that share similar traits, are created by making small incremental changes to the gene.","Our design methodology fosters the generation of diverse creative concepts, space-filling visualisations, and traditional formats like bar charts, circular plots and pie charts.","Through our implementation we showcase the model in action.","As an example application, we integrate the output visualisations onto a smartwatch and visualisation dashboards.","In this article we (1) introduce, define and explain the path model and discuss possibilities for its use, (2) present our implementation, results, and evaluation, and (3) demonstrate and evaluate an application of its use on a mobile watch."],"url":"http://arxiv.org/abs/2408.03681v1"}
{"created":"2024-08-07 10:36:26","title":"L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection","abstract":"LiDAR-based vision systems are integral for 3D object detection, which is crucial for autonomous navigation. However, they suffer from performance degradation in adverse weather conditions due to the quality deterioration of LiDAR point clouds. Fusing LiDAR with the weather-robust 4D radar sensor is expected to solve this problem. However, the fusion of LiDAR and 4D radar is challenging because they differ significantly in terms of data quality and the degree of degradation in adverse weather. To address these issues, we introduce L4DR, a weather-robust 3D object detection method that effectively achieves LiDAR and 4D Radar fusion. Our L4DR includes Multi-Modal Encoding (MME) and Foreground-Aware Denoising (FAD) technique to reconcile sensor gaps, which is the first exploration of the complementarity of early fusion between LiDAR and 4D radar. Additionally, we design an Inter-Modal and Intra-Modal ({IM}2 ) parallel feature extraction backbone coupled with a Multi-Scale Gated Fusion (MSGF) module to counteract the varying degrees of sensor degradation under adverse weather conditions. Experimental evaluation on a VoD dataset with simulated fog proves that L4DR is more adaptable to changing weather conditions. It delivers a significant performance increase under different fog levels, improving the 3D mAP by up to 18.17% over the traditional LiDAR-only approach. Moreover, the results on the K-Radar dataset validate the consistent performance improvement of L4DR in real-world adverse weather conditions.","sentences":["LiDAR-based vision systems are integral for 3D object detection, which is crucial for autonomous navigation.","However, they suffer from performance degradation in adverse weather conditions due to the quality deterioration of LiDAR point clouds.","Fusing LiDAR with the weather-robust 4D radar sensor is expected to solve this problem.","However, the fusion of LiDAR and 4D radar is challenging because they differ significantly in terms of data quality and the degree of degradation in adverse weather.","To address these issues, we introduce L4DR, a weather-robust 3D object detection method that effectively achieves LiDAR and 4D Radar fusion.","Our L4DR includes Multi-Modal Encoding (MME) and Foreground-Aware Denoising (FAD) technique to reconcile sensor gaps, which is the first exploration of the complementarity of early fusion between LiDAR and 4D radar.","Additionally, we design an Inter-Modal and Intra-Modal ({IM}2 ) parallel feature extraction backbone coupled with a Multi-Scale Gated Fusion (MSGF) module to counteract the varying degrees of sensor degradation under adverse weather conditions.","Experimental evaluation on a VoD dataset with simulated fog proves that L4DR is more adaptable to changing weather conditions.","It delivers a significant performance increase under different fog levels, improving the 3D mAP by up to 18.17% over the traditional LiDAR-only approach.","Moreover, the results on the K-Radar dataset validate the consistent performance improvement of L4DR in real-world adverse weather conditions."],"url":"http://arxiv.org/abs/2408.03677v1"}
{"created":"2024-08-07 10:01:50","title":"Deterministic Online Bipartite Edge Coloring","abstract":"We study online bipartite edge coloring, with nodes on one side of the graph revealed sequentially. The trivial greedy algorithm is $(2-o(1))$-competitive, which is optimal for graphs of low maximum degree, $\\Delta=O(\\log n)$ [BNMN IPL'92]. Numerous online edge-coloring algorithms outperforming the greedy algorithm in various settings were designed over the years (e.g., AGKM FOCS'03, BMM SODA'10, CPW FOCS'19, BGW SODA'21, KLSST STOC'22, BSVW STOC'24), all crucially relying on randomization. A commonly-held belief, first stated by [BNMN IPL'92], is that randomization is necessary to outperform greedy.   Surprisingly, we refute this belief, by presenting a deterministic algorithm that beats greedy for sufficiently large $\\Delta=\\Omega(\\log n)$, and in particular has competitive ratio $\\frac{e}{e-1}+o(1)$ for all $\\Delta=\\omega(\\log n)$. We obtain our result via a new and surprisingly simple randomized algorithm that works against adaptive adversaries (as opposed to oblivious adversaries assumed by prior work), which implies the existence of a similarly-competitive deterministic algorithm [BDBKTW STOC'90].","sentences":["We study online bipartite edge coloring, with nodes on one side of the graph revealed sequentially.","The trivial greedy algorithm is $(2-o(1))$-competitive, which is optimal for graphs of low maximum degree, $\\Delta=O(\\log n)$","[BNMN IPL'92].","Numerous online edge-coloring algorithms outperforming the greedy algorithm in various settings were designed over the years (e.g., AGKM FOCS'03, BMM SODA'10, CPW FOCS'19, BGW SODA'21, KLSST STOC'22, BSVW STOC'24), all crucially relying on randomization.","A commonly-held belief, first stated by [BNMN IPL'92], is that randomization is necessary to outperform greedy.   ","Surprisingly, we refute this belief, by presenting a deterministic algorithm that beats greedy for sufficiently large $\\Delta=\\Omega(\\log n)$, and in particular has competitive ratio $\\frac{e}{e-1}+o(1)$ for all $\\Delta=\\omega(\\log n)$. We obtain our result via a new and surprisingly simple randomized algorithm that works against adaptive adversaries (as opposed to oblivious adversaries assumed by prior work), which implies the existence of a similarly-competitive deterministic algorithm","[BDBKTW STOC'90]."],"url":"http://arxiv.org/abs/2408.03661v1"}
{"created":"2024-08-07 09:57:50","title":"Alternating Nominal Automata with Name Allocation","abstract":"Formal languages over infinite alphabets serve as abstractions of structures and processes carrying data. Automata models over infinite alphabets, such as classical register automata or, equivalently, nominal orbit-finite automata, tend to have computationally hard or even undecidable reasoning problems unless stringent restrictions are imposed on either the power of control or the number of registers. This has been shown to be ameliorated in automata models with name allocation such as regular nondeterministic nominal automata, which allow for deciding language inclusion in elementary complexity even with unboundedly many registers while retaining a reasonable level of expressiveness. In the present work, we demonstrate that elementary complexity survives under extending the power of control to alternation: We introduce regular alternating nominal automata (RANAs), and show that their non-emptiness and inclusion problems have elementary complexity even when the number of registers is unbounded. Moreover, we show that RANAs allow for nearly complete de-alternation, specifically de-alternation up to a single deadlocked universal state.","sentences":["Formal languages over infinite alphabets serve as abstractions of structures and processes carrying data.","Automata models over infinite alphabets, such as classical register automata or, equivalently, nominal orbit-finite automata, tend to have computationally hard or even undecidable reasoning problems unless stringent restrictions are imposed on either the power of control or the number of registers.","This has been shown to be ameliorated in automata models with name allocation such as regular nondeterministic nominal automata, which allow for deciding language inclusion in elementary complexity even with unboundedly many registers while retaining a reasonable level of expressiveness.","In the present work, we demonstrate that elementary complexity survives under extending the power of control to alternation: We introduce regular alternating nominal automata (RANAs), and show that their non-emptiness and inclusion problems have elementary complexity even when the number of registers is unbounded.","Moreover, we show that RANAs allow for nearly complete de-alternation, specifically de-alternation up to a single deadlocked universal state."],"url":"http://arxiv.org/abs/2408.03658v1"}
{"created":"2024-08-07 09:52:30","title":"PHOCUS: Physics-Based Deconvolution for Ultrasound Resolution Enhancement","abstract":"Ultrasound is widely used in medical diagnostics allowing for accessible and powerful imaging but suffers from resolution limitations due to diffraction and the finite aperture of the imaging system, which restricts diagnostic use. The impulse function of an ultrasound imaging system is called the point spread function (PSF), which is convolved with the spatial distribution of reflectors in the image formation process. Recovering high-resolution reflector distributions by removing image distortions induced by the convolution process improves image clarity and detail. Conventionally, deconvolution techniques attempt to rectify the imaging system's dependent PSF, working directly on the radio-frequency (RF) data. However, RF data is often not readily accessible. Therefore, we introduce a physics-based deconvolution process using a modeled PSF, working directly on the more commonly available B-mode images. By leveraging Implicit Neural Representations (INRs), we learn a continuous mapping from spatial locations to their respective echogenicity values, effectively compensating for the discretized image space. Our contribution consists of a novel methodology for retrieving a continuous echogenicity map directly from a B-mode image through a differentiable physics-based rendering pipeline for ultrasound resolution enhancement. We qualitatively and quantitatively evaluate our approach on synthetic data, demonstrating improvements over traditional methods in metrics such as PSNR and SSIM. Furthermore, we show qualitative enhancements on an ultrasound phantom and an in-vivo acquisition of a carotid artery.","sentences":["Ultrasound is widely used in medical diagnostics allowing for accessible and powerful imaging but suffers from resolution limitations due to diffraction and the finite aperture of the imaging system, which restricts diagnostic use.","The impulse function of an ultrasound imaging system is called the point spread function (PSF), which is convolved with the spatial distribution of reflectors in the image formation process.","Recovering high-resolution reflector distributions by removing image distortions induced by the convolution process improves image clarity and detail.","Conventionally, deconvolution techniques attempt to rectify the imaging system's dependent PSF, working directly on the radio-frequency (RF) data.","However, RF data is often not readily accessible.","Therefore, we introduce a physics-based deconvolution process using a modeled PSF, working directly on the more commonly available B-mode images.","By leveraging Implicit Neural Representations (INRs), we learn a continuous mapping from spatial locations to their respective echogenicity values, effectively compensating for the discretized image space.","Our contribution consists of a novel methodology for retrieving a continuous echogenicity map directly from a B-mode image through a differentiable physics-based rendering pipeline for ultrasound resolution enhancement.","We qualitatively and quantitatively evaluate our approach on synthetic data, demonstrating improvements over traditional methods in metrics such as PSNR and SSIM.","Furthermore, we show qualitative enhancements on an ultrasound phantom and an in-vivo acquisition of a carotid artery."],"url":"http://arxiv.org/abs/2408.03657v1"}
{"created":"2024-08-07 09:45:24","title":"Consumer Transactions Simulation through Generative Adversarial Networks","abstract":"In the rapidly evolving domain of large-scale retail data systems, envisioning and simulating future consumer transactions has become a crucial area of interest. It offers significant potential to fortify demand forecasting and fine-tune inventory management. This paper presents an innovative application of Generative Adversarial Networks (GANs) to generate synthetic retail transaction data, specifically focusing on a novel system architecture that combines consumer behavior modeling with stock-keeping unit (SKU) availability constraints to address real-world assortment optimization challenges. We diverge from conventional methodologies by integrating SKU data into our GAN architecture and using more sophisticated embedding methods (e.g., hyper-graphs). This design choice enables our system to generate not only simulated consumer purchase behaviors but also reflects the dynamic interplay between consumer behavior and SKU availability -- an aspect often overlooked, among others, because of data scarcity in legacy retail simulation models. Our GAN model generates transactions under stock constraints, pioneering a resourceful experimental system with practical implications for real-world retail operation and strategy. Preliminary results demonstrate enhanced realism in simulated transactions measured by comparing generated items with real ones using methods employed earlier in related studies. This underscores the potential for more accurate predictive modeling.","sentences":["In the rapidly evolving domain of large-scale retail data systems, envisioning and simulating future consumer transactions has become a crucial area of interest.","It offers significant potential to fortify demand forecasting and fine-tune inventory management.","This paper presents an innovative application of Generative Adversarial Networks (GANs) to generate synthetic retail transaction data, specifically focusing on a novel system architecture that combines consumer behavior modeling with stock-keeping unit (SKU) availability constraints to address real-world assortment optimization challenges.","We diverge from conventional methodologies by integrating SKU data into our GAN architecture and using more sophisticated embedding methods (e.g., hyper-graphs).","This design choice enables our system to generate not only simulated consumer purchase behaviors but also reflects the dynamic interplay between consumer behavior and SKU availability -- an aspect often overlooked, among others, because of data scarcity in legacy retail simulation models.","Our GAN model generates transactions under stock constraints, pioneering a resourceful experimental system with practical implications for real-world retail operation and strategy.","Preliminary results demonstrate enhanced realism in simulated transactions measured by comparing generated items with real ones using methods employed earlier in related studies.","This underscores the potential for more accurate predictive modeling."],"url":"http://arxiv.org/abs/2408.03655v1"}
{"created":"2024-08-07 09:34:55","title":"mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search","abstract":"Named Entity Recognition (NER) is a task in Natural Language Processing (NLP) that aims to identify and classify entities in text into predefined categories. However, when applied to Arabic data, NER encounters unique challenges stemming from the language's rich morphological inflections, absence of capitalization cues, and spelling variants, where a single word can comprise multiple morphemes. In this paper, we introduce Arabic KNN-NER, our submission to the Wojood NER Shared Task 2024 (ArabicNLP 2024). We have participated in the shared sub-task 1 Flat NER. In this shared sub-task, we tackle fine-grained flat-entity recognition for Arabic text, where we identify a single main entity and possibly zero or multiple sub-entities for each word. Arabic KNN-NER augments the probability distribution of a fine-tuned model with another label probability distribution derived from performing a KNN search over the cached training data. Our submission achieved 91% on the test set on the WojoodFine dataset, placing Arabic KNN-NER on top of the leaderboard for the shared task.","sentences":["Named Entity Recognition (NER) is a task in Natural Language Processing (NLP) that aims to identify and classify entities in text into predefined categories.","However, when applied to Arabic data, NER encounters unique challenges stemming from the language's rich morphological inflections, absence of capitalization cues, and spelling variants, where a single word can comprise multiple morphemes.","In this paper, we introduce Arabic KNN-NER, our submission to the Wojood NER Shared Task 2024 (ArabicNLP 2024).","We have participated in the shared sub-task 1 Flat NER.","In this shared sub-task, we tackle fine-grained flat-entity recognition for Arabic text, where we identify a single main entity and possibly zero or multiple sub-entities for each word.","Arabic KNN-NER augments the probability distribution of a fine-tuned model with another label probability distribution derived from performing a KNN search over the cached training data.","Our submission achieved 91% on the test set on the WojoodFine dataset, placing Arabic KNN-NER on top of the leaderboard for the shared task."],"url":"http://arxiv.org/abs/2408.03652v1"}
{"created":"2024-08-07 09:25:17","title":"Towards Multimodal Emotional Support Conversation Systems","abstract":"The integration of conversational artificial intelligence (AI) into mental health care promises a new horizon for therapist-client interactions, aiming to closely emulate the depth and nuance of human conversations. Despite the potential, the current landscape of conversational AI is markedly limited by its reliance on single-modal data, constraining the systems' ability to empathize and provide effective emotional support. This limitation stems from a paucity of resources that encapsulate the multimodal nature of human communication essential for therapeutic counseling. To address this gap, we introduce the Multimodal Emotional Support Conversation (MESC) dataset, a first-of-its-kind resource enriched with comprehensive annotations across text, audio, and video modalities. This dataset captures the intricate interplay of user emotions, system strategies, system emotion, and system responses, setting a new precedent in the field. Leveraging the MESC dataset, we propose a general Sequential Multimodal Emotional Support framework (SMES) grounded in Therapeutic Skills Theory. Tailored for multimodal dialogue systems, the SMES framework incorporates an LLM-based reasoning model that sequentially generates user emotion recognition, system strategy prediction, system emotion prediction, and response generation. Our rigorous evaluations demonstrate that this framework significantly enhances the capability of AI systems to mimic therapist behaviors with heightened empathy and strategic responsiveness. By integrating multimodal data in this innovative manner, we bridge the critical gap between emotion recognition and emotional support, marking a significant advancement in conversational AI for mental health support.","sentences":["The integration of conversational artificial intelligence (AI) into mental health care promises a new horizon for therapist-client interactions, aiming to closely emulate the depth and nuance of human conversations.","Despite the potential, the current landscape of conversational AI is markedly limited by its reliance on single-modal data, constraining the systems' ability to empathize and provide effective emotional support.","This limitation stems from a paucity of resources that encapsulate the multimodal nature of human communication essential for therapeutic counseling.","To address this gap, we introduce the Multimodal Emotional Support Conversation (MESC) dataset, a first-of-its-kind resource enriched with comprehensive annotations across text, audio, and video modalities.","This dataset captures the intricate interplay of user emotions, system strategies, system emotion, and system responses, setting a new precedent in the field.","Leveraging the MESC dataset, we propose a general Sequential Multimodal Emotional Support framework (SMES) grounded in Therapeutic Skills Theory.","Tailored for multimodal dialogue systems, the SMES framework incorporates an LLM-based reasoning model that sequentially generates user emotion recognition, system strategy prediction, system emotion prediction, and response generation.","Our rigorous evaluations demonstrate that this framework significantly enhances the capability of AI systems to mimic therapist behaviors with heightened empathy and strategic responsiveness.","By integrating multimodal data in this innovative manner, we bridge the critical gap between emotion recognition and emotional support, marking a significant advancement in conversational AI for mental health support."],"url":"http://arxiv.org/abs/2408.03650v1"}
{"created":"2024-08-07 09:23:01","title":"HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection","abstract":"The utilization of automated depression detection significantly enhances early intervention for individuals experiencing depression. Despite numerous proposals on automated depression detection using recorded clinical interview videos, limited attention has been paid to considering the hierarchical structure of the interview questions. In clinical interviews for diagnosing depression, clinicians use a structured questionnaire that includes routine baseline questions and follow-up questions to assess the interviewee's condition. This paper introduces HiQuE (Hierarchical Question Embedding network), a novel depression detection framework that leverages the hierarchical relationship between primary and follow-up questions in clinical interviews. HiQuE can effectively capture the importance of each question in diagnosing depression by learning mutual information across multiple modalities. We conduct extensive experiments on the widely-used clinical interview data, DAIC-WOZ, where our model outperforms other state-of-the-art multimodal depression detection models and emotion recognition models, showcasing its clinical utility in depression detection.","sentences":["The utilization of automated depression detection significantly enhances early intervention for individuals experiencing depression.","Despite numerous proposals on automated depression detection using recorded clinical interview videos, limited attention has been paid to considering the hierarchical structure of the interview questions.","In clinical interviews for diagnosing depression, clinicians use a structured questionnaire that includes routine baseline questions and follow-up questions to assess the interviewee's condition.","This paper introduces HiQuE (Hierarchical Question Embedding network), a novel depression detection framework that leverages the hierarchical relationship between primary and follow-up questions in clinical interviews.","HiQuE can effectively capture the importance of each question in diagnosing depression by learning mutual information across multiple modalities.","We conduct extensive experiments on the widely-used clinical interview data, DAIC-WOZ, where our model outperforms other state-of-the-art multimodal depression detection models and emotion recognition models, showcasing its clinical utility in depression detection."],"url":"http://arxiv.org/abs/2408.03648v1"}
{"created":"2024-08-07 08:51:10","title":"Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models","abstract":"Despite the massive attention given to time-series explanations due to their extensive applications, a notable limitation in existing approaches is their primary reliance on the time-domain. This overlooks the inherent characteristic of time-series data containing both time and frequency features. In this work, we present Spectral eXplanation (SpectralX), an XAI framework that provides time-frequency explanations for time-series black-box classifiers. This easily adaptable framework enables users to \"plug-in\" various perturbation-based XAI methods for any pre-trained time-series classification models to assess their impact on the explanation quality without having to modify the framework architecture. Additionally, we introduce Feature Importance Approximations (FIA), a new perturbation-based XAI method. These methods consist of feature insertion, deletion, and combination techniques to enhance computational efficiency and class-specific explanations in time-series classification tasks. We conduct extensive experiments in the generated synthetic dataset and various UCR Time-Series datasets to first compare the explanation performance of FIA and other existing perturbation-based XAI methods in both time-domain and time-frequency domain, and then show the superiority of our FIA in the time-frequency domain with the SpectralX framework. Finally, we conduct a user study to confirm the practicality of our FIA in SpectralX framework for class-specific time-frequency based time-series explanations. The source code is available in https://github.com/gustmd0121/Time_is_not_Enough","sentences":["Despite the massive attention given to time-series explanations due to their extensive applications, a notable limitation in existing approaches is their primary reliance on the time-domain.","This overlooks the inherent characteristic of time-series data containing both time and frequency features.","In this work, we present Spectral eXplanation (SpectralX), an XAI framework that provides time-frequency explanations for time-series black-box classifiers.","This easily adaptable framework enables users to \"plug-in\" various perturbation-based XAI methods for any pre-trained time-series classification models to assess their impact on the explanation quality without having to modify the framework architecture.","Additionally, we introduce Feature Importance Approximations (FIA), a new perturbation-based XAI method.","These methods consist of feature insertion, deletion, and combination techniques to enhance computational efficiency and class-specific explanations in time-series classification tasks.","We conduct extensive experiments in the generated synthetic dataset and various UCR Time-Series datasets to first compare the explanation performance of FIA and other existing perturbation-based XAI methods in both time-domain and time-frequency domain, and then show the superiority of our FIA in the time-frequency domain with the SpectralX framework.","Finally, we conduct a user study to confirm the practicality of our FIA in SpectralX framework for class-specific time-frequency based time-series explanations.","The source code is available in https://github.com/gustmd0121/Time_is_not_Enough"],"url":"http://arxiv.org/abs/2408.03636v1"}
{"created":"2024-08-07 08:44:44","title":"CARE: A Clue-guided Assistant for CSRs to Read User Manuals","abstract":"It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones. Current solutions don't fit the online custom service scenarios well due to the lack of attention to user questions and possible responses. Hence, we propose to develop a time-saving and careful reading assistant for CSRs, named CARE. It can help the CSRs quickly find proper responses from the user manuals via explicit clue chains. Specifically, each of the clue chains is formed by inferring over the user manuals, starting from the question clue aligned with the user question and ending at a possible response. To overcome the shortage of supervised data, we adopt the self-supervised strategy for model learning. The offline experiment shows that CARE is efficient in automatically inferring accurate responses from the user manual. The online experiment further demonstrates the superiority of CARE to reduce CSRs' reading burden and keep high service quality, in particular with >35% decrease in time spent and keeping a >0.75 ICC score.","sentences":["It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones.","Current solutions don't fit the online custom service scenarios well due to the lack of attention to user questions and possible responses.","Hence, we propose to develop a time-saving and careful reading assistant for CSRs, named CARE.","It can help the CSRs quickly find proper responses from the user manuals via explicit clue chains.","Specifically, each of the clue chains is formed by inferring over the user manuals, starting from the question clue aligned with the user question and ending at a possible response.","To overcome the shortage of supervised data, we adopt the self-supervised strategy for model learning.","The offline experiment shows that CARE is efficient in automatically inferring accurate responses from the user manual.","The online experiment further demonstrates the superiority of CARE to reduce CSRs' reading burden and keep high service quality, in particular with >35% decrease in time spent and keeping a >0.75 ICC score."],"url":"http://arxiv.org/abs/2408.03633v2"}
{"created":"2024-08-07 08:43:32","title":"Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent","abstract":"Traditional base station siting (BSS) methods rely heavily on drive testing and user feedback, which are laborious and require extensive expertise in communication, networking, and optimization. As large language models (LLMs) and their associated technologies advance, particularly in the realms of prompt engineering and agent engineering, network optimization will witness a revolutionary approach. This approach entails the strategic use of well-crafted prompts to infuse human experience and knowledge into these sophisticated LLMs, and the deployment of autonomous agents as a communication bridge to seamlessly connect the machine language based LLMs with human users using natural language. This integration represents the future paradigm of artificial intelligence (AI) as a service and AI for more ease. As a preliminary exploration, this research first develops a novel LLM-empowered BSS optimization framework, and heuristically proposes four different potential implementations: the strategies based on Prompt-optimized LLM (PoL), human-in-the-Loop LLM (HiLL), LLM-empowered autonomous BSS agent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa). Through evaluation on real-world data, the experiments demonstrate that prompt-assisted LLMs and LLM-based agents can generate more efficient, cost-effective, and reliable network deployments, noticeably enhancing the efficiency of BSS optimization and reducing trivial manual participation.","sentences":["Traditional base station siting (BSS) methods rely heavily on drive testing and user feedback, which are laborious and require extensive expertise in communication, networking, and optimization.","As large language models (LLMs) and their associated technologies advance, particularly in the realms of prompt engineering and agent engineering, network optimization will witness a revolutionary approach.","This approach entails the strategic use of well-crafted prompts to infuse human experience and knowledge into these sophisticated LLMs, and the deployment of autonomous agents as a communication bridge to seamlessly connect the machine language based LLMs with human users using natural language.","This integration represents the future paradigm of artificial intelligence (AI) as a service and AI for more ease.","As a preliminary exploration, this research first develops a novel LLM-empowered BSS optimization framework, and heuristically proposes four different potential implementations: the strategies based on Prompt-optimized LLM (PoL), human-in-the-Loop LLM (HiLL), LLM-empowered autonomous BSS agent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa).","Through evaluation on real-world data, the experiments demonstrate that prompt-assisted LLMs and LLM-based agents can generate more efficient, cost-effective, and reliable network deployments, noticeably enhancing the efficiency of BSS optimization and reducing trivial manual participation."],"url":"http://arxiv.org/abs/2408.03631v1"}
{"created":"2024-08-07 08:43:18","title":"PAGED: A Benchmark for Procedural Graphs Extraction from Documents","abstract":"Automatic extraction of procedural graphs from documents creates a low-cost way for users to easily understand a complex procedure by skimming visual graphs. Despite the progress in recent studies, it remains unanswered: whether the existing studies have well solved this task (Q1) and whether the emerging large language models (LLMs) can bring new opportunities to this task (Q2). To this end, we propose a new benchmark PAGED, equipped with a large high-quality dataset and standard evaluations. It investigates five state-of-the-art baselines, revealing that they fail to extract optimal procedural graphs well because of their heavy reliance on hand-written rules and limited available data. We further involve three advanced LLMs in PAGED and enhance them with a novel self-refine strategy. The results point out the advantages of LLMs in identifying textual elements and their gaps in building logical structures. We hope PAGED can serve as a major landmark for automatic procedural graph extraction and the investigations in PAGED can offer insights into the research on logic reasoning among non-sequential elements.","sentences":["Automatic extraction of procedural graphs from documents creates a low-cost way for users to easily understand a complex procedure by skimming visual graphs.","Despite the progress in recent studies, it remains unanswered: whether the existing studies have well solved this task (Q1) and whether the emerging large language models (LLMs) can bring new opportunities to this task (Q2).","To this end, we propose a new benchmark PAGED, equipped with a large high-quality dataset and standard evaluations.","It investigates five state-of-the-art baselines, revealing that they fail to extract optimal procedural graphs well because of their heavy reliance on hand-written rules and limited available data.","We further involve three advanced LLMs in PAGED and enhance them with a novel self-refine strategy.","The results point out the advantages of LLMs in identifying textual elements and their gaps in building logical structures.","We hope PAGED can serve as a major landmark for automatic procedural graph extraction and the investigations in PAGED can offer insights into the research on logic reasoning among non-sequential elements."],"url":"http://arxiv.org/abs/2408.03630v2"}
{"created":"2024-08-07 08:39:33","title":"Weakly Contrastive Learning via Batch Instance Discrimination and Feature Clustering for Small Sample SAR ATR","abstract":"In recent years, impressive performance of deep learning technology has been recognized in Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR). Since a large amount of annotated data is required in this technique, it poses a trenchant challenge to the issue of obtaining a high recognition rate through less labeled data. To overcome this problem, inspired by the contrastive learning, we proposed a novel framework named Batch Instance Discrimination and Feature Clustering (BIDFC). In this framework, different from that of the objective of general contrastive learning methods, embedding distance between samples should be moderate because of the high similarity between samples in the SAR images. Consequently, our flexible framework is equipped with adjustable distance between embedding, which we term as weakly contrastive learning. Technically, instance labels are assigned to the unlabeled data in per batch and random augmentation and training are performed few times on these augmented data. Meanwhile, a novel Dynamic-Weighted Variance loss (DWV loss) function is also posed to cluster the embedding of enhanced versions for each sample. Experimental results on the moving and stationary target acquisition and recognition (MSTAR) database indicate a 91.25% classification accuracy of our method fine-tuned on only 3.13% training data. Even though a linear evaluation is performed on the same training data, the accuracy can still reach 90.13%. We also verified the effectiveness of BIDFC in OpenSarShip database, indicating that our method can be generalized to other datasets. Our code is avaliable at: https://github.com/Wenlve-Zhou/BIDFC-master.","sentences":["In recent years, impressive performance of deep learning technology has been recognized in Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR).","Since a large amount of annotated data is required in this technique, it poses a trenchant challenge to the issue of obtaining a high recognition rate through less labeled data.","To overcome this problem, inspired by the contrastive learning, we proposed a novel framework named Batch Instance Discrimination and Feature Clustering (BIDFC).","In this framework, different from that of the objective of general contrastive learning methods, embedding distance between samples should be moderate because of the high similarity between samples in the SAR images.","Consequently, our flexible framework is equipped with adjustable distance between embedding, which we term as weakly contrastive learning.","Technically, instance labels are assigned to the unlabeled data in per batch and random augmentation and training are performed few times on these augmented data.","Meanwhile, a novel Dynamic-Weighted Variance loss (DWV loss) function is also posed to cluster the embedding of enhanced versions for each sample.","Experimental results on the moving and stationary target acquisition and recognition (MSTAR) database indicate a 91.25% classification accuracy of our method fine-tuned on only 3.13% training data.","Even though a linear evaluation is performed on the same training data, the accuracy can still reach 90.13%.","We also verified the effectiveness of BIDFC in OpenSarShip database, indicating that our method can be generalized to other datasets.","Our code is avaliable at: https://github.com/Wenlve-Zhou/BIDFC-master."],"url":"http://arxiv.org/abs/2408.03627v1"}
{"created":"2024-08-07 08:37:23","title":"On the choice of the non-trainable internal weights in random feature maps","abstract":"The computationally cheap machine learning architecture of random feature maps can be viewed as a single-layer feedforward network in which the weights of the hidden layer are random but fixed and only the outer weights are learned via linear regression. The internal weights are typically chosen from a prescribed distribution. The choice of the internal weights significantly impacts the accuracy of random feature maps. We address here the task of how to best select the internal weights. In particular, we consider the forecasting problem whereby random feature maps are used to learn a one-step propagator map for a dynamical system. We provide a computationally cheap hit-and-run algorithm to select good internal weights which lead to good forecasting skill. We show that the number of good features is the main factor controlling the forecasting skill of random feature maps and acts as an effective feature dimension. Lastly, we compare random feature maps with single-layer feedforward neural networks in which the internal weights are now learned using gradient descent. We find that random feature maps have superior forecasting capabilities whilst having several orders of magnitude lower computational cost.","sentences":["The computationally cheap machine learning architecture of random feature maps can be viewed as a single-layer feedforward network in which the weights of the hidden layer are random but fixed and only the outer weights are learned via linear regression.","The internal weights are typically chosen from a prescribed distribution.","The choice of the internal weights significantly impacts the accuracy of random feature maps.","We address here the task of how to best select the internal weights.","In particular, we consider the forecasting problem whereby random feature maps are used to learn a one-step propagator map for a dynamical system.","We provide a computationally cheap hit-and-run algorithm to select good internal weights which lead to good forecasting skill.","We show that the number of good features is the main factor controlling the forecasting skill of random feature maps and acts as an effective feature dimension.","Lastly, we compare random feature maps with single-layer feedforward neural networks in which the internal weights are now learned using gradient descent.","We find that random feature maps have superior forecasting capabilities whilst having several orders of magnitude lower computational cost."],"url":"http://arxiv.org/abs/2408.03626v1"}
{"created":"2024-08-07 08:23:42","title":"Making Robust Generalizers Less Rigid with Soft Ascent-Descent","abstract":"While the traditional formulation of machine learning tasks is in terms of performance on average, in practice we are often interested in how well a trained model performs on rare or difficult data points at test time. To achieve more robust and balanced generalization, methods applying sharpness-aware minimization to a subset of worst-case examples have proven successful for image classification tasks, but only using deep neural networks in a scenario where the most difficult points are also the least common. In this work, we show how such a strategy can dramatically break down under more diverse models, and as a more robust alternative, instead of typical sharpness we propose and evaluate a training criterion which penalizes poor loss concentration, which can be easily combined with loss transformations such as CVaR or DRO that control tail emphasis.","sentences":["While the traditional formulation of machine learning tasks is in terms of performance on average, in practice we are often interested in how well a trained model performs on rare or difficult data points at test time.","To achieve more robust and balanced generalization, methods applying sharpness-aware minimization to a subset of worst-case examples have proven successful for image classification tasks, but only using deep neural networks in a scenario where the most difficult points are also the least common.","In this work, we show how such a strategy can dramatically break down under more diverse models, and as a more robust alternative, instead of typical sharpness we propose and evaluate a training criterion which penalizes poor loss concentration, which can be easily combined with loss transformations such as CVaR or DRO that control tail emphasis."],"url":"http://arxiv.org/abs/2408.03619v1"}
{"created":"2024-08-07 08:18:51","title":"Is Child-Directed Speech Effective Training Data for Language Models?","abstract":"While high-performing language models are typically trained on hundreds of billions of words, human children become fluent language users with a much smaller amount of data. What are the features of the data they receive, and how do these features support language modeling objectives? To investigate this question, we train GPT-2 models on 29M words of English-language child-directed speech and a new matched, synthetic dataset (TinyDialogues), comparing to a heterogeneous blend of datasets from the BabyLM challenge. We evaluate both the syntactic and semantic knowledge of these models using developmentally-inspired evaluations. Through pretraining experiments, we test whether the global developmental ordering or the local discourse ordering of children's training data support high performance relative to other datasets. The local properties of the data affect model results, but somewhat surprisingly, global properties do not. Further, child language input is not uniquely valuable for training language models. These findings support the hypothesis that, rather than proceeding from better data, children's learning is instead substantially more efficient than current language modeling techniques.","sentences":["While high-performing language models are typically trained on hundreds of billions of words, human children become fluent language users with a much smaller amount of data.","What are the features of the data they receive, and how do these features support language modeling objectives?","To investigate this question, we train GPT-2 models on 29M words of English-language child-directed speech and a new matched, synthetic dataset (TinyDialogues), comparing to a heterogeneous blend of datasets from the BabyLM challenge.","We evaluate both the syntactic and semantic knowledge of these models using developmentally-inspired evaluations.","Through pretraining experiments, we test whether the global developmental ordering or the local discourse ordering of children's training data support high performance relative to other datasets.","The local properties of the data affect model results, but somewhat surprisingly, global properties do not.","Further, child language input is not uniquely valuable for training language models.","These findings support the hypothesis that, rather than proceeding from better data, children's learning is instead substantially more efficient than current language modeling techniques."],"url":"http://arxiv.org/abs/2408.03617v1"}
{"created":"2024-08-07 07:59:53","title":"Longest Common Extensions with Wildcards: Trade-off and Applications","abstract":"We study the Longest Common Extension (LCE) problem in a string containing wildcards. Wildcards (also called \"don't cares\" or \"holes\") are special characters that match any other character in the alphabet, similar to the character \"?\" in Unix commands or \".\" in regular expression engines.   We consider the problem parametrized by $G$, the number of maximal contiguous groups of wildcards in the input string. Our main contribution is a simple data structure for this problem that can be built in $O(n (G/t) \\log n)$ time, occupies $O(nG/t)$ space, and answers queries in $O(t)$ time, for any $t \\in [1 .. G]$. Up to the $O(\\log n)$ factor, this interpolates smoothly between the data structure of Crochemore et al. [JDA 2015], which has $O(nG)$ preprocessing time and space, and $O(1)$ query time, and a simple solution based on the ``kangaroo jumping'' technique [Landau and Vishkin, STOC 1986], which has $O(n)$ preprocessing time and space, and $O(G)$ query time.   By establishing a connection between this problem and Boolean matrix multiplication, we show that our solution is optimal up to subpolynomial factors when $G = \\Omega(n)$ under a widely believed hypothesis. In addition, we develop a new simple, deterministic and combinatorial algorithm for sparse Boolean matrix multiplication.   Finally, we show that our data structure can be used to obtain efficient algorithms for approximate pattern matching and structural analysis of strings with wildcards.","sentences":["We study the Longest Common Extension (LCE) problem in a string containing wildcards.","Wildcards (also called \"don't cares\" or \"holes\") are special characters that match any other character in the alphabet, similar to the character \"?\" in Unix commands or \".\"","in regular expression engines.   ","We consider the problem parametrized by $G$, the number of maximal contiguous groups of wildcards in the input string.","Our main contribution is a simple data structure for this problem that can be built in $O(n (G/t) \\log n)$ time, occupies $O(nG/t)$ space, and answers queries in $O(t)$ time, for any $t \\in [1 .. G]$. Up to the $O(\\log n)$ factor, this interpolates smoothly between the data structure of Crochemore et al.","[JDA 2015], which has $O(nG)$ preprocessing time and space, and $O(1)$ query time, and a simple solution based on the ``kangaroo jumping'' technique [Landau and Vishkin, STOC 1986], which has $O(n)$ preprocessing time and space, and $O(G)$ query time.   ","By establishing a connection between this problem and Boolean matrix multiplication, we show that our solution is optimal up to subpolynomial factors when $G = \\Omega(n)$ under a widely believed hypothesis.","In addition, we develop a new simple, deterministic and combinatorial algorithm for sparse Boolean matrix multiplication.   ","Finally, we show that our data structure can be used to obtain efficient algorithms for approximate pattern matching and structural analysis of strings with wildcards."],"url":"http://arxiv.org/abs/2408.03610v1"}
{"created":"2024-08-07 07:54:19","title":"InPer: Whole-Process Domain Generalization via Causal Intervention and Perturbation","abstract":"Despite the considerable advancements achieved by deep neural networks, their performance tends to degenerate when the test environment diverges from the training ones. Domain generalization (DG) solves this issue by learning representations independent of domain-related information, thus facilitating extrapolation to unseen environments. Existing approaches typically focus on formulating tailored training objectives to extract shared features from the source data. However, the disjointed training and testing procedures may compromise robustness, particularly in the face of unforeseen variations during deployment. In this paper, we propose a novel and holistic framework based on causality, named InPer, designed to enhance model generalization by incorporating causal intervention during training and causal perturbation during testing. Specifically, during the training phase, we employ entropy-based causal intervention (EnIn) to refine the selection of causal variables. To identify samples with anti-interference causal variables from the target domain, we propose a novel metric, homeostatic score, through causal perturbation (HoPer) to construct a prototype classifier in test time. Experimental results across multiple cross-domain tasks confirm the efficacy of InPer.","sentences":["Despite the considerable advancements achieved by deep neural networks, their performance tends to degenerate when the test environment diverges from the training ones.","Domain generalization (DG) solves this issue by learning representations independent of domain-related information, thus facilitating extrapolation to unseen environments.","Existing approaches typically focus on formulating tailored training objectives to extract shared features from the source data.","However, the disjointed training and testing procedures may compromise robustness, particularly in the face of unforeseen variations during deployment.","In this paper, we propose a novel and holistic framework based on causality, named InPer, designed to enhance model generalization by incorporating causal intervention during training and causal perturbation during testing.","Specifically, during the training phase, we employ entropy-based causal intervention (EnIn) to refine the selection of causal variables.","To identify samples with anti-interference causal variables from the target domain, we propose a novel metric, homeostatic score, through causal perturbation (HoPer) to construct a prototype classifier in test time.","Experimental results across multiple cross-domain tasks confirm the efficacy of InPer."],"url":"http://arxiv.org/abs/2408.03608v1"}
{"created":"2024-08-07 06:39:45","title":"Deterministic Algorithm and Faster Algorithm for Submodular Maximization subject to a Matroid Constraint","abstract":"We study the problem of maximizing a monotone submodular function subject to a matroid constraint, and present for it a deterministic non-oblivious local search algorithm that has an approximation guarantee of $1 - 1/e - \\varepsilon$ (for any $\\varepsilon> 0$) and query complexity of $\\tilde{O}_\\varepsilon(nr)$, where $n$ is the size of the ground set and $r$ is the rank of the matroid. Our algorithm vastly improves over the previous state-of-the-art $0.5008$-approximation deterministic algorithm, and in fact, shows that there is no separation between the approximation guarantees that can be obtained by deterministic and randomized algorithms for the problem considered. The query complexity of our algorithm can be improved to $\\tilde{O}_\\varepsilon(n + r\\sqrt{n})$ using randomization, which is nearly-linear for $r = O(\\sqrt{n})$, and is always at least as good as the previous state-of-the-art algorithms.","sentences":["We study the problem of maximizing a monotone submodular function subject to a matroid constraint, and present for it a deterministic non-oblivious local search algorithm that has an approximation guarantee of $1 - 1/e - \\varepsilon$ (for any $\\varepsilon> 0$) and query complexity of $\\tilde{O}_\\varepsilon(nr)$, where $n$ is the size of the ground set and $r$ is the rank of the matroid.","Our algorithm vastly improves over the previous state-of-the-art $0.5008$-approximation deterministic algorithm, and in fact, shows that there is no separation between the approximation guarantees that can be obtained by deterministic and randomized algorithms for the problem considered.","The query complexity of our algorithm can be improved to $\\tilde{O}_\\varepsilon(n + r\\sqrt{n})$ using randomization, which is nearly-linear for $r = O(\\sqrt{n})$, and is always at least as good as the previous state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2408.03583v1"}
{"created":"2024-08-07 06:28:52","title":"Mind Drifts, Data Shifts: Utilizing Mind Wandering to Track the Evolution of User Experience with Data Visualizations","abstract":"User experience in data visualization is typically assessed through post-viewing self-reports, but these overlook the dynamic cognitive processes during interaction. This study explores the use of mind wandering -- a phenomenon where attention spontaneously shifts from a primary task to internal, task-related thoughts or unrelated distractions -- as a dynamic measure during visualization exploration. Participants reported mind wandering while viewing visualizations from a pre-labeled visualization database and then provided quantitative ratings of trust, engagement, and design quality, along with qualitative descriptions and short-term/long-term recall assessments. Results show that mind wandering negatively affects short-term visualization recall and various post-viewing measures, particularly for visualizations with little text annotation. Further, the type of mind wandering impacts engagement and emotional response. Mind wandering also functions as an intermediate process linking visualization design elements to post-viewing measures, influencing how viewers engage with and interpret visual information over time. Overall, this research underscores the importance of incorporating mind wandering as a dynamic measure in visualization design and evaluation, offering novel avenues for enhancing user engagement and comprehension.","sentences":["User experience in data visualization is typically assessed through post-viewing self-reports, but these overlook the dynamic cognitive processes during interaction.","This study explores the use of mind wandering -- a phenomenon where attention spontaneously shifts from a primary task to internal, task-related thoughts or unrelated distractions -- as a dynamic measure during visualization exploration.","Participants reported mind wandering while viewing visualizations from a pre-labeled visualization database and then provided quantitative ratings of trust, engagement, and design quality, along with qualitative descriptions and short-term/long-term recall assessments.","Results show that mind wandering negatively affects short-term visualization recall and various post-viewing measures, particularly for visualizations with little text annotation.","Further, the type of mind wandering impacts engagement and emotional response.","Mind wandering also functions as an intermediate process linking visualization design elements to post-viewing measures, influencing how viewers engage with and interpret visual information over time.","Overall, this research underscores the importance of incorporating mind wandering as a dynamic measure in visualization design and evaluation, offering novel avenues for enhancing user engagement and comprehension."],"url":"http://arxiv.org/abs/2408.03576v1"}
{"created":"2024-08-07 06:17:48","title":"Active Testing of Large Language Model via Multi-Stage Sampling","abstract":"Performance evaluation plays a crucial role in the development life cycle of large language models (LLMs). It estimates the model's capability, elucidates behavior characteristics, and facilitates the identification of potential issues and limitations, thereby guiding further improvement. Given that LLMs' diverse task-handling abilities stem from large volumes of training data, a comprehensive evaluation also necessitates abundant, well-annotated, and representative test data to assess LLM performance across various downstream tasks. However, the demand for high-quality test data often entails substantial time, computational resources, and manual efforts, sometimes causing the evaluation to be inefficient or impractical. To address these challenges, researchers propose active testing, which estimates the overall performance by selecting a subset of test data. Nevertheless, the existing active testing methods tend to be inefficient, even inapplicable, given the unique new challenges of LLMs (e.g., diverse task types, increased model complexity, and unavailability of training data). To mitigate such limitations and expedite the development cycle of LLMs, in this work, we introduce AcTracer, an active testing framework tailored for LLMs that strategically selects a small subset of test data to achieve a nearly optimal performance estimation for LLMs. AcTracer utilizes both internal and external information from LLMs to guide the test sampling process, reducing variance through a multi-stage pool-based active selection. Our experiment results demonstrate that AcTracer achieves state-of-the-art performance compared to existing methods across various tasks, with up to 38.83% improvement over previous SOTA.","sentences":["Performance evaluation plays a crucial role in the development life cycle of large language models (LLMs).","It estimates the model's capability, elucidates behavior characteristics, and facilitates the identification of potential issues and limitations, thereby guiding further improvement.","Given that LLMs' diverse task-handling abilities stem from large volumes of training data, a comprehensive evaluation also necessitates abundant, well-annotated, and representative test data to assess LLM performance across various downstream tasks.","However, the demand for high-quality test data often entails substantial time, computational resources, and manual efforts, sometimes causing the evaluation to be inefficient or impractical.","To address these challenges, researchers propose active testing, which estimates the overall performance by selecting a subset of test data.","Nevertheless, the existing active testing methods tend to be inefficient, even inapplicable, given the unique new challenges of LLMs (e.g., diverse task types, increased model complexity, and unavailability of training data).","To mitigate such limitations and expedite the development cycle of LLMs, in this work, we introduce AcTracer, an active testing framework tailored for LLMs that strategically selects a small subset of test data to achieve a nearly optimal performance estimation for LLMs.","AcTracer utilizes both internal and external information from LLMs to guide the test sampling process, reducing variance through a multi-stage pool-based active selection.","Our experiment results demonstrate that AcTracer achieves state-of-the-art performance compared to existing methods across various tasks, with up to 38.83% improvement over previous SOTA."],"url":"http://arxiv.org/abs/2408.03573v1"}
{"created":"2024-08-07 06:16:17","title":"2D-OOB: Attributing Data Contribution through Joint Valuation Framework","abstract":"Data valuation has emerged as a powerful framework to quantify the contribution of each datum to the training of a particular machine learning model. However, it is crucial to recognize that the quality of various cells within a single data point can vary greatly in practice. For example, even in the case of an abnormal data point, not all cells are necessarily noisy. The single scalar valuation assigned by existing methods blurs the distinction between noisy and clean cells of a data point, thereby compromising the interpretability of the valuation. In this paper, we propose 2D-OOB, an out-of-bag estimation framework for jointly determining helpful (or detrimental) samples, as well as the particular cells that drive them. Our comprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art performance across multiple use cases, while being exponentially faster. 2D-OOB excels in detecting and rectifying fine-grained outliers at the cell level, as well as localizing backdoor triggers in data poisoning attacks.","sentences":["Data valuation has emerged as a powerful framework to quantify the contribution of each datum to the training of a particular machine learning model.","However, it is crucial to recognize that the quality of various cells within a single data point can vary greatly in practice.","For example, even in the case of an abnormal data point, not all cells are necessarily noisy.","The single scalar valuation assigned by existing methods blurs the distinction between noisy and clean cells of a data point, thereby compromising the interpretability of the valuation.","In this paper, we propose 2D-OOB, an out-of-bag estimation framework for jointly determining helpful (or detrimental) samples, as well as the particular cells that drive them.","Our comprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art performance across multiple use cases, while being exponentially faster.","2D-OOB excels in detecting and rectifying fine-grained outliers at the cell level, as well as localizing backdoor triggers in data poisoning attacks."],"url":"http://arxiv.org/abs/2408.03572v1"}
{"created":"2024-08-07 06:11:25","title":"A comparative study of generative adversarial networks for image recognition algorithms based on deep learning and traditional methods","abstract":"In this paper, an image recognition algorithm based on the combination of deep learning and generative adversarial network (GAN) is studied, and compared with traditional image recognition methods. The purpose of this study is to evaluate the advantages and application prospects of deep learning technology, especially GAN, in the field of image recognition. Firstly, this paper reviews the basic principles and techniques of traditional image recognition methods, including the classical algorithms based on feature extraction such as SIFT, HOG and their combination with support vector machine (SVM), random forest, and other classifiers. Then, the working principle, network structure, and unique advantages of GAN in image generation and recognition are introduced. In order to verify the effectiveness of GAN in image recognition, a series of experiments are designed and carried out using multiple public image data sets for training and testing. The experimental results show that compared with traditional methods, GAN has excellent performance in processing complex images, recognition accuracy, and anti-noise ability. Specifically, Gans are better able to capture high-dimensional features and details of images, significantly improving recognition performance. In addition, Gans shows unique advantages in dealing with image noise, partial missing information, and generating high-quality images.","sentences":["In this paper, an image recognition algorithm based on the combination of deep learning and generative adversarial network (GAN) is studied, and compared with traditional image recognition methods.","The purpose of this study is to evaluate the advantages and application prospects of deep learning technology, especially GAN, in the field of image recognition.","Firstly, this paper reviews the basic principles and techniques of traditional image recognition methods, including the classical algorithms based on feature extraction such as SIFT, HOG and their combination with support vector machine (SVM), random forest, and other classifiers.","Then, the working principle, network structure, and unique advantages of GAN in image generation and recognition are introduced.","In order to verify the effectiveness of GAN in image recognition, a series of experiments are designed and carried out using multiple public image data sets for training and testing.","The experimental results show that compared with traditional methods, GAN has excellent performance in processing complex images, recognition accuracy, and anti-noise ability.","Specifically, Gans are better able to capture high-dimensional features and details of images, significantly improving recognition performance.","In addition, Gans shows unique advantages in dealing with image noise, partial missing information, and generating high-quality images."],"url":"http://arxiv.org/abs/2408.03568v1"}
{"created":"2024-08-07 06:10:45","title":"Unlocking Exocentric Video-Language Data for Egocentric Video Representation Learning","abstract":"We present EMBED (Egocentric Models Built with Exocentric Data), a method designed to transform exocentric video-language data for egocentric video representation learning. Large-scale exocentric data covers diverse activities with significant potential for egocentric learning, but inherent disparities between egocentric and exocentric data pose challenges in utilizing one view for the other seamlessly. Egocentric videos predominantly feature close-up hand-object interactions, whereas exocentric videos offer a broader perspective on human activities. Additionally, narratives in egocentric datasets are typically more action-centric and closely linked with the visual content, in contrast to the narrative styles found in exocentric datasets. To address these challenges, we employ a data transformation framework to adapt exocentric data for egocentric training, focusing on identifying specific video clips that emphasize hand-object interactions and transforming narration styles to align with egocentric perspectives. By applying both vision and language style transfer, our framework creates a new egocentric dataset derived from exocentric video-language data. Through extensive evaluations, we demonstrate the effectiveness of EMBED, achieving state-of-the-art results across various egocentric downstream tasks, including an absolute improvement of 4.7% on the Epic-Kitchens-100 multi-instance retrieval and 6.2% on the EGTEA classification benchmarks in zero-shot settings. Furthermore, EMBED enables egocentric video-language models to perform competitively in exocentric tasks. Finally, we showcase EMBED's application across various exocentric datasets, exhibiting strong generalization capabilities when applied to different exocentric datasets.","sentences":["We present EMBED (Egocentric Models Built with Exocentric Data), a method designed to transform exocentric video-language data for egocentric video representation learning.","Large-scale exocentric data covers diverse activities with significant potential for egocentric learning, but inherent disparities between egocentric and exocentric data pose challenges in utilizing one view for the other seamlessly.","Egocentric videos predominantly feature close-up hand-object interactions, whereas exocentric videos offer a broader perspective on human activities.","Additionally, narratives in egocentric datasets are typically more action-centric and closely linked with the visual content, in contrast to the narrative styles found in exocentric datasets.","To address these challenges, we employ a data transformation framework to adapt exocentric data for egocentric training, focusing on identifying specific video clips that emphasize hand-object interactions and transforming narration styles to align with egocentric perspectives.","By applying both vision and language style transfer, our framework creates a new egocentric dataset derived from exocentric video-language data.","Through extensive evaluations, we demonstrate the effectiveness of EMBED, achieving state-of-the-art results across various egocentric downstream tasks, including an absolute improvement of 4.7% on the Epic-Kitchens-100 multi-instance retrieval and 6.2% on the EGTEA classification benchmarks in zero-shot settings.","Furthermore, EMBED enables egocentric video-language models to perform competitively in exocentric tasks.","Finally, we showcase EMBED's application across various exocentric datasets, exhibiting strong generalization capabilities when applied to different exocentric datasets."],"url":"http://arxiv.org/abs/2408.03567v1"}
{"created":"2024-08-07 05:56:05","title":"Underwater litter monitoring using consumer-grade aerial-aquatic speedy scanner (AASS) and deep learning based super-resolution reconstruction and detection network","abstract":"Underwater litter is widely spread across aquatic environments such as lakes, rivers, and oceans, significantly impacting natural ecosystems. Current monitoring technologies for detecting underwater litter face limitations in survey efficiency, cost, and environmental conditions, highlighting the need for efficient, consumer-grade technologies for automatic detection. This research introduces the Aerial-Aquatic Speedy Scanner (AASS) combined with Super-Resolution Reconstruction (SRR) and an improved YOLOv8 detection network. AASS enhances data acquisition efficiency over traditional methods, capturing high-quality images that accurately identify underwater waste. SRR improves image-resolution by mitigating motion blur and insufficient resolution, thereby enhancing detection tasks. Specifically, the RCAN model achieved the highest mean average precision (mAP) of 78.6% for detection accuracy on reconstructed images among the tested SRR models. With a magnification factor of 4, the SRR test set shows an improved mAP compared to the conventional bicubic set. These results demonstrate the effectiveness of the proposed method in detecting underwater litter.","sentences":["Underwater litter is widely spread across aquatic environments such as lakes, rivers, and oceans, significantly impacting natural ecosystems.","Current monitoring technologies for detecting underwater litter face limitations in survey efficiency, cost, and environmental conditions, highlighting the need for efficient, consumer-grade technologies for automatic detection.","This research introduces the Aerial-Aquatic Speedy Scanner (AASS) combined with Super-Resolution Reconstruction (SRR) and an improved YOLOv8 detection network.","AASS enhances data acquisition efficiency over traditional methods, capturing high-quality images that accurately identify underwater waste.","SRR improves image-resolution by mitigating motion blur and insufficient resolution, thereby enhancing detection tasks.","Specifically, the RCAN model achieved the highest mean average precision (mAP) of 78.6% for detection accuracy on reconstructed images among the tested SRR models.","With a magnification factor of 4, the SRR test set shows an improved mAP compared to the conventional bicubic set.","These results demonstrate the effectiveness of the proposed method in detecting underwater litter."],"url":"http://arxiv.org/abs/2408.03564v1"}
{"created":"2024-08-07 05:52:00","title":"A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case","abstract":"This research compares large language model (LLM) fine-tuning methods, including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning (RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally compared LLM evaluation methods including End to End (E2E) benchmark method of \"Golden Answers\", traditional natural language processing (NLP) metrics, RAG Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation, using the travel chatbot use case. The travel dataset was sourced from the the Reddit API by requesting posts from travel-related subreddits to get travel-related conversation prompts and personalized travel experiences, and augmented for each fine-tuning method. We used two pretrained LLMs utilized for fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to the two pretrained models. The inferences from these models are extensively evaluated against the aforementioned metrics. The best model according to human evaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a Reinforcement Learning from Human Feedback (RLHF) training pipeline, and ultimately was evaluated as the best model. Our main findings are that: 1) quantitative and Ragas metrics do not align with human evaluation, 2) Open AI GPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep humans in the loop for evaluation because, 4) traditional NLP metrics insufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms QLoRA, but still needs postprocessing, 7) RLHF improves model performance significantly. Next steps include improving data quality, increasing data quantity, exploring RAG methods, and focusing data collection on a specific city, which would improve data quality by narrowing the focus, while creating a useful product.","sentences":["This research compares large language model (LLM) fine-tuning methods, including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning (RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally compared LLM evaluation methods including End to End (E2E) benchmark method of \"Golden Answers\", traditional natural language processing (NLP) metrics, RAG Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation, using the travel chatbot use case.","The travel dataset was sourced from the the Reddit API by requesting posts from travel-related subreddits to get travel-related conversation prompts and personalized travel experiences, and augmented for each fine-tuning method.","We used two pretrained LLMs utilized for fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to the two pretrained models.","The inferences from these models are extensively evaluated against the aforementioned metrics.","The best model according to human evaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a Reinforcement Learning from Human Feedback (RLHF) training pipeline, and ultimately was evaluated as the best model.","Our main findings are that: 1) quantitative and Ragas metrics do not align with human evaluation, 2) Open AI GPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep humans in the loop for evaluation because, 4) traditional NLP metrics insufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms QLoRA, but still needs postprocessing, 7) RLHF improves model performance significantly.","Next steps include improving data quality, increasing data quantity, exploring RAG methods, and focusing data collection on a specific city, which would improve data quality by narrowing the focus, while creating a useful product."],"url":"http://arxiv.org/abs/2408.03562v1"}
{"created":"2024-08-07 05:48:05","title":"In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models","abstract":"Despite advancements, fine-tuning Large Language Models (LLMs) remains costly due to the extensive parameter count and substantial data requirements for model generalization. Accessibility to computing resources remains a barrier for the open-source community. To address this challenge, we propose the In2Core algorithm, which selects a coreset by analyzing the correlation between training and evaluation samples with a trained model. Notably, we assess the model's internal gradients to estimate this relationship, aiming to rank the contribution of each training point. To enhance efficiency, we propose an optimization to compute influence functions with a reduced number of layers while achieving similar accuracy. By applying our algorithm to instruction fine-tuning data of LLMs, we can achieve similar performance with just 50% of the training data. Meantime, using influence functions to analyze model coverage to certain testing samples could provide a reliable and interpretable signal on the training set's coverage of those test points.","sentences":["Despite advancements, fine-tuning Large Language Models (LLMs) remains costly due to the extensive parameter count and substantial data requirements for model generalization.","Accessibility to computing resources remains a barrier for the open-source community.","To address this challenge, we propose the In2Core algorithm, which selects a coreset by analyzing the correlation between training and evaluation samples with a trained model.","Notably, we assess the model's internal gradients to estimate this relationship, aiming to rank the contribution of each training point.","To enhance efficiency, we propose an optimization to compute influence functions with a reduced number of layers while achieving similar accuracy.","By applying our algorithm to instruction fine-tuning data of LLMs, we can achieve similar performance with just 50% of the training data.","Meantime, using influence functions to analyze model coverage to certain testing samples could provide a reliable and interpretable signal on the training set's coverage of those test points."],"url":"http://arxiv.org/abs/2408.03560v1"}
{"created":"2024-08-07 03:48:07","title":"Exploring the extent of similarities in software failures across industries using LLMs","abstract":"The rapid evolution of software development necessitates enhanced safety measures. Extracting information about software failures from companies is becoming increasingly more available through news articles.   This research utilizes the Failure Analysis Investigation with LLMs (FAIL) model to extract industry-specific information. Although the FAIL model's database is rich in information, it could benefit from further categorization and industry-specific insights to further assist software engineers.   In previous work news articles were collected from reputable sources and categorized by incidents inside a database. Prompt engineering and Large Language Models (LLMs) were then applied to extract relevant information regarding the software failure. This research extends these methods by categorizing articles into specific domains and types of software failures. The results are visually represented through graphs.   The analysis shows that throughout the database some software failures occur significantly more often in specific industries. This categorization provides a valuable resource for software engineers and companies to identify and address common failures.   This research highlights the synergy between software engineering and Large Language Models (LLMs) to automate and enhance the analysis of software failures. By transforming data from the database into an industry specific model, we provide a valuable resource that can be used to identify common vulnerabilities, predict potential risks, and implement proactive measures for preventing software failures. Leveraging the power of the current FAIL database and data visualization, we aim to provide an avenue for safer and more secure software in the future.","sentences":["The rapid evolution of software development necessitates enhanced safety measures.","Extracting information about software failures from companies is becoming increasingly more available through news articles.   ","This research utilizes the Failure Analysis Investigation with LLMs (FAIL) model to extract industry-specific information.","Although the FAIL model's database is rich in information, it could benefit from further categorization and industry-specific insights to further assist software engineers.   ","In previous work news articles were collected from reputable sources and categorized by incidents inside a database.","Prompt engineering and Large Language Models (LLMs) were then applied to extract relevant information regarding the software failure.","This research extends these methods by categorizing articles into specific domains and types of software failures.","The results are visually represented through graphs.   ","The analysis shows that throughout the database some software failures occur significantly more often in specific industries.","This categorization provides a valuable resource for software engineers and companies to identify and address common failures.   ","This research highlights the synergy between software engineering and Large Language Models (LLMs) to automate and enhance the analysis of software failures.","By transforming data from the database into an industry specific model, we provide a valuable resource that can be used to identify common vulnerabilities, predict potential risks, and implement proactive measures for preventing software failures.","Leveraging the power of the current FAIL database and data visualization, we aim to provide an avenue for safer and more secure software in the future."],"url":"http://arxiv.org/abs/2408.03528v2"}
{"created":"2024-08-07 02:28:37","title":"MoExtend: Tuning New Experts for Modality and Task Extension","abstract":"Large language models (LLMs) excel in various tasks but are primarily trained on text data, limiting their application scope. Expanding LLM capabilities to include vision-language understanding is vital, yet training them on multimodal data from scratch is challenging and costly. Existing instruction tuning methods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs via fully fine-tuning LLMs to bridge the modality gap. However, full fine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous knowledge, and high training costs particularly in the era of increasing tasks and modalities. To solve this issue, we introduce MoExtend, an effective framework designed to streamline the modality adaptation and extension of Mixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts into pre-trained MoE models, endowing them with novel knowledge without the need to tune pretrained models such as MoE and vision encoders. This approach enables rapid adaptation and extension to new modal data or tasks, effectively addressing the challenge of accommodating new modalities within LLMs. Furthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk of catastrophic forgetting. Experimental results demonstrate the efficacy and efficiency of MoExtend in enhancing the multimodal capabilities of LLMs, contributing to advancements in multimodal AI research. Code: https://github.com/zhongshsh/MoExtend.","sentences":["Large language models (LLMs) excel in various tasks but are primarily trained on text data, limiting their application scope.","Expanding LLM capabilities to include vision-language understanding is vital, yet training them on multimodal data from scratch is challenging and costly.","Existing instruction tuning methods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs via fully fine-tuning LLMs to bridge the modality gap.","However, full fine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous knowledge, and high training costs particularly in the era of increasing tasks and modalities.","To solve this issue, we introduce MoExtend, an effective framework designed to streamline the modality adaptation and extension of Mixture-of-Experts (MoE) models.","MoExtend seamlessly integrates new experts into pre-trained MoE models, endowing them with novel knowledge without the need to tune pretrained models such as MoE and vision encoders.","This approach enables rapid adaptation and extension to new modal data or tasks, effectively addressing the challenge of accommodating new modalities within LLMs.","Furthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk of catastrophic forgetting.","Experimental results demonstrate the efficacy and efficiency of MoExtend in enhancing the multimodal capabilities of LLMs, contributing to advancements in multimodal AI research.","Code: https://github.com/zhongshsh/MoExtend."],"url":"http://arxiv.org/abs/2408.03511v1"}
{"created":"2024-08-07 02:14:52","title":"1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your Language Model Thrives on Quality Data","abstract":"This paper presents a compute-efficient approach to pre-training a Language Model-the \"1.5-Pints\"-in only 9 days, while outperforming state-of-the-art models as an instruction-following assistant.Based on MT-Bench (a benchmark that emulates human judgments), 1.5-Pints outperforms Apple's OpenELM and Microsoft's Phi.This is achieved by a carefully curated pre-training dataset of 57 billion tokens, using a mix of automated workflows and manual human review. The selection of the dataset prioritizes content that is considered expository and \"textbook-like\" to aid the model in reasoning and logical deduction, culminating in its overall ability as a strong and versatile AI model. In terms of the model architecture, we employed a modified Mistral tokenizer, alongside a Llama-2 architecture for wider compatibility. For training, we adopted the methodologies used by StableLM, TinyLlama, and Huggingface Zephyr. 1.5-Pints demonstrates that by focusing on data quality over quantity in LLM training, we can significantly reduce training time and resources required. We believe this approach will not only make pre-training more accessible but also reduce our carbon footprint. Our findings and resources from this research are open-sourced, aiming to facilitate further advancements in the field. The 1.5-Pints model is available in two versions: 2K and 16K context windows.","sentences":["This paper presents a compute-efficient approach to pre-training a Language Model-the \"1.5-Pints\"-in only 9 days, while outperforming state-of-the-art models as an instruction-following assistant.","Based on MT-Bench (a benchmark that emulates human judgments), 1.5-Pints outperforms Apple's OpenELM and Microsoft's Phi.","This is achieved by a carefully curated pre-training dataset of 57 billion tokens, using a mix of automated workflows and manual human review.","The selection of the dataset prioritizes content that is considered expository and \"textbook-like\" to aid the model in reasoning and logical deduction, culminating in its overall ability as a strong and versatile AI model.","In terms of the model architecture, we employed a modified Mistral tokenizer, alongside a Llama-2 architecture for wider compatibility.","For training, we adopted the methodologies used by StableLM, TinyLlama, and Huggingface Zephyr.","1.5-Pints demonstrates that by focusing on data quality over quantity in LLM training, we can significantly reduce training time and resources required.","We believe this approach will not only make pre-training more accessible but also reduce our carbon footprint.","Our findings and resources from this research are open-sourced, aiming to facilitate further advancements in the field.","The 1.5-Pints model is available in two versions: 2K and 16K context windows."],"url":"http://arxiv.org/abs/2408.03506v1"}
{"created":"2024-08-07 02:08:29","title":"Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation","abstract":"Multimodal large language models (MLLMs) have extended the success of large language models (LLMs) to multiple data types, such as image, text and audio, achieving significant performance in various domains, including multimodal translation, visual question answering and content generation. Nonetheless, existing systems are inefficient to train MLLMs due to substantial GPU bubbles caused by the heterogeneous modality models and complex data dependencies in 3D parallelism. This paper proposes Optimus, a distributed MLLM training system that reduces end-to-end MLLM training time. Optimus is based on our principled analysis that scheduling the encoder computation within the LLM bubbles can reduce bubbles in MLLM training. To make scheduling encoder computation possible for all GPUs, Optimus searches the separate parallel plans for encoder and LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM bubbles without breaking the original data dependencies in the MLLM model architecture. We further decompose encoder layer computation into a series of kernels, and analyze the common bubble pattern of 3D parallelism to carefully optimize the sub-millisecond bubble scheduling, minimizing the overall training time. Our experiments in a production cluster show that Optimus accelerates MLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs compared to baselines.","sentences":["Multimodal large language models (MLLMs) have extended the success of large language models (LLMs) to multiple data types, such as image, text and audio, achieving significant performance in various domains, including multimodal translation, visual question answering and content generation.","Nonetheless, existing systems are inefficient to train MLLMs due to substantial GPU bubbles caused by the heterogeneous modality models and complex data dependencies in 3D parallelism.","This paper proposes Optimus, a distributed MLLM training system that reduces end-to-end MLLM training time.","Optimus is based on our principled analysis that scheduling the encoder computation within the LLM bubbles can reduce bubbles in MLLM training.","To make scheduling encoder computation possible for all GPUs, Optimus searches the separate parallel plans for encoder and LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM bubbles without breaking the original data dependencies in the MLLM model architecture.","We further decompose encoder layer computation into a series of kernels, and analyze the common bubble pattern of 3D parallelism to carefully optimize the sub-millisecond bubble scheduling, minimizing the overall training time.","Our experiments in a production cluster show that Optimus accelerates MLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs compared to baselines."],"url":"http://arxiv.org/abs/2408.03505v1"}
{"created":"2024-08-07 00:48:49","title":"Harnessing the Power of LLMs in Source Code Vulnerability Detection","abstract":"Software vulnerabilities, caused by unintentional flaws in source code, are a primary root cause of cyberattacks. Static analysis of source code has been widely used to detect these unintentional defects introduced by software developers. Large Language Models (LLMs) have demonstrated human-like conversational abilities due to their capacity to capture complex patterns in sequential data, such as natural languages. In this paper, we harness LLMs' capabilities to analyze source code and detect known vulnerabilities. To ensure the proposed vulnerability detection method is universal across multiple programming languages, we convert source code to LLVM IR and train LLMs on these intermediate representations. We conduct extensive experiments on various LLM architectures and compare their accuracy. Our comprehensive experiments on real-world and synthetic codes from NVD and SARD demonstrate high accuracy in identifying source code vulnerabilities.","sentences":["Software vulnerabilities, caused by unintentional flaws in source code, are a primary root cause of cyberattacks.","Static analysis of source code has been widely used to detect these unintentional defects introduced by software developers.","Large Language Models (LLMs) have demonstrated human-like conversational abilities due to their capacity to capture complex patterns in sequential data, such as natural languages.","In this paper, we harness LLMs' capabilities to analyze source code and detect known vulnerabilities.","To ensure the proposed vulnerability detection method is universal across multiple programming languages, we convert source code to LLVM IR and train LLMs on these intermediate representations.","We conduct extensive experiments on various LLM architectures and compare their accuracy.","Our comprehensive experiments on real-world and synthetic codes from NVD and SARD demonstrate high accuracy in identifying source code vulnerabilities."],"url":"http://arxiv.org/abs/2408.03489v1"}
{"created":"2024-08-06 23:43:03","title":"Advancing EEG-Based Gaze Prediction Using Depthwise Separable Convolution and Enhanced Pre-Processing","abstract":"In the field of EEG-based gaze prediction, the application of deep learning to interpret complex neural data poses significant challenges. This study evaluates the effectiveness of pre-processing techniques and the effect of additional depthwise separable convolution on EEG vision transformers (ViTs) in a pretrained model architecture. We introduce a novel method, the EEG Deeper Clustered Vision Transformer (EEG-DCViT), which combines depthwise separable convolutional neural networks (CNNs) with vision transformers, enriched by a pre-processing strategy involving data clustering. The new approach demonstrates superior performance, establishing a new benchmark with a Root Mean Square Error (RMSE) of 51.6 mm. This achievement underscores the impact of pre-processing and model refinement in enhancing EEG-based applications.","sentences":["In the field of EEG-based gaze prediction, the application of deep learning to interpret complex neural data poses significant challenges.","This study evaluates the effectiveness of pre-processing techniques and the effect of additional depthwise separable convolution on EEG vision transformers (ViTs) in a pretrained model architecture.","We introduce a novel method, the EEG Deeper Clustered Vision Transformer (EEG-DCViT), which combines depthwise separable convolutional neural networks (CNNs) with vision transformers, enriched by a pre-processing strategy involving data clustering.","The new approach demonstrates superior performance, establishing a new benchmark with a Root Mean Square Error (RMSE) of 51.6 mm.","This achievement underscores the impact of pre-processing and model refinement in enhancing EEG-based applications."],"url":"http://arxiv.org/abs/2408.03480v1"}
{"created":"2024-08-06 23:34:49","title":"Effect of Kernel Size on CNN-Vision-Transformer-Based Gaze Prediction Using Electroencephalography Data","abstract":"In this paper, we present an algorithm of gaze prediction from Electroencephalography (EEG) data. EEG-based gaze prediction is a new research topic that can serve as an alternative to traditional video-based eye-tracking. Compared to the existing state-of-the-art (SOTA) method, we improved the root mean-squared-error of EEG-based gaze prediction to 53.06 millimeters, while reducing the training time to less than 33% of its original duration. Our source code can be found at https://github.com/AmCh-Q/CSCI6907Project","sentences":["In this paper, we present an algorithm of gaze prediction from Electroencephalography (EEG) data.","EEG-based gaze prediction is a new research topic that can serve as an alternative to traditional video-based eye-tracking.","Compared to the existing state-of-the-art (SOTA) method, we improved the root mean-squared-error of EEG-based gaze prediction to 53.06 millimeters, while reducing the training time to less than 33% of its original duration.","Our source code can be found at https://github.com/AmCh-Q/CSCI6907Project"],"url":"http://arxiv.org/abs/2408.03478v1"}
{"created":"2024-08-06 23:05:15","title":"Integrating HCI Datasets in Project-Based Machine Learning Courses: A College-Level Review and Case Study","abstract":"This study explores the integration of real-world machine learning (ML) projects using human-computer interfaces (HCI) datasets in college-level courses to enhance both teaching and learning experiences. Employing a comprehensive literature review, course websites analysis, and a detailed case study, the research identifies best practices for incorporating HCI datasets into project-based ML education. Key f indings demonstrate increased student engagement, motivation, and skill development through hands-on projects, while instructors benefit from effective tools for teaching complex concepts. The study also addresses challenges such as data complexity and resource allocation, offering recommendations for future improvements. These insights provide a valuable framework for educators aiming to bridge the gap between","sentences":["This study explores the integration of real-world machine learning (ML) projects using human-computer interfaces (HCI) datasets in college-level courses to enhance both teaching and learning experiences.","Employing a comprehensive literature review, course websites analysis, and a detailed case study, the research identifies best practices for incorporating HCI datasets into project-based ML education.","Key f indings demonstrate increased student engagement, motivation, and skill development through hands-on projects, while instructors benefit from effective tools for teaching complex concepts.","The study also addresses challenges such as data complexity and resource allocation, offering recommendations for future improvements.","These insights provide a valuable framework for educators aiming to bridge the gap between"],"url":"http://arxiv.org/abs/2408.03472v1"}
{"created":"2024-08-06 22:40:07","title":"Rapid mixing of the down-up walk on matchings of a fixed size","abstract":"Let $G = (V,E)$ be a graph on $n$ vertices and let $m^*(G)$ denote the size of a maximum matching in $G$. We show that for any $\\delta > 0$ and for any $1 \\leq k \\leq (1-\\delta)m^*(G)$, the down-up walk on matchings of size $k$ in $G$ mixes in time polynomial in $n$. Previously, polynomial mixing was not known even for graphs with maximum degree $\\Delta$, and our result makes progress on a conjecture of Jain, Perkins, Sah, and Sawhney [STOC, 2022] that the down-up walk mixes in optimal time $O_{\\Delta,\\delta}(n\\log{n})$.   In contrast with recent works analyzing mixing of down-up walks in various settings using the spectral independence framework, we bound the spectral gap by constructing and analyzing a suitable multi-commodity flow. In fact, we present constructions demonstrating the limitations of the spectral independence approach in our setting.","sentences":["Let $G = (V,E)$ be a graph on $n$ vertices and let $m^*(G)$ denote the size of a maximum matching in $G$. We show that for any $\\delta > 0$ and for any $1 \\leq k \\leq (1-\\delta)m^*(G)$, the down-up walk on matchings of size $k$ in $G$ mixes in time polynomial in $n$. Previously, polynomial mixing was not known even for graphs with maximum degree $\\Delta$, and our result makes progress on a conjecture of Jain, Perkins, Sah, and Sawhney [STOC, 2022] that the down-up walk mixes in optimal time $O_{\\Delta,\\delta}(n\\log{n})$.   In contrast with recent works analyzing mixing of down-up walks in various settings using the spectral independence framework, we bound the spectral gap by constructing and analyzing a suitable multi-commodity flow.","In fact, we present constructions demonstrating the limitations of the spectral independence approach in our setting."],"url":"http://arxiv.org/abs/2408.03466v1"}
{"created":"2024-08-06 22:39:34","title":"AI Foundation Models in Remote Sensing: A Survey","abstract":"Artificial Intelligence (AI) technologies have profoundly transformed the field of remote sensing, revolutionizing data collection, processing, and analysis. Traditionally reliant on manual interpretation and task-specific models, remote sensing has been significantly enhanced by the advent of foundation models--large-scale, pre-trained AI models capable of performing a wide array of tasks with unprecedented accuracy and efficiency. This paper provides a comprehensive survey of foundation models in the remote sensing domain, covering models released between June 2021 and June 2024. We categorize these models based on their applications in computer vision and domain-specific tasks, offering insights into their architectures, pre-training datasets, and methodologies. Through detailed performance comparisons, we highlight emerging trends and the significant advancements achieved by these foundation models. Additionally, we discuss the technical challenges, practical implications, and future research directions, addressing the need for high-quality data, computational resources, and improved model generalization. Our research also finds that pre-training methods, particularly self-supervised learning techniques like contrastive learning and masked autoencoders, significantly enhance the performance and robustness of foundation models in remote sensing tasks such as scene classification, object detection, and other applications. This survey aims to serve as a resource for researchers and practitioners by providing a panorama of advances and promising pathways for continued development and application of foundation models in remote sensing.","sentences":["Artificial Intelligence (AI) technologies have profoundly transformed the field of remote sensing, revolutionizing data collection, processing, and analysis.","Traditionally reliant on manual interpretation and task-specific models, remote sensing has been significantly enhanced by the advent of foundation models--large-scale, pre-trained AI models capable of performing a wide array of tasks with unprecedented accuracy and efficiency.","This paper provides a comprehensive survey of foundation models in the remote sensing domain, covering models released between June 2021 and June 2024.","We categorize these models based on their applications in computer vision and domain-specific tasks, offering insights into their architectures, pre-training datasets, and methodologies.","Through detailed performance comparisons, we highlight emerging trends and the significant advancements achieved by these foundation models.","Additionally, we discuss the technical challenges, practical implications, and future research directions, addressing the need for high-quality data, computational resources, and improved model generalization.","Our research also finds that pre-training methods, particularly self-supervised learning techniques like contrastive learning and masked autoencoders, significantly enhance the performance and robustness of foundation models in remote sensing tasks such as scene classification, object detection, and other applications.","This survey aims to serve as a resource for researchers and practitioners by providing a panorama of advances and promising pathways for continued development and application of foundation models in remote sensing."],"url":"http://arxiv.org/abs/2408.03464v1"}
{"created":"2024-08-06 22:11:00","title":"On the Generalization of Preference Learning with DPO","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities but often struggle to align with human preferences, leading to harmful or undesirable outputs. Preference learning, which trains models to distinguish between preferred and non-preferred responses based on human feedback, has become a crucial component for ensuring that LLMs align with human values. Despite the widespread adoption in real-world systems, a thorough theoretical understanding of the generalization guarantees for these models remain lacking. This paper bridges that gap by introducing a new theoretical framework to analyze the generalization guarantees of models trained with direct preference optimization (DPO). While existing generalization theory often focuses on overparameterized models achieving near-optimal loss or models independent of the training process, our framework rigorously assesses how well models generalize after a finite number of gradient steps, reflecting real-world LLM training practices. By analyzing the reward margin associated with each sample and its trajectory throughout training, we can effectively bound the generalization error. We derive learning guarantees showing that, under specific conditions, models trained with DPO can correctly discern preferred responses on unseen data with high probability. These insights are empirically validated on contemporary LLMs, underscoring the practical relevance of our theoretical findings.","sentences":["Large language models (LLMs) have demonstrated remarkable capabilities but often struggle to align with human preferences, leading to harmful or undesirable outputs.","Preference learning, which trains models to distinguish between preferred and non-preferred responses based on human feedback, has become a crucial component for ensuring that LLMs align with human values.","Despite the widespread adoption in real-world systems, a thorough theoretical understanding of the generalization guarantees for these models remain lacking.","This paper bridges that gap by introducing a new theoretical framework to analyze the generalization guarantees of models trained with direct preference optimization (DPO).","While existing generalization theory often focuses on overparameterized models achieving near-optimal loss or models independent of the training process, our framework rigorously assesses how well models generalize after a finite number of gradient steps, reflecting real-world LLM training practices.","By analyzing the reward margin associated with each sample and its trajectory throughout training, we can effectively bound the generalization error.","We derive learning guarantees showing that, under specific conditions, models trained with DPO can correctly discern preferred responses on unseen data with high probability.","These insights are empirically validated on contemporary LLMs, underscoring the practical relevance of our theoretical findings."],"url":"http://arxiv.org/abs/2408.03459v1"}
{"created":"2024-08-06 21:37:38","title":"Transit Rider Heat Stress in Atlanta, GA under Current and Future Climate Scenarios","abstract":"Transit is a crucial mode of transportation, especially in urban areas and for urban and rural disadvantaged communities. Because extreme temperatures often pose threats to the elderly, members of the disability community, and other vulnerable populations, this study seeks to understand the level of influence that extreme temperatures may have on transit users across different demographic groups. In this case study for Atlanta, GA, heat stress is predicted for 2019 transit riders (using transit rider activity survey data) and for three future climate scenarios, SSP245, SSP370, and SSP585, into the year 2100. The HeatPath Analyzer and TransitSim 4.0 models were applied to predict cumulative heat exposure and trip-level risk for 35,999 trip equivalents for an average Atlanta area weekday in the summer of 2019. The analyses show that under 2019 weather conditions, 8.33% of summer trips were estimated to be conducted under extreme heat. With the projected future climate conditions, the percentage of trips under extreme heat risk grows steadily. By 2100, 37.1%, 56.1%, and 76.4% are projected to be under extreme heat risk for scenarios SSP245, SSP370, and SSP585, respectively. Under current weather conditions, Atlanta transit riders that own no vehicles and transit riders that are African American are disproportionately influenced by extreme heat. The disparity between these two groups and other groups of transit riders becomes wider as climate change continues to exacerbate. The findings of the study highlight an urgent need to implement heat mitigation and adaptation strategies in urban transit networks.","sentences":["Transit is a crucial mode of transportation, especially in urban areas and for urban and rural disadvantaged communities.","Because extreme temperatures often pose threats to the elderly, members of the disability community, and other vulnerable populations, this study seeks to understand the level of influence that extreme temperatures may have on transit users across different demographic groups.","In this case study for Atlanta, GA, heat stress is predicted for 2019 transit riders (using transit rider activity survey data) and for three future climate scenarios, SSP245, SSP370, and SSP585, into the year 2100.","The HeatPath Analyzer and TransitSim 4.0 models were applied to predict cumulative heat exposure and trip-level risk for 35,999 trip equivalents for an average Atlanta area weekday in the summer of 2019.","The analyses show that under 2019 weather conditions, 8.33% of summer trips were estimated to be conducted under extreme heat.","With the projected future climate conditions, the percentage of trips under extreme heat risk grows steadily.","By 2100, 37.1%, 56.1%, and 76.4% are projected to be under extreme heat risk for scenarios SSP245, SSP370, and SSP585, respectively.","Under current weather conditions, Atlanta transit riders that own no vehicles and transit riders that are African American are disproportionately influenced by extreme heat.","The disparity between these two groups and other groups of transit riders becomes wider as climate change continues to exacerbate.","The findings of the study highlight an urgent need to implement heat mitigation and adaptation strategies in urban transit networks."],"url":"http://arxiv.org/abs/2408.03457v1"}
{"created":"2024-08-06 21:18:56","title":"An Interactive Augmented Reality Interface for Personalized Proxemics Modeling","abstract":"Understanding and respecting personal space preferences is essential for socially assistive robots designed for older adult users. This work introduces and evaluates a novel personalized context-aware method for modeling users' proxemics preferences during human-robot interactions. Using an interactive augmented reality interface, we collected a set of user-preferred distances from the robot and employed an active transfer learning approach to fine-tune a specialized deep learning model. We evaluated this approach through two user studies: 1) a convenience population study (N = 24) to validate the efficacy of the active transfer learning approach; and 2) a user study involving older adults (N = 15) to assess the system's usability. We compared the data collected with the augmented reality interface and with the physical robot to examine the relationship between proxemics preferences for a virtual robot versus a physically embodied robot. We found that fine-tuning significantly improved model performance: on average, the error in testing decreased by 26.97% after fine-tuning. The system was well-received by older adult participants, who provided valuable feedback and suggestions for future work.","sentences":["Understanding and respecting personal space preferences is essential for socially assistive robots designed for older adult users.","This work introduces and evaluates a novel personalized context-aware method for modeling users' proxemics preferences during human-robot interactions.","Using an interactive augmented reality interface, we collected a set of user-preferred distances from the robot and employed an active transfer learning approach to fine-tune a specialized deep learning model.","We evaluated this approach through two user studies: 1) a convenience population study (N = 24) to validate the efficacy of the active transfer learning approach; and 2) a user study involving older adults (N = 15) to assess the system's usability.","We compared the data collected with the augmented reality interface and with the physical robot to examine the relationship between proxemics preferences for a virtual robot versus a physically embodied robot.","We found that fine-tuning significantly improved model performance: on average, the error in testing decreased by 26.97% after fine-tuning.","The system was well-received by older adult participants, who provided valuable feedback and suggestions for future work."],"url":"http://arxiv.org/abs/2408.03453v1"}
{"created":"2024-08-06 21:03:16","title":"Probabilistic Surrogate Model for Accelerating the Design of Electric Vehicle Battery Enclosures for Crash Performance","abstract":"This paper presents a probabilistic surrogate model for the accelerated design of electric vehicle battery enclosures with a focus on crash performance. The study integrates high-throughput finite element simulations and Gaussian Process Regression to develop a surrogate model that predicts crash parameters with high accuracy while providing uncertainty estimates. The model was trained using data generated from thermoforming and crash simulations over a range of material and process parameters. Validation against new simulation data demonstrated the model's predictive accuracy with mean absolute percentage errors within 8.08% for all output variables. Additionally, a Monte Carlo uncertainty propagation study revealed the impact of input variability on outputs. The results highlight the efficacy of the Gaussian Process Regression model in capturing complex relationships within the dataset, offering a robust and efficient tool for the design optimization of composite battery enclosures.","sentences":["This paper presents a probabilistic surrogate model for the accelerated design of electric vehicle battery enclosures with a focus on crash performance.","The study integrates high-throughput finite element simulations and Gaussian Process Regression to develop a surrogate model that predicts crash parameters with high accuracy while providing uncertainty estimates.","The model was trained using data generated from thermoforming and crash simulations over a range of material and process parameters.","Validation against new simulation data demonstrated the model's predictive accuracy with mean absolute percentage errors within 8.08% for all output variables.","Additionally, a Monte Carlo uncertainty propagation study revealed the impact of input variability on outputs.","The results highlight the efficacy of the Gaussian Process Regression model in capturing complex relationships within the dataset, offering a robust and efficient tool for the design optimization of composite battery enclosures."],"url":"http://arxiv.org/abs/2408.03450v1"}
{"created":"2024-08-06 20:54:39","title":"Optimizing NOMA Transmissions to Advance Federated Learning in Vehicular Networks","abstract":"Diverse critical data, such as location information and driving patterns, can be collected by IoT devices in vehicular networks to improve driving experiences and road safety. However, drivers are often reluctant to share their data due to privacy concerns. The Federated Vehicular Network (FVN) is a promising technology that tackles these concerns by transmitting model parameters instead of raw data, thereby protecting the privacy of drivers. Nevertheless, the performance of Federated Learning (FL) in a vehicular network depends on the joining ratio, which is restricted by the limited available wireless resources. To address these challenges, this paper proposes to apply Non-Orthogonal Multiple Access (NOMA) to improve the joining ratio in a FVN. Specifically, a vehicle selection and transmission power control algorithm is developed to exploit the power domain differences in the received signal to ensure the maximum number of vehicles capable of joining the FVN. Our simulation results demonstrate that the proposed NOMA-based strategy increases the joining ratio and significantly enhances the performance of the FVN.","sentences":["Diverse critical data, such as location information and driving patterns, can be collected by IoT devices in vehicular networks to improve driving experiences and road safety.","However, drivers are often reluctant to share their data due to privacy concerns.","The Federated Vehicular Network (FVN) is a promising technology that tackles these concerns by transmitting model parameters instead of raw data, thereby protecting the privacy of drivers.","Nevertheless, the performance of Federated Learning (FL) in a vehicular network depends on the joining ratio, which is restricted by the limited available wireless resources.","To address these challenges, this paper proposes to apply Non-Orthogonal Multiple Access (NOMA) to improve the joining ratio in a FVN.","Specifically, a vehicle selection and transmission power control algorithm is developed to exploit the power domain differences in the received signal to ensure the maximum number of vehicles capable of joining the FVN.","Our simulation results demonstrate that the proposed NOMA-based strategy increases the joining ratio and significantly enhances the performance of the FVN."],"url":"http://arxiv.org/abs/2408.03446v1"}
{"created":"2024-08-06 19:53:00","title":"Probabilistic Scores of Classifiers, Calibration is not Enough","abstract":"In binary classification tasks, accurate representation of probabilistic predictions is essential for various real-world applications such as predicting payment defaults or assessing medical risks. The model must then be well-calibrated to ensure alignment between predicted probabilities and actual outcomes. However, when score heterogeneity deviates from the underlying data probability distribution, traditional calibration metrics lose reliability, failing to align score distribution with actual probabilities. In this study, we highlight approaches that prioritize optimizing the alignment between predicted scores and true probability distributions over minimizing traditional performance or calibration metrics. When employing tree-based models such as Random Forest and XGBoost, our analysis emphasizes the flexibility these models offer in tuning hyperparameters to minimize the Kullback-Leibler (KL) divergence between predicted and true distributions. Through extensive empirical analysis across 10 UCI datasets and simulations, we demonstrate that optimizing tree-based models based on KL divergence yields superior alignment between predicted scores and actual probabilities without significant performance loss. In real-world scenarios, the reference probability is determined a priori as a Beta distribution estimated through maximum likelihood. Conversely, minimizing traditional calibration metrics may lead to suboptimal results, characterized by notable performance declines and inferior KL values. Our findings reveal limitations in traditional calibration metrics, which could undermine the reliability of predictive models for critical decision-making.","sentences":["In binary classification tasks, accurate representation of probabilistic predictions is essential for various real-world applications such as predicting payment defaults or assessing medical risks.","The model must then be well-calibrated to ensure alignment between predicted probabilities and actual outcomes.","However, when score heterogeneity deviates from the underlying data probability distribution, traditional calibration metrics lose reliability, failing to align score distribution with actual probabilities.","In this study, we highlight approaches that prioritize optimizing the alignment between predicted scores and true probability distributions over minimizing traditional performance or calibration metrics.","When employing tree-based models such as Random Forest and XGBoost, our analysis emphasizes the flexibility these models offer in tuning hyperparameters to minimize the Kullback-Leibler (KL) divergence between predicted and true distributions.","Through extensive empirical analysis across 10 UCI datasets and simulations, we demonstrate that optimizing tree-based models based on KL divergence yields superior alignment between predicted scores and actual probabilities without significant performance loss.","In real-world scenarios, the reference probability is determined a priori as a Beta distribution estimated through maximum likelihood.","Conversely, minimizing traditional calibration metrics may lead to suboptimal results, characterized by notable performance declines and inferior KL values.","Our findings reveal limitations in traditional calibration metrics, which could undermine the reliability of predictive models for critical decision-making."],"url":"http://arxiv.org/abs/2408.03421v1"}
{"created":"2024-08-06 19:01:47","title":"Deep Clustering via Distribution Learning","abstract":"Distribution learning finds probability density functions from a set of data samples, whereas clustering aims to group similar data points to form clusters. Although there are deep clustering methods that employ distribution learning methods, past work still lacks theoretical analysis regarding the relationship between clustering and distribution learning. Thus, in this work, we provide a theoretical analysis to guide the optimization of clustering via distribution learning. To achieve better results, we embed deep clustering guided by a theoretical analysis. Furthermore, the distribution learning method cannot always be directly applied to data. To overcome this issue, we introduce a clustering-oriented distribution learning method called Monte-Carlo Marginalization for Clustering. We integrate Monte-Carlo Marginalization for Clustering into Deep Clustering, resulting in Deep Clustering via Distribution Learning (DCDL). Eventually, the proposed DCDL achieves promising results compared to state-of-the-art methods on popular datasets. Considering a clustering task, the new distribution learning method outperforms previous methods as well.","sentences":["Distribution learning finds probability density functions from a set of data samples, whereas clustering aims to group similar data points to form clusters.","Although there are deep clustering methods that employ distribution learning methods, past work still lacks theoretical analysis regarding the relationship between clustering and distribution learning.","Thus, in this work, we provide a theoretical analysis to guide the optimization of clustering via distribution learning.","To achieve better results, we embed deep clustering guided by a theoretical analysis.","Furthermore, the distribution learning method cannot always be directly applied to data.","To overcome this issue, we introduce a clustering-oriented distribution learning method called Monte-Carlo Marginalization for Clustering.","We integrate Monte-Carlo Marginalization for Clustering into Deep Clustering, resulting in Deep Clustering via Distribution Learning (DCDL).","Eventually, the proposed DCDL achieves promising results compared to state-of-the-art methods on popular datasets.","Considering a clustering task, the new distribution learning method outperforms previous methods as well."],"url":"http://arxiv.org/abs/2408.03407v1"}
{"created":"2024-08-06 18:52:15","title":"RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms","abstract":"We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS) framework, designed to assess the robustness of hierarchical time series forecasting models and algorithms on real-world datasets. Hierarchical time series, where lower-level forecasts must sum to upper-level ones, are prevalent in various contexts, such as retail sales across countries. Current empirical evaluations of forecasting methods are often limited to a small set of benchmark datasets, offering a narrow view of algorithm behavior. RHiOTS addresses this gap by systematically altering existing datasets and modifying the characteristics of individual series and their interrelations. It uses a set of parameterizable transformations to simulate those changes in the data distribution. Additionally, RHiOTS incorporates an innovative visualization component, turning complex, multidimensional robustness evaluation results into intuitive, easily interpretable visuals. This approach allows an in-depth analysis of algorithm and model behavior under diverse conditions. We illustrate the use of RHiOTS by analyzing the predictive performance of several algorithms. Our findings show that traditional statistical methods are more robust than state-of-the-art deep learning algorithms, except when the transformation effect is highly disruptive. Furthermore, we found no significant differences in the robustness of the algorithms when applying specific reconciliation methods, such as MinT. RHiOTS provides researchers with a comprehensive tool for understanding the nuanced behavior of forecasting algorithms, offering a more reliable basis for selecting the most appropriate method for a given problem.","sentences":["We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS) framework, designed to assess the robustness of hierarchical time series forecasting models and algorithms on real-world datasets.","Hierarchical time series, where lower-level forecasts must sum to upper-level ones, are prevalent in various contexts, such as retail sales across countries.","Current empirical evaluations of forecasting methods are often limited to a small set of benchmark datasets, offering a narrow view of algorithm behavior.","RHiOTS addresses this gap by systematically altering existing datasets and modifying the characteristics of individual series and their interrelations.","It uses a set of parameterizable transformations to simulate those changes in the data distribution.","Additionally, RHiOTS incorporates an innovative visualization component, turning complex, multidimensional robustness evaluation results into intuitive, easily interpretable visuals.","This approach allows an in-depth analysis of algorithm and model behavior under diverse conditions.","We illustrate the use of RHiOTS by analyzing the predictive performance of several algorithms.","Our findings show that traditional statistical methods are more robust than state-of-the-art deep learning algorithms, except when the transformation effect is highly disruptive.","Furthermore, we found no significant differences in the robustness of the algorithms when applying specific reconciliation methods, such as MinT. RHiOTS provides researchers with a comprehensive tool for understanding the nuanced behavior of forecasting algorithms, offering a more reliable basis for selecting the most appropriate method for a given problem."],"url":"http://arxiv.org/abs/2408.03399v1"}
{"created":"2024-08-06 18:18:37","title":"A Non-negative VAE:the Generalized Gamma Belief Network","abstract":"The gamma belief network (GBN), often regarded as a deep topic model, has demonstrated its potential for uncovering multi-layer interpretable latent representations in text data. Its notable capability to acquire interpretable latent factors is partially attributed to sparse and non-negative gamma-distributed latent variables. However, the existing GBN and its variations are constrained by the linear generative model, thereby limiting their expressiveness and applicability. To address this limitation, we introduce the generalized gamma belief network (Generalized GBN) in this paper, which extends the original linear generative model to a more expressive non-linear generative model. Since the parameters of the Generalized GBN no longer possess an analytic conditional posterior, we further propose an upward-downward Weibull inference network to approximate the posterior distribution of the latent variables. The parameters of both the generative model and the inference network are jointly trained within the variational inference framework. Finally, we conduct comprehensive experiments on both expressivity and disentangled representation learning tasks to evaluate the performance of the Generalized GBN against state-of-the-art Gaussian variational autoencoders serving as baselines.","sentences":["The gamma belief network (GBN), often regarded as a deep topic model, has demonstrated its potential for uncovering multi-layer interpretable latent representations in text data.","Its notable capability to acquire interpretable latent factors is partially attributed to sparse and non-negative gamma-distributed latent variables.","However, the existing GBN and its variations are constrained by the linear generative model, thereby limiting their expressiveness and applicability.","To address this limitation, we introduce the generalized gamma belief network (Generalized GBN) in this paper, which extends the original linear generative model to a more expressive non-linear generative model.","Since the parameters of the Generalized GBN no longer possess an analytic conditional posterior, we further propose an upward-downward Weibull inference network to approximate the posterior distribution of the latent variables.","The parameters of both the generative model and the inference network are jointly trained within the variational inference framework.","Finally, we conduct comprehensive experiments on both expressivity and disentangled representation learning tasks to evaluate the performance of the Generalized GBN against state-of-the-art Gaussian variational autoencoders serving as baselines."],"url":"http://arxiv.org/abs/2408.03388v1"}
