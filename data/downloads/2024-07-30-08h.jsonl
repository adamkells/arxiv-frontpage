{"created":"2024-07-29 17:59:50","title":"SAPG: Split and Aggregate Policy Gradients","abstract":"Despite extreme sample inefficiency, on-policy reinforcement learning, aka policy gradients, has become a fundamental tool in decision-making problems. With the recent advances in GPU-driven simulation, the ability to collect large amounts of data for RL training has scaled exponentially. However, we show that current RL methods, e.g. PPO, fail to ingest the benefit of parallelized environments beyond a certain point and their performance saturates. To address this, we propose a new on-policy RL algorithm that can effectively leverage large-scale environments by splitting them into chunks and fusing them back together via importance sampling. Our algorithm, termed SAPG, shows significantly higher performance across a variety of challenging environments where vanilla PPO and other strong baselines fail to achieve high performance. Website at https://sapg-rl.github.io/","sentences":["Despite extreme sample inefficiency, on-policy reinforcement learning, aka policy gradients, has become a fundamental tool in decision-making problems.","With the recent advances in GPU-driven simulation, the ability to collect large amounts of data for RL training has scaled exponentially.","However, we show that current RL methods, e.g. PPO, fail to ingest the benefit of parallelized environments beyond a certain point and their performance saturates.","To address this, we propose a new on-policy RL algorithm that can effectively leverage large-scale environments by splitting them into chunks and fusing them back together via importance sampling.","Our algorithm, termed SAPG, shows significantly higher performance across a variety of challenging environments where vanilla PPO and other strong baselines fail to achieve high performance.","Website at https://sapg-rl.github.io/"],"url":"http://arxiv.org/abs/2407.20230v1"}
{"created":"2024-07-29 17:59:21","title":"Improving 2D Feature Representations by 3D-Aware Fine-Tuning","abstract":"Current visual foundation models are trained purely on unstructured 2D data, limiting their understanding of 3D structure of objects and scenes. In this work, we show that fine-tuning on 3D-aware data improves the quality of emerging semantic features. We design a method to lift semantic 2D features into an efficient 3D Gaussian representation, which allows us to re-render them for arbitrary views. Using the rendered 3D-aware features, we design a fine-tuning strategy to transfer such 3D awareness into a 2D foundation model. We demonstrate that models fine-tuned in that way produce features that readily improve downstream task performance in semantic segmentation and depth estimation through simple linear probing. Notably, though fined-tuned on a single indoor dataset, the improvement is transferable to a variety of indoor datasets and out-of-domain datasets. We hope our study encourages the community to consider injecting 3D awareness when training 2D foundation models. Project page: https://ywyue.github.io/FiT3D.","sentences":["Current visual foundation models are trained purely on unstructured 2D data, limiting their understanding of 3D structure of objects and scenes.","In this work, we show that fine-tuning on 3D-aware data improves the quality of emerging semantic features.","We design a method to lift semantic 2D features into an efficient 3D Gaussian representation, which allows us to re-render them for arbitrary views.","Using the rendered 3D-aware features, we design a fine-tuning strategy to transfer such 3D awareness into a 2D foundation model.","We demonstrate that models fine-tuned in that way produce features that readily improve downstream task performance in semantic segmentation and depth estimation through simple linear probing.","Notably, though fined-tuned on a single indoor dataset, the improvement is transferable to a variety of indoor datasets and out-of-domain datasets.","We hope our study encourages the community to consider injecting 3D awareness when training 2D foundation models.","Project page: https://ywyue.github.io/FiT3D."],"url":"http://arxiv.org/abs/2407.20229v1"}
{"created":"2024-07-29 17:57:38","title":"Correspondence-Free SE(3) Point Cloud Registration in RKHS via Unsupervised Equivariant Learning","abstract":"This paper introduces a robust unsupervised SE(3) point cloud registration method that operates without requiring point correspondences. The method frames point clouds as functions in a reproducing kernel Hilbert space (RKHS), leveraging SE(3)-equivariant features for direct feature space registration. A novel RKHS distance metric is proposed, offering reliable performance amidst noise, outliers, and asymmetrical data. An unsupervised training approach is introduced to effectively handle limited ground truth data, facilitating adaptation to real datasets. The proposed method outperforms classical and supervised methods in terms of registration accuracy on both synthetic (ModelNet40) and real-world (ETH3D) noisy, outlier-rich datasets. To our best knowledge, this marks the first instance of successful real RGB-D odometry data registration using an equivariant method. The code is available at {https://sites.google.com/view/eccv24-equivalign}","sentences":["This paper introduces a robust unsupervised SE(3) point cloud registration method that operates without requiring point correspondences.","The method frames point clouds as functions in a reproducing kernel Hilbert space (RKHS), leveraging SE(3)-equivariant features for direct feature space registration.","A novel RKHS distance metric is proposed, offering reliable performance amidst noise, outliers, and asymmetrical data.","An unsupervised training approach is introduced to effectively handle limited ground truth data, facilitating adaptation to real datasets.","The proposed method outperforms classical and supervised methods in terms of registration accuracy on both synthetic (ModelNet40) and real-world (ETH3D) noisy, outlier-rich datasets.","To our best knowledge, this marks the first instance of successful real RGB-D odometry data registration using an equivariant method.","The code is available at {https://sites.google.com/view/eccv24-equivalign}"],"url":"http://arxiv.org/abs/2407.20223v1"}
{"created":"2024-07-29 17:44:34","title":"SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction","abstract":"Graph-based holistic scene representations facilitate surgical workflow understanding and have recently demonstrated significant success. However, this task is often hindered by the limited availability of densely annotated surgical scene data. In this work, we introduce an end-to-end framework for the generation and optimization of surgical scene graphs on a downstream task. Our approach leverages the flexibility of graph-based spectral clustering and the generalization capability of foundation models to generate unsupervised scene graphs with learnable properties. We reinforce the initial spatial graph with sparse temporal connections using local matches between consecutive frames to predict temporally consistent clusters across a temporal neighborhood. By jointly optimizing the spatiotemporal relations and node features of the dynamic scene graph with the downstream task of phase segmentation, we address the costly and annotation-burdensome task of semantic scene comprehension and scene graph generation in surgical videos using only weak surgical phase labels. Further, by incorporating effective intermediate scene representation disentanglement steps within the pipeline, our solution outperforms the SOTA on the CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow recognition","sentences":["Graph-based holistic scene representations facilitate surgical workflow understanding and have recently demonstrated significant success.","However, this task is often hindered by the limited availability of densely annotated surgical scene data.","In this work, we introduce an end-to-end framework for the generation and optimization of surgical scene graphs on a downstream task.","Our approach leverages the flexibility of graph-based spectral clustering and the generalization capability of foundation models to generate unsupervised scene graphs with learnable properties.","We reinforce the initial spatial graph with sparse temporal connections using local matches between consecutive frames to predict temporally consistent clusters across a temporal neighborhood.","By jointly optimizing the spatiotemporal relations and node features of the dynamic scene graph with the downstream task of phase segmentation, we address the costly and annotation-burdensome task of semantic scene comprehension and scene graph generation in surgical videos using only weak surgical phase labels.","Further, by incorporating effective intermediate scene representation disentanglement steps within the pipeline, our solution outperforms the SOTA on the CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow recognition"],"url":"http://arxiv.org/abs/2407.20214v1"}
{"created":"2024-07-29 17:42:25","title":"Distributed Quantum Approximate Optimization Algorithm on Integrated High-Performance Computing and Quantum Computing Systems for Large-Scale Optimization","abstract":"Quantum approximated optimization algorithm (QAOA) has shown promise for solving combinatorial optimization problems by providing quantum speedup on near-term gate-based quantum computing systems. However, QAOA faces challenges in optimizing variational parameters for high-dimensional problems due to the large number of qubits required and the complexity of deep circuits, which limit its scalability for real-world applications. In this study, we propose a distributed QAOA (DQAOA), which leverages a high-performance computing-quantum computing (HPC-QC) integrated system. DQAOA leverages distributed computing strategies to decompose a large job into smaller tasks, which are then processed on the HPC-QC system. The global solution is iteratively updated by aggregating sub-solutions obtained from DQAOA, allowing convergence toward the optimal solution. We demonstrate that DQAOA can handle considerably large-scale optimization problems (e.g., 1,000-bit problem) achieving high accuracy (~99%) and short time-to-solution (~276 s). To apply this algorithm to material science, we further develop an active learning algorithm integrated with our DQAOA (AL-DQAOA), which involves machine learning, DQAOA, and active data production in an iterative loop. We successfully optimize photonic structures using AL-DQAOA, indicating that solving real-world optimization problems using gate-based quantum computing is feasible with our strategies. We expect the proposed DQAOA to be applicable to a wide range of optimization problems and AL-DQAOA to find broader applications in material design.","sentences":["Quantum approximated optimization algorithm (QAOA) has shown promise for solving combinatorial optimization problems by providing quantum speedup on near-term gate-based quantum computing systems.","However, QAOA faces challenges in optimizing variational parameters for high-dimensional problems due to the large number of qubits required and the complexity of deep circuits, which limit its scalability for real-world applications.","In this study, we propose a distributed QAOA (DQAOA), which leverages a high-performance computing-quantum computing (HPC-QC) integrated system.","DQAOA leverages distributed computing strategies to decompose a large job into smaller tasks, which are then processed on the HPC-QC system.","The global solution is iteratively updated by aggregating sub-solutions obtained from DQAOA, allowing convergence toward the optimal solution.","We demonstrate that DQAOA can handle considerably large-scale optimization problems (e.g., 1,000-bit problem) achieving high accuracy (~99%) and short time-to-solution (~276 s).","To apply this algorithm to material science, we further develop an active learning algorithm integrated with our DQAOA (AL-DQAOA), which involves machine learning, DQAOA, and active data production in an iterative loop.","We successfully optimize photonic structures using AL-DQAOA, indicating that solving real-world optimization problems using gate-based quantum computing is feasible with our strategies.","We expect the proposed DQAOA to be applicable to a wide range of optimization problems and AL-DQAOA to find broader applications in material design."],"url":"http://arxiv.org/abs/2407.20212v1"}
{"created":"2024-07-29 17:36:12","title":"Fast computation of permanents over $\\mathbb{F}_3$ via $\\mathbb{F}_2$ arithmetic","abstract":"We present a method of representing an element of $\\mathbb{F}_3^n$ as an element of $\\mathbb{F}_n^2 \\times \\mathbb{F}_n^2$ which in practice will be a pair of unsigned integers. We show how to do addition, subtraction and pointwise multiplication and division of such vectors quickly using primitive binary operations (and, or, xor). We use this machinery to develop a fast algorithm for computing the permanent of a matrix in $\\mathbb{F}_3^{n\\times n}$. We present Julia code for a natural implementation of the permanent and show that our improved implementation gives, roughly, a factor of 80 speedup for problems of practical size. Using this improved code, we perform Monte Carlo simulations that suggest that the distribution of $\\mbox{perm}(A)$ tends to the uniform distribution as $n \\to \\infty$.","sentences":["We present a method of representing an element of $\\mathbb{F}_3^n$ as an element of $\\mathbb{F}_n^2 \\times \\mathbb{F}_n^2$ which in practice will be a pair of unsigned integers.","We show how to do addition, subtraction and pointwise multiplication and division of such vectors quickly using primitive binary operations (and, or, xor).","We use this machinery to develop a fast algorithm for computing the permanent of a matrix in $\\mathbb{F}_3^{n\\times n}$. We present Julia code for a natural implementation of the permanent and show that our improved implementation gives, roughly, a factor of 80 speedup for problems of practical size.","Using this improved code, we perform Monte Carlo simulations that suggest that the distribution of $\\mbox{perm}(A)$ tends to the uniform distribution as $n \\to \\infty$."],"url":"http://arxiv.org/abs/2407.20205v1"}
{"created":"2024-07-29 17:24:35","title":"Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deployment","abstract":"In this study, we developed a learning method for constructing a neural network system capable of memorizing data and recalling it without parameter updates. The system we built using this method is called the Appendable Memory system. The Appendable Memory system enables an artificial intelligence (AI) to acquire new knowledge even after deployment. It consists of two AIs: the Memorizer and the Recaller. This system is a key-value store built using neural networks. The Memorizer receives data and stores it in the Appendable Memory vector, which is dynamically updated when the AI acquires new knowledge. Meanwhile, the Recaller retrieves information from the Appendable Memory vector. What we want to teach AI in this study are the operations of memorizing and recalling information. However, traditional machine learning methods make AI learn features inherent in the learning dataset. We demonstrate that the systems we intend to create cannot be realized by current machine learning methods, that is, by merely repeating the input and output learning sequences with AI. Instead, we propose a method to teach AI to learn operations, by completely removing the features contained in the learning dataset. Specifically, we probabilized all the data involved in learning. This measure prevented AI from learning the features of the data. The learning method proposed in the study differs from traditional machine learning methods and provides fundamental approaches for building an AI system that can store information in a finite memory and recall it at a later date.","sentences":["In this study, we developed a learning method for constructing a neural network system capable of memorizing data and recalling it without parameter updates.","The system we built using this method is called the Appendable Memory system.","The Appendable Memory system enables an artificial intelligence (AI) to acquire new knowledge even after deployment.","It consists of two AIs: the Memorizer and the Recaller.","This system is a key-value store built using neural networks.","The Memorizer receives data and stores it in the Appendable Memory vector, which is dynamically updated when the AI acquires new knowledge.","Meanwhile, the Recaller retrieves information from the Appendable Memory vector.","What we want to teach AI in this study are the operations of memorizing and recalling information.","However, traditional machine learning methods make AI learn features inherent in the learning dataset.","We demonstrate that the systems we intend to create cannot be realized by current machine learning methods, that is, by merely repeating the input and output learning sequences with AI.","Instead, we propose a method to teach AI to learn operations, by completely removing the features contained in the learning dataset.","Specifically, we probabilized all the data involved in learning.","This measure prevented AI from learning the features of the data.","The learning method proposed in the study differs from traditional machine learning methods and provides fundamental approaches for building an AI system that can store information in a finite memory and recall it at a later date."],"url":"http://arxiv.org/abs/2407.20197v1"}
{"created":"2024-07-29 17:20:55","title":"Radiance Fields for Robotic Teleoperation","abstract":"Radiance field methods such as Neural Radiance Fields (NeRFs) or 3D Gaussian Splatting (3DGS), have revolutionized graphics and novel view synthesis. Their ability to synthesize new viewpoints with photo-realistic quality, as well as capture complex volumetric and specular scenes, makes them an ideal visualization for robotic teleoperation setups. Direct camera teleoperation provides high-fidelity operation at the cost of maneuverability, while reconstruction-based approaches offer controllable scenes with lower fidelity. With this in mind, we propose replacing the traditional reconstruction-visualization components of the robotic teleoperation pipeline with online Radiance Fields, offering highly maneuverable scenes with photorealistic quality. As such, there are three main contributions to state of the art: (1) online training of Radiance Fields using live data from multiple cameras, (2) support for a variety of radiance methods including NeRF and 3DGS, (3) visualization suite for these methods including a virtual reality scene. To enable seamless integration with existing setups, these components were tested with multiple robots in multiple configurations and were displayed using traditional tools as well as the VR headset. The results across methods and robots were compared quantitatively to a baseline of mesh reconstruction, and a user study was conducted to compare the different visualization methods. For videos and code, check out https://leggedrobotics.github.io/rffr.github.io/.","sentences":["Radiance field methods such as Neural Radiance Fields (NeRFs) or 3D Gaussian Splatting (3DGS), have revolutionized graphics and novel view synthesis.","Their ability to synthesize new viewpoints with photo-realistic quality, as well as capture complex volumetric and specular scenes, makes them an ideal visualization for robotic teleoperation setups.","Direct camera teleoperation provides high-fidelity operation at the cost of maneuverability, while reconstruction-based approaches offer controllable scenes with lower fidelity.","With this in mind, we propose replacing the traditional reconstruction-visualization components of the robotic teleoperation pipeline with online Radiance Fields, offering highly maneuverable scenes with photorealistic quality.","As such, there are three main contributions to state of the art: (1) online training of Radiance Fields using live data from multiple cameras, (2) support for a variety of radiance methods including NeRF and 3DGS, (3) visualization suite for these methods including a virtual reality scene.","To enable seamless integration with existing setups, these components were tested with multiple robots in multiple configurations and were displayed using traditional tools as well as the VR headset.","The results across methods and robots were compared quantitatively to a baseline of mesh reconstruction, and a user study was conducted to compare the different visualization methods.","For videos and code, check out https://leggedrobotics.github.io/rffr.github.io/."],"url":"http://arxiv.org/abs/2407.20194v1"}
{"created":"2024-07-29 17:14:36","title":"Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search","abstract":"Conversational search supports multi-turn user-system interactions to solve complex information needs. Different from the traditional single-turn ad-hoc search, conversational search encounters a more challenging problem of context-dependent query understanding with the lengthy and long-tail conversational history context. While conversational query rewriting methods leverage explicit rewritten queries to train a rewriting model to transform the context-dependent query into a stand-stone search query, this is usually done without considering the quality of search results. Conversational dense retrieval methods use fine-tuning to improve a pre-trained ad-hoc query encoder, but they are limited by the conversational search data available for training. In this paper, we leverage both rewritten queries and relevance judgments in the conversational search data to train a better query representation model. The key idea is to align the query representation with those of rewritten queries and relevant documents. The proposed model -- Query Representation Alignment Conversational Dense Retriever, QRACDR, is tested on eight datasets, including various settings in conversational search and ad-hoc search. The results demonstrate the strong performance of QRACDR compared with state-of-the-art methods, and confirm the effectiveness of representation alignment.","sentences":["Conversational search supports multi-turn user-system interactions to solve complex information needs.","Different from the traditional single-turn ad-hoc search, conversational search encounters a more challenging problem of context-dependent query understanding with the lengthy and long-tail conversational history context.","While conversational query rewriting methods leverage explicit rewritten queries to train a rewriting model to transform the context-dependent query into a stand-stone search query, this is usually done without considering the quality of search results.","Conversational dense retrieval methods use fine-tuning to improve a pre-trained ad-hoc query encoder, but they are limited by the conversational search data available for training.","In this paper, we leverage both rewritten queries and relevance judgments in the conversational search data to train a better query representation model.","The key idea is to align the query representation with those of rewritten queries and relevant documents.","The proposed model -- Query Representation Alignment Conversational Dense Retriever, QRACDR, is tested on eight datasets, including various settings in conversational search and ad-hoc search.","The results demonstrate the strong performance of QRACDR compared with state-of-the-art methods, and confirm the effectiveness of representation alignment."],"url":"http://arxiv.org/abs/2407.20189v1"}
{"created":"2024-07-29 17:08:21","title":"Theia: Distilling Diverse Vision Foundation Models for Robot Learning","abstract":"Vision-based robot policy learning, which maps visual inputs to actions, necessitates a holistic understanding of diverse visual tasks beyond single-task needs like classification or segmentation. Inspired by this, we introduce Theia, a vision foundation model for robot learning that distills multiple off-the-shelf vision foundation models trained on varied vision tasks. Theia's rich visual representations encode diverse visual knowledge, enhancing downstream robot learning. Extensive experiments demonstrate that Theia outperforms its teacher models and prior robot learning models using less training data and smaller model sizes. Additionally, we quantify the quality of pre-trained visual representations and hypothesize that higher entropy in feature norm distributions leads to improved robot learning performance. Code and models are available at https://github.com/bdaiinstitute/theia.","sentences":["Vision-based robot policy learning, which maps visual inputs to actions, necessitates a holistic understanding of diverse visual tasks beyond single-task needs like classification or segmentation.","Inspired by this, we introduce Theia, a vision foundation model for robot learning that distills multiple off-the-shelf vision foundation models trained on varied vision tasks.","Theia's rich visual representations encode diverse visual knowledge, enhancing downstream robot learning.","Extensive experiments demonstrate that Theia outperforms its teacher models and prior robot learning models using less training data and smaller model sizes.","Additionally, we quantify the quality of pre-trained visual representations and hypothesize that higher entropy in feature norm distributions leads to improved robot learning performance.","Code and models are available at https://github.com/bdaiinstitute/theia."],"url":"http://arxiv.org/abs/2407.20179v1"}
{"created":"2024-07-29 17:06:30","title":"AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs","abstract":"To ensure performance on a diverse set of downstream tasks, LLMs are pretrained via data mixtures over different domains. In this work, we demonstrate that the optimal data composition for a fixed compute budget varies depending on the scale of the training data, suggesting that the common practice of empirically determining an optimal composition using small-scale experiments will not yield the optimal data mixtures when scaling up to the final model. To address this challenge, we propose *AutoScale*, an automated tool that finds a compute-optimal data composition for training at any desired target scale. AutoScale first determines the optimal composition at a small scale using a novel bilevel optimization framework, Direct Data Optimization (*DDO*), and then fits a predictor to estimate the optimal composition at larger scales. The predictor's design is inspired by our theoretical analysis of scaling laws related to data composition, which could be of independent interest. In empirical studies with pre-training 774M Decoder-only LMs (GPT-2 Large) on RedPajama dataset, AutoScale decreases validation perplexity at least 25% faster than any baseline with up to 38% speed up compared to without reweighting, achieving the best overall performance across downstream tasks. On pre-training Encoder-only LMs (BERT) with masked language modeling, DDO is shown to decrease loss on all domains while visibly improving average task performance on GLUE benchmark by 8.7% and on large-scale QA dataset (SQuAD) by 5.9% compared with without reweighting. AutoScale speeds up training by up to 28%. Our codes are open-sourced.","sentences":["To ensure performance on a diverse set of downstream tasks, LLMs are pretrained via data mixtures over different domains.","In this work, we demonstrate that the optimal data composition for a fixed compute budget varies depending on the scale of the training data, suggesting that the common practice of empirically determining an optimal composition using small-scale experiments will not yield the optimal data mixtures when scaling up to the final model.","To address this challenge, we propose *AutoScale*, an automated tool that finds a compute-optimal data composition for training at any desired target scale.","AutoScale first determines the optimal composition at a small scale using a novel bilevel optimization framework, Direct Data Optimization (*DDO*), and then fits a predictor to estimate the optimal composition at larger scales.","The predictor's design is inspired by our theoretical analysis of scaling laws related to data composition, which could be of independent interest.","In empirical studies with pre-training 774M Decoder-only LMs (GPT-2 Large) on RedPajama dataset, AutoScale decreases validation perplexity at least 25% faster than any baseline with up to 38% speed up compared to without reweighting, achieving the best overall performance across downstream tasks.","On pre-training Encoder-only LMs (BERT) with masked language modeling, DDO is shown to decrease loss on all domains while visibly improving average task performance on GLUE benchmark by 8.7% and on large-scale QA dataset (SQuAD) by 5.9% compared with without reweighting.","AutoScale speeds up training by up to 28%.","Our codes are open-sourced."],"url":"http://arxiv.org/abs/2407.20177v1"}
{"created":"2024-07-29 17:05:12","title":"Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation","abstract":"Emotion-driven melody harmonization aims to generate diverse harmonies for a single melody to convey desired emotions. Previous research found it hard to alter the perceived emotional valence of lead sheets only by harmonizing the same melody with different chords, which may be attributed to the constraints imposed by the melody itself and the limitation of existing music representation. In this paper, we propose a novel functional representation for symbolic music. This new method takes musical keys into account, recognizing their significant role in shaping music's emotional character through major-minor tonality. It also allows for melodic variation with respect to keys and addresses the problem of data scarcity for better emotion modeling. A Transformer is employed to harmonize key-adaptable melodies, allowing for keys determined in rule-based or model-based manner. Experimental results confirm the effectiveness of our new representation in generating key-aware harmonies, with objective and subjective evaluations affirming the potential of our approach to convey specific valence for versatile melody.","sentences":["Emotion-driven melody harmonization aims to generate diverse harmonies for a single melody to convey desired emotions.","Previous research found it hard to alter the perceived emotional valence of lead sheets only by harmonizing the same melody with different chords, which may be attributed to the constraints imposed by the melody itself and the limitation of existing music representation.","In this paper, we propose a novel functional representation for symbolic music.","This new method takes musical keys into account, recognizing their significant role in shaping music's emotional character through major-minor tonality.","It also allows for melodic variation with respect to keys and addresses the problem of data scarcity for better emotion modeling.","A Transformer is employed to harmonize key-adaptable melodies, allowing for keys determined in rule-based or model-based manner.","Experimental results confirm the effectiveness of our new representation in generating key-aware harmonies, with objective and subjective evaluations affirming the potential of our approach to convey specific valence for versatile melody."],"url":"http://arxiv.org/abs/2407.20176v1"}
{"created":"2024-07-29 17:04:34","title":"Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning","abstract":"Emerging multimodal large language models (MLLMs) exhibit great potential for chart question answering (CQA). Recent efforts primarily focus on scaling up training datasets (i.e., charts, data tables, and question-answer (QA) pairs) through data collection and synthesis. However, our empirical study on existing MLLMs and CQA datasets reveals notable gaps. First, current data collection and synthesis focus on data volume and lack consideration of fine-grained visual encodings and QA tasks, resulting in unbalanced data distribution divergent from practical CQA scenarios. Second, existing work follows the training recipe of the base MLLMs initially designed for natural images, under-exploring the adaptation to unique chart characteristics, such as rich text elements. To fill the gap, we propose a visualization-referenced instruction tuning approach to guide the training dataset enhancement and model development. Specifically, we propose a novel data engine to effectively filter diverse and high-quality data from existing datasets and subsequently refine and augment the data using LLM-based generation techniques to better align with practical QA tasks and visual encodings. Then, to facilitate the adaptation to chart characteristics, we utilize the enriched data to train an MLLM by unfreezing the vision encoder and incorporating a mixture-of-resolution adaptation strategy for enhanced fine-grained recognition. Experimental results validate the effectiveness of our approach. Even with fewer training examples, our model consistently outperforms state-of-the-art CQA models on established benchmarks. We also contribute a dataset split as a benchmark for future research. Source codes and datasets of this paper are available at https://github.com/zengxingchen/ChartQA-MLLM.","sentences":["Emerging multimodal large language models (MLLMs) exhibit great potential for chart question answering (CQA).","Recent efforts primarily focus on scaling up training datasets (i.e., charts, data tables, and question-answer (QA) pairs) through data collection and synthesis.","However, our empirical study on existing MLLMs and CQA datasets reveals notable gaps.","First, current data collection and synthesis focus on data volume and lack consideration of fine-grained visual encodings and QA tasks, resulting in unbalanced data distribution divergent from practical CQA scenarios.","Second, existing work follows the training recipe of the base MLLMs initially designed for natural images, under-exploring the adaptation to unique chart characteristics, such as rich text elements.","To fill the gap, we propose a visualization-referenced instruction tuning approach to guide the training dataset enhancement and model development.","Specifically, we propose a novel data engine to effectively filter diverse and high-quality data from existing datasets and subsequently refine and augment the data using LLM-based generation techniques to better align with practical QA tasks and visual encodings.","Then, to facilitate the adaptation to chart characteristics, we utilize the enriched data to train an MLLM by unfreezing the vision encoder and incorporating a mixture-of-resolution adaptation strategy for enhanced fine-grained recognition.","Experimental results validate the effectiveness of our approach.","Even with fewer training examples, our model consistently outperforms state-of-the-art CQA models on established benchmarks.","We also contribute a dataset split as a benchmark for future research.","Source codes and datasets of this paper are available at https://github.com/zengxingchen/ChartQA-MLLM."],"url":"http://arxiv.org/abs/2407.20174v1"}
{"created":"2024-07-29 16:49:30","title":"Language-Conditioned Offline RL for Multi-Robot Navigation","abstract":"We present a method for developing navigation policies for multi-robot teams that interpret and follow natural language instructions. We condition these policies on embeddings from pretrained Large Language Models (LLMs), and train them via offline reinforcement learning with as little as 20 minutes of randomly-collected data. Experiments on a team of five real robots show that these policies generalize well to unseen commands, indicating an understanding of the LLM latent space. Our method requires no simulators or environment models, and produces low-latency control policies that can be deployed directly to real robots without finetuning. We provide videos of our experiments at https://sites.google.com/view/llm-marl.","sentences":["We present a method for developing navigation policies for multi-robot teams that interpret and follow natural language instructions.","We condition these policies on embeddings from pretrained Large Language Models (LLMs), and train them via offline reinforcement learning with as little as 20 minutes of randomly-collected data.","Experiments on a team of five real robots show that these policies generalize well to unseen commands, indicating an understanding of the LLM latent space.","Our method requires no simulators or environment models, and produces low-latency control policies that can be deployed directly to real robots without finetuning.","We provide videos of our experiments at https://sites.google.com/view/llm-marl."],"url":"http://arxiv.org/abs/2407.20164v1"}
{"created":"2024-07-29 16:34:47","title":"Machine Learning for predicting chaotic systems","abstract":"Predicting chaotic dynamical systems is critical in many scientific fields such as weather prediction, but challenging due to the characterizing sensitive dependence on initial conditions. Traditional modeling approaches require extensive domain knowledge, often leading to a shift towards data-driven methods using machine learning. However, existing research provides inconclusive results on which machine learning methods are best suited for predicting chaotic systems. In this paper, we compare different lightweight and heavyweight machine learning architectures using extensive existing databases, as well as a newly introduced one that allows for uncertainty quantification in the benchmark results. We perform hyperparameter tuning based on computational cost and introduce a novel error metric, the cumulative maximum error, which combines several desirable properties of traditional metrics, tailored for chaotic systems. Our results show that well-tuned simple methods, as well as untuned baseline methods, often outperform state-of-the-art deep learning models, but their performance can vary significantly with different experimental setups. These findings underscore the importance of matching prediction methods to data characteristics and available computational resources.","sentences":["Predicting chaotic dynamical systems is critical in many scientific fields such as weather prediction, but challenging due to the characterizing sensitive dependence on initial conditions.","Traditional modeling approaches require extensive domain knowledge, often leading to a shift towards data-driven methods using machine learning.","However, existing research provides inconclusive results on which machine learning methods are best suited for predicting chaotic systems.","In this paper, we compare different lightweight and heavyweight machine learning architectures using extensive existing databases, as well as a newly introduced one that allows for uncertainty quantification in the benchmark results.","We perform hyperparameter tuning based on computational cost and introduce a novel error metric, the cumulative maximum error, which combines several desirable properties of traditional metrics, tailored for chaotic systems.","Our results show that well-tuned simple methods, as well as untuned baseline methods, often outperform state-of-the-art deep learning models, but their performance can vary significantly with different experimental setups.","These findings underscore the importance of matching prediction methods to data characteristics and available computational resources."],"url":"http://arxiv.org/abs/2407.20158v1"}
{"created":"2024-07-29 16:25:43","title":"Hierarchically Disentangled Recurrent Network for Factorizing System Dynamics of Multi-scale Systems","abstract":"We present a knowledge-guided machine learning (KGML) framework for modeling multi-scale processes, and study its performance in the context of streamflow forecasting in hydrology. Specifically, we propose a novel hierarchical recurrent neural architecture that factorizes the system dynamics at multiple temporal scales and captures their interactions. This framework consists of an inverse and a forward model. The inverse model is used to empirically resolve the system's temporal modes from data (physical model simulations, observed data, or a combination of them from the past), and these states are then used in the forward model to predict streamflow. In a hydrological system, these modes can represent different processes, evolving at different temporal scales (e.g., slow: groundwater recharge and baseflow vs. fast: surface runoff due to extreme rainfall). A key advantage of our framework is that once trained, it can incorporate new observations into the model's context (internal state) without expensive optimization approaches (e.g., EnKF) that are traditionally used in physical sciences for data assimilation. Experiments with several river catchments from the NWS NCRFC region show the efficacy of this ML-based data assimilation framework compared to standard baselines, especially for basins that have a long history of observations. Even for basins that have a shorter observation history, we present two orthogonal strategies of training our FHNN framework: (a) using simulation data from imperfect simulations and (b) using observation data from multiple basins to build a global model. We show that both of these strategies (that can be used individually or together) are highly effective in mitigating the lack of training data. The improvement in forecast accuracy is particularly noteworthy for basins where local models perform poorly because of data sparsity.","sentences":["We present a knowledge-guided machine learning (KGML) framework for modeling multi-scale processes, and study its performance in the context of streamflow forecasting in hydrology.","Specifically, we propose a novel hierarchical recurrent neural architecture that factorizes the system dynamics at multiple temporal scales and captures their interactions.","This framework consists of an inverse and a forward model.","The inverse model is used to empirically resolve the system's temporal modes from data (physical model simulations, observed data, or a combination of them from the past), and these states are then used in the forward model to predict streamflow.","In a hydrological system, these modes can represent different processes, evolving at different temporal scales (e.g., slow: groundwater recharge and baseflow vs. fast: surface runoff due to extreme rainfall).","A key advantage of our framework is that once trained, it can incorporate new observations into the model's context (internal state) without expensive optimization approaches (e.g., EnKF) that are traditionally used in physical sciences for data assimilation.","Experiments with several river catchments from the NWS NCRFC region show the efficacy of this ML-based data assimilation framework compared to standard baselines, especially for basins that have a long history of observations.","Even for basins that have a shorter observation history, we present two orthogonal strategies of training our FHNN framework: (a) using simulation data from imperfect simulations and (b) using observation data from multiple basins to build a global model.","We show that both of these strategies (that can be used individually or together) are highly effective in mitigating the lack of training data.","The improvement in forecast accuracy is particularly noteworthy for basins where local models perform poorly because of data sparsity."],"url":"http://arxiv.org/abs/2407.20152v1"}
{"created":"2024-07-29 16:18:20","title":"ByteCheckpoint: A Unified Checkpointing System for LLM Development","abstract":"The development of real-world Large Language Models (LLMs) necessitates checkpointing of training states in persistent storage to mitigate potential software and hardware failures, as well as to facilitate checkpoint transferring within the training pipeline and across various tasks. Due to the immense size of LLMs, saving and loading checkpoints often incur intolerable minute-level stalls, significantly diminishing training efficiency. Besides, when transferring checkpoints across tasks, checkpoint resharding, defined as loading checkpoints into parallel configurations differing from those used for saving, is often required according to the characteristics and resource quota of specific tasks. Previous checkpointing systems [16,3,33,6] assume consistent parallel configurations, failing to address the complexities of checkpoint transformation during resharding. Furthermore, in the industry platform, developers create checkpoints from different training frameworks[23,36,21,11], each with its own unique storage and I/O logic. This diversity complicates the implementation of unified checkpoint management and optimization. To address these challenges, we introduce ByteCheckpoint, a PyTorch-native multi-framework LLM checkpointing system that supports automatic online checkpoint resharding. ByteCheckpoint employs a data/metadata disaggregated storage architecture, decoupling checkpoint storage from the adopted parallelism strategies and training frameworks. We design an efficient asynchronous tensor merging technique to settle the irregular tensor sharding problem and propose several I/O performance optimizations to significantly enhance the efficiency of checkpoint saving and loading. Experimental results demonstrate ByteCheckpoint's substantial advantages in reducing checkpoint saving (by up to 529.22X) and loading (by up to 3.51X) costs, compared to baseline methods.","sentences":["The development of real-world Large Language Models (LLMs) necessitates checkpointing of training states in persistent storage to mitigate potential software and hardware failures, as well as to facilitate checkpoint transferring within the training pipeline and across various tasks.","Due to the immense size of LLMs, saving and loading checkpoints often incur intolerable minute-level stalls, significantly diminishing training efficiency.","Besides, when transferring checkpoints across tasks, checkpoint resharding, defined as loading checkpoints into parallel configurations differing from those used for saving, is often required according to the characteristics and resource quota of specific tasks.","Previous checkpointing systems","[16,3,33,6] assume consistent parallel configurations, failing to address the complexities of checkpoint transformation during resharding.","Furthermore, in the industry platform, developers create checkpoints from different training frameworks[23,36,21,11], each with its own unique storage and I/O logic.","This diversity complicates the implementation of unified checkpoint management and optimization.","To address these challenges, we introduce ByteCheckpoint, a PyTorch-native multi-framework LLM checkpointing system that supports automatic online checkpoint resharding.","ByteCheckpoint employs a data/metadata disaggregated storage architecture, decoupling checkpoint storage from the adopted parallelism strategies and training frameworks.","We design an efficient asynchronous tensor merging technique to settle the irregular tensor sharding problem and propose several I/O performance optimizations to significantly enhance the efficiency of checkpoint saving and loading.","Experimental results demonstrate ByteCheckpoint's substantial advantages in reducing checkpoint saving (by up to 529.22X) and loading (by up to 3.51X) costs, compared to baseline methods."],"url":"http://arxiv.org/abs/2407.20143v1"}
{"created":"2024-07-29 15:51:09","title":"Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number","abstract":"We introduce a novel self-supervised deep clustering approach tailored for unstructured data without requiring prior knowledge of the number of clusters, termed Adaptive Self-supervised Robust Clustering (ASRC). In particular, ASRC adaptively learns the graph structure and edge weights to capture both local and global structural information. The obtained graph enables us to learn clustering-friendly feature representations by an enhanced graph auto-encoder with contrastive learning technique. It further leverages the clustering results adaptively obtained by robust continuous clustering (RCC) to generate prototypes for negative sampling, which can further contribute to promoting consistency among positive pairs and enlarging the gap between positive and negative samples. ASRC obtains the final clustering results by applying RCC to the learned feature representations with their consistent graph structure and edge weights. Extensive experiments conducted on seven benchmark datasets demonstrate the efficacy of ASRC, demonstrating its superior performance over other popular clustering models. Notably, ASRC even outperforms methods that rely on prior knowledge of the number of clusters, highlighting its effectiveness in addressing the challenges of clustering unstructured data.","sentences":["We introduce a novel self-supervised deep clustering approach tailored for unstructured data without requiring prior knowledge of the number of clusters, termed Adaptive Self-supervised Robust Clustering (ASRC).","In particular, ASRC adaptively learns the graph structure and edge weights to capture both local and global structural information.","The obtained graph enables us to learn clustering-friendly feature representations by an enhanced graph auto-encoder with contrastive learning technique.","It further leverages the clustering results adaptively obtained by robust continuous clustering (RCC) to generate prototypes for negative sampling, which can further contribute to promoting consistency among positive pairs and enlarging the gap between positive and negative samples.","ASRC obtains the final clustering results by applying RCC to the learned feature representations with their consistent graph structure and edge weights.","Extensive experiments conducted on seven benchmark datasets demonstrate the efficacy of ASRC, demonstrating its superior performance over other popular clustering models.","Notably, ASRC even outperforms methods that rely on prior knowledge of the number of clusters, highlighting its effectiveness in addressing the challenges of clustering unstructured data."],"url":"http://arxiv.org/abs/2407.20119v1"}
{"created":"2024-07-29 15:44:22","title":"FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis","abstract":"In the field of Image-Text Retrieval (ITR), recent advancements have leveraged large-scale Vision-Language Pretraining (VLP) for Fine-Grained (FG) instance-level retrieval, achieving high accuracy at the cost of increased computational complexity. For Coarse-Grained (CG) category-level retrieval, prominent approaches employ Cross-Modal Hashing (CMH) to prioritise efficiency, albeit at the cost of retrieval performance. Due to differences in methodologies, FG and CG models are rarely compared directly within evaluations in the literature, resulting in a lack of empirical data quantifying the retrieval performance-efficiency tradeoffs between the two. This paper addresses this gap by introducing the \\texttt{FiCo-ITR} library, which standardises evaluation methodologies for both FG and CG models, facilitating direct comparisons. We conduct empirical evaluations of representative models from both subfields, analysing precision, recall, and computational complexity across varying data scales. Our findings offer new insights into the performance-efficiency trade-offs between recent representative FG and CG models, highlighting their respective strengths and limitations. These findings provide the foundation necessary to make more informed decisions regarding model selection for specific retrieval tasks and highlight avenues for future research into hybrid systems that leverage the strengths of both FG and CG approaches.","sentences":["In the field of Image-Text Retrieval (ITR), recent advancements have leveraged large-scale Vision-Language Pretraining (VLP) for Fine-Grained (FG) instance-level retrieval, achieving high accuracy at the cost of increased computational complexity.","For Coarse-Grained (CG) category-level retrieval, prominent approaches employ Cross-Modal Hashing (CMH) to prioritise efficiency, albeit at the cost of retrieval performance.","Due to differences in methodologies, FG and CG models are rarely compared directly within evaluations in the literature, resulting in a lack of empirical data quantifying the retrieval performance-efficiency tradeoffs between the two.","This paper addresses this gap by introducing the \\texttt{FiCo-ITR} library, which standardises evaluation methodologies for both FG and CG models, facilitating direct comparisons.","We conduct empirical evaluations of representative models from both subfields, analysing precision, recall, and computational complexity across varying data scales.","Our findings offer new insights into the performance-efficiency trade-offs between recent representative FG and CG models, highlighting their respective strengths and limitations.","These findings provide the foundation necessary to make more informed decisions regarding model selection for specific retrieval tasks and highlight avenues for future research into hybrid systems that leverage the strengths of both FG and CG approaches."],"url":"http://arxiv.org/abs/2407.20114v1"}
{"created":"2024-07-29 15:39:25","title":"Enhancing Anti-spoofing Countermeasures Robustness through Joint Optimization and Transfer Learning","abstract":"Current research in synthesized speech detection primarily focuses on the generalization of detection systems to unknown spoofing methods of noise-free speech. However, the performance of anti-spoofing countermeasures (CM) system is often don't work as well in more challenging scenarios, such as those involving noise and reverberation. To address the problem of enhancing the robustness of CM systems, we propose a transfer learning-based speech enhancement front-end joint optimization (TL-SEJ) method, investigating its effectiveness in improving robustness against noise and reverberation. We evaluated the proposed method's performance through a series of comparative and ablation experiments. The experimental results show that, across different signal-to-noise ratio test conditions, the proposed TL-SEJ method improves recognition accuracy by 2.7% to 15.8% compared to the baseline. Compared to conventional data augmentation methods, our system achieves an accuracy improvement ranging from 0.7% to 5.8% in various noisy conditions and from 1.7% to 2.8% under different RT60 reverberation scenarios. These experiments demonstrate that the proposed method effectively enhances system robustness in noisy and reverberant conditions.","sentences":["Current research in synthesized speech detection primarily focuses on the generalization of detection systems to unknown spoofing methods of noise-free speech.","However, the performance of anti-spoofing countermeasures (CM) system is often don't work as well in more challenging scenarios, such as those involving noise and reverberation.","To address the problem of enhancing the robustness of CM systems, we propose a transfer learning-based speech enhancement front-end joint optimization (TL-SEJ) method, investigating its effectiveness in improving robustness against noise and reverberation.","We evaluated the proposed method's performance through a series of comparative and ablation experiments.","The experimental results show that, across different signal-to-noise ratio test conditions, the proposed TL-SEJ method improves recognition accuracy by 2.7% to 15.8% compared to the baseline.","Compared to conventional data augmentation methods, our system achieves an accuracy improvement ranging from 0.7% to 5.8% in various noisy conditions and from 1.7% to 2.8% under different RT60 reverberation scenarios.","These experiments demonstrate that the proposed method effectively enhances system robustness in noisy and reverberant conditions."],"url":"http://arxiv.org/abs/2407.20111v1"}
{"created":"2024-07-29 15:36:42","title":"Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning","abstract":"One important property of DIstribution Correction Estimation (DICE) methods is that the solution is the optimal stationary distribution ratio between the optimized and data collection policy. In this work, we show that DICE-based methods can be viewed as a transformation from the behavior distribution to the optimal policy distribution. Based on this, we propose a novel approach, Diffusion-DICE, that directly performs this transformation using diffusion models. We find that the optimal policy's score function can be decomposed into two terms: the behavior policy's score function and the gradient of a guidance term which depends on the optimal distribution ratio. The first term can be obtained from a diffusion model trained on the dataset and we propose an in-sample learning objective to learn the second term. Due to the multi-modality contained in the optimal policy distribution, the transformation in Diffusion-DICE may guide towards those local-optimal modes. We thus generate a few candidate actions and carefully select from them to approach global-optimum. Different from all other diffusion-based offline RL methods, the guide-then-select paradigm in Diffusion-DICE only uses in-sample actions for training and brings minimal error exploitation in the value function. We use a didatic toycase example to show how previous diffusion-based methods fail to generate optimal actions due to leveraging these errors and how Diffusion-DICE successfully avoids that. We then conduct extensive experiments on benchmark datasets to show the strong performance of Diffusion-DICE.","sentences":["One important property of DIstribution Correction Estimation (DICE) methods is that the solution is the optimal stationary distribution ratio between the optimized and data collection policy.","In this work, we show that DICE-based methods can be viewed as a transformation from the behavior distribution to the optimal policy distribution.","Based on this, we propose a novel approach, Diffusion-DICE, that directly performs this transformation using diffusion models.","We find that the optimal policy's score function can be decomposed into two terms: the behavior policy's score function and the gradient of a guidance term which depends on the optimal distribution ratio.","The first term can be obtained from a diffusion model trained on the dataset and we propose an in-sample learning objective to learn the second term.","Due to the multi-modality contained in the optimal policy distribution, the transformation in Diffusion-DICE may guide towards those local-optimal modes.","We thus generate a few candidate actions and carefully select from them to approach global-optimum.","Different from all other diffusion-based offline RL methods, the guide-then-select paradigm in Diffusion-DICE only uses in-sample actions for training and brings minimal error exploitation in the value function.","We use a didatic toycase example to show how previous diffusion-based methods fail to generate optimal actions due to leveraging these errors and how Diffusion-DICE successfully avoids that.","We then conduct extensive experiments on benchmark datasets to show the strong performance of Diffusion-DICE."],"url":"http://arxiv.org/abs/2407.20109v1"}
{"created":"2024-07-29 15:32:30","title":"Strong Copyright Protection for Language Models via Adaptive Model Fusion","abstract":"The risk of language models unintentionally reproducing copyrighted material from their training data has led to the development of various protective measures. In this paper, we propose model fusion as an effective solution to safeguard against copyright infringement. In particular, we introduce Copyright-Protecting Fusion (CP-Fuse), an algorithm that adaptively combines language models to minimize the reproduction of protected materials. CP-Fuse is inspired by the recently proposed Near-Access Free (NAF) framework and additionally incorporates a desirable balancing property that we demonstrate prevents the reproduction of memorized training data. Our results show that CP-Fuse significantly reduces the memorization of copyrighted content while maintaining high-quality text and code generation. Furthermore, we demonstrate how CP-Fuse can be integrated with other techniques for enhanced protection.","sentences":["The risk of language models unintentionally reproducing copyrighted material from their training data has led to the development of various protective measures.","In this paper, we propose model fusion as an effective solution to safeguard against copyright infringement.","In particular, we introduce Copyright-Protecting Fusion (CP-Fuse), an algorithm that adaptively combines language models to minimize the reproduction of protected materials.","CP-Fuse is inspired by the recently proposed Near-Access Free (NAF) framework and additionally incorporates a desirable balancing property that we demonstrate prevents the reproduction of memorized training data.","Our results show that CP-Fuse significantly reduces the memorization of copyrighted content while maintaining high-quality text and code generation.","Furthermore, we demonstrate how CP-Fuse can be integrated with other techniques for enhanced protection."],"url":"http://arxiv.org/abs/2407.20105v1"}
{"created":"2024-07-29 15:04:53","title":"UniTTA: Unified Benchmark and Versatile Framework Towards Realistic Test-Time Adaptation","abstract":"Test-Time Adaptation (TTA) aims to adapt pre-trained models to the target domain during testing. In reality, this adaptability can be influenced by multiple factors. Researchers have identified various challenging scenarios and developed diverse methods to address these challenges, such as dealing with continual domain shifts, mixed domains, and temporally correlated or imbalanced class distributions. Despite these efforts, a unified and comprehensive benchmark has yet to be established. To this end, we propose a Unified Test-Time Adaptation (UniTTA) benchmark, which is comprehensive and widely applicable. Each scenario within the benchmark is fully described by a Markov state transition matrix for sampling from the original dataset. The UniTTA benchmark considers both domain and class as two independent dimensions of data and addresses various combinations of imbalance/balance and i.i.d./non-i.i.d./continual conditions, covering a total of \\( (2 \\times 3)^2 = 36 \\) scenarios. It establishes a comprehensive evaluation benchmark for realistic TTA and provides a guideline for practitioners to select the most suitable TTA method. Alongside this benchmark, we propose a versatile UniTTA framework, which includes a Balanced Domain Normalization (BDN) layer and a COrrelated Feature Adaptation (COFA) method--designed to mitigate distribution gaps in domain and class, respectively. Extensive experiments demonstrate that our UniTTA framework excels within the UniTTA benchmark and achieves state-of-the-art performance on average. Our code is available at \\url{https://github.com/LeapLabTHU/UniTTA}.","sentences":["Test-Time Adaptation (TTA) aims to adapt pre-trained models to the target domain during testing.","In reality, this adaptability can be influenced by multiple factors.","Researchers have identified various challenging scenarios and developed diverse methods to address these challenges, such as dealing with continual domain shifts, mixed domains, and temporally correlated or imbalanced class distributions.","Despite these efforts, a unified and comprehensive benchmark has yet to be established.","To this end, we propose a Unified Test-Time Adaptation (UniTTA) benchmark, which is comprehensive and widely applicable.","Each scenario within the benchmark is fully described by a Markov state transition matrix for sampling from the original dataset.","The UniTTA benchmark considers both domain and class as two independent dimensions of data and addresses various combinations of imbalance/balance and i.i.d./non-i.i.d./continual conditions, covering a total of \\( (2 \\times 3)^2 = 36 \\) scenarios.","It establishes a comprehensive evaluation benchmark for realistic TTA and provides a guideline for practitioners to select the most suitable TTA method.","Alongside this benchmark, we propose a versatile UniTTA framework, which includes a Balanced Domain Normalization (BDN) layer and a COrrelated Feature Adaptation (COFA) method--designed to mitigate distribution gaps in domain and class, respectively.","Extensive experiments demonstrate that our UniTTA framework excels within the UniTTA benchmark and achieves state-of-the-art performance on average.","Our code is available at \\url{https://github.com/LeapLabTHU/UniTTA}."],"url":"http://arxiv.org/abs/2407.20080v1"}
{"created":"2024-07-29 15:02:51","title":"Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Language","abstract":"Offensive language detection is a crucial task in today's digital landscape, where online platforms grapple with maintaining a respectful and inclusive environment. However, building robust offensive language detection models requires large amounts of labeled data, which can be expensive and time-consuming to obtain. Semi-supervised learning offers a feasible solution by utilizing labeled and unlabeled data to create more accurate and robust models. In this paper, we explore a few different semi-supervised methods, as well as data augmentation techniques. Concretely, we implemented eight semi-supervised methods and ran experiments for them using only the available data in the RO-Offense dataset and applying five augmentation techniques before feeding the data to the models. Experimental results demonstrate that some of them benefit more from augmentations than others.","sentences":["Offensive language detection is a crucial task in today's digital landscape, where online platforms grapple with maintaining a respectful and inclusive environment.","However, building robust offensive language detection models requires large amounts of labeled data, which can be expensive and time-consuming to obtain.","Semi-supervised learning offers a feasible solution by utilizing labeled and unlabeled data to create more accurate and robust models.","In this paper, we explore a few different semi-supervised methods, as well as data augmentation techniques.","Concretely, we implemented eight semi-supervised methods and ran experiments for them using only the available data in the RO-Offense dataset and applying five augmentation techniques before feeding the data to the models.","Experimental results demonstrate that some of them benefit more from augmentations than others."],"url":"http://arxiv.org/abs/2407.20076v1"}
{"created":"2024-07-29 14:54:28","title":"Unleash the Power of Ellipsis: Accuracy-enhanced Sparse Vector Technique with Exponential Noise","abstract":"The Sparse Vector Technique (SVT) is one of the most fundamental tools in differential privacy (DP). It works as a backbone for adaptive data analysis by answering a sequence of queries on a given dataset, and gleaning useful information in a privacy-preserving manner. Unlike the typical private query releases that directly publicize the noisy query results, SVT is less informative -- it keeps the noisy query results to itself and only reveals a binary bit for each query, indicating whether the query result surpasses a predefined threshold. To provide a rigorous DP guarantee for SVT, prior works in the literature adopt a conservative privacy analysis by assuming the direct disclosure of noisy query results as in typical private query releases. This approach, however, hinders SVT from achieving higher query accuracy due to an overestimation of the privacy risks, which further leads to an excessive noise injection using the Laplacian or Gaussian noise for perturbation. Motivated by this, we provide a new privacy analysis for SVT by considering its less informative nature. Our analysis results not only broaden the range of applicable noise types for perturbation in SVT, but also identify the exponential noise as optimal among all evaluated noises (which, however, is usually deemed non-applicable in prior works). The main challenge in applying exponential noise to SVT is mitigating the sub-optimal performance due to the bias introduced by noise distributions. To address this, we develop a utility-oriented optimal threshold correction method and an appending strategy, which enhances the performance of SVT by increasing the precision and recall, respectively. The effectiveness of our proposed methods is substantiated both theoretically and empirically, demonstrating significant improvements up to $50\\%$ across evaluated metrics.","sentences":["The Sparse Vector Technique (SVT) is one of the most fundamental tools in differential privacy (DP).","It works as a backbone for adaptive data analysis by answering a sequence of queries on a given dataset, and gleaning useful information in a privacy-preserving manner.","Unlike the typical private query releases that directly publicize the noisy query results, SVT is less informative -- it keeps the noisy query results to itself and only reveals a binary bit for each query, indicating whether the query result surpasses a predefined threshold.","To provide a rigorous DP guarantee for SVT, prior works in the literature adopt a conservative privacy analysis by assuming the direct disclosure of noisy query results as in typical private query releases.","This approach, however, hinders SVT from achieving higher query accuracy due to an overestimation of the privacy risks, which further leads to an excessive noise injection using the Laplacian or Gaussian noise for perturbation.","Motivated by this, we provide a new privacy analysis for SVT by considering its less informative nature.","Our analysis results not only broaden the range of applicable noise types for perturbation in SVT, but also identify the exponential noise as optimal among all evaluated noises (which, however, is usually deemed non-applicable in prior works).","The main challenge in applying exponential noise to SVT is mitigating the sub-optimal performance due to the bias introduced by noise distributions.","To address this, we develop a utility-oriented optimal threshold correction method and an appending strategy, which enhances the performance of SVT by increasing the precision and recall, respectively.","The effectiveness of our proposed methods is substantiated both theoretically and empirically, demonstrating significant improvements up to $50\\%$ across evaluated metrics."],"url":"http://arxiv.org/abs/2407.20068v1"}
{"created":"2024-07-29 14:53:45","title":"xAI-Drop: Don't Use What You Cannot Explain","abstract":"Graph Neural Networks (GNNs) have emerged as the predominant paradigm for learning from graph-structured data, offering a wide range of applications from social network analysis to bioinformatics. Despite their versatility, GNNs face challenges such as oversmoothing, lack of generalization and poor interpretability, which hinder their wider adoption and reliability in critical applications. Dropping has emerged as an effective paradigm for reducing noise during training and improving robustness of GNNs. However, existing approaches often rely on random or heuristic-based selection criteria, lacking a principled method to identify and exclude nodes that contribute to noise and over-complexity in the model. In this work, we argue that explainability should be a key indicator of a model's robustness throughout its training phase. To this end, we introduce xAI-Drop, a novel topological-level dropping regularizer that leverages explainability to pinpoint noisy network elements to be excluded from the GNN propagation mechanism. An empirical evaluation on diverse real-world datasets demonstrates that our method outperforms current state-of-the-art dropping approaches in accuracy, effectively reduces over-smoothing, and improves explanation quality.","sentences":["Graph Neural Networks (GNNs) have emerged as the predominant paradigm for learning from graph-structured data, offering a wide range of applications from social network analysis to bioinformatics.","Despite their versatility, GNNs face challenges such as oversmoothing, lack of generalization and poor interpretability, which hinder their wider adoption and reliability in critical applications.","Dropping has emerged as an effective paradigm for reducing noise during training and improving robustness of GNNs.","However, existing approaches often rely on random or heuristic-based selection criteria, lacking a principled method to identify and exclude nodes that contribute to noise and over-complexity in the model.","In this work, we argue that explainability should be a key indicator of a model's robustness throughout its training phase.","To this end, we introduce xAI-Drop, a novel topological-level dropping regularizer that leverages explainability to pinpoint noisy network elements to be excluded from the GNN propagation mechanism.","An empirical evaluation on diverse real-world datasets demonstrates that our method outperforms current state-of-the-art dropping approaches in accuracy, effectively reduces over-smoothing, and improves explanation quality."],"url":"http://arxiv.org/abs/2407.20067v1"}
{"created":"2024-07-29 14:46:13","title":"RelBench: A Benchmark for Deep Learning on Relational Databases","abstract":"We present RelBench, a public benchmark for solving predictive tasks over relational databases with graph neural networks. RelBench provides databases and tasks spanning diverse domains and scales, and is intended to be a foundational infrastructure for future research. We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables. End-to-end learned RDL models fully exploit the predictive signal encoded in primary-foreign key links, marking a significant shift away from the dominant paradigm of manual feature engineering combined with tabular models. To thoroughly evaluate RDL against this prior gold-standard, we conduct an in-depth user study where an experienced data scientist manually engineers features for each task. In this study, RDL learns better models whilst reducing human work needed by more than an order of magnitude. This demonstrates the power of deep learning for solving predictive tasks over relational databases, opening up many new research opportunities enabled by RelBench.","sentences":["We present RelBench, a public benchmark for solving predictive tasks over relational databases with graph neural networks.","RelBench provides databases and tasks spanning diverse domains and scales, and is intended to be a foundational infrastructure for future research.","We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables.","End-to-end learned RDL models fully exploit the predictive signal encoded in primary-foreign key links, marking a significant shift away from the dominant paradigm of manual feature engineering combined with tabular models.","To thoroughly evaluate RDL against this prior gold-standard, we conduct an in-depth user study where an experienced data scientist manually engineers features for each task.","In this study, RDL learns better models whilst reducing human work needed by more than an order of magnitude.","This demonstrates the power of deep learning for solving predictive tasks over relational databases, opening up many new research opportunities enabled by RelBench."],"url":"http://arxiv.org/abs/2407.20060v1"}
{"created":"2024-07-29 14:40:07","title":"Orca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models","abstract":"Significant wave height (SWH) is a vital metric in marine science, and accurate SWH estimation is crucial for various applications, e.g., marine energy development, fishery, early warning systems for potential risks, etc. Traditional SWH estimation methods that are based on numerical models and physical theories are hindered by computational inefficiencies. Recently, machine learning has emerged as an appealing alternative to improve accuracy and reduce computational time. However, due to limited observational technology and high costs, the scarcity of real-world data restricts the potential of machine learning models. To overcome these limitations, we propose an ocean SWH estimation framework, namely Orca. Specifically, Orca enhances the limited spatio-temporal reasoning abilities of classic LLMs with a novel spatiotemporal aware encoding module. By segmenting the limited buoy observational data temporally, encoding the buoys' locations spatially, and designing prompt templates, Orca capitalizes on the robust generalization ability of LLMs to estimate significant wave height effectively with limited data. Experimental results on the Gulf of Mexico demonstrate that Orca achieves state-of-the-art performance in SWH estimation.","sentences":["Significant wave height (SWH) is a vital metric in marine science, and accurate SWH estimation is crucial for various applications, e.g., marine energy development, fishery, early warning systems for potential risks, etc.","Traditional SWH estimation methods that are based on numerical models and physical theories are hindered by computational inefficiencies.","Recently, machine learning has emerged as an appealing alternative to improve accuracy and reduce computational time.","However, due to limited observational technology and high costs, the scarcity of real-world data restricts the potential of machine learning models.","To overcome these limitations, we propose an ocean SWH estimation framework, namely Orca.","Specifically, Orca enhances the limited spatio-temporal reasoning abilities of classic LLMs with a novel spatiotemporal aware encoding module.","By segmenting the limited buoy observational data temporally, encoding the buoys' locations spatially, and designing prompt templates, Orca capitalizes on the robust generalization ability of LLMs to estimate significant wave height effectively with limited data.","Experimental results on the Gulf of Mexico demonstrate that Orca achieves state-of-the-art performance in SWH estimation."],"url":"http://arxiv.org/abs/2407.20053v1"}
{"created":"2024-07-29 14:31:44","title":"Denoising ESG: quantifying data uncertainty from missing data with Machine Learning and prediction intervals","abstract":"Environmental, Social, and Governance (ESG) datasets are frequently plagued by significant data gaps, leading to inconsistencies in ESG ratings due to varying imputation methods. This paper explores the application of established machine learning techniques for imputing missing data in a real-world ESG dataset, emphasizing the quantification of uncertainty through prediction intervals. By employing multiple imputation strategies, this study assesses the robustness of imputation methods and quantifies the uncertainty associated with missing data. The findings highlight the importance of probabilistic machine learning models in providing better understanding of ESG scores, thereby addressing the inherent risks of wrong ratings due to incomplete data. This approach improves imputation practices to enhance the reliability of ESG ratings.","sentences":["Environmental, Social, and Governance (ESG) datasets are frequently plagued by significant data gaps, leading to inconsistencies in ESG ratings due to varying imputation methods.","This paper explores the application of established machine learning techniques for imputing missing data in a real-world ESG dataset, emphasizing the quantification of uncertainty through prediction intervals.","By employing multiple imputation strategies, this study assesses the robustness of imputation methods and quantifies the uncertainty associated with missing data.","The findings highlight the importance of probabilistic machine learning models in providing better understanding of ESG scores, thereby addressing the inherent risks of wrong ratings due to incomplete data.","This approach improves imputation practices to enhance the reliability of ESG ratings."],"url":"http://arxiv.org/abs/2407.20047v1"}
{"created":"2024-07-29 14:27:08","title":"When to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention","abstract":"Code generation aims to automatically generate code snippets that meet given natural language requirements and plays an important role in software development. Although Code LLMs have shown excellent performance in this domain, their long generation time poses a signification limitation in practice use. In this paper, we first conduct an in-depth preliminary study with different Code LLMs on code generation tasks and identify a significant efficiency issue, i.e., continual generation of excess tokens. It harms the developer productivity and leads to huge computational wastes. To address it, we introduce CodeFast, an inference acceleration approach for Code LLMs on code generation. The key idea of CodeFast is to terminate the inference process in time when unnecessary excess tokens are detected. First, we propose an automatic data construction framework to obtain training data. Then, we train a unified lightweight model GenGuard applicable to multiple programming languages to predict whether to terminate inference at the current step. Finally, we enhance Code LLM with GenGuard to accelerate its inference in code generation tasks. We conduct extensive experiments with CodeFast on five representative Code LLMs across four widely used code generation datasets. Experimental results show that (1) CodeFast can significantly improve the inference speed of various Code LLMs in code generation, ranging form 34% to 452%, without compromising the quality of generated code. (2) CodeFast is stable across different parameter settings and can generalize to untrained datasets. Our code and data are available at https://github.com/DeepSoftwareAnalytics/CodeFast","sentences":["Code generation aims to automatically generate code snippets that meet given natural language requirements and plays an important role in software development.","Although Code LLMs have shown excellent performance in this domain, their long generation time poses a signification limitation in practice use.","In this paper, we first conduct an in-depth preliminary study with different Code LLMs on code generation tasks and identify a significant efficiency issue, i.e., continual generation of excess tokens.","It harms the developer productivity and leads to huge computational wastes.","To address it, we introduce CodeFast, an inference acceleration approach for Code LLMs on code generation.","The key idea of CodeFast is to terminate the inference process in time when unnecessary excess tokens are detected.","First, we propose an automatic data construction framework to obtain training data.","Then, we train a unified lightweight model GenGuard applicable to multiple programming languages to predict whether to terminate inference at the current step.","Finally, we enhance Code LLM with GenGuard to accelerate its inference in code generation tasks.","We conduct extensive experiments with CodeFast on five representative Code LLMs across four widely used code generation datasets.","Experimental results show that (1) CodeFast can significantly improve the inference speed of various Code LLMs in code generation, ranging form 34% to 452%, without compromising the quality of generated code.","(2) CodeFast is stable across different parameter settings and can generalize to untrained datasets.","Our code and data are available at https://github.com/DeepSoftwareAnalytics/CodeFast"],"url":"http://arxiv.org/abs/2407.20042v1"}
{"created":"2024-07-29 14:22:55","title":"Planning For Edge Failure in Fixed-Charge Flow Networks","abstract":"The Fixed-Charge Network Flow problem is a well-studied NP-hard problem that has the goal of finding a flow in a network where fixed edge costs are incurred, regardless of the amount of flow hosted by the edge. In this paper, we consider scenarios where a designated edge in the network has the potential to fail after edges have already been purchased. If the edge does fail, procurement of additional edges may be required to repair the flow and compensate for the failed edge so as to maintain the original flow amount. We formulate a multi-objective optimization problem that aims to minimize the costs of both the initial flow as well as the repaired flow. We introduce an algorithm that finds the Pareto front between these two objectives, thereby providing decision makers with a sequence of solutions that trade off initial flow cost with repaired flow cost. We demonstrate the algorithm's efficacy with an evaluation using real-world CO2 capture and storage infrastructure data.","sentences":["The Fixed-Charge Network Flow problem is a well-studied NP-hard problem that has the goal of finding a flow in a network where fixed edge costs are incurred, regardless of the amount of flow hosted by the edge.","In this paper, we consider scenarios where a designated edge in the network has the potential to fail after edges have already been purchased.","If the edge does fail, procurement of additional edges may be required to repair the flow and compensate for the failed edge so as to maintain the original flow amount.","We formulate a multi-objective optimization problem that aims to minimize the costs of both the initial flow as well as the repaired flow.","We introduce an algorithm that finds the Pareto front between these two objectives, thereby providing decision makers with a sequence of solutions that trade off initial flow cost with repaired flow cost.","We demonstrate the algorithm's efficacy with an evaluation using real-world CO2 capture and storage infrastructure data."],"url":"http://arxiv.org/abs/2407.20036v1"}
{"created":"2024-07-29 14:04:46","title":"Aircraft Trajectory Segmentation-based Contrastive Coding: A Framework for Self-supervised Trajectory Representation","abstract":"Air traffic trajectory recognition has gained significant interest within the air traffic management community, particularly for fundamental tasks such as classification and clustering. This paper introduces Aircraft Trajectory Segmentation-based Contrastive Coding (ATSCC), a novel self-supervised time series representation learning framework designed to capture semantic information in air traffic trajectory data. The framework leverages the segmentable characteristic of trajectories and ensures consistency within the self-assigned segments. Intensive experiments were conducted on datasets from three different airports, totaling four datasets, comparing the learned representation's performance of downstream classification and clustering with other state-of-the-art representation learning techniques. The results show that ATSCC outperforms these methods by aligning with the labels defined by aeronautical procedures. ATSCC is adaptable to various airport configurations and scalable to incomplete trajectories. This research has expanded upon existing capabilities, achieving these improvements independently without predefined inputs such as airport configurations, maneuvering procedures, or labeled data.","sentences":["Air traffic trajectory recognition has gained significant interest within the air traffic management community, particularly for fundamental tasks such as classification and clustering.","This paper introduces Aircraft Trajectory Segmentation-based Contrastive Coding (ATSCC), a novel self-supervised time series representation learning framework designed to capture semantic information in air traffic trajectory data.","The framework leverages the segmentable characteristic of trajectories and ensures consistency within the self-assigned segments.","Intensive experiments were conducted on datasets from three different airports, totaling four datasets, comparing the learned representation's performance of downstream classification and clustering with other state-of-the-art representation learning techniques.","The results show that ATSCC outperforms these methods by aligning with the labels defined by aeronautical procedures.","ATSCC is adaptable to various airport configurations and scalable to incomplete trajectories.","This research has expanded upon existing capabilities, achieving these improvements independently without predefined inputs such as airport configurations, maneuvering procedures, or labeled data."],"url":"http://arxiv.org/abs/2407.20028v1"}
{"created":"2024-07-29 14:01:26","title":"Fairness Through Controlled (Un)Awareness in Node Embeddings","abstract":"Graph representation learning is central for the application of machine learning (ML) models to complex graphs, such as social networks. Ensuring `fair' representations is essential, due to the societal implications and the use of sensitive personal data. In this paper, we demonstrate how the parametrization of the \\emph{CrossWalk} algorithm influences the ability to infer a sensitive attributes from node embeddings. By fine-tuning hyperparameters, we show that it is possible to either significantly enhance or obscure the detectability of these attributes. This functionality offers a valuable tool for improving the fairness of ML systems utilizing graph embeddings, making them adaptable to different fairness paradigms.","sentences":["Graph representation learning is central for the application of machine learning (ML) models to complex graphs, such as social networks.","Ensuring `fair' representations is essential, due to the societal implications and the use of sensitive personal data.","In this paper, we demonstrate how the parametrization of the \\emph{CrossWalk} algorithm influences the ability to infer a sensitive attributes from node embeddings.","By fine-tuning hyperparameters, we show that it is possible to either significantly enhance or obscure the detectability of these attributes.","This functionality offers a valuable tool for improving the fairness of ML systems utilizing graph embeddings, making them adaptable to different fairness paradigms."],"url":"http://arxiv.org/abs/2407.20024v1"}
{"created":"2024-07-29 13:57:40","title":"MimiQ: Low-Bit Data-Free Quantization of Vision Transformers","abstract":"Data-free quantization (DFQ) is a technique that creates a lightweight network from its full-precision counterpart without the original training data, often through a synthetic dataset. Although several DFQ methods have been proposed for vision transformer (ViT) architectures, they fail to achieve efficacy in low-bit settings. Examining the existing methods, we identify that their synthetic data produce misaligned attention maps, while those of the real samples are highly aligned. From the observation of aligned attention, we find that aligning attention maps of synthetic data helps to improve the overall performance of quantized ViTs. Motivated by this finding, we devise \\aname, a novel DFQ method designed for ViTs that focuses on inter-head attention similarity. First, we generate synthetic data by aligning head-wise attention responses in relation to spatial query patches. Then, we apply head-wise structural attention distillation to align the attention maps of the quantized network to those of the full-precision teacher. The experimental results show that the proposed method significantly outperforms baselines, setting a new state-of-the-art performance for data-free ViT quantization.","sentences":["Data-free quantization (DFQ) is a technique that creates a lightweight network from its full-precision counterpart without the original training data, often through a synthetic dataset.","Although several DFQ methods have been proposed for vision transformer (ViT) architectures, they fail to achieve efficacy in low-bit settings.","Examining the existing methods, we identify that their synthetic data produce misaligned attention maps, while those of the real samples are highly aligned.","From the observation of aligned attention, we find that aligning attention maps of synthetic data helps to improve the overall performance of quantized ViTs.","Motivated by this finding, we devise \\aname, a novel DFQ method designed for ViTs that focuses on inter-head attention similarity.","First, we generate synthetic data by aligning head-wise attention responses in relation to spatial query patches.","Then, we apply head-wise structural attention distillation to align the attention maps of the quantized network to those of the full-precision teacher.","The experimental results show that the proposed method significantly outperforms baselines, setting a new state-of-the-art performance for data-free ViT quantization."],"url":"http://arxiv.org/abs/2407.20021v1"}
{"created":"2024-07-29 13:57:24","title":"ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning","abstract":"Generative models, such as diffusion models (DMs), variational autoencoders (VAEs), and generative adversarial networks (GANs), produce images with a level of authenticity that makes them nearly indistinguishable from real photos and artwork. While this capability is beneficial for many industries, the difficulty of identifying synthetic images leaves online media platforms vulnerable to impersonation and misinformation attempts. To support the development of defensive methods, we introduce ImagiNet, a high-resolution and balanced dataset for synthetic image detection, designed to mitigate potential biases in existing resources. It contains 200K examples, spanning four content categories: photos, paintings, faces, and uncategorized. Synthetic images are produced with open-source and proprietary generators, whereas real counterparts of the same content type are collected from public datasets. The structure of ImagiNet allows for a two-track evaluation system: i) classification as real or synthetic and ii) identification of the generative model. To establish a baseline, we train a ResNet-50 model using a self-supervised contrastive objective (SelfCon) for each track. The model demonstrates state-of-the-art performance and high inference speed across established benchmarks, achieving an AUC of up to 0.99 and balanced accuracy ranging from 86% to 95%, even under social network conditions that involve compression and resizing. Our data and code are available at https://github.com/delyan-boychev/imaginet.","sentences":["Generative models, such as diffusion models (DMs), variational autoencoders (VAEs), and generative adversarial networks (GANs), produce images with a level of authenticity that makes them nearly indistinguishable from real photos and artwork.","While this capability is beneficial for many industries, the difficulty of identifying synthetic images leaves online media platforms vulnerable to impersonation and misinformation attempts.","To support the development of defensive methods, we introduce ImagiNet, a high-resolution and balanced dataset for synthetic image detection, designed to mitigate potential biases in existing resources.","It contains 200K examples, spanning four content categories: photos, paintings, faces, and uncategorized.","Synthetic images are produced with open-source and proprietary generators, whereas real counterparts of the same content type are collected from public datasets.","The structure of ImagiNet allows for a two-track evaluation system: i) classification as real or synthetic and ii) identification of the generative model.","To establish a baseline, we train a ResNet-50 model using a self-supervised contrastive objective (SelfCon) for each track.","The model demonstrates state-of-the-art performance and high inference speed across established benchmarks, achieving an AUC of up to 0.99 and balanced accuracy ranging from 86% to 95%, even under social network conditions that involve compression and resizing.","Our data and code are available at https://github.com/delyan-boychev/imaginet."],"url":"http://arxiv.org/abs/2407.20020v1"}
{"created":"2024-07-29 13:41:34","title":"Rosetta Statements: Lowering the Barrier for Semantic Parsing and Increasing the Cognitive Interoperability of Knowledge Graphs","abstract":"Machines need data and metadata to be machine-actionable and FAIR (findable, accessible, interoperable, reusable) to manage increasing data volumes. Knowledge graphs and ontologies are key to this, but their use is hampered by high access barriers due to required prior knowledge in semantics and data modelling. The Rosetta Statement approach proposes modeling English natural language statements instead of a mind-independent reality. We propose a metamodel for creating semantic schema patterns for simple statement types. The approach supports versioning of statements and provides a detailed editing history. Each Rosetta Statement pattern has a dynamic label for displaying statements as natural language sentences. Implemented in the Open Research Knowledge Graph (ORKG) as a use case, this approach allows domain experts to define data schema patterns without needing semantic knowledge. Future plans include combining Rosetta Statements with semantic units to organize ORKG into meaningful subgraphs, improving usability. A search interface for querying statements without needing SPARQL or Cypher knowledge is also planned, along with tools for data entry and display using Large Language Models and NLP. The Rosetta Statement metamodel supports a two-step knowledge graph construction procedure. Domain experts can model semantic content without support from ontology engineers, lowering entry barriers and increasing cognitive interoperability. The second level involves developing semantic graph patterns for reasoning, requiring collaboration with ontology engineers.","sentences":["Machines need data and metadata to be machine-actionable and FAIR (findable, accessible, interoperable, reusable) to manage increasing data volumes.","Knowledge graphs and ontologies are key to this, but their use is hampered by high access barriers due to required prior knowledge in semantics and data modelling.","The Rosetta Statement approach proposes modeling English natural language statements instead of a mind-independent reality.","We propose a metamodel for creating semantic schema patterns for simple statement types.","The approach supports versioning of statements and provides a detailed editing history.","Each Rosetta Statement pattern has a dynamic label for displaying statements as natural language sentences.","Implemented in the Open Research Knowledge Graph (ORKG) as a use case, this approach allows domain experts to define data schema patterns without needing semantic knowledge.","Future plans include combining Rosetta Statements with semantic units to organize ORKG into meaningful subgraphs, improving usability.","A search interface for querying statements without needing SPARQL or Cypher knowledge is also planned, along with tools for data entry and display using Large Language Models and NLP.","The Rosetta Statement metamodel supports a two-step knowledge graph construction procedure.","Domain experts can model semantic content without support from ontology engineers, lowering entry barriers and increasing cognitive interoperability.","The second level involves developing semantic graph patterns for reasoning, requiring collaboration with ontology engineers."],"url":"http://arxiv.org/abs/2407.20007v1"}
{"created":"2024-07-29 13:35:52","title":"Navigation services amplify concentration of traffic and emissions in our cities","abstract":"The proliferation of human-AI ecosystems involving human interaction with algorithms, such as assistants and recommenders, raises concerns about large-scale social behaviour. Despite evidence of such phenomena across several contexts, the collective impact of GPS navigation services remains unclear: while beneficial to the user, they can also cause chaos if too many vehicles are driven through the same few roads. Our study employs a simulation framework to assess navigation services' influence on road network usage and CO2 emissions. The results demonstrate a universal pattern of amplified conformity: increasing adoption rates of navigation services cause a reduction of route diversity of mobile travellers and increased concentration of traffic and emissions on fewer roads, thus exacerbating an unequal distribution of negative externalities on selected neighbourhoods. Although navigation services recommendations can help reduce CO2 emissions when their adoption rate is low, these benefits diminish or even disappear when the adoption rate is high and exceeds a certain city- and service-dependent threshold. We summarize these discoveries in a non-linear function that connects the marginal increase of conformity with the marginal reduction in CO2 emissions. Our simulation approach addresses the challenges posed by the complexity of transportation systems and the lack of data and algorithmic transparency.","sentences":["The proliferation of human-AI ecosystems involving human interaction with algorithms, such as assistants and recommenders, raises concerns about large-scale social behaviour.","Despite evidence of such phenomena across several contexts, the collective impact of GPS navigation services remains unclear: while beneficial to the user, they can also cause chaos if too many vehicles are driven through the same few roads.","Our study employs a simulation framework to assess navigation services' influence on road network usage and CO2 emissions.","The results demonstrate a universal pattern of amplified conformity: increasing adoption rates of navigation services cause a reduction of route diversity of mobile travellers and increased concentration of traffic and emissions on fewer roads, thus exacerbating an unequal distribution of negative externalities on selected neighbourhoods.","Although navigation services recommendations can help reduce CO2 emissions when their adoption rate is low, these benefits diminish or even disappear when the adoption rate is high and exceeds a certain city- and service-dependent threshold.","We summarize these discoveries in a non-linear function that connects the marginal increase of conformity with the marginal reduction in CO2 emissions.","Our simulation approach addresses the challenges posed by the complexity of transportation systems and the lack of data and algorithmic transparency."],"url":"http://arxiv.org/abs/2407.20004v1"}
{"created":"2024-07-29 13:34:34","title":"On the Effects of Irrelevant Variables in Treatment Effect Estimation with Deep Disentanglement","abstract":"Estimating treatment effects from observational data is paramount in healthcare, education, and economics, but current deep disentanglement-based methods to address selection bias are insufficiently handling irrelevant variables. We demonstrate in experiments that this leads to prediction errors. We disentangle pre-treatment variables with a deep embedding method and explicitly identify and represent irrelevant variables, additionally to instrumental, confounding and adjustment latent factors. To this end, we introduce a reconstruction objective and create an embedding space for irrelevant variables using an attached autoencoder. Instead of relying on serendipitous suppression of irrelevant variables as in previous deep disentanglement approaches, we explicitly force irrelevant variables into this embedding space and employ orthogonalization to prevent irrelevant information from leaking into the latent space representations of the other factors. Our experiments with synthetic and real-world benchmark datasets show that we can better identify irrelevant variables and more precisely predict treatment effects than previous methods, while prediction quality degrades less when additional irrelevant variables are introduced.","sentences":["Estimating treatment effects from observational data is paramount in healthcare, education, and economics, but current deep disentanglement-based methods to address selection bias are insufficiently handling irrelevant variables.","We demonstrate in experiments that this leads to prediction errors.","We disentangle pre-treatment variables with a deep embedding method and explicitly identify and represent irrelevant variables, additionally to instrumental, confounding and adjustment latent factors.","To this end, we introduce a reconstruction objective and create an embedding space for irrelevant variables using an attached autoencoder.","Instead of relying on serendipitous suppression of irrelevant variables as in previous deep disentanglement approaches, we explicitly force irrelevant variables into this embedding space and employ orthogonalization to prevent irrelevant information from leaking into the latent space representations of the other factors.","Our experiments with synthetic and real-world benchmark datasets show that we can better identify irrelevant variables and more precisely predict treatment effects than previous methods, while prediction quality degrades less when additional irrelevant variables are introduced."],"url":"http://arxiv.org/abs/2407.20003v1"}
{"created":"2024-07-29 13:29:43","title":"Do LLMs Really Adapt to Domains? An Ontology Learning Perspective","abstract":"Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains. Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL). However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone. This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage. This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning? To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms. We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame. However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL.","sentences":["Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains.","Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL).","However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone.","This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage.","This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning?","To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms.","We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery.","Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame.","However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL."],"url":"http://arxiv.org/abs/2407.19998v1"}
{"created":"2024-07-29 13:26:43","title":"A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph","abstract":"This study aims to improve knowledge-based question-answering (QA) systems by overcoming the limitations of existing Retrieval-Augmented Generation (RAG) models and implementing an advanced RAG system based on Graph technology to develop high-quality generative AI services. While existing RAG models demonstrate high accuracy and fluency by utilizing retrieved information, they may suffer from accuracy degradation as they generate responses using pre-loaded knowledge without reprocessing. Additionally, they cannot incorporate real-time data after the RAG configuration stage, leading to issues with contextual understanding and biased information. To address these limitations, this study implemented an enhanced RAG system utilizing Graph technology. This system is designed to efficiently search and utilize information. Specifically, it employs LangGraph to evaluate the reliability of retrieved information and synthesizes diverse data to generate more accurate and enhanced responses. Furthermore, the study provides a detailed explanation of the system's operation, key implementation steps, and examples through implementation code and validation results, thereby enhancing the understanding of advanced RAG technology. This approach offers practical guidelines for implementing advanced RAG systems in corporate services, making it a valuable resource for practical application.","sentences":["This study aims to improve knowledge-based question-answering (QA) systems by overcoming the limitations of existing Retrieval-Augmented Generation (RAG) models and implementing an advanced RAG system based on Graph technology to develop high-quality generative AI services.","While existing RAG models demonstrate high accuracy and fluency by utilizing retrieved information, they may suffer from accuracy degradation as they generate responses using pre-loaded knowledge without reprocessing.","Additionally, they cannot incorporate real-time data after the RAG configuration stage, leading to issues with contextual understanding and biased information.","To address these limitations, this study implemented an enhanced RAG system utilizing Graph technology.","This system is designed to efficiently search and utilize information.","Specifically, it employs LangGraph to evaluate the reliability of retrieved information and synthesizes diverse data to generate more accurate and enhanced responses.","Furthermore, the study provides a detailed explanation of the system's operation, key implementation steps, and examples through implementation code and validation results, thereby enhancing the understanding of advanced RAG technology.","This approach offers practical guidelines for implementing advanced RAG systems in corporate services, making it a valuable resource for practical application."],"url":"http://arxiv.org/abs/2407.19994v1"}
{"created":"2024-07-29 13:24:55","title":"More precise edge detections","abstract":"Image Edge detection (ED) is a base task in computer vision. While the performance of the ED algorithm has been improved greatly by introducing CNN-based models, current models still suffer from unsatisfactory precision rates especially when only a low error toleration distance is allowed. Therefore, model architecture for more precise predictions still needs an investigation. On the other hand, the unavoidable noise training data provided by humans would lead to unsatisfactory model predictions even when inputs are edge maps themselves, which also needs improvement. In this paper, more precise ED models are presented with cascaded skipping density blocks (CSDB). Our models obtain state-of-the-art(SOTA) predictions in several datasets, especially in average precision rate (AP), which is confirmed by extensive experiments. Moreover, our models do not include down-sample operations, demonstrating those widely believed operations are not necessary. Also, a novel modification on data augmentation for training is employed, which allows noiseless data to be employed in model training and thus improves the performance of models predicting on edge maps themselves.","sentences":["Image Edge detection (ED) is a base task in computer vision.","While the performance of the ED algorithm has been improved greatly by introducing CNN-based models, current models still suffer from unsatisfactory precision rates especially when only a low error toleration distance is allowed.","Therefore, model architecture for more precise predictions still needs an investigation.","On the other hand, the unavoidable noise training data provided by humans would lead to unsatisfactory model predictions even when inputs are edge maps themselves, which also needs improvement.","In this paper, more precise ED models are presented with cascaded skipping density blocks (CSDB).","Our models obtain state-of-the-art(SOTA) predictions in several datasets, especially in average precision rate (AP), which is confirmed by extensive experiments.","Moreover, our models do not include down-sample operations, demonstrating those widely believed operations are not necessary.","Also, a novel modification on data augmentation for training is employed, which allows noiseless data to be employed in model training and thus improves the performance of models predicting on edge maps themselves."],"url":"http://arxiv.org/abs/2407.19992v1"}
{"created":"2024-07-29 13:22:49","title":"Classification of Alzheimer's Dementia vs. Healthy subjects by studying structural disparities in fMRI Time-Series of DMN","abstract":"Time series from different regions of interest (ROI) of default mode network (DMN) from Functional Magnetic Resonance Imaging (fMRI) can reveal significant differences between healthy and unhealthy people. Here, we propose the utility of an existing metric quantifying the lack/presence of structure in a signal called, \"deviation from stochasticity\" (DS) measure to characterize resting-state fMRI time series. The hypothesis is that differences in the level of structure in the time series can lead to discrimination between the subject groups. In this work, an autoencoder-based model is utilized to learn efficient representations of data by training the network to reconstruct its input data. The proposed methodology is applied on fMRI time series of 50 healthy individuals and 50 subjects with Alzheimer's Disease (AD), obtained from publicly available ADNI database. DS measure for healthy fMRI as expected turns out to be different compared to that of AD. Peak classification accuracy of 95% was obtained using Gradient Boosting classifier, using the DS measure applied on 100 subjects.","sentences":["Time series from different regions of interest (ROI) of default mode network (DMN) from Functional Magnetic Resonance Imaging (fMRI) can reveal significant differences between healthy and unhealthy people.","Here, we propose the utility of an existing metric quantifying the lack/presence of structure in a signal called, \"deviation from stochasticity\" (DS) measure to characterize resting-state fMRI time series.","The hypothesis is that differences in the level of structure in the time series can lead to discrimination between the subject groups.","In this work, an autoencoder-based model is utilized to learn efficient representations of data by training the network to reconstruct its input data.","The proposed methodology is applied on fMRI time series of 50 healthy individuals and 50 subjects with Alzheimer's Disease (AD), obtained from publicly available ADNI database.","DS measure for healthy fMRI as expected turns out to be different compared to that of AD.","Peak classification accuracy of 95% was obtained using Gradient Boosting classifier, using the DS measure applied on 100 subjects."],"url":"http://arxiv.org/abs/2407.19990v1"}
{"created":"2024-07-29 13:19:31","title":"Mixture of Nested Experts: Adaptive Processing of Visual Tokens","abstract":"The visual medium (images and videos) naturally contains a large amount of information redundancy, thereby providing a great opportunity for leveraging efficiency in processing. While Vision Transformer (ViT) based models scale effectively to large data regimes, they fail to capitalize on this inherent redundancy, leading to higher computational costs. Mixture of Experts (MoE) networks demonstrate scalability while maintaining same inference-time costs, but they come with a larger parameter footprint. We present Mixture of Nested Experts (MoNE), which utilizes a nested structure for experts, wherein individual experts fall on an increasing compute-accuracy curve. Given a compute budget, MoNE learns to dynamically choose tokens in a priority order, and thus redundant tokens are processed through cheaper nested experts. Using this framework, we achieve equivalent performance as the baseline models, while reducing inference time compute by over two-fold. We validate our approach on standard image and video datasets - ImageNet-21K, Kinetics400, and Something-Something-v2. We further highlight MoNE$'$s adaptability by showcasing its ability to maintain strong performance across different inference-time compute budgets on videos, using only a single trained model.","sentences":["The visual medium (images and videos) naturally contains a large amount of information redundancy, thereby providing a great opportunity for leveraging efficiency in processing.","While Vision Transformer (ViT) based models scale effectively to large data regimes, they fail to capitalize on this inherent redundancy, leading to higher computational costs.","Mixture of Experts (MoE) networks demonstrate scalability while maintaining same inference-time costs, but they come with a larger parameter footprint.","We present Mixture of Nested Experts (MoNE), which utilizes a nested structure for experts, wherein individual experts fall on an increasing compute-accuracy curve.","Given a compute budget, MoNE learns to dynamically choose tokens in a priority order, and thus redundant tokens are processed through cheaper nested experts.","Using this framework, we achieve equivalent performance as the baseline models, while reducing inference time compute by over two-fold.","We validate our approach on standard image and video datasets - ImageNet-21K, Kinetics400, and Something-Something-v2.","We further highlight MoNE$'$s adaptability by showcasing its ability to maintain strong performance across different inference-time compute budgets on videos, using only a single trained model."],"url":"http://arxiv.org/abs/2407.19985v1"}
{"created":"2024-07-29 13:11:53","title":"Private and Secure Fuzzy Name Matching","abstract":"Modern financial institutions rely on data for many operations, including a need to drive efficiency, enhance services and prevent financial crime. Data sharing across an organisation or between institutions can facilitate rapid, evidence-based decision making, including identifying money laundering and fraud. However, data privacy regulations impose restrictions on data sharing. Privacy-enhancing technologies are being increasingly employed to allow organisations to derive shared intelligence while ensuring regulatory compliance. This paper examines the case in which regulatory restrictions mean a party cannot share data on accounts of interest with another (internal or external) party to identify people that hold an account in each dataset. We observe that the names of account holders may be recorded differently in each data set. We introduce a novel privacy-preserving approach for fuzzy name matching across institutions, employing fully homomorphic encryption with locality-sensitive hashing. The efficiency of the approach is enhanced using a clustering mechanism. The practicality and effectiveness of the proposed approach are evaluated using different datasets. Experimental results demonstrate it takes around 100 and 1000 seconds to search 1000 names from 10k and 100k names, respectively. Moreover, the proposed approach exhibits significant improvement in reducing communication overhead by 30-300 times, using clustering.","sentences":["Modern financial institutions rely on data for many operations, including a need to drive efficiency, enhance services and prevent financial crime.","Data sharing across an organisation or between institutions can facilitate rapid, evidence-based decision making, including identifying money laundering and fraud.","However, data privacy regulations impose restrictions on data sharing.","Privacy-enhancing technologies are being increasingly employed to allow organisations to derive shared intelligence while ensuring regulatory compliance.","This paper examines the case in which regulatory restrictions mean a party cannot share data on accounts of interest with another (internal or external) party to identify people that hold an account in each dataset.","We observe that the names of account holders may be recorded differently in each data set.","We introduce a novel privacy-preserving approach for fuzzy name matching across institutions, employing fully homomorphic encryption with locality-sensitive hashing.","The efficiency of the approach is enhanced using a clustering mechanism.","The practicality and effectiveness of the proposed approach are evaluated using different datasets.","Experimental results demonstrate it takes around 100 and 1000 seconds to search 1000 names from 10k and 100k names, respectively.","Moreover, the proposed approach exhibits significant improvement in reducing communication overhead by 30-300 times, using clustering."],"url":"http://arxiv.org/abs/2407.19979v1"}
{"created":"2024-07-29 13:09:26","title":"MambaGesture: Enhancing Co-Speech Gesture Generation with Mamba and Disentangled Multi-Modality Fusion","abstract":"Co-speech gesture generation is crucial for producing synchronized and realistic human gestures that accompany speech, enhancing the animation of lifelike avatars in virtual environments. While diffusion models have shown impressive capabilities, current approaches often overlook a wide range of modalities and their interactions, resulting in less dynamic and contextually varied gestures. To address these challenges, we present MambaGesture, a novel framework integrating a Mamba-based attention block, MambaAttn, with a multi-modality feature fusion module, SEAD. The MambaAttn block combines the sequential data processing strengths of the Mamba model with the contextual richness of attention mechanisms, enhancing the temporal coherence of generated gestures. SEAD adeptly fuses audio, text, style, and emotion modalities, employing disentanglement to deepen the fusion process and yield gestures with greater realism and diversity. Our approach, rigorously evaluated on the multi-modal BEAT dataset, demonstrates significant improvements in Fr\\'echet Gesture Distance (FGD), diversity scores, and beat alignment, achieving state-of-the-art performance in co-speech gesture generation.","sentences":["Co-speech gesture generation is crucial for producing synchronized and realistic human gestures that accompany speech, enhancing the animation of lifelike avatars in virtual environments.","While diffusion models have shown impressive capabilities, current approaches often overlook a wide range of modalities and their interactions, resulting in less dynamic and contextually varied gestures.","To address these challenges, we present MambaGesture, a novel framework integrating a Mamba-based attention block, MambaAttn, with a multi-modality feature fusion module, SEAD.","The MambaAttn block combines the sequential data processing strengths of the Mamba model with the contextual richness of attention mechanisms, enhancing the temporal coherence of generated gestures.","SEAD adeptly fuses audio, text, style, and emotion modalities, employing disentanglement to deepen the fusion process and yield gestures with greater realism and diversity.","Our approach, rigorously evaluated on the multi-modal BEAT dataset, demonstrates significant improvements in Fr\\'echet Gesture Distance (FGD), diversity scores, and beat alignment, achieving state-of-the-art performance in co-speech gesture generation."],"url":"http://arxiv.org/abs/2407.19976v1"}
{"created":"2024-07-29 13:09:02","title":"Integrated Scenario-based Analysis: A data-driven approach to support automated driving systems development and safety evaluation","abstract":"Several scenario-based frameworks exist to aid in vehicle system development and safety assurance. However, there is a need for approaches that combine different types of datasets that offer varying levels of case severity, data richness, and representativeness. This study presents an integrated scenario-based analysis approach that encompasses scenario definition, fusion, parametrization, and test case generation. For this process, ten years of fatal and non-fatal national crash data from the United States are combined with over 34 million miles of naturalistic driving data. An illustrative example scenario, \"turns at intersection\", is chosen to demonstrate this approach. First, scenario definitions are established from both record-based and continuous time series data. Second, a frequency analysis is performed to understand how often events from the same scenario occur at different severities across datasets. Third, an analysis is performed to show the key factors relevant to the scenario and the distribution of various parameters. Finally, a method to combine both types of data into representative test case scenarios is presented. These techniques improve scenario representativeness in two major ways: first, they populate an entire spectrum of cases ranging from routine events to fatal crashes; and second, they provide context-rich, multi-year data by combining large-scale national and naturalistic datasets.","sentences":["Several scenario-based frameworks exist to aid in vehicle system development and safety assurance.","However, there is a need for approaches that combine different types of datasets that offer varying levels of case severity, data richness, and representativeness.","This study presents an integrated scenario-based analysis approach that encompasses scenario definition, fusion, parametrization, and test case generation.","For this process, ten years of fatal and non-fatal national crash data from the United States are combined with over 34 million miles of naturalistic driving data.","An illustrative example scenario, \"turns at intersection\", is chosen to demonstrate this approach.","First, scenario definitions are established from both record-based and continuous time series data.","Second, a frequency analysis is performed to understand how often events from the same scenario occur at different severities across datasets.","Third, an analysis is performed to show the key factors relevant to the scenario and the distribution of various parameters.","Finally, a method to combine both types of data into representative test case scenarios is presented.","These techniques improve scenario representativeness in two major ways: first, they populate an entire spectrum of cases ranging from routine events to fatal crashes; and second, they provide context-rich, multi-year data by combining large-scale national and naturalistic datasets."],"url":"http://arxiv.org/abs/2407.19975v1"}
{"created":"2024-07-29 13:01:20","title":"From Flat to Spatial: Comparison of 4 methods constructing 3D, 2 and 1/2D Models from 2D Plans with neural networks","abstract":"In the field of architecture, the conversion of single images into 2 and 1/2D and 3D meshes is a promising technology that enhances design visualization and efficiency. This paper evaluates four innovative methods: \"One-2-3-45,\" \"CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model,\" \"Instant Mesh,\" and \"Image-to-Mesh.\" These methods are at the forefront of this technology, focusing on their applicability in architectural design and visualization. They streamline the creation of 3D architectural models, enabling rapid prototyping and detailed visualization from minimal initial inputs, such as photographs or simple sketches.One-2-3-45 leverages a diffusion-based approach to generate multi-view reconstructions, ensuring high geometric fidelity and texture quality. CRM utilizes a convolutional network to integrate geometric priors into its architecture, producing detailed and textured meshes quickly and efficiently. Instant Mesh combines the strengths of multi-view diffusion and sparse-view models to offer speed and scalability, suitable for diverse architectural projects. Image-to-Mesh leverages a generative adversarial network (GAN) to produce 3D meshes from single images, focusing on maintaining high texture fidelity and geometric accuracy by incorporating image and depth map data into its training process. It uses a hybrid approach that combines voxel-based representations with surface reconstruction techniques to ensure detailed and realistic 3D models.This comparative study highlights each method's contribution to reducing design cycle times, improving accuracy, and enabling flexible adaptations to various architectural styles and requirements. By providing architects with powerful tools for rapid visualization and iteration, these advancements in 3D mesh generation are set to revolutionize architectural practices.","sentences":["In the field of architecture, the conversion of single images into 2 and 1/2D and 3D meshes is a promising technology that enhances design visualization and efficiency.","This paper evaluates four innovative methods: \"One-2-3-45,\" \"CRM: Single Image to 3D Textured Mesh with Convolutional Reconstruction Model,\" \"Instant Mesh,\" and \"Image-to-Mesh.\"","These methods are at the forefront of this technology, focusing on their applicability in architectural design and visualization.","They streamline the creation of 3D architectural models, enabling rapid prototyping and detailed visualization from minimal initial inputs, such as photographs or simple sketches.","One-2-3-45 leverages a diffusion-based approach to generate multi-view reconstructions, ensuring high geometric fidelity and texture quality.","CRM utilizes a convolutional network to integrate geometric priors into its architecture, producing detailed and textured meshes quickly and efficiently.","Instant Mesh combines the strengths of multi-view diffusion and sparse-view models to offer speed and scalability, suitable for diverse architectural projects.","Image-to-Mesh leverages a generative adversarial network (GAN) to produce 3D meshes from single images, focusing on maintaining high texture fidelity and geometric accuracy by incorporating image and depth map data into its training process.","It uses a hybrid approach that combines voxel-based representations with surface reconstruction techniques to ensure detailed and realistic 3D models.","This comparative study highlights each method's contribution to reducing design cycle times, improving accuracy, and enabling flexible adaptations to various architectural styles and requirements.","By providing architects with powerful tools for rapid visualization and iteration, these advancements in 3D mesh generation are set to revolutionize architectural practices."],"url":"http://arxiv.org/abs/2407.19970v1"}
{"created":"2024-07-29 13:00:36","title":"A Temporal Psycholinguistics Approach to Identity Resolution of Social Media Users","abstract":"In this thesis, we propose an approach to identity resolution across social media platforms using the topics, sentiments, and timings of the posts on the platforms. After collecting the public posts of around 5000 profiles from Disqus and Twitter, we analyze their posts to match their profiles across the two platforms. We pursue both temporal and non-temporal methods in our analysis. While neither approach proves definitively superior, the temporal approach generally performs better. We found that the temporal window size influences results more than the shifting amount. On the other hand, our sentiment analysis shows that the inclusion of sentiment makes little difference, probably due to flawed data extraction methods. We also experimented with a distance-based reward-and-punishment-focused scoring model, which achieved an accuracy of 24.198% and an average rank of 158.217 out of 2525 in our collected corpus. Future work includes refining sentiment analysis by evaluating sentiments per topic, extending temporal analysis with additional phases, and improving the scoring model through weight adjustments and modified rewards.","sentences":["In this thesis, we propose an approach to identity resolution across social media platforms using the topics, sentiments, and timings of the posts on the platforms.","After collecting the public posts of around 5000 profiles from Disqus and Twitter, we analyze their posts to match their profiles across the two platforms.","We pursue both temporal and non-temporal methods in our analysis.","While neither approach proves definitively superior, the temporal approach generally performs better.","We found that the temporal window size influences results more than the shifting amount.","On the other hand, our sentiment analysis shows that the inclusion of sentiment makes little difference, probably due to flawed data extraction methods.","We also experimented with a distance-based reward-and-punishment-focused scoring model, which achieved an accuracy of 24.198% and an average rank of 158.217 out of 2525 in our collected corpus.","Future work includes refining sentiment analysis by evaluating sentiments per topic, extending temporal analysis with additional phases, and improving the scoring model through weight adjustments and modified rewards."],"url":"http://arxiv.org/abs/2407.19967v1"}
{"created":"2024-07-29 12:52:27","title":"Prichain II: CloudGuardian Cloud Security Proposal with Blockchain","abstract":"With the advancement of cloud computing, data storage, and security have become crucial. The growing adoption of cloud services by companies, accompanied by increased threats from cybersecurity, highlights the importance of privacy and ownership of user data. Between 2022 and 2023, there has been an increase of around 48% in cloud security threats, emphasizing the urgent need for strong security solutions. To face these challenges, in this project, we propose integrating the Ethereum network's blockchain technology with a database located in the PostgreSQL cloud. The proposed solution aims to provide bidirectional data synchronization and strict control of access mechanisms. Blockchain technology ensures immutability and transparency of transactions, while PostgreSQL provides efficient and scalable storage. Through rigorous testing in an adaptive traffic control scenario, the results obtained indicate that this solution offers a significantly high level of security due to the decentralization of data, confirming that this solution is effective, and making it a powerful new option to improve security in cloud environments. In conclusion, the solution proposed in this project not only increases information security but also demonstrates the practical feasibility of integrating blockchain with cloud relational databases. This two-way alignment improves protection against cyberattacks and ensures that user data is protected from unauthorized access and malicious changes.","sentences":["With the advancement of cloud computing, data storage, and security have become crucial.","The growing adoption of cloud services by companies, accompanied by increased threats from cybersecurity, highlights the importance of privacy and ownership of user data.","Between 2022 and 2023, there has been an increase of around 48% in cloud security threats, emphasizing the urgent need for strong security solutions.","To face these challenges, in this project, we propose integrating the Ethereum network's blockchain technology with a database located in the PostgreSQL cloud.","The proposed solution aims to provide bidirectional data synchronization and strict control of access mechanisms.","Blockchain technology ensures immutability and transparency of transactions, while PostgreSQL provides efficient and scalable storage.","Through rigorous testing in an adaptive traffic control scenario, the results obtained indicate that this solution offers a significantly high level of security due to the decentralization of data, confirming that this solution is effective, and making it a powerful new option to improve security in cloud environments.","In conclusion, the solution proposed in this project not only increases information security but also demonstrates the practical feasibility of integrating blockchain with cloud relational databases.","This two-way alignment improves protection against cyberattacks and ensures that user data is protected from unauthorized access and malicious changes."],"url":"http://arxiv.org/abs/2407.19961v1"}
{"created":"2024-07-29 12:51:26","title":"Integrated Communications and Security: RIS-Assisted Simultaneous Transmission and Generation of Secret Keys","abstract":"We develop a new integrated communications and security (ICAS) design paradigm by leveraging the concept of reconfigurable intelligent surfaces (RISs). In particular, we propose RIS-assisted simultaneous transmission and secret key generation by sharing the RIS for these two tasks. Specifically, the legitimate transceivers intend to jointly optimize the data transmission rate and the key generation rate by configuring the phase-shift of the RIS in the presence of a smart attacker. We first derive the key generation rate of the RIS-assisted physical layer key generation (PLKG). Then, to obtain the optimal RIS configuration, we formulate the problem as a secure transmission (ST) game and prove the existence of the Nash equilibrium (NE), and then derive the NE point of the static game. For the dynamic ST game, we model the problem as a finite Markov decision process and propose a model-free reinforcement learning approach to obtain the NE point. Particularly, considering that the legitimate transceivers cannot obtain the channel state information (CSI) of the attacker in real-world conditions, we develop a deep recurrent Q-network (DRQN) based dynamic ST strategy to learn the optimal RIS configuration. The details of the algorithm are provided, and then, the system complexity is analyzed. Our simulation results show that the proposed DRQN based dynamic ST strategy has a better performance than the benchmarks even with a partial observation information, and achieves \"one time pad\" communication by allocating a suitable weight factor for data transmission and PLKG.","sentences":["We develop a new integrated communications and security (ICAS) design paradigm by leveraging the concept of reconfigurable intelligent surfaces (RISs).","In particular, we propose RIS-assisted simultaneous transmission and secret key generation by sharing the RIS for these two tasks.","Specifically, the legitimate transceivers intend to jointly optimize the data transmission rate and the key generation rate by configuring the phase-shift of the RIS in the presence of a smart attacker.","We first derive the key generation rate of the RIS-assisted physical layer key generation (PLKG).","Then, to obtain the optimal RIS configuration, we formulate the problem as a secure transmission (ST) game and prove the existence of the Nash equilibrium (NE), and then derive the NE point of the static game.","For the dynamic ST game, we model the problem as a finite Markov decision process and propose a model-free reinforcement learning approach to obtain the NE point.","Particularly, considering that the legitimate transceivers cannot obtain the channel state information (CSI) of the attacker in real-world conditions, we develop a deep recurrent Q-network (DRQN) based dynamic ST strategy to learn the optimal RIS configuration.","The details of the algorithm are provided, and then, the system complexity is analyzed.","Our simulation results show that the proposed DRQN based dynamic ST strategy has a better performance than the benchmarks even with a partial observation information, and achieves \"one time pad\" communication by allocating a suitable weight factor for data transmission and PLKG."],"url":"http://arxiv.org/abs/2407.19960v1"}
{"created":"2024-07-29 12:40:12","title":"FedDEO: Description-Enhanced One-Shot Federated Learning with Diffusion Models","abstract":"In recent years, the attention towards One-Shot Federated Learning (OSFL) has been driven by its capacity to minimize communication. With the development of the diffusion model (DM), several methods employ the DM for OSFL, utilizing model parameters, image features, or textual prompts as mediums to transfer the local client knowledge to the server. However, these mediums often require public datasets or the uniform feature extractor, significantly limiting their practicality. In this paper, we propose FedDEO, a Description-Enhanced One-Shot Federated Learning Method with DMs, offering a novel exploration of utilizing the DM in OSFL. The core idea of our method involves training local descriptions on the clients, serving as the medium to transfer the knowledge of the distributed clients to the server. Firstly, we train local descriptions on the client data to capture the characteristics of client distributions, which are then uploaded to the server. On the server, the descriptions are used as conditions to guide the DM in generating synthetic datasets that comply with the distributions of various clients, enabling the training of the aggregated model. Theoretical analyses and sufficient quantitation and visualization experiments on three large-scale real-world datasets demonstrate that through the training of local descriptions, the server is capable of generating synthetic datasets with high quality and diversity. Consequently, with advantages in communication and privacy protection, the aggregated model outperforms compared FL or diffusion-based OSFL methods and, on some clients, outperforms the performance ceiling of centralized training.","sentences":["In recent years, the attention towards One-Shot Federated Learning (OSFL) has been driven by its capacity to minimize communication.","With the development of the diffusion model (DM), several methods employ the DM for OSFL, utilizing model parameters, image features, or textual prompts as mediums to transfer the local client knowledge to the server.","However, these mediums often require public datasets or the uniform feature extractor, significantly limiting their practicality.","In this paper, we propose FedDEO, a Description-Enhanced One-Shot Federated Learning Method with DMs, offering a novel exploration of utilizing the DM in OSFL.","The core idea of our method involves training local descriptions on the clients, serving as the medium to transfer the knowledge of the distributed clients to the server.","Firstly, we train local descriptions on the client data to capture the characteristics of client distributions, which are then uploaded to the server.","On the server, the descriptions are used as conditions to guide the DM in generating synthetic datasets that comply with the distributions of various clients, enabling the training of the aggregated model.","Theoretical analyses and sufficient quantitation and visualization experiments on three large-scale real-world datasets demonstrate that through the training of local descriptions, the server is capable of generating synthetic datasets with high quality and diversity.","Consequently, with advantages in communication and privacy protection, the aggregated model outperforms compared FL or diffusion-based OSFL methods and, on some clients, outperforms the performance ceiling of centralized training."],"url":"http://arxiv.org/abs/2407.19953v1"}
{"created":"2024-07-29 12:28:12","title":"Engineering an Efficient Approximate DNF-Counter","abstract":"Model counting is a fundamental problem in many practical applications, including query evaluation in probabilistic databases and failure-probability estimation of networks. In this work, we focus on a variant of this problem where the underlying formula is expressed in the Disjunctive Normal Form (DNF), also known as #DNF. This problem has been shown to be #P-complete, making it often intractable to solve exactly. Much research has therefore focused on obtaining approximate solutions, particularly in the form of $(\\varepsilon, \\delta)$ approximations.   The primary contribution of this paper is a new approach, called pepin, an approximate #DNF counter that significantly outperforms prior state-of-the-art approaches. Our work is based on the recent breakthrough in the context of the union of sets in the streaming model. We demonstrate the effectiveness of our approach through extensive experiments and show that it provides an affirmative answer to the challenge of efficiently computing #DNF.","sentences":["Model counting is a fundamental problem in many practical applications, including query evaluation in probabilistic databases and failure-probability estimation of networks.","In this work, we focus on a variant of this problem where the underlying formula is expressed in the Disjunctive Normal Form (DNF), also known as #DNF.","This problem has been shown to be #P-complete, making it often intractable to solve exactly.","Much research has therefore focused on obtaining approximate solutions, particularly in the form of $(\\varepsilon, \\delta)$ approximations.   ","The primary contribution of this paper is a new approach, called pepin, an approximate #DNF counter that significantly outperforms prior state-of-the-art approaches.","Our work is based on the recent breakthrough in the context of the union of sets in the streaming model.","We demonstrate the effectiveness of our approach through extensive experiments and show that it provides an affirmative answer to the challenge of efficiently computing #DNF."],"url":"http://arxiv.org/abs/2407.19946v1"}
{"created":"2024-07-29 12:24:28","title":"Noise-Resilient Unsupervised Graph Representation Learning via Multi-Hop Feature Quality Estimation","abstract":"Unsupervised graph representation learning (UGRL) based on graph neural networks (GNNs), has received increasing attention owing to its efficacy in handling graph-structured data. However, existing UGRL methods ideally assume that the node features are noise-free, which makes them fail to distinguish between useful information and noise when applied to real data with noisy features, thus affecting the quality of learned representations. This urges us to take node noisy features into account in real-world UGRL. With empirical analysis, we reveal that feature propagation, the essential operation in GNNs, acts as a \"double-edged sword\" in handling noisy features - it can both denoise and diffuse noise, leading to varying feature quality across nodes, even within the same node at different hops. Building on this insight, we propose a novel UGRL method based on Multi-hop feature Quality Estimation (MQE for short). Unlike most UGRL models that directly utilize propagation-based GNNs to generate representations, our approach aims to learn representations through estimating the quality of propagated features at different hops. Specifically, we introduce a Gaussian model that utilizes a learnable \"meta-representation\" as a condition to estimate the expectation and variance of multi-hop propagated features via neural networks. In this way, the \"meta representation\" captures the semantic and structural information underlying multiple propagated features but is naturally less susceptible to interference by noise, thereby serving as high-quality node representations beneficial for downstream tasks. Extensive experiments on multiple real-world datasets demonstrate that MQE in learning reliable node representations in scenarios with diverse types of feature noise.","sentences":["Unsupervised graph representation learning (UGRL) based on graph neural networks (GNNs), has received increasing attention owing to its efficacy in handling graph-structured data.","However, existing UGRL methods ideally assume that the node features are noise-free, which makes them fail to distinguish between useful information and noise when applied to real data with noisy features, thus affecting the quality of learned representations.","This urges us to take node noisy features into account in real-world UGRL.","With empirical analysis, we reveal that feature propagation, the essential operation in GNNs, acts as a \"double-edged sword\" in handling noisy features - it can both denoise and diffuse noise, leading to varying feature quality across nodes, even within the same node at different hops.","Building on this insight, we propose a novel UGRL method based on Multi-hop feature Quality Estimation (MQE for short).","Unlike most UGRL models that directly utilize propagation-based GNNs to generate representations, our approach aims to learn representations through estimating the quality of propagated features at different hops.","Specifically, we introduce a Gaussian model that utilizes a learnable \"meta-representation\" as a condition to estimate the expectation and variance of multi-hop propagated features via neural networks.","In this way, the \"meta representation\" captures the semantic and structural information underlying multiple propagated features but is naturally less susceptible to interference by noise, thereby serving as high-quality node representations beneficial for downstream tasks.","Extensive experiments on multiple real-world datasets demonstrate that MQE in learning reliable node representations in scenarios with diverse types of feature noise."],"url":"http://arxiv.org/abs/2407.19944v1"}
{"created":"2024-07-29 12:23:15","title":"Predicting citation impact of research papers using GPT and other text embeddings","abstract":"The impact of research papers, typically measured in terms of citation counts, depends on several factors, including the reputation of the authors, journals, and institutions, in addition to the quality of the scientific work. In this paper, we present an approach that combines natural language processing and machine learning to predict the impact of papers in a specific journal. Our focus is on the text, which should correlate with impact and the topics covered in the research. We employed a dataset of over 40,000 articles from ACS Applied Materials and Interfaces spanning from 2012 to 2022. The data was processed using various text embedding techniques and classified with supervised machine learning algorithms. Papers were categorized into the top 20% most cited within the journal, using both yearly and cumulative citation counts as metrics. Our analysis reveals that the method employing generative pre-trained transformers (GPT) was the most efficient for embedding, while the random forest algorithm exhibited the best predictive power among the machine learning algorithms. An optimized accuracy of 80\\% in predicting whether a paper was among the top 20% most cited was achieved for the cumulative citation count when abstracts were processed. This accuracy is noteworthy, considering that author, institution, and early citation pattern information were not taken into account. The accuracy increased only slightly when the full texts of the papers were processed. Also significant is the finding that a simpler embedding technique, term frequency-inverse document frequency (TFIDF), yielded performance close to that of GPT. Since TFIDF captures the topics of the paper we infer that, apart from considering author and institution biases, citation counts for the considered journal may be predicted by identifying topics and \"reading\" the abstract of a paper.","sentences":["The impact of research papers, typically measured in terms of citation counts, depends on several factors, including the reputation of the authors, journals, and institutions, in addition to the quality of the scientific work.","In this paper, we present an approach that combines natural language processing and machine learning to predict the impact of papers in a specific journal.","Our focus is on the text, which should correlate with impact and the topics covered in the research.","We employed a dataset of over 40,000 articles from ACS Applied Materials and Interfaces spanning from 2012 to 2022.","The data was processed using various text embedding techniques and classified with supervised machine learning algorithms.","Papers were categorized into the top 20% most cited within the journal, using both yearly and cumulative citation counts as metrics.","Our analysis reveals that the method employing generative pre-trained transformers (GPT) was the most efficient for embedding, while the random forest algorithm exhibited the best predictive power among the machine learning algorithms.","An optimized accuracy of 80\\% in predicting whether a paper was among the top 20% most cited was achieved for the cumulative citation count when abstracts were processed.","This accuracy is noteworthy, considering that author, institution, and early citation pattern information were not taken into account.","The accuracy increased only slightly when the full texts of the papers were processed.","Also significant is the finding that a simpler embedding technique, term frequency-inverse document frequency (TFIDF), yielded performance close to that of GPT.","Since TFIDF captures the topics of the paper we infer that, apart from considering author and institution biases, citation counts for the considered journal may be predicted by identifying topics and \"reading\" the abstract of a paper."],"url":"http://arxiv.org/abs/2407.19942v1"}
{"created":"2024-07-29 12:22:16","title":"Boosting Graph Foundation Model from Structural Perspective","abstract":"Graph foundation models have recently attracted significant attention due to its strong generalizability. Although existing methods resort to language models to learn unified semantic representations across domains, they disregard the unique structural characteristics of graphs from different domains. To address the problem, in this paper, we boost graph foundation model from structural perspective and propose BooG. The model constructs virtual super nodes to unify structural characteristics of graph data from different domains. Specifically, the super nodes fuse the information of anchor nodes and class labels, where each anchor node captures the information of a node or a graph instance to be classified. Instead of using the raw graph structure, we connect super nodes to all nodes within their neighborhood by virtual edges. This new structure allows for effective information aggregation while unifying cross-domain structural characteristics. Additionally, we propose a novel pre-training objective based on contrastive learning, which learns more expressive representations for graph data and generalizes effectively to different domains and downstream tasks. Experimental results on various datasets and tasks demonstrate the superior performance of BooG. We provide our code and data here: https://anonymous.4open.science/r/BooG-EE42/.","sentences":["Graph foundation models have recently attracted significant attention due to its strong generalizability.","Although existing methods resort to language models to learn unified semantic representations across domains, they disregard the unique structural characteristics of graphs from different domains.","To address the problem, in this paper, we boost graph foundation model from structural perspective and propose BooG. The model constructs virtual super nodes to unify structural characteristics of graph data from different domains.","Specifically, the super nodes fuse the information of anchor nodes and class labels, where each anchor node captures the information of a node or a graph instance to be classified.","Instead of using the raw graph structure, we connect super nodes to all nodes within their neighborhood by virtual edges.","This new structure allows for effective information aggregation while unifying cross-domain structural characteristics.","Additionally, we propose a novel pre-training objective based on contrastive learning, which learns more expressive representations for graph data and generalizes effectively to different domains and downstream tasks.","Experimental results on various datasets and tasks demonstrate the superior performance of BooG. We provide our code and data here: https://anonymous.4open.science/r/BooG-EE42/."],"url":"http://arxiv.org/abs/2407.19941v1"}
{"created":"2024-07-29 12:18:07","title":"Robust Conformal Volume Estimation in 3D Medical Images","abstract":"Volumetry is one of the principal downstream applications of 3D medical image segmentation, for example, to detect abnormal tissue growth or for surgery planning. Conformal Prediction is a promising framework for uncertainty quantification, providing calibrated predictive intervals associated with automatic volume measurements. However, this methodology is based on the hypothesis that calibration and test samples are exchangeable, an assumption that is in practice often violated in medical image applications. A weighted formulation of Conformal Prediction can be framed to mitigate this issue, but its empirical investigation in the medical domain is still lacking. A potential reason is that it relies on the estimation of the density ratio between the calibration and test distributions, which is likely to be intractable in scenarios involving high-dimensional data. To circumvent this, we propose an efficient approach for density ratio estimation relying on the compressed latent representations generated by the segmentation model. Our experiments demonstrate the efficiency of our approach to reduce the coverage error in the presence of covariate shifts, in both synthetic and real-world settings. Our implementation is available at https://github.com/benolmbrt/wcp_miccai","sentences":["Volumetry is one of the principal downstream applications of 3D medical image segmentation, for example, to detect abnormal tissue growth or for surgery planning.","Conformal Prediction is a promising framework for uncertainty quantification, providing calibrated predictive intervals associated with automatic volume measurements.","However, this methodology is based on the hypothesis that calibration and test samples are exchangeable, an assumption that is in practice often violated in medical image applications.","A weighted formulation of Conformal Prediction can be framed to mitigate this issue, but its empirical investigation in the medical domain is still lacking.","A potential reason is that it relies on the estimation of the density ratio between the calibration and test distributions, which is likely to be intractable in scenarios involving high-dimensional data.","To circumvent this, we propose an efficient approach for density ratio estimation relying on the compressed latent representations generated by the segmentation model.","Our experiments demonstrate the efficiency of our approach to reduce the coverage error in the presence of covariate shifts, in both synthetic and real-world settings.","Our implementation is available at https://github.com/benolmbrt/wcp_miccai"],"url":"http://arxiv.org/abs/2407.19938v1"}
{"created":"2024-07-29 12:01:50","title":"Lightweight Dataset for Decoy Development to Improve IoT Security","abstract":"In this paper, the authors introduce a lightweight dataset to interpret IoT (Internet of Things) activity in preparation to create decoys by replicating known data traffic patterns. The dataset comprises different scenarios in a real network setting. This paper also surveys information related to other IoT datasets along with the characteristics that make our data valuable. Many of the datasets available are synthesized (simulated) or often address industrial applications, while the IoT dataset we present is based on likely smart home scenarios. Further, there are only a limited number of IoT datasets that contain both normal operation and attack scenarios. A discussion of the network configuration and the steps taken to prepare this dataset are presented as we prepare to create replicative patterns for decoy purposes. The dataset, which we refer to as IoT Flex Data, consists of four categories, namely, IoT benign idle, IoT benign active, IoT setup, and malicious (attack) traffic associating the IoT devices with the scenarios under consideration.","sentences":["In this paper, the authors introduce a lightweight dataset to interpret IoT (Internet of Things) activity in preparation to create decoys by replicating known data traffic patterns.","The dataset comprises different scenarios in a real network setting.","This paper also surveys information related to other IoT datasets along with the characteristics that make our data valuable.","Many of the datasets available are synthesized (simulated) or often address industrial applications, while the IoT dataset we present is based on likely smart home scenarios.","Further, there are only a limited number of IoT datasets that contain both normal operation and attack scenarios.","A discussion of the network configuration and the steps taken to prepare this dataset are presented as we prepare to create replicative patterns for decoy purposes.","The dataset, which we refer to as IoT Flex Data, consists of four categories, namely, IoT benign idle, IoT benign active, IoT setup, and malicious (attack) traffic associating the IoT devices with the scenarios under consideration."],"url":"http://arxiv.org/abs/2407.19926v1"}
{"created":"2024-07-29 11:58:54","title":"Monetizing Currency Pair Sentiments through LLM Explainability","abstract":"Large language models (LLMs) play a vital role in almost every domain in today's organizations. In the context of this work, we highlight the use of LLMs for sentiment analysis (SA) and explainability. Specifically, we contribute a novel technique to leverage LLMs as a post-hoc model-independent tool for the explainability of SA. We applied our technique in the financial domain for currency-pair price predictions using open news feed data merged with market prices. Our application shows that the developed technique is not only a viable alternative to using conventional eXplainable AI but can also be fed back to enrich the input to the machine learning (ML) model to better predict future currency-pair values. We envision our results could be generalized to employing explainability as a conventional enrichment for ML input for better ML predictions in general.","sentences":["Large language models (LLMs) play a vital role in almost every domain in today's organizations.","In the context of this work, we highlight the use of LLMs for sentiment analysis (SA) and explainability.","Specifically, we contribute a novel technique to leverage LLMs as a post-hoc model-independent tool for the explainability of SA.","We applied our technique in the financial domain for currency-pair price predictions using open news feed data merged with market prices.","Our application shows that the developed technique is not only a viable alternative to using conventional eXplainable AI but can also be fed back to enrich the input to the machine learning (ML) model to better predict future currency-pair values.","We envision our results could be generalized to employing explainability as a conventional enrichment for ML input for better ML predictions in general."],"url":"http://arxiv.org/abs/2407.19922v1"}
{"created":"2024-07-29 11:52:07","title":"FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention","abstract":"Video diffusion models have made substantial progress in various video generation applications. However, training models for long video generation tasks require significant computational and data resources, posing a challenge to developing long video diffusion models. This paper investigates a straightforward and training-free approach to extend an existing short video diffusion model (e.g. pre-trained on 16-frame videos) for consistent long video generation (e.g. 128 frames). Our preliminary observation has found that directly applying the short video diffusion model to generate long videos can lead to severe video quality degradation. Further investigation reveals that this degradation is primarily due to the distortion of high-frequency components in long videos, characterized by a decrease in spatial high-frequency components and an increase in temporal high-frequency components. Motivated by this, we propose a novel solution named FreeLong to balance the frequency distribution of long video features during the denoising process. FreeLong blends the low-frequency components of global video features, which encapsulate the entire video sequence, with the high-frequency components of local video features that focus on shorter subsequences of frames. This approach maintains global consistency while incorporating diverse and high-quality spatiotemporal details from local videos, enhancing both the consistency and fidelity of long video generation. We evaluated FreeLong on multiple base video diffusion models and observed significant improvements. Additionally, our method supports coherent multi-prompt generation, ensuring both visual coherence and seamless transitions between scenes.","sentences":["Video diffusion models have made substantial progress in various video generation applications.","However, training models for long video generation tasks require significant computational and data resources, posing a challenge to developing long video diffusion models.","This paper investigates a straightforward and training-free approach to extend an existing short video diffusion model (e.g. pre-trained on 16-frame videos) for consistent long video generation (e.g. 128 frames).","Our preliminary observation has found that directly applying the short video diffusion model to generate long videos can lead to severe video quality degradation.","Further investigation reveals that this degradation is primarily due to the distortion of high-frequency components in long videos, characterized by a decrease in spatial high-frequency components and an increase in temporal high-frequency components.","Motivated by this, we propose a novel solution named FreeLong to balance the frequency distribution of long video features during the denoising process.","FreeLong blends the low-frequency components of global video features, which encapsulate the entire video sequence, with the high-frequency components of local video features that focus on shorter subsequences of frames.","This approach maintains global consistency while incorporating diverse and high-quality spatiotemporal details from local videos, enhancing both the consistency and fidelity of long video generation.","We evaluated FreeLong on multiple base video diffusion models and observed significant improvements.","Additionally, our method supports coherent multi-prompt generation, ensuring both visual coherence and seamless transitions between scenes."],"url":"http://arxiv.org/abs/2407.19918v1"}
{"created":"2024-07-29 11:34:32","title":"Neural Control Barrier Functions for Safe Navigation","abstract":"Autonomous robot navigation can be particularly demanding, especially when the surrounding environment is not known and safety of the robot is crucial. This work relates to the synthesis of Control Barrier Functions (CBFs) through data for safe navigation in unknown environments. A novel methodology to jointly learn CBFs and corresponding safe controllers, in simulation, inspired by the State Dependent Riccati Equation (SDRE) is proposed. The CBF is used to obtain admissible commands from any nominal, possibly unsafe controller. An approach to apply the CBF inside a safety filter without the need for a consistent map or position estimate is developed. Subsequently, the resulting reactive safety filter is deployed on a multirotor platform integrating a LiDAR sensor both in simulation and real-world experiments.","sentences":["Autonomous robot navigation can be particularly demanding, especially when the surrounding environment is not known and safety of the robot is crucial.","This work relates to the synthesis of Control Barrier Functions (CBFs) through data for safe navigation in unknown environments.","A novel methodology to jointly learn CBFs and corresponding safe controllers, in simulation, inspired by the State Dependent Riccati Equation (SDRE) is proposed.","The CBF is used to obtain admissible commands from any nominal, possibly unsafe controller.","An approach to apply the CBF inside a safety filter without the need for a consistent map or position estimate is developed.","Subsequently, the resulting reactive safety filter is deployed on a multirotor platform integrating a LiDAR sensor both in simulation and real-world experiments."],"url":"http://arxiv.org/abs/2407.19907v1"}
{"created":"2024-07-29 11:29:14","title":"The Bidirected Cut Relaxation for Steiner Tree has Integrality Gap Smaller than 2","abstract":"The Steiner tree problem is one of the most prominent problems in network design. Given an edge-weighted undirected graph and a subset of the vertices, called terminals, the task is to compute a minimum-weight tree containing all terminals (and possibly further vertices). The best-known approximation algorithms for Steiner tree involve enumeration of a (polynomial but) very large number of candidate components and are therefore slow in practice.   A promising ingredient for the design of fast and accurate approximation algorithms for Steiner tree is the bidirected cut relaxation (BCR): bidirect all edges, choose an arbitrary terminal as a root, and enforce that each cut containing some terminal but not the root has one unit of fractional edges leaving it. BCR is known to be integral in the spanning tree case [Edmonds'67], i.e., when all the vertices are terminals. For general instances, however, it was not even known whether the integrality gap of BCR is better than the integrality gap of the natural undirected relaxation, which is exactly 2. We resolve this question by proving an upper bound of 1.9988 on the integrality gap of BCR.","sentences":["The Steiner tree problem is one of the most prominent problems in network design.","Given an edge-weighted undirected graph and a subset of the vertices, called terminals, the task is to compute a minimum-weight tree containing all terminals (and possibly further vertices).","The best-known approximation algorithms for Steiner tree involve enumeration of a (polynomial but) very large number of candidate components and are therefore slow in practice.   ","A promising ingredient for the design of fast and accurate approximation algorithms for Steiner tree is the bidirected cut relaxation (BCR): bidirect all edges, choose an arbitrary terminal as a root, and enforce that each cut containing some terminal but not the root has one unit of fractional edges leaving it.","BCR is known to be integral in the spanning tree case","[Edmonds'67], i.e., when all the vertices are terminals.","For general instances, however, it was not even known whether the integrality gap of BCR is better than the integrality gap of the natural undirected relaxation, which is exactly 2.","We resolve this question by proving an upper bound of 1.9988 on the integrality gap of BCR."],"url":"http://arxiv.org/abs/2407.19905v1"}
{"created":"2024-07-29 11:26:17","title":"A Differential Dynamic Programming Framework for Inverse Reinforcement Learning","abstract":"A differential dynamic programming (DDP)-based framework for inverse reinforcement learning (IRL) is introduced to recover the parameters in the cost function, system dynamics, and constraints from demonstrations. Different from existing work, where DDP was used for the inner forward problem with inequality constraints, our proposed framework uses it for efficient computation of the gradient required in the outer inverse problem with equality and inequality constraints. The equivalence between the proposed method and existing methods based on Pontryagin's Maximum Principle (PMP) is established. More importantly, using this DDP-based IRL with an open-loop loss function, a closed-loop IRL framework is presented. In this framework, a loss function is proposed to capture the closed-loop nature of demonstrations. It is shown to be better than the commonly used open-loop loss function. We show that the closed-loop IRL framework reduces to a constrained inverse optimal control problem under certain assumptions. Under these assumptions and a rank condition, it is proven that the learning parameters can be recovered from the demonstration data. The proposed framework is extensively evaluated through four numerical robot examples and one real-world quadrotor system. The experiments validate the theoretical results and illustrate the practical relevance of the approach.","sentences":["A differential dynamic programming (DDP)-based framework for inverse reinforcement learning (IRL) is introduced to recover the parameters in the cost function, system dynamics, and constraints from demonstrations.","Different from existing work, where DDP was used for the inner forward problem with inequality constraints, our proposed framework uses it for efficient computation of the gradient required in the outer inverse problem with equality and inequality constraints.","The equivalence between the proposed method and existing methods based on Pontryagin's Maximum Principle (PMP) is established.","More importantly, using this DDP-based IRL with an open-loop loss function, a closed-loop IRL framework is presented.","In this framework, a loss function is proposed to capture the closed-loop nature of demonstrations.","It is shown to be better than the commonly used open-loop loss function.","We show that the closed-loop IRL framework reduces to a constrained inverse optimal control problem under certain assumptions.","Under these assumptions and a rank condition, it is proven that the learning parameters can be recovered from the demonstration data.","The proposed framework is extensively evaluated through four numerical robot examples and one real-world quadrotor system.","The experiments validate the theoretical results and illustrate the practical relevance of the approach."],"url":"http://arxiv.org/abs/2407.19902v1"}
{"created":"2024-07-29 11:24:10","title":"Practical and Reproducible Symbolic Music Generation by Large Language Models with Structural Embeddings","abstract":"Music generation introduces challenging complexities to large language models. Symbolic structures of music often include vertical harmonization as well as horizontal counterpoint, urging various adaptations and enhancements for large-scale Transformers. However, existing works share three major drawbacks: 1) their tokenization requires domain-specific annotations, such as bars and beats, that are typically missing in raw MIDI data; 2) the pure impact of enhancing token embedding methods is hardly examined without domain-specific annotations; and 3) existing works to overcome the aforementioned drawbacks, such as MuseNet, lack reproducibility. To tackle such limitations, we develop a MIDI-based music generation framework inspired by MuseNet, empirically studying two structural embeddings that do not rely on domain-specific annotations. We provide various metrics and insights that can guide suitable encoding to deploy. We also verify that multiple embedding configurations can selectively boost certain musical aspects. By providing open-source implementations via HuggingFace, our findings shed light on leveraging large language models toward practical and reproducible music generation.","sentences":["Music generation introduces challenging complexities to large language models.","Symbolic structures of music often include vertical harmonization as well as horizontal counterpoint, urging various adaptations and enhancements for large-scale Transformers.","However, existing works share three major drawbacks: 1) their tokenization requires domain-specific annotations, such as bars and beats, that are typically missing in raw MIDI data; 2) the pure impact of enhancing token embedding methods is hardly examined without domain-specific annotations; and 3) existing works to overcome the aforementioned drawbacks, such as MuseNet, lack reproducibility.","To tackle such limitations, we develop a MIDI-based music generation framework inspired by MuseNet, empirically studying two structural embeddings that do not rely on domain-specific annotations.","We provide various metrics and insights that can guide suitable encoding to deploy.","We also verify that multiple embedding configurations can selectively boost certain musical aspects.","By providing open-source implementations via HuggingFace, our findings shed light on leveraging large language models toward practical and reproducible music generation."],"url":"http://arxiv.org/abs/2407.19900v1"}
{"created":"2024-07-29 11:21:17","title":"BEExAI: Benchmark to Evaluate Explainable AI","abstract":"Recent research in explainability has given rise to numerous post-hoc attribution methods aimed at enhancing our comprehension of the outputs of black-box machine learning models. However, evaluating the quality of explanations lacks a cohesive approach and a consensus on the methodology for deriving quantitative metrics that gauge the efficacy of explainability post-hoc attribution methods. Furthermore, with the development of increasingly complex deep learning models for diverse data applications, the need for a reliable way of measuring the quality and correctness of explanations is becoming critical. We address this by proposing BEExAI, a benchmark tool that allows large-scale comparison of different post-hoc XAI methods, employing a set of selected evaluation metrics.","sentences":["Recent research in explainability has given rise to numerous post-hoc attribution methods aimed at enhancing our comprehension of the outputs of black-box machine learning models.","However, evaluating the quality of explanations lacks a cohesive approach and a consensus on the methodology for deriving quantitative metrics that gauge the efficacy of explainability post-hoc attribution methods.","Furthermore, with the development of increasingly complex deep learning models for diverse data applications, the need for a reliable way of measuring the quality and correctness of explanations is becoming critical.","We address this by proposing BEExAI, a benchmark tool that allows large-scale comparison of different post-hoc XAI methods, employing a set of selected evaluation metrics."],"url":"http://arxiv.org/abs/2407.19897v1"}
{"created":"2024-07-29 11:16:48","title":"Leveraging Foundation Models for Zero-Shot IoT Sensing","abstract":"Deep learning models are increasingly deployed on edge Internet of Things (IoT) devices. However, these models typically operate under supervised conditions and fail to recognize unseen classes different from training. To address this, zero-shot learning (ZSL) aims to classify data of unseen classes with the help of semantic information. Foundation models (FMs) trained on web-scale data have shown impressive ZSL capability in natural language processing and visual understanding. However, leveraging FMs' generalized knowledge for zero-shot IoT sensing using signals such as mmWave, IMU, and Wi-Fi has not been fully investigated. In this work, we align the IoT data embeddings with the semantic embeddings generated by an FM's text encoder for zero-shot IoT sensing. To utilize the physics principles governing the generation of IoT sensor signals to derive more effective prompts for semantic embedding extraction, we propose to use cross-attention to combine a learnable soft prompt that is optimized automatically on training data and an auxiliary hard prompt that encodes domain knowledge of the IoT sensing task. To address the problem of IoT embeddings biasing to seen classes due to the lack of unseen class data during training, we propose using data augmentation to synthesize unseen class IoT data for fine-tuning the IoT feature extractor and embedding projector. We evaluate our approach on multiple IoT sensing tasks. Results show that our approach achieves superior open-set detection and generalized zero-shot learning performance compared with various baselines. Our code is available at https://github.com/schrodingho/FM\\_ZSL\\_IoT.","sentences":["Deep learning models are increasingly deployed on edge Internet of Things (IoT) devices.","However, these models typically operate under supervised conditions and fail to recognize unseen classes different from training.","To address this, zero-shot learning (ZSL) aims to classify data of unseen classes with the help of semantic information.","Foundation models (FMs) trained on web-scale data have shown impressive ZSL capability in natural language processing and visual understanding.","However, leveraging FMs' generalized knowledge for zero-shot IoT sensing using signals such as mmWave, IMU, and Wi-Fi has not been fully investigated.","In this work, we align the IoT data embeddings with the semantic embeddings generated by an FM's text encoder for zero-shot IoT sensing.","To utilize the physics principles governing the generation of IoT sensor signals to derive more effective prompts for semantic embedding extraction, we propose to use cross-attention to combine a learnable soft prompt that is optimized automatically on training data and an auxiliary hard prompt that encodes domain knowledge of the IoT sensing task.","To address the problem of IoT embeddings biasing to seen classes due to the lack of unseen class data during training, we propose using data augmentation to synthesize unseen class IoT data for fine-tuning the IoT feature extractor and embedding projector.","We evaluate our approach on multiple IoT sensing tasks.","Results show that our approach achieves superior open-set detection and generalized zero-shot learning performance compared with various baselines.","Our code is available at https://github.com/schrodingho/FM\\_ZSL\\_IoT."],"url":"http://arxiv.org/abs/2407.19893v1"}
{"created":"2024-07-29 11:11:17","title":"Self-Supervised Learning for Text Recognition: A Critical Survey","abstract":"Text Recognition (TR) refers to the research area that focuses on retrieving textual information from images, a topic that has seen significant advancements in the last decade due to the use of Deep Neural Networks (DNN). However, these solutions often necessitate vast amounts of manually labeled or synthetic data. Addressing this challenge, Self-Supervised Learning (SSL) has gained attention by utilizing large datasets of unlabeled data to train DNN, thereby generating meaningful and robust representations. Although SSL was initially overlooked in TR because of its unique characteristics, recent years have witnessed a surge in the development of SSL methods specifically for this field. This rapid development, however, has led to many methods being explored independently, without taking previous efforts in methodology or comparison into account, thereby hindering progress in the field of research. This paper, therefore, seeks to consolidate the use of SSL in the field of TR, offering a critical and comprehensive overview of the current state of the art. We will review and analyze the existing methods, compare their results, and highlight inconsistencies in the current literature. This thorough analysis aims to provide general insights into the field, propose standardizations, identify new research directions, and foster its proper development.","sentences":["Text Recognition (TR) refers to the research area that focuses on retrieving textual information from images, a topic that has seen significant advancements in the last decade due to the use of Deep Neural Networks (DNN).","However, these solutions often necessitate vast amounts of manually labeled or synthetic data.","Addressing this challenge, Self-Supervised Learning (SSL) has gained attention by utilizing large datasets of unlabeled data to train DNN, thereby generating meaningful and robust representations.","Although SSL was initially overlooked in TR because of its unique characteristics, recent years have witnessed a surge in the development of SSL methods specifically for this field.","This rapid development, however, has led to many methods being explored independently, without taking previous efforts in methodology or comparison into account, thereby hindering progress in the field of research.","This paper, therefore, seeks to consolidate the use of SSL in the field of TR, offering a critical and comprehensive overview of the current state of the art.","We will review and analyze the existing methods, compare their results, and highlight inconsistencies in the current literature.","This thorough analysis aims to provide general insights into the field, propose standardizations, identify new research directions, and foster its proper development."],"url":"http://arxiv.org/abs/2407.19889v1"}
{"created":"2024-07-29 11:04:31","title":"A Unified Graph Transformer for Overcoming Isolations in Multi-modal Recommendation","abstract":"With the rapid development of online multimedia services, especially in e-commerce platforms, there is a pressing need for personalised recommendation systems that can effectively encode the diverse multi-modal content associated with each item. However, we argue that existing multi-modal recommender systems typically use isolated processes for both feature extraction and modality modelling. Such isolated processes can harm the recommendation performance. Firstly, an isolated extraction process underestimates the importance of effective feature extraction in multi-modal recommendations, potentially incorporating non-relevant information, which is harmful to item representations. Second, an isolated modality modelling process produces disjointed embeddings for item modalities due to the individual processing of each modality, which leads to a suboptimal fusion of user/item representations for effective user preferences prediction. We hypothesise that the use of a unified model for addressing both aforementioned isolated processes will enable the consistent extraction and cohesive fusion of joint multi-modal features, thereby enhancing the effectiveness of multi-modal recommender systems. In this paper, we propose a novel model, called Unified Multi-modal Graph Transformer (UGT), which firstly leverages a multi-way transformer to extract aligned multi-modal features from raw data for top-k recommendation. Subsequently, we build a unified graph neural network in our UGT model to jointly fuse the user/item representations with their corresponding multi-modal features. Using the graph transformer architecture of our UGT model, we show that the UGT model can achieve significant effectiveness gains, especially when jointly optimised with the commonly-used multi-modal recommendation losses.","sentences":["With the rapid development of online multimedia services, especially in e-commerce platforms, there is a pressing need for personalised recommendation systems that can effectively encode the diverse multi-modal content associated with each item.","However, we argue that existing multi-modal recommender systems typically use isolated processes for both feature extraction and modality modelling.","Such isolated processes can harm the recommendation performance.","Firstly, an isolated extraction process underestimates the importance of effective feature extraction in multi-modal recommendations, potentially incorporating non-relevant information, which is harmful to item representations.","Second, an isolated modality modelling process produces disjointed embeddings for item modalities due to the individual processing of each modality, which leads to a suboptimal fusion of user/item representations for effective user preferences prediction.","We hypothesise that the use of a unified model for addressing both aforementioned isolated processes will enable the consistent extraction and cohesive fusion of joint multi-modal features, thereby enhancing the effectiveness of multi-modal recommender systems.","In this paper, we propose a novel model, called Unified Multi-modal Graph Transformer (UGT), which firstly leverages a multi-way transformer to extract aligned multi-modal features from raw data for top-k recommendation.","Subsequently, we build a unified graph neural network in our UGT model to jointly fuse the user/item representations with their corresponding multi-modal features.","Using the graph transformer architecture of our UGT model, we show that the UGT model can achieve significant effectiveness gains, especially when jointly optimised with the commonly-used multi-modal recommendation losses."],"url":"http://arxiv.org/abs/2407.19886v1"}
{"created":"2024-07-29 10:55:17","title":"Language-driven Grasp Detection with Mask-guided Attention","abstract":"Grasp detection is an essential task in robotics with various industrial applications. However, traditional methods often struggle with occlusions and do not utilize language for grasping. Incorporating natural language into grasp detection remains a challenging task and largely unexplored. To address this gap, we propose a new method for language-driven grasp detection with mask-guided attention by utilizing the transformer attention mechanism with semantic segmentation features. Our approach integrates visual data, segmentation mask features, and natural language instructions, significantly improving grasp detection accuracy. Our work introduces a new framework for language-driven grasp detection, paving the way for language-driven robotic applications. Intensive experiments show that our method outperforms other recent baselines by a clear margin, with a 10.0% success score improvement. We further validate our method in real-world robotic experiments, confirming the effectiveness of our approach.","sentences":["Grasp detection is an essential task in robotics with various industrial applications.","However, traditional methods often struggle with occlusions and do not utilize language for grasping.","Incorporating natural language into grasp detection remains a challenging task and largely unexplored.","To address this gap, we propose a new method for language-driven grasp detection with mask-guided attention by utilizing the transformer attention mechanism with semantic segmentation features.","Our approach integrates visual data, segmentation mask features, and natural language instructions, significantly improving grasp detection accuracy.","Our work introduces a new framework for language-driven grasp detection, paving the way for language-driven robotic applications.","Intensive experiments show that our method outperforms other recent baselines by a clear margin, with a 10.0% success score improvement.","We further validate our method in real-world robotic experiments, confirming the effectiveness of our approach."],"url":"http://arxiv.org/abs/2407.19877v1"}
{"created":"2024-07-29 10:51:31","title":"Exploring Robust Face-Voice Matching in Multilingual Environments","abstract":"This paper presents Team Xaiofei's innovative approach to exploring Face-Voice Association in Multilingual Environments (FAME) at ACM Multimedia 2024. We focus on the impact of different languages in face-voice matching by building upon Fusion and Orthogonal Projection (FOP), introducing four key components: a dual-branch structure, dynamic sample pair weighting, robust data augmentation, and score polarization strategy. Our dual-branch structure serves as an auxiliary mechanism to better integrate and provide more comprehensive information. We also introduce a dynamic weighting mechanism for various sample pairs to optimize learning. Data augmentation techniques are employed to enhance the model's generalization across diverse conditions. Additionally, score polarization strategy based on age and gender matching confidence clarifies and accentuates the final results. Our methods demonstrate significant effectiveness, achieving an equal error rate (EER) of 20.07 on the V2-EH dataset and 21.76 on the V1-EU dataset.","sentences":["This paper presents Team Xaiofei's innovative approach to exploring Face-Voice Association in Multilingual Environments (FAME) at ACM Multimedia 2024.","We focus on the impact of different languages in face-voice matching by building upon Fusion and Orthogonal Projection (FOP), introducing four key components: a dual-branch structure, dynamic sample pair weighting, robust data augmentation, and score polarization strategy.","Our dual-branch structure serves as an auxiliary mechanism to better integrate and provide more comprehensive information.","We also introduce a dynamic weighting mechanism for various sample pairs to optimize learning.","Data augmentation techniques are employed to enhance the model's generalization across diverse conditions.","Additionally, score polarization strategy based on age and gender matching confidence clarifies and accentuates the final results.","Our methods demonstrate significant effectiveness, achieving an equal error rate (EER) of 20.07 on the V2-EH dataset and 21.76 on the V1-EU dataset."],"url":"http://arxiv.org/abs/2407.19875v1"}
{"created":"2024-07-29 10:43:15","title":"OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city Analysis of Area Usage Patterns","abstract":"We publicly release OpenUAS, a dataset of area embeddings based on urban usage patterns, including embeddings for over 1.3 million 50-meter square meshes covering a total area of 3,300 square kilometers. This dataset is valuable for analyzing area functions in fields such as market analysis, urban planning, transportation infrastructure, and infection prediction. It captures the characteristics of each area in the city, such as office districts and residential areas, by employing an area embedding technique that utilizes location information typically obtained by GPS. Numerous area embedding techniques have been proposed, and while the public release of such embedding datasets is technically feasible, it has not been realized. One of the obstacles has been the integration of data from different cities and periods into a unified space without sharing raw location data. We address this issue by developing an anchoring method that establishes anchors within a shared embedding space. We publicly release this anchor dataset along with area embedding datasets from several periods in eight major Japanese cities. This dataset allows users to analyze urban usage patterns in Japanese cities and embed their urban dataset into the same embedding space using the anchoring method. Our key contributions include the development of the anchoring method, releasing area embedding datasets for Japanese cities, and providing tools for effective data utilization.","sentences":["We publicly release OpenUAS, a dataset of area embeddings based on urban usage patterns, including embeddings for over 1.3 million 50-meter square meshes covering a total area of 3,300 square kilometers.","This dataset is valuable for analyzing area functions in fields such as market analysis, urban planning, transportation infrastructure, and infection prediction.","It captures the characteristics of each area in the city, such as office districts and residential areas, by employing an area embedding technique that utilizes location information typically obtained by GPS.","Numerous area embedding techniques have been proposed, and while the public release of such embedding datasets is technically feasible, it has not been realized.","One of the obstacles has been the integration of data from different cities and periods into a unified space without sharing raw location data.","We address this issue by developing an anchoring method that establishes anchors within a shared embedding space.","We publicly release this anchor dataset along with area embedding datasets from several periods in eight major Japanese cities.","This dataset allows users to analyze urban usage patterns in Japanese cities and embed their urban dataset into the same embedding space using the anchoring method.","Our key contributions include the development of the anchoring method, releasing area embedding datasets for Japanese cities, and providing tools for effective data utilization."],"url":"http://arxiv.org/abs/2407.19872v1"}
{"created":"2024-07-29 10:42:17","title":"Fast Private Location-based Information Retrieval Over the Torus","abstract":"Location-based services offer immense utility, but also pose significant privacy risks. In response, we propose LocPIR, a novel framework using homomorphic encryption (HE), specifically the TFHE scheme, to preserve user location privacy when retrieving data from public clouds. Our system employs TFHE's expertise in non-polynomial evaluations, crucial for comparison operations. LocPIR showcases minimal client-server interaction, reduced memory overhead, and efficient throughput. Performance tests confirm its computational speed, making it a viable solution for practical scenarios, demonstrated via application to a COVID-19 alert model. Thus, LocPIR effectively addresses privacy concerns in location-based services, enabling secure data sharing from the public cloud.","sentences":["Location-based services offer immense utility, but also pose significant privacy risks.","In response, we propose LocPIR, a novel framework using homomorphic encryption (HE), specifically the TFHE scheme, to preserve user location privacy when retrieving data from public clouds.","Our system employs TFHE's expertise in non-polynomial evaluations, crucial for comparison operations.","LocPIR showcases minimal client-server interaction, reduced memory overhead, and efficient throughput.","Performance tests confirm its computational speed, making it a viable solution for practical scenarios, demonstrated via application to a COVID-19 alert model.","Thus, LocPIR effectively addresses privacy concerns in location-based services, enabling secure data sharing from the public cloud."],"url":"http://arxiv.org/abs/2407.19871v1"}
{"created":"2024-07-29 10:10:40","title":"Online Multi-Source Domain Adaptation through Gaussian Mixtures and Dataset Dictionary Learning","abstract":"This paper addresses the challenge of online multi-source domain adaptation (MSDA) in transfer learning, a scenario where one needs to adapt multiple, heterogeneous source domains towards a target domain that comes in a stream. We introduce a novel approach for the online fit of a Gaussian Mixture Model (GMM), based on the Wasserstein geometry of Gaussian measures. We build upon this method and recent developments in dataset dictionary learning for proposing a novel strategy in online MSDA. Experiments on the challenging Tennessee Eastman Process benchmark demonstrate that our approach is able to adapt \\emph{on the fly} to the stream of target domain data. Furthermore, our online GMM serves as a memory, representing the whole stream of data.","sentences":["This paper addresses the challenge of online multi-source domain adaptation (MSDA) in transfer learning, a scenario where one needs to adapt multiple, heterogeneous source domains towards a target domain that comes in a stream.","We introduce a novel approach for the online fit of a Gaussian Mixture Model (GMM), based on the Wasserstein geometry of Gaussian measures.","We build upon this method and recent developments in dataset dictionary learning for proposing a novel strategy in online MSDA.","Experiments on the challenging Tennessee Eastman Process benchmark demonstrate that our approach is able to adapt \\emph{on the fly} to the stream of target domain data.","Furthermore, our online GMM serves as a memory, representing the whole stream of data."],"url":"http://arxiv.org/abs/2407.19853v1"}
{"created":"2024-07-29 09:59:33","title":"Normality Addition via Normality Detection in Industrial Image Anomaly Detection Models","abstract":"The task of image anomaly detection (IAD) aims to identify deviations from normality in image data. These anomalies are patterns that deviate significantly from what the IAD model has learned from the data during training. However, in real-world scenarios, the criteria for what constitutes normality often change, necessitating the reclassification of previously anomalous instances as normal. To address this challenge, we propose a new scenario termed \"normality addition,\" involving the post-training adjustment of decision boundaries to incorporate new normalities. To address this challenge, we propose a method called Normality Addition via Normality Detection (NAND), leveraging a vision-language model. NAND performs normality detection which detect patterns related to the intended normality within images based on textual descriptions. We then modify the results of a pre-trained IAD model to implement this normality addition. Using the benchmark dataset in IAD, MVTec AD, we establish an evaluation protocol for the normality addition task and empirically demonstrate the effectiveness of the NAND method.","sentences":["The task of image anomaly detection (IAD) aims to identify deviations from normality in image data.","These anomalies are patterns that deviate significantly from what the IAD model has learned from the data during training.","However, in real-world scenarios, the criteria for what constitutes normality often change, necessitating the reclassification of previously anomalous instances as normal.","To address this challenge, we propose a new scenario termed \"normality addition,\" involving the post-training adjustment of decision boundaries to incorporate new normalities.","To address this challenge, we propose a method called Normality Addition via Normality Detection (NAND), leveraging a vision-language model.","NAND performs normality detection which detect patterns related to the intended normality within images based on textual descriptions.","We then modify the results of a pre-trained IAD model to implement this normality addition.","Using the benchmark dataset in IAD, MVTec AD, we establish an evaluation protocol for the normality addition task and empirically demonstrate the effectiveness of the NAND method."],"url":"http://arxiv.org/abs/2407.19849v1"}
{"created":"2024-07-29 09:55:40","title":"The Second Joint Workshop on Cross Reality","abstract":"The 2nd Joint Workshop on Cross Reality (JWCR'24), organized as part of ISMAR 2024, seeks to explore the burgeoning field of Cross Reality (CR), which encompasses the seamless integration and transition between various points on the reality-virtuality continuum (RVC) such as Virtual Reality (VR), Augmented Virtuality (AV), and Augmented Reality (AR). This hybrid workshop aims to build upon the foundation laid by the inaugural JWCR at ISMAR 2023, which successfully unified diverse CR research communities. The workshop will address key themes including CR visualization, interaction, user behavior, design, development, engineering, and collaboration. CR Visualization focuses on creating and displaying spatial data across the RVC, enabling users to navigate and interpret information fluidly. CR Interaction delves into natural user engagements using gestures, voice commands, and other advanced techniques to enhance immersion. The study of CR User Behavior and Experience investigates how users perceive and interact within these hybrid environments. Furthermore, CR Design and Development emphasizes creating effective CR applications using innovative processes and tools, while CR Collaboration examines methods for fostering teamwork in mixed reality settings.","sentences":["The 2nd Joint Workshop on Cross Reality (JWCR'24), organized as part of ISMAR 2024, seeks to explore the burgeoning field of Cross Reality (CR), which encompasses the seamless integration and transition between various points on the reality-virtuality continuum (RVC) such as Virtual Reality (VR), Augmented Virtuality (AV), and Augmented Reality (AR).","This hybrid workshop aims to build upon the foundation laid by the inaugural JWCR at ISMAR 2023, which successfully unified diverse CR research communities.","The workshop will address key themes including CR visualization, interaction, user behavior, design, development, engineering, and collaboration.","CR Visualization focuses on creating and displaying spatial data across the RVC, enabling users to navigate and interpret information fluidly.","CR Interaction delves into natural user engagements using gestures, voice commands, and other advanced techniques to enhance immersion.","The study of CR User Behavior and Experience investigates how users perceive and interact within these hybrid environments.","Furthermore, CR Design and Development emphasizes creating effective CR applications using innovative processes and tools, while CR Collaboration examines methods for fostering teamwork in mixed reality settings."],"url":"http://arxiv.org/abs/2407.19843v1"}
{"created":"2024-07-29 09:55:34","title":"Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability","abstract":"Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the application of LLMs across a wide range of contexts. However, neural networks in general, and LLMs in particular, are known to be vulnerable to adversarial attacks, where an imperceptible change to the input can mislead the output of the model. This is a serious concern that impedes the use of LLMs on high-stakes applications, such as healthcare, where a wrong prediction can imply serious consequences. Even though there are many efforts on making LLMs more robust to adversarial attacks, there are almost no works that study \\emph{how} and \\emph{where} these vulnerabilities that make LLMs prone to adversarial attacks happen. Motivated by these facts, we explore how to localize and understand vulnerabilities, and propose a method, based on Mechanistic Interpretability (MI) techniques, to guide this process. Specifically, this method enables us to detect vulnerabilities related to a concrete task by (i) obtaining the subset of the model that is responsible for that task, (ii) generating adversarial samples for that task, and (iii) using MI techniques together with the previous samples to discover and understand the possible vulnerabilities. We showcase our method on a pretrained GPT-2 Small model carrying out the task of predicting 3-letter acronyms to demonstrate its effectiveness on locating and understanding concrete vulnerabilities of the model.","sentences":["Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks.","Indeed, their generative abilities have aroused interest on the application of LLMs across a wide range of contexts.","However, neural networks in general, and LLMs in particular, are known to be vulnerable to adversarial attacks, where an imperceptible change to the input can mislead the output of the model.","This is a serious concern that impedes the use of LLMs on high-stakes applications, such as healthcare, where a wrong prediction can imply serious consequences.","Even though there are many efforts on making LLMs more robust to adversarial attacks, there are almost no works that study \\emph{how} and \\emph{where} these vulnerabilities that make LLMs prone to adversarial attacks happen.","Motivated by these facts, we explore how to localize and understand vulnerabilities, and propose a method, based on Mechanistic Interpretability (MI) techniques, to guide this process.","Specifically, this method enables us to detect vulnerabilities related to a concrete task by (i) obtaining the subset of the model that is responsible for that task, (ii) generating adversarial samples for that task, and (iii) using MI techniques together with the previous samples to discover and understand the possible vulnerabilities.","We showcase our method on a pretrained GPT-2 Small model carrying out the task of predicting 3-letter acronyms to demonstrate its effectiveness on locating and understanding concrete vulnerabilities of the model."],"url":"http://arxiv.org/abs/2407.19842v1"}
{"created":"2024-07-29 09:45:34","title":"ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation","abstract":"Classical Arabic represents a significant era, encompassing the golden age of Arab culture, philosophy, and scientific literature. With a broad consensus on the importance of translating these literatures to enrich knowledge dissemination across communities, the advent of large language models (LLMs) and translation systems offers promising tools to facilitate this goal. However, we have identified a scarcity of translation datasets in Classical Arabic, which are often limited in scope and topics, hindering the development of high-quality translation systems. In response, we present the ATHAR dataset, comprising 66,000 high-quality Classical Arabic to English translation samples that cover a wide array of subjects including science, culture, and philosophy. Furthermore, we assess the performance of current state-of-the-art LLMs under various settings, concluding that there is a need for such datasets in current systems. Our findings highlight how models can benefit from fine-tuning or incorporating this dataset into their pretraining pipelines. The dataset is publicly available on the HuggingFace Data Hub at \\url{https://huggingface.co/datasets/mohamed-khalil/ATHAR}.","sentences":["Classical Arabic represents a significant era, encompassing the golden age of Arab culture, philosophy, and scientific literature.","With a broad consensus on the importance of translating these literatures to enrich knowledge dissemination across communities, the advent of large language models (LLMs) and translation systems offers promising tools to facilitate this goal.","However, we have identified a scarcity of translation datasets in Classical Arabic, which are often limited in scope and topics, hindering the development of high-quality translation systems.","In response, we present the ATHAR dataset, comprising 66,000 high-quality Classical Arabic to English translation samples that cover a wide array of subjects including science, culture, and philosophy.","Furthermore, we assess the performance of current state-of-the-art LLMs under various settings, concluding that there is a need for such datasets in current systems.","Our findings highlight how models can benefit from fine-tuning or incorporating this dataset into their pretraining pipelines.","The dataset is publicly available on the HuggingFace Data Hub at \\url{https://huggingface.co/datasets/mohamed-khalil/ATHAR}."],"url":"http://arxiv.org/abs/2407.19835v1"}
{"created":"2024-07-29 09:31:19","title":"Generative Retrieval with Preference Optimization for E-commerce Search","abstract":"Generative retrieval introduces a groundbreaking paradigm to document retrieval by directly generating the identifier of a pertinent document in response to a specific query. This paradigm has demonstrated considerable benefits and potential, particularly in representation and generalization capabilities, within the context of large language models. However, it faces significant challenges in E-commerce search scenarios, including the complexity of generating detailed item titles from brief queries, the presence of noise in item titles with weak language order, issues with long-tail queries, and the interpretability of results. To address these challenges, we have developed an innovative framework for E-commerce search, called generative retrieval with preference optimization. This framework is designed to effectively learn and align an autoregressive model with target data, subsequently generating the final item through constraint-based beam search. By employing multi-span identifiers to represent raw item titles and transforming the task of generating titles from queries into the task of generating multi-span identifiers from queries, we aim to simplify the generation process. The framework further aligns with human preferences using click data and employs a constrained search method to identify key spans for retrieving the final item, thereby enhancing result interpretability. Our extensive experiments show that this framework achieves competitive performance on a real-world dataset, and online A/B tests demonstrate the superiority and effectiveness in improving conversion gains.","sentences":["Generative retrieval introduces a groundbreaking paradigm to document retrieval by directly generating the identifier of a pertinent document in response to a specific query.","This paradigm has demonstrated considerable benefits and potential, particularly in representation and generalization capabilities, within the context of large language models.","However, it faces significant challenges in E-commerce search scenarios, including the complexity of generating detailed item titles from brief queries, the presence of noise in item titles with weak language order, issues with long-tail queries, and the interpretability of results.","To address these challenges, we have developed an innovative framework for E-commerce search, called generative retrieval with preference optimization.","This framework is designed to effectively learn and align an autoregressive model with target data, subsequently generating the final item through constraint-based beam search.","By employing multi-span identifiers to represent raw item titles and transforming the task of generating titles from queries into the task of generating multi-span identifiers from queries, we aim to simplify the generation process.","The framework further aligns with human preferences using click data and employs a constrained search method to identify key spans for retrieving the final item, thereby enhancing result interpretability.","Our extensive experiments show that this framework achieves competitive performance on a real-world dataset, and online A/B tests demonstrate the superiority and effectiveness in improving conversion gains."],"url":"http://arxiv.org/abs/2407.19829v1"}
{"created":"2024-07-29 09:30:00","title":"Federated Learning based Latent Factorization of Tensors for Privacy-Preserving QoS Prediction","abstract":"In applications related to big data and service computing, dynamic connections tend to be encountered, especially the dynamic data of user-perspective quality of service (QoS) in Web services. They are transformed into high-dimensional and incomplete (HDI) tensors which include abundant temporal pattern information. Latent factorization of tensors (LFT) is an extremely efficient and typical approach for extracting such patterns from an HDI tensor. However, current LFT models require the QoS data to be maintained in a central place (e.g., a central server), which is impossible for increasingly privacy-sensitive users. To address this problem, this article creatively designs a federated learning based on latent factorization of tensors (FL-LFT). It builds a data-density -oriented federated learning model to enable isolated users to collaboratively train a global LFT model while protecting user's privacy. Extensive experiments on a QoS dataset collected from the real world verify that FL-LFT shows a remarkable increase in prediction accuracy when compared to state-of-the-art federated learning (FL) approaches.","sentences":["In applications related to big data and service computing, dynamic connections tend to be encountered, especially the dynamic data of user-perspective quality of service (QoS) in Web services.","They are transformed into high-dimensional and incomplete (HDI) tensors which include abundant temporal pattern information.","Latent factorization of tensors (LFT) is an extremely efficient and typical approach for extracting such patterns from an HDI tensor.","However, current LFT models require the QoS data to be maintained in a central place (e.g., a central server), which is impossible for increasingly privacy-sensitive users.","To address this problem, this article creatively designs a federated learning based on latent factorization of tensors (FL-LFT).","It builds a data-density -oriented federated learning model to enable isolated users to collaboratively train a global LFT model while protecting user's privacy.","Extensive experiments on a QoS dataset collected from the real world verify that FL-LFT shows a remarkable increase in prediction accuracy when compared to state-of-the-art federated learning (FL) approaches."],"url":"http://arxiv.org/abs/2407.19828v1"}
{"created":"2024-07-29 09:17:16","title":"Analyzing and reducing the synthetic-to-real transfer gap in Music Information Retrieval: the task of automatic drum transcription","abstract":"Automatic drum transcription is a critical tool in Music Information Retrieval for extracting and analyzing the rhythm of a music track, but it is limited by the size of the datasets available for training. A popular method used to increase the amount of data is by generating them synthetically from music scores rendered with virtual instruments. This method can produce a virtually infinite quantity of tracks, but empirical evidence shows that models trained on previously created synthetic datasets do not transfer well to real tracks. In this work, besides increasing the amount of data, we identify and evaluate three more strategies that practitioners can use to improve the realism of the generated data and, thus, narrow the synthetic-to-real transfer gap. To explore their efficacy, we used them to build a new synthetic dataset and then we measured how the performance of a model scales and, specifically, at what value it will stagnate when increasing the number of training tracks for different datasets. By doing this, we were able to prove that the aforementioned strategies contribute to make our dataset the one with the most realistic data distribution and the lowest synthetic-to-real transfer gap among the synthetic datasets we evaluated. We conclude by highlighting the limits of training with infinite data in drum transcription and we show how they can be overcome.","sentences":["Automatic drum transcription is a critical tool in Music Information Retrieval for extracting and analyzing the rhythm of a music track, but it is limited by the size of the datasets available for training.","A popular method used to increase the amount of data is by generating them synthetically from music scores rendered with virtual instruments.","This method can produce a virtually infinite quantity of tracks, but empirical evidence shows that models trained on previously created synthetic datasets do not transfer well to real tracks.","In this work, besides increasing the amount of data, we identify and evaluate three more strategies that practitioners can use to improve the realism of the generated data and, thus, narrow the synthetic-to-real transfer gap.","To explore their efficacy, we used them to build a new synthetic dataset and then we measured how the performance of a model scales and, specifically, at what value it will stagnate when increasing the number of training tracks for different datasets.","By doing this, we were able to prove that the aforementioned strategies contribute to make our dataset the one with the most realistic data distribution and the lowest synthetic-to-real transfer gap among the synthetic datasets we evaluated.","We conclude by highlighting the limits of training with infinite data in drum transcription and we show how they can be overcome."],"url":"http://arxiv.org/abs/2407.19823v1"}
{"created":"2024-07-29 09:01:06","title":"Imputation for prediction: beware of diminishing returns","abstract":"Missing values are prevalent across various fields, posing challenges for training and deploying predictive models. In this context, imputation is a common practice, driven by the hope that accurate imputations will enhance predictions. However, recent theoretical and empirical studies indicate that simple constant imputation can be consistent and competitive. This empirical study aims at clarifying if and when investing in advanced imputation methods yields significantly better predictions. Relating imputation and predictive accuracies across combinations of imputation and predictive models on 20 datasets, we show that imputation accuracy matters less i) when using expressive models, ii) when incorporating missingness indicators as complementary inputs, iii) matters much more for generated linear outcomes than for real-data outcomes. Interestingly, we also show that the use of the missingness indicator is beneficial to the prediction performance, even in MCAR scenarios. Overall, on real-data with powerful models, improving imputation only has a minor effect on prediction performance. Thus, investing in better imputations for improved predictions often offers limited benefits.","sentences":["Missing values are prevalent across various fields, posing challenges for training and deploying predictive models.","In this context, imputation is a common practice, driven by the hope that accurate imputations will enhance predictions.","However, recent theoretical and empirical studies indicate that simple constant imputation can be consistent and competitive.","This empirical study aims at clarifying if and when investing in advanced imputation methods yields significantly better predictions.","Relating imputation and predictive accuracies across combinations of imputation and predictive models on 20 datasets, we show that imputation accuracy matters less i) when using expressive models, ii) when incorporating missingness indicators as complementary inputs, iii) matters much more for generated linear outcomes than for real-data outcomes.","Interestingly, we also show that the use of the missingness indicator is beneficial to the prediction performance, even in MCAR scenarios.","Overall, on real-data with powerful models, improving imputation only has a minor effect on prediction performance.","Thus, investing in better imputations for improved predictions often offers limited benefits."],"url":"http://arxiv.org/abs/2407.19804v1"}
{"created":"2024-07-29 08:41:44","title":"Subsequence Pattern Matching with Segment Number Constraint","abstract":"This paper is concerned with subsequences that consist of limited numbers of segments. We call a subsequence \\emph{$f$-segmental} if it is composed of $f$ factors. More precisely, any string of the form $u_1 \\dots u_f$ is an $f$-segmental subsequence of a string $v_0u_1v_1 \\dots u_fv_f$. Since factors are $1$-segmental subsequences, this relativizes the notions of factors and subsequences. This paper studies some basic problems concerning $f$-segmental subsequences: namely, the longest common $f$-segmental subsequence problem and the $f$-segmental subsequence matching problem. The former asks the longest string that is an $f_i$-segmental subsequence of two input strings $T_i$ with $i=1,2$. The latter asks whether an input string $P$ is an $f$-segmental subsequence of the other input string $T$. We present polynomial-time algorithms for those problems and show that the one for the $f$-segmental subsequence matching problem is optimal modulo sub-polynomial factors under the strong exponential-time hypothesis.","sentences":["This paper is concerned with subsequences that consist of limited numbers of segments.","We call a subsequence \\emph{$f$-segmental} if it is composed of $f$ factors.","More precisely, any string of the form $u_1 \\dots u_f$ is an $f$-segmental subsequence of a string $v_0u_1v_1 \\dots u_fv_f$.","Since factors are $1$-segmental subsequences, this relativizes the notions of factors and subsequences.","This paper studies some basic problems concerning $f$-segmental subsequences: namely, the longest common $f$-segmental subsequence problem and the $f$-segmental subsequence matching problem.","The former asks the longest string that is an $f_i$-segmental subsequence of two input strings $T_i$ with $i=1,2$. The latter asks whether an input string $P$ is an $f$-segmental subsequence of the other input string","$T$. We present polynomial-time algorithms for those problems and show that the one for the $f$-segmental subsequence matching problem is optimal modulo sub-polynomial factors under the strong exponential-time hypothesis."],"url":"http://arxiv.org/abs/2407.19796v1"}
{"created":"2024-07-29 08:38:46","title":"VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks","abstract":"Domain generalizability is a crucial aspect of a deep learning model since it determines the capability of the model to perform well on data from unseen domains. However, research on the domain generalizability of deep learning models for vision-language tasks remains limited, primarily because of the lack of required datasets. To address these challenges, we propose VolDoGer: Vision-Language Dataset for Domain Generalization, a dedicated dataset designed for domain generalization that addresses three vision-language tasks: image captioning, visual question answering, and visual entailment. We constructed VolDoGer by extending LLM-based data annotation techniques to vision-language tasks, thereby alleviating the burden of recruiting human annotators. We evaluated the domain generalizability of various models, ranging from fine-tuned models to a recent multimodal large language model, through VolDoGer.","sentences":["Domain generalizability is a crucial aspect of a deep learning model since it determines the capability of the model to perform well on data from unseen domains.","However, research on the domain generalizability of deep learning models for vision-language tasks remains limited, primarily because of the lack of required datasets.","To address these challenges, we propose VolDoGer:","Vision-Language Dataset for Domain Generalization, a dedicated dataset designed for domain generalization that addresses three vision-language tasks: image captioning, visual question answering, and visual entailment.","We constructed VolDoGer by extending LLM-based data annotation techniques to vision-language tasks, thereby alleviating the burden of recruiting human annotators.","We evaluated the domain generalizability of various models, ranging from fine-tuned models to a recent multimodal large language model, through VolDoGer."],"url":"http://arxiv.org/abs/2407.19795v1"}
{"created":"2024-07-29 08:27:21","title":"Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting","abstract":"Alongside the continuous process of improving AI performance through the development of more sophisticated models, researchers have also focused their attention to the emerging concept of data-centric AI, which emphasizes the important role of data in a systematic machine learning training process. Nonetheless, the development of models has also continued apace. One result of this progress is the development of the Transformer Architecture, which possesses a high level of capability in multiple domains such as Natural Language Processing (NLP), Computer Vision (CV) and Time Series Forecasting (TSF). Its performance is, however, heavily dependent on input data preprocessing and output data evaluation, justifying a data-centric approach to future research. We argue that data-centric AI is essential for training AI models, particularly for transformer-based TSF models efficiently. However, there is a gap regarding the integration of transformer-based TSF and data-centric AI. This survey aims to pin down this gap via the extensive literature review based on the proposed taxonomy. We review the previous research works from a data-centric AI perspective and we intend to lay the foundation work for the future development of transformer-based architecture and data-centric AI.","sentences":["Alongside the continuous process of improving AI performance through the development of more sophisticated models, researchers have also focused their attention to the emerging concept of data-centric AI, which emphasizes the important role of data in a systematic machine learning training process.","Nonetheless, the development of models has also continued apace.","One result of this progress is the development of the Transformer Architecture, which possesses a high level of capability in multiple domains such as Natural Language Processing (NLP), Computer Vision (CV) and Time Series Forecasting (TSF).","Its performance is, however, heavily dependent on input data preprocessing and output data evaluation, justifying a data-centric approach to future research.","We argue that data-centric AI is essential for training AI models, particularly for transformer-based TSF models efficiently.","However, there is a gap regarding the integration of transformer-based TSF and data-centric AI.","This survey aims to pin down this gap via the extensive literature review based on the proposed taxonomy.","We review the previous research works from a data-centric AI perspective and we intend to lay the foundation work for the future development of transformer-based architecture and data-centric AI."],"url":"http://arxiv.org/abs/2407.19784v1"}
{"created":"2024-07-29 08:21:25","title":"Multimodal Large Language Models for Bioimage Analysis","abstract":"Rapid advancements in imaging techniques and analytical methods over the past decade have revolutionized our ability to comprehensively probe the biological world at multiple scales, pinpointing the type, quantity, location, and even temporal dynamics of biomolecules. The surge in data complexity and volume presents significant challenges in translating this wealth of information into knowledge. The recently emerged Multimodal Large Language Models (MLLMs) exhibit strong emergent capacities, such as understanding, analyzing, reasoning, and generalization. With these capabilities, MLLMs hold promise to extract intricate information from biological images and data obtained through various modalities, thereby expediting our biological understanding and aiding in the development of novel computational frameworks. Previously, such capabilities were mostly attributed to humans for interpreting and summarizing meaningful conclusions from comprehensive observations and analysis of biological images. However, the current development of MLLMs shows increasing promise in serving as intelligent assistants or agents for augmenting human researchers in biology research","sentences":["Rapid advancements in imaging techniques and analytical methods over the past decade have revolutionized our ability to comprehensively probe the biological world at multiple scales, pinpointing the type, quantity, location, and even temporal dynamics of biomolecules.","The surge in data complexity and volume presents significant challenges in translating this wealth of information into knowledge.","The recently emerged Multimodal Large Language Models (MLLMs) exhibit strong emergent capacities, such as understanding, analyzing, reasoning, and generalization.","With these capabilities, MLLMs hold promise to extract intricate information from biological images and data obtained through various modalities, thereby expediting our biological understanding and aiding in the development of novel computational frameworks.","Previously, such capabilities were mostly attributed to humans for interpreting and summarizing meaningful conclusions from comprehensive observations and analysis of biological images.","However, the current development of MLLMs shows increasing promise in serving as intelligent assistants or agents for augmenting human researchers in biology research"],"url":"http://arxiv.org/abs/2407.19778v1"}
{"created":"2024-07-29 08:20:49","title":"Revisiting Agnostic PAC Learning","abstract":"PAC learning, dating back to Valiant'84 and Vapnik and Chervonenkis'64,'74, is a classic model for studying supervised learning. In the agnostic setting, we have access to a hypothesis set $\\mathcal{H}$ and a training set of labeled samples $(x_1,y_1),\\dots,(x_n,y_n) \\in \\mathcal{X} \\times \\{-1,1\\}$ drawn i.i.d. from an unknown distribution $\\mathcal{D}$. The goal is to produce a classifier $h : \\mathcal{X} \\to \\{-1,1\\}$ that is competitive with the hypothesis $h^\\star_{\\mathcal{D}} \\in \\mathcal{H}$ having the least probability of mispredicting the label $y$ of a new sample $(x,y)\\sim \\mathcal{D}$.   Empirical Risk Minimization (ERM) is a natural learning algorithm, where one simply outputs the hypothesis from $\\mathcal{H}$ making the fewest mistakes on the training data. This simple algorithm is known to have an optimal error in terms of the VC-dimension of $\\mathcal{H}$ and the number of samples $n$.   In this work, we revisit agnostic PAC learning and first show that ERM is in fact sub-optimal if we treat the performance of the best hypothesis, denoted $\\tau:=\\Pr_{\\mathcal{D}}[h^\\star_{\\mathcal{D}}(x) \\neq y]$, as a parameter. Concretely we show that ERM, and any other proper learning algorithm, is sub-optimal by a $\\sqrt{\\ln(1/\\tau)}$ factor. We then complement this lower bound with the first learning algorithm achieving an optimal error for nearly the full range of $\\tau$. Our algorithm introduces several new ideas that we hope may find further applications in learning theory.","sentences":["PAC learning, dating back to Valiant'84 and Vapnik and Chervonenkis'64,'74, is a classic model for studying supervised learning.","In the agnostic setting, we have access to a hypothesis set $\\mathcal{H}$ and a training set of labeled samples $(x_1,y_1),\\dots,(x_n,y_n) \\in \\mathcal{X} \\times \\{-1,1\\}$ drawn i.i.d.","from an unknown distribution $\\mathcal{D}$. The goal is to produce a classifier $h : \\mathcal{X} \\to \\{-1,1\\}$ that is competitive with the hypothesis $h^\\star_{\\mathcal{D}} \\in \\mathcal{H}$ having the least probability of mispredicting the label $y$ of a new sample $(x,y)\\sim \\mathcal{D}$.   Empirical Risk Minimization (ERM) is a natural learning algorithm, where one simply outputs the hypothesis from $\\mathcal{H}$ making the fewest mistakes on the training data.","This simple algorithm is known to have an optimal error in terms of the VC-dimension of $\\mathcal{H}$ and the number of samples $n$.   In this work, we revisit agnostic PAC learning and first show that ERM is in fact sub-optimal if we treat the performance of the best hypothesis, denoted $\\tau:=\\Pr_{\\mathcal{D}}[h^\\star_{\\mathcal{D}}(x) \\neq y]$, as a parameter.","Concretely we show that ERM, and any other proper learning algorithm, is sub-optimal by a $\\sqrt{\\ln(1/\\tau)}$ factor.","We then complement this lower bound with the first learning algorithm achieving an optimal error for nearly the full range of $\\tau$. Our algorithm introduces several new ideas that we hope may find further applications in learning theory."],"url":"http://arxiv.org/abs/2407.19777v1"}
{"created":"2024-07-29 08:20:04","title":"Advancement of metal oxide nanomaterials on agri-food fronts","abstract":"The application of metal oxide nanomaterials (MOx NMs) in the agrifood industry offers innovative solutions that can facilitate a paradigm shift in a sector that is currently facing challenges in meeting the growing requirements for food production, while safeguarding the environment from the impacts of current agriculture practices. This review comprehensively illustrates recent advancements and applications of MOx for sustainable practices in the food and agricultural industries and environmental preservation. Relevant published data point out that MOx NMs can be tailored for specific properties, enabling advanced design concepts with improved features for various applications in the agrifood industry. Applications include nano-agrochemical formulation, control of food quality through nanosensors, and smart food packaging. Furthermore, recent research suggests MOx's vital role in addressing environmental challenges by removing toxic elements from contaminated soil and water. This mitigates the environmental effects of widespread agrichemical use and creates a more favorable environment for plant growth. The review also discusses potential barriers, particularly regarding MOx toxicity and risk evaluation. Fundamental concerns about possible adverse effects on human health and the environment must be addressed to establish an appropriate regulatory framework for nano metal oxide-based food and agricultural products.","sentences":["The application of metal oxide nanomaterials (MOx NMs) in the agrifood industry offers innovative solutions that can facilitate a paradigm shift in a sector that is currently facing challenges in meeting the growing requirements for food production, while safeguarding the environment from the impacts of current agriculture practices.","This review comprehensively illustrates recent advancements and applications of MOx for sustainable practices in the food and agricultural industries and environmental preservation.","Relevant published data point out that MOx NMs can be tailored for specific properties, enabling advanced design concepts with improved features for various applications in the agrifood industry.","Applications include nano-agrochemical formulation, control of food quality through nanosensors, and smart food packaging.","Furthermore, recent research suggests MOx's vital role in addressing environmental challenges by removing toxic elements from contaminated soil and water.","This mitigates the environmental effects of widespread agrichemical use and creates a more favorable environment for plant growth.","The review also discusses potential barriers, particularly regarding MOx toxicity and risk evaluation.","Fundamental concerns about possible adverse effects on human health and the environment must be addressed to establish an appropriate regulatory framework for nano metal oxide-based food and agricultural products."],"url":"http://arxiv.org/abs/2407.19776v1"}
{"created":"2024-07-29 08:18:48","title":"Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference","abstract":"The rapid growth of large-scale AI models, particularly large language models has brought significant challenges in data privacy, computational resources, and accessibility. Traditional centralized architectures often struggle to meet required data security and scalability needs which hinders the democratization of AI systems. Nesa introduces a model-agnostic sharding framework designed for decentralized AI inference. Our framework uses blockchain-based sequential deep neural network sharding to distribute computational tasks across a diverse network of nodes based on a personalised heuristic and routing mechanism. This enables efficient distributed training and inference for recent large-scale models even on consumer-grade hardware. We use compression techniques like dynamic blockwise quantization and mixed matrix decomposition to reduce data transfer and memory needs. We also integrate robust security measures, including hardware-based trusted execution environments to ensure data integrity and confidentiality. Evaluating our system across various natural language processing and vision tasks shows that these compression strategies do not compromise model accuracy. Our results highlight the potential to democratize access to cutting-edge AI technologies by enabling secure and efficient inference on a decentralized network.","sentences":["The rapid growth of large-scale AI models, particularly large language models has brought significant challenges in data privacy, computational resources, and accessibility.","Traditional centralized architectures often struggle to meet required data security and scalability needs which hinders the democratization of AI systems.","Nesa introduces a model-agnostic sharding framework designed for decentralized AI inference.","Our framework uses blockchain-based sequential deep neural network sharding to distribute computational tasks across a diverse network of nodes based on a personalised heuristic and routing mechanism.","This enables efficient distributed training and inference for recent large-scale models even on consumer-grade hardware.","We use compression techniques like dynamic blockwise quantization and mixed matrix decomposition to reduce data transfer and memory needs.","We also integrate robust security measures, including hardware-based trusted execution environments to ensure data integrity and confidentiality.","Evaluating our system across various natural language processing and vision tasks shows that these compression strategies do not compromise model accuracy.","Our results highlight the potential to democratize access to cutting-edge AI technologies by enabling secure and efficient inference on a decentralized network."],"url":"http://arxiv.org/abs/2407.19775v1"}
{"created":"2024-07-29 08:17:05","title":"Garment Animation NeRF with Color Editing","abstract":"Generating high-fidelity garment animations through traditional workflows, from modeling to rendering, is both tedious and expensive. These workflows often require repetitive steps in response to updates in character motion, rendering viewpoint changes, or appearance edits. Although recent neural rendering offers an efficient solution for computationally intensive processes, it struggles with rendering complex garment animations containing fine wrinkle details and realistic garment-and-body occlusions, while maintaining structural consistency across frames and dense view rendering. In this paper, we propose a novel approach to directly synthesize garment animations from body motion sequences without the need for an explicit garment proxy. Our approach infers garment dynamic features from body motion, providing a preliminary overview of garment structure. Simultaneously, we capture detailed features from synthesized reference images of the garment's front and back, generated by a pre-trained image model. These features are then used to construct a neural radiance field that renders the garment animation video. Additionally, our technique enables garment recoloring by decomposing its visual elements. We demonstrate the generalizability of our method across unseen body motions and camera views, ensuring detailed structural consistency. Furthermore, we showcase its applicability to color editing on both real and synthetic garment data. Compared to existing neural rendering techniques, our method exhibits qualitative and quantitative improvements in garment dynamics and wrinkle detail modeling. Code is available at \\url{https://github.com/wrk226/GarmentAnimationNeRF}.","sentences":["Generating high-fidelity garment animations through traditional workflows, from modeling to rendering, is both tedious and expensive.","These workflows often require repetitive steps in response to updates in character motion, rendering viewpoint changes, or appearance edits.","Although recent neural rendering offers an efficient solution for computationally intensive processes, it struggles with rendering complex garment animations containing fine wrinkle details and realistic garment-and-body occlusions, while maintaining structural consistency across frames and dense view rendering.","In this paper, we propose a novel approach to directly synthesize garment animations from body motion sequences without the need for an explicit garment proxy.","Our approach infers garment dynamic features from body motion, providing a preliminary overview of garment structure.","Simultaneously, we capture detailed features from synthesized reference images of the garment's front and back, generated by a pre-trained image model.","These features are then used to construct a neural radiance field that renders the garment animation video.","Additionally, our technique enables garment recoloring by decomposing its visual elements.","We demonstrate the generalizability of our method across unseen body motions and camera views, ensuring detailed structural consistency.","Furthermore, we showcase its applicability to color editing on both real and synthetic garment data.","Compared to existing neural rendering techniques, our method exhibits qualitative and quantitative improvements in garment dynamics and wrinkle detail modeling.","Code is available at \\url{https://github.com/wrk226/GarmentAnimationNeRF}."],"url":"http://arxiv.org/abs/2407.19774v1"}
{"created":"2024-07-29 08:11:20","title":"Generating Unseen Code Tests In Infinitum","abstract":"Large Language Models (LLMs) are used for many tasks, including those related to coding. An important aspect of being able to utilize LLMs is the ability to assess their fitness for specific usages. The common practice is to evaluate LLMs against a set of benchmarks. While benchmarks provide a sound foundation for evaluation and comparison of alternatives, they suffer from the well-known weakness of leaking into the training data \\cite{Xu2024Benchmarking}. We present a method for creating benchmark variations that generalize across coding tasks and programming languages, and may also be applied to in-house code bases. Our approach enables ongoing generation of test-data thus mitigating the leaking into the training data issue. We implement one benchmark, called \\textit{auto-regression}, for the task of text-to-code generation in Python. Auto-regression is specifically created to aid in debugging and in tracking model generation changes as part of the LLM regression testing process.","sentences":["Large Language Models (LLMs) are used for many tasks, including those related to coding.","An important aspect of being able to utilize LLMs is the ability to assess their fitness for specific usages.","The common practice is to evaluate LLMs against a set of benchmarks.","While benchmarks provide a sound foundation for evaluation and comparison of alternatives, they suffer from the well-known weakness of leaking into the training data \\cite{Xu2024Benchmarking}.","We present a method for creating benchmark variations that generalize across coding tasks and programming languages, and may also be applied to in-house code bases.","Our approach enables ongoing generation of test-data thus mitigating the leaking into the training data issue.","We implement one benchmark, called \\textit{auto-regression}, for the task of text-to-code generation in Python.","Auto-regression is specifically created to aid in debugging and in tracking model generation changes as part of the LLM regression testing process."],"url":"http://arxiv.org/abs/2407.19772v1"}
{"created":"2024-07-29 07:51:43","title":"Legal Minds, Algorithmic Decisions: How LLMs Apply Constitutional Principles in Complex Scenarios","abstract":"In this paper, we conduct an empirical analysis of how large language models (LLMs), specifically GPT-4, interpret constitutional principles in complex decision-making scenarios. We examine rulings from the Italian Constitutional Court on bioethics issues that involve trade-offs between competing values and compare model-generated legal arguments on these issues to those presented by the State, the Court, and the applicants. Our results indicate that GPT-4 consistently aligns more closely with progressive interpretations of the Constitution, often overlooking competing values and mirroring the applicants' views rather than the more conservative perspectives of the State or the Court's moderate positions. Our experiments reveal a distinct tendency of GPT-4 to favor progressive legal interpretations, underscoring the influence of underlying data biases. We thus underscore the importance of testing alignment in real-world scenarios and considering the implications of deploying LLMs in decision-making processes.","sentences":["In this paper, we conduct an empirical analysis of how large language models (LLMs), specifically GPT-4, interpret constitutional principles in complex decision-making scenarios.","We examine rulings from the Italian Constitutional Court on bioethics issues that involve trade-offs between competing values and compare model-generated legal arguments on these issues to those presented by the State, the Court, and the applicants.","Our results indicate that GPT-4 consistently aligns more closely with progressive interpretations of the Constitution, often overlooking competing values and mirroring the applicants' views rather than the more conservative perspectives of the State or the Court's moderate positions.","Our experiments reveal a distinct tendency of GPT-4 to favor progressive legal interpretations, underscoring the influence of underlying data biases.","We thus underscore the importance of testing alignment in real-world scenarios and considering the implications of deploying LLMs in decision-making processes."],"url":"http://arxiv.org/abs/2407.19760v1"}
{"created":"2024-07-29 07:30:41","title":"Contextuality Helps Representation Learning for Generalized Category Discovery","abstract":"This paper introduces a novel approach to Generalized Category Discovery (GCD) by leveraging the concept of contextuality to enhance the identification and classification of categories in unlabeled datasets. Drawing inspiration from human cognition's ability to recognize objects within their context, we propose a dual-context based method.   Our model integrates two levels of contextuality: instance-level, where nearest-neighbor contexts are utilized for contrastive learning, and cluster-level, employing prototypical contrastive learning based on category prototypes. The integration of the contextual information effectively improves the feature learning and thereby the classification accuracy of all categories, which better deals with the real-world datasets. Different from the traditional semi-supervised and novel category discovery techniques, our model focuses on a more realistic and challenging scenario where both known and novel categories are present in the unlabeled data. Extensive experimental results on several benchmark data sets demonstrate that the proposed model outperforms the state-of-the-art. Code is available at: https://github.com/Clarence-CV/Contexuality-GCD","sentences":["This paper introduces a novel approach to Generalized Category Discovery (GCD) by leveraging the concept of contextuality to enhance the identification and classification of categories in unlabeled datasets.","Drawing inspiration from human cognition's ability to recognize objects within their context, we propose a dual-context based method.   ","Our model integrates two levels of contextuality: instance-level, where nearest-neighbor contexts are utilized for contrastive learning, and cluster-level, employing prototypical contrastive learning based on category prototypes.","The integration of the contextual information effectively improves the feature learning and thereby the classification accuracy of all categories, which better deals with the real-world datasets.","Different from the traditional semi-supervised and novel category discovery techniques, our model focuses on a more realistic and challenging scenario where both known and novel categories are present in the unlabeled data.","Extensive experimental results on several benchmark data sets demonstrate that the proposed model outperforms the state-of-the-art.","Code is available at: https://github.com/Clarence-CV/Contexuality-GCD"],"url":"http://arxiv.org/abs/2407.19752v1"}
{"created":"2024-07-29 07:07:37","title":"KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations in Dialogical Argument Mining","abstract":"Dialogical Argument Mining(DialAM) is an important branch of Argument Mining(AM). DialAM-2024 is a shared task focusing on dialogical argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes. To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment the training data in both stages and introduce context in Stage 2. We successfully completed the task and achieved good results. Our team Pokemon ranked 1st in the ARI Focused score and 4th in the Global Focused score.","sentences":["Dialogical Argument Mining(DialAM) is an important branch of Argument Mining(AM).","DialAM-2024 is a shared task focusing on dialogical argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes.","To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2.","We also augment the training data in both stages and introduce context in Stage 2.","We successfully completed the task and achieved good results.","Our team Pokemon ranked 1st in the ARI Focused score and 4th in the Global Focused score."],"url":"http://arxiv.org/abs/2407.19740v1"}
{"created":"2024-07-29 06:17:41","title":"PersonalityScanner: Exploring the Validity of Personality Assessment Based on Multimodal Signals in Virtual Reality","abstract":"Human cognition significantly influences expressed behavior and is intrinsically tied to authentic personality traits. Personality assessment plays a pivotal role in various fields, including psychology, education, social media, etc. However, traditional self-report questionnaires can only provide data based on what individuals are willing and able to disclose, thereby lacking objective. Moreover, automated measurements and peer assessments demand significant human effort and resources. In this paper, given the advantages of the Virtual Reality (VR) technique, we develop a VR simulator -- PersonalityScanner, to stimulate cognitive processes and simulate daily behaviors based on an immersive and interactive simulation environment, in which participants carry out a battery of engaging tasks that formulate a natural story of first-day at work. Through this simulator, we collect a synchronous multi-modal dataset with ten modalities, including first/third-person video, audio, text, eye tracking, facial microexpression, pose, depth data, log, and inertial measurement unit. By systematically examining the contributions of different modalities on revealing personality, we demonstrate the superior performance and effectiveness of PersonalityScanner.","sentences":["Human cognition significantly influences expressed behavior and is intrinsically tied to authentic personality traits.","Personality assessment plays a pivotal role in various fields, including psychology, education, social media, etc.","However, traditional self-report questionnaires can only provide data based on what individuals are willing and able to disclose, thereby lacking objective.","Moreover, automated measurements and peer assessments demand significant human effort and resources.","In this paper, given the advantages of the Virtual Reality (VR) technique, we develop a VR simulator -- PersonalityScanner, to stimulate cognitive processes and simulate daily behaviors based on an immersive and interactive simulation environment, in which participants carry out a battery of engaging tasks that formulate a natural story of first-day at work.","Through this simulator, we collect a synchronous multi-modal dataset with ten modalities, including first/third-person video, audio, text, eye tracking, facial microexpression, pose, depth data, log, and inertial measurement unit.","By systematically examining the contributions of different modalities on revealing personality, we demonstrate the superior performance and effectiveness of PersonalityScanner."],"url":"http://arxiv.org/abs/2407.19728v1"}
{"created":"2024-07-29 06:17:33","title":"Adaptive Utilization of Cross-scenario Information for Multi-scenario Recommendation","abstract":"Recommender system of the e-commerce platform usually serves multiple business scenarios. Multi-scenario Recommendation (MSR) is an important topic that improves ranking performance by leveraging information from different scenarios. Recent methods for MSR mostly construct scenario shared or specific modules to model commonalities and differences among scenarios. However, when the amount of data among scenarios is skewed or data in some scenarios is extremely sparse, it is difficult to learn scenario-specific parameters well. Besides, simple sharing of information from other scenarios may result in a negative transfer. In this paper, we propose a unified model named Cross-Scenario Information Interaction (CSII) to serve all scenarios by a mixture of scenario-dominated experts. Specifically, we propose a novel method to select highly transferable features in data instances. Then, we propose an attention-based aggregator module, which can adaptively extract relative knowledge from cross-scenario. Experiments on the production dataset verify the superiority of our method. Online A/B test in Meituan Waimai APP also shows a significant performance gain, leading to an average improvement in GMV (Gross Merchandise Value) of 1.0% for overall scenarios.","sentences":["Recommender system of the e-commerce platform usually serves multiple business scenarios.","Multi-scenario Recommendation (MSR) is an important topic that improves ranking performance by leveraging information from different scenarios.","Recent methods for MSR mostly construct scenario shared or specific modules to model commonalities and differences among scenarios.","However, when the amount of data among scenarios is skewed or data in some scenarios is extremely sparse, it is difficult to learn scenario-specific parameters well.","Besides, simple sharing of information from other scenarios may result in a negative transfer.","In this paper, we propose a unified model named Cross-Scenario Information Interaction (CSII) to serve all scenarios by a mixture of scenario-dominated experts.","Specifically, we propose a novel method to select highly transferable features in data instances.","Then, we propose an attention-based aggregator module, which can adaptively extract relative knowledge from cross-scenario.","Experiments on the production dataset verify the superiority of our method.","Online A/B test in Meituan Waimai APP also shows a significant performance gain, leading to an average improvement in GMV (Gross Merchandise Value) of 1.0% for overall scenarios."],"url":"http://arxiv.org/abs/2407.19727v1"}
{"created":"2024-07-29 06:13:28","title":"Do Text-to-Vis Benchmarks Test Real Use of Visualisations?","abstract":"Large language models are able to generate code for visualisations in response to user requests. This is a useful application, and an appealing one for NLP research because plots of data provide grounding for language. However, there are relatively few benchmarks, and it is unknown whether those that exist are representative of what people do in practice. This paper aims to answer that question through an empirical study comparing benchmark datasets and code from public repositories. Our findings reveal a substantial gap in datasets, with evaluations not testing the same distribution of chart types, attributes, and the number of actions. The only representative dataset requires modification to become an end-to-end and practical benchmark. This shows that new, more benchmarks are needed to support the development of systems that truly address users' visualisation needs. These observations will guide future data creation, highlighting which features hold genuine significance for users.","sentences":["Large language models are able to generate code for visualisations in response to user requests.","This is a useful application, and an appealing one for NLP research because plots of data provide grounding for language.","However, there are relatively few benchmarks, and it is unknown whether those that exist are representative of what people do in practice.","This paper aims to answer that question through an empirical study comparing benchmark datasets and code from public repositories.","Our findings reveal a substantial gap in datasets, with evaluations not testing the same distribution of chart types, attributes, and the number of actions.","The only representative dataset requires modification to become an end-to-end and practical benchmark.","This shows that new, more benchmarks are needed to support the development of systems that truly address users' visualisation needs.","These observations will guide future data creation, highlighting which features hold genuine significance for users."],"url":"http://arxiv.org/abs/2407.19726v1"}
{"created":"2024-07-29 06:03:13","title":"Revolutionizing Urban Safety Perception Assessments: Integrating Multimodal Large Language Models with Street View Images","abstract":"Measuring urban safety perception is an important and complex task that traditionally relies heavily on human resources. This process often involves extensive field surveys, manual data collection, and subjective assessments, which can be time-consuming, costly, and sometimes inconsistent. Street View Images (SVIs), along with deep learning methods, provide a way to realize large-scale urban safety detection. However, achieving this goal often requires extensive human annotation to train safety ranking models, and the architectural differences between cities hinder the transferability of these models. Thus, a fully automated method for conducting safety evaluations is essential. Recent advances in multimodal large language models (MLLMs) have demonstrated powerful reasoning and analytical capabilities. Cutting-edge models, e.g., GPT-4 have shown surprising performance in many tasks. We employed these models for urban safety ranking on a human-annotated anchor set and validated that the results from MLLMs align closely with human perceptions. Additionally, we proposed a method based on the pre-trained Contrastive Language-Image Pre-training (CLIP) feature and K-Nearest Neighbors (K-NN) retrieval to quickly assess the safety index of the entire city. Experimental results show that our method outperforms existing training needed deep learning approaches, achieving efficient and accurate urban safety evaluations. The proposed automation for urban safety perception assessment is a valuable tool for city planners, policymakers, and researchers aiming to improve urban environments.","sentences":["Measuring urban safety perception is an important and complex task that traditionally relies heavily on human resources.","This process often involves extensive field surveys, manual data collection, and subjective assessments, which can be time-consuming, costly, and sometimes inconsistent.","Street View Images (SVIs), along with deep learning methods, provide a way to realize large-scale urban safety detection.","However, achieving this goal often requires extensive human annotation to train safety ranking models, and the architectural differences between cities hinder the transferability of these models.","Thus, a fully automated method for conducting safety evaluations is essential.","Recent advances in multimodal large language models (MLLMs) have demonstrated powerful reasoning and analytical capabilities.","Cutting-edge models, e.g., GPT-4 have shown surprising performance in many tasks.","We employed these models for urban safety ranking on a human-annotated anchor set and validated that the results from MLLMs align closely with human perceptions.","Additionally, we proposed a method based on the pre-trained Contrastive Language-Image Pre-training (CLIP) feature and K-Nearest Neighbors (K-NN) retrieval to quickly assess the safety index of the entire city.","Experimental results show that our method outperforms existing training needed deep learning approaches, achieving efficient and accurate urban safety evaluations.","The proposed automation for urban safety perception assessment is a valuable tool for city planners, policymakers, and researchers aiming to improve urban environments."],"url":"http://arxiv.org/abs/2407.19719v1"}
{"created":"2024-07-29 05:26:57","title":"TVDiag: A Task-oriented and View-invariant Failure Diagnosis Framework with Multimodal Data","abstract":"Microservice-based systems often suffer from reliability issues due to their intricate interactions and expanding scale. With the rapid growth of observability techniques, various methods have been proposed to achieve failure diagnosis, including root cause localization and failure type identification, by leveraging diverse monitoring data such as logs, metrics, or traces. However, traditional failure diagnosis methods that use single-modal data can hardly cover all failure scenarios due to the restricted information. Several failure diagnosis methods have been recently proposed to integrate multimodal data based on deep learning. These methods, however, tend to combine modalities indiscriminately and treat them equally in failure diagnosis, ignoring the relationship between specific modalities and different diagnostic tasks. This oversight hinders the effective utilization of the unique advantages offered by each modality. To address the limitation, we propose \\textit{TVDiag}, a multimodal failure diagnosis framework for locating culprit microservice instances and identifying their failure types (e.g., Net-packets Corruption) in microservice-based systems. \\textit{TVDiag} employs task-oriented learning to enhance the potential advantages of each modality and establishes cross-modal associations based on contrastive learning to extract view-invariant failure information. Furthermore, we develop a graph-level data augmentation strategy that randomly inactivates the observability of some normal microservice instances during training to mitigate the shortage of training data. Experimental results show that \\textit{TVDiag} outperforms state-of-the-art methods in multimodal failure diagnosis, achieving at least a 55.94\\% higher $HR@1$ accuracy and over a 4.08\\% increase in F1-score across two datasets.","sentences":["Microservice-based systems often suffer from reliability issues due to their intricate interactions and expanding scale.","With the rapid growth of observability techniques, various methods have been proposed to achieve failure diagnosis, including root cause localization and failure type identification, by leveraging diverse monitoring data such as logs, metrics, or traces.","However, traditional failure diagnosis methods that use single-modal data can hardly cover all failure scenarios due to the restricted information.","Several failure diagnosis methods have been recently proposed to integrate multimodal data based on deep learning.","These methods, however, tend to combine modalities indiscriminately and treat them equally in failure diagnosis, ignoring the relationship between specific modalities and different diagnostic tasks.","This oversight hinders the effective utilization of the unique advantages offered by each modality.","To address the limitation, we propose \\textit{TVDiag}, a multimodal failure diagnosis framework for locating culprit microservice instances and identifying their failure types (e.g., Net-packets Corruption) in microservice-based systems.","\\textit{TVDiag} employs task-oriented learning to enhance the potential advantages of each modality and establishes cross-modal associations based on contrastive learning to extract view-invariant failure information.","Furthermore, we develop a graph-level data augmentation strategy that randomly inactivates the observability of some normal microservice instances during training to mitigate the shortage of training data.","Experimental results show that \\textit{TVDiag} outperforms state-of-the-art methods in multimodal failure diagnosis, achieving at least a 55.94\\% higher $HR@1$ accuracy and over a 4.08\\% increase in F1-score across two datasets."],"url":"http://arxiv.org/abs/2407.19711v1"}
{"created":"2024-07-29 05:00:48","title":"CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare","abstract":"The rapid progress in Large Language Models (LLMs) has prompted the creation of numerous benchmarks to evaluate their capabilities.This study focuses on the Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset diversity and distribution in supervised fine-tuning (SFT) may enhance LLM performance.Remarkably, We successfully trained a smaller base model to achieve scores comparable to larger models, indicating that a diverse and well-distributed dataset can optimize performance regardless of model size.This study suggests that even smaller models may reach high performance levels with carefully curated and varied datasets.By integrating a wide range of instructional content, our approach addresses potential issues such as data quality inconsistencies. Our results imply that a broader spectrum of training data may enhance a model's ability to generalize and perform effectively across different medical scenarios, highlighting the importance of dataset quality and diversity in fine-tuning processes.","sentences":["The rapid progress in Large Language Models (LLMs) has prompted the creation of numerous benchmarks to evaluate their capabilities.","This study focuses on the Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset diversity and distribution in supervised fine-tuning (SFT) may enhance LLM performance.","Remarkably, We successfully trained a smaller base model to achieve scores comparable to larger models, indicating that a diverse and well-distributed dataset can optimize performance regardless of model size.","This study suggests that even smaller models may reach high performance levels with carefully curated and varied datasets.","By integrating a wide range of instructional content, our approach addresses potential issues such as data quality inconsistencies.","Our results imply that a broader spectrum of training data may enhance a model's ability to generalize and perform effectively across different medical scenarios, highlighting the importance of dataset quality and diversity in fine-tuning processes."],"url":"http://arxiv.org/abs/2407.19705v1"}
{"created":"2024-07-29 04:55:30","title":"Efficient Byzantine-Robust and Provably Privacy-Preserving Federated Learning","abstract":"Federated learning (FL) is an emerging distributed learning paradigm without sharing participating clients' private data. However, existing works show that FL is vulnerable to both Byzantine (security) attacks and data reconstruction (privacy) attacks. Almost all the existing FL defenses only address one of the two attacks. A few defenses address the two attacks, but they are not efficient and effective enough. We propose BPFL, an efficient Byzantine-robust and provably privacy-preserving FL method that addresses all the issues. Specifically, we draw on state-of-the-art Byzantine-robust FL methods and use similarity metrics to measure the robustness of each participating client in FL. The validity of clients are formulated as circuit constraints on similarity metrics and verified via a zero-knowledge proof. Moreover, the client models are masked by a shared random vector, which is generated based on homomorphic encryption. In doing so, the server receives the masked client models rather than the true ones, which are proven to be private. BPFL is also efficient due to the usage of non-interactive zero-knowledge proof. Experimental results on various datasets show that our BPFL is efficient, Byzantine-robust, and privacy-preserving.","sentences":["Federated learning (FL) is an emerging distributed learning paradigm without sharing participating clients' private data.","However, existing works show that FL is vulnerable to both Byzantine (security) attacks and data reconstruction (privacy) attacks.","Almost all the existing FL defenses only address one of the two attacks.","A few defenses address the two attacks, but they are not efficient and effective enough.","We propose BPFL, an efficient Byzantine-robust and provably privacy-preserving FL method that addresses all the issues.","Specifically, we draw on state-of-the-art Byzantine-robust FL methods and use similarity metrics to measure the robustness of each participating client in FL.","The validity of clients are formulated as circuit constraints on similarity metrics and verified via a zero-knowledge proof.","Moreover, the client models are masked by a shared random vector, which is generated based on homomorphic encryption.","In doing so, the server receives the masked client models rather than the true ones, which are proven to be private.","BPFL is also efficient due to the usage of non-interactive zero-knowledge proof.","Experimental results on various datasets show that our BPFL is efficient, Byzantine-robust, and privacy-preserving."],"url":"http://arxiv.org/abs/2407.19703v1"}
{"created":"2024-07-29 04:30:38","title":"High-Order Fusion Graph Contrastive Learning for Recommendation","abstract":"Self-supervised learning (SSL) has recently attracted significant attention in the field of recommender systems. Contrastive learning (CL) stands out as a major SSL paradigm due to its robust ability to generate self-supervised signals. Mainstream graph contrastive learning (GCL)-based methods typically implement CL by creating contrastive views through various data augmentation techniques. Despite these methods are effective, we argue that there still exist several challenges: i) Data augmentation (e.g., discarding edges or adding noise) necessitates additional graph convolution (GCN) or modeling operations, which are highly time-consuming and potentially harm the embedding quality. ii) Existing CL-based methods use traditional CL objectives to capture self-supervised signals. However, few studies have explored obtaining CL objectives from more perspectives and have attempted to fuse the varying signals from these CL objectives to enhance recommendation performance.   To overcome these challenges, we propose a High-Order Fusion Graph Contrastive Learning (HFGCL) framework for recommendation. Specifically, we discards the data augmentations and instead high-order information from GCN process to create contrastive views. Additionally, to integrate self-supervised signals from various CL objectives, we propose an advanced CL objective. By ensuring that positive pairs are distanced from negative samples derived from both contrastive views, we effectively fuse self-supervised signals from distinct CL objectives, thereby enhancing the mutual information between positive pairs. Experimental results on three public datasets demonstrate the superior effectiveness of HFGCL compared to the state-of-the-art baselines.","sentences":["Self-supervised learning (SSL) has recently attracted significant attention in the field of recommender systems.","Contrastive learning (CL) stands out as a major SSL paradigm due to its robust ability to generate self-supervised signals.","Mainstream graph contrastive learning (GCL)-based methods typically implement CL by creating contrastive views through various data augmentation techniques.","Despite these methods are effective, we argue that there still exist several challenges: i) Data augmentation (e.g., discarding edges or adding noise) necessitates additional graph convolution (GCN) or modeling operations, which are highly time-consuming and potentially harm the embedding quality.","ii) Existing CL-based methods use traditional CL objectives to capture self-supervised signals.","However, few studies have explored obtaining CL objectives from more perspectives and have attempted to fuse the varying signals from these CL objectives to enhance recommendation performance.   ","To overcome these challenges, we propose a High-Order Fusion Graph Contrastive Learning (HFGCL) framework for recommendation.","Specifically, we discards the data augmentations and instead high-order information from GCN process to create contrastive views.","Additionally, to integrate self-supervised signals from various CL objectives, we propose an advanced CL objective.","By ensuring that positive pairs are distanced from negative samples derived from both contrastive views, we effectively fuse self-supervised signals from distinct CL objectives, thereby enhancing the mutual information between positive pairs.","Experimental results on three public datasets demonstrate the superior effectiveness of HFGCL compared to the state-of-the-art baselines."],"url":"http://arxiv.org/abs/2407.19692v1"}
{"created":"2024-07-29 04:08:15","title":"Billiards Sports Analytics: Datasets and Tasks","abstract":"Nowadays, it becomes a common practice to capture some data of sports games with devices such as GPS sensors and cameras and then use the data to perform various analyses on sports games, including tactics discovery, similar game retrieval, performance study, etc. While this practice has been conducted to many sports such as basketball and soccer, it remains largely unexplored on the billiards sports, which is mainly due to the lack of publicly available datasets. Motivated by this, we collect a dataset of billiards sports, which includes the layouts (i.e., locations) of billiards balls after performing break shots, called break shot layouts, the traces of the balls as a result of strikes (in the form of trajectories), and detailed statistics and performance indicators. We then study and develop techniques for three tasks on the collected dataset, including (1) prediction and (2) generation on the layouts data, and (3) similar billiards layout retrieval on the layouts data, which can serve different users such as coaches, players and fans. We conduct extensive experiments on the collected dataset and the results show that our methods perform effectively and efficiently.","sentences":["Nowadays, it becomes a common practice to capture some data of sports games with devices such as GPS sensors and cameras and then use the data to perform various analyses on sports games, including tactics discovery, similar game retrieval, performance study, etc.","While this practice has been conducted to many sports such as basketball and soccer, it remains largely unexplored on the billiards sports, which is mainly due to the lack of publicly available datasets.","Motivated by this, we collect a dataset of billiards sports, which includes the layouts (i.e., locations) of billiards balls after performing break shots, called break shot layouts, the traces of the balls as a result of strikes (in the form of trajectories), and detailed statistics and performance indicators.","We then study and develop techniques for three tasks on the collected dataset, including (1) prediction and (2) generation on the layouts data, and (3) similar billiards layout retrieval on the layouts data, which can serve different users such as coaches, players and fans.","We conduct extensive experiments on the collected dataset and the results show that our methods perform effectively and efficiently."],"url":"http://arxiv.org/abs/2407.19686v1"}
{"created":"2024-07-29 03:58:37","title":"Application of Computer Technology in Financial Investment","abstract":"In order to understand the application of computer technology in financial investment, the author proposes a research on the application of computer technology in financial investment. The author used user transaction data from a certain online payment platform as a sample, with a total of 284908 sample records, including 593 positive samples (fraud samples) and 285214 negative samples (normal samples), to conduct an empirical study on user fraud detection based on data mining. In this process, facing the problem of imbalanced positive and negative samples, the author proposes to use the Under Sampling method to construct sub samples, and then perform feature scaling, outlier detection, feature screening and other processing on the sub samples. Then, four classification models, logistic regression, K-nearest neighbor algorithm, decision tree, and support vector machine, are trained on the processed sub samples. The prediction results of the four models are evaluated, and the results show that the recall rate, Fl score, and AUC value of the logistic regression model are the highest, indicating that the detection method based on computer data mining is practical and feasible.","sentences":["In order to understand the application of computer technology in financial investment, the author proposes a research on the application of computer technology in financial investment.","The author used user transaction data from a certain online payment platform as a sample, with a total of 284908 sample records, including 593 positive samples (fraud samples) and 285214 negative samples (normal samples), to conduct an empirical study on user fraud detection based on data mining.","In this process, facing the problem of imbalanced positive and negative samples, the author proposes to use the Under Sampling method to construct sub samples, and then perform feature scaling, outlier detection, feature screening and other processing on the sub samples.","Then, four classification models, logistic regression, K-nearest neighbor algorithm, decision tree, and support vector machine, are trained on the processed sub samples.","The prediction results of the four models are evaluated, and the results show that the recall rate, Fl score, and AUC value of the logistic regression model are the highest, indicating that the detection method based on computer data mining is practical and feasible."],"url":"http://arxiv.org/abs/2407.19684v1"}
{"created":"2024-07-29 03:55:52","title":"Revisiting the robustness of post-hoc interpretability methods","abstract":"Post-hoc interpretability methods play a critical role in explainable artificial intelligence (XAI), as they pinpoint portions of data that a trained deep learning model deemed important to make a decision. However, different post-hoc interpretability methods often provide different results, casting doubts on their accuracy. For this reason, several evaluation strategies have been proposed to understand the accuracy of post-hoc interpretability. Many of these evaluation strategies provide a coarse-grained assessment -- i.e., they evaluate how the performance of the model degrades on average by corrupting different data points across multiple samples. While these strategies are effective in selecting the post-hoc interpretability method that is most reliable on average, they fail to provide a sample-level, also referred to as fine-grained, assessment. In other words, they do not measure the robustness of post-hoc interpretability methods. We propose an approach and two new metrics to provide a fine-grained assessment of post-hoc interpretability methods. We show that the robustness is generally linked to its coarse-grained performance.","sentences":["Post-hoc interpretability methods play a critical role in explainable artificial intelligence (XAI), as they pinpoint portions of data that a trained deep learning model deemed important to make a decision.","However, different post-hoc interpretability methods often provide different results, casting doubts on their accuracy.","For this reason, several evaluation strategies have been proposed to understand the accuracy of post-hoc interpretability.","Many of these evaluation strategies provide a coarse-grained assessment -- i.e., they evaluate how the performance of the model degrades on average by corrupting different data points across multiple samples.","While these strategies are effective in selecting the post-hoc interpretability method that is most reliable on average, they fail to provide a sample-level, also referred to as fine-grained, assessment.","In other words, they do not measure the robustness of post-hoc interpretability methods.","We propose an approach and two new metrics to provide a fine-grained assessment of post-hoc interpretability methods.","We show that the robustness is generally linked to its coarse-grained performance."],"url":"http://arxiv.org/abs/2407.19683v1"}
{"created":"2024-07-29 03:53:14","title":"Motion Manifold Flow Primitives for Language-Guided Trajectory Generation","abstract":"Developing text-based robot trajectory generation models is made particularly difficult by the small dataset size, high dimensionality of the trajectory space, and the inherent complexity of the text-conditional motion distribution. Recent manifold learning-based methods have partially addressed the dimensionality and dataset size issues, but struggle with the complex text-conditional distribution. In this paper we propose a text-based trajectory generation model that attempts to address all three challenges while relying on only a handful of demonstration trajectory data. Our key idea is to leverage recent flow-based models capable of capturing complex conditional distributions, not directly in the high-dimensional trajectory space, but rather in the low-dimensional latent coordinate space of the motion manifold, with deliberately designed regularization terms to ensure smoothness of motions and robustness to text variations. We show that our {\\it Motion Manifold Flow Primitive (MMFP)} framework can accurately generate qualitatively distinct motions for a wide range of text inputs, significantly outperforming existing methods.","sentences":["Developing text-based robot trajectory generation models is made particularly difficult by the small dataset size, high dimensionality of the trajectory space, and the inherent complexity of the text-conditional motion distribution.","Recent manifold learning-based methods have partially addressed the dimensionality and dataset size issues, but struggle with the complex text-conditional distribution.","In this paper we propose a text-based trajectory generation model that attempts to address all three challenges while relying on only a handful of demonstration trajectory data.","Our key idea is to leverage recent flow-based models capable of capturing complex conditional distributions, not directly in the high-dimensional trajectory space, but rather in the low-dimensional latent coordinate space of the motion manifold, with deliberately designed regularization terms to ensure smoothness of motions and robustness to text variations.","We show that our {\\it Motion Manifold Flow Primitive (MMFP)} framework can accurately generate qualitatively distinct motions for a wide range of text inputs, significantly outperforming existing methods."],"url":"http://arxiv.org/abs/2407.19681v1"}
{"created":"2024-07-29 03:43:16","title":"Navigating the United States Legislative Landscape on Voice Privacy: Existing Laws, Proposed Bills, Protection for Children, and Synthetic Data for AI","abstract":"Privacy is a hot topic for policymakers across the globe, including the United States. Evolving advances in AI and emerging concerns about the misuse of personal data have pushed policymakers to draft legislation on trustworthy AI and privacy protection for its citizens. This paper presents the state of the privacy legislation at the U.S. Congress and outlines how voice data is considered as part of the legislation definition. This paper also reviews additional privacy protection for children. This paper presents a holistic review of enacted and proposed privacy laws, and consideration for voice data, including guidelines for processing children's data, in those laws across the fifty U.S. states. As a groundbreaking alternative to actual human data, ethically generated synthetic data allows much flexibility to keep AI innovation in progress. Given the consideration of synthetic data in AI legislation by policymakers to be relatively new, as compared to that of privacy laws, this paper reviews regulatory considerations for synthetic data.","sentences":["Privacy is a hot topic for policymakers across the globe, including the United States.","Evolving advances in AI and emerging concerns about the misuse of personal data have pushed policymakers to draft legislation on trustworthy AI and privacy protection for its citizens.","This paper presents the state of the privacy legislation at the U.S. Congress and outlines how voice data is considered as part of the legislation definition.","This paper also reviews additional privacy protection for children.","This paper presents a holistic review of enacted and proposed privacy laws, and consideration for voice data, including guidelines for processing children's data, in those laws across the fifty U.S. states.","As a groundbreaking alternative to actual human data, ethically generated synthetic data allows much flexibility to keep AI innovation in progress.","Given the consideration of synthetic data in AI legislation by policymakers to be relatively new, as compared to that of privacy laws, this paper reviews regulatory considerations for synthetic data."],"url":"http://arxiv.org/abs/2407.19677v1"}
{"created":"2024-07-29 03:36:39","title":"Semi-Supervised Teacher-Reference-Student Architecture for Action Quality Assessment","abstract":"Existing action quality assessment (AQA) methods often require a large number of label annotations for fully supervised learning, which are laborious and expensive. In practice, the labeled data are difficult to obtain because the AQA annotation process requires domain-specific expertise. In this paper, we propose a novel semi-supervised method, which can be utilized for better assessment of the AQA task by exploiting a large amount of unlabeled data and a small portion of labeled data. Differing from the traditional teacher-student network, we propose a teacher-reference-student architecture to learn both unlabeled and labeled data, where the teacher network and the reference network are used to generate pseudo-labels for unlabeled data to supervise the student network. Specifically, the teacher predicts pseudo-labels by capturing high-level features of unlabeled data. The reference network provides adequate supervision of the student network by referring to additional action information. Moreover, we introduce confidence memory to improve the reliability of pseudo-labels by storing the most accurate ever output of the teacher network and reference network. To validate our method, we conduct extensive experiments on three AQA benchmark datasets. Experimental results show that our method achieves significant improvements and outperforms existing semi-supervised AQA methods.","sentences":["Existing action quality assessment (AQA) methods often require a large number of label annotations for fully supervised learning, which are laborious and expensive.","In practice, the labeled data are difficult to obtain because the AQA annotation process requires domain-specific expertise.","In this paper, we propose a novel semi-supervised method, which can be utilized for better assessment of the AQA task by exploiting a large amount of unlabeled data and a small portion of labeled data.","Differing from the traditional teacher-student network, we propose a teacher-reference-student architecture to learn both unlabeled and labeled data, where the teacher network and the reference network are used to generate pseudo-labels for unlabeled data to supervise the student network.","Specifically, the teacher predicts pseudo-labels by capturing high-level features of unlabeled data.","The reference network provides adequate supervision of the student network by referring to additional action information.","Moreover, we introduce confidence memory to improve the reliability of pseudo-labels by storing the most accurate ever output of the teacher network and reference network.","To validate our method, we conduct extensive experiments on three AQA benchmark datasets.","Experimental results show that our method achieves significant improvements and outperforms existing semi-supervised AQA methods."],"url":"http://arxiv.org/abs/2407.19675v1"}
{"created":"2024-07-29 03:10:15","title":"Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity","abstract":"Traffic accidents pose a significant risk to human health and property safety. Therefore, to prevent traffic accidents, predicting their risks has garnered growing interest. We argue that a desired prediction solution should demonstrate resilience to the complexity of traffic accidents. In particular, it should adequately consider the regional background, accurately capture both spatial proximity and semantic similarity, and effectively address the sparsity of traffic accidents. However, these factors are often overlooked or difficult to incorporate. In this paper, we propose a novel multi-granularity hierarchical spatio-temporal network. Initially, we innovate by incorporating remote sensing data, facilitating the creation of hierarchical multi-granularity structure and the comprehension of regional background. We construct multiple high-level risk prediction tasks to enhance model's ability to cope with sparsity. Subsequently, to capture both spatial proximity and semantic similarity, region feature and multi-view graph undergo encoding processes to distill effective representations. Additionally, we propose message passing and adaptive temporal attention module that bridges different granularities and dynamically captures time correlations inherent in traffic accident patterns. At last, a multivariate hierarchical loss function is devised considering the complexity of the prediction purpose. Extensive experiments on two real datasets verify the superiority of our model against the state-of-the-art methods.","sentences":["Traffic accidents pose a significant risk to human health and property safety.","Therefore, to prevent traffic accidents, predicting their risks has garnered growing interest.","We argue that a desired prediction solution should demonstrate resilience to the complexity of traffic accidents.","In particular, it should adequately consider the regional background, accurately capture both spatial proximity and semantic similarity, and effectively address the sparsity of traffic accidents.","However, these factors are often overlooked or difficult to incorporate.","In this paper, we propose a novel multi-granularity hierarchical spatio-temporal network.","Initially, we innovate by incorporating remote sensing data, facilitating the creation of hierarchical multi-granularity structure and the comprehension of regional background.","We construct multiple high-level risk prediction tasks to enhance model's ability to cope with sparsity.","Subsequently, to capture both spatial proximity and semantic similarity, region feature and multi-view graph undergo encoding processes to distill effective representations.","Additionally, we propose message passing and adaptive temporal attention module that bridges different granularities and dynamically captures time correlations inherent in traffic accident patterns.","At last, a multivariate hierarchical loss function is devised considering the complexity of the prediction purpose.","Extensive experiments on two real datasets verify the superiority of our model against the state-of-the-art methods."],"url":"http://arxiv.org/abs/2407.19668v1"}
{"created":"2024-07-29 02:56:19","title":"Take A Step Back: Rethinking the Two Stages in Visual Reasoning","abstract":"Visual reasoning, as a prominent research area, plays a crucial role in AI by facilitating concept formation and interaction with the world. However, current works are usually carried out separately on small datasets thus lacking generalization ability. Through rigorous evaluation of diverse benchmarks, we demonstrate the shortcomings of existing ad-hoc methods in achieving cross-domain reasoning and their tendency to data bias fitting. In this paper, we revisit visual reasoning with a two-stage perspective: (1) symbolization and (2) logical reasoning given symbols or their representations. We find that the reasoning stage is better at generalization than symbolization. Thus, it is more efficient to implement symbolization via separated encoders for different data domains while using a shared reasoner. Given our findings, we establish design principles for visual reasoning frameworks following the separated symbolization and shared reasoning. The proposed two-stage framework achieves impressive generalization ability on various visual reasoning tasks, including puzzles, physical prediction, and visual question answering (VQA), encompassing both 2D and 3D modalities. We believe our insights will pave the way for generalizable visual reasoning.","sentences":["Visual reasoning, as a prominent research area, plays a crucial role in AI by facilitating concept formation and interaction with the world.","However, current works are usually carried out separately on small datasets thus lacking generalization ability.","Through rigorous evaluation of diverse benchmarks, we demonstrate the shortcomings of existing ad-hoc methods in achieving cross-domain reasoning and their tendency to data bias fitting.","In this paper, we revisit visual reasoning with a two-stage perspective: (1) symbolization and (2) logical reasoning given symbols or their representations.","We find that the reasoning stage is better at generalization than symbolization.","Thus, it is more efficient to implement symbolization via separated encoders for different data domains while using a shared reasoner.","Given our findings, we establish design principles for visual reasoning frameworks following the separated symbolization and shared reasoning.","The proposed two-stage framework achieves impressive generalization ability on various visual reasoning tasks, including puzzles, physical prediction, and visual question answering (VQA), encompassing both 2D and 3D modalities.","We believe our insights will pave the way for generalizable visual reasoning."],"url":"http://arxiv.org/abs/2407.19666v1"}
{"created":"2024-07-29 02:52:59","title":"Towards Detecting IoT Event Spoofing Attacks Using Time-Series Classification","abstract":"Internet of Things (IoT) devices have grown in popularity since they can directly interact with the real world. Home automation systems automate these interactions. IoT events are crucial to these systems' decision-making but are often unreliable. Security vulnerabilities allow attackers to impersonate events. Using statistical machine learning, IoT event fingerprints from deployed sensors have been used to detect spoofed events. Multivariate temporal data from these sensors has structural and temporal properties that statistical machine learning cannot learn. These schemes' accuracy depends on the knowledge base; the larger, the more accurate. However, the lack of huge datasets with enough samples of each IoT event in the nascent field of IoT can be a bottleneck. In this work, we deployed advanced machine learning to detect event-spoofing assaults. The temporal nature of sensor data lets us discover important patterns with fewer events. Our rigorous investigation of a publicly available real-world dataset indicates that our time-series-based solution technique learns temporal features from sensor data faster than earlier work, even with a 100- or 500-fold smaller training sample, making it a realistic IoT solution.","sentences":["Internet of Things (IoT) devices have grown in popularity since they can directly interact with the real world.","Home automation systems automate these interactions.","IoT events are crucial to these systems' decision-making but are often unreliable.","Security vulnerabilities allow attackers to impersonate events.","Using statistical machine learning, IoT event fingerprints from deployed sensors have been used to detect spoofed events.","Multivariate temporal data from these sensors has structural and temporal properties that statistical machine learning cannot learn.","These schemes' accuracy depends on the knowledge base; the larger, the more accurate.","However, the lack of huge datasets with enough samples of each IoT event in the nascent field of IoT can be a bottleneck.","In this work, we deployed advanced machine learning to detect event-spoofing assaults.","The temporal nature of sensor data lets us discover important patterns with fewer events.","Our rigorous investigation of a publicly available real-world dataset indicates that our time-series-based solution technique learns temporal features from sensor data faster than earlier work, even with a 100- or 500-fold smaller training sample, making it a realistic IoT solution."],"url":"http://arxiv.org/abs/2407.19662v1"}
{"created":"2024-07-29 02:49:55","title":"Towards a Knowledge guided Multimodal Foundation Model for Spatio-Temporal Remote Sensing Applications","abstract":"In recent years, there is increased interest in foundation models for geoscience due to vast amount of earth observing satellite imagery. Existing remote sensing foundation models make use of the various sources of spectral imagery to create large models pretrained on masked reconstruction task. The embeddings from these foundation models are then used for various downstream remote sensing applications. In this paper we propose a foundational modeling framework for remote sensing geoscience applications, that goes beyond these traditional single modality masked autoencoder family of foundation models. This framework leverages the knowledge guided principles that the spectral imagery captures the impact of the physical drivers on the environmental system, and that the relationship between them is governed by the characteristics of the system. Specifically, our method, called MultiModal Variable Step Forecasting (MM-VSF), uses mutlimodal data (spectral imagery and weather) as its input and a variable step forecasting task as its pretraining objective. In our evaluation we show forecasting of satellite imagery using weather can be used as an effective pretraining task for foundation models. We further show the effectiveness of the embeddings from MM-VSF on the downstream task of pixel wise crop mapping, when compared with a model trained in the traditional setting of single modality input and masked reconstruction based pretraining.","sentences":["In recent years, there is increased interest in foundation models for geoscience due to vast amount of earth observing satellite imagery.","Existing remote sensing foundation models make use of the various sources of spectral imagery to create large models pretrained on masked reconstruction task.","The embeddings from these foundation models are then used for various downstream remote sensing applications.","In this paper we propose a foundational modeling framework for remote sensing geoscience applications, that goes beyond these traditional single modality masked autoencoder family of foundation models.","This framework leverages the knowledge guided principles that the spectral imagery captures the impact of the physical drivers on the environmental system, and that the relationship between them is governed by the characteristics of the system.","Specifically, our method, called MultiModal Variable Step Forecasting (MM-VSF), uses mutlimodal data (spectral imagery and weather) as its input and a variable step forecasting task as its pretraining objective.","In our evaluation we show forecasting of satellite imagery using weather can be used as an effective pretraining task for foundation models.","We further show the effectiveness of the embeddings from MM-VSF on the downstream task of pixel wise crop mapping, when compared with a model trained in the traditional setting of single modality input and masked reconstruction based pretraining."],"url":"http://arxiv.org/abs/2407.19660v1"}
{"created":"2024-07-29 02:39:17","title":"AI-Driven Healthcare: A Survey on Ensuring Fairness and Mitigating Bias","abstract":"Artificial intelligence (AI) is rapidly advancing in healthcare, enhancing the efficiency and effectiveness of services across various specialties, including cardiology, ophthalmology, dermatology, emergency medicine, etc. AI applications have significantly improved diagnostic accuracy, treatment personalization, and patient outcome predictions by leveraging technologies such as machine learning, neural networks, and natural language processing. However, these advancements also introduce substantial ethical and fairness challenges, particularly related to biases in data and algorithms. These biases can lead to disparities in healthcare delivery, affecting diagnostic accuracy and treatment outcomes across different demographic groups. This survey paper examines the integration of AI in healthcare, highlighting critical challenges related to bias and exploring strategies for mitigation. We emphasize the necessity of diverse datasets, fairness-aware algorithms, and regulatory frameworks to ensure equitable healthcare delivery. The paper concludes with recommendations for future research, advocating for interdisciplinary approaches, transparency in AI decision-making, and the development of innovative and inclusive AI applications.","sentences":["Artificial intelligence (AI) is rapidly advancing in healthcare, enhancing the efficiency and effectiveness of services across various specialties, including cardiology, ophthalmology, dermatology, emergency medicine, etc.","AI applications have significantly improved diagnostic accuracy, treatment personalization, and patient outcome predictions by leveraging technologies such as machine learning, neural networks, and natural language processing.","However, these advancements also introduce substantial ethical and fairness challenges, particularly related to biases in data and algorithms.","These biases can lead to disparities in healthcare delivery, affecting diagnostic accuracy and treatment outcomes across different demographic groups.","This survey paper examines the integration of AI in healthcare, highlighting critical challenges related to bias and exploring strategies for mitigation.","We emphasize the necessity of diverse datasets, fairness-aware algorithms, and regulatory frameworks to ensure equitable healthcare delivery.","The paper concludes with recommendations for future research, advocating for interdisciplinary approaches, transparency in AI decision-making, and the development of innovative and inclusive AI applications."],"url":"http://arxiv.org/abs/2407.19655v1"}
{"created":"2024-07-29 02:04:29","title":"Foundations for Unfairness in Anomaly Detection -- Case Studies in Facial Imaging Data","abstract":"Deep anomaly detection (AD) is perhaps the most controversial of data analytic tasks as it identifies entities that are then specifically targeted for further investigation or exclusion. Also controversial is the application of AI to facial imaging data. This work explores the intersection of these two areas to understand two core questions: \"Who\" these algorithms are being unfair to and equally important \"Why\". Recent work has shown that deep AD can be unfair to different groups despite being unsupervised with a recent study showing that for portraits of people: men of color are far more likely to be chosen to be outliers. We study the two main categories of AD algorithms: autoencoder-based and single-class-based which effectively try to compress all the instances with those that can not be easily compressed being deemed to be outliers. We experimentally verify sources of unfairness such as the under-representation of a group (e.g. people of color are relatively rare), spurious group features (e.g. men are often photographed with hats), and group labeling noise (e.g. race is subjective). We conjecture that lack of compressibility is the main foundation and the others cause it but experimental results show otherwise and we present a natural hierarchy amongst them.","sentences":["Deep anomaly detection (AD) is perhaps the most controversial of data analytic tasks as it identifies entities that are then specifically targeted for further investigation or exclusion.","Also controversial is the application of AI to facial imaging data.","This work explores the intersection of these two areas to understand two core questions: \"Who\" these algorithms are being unfair to and equally important \"Why\".","Recent work has shown that deep AD can be unfair to different groups despite being unsupervised with a recent study showing that for portraits of people: men of color are far more likely to be chosen to be outliers.","We study the two main categories of AD algorithms: autoencoder-based and single-class-based which effectively try to compress all the instances with those that can not be easily compressed being deemed to be outliers.","We experimentally verify sources of unfairness such as the under-representation of a group (e.g. people of color are relatively rare), spurious group features (e.g. men are often photographed with hats), and group labeling noise (e.g. race is subjective).","We conjecture that lack of compressibility is the main foundation and the others cause it but experimental results show otherwise and we present a natural hierarchy amongst them."],"url":"http://arxiv.org/abs/2407.19646v1"}
{"created":"2024-07-29 01:57:10","title":"Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation","abstract":"Knowledge graphs (KGs) are essential in applications such as network alignment, question-answering, and recommender systems (RSs) since they offer structured relational data that facilitate the inference of indirect relationships. However, the development of KG-based RSs capable of processing user inputs in natural language faces significant challenges. Firstly, natural language processing units must effectively handle the ambiguity and variability in human language to interpret user intents accurately. Secondly, the system must precisely identify and link entities, like product names, to their corresponding nodes in KGs. To overcome these challenges, supported by Lenovo, we developed a novel chatbot called \"Prometheus,\" which integrates a KG with a large language model (LLM), specifically designed for recommending computer components. This chatbot can accurately decode user requests and deliver personalized recommendations derived from KGs, ensuring precise comprehension and response to their computer setup needs.","sentences":["Knowledge graphs (KGs) are essential in applications such as network alignment, question-answering, and recommender systems (RSs) since they offer structured relational data that facilitate the inference of indirect relationships.","However, the development of KG-based RSs capable of processing user inputs in natural language faces significant challenges.","Firstly, natural language processing units must effectively handle the ambiguity and variability in human language to interpret user intents accurately.","Secondly, the system must precisely identify and link entities, like product names, to their corresponding nodes in KGs.","To overcome these challenges, supported by Lenovo, we developed a novel chatbot called \"Prometheus,\" which integrates a KG with a large language model (LLM), specifically designed for recommending computer components.","This chatbot can accurately decode user requests and deliver personalized recommendations derived from KGs, ensuring precise comprehension and response to their computer setup needs."],"url":"http://arxiv.org/abs/2407.19643v1"}
{"created":"2024-07-29 01:46:44","title":"Segmented Private Data Aggregation in the Multi-message Shuffle Model","abstract":"The shuffle model of differential privacy (DP) offers compelling privacy-utility trade-offs in decentralized settings (e.g., internet of things, mobile edge networks). Particularly, the multi-message shuffle model, where each user may contribute multiple messages, has shown that accuracy can approach that of the central model of DP. However, existing studies typically assume a uniform privacy protection level for all users, which may deter conservative users from participating and prevent liberal users from contributing more information, thereby reducing the overall data utility, such as the accuracy of aggregated statistics. In this work, we pioneer the study of segmented private data aggregation within the multi-message shuffle model of DP, introducing flexible privacy protection for users and enhanced utility for the aggregation server. Our framework not only protects users' data but also anonymizes their privacy level choices to prevent potential data leakage from these choices. To optimize the privacy-utility-communication trade-offs, we explore approximately optimal configurations for the number of blanket messages and conduct almost tight privacy amplification analyses within the shuffle model. Through extensive experiments, we demonstrate that our segmented multi-message shuffle framework achieves a reduction of about 50\\% in estimation error compared to existing approaches, significantly enhancing both privacy and utility.","sentences":["The shuffle model of differential privacy (DP) offers compelling privacy-utility trade-offs in decentralized settings (e.g., internet of things, mobile edge networks).","Particularly, the multi-message shuffle model, where each user may contribute multiple messages, has shown that accuracy can approach that of the central model of DP.","However, existing studies typically assume a uniform privacy protection level for all users, which may deter conservative users from participating and prevent liberal users from contributing more information, thereby reducing the overall data utility, such as the accuracy of aggregated statistics.","In this work, we pioneer the study of segmented private data aggregation within the multi-message shuffle model of DP, introducing flexible privacy protection for users and enhanced utility for the aggregation server.","Our framework not only protects users' data but also anonymizes their privacy level choices to prevent potential data leakage from these choices.","To optimize the privacy-utility-communication trade-offs, we explore approximately optimal configurations for the number of blanket messages and conduct almost tight privacy amplification analyses within the shuffle model.","Through extensive experiments, we demonstrate that our segmented multi-message shuffle framework achieves a reduction of about 50\\% in estimation error compared to existing approaches, significantly enhancing both privacy and utility."],"url":"http://arxiv.org/abs/2407.19639v1"}
{"created":"2024-07-29 01:43:26","title":"STT-RAM-based Hierarchical In-Memory Computing","abstract":"In-memory computing promises to overcome the von Neumann bottleneck in computer systems by performing computations directly within the memory. Previous research has suggested using Spin-Transfer Torque RAM (STT-RAM) for in-memory computing due to its non-volatility, low leakage power, high density, endurance, and commercial viability. This paper explores hierarchical in-memory computing, where different levels of the memory hierarchy are augmented with processing elements to optimize workload execution. The paper investigates processing in memory (PiM) using non-volatile STT-RAM and processing in cache (PiC) using volatile STT-RAM with relaxed retention, which helps mitigate STT-RAM's write latency and energy overheads. We analyze tradeoffs and overheads associated with data movement for PiC versus write overheads for PiM using STT-RAMs for various workloads. We examine workload characteristics, such as computational intensity and CPU-dependent workloads with limited instruction-level parallelism, and their impact on PiC/PiM tradeoffs. Using these workloads, we evaluate computing in STT-RAM versus SRAM at different cache hierarchy levels and explore the potential of heterogeneous STT-RAM cache architectures with various retention times for PiC and CPU-based computing. Our experiments reveal significant advantages of STT-RAM-based PiC over PiM for specific workloads. Finally, we describe open research problems in hierarchical in-memory computing architectures to further enhance this paradigm.","sentences":["In-memory computing promises to overcome the von Neumann bottleneck in computer systems by performing computations directly within the memory.","Previous research has suggested using Spin-Transfer Torque RAM (STT-RAM) for in-memory computing due to its non-volatility, low leakage power, high density, endurance, and commercial viability.","This paper explores hierarchical in-memory computing, where different levels of the memory hierarchy are augmented with processing elements to optimize workload execution.","The paper investigates processing in memory (PiM) using non-volatile STT-RAM and processing in cache (PiC) using volatile STT-RAM with relaxed retention, which helps mitigate STT-RAM's write latency and energy overheads.","We analyze tradeoffs and overheads associated with data movement for PiC versus write overheads for PiM using STT-RAMs for various workloads.","We examine workload characteristics, such as computational intensity and CPU-dependent workloads with limited instruction-level parallelism, and their impact on PiC/PiM tradeoffs.","Using these workloads, we evaluate computing in STT-RAM versus SRAM at different cache hierarchy levels and explore the potential of heterogeneous STT-RAM cache architectures with various retention times for PiC and CPU-based computing.","Our experiments reveal significant advantages of STT-RAM-based PiC over PiM for specific workloads.","Finally, we describe open research problems in hierarchical in-memory computing architectures to further enhance this paradigm."],"url":"http://arxiv.org/abs/2407.19637v1"}
{"created":"2024-07-29 01:31:45","title":"OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale","abstract":"Optimization problems are pervasive in sectors from manufacturing and distribution to healthcare. However, most such problems are still solved heuristically by hand rather than optimally by state-of-the art solvers because the expertise required to formulate and solve these problems limits the widespread adoption of optimization tools and techniques. We introduce a Large Language Model (LLM)-based system designed to formulate and solve (mixed integer) linear programming problems from their natural language descriptions. Our system is capable of developing mathematical models, writing and debugging solver code, evaluating the generated solutions, and improving efficiency and correctness of its model and code based on these evaluations. OptiMUS-0.3 utilizes a modular structure to process problems, allowing it to handle problems with long descriptions and complex data without long prompts. Experiments demonstrate that OptiMUS-0.3 outperforms existing state-of-the-art methods on easy datasets by more than 12% and on hard datasets (including a new dataset, NLP4LP, released with this paper that features long and complex problems) by more than 8%.","sentences":["Optimization problems are pervasive in sectors from manufacturing and distribution to healthcare.","However, most such problems are still solved heuristically by hand rather than optimally by state-of-the art solvers because the expertise required to formulate and solve these problems limits the widespread adoption of optimization tools and techniques.","We introduce a Large Language Model (LLM)-based system designed to formulate and solve (mixed integer) linear programming problems from their natural language descriptions.","Our system is capable of developing mathematical models, writing and debugging solver code, evaluating the generated solutions, and improving efficiency and correctness of its model and code based on these evaluations.","OptiMUS-0.3 utilizes a modular structure to process problems, allowing it to handle problems with long descriptions and complex data without long prompts.","Experiments demonstrate that OptiMUS-0.3 outperforms existing state-of-the-art methods on easy datasets by more than 12% and on hard datasets (including a new dataset, NLP4LP, released with this paper that features long and complex problems) by more than 8%."],"url":"http://arxiv.org/abs/2407.19633v1"}
{"created":"2024-07-29 01:21:11","title":"LLMs' Understanding of Natural Language Revealed","abstract":"Large language models (LLMs) are the result of a massive experiment in bottom-up, data-driven reverse engineering of language at scale. Despite their utility in a number of downstream NLP tasks, ample research has shown that LLMs are incapable of performing reasoning in tasks that require quantification over and the manipulation of symbolic variables (e.g., planning and problem solving); see for example [25][26]. In this document, however, we will focus on testing LLMs for their language understanding capabilities, their supposed forte. As we will show here, the language understanding capabilities of LLMs have been widely exaggerated. While LLMs have proven to generate human-like coherent language (since that's how they were designed), their language understanding capabilities have not been properly tested. In particular, we believe that the language understanding capabilities of LLMs should be tested by performing an operation that is the opposite of 'text generation' and specifically by giving the LLM snippets of text as input and then querying what the LLM \"understood\". As we show here, when doing so it will become apparent that LLMs do not truly understand language, beyond very superficial inferences that are essentially the byproduct of the memorization of massive amounts of ingested text.","sentences":["Large language models (LLMs) are the result of a massive experiment in bottom-up, data-driven reverse engineering of language at scale.","Despite their utility in a number of downstream NLP tasks, ample research has shown that LLMs are incapable of performing reasoning in tasks that require quantification over and the manipulation of symbolic variables (e.g., planning and problem solving); see for example","[25][26].","In this document, however, we will focus on testing LLMs for their language understanding capabilities, their supposed forte.","As we will show here, the language understanding capabilities of LLMs have been widely exaggerated.","While LLMs have proven to generate human-like coherent language (since that's how they were designed), their language understanding capabilities have not been properly tested.","In particular, we believe that the language understanding capabilities of LLMs should be tested by performing an operation that is the opposite of 'text generation' and specifically by giving the LLM snippets of text as input and then querying what the LLM \"understood\".","As we show here, when doing so it will become apparent that LLMs do not truly understand language, beyond very superficial inferences that are essentially the byproduct of the memorization of massive amounts of ingested text."],"url":"http://arxiv.org/abs/2407.19630v1"}
{"created":"2024-07-29 01:18:47","title":"Text2LiDAR: Text-guided LiDAR Point Cloud Generation via Equirectangular Transformer","abstract":"The complex traffic environment and various weather conditions make the collection of LiDAR data expensive and challenging. Achieving high-quality and controllable LiDAR data generation is urgently needed, controlling with text is a common practice, but there is little research in this field. To this end, we propose Text2LiDAR, the first efficient, diverse, and text-controllable LiDAR data generation model. Specifically, we design an equirectangular transformer architecture, utilizing the designed equirectangular attention to capture LiDAR features in a manner with data characteristics. Then, we design a control-signal embedding injector to efficiently integrate control signals through the global-to-focused attention mechanism. Additionally, we devise a frequency modulator to assist the model in recovering high-frequency details, ensuring the clarity of the generated point cloud. To foster development in the field and optimize text-controlled generation performance, we construct nuLiDARtext which offers diverse text descriptors for 34,149 LiDAR point clouds from 850 scenes. Experiments on uncontrolled and text-controlled generation in various forms on KITTI-360 and nuScenes datasets demonstrate the superiority of our approach.","sentences":["The complex traffic environment and various weather conditions make the collection of LiDAR data expensive and challenging.","Achieving high-quality and controllable LiDAR data generation is urgently needed, controlling with text is a common practice, but there is little research in this field.","To this end, we propose Text2LiDAR, the first efficient, diverse, and text-controllable LiDAR data generation model.","Specifically, we design an equirectangular transformer architecture, utilizing the designed equirectangular attention to capture LiDAR features in a manner with data characteristics.","Then, we design a control-signal embedding injector to efficiently integrate control signals through the global-to-focused attention mechanism.","Additionally, we devise a frequency modulator to assist the model in recovering high-frequency details, ensuring the clarity of the generated point cloud.","To foster development in the field and optimize text-controlled generation performance, we construct nuLiDARtext which offers diverse text descriptors for 34,149 LiDAR point clouds from 850 scenes.","Experiments on uncontrolled and text-controlled generation in various forms on KITTI-360 and nuScenes datasets demonstrate the superiority of our approach."],"url":"http://arxiv.org/abs/2407.19628v1"}
{"created":"2024-07-29 01:17:54","title":"CHIME: Energy-Efficient STT-RAM-based Concurrent Hierarchical In-Memory Processing","abstract":"Processing-in-cache (PiC) and Processing-in-memory (PiM) architectures, especially those utilizing bit-line computing, offer promising solutions to mitigate data movement bottlenecks within the memory hierarchy. While previous studies have explored the integration of compute units within individual memory levels, the complexity and potential overheads associated with these designs have often limited their capabilities. This paper introduces a novel PiC/PiM architecture, Concurrent Hierarchical In-Memory Processing (CHIME), which strategically incorporates heterogeneous compute units across multiple levels of the memory hierarchy. This design targets the efficient execution of diverse, domain-specific workloads by placing computations closest to the data where it optimizes performance, energy consumption, data movement costs, and area. CHIME employs STT-RAM due to its various advantages in PiC/PiM computing, such as high density, low leakage, and better resiliency to data corruption from activating multiple word lines. We demonstrate that CHIME enhances concurrency and improves compute unit utilization at each level of the memory hierarchy. We present strategies for exploring the design space, grouping, and placing the compute units across the memory hierarchy. Experiments reveal that, compared to the state-of-the-art bit-line computing approaches, CHIME achieves significant speedup and energy savings of 57.95% and 78.23% for various domain-specific workloads, while reducing the overheads associated with single-level compute designs.","sentences":["Processing-in-cache (PiC) and Processing-in-memory (PiM) architectures, especially those utilizing bit-line computing, offer promising solutions to mitigate data movement bottlenecks within the memory hierarchy.","While previous studies have explored the integration of compute units within individual memory levels, the complexity and potential overheads associated with these designs have often limited their capabilities.","This paper introduces a novel PiC/PiM architecture, Concurrent Hierarchical In-Memory Processing (CHIME), which strategically incorporates heterogeneous compute units across multiple levels of the memory hierarchy.","This design targets the efficient execution of diverse, domain-specific workloads by placing computations closest to the data where it optimizes performance, energy consumption, data movement costs, and area.","CHIME employs STT-RAM due to its various advantages in PiC/PiM computing, such as high density, low leakage, and better resiliency to data corruption from activating multiple word lines.","We demonstrate that CHIME enhances concurrency and improves compute unit utilization at each level of the memory hierarchy.","We present strategies for exploring the design space, grouping, and placing the compute units across the memory hierarchy.","Experiments reveal that, compared to the state-of-the-art bit-line computing approaches, CHIME achieves significant speedup and energy savings of 57.95% and 78.23% for various domain-specific workloads, while reducing the overheads associated with single-level compute designs."],"url":"http://arxiv.org/abs/2407.19627v1"}
{"created":"2024-07-29 00:58:21","title":"Structure-Aware Simplification for Hypergraph Visualization","abstract":"Hypergraphs provide a natural way to represent polyadic relationships in network data. For large hypergraphs, it is often difficult to visually detect structures within the data. Recently, a scalable polygon-based visualization approach was developed allowing hypergraphs with thousands of hyperedges to be simplified and examined at different levels of detail. However, this approach is not guaranteed to eliminate all of the visual clutter caused by unavoidable overlaps. Furthermore, meaningful structures can be lost at simplified scales, making their interpretation unreliable. In this paper, we define hypergraph structures using the bipartite graph representation, allowing us to decompose the hypergraph into a union of structures including topological blocks, bridges, and branches, and to identify exactly where unavoidable overlaps must occur. We also introduce a set of topology preserving and topology altering atomic operations, enabling the preservation of important structures while reducing unavoidable overlaps to improve visual clarity and interpretability in simplified scales. We demonstrate our approach in several real-world applications.","sentences":["Hypergraphs provide a natural way to represent polyadic relationships in network data.","For large hypergraphs, it is often difficult to visually detect structures within the data.","Recently, a scalable polygon-based visualization approach was developed allowing hypergraphs with thousands of hyperedges to be simplified and examined at different levels of detail.","However, this approach is not guaranteed to eliminate all of the visual clutter caused by unavoidable overlaps.","Furthermore, meaningful structures can be lost at simplified scales, making their interpretation unreliable.","In this paper, we define hypergraph structures using the bipartite graph representation, allowing us to decompose the hypergraph into a union of structures including topological blocks, bridges, and branches, and to identify exactly where unavoidable overlaps must occur.","We also introduce a set of topology preserving and topology altering atomic operations, enabling the preservation of important structures while reducing unavoidable overlaps to improve visual clarity and interpretability in simplified scales.","We demonstrate our approach in several real-world applications."],"url":"http://arxiv.org/abs/2407.19621v1"}
{"created":"2024-07-28 22:12:36","title":"You shall know a piece by the company it keeps. Chess plays as a data for word2vec models","abstract":"In this paper, I apply linguistic methods of analysis to non-linguistic data, chess plays, metaphorically equating one with the other and seeking analogies. Chess game notations are also a kind of text, and one can consider the records of moves or positions of pieces as words and statements in a certain language. In this article I show how word embeddings (word2vec) can work on chess game texts instead of natural language texts. I don't see how this representation of chess data can be used productively. It's unlikely that these vector models will help engines or people choose the best move. But in a purely academic sense, it's clear that such methods of information representation capture something important about the very nature of the game, which doesn't necessarily lead to a win.","sentences":["In this paper, I apply linguistic methods of analysis to non-linguistic data, chess plays, metaphorically equating one with the other and seeking analogies.","Chess game notations are also a kind of text, and one can consider the records of moves or positions of pieces as words and statements in a certain language.","In this article I show how word embeddings (word2vec) can work on chess game texts instead of natural language texts.","I don't see how this representation of chess data can be used productively.","It's unlikely that these vector models will help engines or people choose the best move.","But in a purely academic sense, it's clear that such methods of information representation capture something important about the very nature of the game, which doesn't necessarily lead to a win."],"url":"http://arxiv.org/abs/2407.19600v1"}
{"created":"2024-07-28 21:58:28","title":"Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge","abstract":"Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains. While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can improve by judging their own responses instead of relying on human labelers. However, existing methods have primarily focused on improving model responses rather than judgment capabilities, resulting in rapid saturation during iterative training. To address this issue, we introduce a novel Meta-Rewarding step to the self-improvement process, where the model judges its own judgements and uses that feedback to refine its judgment skills. Surprisingly, this unsupervised approach improves the model's ability to judge {\\em and} follow instructions, as demonstrated by a win rate improvement of Llama-3-8B-Instruct from 22.9% to 39.4% on AlpacaEval 2, and 20.6% to 29.1% on Arena-Hard. These results strongly suggest the potential for self-improving models without human supervision.","sentences":["Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains.","While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can improve by judging their own responses instead of relying on human labelers.","However, existing methods have primarily focused on improving model responses rather than judgment capabilities, resulting in rapid saturation during iterative training.","To address this issue, we introduce a novel Meta-Rewarding step to the self-improvement process, where the model judges its own judgements and uses that feedback to refine its judgment skills.","Surprisingly, this unsupervised approach improves the model's ability to judge {\\em and} follow instructions, as demonstrated by a win rate improvement of Llama-3-8B-Instruct from 22.9% to 39.4% on AlpacaEval 2, and 20.6% to 29.1% on Arena-Hard.","These results strongly suggest the potential for self-improving models without human supervision."],"url":"http://arxiv.org/abs/2407.19594v1"}
{"created":"2024-07-28 20:50:53","title":"SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain","abstract":"In this paper, we introduce SaulLM-54B and SaulLM-141B, two large language models (LLMs) tailored for the legal sector. These models, which feature architectures of 54 billion and 141 billion parameters, respectively, are based on the Mixtral architecture. The development of SaulLM-54B and SaulLM-141B is guided by large-scale domain adaptation, divided into three strategies: (1) the exploitation of continued pretraining involving a base corpus that includes over 540 billion of legal tokens, (2) the implementation of a specialized legal instruction-following protocol, and (3) the alignment of model outputs with human preferences in legal interpretations. The integration of synthetically generated data in the second and third steps enhances the models' capabilities in interpreting and processing legal texts, effectively reaching state-of-the-art performance and outperforming previous open-source models on LegalBench-Instruct. This work explores the trade-offs involved in domain-specific adaptation at this scale, offering insights that may inform future studies on domain adaptation using strong decoder models. Building upon SaulLM-7B, this study refines the approach to produce an LLM better equipped for legal tasks. We are releasing base, instruct, and aligned versions on top of SaulLM-54B and SaulLM-141B under the MIT License to facilitate reuse and collaborative research.","sentences":["In this paper, we introduce SaulLM-54B and SaulLM-141B, two large language models (LLMs) tailored for the legal sector.","These models, which feature architectures of 54 billion and 141 billion parameters, respectively, are based on the Mixtral architecture.","The development of SaulLM-54B and SaulLM-141B is guided by large-scale domain adaptation, divided into three strategies: (1) the exploitation of continued pretraining involving a base corpus that includes over 540 billion of legal tokens, (2) the implementation of a specialized legal instruction-following protocol, and (3) the alignment of model outputs with human preferences in legal interpretations.","The integration of synthetically generated data in the second and third steps enhances the models' capabilities in interpreting and processing legal texts, effectively reaching state-of-the-art performance and outperforming previous open-source models on LegalBench-Instruct.","This work explores the trade-offs involved in domain-specific adaptation at this scale, offering insights that may inform future studies on domain adaptation using strong decoder models.","Building upon SaulLM-7B, this study refines the approach to produce an LLM better equipped for legal tasks.","We are releasing base, instruct, and aligned versions on top of SaulLM-54B and SaulLM-141B under the MIT License to facilitate reuse and collaborative research."],"url":"http://arxiv.org/abs/2407.19584v1"}
{"created":"2024-07-28 19:31:37","title":"Detection of Unknown Errors in Human-Centered Systems","abstract":"Artificial Intelligence-enabled systems are increasingly being deployed in real-world safety-critical settings involving human participants. It is vital to ensure the safety of such systems and stop the evolution of the system with error before causing harm to human participants. We propose a model-agnostic approach to detecting unknown errors in such human-centered systems without requiring any knowledge about the error signatures. Our approach employs dynamics-induced hybrid recurrent neural networks (DiH-RNN) for constructing physics-based models from operational data, coupled with conformal inference for assessing errors in the underlying model caused by violations of physical laws, thereby facilitating early detection of unknown errors before unsafe shifts in operational data distribution occur. We evaluate our framework on multiple real-world safety critical systems and show that our technique outperforms the existing state-of-the-art in detecting unknown errors.","sentences":["Artificial Intelligence-enabled systems are increasingly being deployed in real-world safety-critical settings involving human participants.","It is vital to ensure the safety of such systems and stop the evolution of the system with error before causing harm to human participants.","We propose a model-agnostic approach to detecting unknown errors in such human-centered systems without requiring any knowledge about the error signatures.","Our approach employs dynamics-induced hybrid recurrent neural networks (DiH-RNN) for constructing physics-based models from operational data, coupled with conformal inference for assessing errors in the underlying model caused by violations of physical laws, thereby facilitating early detection of unknown errors before unsafe shifts in operational data distribution occur.","We evaluate our framework on multiple real-world safety critical systems and show that our technique outperforms the existing state-of-the-art in detecting unknown errors."],"url":"http://arxiv.org/abs/2407.19569v1"}
{"created":"2024-07-28 19:23:09","title":"Rouser: Robust SNN training using adaptive threshold learning","abstract":"In Spiking Neural Networks (SNNs), learning rules are based on neuron spiking behavior, that is, if and when spikes are generated due to a neuron's membrane potential exceeding that neuron's firing threshold, and this spike timing encodes vital information. However, the threshold is generally treated as a hyperparameter, and incorrect selection can lead to neurons that do not spike for large portions of the training process, hindering the effective rate of learning. Inspired by homeostatic mechanisms in biological neurons, this work (Rouser) presents a study to rouse training-inactive neurons and improve the SNN training by using an in-loop adaptive threshold learning mechanism. Rouser's adaptive threshold allows for dynamic adjustments based on input data and network hyperparameters, influencing spike timing and improving training. This study focuses primarily on investigating the significance of learning neuron thresholds alongside weights in SNNs. We evaluate the performance of Rouser on the spatiotemporal datasets NMNIST, DVS128 and Spiking Heidelberg Digits (SHD), compare our results with state-of-the-art SNN training techniques, and discuss the strengths and limitations of our approach. Our results suggest that promoting threshold from a hyperparameter to a parameter can effectively address the issue of dead neurons during training, resulting in a more robust training algorithm that leads to improved training convergence, increased test accuracy, and substantial reductions in the number of training epochs needed to achieve viable accuracy. Rouser achieves up to 70% lower training latency while providing up to 2% higher accuracy over state-of-the-art SNNs with similar network architecture on the neuromorphic datasets NMNIST, DVS128 and SHD.","sentences":["In Spiking Neural Networks (SNNs), learning rules are based on neuron spiking behavior, that is, if and when spikes are generated due to a neuron's membrane potential exceeding that neuron's firing threshold, and this spike timing encodes vital information.","However, the threshold is generally treated as a hyperparameter, and incorrect selection can lead to neurons that do not spike for large portions of the training process, hindering the effective rate of learning.","Inspired by homeostatic mechanisms in biological neurons, this work (Rouser) presents a study to rouse training-inactive neurons and improve the SNN training by using an in-loop adaptive threshold learning mechanism.","Rouser's adaptive threshold allows for dynamic adjustments based on input data and network hyperparameters, influencing spike timing and improving training.","This study focuses primarily on investigating the significance of learning neuron thresholds alongside weights in SNNs.","We evaluate the performance of Rouser on the spatiotemporal datasets NMNIST, DVS128 and Spiking Heidelberg Digits (SHD), compare our results with state-of-the-art SNN training techniques, and discuss the strengths and limitations of our approach.","Our results suggest that promoting threshold from a hyperparameter to a parameter can effectively address the issue of dead neurons during training, resulting in a more robust training algorithm that leads to improved training convergence, increased test accuracy, and substantial reductions in the number of training epochs needed to achieve viable accuracy.","Rouser achieves up to 70% lower training latency while providing up to 2% higher accuracy over state-of-the-art SNNs with similar network architecture on the neuromorphic datasets NMNIST, DVS128 and SHD."],"url":"http://arxiv.org/abs/2407.19566v1"}
{"created":"2024-07-28 19:20:14","title":"Machine-arranged Interactions Improve Institutional Belonging and Cohesion","abstract":"We investigated how participation in machine-arranged meetings were associated with feelings of institutional belonging and perceptions of demographic groups. We collected data from 535 individuals who participated in a program to meet new friends. Data consisted of surveys measuring demography, belonging, and perceptions of various demographic groups at the start and end of the program. Participants were partitioned into a control group who received zero introductions, and an intervention group who received multiple introductions. For each participant, we computed twelve features describing participation status, demography and the amount of program-facilitated exposure to others who were similar to them and different from them. We used a linear model to study the association of our features with the participants' final belonging and perceptions while controlling for their initial belonging and perceptions. We found that those who participated in the machine-arranged meetings had 4.5% higher belonging, and 3.9% more positive perception of others.","sentences":["We investigated how participation in machine-arranged meetings were associated with feelings of institutional belonging and perceptions of demographic groups.","We collected data from 535 individuals who participated in a program to meet new friends.","Data consisted of surveys measuring demography, belonging, and perceptions of various demographic groups at the start and end of the program.","Participants were partitioned into a control group who received zero introductions, and an intervention group who received multiple introductions.","For each participant, we computed twelve features describing participation status, demography and the amount of program-facilitated exposure to others who were similar to them and different from them.","We used a linear model to study the association of our features with the participants' final belonging and perceptions while controlling for their initial belonging and perceptions.","We found that those who participated in the machine-arranged meetings had 4.5% higher belonging, and 3.9% more positive perception of others."],"url":"http://arxiv.org/abs/2407.19565v1"}
