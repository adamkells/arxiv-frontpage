{"created":"2023-11-29 18:59:59","title":"A Simple Recipe for Language-guided Domain Generalized Segmentation","abstract":"Generalization to new domains not seen during training is one of the long-standing goals and challenges in deploying neural networks in real-world applications. Existing generalization techniques necessitate substantial data augmentation, potentially sourced from external datasets, and aim at learning invariant representations by imposing various alignment constraints. Large-scale pretraining has recently shown promising generalization capabilities, along with the potential of bridging different modalities. For instance, the recent advent of vision-language models like CLIP has opened the doorway for vision models to exploit the textual modality. In this paper, we introduce a simple framework for generalizing semantic segmentation networks by employing language as the source of randomization. Our recipe comprises three key ingredients: i) the preservation of the intrinsic CLIP robustness through minimal fine-tuning, ii) language-driven local style augmentation, and iii) randomization by locally mixing the source and augmented styles during training. Extensive experiments report state-of-the-art results on various generalization benchmarks. The code will be made available.","sentences":["Generalization to new domains not seen during training is one of the long-standing goals and challenges in deploying neural networks in real-world applications.","Existing generalization techniques necessitate substantial data augmentation, potentially sourced from external datasets, and aim at learning invariant representations by imposing various alignment constraints.","Large-scale pretraining has recently shown promising generalization capabilities, along with the potential of bridging different modalities.","For instance, the recent advent of vision-language models like CLIP has opened the doorway for vision models to exploit the textual modality.","In this paper, we introduce a simple framework for generalizing semantic segmentation networks by employing language as the source of randomization.","Our recipe comprises three key ingredients: i) the preservation of the intrinsic CLIP robustness through minimal fine-tuning, ii) language-driven local style augmentation, and iii) randomization by locally mixing the source and augmented styles during training.","Extensive experiments report state-of-the-art results on various generalization benchmarks.","The code will be made available."],"url":"http://arxiv.org/abs/2311.17922v1"}
{"created":"2023-11-29 18:57:07","title":"OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation","abstract":"Hallucination, posed as a pervasive challenge of multi-modal large language models (MLLMs), has significantly impeded their real-world usage that demands precise judgment. Existing methods mitigate this issue with either training with specific designed data or inferencing with external knowledge from other sources, incurring inevitable additional costs. In this paper, we present OPERA, a novel MLLM decoding method grounded in an Over-trust Penalty and a Retrospection-Allocation strategy, serving as a nearly free lunch to alleviate the hallucination issue without additional data, knowledge, or training. Our approach begins with an interesting observation that, most hallucinations are closely tied to the knowledge aggregation patterns manifested in the self-attention matrix, i.e., MLLMs tend to generate new tokens by focusing on a few summary tokens, but not all the previous tokens. Such partial over-trust inclination results in the neglecting of image tokens and describes the image content with hallucination. Statistically, we observe an 80%$\\sim$95% co-currency rate between hallucination contents and such knowledge aggregation patterns. Based on the observation, OPERA introduces a penalty term on the model logits during the beam-search decoding to mitigate the over-trust issue, along with a rollback strategy that retrospects the presence of summary tokens in the previously generated tokens, and re-allocate the token selection if necessary. With extensive experiments, OPERA shows significant hallucination-mitigating performance on different MLLMs and metrics, proving its effectiveness and generality. Our code is available at: https://github.com/shikiw/OPERA.","sentences":["Hallucination, posed as a pervasive challenge of multi-modal large language models (MLLMs), has significantly impeded their real-world usage that demands precise judgment.","Existing methods mitigate this issue with either training with specific designed data or inferencing with external knowledge from other sources, incurring inevitable additional costs.","In this paper, we present OPERA, a novel MLLM decoding method grounded in an Over-trust Penalty and a Retrospection-Allocation strategy, serving as a nearly free lunch to alleviate the hallucination issue without additional data, knowledge, or training.","Our approach begins with an interesting observation that, most hallucinations are closely tied to the knowledge aggregation patterns manifested in the self-attention matrix, i.e., MLLMs tend to generate new tokens by focusing on a few summary tokens, but not all the previous tokens.","Such partial over-trust inclination results in the neglecting of image tokens and describes the image content with hallucination.","Statistically, we observe an 80%$\\sim$95% co-currency rate between hallucination contents and such knowledge aggregation patterns.","Based on the observation, OPERA introduces a penalty term on the model logits during the beam-search decoding to mitigate the over-trust issue, along with a rollback strategy that retrospects the presence of summary tokens in the previously generated tokens, and re-allocate the token selection if necessary.","With extensive experiments, OPERA shows significant hallucination-mitigating performance on different MLLMs and metrics, proving its effectiveness and generality.","Our code is available at: https://github.com/shikiw/OPERA."],"url":"http://arxiv.org/abs/2311.17911v1"}
{"created":"2023-11-29 18:53:47","title":"Language-conditioned Detection Transformer","abstract":"We present a new open-vocabulary detection framework. Our framework uses both image-level labels and detailed detection annotations when available. Our framework proceeds in three steps. We first train a language-conditioned object detector on fully-supervised detection data. This detector gets to see the presence or absence of ground truth classes during training, and conditions prediction on the set of present classes. We use this detector to pseudo-label images with image-level labels. Our detector provides much more accurate pseudo-labels than prior approaches with its conditioning mechanism. Finally, we train an unconditioned open-vocabulary detector on the pseudo-annotated images. The resulting detector, named DECOLA, shows strong zero-shot performance in open-vocabulary LVIS benchmark as well as direct zero-shot transfer benchmarks on LVIS, COCO, Object365, and OpenImages. DECOLA outperforms the prior arts by 17.1 AP-rare and 9.4 mAP on zero-shot LVIS benchmark. DECOLA achieves state-of-the-art results in various model sizes, architectures, and datasets by only training on open-sourced data and academic-scale computing. Code is available at https://github.com/janghyuncho/DECOLA.","sentences":["We present a new open-vocabulary detection framework.","Our framework uses both image-level labels and detailed detection annotations when available.","Our framework proceeds in three steps.","We first train a language-conditioned object detector on fully-supervised detection data.","This detector gets to see the presence or absence of ground truth classes during training, and conditions prediction on the set of present classes.","We use this detector to pseudo-label images with image-level labels.","Our detector provides much more accurate pseudo-labels than prior approaches with its conditioning mechanism.","Finally, we train an unconditioned open-vocabulary detector on the pseudo-annotated images.","The resulting detector, named DECOLA, shows strong zero-shot performance in open-vocabulary LVIS benchmark as well as direct zero-shot transfer benchmarks on LVIS, COCO, Object365, and OpenImages.","DECOLA outperforms the prior arts by 17.1 AP-rare and 9.4 mAP on zero-shot LVIS benchmark.","DECOLA achieves state-of-the-art results in various model sizes, architectures, and datasets by only training on open-sourced data and academic-scale computing.","Code is available at https://github.com/janghyuncho/DECOLA."],"url":"http://arxiv.org/abs/2311.17902v1"}
{"created":"2023-11-29 18:44:12","title":"Pose Anything: A Graph-Based Approach for Category-Agnostic Pose Estimation","abstract":"Traditional 2D pose estimation models are limited by their category-specific design, making them suitable only for predefined object categories. This restriction becomes particularly challenging when dealing with novel objects due to the lack of relevant training data.   To address this limitation, category-agnostic pose estimation (CAPE) was introduced. CAPE aims to enable keypoint localization for arbitrary object categories using a single model, requiring minimal support images with annotated keypoints. This approach not only enables object pose generation based on arbitrary keypoint definitions but also significantly reduces the associated costs, paving the way for versatile and adaptable pose estimation applications.   We present a novel approach to CAPE that leverages the inherent geometrical relations between keypoints through a newly designed Graph Transformer Decoder. By capturing and incorporating this crucial structural information, our method enhances the accuracy of keypoint localization, marking a significant departure from conventional CAPE techniques that treat keypoints as isolated entities.   We validate our approach on the MP-100 benchmark, a comprehensive dataset comprising over 20,000 images spanning more than 100 categories. Our method outperforms the prior state-of-the-art by substantial margins, achieving remarkable improvements of 2.16% and 1.82% under 1-shot and 5-shot settings, respectively. Furthermore, our method's end-to-end training demonstrates both scalability and efficiency compared to previous CAPE approaches.","sentences":["Traditional 2D pose estimation models are limited by their category-specific design, making them suitable only for predefined object categories.","This restriction becomes particularly challenging when dealing with novel objects due to the lack of relevant training data.   ","To address this limitation, category-agnostic pose estimation (CAPE) was introduced.","CAPE aims to enable keypoint localization for arbitrary object categories using a single model, requiring minimal support images with annotated keypoints.","This approach not only enables object pose generation based on arbitrary keypoint definitions but also significantly reduces the associated costs, paving the way for versatile and adaptable pose estimation applications.   ","We present a novel approach to CAPE that leverages the inherent geometrical relations between keypoints through a newly designed Graph Transformer Decoder.","By capturing and incorporating this crucial structural information, our method enhances the accuracy of keypoint localization, marking a significant departure from conventional CAPE techniques that treat keypoints as isolated entities.   ","We validate our approach on the MP-100 benchmark, a comprehensive dataset comprising over 20,000 images spanning more than 100 categories.","Our method outperforms the prior state-of-the-art by substantial margins, achieving remarkable improvements of 2.16% and 1.82% under 1-shot and 5-shot settings, respectively.","Furthermore, our method's end-to-end training demonstrates both scalability and efficiency compared to previous CAPE approaches."],"url":"http://arxiv.org/abs/2311.17891v1"}
{"created":"2023-11-29 18:20:16","title":"FisherRF: Active View Selection and Uncertainty Quantification for Radiance Fields using Fisher Information","abstract":"This study addresses the challenging problem of active view selection and uncertainty quantification within the domain of Radiance Fields. Neural Radiance Fields (NeRF) have greatly advanced image rendering and reconstruction, but the limited availability of 2D images poses uncertainties stemming from occlusions, depth ambiguities, and imaging errors. Efficiently selecting informative views becomes crucial, and quantifying NeRF model uncertainty presents intricate challenges. Existing approaches either depend on model architecture or are based on assumptions regarding density distributions that are not generally applicable. By leveraging Fisher Information, we efficiently quantify observed information within Radiance Fields without ground truth data. This can be used for the next best view selection and pixel-wise uncertainty quantification. Our method overcomes existing limitations on model architecture and effectiveness, achieving state-of-the-art results in both view selection and uncertainty quantification, demonstrating its potential to advance the field of Radiance Fields. Our method with the 3D Gaussian Splatting backend could perform view selections at 70 fps.","sentences":["This study addresses the challenging problem of active view selection and uncertainty quantification within the domain of Radiance Fields.","Neural Radiance Fields (NeRF) have greatly advanced image rendering and reconstruction, but the limited availability of 2D images poses uncertainties stemming from occlusions, depth ambiguities, and imaging errors.","Efficiently selecting informative views becomes crucial, and quantifying NeRF model uncertainty presents intricate challenges.","Existing approaches either depend on model architecture or are based on assumptions regarding density distributions that are not generally applicable.","By leveraging Fisher Information, we efficiently quantify observed information within Radiance Fields without ground truth data.","This can be used for the next best view selection and pixel-wise uncertainty quantification.","Our method overcomes existing limitations on model architecture and effectiveness, achieving state-of-the-art results in both view selection and uncertainty quantification, demonstrating its potential to advance the field of Radiance Fields.","Our method with the 3D Gaussian Splatting backend could perform view selections at 70 fps."],"url":"http://arxiv.org/abs/2311.17874v1"}
{"created":"2023-11-29 18:19:24","title":"Assessing the reliability of multistate flow networks considering distance constraints","abstract":"Evaluating the reliability of complex technical networks, such as those in energy distribution, logistics, and transportation systems, is of paramount importance. These networks are often represented as multistate flow networks (MFNs). While there has been considerable research on assessing MFN reliability, many studies still need to pay more attention to a critical factor: transmission distance constraints. These constraints are typical in real-world applications, such as Internet infrastructure, where controlling the distances between data centers, network nodes, and end-users is vital for ensuring low latency and efficient data transmission. This paper addresses the evaluation of MFN reliability under distance constraints. Specifically, it focuses on determining the probability that a minimum of $d$ flow units can be transmitted successfully from a source node to a sink node, using only paths with lengths not exceeding a predefined distance limit of $\\lambda $. We introduce an effective algorithm to tackle this challenge, provide a benchmark example to illustrate its application and analyze its computational complexity.","sentences":["Evaluating the reliability of complex technical networks, such as those in energy distribution, logistics, and transportation systems, is of paramount importance.","These networks are often represented as multistate flow networks (MFNs).","While there has been considerable research on assessing MFN reliability, many studies still need to pay more attention to a critical factor: transmission distance constraints.","These constraints are typical in real-world applications, such as Internet infrastructure, where controlling the distances between data centers, network nodes, and end-users is vital for ensuring low latency and efficient data transmission.","This paper addresses the evaluation of MFN reliability under distance constraints.","Specifically, it focuses on determining the probability that a minimum of $d$ flow units can be transmitted successfully from a source node to a sink node, using only paths with lengths not exceeding a predefined distance limit of $\\lambda $.","We introduce an effective algorithm to tackle this challenge, provide a benchmark example to illustrate its application and analyze its computational complexity."],"url":"http://arxiv.org/abs/2311.17872v1"}
{"created":"2023-11-29 18:17:35","title":"SAIBench: A Structural Interpretation of AI for Science Through Benchmarks","abstract":"Artificial Intelligence for Science (AI4S) is an emerging research field that utilizes machine learning advancements to tackle complex scientific computational issues, aiming to enhance computational efficiency and accuracy. However, the data-driven nature of AI4S lacks the correctness or accuracy assurances of conventional scientific computing, posing challenges when deploying AI4S models in real-world applications. To mitigate these, more comprehensive benchmarking procedures are needed to better understand AI4S models. This paper introduces a novel benchmarking approach, known as structural interpretation, which addresses two key requirements: identifying the trusted operating range in the problem space and tracing errors back to their computational components. This method partitions both the problem and metric spaces, facilitating a structural exploration of these spaces. The practical utility and effectiveness of structural interpretation are illustrated through its application to three distinct AI4S workloads: machine-learning force fields (MLFF), jet tagging, and precipitation nowcasting. The benchmarks effectively model the trusted operating range, trace errors, and reveal novel perspectives for refining the model, training process, and data sampling strategy. This work is part of the SAIBench project, an AI4S benchmarking suite.","sentences":["Artificial Intelligence for Science (AI4S) is an emerging research field that utilizes machine learning advancements to tackle complex scientific computational issues, aiming to enhance computational efficiency and accuracy.","However, the data-driven nature of AI4S lacks the correctness or accuracy assurances of conventional scientific computing, posing challenges when deploying AI4S models in real-world applications.","To mitigate these, more comprehensive benchmarking procedures are needed to better understand AI4S models.","This paper introduces a novel benchmarking approach, known as structural interpretation, which addresses two key requirements: identifying the trusted operating range in the problem space and tracing errors back to their computational components.","This method partitions both the problem and metric spaces, facilitating a structural exploration of these spaces.","The practical utility and effectiveness of structural interpretation are illustrated through its application to three distinct AI4S workloads: machine-learning force fields (MLFF), jet tagging, and precipitation nowcasting.","The benchmarks effectively model the trusted operating range, trace errors, and reveal novel perspectives for refining the model, training process, and data sampling strategy.","This work is part of the SAIBench project, an AI4S benchmarking suite."],"url":"http://arxiv.org/abs/2311.17869v1"}
{"created":"2023-11-29 18:14:34","title":"Space-Optimal Profile Estimation in Data Streams with Applications to Symmetric Functions","abstract":"We revisit the problem of estimating the profile (also known as the rarity) in the data stream model. Given a sequence of $m$ elements from a universe of size $n$, its profile is a vector $\\phi$ whose $i$-th entry $\\phi_i$ represents the number of distinct elements that appear in the stream exactly $i$ times. A classic paper by Datar and Muthukrishan from 2002 gave an algorithm which estimates any entry $\\phi_i$ up to an additive error of $\\pm \\epsilon D$ using $O(1/\\epsilon^2 (\\log n + \\log m))$ bits of space, where $D$ is the number of distinct elements in the stream. In this paper, we considerably improve on this result by designing an algorithm which simultaneously estimates many coordinates of the profile vector $\\phi$ up to small overall error. We give an algorithm which, with constant probability, produces an estimated profile $\\hat\\phi$ with the following guarantees in terms of space and estimation error:   - For any constant $\\tau$, with $O(1 / \\epsilon^2 + \\log n)$ bits of space, $\\sum_{i=1}^\\tau |\\phi_i - \\hat\\phi_i| \\leq \\epsilon D$.   - With $O(1/ \\epsilon^2\\log (1/\\epsilon) + \\log n + \\log \\log m)$ bits of space, $\\sum_{i=1}^m |\\phi_i - \\hat\\phi_i| \\leq \\epsilon m$.   In addition to bounding the error across multiple coordinates, our space bounds separate the terms that depend on $1/\\epsilon$ and those that depend on $n$ and $m$. We prove matching lower bounds on space in both regimes. Application of our profile estimation algorithm gives estimates within error $\\pm \\epsilon D$ of several symmetric functions of frequencies in $O(1/\\epsilon^2 + \\log n)$ bits. This generalizes space-optimal algorithms for the distinct elements problems to other problems including estimating the Huber and Tukey losses as well as frequency cap statistics.","sentences":["We revisit the problem of estimating the profile (also known as the rarity) in the data stream model.","Given a sequence of $m$ elements from a universe of size $n$, its profile is a vector $\\phi$ whose $i$-th entry $\\phi_i$ represents the number of distinct elements that appear in the stream exactly $i$ times.","A classic paper by Datar and Muthukrishan from 2002 gave an algorithm which estimates any entry $\\phi_i$ up to an additive error of $\\pm \\epsilon D$ using $O(1/\\epsilon^2 (\\log n + \\log m))$ bits of space, where $D$ is the number of distinct elements in the stream.","In this paper, we considerably improve on this result by designing an algorithm which simultaneously estimates many coordinates of the profile vector $\\phi$ up to small overall error.","We give an algorithm which, with constant probability, produces an estimated profile $\\hat\\phi$ with the following guarantees in terms of space and estimation error:   -","For any constant $\\tau$, with $O(1 / \\epsilon^2 + \\log n)$ bits of space, $\\sum_{i=1}^\\tau |\\phi_i - \\hat\\phi_i| \\leq \\epsilon D$.   - With $O(1/ \\epsilon^2\\log (1/\\epsilon) + \\log n + \\log \\log m)$ bits of space, $\\sum_{i=1}^m |\\phi_i - \\hat\\phi_i| \\leq \\epsilon m$.   ","In addition to bounding the error across multiple coordinates, our space bounds separate the terms that depend on $1/\\epsilon$ and those that depend on $n$ and $m$. We prove matching lower bounds on space in both regimes.","Application of our profile estimation algorithm gives estimates within error $\\pm \\epsilon D$ of several symmetric functions of frequencies in $O(1/\\epsilon^2 + \\log n)$ bits.","This generalizes space-optimal algorithms for the distinct elements problems to other problems including estimating the Huber and Tukey losses as well as frequency cap statistics."],"url":"http://arxiv.org/abs/2311.17868v1"}
{"created":"2023-11-29 17:59:18","title":"On the Adversarial Robustness of Graph Contrastive Learning Methods","abstract":"Contrastive learning (CL) has emerged as a powerful framework for learning representations of images and text in a self-supervised manner while enhancing model robustness against adversarial attacks. More recently, researchers have extended the principles of contrastive learning to graph-structured data, giving birth to the field of graph contrastive learning (GCL). However, whether GCL methods can deliver the same advantages in adversarial robustness as their counterparts in the image and text domains remains an open question. In this paper, we introduce a comprehensive robustness evaluation protocol tailored to assess the robustness of GCL models. We subject these models to adaptive adversarial attacks targeting the graph structure, specifically in the evasion scenario. We evaluate node and graph classification tasks using diverse real-world datasets and attack strategies. With our work, we aim to offer insights into the robustness of GCL methods and hope to open avenues for potential future research directions.","sentences":["Contrastive learning (CL) has emerged as a powerful framework for learning representations of images and text in a self-supervised manner while enhancing model robustness against adversarial attacks.","More recently, researchers have extended the principles of contrastive learning to graph-structured data, giving birth to the field of graph contrastive learning (GCL).","However, whether GCL methods can deliver the same advantages in adversarial robustness as their counterparts in the image and text domains remains an open question.","In this paper, we introduce a comprehensive robustness evaluation protocol tailored to assess the robustness of GCL models.","We subject these models to adaptive adversarial attacks targeting the graph structure, specifically in the evasion scenario.","We evaluate node and graph classification tasks using diverse real-world datasets and attack strategies.","With our work, we aim to offer insights into the robustness of GCL methods and hope to open avenues for potential future research directions."],"url":"http://arxiv.org/abs/2311.17853v1"}
{"created":"2023-11-29 17:49:33","title":"Towards Real-World Focus Stacking with Deep Learning","abstract":"Focus stacking is widely used in micro, macro, and landscape photography to reconstruct all-in-focus images from multiple frames obtained with focus bracketing, that is, with shallow depth of field and different focus planes. Existing deep learning approaches to the underlying multi-focus image fusion problem have limited applicability to real-world imagery since they are designed for very short image sequences (two to four images), and are typically trained on small, low-resolution datasets either acquired by light-field cameras or generated synthetically. We introduce a new dataset consisting of 94 high-resolution bursts of raw images with focus bracketing, with pseudo ground truth computed from the data using state-of-the-art commercial software. This dataset is used to train the first deep learning algorithm for focus stacking capable of handling bursts of sufficient length for real-world applications. Qualitative experiments demonstrate that it is on par with existing commercial solutions in the long-burst, realistic regime while being significantly more tolerant to noise. The code and dataset are available at https://github.com/araujoalexandre/FocusStackingDataset.","sentences":["Focus stacking is widely used in micro, macro, and landscape photography to reconstruct all-in-focus images from multiple frames obtained with focus bracketing, that is, with shallow depth of field and different focus planes.","Existing deep learning approaches to the underlying multi-focus image fusion problem have limited applicability to real-world imagery since they are designed for very short image sequences (two to four images), and are typically trained on small, low-resolution datasets either acquired by light-field cameras or generated synthetically.","We introduce a new dataset consisting of 94 high-resolution bursts of raw images with focus bracketing, with pseudo ground truth computed from the data using state-of-the-art commercial software.","This dataset is used to train the first deep learning algorithm for focus stacking capable of handling bursts of sufficient length for real-world applications.","Qualitative experiments demonstrate that it is on par with existing commercial solutions in the long-burst, realistic regime while being significantly more tolerant to noise.","The code and dataset are available at https://github.com/araujoalexandre/FocusStackingDataset."],"url":"http://arxiv.org/abs/2311.17846v1"}
{"created":"2023-11-29 17:46:25","title":"Look Before You Leap: Unveiling the Power of GPT-4V in Robotic Vision-Language Planning","abstract":"In this study, we are interested in imbuing robots with the capability of physically-grounded task planning. Recent advancements have shown that large language models (LLMs) possess extensive knowledge useful in robotic tasks, especially in reasoning and planning. However, LLMs are constrained by their lack of world grounding and dependence on external affordance models to perceive environmental information, which cannot jointly reason with LLMs. We argue that a task planner should be an inherently grounded, unified multimodal system. To this end, we introduce Robotic Vision-Language Planning (ViLa), a novel approach for long-horizon robotic planning that leverages vision-language models (VLMs) to generate a sequence of actionable steps. ViLa directly integrates perceptual data into its reasoning and planning process, enabling a profound understanding of commonsense knowledge in the visual world, including spatial layouts and object attributes. It also supports flexible multimodal goal specification and naturally incorporates visual feedback. Our extensive evaluation, conducted in both real-robot and simulated environments, demonstrates ViLa's superiority over existing LLM-based planners, highlighting its effectiveness in a wide array of open-world manipulation tasks.","sentences":["In this study, we are interested in imbuing robots with the capability of physically-grounded task planning.","Recent advancements have shown that large language models (LLMs) possess extensive knowledge useful in robotic tasks, especially in reasoning and planning.","However, LLMs are constrained by their lack of world grounding and dependence on external affordance models to perceive environmental information, which cannot jointly reason with LLMs.","We argue that a task planner should be an inherently grounded, unified multimodal system.","To this end, we introduce Robotic Vision-Language Planning (ViLa), a novel approach for long-horizon robotic planning that leverages vision-language models (VLMs) to generate a sequence of actionable steps.","ViLa directly integrates perceptual data into its reasoning and planning process, enabling a profound understanding of commonsense knowledge in the visual world, including spatial layouts and object attributes.","It also supports flexible multimodal goal specification and naturally incorporates visual feedback.","Our extensive evaluation, conducted in both real-robot and simulated environments, demonstrates ViLa's superiority over existing LLM-based planners, highlighting its effectiveness in a wide array of open-world manipulation tasks."],"url":"http://arxiv.org/abs/2311.17842v1"}
{"created":"2023-11-29 17:42:05","title":"A quasi-polynomial time algorithm for Multi-Dimensional Scaling via LP hierarchies","abstract":"Multi-dimensional Scaling (MDS) is a family of methods for embedding pair-wise dissimilarities between $n$ objects into low-dimensional space. MDS is widely used as a data visualization tool in the social and biological sciences, statistics, and machine learning. We study the Kamada-Kawai formulation of MDS: given a set of non-negative dissimilarities $\\{d_{i,j}\\}_{i , j \\in [n]}$ over $n$ points, the goal is to find an embedding $\\{x_1,\\dots,x_n\\} \\subset \\mathbb{R}^k$ that minimizes \\[ \\text{OPT} = \\min_{x} \\mathbb{E}_{i,j \\in [n]} \\left[ \\left(1-\\frac{\\|x_i - x_j\\|}{d_{i,j}}\\right)^2 \\right] \\]   Despite its popularity, our theoretical understanding of MDS is extremely limited. Recently, Demaine, Hesterberg, Koehler, Lynch, and Urschel (arXiv:2109.11505) gave the first approximation algorithm with provable guarantees for Kamada-Kawai, which achieves an embedding with cost $\\text{OPT} +\\epsilon$ in $n^2 \\cdot 2^{\\tilde{\\mathcal{O}}(k \\Delta^4 / \\epsilon^2)}$ time, where $\\Delta$ is the aspect ratio of the input dissimilarities. In this work, we give the first approximation algorithm for MDS with quasi-polynomial dependency on $\\Delta$: for target dimension $k$, we achieve a solution with cost $\\mathcal{O}(\\text{OPT}^{ \\hspace{0.04in}1/k } \\cdot \\log(\\Delta/\\epsilon) )+ \\epsilon$ in time $n^{ \\mathcal{O}(1)} \\cdot 2^{\\tilde{\\mathcal{O}}( k^2 (\\log(\\Delta)/\\epsilon)^{k/2 + 1} ) }$.   Our approach is based on a novel analysis of a conditioning-based rounding scheme for the Sherali-Adams LP Hierarchy. Crucially, our analysis exploits the geometry of low-dimensional Euclidean space, allowing us to avoid an exponential dependence on the aspect ratio $\\Delta$. We believe our geometry-aware treatment of the Sherali-Adams Hierarchy is an important step towards developing general-purpose techniques for efficient metric optimization algorithms.","sentences":["Multi-dimensional Scaling (MDS) is a family of methods for embedding pair-wise dissimilarities between $n$ objects into low-dimensional space.","MDS is widely used as a data visualization tool in the social and biological sciences, statistics, and machine learning.","We study the Kamada-Kawai formulation of MDS: given a set of non-negative dissimilarities $\\{d_{i,j}\\}_{i , j \\in","[n]}$ over $n$ points, the goal is to find an embedding $\\{x_1,\\dots,x_n\\} \\subset \\mathbb{R}^k$ that minimizes \\[ \\text{OPT} = \\min_{x} \\mathbb{E}_{i,j \\in [n]} \\left[ \\left(1-\\frac{\\|x_i - x_j\\|}{d_{i,j}}\\right)^2 \\right] \\]   Despite its popularity, our theoretical understanding of MDS is extremely limited.","Recently, Demaine, Hesterberg, Koehler, Lynch, and Urschel (arXiv:2109.11505) gave the first approximation algorithm with provable guarantees for Kamada-Kawai, which achieves an embedding with cost $\\text{OPT} +\\epsilon$ in $n^2 \\cdot 2^{\\tilde{\\mathcal{O}}(k \\Delta^4 / \\epsilon^2)}$ time, where $\\Delta$ is the aspect ratio of the input dissimilarities.","In this work, we give the first approximation algorithm for MDS with quasi-polynomial dependency on $\\Delta$: for target dimension $k$, we achieve a solution with cost $\\mathcal{O}(\\text{OPT}^{ \\hspace{0.04in}1/k } \\cdot \\log(\\Delta/\\epsilon) )","+ \\epsilon$ in time $n^{ \\mathcal{O}(1)} \\cdot 2^{\\tilde{\\mathcal{O}}( k^2 (\\log(\\Delta)/\\epsilon)^{k/2 + 1} ) }$.   ","Our approach is based on a novel analysis of a conditioning-based rounding scheme for the Sherali-Adams LP Hierarchy.","Crucially, our analysis exploits the geometry of low-dimensional Euclidean space, allowing us to avoid an exponential dependence on the aspect ratio $\\Delta$. We believe our geometry-aware treatment of the Sherali-Adams Hierarchy is an important step towards developing general-purpose techniques for efficient metric optimization algorithms."],"url":"http://arxiv.org/abs/2311.17840v1"}
{"created":"2023-11-29 17:22:28","title":"Anomalous Behavior Detection in Trajectory Data of Older Drivers","abstract":"Given a road network and a set of trajectory data, the anomalous behavior detection (ABD) problem is to identify drivers that show significant directional deviations, hardbrakings, and accelerations in their trips. The ABD problem is important in many societal applications, including Mild Cognitive Impairment (MCI) detection and safe route recommendations for older drivers. The ABD problem is computationally challenging due to the large size of temporally-detailed trajectories dataset. In this paper, we propose an Edge-Attributed Matrix that can represent the key properties of temporally-detailed trajectory datasets and identify abnormal driving behaviors. Experiments using real-world datasets demonstrated that our approach identifies abnormal driving behaviors.","sentences":["Given a road network and a set of trajectory data, the anomalous behavior detection (ABD) problem is to identify drivers that show significant directional deviations, hardbrakings, and accelerations in their trips.","The ABD problem is important in many societal applications, including Mild Cognitive Impairment (MCI) detection and safe route recommendations for older drivers.","The ABD problem is computationally challenging due to the large size of temporally-detailed trajectories dataset.","In this paper, we propose an Edge-Attributed Matrix that can represent the key properties of temporally-detailed trajectory datasets and identify abnormal driving behaviors.","Experiments using real-world datasets demonstrated that our approach identifies abnormal driving behaviors."],"url":"http://arxiv.org/abs/2311.17822v1"}
{"created":"2023-11-29 17:10:16","title":"A Survey on Design Methodologies for Accelerating Deep Learning on Heterogeneous Architectures","abstract":"In recent years, the field of Deep Learning has seen many disruptive and impactful advancements. Given the increasing complexity of deep neural networks, the need for efficient hardware accelerators has become more and more pressing to design heterogeneous HPC platforms. The design of Deep Learning accelerators requires a multidisciplinary approach, combining expertise from several areas, spanning from computer architecture to approximate computing, computational models, and machine learning algorithms. Several methodologies and tools have been proposed to design accelerators for Deep Learning, including hardware-software co-design approaches, high-level synthesis methods, specific customized compilers, and methodologies for design space exploration, modeling, and simulation. These methodologies aim to maximize the exploitable parallelism and minimize data movement to achieve high performance and energy efficiency. This survey provides a holistic review of the most influential design methodologies and EDA tools proposed in recent years to implement Deep Learning accelerators, offering the reader a wide perspective in this rapidly evolving field. In particular, this work complements the previous survey proposed by the same authors in [203], which focuses on Deep Learning hardware accelerators for heterogeneous HPC platforms.","sentences":["In recent years, the field of Deep Learning has seen many disruptive and impactful advancements.","Given the increasing complexity of deep neural networks, the need for efficient hardware accelerators has become more and more pressing to design heterogeneous HPC platforms.","The design of Deep Learning accelerators requires a multidisciplinary approach, combining expertise from several areas, spanning from computer architecture to approximate computing, computational models, and machine learning algorithms.","Several methodologies and tools have been proposed to design accelerators for Deep Learning, including hardware-software co-design approaches, high-level synthesis methods, specific customized compilers, and methodologies for design space exploration, modeling, and simulation.","These methodologies aim to maximize the exploitable parallelism and minimize data movement to achieve high performance and energy efficiency.","This survey provides a holistic review of the most influential design methodologies and EDA tools proposed in recent years to implement Deep Learning accelerators, offering the reader a wide perspective in this rapidly evolving field.","In particular, this work complements the previous survey proposed by the same authors in [203], which focuses on Deep Learning hardware accelerators for heterogeneous HPC platforms."],"url":"http://arxiv.org/abs/2311.17815v1"}
{"created":"2023-11-29 16:51:21","title":"Towards Efficient Hyperdimensional Computing Using Photonics","abstract":"Over the past few years, silicon photonics-based computing has emerged as a promising alternative to CMOS-based computing for Deep Neural Networks (DNN). Unfortunately, the non-linear operations and the high-precision requirements of DNNs make it extremely challenging to design efficient silicon photonics-based systems for DNN inference and training. Hyperdimensional Computing (HDC) is an emerging, brain-inspired machine learning technique that enjoys several advantages over existing DNNs, including being lightweight, requiring low-precision operands, and being robust to noise introduced by the nonidealities in the hardware. For HDC, computing in-memory (CiM) approaches have been widely used, as CiM reduces the data transfer cost if the operands can fit into the memory. However, inefficient multi-bit operations, high write latency, and low endurance make CiM ill-suited for HDC. On the other hand, the existing electro-photonic DNN accelerators are inefficient for HDC because they are specifically optimized for matrix multiplication in DNNs and consume a lot of power with high-precision data converters.   In this paper, we argue that photonic computing and HDC complement each other better than photonic computing and DNNs, or CiM and HDC. We propose PhotoHDC, the first-ever electro-photonic accelerator for HDC training and inference, supporting the basic, record-based, and graph encoding schemes. Evaluating with popular datasets, we show that our accelerator can achieve two to five orders of magnitude lower EDP than the state-of-the-art electro-photonic DNN accelerators for implementing HDC training and inference. PhotoHDC also achieves four orders of magnitude lower energy-delay product than CiM-based accelerators for both HDC training and inference.","sentences":["Over the past few years, silicon photonics-based computing has emerged as a promising alternative to CMOS-based computing for Deep Neural Networks (DNN).","Unfortunately, the non-linear operations and the high-precision requirements of DNNs make it extremely challenging to design efficient silicon photonics-based systems for DNN inference and training.","Hyperdimensional Computing (HDC) is an emerging, brain-inspired machine learning technique that enjoys several advantages over existing DNNs, including being lightweight, requiring low-precision operands, and being robust to noise introduced by the nonidealities in the hardware.","For HDC, computing in-memory (CiM) approaches have been widely used, as CiM reduces the data transfer cost if the operands can fit into the memory.","However, inefficient multi-bit operations, high write latency, and low endurance make CiM ill-suited for HDC.","On the other hand, the existing electro-photonic DNN accelerators are inefficient for HDC because they are specifically optimized for matrix multiplication in DNNs and consume a lot of power with high-precision data converters.   ","In this paper, we argue that photonic computing and HDC complement each other better than photonic computing and DNNs, or CiM and HDC.","We propose PhotoHDC, the first-ever electro-photonic accelerator for HDC training and inference, supporting the basic, record-based, and graph encoding schemes.","Evaluating with popular datasets, we show that our accelerator can achieve two to five orders of magnitude lower EDP than the state-of-the-art electro-photonic DNN accelerators for implementing HDC training and inference.","PhotoHDC also achieves four orders of magnitude lower energy-delay product than CiM-based accelerators for both HDC training and inference."],"url":"http://arxiv.org/abs/2311.17801v1"}
{"created":"2023-11-29 16:45:43","title":"Marginal Laplacian Score","abstract":"High-dimensional imbalanced data poses a machine learning challenge. In the absence of sufficient or high-quality labels, unsupervised feature selection methods are crucial for the success of subsequent algorithms. Therefore, there is a growing need for unsupervised feature selection algorithms focused on imbalanced data. Thus, we propose a Marginal Laplacian Score (MLS) a modification of the well-known Laplacian Score (LS) to be better suited for imbalance data. We introduce an assumption that the minority class or anomalous appear more frequently in the margin of the features. Consequently, MLS aims to preserve the local structure of the data set's margin. As MLS is better suited for handling imbalanced data, we propose its integration into modern feature selection methods that utilize the Laplacian score. We integrate the MLS algorithm into the Differentiable Unsupervised Feature Selection (DUFS), resulting in DUFS-MLS. The proposed methods demonstrate robust and improved performance on synthetic and public data sets.","sentences":["High-dimensional imbalanced data poses a machine learning challenge.","In the absence of sufficient or high-quality labels, unsupervised feature selection methods are crucial for the success of subsequent algorithms.","Therefore, there is a growing need for unsupervised feature selection algorithms focused on imbalanced data.","Thus, we propose a Marginal Laplacian Score (MLS) a modification of the well-known Laplacian Score (LS) to be better suited for imbalance data.","We introduce an assumption that the minority class or anomalous appear more frequently in the margin of the features.","Consequently, MLS aims to preserve the local structure of the data set's margin.","As MLS is better suited for handling imbalanced data, we propose its integration into modern feature selection methods that utilize the Laplacian score.","We integrate the MLS algorithm into the Differentiable Unsupervised Feature Selection (DUFS), resulting in DUFS-MLS.","The proposed methods demonstrate robust and improved performance on synthetic and public data sets."],"url":"http://arxiv.org/abs/2311.17795v1"}
{"created":"2023-11-29 16:34:39","title":"The Symmetric alpha-Stable Privacy Mechanism","abstract":"With the rapid growth of digital platforms, there is increasing apprehension about how personal data is being collected, stored, and used by various entities. These concerns range from data breaches and cyber-attacks to potential misuse of personal information for targeted advertising and surveillance. As a result, differential privacy (DP) has emerged as a prominent tool for quantifying a system's level of protection. The Gaussian mechanism is commonly used because the Gaussian density is closed under convolution, a common method utilized when aggregating datasets. However, the Gaussian mechanism only satisfies approximate differential privacy. In this work, we present novel analysis of the Symmetric alpha-Stable (SaS) mechanism. We prove that the mechanism is purely differentially private while remaining closed under convolution. From our analysis, we believe the SaS Mechanism is an appealing choice for privacy focused applications.","sentences":["With the rapid growth of digital platforms, there is increasing apprehension about how personal data is being collected, stored, and used by various entities.","These concerns range from data breaches and cyber-attacks to potential misuse of personal information for targeted advertising and surveillance.","As a result, differential privacy (DP) has emerged as a prominent tool for quantifying a system's level of protection.","The Gaussian mechanism is commonly used because the Gaussian density is closed under convolution, a common method utilized when aggregating datasets.","However, the Gaussian mechanism only satisfies approximate differential privacy.","In this work, we present novel analysis of the Symmetric alpha-Stable (SaS) mechanism.","We prove that the mechanism is purely differentially private while remaining closed under convolution.","From our analysis, we believe the SaS Mechanism is an appealing choice for privacy focused applications."],"url":"http://arxiv.org/abs/2311.17789v1"}
{"created":"2023-11-29 16:33:19","title":"DSS: Synthesizing long Digital Ink using Data augmentation, Style encoding and Split generation","abstract":"As text generative models can give increasingly long answers, we tackle the problem of synthesizing long text in digital ink. We show that the commonly used models for this task fail to generalize to long-form data and how this problem can be solved by augmenting the training data, changing the model architecture and the inference procedure. These methods use contrastive learning technique and are tailored specifically for the handwriting domain. They can be applied to any encoder-decoder model that works with digital ink. We demonstrate that our method reduces the character error rate on long-form English data by half compared to baseline RNN and by 16% compared to the previous approach that aims at addressing the same problem. We show that all three parts of the method improve recognizability of generated inks. In addition, we evaluate synthesized data in a human study and find that people perceive most of generated data as real.","sentences":["As text generative models can give increasingly long answers, we tackle the problem of synthesizing long text in digital ink.","We show that the commonly used models for this task fail to generalize to long-form data and how this problem can be solved by augmenting the training data, changing the model architecture and the inference procedure.","These methods use contrastive learning technique and are tailored specifically for the handwriting domain.","They can be applied to any encoder-decoder model that works with digital ink.","We demonstrate that our method reduces the character error rate on long-form English data by half compared to baseline RNN and by 16% compared to the previous approach that aims at addressing the same problem.","We show that all three parts of the method improve recognizability of generated inks.","In addition, we evaluate synthesized data in a human study and find that people perceive most of generated data as real."],"url":"http://arxiv.org/abs/2311.17786v1"}
{"created":"2023-11-29 16:23:42","title":"Understanding the leakage process for multi-scale water infrastructure asset management: necessity for a dialogue between sociological and data sciences","abstract":"Reducing water losses is one of the most pressing issues for modern water utilities. To that end, improving the efficiency of the pipe leakage and repair process and aiding the selection of the pipes that are to be renewed or rehabilitated are essential. To help addressing these tasks, in this work, we develop a model predicting the probability of a pipe to be leaking. This work is set the context of a multidisciplinary project with Soci{\\'e}t{\\'e} Wallone des Eaux and it is aligned with their goal to improve their Infrastructure Asset Management in the short and the long terms. Developing and feeding this leakage probability model relies on an intense data processing phase, mobilizing data and water engineering sciences, since the raw data from SWDE is not ready to be used in the model. Complementarily, we thus employ techniques from sociology (e.g., interviews, analyses of the human/non-human actors and of the tools, sociotechnical translations) in order to complete the data, to improve our understanding of its production, and to increase its value and its availability for the prediction of the pipe leakage probability. This model will be implemented in SWDE's information system and used for strategies to reduce water losses.","sentences":["Reducing water losses is one of the most pressing issues for modern water utilities.","To that end, improving the efficiency of the pipe leakage and repair process and aiding the selection of the pipes that are to be renewed or rehabilitated are essential.","To help addressing these tasks, in this work, we develop a model predicting the probability of a pipe to be leaking.","This work is set the context of a multidisciplinary project with Soci{\\'e}t{\\'e} Wallone des Eaux and it is aligned with their goal to improve their Infrastructure Asset Management in the short and the long terms.","Developing and feeding this leakage probability model relies on an intense data processing phase, mobilizing data and water engineering sciences, since the raw data from SWDE is not ready to be used in the model.","Complementarily, we thus employ techniques from sociology (e.g., interviews, analyses of the human/non-human actors and of the tools, sociotechnical translations) in order to complete the data, to improve our understanding of its production, and to increase its value and its availability for the prediction of the pipe leakage probability.","This model will be implemented in SWDE's information system and used for strategies to reduce water losses."],"url":"http://arxiv.org/abs/2311.17777v1"}
{"created":"2023-11-29 16:23:06","title":"One-Shot Open Affordance Learning with Foundation Models","abstract":"We introduce One-shot Open Affordance Learning (OOAL), where a model is trained with just one example per base object category, but is expected to identify novel objects and affordances. While vision-language models excel at recognizing novel objects and scenes, they often struggle to understand finer levels of granularity such as affordances. To handle this issue, we conduct a comprehensive analysis of existing foundation models, to explore their inherent understanding of affordances and assess the potential for data-limited affordance learning. We then propose a vision-language framework with simple and effective designs that boost the alignment between visual features and affordance text embeddings. Experiments on two affordance segmentation benchmarks show that the proposed method outperforms state-of-the-art models with less than 1% of the full training data, and exhibits reasonable generalization capability on unseen objects and affordances.","sentences":["We introduce One-shot Open Affordance Learning (OOAL), where a model is trained with just one example per base object category, but is expected to identify novel objects and affordances.","While vision-language models excel at recognizing novel objects and scenes, they often struggle to understand finer levels of granularity such as affordances.","To handle this issue, we conduct a comprehensive analysis of existing foundation models, to explore their inherent understanding of affordances and assess the potential for data-limited affordance learning.","We then propose a vision-language framework with simple and effective designs that boost the alignment between visual features and affordance text embeddings.","Experiments on two affordance segmentation benchmarks show that the proposed method outperforms state-of-the-art models with less than 1% of the full training data, and exhibits reasonable generalization capability on unseen objects and affordances."],"url":"http://arxiv.org/abs/2311.17776v1"}
{"created":"2023-11-29 16:06:17","title":"Robustness Approaches for the Examination Timetabling Problem under Data Uncertainty","abstract":"In the literature the examination timetabling problem (ETTP) is often considered a post-enrollment problem (PE-ETTP). In the real world, universities often schedule their exams before students register using information from previous terms. A direct consequence of this approach is the uncertainty present in the resulting models. In this work we discuss several approaches available in the robust optimization literature. We consider the implications of each approach in respect to the examination timetabling problem and present how the most favorable approaches can be applied to the ETTP. Afterwards we analyze the impact of some possible implementations of the given robustness approaches on two real world instances and several random instances generated by our instance generation framework which we introduce in this work.","sentences":["In the literature the examination timetabling problem (ETTP) is often considered a post-enrollment problem (PE-ETTP).","In the real world, universities often schedule their exams before students register using information from previous terms.","A direct consequence of this approach is the uncertainty present in the resulting models.","In this work we discuss several approaches available in the robust optimization literature.","We consider the implications of each approach in respect to the examination timetabling problem and present how the most favorable approaches can be applied to the ETTP.","Afterwards we analyze the impact of some possible implementations of the given robustness approaches on two real world instances and several random instances generated by our instance generation framework which we introduce in this work."],"url":"http://arxiv.org/abs/2311.17766v1"}
{"created":"2023-11-29 15:54:15","title":"Addressing Membership Inference Attack in Federated Learning with Model Compression","abstract":"Federated Learning (FL) has been proposed as a privacy-preserving solution for machine learning. However, recent works have shown that Federated Learning can leak private client data through membership attacks. In this paper, we show that the effectiveness of these attacks on the clients negatively correlates with the size of the client datasets and model complexity. Based on this finding, we propose model-agnostic Federated Learning as a privacy-enhancing solution because it enables the use of models of varying complexity in the clients. To this end, we present $\\texttt{MaPP-FL}$, a novel privacy-aware FL approach that leverages model compression on the clients while keeping a full model on the server. We compare the performance of $\\texttt{MaPP-FL}$ against state-of-the-art model-agnostic FL methods on the CIFAR-10, CIFAR-100, and FEMNIST vision datasets. Our experiments show the effectiveness of $\\texttt{MaPP-FL}$ in preserving the clients' and the server's privacy while achieving competitive classification accuracies.","sentences":["Federated Learning (FL) has been proposed as a privacy-preserving solution for machine learning.","However, recent works have shown that Federated Learning can leak private client data through membership attacks.","In this paper, we show that the effectiveness of these attacks on the clients negatively correlates with the size of the client datasets and model complexity.","Based on this finding, we propose model-agnostic Federated Learning as a privacy-enhancing solution because it enables the use of models of varying complexity in the clients.","To this end, we present $\\texttt{MaPP-FL}$, a novel privacy-aware FL approach that leverages model compression on the clients while keeping a full model on the server.","We compare the performance of $\\texttt{MaPP-FL}$ against state-of-the-art model-agnostic FL methods on the CIFAR-10, CIFAR-100, and FEMNIST vision datasets.","Our experiments show the effectiveness of $\\texttt{MaPP-FL}$ in preserving the clients' and the server's privacy while achieving competitive classification accuracies."],"url":"http://arxiv.org/abs/2311.17750v1"}
{"created":"2023-11-29 15:49:31","title":"Variational Bayes image restoration with compressive autoencoders","abstract":"Regularization of inverse problems is of paramount importance in computational imaging. The ability of neural networks to learn efficient image representations has been recently exploited to design powerful data-driven regularizers. While state-of-the-art plug-and-play methods rely on an implicit regularization provided by neural denoisers, alternative Bayesian approaches consider Maximum A Posteriori (MAP) estimation in the latent space of a generative model, thus with an explicit regularization. However, state-of-the-art deep generative models require a huge amount of training data compared to denoisers. Besides, their complexity hampers the optimization of the latent MAP. In this work, we propose to use compressive autoencoders for latent estimation. These networks, which can be seen as variational autoencoders with a flexible latent prior, are smaller and easier to train than state-of-the-art generative models. We then introduce the Variational Bayes Latent Estimation (VBLE) algorithm, which performs this estimation within the framework of variational inference. This allows for fast and easy (approximate) posterior sampling. Experimental results on image datasets BSD and FFHQ demonstrate that VBLE reaches similar performance than state-of-the-art plug-and-play methods, while being able to quantify uncertainties faster than other existing posterior sampling techniques.","sentences":["Regularization of inverse problems is of paramount importance in computational imaging.","The ability of neural networks to learn efficient image representations has been recently exploited to design powerful data-driven regularizers.","While state-of-the-art plug-and-play methods rely on an implicit regularization provided by neural denoisers, alternative Bayesian approaches consider Maximum A Posteriori (MAP) estimation in the latent space of a generative model, thus with an explicit regularization.","However, state-of-the-art deep generative models require a huge amount of training data compared to denoisers.","Besides, their complexity hampers the optimization of the latent MAP.","In this work, we propose to use compressive autoencoders for latent estimation.","These networks, which can be seen as variational autoencoders with a flexible latent prior, are smaller and easier to train than state-of-the-art generative models.","We then introduce the Variational Bayes Latent Estimation (VBLE) algorithm, which performs this estimation within the framework of variational inference.","This allows for fast and easy (approximate) posterior sampling.","Experimental results on image datasets BSD and FFHQ demonstrate that VBLE reaches similar performance than state-of-the-art plug-and-play methods, while being able to quantify uncertainties faster than other existing posterior sampling techniques."],"url":"http://arxiv.org/abs/2311.17744v1"}
{"created":"2023-11-29 15:49:24","title":"Mukhyansh: A Headline Generation Dataset for Indic Languages","abstract":"The task of headline generation within the realm of Natural Language Processing (NLP) holds immense significance, as it strives to distill the true essence of textual content into concise and attention-grabbing summaries. While noteworthy progress has been made in headline generation for widely spoken languages like English, there persist numerous challenges when it comes to generating headlines in low-resource languages, such as the rich and diverse Indian languages. A prominent obstacle that specifically hinders headline generation in Indian languages is the scarcity of high-quality annotated data. To address this crucial gap, we proudly present Mukhyansh, an extensive multilingual dataset, tailored for Indian language headline generation. Comprising an impressive collection of over 3.39 million article-headline pairs, Mukhyansh spans across eight prominent Indian languages, namely Telugu, Tamil, Kannada, Malayalam, Hindi, Bengali, Marathi, and Gujarati. We present a comprehensive evaluation of several state-of-the-art baseline models. Additionally, through an empirical analysis of existing works, we demonstrate that Mukhyansh outperforms all other models, achieving an impressive average ROUGE-L score of 31.43 across all 8 languages.","sentences":["The task of headline generation within the realm of Natural Language Processing (NLP) holds immense significance, as it strives to distill the true essence of textual content into concise and attention-grabbing summaries.","While noteworthy progress has been made in headline generation for widely spoken languages like English, there persist numerous challenges when it comes to generating headlines in low-resource languages, such as the rich and diverse Indian languages.","A prominent obstacle that specifically hinders headline generation in Indian languages is the scarcity of high-quality annotated data.","To address this crucial gap, we proudly present Mukhyansh, an extensive multilingual dataset, tailored for Indian language headline generation.","Comprising an impressive collection of over 3.39 million article-headline pairs, Mukhyansh spans across eight prominent Indian languages, namely Telugu, Tamil, Kannada, Malayalam, Hindi, Bengali, Marathi, and Gujarati.","We present a comprehensive evaluation of several state-of-the-art baseline models.","Additionally, through an empirical analysis of existing works, we demonstrate that Mukhyansh outperforms all other models, achieving an impressive average ROUGE-L score of 31.43 across all 8 languages."],"url":"http://arxiv.org/abs/2311.17743v1"}
{"created":"2023-11-29 15:44:39","title":"End-to-end Joint Rich and Normalized ASR with a limited amount of rich training data","abstract":"Joint rich and normalized automatic speech recognition (ASR), that produces transcriptions both with and without punctuation and capitalization, remains a challenge. End-to-end (E2E) ASR models offer both convenience and the ability to perform such joint transcription of speech. Training such models requires paired speech and rich text data, which is not widely available. In this paper, we compare two different approaches to train a stateless Transducer-based E2E joint rich and normalized ASR system, ready for streaming applications, with a limited amount of rich labeled data. The first approach uses a language model to generate pseudo-rich transcriptions of normalized training data. The second approach uses a single decoder conditioned on the type of the output. The first approach leads to E2E rich ASR which perform better on out-of-domain data, with up to 9% relative reduction in errors. The second approach demonstrates the feasibility of an E2E joint rich and normalized ASR system using as low as 5% rich training data with moderate (2.42% absolute) increase in errors.","sentences":["Joint rich and normalized automatic speech recognition (ASR), that produces transcriptions both with and without punctuation and capitalization, remains a challenge.","End-to-end (E2E) ASR models offer both convenience and the ability to perform such joint transcription of speech.","Training such models requires paired speech and rich text data, which is not widely available.","In this paper, we compare two different approaches to train a stateless Transducer-based E2E joint rich and normalized ASR system, ready for streaming applications, with a limited amount of rich labeled data.","The first approach uses a language model to generate pseudo-rich transcriptions of normalized training data.","The second approach uses a single decoder conditioned on the type of the output.","The first approach leads to E2E rich ASR which perform better on out-of-domain data, with up to 9% relative reduction in errors.","The second approach demonstrates the feasibility of an E2E joint rich and normalized ASR system using as low as 5% rich training data with moderate (2.42% absolute) increase in errors."],"url":"http://arxiv.org/abs/2311.17741v1"}
{"created":"2023-11-29 15:40:11","title":"GenZI: Zero-Shot 3D Human-Scene Interaction Generation","abstract":"Can we synthesize 3D humans interacting with scenes without learning from any 3D human-scene interaction data? We propose GenZI, the first zero-shot approach to generating 3D human-scene interactions. Key to GenZI is our distillation of interaction priors from large vision-language models (VLMs), which have learned a rich semantic space of 2D human-scene compositions. Given a natural language description and a coarse point location of the desired interaction in a 3D scene, we first leverage VLMs to imagine plausible 2D human interactions inpainted into multiple rendered views of the scene. We then formulate a robust iterative optimization to synthesize the pose and shape of a 3D human model in the scene, guided by consistency with the 2D interaction hypotheses. In contrast to existing learning-based approaches, GenZI circumvents the conventional need for captured 3D interaction data, and allows for flexible control of the 3D interaction synthesis with easy-to-use text prompts. Extensive experiments show that our zero-shot approach has high flexibility and generality, making it applicable to diverse scene types, including both indoor and outdoor environments.","sentences":["Can we synthesize 3D humans interacting with scenes without learning from any 3D human-scene interaction data?","We propose GenZI, the first zero-shot approach to generating 3D human-scene interactions.","Key to GenZI is our distillation of interaction priors from large vision-language models (VLMs), which have learned a rich semantic space of 2D human-scene compositions.","Given a natural language description and a coarse point location of the desired interaction in a 3D scene, we first leverage VLMs to imagine plausible 2D human interactions inpainted into multiple rendered views of the scene.","We then formulate a robust iterative optimization to synthesize the pose and shape of a 3D human model in the scene, guided by consistency with the 2D interaction hypotheses.","In contrast to existing learning-based approaches, GenZI circumvents the conventional need for captured 3D interaction data, and allows for flexible control of the 3D interaction synthesis with easy-to-use text prompts.","Extensive experiments show that our zero-shot approach has high flexibility and generality, making it applicable to diverse scene types, including both indoor and outdoor environments."],"url":"http://arxiv.org/abs/2311.17737v1"}
{"created":"2023-11-29 15:21:35","title":"SenTest: Evaluating Robustness of Sentence Encoders","abstract":"Contrastive learning has proven to be an effective method for pre-training models using weakly labeled data in the vision domain. Sentence transformers are the NLP counterparts to this architecture, and have been growing in popularity due to their rich and effective sentence representations. Having effective sentence representations is paramount in multiple tasks, such as information retrieval, retrieval augmented generation (RAG), and sentence comparison. Keeping in mind the deployability factor of transformers, evaluating the robustness of sentence transformers is of utmost importance. This work focuses on evaluating the robustness of the sentence encoders. We employ several adversarial attacks to evaluate its robustness. This system uses character-level attacks in the form of random character substitution, word-level attacks in the form of synonym replacement, and sentence-level attacks in the form of intra-sentence word order shuffling. The results of the experiments strongly undermine the robustness of sentence encoders. The models produce significantly different predictions as well as embeddings on perturbed datasets. The accuracy of the models can fall up to 15 percent on perturbed datasets as compared to unperturbed datasets. Furthermore, the experiments demonstrate that these embeddings does capture the semantic and syntactic structure (sentence order) of sentences. However, existing supervised classification strategies fail to leverage this information, and merely function as n-gram detectors.","sentences":["Contrastive learning has proven to be an effective method for pre-training models using weakly labeled data in the vision domain.","Sentence transformers are the NLP counterparts to this architecture, and have been growing in popularity due to their rich and effective sentence representations.","Having effective sentence representations is paramount in multiple tasks, such as information retrieval, retrieval augmented generation (RAG), and sentence comparison.","Keeping in mind the deployability factor of transformers, evaluating the robustness of sentence transformers is of utmost importance.","This work focuses on evaluating the robustness of the sentence encoders.","We employ several adversarial attacks to evaluate its robustness.","This system uses character-level attacks in the form of random character substitution, word-level attacks in the form of synonym replacement, and sentence-level attacks in the form of intra-sentence word order shuffling.","The results of the experiments strongly undermine the robustness of sentence encoders.","The models produce significantly different predictions as well as embeddings on perturbed datasets.","The accuracy of the models can fall up to 15 percent on perturbed datasets as compared to unperturbed datasets.","Furthermore, the experiments demonstrate that these embeddings does capture the semantic and syntactic structure (sentence order) of sentences.","However, existing supervised classification strategies fail to leverage this information, and merely function as n-gram detectors."],"url":"http://arxiv.org/abs/2311.17722v1"}
{"created":"2023-11-29 15:11:03","title":"SAMPro3D: Locating SAM Prompts in 3D for Zero-Shot Scene Segmentation","abstract":"We introduce SAMPro3D for zero-shot 3D indoor scene segmentation. Given the 3D point cloud and multiple posed 2D frames of 3D scenes, our approach segments 3D scenes by applying the pretrained Segment Anything Model (SAM) to 2D frames. Our key idea involves locating 3D points in scenes as natural 3D prompts to align their projected pixel prompts across frames, ensuring frame-consistency in both pixel prompts and their SAM-predicted masks. Moreover, we suggest filtering out low-quality 3D prompts based on feedback from all 2D frames, for enhancing segmentation quality. We also propose to consolidate different 3D prompts if they are segmenting the same object, bringing a more comprehensive segmentation. Notably, our method does not require any additional training on domain-specific data, enabling us to preserve the zero-shot power of SAM. Extensive qualitative and quantitative results show that our method consistently achieves higher quality and more diverse segmentation than previous zero-shot or fully supervised approaches, and in many cases even surpasses human-level annotations. The project page can be accessed at https://mutianxu.github.io/sampro3d/.","sentences":["We introduce SAMPro3D for zero-shot 3D indoor scene segmentation.","Given the 3D point cloud and multiple posed 2D frames of 3D scenes, our approach segments 3D scenes by applying the pretrained Segment Anything Model (SAM) to 2D frames.","Our key idea involves locating 3D points in scenes as natural 3D prompts to align their projected pixel prompts across frames, ensuring frame-consistency in both pixel prompts and their SAM-predicted masks.","Moreover, we suggest filtering out low-quality 3D prompts based on feedback from all 2D frames, for enhancing segmentation quality.","We also propose to consolidate different 3D prompts if they are segmenting the same object, bringing a more comprehensive segmentation.","Notably, our method does not require any additional training on domain-specific data, enabling us to preserve the zero-shot power of SAM.","Extensive qualitative and quantitative results show that our method consistently achieves higher quality and more diverse segmentation than previous zero-shot or fully supervised approaches, and in many cases even surpasses human-level annotations.","The project page can be accessed at https://mutianxu.github.io/sampro3d/."],"url":"http://arxiv.org/abs/2311.17707v1"}
{"created":"2023-11-29 15:09:24","title":"An Efficient Algorithm for Unbalanced 1D Transportation","abstract":"Optimal transport (OT) and unbalanced optimal transport (UOT) are central in many machine learning, statistics and engineering applications. 1D OT is easily solved, with complexity O(n log n), but no efficient algorithm was known for 1D UOT. We present a new approach that leverages the successive shortest path algorithm for the corresponding network flow problem. By employing a suitable representation, we bundle together multiple steps that do not change the cost of the shortest path. We prove that our algorithm solves 1D UOT in O(n log n), closing the gap.","sentences":["Optimal transport (OT) and unbalanced optimal transport (UOT) are central in many machine learning, statistics and engineering applications.","1D OT is easily solved, with complexity O(n log n), but no efficient algorithm was known for 1D UOT.","We present a new approach that leverages the successive shortest path algorithm for the corresponding network flow problem.","By employing a suitable representation, we bundle together multiple steps that do not change the cost of the shortest path.","We prove that our algorithm solves 1D UOT in O(n log n), closing the gap."],"url":"http://arxiv.org/abs/2311.17704v1"}
{"created":"2023-11-29 15:02:46","title":"How to Build an AI Tutor that Can Adapt to Any Course and Provide Accurate Answers Using Large Language Model and Retrieval-Augmented Generation","abstract":"Artificial intelligence is transforming education through data-driven, personalized learning solutions. This paper introduces AI Tutor, an innovative web application that provides personalized tutoring in any subject using state-of-the-art Large Language Model (LLM). AI Tutor ingests course materials to construct an adaptive knowledge base tailored to the course. When students pose questions, it retrieves the most relevant information and generates detailed, conversational responses citing supporting evidence. The system is powered by advanced large language models and Retrieval-Augmented Generation (RAG) techniques for accurate, natural question answering. We present a fully-functional web interface and video demonstration that showcase AI Tutor's versatility across diverse subjects and its ability to produce pedagogically cogent responses. While an initial prototype, this work represents a pioneering step toward AI-enabled tutoring systems that can democratize access to high-quality, customized educational support.","sentences":["Artificial intelligence is transforming education through data-driven, personalized learning solutions.","This paper introduces AI Tutor, an innovative web application that provides personalized tutoring in any subject using state-of-the-art Large Language Model (LLM).","AI Tutor ingests course materials to construct an adaptive knowledge base tailored to the course.","When students pose questions, it retrieves the most relevant information and generates detailed, conversational responses citing supporting evidence.","The system is powered by advanced large language models and Retrieval-Augmented Generation (RAG) techniques for accurate, natural question answering.","We present a fully-functional web interface and video demonstration that showcase AI Tutor's versatility across diverse subjects and its ability to produce pedagogically cogent responses.","While an initial prototype, this work represents a pioneering step toward AI-enabled tutoring systems that can democratize access to high-quality, customized educational support."],"url":"http://arxiv.org/abs/2311.17696v1"}
{"created":"2023-11-29 15:00:06","title":"Toward a Surgeon-in-the-Loop Ophthalmic Robotic Apprentice using Reinforcement and Imitation Learning","abstract":"Robotic-assisted surgical systems have demonstrated significant potential in enhancing surgical precision and minimizing human errors. However, existing systems lack the ability to accommodate the unique preferences and requirements of individual surgeons. Additionally, they primarily focus on general surgeries (e.g., laparoscopy) and are not suitable for highly precise microsurgeries, such as ophthalmic procedures. Thus, we propose a simulation-based image-guided approach for surgeon-centered autonomous agents that can adapt to the individual surgeon's skill level and preferred surgical techniques during ophthalmic cataract surgery. Our approach utilizes a simulated environment to train reinforcement and imitation learning agents guided by image data to perform all tasks of the incision phase of cataract surgery. By integrating the surgeon's actions and preferences into the training process with the surgeon-in-the-loop, our approach enables the robot to implicitly learn and adapt to the individual surgeon's unique approach through demonstrations. This results in a more intuitive and personalized surgical experience for the surgeon. Simultaneously, it ensures consistent performance for the autonomous robotic apprentice. We define and evaluate the effectiveness of our approach using our proposed metrics; and highlight the trade-off between a generic agent and a surgeon-centered adapted agent. Moreover, our approach has the potential to extend to other ophthalmic surgical procedures, opening the door to a new generation of surgeon-in-the-loop autonomous surgical robots. We provide an open-source simulation framework for future development and reproducibility.","sentences":["Robotic-assisted surgical systems have demonstrated significant potential in enhancing surgical precision and minimizing human errors.","However, existing systems lack the ability to accommodate the unique preferences and requirements of individual surgeons.","Additionally, they primarily focus on general surgeries (e.g., laparoscopy) and are not suitable for highly precise microsurgeries, such as ophthalmic procedures.","Thus, we propose a simulation-based image-guided approach for surgeon-centered autonomous agents that can adapt to the individual surgeon's skill level and preferred surgical techniques during ophthalmic cataract surgery.","Our approach utilizes a simulated environment to train reinforcement and imitation learning agents guided by image data to perform all tasks of the incision phase of cataract surgery.","By integrating the surgeon's actions and preferences into the training process with the surgeon-in-the-loop, our approach enables the robot to implicitly learn and adapt to the individual surgeon's unique approach through demonstrations.","This results in a more intuitive and personalized surgical experience for the surgeon.","Simultaneously, it ensures consistent performance for the autonomous robotic apprentice.","We define and evaluate the effectiveness of our approach using our proposed metrics; and highlight the trade-off between a generic agent and a surgeon-centered adapted agent.","Moreover, our approach has the potential to extend to other ophthalmic surgical procedures, opening the door to a new generation of surgeon-in-the-loop autonomous surgical robots.","We provide an open-source simulation framework for future development and reproducibility."],"url":"http://arxiv.org/abs/2311.17693v1"}
{"created":"2023-11-29 14:49:31","title":"AviationGPT: A Large Language Model for the Aviation Domain","abstract":"The advent of ChatGPT and GPT-4 has captivated the world with large language models (LLMs), demonstrating exceptional performance in question-answering, summarization, and content generation. The aviation industry is characterized by an abundance of complex, unstructured text data, replete with technical jargon and specialized terminology. Moreover, labeled data for model building are scarce in this domain, resulting in low usage of aviation text data. The emergence of LLMs presents an opportunity to transform this situation, but there is a lack of LLMs specifically designed for the aviation domain. To address this gap, we propose AviationGPT, which is built on open-source LLaMA-2 and Mistral architectures and continuously trained on a wealth of carefully curated aviation datasets. Experimental results reveal that AviationGPT offers users multiple advantages, including the versatility to tackle diverse natural language processing (NLP) problems (e.g., question-answering, summarization, document writing, information extraction, report querying, data cleaning, and interactive data exploration). It also provides accurate and contextually relevant responses within the aviation domain and significantly improves performance (e.g., over a 40% performance gain in tested cases). With AviationGPT, the aviation industry is better equipped to address more complex research problems and enhance the efficiency and safety of National Airspace System (NAS) operations.","sentences":["The advent of ChatGPT and GPT-4 has captivated the world with large language models (LLMs), demonstrating exceptional performance in question-answering, summarization, and content generation.","The aviation industry is characterized by an abundance of complex, unstructured text data, replete with technical jargon and specialized terminology.","Moreover, labeled data for model building are scarce in this domain, resulting in low usage of aviation text data.","The emergence of LLMs presents an opportunity to transform this situation, but there is a lack of LLMs specifically designed for the aviation domain.","To address this gap, we propose AviationGPT, which is built on open-source LLaMA-2 and Mistral architectures and continuously trained on a wealth of carefully curated aviation datasets.","Experimental results reveal that AviationGPT offers users multiple advantages, including the versatility to tackle diverse natural language processing (NLP) problems (e.g., question-answering, summarization, document writing, information extraction, report querying, data cleaning, and interactive data exploration).","It also provides accurate and contextually relevant responses within the aviation domain and significantly improves performance (e.g., over a 40% performance gain in tested cases).","With AviationGPT, the aviation industry is better equipped to address more complex research problems and enhance the efficiency and safety of National Airspace System (NAS) operations."],"url":"http://arxiv.org/abs/2311.17686v1"}
{"created":"2023-11-29 14:45:11","title":"Who can help me? Reconstructing users' psychological journeys in depression-related social media interactions","abstract":"Social media are increasingly being used as self-help boards, where individuals can disclose personal experiences and feelings and look for support from peers or experts. Here we investigate several popular mental health-related Reddit boards about depression while proposing a novel psycho-social framework. We reconstruct users' psychological/linguistic profiles together with their social interactions. We cover a total of 303,016 users, engaging in 378,483 posts and 1,475,044 comments from 01/05/2018 to 01/05/2020. After identifying a network of users' interactions, e.g., who replied to whom, we open an unprecedented window over psycholinguistic, cognitive, and affective digital traces with relevance for mental health research. Through user-generated content, we identify four categories or archetypes of users in agreement with the Patient Health Engagement model: the emotionally turbulent/under blackout, the aroused, the adherent-yet-conflicted, and the eudaimonically hopeful. Analyzing users' transitions over time through conditional Markov processes, we show how these four archetypes are not consecutive stages. We do not find a linear progression or sequential patient journey, where users evolve from struggling to serenity through feelings of conflict. Instead, we find online users to follow spirals towards both negative and positive archetypal stages. Through psychological/linguistic and social network modelling, we can provide compelling quantitative pieces of evidence on how such a complex path unfolds through positive, negative, and conflicting online contexts. Our approach opens the way to data-informed understandings of psychological coping with mental health issues through social media.","sentences":["Social media are increasingly being used as self-help boards, where individuals can disclose personal experiences and feelings and look for support from peers or experts.","Here we investigate several popular mental health-related Reddit boards about depression while proposing a novel psycho-social framework.","We reconstruct users' psychological/linguistic profiles together with their social interactions.","We cover a total of 303,016 users, engaging in 378,483 posts and 1,475,044 comments from 01/05/2018 to 01/05/2020.","After identifying a network of users' interactions, e.g., who replied to whom, we open an unprecedented window over psycholinguistic, cognitive, and affective digital traces with relevance for mental health research.","Through user-generated content, we identify four categories or archetypes of users in agreement with the Patient Health Engagement model: the emotionally turbulent/under blackout, the aroused, the adherent-yet-conflicted, and the eudaimonically hopeful.","Analyzing users' transitions over time through conditional Markov processes, we show how these four archetypes are not consecutive stages.","We do not find a linear progression or sequential patient journey, where users evolve from struggling to serenity through feelings of conflict.","Instead, we find online users to follow spirals towards both negative and positive archetypal stages.","Through psychological/linguistic and social network modelling, we can provide compelling quantitative pieces of evidence on how such a complex path unfolds through positive, negative, and conflicting online contexts.","Our approach opens the way to data-informed understandings of psychological coping with mental health issues through social media."],"url":"http://arxiv.org/abs/2311.17684v1"}
{"created":"2023-11-29 14:39:38","title":"Improving Minority Stress Detection with Emotions","abstract":"Psychological stress detection is an important task for mental healthcare research, but there has been little prior work investigating the effectiveness of psychological stress models on minority individuals, who are especially vulnerable to poor mental health outcomes. In this work, we use the related task of minority stress detection to evaluate the ability of psychological stress models to understand the language of sexual and gender minorities. We find that traditional psychological stress models underperform on minority stress detection, and we propose using emotion-infused models to reduce that performance disparity. We further demonstrate that multi-task psychological stress models outperform the current state-of-the-art for minority stress detection without directly training on minority stress data. We provide explanatory analysis showing that minority communities have different distributions of emotions than the general population and that emotion-infused models improve the performance of stress models on underrepresented groups because of their effectiveness in low-data environments, and we propose that integrating emotions may benefit underrepresented groups in other mental health detection tasks.","sentences":["Psychological stress detection is an important task for mental healthcare research, but there has been little prior work investigating the effectiveness of psychological stress models on minority individuals, who are especially vulnerable to poor mental health outcomes.","In this work, we use the related task of minority stress detection to evaluate the ability of psychological stress models to understand the language of sexual and gender minorities.","We find that traditional psychological stress models underperform on minority stress detection, and we propose using emotion-infused models to reduce that performance disparity.","We further demonstrate that multi-task psychological stress models outperform the current state-of-the-art for minority stress detection without directly training on minority stress data.","We provide explanatory analysis showing that minority communities have different distributions of emotions than the general population and that emotion-infused models improve the performance of stress models on underrepresented groups because of their effectiveness in low-data environments, and we propose that integrating emotions may benefit underrepresented groups in other mental health detection tasks."],"url":"http://arxiv.org/abs/2311.17676v1"}
{"created":"2023-11-29 13:44:15","title":"Optimization in Mobile Augmented Reality Systems for the Metaverse over Wireless Communications","abstract":"As the essential technical support for Metaverse, Mobile Augmented Reality (MAR) has attracted the attention of many researchers. MAR applications rely on real-time processing of visual and audio data, and thus those heavy workloads can quickly drain the battery of a mobile device. To address such problem, edge-based solutions have appeared for handling some tasks that require more computing power. However, such strategies introduce a new trade-off: reducing the network latency and overall energy consumption requires limiting the size of the data sent to the edge server, which, in turn, results in lower accuracy. In this paper, we design an edge-based MAR system and propose a mathematical model to describe it and analyze the trade-off between latency, accuracy, server resources allocation and energy consumption. Furthermore, an algorithm named LEAO is proposed to solve this problem. We evaluate the performance of the LEAO and other related algorithms across various simulation scenarios. The results demonstrate the superiority of the LEAO algorithm. Finally, our work provides insight into optimization problem in edge-based MAR system for Metaverse.","sentences":["As the essential technical support for Metaverse, Mobile Augmented Reality (MAR) has attracted the attention of many researchers.","MAR applications rely on real-time processing of visual and audio data, and thus those heavy workloads can quickly drain the battery of a mobile device.","To address such problem, edge-based solutions have appeared for handling some tasks that require more computing power.","However, such strategies introduce a new trade-off: reducing the network latency and overall energy consumption requires limiting the size of the data sent to the edge server, which, in turn, results in lower accuracy.","In this paper, we design an edge-based MAR system and propose a mathematical model to describe it and analyze the trade-off between latency, accuracy, server resources allocation and energy consumption.","Furthermore, an algorithm named LEAO is proposed to solve this problem.","We evaluate the performance of the LEAO and other related algorithms across various simulation scenarios.","The results demonstrate the superiority of the LEAO algorithm.","Finally, our work provides insight into optimization problem in edge-based MAR system for Metaverse."],"url":"http://arxiv.org/abs/2311.17630v1"}
{"created":"2023-11-29 13:30:26","title":"The AutoSPADA Platform: User-Friendly Edge Computing for Distributed Learning and Data Analytics in Connected Vehicles","abstract":"Contemporary connected vehicles host numerous applications, such as diagnostics and navigation, and new software is continuously being developed. However, the development process typically requires offline batch processing of large data volumes. In an edge computing approach, data analysts and developers can instead process sensor data directly on computational resources inside vehicles. This enables rapid prototyping to shorten development cycles and reduce the time to create new business values or insights. This paper presents the design, implementation, and operation of the AutoSPADA edge computing platform for distributed data analytics. The platform's design follows scalability, reliability, resource efficiency, privacy, and security principles promoted through mature and industrially proven technologies. In AutoSPADA, computational tasks are general Python scripts, and we provide a library to, for example, read signals from the vehicle and publish results to the cloud. Hence, users only need Python knowledge to use the platform. Moreover, the platform is designed to be extended to support additional programming languages.","sentences":["Contemporary connected vehicles host numerous applications, such as diagnostics and navigation, and new software is continuously being developed.","However, the development process typically requires offline batch processing of large data volumes.","In an edge computing approach, data analysts and developers can instead process sensor data directly on computational resources inside vehicles.","This enables rapid prototyping to shorten development cycles and reduce the time to create new business values or insights.","This paper presents the design, implementation, and operation of the AutoSPADA edge computing platform for distributed data analytics.","The platform's design follows scalability, reliability, resource efficiency, privacy, and security principles promoted through mature and industrially proven technologies.","In AutoSPADA, computational tasks are general Python scripts, and we provide a library to, for example, read signals from the vehicle and publish results to the cloud.","Hence, users only need Python knowledge to use the platform.","Moreover, the platform is designed to be extended to support additional programming languages."],"url":"http://arxiv.org/abs/2311.17621v1"}
{"created":"2023-11-29 13:26:29","title":"ShapeGPT: 3D Shape Generation with A Unified Multi-modal Language Model","abstract":"The advent of large language models, enabling flexibility through instruction-driven approaches, has revolutionized many traditional generative tasks, but large models for 3D data, particularly in comprehensively handling 3D shapes with other modalities, are still under-explored. By achieving instruction-based shape generations, versatile multimodal generative shape models can significantly benefit various fields like 3D virtual construction and network-aided design. In this work, we present ShapeGPT, a shape-included multi-modal framework to leverage strong pre-trained language models to address multiple shape-relevant tasks. Specifically, ShapeGPT employs a word-sentence-paragraph framework to discretize continuous shapes into shape words, further assembles these words for shape sentences, as well as integrates shape with instructional text for multi-modal paragraphs. To learn this shape-language model, we use a three-stage training scheme, including shape representation, multimodal alignment, and instruction-based generation, to align shape-language codebooks and learn the intricate correlations among these modalities. Extensive experiments demonstrate that ShapeGPT achieves comparable performance across shape-relevant tasks, including text-to-shape, shape-to-text, shape completion, and shape editing.","sentences":["The advent of large language models, enabling flexibility through instruction-driven approaches, has revolutionized many traditional generative tasks, but large models for 3D data, particularly in comprehensively handling 3D shapes with other modalities, are still under-explored.","By achieving instruction-based shape generations, versatile multimodal generative shape models can significantly benefit various fields like 3D virtual construction and network-aided design.","In this work, we present ShapeGPT, a shape-included multi-modal framework to leverage strong pre-trained language models to address multiple shape-relevant tasks.","Specifically, ShapeGPT employs a word-sentence-paragraph framework to discretize continuous shapes into shape words, further assembles these words for shape sentences, as well as integrates shape with instructional text for multi-modal paragraphs.","To learn this shape-language model, we use a three-stage training scheme, including shape representation, multimodal alignment, and instruction-based generation, to align shape-language codebooks and learn the intricate correlations among these modalities.","Extensive experiments demonstrate that ShapeGPT achieves comparable performance across shape-relevant tasks, including text-to-shape, shape-to-text, shape completion, and shape editing."],"url":"http://arxiv.org/abs/2311.17618v1"}
{"created":"2023-11-29 13:05:20","title":"Adversarial Robust Memory-Based Continual Learner","abstract":"Despite the remarkable advances that have been made in continual learning, the adversarial vulnerability of such methods has not been fully discussed. We delve into the adversarial robustness of memory-based continual learning algorithms and observe limited robustness improvement by directly applying adversarial training techniques. Preliminary studies reveal the twin challenges for building adversarial robust continual learners: accelerated forgetting in continual learning and gradient obfuscation in adversarial robustness. In this study, we put forward a novel adversarial robust memory-based continual learner that adjusts data logits to mitigate the forgetting of pasts caused by adversarial samples. Furthermore, we devise a gradient-based data selection mechanism to overcome the gradient obfuscation caused by limited stored data. The proposed approach can widely integrate with existing memory-based continual learning as well as adversarial training algorithms in a plug-and-play way. Extensive experiments on Split-CIFAR10/100 and Split-Tiny-ImageNet demonstrate the effectiveness of our approach, achieving up to 8.13% higher accuracy for adversarial data.","sentences":["Despite the remarkable advances that have been made in continual learning, the adversarial vulnerability of such methods has not been fully discussed.","We delve into the adversarial robustness of memory-based continual learning algorithms and observe limited robustness improvement by directly applying adversarial training techniques.","Preliminary studies reveal the twin challenges for building adversarial robust continual learners: accelerated forgetting in continual learning and gradient obfuscation in adversarial robustness.","In this study, we put forward a novel adversarial robust memory-based continual learner that adjusts data logits to mitigate the forgetting of pasts caused by adversarial samples.","Furthermore, we devise a gradient-based data selection mechanism to overcome the gradient obfuscation caused by limited stored data.","The proposed approach can widely integrate with existing memory-based continual learning as well as adversarial training algorithms in a plug-and-play way.","Extensive experiments on Split-CIFAR10/100 and Split-Tiny-ImageNet demonstrate the effectiveness of our approach, achieving up to 8.13% higher accuracy for adversarial data."],"url":"http://arxiv.org/abs/2311.17608v1"}
{"created":"2023-11-29 13:05:06","title":"Topology-Preserving Adversarial Training","abstract":"Despite the effectiveness in improving the robustness of neural networks, adversarial training has suffered from the natural accuracy degradation problem, i.e., accuracy on natural samples has reduced significantly. In this study, we reveal that natural accuracy degradation is highly related to the disruption of the natural sample topology in the representation space by quantitative and qualitative experiments. Based on this observation, we propose Topology-pReserving Adversarial traINing (TRAIN) to alleviate the problem by preserving the topology structure of natural samples from a standard model trained only on natural samples during adversarial training. As an additional regularization, our method can easily be combined with various popular adversarial training algorithms in a plug-and-play manner, taking advantage of both sides. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet show that our proposed method achieves consistent and significant improvements over various strong baselines in most cases. Specifically, without additional data, our proposed method achieves up to 8.78% improvement in natural accuracy and 4.50% improvement in robust accuracy.","sentences":["Despite the effectiveness in improving the robustness of neural networks, adversarial training has suffered from the natural accuracy degradation problem, i.e., accuracy on natural samples has reduced significantly.","In this study, we reveal that natural accuracy degradation is highly related to the disruption of the natural sample topology in the representation space by quantitative and qualitative experiments.","Based on this observation, we propose Topology-pReserving Adversarial traINing (TRAIN) to alleviate the problem by preserving the topology structure of natural samples from a standard model trained only on natural samples during adversarial training.","As an additional regularization, our method can easily be combined with various popular adversarial training algorithms in a plug-and-play manner, taking advantage of both sides.","Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet show that our proposed method achieves consistent and significant improvements over various strong baselines in most cases.","Specifically, without additional data, our proposed method achieves up to 8.78% improvement in natural accuracy and 4.50% improvement in robust accuracy."],"url":"http://arxiv.org/abs/2311.17607v1"}
{"created":"2023-11-29 12:55:16","title":"sec-certs: Examining the security certification practice for better vulnerability mitigation","abstract":"Products certified under security certification frameworks such as Common Criteria undergo significant scrutiny during the costly certification process. Yet, critical vulnerabilities, including private key recovery (ROCA, Minerva, TPM-Fail...), get discovered in certified products with high assurance levels. Furthermore, assessing which certified products are impacted by such vulnerabilities is complicated due to the large amount of unstructured certification-related data and unclear relationships between the certificates. To address these problems, we conducted a large-scale automated analysis of Common Criteria and FIPS 140 certificates. We trained unsupervised models to learn which vulnerabilities from NIST's National Vulnerability Database impact existing certified products and how certified products reference each other. Our tooling automates the analysis of tens of thousands of certification-related documents, extracting machine-readable features where manual analysis is unattainable. Further, we identify the security requirements that are associated with products being affected by fewer and less severe vulnerabilities (on average). This indicates which aspects of certification correlate with higher security. We demonstrate how our tool can be used for better vulnerability mitigation on four case studies of known, high-profile vulnerabilities. All tools and continuously updated results are available at https://seccerts.org.","sentences":["Products certified under security certification frameworks such as Common Criteria undergo significant scrutiny during the costly certification process.","Yet, critical vulnerabilities, including private key recovery (ROCA, Minerva, TPM-Fail...), get discovered in certified products with high assurance levels.","Furthermore, assessing which certified products are impacted by such vulnerabilities is complicated due to the large amount of unstructured certification-related data and unclear relationships between the certificates.","To address these problems, we conducted a large-scale automated analysis of Common Criteria and FIPS 140 certificates.","We trained unsupervised models to learn which vulnerabilities from NIST's National Vulnerability Database impact existing certified products and how certified products reference each other.","Our tooling automates the analysis of tens of thousands of certification-related documents, extracting machine-readable features where manual analysis is unattainable.","Further, we identify the security requirements that are associated with products being affected by fewer and less severe vulnerabilities (on average).","This indicates which aspects of certification correlate with higher security.","We demonstrate how our tool can be used for better vulnerability mitigation on four case studies of known, high-profile vulnerabilities.","All tools and continuously updated results are available at https://seccerts.org."],"url":"http://arxiv.org/abs/2311.17603v1"}
{"created":"2023-11-29 12:53:32","title":"Continual Learning with Low Rank Adaptation","abstract":"Recent work using pretrained transformers has shown impressive performance when fine-tuned with data from the downstream problem of interest. However, they struggle to retain that performance when the data characteristics changes. In this paper, we focus on continual learning, where a pre-trained transformer is updated to perform well on new data, while retaining its performance on data it was previously trained on. Earlier works have tackled this primarily through methods inspired from prompt tuning. We question this choice, and investigate the applicability of Low Rank Adaptation (LoRA) to continual learning. On a range of domain-incremental learning benchmarks, our LoRA-based solution, CoLoR, yields state-of-the-art performance, while still being as parameter efficient as the prompt tuning based methods.","sentences":["Recent work using pretrained transformers has shown impressive performance when fine-tuned with data from the downstream problem of interest.","However, they struggle to retain that performance when the data characteristics changes.","In this paper, we focus on continual learning, where a pre-trained transformer is updated to perform well on new data, while retaining its performance on data it was previously trained on.","Earlier works have tackled this primarily through methods inspired from prompt tuning.","We question this choice, and investigate the applicability of Low Rank Adaptation (LoRA) to continual learning.","On a range of domain-incremental learning benchmarks, our LoRA-based solution, CoLoR, yields state-of-the-art performance, while still being as parameter efficient as the prompt tuning based methods."],"url":"http://arxiv.org/abs/2311.17601v1"}
{"created":"2023-11-29 12:48:33","title":"Improving embedding of graphs with missing data by soft manifolds","abstract":"Embedding graphs in continous spaces is a key factor in designing and developing algorithms for automatic information extraction to be applied in diverse tasks (e.g., learning, inferring, predicting). The reliability of graph embeddings directly depends on how much the geometry of the continuous space matches the graph structure. Manifolds are mathematical structure that can enable to incorporate in their topological spaces the graph characteristics, and in particular nodes distances. State-of-the-art of manifold-based graph embedding algorithms take advantage of the assumption that the projection on a tangential space of each point in the manifold (corresponding to a node in the graph) would locally resemble a Euclidean space. Although this condition helps in achieving efficient analytical solutions to the embedding problem, it does not represent an adequate set-up to work with modern real life graphs, that are characterized by weighted connections across nodes often computed over sparse datasets with missing records. In this work, we introduce a new class of manifold, named soft manifold, that can solve this situation. In particular, soft manifolds are mathematical structures with spherical symmetry where the tangent spaces to each point are hypocycloids whose shape is defined according to the velocity of information propagation across the data points. Using soft manifolds for graph embedding, we can provide continuous spaces to pursue any task in data analysis over complex datasets. Experimental results on reconstruction tasks on synthetic and real datasets show how the proposed approach enable more accurate and reliable characterization of graphs in continuous spaces with respect to the state-of-the-art.","sentences":["Embedding graphs in continous spaces is a key factor in designing and developing algorithms for automatic information extraction to be applied in diverse tasks (e.g., learning, inferring, predicting).","The reliability of graph embeddings directly depends on how much the geometry of the continuous space matches the graph structure.","Manifolds are mathematical structure that can enable to incorporate in their topological spaces the graph characteristics, and in particular nodes distances.","State-of-the-art of manifold-based graph embedding algorithms take advantage of the assumption that the projection on a tangential space of each point in the manifold (corresponding to a node in the graph) would locally resemble a Euclidean space.","Although this condition helps in achieving efficient analytical solutions to the embedding problem, it does not represent an adequate set-up to work with modern real life graphs, that are characterized by weighted connections across nodes often computed over sparse datasets with missing records.","In this work, we introduce a new class of manifold, named soft manifold, that can solve this situation.","In particular, soft manifolds are mathematical structures with spherical symmetry where the tangent spaces to each point are hypocycloids whose shape is defined according to the velocity of information propagation across the data points.","Using soft manifolds for graph embedding, we can provide continuous spaces to pursue any task in data analysis over complex datasets.","Experimental results on reconstruction tasks on synthetic and real datasets show how the proposed approach enable more accurate and reliable characterization of graphs in continuous spaces with respect to the state-of-the-art."],"url":"http://arxiv.org/abs/2311.17598v1"}
{"created":"2023-11-29 12:47:42","title":"Continual Self-supervised Learning: Towards Universal Multi-modal Medical Data Representation Learning","abstract":"Self-supervised learning is an efficient pre-training method for medical image analysis. However, current research is mostly confined to specific-modality data pre-training, consuming considerable time and resources without achieving universality across different modalities. A straightforward solution is combining all modality data for joint self-supervised pre-training, which poses practical challenges. Firstly, our experiments reveal conflicts in representation learning as the number of modalities increases. Secondly, multi-modal data collected in advance cannot cover all real-world scenarios. In this paper, we reconsider versatile self-supervised learning from the perspective of continual learning and propose MedCoSS, a continuous self-supervised learning approach for multi-modal medical data. Unlike joint self-supervised learning, MedCoSS assigns different modality data to different training stages, forming a multi-stage pre-training process. To balance modal conflicts and prevent catastrophic forgetting, we propose a rehearsal-based continual learning method. We introduce the k-means sampling strategy to retain data from previous modalities and rehearse it when learning new modalities. Instead of executing the pretext task on buffer data, a feature distillation strategy and an intra-modal mixup strategy are applied to these data for knowledge retention. We conduct continuous self-supervised pre-training on a large-scale multi-modal unlabeled dataset, including clinical reports, X-rays, CT scans, MRI scans, and pathological images. Experimental results demonstrate MedCoSS's exceptional generalization ability across nine downstream datasets and its significant scalability in integrating new modality data. Code and pre-trained weight are available at https://github.com/yeerwen/MedCoSS.","sentences":["Self-supervised learning is an efficient pre-training method for medical image analysis.","However, current research is mostly confined to specific-modality data pre-training, consuming considerable time and resources without achieving universality across different modalities.","A straightforward solution is combining all modality data for joint self-supervised pre-training, which poses practical challenges.","Firstly, our experiments reveal conflicts in representation learning as the number of modalities increases.","Secondly, multi-modal data collected in advance cannot cover all real-world scenarios.","In this paper, we reconsider versatile self-supervised learning from the perspective of continual learning and propose MedCoSS, a continuous self-supervised learning approach for multi-modal medical data.","Unlike joint self-supervised learning, MedCoSS assigns different modality data to different training stages, forming a multi-stage pre-training process.","To balance modal conflicts and prevent catastrophic forgetting, we propose a rehearsal-based continual learning method.","We introduce the k-means sampling strategy to retain data from previous modalities and rehearse it when learning new modalities.","Instead of executing the pretext task on buffer data, a feature distillation strategy and an intra-modal mixup strategy are applied to these data for knowledge retention.","We conduct continuous self-supervised pre-training on a large-scale multi-modal unlabeled dataset, including clinical reports, X-rays, CT scans, MRI scans, and pathological images.","Experimental results demonstrate MedCoSS's exceptional generalization ability across nine downstream datasets and its significant scalability in integrating new modality data.","Code and pre-trained weight are available at https://github.com/yeerwen/MedCoSS."],"url":"http://arxiv.org/abs/2311.17597v1"}
{"created":"2023-11-29 12:18:46","title":"LoCoMotif: Discovering time-warped motifs in time series","abstract":"Time Series Motif Discovery (TSMD) refers to the task of identifying patterns that occur multiple times (possibly with minor variations) in a time series. All existing methods for TSMD have one or more of the following limitations: they only look for the two most similar occurrences of a pattern; they only look for patterns of a pre-specified, fixed length; they cannot handle variability along the time axis; and they only handle univariate time series. In this paper, we present a new method, LoCoMotif, that has none of these limitations. The method is motivated by a concrete use case from physiotherapy. We demonstrate the value of the proposed method on this use case. We also introduce a new quantitative evaluation metric for motif discovery, and benchmark data for comparing TSMD methods. LoCoMotif substantially outperforms the existing methods, on top of being more broadly applicable.","sentences":["Time Series Motif Discovery (TSMD) refers to the task of identifying patterns that occur multiple times (possibly with minor variations) in a time series.","All existing methods for TSMD have one or more of the following limitations: they only look for the two most similar occurrences of a pattern; they only look for patterns of a pre-specified, fixed length; they cannot handle variability along the time axis; and they only handle univariate time series.","In this paper, we present a new method, LoCoMotif, that has none of these limitations.","The method is motivated by a concrete use case from physiotherapy.","We demonstrate the value of the proposed method on this use case.","We also introduce a new quantitative evaluation metric for motif discovery, and benchmark data for comparing TSMD methods.","LoCoMotif substantially outperforms the existing methods, on top of being more broadly applicable."],"url":"http://arxiv.org/abs/2311.17582v1"}
{"created":"2023-11-29 12:14:01","title":"Data Driven Approaches to Cybersecurity Governance for Board Decision-Making -- A Systematic Review","abstract":"Cybersecurity governance influences the quality of strategic decision-making to ensure cyber risks are managed effectively. Board of Directors are the decisions-makers held accountable for managing this risk; however, they lack adequate and efficient information necessary for making such decisions. In addition to the myriad of challenges they face, they are often insufficiently versed in the technology or cybersecurity terminology or not provided with the correct tools to support them to make sound decisions to govern cybersecurity effectively. A different approach is needed to ensure BoDs are clear on the approach the business is taking to build a cyber resilient organization. This systematic literature review investigates the existing risk measurement instruments, cybersecurity metrics, and associated models for supporting BoDs. We identified seven conceptual themes through literature analysis that form the basis of this study's main contribution. The findings showed that, although sophisticated cybersecurity tools exist and are developing, there is limited information for Board of Directors to support them in terms of metrics and models to govern cybersecurity in a language they understand. The review also provides some recommendations on theories and models that can be further investigated to provide support to Board of Directors.","sentences":["Cybersecurity governance influences the quality of strategic decision-making to ensure cyber risks are managed effectively.","Board of Directors are the decisions-makers held accountable for managing this risk; however, they lack adequate and efficient information necessary for making such decisions.","In addition to the myriad of challenges they face, they are often insufficiently versed in the technology or cybersecurity terminology or not provided with the correct tools to support them to make sound decisions to govern cybersecurity effectively.","A different approach is needed to ensure BoDs are clear on the approach the business is taking to build a cyber resilient organization.","This systematic literature review investigates the existing risk measurement instruments, cybersecurity metrics, and associated models for supporting BoDs.","We identified seven conceptual themes through literature analysis that form the basis of this study's main contribution.","The findings showed that, although sophisticated cybersecurity tools exist and are developing, there is limited information for Board of Directors to support them in terms of metrics and models to govern cybersecurity in a language they understand.","The review also provides some recommendations on theories and models that can be further investigated to provide support to Board of Directors."],"url":"http://arxiv.org/abs/2311.17578v1"}
{"created":"2023-11-29 12:01:17","title":"Network characteristics of financial networks","abstract":"We embrace a fresh perspective to auditing by analyzing a large set of companies as complex financial networks rather than static aggregates of balance sheet data. Preliminary analyses show that network centrality measures within these networks could significantly enhance auditors' insights into financial structures. Utilizing data from over 300 diverse companies, we examine the structure of financial statement networks through bipartite graph analysis, exploring their scale-freeness by comparing degree distributions to power-law and exponential models. Our findings indicate heavy-tailed degree distribution for financial account nodes, networks that grow with the same diameter, and the presence of influential hubs. This study lays the groundwork for future auditing methodologies where baseline network statistics could serve as indicators for anomaly detection, marking a substantial advancement in audit research and network science.","sentences":["We embrace a fresh perspective to auditing by analyzing a large set of companies as complex financial networks rather than static aggregates of balance sheet data.","Preliminary analyses show that network centrality measures within these networks could significantly enhance auditors' insights into financial structures.","Utilizing data from over 300 diverse companies, we examine the structure of financial statement networks through bipartite graph analysis, exploring their scale-freeness by comparing degree distributions to power-law and exponential models.","Our findings indicate heavy-tailed degree distribution for financial account nodes, networks that grow with the same diameter, and the presence of influential hubs.","This study lays the groundwork for future auditing methodologies where baseline network statistics could serve as indicators for anomaly detection, marking a substantial advancement in audit research and network science."],"url":"http://arxiv.org/abs/2311.17567v1"}
{"created":"2023-11-29 11:48:16","title":"Interpreting Differentiable Latent States for Healthcare Time-series Data","abstract":"Machine learning enables extracting clinical insights from large temporal datasets. The applications of such machine learning models include identifying disease patterns and predicting patient outcomes. However, limited interpretability poses challenges for deploying advanced machine learning in digital healthcare. Understanding the meaning of latent states is crucial for interpreting machine learning models, assuming they capture underlying patterns. In this paper, we present a concise algorithm that allows for i) interpreting latent states using highly related input features; ii) interpreting predictions using subsets of input features via latent states; and iii) interpreting changes in latent states over time. The proposed algorithm is feasible for any model that is differentiable. We demonstrate that this approach enables the identification of a daytime behavioral pattern for predicting nocturnal behavior in a real-world healthcare dataset.","sentences":["Machine learning enables extracting clinical insights from large temporal datasets.","The applications of such machine learning models include identifying disease patterns and predicting patient outcomes.","However, limited interpretability poses challenges for deploying advanced machine learning in digital healthcare.","Understanding the meaning of latent states is crucial for interpreting machine learning models, assuming they capture underlying patterns.","In this paper, we present a concise algorithm that allows for i) interpreting latent states using highly related input features; ii) interpreting predictions using subsets of input features via latent states; and iii) interpreting changes in latent states over time.","The proposed algorithm is feasible for any model that is differentiable.","We demonstrate that this approach enables the identification of a daytime behavioral pattern for predicting nocturnal behavior in a real-world healthcare dataset."],"url":"http://arxiv.org/abs/2311.17560v1"}
{"created":"2023-11-29 11:27:07","title":"Performance Evaluation of Checkpoint/Restart Techniques","abstract":"Distributed applications running on a large cluster environment, such as the cloud instances will have shorter execution time. However, the application might suffer from sudden termination due to unpredicted computing node failures, thus loosing the whole computation. Checkpoint/restart is a fault tolerance technique used to solve this problem. In this work we evaluated the performance of two of the most commonly used checkpoint/restart techniques (Distributed Multithreaded Checkpointing (DMTCP) and Berkeley Lab Checkpoint/Restart library (BLCR) integrated into the OpenMPI framework). We aimed to test their validity and evaluate their performance in both local and Amazon Elastic Compute Cloud (EC2) environments. The experiments were conducted on Amazon EC2 as a well-known proprietary cloud computing service provider. Results obtained were reported and compared to evaluate checkpoint and restart time values, data scalability and compute processes scalability. The findings proved that DMTCP performs better than BLCR for checkpoint and restart speed, data scalability and compute processes scalability experiments.","sentences":["Distributed applications running on a large cluster environment, such as the cloud instances will have shorter execution time.","However, the application might suffer from sudden termination due to unpredicted computing node failures, thus loosing the whole computation.","Checkpoint/restart is a fault tolerance technique used to solve this problem.","In this work we evaluated the performance of two of the most commonly used checkpoint/restart techniques (Distributed Multithreaded Checkpointing (DMTCP) and Berkeley Lab Checkpoint/Restart library (BLCR) integrated into the OpenMPI framework).","We aimed to test their validity and evaluate their performance in both local and Amazon Elastic Compute Cloud (EC2) environments.","The experiments were conducted on Amazon EC2 as a well-known proprietary cloud computing service provider.","Results obtained were reported and compared to evaluate checkpoint and restart time values, data scalability and compute processes scalability.","The findings proved that DMTCP performs better than BLCR for checkpoint and restart speed, data scalability and compute processes scalability experiments."],"url":"http://arxiv.org/abs/2311.17545v1"}
{"created":"2023-11-29 11:23:42","title":"TaskWeaver: A Code-First Agent Framework","abstract":"Language Language Models (LLMs) have shown impressive abilities in natural language understanding and generation, leading to their use in applications such as chatbots and virtual assistants. However, existing LLM frameworks face limitations in handling domain-specific data analytics tasks with rich data structures. Moreover, they struggle with flexibility to meet diverse user requirements. To address these issues, TaskWeaver is proposed as a code-first framework for building LLM-powered autonomous agents. It converts user requests into executable code and treats user-defined plugins as callable functions. TaskWeaver provides support for rich data structures, flexible plugin usage, and dynamic plugin selection, and leverages LLM coding capabilities for complex logic. It also incorporates domain-specific knowledge through examples and ensures the secure execution of generated code. TaskWeaver offers a powerful and flexible framework for creating intelligent conversational agents that can handle complex tasks and adapt to domain-specific scenarios. The code is open-sourced at https://github.com/microsoft/TaskWeaver/.","sentences":["Language Language Models (LLMs) have shown impressive abilities in natural language understanding and generation, leading to their use in applications such as chatbots and virtual assistants.","However, existing LLM frameworks face limitations in handling domain-specific data analytics tasks with rich data structures.","Moreover, they struggle with flexibility to meet diverse user requirements.","To address these issues, TaskWeaver is proposed as a code-first framework for building LLM-powered autonomous agents.","It converts user requests into executable code and treats user-defined plugins as callable functions.","TaskWeaver provides support for rich data structures, flexible plugin usage, and dynamic plugin selection, and leverages LLM coding capabilities for complex logic.","It also incorporates domain-specific knowledge through examples and ensures the secure execution of generated code.","TaskWeaver offers a powerful and flexible framework for creating intelligent conversational agents that can handle complex tasks and adapt to domain-specific scenarios.","The code is open-sourced at https://github.com/microsoft/TaskWeaver/."],"url":"http://arxiv.org/abs/2311.17541v1"}
{"created":"2023-11-29 10:53:05","title":"Improving Stability during Upsampling -- on the Importance of Spatial Context","abstract":"State-of-the-art models for pixel-wise prediction tasks such as image restoration, image segmentation, or disparity estimation, involve several stages of data resampling, in which the resolution of feature maps is first reduced to aggregate information and then sequentially increased to generate a high-resolution output. Several previous works have investigated the effect of artifacts that are invoked during downsampling and diverse cures have been proposed that facilitate to improve prediction stability and even robustness for image classification. However, equally relevant, artifacts that arise during upsampling have been less discussed. This is significantly relevant as upsampling and downsampling approaches face fundamentally different challenges. While during downsampling, aliases and artifacts can be reduced by blurring feature maps, the emergence of fine details is crucial during upsampling. Blurring is therefore not an option and dedicated operations need to be considered. In this work, we are the first to explore the relevance of context during upsampling by employing convolutional upsampling operations with increasing kernel size while keeping the encoder unchanged. We find that increased kernel sizes can in general improve the prediction stability in tasks such as image restoration or image segmentation, while a block that allows for a combination of small-size kernels for fine details and large-size kernels for artifact removal and increased context yields the best results.","sentences":["State-of-the-art models for pixel-wise prediction tasks such as image restoration, image segmentation, or disparity estimation, involve several stages of data resampling, in which the resolution of feature maps is first reduced to aggregate information and then sequentially increased to generate a high-resolution output.","Several previous works have investigated the effect of artifacts that are invoked during downsampling and diverse cures have been proposed that facilitate to improve prediction stability and even robustness for image classification.","However, equally relevant, artifacts that arise during upsampling have been less discussed.","This is significantly relevant as upsampling and downsampling approaches face fundamentally different challenges.","While during downsampling, aliases and artifacts can be reduced by blurring feature maps, the emergence of fine details is crucial during upsampling.","Blurring is therefore not an option and dedicated operations need to be considered.","In this work, we are the first to explore the relevance of context during upsampling by employing convolutional upsampling operations with increasing kernel size while keeping the encoder unchanged.","We find that increased kernel sizes can in general improve the prediction stability in tasks such as image restoration or image segmentation, while a block that allows for a combination of small-size kernels for fine details and large-size kernels for artifact removal and increased context yields the best results."],"url":"http://arxiv.org/abs/2311.17524v1"}
{"created":"2023-11-29 10:40:52","title":"The devil is in the fine-grained details: Evaluating open-vocabulary object detectors for fine-grained understanding","abstract":"Recent advancements in large vision-language models enabled visual object detection in open-vocabulary scenarios, where object classes are defined in free-text formats during inference. In this paper, we aim to probe the state-of-the-art methods for open-vocabulary object detection to determine to what extent they understand fine-grained properties of objects and their parts. To this end, we introduce an evaluation protocol based on dynamic vocabulary generation to test whether models detect, discern, and assign the correct fine-grained description to objects in the presence of hard-negative classes. We contribute with a benchmark suite of increasing difficulty and probing different properties like color, pattern, and material. We further enhance our investigation by evaluating several state-of-the-art open-vocabulary object detectors using the proposed protocol and find that most existing solutions, which shine in standard open-vocabulary benchmarks, struggle to accurately capture and distinguish finer object details. We conclude the paper by highlighting the limitations of current methodologies and exploring promising research directions to overcome the discovered drawbacks. Data and code are available at https://github.com/lorebianchi98/FG-OVD.","sentences":["Recent advancements in large vision-language models enabled visual object detection in open-vocabulary scenarios, where object classes are defined in free-text formats during inference.","In this paper, we aim to probe the state-of-the-art methods for open-vocabulary object detection to determine to what extent they understand fine-grained properties of objects and their parts.","To this end, we introduce an evaluation protocol based on dynamic vocabulary generation to test whether models detect, discern, and assign the correct fine-grained description to objects in the presence of hard-negative classes.","We contribute with a benchmark suite of increasing difficulty and probing different properties like color, pattern, and material.","We further enhance our investigation by evaluating several state-of-the-art open-vocabulary object detectors using the proposed protocol and find that most existing solutions, which shine in standard open-vocabulary benchmarks, struggle to accurately capture and distinguish finer object details.","We conclude the paper by highlighting the limitations of current methodologies and exploring promising research directions to overcome the discovered drawbacks.","Data and code are available at https://github.com/lorebianchi98/FG-OVD."],"url":"http://arxiv.org/abs/2311.17518v1"}
{"created":"2023-11-29 10:35:00","title":"StructRe: Rewriting for Structured Shape Modeling","abstract":"Man-made 3D shapes are naturally organized in parts and hierarchies; such structures provide important constraints for shape reconstruction and generation. Modeling shape structures is difficult, because there can be multiple hierarchies for a given shape, causing ambiguity, and across different categories the shape structures are correlated with semantics, limiting generalization. We present StructRe, a structure rewriting system, as a novel approach to structured shape modeling. Given a 3D object represented by points and components, StructRe can rewrite it upward into more concise structures, or downward into more detailed structures; by iterating the rewriting process, hierarchies are obtained. Such a localized rewriting process enables probabilistic modeling of ambiguous structures and robust generalization across object categories. We train StructRe on PartNet data and show its generalization to cross-category and multiple object hierarchies, and test its extension to ShapeNet. We also demonstrate the benefits of probabilistic and generalizable structure modeling for shape reconstruction, generation and editing tasks.","sentences":["Man-made 3D shapes are naturally organized in parts and hierarchies; such structures provide important constraints for shape reconstruction and generation.","Modeling shape structures is difficult, because there can be multiple hierarchies for a given shape, causing ambiguity, and across different categories the shape structures are correlated with semantics, limiting generalization.","We present StructRe, a structure rewriting system, as a novel approach to structured shape modeling.","Given a 3D object represented by points and components, StructRe can rewrite it upward into more concise structures, or downward into more detailed structures; by iterating the rewriting process, hierarchies are obtained.","Such a localized rewriting process enables probabilistic modeling of ambiguous structures and robust generalization across object categories.","We train StructRe on PartNet data and show its generalization to cross-category and multiple object hierarchies, and test its extension to ShapeNet.","We also demonstrate the benefits of probabilistic and generalizable structure modeling for shape reconstruction, generation and editing tasks."],"url":"http://arxiv.org/abs/2311.17510v1"}
{"created":"2023-11-29 10:32:40","title":"Model Performance Prediction for Hyperparameter Optimization of Deep Learning Models Using High Performance Computing and Quantum Annealing","abstract":"Hyperparameter Optimization (HPO) of Deep Learning-based models tends to be a compute resource intensive process as it usually requires to train the target model with many different hyperparameter configurations. We show that integrating model performance prediction with early stopping methods holds great potential to speed up the HPO process of deep learning models. Moreover, we propose a novel algorithm called Swift-Hyperband that can use either classical or quantum support vector regression for performance prediction and benefit from distributed High Performance Computing environments. This algorithm is tested not only for the Machine-Learned Particle Flow model used in High Energy Physics, but also for a wider range of target models from domains such as computer vision and natural language processing. Swift-Hyperband is shown to find comparable (or better) hyperparameters as well as using less computational resources in all test cases.","sentences":["Hyperparameter Optimization (HPO) of Deep Learning-based models tends to be a compute resource intensive process as it usually requires to train the target model with many different hyperparameter configurations.","We show that integrating model performance prediction with early stopping methods holds great potential to speed up the HPO process of deep learning models.","Moreover, we propose a novel algorithm called Swift-Hyperband that can use either classical or quantum support vector regression for performance prediction and benefit from distributed High Performance Computing environments.","This algorithm is tested not only for the Machine-Learned Particle Flow model used in High Energy Physics, but also for a wider range of target models from domains such as computer vision and natural language processing.","Swift-Hyperband is shown to find comparable (or better) hyperparameters as well as using less computational resources in all test cases."],"url":"http://arxiv.org/abs/2311.17508v1"}
{"created":"2023-11-29 10:19:34","title":"A Multiparty Commutative Hashing Protocol based on the Discrete Logarithm Problem","abstract":"Let $\\mathcal{X}$ and $\\mathcal{Y}$ be two sets and suppose that a set of participants $P=\\{P_1,P_2,\\dots,P_n\\}$ would like to calculate the keyed hash value of some message $m\\in\\mathcal{X}$ known to a single participant in $P$ called the data owner. Also, suppose that each participant $P_i$ knows a secret value $x_i\\in\\mathcal{X}$. In this paper, we will propose a protocol that enables the participants in this setup to calculate the value $y=H(m,x_1,x_2,\\dots ,x_n)$ of a hash function $H:\\mathcal{X}^{n+1}\\rightarrow\\mathcal{Y}$ such that the function $H$ is a one-way function, participants in $P\\backslash\\{P_i\\}$ cannot obtain $x_i$, participants other than the data owner cannot obtain $m$, and the hash value $y=H(m,x_1,x_2,\\dots ,x_n)$ remains the same regardless the order of the secret $x_i$ values.","sentences":["Let $\\mathcal{X}$ and $\\mathcal{Y}$ be two sets and suppose that a set of participants $P=\\{P_1,P_2,\\dots,P_n\\}$ would like to calculate the keyed hash value of some message $m\\in\\mathcal{X}$ known to a single participant in $P$ called the data owner.","Also, suppose that each participant $P_i$ knows a secret value","$x_i\\in\\mathcal{X}$.","In this paper, we will propose a protocol that enables the participants in this setup to calculate the value $y=H(m,x_1,x_2,\\dots ,x_n)$ of a hash function $H:\\mathcal{X}^{n+1}\\rightarrow\\mathcal{Y}$ such that the function $H$ is a one-way function, participants in $P\\backslash\\{P_i\\}$ cannot obtain $x_i$, participants other than the data owner cannot obtain $m$, and the hash value $y=H(m,x_1,x_2,\\dots ,x_n)$ remains the same regardless the order of the secret $x_i$ values."],"url":"http://arxiv.org/abs/2311.17498v1"}
{"created":"2023-11-29 10:01:48","title":"Mergen: The First Manchu-Korean Machine Translation Model Trained on Augmented Data","abstract":"The Manchu language, with its roots in the historical Manchurian region of Northeast China, is now facing a critical threat of extinction, as there are very few speakers left. In our efforts to safeguard the Manchu language, we introduce Mergen, the first-ever attempt at a Manchu-Korean Machine Translation (MT) model. To develop this model, we utilize valuable resources such as the Manwen Laodang(a historical book) and a Manchu-Korean dictionary. Due to the scarcity of a Manchu-Korean parallel dataset, we expand our data by employing word replacement guided by GloVe embeddings, trained on both monolingual and parallel texts. Our approach is built around an encoder-decoder neural machine translation model, incorporating a bi-directional Gated Recurrent Unit (GRU) layer. The experiments have yielded promising results, showcasing a significant enhancement in Manchu-Korean translation, with a remarkable 20-30 point increase in the BLEU score.","sentences":["The Manchu language, with its roots in the historical Manchurian region of Northeast China, is now facing a critical threat of extinction, as there are very few speakers left.","In our efforts to safeguard the Manchu language, we introduce Mergen, the first-ever attempt at a Manchu-Korean Machine Translation (MT) model.","To develop this model, we utilize valuable resources such as the Manwen Laodang(a historical book) and a Manchu-Korean dictionary.","Due to the scarcity of a Manchu-Korean parallel dataset, we expand our data by employing word replacement guided by GloVe embeddings, trained on both monolingual and parallel texts.","Our approach is built around an encoder-decoder neural machine translation model, incorporating a bi-directional Gated Recurrent Unit (GRU) layer.","The experiments have yielded promising results, showcasing a significant enhancement in Manchu-Korean translation, with a remarkable 20-30 point increase in the BLEU score."],"url":"http://arxiv.org/abs/2311.17492v1"}
{"created":"2023-11-29 09:48:01","title":"Non-Visible Light Data Synthesis and Application: A Case Study for Synthetic Aperture Radar Imagery","abstract":"We explore the \"hidden\" ability of large-scale pre-trained image generation models, such as Stable Diffusion and Imagen, in non-visible light domains, taking Synthetic Aperture Radar (SAR) data for a case study. Due to the inherent challenges in capturing satellite data, acquiring ample SAR training samples is infeasible. For instance, for a particular category of ship in the open sea, we can collect only few-shot SAR images which are too limited to derive effective ship recognition models. If large-scale models pre-trained with regular images can be adapted to generating novel SAR images, the problem is solved. In preliminary study, we found that fine-tuning these models with few-shot SAR images is not working, as the models can not capture the two primary differences between SAR and regular images: structure and modality. To address this, we propose a 2-stage low-rank adaptation method, and we call it 2LoRA. In the first stage, the model is adapted using aerial-view regular image data (whose structure matches SAR), followed by the second stage where the base model from the first stage is further adapted using SAR modality data. Particularly in the second stage, we introduce a novel prototype LoRA (pLoRA), as an improved version of 2LoRA, to resolve the class imbalance problem in SAR datasets. For evaluation, we employ the resulting generation model to synthesize additional SAR data. This augmentation, when integrated into the training process of SAR classification as well as segmentation models, yields notably improved performance for minor classes","sentences":["We explore the \"hidden\" ability of large-scale pre-trained image generation models, such as Stable Diffusion and Imagen, in non-visible light domains, taking Synthetic Aperture Radar (SAR) data for a case study.","Due to the inherent challenges in capturing satellite data, acquiring ample SAR training samples is infeasible.","For instance, for a particular category of ship in the open sea, we can collect only few-shot SAR images which are too limited to derive effective ship recognition models.","If large-scale models pre-trained with regular images can be adapted to generating novel SAR images, the problem is solved.","In preliminary study, we found that fine-tuning these models with few-shot SAR images is not working, as the models can not capture the two primary differences between SAR and regular images: structure and modality.","To address this, we propose a 2-stage low-rank adaptation method, and we call it 2LoRA.","In the first stage, the model is adapted using aerial-view regular image data (whose structure matches SAR), followed by the second stage where the base model from the first stage is further adapted using SAR modality data.","Particularly in the second stage, we introduce a novel prototype LoRA (pLoRA), as an improved version of 2LoRA, to resolve the class imbalance problem in SAR datasets.","For evaluation, we employ the resulting generation model to synthesize additional SAR data.","This augmentation, when integrated into the training process of SAR classification as well as segmentation models, yields notably improved performance for minor classes"],"url":"http://arxiv.org/abs/2311.17486v1"}
{"created":"2023-11-29 09:31:04","title":"Exploring Multi-Reader Buffers and Channel Placement during Dataflow Network Mapping to Heterogeneous Many-core Systems","abstract":"This paper presents an approach for reducing the memory requirements of dataflow applications, while minimizing the execution period when deployed on a many-core target. Often, straightforward implementations of dataflow applications suffer from data duplication if identical data has to be processed by multiple actors. In fact, multi-cast actors can produce huge memory overheads when storing and communicating copies of the same data. As a remedy, so-called Multi-Reader Buffers (MRBs) can be utilized to forward identical data to multiple actors in a FIFO manner while storing each data item only once. However, MRBs may increase the achievable period due to communication contention when accessing the shared data. A novel multi-objective design space exploration approach is proposed that selectively replaces multi-cast actors with MRBs and explores actor and FIFO channel mappings to find trade-offs between the objectives of period, memory footprint, and core cost. Our approach considers (i) memory-size constraints, (ii) hierarchical memories to implement the buffers, (iii) supports heterogeneous many-core platforms, and (iv) optimizes the buffer placement and overall scheduling to minimize the execution period by proposing a novel combined actor and communications scheduling heuristic for period minimization called CAPS-HMS. Our results show that the explored Pareto fronts improve a hypervolume indicator over a reference approach by up to 66 % for small to mid-size applications and 90 % for large applications. Moreover, selectively replacing multi-cast actors with corresponding MRBs proves to be always superior to never or always replacing them. Finally, it is shown that the quality of the explored Pareto fronts does not degrade when replacing the efficient scheduling heuristic CAPS-HMS by an exact integer linear programming (ILP) solver.","sentences":["This paper presents an approach for reducing the memory requirements of dataflow applications, while minimizing the execution period when deployed on a many-core target.","Often, straightforward implementations of dataflow applications suffer from data duplication if identical data has to be processed by multiple actors.","In fact, multi-cast actors can produce huge memory overheads when storing and communicating copies of the same data.","As a remedy, so-called Multi-Reader Buffers (MRBs) can be utilized to forward identical data to multiple actors in a FIFO manner while storing each data item only once.","However, MRBs may increase the achievable period due to communication contention when accessing the shared data.","A novel multi-objective design space exploration approach is proposed that selectively replaces multi-cast actors with MRBs and explores actor and FIFO channel mappings to find trade-offs between the objectives of period, memory footprint, and core cost.","Our approach considers (i) memory-size constraints, (ii) hierarchical memories to implement the buffers, (iii) supports heterogeneous many-core platforms, and (iv) optimizes the buffer placement and overall scheduling to minimize the execution period by proposing a novel combined actor and communications scheduling heuristic for period minimization called CAPS-HMS.","Our results show that the explored Pareto fronts improve a hypervolume indicator over a reference approach by up to 66 % for small to mid-size applications and 90 % for large applications.","Moreover, selectively replacing multi-cast actors with corresponding MRBs proves to be always superior to never or always replacing them.","Finally, it is shown that the quality of the explored Pareto fronts does not degrade when replacing the efficient scheduling heuristic CAPS-HMS by an exact integer linear programming (ILP) solver."],"url":"http://arxiv.org/abs/2311.17473v1"}
{"created":"2023-11-29 08:51:40","title":"Privacy Measurement in Tabular Synthetic Data: State of the Art and Future Research Directions","abstract":"Synthetic data (SD) have garnered attention as a privacy enhancing technology. Unfortunately, there is no standard for quantifying their degree of privacy protection. In this paper, we discuss proposed quantification approaches. This contributes to the development of SD privacy standards; stimulates multi-disciplinary discussion; and helps SD researchers make informed modeling and evaluation decisions.","sentences":["Synthetic data (SD) have garnered attention as a privacy enhancing technology.","Unfortunately, there is no standard for quantifying their degree of privacy protection.","In this paper, we discuss proposed quantification approaches.","This contributes to the development of SD privacy standards; stimulates multi-disciplinary discussion; and helps SD researchers make informed modeling and evaluation decisions."],"url":"http://arxiv.org/abs/2311.17453v1"}
{"created":"2023-11-29 08:43:04","title":"Weakly-semi-supervised object detection in remotely sensed imagery","abstract":"Deep learning for detecting objects in remotely sensed imagery can enable new technologies for important applications including mitigating climate change. However, these models often require large datasets labeled with bounding box annotations which are expensive to curate, prohibiting the development of models for new tasks and geographies. To address this challenge, we develop weakly-semi-supervised object detection (WSSOD) models on remotely sensed imagery which can leverage a small amount of bounding boxes together with a large amount of point labels that are easy to acquire at scale in geospatial data. We train WSSOD models which use large amounts of point-labeled images with varying fractions of bounding box labeled images in FAIR1M and a wind turbine detection dataset, and demonstrate that they substantially outperform fully supervised models trained with the same amount of bounding box labeled images on both datasets. Furthermore, we find that the WSSOD models trained with 2-10x fewer bounding box labeled images can perform similarly to or outperform fully supervised models trained on the full set of bounding-box labeled images. We believe that the approach can be extended to other remote sensing tasks to reduce reliance on bounding box labels and increase development of models for impactful applications.","sentences":["Deep learning for detecting objects in remotely sensed imagery can enable new technologies for important applications including mitigating climate change.","However, these models often require large datasets labeled with bounding box annotations which are expensive to curate, prohibiting the development of models for new tasks and geographies.","To address this challenge, we develop weakly-semi-supervised object detection (WSSOD) models on remotely sensed imagery which can leverage a small amount of bounding boxes together with a large amount of point labels that are easy to acquire at scale in geospatial data.","We train WSSOD models which use large amounts of point-labeled images with varying fractions of bounding box labeled images in FAIR1M and a wind turbine detection dataset, and demonstrate that they substantially outperform fully supervised models trained with the same amount of bounding box labeled images on both datasets.","Furthermore, we find that the WSSOD models trained with 2-10x fewer bounding box labeled images can perform similarly to or outperform fully supervised models trained on the full set of bounding-box labeled images.","We believe that the approach can be extended to other remote sensing tasks to reduce reliance on bounding box labels and increase development of models for impactful applications."],"url":"http://arxiv.org/abs/2311.17449v1"}
{"created":"2023-11-29 08:33:46","title":"Asynchronous Merkle Trees","abstract":"Merkle trees have become a widely successful cryptographic data structure. Enabling a vast variety of applications from checking for inconsistencies in databases like Dynamo to essential tools like Git to large scale distributed systems like Bitcoin and other blockchains. There have also been various versions of Merkle trees like Jellyfish Merkle Trees and Sparse Merkle Trees designed for different applications. However, one key drawback of all these Merkle trees is that with a large data set the cost of computing the tree increases significantly, moreover insert operations on a single leaf require re-building the entire tree. For certain use cases building the tree this way is acceptable, however in environments where compute time needs to be as low as possible and where data is processed in parallel, we are presented with a need for asynchronous computation. This paper proposes a solution where given a batch of data that has to be processed concurrently, a Merkle Tree can be constructed from the batch asynchronously without needing to recalculate the tree for every insert.","sentences":["Merkle trees have become a widely successful cryptographic data structure.","Enabling a vast variety of applications from checking for inconsistencies in databases like Dynamo to essential tools like Git to large scale distributed systems like Bitcoin and other blockchains.","There have also been various versions of Merkle trees like Jellyfish Merkle Trees and Sparse Merkle Trees designed for different applications.","However, one key drawback of all these Merkle trees is that with a large data set the cost of computing the tree increases significantly, moreover insert operations on a single leaf require re-building the entire tree.","For certain use cases building the tree this way is acceptable, however in environments where compute time needs to be as low as possible and where data is processed in parallel, we are presented with a need for asynchronous computation.","This paper proposes a solution where given a batch of data that has to be processed concurrently, a Merkle Tree can be constructed from the batch asynchronously without needing to recalculate the tree for every insert."],"url":"http://arxiv.org/abs/2311.17441v1"}
{"created":"2023-11-29 08:21:42","title":"Grounding Foundation Models through Federated Transfer Learning: A General Framework","abstract":"Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. In recent years, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated learning setting, construct a detailed taxonomy based on the FTL-FM framework to categorize state-of-the-art FTL-FM works, and comprehensively overview FTL-FM works based on the proposed taxonomy. We also establish correspondences between FTL-FM and conventional phases of adapting FM so that FM practitioners can align their research works with FTL-FM. In addition, we overview advanced efficiency-improving and privacy-preserving techniques because efficiency and privacy are critical concerns in FTL-FM. Last, we discuss opportunities and future research directions of FTL-FM.","sentences":["Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks.","Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs.","However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership.","Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges.","In recent years, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry.","Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated learning setting, construct a detailed taxonomy based on the FTL-FM framework to categorize state-of-the-art FTL-FM works, and comprehensively overview FTL-FM works based on the proposed taxonomy.","We also establish correspondences between FTL-FM and conventional phases of adapting FM so that FM practitioners can align their research works with FTL-FM.","In addition, we overview advanced efficiency-improving and privacy-preserving techniques because efficiency and privacy are critical concerns in FTL-FM.","Last, we discuss opportunities and future research directions of FTL-FM."],"url":"http://arxiv.org/abs/2311.17431v1"}
{"created":"2023-11-29 08:12:09","title":"TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP Models via GPT4","abstract":"Prompt-based learning has been widely applied in many low-resource NLP tasks such as few-shot scenarios. However, this paradigm has been shown to be vulnerable to backdoor attacks. Most of the existing attack methods focus on inserting manually predefined templates as triggers in the pre-training phase to train the victim model and utilize the same triggers in the downstream task to perform inference, which tends to ignore the transferability and stealthiness of the templates. In this work, we propose a novel approach of TARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models via GPT4), which is a data-independent attack method. Specifically, we first utilize GPT4 to reformulate manual templates to generate tone-strong and normal templates, and the former are injected into the model as a backdoor trigger in the pre-training phase. Then, we not only directly employ the above templates in the downstream task, but also use GPT4 to generate templates with similar tone to the above templates to carry out transferable attacks. Finally we have conducted extensive experiments on five NLP datasets and three BERT series models, with experimental results justifying that our TARGET method has better attack performance and stealthiness compared to the two-external baseline methods on direct attacks, and in addition achieves satisfactory attack capability in the unseen tone-similar templates.","sentences":["Prompt-based learning has been widely applied in many low-resource NLP tasks such as few-shot scenarios.","However, this paradigm has been shown to be vulnerable to backdoor attacks.","Most of the existing attack methods focus on inserting manually predefined templates as triggers in the pre-training phase to train the victim model and utilize the same triggers in the downstream task to perform inference, which tends to ignore the transferability and stealthiness of the templates.","In this work, we propose a novel approach of TARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models via GPT4), which is a data-independent attack method.","Specifically, we first utilize GPT4 to reformulate manual templates to generate tone-strong and normal templates, and the former are injected into the model as a backdoor trigger in the pre-training phase.","Then, we not only directly employ the above templates in the downstream task, but also use GPT4 to generate templates with similar tone to the above templates to carry out transferable attacks.","Finally we have conducted extensive experiments on five NLP datasets and three BERT series models, with experimental results justifying that our TARGET method has better attack performance and stealthiness compared to the two-external baseline methods on direct attacks, and in addition achieves satisfactory attack capability in the unseen tone-similar templates."],"url":"http://arxiv.org/abs/2311.17429v1"}
{"created":"2023-11-29 07:30:32","title":"GNNFlow: A Distributed Framework for Continuous Temporal GNN Learning on Dynamic Graphs","abstract":"Graph Neural Networks (GNNs) play a crucial role in various fields. However, most existing deep graph learning frameworks assume pre-stored static graphs and do not support training on graph streams. In contrast, many real-world graphs are dynamic and contain time domain information. We introduce GNNFlow, a distributed framework that enables efficient continuous temporal graph representation learning on dynamic graphs on multi-GPU machines. GNNFlow introduces an adaptive time-indexed block-based data structure that effectively balances memory usage with graph update and sampling operation efficiency. It features a hybrid GPU-CPU graph data placement for rapid GPU-based temporal neighborhood sampling and kernel optimizations for enhanced sampling processes. A dynamic GPU cache for node and edge features is developed to maximize cache hit rates through reuse and restoration strategies. GNNFlow supports distributed training across multiple machines with static scheduling to ensure load balance. We implement GNNFlow based on DGL and PyTorch. Our experimental results show that GNNFlow provides up to 21.1x faster continuous learning than existing systems.","sentences":["Graph Neural Networks (GNNs) play a crucial role in various fields.","However, most existing deep graph learning frameworks assume pre-stored static graphs and do not support training on graph streams.","In contrast, many real-world graphs are dynamic and contain time domain information.","We introduce GNNFlow, a distributed framework that enables efficient continuous temporal graph representation learning on dynamic graphs on multi-GPU machines.","GNNFlow introduces an adaptive time-indexed block-based data structure that effectively balances memory usage with graph update and sampling operation efficiency.","It features a hybrid GPU-CPU graph data placement for rapid GPU-based temporal neighborhood sampling and kernel optimizations for enhanced sampling processes.","A dynamic GPU cache for node and edge features is developed to maximize cache hit rates through reuse and restoration strategies.","GNNFlow supports distributed training across multiple machines with static scheduling to ensure load balance.","We implement GNNFlow based on DGL and PyTorch.","Our experimental results show that GNNFlow provides up to 21.1x faster continuous learning than existing systems."],"url":"http://arxiv.org/abs/2311.17410v1"}
{"created":"2023-11-29 07:25:49","title":"Dynamic Dense Graph Convolutional Network for Skeleton-based Human Motion Prediction","abstract":"Graph Convolutional Networks (GCN) which typically follows a neural message passing framework to model dependencies among skeletal joints has achieved high success in skeleton-based human motion prediction task. Nevertheless, how to construct a graph from a skeleton sequence and how to perform message passing on the graph are still open problems, which severely affect the performance of GCN. To solve both problems, this paper presents a Dynamic Dense Graph Convolutional Network (DD-GCN), which constructs a dense graph and implements an integrated dynamic message passing. More specifically, we construct a dense graph with 4D adjacency modeling as a comprehensive representation of motion sequence at different levels of abstraction. Based on the dense graph, we propose a dynamic message passing framework that learns dynamically from data to generate distinctive messages reflecting sample-specific relevance among nodes in the graph. Extensive experiments on benchmark Human 3.6M and CMU Mocap datasets verify the effectiveness of our DD-GCN which obviously outperforms state-of-the-art GCN-based methods, especially when using long-term and our proposed extremely long-term protocol.","sentences":["Graph Convolutional Networks (GCN) which typically follows a neural message passing framework to model dependencies among skeletal joints has achieved high success in skeleton-based human motion prediction task.","Nevertheless, how to construct a graph from a skeleton sequence and how to perform message passing on the graph are still open problems, which severely affect the performance of GCN.","To solve both problems, this paper presents a Dynamic Dense Graph Convolutional Network (DD-GCN), which constructs a dense graph and implements an integrated dynamic message passing.","More specifically, we construct a dense graph with 4D adjacency modeling as a comprehensive representation of motion sequence at different levels of abstraction.","Based on the dense graph, we propose a dynamic message passing framework that learns dynamically from data to generate distinctive messages reflecting sample-specific relevance among nodes in the graph.","Extensive experiments on benchmark Human 3.6M and CMU Mocap datasets verify the effectiveness of our DD-GCN which obviously outperforms state-of-the-art GCN-based methods, especially when using long-term and our proposed extremely long-term protocol."],"url":"http://arxiv.org/abs/2311.17408v1"}
{"created":"2023-11-29 07:16:34","title":"Learning and Autonomy for Extraterrestrial Terrain Sampling: An Experience Report from OWLAT Deployment","abstract":"Extraterrestrial autonomous lander missions increasingly demand adaptive capabilities to handle the unpredictable and diverse nature of the terrain. This paper discusses the deployment of a Deep Meta-Learning with Controlled Deployment Gaps (CoDeGa) trained model for terrain scooping tasks in Ocean Worlds Lander Autonomy Testbed (OWLAT) at NASA Jet Propulsion Laboratory. The CoDeGa-powered scooping strategy is designed to adapt to novel terrains, selecting scooping actions based on the available RGB-D image data and limited experience. The paper presents our experiences with transferring the scooping framework with CoDeGa-trained model from a low-fidelity testbed to the high-fidelity OWLAT testbed. Additionally, it validates the method's performance in novel, realistic environments, and shares the lessons learned from deploying learning-based autonomy algorithms for space exploration. Experimental results from OWLAT substantiate the efficacy of CoDeGa in rapidly adapting to unfamiliar terrains and effectively making autonomous decisions under considerable domain shifts, thereby endorsing its potential utility in future extraterrestrial missions.","sentences":["Extraterrestrial autonomous lander missions increasingly demand adaptive capabilities to handle the unpredictable and diverse nature of the terrain.","This paper discusses the deployment of a Deep Meta-Learning with Controlled Deployment Gaps (CoDeGa) trained model for terrain scooping tasks in Ocean Worlds Lander Autonomy Testbed (OWLAT) at NASA Jet Propulsion Laboratory.","The CoDeGa-powered scooping strategy is designed to adapt to novel terrains, selecting scooping actions based on the available RGB-D image data and limited experience.","The paper presents our experiences with transferring the scooping framework with CoDeGa-trained model from a low-fidelity testbed to the high-fidelity OWLAT testbed.","Additionally, it validates the method's performance in novel, realistic environments, and shares the lessons learned from deploying learning-based autonomy algorithms for space exploration.","Experimental results from OWLAT substantiate the efficacy of CoDeGa in rapidly adapting to unfamiliar terrains and effectively making autonomous decisions under considerable domain shifts, thereby endorsing its potential utility in future extraterrestrial missions."],"url":"http://arxiv.org/abs/2311.17405v1"}
{"created":"2023-11-29 07:15:34","title":"VITATECS: A Diagnostic Dataset for Temporal Concept Understanding of Video-Language Models","abstract":"The ability to perceive how objects change over time is a crucial ingredient in human intelligence. However, current benchmarks cannot faithfully reflect the temporal understanding abilities of video-language models (VidLMs) due to the existence of static visual shortcuts. To remedy this issue, we present VITATECS, a diagnostic VIdeo-Text dAtaset for the evaluation of TEmporal Concept underStanding. Specifically, we first introduce a fine-grained taxonomy of temporal concepts in natural language in order to diagnose the capability of VidLMs to comprehend different temporal aspects. Furthermore, to disentangle the correlation between static and temporal information, we generate counterfactual video descriptions that differ from the original one only in the specified temporal aspect. We employ a semi-automatic data collection framework using large language models and human-in-the-loop annotation to obtain high-quality counterfactual descriptions efficiently. Evaluation of representative video-language understanding models confirms their deficiency in temporal understanding, revealing the need for greater emphasis on the temporal elements in video-language research.","sentences":["The ability to perceive how objects change over time is a crucial ingredient in human intelligence.","However, current benchmarks cannot faithfully reflect the temporal understanding abilities of video-language models (VidLMs) due to the existence of static visual shortcuts.","To remedy this issue, we present VITATECS, a diagnostic VIdeo-Text dAtaset for the evaluation of TEmporal Concept underStanding.","Specifically, we first introduce a fine-grained taxonomy of temporal concepts in natural language in order to diagnose the capability of VidLMs to comprehend different temporal aspects.","Furthermore, to disentangle the correlation between static and temporal information, we generate counterfactual video descriptions that differ from the original one only in the specified temporal aspect.","We employ a semi-automatic data collection framework using large language models and human-in-the-loop annotation to obtain high-quality counterfactual descriptions efficiently.","Evaluation of representative video-language understanding models confirms their deficiency in temporal understanding, revealing the need for greater emphasis on the temporal elements in video-language research."],"url":"http://arxiv.org/abs/2311.17404v1"}
{"created":"2023-11-29 07:09:25","title":"Gene-MOE: A Sparsely-gated Framework for Pan-Cancer Genomic Analysis","abstract":"Analyzing the genomic information from the Pan-Cancer database can help us understand cancer-related factors and contribute to the cancer diagnosis and prognosis. However, existing computational methods and deep learning methods can not effectively find the deep correlations between tens of thousands of genes, which leads to precision loss. In this paper, we proposed a novel pretrained model called Gene-MOE to learn the general feature representations of the Pan-Cancer dataset and transfer the pretrained weights to the downstream tasks. The Gene-MOE fully exploits the mixture of expert (MOE) layers to learn rich feature representations of high-dimensional genes. At the same time, we build a mixture of attention expert (MOAE) model to learn the deep semantic relationships within genetic features. Finally, we proposed a new self-supervised pretraining strategy including loss function design, data enhancement, and optimization strategy to train the Gene-MOE and further improve the performance for the downstream analysis. We carried out cancer classification and survival analysis experiments based on the Gene-MOE. According to the survival analysis results on 14 cancer types, using Gene-MOE outperformed state-of-the-art models on 12 cancer types. According to the classification results, the total accuracy of the classification model for 33 cancer classifications reached 95.2\\%. Through detailed feature analysis, we found the Gene-MOE model can learn rich feature representations of high-dimensional genes.","sentences":["Analyzing the genomic information from the Pan-Cancer database can help us understand cancer-related factors and contribute to the cancer diagnosis and prognosis.","However, existing computational methods and deep learning methods can not effectively find the deep correlations between tens of thousands of genes, which leads to precision loss.","In this paper, we proposed a novel pretrained model called Gene-MOE to learn the general feature representations of the Pan-Cancer dataset and transfer the pretrained weights to the downstream tasks.","The Gene-MOE fully exploits the mixture of expert (MOE) layers to learn rich feature representations of high-dimensional genes.","At the same time, we build a mixture of attention expert (MOAE) model to learn the deep semantic relationships within genetic features.","Finally, we proposed a new self-supervised pretraining strategy including loss function design, data enhancement, and optimization strategy to train the Gene-MOE and further improve the performance for the downstream analysis.","We carried out cancer classification and survival analysis experiments based on the Gene-MOE.","According to the survival analysis results on 14 cancer types, using Gene-MOE outperformed state-of-the-art models on 12 cancer types.","According to the classification results, the total accuracy of the classification model for 33 cancer classifications reached 95.2\\%.","Through detailed feature analysis, we found the Gene-MOE model can learn rich feature representations of high-dimensional genes."],"url":"http://arxiv.org/abs/2311.17401v1"}
{"created":"2023-11-29 06:53:23","title":"Spectral and Polarization Vision: Spectro-polarimetric Real-world Dataset","abstract":"Image datasets are essential not only in validating existing methods in computer vision but also in developing new methods. Most existing image datasets focus on trichromatic intensity images to mimic human vision. However, polarization and spectrum, the wave properties of light that animals in harsh environments and with limited brain capacity often rely on, remain underrepresented in existing datasets. Although spectro-polarimetric datasets exist, these datasets have insufficient object diversity, limited illumination conditions, linear-only polarization data, and inadequate image count. Here, we introduce two spectro-polarimetric datasets: trichromatic Stokes images and hyperspectral Stokes images. These novel datasets encompass both linear and circular polarization; they introduce multiple spectral channels; and they feature a broad selection of real-world scenes. With our dataset in hand, we analyze the spectro-polarimetric image statistics, develop efficient representations of such high-dimensional data, and evaluate spectral dependency of shape-from-polarization methods. As such, the proposed dataset promises a foundation for data-driven spectro-polarimetric imaging and vision research. Dataset and code will be publicly available.","sentences":["Image datasets are essential not only in validating existing methods in computer vision but also in developing new methods.","Most existing image datasets focus on trichromatic intensity images to mimic human vision.","However, polarization and spectrum, the wave properties of light that animals in harsh environments and with limited brain capacity often rely on, remain underrepresented in existing datasets.","Although spectro-polarimetric datasets exist, these datasets have insufficient object diversity, limited illumination conditions, linear-only polarization data, and inadequate image count.","Here, we introduce two spectro-polarimetric datasets: trichromatic Stokes images and hyperspectral Stokes images.","These novel datasets encompass both linear and circular polarization; they introduce multiple spectral channels; and they feature a broad selection of real-world scenes.","With our dataset in hand, we analyze the spectro-polarimetric image statistics, develop efficient representations of such high-dimensional data, and evaluate spectral dependency of shape-from-polarization methods.","As such, the proposed dataset promises a foundation for data-driven spectro-polarimetric imaging and vision research.","Dataset and code will be publicly available."],"url":"http://arxiv.org/abs/2311.17396v1"}
{"created":"2023-11-29 06:42:12","title":"360Loc: A Dataset and Benchmark for Omnidirectional Visual Localization with Cross-device Queries","abstract":"Portable 360$^\\circ$ cameras are becoming a cheap and efficient tool to establish large visual databases. By capturing omnidirectional views of a scene, these cameras could expedite building environment models that are essential for visual localization. However, such an advantage is often overlooked due to the lack of valuable datasets. This paper introduces a new benchmark dataset, 360Loc, composed of 360$^\\circ$ images with ground truth poses for visual localization. We present a practical implementation of 360$^\\circ$ mapping combining 360$^\\circ$ images with lidar data to generate the ground truth 6DoF poses. 360Loc is the first dataset and benchmark that explores the challenge of cross-device visual positioning, involving 360$^\\circ$ reference frames, and query frames from pinhole, ultra-wide FoV fisheye, and 360$^\\circ$ cameras. We propose a virtual camera approach to generate lower-FoV query frames from 360$^\\circ$ images, which ensures a fair comparison of performance among different query types in visual localization tasks. We also extend this virtual camera approach to feature matching-based and pose regression-based methods to alleviate the performance loss caused by the cross-device domain gap, and evaluate its effectiveness against state-of-the-art baselines. We demonstrate that omnidirectional visual localization is more robust in challenging large-scale scenes with symmetries and repetitive structures. These results provide new insights into 360-camera mapping and omnidirectional visual localization with cross-device queries.","sentences":["Portable 360$^\\circ$ cameras are becoming a cheap and efficient tool to establish large visual databases.","By capturing omnidirectional views of a scene, these cameras could expedite building environment models that are essential for visual localization.","However, such an advantage is often overlooked due to the lack of valuable datasets.","This paper introduces a new benchmark dataset, 360Loc, composed of 360$^\\circ$ images with ground truth poses for visual localization.","We present a practical implementation of 360$^\\circ$ mapping combining 360$^\\circ$ images with lidar data to generate the ground truth 6DoF poses.","360Loc is the first dataset and benchmark that explores the challenge of cross-device visual positioning, involving 360$^\\circ$ reference frames, and query frames from pinhole, ultra-wide FoV fisheye, and 360$^\\circ$ cameras.","We propose a virtual camera approach to generate lower-FoV query frames from 360$^\\circ$ images, which ensures a fair comparison of performance among different query types in visual localization tasks.","We also extend this virtual camera approach to feature matching-based and pose regression-based methods to alleviate the performance loss caused by the cross-device domain gap, and evaluate its effectiveness against state-of-the-art baselines.","We demonstrate that omnidirectional visual localization is more robust in challenging large-scale scenes with symmetries and repetitive structures.","These results provide new insights into 360-camera mapping and omnidirectional visual localization with cross-device queries."],"url":"http://arxiv.org/abs/2311.17389v1"}
{"created":"2023-11-29 05:59:24","title":"Attribute Simulation for Item Embedding Enhancement in Multi-interest Recommendation","abstract":"Although multi-interest recommenders have achieved significant progress in the matching stage, our research reveals that existing models tend to exhibit an under-clustered item embedding space, which leads to a low discernibility between items and hampers item retrieval. This highlights the necessity for item embedding enhancement. However, item attributes, which serve as effective and straightforward side information for enhancement, are either unavailable or incomplete in many public datasets due to the labor-intensive nature of manual annotation tasks. This dilemma raises two meaningful questions: 1. Can we bypass manual annotation and directly simulate complete attribute information from the interaction data? And 2. If feasible, how to simulate attributes with high accuracy and low complexity in the matching stage?   In this paper, we first establish an inspiring theoretical feasibility that the item-attribute correlation matrix can be approximated through elementary transformations on the item co-occurrence matrix. Then based on formula derivation, we propose a simple yet effective module, SimEmb (Item Embedding Enhancement via Simulated Attribute), in the multi-interest recommendation of the matching stage to implement our findings. By simulating attributes with the co-occurrence matrix, SimEmb discards the item ID-based embedding and employs the attribute-weighted summation for item embedding enhancement. Comprehensive experiments on four benchmark datasets demonstrate that our approach notably enhances the clustering of item embedding and significantly outperforms SOTA models with an average improvement of 25.59% on Recall@20.","sentences":["Although multi-interest recommenders have achieved significant progress in the matching stage, our research reveals that existing models tend to exhibit an under-clustered item embedding space, which leads to a low discernibility between items and hampers item retrieval.","This highlights the necessity for item embedding enhancement.","However, item attributes, which serve as effective and straightforward side information for enhancement, are either unavailable or incomplete in many public datasets due to the labor-intensive nature of manual annotation tasks.","This dilemma raises two meaningful questions:","1.","Can we bypass manual annotation and directly simulate complete attribute information from the interaction data?","And 2.","If feasible, how to simulate attributes with high accuracy and low complexity in the matching stage?   ","In this paper, we first establish an inspiring theoretical feasibility that the item-attribute correlation matrix can be approximated through elementary transformations on the item co-occurrence matrix.","Then based on formula derivation, we propose a simple yet effective module, SimEmb (Item Embedding Enhancement via Simulated Attribute), in the multi-interest recommendation of the matching stage to implement our findings.","By simulating attributes with the co-occurrence matrix, SimEmb discards the item ID-based embedding and employs the attribute-weighted summation for item embedding enhancement.","Comprehensive experiments on four benchmark datasets demonstrate that our approach notably enhances the clustering of item embedding and significantly outperforms SOTA models with an average improvement of 25.59% on Recall@20."],"url":"http://arxiv.org/abs/2311.17374v1"}
{"created":"2023-11-29 05:54:58","title":"The Devil is in the Data: Learning Fair Graph Neural Networks via Partial Knowledge Distillation","abstract":"Graph neural networks (GNNs) are being increasingly used in many high-stakes tasks, and as a result, there is growing attention on their fairness recently. GNNs have been shown to be unfair as they tend to make discriminatory decisions toward certain demographic groups, divided by sensitive attributes such as gender and race. While recent works have been devoted to improving their fairness performance, they often require accessible demographic information. This greatly limits their applicability in real-world scenarios due to legal restrictions. To address this problem, we present a demographic-agnostic method to learn fair GNNs via knowledge distillation, namely FairGKD. Our work is motivated by the empirical observation that training GNNs on partial data (i.e., only node attributes or topology data) can improve their fairness, albeit at the cost of utility. To make a balanced trade-off between fairness and utility performance, we employ a set of fairness experts (i.e., GNNs trained on different partial data) to construct the synthetic teacher, which distills fairer and informative knowledge to guide the learning of the GNN student. Experiments on several benchmark datasets demonstrate that FairGKD, which does not require access to demographic information, significantly improves the fairness of GNNs by a large margin while maintaining their utility.","sentences":["Graph neural networks (GNNs) are being increasingly used in many high-stakes tasks, and as a result, there is growing attention on their fairness recently.","GNNs have been shown to be unfair as they tend to make discriminatory decisions toward certain demographic groups, divided by sensitive attributes such as gender and race.","While recent works have been devoted to improving their fairness performance, they often require accessible demographic information.","This greatly limits their applicability in real-world scenarios due to legal restrictions.","To address this problem, we present a demographic-agnostic method to learn fair GNNs via knowledge distillation, namely FairGKD.","Our work is motivated by the empirical observation that training GNNs on partial data (i.e., only node attributes or topology data) can improve their fairness, albeit at the cost of utility.","To make a balanced trade-off between fairness and utility performance, we employ a set of fairness experts (i.e., GNNs trained on different partial data) to construct the synthetic teacher, which distills fairer and informative knowledge to guide the learning of the GNN student.","Experiments on several benchmark datasets demonstrate that FairGKD, which does not require access to demographic information, significantly improves the fairness of GNNs by a large margin while maintaining their utility."],"url":"http://arxiv.org/abs/2311.17373v1"}
{"created":"2023-11-29 05:49:00","title":"Efficient and Scalable Architecture for Multiple-chip Implementation of Simulated Bifurcation Machines","abstract":"Ising machines are specialized computers for finding the lowest energy states of Ising spin models, onto which many practical combinatorial optimization problems can be mapped. Simulated bifurcation (SB) is a quantum-inspired parallelizable algorithm for Ising problems that enables scalable multi-chip implementations of Ising machines. However, the computational performance of a previously proposed multi-chip architecture tends to saturate as the number of chips increases for a given problem size because both computation and communication are exclusive in the time domain. In this paper, we propose a streaming architecture for multi-chip implementations of SB-based Ising machines with full spin-to-spin connectivity. The data flow in in-chip computation is harmonized with the data flow in inter-chip communication, enabling the computation and communication to overlap and the communication time to be hidden. Systematic experiments demonstrate linear strong scaling of performance up to the vicinity of the ideal communication limit determined only by the latency of chip-to-chip communication. Our eight-FPGA (field-programmable gate array) cluster can compute a 32,768-spin problem with a high pipeline efficiency of 97.9%. The performance of a 79-FPGA cluster for a 100,000-spin problem, projected using a theoretical performance model validated on smaller experimental clusters, is comparable to that of a state-of-the-art 100,000-spin optical Ising machine.","sentences":["Ising machines are specialized computers for finding the lowest energy states of Ising spin models, onto which many practical combinatorial optimization problems can be mapped.","Simulated bifurcation (SB) is a quantum-inspired parallelizable algorithm for Ising problems that enables scalable multi-chip implementations of Ising machines.","However, the computational performance of a previously proposed multi-chip architecture tends to saturate as the number of chips increases for a given problem size because both computation and communication are exclusive in the time domain.","In this paper, we propose a streaming architecture for multi-chip implementations of SB-based Ising machines with full spin-to-spin connectivity.","The data flow in in-chip computation is harmonized with the data flow in inter-chip communication, enabling the computation and communication to overlap and the communication time to be hidden.","Systematic experiments demonstrate linear strong scaling of performance up to the vicinity of the ideal communication limit determined only by the latency of chip-to-chip communication.","Our eight-FPGA (field-programmable gate array)","cluster can compute a 32,768-spin problem with a high pipeline efficiency of 97.9%.","The performance of a 79-FPGA cluster for a 100,000-spin problem, projected using a theoretical performance model validated on smaller experimental clusters, is comparable to that of a state-of-the-art 100,000-spin optical Ising machine."],"url":"http://arxiv.org/abs/2311.17370v1"}
{"created":"2023-11-29 05:42:25","title":"Two Scalable Approaches for Burned-Area Mapping Using U-Net and Landsat Imagery","abstract":"Monitoring wildfires is an essential step in minimizing their impact on the planet, understanding the many negative environmental, economic, and social consequences. Recent advances in remote sensing technology combined with the increasing application of artificial intelligence methods have improved real-time, high-resolution fire monitoring. This study explores two proposed approaches based on the U-Net model for automating and optimizing the burned-area mapping process. Denoted 128 and AllSizes (AS), they are trained on datasets with a different class balance by cropping input images to different sizes. They are then applied to Landsat imagery and time-series data from two fire-prone regions in Chile. The results obtained after enhancement of model performance by hyperparameter optimization demonstrate the effectiveness of both approaches. Tests based on 195 representative images of the study area show that increasing dataset balance using the AS model yields better performance. More specifically, AS exhibited a Dice Coefficient (DC) of 0.93, an Omission Error (OE) of 0.086, and a Commission Error (CE) of 0.045, while the 128 model achieved a DC of 0.86, an OE of 0.12, and a CE of 0.12. These findings should provide a basis for further development of scalable automatic burned-area mapping tools.","sentences":["Monitoring wildfires is an essential step in minimizing their impact on the planet, understanding the many negative environmental, economic, and social consequences.","Recent advances in remote sensing technology combined with the increasing application of artificial intelligence methods have improved real-time, high-resolution fire monitoring.","This study explores two proposed approaches based on the U-Net model for automating and optimizing the burned-area mapping process.","Denoted 128 and AllSizes (AS), they are trained on datasets with a different class balance by cropping input images to different sizes.","They are then applied to Landsat imagery and time-series data from two fire-prone regions in Chile.","The results obtained after enhancement of model performance by hyperparameter optimization demonstrate the effectiveness of both approaches.","Tests based on 195 representative images of the study area show that increasing dataset balance using the AS model yields better performance.","More specifically, AS exhibited a Dice Coefficient (DC) of 0.93, an Omission Error (OE) of 0.086, and a Commission Error (CE) of 0.045, while the 128 model achieved a DC of 0.86, an OE of 0.12, and a CE of 0.12.","These findings should provide a basis for further development of scalable automatic burned-area mapping tools."],"url":"http://arxiv.org/abs/2311.17368v1"}
{"created":"2023-11-29 05:27:14","title":"Symbol-LLM: Leverage Language Models for Symbolic System in Visual Human Activity Reasoning","abstract":"Human reasoning can be understood as a cooperation between the intuitive, associative \"System-1\" and the deliberative, logical \"System-2\". For existing System-1-like methods in visual activity understanding, it is crucial to integrate System-2 processing to improve explainability, generalization, and data efficiency. One possible path of activity reasoning is building a symbolic system composed of symbols and rules, where one rule connects multiple symbols, implying human knowledge and reasoning abilities. Previous methods have made progress, but are defective with limited symbols from handcraft and limited rules from visual-based annotations, failing to cover the complex patterns of activities and lacking compositional generalization. To overcome the defects, we propose a new symbolic system with two ideal important properties: broad-coverage symbols and rational rules. Collecting massive human knowledge via manual annotations is expensive to instantiate this symbolic system. Instead, we leverage the recent advancement of LLMs (Large Language Models) as an approximation of the two ideal properties, i.e., Symbols from Large Language Models (Symbol-LLM). Then, given an image, visual contents from the images are extracted and checked as symbols and activity semantics are reasoned out based on rules via fuzzy logic calculation. Our method shows superiority in extensive activity understanding tasks. Code and data are available at https://mvig-rhos.com/symbol_llm.","sentences":["Human reasoning can be understood as a cooperation between the intuitive, associative \"System-1\" and the deliberative, logical \"System-2\".","For existing System-1-like methods in visual activity understanding, it is crucial to integrate System-2 processing to improve explainability, generalization, and data efficiency.","One possible path of activity reasoning is building a symbolic system composed of symbols and rules, where one rule connects multiple symbols, implying human knowledge and reasoning abilities.","Previous methods have made progress, but are defective with limited symbols from handcraft and limited rules from visual-based annotations, failing to cover the complex patterns of activities and lacking compositional generalization.","To overcome the defects, we propose a new symbolic system with two ideal important properties: broad-coverage symbols and rational rules.","Collecting massive human knowledge via manual annotations is expensive to instantiate this symbolic system.","Instead, we leverage the recent advancement of LLMs (Large Language Models) as an approximation of the two ideal properties, i.e., Symbols from Large Language Models (Symbol-LLM).","Then, given an image, visual contents from the images are extracted and checked as symbols and activity semantics are reasoned out based on rules via fuzzy logic calculation.","Our method shows superiority in extensive activity understanding tasks.","Code and data are available at https://mvig-rhos.com/symbol_llm."],"url":"http://arxiv.org/abs/2311.17365v1"}
{"created":"2023-11-29 05:20:10","title":"How does spatial structure affect psychological restoration? A method based on Graph Neural Networks and Street View Imagery","abstract":"The Attention Restoration Theory (ART) presents a theoretical framework with four essential indicators (being away, extent, fascinating, and compatibility) for comprehending urban and natural restoration quality. However, previous studies relied on non-sequential data and non-spatial dependent methods, which overlooks the impact of spatial structure defined here as the positional relationships between scene entities on restoration quality. The past methods also make it challenging to measure restoration quality on an urban scale. In this work, a spatial-dependent graph neural networks (GNNs) approach is proposed to reveal the relation between spatial structure and restoration quality on an urban scale. Specifically, we constructed two different types of graphs at the street and city levels. The street-level graphs, using sequential street view images (SVIs) of road segments to capture position relationships between entities, were used to represent spatial structure. The city-level graph, modeling the topological relationships of roads as non-Euclidean data structures and embedding urban features (including Perception-features, Spatial-features, and Socioeconomic-features), was used to measure restoration quality. The results demonstrate that: 1) spatial-dependent GNNs model outperforms traditional methods (Acc = 0.735, F1 = 0.732); 2) spatial structure portrayed through sequential SVIs data significantly influences restoration quality; 3) spaces with the same restoration quality exhibited distinct spatial structures patterns. This study clarifies the association between spatial structure and restoration quality, providing a new perspective to improve urban well-being in the future.","sentences":["The Attention Restoration Theory (ART) presents a theoretical framework with four essential indicators (being away, extent, fascinating, and compatibility) for comprehending urban and natural restoration quality.","However, previous studies relied on non-sequential data and non-spatial dependent methods, which overlooks the impact of spatial structure defined here as the positional relationships between scene entities on restoration quality.","The past methods also make it challenging to measure restoration quality on an urban scale.","In this work, a spatial-dependent graph neural networks (GNNs) approach is proposed to reveal the relation between spatial structure and restoration quality on an urban scale.","Specifically, we constructed two different types of graphs at the street and city levels.","The street-level graphs, using sequential street view images (SVIs) of road segments to capture position relationships between entities, were used to represent spatial structure.","The city-level graph, modeling the topological relationships of roads as non-Euclidean data structures and embedding urban features (including Perception-features, Spatial-features, and Socioeconomic-features), was used to measure restoration quality.","The results demonstrate that: 1) spatial-dependent GNNs model outperforms traditional methods (Acc = 0.735, F1 = 0.732); 2) spatial structure portrayed through sequential SVIs data significantly influences restoration quality; 3) spaces with the same restoration quality exhibited distinct spatial structures patterns.","This study clarifies the association between spatial structure and restoration quality, providing a new perspective to improve urban well-being in the future."],"url":"http://arxiv.org/abs/2311.17361v1"}
{"created":"2023-11-29 04:25:15","title":"Exploring Large Language Models for Human Mobility Prediction under Public Events","abstract":"Public events, such as concerts and sports games, can be major attractors for large crowds, leading to irregular surges in travel demand. Accurate human mobility prediction for public events is thus crucial for event planning as well as traffic or crowd management. While rich textual descriptions about public events are commonly available from online sources, it is challenging to encode such information in statistical or machine learning models. Existing methods are generally limited in incorporating textual information, handling data sparsity, or providing rationales for their predictions. To address these challenges, we introduce a framework for human mobility prediction under public events (LLM-MPE) based on Large Language Models (LLMs), leveraging their unprecedented ability to process textual data, learn from minimal examples, and generate human-readable explanations. Specifically, LLM-MPE first transforms raw, unstructured event descriptions from online sources into a standardized format, and then segments historical mobility data into regular and event-related components. A prompting strategy is designed to direct LLMs in making and rationalizing demand predictions considering historical mobility and event features. A case study is conducted for Barclays Center in New York City, based on publicly available event information and taxi trip data. Results show that LLM-MPE surpasses traditional models, particularly on event days, with textual data significantly enhancing its accuracy. Furthermore, LLM-MPE offers interpretable insights into its predictions. Despite the great potential of LLMs, we also identify key challenges including misinformation and high costs that remain barriers to their broader adoption in large-scale human mobility analysis.","sentences":["Public events, such as concerts and sports games, can be major attractors for large crowds, leading to irregular surges in travel demand.","Accurate human mobility prediction for public events is thus crucial for event planning as well as traffic or crowd management.","While rich textual descriptions about public events are commonly available from online sources, it is challenging to encode such information in statistical or machine learning models.","Existing methods are generally limited in incorporating textual information, handling data sparsity, or providing rationales for their predictions.","To address these challenges, we introduce a framework for human mobility prediction under public events (LLM-MPE) based on Large Language Models (LLMs), leveraging their unprecedented ability to process textual data, learn from minimal examples, and generate human-readable explanations.","Specifically, LLM-MPE first transforms raw, unstructured event descriptions from online sources into a standardized format, and then segments historical mobility data into regular and event-related components.","A prompting strategy is designed to direct LLMs in making and rationalizing demand predictions considering historical mobility and event features.","A case study is conducted for Barclays Center in New York City, based on publicly available event information and taxi trip data.","Results show that LLM-MPE surpasses traditional models, particularly on event days, with textual data significantly enhancing its accuracy.","Furthermore, LLM-MPE offers interpretable insights into its predictions.","Despite the great potential of LLMs, we also identify key challenges including misinformation and high costs that remain barriers to their broader adoption in large-scale human mobility analysis."],"url":"http://arxiv.org/abs/2311.17351v1"}
{"created":"2023-11-29 04:15:57","title":"Implicit-explicit Integrated Representations for Multi-view Video Compression","abstract":"With the increasing consumption of 3D displays and virtual reality, multi-view video has become a promising format. However, its high resolution and multi-camera shooting result in a substantial increase in data volume, making storage and transmission a challenging task. To tackle these difficulties, we propose an implicit-explicit integrated representation for multi-view video compression. Specifically, we first use the explicit representation-based 2D video codec to encode one of the source views. Subsequently, we propose employing the implicit neural representation (INR)-based codec to encode the remaining views. The implicit codec takes the time and view index of multi-view video as coordinate inputs and generates the corresponding implicit reconstruction frames.To enhance the compressibility, we introduce a multi-level feature grid embedding and a fully convolutional architecture into the implicit codec. These components facilitate coordinate-feature and feature-RGB mapping, respectively. To further enhance the reconstruction quality from the INR codec, we leverage the high-quality reconstructed frames from the explicit codec to achieve inter-view compensation. Finally, the compensated results are fused with the implicit reconstructions from the INR to obtain the final reconstructed frames. Our proposed framework combines the strengths of both implicit neural representation and explicit 2D codec. Extensive experiments conducted on public datasets demonstrate that the proposed framework can achieve comparable or even superior performance to the latest multi-view video compression standard MIV and other INR-based schemes in terms of view compression and scene modeling.","sentences":["With the increasing consumption of 3D displays and virtual reality, multi-view video has become a promising format.","However, its high resolution and multi-camera shooting result in a substantial increase in data volume, making storage and transmission a challenging task.","To tackle these difficulties, we propose an implicit-explicit integrated representation for multi-view video compression.","Specifically, we first use the explicit representation-based 2D video codec to encode one of the source views.","Subsequently, we propose employing the implicit neural representation (INR)-based codec to encode the remaining views.","The implicit codec takes the time and view index of multi-view video as coordinate inputs and generates the corresponding implicit reconstruction frames.","To enhance the compressibility, we introduce a multi-level feature grid embedding and a fully convolutional architecture into the implicit codec.","These components facilitate coordinate-feature and feature-RGB mapping, respectively.","To further enhance the reconstruction quality from the INR codec, we leverage the high-quality reconstructed frames from the explicit codec to achieve inter-view compensation.","Finally, the compensated results are fused with the implicit reconstructions from the INR to obtain the final reconstructed frames.","Our proposed framework combines the strengths of both implicit neural representation and explicit 2D codec.","Extensive experiments conducted on public datasets demonstrate that the proposed framework can achieve comparable or even superior performance to the latest multi-view video compression standard MIV and other INR-based schemes in terms of view compression and scene modeling."],"url":"http://arxiv.org/abs/2311.17350v1"}
{"created":"2023-11-29 04:14:02","title":"Data-driven Bandwidth Adaptation for Radio Access Network Slices","abstract":"We develop a Bandwidth Demand Estimator (BDE); a network function that periodically monitors the traffic of a Network Slice (NS) and adapts the bandwidth at the base station to efficiently meet its packet delay requirements. We design the BDE based on a data-driven approach that utilizes QoS feedback. Given the traffic of the NS, the BDE needs to learn the bandwidth required to satisfy the QoS. However, it also needs to consider the future effects of its actions since low bandwidths may create large packet queues that hinder the allocation process later on. For this reason, we propose a reinforcement learning approach. The action is the allocated bandwidth. The state describes the traffic, the wireless channel and the packet queue of the NS. The cost is a weighted sum of the bandwidth and of a binary variable that equals 1 if the QoS is violated. We periodically estimate the transition matrix of the system and perform value iteration to find the optimal policy. To speed up the estimation process, we initialize our algorithm with multi-armed bandits and exploit the monotonicity of the cost w.r.t. the action. The overall approach can be viewed as a data-driven version of receding horizon control. We implement our BDE on a 3GPP compliant testbed developed by Amarisoft. Experimental results show that the BDE reduces both the average allocated bandwidth and the QoS violations in the NS when compared to baseline schemes. The BDE can also satisfy per user tail packet delay requirements.","sentences":["We develop a Bandwidth Demand Estimator (BDE); a network function that periodically monitors the traffic of a Network Slice (NS) and adapts the bandwidth at the base station to efficiently meet its packet delay requirements.","We design the BDE based on a data-driven approach that utilizes QoS feedback.","Given the traffic of the NS, the BDE needs to learn the bandwidth required to satisfy the QoS.","However, it also needs to consider the future effects of its actions since low bandwidths may create large packet queues that hinder the allocation process later on.","For this reason, we propose a reinforcement learning approach.","The action is the allocated bandwidth.","The state describes the traffic, the wireless channel and the packet queue of the NS.","The cost is a weighted sum of the bandwidth and of a binary variable that equals 1 if the QoS is violated.","We periodically estimate the transition matrix of the system and perform value iteration to find the optimal policy.","To speed up the estimation process, we initialize our algorithm with multi-armed bandits and exploit the monotonicity of the cost w.r.t.","the action.","The overall approach can be viewed as a data-driven version of receding horizon control.","We implement our BDE on a 3GPP compliant testbed developed by Amarisoft.","Experimental results show that the BDE reduces both the average allocated bandwidth and the QoS violations in the NS when compared to baseline schemes.","The BDE can also satisfy per user tail packet delay requirements."],"url":"http://arxiv.org/abs/2311.17347v1"}
{"created":"2023-11-29 04:08:09","title":"Perancangan UI/UX Aplikasi Sistem Informasi Layanan Administrasi dalam Perspektif Psikologi Menggunakan Metode Prototype","abstract":"Bina Darma University student administration services are still carried out conventionally. Students meet the lecturer to ask the lecturer to sign their administrative documents. However, cases of forged signatures still occur at Bina Darma University. This problem can cause material loss and is included in the category of criminal offense. The aim of this research is to design an Administrative Services Information System (SILASTRI) interface by applying color psychology theory, Gestalt principles with a good user experience. SILASTRI is designed to support student administration services at Bina Darma University. Data collection through observation, distributing questionnaires and literature study. This research uses a prototype method which consists of communication, quick plan, modeling quick design, construction of prototype and deployment delivery & feedback. The prototype method proves technical feasibility and validates the usability of the user interface display by estimating the software so that if there are deficiencies they can be corrected immediately. Based on the results of usability testing using Maze, which was tested by 70 respondents, the Maze usability value was 89 and the SUS calculation value was 88, which is in the good category. Therefore, it can be concluded that the UI/UX design of the SILASTRI application by applying a psychological perspective has an interface and user experience that is well received by users. The results of this testing and evaluation prove that the SILASTRI display design is ready to be developed into an application.","sentences":["Bina Darma University student administration services are still carried out conventionally.","Students meet the lecturer to ask the lecturer to sign their administrative documents.","However, cases of forged signatures still occur at Bina Darma University.","This problem can cause material loss and is included in the category of criminal offense.","The aim of this research is to design an Administrative Services Information System (SILASTRI) interface by applying color psychology theory, Gestalt principles with a good user experience.","SILASTRI is designed to support student administration services at Bina Darma University.","Data collection through observation, distributing questionnaires and literature study.","This research uses a prototype method which consists of communication, quick plan, modeling quick design, construction of prototype and deployment delivery & feedback.","The prototype method proves technical feasibility and validates the usability of the user interface display by estimating the software so that if there are deficiencies they can be corrected immediately.","Based on the results of usability testing using Maze, which was tested by 70 respondents, the Maze usability value was 89 and the SUS calculation value was 88, which is in the good category.","Therefore, it can be concluded that the UI/UX design of the SILASTRI application by applying a psychological perspective has an interface and user experience that is well received by users.","The results of this testing and evaluation prove that the SILASTRI display design is ready to be developed into an application."],"url":"http://arxiv.org/abs/2311.17345v1"}
{"created":"2023-11-29 03:36:07","title":"VideoAssembler: Identity-Consistent Video Generation with Reference Entities using Diffusion Model","abstract":"Identity-consistent video generation seeks to synthesize videos that are guided by both textual prompts and reference images of entities. Current approaches typically utilize cross-attention layers to integrate the appearance of the entity, which predominantly captures semantic attributes, resulting in compromised fidelity of entities. Moreover, these methods necessitate iterative fine-tuning for each new entity encountered, thereby limiting their applicability. To address these challenges, we introduce VideoAssembler, a novel end-to-end framework for identity-consistent video generation that can conduct inference directly when encountering new entities. VideoAssembler is adept at producing videos that are not only flexible with respect to the input reference entities but also responsive to textual conditions. Additionally, by modulating the quantity of input images for the entity, VideoAssembler enables the execution of tasks ranging from image-to-video generation to sophisticated video editing. VideoAssembler comprises two principal components: the Reference Entity Pyramid (REP) encoder and the Entity-Prompt Attention Fusion (EPAF) module. The REP encoder is designed to infuse comprehensive appearance details into the denoising stages of the stable diffusion model. Concurrently, the EPAF module is utilized to integrate text-aligned features effectively. Furthermore, to mitigate the challenge of scarce data, we present a methodology for the preprocessing of training data. Our evaluation of the VideoAssembler framework on the UCF-101, MSR-VTT, and DAVIS datasets indicates that it achieves good performances in both quantitative and qualitative analyses (346.84 in FVD and 48.01 in IS on UCF-101). Our project page is at https://videoassembler.github.io/videoassembler.","sentences":["Identity-consistent video generation seeks to synthesize videos that are guided by both textual prompts and reference images of entities.","Current approaches typically utilize cross-attention layers to integrate the appearance of the entity, which predominantly captures semantic attributes, resulting in compromised fidelity of entities.","Moreover, these methods necessitate iterative fine-tuning for each new entity encountered, thereby limiting their applicability.","To address these challenges, we introduce VideoAssembler, a novel end-to-end framework for identity-consistent video generation that can conduct inference directly when encountering new entities.","VideoAssembler is adept at producing videos that are not only flexible with respect to the input reference entities but also responsive to textual conditions.","Additionally, by modulating the quantity of input images for the entity, VideoAssembler enables the execution of tasks ranging from image-to-video generation to sophisticated video editing.","VideoAssembler comprises two principal components: the Reference Entity Pyramid (REP) encoder and the Entity-Prompt Attention Fusion (EPAF) module.","The REP encoder is designed to infuse comprehensive appearance details into the denoising stages of the stable diffusion model.","Concurrently, the EPAF module is utilized to integrate text-aligned features effectively.","Furthermore, to mitigate the challenge of scarce data, we present a methodology for the preprocessing of training data.","Our evaluation of the VideoAssembler framework on the UCF-101, MSR-VTT, and DAVIS datasets indicates that it achieves good performances in both quantitative and qualitative analyses (346.84 in FVD and 48.01 in IS on UCF-101).","Our project page is at https://videoassembler.github.io/videoassembler."],"url":"http://arxiv.org/abs/2311.17338v1"}
{"created":"2023-11-29 03:25:48","title":"Incremental Neural Controlled Differential Equations for Modeling of Path-dependent Materials","abstract":"Data-driven surrogate modeling or metamodeling has emerged as a promising approach for reducing computational expenses of multiscale simulations. Recurrent Neural Network (RNN) is a common choice for modeling of path-dependent behavior. However, previous studies have shown that RNNs fail to make predictions that are consistent with perturbation in the input strain, leading to potential oscillations and lack of convergence when implemented within finite element simulations. In this work, we leverage neural differential equations which have recently emerged to model time series in a continuous manner and show their robustness in modeling elasto-plastic path-dependent material behavior. We develop a new sequential model called Incremental Neural Controlled Differential Equation (INCDE) for general time-variant dynamical systems, including path-dependent constitutive models. INCDE is formulated and analyzed in terms of stability and convergence. A surrogate model based on INCDE is subsequently trained and tested for J2 plasticity. The surrogate model is implemented for material point simulations and boundary value problems solved using the finite element method with various cyclic and monotonic loading protocols to demonstrate the robustness, consistency and accuracy of the proposed approach.","sentences":["Data-driven surrogate modeling or metamodeling has emerged as a promising approach for reducing computational expenses of multiscale simulations.","Recurrent Neural Network (RNN) is a common choice for modeling of path-dependent behavior.","However, previous studies have shown that RNNs fail to make predictions that are consistent with perturbation in the input strain, leading to potential oscillations and lack of convergence when implemented within finite element simulations.","In this work, we leverage neural differential equations which have recently emerged to model time series in a continuous manner and show their robustness in modeling elasto-plastic path-dependent material behavior.","We develop a new sequential model called Incremental Neural Controlled Differential Equation (INCDE) for general time-variant dynamical systems, including path-dependent constitutive models.","INCDE is formulated and analyzed in terms of stability and convergence.","A surrogate model based on INCDE is subsequently trained and tested for J2 plasticity.","The surrogate model is implemented for material point simulations and boundary value problems solved using the finite element method with various cyclic and monotonic loading protocols to demonstrate the robustness, consistency and accuracy of the proposed approach."],"url":"http://arxiv.org/abs/2311.17336v1"}
{"created":"2023-11-29 03:24:30","title":"eMotions: A Large-Scale Dataset for Emotion Recognition in Short Videos","abstract":"Nowadays, short videos (SVs) are essential to information acquisition and sharing in our life. The prevailing use of SVs to spread emotions leads to the necessity of emotion recognition in SVs. Considering the lack of SVs emotion data, we introduce a large-scale dataset named eMotions, comprising 27,996 videos. Meanwhile, we alleviate the impact of subjectivities on labeling quality by emphasizing better personnel allocations and multi-stage annotations. In addition, we provide the category-balanced and test-oriented variants through targeted data sampling. Some commonly used videos (e.g., facial expressions and postures) have been well studied. However, it is still challenging to understand the emotions in SVs. Since the enhanced content diversity brings more distinct semantic gaps and difficulties in learning emotion-related features, and there exists information gaps caused by the emotion incompleteness under the prevalently audio-visual co-expressions. To tackle these problems, we present an end-to-end baseline method AV-CPNet that employs the video transformer to better learn semantically relevant representations. We further design the two-stage cross-modal fusion module to complementarily model the correlations of audio-visual features. The EP-CE Loss, incorporating three emotion polarities, is then applied to guide model optimization. Extensive experimental results on nine datasets verify the effectiveness of AV-CPNet. Datasets and code will be open on https://github.com/XuecWu/eMotions.","sentences":["Nowadays, short videos (SVs) are essential to information acquisition and sharing in our life.","The prevailing use of SVs to spread emotions leads to the necessity of emotion recognition in SVs.","Considering the lack of SVs emotion data, we introduce a large-scale dataset named eMotions, comprising 27,996 videos.","Meanwhile, we alleviate the impact of subjectivities on labeling quality by emphasizing better personnel allocations and multi-stage annotations.","In addition, we provide the category-balanced and test-oriented variants through targeted data sampling.","Some commonly used videos (e.g., facial expressions and postures) have been well studied.","However, it is still challenging to understand the emotions in SVs.","Since the enhanced content diversity brings more distinct semantic gaps and difficulties in learning emotion-related features, and there exists information gaps caused by the emotion incompleteness under the prevalently audio-visual co-expressions.","To tackle these problems, we present an end-to-end baseline method AV-CPNet that employs the video transformer to better learn semantically relevant representations.","We further design the two-stage cross-modal fusion module to complementarily model the correlations of audio-visual features.","The EP-CE Loss, incorporating three emotion polarities, is then applied to guide model optimization.","Extensive experimental results on nine datasets verify the effectiveness of AV-CPNet.","Datasets and code will be open on https://github.com/XuecWu/eMotions."],"url":"http://arxiv.org/abs/2311.17335v1"}
{"created":"2023-11-29 03:10:42","title":"Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering","abstract":"Recently, Vision Language Models (VLMs) have gained significant attention, exhibiting notable advancements across various tasks by leveraging extensive image-text paired data. However, prevailing VLMs often treat Visual Question Answering (VQA) as perception tasks, employing black-box models that overlook explicit modeling of relationships between different questions within the same visual scene. Moreover, the existing VQA methods that rely on Knowledge Bases (KBs) might frequently encounter biases from limited data and face challenges in relevant information indexing. Attempt to overcome these limitations, this paper introduces an explainable multi-agent collaboration framework by tapping into knowledge embedded in Large Language Models (LLMs) trained on extensive corpora. Inspired by human cognition, our framework uncovers latent information within the given question by employing three agents, i.e., Seeker, Responder, and Integrator, to perform a top-down reasoning process. The Seeker agent generates relevant issues related to the original question. The Responder agent, based on VLM, handles simple VQA tasks and provides candidate answers. The Integrator agent combines information from the Seeker agent and the Responder agent to produce the final VQA answer. Through the above collaboration mechanism, our framework explicitly constructs a multi-view knowledge base for a specific image scene, reasoning answers in a top-down processing manner. We extensively evaluate our method on diverse VQA datasets and VLMs, demonstrating its broad applicability and interpretability with comprehensive experimental results.","sentences":["Recently, Vision Language Models (VLMs) have gained significant attention, exhibiting notable advancements across various tasks by leveraging extensive image-text paired data.","However, prevailing VLMs often treat Visual Question Answering (VQA) as perception tasks, employing black-box models that overlook explicit modeling of relationships between different questions within the same visual scene.","Moreover, the existing VQA methods that rely on Knowledge Bases (KBs) might frequently encounter biases from limited data and face challenges in relevant information indexing.","Attempt to overcome these limitations, this paper introduces an explainable multi-agent collaboration framework by tapping into knowledge embedded in Large Language Models (LLMs) trained on extensive corpora.","Inspired by human cognition, our framework uncovers latent information within the given question by employing three agents, i.e., Seeker, Responder, and Integrator, to perform a top-down reasoning process.","The Seeker agent generates relevant issues related to the original question.","The Responder agent, based on VLM, handles simple VQA tasks and provides candidate answers.","The Integrator agent combines information from the Seeker agent and the Responder agent to produce the final VQA answer.","Through the above collaboration mechanism, our framework explicitly constructs a multi-view knowledge base for a specific image scene, reasoning answers in a top-down processing manner.","We extensively evaluate our method on diverse VQA datasets and VLMs, demonstrating its broad applicability and interpretability with comprehensive experimental results."],"url":"http://arxiv.org/abs/2311.17331v1"}
{"created":"2023-11-29 03:07:00","title":"Biomedical knowledge graph-enhanced prompt generation for large language models","abstract":"Large Language Models (LLMs) have been driving progress in AI at an unprecedented rate, yet still face challenges in knowledge-intensive domains like biomedicine. Solutions such as pre-training and domain-specific fine-tuning add substantial computational overhead, and the latter require domain-expertise. External knowledge infusion is task-specific and requires model training. Here, we introduce a task-agnostic Knowledge Graph-based Retrieval Augmented Generation (KG-RAG) framework by leveraging the massive biomedical KG SPOKE with LLMs such as Llama-2-13b, GPT-3.5-Turbo and GPT-4, to generate meaningful biomedical text rooted in established knowledge. KG-RAG consistently enhanced the performance of LLMs across various prompt types, including one-hop and two-hop prompts, drug repurposing queries, biomedical true/false questions, and multiple-choice questions (MCQ). Notably, KG-RAG provides a remarkable 71% boost in the performance of the Llama-2 model on the challenging MCQ dataset, demonstrating the framework's capacity to empower open-source models with fewer parameters for domain-specific questions. Furthermore, KG-RAG enhanced the performance of proprietary GPT models, such as GPT-3.5 which exhibited improvement over GPT-4 in context utilization on MCQ data. Our approach was also able to address drug repurposing questions, returning meaningful repurposing suggestions. In summary, the proposed framework combines explicit and implicit knowledge of KG and LLM, respectively, in an optimized fashion, thus enhancing the adaptability of general-purpose LLMs to tackle domain-specific questions in a unified framework.","sentences":["Large Language Models (LLMs) have been driving progress in AI at an unprecedented rate, yet still face challenges in knowledge-intensive domains like biomedicine.","Solutions such as pre-training and domain-specific fine-tuning add substantial computational overhead, and the latter require domain-expertise.","External knowledge infusion is task-specific and requires model training.","Here, we introduce a task-agnostic Knowledge Graph-based Retrieval Augmented Generation (KG-RAG) framework by leveraging the massive biomedical KG SPOKE with LLMs such as Llama-2-13b, GPT-3.5-Turbo and GPT-4, to generate meaningful biomedical text rooted in established knowledge.","KG-RAG consistently enhanced the performance of LLMs across various prompt types, including one-hop and two-hop prompts, drug repurposing queries, biomedical true/false questions, and multiple-choice questions (MCQ).","Notably, KG-RAG provides a remarkable 71% boost in the performance of the Llama-2 model on the challenging MCQ dataset, demonstrating the framework's capacity to empower open-source models with fewer parameters for domain-specific questions.","Furthermore, KG-RAG enhanced the performance of proprietary GPT models, such as GPT-3.5 which exhibited improvement over GPT-4 in context utilization on MCQ data.","Our approach was also able to address drug repurposing questions, returning meaningful repurposing suggestions.","In summary, the proposed framework combines explicit and implicit knowledge of KG and LLM, respectively, in an optimized fashion, thus enhancing the adaptability of general-purpose LLMs to tackle domain-specific questions in a unified framework."],"url":"http://arxiv.org/abs/2311.17330v1"}
{"created":"2023-11-29 03:03:21","title":"Cascade: A Platform for Delay-Sensitive Edge Intelligence","abstract":"Interactive intelligent computing applications are increasingly prevalent, creating a need for AI/ML platforms optimized to reduce per-event latency while maintaining high throughput and efficient resource management. Yet many intelligent applications run on AI/ML platforms that optimize for high throughput even at the cost of high tail-latency. Cascade is a new AI/ML hosting platform intended to untangle this puzzle. Innovations include a legacy-friendly storage layer that moves data with minimal copying and a \"fast path\" that collocates data and computation to maximize responsiveness. Our evaluation shows that Cascade reduces latency by orders of magnitude with no loss of throughput.","sentences":["Interactive intelligent computing applications are increasingly prevalent, creating a need for AI/ML platforms optimized to reduce per-event latency while maintaining high throughput and efficient resource management.","Yet many intelligent applications run on AI/ML platforms that optimize for high throughput even at the cost of high tail-latency.","Cascade is a new AI/ML hosting platform intended to untangle this puzzle.","Innovations include a legacy-friendly storage layer that moves data with minimal copying and a \"fast path\" that collocates data and computation to maximize responsiveness.","Our evaluation shows that Cascade reduces latency by orders of magnitude with no loss of throughput."],"url":"http://arxiv.org/abs/2311.17329v1"}
{"created":"2023-11-29 02:58:30","title":"Improving Self-supervised Molecular Representation Learning using Persistent Homology","abstract":"Self-supervised learning (SSL) has great potential for molecular representation learning given the complexity of molecular graphs, the large amounts of unlabelled data available, the considerable cost of obtaining labels experimentally, and the hence often only small training datasets. The importance of the topic is reflected in the variety of paradigms and architectures that have been investigated recently. Yet the differences in performance seem often minor and are barely understood to date. In this paper, we study SSL based on persistent homology (PH), a mathematical tool for modeling topological features of data that persist across multiple scales. It has several unique features which particularly suit SSL, naturally offering: different views of the data, stability in terms of distance preservation, and the opportunity to flexibly incorporate domain knowledge. We (1) investigate an autoencoder, which shows the general representational power of PH, and (2) propose a contrastive loss that complements existing approaches. We rigorously evaluate our approach for molecular property prediction and demonstrate its particular features in improving the embedding space: after SSL, the representations are better and offer considerably more predictive power than the baselines over different probing tasks; our loss increases baseline performance, sometimes largely; and we often obtain substantial improvements over very small datasets, a common scenario in practice.","sentences":["Self-supervised learning (SSL) has great potential for molecular representation learning given the complexity of molecular graphs, the large amounts of unlabelled data available, the considerable cost of obtaining labels experimentally, and the hence often only small training datasets.","The importance of the topic is reflected in the variety of paradigms and architectures that have been investigated recently.","Yet the differences in performance seem often minor and are barely understood to date.","In this paper, we study SSL based on persistent homology (PH), a mathematical tool for modeling topological features of data that persist across multiple scales.","It has several unique features which particularly suit SSL, naturally offering: different views of the data, stability in terms of distance preservation, and the opportunity to flexibly incorporate domain knowledge.","We (1) investigate an autoencoder, which shows the general representational power of PH, and (2) propose a contrastive loss that complements existing approaches.","We rigorously evaluate our approach for molecular property prediction and demonstrate its particular features in improving the embedding space: after SSL, the representations are better and offer considerably more predictive power than the baselines over different probing tasks; our loss increases baseline performance, sometimes largely; and we often obtain substantial improvements over very small datasets, a common scenario in practice."],"url":"http://arxiv.org/abs/2311.17327v1"}
{"created":"2023-11-29 02:53:32","title":"Mostly Beneficial Clustering: Aggregating Data for Operational Decision Making","abstract":"With increasingly volatile market conditions and rapid product innovations, operational decision-making for large-scale systems entails solving thousands of problems with limited data. Data aggregation is proposed to combine the data across problems to improve the decisions obtained by solving those problems individually. We propose a novel cluster-based shrunken-SAA approach that can exploit the cluster structure among problems when implementing the data aggregation approaches. We prove that, as the number of problems grows, leveraging the known cluster structure among problems yields additional benefits over the data aggregation approaches that neglect such structure. When the cluster structure is unknown, we show that unveiling the cluster structure, even at the cost of a few data points, can be beneficial, especially when the distance between clusters of problems is substantial. Our proposed approach can be extended to general cost functions under mild conditions. When the number of problems gets large, the optimality gap of our proposed approach decreases exponentially in the distance between the clusters. We explore the performance of the proposed approach through the application of managing newsvendor systems via numerical experiments. We investigate the impacts of distance metrics between problem instances on the performance of the cluster-based Shrunken-SAA approach with synthetic data. We further validate our proposed approach with real data and highlight the advantages of cluster-based data aggregation, especially in the small-data large-scale regime, compared to the existing approaches.","sentences":["With increasingly volatile market conditions and rapid product innovations, operational decision-making for large-scale systems entails solving thousands of problems with limited data.","Data aggregation is proposed to combine the data across problems to improve the decisions obtained by solving those problems individually.","We propose a novel cluster-based shrunken-SAA approach that can exploit the cluster structure among problems when implementing the data aggregation approaches.","We prove that, as the number of problems grows, leveraging the known cluster structure among problems yields additional benefits over the data aggregation approaches that neglect such structure.","When the cluster structure is unknown, we show that unveiling the cluster structure, even at the cost of a few data points, can be beneficial, especially when the distance between clusters of problems is substantial.","Our proposed approach can be extended to general cost functions under mild conditions.","When the number of problems gets large, the optimality gap of our proposed approach decreases exponentially in the distance between the clusters.","We explore the performance of the proposed approach through the application of managing newsvendor systems via numerical experiments.","We investigate the impacts of distance metrics between problem instances on the performance of the cluster-based Shrunken-SAA approach with synthetic data.","We further validate our proposed approach with real data and highlight the advantages of cluster-based data aggregation, especially in the small-data large-scale regime, compared to the existing approaches."],"url":"http://arxiv.org/abs/2311.17326v1"}
{"created":"2023-11-29 02:44:54","title":"Alternate Diverse Teaching for Semi-supervised Medical Image Segmentation","abstract":"Semi-supervised medical image segmentation studies have shown promise in training models with limited labeled data. However, current dominant teacher-student based approaches can suffer from the confirmation bias. To address this challenge, we propose AD-MT, an alternate diverse teaching approach in a teacher-student framework. It involves a single student model and two non-trainable teacher models that are momentum-updated periodically and randomly in an alternate fashion. To mitigate the confirmation bias from the diverse supervision, the core of AD-MT lies in two proposed modules: the Random Periodic Alternate (RPA) Updating Module and the Conflict-Combating Module (CCM). The RPA schedules the alternating diverse updating process with complementary data batches, distinct data augmentation, and random switching periods to encourage diverse reasoning from different teaching perspectives. The CCM employs an entropy-based ensembling strategy to encourage the model to learn from both the consistent and conflicting predictions between the teachers. Experimental results demonstrate the effectiveness and superiority of our AD-MT on the 2D and 3D medical segmentation benchmarks across various semi-supervised settings.","sentences":["Semi-supervised medical image segmentation studies have shown promise in training models with limited labeled data.","However, current dominant teacher-student based approaches can suffer from the confirmation bias.","To address this challenge, we propose AD-MT, an alternate diverse teaching approach in a teacher-student framework.","It involves a single student model and two non-trainable teacher models that are momentum-updated periodically and randomly in an alternate fashion.","To mitigate the confirmation bias from the diverse supervision, the core of AD-MT lies in two proposed modules: the Random Periodic Alternate (RPA) Updating Module and the Conflict-Combating Module (CCM).","The RPA schedules the alternating diverse updating process with complementary data batches, distinct data augmentation, and random switching periods to encourage diverse reasoning from different teaching perspectives.","The CCM employs an entropy-based ensembling strategy to encourage the model to learn from both the consistent and conflicting predictions between the teachers.","Experimental results demonstrate the effectiveness and superiority of our AD-MT on the 2D and 3D medical segmentation benchmarks across various semi-supervised settings."],"url":"http://arxiv.org/abs/2311.17325v1"}
{"created":"2023-11-29 02:40:12","title":"Accelerating DNN Training With Photonics: A Residue Number System-Based Design","abstract":"Photonic computing is a compelling avenue for performing highly efficient matrix multiplication, a crucial operation in Deep Neural Networks (DNNs). While this method has shown great success in DNN inference, meeting the high precision demands of DNN training proves challenging due to the precision limitations imposed by costly data converters and the analog noise inherent in photonic hardware. This paper proposes Mirage, a photonic DNN training accelerator that overcomes the precision challenges in photonic hardware using the Residue Number System (RNS). RNS is a numeral system based on modular arithmetic$\\unicode{x2014}$allowing us to perform high-precision operations via multiple low-precision modular operations. In this work, we present a novel micro-architecture and dataflow for an RNS-based photonic tensor core performing modular arithmetic in the analog domain. By combining RNS and photonics, Mirage provides high energy efficiency without compromising precision and can successfully train state-of-the-art DNNs achieving accuracy comparable to FP32 training. Our study shows that on average across several DNNs when compared to systolic arrays, Mirage achieves more than $23.8\\times$ faster training and $32.1\\times$ lower EDP in an iso-energy scenario and consumes $42.8\\times$ lower power with comparable or better EDP in an iso-area scenario.","sentences":["Photonic computing is a compelling avenue for performing highly efficient matrix multiplication, a crucial operation in Deep Neural Networks (DNNs).","While this method has shown great success in DNN inference, meeting the high precision demands of DNN training proves challenging due to the precision limitations imposed by costly data converters and the analog noise inherent in photonic hardware.","This paper proposes Mirage, a photonic DNN training accelerator that overcomes the precision challenges in photonic hardware using the Residue Number System (RNS).","RNS is a numeral system based on modular arithmetic$\\unicode{x2014}$allowing us to perform high-precision operations via multiple low-precision modular operations.","In this work, we present a novel micro-architecture and dataflow for an RNS-based photonic tensor core performing modular arithmetic in the analog domain.","By combining RNS and photonics, Mirage provides high energy efficiency without compromising precision and can successfully train state-of-the-art DNNs achieving accuracy comparable to FP32 training.","Our study shows that on average across several DNNs when compared to systolic arrays, Mirage achieves more than $23.8\\times$ faster training and $32.1\\times$ lower EDP in an iso-energy scenario and consumes $42.8\\times$ lower power with comparable or better EDP in an iso-area scenario."],"url":"http://arxiv.org/abs/2311.17323v1"}
{"created":"2023-11-29 02:20:47","title":"Microstructure reconstruction of 2D/3D random materials via diffusion-based deep generative models","abstract":"Microstructure reconstruction serves as a crucial foundation for establishing Process-Structure-Property (PSP) relationship in material design. Confronting the limitations of variational autoencoder and generative adversarial network within generative modeling, this study adopted the denoising diffusion probability model (DDPM) to learn the probability distribution of high-dimensional raw data and successfully reconstructed the microstructures of various composite materials, such as inclusion materials, spinodal decomposition materials, chessboard materials, fractal noise materials, and so on. The quality of generated microstructure was evaluated using quantitative measures like spatial correlation functions and Fourier descriptor. On this basis, this study also successfully achieved the regulation of microstructure randomness and the generation of gradient materials through continuous interpolation in latent space using denoising diffusion implicit model (DDIM). Furthermore, the two-dimensional microstructure reconstruction is extended to three-dimensional framework and integrates permeability as a feature encoding embedding. This enables the conditional generation of three-dimensional microstructures for random porous materials within a defined permeability range. The permeabilities of these generated microstructures were further validated through the application of the Boltzmann method.","sentences":["Microstructure reconstruction serves as a crucial foundation for establishing Process-Structure-Property (PSP) relationship in material design.","Confronting the limitations of variational autoencoder and generative adversarial network within generative modeling, this study adopted the denoising diffusion probability model (DDPM) to learn the probability distribution of high-dimensional raw data and successfully reconstructed the microstructures of various composite materials, such as inclusion materials, spinodal decomposition materials, chessboard materials, fractal noise materials, and so on.","The quality of generated microstructure was evaluated using quantitative measures like spatial correlation functions and Fourier descriptor.","On this basis, this study also successfully achieved the regulation of microstructure randomness and the generation of gradient materials through continuous interpolation in latent space using denoising diffusion implicit model (DDIM).","Furthermore, the two-dimensional microstructure reconstruction is extended to three-dimensional framework and integrates permeability as a feature encoding embedding.","This enables the conditional generation of three-dimensional microstructures for random porous materials within a defined permeability range.","The permeabilities of these generated microstructures were further validated through the application of the Boltzmann method."],"url":"http://arxiv.org/abs/2311.17319v1"}
{"created":"2023-11-29 02:10:31","title":"Explaining CLIP's performance disparities on data from blind/low vision users","abstract":"Large multi-modal models (LMMs) hold the potential to usher in a new era of automated visual assistance for people who are blind or low vision (BLV). Yet, these models have not been systematically evaluated on data captured by BLV users. We address this by empirically assessing CLIP, a widely-used LMM likely to underpin many assistive technologies. Testing 25 CLIP variants in a zero-shot classification task, we find that their accuracy is 15 percentage points lower on average for images captured by BLV users than web-crawled images. This disparity stems from CLIP's sensitivities to 1) image content (e.g. not recognizing disability objects as well as other objects); 2) image quality (e.g. not being robust to lighting variation); and 3) text content (e.g. not recognizing objects described by tactile adjectives as well as visual ones). We delve deeper with a textual analysis of three common pre-training datasets: LAION-400M, LAION-2B and DataComp-1B, showing that disability content is rarely mentioned. We then provide three examples that illustrate how the performance disparities extend to three downstream models underpinned by CLIP: OWL-ViT, CLIPSeg and DALL-E2. We find that few-shot learning with as few as 5 images can mitigate CLIP's quality-of-service disparities for BLV users in some scenarios, which we discuss alongside a set of other possible mitigations.","sentences":["Large multi-modal models (LMMs) hold the potential to usher in a new era of automated visual assistance for people who are blind or low vision (BLV).","Yet, these models have not been systematically evaluated on data captured by BLV users.","We address this by empirically assessing CLIP, a widely-used LMM likely to underpin many assistive technologies.","Testing 25 CLIP variants in a zero-shot classification task, we find that their accuracy is 15 percentage points lower on average for images captured by BLV users than web-crawled images.","This disparity stems from CLIP's sensitivities to 1) image content (e.g. not recognizing disability objects as well as other objects); 2) image quality (e.g. not being robust to lighting variation); and 3) text content (e.g. not recognizing objects described by tactile adjectives as well as visual ones).","We delve deeper with a textual analysis of three common pre-training datasets: LAION-400M, LAION-2B and DataComp-1B, showing that disability content is rarely mentioned.","We then provide three examples that illustrate how the performance disparities extend to three downstream models underpinned by CLIP: OWL-ViT, CLIPSeg and DALL-E2.","We find that few-shot learning with as few as 5 images can mitigate CLIP's quality-of-service disparities for BLV users in some scenarios, which we discuss alongside a set of other possible mitigations."],"url":"http://arxiv.org/abs/2311.17315v1"}
{"created":"2023-11-29 01:25:00","title":"Enhancing the Performance of Neural Networks Through Causal Discovery and Integration of Domain Knowledge","abstract":"In this paper, we develop a generic methodology to encode hierarchical causality structure among observed variables into a neural network in order to improve its predictive performance. The proposed methodology, called causality-informed neural network (CINN), leverages three coherent steps to systematically map the structural causal knowledge into the layer-to-layer design of neural network while strictly preserving the orientation of every causal relationship. In the first step, CINN discovers causal relationships from observational data via directed acyclic graph (DAG) learning, where causal discovery is recast as a continuous optimization problem to avoid the combinatorial nature. In the second step, the discovered hierarchical causality structure among observed variables is systematically encoded into neural network through a dedicated architecture and customized loss function. By categorizing variables in the causal DAG as root, intermediate, and leaf nodes, the hierarchical causal DAG is translated into CINN with a one-to-one correspondence between nodes in the causal DAG and units in the CINN while maintaining the relative order among these nodes. Regarding the loss function, both intermediate and leaf nodes in the DAG graph are treated as target outputs during CINN training so as to drive co-learning of causal relationships among different types of nodes. As multiple loss components emerge in CINN, we leverage the projection of conflicting gradients to mitigate gradient interference among the multiple learning tasks. Computational experiments across a broad spectrum of UCI data sets demonstrate substantial advantages of CINN in predictive performance over other state-of-the-art methods. In addition, an ablation study underscores the value of integrating structural and quantitative causal knowledge in enhancing the neural network's predictive performance incrementally.","sentences":["In this paper, we develop a generic methodology to encode hierarchical causality structure among observed variables into a neural network in order to improve its predictive performance.","The proposed methodology, called causality-informed neural network (CINN), leverages three coherent steps to systematically map the structural causal knowledge into the layer-to-layer design of neural network while strictly preserving the orientation of every causal relationship.","In the first step, CINN discovers causal relationships from observational data via directed acyclic graph (DAG) learning, where causal discovery is recast as a continuous optimization problem to avoid the combinatorial nature.","In the second step, the discovered hierarchical causality structure among observed variables is systematically encoded into neural network through a dedicated architecture and customized loss function.","By categorizing variables in the causal DAG as root, intermediate, and leaf nodes, the hierarchical causal DAG is translated into CINN with a one-to-one correspondence between nodes in the causal DAG and units in the CINN while maintaining the relative order among these nodes.","Regarding the loss function, both intermediate and leaf nodes in the DAG graph are treated as target outputs during CINN training so as to drive co-learning of causal relationships among different types of nodes.","As multiple loss components emerge in CINN, we leverage the projection of conflicting gradients to mitigate gradient interference among the multiple learning tasks.","Computational experiments across a broad spectrum of UCI data sets demonstrate substantial advantages of CINN in predictive performance over other state-of-the-art methods.","In addition, an ablation study underscores the value of integrating structural and quantitative causal knowledge in enhancing the neural network's predictive performance incrementally."],"url":"http://arxiv.org/abs/2311.17303v1"}
{"created":"2023-11-29 00:48:25","title":"Stability control for USVs with SINDY-based online dynamic model update","abstract":"Unmanned Surface Vehicles (USVs) play a pivotal role in various applications, including surface rescue, commercial transactions, scientific exploration, water rescue, and military operations. The effective control of high-speed unmanned surface boats stands as a critical aspect within the overall USV system, particularly in challenging environments marked by complex surface obstacles and dynamic conditions, such as time-varying surges, non-directional forces, and unpredictable winds. In this paper, we propose a data-driven control method based on Koopman theory. This involves constructing a high-dimensional linear model by mapping a low-dimensional nonlinear model to a higher-dimensional linear space through data identification. The observable USVs dynamical system is dynamically reconstructed using online error learning. To enhance tracking control accuracy, we utilize a Constructive Lyapunov Function (CLF)-Control Barrier Function (CBF)-Quadratic Programming (QP) approach to regulate the high-dimensional linear dynamical system obtained through identification. This approach facilitates error compensation, thereby achieving more precise tracking control.","sentences":["Unmanned Surface Vehicles (USVs) play a pivotal role in various applications, including surface rescue, commercial transactions, scientific exploration, water rescue, and military operations.","The effective control of high-speed unmanned surface boats stands as a critical aspect within the overall USV system, particularly in challenging environments marked by complex surface obstacles and dynamic conditions, such as time-varying surges, non-directional forces, and unpredictable winds.","In this paper, we propose a data-driven control method based on Koopman theory.","This involves constructing a high-dimensional linear model by mapping a low-dimensional nonlinear model to a higher-dimensional linear space through data identification.","The observable USVs dynamical system is dynamically reconstructed using online error learning.","To enhance tracking control accuracy, we utilize a Constructive Lyapunov Function (CLF)-Control Barrier Function (CBF)-Quadratic Programming (QP) approach to regulate the high-dimensional linear dynamical system obtained through identification.","This approach facilitates error compensation, thereby achieving more precise tracking control."],"url":"http://arxiv.org/abs/2311.17297v1"}
{"created":"2023-11-29 00:14:30","title":"Utilizing Model Residuals to Identify Rental Properties of Interest: The Price Anomaly Score (PAS) and Its Application to Real-time Data in Manhattan","abstract":"Understanding whether a property is priced fairly hinders buyers and sellers since they usually do not have an objective viewpoint of the price distribution for the overall market of their interest. Drawing from data collected of all possible available properties for rent in Manhattan as of September 2023, this paper aims to strengthen our understanding of model residuals; specifically on machine learning models which generalize for a majority of the distribution of a well-proportioned dataset. Most models generally perceive deviations from predicted values as mere inaccuracies, however this paper proposes a different vantage point: when generalizing to at least 75\\% of the data-set, the remaining deviations reveal significant insights. To harness these insights, we introduce the Price Anomaly Score (PAS), a metric capable of capturing boundaries between irregularly predicted prices. By combining relative pricing discrepancies with statistical significance, the Price Anomaly Score (PAS) offers a multifaceted view of rental valuations. This metric allows experts to identify overpriced or underpriced properties within a dataset by aggregating PAS values, then fine-tuning upper and lower boundaries to any threshold to set indicators of choice.","sentences":["Understanding whether a property is priced fairly hinders buyers and sellers since they usually do not have an objective viewpoint of the price distribution for the overall market of their interest.","Drawing from data collected of all possible available properties for rent in Manhattan as of September 2023, this paper aims to strengthen our understanding of model residuals; specifically on machine learning models which generalize for a majority of the distribution of a well-proportioned dataset.","Most models generally perceive deviations from predicted values as mere inaccuracies, however this paper proposes a different vantage point: when generalizing to at least 75\\% of the data-set, the remaining deviations reveal significant insights.","To harness these insights, we introduce the Price Anomaly Score (PAS), a metric capable of capturing boundaries between irregularly predicted prices.","By combining relative pricing discrepancies with statistical significance, the Price Anomaly Score (PAS) offers a multifaceted view of rental valuations.","This metric allows experts to identify overpriced or underpriced properties within a dataset by aggregating PAS values, then fine-tuning upper and lower boundaries to any threshold to set indicators of choice."],"url":"http://arxiv.org/abs/2311.17287v1"}
{"created":"2023-11-29 00:09:45","title":"LEOD: Label-Efficient Object Detection for Event Cameras","abstract":"Object detection with event cameras enjoys the property of low latency and high dynamic range, making it suitable for safety-critical scenarios such as self-driving. However, labeling event streams with high temporal resolutions for supervised training is costly. We address this issue with LEOD, the first framework for label-efficient event-based detection. Our method unifies weakly- and semi-supervised object detection with a self-training mechanism. We first utilize a detector pre-trained on limited labels to produce pseudo ground truth on unlabeled events, and then re-train the detector with both real and generated labels. Leveraging the temporal consistency of events, we run bi-directional inference and apply tracking-based post-processing to enhance the quality of pseudo labels. To stabilize training, we further design a soft anchor assignment strategy to mitigate the noise in labels. We introduce new experimental protocols to evaluate the task of label-efficient event-based detection on Gen1 and 1Mpx datasets. LEOD consistently outperforms supervised baselines across various labeling ratios. For example, on Gen1, it improves mAP by 8.6% and 7.8% for RVT-S trained with 1% and 2% labels. On 1Mpx, RVT-S with 10% labels even surpasses its fully-supervised counterpart using 100% labels. LEOD maintains its effectiveness even when all labeled data are available, reaching new state-of-the-art results. Finally, we show that our method readily scales to improve larger detectors as well.","sentences":["Object detection with event cameras enjoys the property of low latency and high dynamic range, making it suitable for safety-critical scenarios such as self-driving.","However, labeling event streams with high temporal resolutions for supervised training is costly.","We address this issue with LEOD, the first framework for label-efficient event-based detection.","Our method unifies weakly- and semi-supervised object detection with a self-training mechanism.","We first utilize a detector pre-trained on limited labels to produce pseudo ground truth on unlabeled events, and then re-train the detector with both real and generated labels.","Leveraging the temporal consistency of events, we run bi-directional inference and apply tracking-based post-processing to enhance the quality of pseudo labels.","To stabilize training, we further design a soft anchor assignment strategy to mitigate the noise in labels.","We introduce new experimental protocols to evaluate the task of label-efficient event-based detection on Gen1 and 1Mpx datasets.","LEOD consistently outperforms supervised baselines across various labeling ratios.","For example, on Gen1, it improves mAP by 8.6% and 7.8% for RVT-S trained with 1% and 2% labels.","On 1Mpx, RVT-S with 10% labels even surpasses its fully-supervised counterpart using 100% labels.","LEOD maintains its effectiveness even when all labeled data are available, reaching new state-of-the-art results.","Finally, we show that our method readily scales to improve larger detectors as well."],"url":"http://arxiv.org/abs/2311.17286v1"}
{"created":"2023-11-28 23:45:20","title":"Lower Bounds on Adaptive Sensing for Matrix Recovery","abstract":"We study lower bounds on adaptive sensing algorithms for recovering low rank matrices using linear measurements. Given an $n \\times n$ matrix $A$, a general linear measurement $S(A)$, for an $n \\times n$ matrix $S$, is just the inner product of $S$ and $A$, each treated as $n^2$-dimensional vectors. By performing as few linear measurements as possible on a rank-$r$ matrix $A$, we hope to construct a matrix $\\hat{A}$ that satisfies $\\|A - \\hat{A}\\|_F^2 \\le c\\|A\\|_F^2$, for a small constant $c$. It is commonly assumed that when measuring $A$ with $S$, the response is corrupted with an independent Gaussian random variable of mean $0$ and variance $\\sigma^2$. Cand\\'es and Plan study non-adaptive algorithms for low rank matrix recovery using random linear measurements.   At a certain noise level, it is known that their non-adaptive algorithms need to perform $\\Omega(n^2)$ measurements, which amounts to reading the entire matrix. An important question is whether adaptivity helps in decreasing the overall number of measurements. We show that any adaptive algorithm that uses $k$ linear measurements in each round and outputs an approximation to the underlying matrix with probability $\\ge 9/10$ must run for $t = \\Omega(\\log(n^2/k)/\\log\\log n)$ rounds showing that any adaptive algorithm which uses $n^{2-\\beta}$ linear measurements in each round must run for $\\Omega(\\log n/\\log\\log n)$ rounds to compute a reconstruction with probability $\\ge 9/10$. Hence any adaptive algorithm that has $o(\\log n/\\log\\log n)$ rounds must use an overall $\\Omega(n^2)$ linear measurements. Our techniques also readily extend to obtain lower bounds on adaptive algorithms for tensor recovery and obtain measurement-vs-rounds trade-off for many sensing problems in numerical linear algebra, such as spectral norm low rank approximation, Frobenius norm low rank approximation, singular vector approximation, and more.","sentences":["We study lower bounds on adaptive sensing algorithms for recovering low rank matrices using linear measurements.","Given an $n \\times n$ matrix $A$, a general linear measurement $S(A)$, for an $n \\times n$ matrix $S$, is just the inner product of $S$ and $A$, each treated as $n^2$-dimensional vectors.","By performing as few linear measurements as possible on a rank-$r$ matrix $A$, we hope to construct a matrix $\\hat{A}$ that satisfies $\\|A - \\hat{A}\\|_F^2 \\le c\\|A\\|_F^2$, for a small constant $c$. It is commonly assumed that when measuring $A$ with $S$, the response is corrupted with an independent Gaussian random variable of mean $0$ and variance $\\sigma^2$. Cand\\'es and Plan study non-adaptive algorithms for low rank matrix recovery using random linear measurements.   ","At a certain noise level, it is known that their non-adaptive algorithms need to perform $\\Omega(n^2)$ measurements, which amounts to reading the entire matrix.","An important question is whether adaptivity helps in decreasing the overall number of measurements.","We show that any adaptive algorithm that uses $k$ linear measurements in each round and outputs an approximation to the underlying matrix with probability $\\ge 9/10$ must run for $t = \\Omega(\\log(n^2/k)/\\log\\log n)$ rounds showing that any adaptive algorithm which uses $n^{2-\\beta}$ linear measurements in each round must run for $\\Omega(\\log n/\\log\\log n)$ rounds to compute a reconstruction with probability $\\ge 9/10$. Hence any adaptive algorithm that has $o(\\log n/\\log\\log n)$ rounds must use an overall $\\Omega(n^2)$ linear measurements.","Our techniques also readily extend to obtain lower bounds on adaptive algorithms for tensor recovery and obtain measurement-vs-rounds trade-off for many sensing problems in numerical linear algebra, such as spectral norm low rank approximation, Frobenius norm low rank approximation, singular vector approximation, and more."],"url":"http://arxiv.org/abs/2311.17281v1"}
{"created":"2023-11-28 23:40:13","title":"Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?","abstract":"Data augmentation via back-translation is common when pretraining Vision-and-Language Navigation (VLN) models, even though the generated instructions are noisy. But: does that noise matter? We find that nonsensical or irrelevant language instructions during pretraining can have little effect on downstream performance for both HAMT and VLN-BERT on R2R, and is still better than only using clean, human data. To underscore these results, we concoct an efficient augmentation method, Unigram + Object, which generates nonsensical instructions that nonetheless improve downstream performance. Our findings suggest that what matters for VLN R2R pretraining is the quantity of visual trajectories, not the quality of instructions.","sentences":["Data augmentation via back-translation is common when pretraining Vision-and-Language Navigation (VLN) models, even though the generated instructions are noisy.","But: does that noise matter?","We find that nonsensical or irrelevant language instructions during pretraining can have little effect on downstream performance for both HAMT and VLN-BERT on R2R, and is still better than only using clean, human data.","To underscore these results, we concoct an efficient augmentation method, Unigram + Object, which generates nonsensical instructions that nonetheless improve downstream performance.","Our findings suggest that what matters for VLN R2R pretraining is the quantity of visual trajectories, not the quality of instructions."],"url":"http://arxiv.org/abs/2311.17280v1"}
{"created":"2023-11-28 23:32:42","title":"Machine Unlearning in Learned Databases: An Experimental Analysis","abstract":"Machine learning models based on neural networks (NNs) are enjoying ever-increasing attention in the DB community. However, an important issue has been largely overlooked, namely the challenge of dealing with the highly dynamic nature of DBs, where data updates are fundamental, highly-frequent operations. Although some recent research has addressed the issues of maintaining updated NN models in the presence of new data insertions, the effects of data deletions (a.k.a., \"machine unlearning\") remain a blind spot. With this work, for the first time to our knowledge, we pose and answer the following key questions: What is the effect of unlearning algorithms on NN-based DB models? How do these effects translate to effects on downstream DB tasks, such as selectivity estimation (SE), approximate query processing (AQP), data generation (DG), and upstream tasks like data classification (DC)? What metrics should we use to assess the impact and efficacy of unlearning algorithms in learned DBs? Is the problem of machine unlearning in DBs different from that of machine learning in DBs in the face of data insertions? Is the problem of machine unlearning for DBs different from unlearning in the ML literature? what are the overhead and efficiency of unlearning algorithms? What is the sensitivity of unlearning on batching delete operations? If we have a suitable unlearning algorithm, can we combine it with an algorithm handling data insertions en route to solving the general adaptability/updatability requirement in learned DBs in the face of both data inserts and deletes? We answer these questions using a comprehensive set of experiments, various unlearning algorithms, a variety of downstream DB tasks, and an upstream task (DC), each with different NNs, and using a variety of metrics on a variety of real datasets, making this also a first key step towards a benchmark for learned DB unlearning.","sentences":["Machine learning models based on neural networks (NNs) are enjoying ever-increasing attention in the DB community.","However, an important issue has been largely overlooked, namely the challenge of dealing with the highly dynamic nature of DBs, where data updates are fundamental, highly-frequent operations.","Although some recent research has addressed the issues of maintaining updated NN models in the presence of new data insertions, the effects of data deletions (a.k.a., \"machine unlearning\") remain a blind spot.","With this work, for the first time to our knowledge, we pose and answer the following key questions: What is the effect of unlearning algorithms on NN-based DB models?","How do these effects translate to effects on downstream DB tasks, such as selectivity estimation (SE), approximate query processing (AQP), data generation (DG), and upstream tasks like data classification (DC)?","What metrics should we use to assess the impact and efficacy of unlearning algorithms in learned DBs?","Is the problem of machine unlearning in DBs different from that of machine learning in DBs in the face of data insertions?","Is the problem of machine unlearning for DBs different from unlearning in the ML literature?","what are the overhead and efficiency of unlearning algorithms?","What is the sensitivity of unlearning on batching delete operations?","If we have a suitable unlearning algorithm, can we combine it with an algorithm handling data insertions en route to solving the general adaptability/updatability requirement in learned DBs in the face of both data inserts and deletes?","We answer these questions using a comprehensive set of experiments, various unlearning algorithms, a variety of downstream DB tasks, and an upstream task (DC), each with different NNs, and using a variety of metrics on a variety of real datasets, making this also a first key step towards a benchmark for learned DB unlearning."],"url":"http://arxiv.org/abs/2311.17276v1"}
{"created":"2023-11-28 22:57:17","title":"E-ViLM: Efficient Video-Language Model via Masked Video Modeling with Semantic Vector-Quantized Tokenizer","abstract":"To build scalable models for challenging real-world tasks, it is important to learn from diverse, multi-modal data in various forms (e.g., videos, text, and images). Among the existing works, a plethora of them have focused on leveraging large but cumbersome cross-modal architectures. Regardless of their effectiveness, larger architectures unavoidably prevent the models from being extended to real-world applications, so building a lightweight VL architecture and an efficient learning schema is of great practical value. In this paper, we propose an Efficient Video-Language Model (dubbed as E-ViLM) and a masked video modeling (MVM) schema, assisted with a semantic vector-quantized tokenizer. In particular, our E-ViLM learns to reconstruct the semantic labels of masked video regions, produced by the pre-trained vector-quantized tokenizer, which discretizes the continuous visual signals into labels. We show that with our simple MVM task and regular VL pre-training modelings, our E-ViLM, despite its compactness, is able to learn expressive representations from Video-Language corpus and generalize well to extensive Video-Language tasks including video question answering, text-to-video retrieval, etc. In particular, our E-ViLM obtains obvious efficiency improvements by reaching competing performances with faster inference speed, i.e., our model reaches $39.3$% Top-$1$ accuracy on the MSRVTT benchmark, retaining $91.4$% of the accuracy of state-of-the-art larger VL architecture with only $15%$ parameters and $94.8%$ fewer GFLOPs. We also provide extensive ablative studies that validate the effectiveness of our proposed learning schema for E-ViLM.","sentences":["To build scalable models for challenging real-world tasks, it is important to learn from diverse, multi-modal data in various forms (e.g., videos, text, and images).","Among the existing works, a plethora of them have focused on leveraging large but cumbersome cross-modal architectures.","Regardless of their effectiveness, larger architectures unavoidably prevent the models from being extended to real-world applications, so building a lightweight VL architecture and an efficient learning schema is of great practical value.","In this paper, we propose an Efficient Video-Language Model (dubbed as E-ViLM) and a masked video modeling (MVM) schema, assisted with a semantic vector-quantized tokenizer.","In particular, our E-ViLM learns to reconstruct the semantic labels of masked video regions, produced by the pre-trained vector-quantized tokenizer, which discretizes the continuous visual signals into labels.","We show that with our simple MVM task and regular VL pre-training modelings, our E-ViLM, despite its compactness, is able to learn expressive representations from Video-Language corpus and generalize well to extensive Video-Language tasks including video question answering, text-to-video retrieval, etc.","In particular, our E-ViLM obtains obvious efficiency improvements by reaching competing performances with faster inference speed, i.e., our model reaches $39.3$% Top-$1$ accuracy on the MSRVTT benchmark, retaining $91.4$% of the accuracy of state-of-the-art larger VL architecture with only $15%$ parameters and $94.8%$ fewer GFLOPs.","We also provide extensive ablative studies that validate the effectiveness of our proposed learning schema for E-ViLM."],"url":"http://arxiv.org/abs/2311.17267v1"}
{"created":"2023-11-28 22:48:00","title":"SoUnD Framework: Analyzing (So)cial Representation in (Un)structured (D)ata","abstract":"The unstructured nature of data used in foundation model development is a challenge to systematic analyses for making data use and documentation decisions. From a Responsible AI perspective, these decisions often rely upon understanding how people are represented in data. We propose a framework designed to guide analysis of human representation in unstructured data and identify downstream risks. We apply the framework in two toy examples using the Common Crawl web text corpus (C4) and LAION-400M. We also propose a set of hypothetical action steps in service of dataset use, development, and documentation.","sentences":["The unstructured nature of data used in foundation model development is a challenge to systematic analyses for making data use and documentation decisions.","From a Responsible AI perspective, these decisions often rely upon understanding how people are represented in data.","We propose a framework designed to guide analysis of human representation in unstructured data and identify downstream risks.","We apply the framework in two toy examples using the Common Crawl web text corpus (C4) and","LAION-400M. We also propose a set of hypothetical action steps in service of dataset use, development, and documentation."],"url":"http://arxiv.org/abs/2311.17259v1"}
{"created":"2023-11-28 22:33:22","title":"Pattern retrieval of traffic congestion using graph-based associations of traffic domain-specific features","abstract":"The fast-growing amount of traffic data brings many opportunities for revealing more insightful information about traffic dynamics. However, it also demands an effective database management system in which information retrieval is arguably an important feature. The ability to locate similar patterns in big datasets potentially paves the way for further valuable analyses in traffic management. This paper proposes a content-based retrieval system for spatiotemporal patterns of highway traffic congestion. There are two main components in our framework, namely pattern representation and similarity measurement. To effectively interpret retrieval outcomes, the paper proposes a graph-based approach (relation-graph) for the former component, in which fundamental traffic phenomena are encoded as nodes and their spatiotemporal relationships as edges. In the latter component, the similarities between congestion patterns are customizable with various aspects according to user expectations. We evaluated the proposed framework by applying it to a dataset of hundreds of patterns with various complexities (temporally and spatially). The example queries indicate the effectiveness of the proposed method, i.e. the obtained patterns present similar traffic phenomena as in the given examples. In addition, the success of the proposed approach directly derives a new opportunity for semantic retrieval, in which expected patterns are described by adopting the relation-graph notion to associate fundamental traffic phenomena.","sentences":["The fast-growing amount of traffic data brings many opportunities for revealing more insightful information about traffic dynamics.","However, it also demands an effective database management system in which information retrieval is arguably an important feature.","The ability to locate similar patterns in big datasets potentially paves the way for further valuable analyses in traffic management.","This paper proposes a content-based retrieval system for spatiotemporal patterns of highway traffic congestion.","There are two main components in our framework, namely pattern representation and similarity measurement.","To effectively interpret retrieval outcomes, the paper proposes a graph-based approach (relation-graph) for the former component, in which fundamental traffic phenomena are encoded as nodes and their spatiotemporal relationships as edges.","In the latter component, the similarities between congestion patterns are customizable with various aspects according to user expectations.","We evaluated the proposed framework by applying it to a dataset of hundreds of patterns with various complexities (temporally and spatially).","The example queries indicate the effectiveness of the proposed method, i.e. the obtained patterns present similar traffic phenomena as in the given examples.","In addition, the success of the proposed approach directly derives a new opportunity for semantic retrieval, in which expected patterns are described by adopting the relation-graph notion to associate fundamental traffic phenomena."],"url":"http://arxiv.org/abs/2311.17256v1"}
{"created":"2023-11-28 22:11:15","title":"Fourier Neural Differential Equations for learning Quantum Field Theories","abstract":"A Quantum Field Theory is defined by its interaction Hamiltonian, and linked to experimental data by the scattering matrix. The scattering matrix is calculated as a perturbative series, and represented succinctly as a first order differential equation in time. Neural Differential Equations (NDEs) learn the time derivative of a residual network's hidden state, and have proven efficacy in learning differential equations with physical constraints. Hence using an NDE to learn particle scattering matrices presents a possible experiment-theory phenomenological connection. In this paper, NDE models are used to learn $\\phi^4$ theory, Scalar-Yukawa theory and Scalar Quantum Electrodynamics. A new NDE architecture is also introduced, the Fourier Neural Differential Equation (FNDE), which combines NDE integration and Fourier network convolution. The FNDE model demonstrates better generalisability than the non-integrated equivalent FNO model. It is also shown that by training on scattering data, the interaction Hamiltonian of a theory can be extracted from network parameters.","sentences":["A Quantum Field Theory is defined by its interaction Hamiltonian, and linked to experimental data by the scattering matrix.","The scattering matrix is calculated as a perturbative series, and represented succinctly as a first order differential equation in time.","Neural Differential Equations (NDEs) learn the time derivative of a residual network's hidden state, and have proven efficacy in learning differential equations with physical constraints.","Hence using an NDE to learn particle scattering matrices presents a possible experiment-theory phenomenological connection.","In this paper, NDE models are used to learn $\\phi^4$ theory, Scalar-Yukawa theory and Scalar Quantum Electrodynamics.","A new NDE architecture is also introduced, the Fourier Neural Differential Equation (FNDE), which combines NDE integration and Fourier network convolution.","The FNDE model demonstrates better generalisability than the non-integrated equivalent FNO model.","It is also shown that by training on scattering data, the interaction Hamiltonian of a theory can be extracted from network parameters."],"url":"http://arxiv.org/abs/2311.17250v1"}
{"created":"2023-11-28 21:31:04","title":"End-to-End Temporal Action Detection with 1B Parameters Across 1000 Frames","abstract":"Recently, temporal action detection (TAD) has seen significant performance improvement with end-to-end training. However, due to the memory bottleneck, only models with limited scales and limited data volumes can afford end-to-end training, which inevitably restricts TAD performance. In this paper, we reduce the memory consumption for end-to-end training, and manage to scale up the TAD backbone to 1 billion parameters and the input video to 1,536 frames, leading to significant detection performance. The key to our approach lies in our proposed temporal-informative adapter (TIA), which is a novel lightweight module that reduces training memory. Using TIA, we free the humongous backbone from learning to adapt to the TAD task by only updating the parameters in TIA. TIA also leads to better TAD representation by temporally aggregating context from adjacent frames throughout the backbone. We evaluate our model across four representative datasets. Owing to our efficient design, we are able to train end-to-end on VideoMAEv2-giant and achieve 75.4% mAP on THUMOS14, being the first end-to-end model to outperform the best feature-based methods.","sentences":["Recently, temporal action detection (TAD) has seen significant performance improvement with end-to-end training.","However, due to the memory bottleneck, only models with limited scales and limited data volumes can afford end-to-end training, which inevitably restricts TAD performance.","In this paper, we reduce the memory consumption for end-to-end training, and manage to scale up the TAD backbone to 1 billion parameters and the input video to 1,536 frames, leading to significant detection performance.","The key to our approach lies in our proposed temporal-informative adapter (TIA), which is a novel lightweight module that reduces training memory.","Using TIA, we free the humongous backbone from learning to adapt to the TAD task by only updating the parameters in TIA.","TIA also leads to better TAD representation by temporally aggregating context from adjacent frames throughout the backbone.","We evaluate our model across four representative datasets.","Owing to our efficient design, we are able to train end-to-end on VideoMAEv2-giant and achieve 75.4% mAP on THUMOS14, being the first end-to-end model to outperform the best feature-based methods."],"url":"http://arxiv.org/abs/2311.17241v1"}
{"created":"2023-11-28 21:15:24","title":"Quantifying the redundancy between prosody and text","abstract":"Prosody -- the suprasegmental component of speech, including pitch, loudness, and tempo -- carries critical aspects of meaning. However, the relationship between the information conveyed by prosody vs. by the words themselves remains poorly understood. We use large language models (LLMs) to estimate how much information is redundant between prosody and the words themselves. Using a large spoken corpus of English audiobooks, we extract prosodic features aligned to individual words and test how well they can be predicted from LLM embeddings, compared to non-contextual word embeddings. We find a high degree of redundancy between the information carried by the words and prosodic information across several prosodic features, including intensity, duration, pauses, and pitch contours. Furthermore, a word's prosodic information is redundant with both the word itself and the context preceding as well as following it. Still, we observe that prosodic features can not be fully predicted from text, suggesting that prosody carries information above and beyond the words. Along with this paper, we release a general-purpose data processing pipeline for quantifying the relationship between linguistic information and extra-linguistic features.","sentences":["Prosody -- the suprasegmental component of speech, including pitch, loudness, and tempo -- carries critical aspects of meaning.","However, the relationship between the information conveyed by prosody vs. by the words themselves remains poorly understood.","We use large language models (LLMs) to estimate how much information is redundant between prosody and the words themselves.","Using a large spoken corpus of English audiobooks, we extract prosodic features aligned to individual words and test how well they can be predicted from LLM embeddings, compared to non-contextual word embeddings.","We find a high degree of redundancy between the information carried by the words and prosodic information across several prosodic features, including intensity, duration, pauses, and pitch contours.","Furthermore, a word's prosodic information is redundant with both the word itself and the context preceding as well as following it.","Still, we observe that prosodic features can not be fully predicted from text, suggesting that prosody carries information above and beyond the words.","Along with this paper, we release a general-purpose data processing pipeline for quantifying the relationship between linguistic information and extra-linguistic features."],"url":"http://arxiv.org/abs/2311.17233v1"}
{"created":"2023-11-28 21:14:05","title":"ReWaRD: Retinal Waves for Pre-Training Artificial Neural Networks Mimicking Real Prenatal Development","abstract":"Computational models trained on a large amount of natural images are the state-of-the-art to study human vision - usually adult vision. Computational models of infant vision and its further development are gaining more and more attention in the community. In this work we aim at the very beginning of our visual experience - pre- and post-natal retinal waves which suggest to be a pre-training mechanism for the primate visual system at a very early stage of development. We see this approach as an instance of biologically plausible data driven inductive bias through pre-training. We built a computational model that mimics this development mechanism by pre-training different artificial convolutional neural networks with simulated retinal wave images. The resulting features of this biologically plausible pre-training closely match the V1 features of the primate visual system. We show that the performance gain by pre-training with retinal waves is similar to a state-of-the art pre-training pipeline. Our framework contains the retinal wave generator, as well as a training strategy, which can be a first step in a curriculum learning based training diet for various models of development. We release code, data and trained networks to build the basis for future work on visual development and based on a curriculum learning approach including prenatal development to support studies of innate vs. learned properties of the primate visual system. An additional benefit of our pre-trained networks for neuroscience or computer vision applications is the absence of biases inherited from datasets like ImageNet.","sentences":["Computational models trained on a large amount of natural images are the state-of-the-art to study human vision - usually adult vision.","Computational models of infant vision and its further development are gaining more and more attention in the community.","In this work we aim at the very beginning of our visual experience - pre- and post-natal retinal waves which suggest to be a pre-training mechanism for the primate visual system at a very early stage of development.","We see this approach as an instance of biologically plausible data driven inductive bias through pre-training.","We built a computational model that mimics this development mechanism by pre-training different artificial convolutional neural networks with simulated retinal wave images.","The resulting features of this biologically plausible pre-training closely match the V1 features of the primate visual system.","We show that the performance gain by pre-training with retinal waves is similar to a state-of-the art pre-training pipeline.","Our framework contains the retinal wave generator, as well as a training strategy, which can be a first step in a curriculum learning based training diet for various models of development.","We release code, data and trained networks to build the basis for future work on visual development and based on a curriculum learning approach including prenatal development to support studies of innate vs. learned properties of the primate visual system.","An additional benefit of our pre-trained networks for neuroscience or computer vision applications is the absence of biases inherited from datasets like ImageNet."],"url":"http://arxiv.org/abs/2311.17232v1"}
{"created":"2023-11-28 21:00:56","title":"Survey on AI Ethics: A Socio-technical Perspective","abstract":"The past decade has observed a great advancement in AI with deep learning-based models being deployed in diverse scenarios including safety-critical applications. As these AI systems become deeply embedded in our societal infrastructure, the repercussions of their decisions and actions have significant consequences, making the ethical implications of AI deployment highly relevant and important. The ethical concerns associated with AI are multifaceted, including challenging issues of fairness, privacy and data protection, responsibility and accountability, safety and robustness, transparency and explainability, and environmental impact. These principles together form the foundations of ethical AI considerations that concern every stakeholder in the AI system lifecycle. In light of the present ethical and future x-risk concerns, governments have shown increasing interest in establishing guidelines for the ethical deployment of AI. This work unifies the current and future ethical concerns of deploying AI into society. While we acknowledge and appreciate the technical surveys for each of the ethical principles concerned, in this paper, we aim to provide a comprehensive overview that not only addresses each principle from a technical point of view but also discusses them from a social perspective.","sentences":["The past decade has observed a great advancement in AI with deep learning-based models being deployed in diverse scenarios including safety-critical applications.","As these AI systems become deeply embedded in our societal infrastructure, the repercussions of their decisions and actions have significant consequences, making the ethical implications of AI deployment highly relevant and important.","The ethical concerns associated with AI are multifaceted, including challenging issues of fairness, privacy and data protection, responsibility and accountability, safety and robustness, transparency and explainability, and environmental impact.","These principles together form the foundations of ethical AI considerations that concern every stakeholder in the AI system lifecycle.","In light of the present ethical and future x-risk concerns, governments have shown increasing interest in establishing guidelines for the ethical deployment of AI.","This work unifies the current and future ethical concerns of deploying AI into society.","While we acknowledge and appreciate the technical surveys for each of the ethical principles concerned, in this paper, we aim to provide a comprehensive overview that not only addresses each principle from a technical point of view but also discusses them from a social perspective."],"url":"http://arxiv.org/abs/2311.17228v1"}
{"created":"2023-11-28 20:59:49","title":"War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars","abstract":"Can we avoid wars at the crossroads of history? This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history. In this research, we attempt to answer the question based on the recent advances of Artificial Intelligence (AI) and Large Language Models (LLMs). We propose \\textbf{WarAgent}, an LLM-powered multi-agent AI system, to simulate the participating countries, their decisions, and the consequences, in historical international conflicts, including the World War I (WWI), the World War II (WWII), and the Warring States Period (WSP) in Ancient China. By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge AI systems' abilities in studying complex collective human behaviors such as international conflicts under diverse settings. In these simulations, the emergent interactions among agents also offer a novel perspective for examining the triggers and conditions that lead to war. Our findings offer data-driven and AI-augmented insights that can redefine how we approach conflict resolution and peacekeeping strategies. The implications stretch beyond historical analysis, offering a blueprint for using AI to understand human history and possibly prevent future international conflicts. Code and data are available at \\url{https://github.com/agiresearch/WarAgent}.","sentences":["Can we avoid wars at the crossroads of history?","This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history.","In this research, we attempt to answer the question based on the recent advances of Artificial Intelligence (AI) and Large Language Models (LLMs).","We propose \\textbf{WarAgent}, an LLM-powered multi-agent AI system, to simulate the participating countries, their decisions, and the consequences, in historical international conflicts, including the World War I (WWI), the World War II (WWII), and the Warring States Period (WSP) in Ancient China.","By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge AI systems' abilities in studying complex collective human behaviors such as international conflicts under diverse settings.","In these simulations, the emergent interactions among agents also offer a novel perspective for examining the triggers and conditions that lead to war.","Our findings offer data-driven and AI-augmented insights that can redefine how we approach conflict resolution and peacekeeping strategies.","The implications stretch beyond historical analysis, offering a blueprint for using AI to understand human history and possibly prevent future international conflicts.","Code and data are available at \\url{https://github.com/agiresearch/WarAgent}."],"url":"http://arxiv.org/abs/2311.17227v1"}
{"created":"2023-11-28 20:54:53","title":"On the Complexity of the Median and Closest Permutation Problems","abstract":"Genome rearrangements are events where large blocks of DNA exchange places during evolution. The analysis of these events is a promising tool for understanding evolutionary genomics, providing data for phylogenetic reconstruction based on genome rearrangement measures. Many pairwise rearrangement distances have been proposed, based on finding the minimum number of rearrangement events to transform one genome into the other, using some predefined operation. When more than two genomes are considered, we have the more challenging problem of rearrangement-based phylogeny reconstruction. Given a set of genomes and a distance notion, there are at least two natural ways to define the \"target\" genome. On the one hand, finding a genome that minimizes the sum of the distances from this to any other, called the median genome. Finding a genome that minimizes the maximum distance to any other, called the closest genome. Considering genomes as permutations, some distance metrics have been extensively studied. We investigate median and closest problems on permutations over the metrics: breakpoint, swap, block-interchange, short-block-move, and transposition. In biological matters some values are usually small, such as the solution value d or the number k of input permutations. For each of these metrics and parameters d or k, we analyze the closest and the median problems from the viewpoint of parameterized complexity. We obtain the following results: NP-hardness for finding the median/closest permutation for some metrics, even for k = 3; Polynomial kernels for the problems of finding the median permutation of all studied metrics, considering the target distance d as parameter; NP-hardness result for finding the closest permutation by short-block-moves; FPT algorithms and infeasibility of polynomial kernels for finding the closest permutation for some metrics parameterized by the target distance d.","sentences":["Genome rearrangements are events where large blocks of DNA exchange places during evolution.","The analysis of these events is a promising tool for understanding evolutionary genomics, providing data for phylogenetic reconstruction based on genome rearrangement measures.","Many pairwise rearrangement distances have been proposed, based on finding the minimum number of rearrangement events to transform one genome into the other, using some predefined operation.","When more than two genomes are considered, we have the more challenging problem of rearrangement-based phylogeny reconstruction.","Given a set of genomes and a distance notion, there are at least two natural ways to define the \"target\" genome.","On the one hand, finding a genome that minimizes the sum of the distances from this to any other, called the median genome.","Finding a genome that minimizes the maximum distance to any other, called the closest genome.","Considering genomes as permutations, some distance metrics have been extensively studied.","We investigate median and closest problems on permutations over the metrics: breakpoint, swap, block-interchange, short-block-move, and transposition.","In biological matters some values are usually small, such as the solution value d or the number k of input permutations.","For each of these metrics and parameters d or k, we analyze the closest and the median problems from the viewpoint of parameterized complexity.","We obtain the following results: NP-hardness for finding the median/closest permutation for some metrics, even for k = 3; Polynomial kernels for the problems of finding the median permutation of all studied metrics, considering the target distance d as parameter; NP-hardness result for finding the closest permutation by short-block-moves; FPT algorithms and infeasibility of polynomial kernels for finding the closest permutation for some metrics parameterized by the target distance d."],"url":"http://arxiv.org/abs/2311.17224v1"}
{"created":"2023-11-28 20:42:30","title":"BIM: Block-Wise Self-Supervised Learning with Masked Image Modeling","abstract":"Like masked language modeling (MLM) in natural language processing, masked image modeling (MIM) aims to extract valuable insights from image patches to enhance the feature extraction capabilities of the underlying deep neural network (DNN). Contrasted with other training paradigms like supervised learning and unsupervised contrastive learning, masked image modeling (MIM) pretraining typically demands significant computational resources in order to manage large training data batches (e.g., 4096). The significant memory and computation requirements pose a considerable challenge to its broad adoption. To mitigate this, we introduce a novel learning framework, termed~\\textit{Block-Wise Masked Image Modeling} (BIM). This framework involves decomposing the MIM tasks into several sub-tasks with independent computation patterns, resulting in block-wise back-propagation operations instead of the traditional end-to-end approach. Our proposed BIM maintains superior performance compared to conventional MIM while greatly reducing peak memory consumption. Moreover, BIM naturally enables the concurrent training of numerous DNN backbones of varying depths. This leads to the creation of multiple trained DNN backbones, each tailored to different hardware platforms with distinct computing capabilities. This approach significantly reduces computational costs in comparison with training each DNN backbone individually. Our framework offers a promising solution for resource constrained training of MIM.","sentences":["Like masked language modeling (MLM) in natural language processing, masked image modeling (MIM) aims to extract valuable insights from image patches to enhance the feature extraction capabilities of the underlying deep neural network (DNN).","Contrasted with other training paradigms like supervised learning and unsupervised contrastive learning, masked image modeling (MIM) pretraining typically demands significant computational resources in order to manage large training data batches (e.g., 4096).","The significant memory and computation requirements pose a considerable challenge to its broad adoption.","To mitigate this, we introduce a novel learning framework, termed~\\textit{Block-Wise Masked Image Modeling} (BIM).","This framework involves decomposing the MIM tasks into several sub-tasks with independent computation patterns, resulting in block-wise back-propagation operations instead of the traditional end-to-end approach.","Our proposed BIM maintains superior performance compared to conventional MIM while greatly reducing peak memory consumption.","Moreover, BIM naturally enables the concurrent training of numerous DNN backbones of varying depths.","This leads to the creation of multiple trained DNN backbones, each tailored to different hardware platforms with distinct computing capabilities.","This approach significantly reduces computational costs in comparison with training each DNN backbone individually.","Our framework offers a promising solution for resource constrained training of MIM."],"url":"http://arxiv.org/abs/2311.17218v1"}
{"created":"2023-11-28 20:34:40","title":"General-Purpose vs. Domain-Adapted Large Language Models for Extraction of Data from Thoracic Radiology Reports","abstract":"Radiologists produce unstructured data that could be valuable for clinical care when consumed by information systems. However, variability in style limits usage. Study compares performance of system using domain-adapted language model (RadLing) and general-purpose large language model (GPT-4) in extracting common data elements (CDE) from thoracic radiology reports. Three radiologists annotated a retrospective dataset of 1300 thoracic reports (900 training, 400 test) and mapped to 21 pre-selected relevant CDEs. RadLing was used to generate embeddings for sentences and identify CDEs using cosine-similarity, which were mapped to values using light-weight mapper. GPT-4 system used OpenAI's general-purpose embeddings to identify relevant CDEs and used GPT-4 to map to values. The output CDE:value pairs were compared to the reference standard; an identical match was considered true positive. Precision (positive predictive value) was 96% (2700/2824) for RadLing and 99% (2034/2047) for GPT-4. Recall (sensitivity) was 94% (2700/2876) for RadLing and 70% (2034/2887) for GPT-4; the difference was statistically significant (P<.001). RadLing's domain-adapted embeddings were more sensitive in CDE identification (95% vs 71%) and its light-weight mapper had comparable precision in value assignment (95.4% vs 95.0%). RadLing system exhibited higher performance than GPT-4 system in extracting CDEs from radiology reports. RadLing system's domain-adapted embeddings outperform general-purpose embeddings from OpenAI in CDE identification and its light-weight value mapper achieves comparable precision to large GPT-4. RadLing system offers operational advantages including local deployment and reduced runtime costs. Domain-adapted RadLing system surpasses GPT-4 system in extracting common data elements from radiology reports, while providing benefits of local deployment and lower costs.","sentences":["Radiologists produce unstructured data that could be valuable for clinical care when consumed by information systems.","However, variability in style limits usage.","Study compares performance of system using domain-adapted language model (RadLing) and general-purpose large language model (GPT-4) in extracting common data elements (CDE) from thoracic radiology reports.","Three radiologists annotated a retrospective dataset of 1300 thoracic reports (900 training, 400 test) and mapped to 21 pre-selected relevant CDEs.","RadLing was used to generate embeddings for sentences and identify CDEs using cosine-similarity, which were mapped to values using light-weight mapper.","GPT-4 system used OpenAI's general-purpose embeddings to identify relevant CDEs and used GPT-4 to map to values.","The output CDE:value pairs were compared to the reference standard; an identical match was considered true positive.","Precision (positive predictive value) was 96% (2700/2824) for RadLing and 99% (2034/2047) for GPT-4.","Recall (sensitivity) was 94% (2700/2876) for RadLing and 70% (2034/2887) for GPT-4; the difference was statistically significant (P<.001).","RadLing's domain-adapted embeddings were more sensitive in CDE identification (95% vs 71%) and its light-weight mapper had comparable precision in value assignment (95.4% vs 95.0%).","RadLing system exhibited higher performance than GPT-4 system in extracting CDEs from radiology reports.","RadLing system's domain-adapted embeddings outperform general-purpose embeddings from OpenAI in CDE identification and its light-weight value mapper achieves comparable precision to large GPT-4.","RadLing system offers operational advantages including local deployment and reduced runtime costs.","Domain-adapted RadLing system surpasses GPT-4 system in extracting common data elements from radiology reports, while providing benefits of local deployment and lower costs."],"url":"http://arxiv.org/abs/2311.17213v1"}
{"created":"2023-11-28 19:34:40","title":"Minimax Exploiter: A Data Efficient Approach for Competitive Self-Play","abstract":"Recent advances in Competitive Self-Play (CSP) have achieved, or even surpassed, human level performance in complex game environments such as Dota 2 and StarCraft II using Distributed Multi-Agent Reinforcement Learning (MARL). One core component of these methods relies on creating a pool of learning agents -- consisting of the Main Agent, past versions of this agent, and Exploiter Agents -- where Exploiter Agents learn counter-strategies to the Main Agents. A key drawback of these approaches is the large computational cost and physical time that is required to train the system, making them impractical to deploy in highly iterative real-life settings such as video game productions. In this paper, we propose the Minimax Exploiter, a game theoretic approach to exploiting Main Agents that leverages knowledge of its opponents, leading to significant increases in data efficiency. We validate our approach in a diversity of settings, including simple turn based games, the arcade learning environment, and For Honor, a modern video game. The Minimax Exploiter consistently outperforms strong baselines, demonstrating improved stability and data efficiency, leading to a robust CSP-MARL method that is both flexible and easy to deploy.","sentences":["Recent advances in Competitive Self-Play (CSP) have achieved, or even surpassed, human level performance in complex game environments such as Dota 2 and StarCraft II using Distributed Multi-Agent Reinforcement Learning (MARL).","One core component of these methods relies on creating a pool of learning agents -- consisting of the Main Agent, past versions of this agent, and Exploiter Agents -- where Exploiter Agents learn counter-strategies to the Main Agents.","A key drawback of these approaches is the large computational cost and physical time that is required to train the system, making them impractical to deploy in highly iterative real-life settings such as video game productions.","In this paper, we propose the Minimax Exploiter, a game theoretic approach to exploiting Main Agents that leverages knowledge of its opponents, leading to significant increases in data efficiency.","We validate our approach in a diversity of settings, including simple turn based games, the arcade learning environment, and For Honor, a modern video game.","The Minimax Exploiter consistently outperforms strong baselines, demonstrating improved stability and data efficiency, leading to a robust CSP-MARL method that is both flexible and easy to deploy."],"url":"http://arxiv.org/abs/2311.17190v1"}
{"created":"2023-11-28 19:14:40","title":"SatCLIP: Global, General-Purpose Location Embeddings with Satellite Imagery","abstract":"Geographic location is essential for modeling tasks in fields ranging from ecology to epidemiology to the Earth system sciences. However, extracting relevant and meaningful characteristics of a location can be challenging, often entailing expensive data fusion or data distillation from global imagery datasets. To address this challenge, we introduce Satellite Contrastive Location-Image Pretraining (SatCLIP), a global, general-purpose geographic location encoder that learns an implicit representation of locations from openly available satellite imagery. Trained location encoders provide vector embeddings summarizing the characteristics of any given location for convenient usage in diverse downstream tasks. We show that SatCLIP embeddings, pretrained on globally sampled multi-spectral Sentinel-2 satellite data, can be used in various predictive tasks that depend on location information but not necessarily satellite imagery, including temperature prediction, animal recognition in imagery, and population density estimation. Across tasks, SatCLIP embeddings consistently outperform embeddings from existing pretrained location encoders, ranging from models trained on natural images to models trained on semantic context. SatCLIP embeddings also help to improve geographic generalization. This demonstrates the potential of general-purpose location encoders and opens the door to learning meaningful representations of our planet from the vast, varied, and largely untapped modalities of geospatial data.","sentences":["Geographic location is essential for modeling tasks in fields ranging from ecology to epidemiology to the Earth system sciences.","However, extracting relevant and meaningful characteristics of a location can be challenging, often entailing expensive data fusion or data distillation from global imagery datasets.","To address this challenge, we introduce Satellite Contrastive Location-Image Pretraining (SatCLIP), a global, general-purpose geographic location encoder that learns an implicit representation of locations from openly available satellite imagery.","Trained location encoders provide vector embeddings summarizing the characteristics of any given location for convenient usage in diverse downstream tasks.","We show that SatCLIP embeddings, pretrained on globally sampled multi-spectral Sentinel-2 satellite data, can be used in various predictive tasks that depend on location information but not necessarily satellite imagery, including temperature prediction, animal recognition in imagery, and population density estimation.","Across tasks, SatCLIP embeddings consistently outperform embeddings from existing pretrained location encoders, ranging from models trained on natural images to models trained on semantic context.","SatCLIP embeddings also help to improve geographic generalization.","This demonstrates the potential of general-purpose location encoders and opens the door to learning meaningful representations of our planet from the vast, varied, and largely untapped modalities of geospatial data."],"url":"http://arxiv.org/abs/2311.17179v1"}
{"created":"2023-11-28 19:11:01","title":"THInImg: Cross-modal Steganography for Presenting Talking Heads in Images","abstract":"Cross-modal Steganography is the practice of concealing secret signals in publicly available cover signals (distinct from the modality of the secret signals) unobtrusively. While previous approaches primarily concentrated on concealing a relatively small amount of information, we propose THInImg, which manages to hide lengthy audio data (and subsequently decode talking head video) inside an identity image by leveraging the properties of human face, which can be effectively utilized for covert communication, transmission and copyright protection. THInImg consists of two parts: the encoder and decoder. Inside the encoder-decoder pipeline, we introduce a novel architecture that substantially increase the capacity of hiding audio in images. Moreover, our framework can be extended to iteratively hide multiple audio clips into an identity image, offering multiple levels of control over permissions. We conduct extensive experiments to prove the effectiveness of our method, demonstrating that THInImg can present up to 80 seconds of high quality talking-head video (including audio) in an identity image with 160x160 resolution.","sentences":["Cross-modal Steganography is the practice of concealing secret signals in publicly available cover signals (distinct from the modality of the secret signals) unobtrusively.","While previous approaches primarily concentrated on concealing a relatively small amount of information, we propose THInImg, which manages to hide lengthy audio data (and subsequently decode talking head video) inside an identity image by leveraging the properties of human face, which can be effectively utilized for covert communication, transmission and copyright protection.","THInImg consists of two parts: the encoder and decoder.","Inside the encoder-decoder pipeline, we introduce a novel architecture that substantially increase the capacity of hiding audio in images.","Moreover, our framework can be extended to iteratively hide multiple audio clips into an identity image, offering multiple levels of control over permissions.","We conduct extensive experiments to prove the effectiveness of our method, demonstrating that THInImg can present up to 80 seconds of high quality talking-head video (including audio) in an identity image with 160x160 resolution."],"url":"http://arxiv.org/abs/2311.17177v1"}
{"created":"2023-11-28 19:07:30","title":"A personalized Uncertainty Quantification framework for patient survival models: estimating individual uncertainty of patients with metastatic brain tumors in the absence of ground truth","abstract":"TodevelopanovelUncertaintyQuantification (UQ) framework to estimate the uncertainty of patient survival models in the absence of ground truth, we developed and evaluated our approach based on a dataset of 1383 patients treated with stereotactic radiosurgery (SRS) for brain metastases between January 2015 and December 2020. Our motivating hypothesis is that a time-to-event prediction of a test patient on inference is more certain given a higher feature-space-similarity to patients in the training set. Therefore, the uncertainty for a particular patient-of-interest is represented by the concordance index between a patient similarity rank and a prediction similarity rank. Model uncertainty was defined as the increased percentage of the max uncertainty-constrained-AUC compared to the model AUC. We evaluated our method on multiple clinically-relevant endpoints, including time to intracranial progression (ICP), progression-free survival (PFS) after SRS, overall survival (OS), and time to ICP and/or death (ICPD), on a variety of both statistical and non-statistical models, including CoxPH, conditional survival forest (CSF), and neural multi-task linear regression (NMTLR). Our results show that all models had the lowest uncertainty on ICP (2.21%) and the highest uncertainty (17.28%) on ICPD. OS models demonstrated high variation in uncertainty performance, where NMTLR had the lowest uncertainty(1.96%)and CSF had the highest uncertainty (14.29%). In conclusion, our method can estimate the uncertainty of individual patient survival modeling results. As expected, our data empirically demonstrate that as model uncertainty measured via our technique increases, the similarity between a feature-space and its predicted outcome decreases.","sentences":["TodevelopanovelUncertaintyQuantification (UQ) framework to estimate the uncertainty of patient survival models in the absence of ground truth, we developed and evaluated our approach based on a dataset of 1383 patients treated with stereotactic radiosurgery (SRS) for brain metastases between January 2015 and December 2020.","Our motivating hypothesis is that a time-to-event prediction of a test patient on inference is more certain given a higher feature-space-similarity to patients in the training set.","Therefore, the uncertainty for a particular patient-of-interest is represented by the concordance index between a patient similarity rank and a prediction similarity rank.","Model uncertainty was defined as the increased percentage of the max uncertainty-constrained-AUC compared to the model AUC.","We evaluated our method on multiple clinically-relevant endpoints, including time to intracranial progression (ICP), progression-free survival (PFS) after SRS, overall survival (OS), and time to ICP and/or death (ICPD), on a variety of both statistical and non-statistical models, including CoxPH, conditional survival forest (CSF), and neural multi-task linear regression (NMTLR).","Our results show that all models had the lowest uncertainty on ICP (2.21%) and the highest uncertainty (17.28%) on ICPD.","OS models demonstrated high variation in uncertainty performance, where NMTLR had the lowest uncertainty(1.96%)and CSF had the highest uncertainty (14.29%).","In conclusion, our method can estimate the uncertainty of individual patient survival modeling results.","As expected, our data empirically demonstrate that as model uncertainty measured via our technique increases, the similarity between a feature-space and its predicted outcome decreases."],"url":"http://arxiv.org/abs/2311.17173v1"}
