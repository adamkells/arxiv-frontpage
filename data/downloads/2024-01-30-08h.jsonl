{"created":"2024-01-29 18:59:22","title":"Strategic Usage in a Multi-Learner Setting","abstract":"Real-world systems often involve some pool of users choosing between a set of services. With the increase in popularity of online learning algorithms, these services can now self-optimize, leveraging data collected on users to maximize some reward such as service quality. On the flipside, users may strategically choose which services to use in order to pursue their own reward functions, in the process wielding power over which services can see and use their data. Extensive prior research has been conducted on the effects of strategic users in single-service settings, with strategic behavior manifesting in the manipulation of observable features to achieve a desired classification; however, this can often be costly or unattainable for users and fails to capture the full behavior of multi-service dynamic systems. As such, we analyze a setting in which strategic users choose among several available services in order to pursue positive classifications, while services seek to minimize loss functions on their observations. We focus our analysis on realizable settings, and show that naive retraining can still lead to oscillation even if all users are observed at different times; however, if this retraining uses memory of past observations, convergent behavior can be guaranteed for certain loss function classes. We provide results obtained from synthetic and real-world data to empirically validate our theoretical findings.","sentences":["Real-world systems often involve some pool of users choosing between a set of services.","With the increase in popularity of online learning algorithms, these services can now self-optimize, leveraging data collected on users to maximize some reward such as service quality.","On the flipside, users may strategically choose which services to use in order to pursue their own reward functions, in the process wielding power over which services can see and use their data.","Extensive prior research has been conducted on the effects of strategic users in single-service settings, with strategic behavior manifesting in the manipulation of observable features to achieve a desired classification; however, this can often be costly or unattainable for users and fails to capture the full behavior of multi-service dynamic systems.","As such, we analyze a setting in which strategic users choose among several available services in order to pursue positive classifications, while services seek to minimize loss functions on their observations.","We focus our analysis on realizable settings, and show that naive retraining can still lead to oscillation even if all users are observed at different times; however, if this retraining uses memory of past observations, convergent behavior can be guaranteed for certain loss function classes.","We provide results obtained from synthetic and real-world data to empirically validate our theoretical findings."],"url":"http://arxiv.org/abs/2401.16422v1"}
{"created":"2024-01-29 18:55:29","title":"Endo-4DGS: Distilling Depth Ranking for Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting","abstract":"In the realm of robot-assisted minimally invasive surgery, dynamic scene reconstruction can significantly enhance downstream tasks and improve surgical outcomes. Neural Radiance Fields (NeRF)-based methods have recently risen to prominence for their exceptional ability to reconstruct scenes. Nonetheless, these methods are hampered by slow inference, prolonged training, and substantial computational demands. Additionally, some rely on stereo depth estimation, which is often infeasible due to the high costs and logistical challenges associated with stereo cameras. Moreover, the monocular reconstruction quality for deformable scenes is currently inadequate. To overcome these obstacles, we present Endo-4DGS, an innovative, real-time endoscopic dynamic reconstruction approach that utilizes 4D Gaussian Splatting (GS) and requires no ground truth depth data. This method extends 3D GS by incorporating a temporal component and leverages a lightweight MLP to capture temporal Gaussian deformations. This effectively facilitates the reconstruction of dynamic surgical scenes with variable conditions. We also integrate Depth-Anything to generate pseudo-depth maps from monocular views, enhancing the depth-guided reconstruction process. Our approach has been validated on two surgical datasets, where it has proven to render in real-time, compute efficiently, and reconstruct with remarkable accuracy. These results underline the vast potential of Endo-4DGS to improve surgical assistance.","sentences":["In the realm of robot-assisted minimally invasive surgery, dynamic scene reconstruction can significantly enhance downstream tasks and improve surgical outcomes.","Neural Radiance Fields (NeRF)-based methods have recently risen to prominence for their exceptional ability to reconstruct scenes.","Nonetheless, these methods are hampered by slow inference, prolonged training, and substantial computational demands.","Additionally, some rely on stereo depth estimation, which is often infeasible due to the high costs and logistical challenges associated with stereo cameras.","Moreover, the monocular reconstruction quality for deformable scenes is currently inadequate.","To overcome these obstacles, we present Endo-4DGS, an innovative, real-time endoscopic dynamic reconstruction approach that utilizes 4D Gaussian Splatting (GS) and requires no ground truth depth data.","This method extends 3D GS by incorporating a temporal component and leverages a lightweight MLP to capture temporal Gaussian deformations.","This effectively facilitates the reconstruction of dynamic surgical scenes with variable conditions.","We also integrate Depth-Anything to generate pseudo-depth maps from monocular views, enhancing the depth-guided reconstruction process.","Our approach has been validated on two surgical datasets, where it has proven to render in real-time, compute efficiently, and reconstruct with remarkable accuracy.","These results underline the vast potential of Endo-4DGS to improve surgical assistance."],"url":"http://arxiv.org/abs/2401.16416v1"}
{"created":"2024-01-29 18:41:21","title":"A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect","abstract":"Visual Anomaly Detection (VAD) endeavors to pinpoint deviations from the concept of normality in visual data, widely applied across diverse domains, e.g., industrial defect inspection, and medical lesion detection. This survey comprehensively examines recent advancements in VAD by identifying three primary challenges: 1) scarcity of training data, 2) diversity of visual modalities, and 3) complexity of hierarchical anomalies. Starting with a brief overview of the VAD background and its generic concept definitions, we progressively categorize, emphasize, and discuss the latest VAD progress from the perspective of sample number, data modality, and anomaly hierarchy. Through an in-depth analysis of the VAD field, we finally summarize future developments for VAD and conclude the key findings and contributions of this survey.","sentences":["Visual Anomaly Detection (VAD) endeavors to pinpoint deviations from the concept of normality in visual data, widely applied across diverse domains, e.g., industrial defect inspection, and medical lesion detection.","This survey comprehensively examines recent advancements in VAD by identifying three primary challenges: 1) scarcity of training data, 2) diversity of visual modalities, and 3) complexity of hierarchical anomalies.","Starting with a brief overview of the VAD background and its generic concept definitions, we progressively categorize, emphasize, and discuss the latest VAD progress from the perspective of sample number, data modality, and anomaly hierarchy.","Through an in-depth analysis of the VAD field, we finally summarize future developments for VAD and conclude the key findings and contributions of this survey."],"url":"http://arxiv.org/abs/2401.16402v1"}
{"created":"2024-01-29 18:34:36","title":"Amazon's 2023 Drought: Sentinel-1 Reveals Extreme Rio Negro River Contraction","abstract":"The Amazon, the world's largest rainforest, faces a severe historic drought. The Rio Negro River, one of the major Amazon River tributaries, reaches its lowest level in a century in October 2023. Here, we used a U-net deep learning model to map water surfaces in the Rio Negro River basin every 12 days in 2022 and 2023 using 10 m spatial resolution Sentinel-1 satellite radar images. The accuracy of the water surface model was high with an F1-score of 0.93. The 12 days mosaic time series of water surface was generated from the Sentinel-1 prediction. The water surface mask demonstrated relatively consistent agreement with the Global Surface Water (GSW) product from Joint Research Centre (F1-score: 0.708) and with the Brazilian Mapbiomas Water initiative (F1-score: 0.686). The main errors of the map were omission errors in flooded woodland, in flooded shrub and because of clouds. Rio Negro water surfaces reached their lowest level around the 25th of November 2023 and were reduced to 68.1\\% (9,559.9 km$^2$) of the maximum water surfaces observed in the period 2022-2023 (14,036.3 km$^2$). Synthetic Aperture Radar (SAR) data, in conjunction with deep learning techniques, can significantly improve near real-time mapping of water surface in tropical regions.","sentences":["The Amazon, the world's largest rainforest, faces a severe historic drought.","The Rio Negro River, one of the major Amazon River tributaries, reaches its lowest level in a century in October 2023.","Here, we used a U-net deep learning model to map water surfaces in the Rio Negro River basin every 12 days in 2022 and 2023 using 10 m spatial resolution Sentinel-1 satellite radar images.","The accuracy of the water surface model was high with an F1-score of 0.93.","The 12 days mosaic time series of water surface was generated from the Sentinel-1 prediction.","The water surface mask demonstrated relatively consistent agreement with the Global Surface Water (GSW) product from Joint Research Centre (F1-score: 0.708) and with the Brazilian Mapbiomas Water initiative (F1-score: 0.686).","The main errors of the map were omission errors in flooded woodland, in flooded shrub and because of clouds.","Rio Negro water surfaces reached their lowest level around the 25th of November 2023 and were reduced to 68.1\\% (9,559.9 km$^2$) of the maximum water surfaces observed in the period 2022-2023 (14,036.3 km$^2$).","Synthetic Aperture Radar (SAR) data, in conjunction with deep learning techniques, can significantly improve near real-time mapping of water surface in tropical regions."],"url":"http://arxiv.org/abs/2401.16393v1"}
{"created":"2024-01-29 18:28:28","title":"Green Adaptation of Real-Time Web Services for Industrial CPS within a Cloud Environment","abstract":"Managing energy efficiency under timing constraints is an interesting and big challenge. This work proposes an accurate power model in data centers for time-constrained servers in Cloud computing. This model, as opposed to previous approaches, does not only consider the workload assigned to the processing element, but also incorporates the need of considering the static power consumption and, even more interestingly, its dependency with temperature. The proposed model has been used in a multi-objective optimization environment in which the Dynamic Voltage and Frequency Scaling (DVFS) and workload assignment have been efficiently optimized.","sentences":["Managing energy efficiency under timing constraints is an interesting and big challenge.","This work proposes an accurate power model in data centers for time-constrained servers in Cloud computing.","This model, as opposed to previous approaches, does not only consider the workload assigned to the processing element, but also incorporates the need of considering the static power consumption and, even more interestingly, its dependency with temperature.","The proposed model has been used in a multi-objective optimization environment in which the Dynamic Voltage and Frequency Scaling (DVFS) and workload assignment have been efficiently optimized."],"url":"http://arxiv.org/abs/2401.16387v1"}
{"created":"2024-01-29 18:27:52","title":"Continual Learning with Pre-Trained Models: A Survey","abstract":"Nowadays, real-world applications often face streaming data, which requires the learning system to absorb new knowledge as data evolves. Continual Learning (CL) aims to achieve this goal and meanwhile overcome the catastrophic forgetting of former knowledge when learning new ones. Typical CL methods build the model from scratch to grow with incoming data. However, the advent of the pre-trained model (PTM) era has sparked immense research interest, particularly in leveraging PTMs' robust representational capabilities. This paper presents a comprehensive survey of the latest advancements in PTM-based CL. We categorize existing methodologies into three distinct groups, providing a comparative analysis of their similarities, differences, and respective advantages and disadvantages. Additionally, we offer an empirical study contrasting various state-of-the-art methods to highlight concerns regarding fairness in comparisons. The source code to reproduce these evaluations is available at: https://github.com/sun-hailong/LAMDA-PILOT","sentences":["Nowadays, real-world applications often face streaming data, which requires the learning system to absorb new knowledge as data evolves.","Continual Learning (CL) aims to achieve this goal and meanwhile overcome the catastrophic forgetting of former knowledge when learning new ones.","Typical CL methods build the model from scratch to grow with incoming data.","However, the advent of the pre-trained model (PTM) era has sparked immense research interest, particularly in leveraging PTMs' robust representational capabilities.","This paper presents a comprehensive survey of the latest advancements in PTM-based CL.","We categorize existing methodologies into three distinct groups, providing a comparative analysis of their similarities, differences, and respective advantages and disadvantages.","Additionally, we offer an empirical study contrasting various state-of-the-art methods to highlight concerns regarding fairness in comparisons.","The source code to reproduce these evaluations is available at: https://github.com/sun-hailong/LAMDA-PILOT"],"url":"http://arxiv.org/abs/2401.16386v1"}
{"created":"2024-01-29 18:19:08","title":"Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling","abstract":"Large language models are trained on massive scrapes of the web, which are often unstructured, noisy, and poorly phrased. Current scaling laws show that learning from such data requires an abundance of both compute and data, which grows with the size of the model being trained. This is infeasible both because of the large compute costs and duration associated with pre-training, and the impending scarcity of high-quality data on the web. In this work, we propose Web Rephrase Augmented Pre-training ($\\textbf{WRAP}$) that uses an off-the-shelf instruction-tuned model prompted to paraphrase documents on the web in specific styles such as \"like Wikipedia\" or in \"question-answer format\" to jointly pre-train LLMs on real and synthetic rephrases. First, we show that using WRAP on the C4 dataset, which is naturally noisy, speeds up pre-training by $\\sim3x$. At the same pre-training compute budget, it improves perplexity by more than 10% on average across different subsets of the Pile, and improves zero-shot question answer accuracy across 13 tasks by more than 2%. Second, we investigate the impact of the re-phrasing style on the performance of the model, offering insights into how the composition of the training data can impact the performance of LLMs in OOD settings. Our gains are attributed to the fact that re-phrased synthetic data has higher utility than just real data because it (i) incorporates style diversity that closely reflects downstream evaluation style, and (ii) has higher 'quality' than web-scraped data.","sentences":["Large language models are trained on massive scrapes of the web, which are often unstructured, noisy, and poorly phrased.","Current scaling laws show that learning from such data requires an abundance of both compute and data, which grows with the size of the model being trained.","This is infeasible both because of the large compute costs and duration associated with pre-training, and the impending scarcity of high-quality data on the web.","In this work, we propose Web Rephrase Augmented Pre-training ($\\textbf{WRAP}$) that uses an off-the-shelf instruction-tuned model prompted to paraphrase documents on the web in specific styles such as \"like Wikipedia\" or in \"question-answer format\" to jointly pre-train LLMs on real and synthetic rephrases.","First, we show that using WRAP on the C4 dataset, which is naturally noisy, speeds up pre-training by $\\sim3x$.","At the same pre-training compute budget, it improves perplexity by more than 10% on average across different subsets of the Pile, and improves zero-shot question answer accuracy across 13 tasks by more than 2%.","Second, we investigate the impact of the re-phrasing style on the performance of the model, offering insights into how the composition of the training data can impact the performance of LLMs in OOD settings.","Our gains are attributed to the fact that re-phrased synthetic data has higher utility than just real data because it (i) incorporates style diversity that closely reflects downstream evaluation style, and (ii) has higher 'quality' than web-scraped data."],"url":"http://arxiv.org/abs/2401.16380v1"}
{"created":"2024-01-29 18:00:50","title":"Reference Coverage Analysis of OpenAlex compared to Web of Science and Scopus","abstract":"OpenAlex is a promising open source of scholarly metadata, and competitor to the established proprietary sources, the Web of Science and Scopus. As OpenAlex provides its data freely and openly, it permits researchers to perform bibliometric studies that can be reproduced in the community without licensing barriers. However, as OpenAlex is a rapidly evolving source and the data contained within is expanding and also quickly changing, the question naturally arises as to the trustworthiness of its data. In this empirical paper, we will study the reference and metadata coverage within each database and compare them with each other to help address this open question in bibliometrics. In our large-scale study, we demonstrate that, when restricted to a cleaned dataset of 16,788,282 recent publications shared by all three databases, OpenAlex has average reference numbers comparable to both Web of Science and Scopus. We also demonstrate that the comparison of other core metadata covered by OpenAlex shows mixed results, with OpenAlex capturing more ORCID identifiers, fewer abstracts and a similar number of Open Access information per article when compared to both Web of Science and Scopus.","sentences":["OpenAlex is a promising open source of scholarly metadata, and competitor to the established proprietary sources, the Web of Science and Scopus.","As OpenAlex provides its data freely and openly, it permits researchers to perform bibliometric studies that can be reproduced in the community without licensing barriers.","However, as OpenAlex is a rapidly evolving source and the data contained within is expanding and also quickly changing, the question naturally arises as to the trustworthiness of its data.","In this empirical paper, we will study the reference and metadata coverage within each database and compare them with each other to help address this open question in bibliometrics.","In our large-scale study, we demonstrate that, when restricted to a cleaned dataset of 16,788,282 recent publications shared by all three databases, OpenAlex has average reference numbers comparable to both Web of Science and Scopus.","We also demonstrate that the comparison of other core metadata covered by OpenAlex shows mixed results, with OpenAlex capturing more ORCID identifiers, fewer abstracts and a similar number of Open Access information per article when compared to both Web of Science and Scopus."],"url":"http://arxiv.org/abs/2401.16359v1"}
{"created":"2024-01-29 17:56:15","title":"FedFair^3: Unlocking Threefold Fairness in Federated Learning","abstract":"Federated Learning (FL) is an emerging paradigm in machine learning without exposing clients' raw data. In practical scenarios with numerous clients, encouraging fair and efficient client participation in federated learning is of utmost importance, which is also challenging given the heterogeneity in data distribution and device properties. Existing works have proposed different client-selection methods that consider fairness; however, they fail to select clients with high utilities while simultaneously achieving fair accuracy levels. In this paper, we propose a fair client-selection approach that unlocks threefold fairness in federated learning. In addition to having a fair client-selection strategy, we enforce an equitable number of rounds for client participation and ensure a fair accuracy distribution over the clients. The experimental results demonstrate that FedFair^3, in comparison to the state-of-the-art baselines, achieves 18.15% less accuracy variance on the IID data and 54.78% on the non-IID data, without decreasing the global accuracy. Furthermore, it shows 24.36% less wall-clock training time on average.","sentences":["Federated Learning (FL) is an emerging paradigm in machine learning without exposing clients' raw data.","In practical scenarios with numerous clients, encouraging fair and efficient client participation in federated learning is of utmost importance, which is also challenging given the heterogeneity in data distribution and device properties.","Existing works have proposed different client-selection methods that consider fairness; however, they fail to select clients with high utilities while simultaneously achieving fair accuracy levels.","In this paper, we propose a fair client-selection approach that unlocks threefold fairness in federated learning.","In addition to having a fair client-selection strategy, we enforce an equitable number of rounds for client participation and ensure a fair accuracy distribution over the clients.","The experimental results demonstrate that FedFair^3, in comparison to the state-of-the-art baselines, achieves 18.15% less accuracy variance on the IID data and 54.78% on the non-IID data, without decreasing the global accuracy.","Furthermore, it shows 24.36% less wall-clock training time on average."],"url":"http://arxiv.org/abs/2401.16350v1"}
{"created":"2024-01-29 17:55:18","title":"ConFit: Improving Resume-Job Matching using Data Augmentation and Contrastive Learning","abstract":"A reliable resume-job matching system helps a company find suitable candidates from a pool of resumes, and helps a job seeker find relevant jobs from a list of job posts. However, since job seekers apply only to a few jobs, interaction records in resume-job datasets are sparse. Different from many prior work that use complex modeling techniques, we tackle this sparsity problem using data augmentations and a simple contrastive learning approach. ConFit first creates an augmented resume-job dataset by paraphrasing specific sections in a resume or a job post. Then, ConFit uses contrastive learning to further increase training samples from $B$ pairs per batch to $O(B^2)$ per batch. We evaluate ConFit on two real-world datasets and find it outperforms prior methods (including BM25 and OpenAI text-ada-002) by up to 19% and 31% absolute in nDCG@10 for ranking jobs and ranking resumes, respectively.","sentences":["A reliable resume-job matching system helps a company find suitable candidates from a pool of resumes, and helps a job seeker find relevant jobs from a list of job posts.","However, since job seekers apply only to a few jobs, interaction records in resume-job datasets are sparse.","Different from many prior work that use complex modeling techniques, we tackle this sparsity problem using data augmentations and a simple contrastive learning approach.","ConFit first creates an augmented resume-job dataset by paraphrasing specific sections in a resume or a job post.","Then, ConFit uses contrastive learning to further increase training samples from $B$ pairs per batch to $O(B^2)$ per batch.","We evaluate ConFit on two real-world datasets and find it outperforms prior methods (including BM25 and OpenAI text-ada-002) by up to 19% and 31% absolute in nDCG@10 for ranking jobs and ranking resumes, respectively."],"url":"http://arxiv.org/abs/2401.16349v1"}
{"created":"2024-01-29 17:48:12","title":"On Achievable Rates for the Shotgun Sequencing Channel with Erasures","abstract":"In the shotgun sequencing channel, the input sequence (possibly, a long DNA sequence composed of nucleotide bases) is read into multiple fragments (called `reads') of much shorter lengths. In the context of DNA data storage, the capacity of this channel was identified in a recent work, assuming that the reads themselves are noiseless substrings of the original sequence. Modern shotgun sequencers however also output quality scores for each base read, indicating the confidence in its identification. Bases with low quality scores can be considered to be erased. Motivated by this, we consider the shotgun sequencing channel with erasures, where each symbol in any read can be independently erased with some probability $\\delta$. We identify achievable rates for this channel, using a random code construction and a decoder that uses typicality-like arguments to merge the reads.","sentences":["In the shotgun sequencing channel, the input sequence (possibly, a long DNA sequence composed of nucleotide bases) is read into multiple fragments (called `reads') of much shorter lengths.","In the context of DNA data storage, the capacity of this channel was identified in a recent work, assuming that the reads themselves are noiseless substrings of the original sequence.","Modern shotgun sequencers however also output quality scores for each base read, indicating the confidence in its identification.","Bases with low quality scores can be considered to be erased.","Motivated by this, we consider the shotgun sequencing channel with erasures, where each symbol in any read can be independently erased with some probability $\\delta$.","We identify achievable rates for this channel, using a random code construction and a decoder that uses typicality-like arguments to merge the reads."],"url":"http://arxiv.org/abs/2401.16342v1"}
{"created":"2024-01-29 17:45:23","title":"SAT-CEP-monitor: An air quality monitoring software architecture combining complex event processing with satellite remote sensing","abstract":"Air pollution is a major problem today that causes serious damage to human health. Urban areas are the most affected by the degradation of air quality caused by anthropogenic gas emissions. Although there are multiple proposals for air quality monitoring, in most cases, two limitations are imposed: the impossibility of processing data in Near Real-Time (NRT) for remote sensing approaches and the impossibility of reaching areas of limited accessibility or low network coverage for ground data approaches. We propose a software architecture that efficiently combines complex event processing with remote sensing data from various satellite sensors to monitor air quality in NRT, giving support to decision-makers. We illustrate the proposed solution by calculating the air quality levels for several areas of Morocco and Spain, extracting and processing satellite information in NRT. This study also validates the air quality measured by ground stations and satellite sensor data.","sentences":["Air pollution is a major problem today that causes serious damage to human health.","Urban areas are the most affected by the degradation of air quality caused by anthropogenic gas emissions.","Although there are multiple proposals for air quality monitoring, in most cases, two limitations are imposed: the impossibility of processing data in Near Real-Time (NRT) for remote sensing approaches and the impossibility of reaching areas of limited accessibility or low network coverage for ground data approaches.","We propose a software architecture that efficiently combines complex event processing with remote sensing data from various satellite sensors to monitor air quality in NRT, giving support to decision-makers.","We illustrate the proposed solution by calculating the air quality levels for several areas of Morocco and Spain, extracting and processing satellite information in NRT.","This study also validates the air quality measured by ground stations and satellite sensor data."],"url":"http://arxiv.org/abs/2401.16339v1"}
{"created":"2024-01-29 17:43:42","title":"Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF","abstract":"Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that aligns language models closely with human-centric values. The initial phase of RLHF involves learning human values using a reward model from ranking data. It is observed that the performance of the reward model degrades after one epoch of training, and optimizing too much against the learned reward model eventually hinders the true objective. This paper delves into these issues, leveraging the theoretical insights to design improved reward learning algorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that during each training epoch, we not only update the model with the data, but also update the date using the model, replacing hard labels with soft labels. Our empirical findings highlight the superior performance of this approach over the traditional methods.","sentences":["Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that aligns language models closely with human-centric values.","The initial phase of RLHF involves learning human values using a reward model from ranking data.","It is observed that the performance of the reward model degrades after one epoch of training, and optimizing too much against the learned reward model eventually hinders the true objective.","This paper delves into these issues, leveraging the theoretical insights to design improved reward learning algorithm termed 'Iterative Data Smoothing' (IDS).","The core idea is that during each training epoch, we not only update the model with the data, but also update the date using the model, replacing hard labels with soft labels.","Our empirical findings highlight the superior performance of this approach over the traditional methods."],"url":"http://arxiv.org/abs/2401.16335v1"}
{"created":"2024-01-29 17:32:22","title":"PICL: Physics Informed Contrastive Learning for Partial Differential Equations","abstract":"Neural operators have recently grown in popularity as Partial Differential Equation (PDEs) surrogate models. Learning solution functionals, rather than functions, has proven to be a powerful approach to calculate fast, accurate solutions to complex PDEs. While much work has been done evaluating neural operator performance on a wide variety of surrogate modeling tasks, these works normally evaluate performance on a single equation at a time. In this work, we develop a novel contrastive pretraining framework utilizing Generalized Contrastive Loss that improves neural operator generalization across multiple governing equations simultaneously. Governing equation coefficients are used to measure ground-truth similarity between systems. A combination of physics-informed system evolution and latent-space model output are anchored to input data and used in our distance function. We find that physics-informed contrastive pretraining improves both accuracy and generalization for the Fourier Neural Operator in fixed-future task, with comparable performance on the autoregressive rollout, and superresolution tasks for the 1D Heat, Burgers', and linear advection equations.","sentences":["Neural operators have recently grown in popularity as Partial Differential Equation (PDEs) surrogate models.","Learning solution functionals, rather than functions, has proven to be a powerful approach to calculate fast, accurate solutions to complex PDEs.","While much work has been done evaluating neural operator performance on a wide variety of surrogate modeling tasks, these works normally evaluate performance on a single equation at a time.","In this work, we develop a novel contrastive pretraining framework utilizing Generalized Contrastive Loss that improves neural operator generalization across multiple governing equations simultaneously.","Governing equation coefficients are used to measure ground-truth similarity between systems.","A combination of physics-informed system evolution and latent-space model output are anchored to input data and used in our distance function.","We find that physics-informed contrastive pretraining improves both accuracy and generalization for the Fourier Neural Operator in fixed-future task, with comparable performance on the autoregressive rollout, and superresolution tasks for the 1D Heat, Burgers', and linear advection equations."],"url":"http://arxiv.org/abs/2401.16327v1"}
{"created":"2024-01-29 17:08:57","title":"Momentary Stressor Logging and Reflective Visualizations: Implications for Stress Management with Wearables","abstract":"Commercial wearables from Fitbit, Garmin, and Whoop have recently introduced real-time notifications based on detecting changes in physiological responses indicating potential stress. In this paper, we investigate how these new capabilities can be leveraged to improve stress management. We developed a smartwatch app, a smartphone app, and a cloud service, and conducted a 100-day field study with 122 participants who received prompts triggered by physiological responses several times a day. They were asked whether they were stressed, and if so, to log the most likely stressor. Each week, participants received new visualizations of their data to self-reflect on patterns and trends. Participants reported better awareness of their stressors, and self-initiating fourteen kinds of behavioral changes to reduce stress in their daily lives. Repeated self-reports over 14 weeks showed reductions in both stress intensity (in 26,521 momentary ratings) and stress frequency (in 1,057 weekly surveys).","sentences":["Commercial wearables from Fitbit, Garmin, and Whoop have recently introduced real-time notifications based on detecting changes in physiological responses indicating potential stress.","In this paper, we investigate how these new capabilities can be leveraged to improve stress management.","We developed a smartwatch app, a smartphone app, and a cloud service, and conducted a 100-day field study with 122 participants who received prompts triggered by physiological responses several times a day.","They were asked whether they were stressed, and if so, to log the most likely stressor.","Each week, participants received new visualizations of their data to self-reflect on patterns and trends.","Participants reported better awareness of their stressors, and self-initiating fourteen kinds of behavioral changes to reduce stress in their daily lives.","Repeated self-reports over 14 weeks showed reductions in both stress intensity (in 26,521 momentary ratings) and stress frequency (in 1,057 weekly surveys)."],"url":"http://arxiv.org/abs/2401.16307v1"}
{"created":"2024-01-29 17:04:32","title":"Regressing Transformers for Data-efficient Visual Place Recognition","abstract":"Visual place recognition is a critical task in computer vision, especially for localization and navigation systems. Existing methods often rely on contrastive learning: image descriptors are trained to have small distance for similar images and larger distance for dissimilar ones in a latent space. However, this approach struggles to ensure accurate distance-based image similarity representation, particularly when training with binary pairwise labels, and complex re-ranking strategies are required. This work introduces a fresh perspective by framing place recognition as a regression problem, using camera field-of-view overlap as similarity ground truth for learning. By optimizing image descriptors to align directly with graded similarity labels, this approach enhances ranking capabilities without expensive re-ranking, offering data-efficient training and strong generalization across several benchmark datasets.","sentences":["Visual place recognition is a critical task in computer vision, especially for localization and navigation systems.","Existing methods often rely on contrastive learning: image descriptors are trained to have small distance for similar images and larger distance for dissimilar ones in a latent space.","However, this approach struggles to ensure accurate distance-based image similarity representation, particularly when training with binary pairwise labels, and complex re-ranking strategies are required.","This work introduces a fresh perspective by framing place recognition as a regression problem, using camera field-of-view overlap as similarity ground truth for learning.","By optimizing image descriptors to align directly with graded similarity labels, this approach enhances ranking capabilities without expensive re-ranking, offering data-efficient training and strong generalization across several benchmark datasets."],"url":"http://arxiv.org/abs/2401.16304v1"}
{"created":"2024-01-29 17:03:28","title":"Quantum-safe Encryption: A New Method to Reduce Complexity and/or Improve Security Level","abstract":"This work presents some novel techniques to enhance an encryption scheme motivated by classical McEliece cryptosystem. Contributions include: (1) using masking matrices to hide sensitive data, (2) allowing both legitimate parties to incorporate randomness in the public key without sharing any additional public information, (3) using concatenation of a repetition code for error correction, permitting key recovery with a negligible decoding complexity, (4) making attacks more difficult by increasing the complexity in verifying a given key candidate has resulted in the actual key, (5) introducing memory in the error sequence such that: (i) error vector is composed of a random number of erroneous bits, (ii) errors can be all corrected when used in conjunction with concatenation of a repetition code of length 3. Proposed techniques allow generating significantly larger keys, at the same time, with a much lower complexity, as compared to known post-quantum key generation techniques relying on randomization.","sentences":["This work presents some novel techniques to enhance an encryption scheme motivated by classical McEliece cryptosystem.","Contributions include: (1) using masking matrices to hide sensitive data, (2) allowing both legitimate parties to incorporate randomness in the public key without sharing any additional public information, (3) using concatenation of a repetition code for error correction, permitting key recovery with a negligible decoding complexity, (4) making attacks more difficult by increasing the complexity in verifying a given key candidate has resulted in the actual key, (5) introducing memory in the error sequence such that: (i) error vector is composed of a random number of erroneous bits, (ii) errors can be all corrected when used in conjunction with concatenation of a repetition code of length 3.","Proposed techniques allow generating significantly larger keys, at the same time, with a much lower complexity, as compared to known post-quantum key generation techniques relying on randomization."],"url":"http://arxiv.org/abs/2401.16302v1"}
{"created":"2024-01-29 17:02:14","title":"Scalable Factor Graph-Based Heterogeneous Bayesian DDF for Dynamic Systems","abstract":"Heterogeneous Bayesian decentralized data fusion captures the set of problems in which two robots must combine two probability density functions over non-equal, but overlapping sets of random variables. In the context of multi-robot dynamic systems, this enables robots to take a \"divide and conquer\" approach to reason and share data over complementary tasks instead of over the full joint state space. For example, in a target tracking application, this allows robots to track different subsets of targets and share data on only common targets. This paper presents a framework by which robots can each use a local factor graph to represent relevant partitions of a complex global joint probability distribution, thus allowing them to avoid reasoning over the entirety of a more complex model and saving communication as well as computation costs. From a theoretical point of view, this paper makes contributions by casting the heterogeneous decentralized fusion problem in terms of a factor graph, analyzing the challenges that arise due to dynamic filtering, and then developing a new conservative filtering algorithm that ensures statistical correctness. From a practical point of view, we show how this framework can be used to represent different multi-robot applications and then test it with simulations and hardware experiments to validate and demonstrate its statistical conservativeness, applicability, and robustness to real-world challenges.","sentences":["Heterogeneous Bayesian decentralized data fusion captures the set of problems in which two robots must combine two probability density functions over non-equal, but overlapping sets of random variables.","In the context of multi-robot dynamic systems, this enables robots to take a \"divide and conquer\" approach to reason and share data over complementary tasks instead of over the full joint state space.","For example, in a target tracking application, this allows robots to track different subsets of targets and share data on only common targets.","This paper presents a framework by which robots can each use a local factor graph to represent relevant partitions of a complex global joint probability distribution, thus allowing them to avoid reasoning over the entirety of a more complex model and saving communication as well as computation costs.","From a theoretical point of view, this paper makes contributions by casting the heterogeneous decentralized fusion problem in terms of a factor graph, analyzing the challenges that arise due to dynamic filtering, and then developing a new conservative filtering algorithm that ensures statistical correctness.","From a practical point of view, we show how this framework can be used to represent different multi-robot applications and then test it with simulations and hardware experiments to validate and demonstrate its statistical conservativeness, applicability, and robustness to real-world challenges."],"url":"http://arxiv.org/abs/2401.16301v1"}
{"created":"2024-01-29 16:59:39","title":"Breaking the Barrier: Selective Uncertainty-based Active Learning for Medical Image Segmentation","abstract":"Active learning (AL) has found wide applications in medical image segmentation, aiming to alleviate the annotation workload and enhance performance. Conventional uncertainty-based AL methods, such as entropy and Bayesian, often rely on an aggregate of all pixel-level metrics. However, in imbalanced settings, these methods tend to neglect the significance of target regions, eg., lesions, and tumors. Moreover, uncertainty-based selection introduces redundancy. These factors lead to unsatisfactory performance, and in many cases, even underperform random sampling. To solve this problem, we introduce a novel approach called the Selective Uncertainty-based AL, avoiding the conventional practice of summing up the metrics of all pixels. Through a filtering process, our strategy prioritizes pixels within target areas and those near decision boundaries. This resolves the aforementioned disregard for target areas and redundancy. Our method showed substantial improvements across five different uncertainty-based methods and two distinct datasets, utilizing fewer labeled data to reach the supervised baseline and consistently achieving the highest overall performance. Our code is available at https://github.com/HelenMa9998/Selective\\_Uncertainty\\_AL.","sentences":["Active learning (AL) has found wide applications in medical image segmentation, aiming to alleviate the annotation workload and enhance performance.","Conventional uncertainty-based AL methods, such as entropy and Bayesian, often rely on an aggregate of all pixel-level metrics.","However, in imbalanced settings, these methods tend to neglect the significance of target regions, eg., lesions, and tumors.","Moreover, uncertainty-based selection introduces redundancy.","These factors lead to unsatisfactory performance, and in many cases, even underperform random sampling.","To solve this problem, we introduce a novel approach called the Selective Uncertainty-based AL, avoiding the conventional practice of summing up the metrics of all pixels.","Through a filtering process, our strategy prioritizes pixels within target areas and those near decision boundaries.","This resolves the aforementioned disregard for target areas and redundancy.","Our method showed substantial improvements across five different uncertainty-based methods and two distinct datasets, utilizing fewer labeled data to reach the supervised baseline and consistently achieving the highest overall performance.","Our code is available at https://github.com/HelenMa9998/Selective\\_Uncertainty\\_AL."],"url":"http://arxiv.org/abs/2401.16298v1"}
{"created":"2024-01-29 16:56:21","title":"On the Complexity of Establishing Hereditary Graph Properties via Vertex Splitting","abstract":"Vertex splitting is a graph operation that replaces a vertex $v$ with two nonadjacent new vertices and makes each neighbor of $v$ adjacent with one or both of the introduced vertices. Vertex splitting has been used in contexts from circuit design to statistical analysis. In this work, we explore the computational complexity of achieving a given graph property $\\Pi$ by a limited number of vertex splits, formalized as the problem $\\Pi$ Vertex Splitting ($\\Pi$-VS). We focus on hereditary graph properties and contribute four groups of results: First, we classify the classical complexity of $\\Pi$-VS for graph properties characterized by forbidden subgraphs of size at most 3. Second, we provide a framework that allows to show NP-completeness whenever one can construct a combination of a forbidden subgraph and prescribed vertex splits that satisfy certain conditions. Leveraging this framework we show NP-completeness when $\\Pi$ is characterized by forbidden subgraphs that are sufficiently well connected. In particular, we show that $F$-Free-VS is NP-complete for each biconnected graph $F$. Third, we study infinite families of forbidden subgraphs, obtaining NP-hardness for Bipartite-VS and Perfect-VS. Finally, we touch upon the parameterized complexity of $\\Pi$-VS with respect to the number of allowed splits, showing para-NP-hardness for $K_3$-Free-VS and deriving an XP-algorithm when each vertex is only allowed to be split at most once.","sentences":["Vertex splitting is a graph operation that replaces a vertex $v$ with two nonadjacent new vertices and makes each neighbor of $v$ adjacent with one or both of the introduced vertices.","Vertex splitting has been used in contexts from circuit design to statistical analysis.","In this work, we explore the computational complexity of achieving a given graph property $\\Pi$ by a limited number of vertex splits, formalized as the problem $\\Pi$ Vertex Splitting ($\\Pi$-VS).","We focus on hereditary graph properties and contribute four groups of results:","First, we classify the classical complexity of $\\Pi$-VS for graph properties characterized by forbidden subgraphs of size at most 3.","Second, we provide a framework that allows to show NP-completeness whenever one can construct a combination of a forbidden subgraph and prescribed vertex splits that satisfy certain conditions.","Leveraging this framework we show NP-completeness when $\\Pi$ is characterized by forbidden subgraphs that are sufficiently well connected.","In particular, we show that $F$-Free-VS is NP-complete for each biconnected graph $F$. Third, we study infinite families of forbidden subgraphs, obtaining NP-hardness for Bipartite-VS and Perfect-VS.","Finally, we touch upon the parameterized complexity of $\\Pi$-VS with respect to the number of allowed splits, showing para-NP-hardness for $K_3$-Free-VS and deriving an XP-algorithm when each vertex is only allowed to be split at most once."],"url":"http://arxiv.org/abs/2401.16296v1"}
{"created":"2024-01-29 16:50:32","title":"MachineLearnAthon: An Action-Oriented Machine Learning Didactic Concept","abstract":"Machine Learning (ML) techniques are encountered nowadays across disciplines, from social sciences, through natural sciences to engineering. The broad application of ML and the accelerated pace of its evolution lead to an increasing need for dedicated teaching concepts aimed at making the application of this technology more reliable and responsible. However, teaching ML is a daunting task. Aside from the methodological complexity of ML algorithms, both with respect to theory and implementation, the interdisciplinary and empirical nature of the field need to be taken into consideration. This paper introduces the MachineLearnAthon format, an innovative didactic concept designed to be inclusive for students of different disciplines with heterogeneous levels of mathematics, programming and domain expertise. At the heart of the concept lie ML challenges, which make use of industrial data sets to solve real-world problems. These cover the entire ML pipeline, promoting data literacy and practical skills, from data preparation, through deployment, to evaluation.","sentences":["Machine Learning (ML) techniques are encountered nowadays across disciplines, from social sciences, through natural sciences to engineering.","The broad application of ML and the accelerated pace of its evolution lead to an increasing need for dedicated teaching concepts aimed at making the application of this technology more reliable and responsible.","However, teaching ML is a daunting task.","Aside from the methodological complexity of ML algorithms, both with respect to theory and implementation, the interdisciplinary and empirical nature of the field need to be taken into consideration.","This paper introduces the MachineLearnAthon format, an innovative didactic concept designed to be inclusive for students of different disciplines with heterogeneous levels of mathematics, programming and domain expertise.","At the heart of the concept lie ML challenges, which make use of industrial data sets to solve real-world problems.","These cover the entire ML pipeline, promoting data literacy and practical skills, from data preparation, through deployment, to evaluation."],"url":"http://arxiv.org/abs/2401.16291v1"}
{"created":"2024-01-29 16:42:34","title":"Capturing Pertinent Symbolic Features for Enhanced Content-Based Misinformation Detection","abstract":"Preventing the spread of misinformation is challenging. The detection of misleading content presents a significant hurdle due to its extreme linguistic and domain variability. Content-based models have managed to identify deceptive language by learning representations from textual data such as social media posts and web articles. However, aggregating representative samples of this heterogeneous phenomenon and implementing effective real-world applications is still elusive. Based on analytical work on the language of misinformation, this paper analyzes the linguistic attributes that characterize this phenomenon and how representative of such features some of the most popular misinformation datasets are. We demonstrate that the appropriate use of pertinent symbolic knowledge in combination with neural language models is helpful in detecting misleading content. Our results achieve state-of-the-art performance in misinformation datasets across the board, showing that our approach offers a valid and robust alternative to multi-task transfer learning without requiring any additional training data. Furthermore, our results show evidence that structured knowledge can provide the extra boost required to address a complex and unpredictable real-world problem like misinformation detection, not only in terms of accuracy but also time efficiency and resource utilization.","sentences":["Preventing the spread of misinformation is challenging.","The detection of misleading content presents a significant hurdle due to its extreme linguistic and domain variability.","Content-based models have managed to identify deceptive language by learning representations from textual data such as social media posts and web articles.","However, aggregating representative samples of this heterogeneous phenomenon and implementing effective real-world applications is still elusive.","Based on analytical work on the language of misinformation, this paper analyzes the linguistic attributes that characterize this phenomenon and how representative of such features some of the most popular misinformation datasets are.","We demonstrate that the appropriate use of pertinent symbolic knowledge in combination with neural language models is helpful in detecting misleading content.","Our results achieve state-of-the-art performance in misinformation datasets across the board, showing that our approach offers a valid and robust alternative to multi-task transfer learning without requiring any additional training data.","Furthermore, our results show evidence that structured knowledge can provide the extra boost required to address a complex and unpredictable real-world problem like misinformation detection, not only in terms of accuracy but also time efficiency and resource utilization."],"url":"http://arxiv.org/abs/2401.16285v1"}
{"created":"2024-01-29 16:39:39","title":"MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim Verification","abstract":"Claim verification is an essential step in the automated fact-checking pipeline which assesses the veracity of a claim against a piece of evidence. In this work, we explore the potential of few-shot claim verification, where only very limited data is available for supervision. We propose MAPLE (Micro Analysis of Pairwise Language Evolution), a pioneering approach that explores the alignment between a claim and its evidence with a small seq2seq model and a novel semantic measure. Its innovative utilization of micro language evolution path leverages unlabelled pairwise data to facilitate claim verification while imposing low demand on data annotations and computing resources. MAPLE demonstrates significant performance improvements over SOTA baselines SEED, PET and LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and SciFact. Data and code are available here: https://github.com/XiaZeng0223/MAPLE","sentences":["Claim verification is an essential step in the automated fact-checking pipeline which assesses the veracity of a claim against a piece of evidence.","In this work, we explore the potential of few-shot claim verification, where only very limited data is available for supervision.","We propose MAPLE (Micro Analysis of Pairwise Language Evolution), a pioneering approach that explores the alignment between a claim and its evidence with a small seq2seq model and a novel semantic measure.","Its innovative utilization of micro language evolution path leverages unlabelled pairwise data to facilitate claim verification while imposing low demand on data annotations and computing resources.","MAPLE demonstrates significant performance improvements over SOTA baselines SEED, PET and LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and SciFact.","Data and code are available here: https://github.com/XiaZeng0223/MAPLE"],"url":"http://arxiv.org/abs/2401.16282v1"}
{"created":"2024-01-29 16:25:38","title":"The HSF Conditions Database Reference Implementation","abstract":"Conditions data is the subset of non-event data that is necessary to process event data. It poses a unique set of challenges, namely a heterogeneous structure and high access rates by distributed computing. The HSF Conditions Databases activity is a forum for cross-experiment discussions inviting as broad a participation as possible. It grew out of the HSF Community White Paper work to study conditions data access, where experts from ATLAS, Belle II, and CMS converged on a common language and proposed a schema that represents best practice. Following discussions with a broader community, including NP as well as HEP experiments, a core set of use cases, functionality and behaviour was defined with the aim to describe a core conditions database API. This paper will describe the reference implementation of both the conditions database service and the client which together encapsulate HSF best practice conditions data handling. Django was chosen for the service implementation, which uses an ORM instead of the direct use of SQL for all but one method. The simple relational database schema to organise conditions data is implemented in PostgreSQL. The task of storing conditions data payloads themselves is outsourced to any POSIX- compliant filesystem, allowing for transparent relocation and redundancy. Cru- cially this design provides a clear separation between retrieving the metadata describing which conditions data are needed for a data processing job, and retrieving the actual payloads from storage. The service deployment using Helm on OKD will be described together with scaling tests and operations experience from the sPHENIX experiment running more than 25k cores at BNL.","sentences":["Conditions data is the subset of non-event data that is necessary to process event data.","It poses a unique set of challenges, namely a heterogeneous structure and high access rates by distributed computing.","The HSF Conditions Databases activity is a forum for cross-experiment discussions inviting as broad a participation as possible.","It grew out of the HSF Community White Paper work to study conditions data access, where experts from ATLAS, Belle II, and CMS converged on a common language and proposed a schema that represents best practice.","Following discussions with a broader community, including NP as well as HEP experiments, a core set of use cases, functionality and behaviour was defined with the aim to describe a core conditions database API.","This paper will describe the reference implementation of both the conditions database service and the client which together encapsulate HSF best practice conditions data handling.","Django was chosen for the service implementation, which uses an ORM instead of the direct use of SQL for all but one method.","The simple relational database schema to organise conditions data is implemented in PostgreSQL.","The task of storing conditions data payloads themselves is outsourced to any POSIX- compliant filesystem, allowing for transparent relocation and redundancy.","Cru- cially this design provides a clear separation between retrieving the metadata describing which conditions data are needed for a data processing job, and retrieving the actual payloads from storage.","The service deployment using Helm on OKD will be described together with scaling tests and operations experience from the sPHENIX experiment running more than 25k cores at BNL."],"url":"http://arxiv.org/abs/2401.16274v1"}
{"created":"2024-01-29 16:12:31","title":"CO2: Efficient Distributed Training with Full Communication-Computation Overlap","abstract":"The fundamental success of large language models hinges upon the efficacious implementation of large-scale distributed training techniques. Nevertheless, building a vast, high-performance cluster featuring high-speed communication interconnectivity is prohibitively costly, and accessible only to prominent entities. In this work, we aim to lower this barrier and democratize large-scale training with limited bandwidth clusters. We propose a new approach called CO2 that introduces local-updating and asynchronous communication to the distributed data-parallel training, thereby facilitating the full overlap of COmunication with COmputation. CO2 is able to attain a high scalability even on extensive multi-node clusters constrained by very limited communication bandwidth. We further propose the staleness gap penalty and outer momentum clipping techniques together with CO2 to bolster its convergence and training stability. Besides, CO2 exhibits seamless integration with well-established ZeRO-series optimizers which mitigate memory consumption of model states with large model training. We also provide a mathematical proof of convergence, accompanied by the establishment of a stringent upper bound. Furthermore, we validate our findings through an extensive set of practical experiments encompassing a wide range of tasks in the fields of computer vision and natural language processing. These experiments serve to demonstrate the capabilities of CO2 in terms of convergence, generalization, and scalability when deployed across configurations comprising up to 128 A100 GPUs. The outcomes emphasize the outstanding capacity of CO2 to hugely improve scalability, no matter on clusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections.","sentences":["The fundamental success of large language models hinges upon the efficacious implementation of large-scale distributed training techniques.","Nevertheless, building a vast, high-performance cluster featuring high-speed communication interconnectivity is prohibitively costly, and accessible only to prominent entities.","In this work, we aim to lower this barrier and democratize large-scale training with limited bandwidth clusters.","We propose a new approach called CO2 that introduces local-updating and asynchronous communication to the distributed data-parallel training, thereby facilitating the full overlap of COmunication with COmputation.","CO2 is able to attain a high scalability even on extensive multi-node clusters constrained by very limited communication bandwidth.","We further propose the staleness gap penalty and outer momentum clipping techniques together with CO2 to bolster its convergence and training stability.","Besides, CO2 exhibits seamless integration with well-established ZeRO-series optimizers which mitigate memory consumption of model states with large model training.","We also provide a mathematical proof of convergence, accompanied by the establishment of a stringent upper bound.","Furthermore, we validate our findings through an extensive set of practical experiments encompassing a wide range of tasks in the fields of computer vision and natural language processing.","These experiments serve to demonstrate the capabilities of CO2 in terms of convergence, generalization, and scalability when deployed across configurations comprising up to 128 A100 GPUs.","The outcomes emphasize the outstanding capacity of CO2 to hugely improve scalability, no matter on clusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections."],"url":"http://arxiv.org/abs/2401.16265v1"}
{"created":"2024-01-29 16:01:46","title":"Cross-silo Federated Learning with Record-level Personalized Differential Privacy","abstract":"Federated learning enhanced by differential privacy has emerged as a popular approach to better safeguard the privacy of client-side data by protecting clients' contributions during the training process. Existing solutions typically assume a uniform privacy budget for all records and provide one-size-fits-all solutions that may not be adequate to meet each record's privacy requirement. In this paper, we explore the uncharted territory of cross-silo FL with record-level personalized differential privacy. We devise a novel framework named rPDP-FL, employing a two-stage hybrid sampling scheme with both client-level sampling and non-uniform record-level sampling to accommodate varying privacy requirements. A critical and non-trivial problem is to select the ideal per-record sampling probability q given the personalized privacy budget {\\epsilon}. We introduce a versatile solution named Simulation-CurveFitting, allowing us to uncover a significant insight into the nonlinear correlation between q and {\\epsilon} and derive an elegant mathematical model to tackle the problem. Our evaluation demonstrates that our solution can provide significant performance gains over the baselines that do not consider personalized privacy preservation.","sentences":["Federated learning enhanced by differential privacy has emerged as a popular approach to better safeguard the privacy of client-side data by protecting clients' contributions during the training process.","Existing solutions typically assume a uniform privacy budget for all records and provide one-size-fits-all solutions that may not be adequate to meet each record's privacy requirement.","In this paper, we explore the uncharted territory of cross-silo FL with record-level personalized differential privacy.","We devise a novel framework named rPDP-FL, employing a two-stage hybrid sampling scheme with both client-level sampling and non-uniform record-level sampling to accommodate varying privacy requirements.","A critical and non-trivial problem is to select the ideal per-record sampling probability q given the personalized privacy budget {\\epsilon}.","We introduce a versatile solution named Simulation-CurveFitting, allowing us to uncover a significant insight into the nonlinear correlation between q and {\\epsilon} and derive an elegant mathematical model to tackle the problem.","Our evaluation demonstrates that our solution can provide significant performance gains over the baselines that do not consider personalized privacy preservation."],"url":"http://arxiv.org/abs/2401.16251v1"}
{"created":"2024-01-29 15:49:40","title":"Towards Red Teaming in Multimodal and Multilingual Translation","abstract":"Assessing performance in Natural Language Processing is becoming increasingly complex. One particular challenge is the potential for evaluation datasets to overlap with training data, either directly or indirectly, which can lead to skewed results and overestimation of model performance. As a consequence, human evaluation is gaining increasing interest as a means to assess the performance and reliability of models. One such method is the red teaming approach, which aims to generate edge cases where a model will produce critical errors. While this methodology is becoming standard practice for generative AI, its application to the realm of conditional AI remains largely unexplored. This paper presents the first study on human-based red teaming for Machine Translation (MT), marking a significant step towards understanding and improving the performance of translation models. We delve into both human-based red teaming and a study on automation, reporting lessons learned and providing recommendations for both translation models and red teaming drills. This pioneering work opens up new avenues for research and development in the field of MT.","sentences":["Assessing performance in Natural Language Processing is becoming increasingly complex.","One particular challenge is the potential for evaluation datasets to overlap with training data, either directly or indirectly, which can lead to skewed results and overestimation of model performance.","As a consequence, human evaluation is gaining increasing interest as a means to assess the performance and reliability of models.","One such method is the red teaming approach, which aims to generate edge cases where a model will produce critical errors.","While this methodology is becoming standard practice for generative AI, its application to the realm of conditional AI remains largely unexplored.","This paper presents the first study on human-based red teaming for Machine Translation (MT), marking a significant step towards understanding and improving the performance of translation models.","We delve into both human-based red teaming and a study on automation, reporting lessons learned and providing recommendations for both translation models and red teaming drills.","This pioneering work opens up new avenues for research and development in the field of MT."],"url":"http://arxiv.org/abs/2401.16247v1"}
{"created":"2024-01-29 15:35:05","title":"Effective Communication with Dynamic Feature Compression","abstract":"The remote wireless control of industrial systems is one of the major use cases for 5G and beyond systems: in these cases, the massive amounts of sensory information that need to be shared over the wireless medium may overload even high-capacity connections. Consequently, solving the effective communication problem by optimizing the transmission strategy to discard irrelevant information can provide a significant advantage, but is often a very complex task. In this work, we consider a prototypal system in which an observer must communicate its sensory data to a robot controlling a task (e.g., a mobile robot in a factory). We then model it as a remote Partially Observable Markov Decision Process (POMDP), considering the effect of adopting semantic and effective communication-oriented solutions on the overall system performance. We split the communication problem by considering an ensemble Vector Quantized Variational Autoencoder (VQ-VAE) encoding, and train a Deep Reinforcement Learning (DRL) agent to dynamically adapt the quantization level, considering both the current state of the environment and the memory of past messages. We tested the proposed approach on the well-known CartPole reference control problem, obtaining a significant performance increase over traditional approaches.","sentences":["The remote wireless control of industrial systems is one of the major use cases for 5G and beyond systems: in these cases, the massive amounts of sensory information that need to be shared over the wireless medium may overload even high-capacity connections.","Consequently, solving the effective communication problem by optimizing the transmission strategy to discard irrelevant information can provide a significant advantage, but is often a very complex task.","In this work, we consider a prototypal system in which an observer must communicate its sensory data to a robot controlling a task (e.g., a mobile robot in a factory).","We then model it as a remote Partially Observable Markov Decision Process (POMDP), considering the effect of adopting semantic and effective communication-oriented solutions on the overall system performance.","We split the communication problem by considering an ensemble Vector Quantized Variational Autoencoder (VQ-VAE) encoding, and train a Deep Reinforcement Learning (DRL) agent to dynamically adapt the quantization level, considering both the current state of the environment and the memory of past messages.","We tested the proposed approach on the well-known CartPole reference control problem, obtaining a significant performance increase over traditional approaches."],"url":"http://arxiv.org/abs/2401.16236v1"}
{"created":"2024-01-29 15:34:49","title":"Player Pressure Map - A Novel Representation of Pressure in Soccer for Evaluating Player Performance in Different Game Contexts","abstract":"In soccer, contextual player performance metrics are invaluable to coaches. For example, the ability to perform under pressure during matches distinguishes the elite from the average. Appropriate pressure metric enables teams to assess players' performance accurately under pressure and design targeted training scenarios to address their weaknesses. The primary objective of this paper is to leverage both tracking and event data and game footage to capture the pressure experienced by the possession team in a soccer game scene. We propose a player pressure map to represent a given game scene, which lowers the dimension of raw data and still contains rich contextual information. Not only does it serve as an effective tool for visualizing and evaluating the pressure on the team and each individual, but it can also be utilized as a backbone for accessing players' performance. Overall, our model provides coaches and analysts with a deeper understanding of players' performance under pressure so that they make data-oriented tactical decisions.","sentences":["In soccer, contextual player performance metrics are invaluable to coaches.","For example, the ability to perform under pressure during matches distinguishes the elite from the average.","Appropriate pressure metric enables teams to assess players' performance accurately under pressure and design targeted training scenarios to address their weaknesses.","The primary objective of this paper is to leverage both tracking and event data and game footage to capture the pressure experienced by the possession team in a soccer game scene.","We propose a player pressure map to represent a given game scene, which lowers the dimension of raw data and still contains rich contextual information.","Not only does it serve as an effective tool for visualizing and evaluating the pressure on the team and each individual, but it can also be utilized as a backbone for accessing players' performance.","Overall, our model provides coaches and analysts with a deeper understanding of players' performance under pressure so that they make data-oriented tactical decisions."],"url":"http://arxiv.org/abs/2401.16235v1"}
{"created":"2024-01-29 15:32:18","title":"Cross-Database Liveness Detection: Insights from Comparative Biometric Analysis","abstract":"In an era where biometric security serves as a keystone of modern identity verification systems, ensuring the authenticity of these biometric samples is paramount. Liveness detection, the capability to differentiate between genuine and spoofed biometric samples, stands at the forefront of this challenge. This research presents a comprehensive evaluation of liveness detection models, with a particular focus on their performance in cross-database scenarios, a test paradigm notorious for its complexity and real-world relevance. Our study commenced by meticulously assessing models on individual datasets, revealing the nuances in their performance metrics. Delving into metrics such as the Half Total Error Rate, False Acceptance Rate, and False Rejection Rate, we unearthed invaluable insights into the models' strengths and weaknesses. Crucially, our exploration of cross-database testing provided a unique perspective, highlighting the chasm between training on one dataset and deploying on another. Comparative analysis with extant methodologies, ranging from convolutional networks to more intricate strategies, enriched our understanding of the current landscape. The variance in performance, even among state-of-the-art models, underscored the inherent challenges in this domain. In essence, this paper serves as both a repository of findings and a clarion call for more nuanced, data-diverse, and adaptable approaches in biometric liveness detection. In the dynamic dance between authenticity and deception, our work offers a blueprint for navigating the evolving rhythms of biometric security.","sentences":["In an era where biometric security serves as a keystone of modern identity verification systems, ensuring the authenticity of these biometric samples is paramount.","Liveness detection, the capability to differentiate between genuine and spoofed biometric samples, stands at the forefront of this challenge.","This research presents a comprehensive evaluation of liveness detection models, with a particular focus on their performance in cross-database scenarios, a test paradigm notorious for its complexity and real-world relevance.","Our study commenced by meticulously assessing models on individual datasets, revealing the nuances in their performance metrics.","Delving into metrics such as the Half Total Error Rate, False Acceptance Rate, and False Rejection Rate, we unearthed invaluable insights into the models' strengths and weaknesses.","Crucially, our exploration of cross-database testing provided a unique perspective, highlighting the chasm between training on one dataset and deploying on another.","Comparative analysis with extant methodologies, ranging from convolutional networks to more intricate strategies, enriched our understanding of the current landscape.","The variance in performance, even among state-of-the-art models, underscored the inherent challenges in this domain.","In essence, this paper serves as both a repository of findings and a clarion call for more nuanced, data-diverse, and adaptable approaches in biometric liveness detection.","In the dynamic dance between authenticity and deception, our work offers a blueprint for navigating the evolving rhythms of biometric security."],"url":"http://arxiv.org/abs/2401.16232v1"}
{"created":"2024-01-29 15:30:29","title":"Elementary first-order model checking for sparse graphs","abstract":"It is known that for subgraph-closed graph classes the first-order model checking problem is fixed-parameter tractable if and only if the class is nowhere dense [Grohe, Kreutzer, Siebertz, STOC 2014]. However, the dependency on the formula size is non-elementary, and in fact, this is unavoidable even for the class of all trees [Frick and Grohe, LICS 2002]. On the other hand, it is known that the dependency is elementary for classes of bounded degree [Frick and Grohe, LICS 2002] as well as for classes of bounded pathwidth [Lampis, ICALP 2023]. In this paper we generalise these results and almost completely characterise subgraph-closed graph classes for which the model checking problem is fixed-parameter tractable with an elementary dependency on the formula size. Those are the graph classes for which there exists a number $d$ such that for every $r$, some tree of depth $d$ and size bounded by an elementary function of $r$ is avoided as an $({\\leq} r)$-subdivision in all graphs in the class. In particular, this implies that if the class in question excludes a fixed tree as a topological minor, then first-order model checking for graphs in the class is fixed-parameter tractable with an elementary dependency on the formula size.","sentences":["It is known that for subgraph-closed graph classes the first-order model checking problem is fixed-parameter tractable if and only if the class is nowhere dense [Grohe, Kreutzer, Siebertz, STOC 2014].","However, the dependency on the formula size is non-elementary, and in fact, this is unavoidable even for the class of all trees [Frick and Grohe, LICS 2002].","On the other hand, it is known that the dependency is elementary for classes of bounded degree","[Frick and Grohe, LICS 2002] as well as for classes of bounded pathwidth [Lampis, ICALP 2023].","In this paper we generalise these results and almost completely characterise subgraph-closed graph classes for which the model checking problem is fixed-parameter tractable with an elementary dependency on the formula size.","Those are the graph classes for which there exists a number $d$ such that for every $r$, some tree of depth $d$ and size bounded by an elementary function of $r$ is avoided as an $({\\leq} r)$-subdivision in all graphs in the class.","In particular, this implies that if the class in question excludes a fixed tree as a topological minor, then first-order model checking for graphs in the class is fixed-parameter tractable with an elementary dependency on the formula size."],"url":"http://arxiv.org/abs/2401.16230v1"}
{"created":"2024-01-29 14:53:14","title":"Geospatial Disparities: A Case Study on Real Estate Prices in Paris","abstract":"Driven by an increasing prevalence of trackers, ever more IoT sensors, and the declining cost of computing power, geospatial information has come to play a pivotal role in contemporary predictive models. While enhancing prognostic performance, geospatial data also has the potential to perpetuate many historical socio-economic patterns, raising concerns about a resurgence of biases and exclusionary practices, with their disproportionate impacts on society. Addressing this, our paper emphasizes the crucial need to identify and rectify such biases and calibration errors in predictive models, particularly as algorithms become more intricate and less interpretable. The increasing granularity of geospatial information further introduces ethical concerns, as choosing different geographical scales may exacerbate disparities akin to redlining and exclusionary zoning. To address these issues, we propose a toolkit for identifying and mitigating biases arising from geospatial data. Extending classical fairness definitions, we incorporate an ordinal regression case with spatial attributes, deviating from the binary classification focus. This extension allows us to gauge disparities stemming from data aggregation levels and advocates for a less interfering correction approach. Illustrating our methodology using a Parisian real estate dataset, we showcase practical applications and scrutinize the implications of choosing geographical aggregation levels for fairness and calibration measures.","sentences":["Driven by an increasing prevalence of trackers, ever more IoT sensors, and the declining cost of computing power, geospatial information has come to play a pivotal role in contemporary predictive models.","While enhancing prognostic performance, geospatial data also has the potential to perpetuate many historical socio-economic patterns, raising concerns about a resurgence of biases and exclusionary practices, with their disproportionate impacts on society.","Addressing this, our paper emphasizes the crucial need to identify and rectify such biases and calibration errors in predictive models, particularly as algorithms become more intricate and less interpretable.","The increasing granularity of geospatial information further introduces ethical concerns, as choosing different geographical scales may exacerbate disparities akin to redlining and exclusionary zoning.","To address these issues, we propose a toolkit for identifying and mitigating biases arising from geospatial data.","Extending classical fairness definitions, we incorporate an ordinal regression case with spatial attributes, deviating from the binary classification focus.","This extension allows us to gauge disparities stemming from data aggregation levels and advocates for a less interfering correction approach.","Illustrating our methodology using a Parisian real estate dataset, we showcase practical applications and scrutinize the implications of choosing geographical aggregation levels for fairness and calibration measures."],"url":"http://arxiv.org/abs/2401.16197v1"}
{"created":"2024-01-29 14:47:26","title":"Contributing Dimension Structure of Deep Feature for Coreset Selection","abstract":"Coreset selection seeks to choose a subset of crucial training samples for efficient learning. It has gained traction in deep learning, particularly with the surge in training dataset sizes. Sample selection hinges on two main aspects: a sample's representation in enhancing performance and the role of sample diversity in averting overfitting. Existing methods typically measure both the representation and diversity of data based on similarity metrics, such as L2-norm. They have capably tackled representation via distribution matching guided by the similarities of features, gradients, or other information between data. However, the results of effectively diverse sample selection are mired in sub-optimality. This is because the similarity metrics usually simply aggregate dimension similarities without acknowledging disparities among the dimensions that significantly contribute to the final similarity. As a result, they fall short of adequately capturing diversity. To address this, we propose a feature-based diversity constraint, compelling the chosen subset to exhibit maximum diversity. Our key lies in the introduction of a novel Contributing Dimension Structure (CDS) metric. Different from similarity metrics that measure the overall similarity of high-dimensional features, our CDS metric considers not only the reduction of redundancy in feature dimensions, but also the difference between dimensions that contribute significantly to the final similarity. We reveal that existing methods tend to favor samples with similar CDS, leading to a reduced variety of CDS types within the coreset and subsequently hindering model performance. In response, we enhance the performance of five classical selection methods by integrating the CDS constraint. Our experiments on three datasets demonstrate the general effectiveness of the proposed method in boosting existing methods.","sentences":["Coreset selection seeks to choose a subset of crucial training samples for efficient learning.","It has gained traction in deep learning, particularly with the surge in training dataset sizes.","Sample selection hinges on two main aspects: a sample's representation in enhancing performance and the role of sample diversity in averting overfitting.","Existing methods typically measure both the representation and diversity of data based on similarity metrics, such as L2-norm.","They have capably tackled representation via distribution matching guided by the similarities of features, gradients, or other information between data.","However, the results of effectively diverse sample selection are mired in sub-optimality.","This is because the similarity metrics usually simply aggregate dimension similarities without acknowledging disparities among the dimensions that significantly contribute to the final similarity.","As a result, they fall short of adequately capturing diversity.","To address this, we propose a feature-based diversity constraint, compelling the chosen subset to exhibit maximum diversity.","Our key lies in the introduction of a novel Contributing Dimension Structure (CDS) metric.","Different from similarity metrics that measure the overall similarity of high-dimensional features, our CDS metric considers not only the reduction of redundancy in feature dimensions, but also the difference between dimensions that contribute significantly to the final similarity.","We reveal that existing methods tend to favor samples with similar CDS, leading to a reduced variety of CDS types within the coreset and subsequently hindering model performance.","In response, we enhance the performance of five classical selection methods by integrating the CDS constraint.","Our experiments on three datasets demonstrate the general effectiveness of the proposed method in boosting existing methods."],"url":"http://arxiv.org/abs/2401.16193v1"}
{"created":"2024-01-29 14:41:55","title":"FIMP: Future Interaction Modeling for Multi-Agent Motion Prediction","abstract":"Multi-agent motion prediction is a crucial concern in autonomous driving, yet it remains a challenge owing to the ambiguous intentions of dynamic agents and their intricate interactions. Existing studies have attempted to capture interactions between road entities by using the definite data in history timesteps, as future information is not available and involves high uncertainty. However, without sufficient guidance for capturing future states of interacting agents, they frequently produce unrealistic trajectory overlaps. In this work, we propose Future Interaction modeling for Motion Prediction (FIMP), which captures potential future interactions in an end-to-end manner. FIMP adopts a future decoder that implicitly extracts the potential future information in an intermediate feature-level, and identifies the interacting entity pairs through future affinity learning and top-k filtering strategy. Experiments show that our future interaction modeling improves the performance remarkably, leading to superior performance on the Argoverse motion forecasting benchmark.","sentences":["Multi-agent motion prediction is a crucial concern in autonomous driving, yet it remains a challenge owing to the ambiguous intentions of dynamic agents and their intricate interactions.","Existing studies have attempted to capture interactions between road entities by using the definite data in history timesteps, as future information is not available and involves high uncertainty.","However, without sufficient guidance for capturing future states of interacting agents, they frequently produce unrealistic trajectory overlaps.","In this work, we propose Future Interaction modeling for Motion Prediction (FIMP), which captures potential future interactions in an end-to-end manner.","FIMP adopts a future decoder that implicitly extracts the potential future information in an intermediate feature-level, and identifies the interacting entity pairs through future affinity learning and top-k filtering strategy.","Experiments show that our future interaction modeling improves the performance remarkably, leading to superior performance on the Argoverse motion forecasting benchmark."],"url":"http://arxiv.org/abs/2401.16189v1"}
{"created":"2024-01-29 14:29:48","title":"On the Semantics of LM Latent Space: A Vocabulary-defined Approach","abstract":"In the realm of deep learning, understanding the latent space of language models (LMs) like transformers is crucial for refining their performance and interpretability. However, existing analyses often fall short in providing absolute and model-centric insights into LM semantics, and neglect essential aspects of LM adaption. In response, we introduce a pioneering method called vocabulary-defined semantics, which establishes a fixed reference frame within the LM latent space, ensuring absolute semantic analysis grounded in LM vocabulary. Our approach transcends prior relative analyses, leveraging LM vocabulary for model-centric insights. Furthermore, we propose a novel technique to compute logits, emphasizing differentiability and local isotropy, and introduce a neural clustering module for semantically calibrating data representations during LM adaptation. Through extensive experiments across diverse text understanding datasets, our approach surpasses state-of-the-art methods of retrieval-augmented generation and parameters-efficient finetuning, showcasing its efficacy and broad applicability. Our findings not only shed light on LM mechanics but also offer practical solutions for enhancing LM performance and interpretability.","sentences":["In the realm of deep learning, understanding the latent space of language models (LMs) like transformers is crucial for refining their performance and interpretability.","However, existing analyses often fall short in providing absolute and model-centric insights into LM semantics, and neglect essential aspects of LM adaption.","In response, we introduce a pioneering method called vocabulary-defined semantics, which establishes a fixed reference frame within the LM latent space, ensuring absolute semantic analysis grounded in LM vocabulary.","Our approach transcends prior relative analyses, leveraging LM vocabulary for model-centric insights.","Furthermore, we propose a novel technique to compute logits, emphasizing differentiability and local isotropy, and introduce a neural clustering module for semantically calibrating data representations during LM adaptation.","Through extensive experiments across diverse text understanding datasets, our approach surpasses state-of-the-art methods of retrieval-augmented generation and parameters-efficient finetuning, showcasing its efficacy and broad applicability.","Our findings not only shed light on LM mechanics but also offer practical solutions for enhancing LM performance and interpretability."],"url":"http://arxiv.org/abs/2401.16184v1"}
{"created":"2024-01-29 14:23:51","title":"LLaMandement: Large Language Models for Summarization of French Legislative Proposals","abstract":"This report introduces LLaMandement, a state-of-the-art Large Language Model, fine-tuned by the French government and designed to enhance the efficiency and efficacy of processing parliamentary sessions (including the production of bench memoranda and documents required for interministerial meetings) by generating neutral summaries of legislative proposals. Addressing the administrative challenges of manually processing a growing volume of legislative amendments, LLaMandement stands as a significant legal technological milestone, providing a solution that exceeds the scalability of traditional human efforts while matching the robustness of a specialized legal drafter. We release all our fine-tuned models and training data to the community.","sentences":["This report introduces LLaMandement, a state-of-the-art Large Language Model, fine-tuned by the French government and designed to enhance the efficiency and efficacy of processing parliamentary sessions (including the production of bench memoranda and documents required for interministerial meetings) by generating neutral summaries of legislative proposals.","Addressing the administrative challenges of manually processing a growing volume of legislative amendments, LLaMandement stands as a significant legal technological milestone, providing a solution that exceeds the scalability of traditional human efforts while matching the robustness of a specialized legal drafter.","We release all our fine-tuned models and training data to the community."],"url":"http://arxiv.org/abs/2401.16182v1"}
{"created":"2024-01-29 14:23:38","title":"On Decentralized Linearly Separable Computation With the Minimum Computation Cost","abstract":"The distributed linearly separable computation problem finds extensive applications across domains such as distributed gradient coding, distributed linear transform, real-time rendering, etc. In this paper, we investigate this problem in a fully decentralized scenario, where $\\mathsf{N}$ workers collaboratively perform the computation task without a central master. Each worker aims to compute a linearly separable computation that can be manifested as $\\mathsf{K}_{\\mathrm{c}}$ linear combinations of $\\mathsf{K}$ messages, where each message is a function of a distinct dataset. We require that each worker successfully fulfill the task based on the transmissions from any $\\mathsf{N}_{\\mathrm{r}}$ workers, such that the system can tolerate any $\\mathsf{N}-\\mathsf{N}_{\\mathrm{r}}$ stragglers. We focus on the scenario where the computation cost (the number of uncoded datasets assigned to each worker) is minimum, and aim to minimize the communication cost (the number of symbols the fastest $\\mathsf{N}_{\\mathrm{r}}$ workers transmit). We propose a novel distributed computing scheme that is optimal under the widely used cyclic data assignment. Interestingly, we demonstrate that the side information at each worker is ineffective in reducing the communication cost when $\\mathsf{K}_{\\mathrm{c}}\\leq {\\mathsf{K}}\\mathsf{N}_{\\mathrm{r}}/{\\mathsf{N}}$, while it helps reduce the communication cost as $\\mathsf{K}_{\\mathrm{c}}$ increases.","sentences":["The distributed linearly separable computation problem finds extensive applications across domains such as distributed gradient coding, distributed linear transform, real-time rendering, etc.","In this paper, we investigate this problem in a fully decentralized scenario, where $\\mathsf{N}$ workers collaboratively perform the computation task without a central master.","Each worker aims to compute a linearly separable computation that can be manifested as $\\mathsf{K}_{\\mathrm{c}}$ linear combinations of $\\mathsf{K}$ messages, where each message is a function of a distinct dataset.","We require that each worker successfully fulfill the task based on the transmissions from any $\\mathsf{N}_{\\mathrm{r}}$ workers, such that the system can tolerate any $\\mathsf{N}-\\mathsf{N}_{\\mathrm{r}}$ stragglers.","We focus on the scenario where the computation cost (the number of uncoded datasets assigned to each worker) is minimum, and aim to minimize the communication cost (the number of symbols the fastest $\\mathsf{N}_{\\mathrm{r}}$ workers transmit).","We propose a novel distributed computing scheme that is optimal under the widely used cyclic data assignment.","Interestingly, we demonstrate that the side information at each worker is ineffective in reducing the communication cost when $\\mathsf{K}_{\\mathrm{c}}\\leq {\\mathsf{K}}\\mathsf{N}_{\\mathrm{r}}/{\\mathsf{N}}$, while it helps reduce the communication cost as $\\mathsf{K}_{\\mathrm{c}}$ increases."],"url":"http://arxiv.org/abs/2401.16181v1"}
{"created":"2024-01-29 14:08:02","title":"Reconstructing Close Human Interactions from Multiple Views","abstract":"This paper addresses the challenging task of reconstructing the poses of multiple individuals engaged in close interactions, captured by multiple calibrated cameras. The difficulty arises from the noisy or false 2D keypoint detections due to inter-person occlusion, the heavy ambiguity in associating keypoints to individuals due to the close interactions, and the scarcity of training data as collecting and annotating motion data in crowded scenes is resource-intensive. We introduce a novel system to address these challenges. Our system integrates a learning-based pose estimation component and its corresponding training and inference strategies. The pose estimation component takes multi-view 2D keypoint heatmaps as input and reconstructs the pose of each individual using a 3D conditional volumetric network. As the network doesn't need images as input, we can leverage known camera parameters from test scenes and a large quantity of existing motion capture data to synthesize massive training data that mimics the real data distribution in test scenes. Extensive experiments demonstrate that our approach significantly surpasses previous approaches in terms of pose accuracy and is generalizable across various camera setups and population sizes. The code is available on our project page: https://github.com/zju3dv/CloseMoCap.","sentences":["This paper addresses the challenging task of reconstructing the poses of multiple individuals engaged in close interactions, captured by multiple calibrated cameras.","The difficulty arises from the noisy or false 2D keypoint detections due to inter-person occlusion, the heavy ambiguity in associating keypoints to individuals due to the close interactions, and the scarcity of training data as collecting and annotating motion data in crowded scenes is resource-intensive.","We introduce a novel system to address these challenges.","Our system integrates a learning-based pose estimation component and its corresponding training and inference strategies.","The pose estimation component takes multi-view 2D keypoint heatmaps as input and reconstructs the pose of each individual using a 3D conditional volumetric network.","As the network doesn't need images as input, we can leverage known camera parameters from test scenes and a large quantity of existing motion capture data to synthesize massive training data that mimics the real data distribution in test scenes.","Extensive experiments demonstrate that our approach significantly surpasses previous approaches in terms of pose accuracy and is generalizable across various camera setups and population sizes.","The code is available on our project page: https://github.com/zju3dv/CloseMoCap."],"url":"http://arxiv.org/abs/2401.16173v1"}
{"created":"2024-01-29 13:54:48","title":"\"You tell me\": A Dataset of GPT-4-Based Behaviour Change Support Conversations","abstract":"Conversational agents are increasingly used to address emotional needs on top of information needs. One use case of increasing interest are counselling-style mental health and behaviour change interventions, with large language model (LLM)-based approaches becoming more popular. Research in this context so far has been largely system-focused, foregoing the aspect of user behaviour and the impact this can have on LLM-generated texts. To address this issue, we share a dataset containing text-based user interactions related to behaviour change with two GPT-4-based conversational agents collected in a preregistered user study. This dataset includes conversation data, user language analysis, perception measures, and user feedback for LLM-generated turns, and can offer valuable insights to inform the design of such systems based on real interactions.","sentences":["Conversational agents are increasingly used to address emotional needs on top of information needs.","One use case of increasing interest are counselling-style mental health and behaviour change interventions, with large language model (LLM)-based approaches becoming more popular.","Research in this context so far has been largely system-focused, foregoing the aspect of user behaviour and the impact this can have on LLM-generated texts.","To address this issue, we share a dataset containing text-based user interactions related to behaviour change with two GPT-4-based conversational agents collected in a preregistered user study.","This dataset includes conversation data, user language analysis, perception measures, and user feedback for LLM-generated turns, and can offer valuable insights to inform the design of such systems based on real interactions."],"url":"http://arxiv.org/abs/2401.16167v1"}
{"created":"2024-01-29 13:48:36","title":"LLaVA-MoLE: Sparse Mixture of LoRA Experts for Mitigating Data Conflicts in Instruction Finetuning MLLMs","abstract":"Instruction finetuning on a variety of image-text instruction data is the key to obtaining a versatile Multimodal Large Language Model (MLLM), and different configurations of the instruction data can lead to finetuned models with different capabilities. However, we have discovered that data conflicts are inevitable when mixing instruction data from distinct domains, which can result in performance drops for tasks of a specific domain. To address this issue, we propose to apply a sparse mixture of LoRA experts for instruction finetuning MLLMs. Within the Transformer layers, we extend the popular Low-Rank Adaption (LoRA) method by creating a set of LoRA experts specifically for the MLP layer, and route each token to the top-1 expert based on a routing function, allowing adaptive choices for tokens from different domains. Since the LoRA experts are sparsely activated, the training and inference cost are kept roughly constant compared to the original LoRA method. By replacing the plain-LoRA finetuing of LLaVA-1.5, our final model is named LLaVA-MoLE. Extensive experiments proved that LLaVA-MoLE effectively mitigates the data conflict issue when mixing multiple distinct instruction datasets with various configurations, and achieves consistent performance gains over the strong plain-LoRA baselines. Most importantly, on the mixed datasets, LLaVA-MoLE can even outperform the plain-LoRA baseline trained with twice the samples.","sentences":["Instruction finetuning on a variety of image-text instruction data is the key to obtaining a versatile Multimodal Large Language Model (MLLM), and different configurations of the instruction data can lead to finetuned models with different capabilities.","However, we have discovered that data conflicts are inevitable when mixing instruction data from distinct domains, which can result in performance drops for tasks of a specific domain.","To address this issue, we propose to apply a sparse mixture of LoRA experts for instruction finetuning MLLMs.","Within the Transformer layers, we extend the popular Low-Rank Adaption (LoRA) method by creating a set of LoRA experts specifically for the MLP layer, and route each token to the top-1 expert based on a routing function, allowing adaptive choices for tokens from different domains.","Since the LoRA experts are sparsely activated, the training and inference cost are kept roughly constant compared to the original LoRA method.","By replacing the plain-LoRA finetuing of LLaVA-1.5, our final model is named LLaVA-MoLE.","Extensive experiments proved that LLaVA-MoLE effectively mitigates the data conflict issue when mixing multiple distinct instruction datasets with various configurations, and achieves consistent performance gains over the strong plain-LoRA baselines.","Most importantly, on the mixed datasets, LLaVA-MoLE can even outperform the plain-LoRA baseline trained with twice the samples."],"url":"http://arxiv.org/abs/2401.16160v1"}
{"created":"2024-01-29 13:07:08","title":"Neural Network Training on Encrypted Data with TFHE","abstract":"We present an approach to outsourcing of training neural networks while preserving data confidentiality from malicious parties. We use fully homomorphic encryption to build a unified training approach that works on encrypted data and learns quantized neural network models. The data can be horizontally or vertically split between multiple parties, enabling collaboration on confidential data. We train logistic regression and multi-layer perceptrons on several datasets.","sentences":["We present an approach to outsourcing of training neural networks while preserving data confidentiality from malicious parties.","We use fully homomorphic encryption to build a unified training approach that works on encrypted data and learns quantized neural network models.","The data can be horizontally or vertically split between multiple parties, enabling collaboration on confidential data.","We train logistic regression and multi-layer perceptrons on several datasets."],"url":"http://arxiv.org/abs/2401.16136v1"}
{"created":"2024-01-29 12:48:56","title":"Looking for a better fit? An Incremental Learning Multimodal Object Referencing Framework adapting to Individual Drivers","abstract":"The rapid advancement of the automotive industry towards automated and semi-automated vehicles has rendered traditional methods of vehicle interaction, such as touch-based and voice command systems, inadequate for a widening range of non-driving related tasks, such as referencing objects outside of the vehicle. Consequently, research has shifted toward gestural input (e.g., hand, gaze, and head pose gestures) as a more suitable mode of interaction during driving. However, due to the dynamic nature of driving and individual variation, there are significant differences in drivers' gestural input performance. While, in theory, this inherent variability could be moderated by substantial data-driven machine learning models, prevalent methodologies lean towards constrained, single-instance trained models for object referencing. These models show a limited capacity to continuously adapt to the divergent behaviors of individual drivers and the variety of driving scenarios. To address this, we propose \\textit{IcRegress}, a novel regression-based incremental learning approach that adapts to changing behavior and the unique characteristics of drivers engaged in the dual task of driving and referencing objects. We suggest a more personalized and adaptable solution for multimodal gestural interfaces, employing continuous lifelong learning to enhance driver experience, safety, and convenience. Our approach was evaluated using an outside-the-vehicle object referencing use case, highlighting the superiority of the incremental learning models adapted over a single trained model across various driver traits such as handedness, driving experience, and numerous driving conditions. Finally, to facilitate reproducibility, ease deployment, and promote further research, we offer our approach as an open-source framework at \\url{https://github.com/amrgomaaelhady/IcRegress}.","sentences":["The rapid advancement of the automotive industry towards automated and semi-automated vehicles has rendered traditional methods of vehicle interaction, such as touch-based and voice command systems, inadequate for a widening range of non-driving related tasks, such as referencing objects outside of the vehicle.","Consequently, research has shifted toward gestural input (e.g., hand, gaze, and head pose gestures) as a more suitable mode of interaction during driving.","However, due to the dynamic nature of driving and individual variation, there are significant differences in drivers' gestural input performance.","While, in theory, this inherent variability could be moderated by substantial data-driven machine learning models, prevalent methodologies lean towards constrained, single-instance trained models for object referencing.","These models show a limited capacity to continuously adapt to the divergent behaviors of individual drivers and the variety of driving scenarios.","To address this, we propose \\textit{IcRegress}, a novel regression-based incremental learning approach that adapts to changing behavior and the unique characteristics of drivers engaged in the dual task of driving and referencing objects.","We suggest a more personalized and adaptable solution for multimodal gestural interfaces, employing continuous lifelong learning to enhance driver experience, safety, and convenience.","Our approach was evaluated using an outside-the-vehicle object referencing use case, highlighting the superiority of the incremental learning models adapted over a single trained model across various driver traits such as handedness, driving experience, and numerous driving conditions.","Finally, to facilitate reproducibility, ease deployment, and promote further research, we offer our approach as an open-source framework at \\url{https://github.com/amrgomaaelhady/IcRegress}."],"url":"http://arxiv.org/abs/2401.16123v1"}
{"created":"2024-01-29 12:47:55","title":"DeFlow: Decoder of Scene Flow Network in Autonomous Driving","abstract":"Scene flow estimation determines a scene's 3D motion field, by predicting the motion of points in the scene, especially for aiding tasks in autonomous driving. Many networks with large-scale point clouds as input use voxelization to create a pseudo-image for real-time running. However, the voxelization process often results in the loss of point-specific features. This gives rise to a challenge in recovering those features for scene flow tasks. Our paper introduces DeFlow which enables a transition from voxel-based features to point features using Gated Recurrent Unit (GRU) refinement. To further enhance scene flow estimation performance, we formulate a novel loss function that accounts for the data imbalance between static and dynamic points. Evaluations on the Argoverse 2 scene flow task reveal that DeFlow achieves state-of-the-art results on large-scale point cloud data, demonstrating that our network has better performance and efficiency compared to others. The code is open-sourced at https://github.com/KTH-RPL/deflow.","sentences":["Scene flow estimation determines a scene's 3D motion field, by predicting the motion of points in the scene, especially for aiding tasks in autonomous driving.","Many networks with large-scale point clouds as input use voxelization to create a pseudo-image for real-time running.","However, the voxelization process often results in the loss of point-specific features.","This gives rise to a challenge in recovering those features for scene flow tasks.","Our paper introduces DeFlow which enables a transition from voxel-based features to point features using Gated Recurrent Unit (GRU) refinement.","To further enhance scene flow estimation performance, we formulate a novel loss function that accounts for the data imbalance between static and dynamic points.","Evaluations on the Argoverse 2 scene flow task reveal that DeFlow achieves state-of-the-art results on large-scale point cloud data, demonstrating that our network has better performance and efficiency compared to others.","The code is open-sourced at https://github.com/KTH-RPL/deflow."],"url":"http://arxiv.org/abs/2401.16122v1"}
{"created":"2024-01-29 12:45:27","title":"Triple Disentangled Representation Learning for Multimodal Affective Analysis","abstract":"Multimodal learning has exhibited a significant advantage in affective analysis tasks owing to the comprehensive information of various modalities, particularly the complementary information. Thus, many emerging studies focus on disentangling the modality-invariant and modality-specific representations from input data and then fusing them for prediction. However, our study shows that modality-specific representations may contain information that is irrelevant or conflicting with the tasks, which downgrades the effectiveness of learned multimodal representations. We revisit the disentanglement issue, and propose a novel triple disentanglement approach, TriDiRA, which disentangles the modality-invariant, effective modality-specific and ineffective modality-specific representations from input data. By fusing only the modality-invariant and effective modality-specific representations, TriDiRA can significantly alleviate the impact of irrelevant and conflicting information across modalities during model training. Extensive experiments conducted on four benchmark datasets demonstrate the effectiveness and generalization of our triple disentanglement, which outperforms SOTA methods.","sentences":["Multimodal learning has exhibited a significant advantage in affective analysis tasks owing to the comprehensive information of various modalities, particularly the complementary information.","Thus, many emerging studies focus on disentangling the modality-invariant and modality-specific representations from input data and then fusing them for prediction.","However, our study shows that modality-specific representations may contain information that is irrelevant or conflicting with the tasks, which downgrades the effectiveness of learned multimodal representations.","We revisit the disentanglement issue, and propose a novel triple disentanglement approach, TriDiRA, which disentangles the modality-invariant, effective modality-specific and ineffective modality-specific representations from input data.","By fusing only the modality-invariant and effective modality-specific representations, TriDiRA can significantly alleviate the impact of irrelevant and conflicting information across modalities during model training.","Extensive experiments conducted on four benchmark datasets demonstrate the effectiveness and generalization of our triple disentanglement, which outperforms SOTA methods."],"url":"http://arxiv.org/abs/2401.16119v1"}
{"created":"2024-01-29 12:31:13","title":"Towards Scenario Generalization for Vision-based Roadside 3D Object Detection","abstract":"Roadside perception can greatly increase the safety of autonomous vehicles by extending their perception ability beyond the visual range and addressing blind spots. However, current state-of-the-art vision-based roadside detection methods possess high accuracy on labeled scenes but have inferior performance on new scenes. This is because roadside cameras remain stationary after installation and can only collect data from a single scene, resulting in the algorithm overfitting these roadside backgrounds and camera poses. To address this issue, in this paper, we propose an innovative Scenario Generalization Framework for Vision-based Roadside 3D Object Detection, dubbed SGV3D. Specifically, we employ a Background-suppressed Module (BSM) to mitigate background overfitting in vision-centric pipelines by attenuating background features during the 2D to bird's-eye-view projection. Furthermore, by introducing the Semi-supervised Data Generation Pipeline (SSDG) using unlabeled images from new scenes, diverse instance foregrounds with varying camera poses are generated, addressing the risk of overfitting specific camera poses. We evaluate our method on two large-scale roadside benchmarks. Our method surpasses all previous methods by a significant margin in new scenes, including +42.57% for vehicle, +5.87% for pedestrian, and +14.89% for cyclist compared to BEVHeight on the DAIR-V2X-I heterologous benchmark. On the larger-scale Rope3D heterologous benchmark, we achieve notable gains of 14.48% for car and 12.41% for large vehicle. We aspire to contribute insights on the exploration of roadside perception techniques, emphasizing their capability for scenario generalization. The code will be available at {\\url{ https://github.com/yanglei18/SGV3D}}","sentences":["Roadside perception can greatly increase the safety of autonomous vehicles by extending their perception ability beyond the visual range and addressing blind spots.","However, current state-of-the-art vision-based roadside detection methods possess high accuracy on labeled scenes but have inferior performance on new scenes.","This is because roadside cameras remain stationary after installation and can only collect data from a single scene, resulting in the algorithm overfitting these roadside backgrounds and camera poses.","To address this issue, in this paper, we propose an innovative Scenario Generalization Framework for Vision-based Roadside 3D Object Detection, dubbed SGV3D. Specifically, we employ a Background-suppressed Module (BSM) to mitigate background overfitting in vision-centric pipelines by attenuating background features during the 2D to bird's-eye-view projection.","Furthermore, by introducing the Semi-supervised Data Generation Pipeline (SSDG) using unlabeled images from new scenes, diverse instance foregrounds with varying camera poses are generated, addressing the risk of overfitting specific camera poses.","We evaluate our method on two large-scale roadside benchmarks.","Our method surpasses all previous methods by a significant margin in new scenes, including +42.57% for vehicle, +5.87% for pedestrian, and +14.89% for cyclist compared to BEVHeight on the DAIR-V2X-I heterologous benchmark.","On the larger-scale Rope3D heterologous benchmark, we achieve notable gains of 14.48% for car and 12.41% for large vehicle.","We aspire to contribute insights on the exploration of roadside perception techniques, emphasizing their capability for scenario generalization.","The code will be available at {\\url{ https://github.com/yanglei18/SGV3D}}"],"url":"http://arxiv.org/abs/2401.16110v1"}
{"created":"2024-01-29 12:20:26","title":"A 2D Sinogram-Based Approach to Defect Localization in Computed Tomography","abstract":"The rise of deep learning has introduced a transformative era in the field of image processing, particularly in the context of computed tomography. Deep learning has made a significant contribution to the field of industrial Computed Tomography. However, many defect detection algorithms are applied directly to the reconstructed domain, often disregarding the raw sensor data. This paper shifts the focus to the use of sinograms. Within this framework, we present a comprehensive three-step deep learning algorithm, designed to identify and analyze defects within objects without resorting to image reconstruction. These three steps are defect segmentation, mask isolation, and defect analysis. We use a U-Net-based architecture for defect segmentation. Our method achieves the Intersection over Union of 92.02% on our simulated data, with an average position error of 1.3 pixels for defect detection on a 512-pixel-wide detector.","sentences":["The rise of deep learning has introduced a transformative era in the field of image processing, particularly in the context of computed tomography.","Deep learning has made a significant contribution to the field of industrial Computed Tomography.","However, many defect detection algorithms are applied directly to the reconstructed domain, often disregarding the raw sensor data.","This paper shifts the focus to the use of sinograms.","Within this framework, we present a comprehensive three-step deep learning algorithm, designed to identify and analyze defects within objects without resorting to image reconstruction.","These three steps are defect segmentation, mask isolation, and defect analysis.","We use a U-Net-based architecture for defect segmentation.","Our method achieves the Intersection over Union of 92.02% on our simulated data, with an average position error of 1.3 pixels for defect detection on a 512-pixel-wide detector."],"url":"http://arxiv.org/abs/2401.16104v1"}
{"created":"2024-01-29 12:20:17","title":"Flexible Parallel Neural Network Architecture Model for Early Prediction of Lithium Battery Life","abstract":"The early prediction of battery life (EPBL) is vital for enhancing the efficiency and extending the lifespan of lithium batteries. Traditional models with fixed architectures often encounter underfitting or overfitting issues due to the diverse data distributions in different EPBL tasks. An interpretable deep learning model of flexible parallel neural network (FPNN) is proposed, which includes an InceptionBlock, a 3D convolutional neural network (CNN), a 2D CNN, and a dual-stream network. The proposed model effectively extracts electrochemical features from video-like formatted data using the 3D CNN and achieves advanced multi-scale feature abstraction through the InceptionBlock. The FPNN can adaptively adjust the number of InceptionBlocks to flexibly handle tasks of varying complexity in EPBL. The test on the MIT dataset shows that the FPNN model achieves outstanding predictive accuracy in EPBL tasks, with MAPEs of 2.47%, 1.29%, 1.08%, and 0.88% when the input cyclic data volumes are 10, 20, 30, and 40, respectively. The interpretability of the FPNN is mainly reflected in its flexible unit structure and parameter selection: its diverse branching structure enables the model to capture features at different scales, thus allowing the machine to learn informative features. The approach presented herein provides an accurate, adaptable, and comprehensible solution for early life prediction of lithium batteries, opening new possibilities in the field of battery health monitoring.","sentences":["The early prediction of battery life (EPBL) is vital for enhancing the efficiency and extending the lifespan of lithium batteries.","Traditional models with fixed architectures often encounter underfitting or overfitting issues due to the diverse data distributions in different EPBL tasks.","An interpretable deep learning model of flexible parallel neural network (FPNN) is proposed, which includes an InceptionBlock, a 3D convolutional neural network (CNN), a 2D CNN, and a dual-stream network.","The proposed model effectively extracts electrochemical features from video-like formatted data using the 3D CNN and achieves advanced multi-scale feature abstraction through the InceptionBlock.","The FPNN can adaptively adjust the number of InceptionBlocks to flexibly handle tasks of varying complexity in EPBL.","The test on the MIT dataset shows that the FPNN model achieves outstanding predictive accuracy in EPBL tasks, with MAPEs of 2.47%, 1.29%, 1.08%, and 0.88% when the input cyclic data volumes are 10, 20, 30, and 40, respectively.","The interpretability of the FPNN is mainly reflected in its flexible unit structure and parameter selection: its diverse branching structure enables the model to capture features at different scales, thus allowing the machine to learn informative features.","The approach presented herein provides an accurate, adaptable, and comprehensible solution for early life prediction of lithium batteries, opening new possibilities in the field of battery health monitoring."],"url":"http://arxiv.org/abs/2401.16102v1"}
{"created":"2024-01-29 12:11:34","title":"Pushing the Limits: Concurrency Detection in Acyclic, Live, and 1-Safe Free-Choice Nets in $O\\big((P + T)^2\\big)$","abstract":"Concurrency is an important aspect of (Petri) nets to describe and simulate the behavior of complex systems. Knowing which places and transitions could be executed in parallel helps to understand nets and enables analysis techniques and the computation of other properties, such as causality, exclusivity, etc.. All techniques based on concurrency detection depend on the efficiency of this detection methodology. Kovalyov and Esparza have developed algorithms that compute all concurrent places in $O\\big((P+T)TP^2\\big)$ for live nets (where $P$ and $T$ are the numbers of places and transitions) and in $O\\big(P(P+T)^2\\big)$ for live free-choice nets. Although these algorithms have a reasonably good computational complexity, large numbers of concurrent pairs of nodes may still lead to long computation times. Furthermore, both algorithms cannot be parallelized without additional effort. This paper complements the palette of concurrency detection algorithms with the Concurrent Paths (CP) algorithm for safe, live, free-choice nets. The algorithm allows parallelization and has a worst-case computational complexity of $O\\big((P+T)^2\\big)$ for acyclic nets and of $O\\big(P^3+PT^2\\big)$ for cyclic nets. Although the computational complexity of cyclic nets has not improved, the evaluation shows the benefits of CP, especially, if the net contains many nodes in concurrency relation.","sentences":["Concurrency is an important aspect of (Petri) nets to describe and simulate the behavior of complex systems.","Knowing which places and transitions could be executed in parallel helps to understand nets and enables analysis techniques and the computation of other properties, such as causality, exclusivity, etc.. All techniques based on concurrency detection depend on the efficiency of this detection methodology.","Kovalyov and Esparza have developed algorithms that compute all concurrent places in $O\\big((P+T)TP^2\\big)$ for live nets (where $P$ and $T$ are the numbers of places and transitions) and in $O\\big(P(P+T)^2\\big)$ for live free-choice nets.","Although these algorithms have a reasonably good computational complexity, large numbers of concurrent pairs of nodes may still lead to long computation times.","Furthermore, both algorithms cannot be parallelized without additional effort.","This paper complements the palette of concurrency detection algorithms with the Concurrent Paths (CP) algorithm for safe, live, free-choice nets.","The algorithm allows parallelization and has a worst-case computational complexity of $O\\big((P+T)^2\\big)$ for acyclic nets and of $O\\big(P^3+PT^2\\big)$ for cyclic nets.","Although the computational complexity of cyclic nets has not improved, the evaluation shows the benefits of CP, especially, if the net contains many nodes in concurrency relation."],"url":"http://arxiv.org/abs/2401.16097v1"}
{"created":"2024-01-29 12:04:14","title":"Federated unsupervised random forest for privacy-preserving patient stratification","abstract":"In the realm of precision medicine, effective patient stratification and disease subtyping demand innovative methodologies tailored for multi-omics data. Clustering techniques applied to multi-omics data have become instrumental in identifying distinct subgroups of patients, enabling a finer-grained understanding of disease variability. This work establishes a powerful framework for advancing precision medicine through unsupervised random-forest-based clustering and federated computing. We introduce a novel multi-omics clustering approach utilizing unsupervised random-forests. The unsupervised nature of the random forest enables the determination of cluster-specific feature importance, unraveling key molecular contributors to distinct patient groups. Moreover, our methodology is designed for federated execution, a crucial aspect in the medical domain where privacy concerns are paramount. We have validated our approach on machine learning benchmark data sets as well as on cancer data from The Cancer Genome Atlas (TCGA). Our method is competitive with the state-of-the-art in terms of disease subtyping, but at the same time substantially improves the cluster interpretability. Experiments indicate that local clustering performance can be improved through federated computing.","sentences":["In the realm of precision medicine, effective patient stratification and disease subtyping demand innovative methodologies tailored for multi-omics data.","Clustering techniques applied to multi-omics data have become instrumental in identifying distinct subgroups of patients, enabling a finer-grained understanding of disease variability.","This work establishes a powerful framework for advancing precision medicine through unsupervised random-forest-based clustering and federated computing.","We introduce a novel multi-omics clustering approach utilizing unsupervised random-forests.","The unsupervised nature of the random forest enables the determination of cluster-specific feature importance, unraveling key molecular contributors to distinct patient groups.","Moreover, our methodology is designed for federated execution, a crucial aspect in the medical domain where privacy concerns are paramount.","We have validated our approach on machine learning benchmark data sets as well as on cancer data from The Cancer Genome Atlas (TCGA).","Our method is competitive with the state-of-the-art in terms of disease subtyping, but at the same time substantially improves the cluster interpretability.","Experiments indicate that local clustering performance can be improved through federated computing."],"url":"http://arxiv.org/abs/2401.16094v1"}
{"created":"2024-01-29 11:55:45","title":"Fairness in Algorithmic Recourse Through the Lens of Substantive Equality of Opportunity","abstract":"Algorithmic recourse -- providing recommendations to those affected negatively by the outcome of an algorithmic system on how they can take action and change that outcome -- has gained attention as a means of giving persons agency in their interactions with artificial intelligence (AI) systems. Recent work has shown that even if an AI decision-making classifier is ``fair'' (according to some reasonable criteria), recourse itself may be unfair due to differences in the initial circumstances of individuals, compounding disparities for marginalized populations and requiring them to exert more effort than others. There is a need to define more methods and metrics for evaluating fairness in recourse that span a range of normative views of the world, and specifically those that take into account time. Time is a critical element in recourse because the longer it takes an individual to act, the more the setting may change due to model or data drift.   This paper seeks to close this research gap by proposing two notions of fairness in recourse that are in normative alignment with substantive equality of opportunity, and that consider time. The first considers the (often repeated) effort individuals exert per successful recourse event, and the second considers time per successful recourse event. Building upon an agent-based framework for simulating recourse, this paper demonstrates how much effort is needed to overcome disparities in initial circumstances. We then proposes an intervention to improve the fairness of recourse by rewarding effort, and compare it to existing strategies.","sentences":["Algorithmic recourse -- providing recommendations to those affected negatively by the outcome of an algorithmic system on how they can take action and change that outcome -- has gained attention as a means of giving persons agency in their interactions with artificial intelligence (AI) systems.","Recent work has shown that even if an AI decision-making classifier is ``fair'' (according to some reasonable criteria), recourse itself may be unfair due to differences in the initial circumstances of individuals, compounding disparities for marginalized populations and requiring them to exert more effort than others.","There is a need to define more methods and metrics for evaluating fairness in recourse that span a range of normative views of the world, and specifically those that take into account time.","Time is a critical element in recourse because the longer it takes an individual to act, the more the setting may change due to model or data drift.   ","This paper seeks to close this research gap by proposing two notions of fairness in recourse that are in normative alignment with substantive equality of opportunity, and that consider time.","The first considers the (often repeated) effort individuals exert per successful recourse event, and the second considers time per successful recourse event.","Building upon an agent-based framework for simulating recourse, this paper demonstrates how much effort is needed to overcome disparities in initial circumstances.","We then proposes an intervention to improve the fairness of recourse by rewarding effort, and compare it to existing strategies."],"url":"http://arxiv.org/abs/2401.16088v1"}
{"created":"2024-01-29 11:52:45","title":"Non-Fluent Synthetic Target-Language Data Improve Neural Machine Translation","abstract":"When the amount of parallel sentences available to train a neural machine translation is scarce, a common practice is to generate new synthetic training samples from them. A number of approaches have been proposed to produce synthetic parallel sentences that are similar to those in the parallel data available. These approaches work under the assumption that non-fluent target-side synthetic training samples can be harmful and may deteriorate translation performance. Even so, in this paper we demonstrate that synthetic training samples with non-fluent target sentences can improve translation performance if they are used in a multilingual machine translation framework as if they were sentences in another language. We conducted experiments on ten low-resource and four high-resource translation tasks and found out that this simple approach consistently improves translation performance as compared to state-of-the-art methods for generating synthetic training samples similar to those found in corpora. Furthermore, this improvement is independent of the size of the original training corpus, the resulting systems are much more robust against domain shift and produce less hallucinations.","sentences":["When the amount of parallel sentences available to train a neural machine translation is scarce, a common practice is to generate new synthetic training samples from them.","A number of approaches have been proposed to produce synthetic parallel sentences that are similar to those in the parallel data available.","These approaches work under the assumption that non-fluent target-side synthetic training samples can be harmful and may deteriorate translation performance.","Even so, in this paper we demonstrate that synthetic training samples with non-fluent target sentences can improve translation performance if they are used in a multilingual machine translation framework as if they were sentences in another language.","We conducted experiments on ten low-resource and four high-resource translation tasks and found out that this simple approach consistently improves translation performance as compared to state-of-the-art methods for generating synthetic training samples similar to those found in corpora.","Furthermore, this improvement is independent of the size of the original training corpus, the resulting systems are much more robust against domain shift and produce less hallucinations."],"url":"http://arxiv.org/abs/2401.16086v1"}
{"created":"2024-01-29 11:13:18","title":"Neuromorphic Valence and Arousal Estimation","abstract":"Recognizing faces and their underlying emotions is an important aspect of biometrics. In fact, estimating emotional states from faces has been tackled from several angles in the literature. In this paper, we follow the novel route of using neuromorphic data to predict valence and arousal values from faces. Due to the difficulty of gathering event-based annotated videos, we leverage an event camera simulator to create the neuromorphic counterpart of an existing RGB dataset. We demonstrate that not only training models on simulated data can still yield state-of-the-art results in valence-arousal estimation, but also that our trained models can be directly applied to real data without further training to address the downstream task of emotion recognition. In the paper we propose several alternative models to solve the task, both frame-based and video-based.","sentences":["Recognizing faces and their underlying emotions is an important aspect of biometrics.","In fact, estimating emotional states from faces has been tackled from several angles in the literature.","In this paper, we follow the novel route of using neuromorphic data to predict valence and arousal values from faces.","Due to the difficulty of gathering event-based annotated videos, we leverage an event camera simulator to create the neuromorphic counterpart of an existing RGB dataset.","We demonstrate that not only training models on simulated data can still yield state-of-the-art results in valence-arousal estimation, but also that our trained models can be directly applied to real data without further training to address the downstream task of emotion recognition.","In the paper we propose several alternative models to solve the task, both frame-based and video-based."],"url":"http://arxiv.org/abs/2401.16058v1"}
{"created":"2024-01-29 10:22:45","title":"Domain adaptation strategies for 3D reconstruction of the lumbar spine using real fluoroscopy data","abstract":"This study tackles key obstacles in adopting surgical navigation in orthopedic surgeries, including time, cost, radiation, and workflow integration challenges. Recently, our work X23D showed an approach for generating 3D anatomical models of the spine from only a few intraoperative fluoroscopic images. This negates the need for conventional registration-based surgical navigation by creating a direct intraoperative 3D reconstruction of the anatomy. Despite these strides, the practical application of X23D has been limited by a domain gap between synthetic training data and real intraoperative images.   In response, we devised a novel data collection protocol for a paired dataset consisting of synthetic and real fluoroscopic images from the same perspectives. Utilizing this dataset, we refined our deep learning model via transfer learning, effectively bridging the domain gap between synthetic and real X-ray data. A novel style transfer mechanism also allows us to convert real X-rays to mirror the synthetic domain, enabling our in-silico-trained X23D model to achieve high accuracy in real-world settings.   Our results demonstrated that the refined model can rapidly generate accurate 3D reconstructions of the entire lumbar spine from as few as three intraoperative fluoroscopic shots. It achieved an 84% F1 score, matching the accuracy of our previous synthetic data-based research. Additionally, with a computational time of only 81.1 ms, our approach provides real-time capabilities essential for surgery integration.   Through examining ideal imaging setups and view angle dependencies, we've further confirmed our system's practicality and dependability in clinical settings. Our research marks a significant step forward in intraoperative 3D reconstruction, offering enhancements to surgical planning, navigation, and robotics.","sentences":["This study tackles key obstacles in adopting surgical navigation in orthopedic surgeries, including time, cost, radiation, and workflow integration challenges.","Recently, our work X23D showed an approach for generating 3D anatomical models of the spine from only a few intraoperative fluoroscopic images.","This negates the need for conventional registration-based surgical navigation by creating a direct intraoperative 3D reconstruction of the anatomy.","Despite these strides, the practical application of X23D has been limited by a domain gap between synthetic training data and real intraoperative images.   ","In response, we devised a novel data collection protocol for a paired dataset consisting of synthetic and real fluoroscopic images from the same perspectives.","Utilizing this dataset, we refined our deep learning model via transfer learning, effectively bridging the domain gap between synthetic and real X-ray data.","A novel style transfer mechanism also allows us to convert real X-rays to mirror the synthetic domain, enabling our in-silico-trained X23D model to achieve high accuracy in real-world settings.   ","Our results demonstrated that the refined model can rapidly generate accurate 3D reconstructions of the entire lumbar spine from as few as three intraoperative fluoroscopic shots.","It achieved an 84% F1 score, matching the accuracy of our previous synthetic data-based research.","Additionally, with a computational time of only 81.1 ms, our approach provides real-time capabilities essential for surgery integration.   ","Through examining ideal imaging setups and view angle dependencies, we've further confirmed our system's practicality and dependability in clinical settings.","Our research marks a significant step forward in intraoperative 3D reconstruction, offering enhancements to surgical planning, navigation, and robotics."],"url":"http://arxiv.org/abs/2401.16027v1"}
{"created":"2024-01-29 10:17:18","title":"Probabilistic Abduction for Visual Abstract Reasoning via Learning Rules in Vector-symbolic Architectures","abstract":"Abstract reasoning is a cornerstone of human intelligence, and replicating it with artificial intelligence (AI) presents an ongoing challenge. This study focuses on efficiently solving Raven's progressive matrices (RPM), a visual test for assessing abstract reasoning abilities, by using distributed computation and operators provided by vector-symbolic architectures (VSA). Instead of hard-coding the rule formulations associated with RPMs, our approach can learn the VSA rule formulations (hence the name Learn-VRF) with just one pass through the training data. Yet, our approach, with compact parameters, remains transparent and interpretable. Learn-VRF yields accurate predictions on I-RAVEN's in-distribution data, and exhibits strong out-of-distribution capabilities concerning unseen attribute-rule pairs, significantly outperforming pure connectionist baselines including large language models. Our code is available at https://github.com/IBM/learn-vector-symbolic-architectures-rule-formulations.","sentences":["Abstract reasoning is a cornerstone of human intelligence, and replicating it with artificial intelligence (AI) presents an ongoing challenge.","This study focuses on efficiently solving Raven's progressive matrices (RPM), a visual test for assessing abstract reasoning abilities, by using distributed computation and operators provided by vector-symbolic architectures (VSA).","Instead of hard-coding the rule formulations associated with RPMs, our approach can learn the VSA rule formulations (hence the name Learn-VRF) with just one pass through the training data.","Yet, our approach, with compact parameters, remains transparent and interpretable.","Learn-VRF yields accurate predictions on I-RAVEN's in-distribution data, and exhibits strong out-of-distribution capabilities concerning unseen attribute-rule pairs, significantly outperforming pure connectionist baselines including large language models.","Our code is available at https://github.com/IBM/learn-vector-symbolic-architectures-rule-formulations."],"url":"http://arxiv.org/abs/2401.16024v1"}
{"created":"2024-01-29 10:01:10","title":"SERL: A Software Suite for Sample-Efficient Robotic Reinforcement Learning","abstract":"In recent years, significant progress has been made in the field of robotic reinforcement learning (RL), enabling methods that handle complex image observations, train in the real world, and incorporate auxiliary data, such as demonstrations and prior experience. However, despite these advances, robotic RL remains hard to use. It is acknowledged among practitioners that the particular implementation details of these algorithms are often just as important (if not more so) for performance as the choice of algorithm. We posit that a significant challenge to widespread adoption of robotic RL, as well as further development of robotic RL methods, is the comparative inaccessibility of such methods. To address this challenge, we developed a carefully implemented library containing a sample efficient off-policy deep RL method, together with methods for computing rewards and resetting the environment, a high-quality controller for a widely-adopted robot, and a number of challenging example tasks. We provide this library as a resource for the community, describe its design choices, and present experimental results. Perhaps surprisingly, we find that our implementation can achieve very efficient learning, acquiring policies for PCB board assembly, cable routing, and object relocation between 25 to 50 minutes of training per policy on average, improving over state-of-the-art results reported for similar tasks in the literature. These policies achieve perfect or near-perfect success rates, extreme robustness even under perturbations, and exhibit emergent recovery and correction behaviors. We hope that these promising results and our high-quality open-source implementation will provide a tool for the robotics community to facilitate further developments in robotic RL. Our code, documentation, and videos can be found at https://serl-robot.github.io/","sentences":["In recent years, significant progress has been made in the field of robotic reinforcement learning (RL), enabling methods that handle complex image observations, train in the real world, and incorporate auxiliary data, such as demonstrations and prior experience.","However, despite these advances, robotic RL remains hard to use.","It is acknowledged among practitioners that the particular implementation details of these algorithms are often just as important (if not more so) for performance as the choice of algorithm.","We posit that a significant challenge to widespread adoption of robotic RL, as well as further development of robotic RL methods, is the comparative inaccessibility of such methods.","To address this challenge, we developed a carefully implemented library containing a sample efficient off-policy deep RL method, together with methods for computing rewards and resetting the environment, a high-quality controller for a widely-adopted robot, and a number of challenging example tasks.","We provide this library as a resource for the community, describe its design choices, and present experimental results.","Perhaps surprisingly, we find that our implementation can achieve very efficient learning, acquiring policies for PCB board assembly, cable routing, and object relocation between 25 to 50 minutes of training per policy on average, improving over state-of-the-art results reported for similar tasks in the literature.","These policies achieve perfect or near-perfect success rates, extreme robustness even under perturbations, and exhibit emergent recovery and correction behaviors.","We hope that these promising results and our high-quality open-source implementation will provide a tool for the robotics community to facilitate further developments in robotic RL.","Our code, documentation, and videos can be found at https://serl-robot.github.io/"],"url":"http://arxiv.org/abs/2401.16013v1"}
{"created":"2024-01-29 09:44:59","title":"LESSON: Multi-Label Adversarial False Data Injection Attack for Deep Learning Locational Detection","abstract":"Deep learning methods can not only detect false data injection attacks (FDIA) but also locate attacks of FDIA. Although adversarial false data injection attacks (AFDIA) based on deep learning vulnerabilities have been studied in the field of single-label FDIA detection, the adversarial attack and defense against multi-label FDIA locational detection are still not involved. To bridge this gap, this paper first explores the multi-label adversarial example attacks against multi-label FDIA locational detectors and proposes a general multi-label adversarial attack framework, namely muLti-labEl adverSarial falSe data injectiON attack (LESSON). The proposed LESSON attack framework includes three key designs, namely Perturbing State Variables, Tailored Loss Function Design, and Change of Variables, which can help find suitable multi-label adversarial perturbations within the physical constraints to circumvent both Bad Data Detection (BDD) and Neural Attack Location (NAL). Four typical LESSON attacks based on the proposed framework and two dimensions of attack objectives are examined, and the experimental results demonstrate the effectiveness of the proposed attack framework, posing serious and pressing security concerns in smart grids.","sentences":["Deep learning methods can not only detect false data injection attacks (FDIA) but also locate attacks of FDIA.","Although adversarial false data injection attacks (AFDIA) based on deep learning vulnerabilities have been studied in the field of single-label FDIA detection, the adversarial attack and defense against multi-label FDIA locational detection are still not involved.","To bridge this gap, this paper first explores the multi-label adversarial example attacks against multi-label FDIA locational detectors and proposes a general multi-label adversarial attack framework, namely muLti-labEl adverSarial falSe data injectiON attack (LESSON).","The proposed LESSON attack framework includes three key designs, namely Perturbing State Variables, Tailored Loss Function Design, and Change of Variables, which can help find suitable multi-label adversarial perturbations within the physical constraints to circumvent both Bad Data Detection (BDD) and Neural Attack Location (NAL).","Four typical LESSON attacks based on the proposed framework and two dimensions of attack objectives are examined, and the experimental results demonstrate the effectiveness of the proposed attack framework, posing serious and pressing security concerns in smart grids."],"url":"http://arxiv.org/abs/2401.16001v1"}
{"created":"2024-01-29 09:23:56","title":"Extracting and visualizing a new classification system for Colombia's National Administrative Department of Statistics. A visual analytics framework case study","abstract":"In a world filled with data, it is expected for a nation to take decisions informed by data. However, countries need to first collect and publish such data in a way meaningful for both citizens and policy makers. A good thematic classification could be instrumental in helping users navigate and find the right resources on a rich data repository as the one collected by Colombia's National Administrative Department of Statistics (DANE). The Visual Analytics Framework is a methodology for conducting visual analysis developed by T. Munzner et al. [T. Munzner, Visualization Analysis and Design, A K Peters Visualization Series, 1, 2014] that could help with this task. This paper presents a case study applying such framework conducted to help the DANE better visualize their data repository, and present a more understandable classification of it. It describes three main analysis tasks identified, the proposed solutions and the collection of insights generated from them.","sentences":["In a world filled with data, it is expected for a nation to take decisions informed by data.","However, countries need to first collect and publish such data in a way meaningful for both citizens and policy makers.","A good thematic classification could be instrumental in helping users navigate and find the right resources on a rich data repository as the one collected by Colombia's National Administrative Department of Statistics (DANE).","The Visual Analytics Framework is a methodology for conducting visual analysis developed by T. Munzner et al.","[T. Munzner, Visualization Analysis and Design, A K Peters Visualization Series, 1, 2014] that could help with this task.","This paper presents a case study applying such framework conducted to help the DANE better visualize their data repository, and present a more understandable classification of it.","It describes three main analysis tasks identified, the proposed solutions and the collection of insights generated from them."],"url":"http://arxiv.org/abs/2401.15994v1"}
{"created":"2024-01-29 09:17:51","title":"Hand-Centric Motion Refinement for 3D Hand-Object Interaction via Hierarchical Spatial-Temporal Modeling","abstract":"Hands are the main medium when people interact with the world. Generating proper 3D motion for hand-object interaction is vital for applications such as virtual reality and robotics. Although grasp tracking or object manipulation synthesis can produce coarse hand motion, this kind of motion is inevitably noisy and full of jitter. To address this problem, we propose a data-driven method for coarse motion refinement. First, we design a hand-centric representation to describe the dynamic spatial-temporal relation between hands and objects. Compared to the object-centric representation, our hand-centric representation is straightforward and does not require an ambiguous projection process that converts object-based prediction into hand motion. Second, to capture the dynamic clues of hand-object interaction, we propose a new architecture that models the spatial and temporal structure in a hierarchical manner. Extensive experiments demonstrate that our method outperforms previous methods by a noticeable margin.","sentences":["Hands are the main medium when people interact with the world.","Generating proper 3D motion for hand-object interaction is vital for applications such as virtual reality and robotics.","Although grasp tracking or object manipulation synthesis can produce coarse hand motion, this kind of motion is inevitably noisy and full of jitter.","To address this problem, we propose a data-driven method for coarse motion refinement.","First, we design a hand-centric representation to describe the dynamic spatial-temporal relation between hands and objects.","Compared to the object-centric representation, our hand-centric representation is straightforward and does not require an ambiguous projection process that converts object-based prediction into hand motion.","Second, to capture the dynamic clues of hand-object interaction, we propose a new architecture that models the spatial and temporal structure in a hierarchical manner.","Extensive experiments demonstrate that our method outperforms previous methods by a noticeable margin."],"url":"http://arxiv.org/abs/2401.15987v1"}
{"created":"2024-01-29 09:04:45","title":"Sample Weight Estimation Using Meta-Updates for Online Continual Learning","abstract":"The loss function plays an important role in optimizing the performance of a learning system. A crucial aspect of the loss function is the assignment of sample weights within a mini-batch during loss computation. In the context of continual learning (CL), most existing strategies uniformly treat samples when calculating the loss value, thereby assigning equal weights to each sample. While this approach can be effective in certain standard benchmarks, its optimal effectiveness, particularly in more complex scenarios, remains underexplored. This is particularly pertinent in training \"in the wild,\" such as with self-training, where labeling is automated using a reference model. This paper introduces the Online Meta-learning for Sample Importance (OMSI) strategy that approximates sample weights for a mini-batch in an online CL stream using an inner- and meta-update mechanism. This is done by first estimating sample weight parameters for each sample in the mini-batch, then, updating the model with the adapted sample weights. We evaluate OMSI in two distinct experimental settings. First, we show that OMSI enhances both learning and retained accuracy in a controlled noisy-labeled data stream. Then, we test the strategy in three standard benchmarks and compare it with other popular replay-based strategies. This research aims to foster the ongoing exploration in the area of self-adaptive CL.","sentences":["The loss function plays an important role in optimizing the performance of a learning system.","A crucial aspect of the loss function is the assignment of sample weights within a mini-batch during loss computation.","In the context of continual learning (CL), most existing strategies uniformly treat samples when calculating the loss value, thereby assigning equal weights to each sample.","While this approach can be effective in certain standard benchmarks, its optimal effectiveness, particularly in more complex scenarios, remains underexplored.","This is particularly pertinent in training \"in the wild,\" such as with self-training, where labeling is automated using a reference model.","This paper introduces the Online Meta-learning for Sample Importance (OMSI) strategy that approximates sample weights for a mini-batch in an online CL stream using an inner- and meta-update mechanism.","This is done by first estimating sample weight parameters for each sample in the mini-batch, then, updating the model with the adapted sample weights.","We evaluate OMSI in two distinct experimental settings.","First, we show that OMSI enhances both learning and retained accuracy in a controlled noisy-labeled data stream.","Then, we test the strategy in three standard benchmarks and compare it with other popular replay-based strategies.","This research aims to foster the ongoing exploration in the area of self-adaptive CL."],"url":"http://arxiv.org/abs/2401.15973v1"}
{"created":"2024-01-29 08:59:05","title":"HEQuant: Marrying Homomorphic Encryption and Quantization for Communication-Efficient Private Inference","abstract":"Secure two-party computation with homomorphic encryption (HE) protects data privacy with a formal security guarantee but suffers from high communication overhead. While previous works, e.g., Cheetah, Iron, etc, have proposed efficient HE-based protocols for different neural network (NN) operations, they still assume high precision, e.g., fixed point 37 bit, for the NN operations and ignore NNs' native robustness against quantization error. In this paper, we propose HEQuant, which features low-precision-quantization-aware optimization for the HE-based protocols. We observe the benefit of a naive combination of quantization and HE quickly saturates as bit precision goes down. Hence, to further improve communication efficiency, we propose a series of optimizations, including an intra-coefficient packing algorithm and a quantization-aware tiling algorithm, to simultaneously reduce the number and precision of the transferred data. Compared with prior-art HE-based protocols, e.g., CrypTFlow2, Cheetah, Iron, etc, HEQuant achieves $3.5\\sim 23.4\\times$ communication reduction and $3.0\\sim 9.3\\times$ latency reduction. Meanwhile, when compared with prior-art network optimization frameworks, e.g., SENet, SNL, etc, HEQuant also achieves $3.1\\sim 3.6\\times$ communication reduction.","sentences":["Secure two-party computation with homomorphic encryption (HE) protects data privacy with a formal security guarantee but suffers from high communication overhead.","While previous works, e.g., Cheetah, Iron, etc, have proposed efficient HE-based protocols for different neural network (NN) operations, they still assume high precision, e.g., fixed point 37 bit, for the NN operations and ignore NNs' native robustness against quantization error.","In this paper, we propose HEQuant, which features low-precision-quantization-aware optimization for the HE-based protocols.","We observe the benefit of a naive combination of quantization and HE quickly saturates as bit precision goes down.","Hence, to further improve communication efficiency, we propose a series of optimizations, including an intra-coefficient packing algorithm and a quantization-aware tiling algorithm, to simultaneously reduce the number and precision of the transferred data.","Compared with prior-art HE-based protocols, e.g., CrypTFlow2, Cheetah, Iron, etc, HEQuant achieves $3.5\\sim 23.4\\times$ communication reduction and $3.0\\sim 9.3\\times$ latency reduction.","Meanwhile, when compared with prior-art network optimization frameworks, e.g., SENet, SNL, etc, HEQuant also achieves $3.1\\sim 3.6\\times$ communication reduction."],"url":"http://arxiv.org/abs/2401.15970v1"}
{"created":"2024-01-29 08:49:53","title":"Spatio-Temporal Attention Graph Neural Network for Remaining Useful Life Prediction","abstract":"Remaining useful life prediction plays a crucial role in the health management of industrial systems. Given the increasing complexity of systems, data-driven predictive models have attracted significant research interest. Upon reviewing the existing literature, it appears that many studies either do not fully integrate both spatial and temporal features or employ only a single attention mechanism. Furthermore, there seems to be inconsistency in the choice of data normalization methods, particularly concerning operating conditions, which might influence predictive performance. To bridge these observations, this study presents the Spatio-Temporal Attention Graph Neural Network. Our model combines graph neural networks and temporal convolutional neural networks for spatial and temporal feature extraction, respectively. The cascade of these extractors, combined with multi-head attention mechanisms for both spatio-temporal dimensions, aims to improve predictive precision and refine model explainability. Comprehensive experiments were conducted on the C-MAPSS dataset to evaluate the impact of unified versus clustering normalization. The findings suggest that our model performs state-of-the-art results using only the unified normalization. Additionally, when dealing with datasets with multiple operating conditions, cluster normalization enhances the performance of our proposed model by up to 27%.","sentences":["Remaining useful life prediction plays a crucial role in the health management of industrial systems.","Given the increasing complexity of systems, data-driven predictive models have attracted significant research interest.","Upon reviewing the existing literature, it appears that many studies either do not fully integrate both spatial and temporal features or employ only a single attention mechanism.","Furthermore, there seems to be inconsistency in the choice of data normalization methods, particularly concerning operating conditions, which might influence predictive performance.","To bridge these observations, this study presents the Spatio-Temporal Attention Graph Neural Network.","Our model combines graph neural networks and temporal convolutional neural networks for spatial and temporal feature extraction, respectively.","The cascade of these extractors, combined with multi-head attention mechanisms for both spatio-temporal dimensions, aims to improve predictive precision and refine model explainability.","Comprehensive experiments were conducted on the C-MAPSS dataset to evaluate the impact of unified versus clustering normalization.","The findings suggest that our model performs state-of-the-art results using only the unified normalization.","Additionally, when dealing with datasets with multiple operating conditions, cluster normalization enhances the performance of our proposed model by up to 27%."],"url":"http://arxiv.org/abs/2401.15964v1"}
{"created":"2024-01-29 08:46:05","title":"EchoPFL: Asynchronous Personalized Federated Learning on Mobile Devices with On-Demand Staleness Control","abstract":"The rise of mobile devices with abundant sensory data and local computing capabilities has driven the trend of federated learning (FL) on these devices. And personalized FL (PFL) emerges to train specific deep models for each mobile device to address data heterogeneity and varying performance preferences. However, mobile training times vary significantly, resulting in either delay (when waiting for slower devices for aggregation) or accuracy decline (when aggregation proceeds without waiting). In response, we propose a shift towards asynchronous PFL, where the server aggregates updates as soon as they are available. Nevertheless, existing asynchronous protocols are unfit for PFL because they are devised for federated training of a single global model. They suffer from slow convergence and decreased accuracy when confronted with severe data heterogeneity prevalent in PFL. Furthermore, they often exclude slower devices for staleness control, which notably compromises accuracy when these devices possess critical personalized data. Therefore, we propose EchoPFL, a coordination mechanism for asynchronous PFL. Central to EchoPFL is to include updates from all mobile devices regardless of their latency. To cope with the inevitable staleness from slow devices, EchoPFL revisits model broadcasting. It intelligently converts the unscalable broadcast to on-demand broadcast, leveraging the asymmetrical bandwidth in wireless networks and the dynamic clustering-based PFL. Experiments show that compared to status quo approaches, EchoPFL achieves a reduction of up to 88.2% in convergence time, an improvement of up to 46% in accuracy, and a decrease of 37% in communication costs","sentences":["The rise of mobile devices with abundant sensory data and local computing capabilities has driven the trend of federated learning (FL) on these devices.","And personalized FL (PFL) emerges to train specific deep models for each mobile device to address data heterogeneity and varying performance preferences.","However, mobile training times vary significantly, resulting in either delay (when waiting for slower devices for aggregation) or accuracy decline (when aggregation proceeds without waiting).","In response, we propose a shift towards asynchronous PFL, where the server aggregates updates as soon as they are available.","Nevertheless, existing asynchronous protocols are unfit for PFL because they are devised for federated training of a single global model.","They suffer from slow convergence and decreased accuracy when confronted with severe data heterogeneity prevalent in PFL.","Furthermore, they often exclude slower devices for staleness control, which notably compromises accuracy when these devices possess critical personalized data.","Therefore, we propose EchoPFL, a coordination mechanism for asynchronous PFL.","Central to EchoPFL is to include updates from all mobile devices regardless of their latency.","To cope with the inevitable staleness from slow devices, EchoPFL revisits model broadcasting.","It intelligently converts the unscalable broadcast to on-demand broadcast, leveraging the asymmetrical bandwidth in wireless networks and the dynamic clustering-based PFL.","Experiments show that compared to status quo approaches, EchoPFL achieves a reduction of up to 88.2% in convergence time, an improvement of up to 46% in accuracy, and a decrease of 37% in communication costs"],"url":"http://arxiv.org/abs/2401.15960v1"}
{"created":"2024-01-29 08:41:45","title":"Scalable Federated Unlearning via Isolated and Coded Sharding","abstract":"Federated unlearning has emerged as a promising paradigm to erase the client-level data effect without affecting the performance of collaborative learning models. However, the federated unlearning process often introduces extensive storage overhead and consumes substantial computational resources, thus hindering its implementation in practice. To address this issue, this paper proposes a scalable federated unlearning framework based on isolated sharding and coded computing. We first divide distributed clients into multiple isolated shards across stages to reduce the number of clients being affected. Then, to reduce the storage overhead of the central server, we develop a coded computing mechanism by compressing the model parameters across different shards. In addition, we provide the theoretical analysis of time efficiency and storage effectiveness for the isolated and coded sharding. Finally, extensive experiments on two typical learning tasks, i.e., classification and generation, demonstrate that our proposed framework can achieve better performance than three state-of-the-art frameworks in terms of accuracy, retraining time, storage overhead, and F1 scores for resisting membership inference attacks.","sentences":["Federated unlearning has emerged as a promising paradigm to erase the client-level data effect without affecting the performance of collaborative learning models.","However, the federated unlearning process often introduces extensive storage overhead and consumes substantial computational resources, thus hindering its implementation in practice.","To address this issue, this paper proposes a scalable federated unlearning framework based on isolated sharding and coded computing.","We first divide distributed clients into multiple isolated shards across stages to reduce the number of clients being affected.","Then, to reduce the storage overhead of the central server, we develop a coded computing mechanism by compressing the model parameters across different shards.","In addition, we provide the theoretical analysis of time efficiency and storage effectiveness for the isolated and coded sharding.","Finally, extensive experiments on two typical learning tasks, i.e., classification and generation, demonstrate that our proposed framework can achieve better performance than three state-of-the-art frameworks in terms of accuracy, retraining time, storage overhead, and F1 scores for resisting membership inference attacks."],"url":"http://arxiv.org/abs/2401.15957v1"}
{"created":"2024-01-29 08:41:02","title":"MobFuzz: Adaptive Multi-objective Optimization in Gray-box Fuzzing","abstract":"Coverage-guided gray-box fuzzing (CGF) is an efficient software testing technique. There are usually multiple objectives to optimize in CGF. However, existing CGF meth- ods cannot successfully find the optimal values for multiple objectives simultaneously. In this paper, we propose a gray-box fuzzer for multi-objective optimization (MOO) called MobFuzz. We model the multi-objective optimization process as a multi- player multi-armed bandit (MPMAB). First, it adaptively selects the objective combination that contains the most appropriate objectives for the current situation. Second, our model deals with the power schedule, which adaptively allocates energy to the seeds under the chosen objective combination. In MobFuzz, we propose an evolutionary algorithm called NIC to optimize our chosen objectives simultaneously without incurring additional performance overhead. To prove the effectiveness of MobFuzz, we conduct experiments on 12 real-world programs and the MAGMA data set. Experiment results show that multi-objective optimization in MobFuzz outperforms single-objective fuzzing in the baseline fuzzers. In contrast to them, MobFuzz can select the optimal objective combination and increase the values of multiple objectives up to 107%, with at most a 55% reduction in the energy consumption. Moreover, MobFuzz has up to 6% more program coverage and finds 3x more unique bugs than the baseline fuzzers. The NIC algorithm has at least a 2x improvement with a performance overhead of approximately 3%.","sentences":["Coverage-guided gray-box fuzzing (CGF) is an efficient software testing technique.","There are usually multiple objectives to optimize in CGF.","However, existing CGF meth- ods cannot successfully find the optimal values for multiple objectives simultaneously.","In this paper, we propose a gray-box fuzzer for multi-objective optimization (MOO) called MobFuzz.","We model the multi-objective optimization process as a multi- player multi-armed bandit (MPMAB).","First, it adaptively selects the objective combination that contains the most appropriate objectives for the current situation.","Second, our model deals with the power schedule, which adaptively allocates energy to the seeds under the chosen objective combination.","In MobFuzz, we propose an evolutionary algorithm called NIC to optimize our chosen objectives simultaneously without incurring additional performance overhead.","To prove the effectiveness of MobFuzz, we conduct experiments on 12 real-world programs and the MAGMA data set.","Experiment results show that multi-objective optimization in MobFuzz outperforms single-objective fuzzing in the baseline fuzzers.","In contrast to them, MobFuzz can select the optimal objective combination and increase the values of multiple objectives up to 107%, with at most a 55% reduction in the energy consumption.","Moreover, MobFuzz has up to 6% more program coverage and finds 3x more unique bugs than the baseline fuzzers.","The NIC algorithm has at least a 2x improvement with a performance overhead of approximately 3%."],"url":"http://arxiv.org/abs/2401.15956v1"}
{"created":"2024-01-29 08:27:31","title":"A Class-aware Optimal Transport Approach with Higher-Order Moment Matching for Unsupervised Domain Adaptation","abstract":"Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain. In this paper, we introduce a novel approach called class-aware optimal transport (OT), which measures the OT distance between a distribution over the source class-conditional distributions and a mixture of source and target data distribution. Our class-aware OT leverages a cost function that determines the matching extent between a given data example and a source class-conditional distribution. By optimizing this cost function, we find the optimal matching between target examples and source class-conditional distributions, effectively addressing the data and label shifts that occur between the two domains. To handle the class-aware OT efficiently, we propose an amortization solution that employs deep neural networks to formulate the transportation probabilities and the cost function. Additionally, we propose minimizing class-aware Higher-order Moment Matching (HMM) to align the corresponding class regions on the source and target domains. The class-aware HMM component offers an economical computational approach for accurately evaluating the HMM distance between the two distributions. Extensive experiments on benchmark datasets demonstrate that our proposed method significantly outperforms existing state-of-the-art baselines.","sentences":["Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain.","In this paper, we introduce a novel approach called class-aware optimal transport (OT), which measures the OT distance between a distribution over the source class-conditional distributions and a mixture of source and target data distribution.","Our class-aware OT leverages a cost function that determines the matching extent between a given data example and a source class-conditional distribution.","By optimizing this cost function, we find the optimal matching between target examples and source class-conditional distributions, effectively addressing the data and label shifts that occur between the two domains.","To handle the class-aware OT efficiently, we propose an amortization solution that employs deep neural networks to formulate the transportation probabilities and the cost function.","Additionally, we propose minimizing class-aware Higher-order Moment Matching (HMM) to align the corresponding class regions on the source and target domains.","The class-aware HMM component offers an economical computational approach for accurately evaluating the HMM distance between the two distributions.","Extensive experiments on benchmark datasets demonstrate that our proposed method significantly outperforms existing state-of-the-art baselines."],"url":"http://arxiv.org/abs/2401.15952v1"}
{"created":"2024-01-29 08:13:51","title":"AdvNF: Reducing Mode Collapse in Conditional Normalising Flows using Adversarial Learning","abstract":"Deep generative models complement Markov-chain-Monte-Carlo methods for efficiently sampling from high-dimensional distributions. Among these methods, explicit generators, such as Normalising Flows (NFs), in combination with the Metropolis Hastings algorithm have been extensively applied to get unbiased samples from target distributions. We systematically study central problems in conditional NFs, such as high variance, mode collapse and data efficiency. We propose adversarial training for NFs to ameliorate these problems. Experiments are conducted with low-dimensional synthetic datasets and XY spin models in two spatial dimensions.","sentences":["Deep generative models complement Markov-chain-Monte-Carlo methods for efficiently sampling from high-dimensional distributions.","Among these methods, explicit generators, such as Normalising Flows (NFs), in combination with the Metropolis Hastings algorithm have been extensively applied to get unbiased samples from target distributions.","We systematically study central problems in conditional NFs, such as high variance, mode collapse and data efficiency.","We propose adversarial training for NFs to ameliorate these problems.","Experiments are conducted with low-dimensional synthetic datasets and XY spin models in two spatial dimensions."],"url":"http://arxiv.org/abs/2401.15948v1"}
{"created":"2024-01-29 08:06:33","title":"Generating Multi-Center Classifier via Conditional Gaussian Distribution","abstract":"The linear classifier is widely used in various image classification tasks. It works by optimizing the distance between a sample and its corresponding class center. However, in real-world data, one class can contain several local clusters, e.g., birds of different poses. To address this complexity, we propose a novel multi-center classifier. Different from the vanilla linear classifier, our proposal is established on the assumption that the deep features of the training set follow a Gaussian Mixture distribution. Specifically, we create a conditional Gaussian distribution for each class and then sample multiple sub-centers from that distribution to extend the linear classifier. This approach allows the model to capture intra-class local structures more efficiently. In addition, at test time we set the mean of the conditional Gaussian distribution as the class center of the linear classifier and follow the vanilla linear classifier outputs, thus requiring no additional parameters or computational overhead. Extensive experiments on image classification show that the proposed multi-center classifier is a powerful alternative to widely used linear classifiers. Code available at https://github.com/ZheminZhang1/MultiCenter-Classifier.","sentences":["The linear classifier is widely used in various image classification tasks.","It works by optimizing the distance between a sample and its corresponding class center.","However, in real-world data, one class can contain several local clusters, e.g., birds of different poses.","To address this complexity, we propose a novel multi-center classifier.","Different from the vanilla linear classifier, our proposal is established on the assumption that the deep features of the training set follow a Gaussian Mixture distribution.","Specifically, we create a conditional Gaussian distribution for each class and then sample multiple sub-centers from that distribution to extend the linear classifier.","This approach allows the model to capture intra-class local structures more efficiently.","In addition, at test time we set the mean of the conditional Gaussian distribution as the class center of the linear classifier and follow the vanilla linear classifier outputs, thus requiring no additional parameters or computational overhead.","Extensive experiments on image classification show that the proposed multi-center classifier is a powerful alternative to widely used linear classifiers.","Code available at https://github.com/ZheminZhang1/MultiCenter-Classifier."],"url":"http://arxiv.org/abs/2401.15942v1"}
{"created":"2024-01-29 08:01:22","title":"Knowledge-Aware Code Generation with Large Language Models","abstract":"Large Language Models (LLMs) perform well on basic programming problems. However, they encounter challenges when dealing with complex tasks involving the use of diverse algorithmic and data structure skills, particularly programming competition-level problems. Notably, ChatGPT exhibits proficient performance on problems it has encountered during its pre-training phase, but this performance deteriorates when faced with novel problems. Consequently, enhancing the ability of LLMs to address unfamiliar problems has emerged as a pivotal research focus. The problem-solving process of LLMs mirrors human programmers' approach to a certain extent. When confronted with new programming tasks, human programmers engage in task planning and code writing with the previously acquired knowledge about algorithms and data structures. Despite having learned such knowledge, LLMs struggle to effectively apply it when faced with specific new problems. To address this issue, we constructed a novel dataset, CodeF, which contains a portion of programming problems that ChatGPT has not previously encountered. Furthermore, we developed a Knowledge Library tailored for Python programming contest problems and introduced the concept of Knowledge-Aware Code Generation (KareCoder). KareCoder bolsters the models' understanding and problem-solving capabilities by integrating prompt and knowledge from the library into the LLMs' code generation reasoning process, especially on Pass@1 metrics. Upon testing on the CodeF and APPS datasets, KareCoder demonstrated outstanding performance in handling novel problems previously unencountered by LLMs. In contrast with the code directly generated by ChatGPT, KareCoder achieved a relative improvement of 23.3% on the Pass@1 metric on the CodeF post2021-9 dataset. Additionally, it performs well compared to other methods when dealing with problems that LLMs have previously encountered.","sentences":["Large Language Models (LLMs) perform well on basic programming problems.","However, they encounter challenges when dealing with complex tasks involving the use of diverse algorithmic and data structure skills, particularly programming competition-level problems.","Notably, ChatGPT exhibits proficient performance on problems it has encountered during its pre-training phase, but this performance deteriorates when faced with novel problems.","Consequently, enhancing the ability of LLMs to address unfamiliar problems has emerged as a pivotal research focus.","The problem-solving process of LLMs mirrors human programmers' approach to a certain extent.","When confronted with new programming tasks, human programmers engage in task planning and code writing with the previously acquired knowledge about algorithms and data structures.","Despite having learned such knowledge, LLMs struggle to effectively apply it when faced with specific new problems.","To address this issue, we constructed a novel dataset, CodeF, which contains a portion of programming problems that ChatGPT has not previously encountered.","Furthermore, we developed a Knowledge Library tailored for Python programming contest problems and introduced the concept of Knowledge-Aware Code Generation (KareCoder).","KareCoder bolsters the models' understanding and problem-solving capabilities by integrating prompt and knowledge from the library into the LLMs' code generation reasoning process, especially on Pass@1 metrics.","Upon testing on the CodeF and APPS datasets, KareCoder demonstrated outstanding performance in handling novel problems previously unencountered by LLMs.","In contrast with the code directly generated by ChatGPT, KareCoder achieved a relative improvement of 23.3% on the Pass@1 metric on the CodeF post2021-9 dataset.","Additionally, it performs well compared to other methods when dealing with problems that LLMs have previously encountered."],"url":"http://arxiv.org/abs/2401.15940v1"}
{"created":"2024-01-29 07:58:46","title":"Correcting a Single Deletion in Reads from a Nanopore Sequencer","abstract":"Owing to its several merits over other DNA sequencing technologies, nanopore sequencers hold an immense potential to revolutionize the efficiency of DNA storage systems. However, their higher error rates necessitate further research to devise practical and efficient coding schemes that would allow accurate retrieval of the data stored. Our work takes a step in this direction by adopting a simplified model of the nanopore sequencer inspired by Mao \\emph{et al.}, which incorporates some of its physical aspects. This channel model can be viewed as a sliding window of length $\\ell$ that passes over the incoming input sequence and produces the $L_1$-weight of the enclosed $\\ell$ bits, while shifting by one position at each time step. The resulting $(\\ell+1)$-ary vector, referred to as the $\\ell$-\\emph{read vector}, is susceptible to deletion errors due to imperfections inherent in the sequencing process. We establish that at least $\\log n - \\ell$ bits of redundancy are needed to correct a single deletion. An error-correcting code that is optimal up to an additive constant, is also proposed. Furthermore, we find that for $\\ell \\geq 2$, reconstruction from two distinct noisy $\\ell$-read vectors can be accomplished without any redundancy, and provide a suitable reconstruction algorithm to this effect.","sentences":["Owing to its several merits over other DNA sequencing technologies, nanopore sequencers hold an immense potential to revolutionize the efficiency of DNA storage systems.","However, their higher error rates necessitate further research to devise practical and efficient coding schemes that would allow accurate retrieval of the data stored.","Our work takes a step in this direction by adopting a simplified model of the nanopore sequencer inspired by Mao \\emph{et al.}, which incorporates some of its physical aspects.","This channel model can be viewed as a sliding window of length $\\ell$ that passes over the incoming input sequence and produces the $L_1$-weight of the enclosed $\\ell$ bits, while shifting by one position at each time step.","The resulting $(\\ell+1)$-ary vector, referred to as the $\\ell$-\\emph{read vector}, is susceptible to deletion errors due to imperfections inherent in the sequencing process.","We establish that at least $\\log n - \\ell$ bits of redundancy are needed to correct a single deletion.","An error-correcting code that is optimal up to an additive constant, is also proposed.","Furthermore, we find that for $\\ell \\geq 2$, reconstruction from two distinct noisy $\\ell$-read vectors can be accomplished without any redundancy, and provide a suitable reconstruction algorithm to this effect."],"url":"http://arxiv.org/abs/2401.15939v1"}
{"created":"2024-01-29 07:44:09","title":"HICH Image/Text (HICH-IT): Comprehensive Text and Image Datasets for Hypertensive Intracerebral Hemorrhage Research","abstract":"In this paper, we introduce a new multimodal dataset in the medical field of hypertensive intracerebral hemorrhage(HICH), called as HICH-IT, which includes both textual information and head CT images. This dataset is designed to enhance the accuracy of artificial intelligence in the diagnosis and treatment of HICH. This dataset, built upon the foundation of standard text and image data, incorporates specific annotations within the text data, extracting key content from the text information, and categorizes the annotation content of imaging data into four types: brain midline, hematoma, left cerebral ventricle, and right cerebral ventricle. HICH-IT aims to be a foundational dataset for feature learning in image segmentation tasks and named entity recognition. To further understand the dataset, we have trained deep learning algorithms to observe the performance. The pretrained models have been released at both www.daip.club and github.com/Deep-AI-Application-DAIP. The dataset has been uploaded to https://github.com/CYBUS123456/HICH-IT-Datasets.   Index Terms-HICH, Deep learning, Intraparenchymal hemorrhage, named entity recognition, novel dataset","sentences":["In this paper, we introduce a new multimodal dataset in the medical field of hypertensive intracerebral hemorrhage(HICH), called as HICH-IT, which includes both textual information and head CT images.","This dataset is designed to enhance the accuracy of artificial intelligence in the diagnosis and treatment of HICH.","This dataset, built upon the foundation of standard text and image data, incorporates specific annotations within the text data, extracting key content from the text information, and categorizes the annotation content of imaging data into four types: brain midline, hematoma, left cerebral ventricle, and right cerebral ventricle.","HICH-IT aims to be a foundational dataset for feature learning in image segmentation tasks and named entity recognition.","To further understand the dataset, we have trained deep learning algorithms to observe the performance.","The pretrained models have been released at both www.daip.club and github.com/Deep-AI-Application-DAIP.","The dataset has been uploaded to https://github.com/CYBUS123456/HICH-IT-Datasets.   ","Index Terms-HICH, Deep learning, Intraparenchymal hemorrhage, named entity recognition, novel dataset"],"url":"http://arxiv.org/abs/2401.15934v1"}
{"created":"2024-01-29 07:31:12","title":"Energy-Aware Service Offloading for Semantic Communications in Wireless Networks","abstract":"Today, wireless networks are becoming responsible for serving intelligent applications, such as extended reality and metaverse, holographic telepresence, autonomous transportation, and collaborative robots. Although current fifth-generation (5G) networks can provide high data rates in terms of Gigabytes/second, they cannot cope with the high demands of the aforementioned applications, especially in terms of the size of the high-quality live videos and images that need to be communicated in real-time. Therefore, with the help of artificial intelligence (AI)-based future sixth-generation (6G) networks, the semantic communication concept can provide the services demanded by these applications. Unlike Shannon's classical information theory, semantic communication urges the use of the semantics (meaningful contents) of the data in designing more efficient data communication schemes. Hence, in this paper, we model semantic communication as an energy minimization framework in heterogeneous wireless networks with respect to delay and quality-of-service constraints. Then, we propose a sub-optimal solution to the NP-hard combinatorial mixed-integer nonlinear programming problem (MINLP) by utilizing efficient techniques such as discrete optimization variables' relaxation. In addition, AI-based autoencoder and classifier are trained and deployed to perform semantic extraction, reconstruction, and classification services. Finally, we compare our proposed sub-optimal solution with different state-of-the-art methods, and the obtained results demonstrate its superiority.","sentences":["Today, wireless networks are becoming responsible for serving intelligent applications, such as extended reality and metaverse, holographic telepresence, autonomous transportation, and collaborative robots.","Although current fifth-generation (5G) networks can provide high data rates in terms of Gigabytes/second, they cannot cope with the high demands of the aforementioned applications, especially in terms of the size of the high-quality live videos and images that need to be communicated in real-time.","Therefore, with the help of artificial intelligence (AI)-based future sixth-generation (6G) networks, the semantic communication concept can provide the services demanded by these applications.","Unlike Shannon's classical information theory, semantic communication urges the use of the semantics (meaningful contents) of the data in designing more efficient data communication schemes.","Hence, in this paper, we model semantic communication as an energy minimization framework in heterogeneous wireless networks with respect to delay and quality-of-service constraints.","Then, we propose a sub-optimal solution to the NP-hard combinatorial mixed-integer nonlinear programming problem (MINLP) by utilizing efficient techniques such as discrete optimization variables' relaxation.","In addition, AI-based autoencoder and classifier are trained and deployed to perform semantic extraction, reconstruction, and classification services.","Finally, we compare our proposed sub-optimal solution with different state-of-the-art methods, and the obtained results demonstrate its superiority."],"url":"http://arxiv.org/abs/2401.15924v1"}
{"created":"2024-01-29 07:15:26","title":"A New Framework to Predict and Visualize Technology Acceptance: A Case Study of Shared Autonomous Vehicles","abstract":"The burgeoning field of Shared Autonomous Vehicles (SAVs) presents transformative potential for the transport sector, subject to public acceptance. Traditional acceptance models, primarily reliant on Structural Equation Modelling (SEM), often fall short of capturing the complex, non-linear dynamics underlying this acceptance. To address these limitations, this paper proposes a Machine Learning (ML) approach to predict public acceptance of SAVs and employs a chord diagram to visualize the influence of different predictors. This approach reveals nuanced, non-linear relationships between factors at both macro and micro levels, and identifies attitude as the primary predictor of SAV usage intention, followed by perceived risk, perceived usefulness, trust, and perceived ease of use. The framework also uncovers divergent perceptions of these factors among SAV adopters and non-adopters, providing granular insights for strategic initiatives to enhance SAV acceptance. Using SAV acceptance as a case study, our findings contribute a novel, machine learning-based perspective to the discourse on technology acceptance, underscoring the importance of nuanced, data-driven approaches in understanding and fostering public acceptance of emerging transport technologies.","sentences":["The burgeoning field of Shared Autonomous Vehicles (SAVs) presents transformative potential for the transport sector, subject to public acceptance.","Traditional acceptance models, primarily reliant on Structural Equation Modelling (SEM), often fall short of capturing the complex, non-linear dynamics underlying this acceptance.","To address these limitations, this paper proposes a Machine Learning (ML) approach to predict public acceptance of SAVs and employs a chord diagram to visualize the influence of different predictors.","This approach reveals nuanced, non-linear relationships between factors at both macro and micro levels, and identifies attitude as the primary predictor of SAV usage intention, followed by perceived risk, perceived usefulness, trust, and perceived ease of use.","The framework also uncovers divergent perceptions of these factors among SAV adopters and non-adopters, providing granular insights for strategic initiatives to enhance SAV acceptance.","Using SAV acceptance as a case study, our findings contribute a novel, machine learning-based perspective to the discourse on technology acceptance, underscoring the importance of nuanced, data-driven approaches in understanding and fostering public acceptance of emerging transport technologies."],"url":"http://arxiv.org/abs/2401.15921v1"}
{"created":"2024-01-29 07:04:48","title":"Blockchain-enabled Trustworthy Federated Unlearning","abstract":"Federated unlearning is a promising paradigm for protecting the data ownership of distributed clients. It allows central servers to remove historical data effects within the machine learning model as well as address the \"right to be forgotten\" issue in federated learning. However, existing works require central servers to retain the historical model parameters from distributed clients, such that allows the central server to utilize these parameters for further training even, after the clients exit the training process. To address this issue, this paper proposes a new blockchain-enabled trustworthy federated unlearning framework. We first design a proof of federated unlearning protocol, which utilizes the Chameleon hash function to verify data removal and eliminate the data contributions stored in other clients' models. Then, an adaptive contribution-based retraining mechanism is developed to reduce the computational overhead and significantly improve the training efficiency. Extensive experiments demonstrate that the proposed framework can achieve a better data removal effect than the state-of-the-art frameworks, marking a significant stride towards trustworthy federated unlearning.","sentences":["Federated unlearning is a promising paradigm for protecting the data ownership of distributed clients.","It allows central servers to remove historical data effects within the machine learning model as well as address the \"right to be forgotten\" issue in federated learning.","However, existing works require central servers to retain the historical model parameters from distributed clients, such that allows the central server to utilize these parameters for further training even, after the clients exit the training process.","To address this issue, this paper proposes a new blockchain-enabled trustworthy federated unlearning framework.","We first design a proof of federated unlearning protocol, which utilizes the Chameleon hash function to verify data removal and eliminate the data contributions stored in other clients' models.","Then, an adaptive contribution-based retraining mechanism is developed to reduce the computational overhead and significantly improve the training efficiency.","Extensive experiments demonstrate that the proposed framework can achieve a better data removal effect than the state-of-the-art frameworks, marking a significant stride towards trustworthy federated unlearning."],"url":"http://arxiv.org/abs/2401.15917v1"}
{"created":"2024-01-29 06:59:17","title":"Unrestricted Error-Type Codebook Generation for Error Correction Code in DNA Storage Inspired by NLP","abstract":"Recently, DNA storage has surfaced as a promising alternative for data storage, presenting notable benefits in terms of storage capacity, cost-effectiveness in maintenance, and the capability for parallel replication. Mathematically, the DNA storage process can be conceptualized as an insertion, deletion, and substitution (IDS) channel. Due to the mathematical complexity associated with the Levenshtein distance, creating a code that corrects for IDS remains a challenging task. In this paper, we propose a bottom-up generation approach to grow the required codebook based on the computation of Edit Computational Graph (ECG) which differs from the algebraic constructions by incorporating the Derivative-Free Optimization (DFO) method. Specifically, this approach is regardless of the type of errors. Compared the results with the work for 1-substitution-1-deletion and 2-deletion, the redundancy is reduced by about 30-bit and 60-bit, respectively. As far as we know, our method is the first IDS-correcting code designed using classical Natural Language Process (NLP) techniques, marking a turning point in the field of error correction code research. Based on the codebook generated by our method, there may be significant breakthroughs in the complexity of encoding and decoding algorithms.","sentences":["Recently, DNA storage has surfaced as a promising alternative for data storage, presenting notable benefits in terms of storage capacity, cost-effectiveness in maintenance, and the capability for parallel replication.","Mathematically, the DNA storage process can be conceptualized as an insertion, deletion, and substitution (IDS) channel.","Due to the mathematical complexity associated with the Levenshtein distance, creating a code that corrects for IDS remains a challenging task.","In this paper, we propose a bottom-up generation approach to grow the required codebook based on the computation of Edit Computational Graph (ECG) which differs from the algebraic constructions by incorporating the Derivative-Free Optimization (DFO) method.","Specifically, this approach is regardless of the type of errors.","Compared the results with the work for 1-substitution-1-deletion and 2-deletion, the redundancy is reduced by about 30-bit and 60-bit, respectively.","As far as we know, our method is the first IDS-correcting code designed using classical Natural Language Process (NLP) techniques, marking a turning point in the field of error correction code research.","Based on the codebook generated by our method, there may be significant breakthroughs in the complexity of encoding and decoding algorithms."],"url":"http://arxiv.org/abs/2401.15915v1"}
{"created":"2024-01-29 06:57:48","title":"Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization","abstract":"Existing vision-language models exhibit strong generalization on a variety of visual domains and tasks. However, such models mainly perform zero-shot recognition in a closed-set manner, and thus struggle to handle open-domain visual concepts by design. There are recent finetuning methods, such as prompt learning, that not only study the discrimination between in-distribution (ID) and out-of-distribution (OOD) samples, but also show some improvements in both ID and OOD accuracies. In this paper, we first demonstrate that vision-language models, after long enough finetuning but without proper regularization, tend to overfit the known classes in the given dataset, with degraded performance on unknown classes. Then we propose a novel approach OGEN to address this pitfall, with the main focus on improving the OOD GENeralization of finetuned models. Specifically, a class-conditional feature generator is introduced to synthesize OOD features using just the class name of any unknown class. Such synthesized features will provide useful knowledge about unknowns and help regularize the decision boundary between ID and OOD data when optimized jointly. Equally important is our adaptive self-distillation mechanism to regularize our feature generation model during joint optimization, i.e., adaptively transferring knowledge between model states to further prevent overfitting. Experiments validate that our method yields convincing gains in OOD generalization performance in different settings.","sentences":["Existing vision-language models exhibit strong generalization on a variety of visual domains and tasks.","However, such models mainly perform zero-shot recognition in a closed-set manner, and thus struggle to handle open-domain visual concepts by design.","There are recent finetuning methods, such as prompt learning, that not only study the discrimination between in-distribution (ID) and out-of-distribution (OOD) samples, but also show some improvements in both ID and OOD accuracies.","In this paper, we first demonstrate that vision-language models, after long enough finetuning but without proper regularization, tend to overfit the known classes in the given dataset, with degraded performance on unknown classes.","Then we propose a novel approach OGEN to address this pitfall, with the main focus on improving the OOD GENeralization of finetuned models.","Specifically, a class-conditional feature generator is introduced to synthesize OOD features using just the class name of any unknown class.","Such synthesized features will provide useful knowledge about unknowns and help regularize the decision boundary between ID and OOD data when optimized jointly.","Equally important is our adaptive self-distillation mechanism to regularize our feature generation model during joint optimization, i.e., adaptively transferring knowledge between model states to further prevent overfitting.","Experiments validate that our method yields convincing gains in OOD generalization performance in different settings."],"url":"http://arxiv.org/abs/2401.15914v1"}
{"created":"2024-01-29 06:21:29","title":"Mean Estimation with User-Level Privacy for Spatio-Temporal IoT Datasets","abstract":"This paper considers the problem of the private release of sample means of speed values from traffic datasets. Our key contribution is the development of user-level differentially private algorithms that incorporate carefully chosen parameter values to ensure low estimation errors on real-world datasets, while ensuring privacy. We test our algorithms on ITMS (Intelligent Traffic Management System) data from an Indian city, where the speeds of different buses are drawn in a potentially non-i.i.d. manner from an unknown distribution, and where the number of speed samples contributed by different buses is potentially different. We then apply our algorithms to a synthetic dataset, generated based on the ITMS data, having either a large number of users or a large number of samples per user. Here, we provide recommendations for the choices of parameters and algorithm subroutines that result in low estimation errors, while guaranteeing user-level privacy.","sentences":["This paper considers the problem of the private release of sample means of speed values from traffic datasets.","Our key contribution is the development of user-level differentially private algorithms that incorporate carefully chosen parameter values to ensure low estimation errors on real-world datasets, while ensuring privacy.","We test our algorithms on ITMS (Intelligent Traffic Management System) data from an Indian city, where the speeds of different buses are drawn in a potentially non-i.i.d. manner from an unknown distribution, and where the number of speed samples contributed by different buses is potentially different.","We then apply our algorithms to a synthetic dataset, generated based on the ITMS data, having either a large number of users or a large number of samples per user.","Here, we provide recommendations for the choices of parameters and algorithm subroutines that result in low estimation errors, while guaranteeing user-level privacy."],"url":"http://arxiv.org/abs/2401.15906v1"}
{"created":"2024-01-29 06:10:54","title":"Toward the Identifiability of Comparative Deep Generative Models","abstract":"Deep Generative Models (DGMs) are versatile tools for learning data representations while adequately incorporating domain knowledge such as the specification of conditional probability distributions. Recently proposed DGMs tackle the important task of comparing data sets from different sources. One such example is the setting of contrastive analysis that focuses on describing patterns that are enriched in a target data set compared to a background data set. The practical deployment of those models often assumes that DGMs naturally infer interpretable and modular latent representations, which is known to be an issue in practice. Consequently, existing methods often rely on ad-hoc regularization schemes, although without any theoretical grounding. Here, we propose a theory of identifiability for comparative DGMs by extending recent advances in the field of non-linear independent component analysis. We show that, while these models lack identifiability across a general class of mixing functions, they surprisingly become identifiable when the mixing function is piece-wise affine (e.g., parameterized by a ReLU neural network). We also investigate the impact of model misspecification, and empirically show that previously proposed regularization techniques for fitting comparative DGMs help with identifiability when the number of latent variables is not known in advance. Finally, we introduce a novel methodology for fitting comparative DGMs that improves the treatment of multiple data sources via multi-objective optimization and that helps adjust the hyperparameter for the regularization in an interpretable manner, using constrained optimization. We empirically validate our theory and new methodology using simulated data as well as a recent data set of genetic perturbations in cells profiled via single-cell RNA sequencing.","sentences":["Deep Generative Models (DGMs) are versatile tools for learning data representations while adequately incorporating domain knowledge such as the specification of conditional probability distributions.","Recently proposed DGMs tackle the important task of comparing data sets from different sources.","One such example is the setting of contrastive analysis that focuses on describing patterns that are enriched in a target data set compared to a background data set.","The practical deployment of those models often assumes that DGMs naturally infer interpretable and modular latent representations, which is known to be an issue in practice.","Consequently, existing methods often rely on ad-hoc regularization schemes, although without any theoretical grounding.","Here, we propose a theory of identifiability for comparative DGMs by extending recent advances in the field of non-linear independent component analysis.","We show that, while these models lack identifiability across a general class of mixing functions, they surprisingly become identifiable when the mixing function is piece-wise affine (e.g., parameterized by a ReLU neural network).","We also investigate the impact of model misspecification, and empirically show that previously proposed regularization techniques for fitting comparative DGMs help with identifiability when the number of latent variables is not known in advance.","Finally, we introduce a novel methodology for fitting comparative DGMs that improves the treatment of multiple data sources via multi-objective optimization and that helps adjust the hyperparameter for the regularization in an interpretable manner, using constrained optimization.","We empirically validate our theory and new methodology using simulated data as well as a recent data set of genetic perturbations in cells profiled via single-cell RNA sequencing."],"url":"http://arxiv.org/abs/2401.15903v1"}
{"created":"2024-01-29 05:16:19","title":"Arbitrary-Scale Downscaling of Tidal Current Data Using Implicit Continuous Representation","abstract":"Numerical models have long been used to understand geoscientific phenomena, including tidal currents, crucial for renewable energy production and coastal engineering. However, their computational cost hinders generating data of varying resolutions. As an alternative, deep learning-based downscaling methods have gained traction due to their faster inference speeds. But most of them are limited to only inference fixed scale and overlook important characteristics of target geoscientific data. In this paper, we propose a novel downscaling framework for tidal current data, addressing its unique characteristics, which are dissimilar to images: heterogeneity and local dependency. Moreover, our framework can generate any arbitrary-scale output utilizing a continuous representation model. Our proposed framework demonstrates significantly improved flow velocity predictions by 93.21% (MSE) and 63.85% (MAE) compared to the Baseline model while achieving a remarkable 33.2% reduction in FLOPs.","sentences":["Numerical models have long been used to understand geoscientific phenomena, including tidal currents, crucial for renewable energy production and coastal engineering.","However, their computational cost hinders generating data of varying resolutions.","As an alternative, deep learning-based downscaling methods have gained traction due to their faster inference speeds.","But most of them are limited to only inference fixed scale and overlook important characteristics of target geoscientific data.","In this paper, we propose a novel downscaling framework for tidal current data, addressing its unique characteristics, which are dissimilar to images: heterogeneity and local dependency.","Moreover, our framework can generate any arbitrary-scale output utilizing a continuous representation model.","Our proposed framework demonstrates significantly improved flow velocity predictions by 93.21% (MSE) and 63.85% (MAE) compared to the Baseline model while achieving a remarkable 33.2% reduction in FLOPs."],"url":"http://arxiv.org/abs/2401.15893v1"}
{"created":"2024-01-29 04:19:56","title":"Decoding the MITRE Engenuity ATT&CK Enterprise Evaluation: An Analysis of EDR Performance in Real-World Environments","abstract":"Endpoint detection and response (EDR) systems have emerged as a critical component of enterprise security solutions, effectively combating endpoint threats like APT attacks with extended lifecycles. In light of the growing significance of endpoint detection and response (EDR) systems, many cybersecurity providers have developed their own proprietary EDR solutions. It's crucial for users to assess the capabilities of these detection engines to make informed decisions about which products to choose. This is especially urgent given the market's size, which is expected to reach around 3.7 billion dollars by 2023 and is still expanding. MITRE is a leading organization in cyber threat analysis. In 2018, MITRE started to conduct annual APT emulations that cover major EDR vendors worldwide. Indicators include telemetry, detection and blocking capability, etc. Nevertheless, the evaluation results published by MITRE don't contain any further interpretations or suggestions.   In this paper, we thoroughly analyzed MITRE evaluation results to gain further insights into real-world EDR systems under test. Specifically, we designed a whole-graph analysis method, which utilizes additional control flow and data flow information to measure the performance of EDR systems. Besides, we analyze MITRE evaluation's results over multiple years from various aspects, including detection coverage, detection confidence, detection modifier, data source, compatibility, etc. Through the above studies, we have compiled a thorough summary of our findings and gained valuable insights from the evaluation results. We believe these summaries and insights can assist researchers, practitioners, and vendors in better understanding the strengths and limitations of mainstream EDR products.","sentences":["Endpoint detection and response (EDR) systems have emerged as a critical component of enterprise security solutions, effectively combating endpoint threats like APT attacks with extended lifecycles.","In light of the growing significance of endpoint detection and response (EDR) systems, many cybersecurity providers have developed their own proprietary EDR solutions.","It's crucial for users to assess the capabilities of these detection engines to make informed decisions about which products to choose.","This is especially urgent given the market's size, which is expected to reach around 3.7 billion dollars by 2023 and is still expanding.","MITRE is a leading organization in cyber threat analysis.","In 2018, MITRE started to conduct annual APT emulations that cover major EDR vendors worldwide.","Indicators include telemetry, detection and blocking capability, etc.","Nevertheless, the evaluation results published by MITRE don't contain any further interpretations or suggestions.   ","In this paper, we thoroughly analyzed MITRE evaluation results to gain further insights into real-world EDR systems under test.","Specifically, we designed a whole-graph analysis method, which utilizes additional control flow and data flow information to measure the performance of EDR systems.","Besides, we analyze MITRE evaluation's results over multiple years from various aspects, including detection coverage, detection confidence, detection modifier, data source, compatibility, etc.","Through the above studies, we have compiled a thorough summary of our findings and gained valuable insights from the evaluation results.","We believe these summaries and insights can assist researchers, practitioners, and vendors in better understanding the strengths and limitations of mainstream EDR products."],"url":"http://arxiv.org/abs/2401.15878v1"}
{"created":"2024-01-29 04:16:37","title":"3DPFIX: Improving Remote Novices' 3D Printing Troubleshooting through Human-AI Collaboration","abstract":"The widespread consumer-grade 3D printers and learning resources online enable novices to self-train in remote settings. While troubleshooting plays an essential part of 3D printing, the process remains challenging for many remote novices even with the help of well-developed online sources, such as online troubleshooting archives and online community help. We conducted a formative study with 76 active 3D printing users to learn how remote novices leverage online resources in troubleshooting and their challenges. We found that remote novices cannot fully utilize online resources. For example, the online archives statically provide general information, making it hard to search and relate their unique cases with existing descriptions. Online communities can potentially ease their struggles by providing more targeted suggestions, but a helper who can provide custom help is rather scarce, making it hard to obtain timely assistance. We propose 3DPFIX, an interactive 3D troubleshooting system powered by the pipeline to facilitate Human-AI Collaboration, designed to improve novices' 3D printing experiences and thus help them easily accumulate their domain knowledge. We built 3DPFIX that supports automated diagnosis and solution-seeking. 3DPFIX was built upon shared dialogues about failure cases from Q\\&A discourses accumulated in online communities. We leverage social annotations (i.e., comments) to build an annotated failure image dataset for AI classifiers and extract a solution pool. Our summative study revealed that using 3DPFIX helped participants spend significantly less effort in diagnosing failures and finding a more accurate solution than relying on their common practice. We also found that 3DPFIX users learn about 3D printing domain-specific knowledge. We discuss the implications of leveraging community-driven data in developing future Human-AI Collaboration designs.","sentences":["The widespread consumer-grade 3D printers and learning resources online enable novices to self-train in remote settings.","While troubleshooting plays an essential part of 3D printing, the process remains challenging for many remote novices even with the help of well-developed online sources, such as online troubleshooting archives and online community help.","We conducted a formative study with 76 active 3D printing users to learn how remote novices leverage online resources in troubleshooting and their challenges.","We found that remote novices cannot fully utilize online resources.","For example, the online archives statically provide general information, making it hard to search and relate their unique cases with existing descriptions.","Online communities can potentially ease their struggles by providing more targeted suggestions, but a helper who can provide custom help is rather scarce, making it hard to obtain timely assistance.","We propose 3DPFIX, an interactive 3D troubleshooting system powered by the pipeline to facilitate Human-AI Collaboration, designed to improve novices' 3D printing experiences and thus help them easily accumulate their domain knowledge.","We built 3DPFIX that supports automated diagnosis and solution-seeking.","3DPFIX was built upon shared dialogues about failure cases from Q\\&A discourses accumulated in online communities.","We leverage social annotations (i.e., comments) to build an annotated failure image dataset for AI classifiers and extract a solution pool.","Our summative study revealed that using 3DPFIX helped participants spend significantly less effort in diagnosing failures and finding a more accurate solution than relying on their common practice.","We also found that 3DPFIX users learn about 3D printing domain-specific knowledge.","We discuss the implications of leveraging community-driven data in developing future Human-AI Collaboration designs."],"url":"http://arxiv.org/abs/2401.15877v1"}
{"created":"2024-01-29 04:15:22","title":"Combining Satellite and Weather Data for Crop Type Mapping: An Inverse Modelling Approach","abstract":"Accurate and timely crop mapping is essential for yield estimation, insurance claims, and conservation efforts. Over the years, many successful machine learning models for crop mapping have been developed that use just the multi-spectral imagery from satellites to predict crop type over the area of interest. However, these traditional methods do not account for the physical processes that govern crop growth. At a high level, crop growth can be envisioned as physical parameters, such as weather and soil type, acting upon the plant leading to crop growth which can be observed via satellites. In this paper, we propose Weather-based Spatio-Temporal segmentation network with ATTention (WSTATT), a deep learning model that leverages this understanding of crop growth by formulating it as an inverse model that combines weather (Daymet) and satellite imagery (Sentinel-2) to generate accurate crop maps. We show that our approach provides significant improvements over existing algorithms that solely rely on spectral imagery by comparing segmentation maps and F1 classification scores. Furthermore, effective use of attention in WSTATT architecture enables detection of crop types earlier in the season (up to 5 months in advance), which is very useful for improving food supply projections. We finally discuss the impact of weather by correlating our results with crop phenology to show that WSTATT is able to capture physical properties of crop growth.","sentences":["Accurate and timely crop mapping is essential for yield estimation, insurance claims, and conservation efforts.","Over the years, many successful machine learning models for crop mapping have been developed that use just the multi-spectral imagery from satellites to predict crop type over the area of interest.","However, these traditional methods do not account for the physical processes that govern crop growth.","At a high level, crop growth can be envisioned as physical parameters, such as weather and soil type, acting upon the plant leading to crop growth which can be observed via satellites.","In this paper, we propose Weather-based Spatio-Temporal segmentation network with ATTention (WSTATT), a deep learning model that leverages this understanding of crop growth by formulating it as an inverse model that combines weather (Daymet) and satellite imagery (Sentinel-2) to generate accurate crop maps.","We show that our approach provides significant improvements over existing algorithms that solely rely on spectral imagery by comparing segmentation maps and F1 classification scores.","Furthermore, effective use of attention in WSTATT architecture enables detection of crop types earlier in the season (up to 5 months in advance), which is very useful for improving food supply projections.","We finally discuss the impact of weather by correlating our results with crop phenology to show that WSTATT is able to capture physical properties of crop growth."],"url":"http://arxiv.org/abs/2401.15875v1"}
{"created":"2024-01-29 04:14:02","title":"Rethinking Personalized Federated Learning with Clustering-based Dynamic Graph Propagation","abstract":"Most existing personalized federated learning approaches are based on intricate designs, which often require complex implementation and tuning. In order to address this limitation, we propose a simple yet effective personalized federated learning framework. Specifically, during each communication round, we group clients into multiple clusters based on their model training status and data distribution on the server side. We then consider each cluster center as a node equipped with model parameters and construct a graph that connects these nodes using weighted edges. Additionally, we update the model parameters at each node by propagating information across the entire graph. Subsequently, we design a precise personalized model distribution strategy to allow clients to obtain the most suitable model from the server side. We conduct experiments on three image benchmark datasets and create synthetic structured datasets with three types of typologies. Experimental results demonstrate the effectiveness of the proposed work.","sentences":["Most existing personalized federated learning approaches are based on intricate designs, which often require complex implementation and tuning.","In order to address this limitation, we propose a simple yet effective personalized federated learning framework.","Specifically, during each communication round, we group clients into multiple clusters based on their model training status and data distribution on the server side.","We then consider each cluster center as a node equipped with model parameters and construct a graph that connects these nodes using weighted edges.","Additionally, we update the model parameters at each node by propagating information across the entire graph.","Subsequently, we design a precise personalized model distribution strategy to allow clients to obtain the most suitable model from the server side.","We conduct experiments on three image benchmark datasets and create synthetic structured datasets with three types of typologies.","Experimental results demonstrate the effectiveness of the proposed work."],"url":"http://arxiv.org/abs/2401.15874v1"}
{"created":"2024-01-29 03:42:37","title":"Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution","abstract":"Many tasks in explainable machine learning, such as data valuation and feature attribution, perform expensive computation for each data point and can be intractable for large datasets. These methods require efficient approximations, and learning a network that directly predicts the desired output, which is commonly known as amortization, is a promising solution. However, training such models with exact labels is often intractable; we therefore explore training with noisy labels and find that this is inexpensive and surprisingly effective. Through theoretical analysis of the label noise and experiments with various models and datasets, we show that this approach significantly accelerates several feature attribution and data valuation methods, often yielding an order of magnitude speedup over existing approaches.","sentences":["Many tasks in explainable machine learning, such as data valuation and feature attribution, perform expensive computation for each data point and can be intractable for large datasets.","These methods require efficient approximations, and learning a network that directly predicts the desired output, which is commonly known as amortization, is a promising solution.","However, training such models with exact labels is often intractable; we therefore explore training with noisy labels and find that this is inexpensive and surprisingly effective.","Through theoretical analysis of the label noise and experiments with various models and datasets, we show that this approach significantly accelerates several feature attribution and data valuation methods, often yielding an order of magnitude speedup over existing approaches."],"url":"http://arxiv.org/abs/2401.15866v1"}
{"created":"2024-01-29 03:29:39","title":"Importance-Aware Adaptive Dataset Distillation","abstract":"Herein, we propose a novel dataset distillation method for constructing small informative datasets that preserve the information of the large original datasets. The development of deep learning models is enabled by the availability of large-scale datasets. Despite unprecedented success, large-scale datasets considerably increase the storage and transmission costs, resulting in a cumbersome model training process. Moreover, using raw data for training raises privacy and copyright concerns. To address these issues, a new task named dataset distillation has been introduced, aiming to synthesize a compact dataset that retains the essential information from the large original dataset. State-of-the-art (SOTA) dataset distillation methods have been proposed by matching gradients or network parameters obtained during training on real and synthetic datasets. The contribution of different network parameters to the distillation process varies, and uniformly treating them leads to degraded distillation performance. Based on this observation, we propose an importance-aware adaptive dataset distillation (IADD) method that can improve distillation performance by automatically assigning importance weights to different network parameters during distillation, thereby synthesizing more robust distilled datasets. IADD demonstrates superior performance over other SOTA dataset distillation methods based on parameter matching on multiple benchmark datasets and outperforms them in terms of cross-architecture generalization. In addition, the analysis of self-adaptive weights demonstrates the effectiveness of IADD. Furthermore, the effectiveness of IADD is validated in a real-world medical application such as COVID-19 detection.","sentences":["Herein, we propose a novel dataset distillation method for constructing small informative datasets that preserve the information of the large original datasets.","The development of deep learning models is enabled by the availability of large-scale datasets.","Despite unprecedented success, large-scale datasets considerably increase the storage and transmission costs, resulting in a cumbersome model training process.","Moreover, using raw data for training raises privacy and copyright concerns.","To address these issues, a new task named dataset distillation has been introduced, aiming to synthesize a compact dataset that retains the essential information from the large original dataset.","State-of-the-art (SOTA) dataset distillation methods have been proposed by matching gradients or network parameters obtained during training on real and synthetic datasets.","The contribution of different network parameters to the distillation process varies, and uniformly treating them leads to degraded distillation performance.","Based on this observation, we propose an importance-aware adaptive dataset distillation (IADD) method that can improve distillation performance by automatically assigning importance weights to different network parameters during distillation, thereby synthesizing more robust distilled datasets.","IADD demonstrates superior performance over other SOTA dataset distillation methods based on parameter matching on multiple benchmark datasets and outperforms them in terms of cross-architecture generalization.","In addition, the analysis of self-adaptive weights demonstrates the effectiveness of IADD.","Furthermore, the effectiveness of IADD is validated in a real-world medical application such as COVID-19 detection."],"url":"http://arxiv.org/abs/2401.15863v1"}
{"created":"2024-01-29 02:43:40","title":"Muffin or Chihuahua? Challenging Large Vision-Language Models with Multipanel VQA","abstract":"Multipanel images, commonly seen as web screenshots, posters, etc., pervade our daily lives. These images, characterized by their composition of multiple subfigures in distinct layouts, effectively convey information to people. Toward building advanced multimodal AI applications, such as agents that understand complex scenes and navigate through webpages, the skill of multipanel visual reasoning is essential, and a comprehensive evaluation of models in this regard is important. Therefore, our paper introduces Multipanel Visual Question Answering (MultipanelVQA), a novel benchmark that specifically challenges models in comprehending multipanel images. The benchmark comprises 6,600 questions and answers related to multipanel images. While these questions are straightforward for average humans, achieving nearly perfect correctness, they pose significant challenges to the state-of-the-art Large Vision Language Models (LVLMs) we tested. In our study, we utilized synthetically curated multipanel images specifically designed to isolate and evaluate the impact of diverse factors on model performance, revealing the sensitivity of LVLMs to various interferences in multipanel images, such as adjacent subfigures and layout complexity. As a result, MultipanelVQA highlights the need and direction for improving LVLMs' ability to understand complex visual-language contexts. Code and data are released at https://sites.google.com/view/multipanelvqa/home.","sentences":["Multipanel images, commonly seen as web screenshots, posters, etc., pervade our daily lives.","These images, characterized by their composition of multiple subfigures in distinct layouts, effectively convey information to people.","Toward building advanced multimodal AI applications, such as agents that understand complex scenes and navigate through webpages, the skill of multipanel visual reasoning is essential, and a comprehensive evaluation of models in this regard is important.","Therefore, our paper introduces Multipanel Visual Question Answering (MultipanelVQA), a novel benchmark that specifically challenges models in comprehending multipanel images.","The benchmark comprises 6,600 questions and answers related to multipanel images.","While these questions are straightforward for average humans, achieving nearly perfect correctness, they pose significant challenges to the state-of-the-art Large Vision Language Models (LVLMs) we tested.","In our study, we utilized synthetically curated multipanel images specifically designed to isolate and evaluate the impact of diverse factors on model performance, revealing the sensitivity of LVLMs to various interferences in multipanel images, such as adjacent subfigures and layout complexity.","As a result, MultipanelVQA highlights the need and direction for improving LVLMs' ability to understand complex visual-language contexts.","Code and data are released at https://sites.google.com/view/multipanelvqa/home."],"url":"http://arxiv.org/abs/2401.15847v1"}
{"created":"2024-01-29 02:35:42","title":"APIGen: Generative API Method Recommendation","abstract":"Automatic API method recommendation is an essential task of code intelligence, which aims to suggest suitable APIs for programming queries. Existing approaches can be categorized into two primary groups: retrieval-based and learning-based approaches. Although these approaches have achieved remarkable success, they still come with notable limitations. The retrieval-based approaches rely on the text representation capabilities of embedding models, while the learning-based approaches require extensive task-specific labeled data for training. To mitigate the limitations, we propose APIGen, a generative API recommendation approach through enhanced in-context learning (ICL). APIGen involves two main components: (1) Diverse Examples Selection. APIGen searches for similar posts to the programming queries from the lexical, syntactical, and semantic perspectives, providing more informative examples for ICL. (2) Guided API Recommendation. APIGen enables large language models (LLMs) to perform reasoning before generating API recommendations, where the reasoning involves fine-grained matching between the task intent behind the queries and the factual knowledge of the APIs. With the reasoning process, APIGen makes recommended APIs better meet the programming requirement of queries and also enhances the interpretability of results. We compare APIGen with four existing approaches on two publicly available benchmarks. Experiments show that APIGen outperforms the best baseline CLEAR by 105.8% in method-level API recommendation and 54.3% in class-level API recommendation in terms of SuccessRate@1. Besides, APIGen achieves an average 49.87% increase compared to the zero-shot performance of popular LLMs such as GPT-4 in method-level API recommendation regarding the SuccessRate@3 metric.","sentences":["Automatic API method recommendation is an essential task of code intelligence, which aims to suggest suitable APIs for programming queries.","Existing approaches can be categorized into two primary groups: retrieval-based and learning-based approaches.","Although these approaches have achieved remarkable success, they still come with notable limitations.","The retrieval-based approaches rely on the text representation capabilities of embedding models, while the learning-based approaches require extensive task-specific labeled data for training.","To mitigate the limitations, we propose APIGen, a generative API recommendation approach through enhanced in-context learning (ICL).","APIGen involves two main components: (1) Diverse Examples Selection.","APIGen searches for similar posts to the programming queries from the lexical, syntactical, and semantic perspectives, providing more informative examples for ICL.","(2) Guided API Recommendation.","APIGen enables large language models (LLMs) to perform reasoning before generating API recommendations, where the reasoning involves fine-grained matching between the task intent behind the queries and the factual knowledge of the APIs.","With the reasoning process, APIGen makes recommended APIs better meet the programming requirement of queries and also enhances the interpretability of results.","We compare APIGen with four existing approaches on two publicly available benchmarks.","Experiments show that APIGen outperforms the best baseline CLEAR by 105.8% in method-level API recommendation and 54.3% in class-level API recommendation in terms of SuccessRate@1.","Besides, APIGen achieves an average 49.87% increase compared to the zero-shot performance of popular LLMs such as GPT-4 in method-level API recommendation regarding the SuccessRate@3 metric."],"url":"http://arxiv.org/abs/2401.15843v1"}
{"created":"2024-01-29 02:28:39","title":"Emergent Explainability: Adding a causal chain to neural network inference","abstract":"This position paper presents a theoretical framework for enhancing explainable artificial intelligence (xAI) through emergent communication (EmCom), focusing on creating a causal understanding of AI model outputs. We explore the novel integration of EmCom into AI systems, offering a paradigm shift from conventional associative relationships between inputs and outputs to a more nuanced, causal interpretation. The framework aims to revolutionize how AI processes are understood, making them more transparent and interpretable. While the initial application of this model is demonstrated on synthetic data, the implications of this research extend beyond these simple applications. This general approach has the potential to redefine interactions with AI across multiple domains, fostering trust and informed decision-making in healthcare and in various sectors where AI's decision-making processes are critical. The paper discusses the theoretical underpinnings of this approach, its potential broad applications, and its alignment with the growing need for responsible and transparent AI systems in an increasingly digital world.","sentences":["This position paper presents a theoretical framework for enhancing explainable artificial intelligence (xAI) through emergent communication (EmCom), focusing on creating a causal understanding of AI model outputs.","We explore the novel integration of EmCom into AI systems, offering a paradigm shift from conventional associative relationships between inputs and outputs to a more nuanced, causal interpretation.","The framework aims to revolutionize how AI processes are understood, making them more transparent and interpretable.","While the initial application of this model is demonstrated on synthetic data, the implications of this research extend beyond these simple applications.","This general approach has the potential to redefine interactions with AI across multiple domains, fostering trust and informed decision-making in healthcare and in various sectors where AI's decision-making processes are critical.","The paper discusses the theoretical underpinnings of this approach, its potential broad applications, and its alignment with the growing need for responsible and transparent AI systems in an increasingly digital world."],"url":"http://arxiv.org/abs/2401.15840v1"}
{"created":"2024-01-29 02:19:42","title":"Swarm: Cost-Efficient Video Content Distribution with a Peer-to-Peer System","abstract":"As ByteDance's business expands, the substantial infrastructure expenses associated with centralized Content Delivery Network (CDN) networks have rendered content distribution costs prohibitively high. In response, we embarked on exploring a peer-to-peer (P2P) network as a promising solution to alleviate the escalating costs of content distribution. However, the decentralized nature of P2P often introduces performance challenges, given the diversity and dispersion of peer devices. This study introduces Swarm, ByteDance's innovative hybrid system for video streaming. Swarm seamlessly integrates the robustness of a conventional CDN with the cost-efficiency of a decentralized P2P network. Its primary aim is to provide users with reliable streaming quality while minimizing traffic expenses. To achieve this, Swarm employs a centralized control plane comprised of a tracker cluster, overseeing a data plane with numerous edge residual resources. The tracker also takes on the responsibility of mapping clients to servers. Addressing the performance disparities among individual peer servers, Swarm utilizes our proprietary multipath parallel transmission method for communication between clients and peer servers. Operating stably for six years, Swarm now manages over a hundred thousand peer servers, serving nearly a hundred million users daily and saving the company hundreds of millions of RMB annually. Experimental results affirm that, while significantly cutting costs, Swarm performs on par with traditional CDNs.","sentences":["As ByteDance's business expands, the substantial infrastructure expenses associated with centralized Content Delivery Network (CDN) networks have rendered content distribution costs prohibitively high.","In response, we embarked on exploring a peer-to-peer (P2P) network as a promising solution to alleviate the escalating costs of content distribution.","However, the decentralized nature of P2P often introduces performance challenges, given the diversity and dispersion of peer devices.","This study introduces Swarm, ByteDance's innovative hybrid system for video streaming.","Swarm seamlessly integrates the robustness of a conventional CDN with the cost-efficiency of a decentralized P2P network.","Its primary aim is to provide users with reliable streaming quality while minimizing traffic expenses.","To achieve this, Swarm employs a centralized control plane comprised of a tracker cluster, overseeing a data plane with numerous edge residual resources.","The tracker also takes on the responsibility of mapping clients to servers.","Addressing the performance disparities among individual peer servers, Swarm utilizes our proprietary multipath parallel transmission method for communication between clients and peer servers.","Operating stably for six years, Swarm now manages over a hundred thousand peer servers, serving nearly a hundred million users daily and saving the company hundreds of millions of RMB annually.","Experimental results affirm that, while significantly cutting costs, Swarm performs on par with traditional CDNs."],"url":"http://arxiv.org/abs/2401.15839v1"}
{"created":"2024-01-29 01:57:16","title":"Refreshable Tactile Displays for Accessible Data Visualisation","abstract":"Refreshable tactile displays (RTDs) are predicted to soon become a viable option for the provision of accessible graphics for people who are blind or have low vision (BLV). This new technology for the tactile display of braille and graphics, usually using raised pins, makes it easier to generate and access a large number of graphics. However, it differs from existing tactile graphics in terms of scale, height and fidelity. Here, we share the perspectives of four key stakeholders -- blind touch readers, vision specialist teachers, accessible format producers and assistive technology providers -- to explore the potential uses, advantages and needs relating to the introduction of RTDs. We also provide advice on what role the data visualisation community can take to help ensure that people who are BLV are best able to benefit from the introduction of affordable RTDs.","sentences":["Refreshable tactile displays (RTDs) are predicted to soon become a viable option for the provision of accessible graphics for people who are blind or have low vision (BLV).","This new technology for the tactile display of braille and graphics, usually using raised pins, makes it easier to generate and access a large number of graphics.","However, it differs from existing tactile graphics in terms of scale, height and fidelity.","Here, we share the perspectives of four key stakeholders -- blind touch readers, vision specialist teachers, accessible format producers and assistive technology providers -- to explore the potential uses, advantages and needs relating to the introduction of RTDs.","We also provide advice on what role the data visualisation community can take to help ensure that people who are BLV are best able to benefit from the introduction of affordable RTDs."],"url":"http://arxiv.org/abs/2401.15836v1"}
{"created":"2024-01-29 01:52:49","title":"Few and Fewer: Learning Better from Few Examples Using Fewer Base Classes","abstract":"When training data is scarce, it is common to make use of a feature extractor that has been pre-trained on a large base dataset, either by fine-tuning its parameters on the ``target'' dataset or by directly adopting its representation as features for a simple classifier. Fine-tuning is ineffective for few-shot learning, since the target dataset contains only a handful of examples. However, directly adopting the features without fine-tuning relies on the base and target distributions being similar enough that these features achieve separability and generalization. This paper investigates whether better features for the target dataset can be obtained by training on fewer base classes, seeking to identify a more useful base dataset for a given task.We consider cross-domain few-shot image classification in eight different domains from Meta-Dataset and entertain multiple real-world settings (domain-informed, task-informed and uninformed) where progressively less detail is known about the target task. To our knowledge, this is the first demonstration that fine-tuning on a subset of carefully selected base classes can significantly improve few-shot learning. Our contributions are simple and intuitive methods that can be implemented in any few-shot solution. We also give insights into the conditions in which these solutions are likely to provide a boost in accuracy. We release the code to reproduce all experiments from this paper on GitHub. https://github.com/RafLaf/Few-and-Fewer.git","sentences":["When training data is scarce, it is common to make use of a feature extractor that has been pre-trained on a large base dataset, either by fine-tuning its parameters on the ``target'' dataset or by directly adopting its representation as features for a simple classifier.","Fine-tuning is ineffective for few-shot learning, since the target dataset contains only a handful of examples.","However, directly adopting the features without fine-tuning relies on the base and target distributions being similar enough that these features achieve separability and generalization.","This paper investigates whether better features for the target dataset can be obtained by training on fewer base classes, seeking to identify a more useful base dataset for a given task.","We consider cross-domain few-shot image classification in eight different domains from Meta-Dataset and entertain multiple real-world settings (domain-informed, task-informed and uninformed) where progressively less detail is known about the target task.","To our knowledge, this is the first demonstration that fine-tuning on a subset of carefully selected base classes can significantly improve few-shot learning.","Our contributions are simple and intuitive methods that can be implemented in any few-shot solution.","We also give insights into the conditions in which these solutions are likely to provide a boost in accuracy.","We release the code to reproduce all experiments from this paper on GitHub.","https://github.com/RafLaf/Few-and-Fewer.git"],"url":"http://arxiv.org/abs/2401.15834v1"}
{"created":"2024-01-29 00:29:39","title":"OntoMedRec: Logically-Pretrained Model-Agnostic Ontology Encoders for Medication Recommendation","abstract":"Most existing medication recommendation models learn representations for medical concepts based on electronic health records (EHRs) and make recommendations with learnt representations. However, most medications appear in the dataset for limited times, resulting in insufficient learning of their representations. Medical ontologies are the hierarchical classification systems for medical terms where similar terms are in the same class on a certain level. In this paper, we propose OntoMedRec, the logically-pretrained and model-agnostic medical Ontology Encoders for Medication Recommendation that addresses data sparsity problem with medical ontologies. We conduct comprehensive experiments on benchmark datasets to evaluate the effectiveness of OntoMedRec, and the result shows the integration of OntoMedRec improves the performance of various models in both the entire EHR datasets and the admissions with few-shot medications. We provide the GitHub repository for the source code on https://anonymous.4open.science/r/OntoMedRec-D123","sentences":["Most existing medication recommendation models learn representations for medical concepts based on electronic health records (EHRs) and make recommendations with learnt representations.","However, most medications appear in the dataset for limited times, resulting in insufficient learning of their representations.","Medical ontologies are the hierarchical classification systems for medical terms where similar terms are in the same class on a certain level.","In this paper, we propose OntoMedRec, the logically-pretrained and model-agnostic medical Ontology Encoders for Medication Recommendation that addresses data sparsity problem with medical ontologies.","We conduct comprehensive experiments on benchmark datasets to evaluate the effectiveness of OntoMedRec, and the result shows the integration of OntoMedRec improves the performance of various models in both the entire EHR datasets and the admissions with few-shot medications.","We provide the GitHub repository for the source code on https://anonymous.4open.science/r/OntoMedRec-D123"],"url":"http://arxiv.org/abs/2401.15814v1"}
{"created":"2024-01-28 23:33:56","title":"Prediction of Breast Cancer Recurrence Risk Using a Multi-Model Approach Integrating Whole Slide Imaging and Clinicopathologic Features","abstract":"Breast cancer is the most common malignancy affecting women worldwide and is notable for its morphologic and biologic diversity, with varying risks of recurrence following treatment. The Oncotype DX Breast Recurrence Score test is an important predictive and prognostic genomic assay for estrogen receptor-positive breast cancer that guides therapeutic strategies; however, such tests can be expensive, delay care, and are not widely available. The aim of this study was to develop a multi-model approach integrating the analysis of whole slide images and clinicopathologic data to predict their associated breast cancer recurrence risks and categorize these patients into two risk groups according to the predicted score: low and high risk. The proposed novel methodology uses convolutional neural networks for feature extraction and vision transformers for contextual aggregation, complemented by a logistic regression model that analyzes clinicopathologic data for classification into two risk categories. This method was trained and tested on 993 hematoxylin and eosin-stained whole-slide images of breast cancers with corresponding clinicopathological features that had prior Oncotype DX testing. The model's performance was evaluated using an internal test set of 198 patients from Dartmouth Health and an external test set of 418 patients from the University of Chicago. The multi-model approach achieved an AUC of 0.92 (95 percent CI: 0.88-0.96) on the internal set and an AUC of 0.85 (95 percent CI: 0.79-0.90) on the external cohort. These results suggest that with further validation, the proposed methodology could provide an alternative to assist clinicians in personalizing treatment for breast cancer patients and potentially improving their outcomes.","sentences":["Breast cancer is the most common malignancy affecting women worldwide and is notable for its morphologic and biologic diversity, with varying risks of recurrence following treatment.","The Oncotype DX Breast Recurrence Score test is an important predictive and prognostic genomic assay for estrogen receptor-positive breast cancer that guides therapeutic strategies; however, such tests can be expensive, delay care, and are not widely available.","The aim of this study was to develop a multi-model approach integrating the analysis of whole slide images and clinicopathologic data to predict their associated breast cancer recurrence risks and categorize these patients into two risk groups according to the predicted score: low and high risk.","The proposed novel methodology uses convolutional neural networks for feature extraction and vision transformers for contextual aggregation, complemented by a logistic regression model that analyzes clinicopathologic data for classification into two risk categories.","This method was trained and tested on 993 hematoxylin and eosin-stained whole-slide images of breast cancers with corresponding clinicopathological features that had prior Oncotype DX testing.","The model's performance was evaluated using an internal test set of 198 patients from Dartmouth Health and an external test set of 418 patients from the University of Chicago.","The multi-model approach achieved an AUC of 0.92 (95 percent CI: 0.88-0.96) on the internal set and an AUC of 0.85 (95 percent CI: 0.79-0.90) on the external cohort.","These results suggest that with further validation, the proposed methodology could provide an alternative to assist clinicians in personalizing treatment for breast cancer patients and potentially improving their outcomes."],"url":"http://arxiv.org/abs/2401.15805v1"}
{"created":"2024-01-28 23:26:15","title":"GarchingSim: An Autonomous Driving Simulator with Photorealistic Scenes and Minimalist Workflow","abstract":"Conducting real road testing for autonomous driving algorithms can be expensive and sometimes impractical, particularly for small startups and research institutes. Thus, simulation becomes an important method for evaluating these algorithms. However, the availability of free and open-source simulators is limited, and the installation and configuration process can be daunting for beginners and interdisciplinary researchers. We introduce an autonomous driving simulator with photorealistic scenes, meanwhile keeping a user-friendly workflow. The simulator is able to communicate with external algorithms through ROS2 or Socket.IO, making it compatible with existing software stacks. Furthermore, we implement a highly accurate vehicle dynamics model within the simulator to enhance the realism of the vehicle's physical effects. The simulator is able to serve various functions, including generating synthetic data and driving with machine learning-based algorithms. Moreover, we prioritize simplicity in the deployment process, ensuring that beginners find it approachable and user-friendly.","sentences":["Conducting real road testing for autonomous driving algorithms can be expensive and sometimes impractical, particularly for small startups and research institutes.","Thus, simulation becomes an important method for evaluating these algorithms.","However, the availability of free and open-source simulators is limited, and the installation and configuration process can be daunting for beginners and interdisciplinary researchers.","We introduce an autonomous driving simulator with photorealistic scenes, meanwhile keeping a user-friendly workflow.","The simulator is able to communicate with external algorithms through ROS2 or Socket.","IO, making it compatible with existing software stacks.","Furthermore, we implement a highly accurate vehicle dynamics model within the simulator to enhance the realism of the vehicle's physical effects.","The simulator is able to serve various functions, including generating synthetic data and driving with machine learning-based algorithms.","Moreover, we prioritize simplicity in the deployment process, ensuring that beginners find it approachable and user-friendly."],"url":"http://arxiv.org/abs/2401.15803v1"}
{"created":"2024-01-28 22:47:10","title":"Regulation of Algorithmic Collusion","abstract":"Consider sellers in a competitive market that use algorithms to adapt their prices from data that they collect. In such a context it is plausible that algorithms could arrive at prices that are higher than the competitive prices and this may benefit sellers at the expense of consumers (i.e., the buyers in the market). This paper gives a definition of plausible algorithmic non-collusion for pricing algorithms. The definition allows a regulator to empirically audit algorithms by applying a statistical test to the data that they collect. Algorithms that are good, i.e., approximately optimize prices to market conditions, can be augmented to contain the data sufficient to pass the audit. Algorithms that have colluded on, e.g., supra-competitive prices cannot pass the audit. The definition allows sellers to possess useful side information that may be correlated with supply and demand and could affect the prices used by good algorithms. The paper provides an analysis of the statistical complexity of such an audit, i.e., how much data is sufficient for the test of non-collusion to be accurate.","sentences":["Consider sellers in a competitive market that use algorithms to adapt their prices from data that they collect.","In such a context it is plausible that algorithms could arrive at prices that are higher than the competitive prices and this may benefit sellers at the expense of consumers (i.e., the buyers in the market).","This paper gives a definition of plausible algorithmic non-collusion for pricing algorithms.","The definition allows a regulator to empirically audit algorithms by applying a statistical test to the data that they collect.","Algorithms that are good, i.e., approximately optimize prices to market conditions, can be augmented to contain the data sufficient to pass the audit.","Algorithms that have colluded on, e.g., supra-competitive prices cannot pass the audit.","The definition allows sellers to possess useful side information that may be correlated with supply and demand and could affect the prices used by good algorithms.","The paper provides an analysis of the statistical complexity of such an audit, i.e., how much data is sufficient for the test of non-collusion to be accurate."],"url":"http://arxiv.org/abs/2401.15794v1"}
{"created":"2024-01-28 22:30:50","title":"Real-time object detection and robotic manipulation for agriculture using a YOLO-based learning approach","abstract":"The optimisation of crop harvesting processes for commonly cultivated crops is of great importance in the aim of agricultural industrialisation. Nowadays, the utilisation of machine vision has enabled the automated identification of crops, leading to the enhancement of harvesting efficiency, but challenges still exist. This study presents a new framework that combines two separate architectures of convolutional neural networks (CNNs) in order to simultaneously accomplish the tasks of crop detection and harvesting (robotic manipulation) inside a simulated environment. Crop images in the simulated environment are subjected to random rotations, cropping, brightness, and contrast adjustments to create augmented images for dataset generation. The you only look once algorithmic framework is employed with traditional rectangular bounding boxes for crop localization. The proposed method subsequently utilises the acquired image data via a visual geometry group model in order to reveal the grasping positions for the robotic manipulation.","sentences":["The optimisation of crop harvesting processes for commonly cultivated crops is of great importance in the aim of agricultural industrialisation.","Nowadays, the utilisation of machine vision has enabled the automated identification of crops, leading to the enhancement of harvesting efficiency, but challenges still exist.","This study presents a new framework that combines two separate architectures of convolutional neural networks (CNNs) in order to simultaneously accomplish the tasks of crop detection and harvesting (robotic manipulation) inside a simulated environment.","Crop images in the simulated environment are subjected to random rotations, cropping, brightness, and contrast adjustments to create augmented images for dataset generation.","The you only look once algorithmic framework is employed with traditional rectangular bounding boxes for crop localization.","The proposed method subsequently utilises the acquired image data via a visual geometry group model in order to reveal the grasping positions for the robotic manipulation."],"url":"http://arxiv.org/abs/2401.15785v1"}
{"created":"2024-01-28 22:16:10","title":"The Discrepancy of Shortest Paths","abstract":"The hereditary discrepancy of a set system is a certain quantitative measure of the pseudorandom properties of the system. Roughly, hereditary discrepancy measures how well one can $2$-color the elements of the system so that each set contains approximately the same number of elements of each color. Hereditary discrepancy has well-studied applications e.g. in communication complexity and derandomization. More recently, the hereditary discrepancy of set systems of shortest paths has found applications in differential privacy [Chen et al.~SODA 23].   The contribution of this paper is to improve the upper and lower bounds on the hereditary discrepancy of set systems of unique shortest paths in graphs. In particular, we show that any system of unique shortest paths in an undirected weighted graph has hereditary discrepancy $\\widetilde{O}(n^{1/4})$, and we construct lower bound examples demonstrating that this bound is tight up to hidden $\\text{polylog } n$ factors. Our lower bounds apply even in the planar and bipartite settings, and they improve on a previous lower bound of $\\Omega(n^{1/6})$ obtained by applying the trace bound of Chazelle and Lvov [SoCG'00] to a classical point-line system of Erd\\H{o}s. We also show similar bounds on (non-hereditary) discrepancy and in the setting of directed graphs.   As applications, we improve the lower bound on the additive error for differentially-private all pairs shortest distances from $\\Omega(n^{1/6})$ [Chen et al.~SODA 23] to $\\Omega(n^{1/4})$, and we improve the lower bound on additive error for the differentially-private all sets range queries problem to $\\Omega(n^{1/4})$, which is tight up to hidden $\\text{polylog } n$ factors [Deng et al.~WADS 23].","sentences":["The hereditary discrepancy of a set system is a certain quantitative measure of the pseudorandom properties of the system.","Roughly, hereditary discrepancy measures how well one can $2$-color the elements of the system so that each set contains approximately the same number of elements of each color.","Hereditary discrepancy has well-studied applications e.g. in communication complexity and derandomization.","More recently, the hereditary discrepancy of set systems of shortest paths has found applications in differential privacy","[Chen et al.~SODA 23].   ","The contribution of this paper is to improve the upper and lower bounds on the hereditary discrepancy of set systems of unique shortest paths in graphs.","In particular, we show that any system of unique shortest paths in an undirected weighted graph has hereditary discrepancy $\\widetilde{O}(n^{1/4})$, and we construct lower bound examples demonstrating that this bound is tight up to hidden $\\text{polylog } n$ factors.","Our lower bounds apply even in the planar and bipartite settings, and they improve on a previous lower bound of $\\Omega(n^{1/6})$ obtained by applying the trace bound of Chazelle and Lvov","[SoCG'00] to a classical point-line system of Erd\\H{o}s.","We also show similar bounds on (non-hereditary) discrepancy and in the setting of directed graphs.   ","As applications, we improve the lower bound on the additive error for differentially-private all pairs shortest distances from $\\Omega(n^{1/6})$ [Chen et al.~SODA 23] to $\\Omega(n^{1/4})$, and we improve the lower bound on additive error for the differentially-private all sets range queries problem to $\\Omega(n^{1/4})$, which is tight up to hidden $\\text{polylog } n$ factors","[Deng et al.~WADS 23]."],"url":"http://arxiv.org/abs/2401.15781v1"}
{"created":"2024-01-28 22:11:25","title":"Fine-Tuned Large Language Models for Symptom Recognition from Spanish Clinical Text","abstract":"The accurate recognition of symptoms in clinical reports is significantly important in the fields of healthcare and biomedical natural language processing. These entities serve as essential building blocks for clinical information extraction, enabling retrieval of critical medical insights from vast amounts of textual data. Furthermore, the ability to identify and categorize these entities is fundamental for developing advanced clinical decision support systems, aiding healthcare professionals in diagnosis and treatment planning. In this study, we participated in SympTEMIST, a shared task on the detection of symptoms, signs and findings in Spanish medical documents. We combine a set of large language models fine-tuned with the data released by the organizers.","sentences":["The accurate recognition of symptoms in clinical reports is significantly important in the fields of healthcare and biomedical natural language processing.","These entities serve as essential building blocks for clinical information extraction, enabling retrieval of critical medical insights from vast amounts of textual data.","Furthermore, the ability to identify and categorize these entities is fundamental for developing advanced clinical decision support systems, aiding healthcare professionals in diagnosis and treatment planning.","In this study, we participated in SympTEMIST, a shared task on the detection of symptoms, signs and findings in Spanish medical documents.","We combine a set of large language models fine-tuned with the data released by the organizers."],"url":"http://arxiv.org/abs/2401.15780v1"}
{"created":"2024-01-28 21:58:04","title":"cantnlp@LT-EDI-2024: Automatic Detection of Anti-LGBTQ+ Hate Speech in Under-resourced Languages","abstract":"This paper describes our homophobia/transphobia in social media comments detection system developed as part of the shared task at LT-EDI-2024. We took a transformer-based approach to develop our multiclass classification model for ten language conditions (English, Spanish, Gujarati, Hindi, Kannada, Malayalam, Marathi, Tamil, Tulu, and Telugu). We introduced synthetic and organic instances of script-switched language data during domain adaptation to mirror the linguistic realities of social media language as seen in the labelled training data. Our system ranked second for Gujarati and Telugu with varying levels of performance for other language conditions. The results suggest incorporating elements of paralinguistic behaviour such as script-switching may improve the performance of language detection systems especially in the cases of under-resourced languages conditions.","sentences":["This paper describes our homophobia/transphobia in social media comments detection system developed as part of the shared task at LT-EDI-2024.","We took a transformer-based approach to develop our multiclass classification model for ten language conditions (English, Spanish, Gujarati, Hindi, Kannada, Malayalam, Marathi, Tamil, Tulu, and Telugu).","We introduced synthetic and organic instances of script-switched language data during domain adaptation to mirror the linguistic realities of social media language as seen in the labelled training data.","Our system ranked second for Gujarati and Telugu with varying levels of performance for other language conditions.","The results suggest incorporating elements of paralinguistic behaviour such as script-switching may improve the performance of language detection systems especially in the cases of under-resourced languages conditions."],"url":"http://arxiv.org/abs/2401.15777v1"}
{"created":"2024-01-28 20:30:14","title":"An objective comparison of methods for augmented reality in laparoscopic liver resection by preoperative-to-intraoperative image fusion","abstract":"Augmented reality for laparoscopic liver resection is a visualisation mode that allows a surgeon to localise tumours and vessels embedded within the liver by projecting them on top of a laparoscopic image. Preoperative 3D models extracted from CT or MRI data are registered to the intraoperative laparoscopic images during this process. In terms of 3D-2D fusion, most of the algorithms make use of anatomical landmarks to guide registration. These landmarks include the liver's inferior ridge, the falciform ligament, and the occluding contours. They are usually marked by hand in both the laparoscopic image and the 3D model, which is time-consuming and may contain errors if done by a non-experienced user. Therefore, there is a need to automate this process so that augmented reality can be used effectively in the operating room. We present the Preoperative-to-Intraoperative Laparoscopic Fusion Challenge (P2ILF), held during the Medical Imaging and Computer Assisted Interventions (MICCAI 2022) conference, which investigates the possibilities of detecting these landmarks automatically and using them in registration. The challenge was divided into two tasks: 1) A 2D and 3D landmark detection task and 2) a 3D-2D registration task. The teams were provided with training data consisting of 167 laparoscopic images and 9 preoperative 3D models from 9 patients, with the corresponding 2D and 3D landmark annotations. A total of 6 teams from 4 countries participated, whose proposed methods were evaluated on 16 images and two preoperative 3D models from two patients. All the teams proposed deep learning-based methods for the 2D and 3D landmark segmentation tasks and differentiable rendering-based methods for the registration task. Based on the experimental outcomes, we propose three key hypotheses that determine current limitations and future directions for research in this domain.","sentences":["Augmented reality for laparoscopic liver resection is a visualisation mode that allows a surgeon to localise tumours and vessels embedded within the liver by projecting them on top of a laparoscopic image.","Preoperative 3D models extracted from CT or MRI data are registered to the intraoperative laparoscopic images during this process.","In terms of 3D-2D fusion, most of the algorithms make use of anatomical landmarks to guide registration.","These landmarks include the liver's inferior ridge, the falciform ligament, and the occluding contours.","They are usually marked by hand in both the laparoscopic image and the 3D model, which is time-consuming and may contain errors if done by a non-experienced user.","Therefore, there is a need to automate this process so that augmented reality can be used effectively in the operating room.","We present the Preoperative-to-Intraoperative Laparoscopic Fusion Challenge (P2ILF), held during the Medical Imaging and Computer Assisted Interventions (MICCAI 2022) conference, which investigates the possibilities of detecting these landmarks automatically and using them in registration.","The challenge was divided into two tasks: 1) A 2D and 3D landmark detection task and 2) a 3D-2D registration task.","The teams were provided with training data consisting of 167 laparoscopic images and 9 preoperative 3D models from 9 patients, with the corresponding 2D and 3D landmark annotations.","A total of 6 teams from 4 countries participated, whose proposed methods were evaluated on 16 images and two preoperative 3D models from two patients.","All the teams proposed deep learning-based methods for the 2D and 3D landmark segmentation tasks and differentiable rendering-based methods for the registration task.","Based on the experimental outcomes, we propose three key hypotheses that determine current limitations and future directions for research in this domain."],"url":"http://arxiv.org/abs/2401.15753v1"}
{"created":"2024-01-28 19:47:17","title":"SegmentAnyTree: A sensor and platform agnostic deep learning model for tree segmentation using laser scanning data","abstract":"This research advances individual tree crown (ITC) segmentation in lidar data, using a deep learning model applicable to various laser scanning types: airborne (ULS), terrestrial (TLS), and mobile (MLS). It addresses the challenge of transferability across different data characteristics in 3D forest scene analysis. The study evaluates the model's performance based on platform (ULS, MLS) and data density, testing five scenarios with varying input data, including sparse versions, to gauge adaptability and canopy layer efficacy. The model, based on PointGroup architecture, is a 3D CNN with separate heads for semantic and instance segmentation, validated on diverse point cloud datasets. Results show point cloud sparsification enhances performance, aiding sparse data handling and improving detection in dense forests. The model performs well with >50 points per sq. m densities but less so at 10 points per sq. m due to higher omission rates. It outperforms existing methods (e.g., Point2Tree, TLS2trees) in detection, omission, commission rates, and F1 score, setting new benchmarks on LAUTx, Wytham Woods, and TreeLearn datasets. In conclusion, this study shows the feasibility of a sensor-agnostic model for diverse lidar data, surpassing sensor-specific approaches and setting new standards in tree segmentation, particularly in complex forests. This contributes to future ecological modeling and forest management advancements.","sentences":["This research advances individual tree crown (ITC) segmentation in lidar data, using a deep learning model applicable to various laser scanning types: airborne (ULS), terrestrial (TLS), and mobile (MLS).","It addresses the challenge of transferability across different data characteristics in 3D forest scene analysis.","The study evaluates the model's performance based on platform (ULS, MLS) and data density, testing five scenarios with varying input data, including sparse versions, to gauge adaptability and canopy layer efficacy.","The model, based on PointGroup architecture, is a 3D CNN with separate heads for semantic and instance segmentation, validated on diverse point cloud datasets.","Results show point cloud sparsification enhances performance, aiding sparse data handling and improving detection in dense forests.","The model performs well with >50 points per sq. m densities but less so at 10 points per sq. m due to higher omission rates.","It outperforms existing methods (e.g., Point2Tree, TLS2trees) in detection, omission, commission rates, and F1 score, setting new benchmarks on LAUTx, Wytham Woods, and TreeLearn datasets.","In conclusion, this study shows the feasibility of a sensor-agnostic model for diverse lidar data, surpassing sensor-specific approaches and setting new standards in tree segmentation, particularly in complex forests.","This contributes to future ecological modeling and forest management advancements."],"url":"http://arxiv.org/abs/2401.15739v1"}
{"created":"2024-01-28 18:28:33","title":"Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data","abstract":"In the face of escalating climate changes, typhoon intensities and their ensuing damage have surged. Accurate trajectory prediction is crucial for effective damage control. Traditional physics-based models, while comprehensive, are computationally intensive and rely heavily on the expertise of forecasters. Contemporary data-driven methods often rely on reanalysis data, which can be considered to be the closest to the true representation of weather conditions. However, reanalysis data is not produced in real-time and requires time for adjustment because prediction models are calibrated with observational data. This reanalysis data, such as ERA5, falls short in challenging real-world situations. Optimal preparedness necessitates predictions at least 72 hours in advance, beyond the capabilities of standard physics models. In response to these constraints, we present an approach that harnesses real-time Unified Model (UM) data, sidestepping the limitations of reanalysis data. Our model provides predictions at 6-hour intervals for up to 72 hours in advance and outperforms both state-of-the-art data-driven methods and numerical weather prediction models. In line with our efforts to mitigate adversities inflicted by \\rthree{typhoons}, we release our preprocessed \\textit{PHYSICS TRACK} dataset, which includes ERA5 reanalysis data, typhoon best-track, and UM forecast data.","sentences":["In the face of escalating climate changes, typhoon intensities and their ensuing damage have surged.","Accurate trajectory prediction is crucial for effective damage control.","Traditional physics-based models, while comprehensive, are computationally intensive and rely heavily on the expertise of forecasters.","Contemporary data-driven methods often rely on reanalysis data, which can be considered to be the closest to the true representation of weather conditions.","However, reanalysis data is not produced in real-time and requires time for adjustment because prediction models are calibrated with observational data.","This reanalysis data, such as ERA5, falls short in challenging real-world situations.","Optimal preparedness necessitates predictions at least 72 hours in advance, beyond the capabilities of standard physics models.","In response to these constraints, we present an approach that harnesses real-time Unified Model (UM) data, sidestepping the limitations of reanalysis data.","Our model provides predictions at 6-hour intervals for up to 72 hours in advance and outperforms both state-of-the-art data-driven methods and numerical weather prediction models.","In line with our efforts to mitigate adversities inflicted by \\rthree{typhoons}, we release our preprocessed \\textit{PHYSICS TRACK} dataset, which includes ERA5 reanalysis data, typhoon best-track, and UM forecast data."],"url":"http://arxiv.org/abs/2401.15726v1"}
{"created":"2024-01-28 18:13:19","title":"Reducing Coverage Depth in DNA Storage: A Combinatorial Perspective on Random Access Efficiency","abstract":"We investigate the fundamental limits of the recently proposed random access coverage depth problem for DNA data storage. Under this paradigm, it is assumed that the user information consists of $k$ information strands, which are encoded into $n$ strands via some generator matrix $G$. In the sequencing process, the strands are read uniformly at random, since each strand is available in a large number of copies. In this context, the random access coverage depth problem refers to the expected number of reads (i.e., sequenced strands) until it is possible to decode a specific information strand, which is requested by the user. The goal is to minimize the maximum expectation over all possible requested information strands, and this value is denoted by $T_{\\max}(G)$. This paper introduces new techniques to investigate the random access coverage depth problem, which capture its combinatorial nature. We establish two general formulas to find $T_{max}(G)$ for arbitrary matrices. We introduce the concept of recovery balanced codes and combine all these results and notions to compute $T_{\\max}(G)$ for MDS, simplex, and Hamming codes. We also study the performance of modified systematic MDS matrices and our results show that the best results for $T_{\\max}(G)$ are achieved with a specific mix of encoded strands and replication of the information strands.","sentences":["We investigate the fundamental limits of the recently proposed random access coverage depth problem for DNA data storage.","Under this paradigm, it is assumed that the user information consists of $k$ information strands, which are encoded into $n$ strands via some generator matrix $G$. In the sequencing process, the strands are read uniformly at random, since each strand is available in a large number of copies.","In this context, the random access coverage depth problem refers to the expected number of reads (i.e., sequenced strands) until it is possible to decode a specific information strand, which is requested by the user.","The goal is to minimize the maximum expectation over all possible requested information strands, and this value is denoted by $T_{\\max}(G)$. This paper introduces new techniques to investigate the random access coverage depth problem, which capture its combinatorial nature.","We establish two general formulas to find $T_{max}(G)$ for arbitrary matrices.","We introduce the concept of recovery balanced codes and combine all these results and notions to compute $T_{\\max}(G)$ for MDS, simplex, and Hamming codes.","We also study the performance of modified systematic MDS matrices and our results show that the best results for $T_{\\max}(G)$ are achieved with a specific mix of encoded strands and replication of the information strands."],"url":"http://arxiv.org/abs/2401.15722v1"}
{"created":"2024-01-28 18:09:02","title":"A Study of Acquisition Functions for Medical Imaging Deep Active Learning","abstract":"The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \\textit{bald} performs on average better than other acquisition functions. Our extended analyses however revealed that all acquisition functions perform badly on the positive (cancerous) samples, suggesting exploitation of class unbalance, which could be crucial in real-world settings. We finish by suggesting future work directions that would be useful to improve this current work. The code of our implementation is open-sourced at \\url{https://github.com/bonaventuredossou/ece526_course_project}","sentences":["The Deep Learning revolution has enabled groundbreaking achievements in recent years.","From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements.","However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context.","In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited).","We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset.","We also explored the effect of acquired pool size on the model's performance.","Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \\textit{bald} performs on average better than other acquisition functions.","Our extended analyses however revealed that all acquisition functions perform badly on the positive (cancerous) samples, suggesting exploitation of class unbalance, which could be crucial in real-world settings.","We finish by suggesting future work directions that would be useful to improve this current work.","The code of our implementation is open-sourced at \\url{https://github.com/bonaventuredossou/ece526_course_project}"],"url":"http://arxiv.org/abs/2401.15721v1"}
{"created":"2024-01-28 17:22:58","title":"Transformational application of Artificial Intelligence and Machine learning in Financial Technologies and Financial services: A bibliometric review","abstract":"In this study, I employ a multifaceted comprehensive scientometric approach to explore the intellectual underpinnings of AI and ML in financial research by examining the publication patterns of articles, journals, authors, institutions, and nations by leveraging quantitative techniques, that transcend conventional systematic literature reviews, enabling the effective analysis of vast scientometric and bibliographic data. By applying these approaches, I identify influential works, seminal contributions, thought leaders, topical clusters, research streams, and new research frontiers, ultimately fostering a deeper understanding of the knowledge structure in AI and ML finance research by considering publication records from 2010 to 2022 from several search engines and database sources. The present study finds a marked increase in publications from 2017 to 2022, which highlights a growing interest and expanding research activity in the field, indicating its potential significance and relevance in the contemporary academic landscape.","sentences":["In this study, I employ a multifaceted comprehensive scientometric approach to explore the intellectual underpinnings of AI and ML in financial research by examining the publication patterns of articles, journals, authors, institutions, and nations by leveraging quantitative techniques, that transcend conventional systematic literature reviews, enabling the effective analysis of vast scientometric and bibliographic data.","By applying these approaches, I identify influential works, seminal contributions, thought leaders, topical clusters, research streams, and new research frontiers, ultimately fostering a deeper understanding of the knowledge structure in AI and ML finance research by considering publication records from 2010 to 2022 from several search engines and database sources.","The present study finds a marked increase in publications from 2017 to 2022, which highlights a growing interest and expanding research activity in the field, indicating its potential significance and relevance in the contemporary academic landscape."],"url":"http://arxiv.org/abs/2401.15710v1"}
{"created":"2024-01-28 16:44:17","title":"HappyRouting: Learning Emotion-Aware Route Trajectories for Scalable In-The-Wild Navigation","abstract":"Routes represent an integral part of triggering emotions in drivers. Navigation systems allow users to choose a navigation strategy, such as the fastest or shortest route. However, they do not consider the driver's emotional well-being. We present HappyRouting, a novel navigation-based empathic car interface guiding drivers through real-world traffic while evoking positive emotions. We propose design considerations, derive a technical architecture, and implement a routing optimization framework. Our contribution is a machine learning-based generated emotion map layer, predicting emotions along routes based on static and dynamic contextual data. We evaluated HappyRouting in a real-world driving study (N=13), finding that happy routes increase subjectively perceived valence by 11% (p=.007). Although happy routes take 1.25 times longer on average, participants perceived the happy route as shorter, presenting an emotion-enhanced alternative to today's fastest routing mechanisms. We discuss how emotion-based routing can be integrated into navigation apps, promoting emotional well-being for mobility use.","sentences":["Routes represent an integral part of triggering emotions in drivers.","Navigation systems allow users to choose a navigation strategy, such as the fastest or shortest route.","However, they do not consider the driver's emotional well-being.","We present HappyRouting, a novel navigation-based empathic car interface guiding drivers through real-world traffic while evoking positive emotions.","We propose design considerations, derive a technical architecture, and implement a routing optimization framework.","Our contribution is a machine learning-based generated emotion map layer, predicting emotions along routes based on static and dynamic contextual data.","We evaluated HappyRouting in a real-world driving study (N=13), finding that happy routes increase subjectively perceived valence by 11% (p=.007).","Although happy routes take 1.25 times longer on average, participants perceived the happy route as shorter, presenting an emotion-enhanced alternative to today's fastest routing mechanisms.","We discuss how emotion-based routing can be integrated into navigation apps, promoting emotional well-being for mobility use."],"url":"http://arxiv.org/abs/2401.15695v1"}
{"created":"2024-01-28 16:30:13","title":"One for all: A novel Dual-space Co-training baseline for Large-scale Multi-View Clustering","abstract":"In this paper, we propose a novel multi-view clustering model, named Dual-space Co-training Large-scale Multi-view Clustering (DSCMC). The main objective of our approach is to enhance the clustering performance by leveraging co-training in two distinct spaces. In the original space, we learn a projection matrix to obtain latent consistent anchor graphs from different views. This process involves capturing the inherent relationships and structures between data points within each view. Concurrently, we employ a feature transformation matrix to map samples from various views to a shared latent space. This transformation facilitates the alignment of information from multiple views, enabling a comprehensive understanding of the underlying data distribution. We jointly optimize the construction of the latent consistent anchor graph and the feature transformation to generate a discriminative anchor graph. This anchor graph effectively captures the essential characteristics of the multi-view data and serves as a reliable basis for subsequent clustering analysis. Moreover, the element-wise method is proposed to avoid the impact of diverse information between different views. Our algorithm has an approximate linear computational complexity, which guarantees its successful application on large-scale datasets. Through experimental validation, we demonstrate that our method significantly reduces computational complexity while yielding superior clustering performance compared to existing approaches.","sentences":["In this paper, we propose a novel multi-view clustering model, named Dual-space Co-training Large-scale Multi-view Clustering (DSCMC).","The main objective of our approach is to enhance the clustering performance by leveraging co-training in two distinct spaces.","In the original space, we learn a projection matrix to obtain latent consistent anchor graphs from different views.","This process involves capturing the inherent relationships and structures between data points within each view.","Concurrently, we employ a feature transformation matrix to map samples from various views to a shared latent space.","This transformation facilitates the alignment of information from multiple views, enabling a comprehensive understanding of the underlying data distribution.","We jointly optimize the construction of the latent consistent anchor graph and the feature transformation to generate a discriminative anchor graph.","This anchor graph effectively captures the essential characteristics of the multi-view data and serves as a reliable basis for subsequent clustering analysis.","Moreover, the element-wise method is proposed to avoid the impact of diverse information between different views.","Our algorithm has an approximate linear computational complexity, which guarantees its successful application on large-scale datasets.","Through experimental validation, we demonstrate that our method significantly reduces computational complexity while yielding superior clustering performance compared to existing approaches."],"url":"http://arxiv.org/abs/2401.15691v1"}
{"created":"2024-01-28 16:17:59","title":"Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance","abstract":"The synthesis of 3D facial animations from speech has garnered considerable attention. Due to the scarcity of high-quality 4D facial data and well-annotated abundant multi-modality labels, previous methods often suffer from limited realism and a lack of lexible conditioning. We address this challenge through a trilogy. We first introduce Generalized Neural Parametric Facial Asset (GNPFA), an efficient variational auto-encoder mapping facial geometry and images to a highly generalized expression latent space, decoupling expressions and identities. Then, we utilize GNPFA to extract high-quality expressions and accurate head poses from a large array of videos. This presents the M2F-D dataset, a large, diverse, and scan-level co-speech 3D facial animation dataset with well-annotated emotional and style labels. Finally, we propose Media2Face, a diffusion model in GNPFA latent space for co-speech facial animation generation, accepting rich multi-modality guidances from audio, text, and image. Extensive experiments demonstrate that our model not only achieves high fidelity in facial animation synthesis but also broadens the scope of expressiveness and style adaptability in 3D facial animation.","sentences":["The synthesis of 3D facial animations from speech has garnered considerable attention.","Due to the scarcity of high-quality 4D facial data and well-annotated abundant multi-modality labels, previous methods often suffer from limited realism and a lack of lexible conditioning.","We address this challenge through a trilogy.","We first introduce Generalized Neural Parametric Facial Asset (GNPFA), an efficient variational auto-encoder mapping facial geometry and images to a highly generalized expression latent space, decoupling expressions and identities.","Then, we utilize GNPFA to extract high-quality expressions and accurate head poses from a large array of videos.","This presents the M2F-D dataset, a large, diverse, and scan-level co-speech 3D facial animation dataset with well-annotated emotional and style labels.","Finally, we propose Media2Face, a diffusion model in GNPFA latent space for co-speech facial animation generation, accepting rich multi-modality guidances from audio, text, and image.","Extensive experiments demonstrate that our model not only achieves high fidelity in facial animation synthesis but also broadens the scope of expressiveness and style adaptability in 3D facial animation."],"url":"http://arxiv.org/abs/2401.15687v1"}
{"created":"2024-01-28 16:02:27","title":"Assessment of Autism and ADHD: A Comparative Analysis of Drawing Velocity Profiles and the NEPSY Test","abstract":"The increasing prevalence of Autism Spectrum Disorder and Attention-Deficit/ Hyperactivity Disorder among students highlights the need to improve evaluation and diagnostic techniques, as well as effective tools to mitigate the negative consequences associated with these disorders. With the widespread use of touchscreen mobile devices, there is an opportunity to gather comprehensive data beyond visual cues. These devices enable the collection and visualization of information on velocity profiles and the time taken to complete drawing and handwriting tasks. These data can be leveraged to develop new neuropsychological tests based on the velocity profile that assists in distinguishing between challenging cases of ASD and ADHD that are difficult to differentiate in clinical practice. In this paper, we present a proof of concept that compares and combines the results obtained from standardized tasks in the NEPSY-II assessment with a proposed observational scale based on the visual analysis of the velocity profile collected using digital tablets.","sentences":["The increasing prevalence of Autism Spectrum Disorder and Attention-Deficit/ Hyperactivity Disorder among students highlights the need to improve evaluation and diagnostic techniques, as well as effective tools to mitigate the negative consequences associated with these disorders.","With the widespread use of touchscreen mobile devices, there is an opportunity to gather comprehensive data beyond visual cues.","These devices enable the collection and visualization of information on velocity profiles and the time taken to complete drawing and handwriting tasks.","These data can be leveraged to develop new neuropsychological tests based on the velocity profile that assists in distinguishing between challenging cases of ASD and ADHD that are difficult to differentiate in clinical practice.","In this paper, we present a proof of concept that compares and combines the results obtained from standardized tasks in the NEPSY-II assessment with a proposed observational scale based on the visual analysis of the velocity profile collected using digital tablets."],"url":"http://arxiv.org/abs/2401.15685v1"}
{"created":"2024-01-28 14:58:50","title":"A probabilistic analysis on general probabilistic scheduling problems","abstract":"The scheduling problem is a key class of optimization problems and has various kinds of applications both in practical and theoretical scenarios. In the scheduling problem, probabilistic analysis is a basic tool for investigating performance of scheduling algorithms, and therefore has been carried out by plenty amount of prior works. However, probabilistic analysis has several potential problems. For example, current research interest in the scheduling problem is limited to i.i.d. scenarios, due to its simplicity for analysis. This paper provides a new framework for probabilistic analysis in the scheduling problem and aims to deal with such problems. As a consequence, we obtain several theorems including a theoretical limit of the scheduling problem which can be applied to \\emph{general, non-i.i.d. probability distributions}. Several information theoretic techniques, such as \\emph{information-spectrum method}, turned out to be useful to prove our results. Since the scheduling problem has relations to many other research fields, our framework hopefully yields other interesting applications in the future.","sentences":["The scheduling problem is a key class of optimization problems and has various kinds of applications both in practical and theoretical scenarios.","In the scheduling problem, probabilistic analysis is a basic tool for investigating performance of scheduling algorithms, and therefore has been carried out by plenty amount of prior works.","However, probabilistic analysis has several potential problems.","For example, current research interest in the scheduling problem is limited to i.i.d. scenarios, due to its simplicity for analysis.","This paper provides a new framework for probabilistic analysis in the scheduling problem and aims to deal with such problems.","As a consequence, we obtain several theorems including a theoretical limit of the scheduling problem which can be applied to \\emph{general, non-i.i.d. probability distributions}.","Several information theoretic techniques, such as \\emph{information-spectrum method}, turned out to be useful to prove our results.","Since the scheduling problem has relations to many other research fields, our framework hopefully yields other interesting applications in the future."],"url":"http://arxiv.org/abs/2401.15677v1"}
{"created":"2024-01-28 14:39:43","title":"Evaluating Echo State Network for Parkinson's Disease Prediction using Voice Features","abstract":"Parkinson's disease (PD) is a debilitating neurological disorder that necessitates precise and early diagnosis for effective patient care. This study aims to develop a diagnostic model capable of achieving both high accuracy and minimizing false negatives, a critical factor in clinical practice. Given the limited training data, a feature selection strategy utilizing ANOVA is employed to identify the most informative features. Subsequently, various machine learning methods, including Echo State Networks (ESN), Random Forest, k-nearest Neighbors, Support Vector Classifier, Extreme Gradient Boosting, and Decision Tree, are employed and thoroughly evaluated. The statistical analyses of the results highlight ESN's exceptional performance, showcasing not only superior accuracy but also the lowest false negative rate among all methods. Consistently, statistical data indicates that the ESN method consistently maintains a false negative rate of less than 8% in 83% of cases. ESN's capacity to strike a delicate balance between diagnostic precision and minimizing misclassifications positions it as an exemplary choice for PD diagnosis, especially in scenarios characterized by limited data. This research marks a significant step towards more efficient and reliable PD diagnosis, with potential implications for enhanced patient outcomes and healthcare dynamics.","sentences":["Parkinson's disease (PD) is a debilitating neurological disorder that necessitates precise and early diagnosis for effective patient care.","This study aims to develop a diagnostic model capable of achieving both high accuracy and minimizing false negatives, a critical factor in clinical practice.","Given the limited training data, a feature selection strategy utilizing ANOVA is employed to identify the most informative features.","Subsequently, various machine learning methods, including Echo State Networks (ESN), Random Forest, k-nearest Neighbors, Support Vector Classifier, Extreme Gradient Boosting, and Decision Tree, are employed and thoroughly evaluated.","The statistical analyses of the results highlight ESN's exceptional performance, showcasing not only superior accuracy but also the lowest false negative rate among all methods.","Consistently, statistical data indicates that the ESN method consistently maintains a false negative rate of less than 8% in 83% of cases.","ESN's capacity to strike a delicate balance between diagnostic precision and minimizing misclassifications positions it as an exemplary choice for PD diagnosis, especially in scenarios characterized by limited data.","This research marks a significant step towards more efficient and reliable PD diagnosis, with potential implications for enhanced patient outcomes and healthcare dynamics."],"url":"http://arxiv.org/abs/2401.15672v1"}
{"created":"2024-01-28 14:32:15","title":"YODA: Teacher-Student Progressive Learning for Language Models","abstract":"Although large language models (LLMs) have demonstrated adeptness in a range of tasks, they still lag behind human learning efficiency. This disparity is often linked to the inherent human capacity to learn from basic examples, gradually generalize and handle more complex problems, and refine their skills with continuous feedback. Inspired by this, this paper introduces YODA, a novel teacher-student progressive learning framework that emulates the teacher-student education process to improve the efficacy of model fine-tuning. The framework operates on an interactive \\textit{basic-generalized-harder} loop. The teacher agent provides tailored feedback on the student's answers, and systematically organizes the education process. This process unfolds by teaching the student basic examples, reinforcing understanding through generalized questions, and then enhancing learning by posing questions with progressively enhanced complexity. With the teacher's guidance, the student learns to iteratively refine its answer with feedback, and forms a robust and comprehensive understanding of the posed questions. The systematic procedural data, which reflects the progressive learning process of humans, is then utilized for model training. Taking math reasoning as a testbed, experiments show that training LLaMA2 with data from YODA improves SFT with significant performance gain (+17.01\\% on GSM8K and +9.98\\% on MATH). In addition, we find that training with curriculum learning further improves learning robustness.","sentences":["Although large language models (LLMs) have demonstrated adeptness in a range of tasks, they still lag behind human learning efficiency.","This disparity is often linked to the inherent human capacity to learn from basic examples, gradually generalize and handle more complex problems, and refine their skills with continuous feedback.","Inspired by this, this paper introduces YODA, a novel teacher-student progressive learning framework that emulates the teacher-student education process to improve the efficacy of model fine-tuning.","The framework operates on an interactive \\textit{basic-generalized-harder} loop.","The teacher agent provides tailored feedback on the student's answers, and systematically organizes the education process.","This process unfolds by teaching the student basic examples, reinforcing understanding through generalized questions, and then enhancing learning by posing questions with progressively enhanced complexity.","With the teacher's guidance, the student learns to iteratively refine its answer with feedback, and forms a robust and comprehensive understanding of the posed questions.","The systematic procedural data, which reflects the progressive learning process of humans, is then utilized for model training.","Taking math reasoning as a testbed, experiments show that training LLaMA2 with data from YODA improves SFT with significant performance gain (+17.01\\% on GSM8K and +9.98\\% on MATH).","In addition, we find that training with curriculum learning further improves learning robustness."],"url":"http://arxiv.org/abs/2401.15670v1"}
{"created":"2024-01-28 14:12:21","title":"Error-Correcting Codes for Combinatorial DNA Composite","abstract":"Data storage in DNA is developing as a possible solution for archival digital data. Recently, to further increase the potential capacity of DNA-based data storage systems, the combinatorial composite DNA synthesis method was suggested. This approach extends the DNA alphabet by harnessing short DNA fragment reagents, known as shortmers. The shortmers are building blocks of the alphabet symbols, consisting of a fixed number of shortmers. Thus, when information is read, it is possible that one of the shortmers that forms part of the composition of a symbol is missing and therefore the symbol cannot be determined. In this paper, we model this type of error as a type of asymmetric error and propose code constructions that can correct such errors in this setup. We also provide a lower bound on the redundancy of such error-correcting codes and give an explicit encoder and decoder pair for our construction. Our suggested error model is also supported by an analysis of data from actual experiments that produced DNA according to the combinatorial scheme. Lastly, we also provide a statistical evaluation of the probability of observing such error events, as a function of read depth.","sentences":["Data storage in DNA is developing as a possible solution for archival digital data.","Recently, to further increase the potential capacity of DNA-based data storage systems, the combinatorial composite DNA synthesis method was suggested.","This approach extends the DNA alphabet by harnessing short DNA fragment reagents, known as shortmers.","The shortmers are building blocks of the alphabet symbols, consisting of a fixed number of shortmers.","Thus, when information is read, it is possible that one of the shortmers that forms part of the composition of a symbol is missing and therefore the symbol cannot be determined.","In this paper, we model this type of error as a type of asymmetric error and propose code constructions that can correct such errors in this setup.","We also provide a lower bound on the redundancy of such error-correcting codes and give an explicit encoder and decoder pair for our construction.","Our suggested error model is also supported by an analysis of data from actual experiments that produced DNA according to the combinatorial scheme.","Lastly, we also provide a statistical evaluation of the probability of observing such error events, as a function of read depth."],"url":"http://arxiv.org/abs/2401.15666v1"}
{"created":"2024-01-28 13:26:47","title":"Data-Free Generalized Zero-Shot Learning","abstract":"Deep learning models have the ability to extract rich knowledge from large-scale datasets. However, the sharing of data has become increasingly challenging due to concerns regarding data copyright and privacy. Consequently, this hampers the effective transfer of knowledge from existing data to novel downstream tasks and concepts. Zero-shot learning (ZSL) approaches aim to recognize new classes by transferring semantic knowledge learned from base classes. However, traditional generative ZSL methods often require access to real images from base classes and rely on manually annotated attributes, which presents challenges in terms of data restrictions and model scalability. To this end, this paper tackles a challenging and practical problem dubbed as data-free zero-shot learning (DFZSL), where only the CLIP-based base classes data pre-trained classifier is available for zero-shot classification. Specifically, we propose a generic framework for DFZSL, which consists of three main components. Firstly, to recover the virtual features of the base data, we model the CLIP features of base class images as samples from a von Mises-Fisher (vMF) distribution based on the pre-trained classifier. Secondly, we leverage the text features of CLIP as low-cost semantic information and propose a feature-language prompt tuning (FLPT) method to further align the virtual image features and textual features. Thirdly, we train a conditional generative model using the well-aligned virtual image features and corresponding semantic text features, enabling the generation of new classes features and achieve better zero-shot generalization. Our framework has been evaluated on five commonly used benchmarks for generalized ZSL, as well as 11 benchmarks for the base-to-new ZSL. The results demonstrate the superiority and effectiveness of our approach. Our code is available in https://github.com/ylong4/DFZSL","sentences":["Deep learning models have the ability to extract rich knowledge from large-scale datasets.","However, the sharing of data has become increasingly challenging due to concerns regarding data copyright and privacy.","Consequently, this hampers the effective transfer of knowledge from existing data to novel downstream tasks and concepts.","Zero-shot learning (ZSL) approaches aim to recognize new classes by transferring semantic knowledge learned from base classes.","However, traditional generative ZSL methods often require access to real images from base classes and rely on manually annotated attributes, which presents challenges in terms of data restrictions and model scalability.","To this end, this paper tackles a challenging and practical problem dubbed as data-free zero-shot learning (DFZSL), where only the CLIP-based base classes data pre-trained classifier is available for zero-shot classification.","Specifically, we propose a generic framework for DFZSL, which consists of three main components.","Firstly, to recover the virtual features of the base data, we model the CLIP features of base class images as samples from a von Mises-Fisher (vMF) distribution based on the pre-trained classifier.","Secondly, we leverage the text features of CLIP as low-cost semantic information and propose a feature-language prompt tuning (FLPT) method to further align the virtual image features and textual features.","Thirdly, we train a conditional generative model using the well-aligned virtual image features and corresponding semantic text features, enabling the generation of new classes features and achieve better zero-shot generalization.","Our framework has been evaluated on five commonly used benchmarks for generalized ZSL, as well as 11 benchmarks for the base-to-new ZSL.","The results demonstrate the superiority and effectiveness of our approach.","Our code is available in https://github.com/ylong4/DFZSL"],"url":"http://arxiv.org/abs/2401.15657v1"}
{"created":"2024-01-28 12:51:34","title":"CPDM: Content-Preserving Diffusion Model for Underwater Image Enhancement","abstract":"Underwater image enhancement (UIE) is challenging since image degradation in aquatic environments is complicated and changing over time. Existing mainstream methods rely on either physical-model or data-driven, suffering from performance bottlenecks due to changes in imaging conditions or training instability. In this article, we make the first attempt to adapt the diffusion model to the UIE task and propose a Content-Preserving Diffusion Model (CPDM) to address the above challenges. CPDM first leverages a diffusion model as its fundamental model for stable training and then designs a content-preserving framework to deal with changes in imaging conditions. Specifically, we construct a conditional input module by adopting both the raw image and the difference between the raw and noisy images as the input, which can enhance the model's adaptability by considering the changes involving the raw images in underwater environments. To preserve the essential content of the raw images, we construct a content compensation module for content-aware training by extracting low-level features from the raw images. Extensive experimental results validate the effectiveness of our CPDM, surpassing the state-of-the-art methods in terms of both subjective and objective metrics.","sentences":["Underwater image enhancement (UIE) is challenging since image degradation in aquatic environments is complicated and changing over time.","Existing mainstream methods rely on either physical-model or data-driven, suffering from performance bottlenecks due to changes in imaging conditions or training instability.","In this article, we make the first attempt to adapt the diffusion model to the UIE task and propose a Content-Preserving Diffusion Model (CPDM) to address the above challenges.","CPDM first leverages a diffusion model as its fundamental model for stable training and then designs a content-preserving framework to deal with changes in imaging conditions.","Specifically, we construct a conditional input module by adopting both the raw image and the difference between the raw and noisy images as the input, which can enhance the model's adaptability by considering the changes involving the raw images in underwater environments.","To preserve the essential content of the raw images, we construct a content compensation module for content-aware training by extracting low-level features from the raw images.","Extensive experimental results validate the effectiveness of our CPDM, surpassing the state-of-the-art methods in terms of both subjective and objective metrics."],"url":"http://arxiv.org/abs/2401.15649v1"}
