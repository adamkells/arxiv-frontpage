{"created":"2025-01-28 18:59:44","title":"SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training","abstract":"Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models. However, their roles in enhancing model generalization capabilities remain unclear. This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants. We introduce GeneralPoints, an arithmetic reasoning card game, and adopt V-IRL, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants in both textual and visual domains. We show that RL, especially when trained with an outcome-based reward, generalizes across both rule-based textual and visual variants. SFT, in contrast, tends to memorize training data and struggles to generalize out-of-distribution scenarios. Further analysis reveals that RL improves the model's underlying visual recognition capabilities, contributing to its enhanced generalization in the visual domain. Despite RL's superior generalization, we show that SFT remains essential for effective RL training; SFT stabilizes the model's output format, enabling subsequent RL to achieve its performance gains. These findings demonstrates the capability of RL for acquiring generalizable knowledge in complex, multi-modal tasks.","sentences":["Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models.","However, their roles in enhancing model generalization capabilities remain unclear.","This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants.","We introduce GeneralPoints, an arithmetic reasoning card game, and adopt V-IRL, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants in both textual and visual domains.","We show that RL, especially when trained with an outcome-based reward, generalizes across both rule-based textual and visual variants.","SFT, in contrast, tends to memorize training data and struggles to generalize out-of-distribution scenarios.","Further analysis reveals that RL improves the model's underlying visual recognition capabilities, contributing to its enhanced generalization in the visual domain.","Despite RL's superior generalization, we show that SFT remains essential for effective RL training; SFT stabilizes the model's output format, enabling subsequent RL to achieve its performance gains.","These findings demonstrates the capability of RL for acquiring generalizable knowledge in complex, multi-modal tasks."],"url":"http://arxiv.org/abs/2501.17161v1"}
{"created":"2025-01-28 18:53:14","title":"Scanning Trojaned Models Using Out-of-Distribution Samples","abstract":"Scanning for trojan (backdoor) in deep neural networks is crucial due to their significant real-world applications. There has been an increasing focus on developing effective general trojan scanning methods across various trojan attacks. Despite advancements, there remains a shortage of methods that perform effectively without preconceived assumptions about the backdoor attack method. Additionally, we have observed that current methods struggle to identify classifiers trojaned using adversarial training. Motivated by these challenges, our study introduces a novel scanning method named TRODO (TROjan scanning by Detection of adversarial shifts in Out-of-distribution samples). TRODO leverages the concept of \"blind spots\"--regions where trojaned classifiers erroneously identify out-of-distribution (OOD) samples as in-distribution (ID). We scan for these blind spots by adversarially shifting OOD samples towards in-distribution. The increased likelihood of perturbed OOD samples being classified as ID serves as a signature for trojan detection. TRODO is both trojan and label mapping agnostic, effective even against adversarially trained trojaned classifiers. It is applicable even in scenarios where training data is absent, demonstrating high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a robust trojan scanning strategy.","sentences":["Scanning for trojan (backdoor) in deep neural networks is crucial due to their significant real-world applications.","There has been an increasing focus on developing effective general trojan scanning methods across various trojan attacks.","Despite advancements, there remains a shortage of methods that perform effectively without preconceived assumptions about the backdoor attack method.","Additionally, we have observed that current methods struggle to identify classifiers trojaned using adversarial training.","Motivated by these challenges, our study introduces a novel scanning method named TRODO (TROjan scanning by Detection of adversarial shifts in Out-of-distribution samples).","TRODO leverages the concept of \"blind spots\"--regions where trojaned classifiers erroneously identify out-of-distribution (OOD) samples as in-distribution (ID).","We scan for these blind spots by adversarially shifting OOD samples towards in-distribution.","The increased likelihood of perturbed OOD samples being classified as ID serves as a signature for trojan detection.","TRODO is both trojan and label mapping agnostic, effective even against adversarially trained trojaned classifiers.","It is applicable even in scenarios where training data is absent, demonstrating high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a robust trojan scanning strategy."],"url":"http://arxiv.org/abs/2501.17151v1"}
{"created":"2025-01-28 18:45:07","title":"FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data","abstract":"Prior research on training grounded factuality classification models to detect hallucinations in large language models (LLMs) has relied on public natural language inference (NLI) data and synthetic data. However, conventional NLI datasets are not well-suited for document-level reasoning, which is critical for detecting LLM hallucinations. Recent approaches to document-level synthetic data generation involve iteratively removing sentences from documents and annotating factuality using LLM-based prompts. While effective, this method is computationally expensive for long documents and limited by the LLM's capabilities. In this work, we analyze the differences between existing synthetic training data used in state-of-the-art models and real LLM output claims. Based on our findings, we propose a novel approach for synthetic data generation, CG2C, that leverages multi-hop reasoning on context graphs extracted from documents. Our fact checker model, FactCG, demonstrates improved performance with more connected reasoning, using the same backbone models. Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark with much smaller model size.","sentences":["Prior research on training grounded factuality classification models to detect hallucinations in large language models (LLMs) has relied on public natural language inference (NLI) data and synthetic data.","However, conventional NLI datasets are not well-suited for document-level reasoning, which is critical for detecting LLM hallucinations.","Recent approaches to document-level synthetic data generation involve iteratively removing sentences from documents and annotating factuality using LLM-based prompts.","While effective, this method is computationally expensive for long documents and limited by the LLM's capabilities.","In this work, we analyze the differences between existing synthetic training data used in state-of-the-art models and real LLM output claims.","Based on our findings, we propose a novel approach for synthetic data generation, CG2C, that leverages multi-hop reasoning on context graphs extracted from documents.","Our fact checker model, FactCG, demonstrates improved performance with more connected reasoning, using the same backbone models.","Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark with much smaller model size."],"url":"http://arxiv.org/abs/2501.17144v1"}
{"created":"2025-01-28 18:23:12","title":"Scenario Understanding of Traffic Scenes Through Large Visual Language Models","abstract":"Deep learning models for autonomous driving, encompassing perception, planning, and control, depend on vast datasets to achieve their high performance. However, their generalization often suffers due to domain-specific data distributions, making an effective scene-based categorization of samples necessary to improve their reliability across diverse domains. Manual captioning, though valuable, is both labor-intensive and time-consuming, creating a bottleneck in the data annotation process. Large Visual Language Models (LVLMs) present a compelling solution by automating image analysis and categorization through contextual queries, often without requiring retraining for new categories. In this study, we evaluate the capabilities of LVLMs, including GPT-4 and LLaVA, to understand and classify urban traffic scenes on both an in-house dataset and the BDD100K. We propose a scalable captioning pipeline that integrates state-of-the-art models, enabling a flexible deployment on new datasets. Our analysis, combining quantitative metrics with qualitative insights, demonstrates the effectiveness of LVLMs to understand urban traffic scenarios and highlights their potential as an efficient tool for data-driven advancements in autonomous driving.","sentences":["Deep learning models for autonomous driving, encompassing perception, planning, and control, depend on vast datasets to achieve their high performance.","However, their generalization often suffers due to domain-specific data distributions, making an effective scene-based categorization of samples necessary to improve their reliability across diverse domains.","Manual captioning, though valuable, is both labor-intensive and time-consuming, creating a bottleneck in the data annotation process.","Large Visual Language Models (LVLMs) present a compelling solution by automating image analysis and categorization through contextual queries, often without requiring retraining for new categories.","In this study, we evaluate the capabilities of LVLMs, including GPT-4 and LLaVA, to understand and classify urban traffic scenes on both an in-house dataset and the BDD100K. We propose a scalable captioning pipeline that integrates state-of-the-art models, enabling a flexible deployment on new datasets.","Our analysis, combining quantitative metrics with qualitative insights, demonstrates the effectiveness of LVLMs to understand urban traffic scenarios and highlights their potential as an efficient tool for data-driven advancements in autonomous driving."],"url":"http://arxiv.org/abs/2501.17131v1"}
{"created":"2025-01-28 18:16:36","title":"Enhancements to P4TG: Performance, Protocols, and Automation","abstract":"The P4-based traffic generator (P4TG) is a hardware-based traffic generator (TG) running on the Intel Tofino 1 ASIC. The TG can generate up to 1 Tb/s of traffic and directly measures rates, packet loss, and other metrics in the data plane. Many researchers and industrial partners have used it since its publication in 2023 and new features have been requested to be incorporated into P4TG. In this work, we provide an overview of the recently added features of P4TG. These enhancements include new traffic generation capabilities including IPv6 and segment routing v6 (SRv6) support and various encapsulation protocols such as VLAN, QinQ, VxLAN, and MPLS. Further, P4TG is ported to the Intel Tofino 2 platform enabling a generation capability of up to 4 Tb/s. The enhancements to P4TG also provide an improved user experience facilitating automated testing based on RFC 2544, report generation, and visualization.","sentences":["The P4-based traffic generator (P4TG) is a hardware-based traffic generator (TG) running on the Intel Tofino 1 ASIC.","The TG can generate up to 1 Tb/s of traffic and directly measures rates, packet loss, and other metrics in the data plane.","Many researchers and industrial partners have used it since its publication in 2023 and new features have been requested to be incorporated into P4TG.","In this work, we provide an overview of the recently added features of P4TG.","These enhancements include new traffic generation capabilities including IPv6 and segment routing v6 (SRv6) support and various encapsulation protocols such as VLAN, QinQ, VxLAN, and MPLS.","Further, P4TG is ported to the Intel Tofino 2 platform enabling a generation capability of up to 4 Tb/s. The enhancements to P4TG also provide an improved user experience facilitating automated testing based on RFC 2544, report generation, and visualization."],"url":"http://arxiv.org/abs/2501.17127v1"}
{"created":"2025-01-28 18:16:05","title":"ECLYPSE: a Python Framework for Simulation and Emulation of the Cloud-Edge Continuum","abstract":"The Cloud-Edge continuum enhances application performance by bringing computation closer to data sources. However, it presents considerable challenges in managing resources and determining service placement, as these tasks require navigating diverse, dynamic environments characterised by fluctuating network conditions. Addressing these challenges calls for tools combining simulation and emulation of Cloud-Edge systems to rigorously assess novel application and resource management strategies. In this paper, we introduce ECLYPSE, a Python-based framework that enables the simulation and emulation of the Cloud-Edge continuum via adaptable resource allocation and service placement models. ECLYPSE features an event-driven architecture for dynamically adapting network configurations and resources. It also supports seamless transitions between simulated and emulated setups. In this work, ECLYPSE capabilities are illustrated over three use cases, showing how the framework supports rapid prototyping across diverse experimental settings.","sentences":["The Cloud-Edge continuum enhances application performance by bringing computation closer to data sources.","However, it presents considerable challenges in managing resources and determining service placement, as these tasks require navigating diverse, dynamic environments characterised by fluctuating network conditions.","Addressing these challenges calls for tools combining simulation and emulation of Cloud-Edge systems to rigorously assess novel application and resource management strategies.","In this paper, we introduce ECLYPSE, a Python-based framework that enables the simulation and emulation of the Cloud-Edge continuum via adaptable resource allocation and service placement models.","ECLYPSE features an event-driven architecture for dynamically adapting network configurations and resources.","It also supports seamless transitions between simulated and emulated setups.","In this work, ECLYPSE capabilities are illustrated over three use cases, showing how the framework supports rapid prototyping across diverse experimental settings."],"url":"http://arxiv.org/abs/2501.17126v1"}
{"created":"2025-01-28 18:14:43","title":"Hybrid Deep Learning Model for Multiple Cache Side Channel Attacks Detection: A Comparative Analysis","abstract":"Cache side channel attacks are a sophisticated and persistent threat that exploit vulnerabilities in modern processors to extract sensitive information. These attacks leverage weaknesses in shared computational resources, particularly the last level cache, to infer patterns in data access and execution flows, often bypassing traditional security defenses. Such attacks are especially dangerous as they can be executed remotely without requiring physical access to the victim's device. This study focuses on a specific class of these threats: fingerprinting attacks, where an adversary monitors and analyzes the behavior of co-located processes via cache side channels. This can potentially reveal confidential information, such as encryption keys or user activity patterns. A comprehensive threat model illustrates how attackers sharing computational resources with target systems exploit these side channels to compromise sensitive data. To mitigate such risks, a hybrid deep learning model is proposed for detecting cache side channel attacks. Its performance is compared with five widely used deep learning models: Multi-Layer Perceptron, Convolutional Neural Network, Simple Recurrent Neural Network, Long Short-Term Memory, and Gated Recurrent Unit. The experimental results demonstrate that the hybrid model achieves a detection rate of up to 99.96%. These findings highlight the limitations of existing models, the need for enhanced defensive mechanisms, and directions for future research to secure sensitive data against evolving side channel threats.","sentences":["Cache side channel attacks are a sophisticated and persistent threat that exploit vulnerabilities in modern processors to extract sensitive information.","These attacks leverage weaknesses in shared computational resources, particularly the last level cache, to infer patterns in data access and execution flows, often bypassing traditional security defenses.","Such attacks are especially dangerous as they can be executed remotely without requiring physical access to the victim's device.","This study focuses on a specific class of these threats: fingerprinting attacks, where an adversary monitors and analyzes the behavior of co-located processes via cache side channels.","This can potentially reveal confidential information, such as encryption keys or user activity patterns.","A comprehensive threat model illustrates how attackers sharing computational resources with target systems exploit these side channels to compromise sensitive data.","To mitigate such risks, a hybrid deep learning model is proposed for detecting cache side channel attacks.","Its performance is compared with five widely used deep learning models: Multi-Layer Perceptron, Convolutional Neural Network, Simple Recurrent Neural Network, Long Short-Term Memory, and Gated Recurrent Unit.","The experimental results demonstrate that the hybrid model achieves a detection rate of up to 99.96%.","These findings highlight the limitations of existing models, the need for enhanced defensive mechanisms, and directions for future research to secure sensitive data against evolving side channel threats."],"url":"http://arxiv.org/abs/2501.17123v1"}
{"created":"2025-01-28 18:07:30","title":"Histoires Morales: A French Dataset for Assessing Moral Alignment","abstract":"Aligning language models with human values is crucial, especially as they become more integrated into everyday life. While models are often adapted to user preferences, it is equally important to ensure they align with moral norms and behaviours in real-world social situations. Despite significant progress in languages like English and Chinese, French has seen little attention in this area, leaving a gap in understanding how LLMs handle moral reasoning in this language. To address this gap, we introduce Histoires Morales, a French dataset derived from Moral Stories, created through translation and subsequently refined with the assistance of native speakers to guarantee grammatical accuracy and adaptation to the French cultural context. We also rely on annotations of the moral values within the dataset to ensure their alignment with French norms. Histoires Morales covers a wide range of social situations, including differences in tipping practices, expressions of honesty in relationships, and responsibilities toward animals. To foster future research, we also conduct preliminary experiments on the alignment of multilingual models on French and English data and the robustness of the alignment. We find that while LLMs are generally aligned with human moral norms by default, they can be easily influenced with user-preference optimization for both moral and immoral data.","sentences":["Aligning language models with human values is crucial, especially as they become more integrated into everyday life.","While models are often adapted to user preferences, it is equally important to ensure they align with moral norms and behaviours in real-world social situations.","Despite significant progress in languages like English and Chinese, French has seen little attention in this area, leaving a gap in understanding how LLMs handle moral reasoning in this language.","To address this gap, we introduce Histoires Morales, a French dataset derived from Moral Stories, created through translation and subsequently refined with the assistance of native speakers to guarantee grammatical accuracy and adaptation to the French cultural context.","We also rely on annotations of the moral values within the dataset to ensure their alignment with French norms.","Histoires Morales covers a wide range of social situations, including differences in tipping practices, expressions of honesty in relationships, and responsibilities toward animals.","To foster future research, we also conduct preliminary experiments on the alignment of multilingual models on French and English data and the robustness of the alignment.","We find that while LLMs are generally aligned with human moral norms by default, they can be easily influenced with user-preference optimization for both moral and immoral data."],"url":"http://arxiv.org/abs/2501.17117v1"}
{"created":"2025-01-28 17:44:04","title":"COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models","abstract":"We present COS(M+O)S, a System 2-inspired framework for open-ended plot development that systematically explores the vast space of possible story expansions, enabling a 3B-parameter language model to approach the plot quality of a 70B model on select short-story tasks. The method accomplishes this by combining Monte Carlo Tree Search (MCTS), guided by a step-level value model that rewards moderate surprisal (curiosity) while penalizing incoherence, and Odds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value plot expansions. This iterative reinforcement learning loop systematically explores multiple candidate plot branches, backpropagates quality signals, and adapts the policy for faster convergence, notably shifting the policy from puzzle-based Chain-of-Thought to more character-driven storytelling. In small-scale tests with short-story prompts, 67%-77% of participants favored COS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our learned value function aligns. GPT-4o ratings further show that COS(M+O)S surpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming within 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise comparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no statistically significant gap from 70B. Nevertheless, absolute story quality remains modest, constrained by the small model's capacity and limited training data.","sentences":["We present COS(M+O)S, a System 2-inspired framework for open-ended plot development that systematically explores the vast space of possible story expansions, enabling a 3B-parameter language model to approach the plot quality of a 70B model on select short-story tasks.","The method accomplishes this by combining Monte Carlo Tree Search (MCTS), guided by a step-level value model that rewards moderate surprisal (curiosity) while penalizing incoherence, and Odds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value plot expansions.","This iterative reinforcement learning loop systematically explores multiple candidate plot branches, backpropagates quality signals, and adapts the policy for faster convergence, notably shifting the policy from puzzle-based Chain-of-Thought to more character-driven storytelling.","In small-scale tests with short-story prompts, 67%-77% of participants favored COS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our learned value function aligns.","GPT-4o ratings further show that COS(M+O)S surpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming within 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93).","Pairwise comparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no statistically significant gap from 70B.","Nevertheless, absolute story quality remains modest, constrained by the small model's capacity and limited training data."],"url":"http://arxiv.org/abs/2501.17104v1"}
{"created":"2025-01-28 17:23:45","title":"CRSet: Non-Interactive Verifiable Credential Revocation with Metadata Privacy for Issuers and Everyone Else","abstract":"Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics. For instance, exact staff fluctuation through issuance and revocation of employee IDs. We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade. Padding is used to provide deniability for issuer metrics. Issuers periodically publish this filter cascade on a decentralized storage system. Relying Parties (RPs) can download it to perform any number of revocation checks locally. Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally. At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications. We present a prototype using the Ethereum blockchain as decentralized storage. The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain. We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols. Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades.","sentences":["Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise.","Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics.","For instance, exact staff fluctuation through issuance and revocation of employee IDs.","We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade.","Padding is used to provide deniability for issuer metrics.","Issuers periodically publish this filter cascade on a decentralized storage system.","Relying Parties (RPs) can download it to perform any number of revocation checks locally.","Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally.","At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications.","We present a prototype using the Ethereum blockchain as decentralized storage.","The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain.","We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols.","Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades."],"url":"http://arxiv.org/abs/2501.17089v1"}
{"created":"2025-01-28 17:01:42","title":"DINOSTAR: Deep Iterative Neural Object Detector Self-Supervised Training for Roadside LiDAR Applications","abstract":"Recent advancements in deep-learning methods for object detection in point-cloud data have enabled numerous roadside applications, fostering improvements in transportation safety and management. However, the intricate nature of point-cloud data poses significant challenges for human-supervised labeling, resulting in substantial expenditures of time and capital. This paper addresses the issue by developing an end-to-end, scalable, and self-supervised framework for training deep object detectors tailored for roadside point-cloud data. The proposed framework leverages self-supervised, statistically modeled teachers to train off-the-shelf deep object detectors, thus circumventing the need for human supervision. The teacher models follow fine-tuned set standard practices of background filtering, object clustering, bounding-box fitting, and classification to generate noisy labels. It is presented that by training the student model over the combined noisy annotations from multitude of teachers enhances its capacity to discern background/foreground more effectively and forces it to learn diverse point-cloud-representations for object categories of interest. The evaluations, involving publicly available roadside datasets and state-of-art deep object detectors, demonstrate that the proposed framework achieves comparable performance to deep object detectors trained on human-annotated labels, despite not utilizing such human-annotations in its training process.","sentences":["Recent advancements in deep-learning methods for object detection in point-cloud data have enabled numerous roadside applications, fostering improvements in transportation safety and management.","However, the intricate nature of point-cloud data poses significant challenges for human-supervised labeling, resulting in substantial expenditures of time and capital.","This paper addresses the issue by developing an end-to-end, scalable, and self-supervised framework for training deep object detectors tailored for roadside point-cloud data.","The proposed framework leverages self-supervised, statistically modeled teachers to train off-the-shelf deep object detectors, thus circumventing the need for human supervision.","The teacher models follow fine-tuned set standard practices of background filtering, object clustering, bounding-box fitting, and classification to generate noisy labels.","It is presented that by training the student model over the combined noisy annotations from multitude of teachers enhances its capacity to discern background/foreground more effectively and forces it to learn diverse point-cloud-representations for object categories of interest.","The evaluations, involving publicly available roadside datasets and state-of-art deep object detectors, demonstrate that the proposed framework achieves comparable performance to deep object detectors trained on human-annotated labels, despite not utilizing such human-annotations in its training process."],"url":"http://arxiv.org/abs/2501.17076v1"}
{"created":"2025-01-28 16:58:45","title":"DataLens: ML-Oriented Interactive Tabular Data Quality Dashboard","abstract":"Maintaining high data quality is crucial for reliable data analysis and machine learning (ML). However, existing data quality management tools often lack automation, interactivity, and integration with ML workflows. This demonstration paper introduces DataLens, a novel interactive dashboard designed to streamline and automate the data quality management process for tabular data. DataLens integrates a suite of data profiling, error detection, and repair tools, including statistical, rule-based, and ML-based methods. It features a user-in-the-loop module for interactive rule validation, data labeling, and custom rule definition, enabling domain experts to guide the cleaning process. Furthermore, DataLens implements an iterative cleaning module that automatically selects optimal cleaning tools based on downstream ML model performance. To ensure reproducibility, DataLens generates DataSheets capturing essential metadata and integrates with MLflow and Delta Lake for experiment tracking and data version control. This demonstration showcases DataLens's capabilities in effectively identifying and correcting data errors, improving data quality for downstream tasks, and promoting reproducibility in data cleaning pipelines.","sentences":["Maintaining high data quality is crucial for reliable data analysis and machine learning (ML).","However, existing data quality management tools often lack automation, interactivity, and integration with ML workflows.","This demonstration paper introduces DataLens, a novel interactive dashboard designed to streamline and automate the data quality management process for tabular data.","DataLens integrates a suite of data profiling, error detection, and repair tools, including statistical, rule-based, and ML-based methods.","It features a user-in-the-loop module for interactive rule validation, data labeling, and custom rule definition, enabling domain experts to guide the cleaning process.","Furthermore, DataLens implements an iterative cleaning module that automatically selects optimal cleaning tools based on downstream ML model performance.","To ensure reproducibility, DataLens generates DataSheets capturing essential metadata and integrates with MLflow and Delta Lake for experiment tracking and data version control.","This demonstration showcases DataLens's capabilities in effectively identifying and correcting data errors, improving data quality for downstream tasks, and promoting reproducibility in data cleaning pipelines."],"url":"http://arxiv.org/abs/2501.17074v1"}
