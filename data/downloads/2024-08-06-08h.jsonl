{"created":"2024-08-05 17:59:51","title":"Latent-INR: A Flexible Framework for Implicit Representations of Videos with Discriminative Semantics","abstract":"Implicit Neural Networks (INRs) have emerged as powerful representations to encode all forms of data, including images, videos, audios, and scenes. With video, many INRs for video have been proposed for the compression task, and recent methods feature significant improvements with respect to encoding time, storage, and reconstruction quality. However, these encoded representations lack semantic meaning, so they cannot be used for any downstream tasks that require such properties, such as retrieval. This can act as a barrier for adoption of video INRs over traditional codecs as they do not offer any significant edge apart from compression. To alleviate this, we propose a flexible framework that decouples the spatial and temporal aspects of the video INR. We accomplish this with a dictionary of per-frame latents that are learned jointly with a set of video specific hypernetworks, such that given a latent, these hypernetworks can predict the INR weights to reconstruct the given frame. This framework not only retains the compression efficiency, but the learned latents can be aligned with features from large vision models, which grants them discriminative properties. We align these latents with CLIP and show good performance for both compression and video retrieval tasks. By aligning with VideoLlama, we are able to perform open-ended chat with our learned latents as the visual inputs. Additionally, the learned latents serve as a proxy for the underlying weights, allowing us perform tasks like video interpolation. These semantic properties and applications, existing simultaneously with ability to perform compression, interpolation, and superresolution properties, are a first in this field of work.","sentences":["Implicit Neural Networks (INRs) have emerged as powerful representations to encode all forms of data, including images, videos, audios, and scenes.","With video, many INRs for video have been proposed for the compression task, and recent methods feature significant improvements with respect to encoding time, storage, and reconstruction quality.","However, these encoded representations lack semantic meaning, so they cannot be used for any downstream tasks that require such properties, such as retrieval.","This can act as a barrier for adoption of video INRs over traditional codecs as they do not offer any significant edge apart from compression.","To alleviate this, we propose a flexible framework that decouples the spatial and temporal aspects of the video INR.","We accomplish this with a dictionary of per-frame latents that are learned jointly with a set of video specific hypernetworks, such that given a latent, these hypernetworks can predict the INR weights to reconstruct the given frame.","This framework not only retains the compression efficiency, but the learned latents can be aligned with features from large vision models, which grants them discriminative properties.","We align these latents with CLIP and show good performance for both compression and video retrieval tasks.","By aligning with VideoLlama, we are able to perform open-ended chat with our learned latents as the visual inputs.","Additionally, the learned latents serve as a proxy for the underlying weights, allowing us perform tasks like video interpolation.","These semantic properties and applications, existing simultaneously with ability to perform compression, interpolation, and superresolution properties, are a first in this field of work."],"url":"http://arxiv.org/abs/2408.02672v1"}
{"created":"2024-08-05 17:57:02","title":"Self-Taught Evaluators","abstract":"Model-based evaluation is at the heart of successful model development -- as a reward model for training, and as a replacement for human evaluation. To train such evaluators, the standard approach is to collect a large amount of human preference judgments over model responses, which is costly and the data becomes stale as models improve. In this work, we present an approach that aims to im-prove evaluators without human annotations, using synthetic training data only. Starting from unlabeled instructions, our iterative self-improvement scheme generates contrasting model outputs and trains an LLM-as-a-Judge to produce reasoning traces and final judgments, repeating this training at each new iteration using the improved predictions. Without any labeled preference data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct) from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms commonly used LLM judges such as GPT-4 and matches the performance of the top-performing reward models trained with labeled examples.","sentences":["Model-based evaluation is at the heart of successful model development -- as a reward model for training, and as a replacement for human evaluation.","To train such evaluators, the standard approach is to collect a large amount of human preference judgments over model responses, which is costly and the data becomes stale as models improve.","In this work, we present an approach that aims to im-prove evaluators without human annotations, using synthetic training data only.","Starting from unlabeled instructions, our iterative self-improvement scheme generates contrasting model outputs and trains an LLM-as-a-Judge to produce reasoning traces and final judgments, repeating this training at each new iteration using the improved predictions.","Without any labeled preference data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct) from 75.4 to 88.3 (88.7 with majority vote) on RewardBench.","This outperforms commonly used LLM judges such as GPT-4 and matches the performance of the top-performing reward models trained with labeled examples."],"url":"http://arxiv.org/abs/2408.02666v1"}
{"created":"2024-08-05 17:14:35","title":"Detection of Compromised Functions in a Serverless Cloud Environment","abstract":"Serverless computing is an emerging cloud paradigm with serverless functions at its core. While serverless environments enable software developers to focus on developing applications without the need to actively manage the underlying runtime infrastructure, they open the door to a wide variety of security threats that can be challenging to mitigate with existing methods. Existing security solutions do not apply to all serverless architectures, since they require significant modifications to the serverless infrastructure or rely on third-party services for the collection of more detailed data. In this paper, we present an extendable serverless security threat detection model that leverages cloud providers' native monitoring tools to detect anomalous behavior in serverless applications. Our model aims to detect compromised serverless functions by identifying post-exploitation abnormal behavior related to different types of attacks on serverless functions, and therefore, it is a last line of defense. Our approach is not tied to any specific serverless application, is agnostic to the type of threats, and is adaptable through model adjustments. To evaluate our model's performance, we developed a serverless cybersecurity testbed in an AWS cloud environment, which includes two different serverless applications and simulates a variety of attack scenarios that cover the main security threats faced by serverless functions. Our evaluation demonstrates our model's ability to detect all implemented attacks while maintaining a negligible false alarm rate.","sentences":["Serverless computing is an emerging cloud paradigm with serverless functions at its core.","While serverless environments enable software developers to focus on developing applications without the need to actively manage the underlying runtime infrastructure, they open the door to a wide variety of security threats that can be challenging to mitigate with existing methods.","Existing security solutions do not apply to all serverless architectures, since they require significant modifications to the serverless infrastructure or rely on third-party services for the collection of more detailed data.","In this paper, we present an extendable serverless security threat detection model that leverages cloud providers' native monitoring tools to detect anomalous behavior in serverless applications.","Our model aims to detect compromised serverless functions by identifying post-exploitation abnormal behavior related to different types of attacks on serverless functions, and therefore, it is a last line of defense.","Our approach is not tied to any specific serverless application, is agnostic to the type of threats, and is adaptable through model adjustments.","To evaluate our model's performance, we developed a serverless cybersecurity testbed in an AWS cloud environment, which includes two different serverless applications and simulates a variety of attack scenarios that cover the main security threats faced by serverless functions.","Our evaluation demonstrates our model's ability to detect all implemented attacks while maintaining a negligible false alarm rate."],"url":"http://arxiv.org/abs/2408.02641v1"}
{"created":"2024-08-05 16:58:56","title":"Interactive 3D Medical Image Segmentation with SAM 2","abstract":"Interactive medical image segmentation (IMIS) has shown significant potential in enhancing segmentation accuracy by integrating iterative feedback from medical professionals. However, the limited availability of enough 3D medical data restricts the generalization and robustness of most IMIS methods. The Segment Anything Model (SAM), though effective for 2D images, requires expensive semi-auto slice-by-slice annotations for 3D medical images. In this paper, we explore the zero-shot capabilities of SAM 2, the next-generation Meta SAM model trained on videos, for 3D medical image segmentation. By treating sequential 2D slices of 3D images as video frames, SAM 2 can fully automatically propagate annotations from a single frame to the entire 3D volume. We propose a practical pipeline for using SAM 2 in 3D medical image segmentation and present key findings highlighting its efficiency and potential for further optimization. Concretely, numerical experiments on the BraTS2020 and the medical segmentation decathlon datasets demonstrate that SAM 2 still has a gap with supervised methods but can narrow the gap in specific settings and organ types, significantly reducing the annotation burden on medical professionals. Our code will be open-sourced and available at https://github.com/Chuyun-Shen/SAM_2_Medical_3D.","sentences":["Interactive medical image segmentation (IMIS) has shown significant potential in enhancing segmentation accuracy by integrating iterative feedback from medical professionals.","However, the limited availability of enough 3D medical data restricts the generalization and robustness of most IMIS methods.","The Segment Anything Model (SAM), though effective for 2D images, requires expensive semi-auto slice-by-slice annotations for 3D medical images.","In this paper, we explore the zero-shot capabilities of SAM 2, the next-generation Meta SAM model trained on videos, for 3D medical image segmentation.","By treating sequential 2D slices of 3D images as video frames, SAM 2 can fully automatically propagate annotations from a single frame to the entire 3D volume.","We propose a practical pipeline for using SAM 2 in 3D medical image segmentation and present key findings highlighting its efficiency and potential for further optimization.","Concretely, numerical experiments on the BraTS2020 and the medical segmentation decathlon datasets demonstrate that SAM 2 still has a gap with supervised methods but can narrow the gap in specific settings and organ types, significantly reducing the annotation burden on medical professionals.","Our code will be open-sourced and available at https://github.com/Chuyun-Shen/SAM_2_Medical_3D."],"url":"http://arxiv.org/abs/2408.02635v1"}
{"created":"2024-08-05 16:55:06","title":"SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models","abstract":"As large language models (LLMs) continue to advance in capability and influence, ensuring their security and preventing harmful outputs has become crucial. A promising approach to address these concerns involves training models to automatically generate adversarial prompts for red teaming. However, the evolving subtlety of vulnerabilities in LLMs challenges the effectiveness of current adversarial methods, which struggle to specifically target and explore the weaknesses of these models. To tackle these challenges, we introduce the $\\mathbf{S}\\text{elf-}\\mathbf{E}\\text{volving }\\mathbf{A}\\text{dversarial }\\mathbf{S}\\text{afety }\\mathbf{(SEAS)}$ optimization framework, which enhances security by leveraging data generated by the model itself. SEAS operates through three iterative stages: Initialization, Attack, and Adversarial Optimization, refining both the Red Team and Target models to improve robustness and safety. This framework reduces reliance on manual testing and significantly enhances the security capabilities of LLMs. Our contributions include a novel adversarial framework, a comprehensive safety dataset, and after three iterations, the Target model achieves a security level comparable to GPT-4, while the Red Team model shows a marked increase in attack success rate (ASR) against advanced models.","sentences":["As large language models (LLMs) continue to advance in capability and influence, ensuring their security and preventing harmful outputs has become crucial.","A promising approach to address these concerns involves training models to automatically generate adversarial prompts for red teaming.","However, the evolving subtlety of vulnerabilities in LLMs challenges the effectiveness of current adversarial methods, which struggle to specifically target and explore the weaknesses of these models.","To tackle these challenges, we introduce the $\\mathbf{S}\\text{elf-}\\mathbf{E}\\text{volving }\\mathbf{A}\\text{dversarial }\\mathbf{S}\\text{afety }\\mathbf{(SEAS)}$ optimization framework, which enhances security by leveraging data generated by the model itself.","SEAS operates through three iterative stages: Initialization, Attack, and Adversarial Optimization, refining both the Red Team and Target models to improve robustness and safety.","This framework reduces reliance on manual testing and significantly enhances the security capabilities of LLMs.","Our contributions include a novel adversarial framework, a comprehensive safety dataset, and after three iterations, the Target model achieves a security level comparable to GPT-4, while the Red Team model shows a marked increase in attack success rate (ASR) against advanced models."],"url":"http://arxiv.org/abs/2408.02632v1"}
{"created":"2024-08-05 16:53:23","title":"VidGen-1M: A Large-Scale Dataset for Text-to-video Generation","abstract":"The quality of video-text pairs fundamentally determines the upper bound of text-to-video models. Currently, the datasets used for training these models suffer from significant shortcomings, including low temporal consistency, poor-quality captions, substandard video quality, and imbalanced data distribution. The prevailing video curation process, which depends on image models for tagging and manual rule-based curation, leads to a high computational load and leaves behind unclean data. As a result, there is a lack of appropriate training datasets for text-to-video models. To address this problem, we present VidGen-1M, a superior training dataset for text-to-video models. Produced through a coarse-to-fine curation strategy, this dataset guarantees high-quality videos and detailed captions with excellent temporal consistency. When used to train the video generation model, this dataset has led to experimental results that surpass those obtained with other models.","sentences":["The quality of video-text pairs fundamentally determines the upper bound of text-to-video models.","Currently, the datasets used for training these models suffer from significant shortcomings, including low temporal consistency, poor-quality captions, substandard video quality, and imbalanced data distribution.","The prevailing video curation process, which depends on image models for tagging and manual rule-based curation, leads to a high computational load and leaves behind unclean data.","As a result, there is a lack of appropriate training datasets for text-to-video models.","To address this problem, we present VidGen-1M, a superior training dataset for text-to-video models.","Produced through a coarse-to-fine curation strategy, this dataset guarantees high-quality videos and detailed captions with excellent temporal consistency.","When used to train the video generation model, this dataset has led to experimental results that surpass those obtained with other models."],"url":"http://arxiv.org/abs/2408.02629v1"}
{"created":"2024-08-05 16:39:04","title":"Comparison of Code Quality and Best Practices in IoT and non-IoT Software","abstract":"Context: IoT systems, networks of connected devices powered by software, require studying software quality for maintenance. Despite extensive studies on non-IoT software quality, research on IoT software quality is lacking. It is uncertain if IoT and non-IoT systems software are comparable, hindering the confident application of results and best practices gained on non-IoT systems.   Objective: Therefore, we compare the code quality of two equivalent sets of IoT and non-IoT systems to determine whether there are similarities and differences. We also collect and revisit software-engineering best practices in non-IoT contexts to apply them to IoT.   Method: We design and apply a systematic method to select two sets of 94 non-IoT and IoT systems software from GitHub with comparable characteristics. We compute quality metrics on the systems in these two sets and then analyse and compare the metric values. We analyse in depth and provide specific examples of IoT system's complexity and how it manifests in the codebases. After the comparison, We systematically select and present a list of best practices to address the observed difference between IoT and non-IoT code.   Results: Through a comparison of metrics, we conclude that software for IoT systems is more complex, coupled, larger, less maintainable, and cohesive than non-IoT systems. Several factors, such as integrating multiple hardware and software components and managing data communication between them, contribute to these differences. Considering these differences, we present a revisited best practices list with approaches, tools, or techniques for developing IoT systems. As example, applying modularity, and refactoring are best practices for lowering the complexity.   Conclusion: Based on our work, researchers can now make an informed decision using existing studies on the quality of non-IoT systems for IoT systems.","sentences":["Context: IoT systems, networks of connected devices powered by software, require studying software quality for maintenance.","Despite extensive studies on non-IoT software quality, research on IoT software quality is lacking.","It is uncertain if IoT and non-IoT systems software are comparable, hindering the confident application of results and best practices gained on non-IoT systems.   ","Objective:","Therefore, we compare the code quality of two equivalent sets of IoT and non-IoT systems to determine whether there are similarities and differences.","We also collect and revisit software-engineering best practices in non-IoT contexts to apply them to IoT.   Method: We design and apply a systematic method to select two sets of 94 non-IoT and IoT systems software from GitHub with comparable characteristics.","We compute quality metrics on the systems in these two sets and then analyse and compare the metric values.","We analyse in depth and provide specific examples of IoT system's complexity and how it manifests in the codebases.","After the comparison, We systematically select and present a list of best practices to address the observed difference between IoT and non-IoT code.   ","Results: Through a comparison of metrics, we conclude that software for IoT systems is more complex, coupled, larger, less maintainable, and cohesive than non-IoT systems.","Several factors, such as integrating multiple hardware and software components and managing data communication between them, contribute to these differences.","Considering these differences, we present a revisited best practices list with approaches, tools, or techniques for developing IoT systems.","As example, applying modularity, and refactoring are best practices for lowering the complexity.   ","Conclusion: Based on our work, researchers can now make an informed decision using existing studies on the quality of non-IoT systems for IoT systems."],"url":"http://arxiv.org/abs/2408.02614v1"}
{"created":"2024-08-05 16:31:28","title":"Trade-offs of Dynamic Control Structure in Human-swarm Systems","abstract":"Swarm robotics is a study of simple robots that exhibit complex behaviour only by interacting locally with other robots and their environment. The control in swarm robotics is mainly distributed whereas centralised control is widely used in other fields of robotics. Centralised and decentralised control strategies both pose a unique set of benefits and drawbacks for the control of multi-robot systems. While decentralised systems are more scalable and resilient, they are less efficient compared to the centralised systems and they lead to excessive data transmissions to the human operators causing cognitive overload. We examine the trade-offs of each of these approaches in a human-swarm system to perform an environmental monitoring task and propose a flexible hybrid approach, which combines elements of hierarchical and decentralised systems. We find that a flexible hybrid system can outperform a centralised system (in our environmental monitoring task by 19.2%) while reducing the number of messages sent to a human operator (here by 23.1%). We conclude that establishing centralisation for a system is not always optimal for performance and that utilising aspects of centralised and decentralised systems can keep the swarm from hindering its performance.","sentences":["Swarm robotics is a study of simple robots that exhibit complex behaviour only by interacting locally with other robots and their environment.","The control in swarm robotics is mainly distributed whereas centralised control is widely used in other fields of robotics.","Centralised and decentralised control strategies both pose a unique set of benefits and drawbacks for the control of multi-robot systems.","While decentralised systems are more scalable and resilient, they are less efficient compared to the centralised systems and they lead to excessive data transmissions to the human operators causing cognitive overload.","We examine the trade-offs of each of these approaches in a human-swarm system to perform an environmental monitoring task and propose a flexible hybrid approach, which combines elements of hierarchical and decentralised systems.","We find that a flexible hybrid system can outperform a centralised system (in our environmental monitoring task by 19.2%) while reducing the number of messages sent to a human operator (here by 23.1%).","We conclude that establishing centralisation for a system is not always optimal for performance and that utilising aspects of centralised and decentralised systems can keep the swarm from hindering its performance."],"url":"http://arxiv.org/abs/2408.02605v1"}
{"created":"2024-08-05 16:21:17","title":"Progressively Selective Label Enhancement for Language Model Alignment","abstract":"Large Language Models have demonstrated impressive capabilities in various language tasks but may produce content that misaligns with human expectations, raising ethical and legal concerns. Therefore, it is important to explore the limitations and implement restrictions on the models to ensure safety and compliance, with Reinforcement Learning from Human Feedback (RLHF) being the primary method. Due to challenges in stability and scalability with the RLHF stages, researchers are exploring alternative methods to achieve effects comparable to those of RLHF. However, these methods often depend on large high-quality datasets and inefficiently utilize generated data. To deal with this problem, we propose PSLE, i.e., Progressively Selective Label Enhancement for Language Model Alignment, a framework that fully utilizes all generated data by guiding the model with principles to align outputs with human expectations. Using a dynamically updated threshold, our approach ensures efficient data utilization by incorporating all generated responses and weighting them based on their corresponding reward scores. Experimental results on multiple datasets demonstrate the effectiveness of PSLE compared to existing language model alignment methods.","sentences":["Large Language Models have demonstrated impressive capabilities in various language tasks but may produce content that misaligns with human expectations, raising ethical and legal concerns.","Therefore, it is important to explore the limitations and implement restrictions on the models to ensure safety and compliance, with Reinforcement Learning from Human Feedback (RLHF) being the primary method.","Due to challenges in stability and scalability with the RLHF stages, researchers are exploring alternative methods to achieve effects comparable to those of RLHF.","However, these methods often depend on large high-quality datasets and inefficiently utilize generated data.","To deal with this problem, we propose PSLE, i.e., Progressively Selective Label Enhancement for Language Model Alignment, a framework that fully utilizes all generated data by guiding the model with principles to align outputs with human expectations.","Using a dynamically updated threshold, our approach ensures efficient data utilization by incorporating all generated responses and weighting them based on their corresponding reward scores.","Experimental results on multiple datasets demonstrate the effectiveness of PSLE compared to existing language model alignment methods."],"url":"http://arxiv.org/abs/2408.02599v1"}
{"created":"2024-08-05 16:07:31","title":"Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection","abstract":"Sarcasm is a type of irony, characterized by an inherent mismatch between the literal interpretation and the intended connotation. Though sarcasm detection in text has been extensively studied, there are situations in which textual input alone might be insufficient to perceive sarcasm. The inclusion of additional contextual cues, such as images, is essential to recognize sarcasm in social media data effectively. This study presents a novel framework for multimodal sarcasm detection that can process input triplets. Two components of these triplets comprise the input text and its associated image, as provided in the datasets. Additionally, a supplementary modality is introduced in the form of descriptive image captions. The motivation behind incorporating this visual semantic representation is to more accurately capture the discrepancies between the textual and visual content, which are fundamental to the sarcasm detection task. The primary contributions of this study are: (1) a robust textual feature extraction branch that utilizes a cross-lingual language model; (2) a visual feature extraction branch that incorporates a self-regulated residual ConvNet integrated with a lightweight spatially aware attention module; (3) an additional modality in the form of image captions generated using an encoder-decoder architecture capable of reading text embedded in images; (4) distinct attention modules to effectively identify the incongruities between the text and two levels of image representations; (5) multi-level cross-domain semantic incongruity representation achieved through feature fusion. Compared with cutting-edge baselines, the proposed model achieves the best accuracy of 92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and MultiBully datasets.","sentences":["Sarcasm is a type of irony, characterized by an inherent mismatch between the literal interpretation and the intended connotation.","Though sarcasm detection in text has been extensively studied, there are situations in which textual input alone might be insufficient to perceive sarcasm.","The inclusion of additional contextual cues, such as images, is essential to recognize sarcasm in social media data effectively.","This study presents a novel framework for multimodal sarcasm detection that can process input triplets.","Two components of these triplets comprise the input text and its associated image, as provided in the datasets.","Additionally, a supplementary modality is introduced in the form of descriptive image captions.","The motivation behind incorporating this visual semantic representation is to more accurately capture the discrepancies between the textual and visual content, which are fundamental to the sarcasm detection task.","The primary contributions of this study are: (1) a robust textual feature extraction branch that utilizes a cross-lingual language model; (2) a visual feature extraction branch that incorporates a self-regulated residual ConvNet integrated with a lightweight spatially aware attention module; (3) an additional modality in the form of image captions generated using an encoder-decoder architecture capable of reading text embedded in images; (4) distinct attention modules to effectively identify the incongruities between the text and two levels of image representations; (5) multi-level cross-domain semantic incongruity representation achieved through feature fusion.","Compared with cutting-edge baselines, the proposed model achieves the best accuracy of 92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and MultiBully datasets."],"url":"http://arxiv.org/abs/2408.02595v1"}
{"created":"2024-08-05 16:00:36","title":"Massive MIMO-OTFS-Based Random Access for Cooperative LEO Satellite Constellations","abstract":"This paper investigates joint device identification, channel estimation, and symbol detection for cooperative multi-satellite-enhanced random access, where orthogonal time-frequency space modulation with the large antenna array is utilized to combat the dynamics of the terrestrial-satellite links (TSLs). We introduce the generalized complex exponential basis expansion model to parameterize TSLs, thereby reducing the pilot overhead. By exploiting the block sparsity of the TSLs in the angular domain, a message passing algorithm is designed for initial channel estimation. Subsequently, we examine two cooperative modes to leverage the spatial diversity within satellite constellations: the centralized mode, where computations are performed at a high-power central server, and the distributed mode, where computations are offloaded to edge satellites with minimal signaling overhead. Specifically, in the centralized mode, device identification is achieved by aggregating backhaul information from edge satellites, and channel estimation and symbol detection are jointly enhanced through a structured approximate expectation propagation (AEP) algorithm. In the distributed mode, edge satellites share channel information and exchange soft information about data symbols, leading to a distributed version of AEP. The introduced basis expansion model for TSLs enables the efficient implementation of both centralized and distributed algorithms via fast Fourier transform. Simulation results demonstrate that proposed schemes significantly outperform conventional algorithms in terms of the activity error rate, the normalized mean squared error, and the symbol error rate. Notably, the distributed mode achieves performance comparable to the centralized mode with only two exchanges of soft information about data symbols within the constellation.","sentences":["This paper investigates joint device identification, channel estimation, and symbol detection for cooperative multi-satellite-enhanced random access, where orthogonal time-frequency space modulation with the large antenna array is utilized to combat the dynamics of the terrestrial-satellite links (TSLs).","We introduce the generalized complex exponential basis expansion model to parameterize TSLs, thereby reducing the pilot overhead.","By exploiting the block sparsity of the TSLs in the angular domain, a message passing algorithm is designed for initial channel estimation.","Subsequently, we examine two cooperative modes to leverage the spatial diversity within satellite constellations: the centralized mode, where computations are performed at a high-power central server, and the distributed mode, where computations are offloaded to edge satellites with minimal signaling overhead.","Specifically, in the centralized mode, device identification is achieved by aggregating backhaul information from edge satellites, and channel estimation and symbol detection are jointly enhanced through a structured approximate expectation propagation (AEP) algorithm.","In the distributed mode, edge satellites share channel information and exchange soft information about data symbols, leading to a distributed version of AEP.","The introduced basis expansion model for TSLs enables the efficient implementation of both centralized and distributed algorithms via fast Fourier transform.","Simulation results demonstrate that proposed schemes significantly outperform conventional algorithms in terms of the activity error rate, the normalized mean squared error, and the symbol error rate.","Notably, the distributed mode achieves performance comparable to the centralized mode with only two exchanges of soft information about data symbols within the constellation."],"url":"http://arxiv.org/abs/2408.02586v1"}
{"created":"2024-08-05 16:00:07","title":"Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition","abstract":"Modern automatic speech recognition (ASR) systems are typically trained on more than tens of thousands hours of speech data, which is one of the main factors for their great success. However, the distribution of such data is typically biased towards common accents or typical speech patterns. As a result, those systems often poorly perform on atypical accented speech. In this paper, we present accent clustering and mining schemes for fair speech recognition systems which can perform equally well on under-represented accented speech. For accent recognition, we applied three schemes to overcome limited size of supervised accent data: supervised or unsupervised pre-training, distributionally robust optimization (DRO) and unsupervised clustering. Three schemes can significantly improve the accent recognition model especially for unbalanced and small accented speech. Fine-tuning ASR on the mined Indian accent speech using the proposed supervised or unsupervised clustering schemes showed 10.0% and 5.3% relative improvements compared to fine-tuning on the randomly sampled speech, respectively.","sentences":["Modern automatic speech recognition (ASR) systems are typically trained on more than tens of thousands hours of speech data, which is one of the main factors for their great success.","However, the distribution of such data is typically biased towards common accents or typical speech patterns.","As a result, those systems often poorly perform on atypical accented speech.","In this paper, we present accent clustering and mining schemes for fair speech recognition systems which can perform equally well on under-represented accented speech.","For accent recognition, we applied three schemes to overcome limited size of supervised accent data: supervised or unsupervised pre-training, distributionally robust optimization (DRO) and unsupervised clustering.","Three schemes can significantly improve the accent recognition model especially for unbalanced and small accented speech.","Fine-tuning ASR on the mined Indian accent speech using the proposed supervised or unsupervised clustering schemes showed 10.0% and 5.3% relative improvements compared to fine-tuning on the randomly sampled speech, respectively."],"url":"http://arxiv.org/abs/2408.02582v1"}
{"created":"2024-08-05 15:59:36","title":"Operational range bounding of spectroscopy models with anomaly detection","abstract":"Safe operation of machine learning models requires architectures that explicitly delimit their operational ranges. We evaluate the ability of anomaly detection algorithms to provide indicators correlated with degraded model performance. By placing acceptance thresholds over such indicators, hard boundaries are formed that define the model's coverage. As a use case, we consider the extraction of exoplanetary spectra from transit light curves, specifically within the context of ESA's upcoming Ariel mission. Isolation Forests are shown to effectively identify contexts where prediction models are likely to fail. Coverage/error trade-offs are evaluated under conditions of data and concept drift. The best performance is seen when Isolation Forests model projections of the prediction model's explainability SHAP values.","sentences":["Safe operation of machine learning models requires architectures that explicitly delimit their operational ranges.","We evaluate the ability of anomaly detection algorithms to provide indicators correlated with degraded model performance.","By placing acceptance thresholds over such indicators, hard boundaries are formed that define the model's coverage.","As a use case, we consider the extraction of exoplanetary spectra from transit light curves, specifically within the context of ESA's upcoming Ariel mission.","Isolation Forests are shown to effectively identify contexts where prediction models are likely to fail.","Coverage/error trade-offs are evaluated under conditions of data and concept drift.","The best performance is seen when Isolation Forests model projections of the prediction model's explainability SHAP values."],"url":"http://arxiv.org/abs/2408.02581v1"}
{"created":"2024-08-05 15:43:56","title":"Cross-Modality Clustering-based Self-Labeling for Multimodal Data Classification","abstract":"Technological advances facilitate the ability to acquire multimodal data, posing a challenge for recognition systems while also providing an opportunity to use the heterogeneous nature of the information to increase the generalization capability of models. An often overlooked issue is the cost of the labeling process, which is typically high due to the need for a significant investment in time and money associated with human experts. Existing semi-supervised learning methods often focus on operating in the feature space created by the fusion of available modalities, neglecting the potential for cross-utilizing complementary information available in each modality. To address this problem, we propose Cross-Modality Clustering-based Self-Labeling (CMCSL). Based on a small set of pre-labeled data, CMCSL groups instances belonging to each modality in the deep feature space and then propagates known labels within the resulting clusters. Next, information about the instances' class membership in each modality is exchanged based on the Euclidean distance to ensure more accurate labeling. Experimental evaluation conducted on 20 datasets derived from the MM-IMDb dataset indicates that cross-propagation of labels between modalities -- especially when the number of pre-labeled instances is small -- can allow for more reliable labeling and thus increase the classification performance in each modality.","sentences":["Technological advances facilitate the ability to acquire multimodal data, posing a challenge for recognition systems while also providing an opportunity to use the heterogeneous nature of the information to increase the generalization capability of models.","An often overlooked issue is the cost of the labeling process, which is typically high due to the need for a significant investment in time and money associated with human experts.","Existing semi-supervised learning methods often focus on operating in the feature space created by the fusion of available modalities, neglecting the potential for cross-utilizing complementary information available in each modality.","To address this problem, we propose Cross-Modality Clustering-based Self-Labeling (CMCSL).","Based on a small set of pre-labeled data, CMCSL groups instances belonging to each modality in the deep feature space and then propagates known labels within the resulting clusters.","Next, information about the instances' class membership in each modality is exchanged based on the Euclidean distance to ensure more accurate labeling.","Experimental evaluation conducted on 20 datasets derived from the MM-IMDb dataset indicates that cross-propagation of labels between modalities -- especially when the number of pre-labeled instances is small -- can allow for more reliable labeling and thus increase the classification performance in each modality."],"url":"http://arxiv.org/abs/2408.02568v1"}
{"created":"2024-08-05 15:26:39","title":"Process-constrained batch Bayesian approaches for yield optimization in multi-reactor systems","abstract":"The optimization of yields in multi-reactor systems, which are advanced tools in heterogeneous catalysis research, presents a significant challenge due to hierarchical technical constraints. To this respect, this work introduces a novel approach called process-constrained batch Bayesian optimization via Thompson sampling (pc-BO-TS) and its generalized hierarchical extension (hpc-BO-TS). This method, tailored for the efficiency demands in multi-reactor systems, integrates experimental constraints and balances between exploration and exploitation in a sequential batch optimization strategy. It offers an improvement over other Bayesian optimization methods. The performance of pc-BO-TS and hpc-BO-TS is validated in synthetic cases as well as in a realistic scenario based on data obtained from high-throughput experiments done on a multi-reactor system available in the REALCAT platform. The proposed methods often outperform other sequential Bayesian optimizations and existing process-constrained batch Bayesian optimization methods. This work proposes a novel approach to optimize the yield of a reaction in a multi-reactor system, marking a significant step forward in digital catalysis and generally in optimization methods for chemical engineering.","sentences":["The optimization of yields in multi-reactor systems, which are advanced tools in heterogeneous catalysis research, presents a significant challenge due to hierarchical technical constraints.","To this respect, this work introduces a novel approach called process-constrained batch Bayesian optimization via Thompson sampling (pc-BO-TS) and its generalized hierarchical extension (hpc-BO-TS).","This method, tailored for the efficiency demands in multi-reactor systems, integrates experimental constraints and balances between exploration and exploitation in a sequential batch optimization strategy.","It offers an improvement over other Bayesian optimization methods.","The performance of pc-BO-TS and hpc-BO-TS is validated in synthetic cases as well as in a realistic scenario based on data obtained from high-throughput experiments done on a multi-reactor system available in the REALCAT platform.","The proposed methods often outperform other sequential Bayesian optimizations and existing process-constrained batch Bayesian optimization methods.","This work proposes a novel approach to optimize the yield of a reaction in a multi-reactor system, marking a significant step forward in digital catalysis and generally in optimization methods for chemical engineering."],"url":"http://arxiv.org/abs/2408.02551v1"}
{"created":"2024-08-05 15:16:24","title":"RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation","abstract":"Implementing Retrieval-Augmented Generation (RAG) systems is inherently complex, requiring deep understanding of data, use cases, and intricate design decisions. Additionally, evaluating these systems presents significant challenges, necessitating assessment of both retrieval accuracy and generative quality through a multi-faceted approach. We introduce RAG Foundry, an open-source framework for augmenting large language models for RAG use cases. RAG Foundry integrates data creation, training, inference and evaluation into a single workflow, facilitating the creation of data-augmented datasets for training and evaluating large language models in RAG settings. This integration enables rapid prototyping and experimentation with various RAG techniques, allowing users to easily generate datasets and train RAG models using internal or specialized knowledge sources. We demonstrate the framework effectiveness by augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG configurations, showcasing consistent improvements across three knowledge-intensive datasets. Code is released as open-source in https://github.com/IntelLabs/RAGFoundry.","sentences":["Implementing Retrieval-Augmented Generation (RAG) systems is inherently complex, requiring deep understanding of data, use cases, and intricate design decisions.","Additionally, evaluating these systems presents significant challenges, necessitating assessment of both retrieval accuracy and generative quality through a multi-faceted approach.","We introduce RAG Foundry, an open-source framework for augmenting large language models for RAG use cases.","RAG Foundry integrates data creation, training, inference and evaluation into a single workflow, facilitating the creation of data-augmented datasets for training and evaluating large language models in RAG settings.","This integration enables rapid prototyping and experimentation with various RAG techniques, allowing users to easily generate datasets and train RAG models using internal or specialized knowledge sources.","We demonstrate the framework effectiveness by augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG configurations, showcasing consistent improvements across three knowledge-intensive datasets.","Code is released as open-source in https://github.com/IntelLabs/RAGFoundry."],"url":"http://arxiv.org/abs/2408.02545v1"}
{"created":"2024-08-05 15:03:19","title":"LMEMs for post-hoc analysis of HPO Benchmarking","abstract":"The importance of tuning hyperparameters in Machine Learning (ML) and Deep Learning (DL) is established through empirical research and applications, evident from the increase in new hyperparameter optimization (HPO) algorithms and benchmarks steadily added by the community. However, current benchmarking practices using averaged performance across many datasets may obscure key differences between HPO methods, especially for pairwise comparisons. In this work, we apply Linear Mixed-Effect Models-based (LMEMs) significance testing for post-hoc analysis of HPO benchmarking runs. LMEMs allow flexible and expressive modeling on the entire experiment data, including information such as benchmark meta-features, offering deeper insights than current analysis practices. We demonstrate this through a case study on the PriorBand paper's experiment data to find insights not reported in the original work.","sentences":["The importance of tuning hyperparameters in Machine Learning (ML) and Deep Learning (DL) is established through empirical research and applications, evident from the increase in new hyperparameter optimization (HPO) algorithms and benchmarks steadily added by the community.","However, current benchmarking practices using averaged performance across many datasets may obscure key differences between HPO methods, especially for pairwise comparisons.","In this work, we apply Linear Mixed-Effect Models-based (LMEMs) significance testing for post-hoc analysis of HPO benchmarking runs.","LMEMs allow flexible and expressive modeling on the entire experiment data, including information such as benchmark meta-features, offering deeper insights than current analysis practices.","We demonstrate this through a case study on the PriorBand paper's experiment data to find insights not reported in the original work."],"url":"http://arxiv.org/abs/2408.02533v1"}
{"created":"2024-08-05 14:46:35","title":"Online Deterministic Minimum Cost Bipartite Matching with Delays on a Line","abstract":"We study the online minimum cost bipartite perfect matching with delays problem. In this problem, $m$ servers and $m$ requests arrive over time, and an online algorithm can delay the matching between servers and requests by paying the delay cost. The objective is to minimize the total distance and delay cost. When servers and requests lie in a known metric space, there is a randomized $O(\\log n)$-competitive algorithm, where $n$ is the size of the metric space. When the metric space is unknown a priori, Azar and Jacob-Fanani proposed a deterministic $O\\left(\\frac{1}{\\epsilon}m^{\\log\\left(\\frac{3+\\epsilon}{2}\\right)}\\right)$-competitive algorithm for any fixed $\\epsilon > 0$. This competitive ratio is tight when $n = 1$ and becomes $O(m^{0.59})$ for sufficiently small $\\epsilon$.   In this paper, we improve upon the result of Azar and Jacob-Fanani for the case where servers and requests are on the real line, providing a deterministic $\\tilde{O}(m^{0.5})$-competitive algorithm. Our algorithm is based on the Robust Matching (RM) algorithm proposed by Raghvendra for the minimum cost bipartite perfect matching problem. In this problem, delay is not allowed, and all servers arrive in the beginning. When a request arrives, the RM algorithm immediately matches the request to a free server based on the request's minimum $t$-net-cost augmenting path, where $t > 1$ is a constant. In our algorithm, we delay the matching of a request until its waiting time exceeds its minimum $t$-net-cost divided by $t$.","sentences":["We study the online minimum cost bipartite perfect matching with delays problem.","In this problem, $m$ servers and $m$ requests arrive over time, and an online algorithm can delay the matching between servers and requests by paying the delay cost.","The objective is to minimize the total distance and delay cost.","When servers and requests lie in a known metric space, there is a randomized $O(\\log n)$-competitive algorithm, where $n$ is the size of the metric space.","When the metric space is unknown a priori, Azar and Jacob-Fanani proposed a deterministic $O\\left(\\frac{1}{\\epsilon}m^{\\log\\left(\\frac{3+\\epsilon}{2}\\right)}\\right)$-competitive algorithm for any fixed $\\epsilon > 0$.","This competitive ratio is tight when $n = 1$ and becomes $O(m^{0.59})$ for sufficiently small $\\epsilon$.   In this paper, we improve upon the result of Azar and Jacob-Fanani for the case where servers and requests are on the real line, providing a deterministic $\\tilde{O}(m^{0.5})$-competitive algorithm.","Our algorithm is based on the Robust Matching (RM) algorithm proposed by Raghvendra for the minimum cost bipartite perfect matching problem.","In this problem, delay is not allowed, and all servers arrive in the beginning.","When a request arrives, the RM algorithm immediately matches the request to a free server based on the request's minimum $t$-net-cost augmenting path, where $t > 1$ is a constant.","In our algorithm, we delay the matching of a request until its waiting time exceeds its minimum $t$-net-cost divided by $t$."],"url":"http://arxiv.org/abs/2408.02526v1"}
{"created":"2024-08-05 14:40:41","title":"Introducing a Comprehensive, Continuous, and Collaborative Survey of Intrusion Detection Datasets","abstract":"Researchers in the highly active field of intrusion detection largely rely on public datasets for their experimental evaluations. However, the large number of existing datasets, the discovery of previously unknown flaws therein, and the frequent publication of new datasets make it hard to select suitable options and sufficiently understand their respective limitations. Hence, there is a great risk of drawing invalid conclusions from experimental results with respect to detection performance of novel methods in the real world. While there exist various surveys on intrusion detection datasets, they have deficiencies in providing researchers with a profound decision basis since they lack comprehensiveness, actionable details, and up-to-dateness. In this paper, we present COMIDDS, an ongoing effort to comprehensively survey intrusion detection datasets with an unprecedented level of detail, implemented as a website backed by a public GitHub repository. COMIDDS allows researchers to quickly identify suitable datasets depending on their requirements and provides structured and critical information on each dataset, including actual data samples and links to relevant publications. COMIDDS is freely accessible, regularly updated, and open to contributions.","sentences":["Researchers in the highly active field of intrusion detection largely rely on public datasets for their experimental evaluations.","However, the large number of existing datasets, the discovery of previously unknown flaws therein, and the frequent publication of new datasets make it hard to select suitable options and sufficiently understand their respective limitations.","Hence, there is a great risk of drawing invalid conclusions from experimental results with respect to detection performance of novel methods in the real world.","While there exist various surveys on intrusion detection datasets, they have deficiencies in providing researchers with a profound decision basis since they lack comprehensiveness, actionable details, and up-to-dateness.","In this paper, we present COMIDDS, an ongoing effort to comprehensively survey intrusion detection datasets with an unprecedented level of detail, implemented as a website backed by a public GitHub repository.","COMIDDS allows researchers to quickly identify suitable datasets depending on their requirements and provides structured and critical information on each dataset, including actual data samples and links to relevant publications.","COMIDDS is freely accessible, regularly updated, and open to contributions."],"url":"http://arxiv.org/abs/2408.02521v1"}
{"created":"2024-08-05 14:31:09","title":"Estimating Pore Location of PBF-LB/M Processes with Segmentation Models","abstract":"Reliably manufacturing defect free products is still an open challenge for Laser Powder Bed Fusion processes. Particularly, pores that occur frequently have a negative impact on mechanical properties like fatigue performance. Therefore, an accurate localisation of pores is mandatory for quality assurance, but requires time-consuming post-processing steps like computer tomography scans. Although existing solutions using in-situ monitoring data can detect pore occurrence within a layer, they are limited in their localisation precision. Therefore, we propose a pore localisation approach that estimates their position within a single layer using a Gaussian kernel density estimation. This allows segmentation models to learn the correlation between in-situ monitoring data and the derived probability distribution of pore occurrence. Within our experiments, we compare the prediction performance of different segmentation models depending on machine parameter configuration and geometry features. From our results, we conclude that our approach allows a precise localisation of pores that requires minimal data preprocessing. Our research extends the literature by providing a foundation for more precise pore detection systems.","sentences":["Reliably manufacturing defect free products is still an open challenge for Laser Powder Bed Fusion processes.","Particularly, pores that occur frequently have a negative impact on mechanical properties like fatigue performance.","Therefore, an accurate localisation of pores is mandatory for quality assurance, but requires time-consuming post-processing steps like computer tomography scans.","Although existing solutions using in-situ monitoring data can detect pore occurrence within a layer, they are limited in their localisation precision.","Therefore, we propose a pore localisation approach that estimates their position within a single layer using a Gaussian kernel density estimation.","This allows segmentation models to learn the correlation between in-situ monitoring data and the derived probability distribution of pore occurrence.","Within our experiments, we compare the prediction performance of different segmentation models depending on machine parameter configuration and geometry features.","From our results, we conclude that our approach allows a precise localisation of pores that requires minimal data preprocessing.","Our research extends the literature by providing a foundation for more precise pore detection systems."],"url":"http://arxiv.org/abs/2408.02507v1"}
{"created":"2024-08-05 14:21:00","title":"Flow with FlorDB: Incremental Context Maintenance for the Machine Learning Lifecycle","abstract":"The metadata involved in integrating code, data, configuration, and feedback into predictive models is varied and complex. This complexity is further compounded by the agile development practices favored by data scientists and machine learning engineers. These practices emphasize high experimentation velocity and frequent deployments, which can make it challenging to keep track of all the relevant metadata. The iterative nature of agile methods means that models, datasets, and configurations are constantly evolving. Each experiment might involve tweaks to the data preprocessing steps, changes in model hyperparameters, or updates to the deployment environment. The need for rapid iteration can lead to shortcuts or oversights in documentation and metadata management. Effective metadata management requires robust yet flexible tools and practices that can integrate and organize this information without slowing down the development process. Traditional context management often emphasizes a ``metadata first'' approach, which can introduce significant friction for developers. FlorDB reduces this friction through multiversion hindsight logging and incremental context maintenance, allowing developers to add and refine metadata after the fact. This ``metadata later'' approach enables a more flexible and incremental development process, allowing data scientists to focus on model creation and refinement without the burden of documentation upfront. As shown in a demo, FlorDB can be used to build AI/ML applications with integrated train-infer pipelines and managed feedback loops. Ultimately, the goal of FlorDB is to ensure that critical metadata is maintained accurately and efficiently, even in fast-paced agile workflows.","sentences":["The metadata involved in integrating code, data, configuration, and feedback into predictive models is varied and complex.","This complexity is further compounded by the agile development practices favored by data scientists and machine learning engineers.","These practices emphasize high experimentation velocity and frequent deployments, which can make it challenging to keep track of all the relevant metadata.","The iterative nature of agile methods means that models, datasets, and configurations are constantly evolving.","Each experiment might involve tweaks to the data preprocessing steps, changes in model hyperparameters, or updates to the deployment environment.","The need for rapid iteration can lead to shortcuts or oversights in documentation and metadata management.","Effective metadata management requires robust yet flexible tools and practices that can integrate and organize this information without slowing down the development process.","Traditional context management often emphasizes a ``metadata first'' approach, which can introduce significant friction for developers.","FlorDB reduces this friction through multiversion hindsight logging and incremental context maintenance, allowing developers to add and refine metadata after the fact.","This ``metadata later'' approach enables a more flexible and incremental development process, allowing data scientists to focus on model creation and refinement without the burden of documentation upfront.","As shown in a demo, FlorDB can be used to build AI/ML applications with integrated train-infer pipelines and managed feedback loops.","Ultimately, the goal of FlorDB is to ensure that critical metadata is maintained accurately and efficiently, even in fast-paced agile workflows."],"url":"http://arxiv.org/abs/2408.02498v1"}
{"created":"2024-08-05 14:18:29","title":"HyperSpaceX: Radial and Angular Exploration of HyperSpherical Dimensions","abstract":"Traditional deep learning models rely on methods such as softmax cross-entropy and ArcFace loss for tasks like classification and face recognition. These methods mainly explore angular features in a hyperspherical space, often resulting in entangled inter-class features due to dense angular data across many classes. In this paper, a new field of feature exploration is proposed known as HyperSpaceX which enhances class discrimination by exploring both angular and radial dimensions in multi-hyperspherical spaces, facilitated by a novel DistArc loss. The proposed DistArc loss encompasses three feature arrangement components: two angular and one radial, enforcing intra-class binding and inter-class separation in multi-radial arrangement, improving feature discriminability. Evaluation of HyperSpaceX framework for the novel representation utilizes a proposed predictive measure that accounts for both angular and radial elements, providing a more comprehensive assessment of model accuracy beyond standard metrics. Experiments across seven object classification and six face recognition datasets demonstrate state-of-the-art (SoTA) results obtained from HyperSpaceX, achieving up to a 20% performance improvement on large-scale object datasets in lower dimensions and up to 6% gain in higher dimensions.","sentences":["Traditional deep learning models rely on methods such as softmax cross-entropy and ArcFace loss for tasks like classification and face recognition.","These methods mainly explore angular features in a hyperspherical space, often resulting in entangled inter-class features due to dense angular data across many classes.","In this paper, a new field of feature exploration is proposed known as HyperSpaceX which enhances class discrimination by exploring both angular and radial dimensions in multi-hyperspherical spaces, facilitated by a novel DistArc loss.","The proposed DistArc loss encompasses three feature arrangement components: two angular and one radial, enforcing intra-class binding and inter-class separation in multi-radial arrangement, improving feature discriminability.","Evaluation of HyperSpaceX framework for the novel representation utilizes a proposed predictive measure that accounts for both angular and radial elements, providing a more comprehensive assessment of model accuracy beyond standard metrics.","Experiments across seven object classification and six face recognition datasets demonstrate state-of-the-art (SoTA) results obtained from HyperSpaceX, achieving up to a 20% performance improvement on large-scale object datasets in lower dimensions and up to 6% gain in higher dimensions."],"url":"http://arxiv.org/abs/2408.02494v1"}
{"created":"2024-08-05 13:44:22","title":"Fairness and Bias Mitigation in Computer Vision: A Survey","abstract":"Computer vision systems have witnessed rapid progress over the past two decades due to multiple advances in the field. As these systems are increasingly being deployed in high-stakes real-world applications, there is a dire need to ensure that they do not propagate or amplify any discriminatory tendencies in historical or human-curated data or inadvertently learn biases from spurious correlations. This paper presents a comprehensive survey on fairness that summarizes and sheds light on ongoing trends and successes in the context of computer vision. The topics we discuss include 1) The origin and technical definitions of fairness drawn from the wider fair machine learning literature and adjacent disciplines. 2) Work that sought to discover and analyze biases in computer vision systems. 3) A summary of methods proposed to mitigate bias in computer vision systems in recent years. 4) A comprehensive summary of resources and datasets produced by researchers to measure, analyze, and mitigate bias and enhance fairness. 5) Discussion of the field's success, continuing trends in the context of multimodal foundation and generative models, and gaps that still need to be addressed. The presented characterization should help researchers understand the importance of identifying and mitigating bias in computer vision and the state of the field and identify potential directions for future research.","sentences":["Computer vision systems have witnessed rapid progress over the past two decades due to multiple advances in the field.","As these systems are increasingly being deployed in high-stakes real-world applications, there is a dire need to ensure that they do not propagate or amplify any discriminatory tendencies in historical or human-curated data or inadvertently learn biases from spurious correlations.","This paper presents a comprehensive survey on fairness that summarizes and sheds light on ongoing trends and successes in the context of computer vision.","The topics we discuss include 1) The origin and technical definitions of fairness drawn from the wider fair machine learning literature and adjacent disciplines.","2) Work that sought to discover and analyze biases in computer vision systems.","3) A summary of methods proposed to mitigate bias in computer vision systems in recent years.","4) A comprehensive summary of resources and datasets produced by researchers to measure, analyze, and mitigate bias and enhance fairness.","5) Discussion of the field's success, continuing trends in the context of multimodal foundation and generative models, and gaps that still need to be addressed.","The presented characterization should help researchers understand the importance of identifying and mitigating bias in computer vision and the state of the field and identify potential directions for future research."],"url":"http://arxiv.org/abs/2408.02464v1"}
{"created":"2024-08-05 13:28:51","title":"Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach","abstract":"Knowledge graphs (KGs) play a vital role in enhancing search results and recommendation systems. With the rapid increase in the size of the KGs, they are becoming inaccuracy and incomplete. This problem can be solved by the knowledge graph completion methods, of which graph attention network (GAT)-based methods stand out since their superior performance. However, existing GAT-based knowledge graph completion methods often suffer from overfitting issues when dealing with heterogeneous knowledge graphs, primarily due to the unbalanced number of samples. Additionally, these methods demonstrate poor performance in predicting the tail (head) entity that shares the same relation and head (tail) entity with others. To solve these problems, we propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH incorporates two separate attention network modules that work synergistically to predict the missing entities. We also introduce novel encoding and feature transformation approaches, enabling the robust performance of GATH in scenarios with imbalanced samples. Comprehensive experiments are conducted to evaluate the GATH's performance. Compared with the existing SOTA GAT-based model on Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the FB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.","sentences":["Knowledge graphs (KGs) play a vital role in enhancing search results and recommendation systems.","With the rapid increase in the size of the KGs, they are becoming inaccuracy and incomplete.","This problem can be solved by the knowledge graph completion methods, of which graph attention network (GAT)-based methods stand out since their superior performance.","However, existing GAT-based knowledge graph completion methods often suffer from overfitting issues when dealing with heterogeneous knowledge graphs, primarily due to the unbalanced number of samples.","Additionally, these methods demonstrate poor performance in predicting the tail (head) entity that shares the same relation and head (tail) entity with others.","To solve these problems, we propose GATH, a novel GAT-based method designed for Heterogeneous KGs.","GATH incorporates two separate attention network modules that work synergistically to predict the missing entities.","We also introduce novel encoding and feature transformation approaches, enabling the robust performance of GATH in scenarios with imbalanced samples.","Comprehensive experiments are conducted to evaluate the GATH's performance.","Compared with the existing SOTA GAT-based model on Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the FB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively."],"url":"http://arxiv.org/abs/2408.02456v1"}
{"created":"2024-08-05 13:13:17","title":"Second 6G life Workshop on Post Shannon Theory","abstract":"The one-day workshop, held prior to the \"ZIF Workshop on Information Theory and Related Fields\", provided an excellent opportunity for in-depth discussions on several topics within the field of post-Shannon theory. The agenda covered deterministic and randomized identification, focusing on various methods and algorithms for identifying data or signals deterministically and through randomized processes. It explored the theoretical foundations and practical applications of these techniques. The session on resources for increasing identification capacity examined the different resources and strategies that can be utilized to boost the capacity for identifying information. This included discussions on both hardware and software solutions, as well as innovative approaches to resource allocation and optimization. Participants delved into common randomness generation, essential for various cryptographic protocols and communication systems. The session highlighted recent advancements and practical implementations of common randomness in secure communications. The workshop concluded with a detailed look at the development and practical deployment of identification codes. Experts shared insights on code construction techniques, implementation challenges, and real-world applications in various communication systems. We extend our thanks to the esteemed speakers for their valuable contributions: Caspar von Lengerke, Wafa Labidi, Ilya Vorobyev, Johannes Rosenberger, Jonathan Huffmann, and Pau Colomer. Their presentations and insights significantly enriched the workshop. Additionally, we are grateful to all the participants whose active engagement, constructive comments, and stimulating discussions made the event a success. Your involvement was crucial in fostering a collaborative and intellectually vibrant environment.","sentences":["The one-day workshop, held prior to the \"ZIF Workshop on Information Theory and Related Fields\", provided an excellent opportunity for in-depth discussions on several topics within the field of post-Shannon theory.","The agenda covered deterministic and randomized identification, focusing on various methods and algorithms for identifying data or signals deterministically and through randomized processes.","It explored the theoretical foundations and practical applications of these techniques.","The session on resources for increasing identification capacity examined the different resources and strategies that can be utilized to boost the capacity for identifying information.","This included discussions on both hardware and software solutions, as well as innovative approaches to resource allocation and optimization.","Participants delved into common randomness generation, essential for various cryptographic protocols and communication systems.","The session highlighted recent advancements and practical implementations of common randomness in secure communications.","The workshop concluded with a detailed look at the development and practical deployment of identification codes.","Experts shared insights on code construction techniques, implementation challenges, and real-world applications in various communication systems.","We extend our thanks to the esteemed speakers for their valuable contributions: Caspar von Lengerke, Wafa Labidi, Ilya Vorobyev, Johannes Rosenberger, Jonathan Huffmann, and Pau Colomer.","Their presentations and insights significantly enriched the workshop.","Additionally, we are grateful to all the participants whose active engagement, constructive comments, and stimulating discussions made the event a success.","Your involvement was crucial in fostering a collaborative and intellectually vibrant environment."],"url":"http://arxiv.org/abs/2408.02446v1"}
{"created":"2024-08-05 12:34:49","title":"Attenuation-adjusted deep learning of pore defects in 2D radiographs of additive manufacturing powders","abstract":"The presence of gas pores in metal feedstock powder for additive manufacturing greatly affects the final AM product. Since current porosity analysis often involves lengthy X-ray computed tomography (XCT) scans with a full rotation around the sample, motivation exists to explore methods that allow for high throughput -- possibly enabling in-line porosity analysis during manufacturing. Through labelling pore pixels on single 2D radiographs of powders, this work seeks to simulate such future efficient setups. High segmentation accuracy is achieved by combining a model of X-ray attenuation through particles with a variant of the widely applied UNet architecture; notably, F1-score increases by $11.4\\%$ compared to the baseline UNet. The proposed pore segmentation is enabled by: 1) pretraining on synthetic data, 2) making tight particle cutouts, and 3) subtracting an ideal particle without pores generated from a distance map inspired by Lambert-Beers law. This paper explores four image processing methods, where the fastest (yet still unoptimized) segments a particle in mean $0.014s$ time with F1-score $0.78$, and the most accurate in $0.291s$ with F1-score $0.87$. Due to their scalable nature, these strategies can be involved in making high throughput porosity analysis of metal feedstock powder for additive manufacturing.","sentences":["The presence of gas pores in metal feedstock powder for additive manufacturing greatly affects the final AM product.","Since current porosity analysis often involves lengthy X-ray computed tomography (XCT) scans with a full rotation around the sample, motivation exists to explore methods that allow for high throughput -- possibly enabling in-line porosity analysis during manufacturing.","Through labelling pore pixels on single 2D radiographs of powders, this work seeks to simulate such future efficient setups.","High segmentation accuracy is achieved by combining a model of X-ray attenuation through particles with a variant of the widely applied UNet architecture; notably, F1-score increases by $11.4\\%$ compared to the baseline UNet.","The proposed pore segmentation is enabled by: 1) pretraining on synthetic data, 2) making tight particle cutouts, and 3) subtracting an ideal particle without pores generated from a distance map inspired by Lambert-Beers law.","This paper explores four image processing methods, where the fastest (yet still unoptimized) segments a particle in mean $0.014s$ time with F1-score $0.78$, and the most accurate in $0.291s$ with F1-score $0.87$. Due to their scalable nature, these strategies can be involved in making high throughput porosity analysis of metal feedstock powder for additive manufacturing."],"url":"http://arxiv.org/abs/2408.02427v1"}
{"created":"2024-08-05 12:11:09","title":"PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy","abstract":"Convolutional Neural Networks (CNNs), a prominent type of Deep Neural Networks (DNNs), have emerged as a state-of-the-art solution for solving machine learning tasks. To improve the performance and energy efficiency of CNN inference, the employment of specialized hardware accelerators is prevalent. However, CNN accelerators still face performance- and energy-efficiency challenges due to high off-chip memory (DRAM) access latency and energy, which are especially crucial for latency- and energy-constrained embedded applications. Moreover, different DRAM architectures have different profiles of access latency and energy, thus making it challenging to optimize them for high performance and energy-efficient CNN accelerators. To address this, we present PENDRAM, a novel design space exploration methodology that enables high-performance and energy-efficient CNN acceleration through a generalized DRAM data mapping policy. Specifically, it explores the impact of different DRAM data mapping policies and DRAM architectures across different CNN partitioning and scheduling schemes on the DRAM access latency and energy, then identifies the pareto-optimal design choices. The experimental results show that our DRAM data mapping policy improves the energy-delay-product of DRAM accesses in the CNN accelerator over other mapping policies by up to 96%. In this manner, our PENDRAM methodology offers high-performance and energy-efficient CNN acceleration under any given DRAM architectures for diverse embedded AI applications.","sentences":["Convolutional Neural Networks (CNNs), a prominent type of Deep Neural Networks (DNNs), have emerged as a state-of-the-art solution for solving machine learning tasks.","To improve the performance and energy efficiency of CNN inference, the employment of specialized hardware accelerators is prevalent.","However, CNN accelerators still face performance-","and energy-efficiency challenges due to high off-chip memory (DRAM) access latency and energy, which are especially crucial for latency- and energy-constrained embedded applications.","Moreover, different DRAM architectures have different profiles of access latency and energy, thus making it challenging to optimize them for high performance and energy-efficient CNN accelerators.","To address this, we present PENDRAM, a novel design space exploration methodology that enables high-performance and energy-efficient CNN acceleration through a generalized DRAM data mapping policy.","Specifically, it explores the impact of different DRAM data mapping policies and DRAM architectures across different CNN partitioning and scheduling schemes on the DRAM access latency and energy, then identifies the pareto-optimal design choices.","The experimental results show that our DRAM data mapping policy improves the energy-delay-product of DRAM accesses in the CNN accelerator over other mapping policies by up to 96%.","In this manner, our PENDRAM methodology offers high-performance and energy-efficient CNN acceleration under any given DRAM architectures for diverse embedded AI applications."],"url":"http://arxiv.org/abs/2408.02412v1"}
{"created":"2024-08-05 11:55:41","title":"Online Fair Allocation with Best-of-Many-Worlds Guarantees","abstract":"We investigate the online fair allocation problem with sequentially arriving items under various input models, with the goal of balancing fairness and efficiency. We propose the unconstrained PACE (Pacing According to Current Estimated utility) algorithm, a parameter-free allocation dynamic that requires no prior knowledge of the input while using only integral allocations. PACE attains near-optimal convergence or approximation guarantees under stationary, stochastic-but-nonstationary, and adversarial input types, thereby achieving the first best-of-many-worlds guarantee in online fair allocation. Beyond theoretical bounds, PACE is highly simple, efficient, and decentralized, and is thus likely to perform well on a broad range of real-world inputs. Numerical results support the conclusion that PACE works well under a variety of input models. We find that PACE performs very well on two real-world datasets even under the true temporal arrivals in the data, which are highly nonstationary.","sentences":["We investigate the online fair allocation problem with sequentially arriving items under various input models, with the goal of balancing fairness and efficiency.","We propose the unconstrained PACE (Pacing According to Current Estimated utility) algorithm, a parameter-free allocation dynamic that requires no prior knowledge of the input while using only integral allocations.","PACE attains near-optimal convergence or approximation guarantees under stationary, stochastic-but-nonstationary, and adversarial input types, thereby achieving the first best-of-many-worlds guarantee in online fair allocation.","Beyond theoretical bounds, PACE is highly simple, efficient, and decentralized, and is thus likely to perform well on a broad range of real-world inputs.","Numerical results support the conclusion that PACE works well under a variety of input models.","We find that PACE performs very well on two real-world datasets even under the true temporal arrivals in the data, which are highly nonstationary."],"url":"http://arxiv.org/abs/2408.02403v1"}
{"created":"2024-08-05 11:52:34","title":"Enhancing AI-based Generation of Software Exploits with Contextual Information","abstract":"This practical experience report explores Neural Machine Translation (NMT) models' capability to generate offensive security code from natural language (NL) descriptions, highlighting the significance of contextual understanding and its impact on model performance. Our study employs a dataset comprising real shellcodes to evaluate the models across various scenarios, including missing information, necessary context, and unnecessary context. The experiments are designed to assess the models' resilience against incomplete descriptions, their proficiency in leveraging context for enhanced accuracy, and their ability to discern irrelevant information. The findings reveal that the introduction of contextual data significantly improves performance. However, the benefits of additional context diminish beyond a certain point, indicating an optimal level of contextual information for model training. Moreover, the models demonstrate an ability to filter out unnecessary context, maintaining high levels of accuracy in the generation of offensive security code. This study paves the way for future research on optimizing context use in AI-driven code generation, particularly for applications requiring a high degree of technical precision such as the generation of offensive code.","sentences":["This practical experience report explores Neural Machine Translation (NMT) models' capability to generate offensive security code from natural language (NL) descriptions, highlighting the significance of contextual understanding and its impact on model performance.","Our study employs a dataset comprising real shellcodes to evaluate the models across various scenarios, including missing information, necessary context, and unnecessary context.","The experiments are designed to assess the models' resilience against incomplete descriptions, their proficiency in leveraging context for enhanced accuracy, and their ability to discern irrelevant information.","The findings reveal that the introduction of contextual data significantly improves performance.","However, the benefits of additional context diminish beyond a certain point, indicating an optimal level of contextual information for model training.","Moreover, the models demonstrate an ability to filter out unnecessary context, maintaining high levels of accuracy in the generation of offensive security code.","This study paves the way for future research on optimizing context use in AI-driven code generation, particularly for applications requiring a high degree of technical precision such as the generation of offensive code."],"url":"http://arxiv.org/abs/2408.02402v1"}
{"created":"2024-08-05 11:42:41","title":"Tensorial template matching for fast cross-correlation with rotations and its application for tomography","abstract":"Object detection is a main task in computer vision. Template matching is the reference method for detecting objects with arbitrary templates. However, template matching computational complexity depends on the rotation accuracy, being a limiting factor for large 3D images (tomograms). Here, we implement a new algorithm called tensorial template matching, based on a mathematical framework that represents all rotations of a template with a tensor field. Contrary to standard template matching, the computational complexity of the presented algorithm is independent of the rotation accuracy. Using both, synthetic and real data from tomography, we demonstrate that tensorial template matching is much faster than template matching and has the potential to improve its accuracy","sentences":["Object detection is a main task in computer vision.","Template matching is the reference method for detecting objects with arbitrary templates.","However, template matching computational complexity depends on the rotation accuracy, being a limiting factor for large 3D images (tomograms).","Here, we implement a new algorithm called tensorial template matching, based on a mathematical framework that represents all rotations of a template with a tensor field.","Contrary to standard template matching, the computational complexity of the presented algorithm is independent of the rotation accuracy.","Using both, synthetic and real data from tomography, we demonstrate that tensorial template matching is much faster than template matching and has the potential to improve its accuracy"],"url":"http://arxiv.org/abs/2408.02398v1"}
{"created":"2024-08-05 11:39:22","title":"MaFreeI2P: A Matching-Free Image-to-Point Cloud Registration Paradigm with Active Camera Pose Retrieval","abstract":"Image-to-point cloud registration seeks to estimate their relative camera pose, which remains an open question due to the data modality gaps. The recent matching-based methods tend to tackle this by building 2D-3D correspondences. In this paper, we reveal the information loss inherent in these methods and propose a matching-free paradigm, named MaFreeI2P. Our key insight is to actively retrieve the camera pose in SE(3) space by contrasting the geometric features between the point cloud and the query image. To achieve this, we first sample a set of candidate camera poses and construct their cost volume using the cross-modal features. Superior to matching, cost volume can preserve more information and its feature similarity implicitly reflects the confidence level of the sampled poses. Afterwards, we employ a convolutional network to adaptively formulate a similarity assessment function, where the input cost volume is further improved by filtering and pose-based weighting. Finally, we update the camera pose based on the similarity scores, and adopt a heuristic strategy to iteratively shrink the pose sampling space for convergence. Our MaFreeI2P achieves a very competitive registration accuracy and recall on the KITTI-Odometry and Apollo-DaoxiangLake datasets.","sentences":["Image-to-point cloud registration seeks to estimate their relative camera pose, which remains an open question due to the data modality gaps.","The recent matching-based methods tend to tackle this by building 2D-3D correspondences.","In this paper, we reveal the information loss inherent in these methods and propose a matching-free paradigm, named MaFreeI2P. Our key insight is to actively retrieve the camera pose in SE(3) space by contrasting the geometric features between the point cloud and the query image.","To achieve this, we first sample a set of candidate camera poses and construct their cost volume using the cross-modal features.","Superior to matching, cost volume can preserve more information and its feature similarity implicitly reflects the confidence level of the sampled poses.","Afterwards, we employ a convolutional network to adaptively formulate a similarity assessment function, where the input cost volume is further improved by filtering and pose-based weighting.","Finally, we update the camera pose based on the similarity scores, and adopt a heuristic strategy to iteratively shrink the pose sampling space for convergence.","Our MaFreeI2P achieves a very competitive registration accuracy and recall on the KITTI-Odometry and Apollo-DaoxiangLake datasets."],"url":"http://arxiv.org/abs/2408.02392v1"}
{"created":"2024-08-05 11:27:30","title":"Fast Estimation of Percolation Centrality","abstract":"In this work, we present a new algorithm to approximate the percolation centrality of every node in a graph. Such a centrality measure quantifies the importance of the vertices in a network during a contagious process. In this paper, we present a randomized approximation algorithm that can compute probabilistically guaranteed high-quality percolation centrality estimates, generalizing techniques used by Pellegrina and Vandin (TKDD 2024) for the betweenness centrality. The estimation obtained by our algorithm is within $\\varepsilon$ of the value with probability at least $1-\\delta$, for fixed constants $\\varepsilon,\\delta \\in (0,1)$. We our theoretical results with an extensive experimental analysis on several real-world networks and provide empirical evidence that our algorithm improves the current state of the art in speed, and sample size while maintaining high accuracy of the percolation centrality estimates.","sentences":["In this work, we present a new algorithm to approximate the percolation centrality of every node in a graph.","Such a centrality measure quantifies the importance of the vertices in a network during a contagious process.","In this paper, we present a randomized approximation algorithm that can compute probabilistically guaranteed high-quality percolation centrality estimates, generalizing techniques used by Pellegrina and Vandin (TKDD 2024) for the betweenness centrality.","The estimation obtained by our algorithm is within $\\varepsilon$ of the value with probability at least $1-\\delta$, for fixed constants $\\varepsilon,\\delta \\in (0,1)$. We our theoretical results with an extensive experimental analysis on several real-world networks and provide empirical evidence that our algorithm improves the current state of the art in speed, and sample size while maintaining high accuracy of the percolation centrality estimates."],"url":"http://arxiv.org/abs/2408.02389v1"}
{"created":"2024-08-05 11:16:26","title":"Strategic Federated Learning: Application to Smart Meter Data Clustering","abstract":"Federated learning (FL) involves several clients that share with a fusion center (FC), the model each client has trained with its own data. Conventional FL, which can be interpreted as an estimation or distortion-based approach, ignores the final use of model information (MI) by the FC and the other clients. In this paper, we introduce a novel FL framework in which the FC uses an aggregate version of the MI to make decisions that affect the client's utility functions. Clients cannot choose the decisions and can only use the MI reported to the FC to maximize their utility. Depending on the alignment between the client and FC utilities, the client may have an individual interest in adding strategic noise to the model. This general framework is stated and specialized to the case of clustering, in which noisy cluster representative information is reported. This is applied to the problem of power consumption scheduling. In this context, utility non-alignment occurs, for instance, when the client wants to consume when the price of electricity is low, whereas the FC wants the consumption to occur when the total power is the lowest. This is illustrated with aggregated real data from Ausgrid \\cite{ausgrid}. Our numerical analysis clearly shows that the client can increase his utility by adding noise to the model reported to the FC. Corresponding results and source codes can be downloaded from \\cite{source-code}.","sentences":["Federated learning (FL) involves several clients that share with a fusion center (FC), the model each client has trained with its own data.","Conventional FL, which can be interpreted as an estimation or distortion-based approach, ignores the final use of model information (MI) by the FC and the other clients.","In this paper, we introduce a novel FL framework in which the FC uses an aggregate version of the MI to make decisions that affect the client's utility functions.","Clients cannot choose the decisions and can only use the MI reported to the FC to maximize their utility.","Depending on the alignment between the client and FC utilities, the client may have an individual interest in adding strategic noise to the model.","This general framework is stated and specialized to the case of clustering, in which noisy cluster representative information is reported.","This is applied to the problem of power consumption scheduling.","In this context, utility non-alignment occurs, for instance, when the client wants to consume when the price of electricity is low, whereas the FC wants the consumption to occur when the total power is the lowest.","This is illustrated with aggregated real data from Ausgrid \\cite{ausgrid}.","Our numerical analysis clearly shows that the client can increase his utility by adding noise to the model reported to the FC.","Corresponding results and source codes can be downloaded from \\cite{source-code}."],"url":"http://arxiv.org/abs/2408.02384v1"}
{"created":"2024-08-05 11:14:23","title":"Cross Psuedo Supervision Framework for Sparsely Labelled Geo-spatial Images","abstract":"Land Use Land Cover (LULC) mapping is essential for urban and resource planning and is one of the key elements in developing smart and sustainable cities. This study introduces a semi-supervised segmentation model for LULC prediction using high-resolution satellite images with a huge diversity in data distributions in different areas from the country of India. Our approach ensures a robust generalization across different types of buildings, roads, trees, and water bodies within these distinct areas. We propose a modified Cross Pseudo Supervision framework to train image segmentation models on sparsely labelled data. The proposed framework addresses the limitations of the popular \"Cross Pseudo Supervision\" technique for semi-supervised learning. Specifically, it tackles the challenges of training segmentation models on noisy satellite image data with sparse and inaccurate labels. This comprehensive approach enhances the accuracy and utility of LULC mapping for various urban planning applications.","sentences":["Land Use Land Cover (LULC) mapping is essential for urban and resource planning and is one of the key elements in developing smart and sustainable cities.","This study introduces a semi-supervised segmentation model for LULC prediction using high-resolution satellite images with a huge diversity in data distributions in different areas from the country of India.","Our approach ensures a robust generalization across different types of buildings, roads, trees, and water bodies within these distinct areas.","We propose a modified Cross Pseudo Supervision framework to train image segmentation models on sparsely labelled data.","The proposed framework addresses the limitations of the popular \"Cross Pseudo Supervision\" technique for semi-supervised learning.","Specifically, it tackles the challenges of training segmentation models on noisy satellite image data with sparse and inaccurate labels.","This comprehensive approach enhances the accuracy and utility of LULC mapping for various urban planning applications."],"url":"http://arxiv.org/abs/2408.02382v1"}
{"created":"2024-08-05 11:06:36","title":"A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models","abstract":"Knowledge graphs (KGs) have been successfully applied to the analysis of complex scientific and technological domains, with automatic KG generation methods typically building upon relation extraction models capturing fine-grained relations between domain entities in text. While these relations are fully applicable across scientific areas, existing models are trained on few domain-specific datasets such as SciERC and do not perform well on new target domains. In this paper, we experiment with leveraging in-context learning capabilities of Large Language Models to perform schema-constrained data annotation, collecting in-domain training instances for a Transformer-based relation extraction model deployed on titles and abstracts of research papers in the Architecture, Construction, Engineering and Operations (AECO) domain. By assessing the performance gain with respect to a baseline Deep Learning architecture trained on off-domain data, we show that by using a few-shot learning strategy with structured prompts and only minimal expert annotation the presented approach can potentially support domain adaptation of a science KG generation model.","sentences":["Knowledge graphs (KGs) have been successfully applied to the analysis of complex scientific and technological domains, with automatic KG generation methods typically building upon relation extraction models capturing fine-grained relations between domain entities in text.","While these relations are fully applicable across scientific areas, existing models are trained on few domain-specific datasets such as SciERC and do not perform well on new target domains.","In this paper, we experiment with leveraging in-context learning capabilities of Large Language Models to perform schema-constrained data annotation, collecting in-domain training instances for a Transformer-based relation extraction model deployed on titles and abstracts of research papers in the Architecture, Construction, Engineering and Operations (AECO) domain.","By assessing the performance gain with respect to a baseline Deep Learning architecture trained on off-domain data, we show that by using a few-shot learning strategy with structured prompts and only minimal expert annotation the presented approach can potentially support domain adaptation of a science KG generation model."],"url":"http://arxiv.org/abs/2408.02377v1"}
{"created":"2024-08-05 10:53:51","title":"Operationalizing Contextual Integrity in Privacy-Conscious Assistants","abstract":"Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize $\\textit{contextual integrity}$ (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of synthetic data and human annotations, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields strong results.","sentences":["Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users.","While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision.","To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize $\\textit{contextual integrity}$ (CI), a framework that equates privacy with the appropriate flow of information in a given context.","In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant.","Our evaluation is based on a novel form filling benchmark composed of synthetic data and human annotations, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields strong results."],"url":"http://arxiv.org/abs/2408.02373v1"}
{"created":"2024-08-05 10:38:50","title":"The NPU-ASLP System Description for Visual Speech Recognition in CNVSRC 2024","abstract":"This paper delineates the visual speech recognition (VSR) system introduced by the NPU-ASLP (Team 237) in the second Chinese Continuous Visual Speech Recognition Challenge (CNVSRC 2024), engaging in all four tracks, including the fixed and open tracks of Single-Speaker VSR Task and Multi-Speaker VSR Task. In terms of data processing, we leverage the lip motion extractor from the baseline1 to produce multiscale video data. Besides, various augmentation techniques are applied during training, encompassing speed perturbation, random rotation, horizontal flipping, and color transformation. The VSR model adopts an end-to-end architecture with joint CTC/attention loss, introducing Enhanced ResNet3D visual frontend, E-Branchformer encoder, and Bi-directional Transformer decoder. Our approach yields a 30.47% CER for the Single-Speaker Task and 34.30% CER for the Multi-Speaker Task, securing second place in the open track of the Single-Speaker Task and first place in the other three tracks.","sentences":["This paper delineates the visual speech recognition (VSR) system introduced by the NPU-ASLP (Team 237) in the second Chinese Continuous Visual Speech Recognition Challenge (CNVSRC 2024), engaging in all four tracks, including the fixed and open tracks of Single-Speaker VSR Task and Multi-Speaker VSR Task.","In terms of data processing, we leverage the lip motion extractor from the baseline1 to produce multiscale video data.","Besides, various augmentation techniques are applied during training, encompassing speed perturbation, random rotation, horizontal flipping, and color transformation.","The VSR model adopts an end-to-end architecture with joint CTC/attention loss, introducing Enhanced ResNet3D visual frontend, E-Branchformer encoder, and Bi-directional Transformer decoder.","Our approach yields a 30.47% CER for the Single-Speaker Task and 34.30% CER for the Multi-Speaker Task, securing second place in the open track of the Single-Speaker Task and first place in the other three tracks."],"url":"http://arxiv.org/abs/2408.02369v1"}
{"created":"2024-08-05 10:10:01","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding","abstract":"State-of-the-art task-oriented dialogue systems typically rely on task-specific ontologies for fulfilling user queries. The majority of task-oriented dialogue data, such as customer service recordings, comes without ontology and annotation. Such ontologies are normally built manually, limiting the application of specialised systems. Dialogue ontology construction is an approach for automating that process and typically consists of two steps: term extraction and relation extraction. In this work, we focus on relation extraction in a transfer learning set-up. To improve the generalisation, we propose an extension to the decoding mechanism of large language models. We adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning problems, to generative relation extraction. Here, we generate multiple branches in the decoding space and select the relations based on a confidence threshold. By constraining the decoding to ontology terms and relations, we aim to decrease the risk of hallucination. We conduct extensive experimentation on two widely used datasets and find improvements in performance on target ontology for source fine-tuned and one-shot prompted large language models.","sentences":["State-of-the-art task-oriented dialogue systems typically rely on task-specific ontologies for fulfilling user queries.","The majority of task-oriented dialogue data, such as customer service recordings, comes without ontology and annotation.","Such ontologies are normally built manually, limiting the application of specialised systems.","Dialogue ontology construction is an approach for automating that process and typically consists of two steps: term extraction and relation extraction.","In this work, we focus on relation extraction in a transfer learning set-up.","To improve the generalisation, we propose an extension to the decoding mechanism of large language models.","We adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning problems, to generative relation extraction.","Here, we generate multiple branches in the decoding space and select the relations based on a confidence threshold.","By constraining the decoding to ontology terms and relations, we aim to decrease the risk of hallucination.","We conduct extensive experimentation on two widely used datasets and find improvements in performance on target ontology for source fine-tuned and one-shot prompted large language models."],"url":"http://arxiv.org/abs/2408.02361v1"}
{"created":"2024-08-05 09:54:08","title":"Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning","abstract":"Osteoarthritis (OA) is the most common musculoskeletal disease, which has no cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and it costs billions of United States dollars to the global community. Prediction of KOA progression has been of high interest to the community for years, as it can advance treatment development through more efficient clinical trials and improve patient outcomes through more efficient healthcare utilization. Existing approaches for predicting KOA, however, are predominantly static, i.e. consider data from a single time point to predict progression many years into the future, and knee level, i.e. consider progression in a single joint only. Due to these and related reasons, these methods fail to deliver the level of predictive performance, which is sufficient to result in cost savings and better patient outcomes. Collecting extensive data from all patients on a regular basis could address the issue, but it is limited by the high cost at a population level. In this work, we propose to go beyond static prediction models in OA, and bring a novel Active Sensing (AS) approach, designed to dynamically follow up patients with the objective of maximizing the number of informative data acquisitions, while minimizing their total cost over a period of time. Our approach is based on Reinforcement Learning (RL), and it leverages a novel reward function designed specifically for AS of disease progression in more than one part of a human body. Our method is end-to-end, relies on multi-modal Deep Learning, and requires no human input at inference time. Throughout an exhaustive experimental evaluation, we show that using RL can provide a higher monetary benefit when compared to state-of-the-art baselines.","sentences":["Osteoarthritis (OA) is the most common musculoskeletal disease, which has no cure.","Knee OA (KOA) is one of the highest causes of disability worldwide, and it costs billions of United States dollars to the global community.","Prediction of KOA progression has been of high interest to the community for years, as it can advance treatment development through more efficient clinical trials and improve patient outcomes through more efficient healthcare utilization.","Existing approaches for predicting KOA, however, are predominantly static, i.e. consider data from a single time point to predict progression many years into the future, and knee level, i.e. consider progression in a single joint only.","Due to these and related reasons, these methods fail to deliver the level of predictive performance, which is sufficient to result in cost savings and better patient outcomes.","Collecting extensive data from all patients on a regular basis could address the issue, but it is limited by the high cost at a population level.","In this work, we propose to go beyond static prediction models in OA, and bring a novel Active Sensing (AS) approach, designed to dynamically follow up patients with the objective of maximizing the number of informative data acquisitions, while minimizing their total cost over a period of time.","Our approach is based on Reinforcement Learning (RL), and it leverages a novel reward function designed specifically for AS of disease progression in more than one part of a human body.","Our method is end-to-end, relies on multi-modal Deep Learning, and requires no human input at inference time.","Throughout an exhaustive experimental evaluation, we show that using RL can provide a higher monetary benefit when compared to state-of-the-art baselines."],"url":"http://arxiv.org/abs/2408.02349v1"}
{"created":"2024-08-05 09:50:16","title":"Earth System Data Cubes: Avenues for advancing Earth system research","abstract":"Recent advancements in Earth system science have been marked by the exponential increase in the availability of diverse, multivariate datasets characterised by moderate to high spatio-temporal resolutions. Earth System Data Cubes (ESDCs) have emerged as one suitable solution for transforming this flood of data into a simple yet robust data structure. ESDCs achieve this by organising data into an analysis-ready format aligned with a spatio-temporal grid, facilitating user-friendly analysis and diminishing the need for extensive technical data processing knowledge. Despite these significant benefits, the completion of the entire ESDC life cycle remains a challenging task. Obstacles are not only of a technical nature but also relate to domain-specific problems in Earth system research. There exist barriers to realising the full potential of data collections in light of novel cloud-based technologies, particularly in curating data tailored for specific application domains. These include transforming data to conform to a spatio-temporal grid with minimum distortions and managing complexities such as spatio-temporal autocorrelation issues. Addressing these challenges is pivotal for the effective application of Artificial Intelligence (AI) approaches. Furthermore, adhering to open science principles for data dissemination, reproducibility, visualisation, and reuse is crucial for fostering sustainable research. Overcoming these challenges offers a substantial opportunity to advance data-driven Earth system research, unlocking the full potential of an integrated, multidimensional view of Earth system processes. This is particularly true when such research is coupled with innovative research paradigms and technological progress.","sentences":["Recent advancements in Earth system science have been marked by the exponential increase in the availability of diverse, multivariate datasets characterised by moderate to high spatio-temporal resolutions.","Earth System Data Cubes (ESDCs) have emerged as one suitable solution for transforming this flood of data into a simple yet robust data structure.","ESDCs achieve this by organising data into an analysis-ready format aligned with a spatio-temporal grid, facilitating user-friendly analysis and diminishing the need for extensive technical data processing knowledge.","Despite these significant benefits, the completion of the entire ESDC life cycle remains a challenging task.","Obstacles are not only of a technical nature but also relate to domain-specific problems in Earth system research.","There exist barriers to realising the full potential of data collections in light of novel cloud-based technologies, particularly in curating data tailored for specific application domains.","These include transforming data to conform to a spatio-temporal grid with minimum distortions and managing complexities such as spatio-temporal autocorrelation issues.","Addressing these challenges is pivotal for the effective application of Artificial Intelligence (AI) approaches.","Furthermore, adhering to open science principles for data dissemination, reproducibility, visualisation, and reuse is crucial for fostering sustainable research.","Overcoming these challenges offers a substantial opportunity to advance data-driven Earth system research, unlocking the full potential of an integrated, multidimensional view of Earth system processes.","This is particularly true when such research is coupled with innovative research paradigms and technological progress."],"url":"http://arxiv.org/abs/2408.02348v1"}
{"created":"2024-08-05 09:45:39","title":"Improved Bounds for High-Dimensional Equivalence and Product Testing using Subcube Queries","abstract":"We study property testing in the subcube conditional model introduced by Bhattacharyya and Chakraborty (2017). We obtain the first equivalence test for $n$-dimensional distributions that is quasi-linear in $n$, improving the previously known $\\tilde{O}(n^2/\\varepsilon^2)$ query complexity bound to $\\tilde{O}(n/\\varepsilon^2)$. We extend this result to general finite alphabets with logarithmic cost in the alphabet size.   By exploiting the specific structure of the queries that we use (which are more restrictive than general subcube queries), we obtain a cubic improvement over the best known test for distributions over $\\{1,\\ldots,N\\}$ under the interval querying model of Canonne, Ron and Servedio (2015), attaining a query complexity of $\\tilde{O}((\\log N)/\\varepsilon^2)$, which for fixed $\\varepsilon$ almost matches the known lower bound of $\\Omega((\\log N)/\\log\\log N)$. We also derive a product test for $n$-dimensional distributions with $\\tilde{O}(n / \\varepsilon^2)$ queries, and provide an $\\Omega(\\sqrt{n} / \\varepsilon^2)$ lower bound for this property.","sentences":["We study property testing in the subcube conditional model introduced by Bhattacharyya and Chakraborty (2017).","We obtain the first equivalence test for $n$-dimensional distributions that is quasi-linear in $n$, improving the previously known $\\tilde{O}(n^2/\\varepsilon^2)$ query complexity bound to $\\tilde{O}(n/\\varepsilon^2)$. We extend this result to general finite alphabets with logarithmic cost in the alphabet size.   ","By exploiting the specific structure of the queries that we use (which are more restrictive than general subcube queries), we obtain a cubic improvement over the best known test for distributions over $\\{1,\\ldots,N\\}$ under the interval querying model of Canonne, Ron and Servedio (2015), attaining a query complexity of $\\tilde{O}((\\log N)/\\varepsilon^2)$, which for fixed $\\varepsilon$ almost matches the known lower bound of $\\Omega((\\log N)/\\log\\log N)$. We also derive a product test for $n$-dimensional distributions with $\\tilde{O}(n / \\varepsilon^2)$ queries, and provide an $\\Omega(\\sqrt{n} / \\varepsilon^2)$ lower bound for this property."],"url":"http://arxiv.org/abs/2408.02347v1"}
{"created":"2024-08-05 09:45:31","title":"Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel Precision Matrices","abstract":"The Hilbert-space Gaussian Process (HGP) approach offers a hyperparameter-independent basis function approximation for speeding up Gaussian Process (GP) inference by projecting the GP onto M basis functions. These properties result in a favorable data-independent $\\mathcal{O}(M^3)$ computational complexity during hyperparameter optimization but require a dominating one-time precomputation of the precision matrix costing $\\mathcal{O}(NM^2)$ operations. In this paper, we lower this dominating computational complexity to $\\mathcal{O}(NM)$ with no additional approximations. We can do this because we realize that the precision matrix can be split into a sum of Hankel-Toeplitz matrices, each having $\\mathcal{O}(M)$ unique entries. Based on this realization we propose computing only these unique entries at $\\mathcal{O}(NM)$ costs. Further, we develop two theorems that prescribe sufficient conditions for the complexity reduction to hold generally for a wide range of other approximate GP models, such as the Variational Fourier Feature (VFF) approach. The two theorems do this with no assumptions on the data and no additional approximations of the GP models themselves. Thus, our contribution provides a pure speed-up of several existing, widely used, GP approximations, without further approximations.","sentences":["The Hilbert-space Gaussian Process (HGP) approach offers a hyperparameter-independent basis function approximation for speeding up Gaussian Process (GP) inference by projecting the GP onto M basis functions.","These properties result in a favorable data-independent $\\mathcal{O}(M^3)$ computational complexity during hyperparameter optimization but require a dominating one-time precomputation of the precision matrix costing $\\mathcal{O}(NM^2)$ operations.","In this paper, we lower this dominating computational complexity to $\\mathcal{O}(NM)$ with no additional approximations.","We can do this because we realize that the precision matrix can be split into a sum of Hankel-Toeplitz matrices, each having $\\mathcal{O}(M)$ unique entries.","Based on this realization we propose computing only these unique entries at $\\mathcal{O}(NM)$ costs.","Further, we develop two theorems that prescribe sufficient conditions for the complexity reduction to hold generally for a wide range of other approximate GP models, such as the Variational Fourier Feature (VFF) approach.","The two theorems do this with no assumptions on the data and no additional approximations of the GP models themselves.","Thus, our contribution provides a pure speed-up of several existing, widely used, GP approximations, without further approximations."],"url":"http://arxiv.org/abs/2408.02346v1"}
{"created":"2024-08-05 09:41:34","title":"Machine Learning Applications in Medical Prognostics: A Comprehensive Review","abstract":"Machine learning (ML) has revolutionized medical prognostics by integrating advanced algorithms with clinical data to enhance disease prediction, risk assessment, and patient outcome forecasting. This comprehensive review critically examines the application of various ML techniques in medical prognostics, focusing on their efficacy, challenges, and future directions. The methodologies discussed include Random Forest (RF) for sepsis prediction, logistic regression for cardiovascular risk assessment, Convolutional Neural Networks (CNNs) for cancer detection, and Long Short-Term Memory (LSTM) networks for predicting clinical deterioration. RF models demonstrate robust performance in handling high-dimensional data and capturing non-linear relationships, making them particularly effective for sepsis prediction. Logistic regression remains valuable for its interpretability and ease of use in cardiovascular risk assessment. CNNs have shown exceptional accuracy in cancer detection, leveraging their ability to learn complex visual patterns from medical imaging. LSTM networks excel in analyzing temporal data, providing accurate predictions of clinical deterioration. The review highlights the strengths and limitations of each technique, the importance of model interpretability, and the challenges of data quality and privacy. Future research directions include the integration of multi-modal data sources, the application of transfer learning, and the development of continuous learning systems. These advancements aim to enhance the predictive power and clinical applicability of ML models, ultimately improving patient outcomes in healthcare settings.","sentences":["Machine learning (ML) has revolutionized medical prognostics by integrating advanced algorithms with clinical data to enhance disease prediction, risk assessment, and patient outcome forecasting.","This comprehensive review critically examines the application of various ML techniques in medical prognostics, focusing on their efficacy, challenges, and future directions.","The methodologies discussed include Random Forest (RF) for sepsis prediction, logistic regression for cardiovascular risk assessment, Convolutional Neural Networks (CNNs) for cancer detection, and Long Short-Term Memory (LSTM) networks for predicting clinical deterioration.","RF models demonstrate robust performance in handling high-dimensional data and capturing non-linear relationships, making them particularly effective for sepsis prediction.","Logistic regression remains valuable for its interpretability and ease of use in cardiovascular risk assessment.","CNNs have shown exceptional accuracy in cancer detection, leveraging their ability to learn complex visual patterns from medical imaging.","LSTM networks excel in analyzing temporal data, providing accurate predictions of clinical deterioration.","The review highlights the strengths and limitations of each technique, the importance of model interpretability, and the challenges of data quality and privacy.","Future research directions include the integration of multi-modal data sources, the application of transfer learning, and the development of continuous learning systems.","These advancements aim to enhance the predictive power and clinical applicability of ML models, ultimately improving patient outcomes in healthcare settings."],"url":"http://arxiv.org/abs/2408.02344v1"}
{"created":"2024-08-05 09:02:45","title":"The OpenCitations Index","abstract":"This article presents the OpenCitations Index, a collection of open citation data maintained by OpenCitations, an independent, not-for-profit infrastructure organisation for open scholarship dedicated to publishing open bibliographic and citation data using Semantic Web and Linked Open Data technologies. The collection involves citation data harvested from multiple sources. To address the possibility of different sources providing citation data for bibliographic entities represented with different identifiers, therefore potentially representing same citation, a deduplication mechanism has been implemented. This ensures that citations integrated into OpenCitations Index are accurately identified uniquely, even when different identifiers are used. This mechanism follows a specific workflow, which encompasses a preprocessing of the original source data, a management of the provided bibliographic metadata, and the generation of new citation data to be integrated into the OpenCitations Index. The process relies on another data collection: OpenCitations Meta, and on the use of a new globally persistent identifier, namely OMID (OpenCitations Meta Identifier). As of July 2024, OpenCitations Index stores over 2 billion unique citation links, harvest from Crossref, the National Institute of Heath Open Citation Collection (NIH-OCC), DataCite, OpenAIRE, and the Japan Link Center (JaLC). OpenCitations Index can be systematically accessed and queried through several services, including SPARQL endpoint, REST APIs, and web interfaces. Additionally, dataset dumps are available for free download and reuse (under CC0 waiver) in various formats (CSV, N-Triples, and Scholix), including provenance and change tracking information.","sentences":["This article presents the OpenCitations Index, a collection of open citation data maintained by OpenCitations, an independent, not-for-profit infrastructure organisation for open scholarship dedicated to publishing open bibliographic and citation data using Semantic Web and Linked Open Data technologies.","The collection involves citation data harvested from multiple sources.","To address the possibility of different sources providing citation data for bibliographic entities represented with different identifiers, therefore potentially representing same citation, a deduplication mechanism has been implemented.","This ensures that citations integrated into OpenCitations Index are accurately identified uniquely, even when different identifiers are used.","This mechanism follows a specific workflow, which encompasses a preprocessing of the original source data, a management of the provided bibliographic metadata, and the generation of new citation data to be integrated into the OpenCitations Index.","The process relies on another data collection: OpenCitations Meta, and on the use of a new globally persistent identifier, namely OMID (OpenCitations Meta Identifier).","As of July 2024, OpenCitations Index stores over 2 billion unique citation links, harvest from Crossref, the National Institute of Heath Open Citation Collection (NIH-OCC), DataCite, OpenAIRE, and the Japan Link Center (JaLC).","OpenCitations Index can be systematically accessed and queried through several services, including SPARQL endpoint, REST APIs, and web interfaces.","Additionally, dataset dumps are available for free download and reuse (under CC0 waiver) in various formats (CSV, N-Triples, and Scholix), including provenance and change tracking information."],"url":"http://arxiv.org/abs/2408.02321v1"}
{"created":"2024-08-05 09:02:24","title":"A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion Models","abstract":"Diffusion models, which convert noise into new data instances by learning to reverse a diffusion process, have become a cornerstone in contemporary generative modeling. In this work, we develop non-asymptotic convergence theory for a popular diffusion-based sampler (i.e., the probability flow ODE sampler) in discrete time, assuming access to $\\ell_2$-accurate estimates of the (Stein) score functions. For distributions in $\\mathbb{R}^d$, we prove that $d/\\varepsilon$ iterations -- modulo some logarithmic and lower-order terms -- are sufficient to approximate the target distribution to within $\\varepsilon$ total-variation distance. This is the first result establishing nearly linear dimension-dependency (in $d$) for the probability flow ODE sampler. Imposing only minimal assumptions on the target data distribution (e.g., no smoothness assumption is imposed), our results also characterize how $\\ell_2$ score estimation errors affect the quality of the data generation processes. In contrast to prior works, our theory is developed based on an elementary yet versatile non-asymptotic approach without the need of resorting to SDE and ODE toolboxes.","sentences":["Diffusion models, which convert noise into new data instances by learning to reverse a diffusion process, have become a cornerstone in contemporary generative modeling.","In this work, we develop non-asymptotic convergence theory for a popular diffusion-based sampler (i.e., the probability flow ODE sampler) in discrete time, assuming access to $\\ell_2$-accurate estimates of the (Stein) score functions.","For distributions in $\\mathbb{R}^d$, we prove that $d/\\varepsilon$ iterations -- modulo some logarithmic and lower-order terms -- are sufficient to approximate the target distribution to within $\\varepsilon$ total-variation distance.","This is the first result establishing nearly linear dimension-dependency (in $d$) for the probability flow ODE sampler.","Imposing only minimal assumptions on the target data distribution (e.g., no smoothness assumption is imposed), our results also characterize how $\\ell_2$ score estimation errors affect the quality of the data generation processes.","In contrast to prior works, our theory is developed based on an elementary yet versatile non-asymptotic approach without the need of resorting to SDE and ODE toolboxes."],"url":"http://arxiv.org/abs/2408.02320v1"}
{"created":"2024-08-05 08:24:24","title":"SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models","abstract":"Large language models (LLMs) have become powerful tools for advancing natural language processing applications in the financial industry. However, existing financial LLMs often face challenges such as hallucinations or superficial parameter training, resulting in suboptimal performance, particularly in financial computing and machine reading comprehension (MRC). To address these issues, we propose a novel large language model specifically designed for the Chinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific tasks such as answering questions, summarizing financial research reports, analyzing sentiment, and executing financial calculations. We then perform the supervised fine-tuning (SFT) to enhance the model's proficiency across various financial domains. Specifically, we gather extensive financial data and create a high-quality instruction dataset composed of news articles, professional papers, and research reports of finance domain. Utilizing both domain-specific and general datasets, we proceed with continuous pre-training on an established open-source base model, resulting in SNFinLLM-base. Following this, we engage in supervised fine-tuning (SFT) to bolster the model's capability across multiple financial tasks. Crucially, we employ a straightforward Direct Preference Optimization (DPO) method to better align the model with human preferences. Extensive experiments conducted on finance benchmarks and our evaluation dataset demonstrate that SNFinLLM markedly outperforms other state-of-the-art financial language models. For more details, check out our demo video here: https://www.youtube.com/watch?v=GYT-65HZwus.","sentences":["Large language models (LLMs) have become powerful tools for advancing natural language processing applications in the financial industry.","However, existing financial LLMs often face challenges such as hallucinations or superficial parameter training, resulting in suboptimal performance, particularly in financial computing and machine reading comprehension (MRC).","To address these issues, we propose a novel large language model specifically designed for the Chinese financial domain, named SNFinLLM.","SNFinLLM excels in domain-specific tasks such as answering questions, summarizing financial research reports, analyzing sentiment, and executing financial calculations.","We then perform the supervised fine-tuning (SFT) to enhance the model's proficiency across various financial domains.","Specifically, we gather extensive financial data and create a high-quality instruction dataset composed of news articles, professional papers, and research reports of finance domain.","Utilizing both domain-specific and general datasets, we proceed with continuous pre-training on an established open-source base model, resulting in SNFinLLM-base.","Following this, we engage in supervised fine-tuning (SFT) to bolster the model's capability across multiple financial tasks.","Crucially, we employ a straightforward Direct Preference Optimization (DPO) method to better align the model with human preferences.","Extensive experiments conducted on finance benchmarks and our evaluation dataset demonstrate that SNFinLLM markedly outperforms other state-of-the-art financial language models.","For more details, check out our demo video here: https://www.youtube.com/watch?v=GYT-65HZwus."],"url":"http://arxiv.org/abs/2408.02302v1"}
{"created":"2024-08-05 08:17:34","title":"A Lower Bound for Local Search Proportional Approval Voting","abstract":"Selecting $k$ out of $m$ items based on the preferences of $n$ heterogeneous agents is a widely studied problem in algorithmic game theory. If agents have approval preferences over individual items and harmonic utility functions over bundles -- an agent receives $\\sum_{j=1}^t\\frac{1}{j}$ utility if $t$ of her approved items are selected -- then welfare optimisation is captured by a voting rule known as Proportional Approval Voting (PAV). PAV also satisfies demanding fairness axioms. However, finding a winning set of items under PAV is NP-hard. In search of a tractable method with strong fairness guarantees, a bounded local search version of PAV was proposed by Aziz et al. It proceeds by starting with an arbitrary size-$k$ set $W$ and, at each step, checking if there is a pair of candidates $a\\in W$, $b\\not\\in W$ such that swapping $a$ and $b$ increases the total welfare by at least $\\varepsilon$; if yes, it performs the swap. Aziz et al.~show that setting $\\varepsilon=\\frac{n}{k^2}$ ensures both the desired fairness guarantees and polynomial running time. However, they leave it open whether the algorithm converges in polynomial time if $\\varepsilon$ is very small (in particular, if we do not stop until there are no welfare-improving swaps). We resolve this open question, by showing that if $\\varepsilon$ can be arbitrarily small, the running time of this algorithm may be super-polynomial. Specifically, we prove a lower bound of~$\\Omega(k^{\\log k})$ if improvements are chosen lexicographically. To complement our lower bound, we provide an empirical comparison of two variants of local search -- better-response and best-response -- on several real-life data sets and a variety of synthetic data sets. Our experiments indicate that, empirically, better response exhibits faster running time than best response.","sentences":["Selecting $k$ out of $m$ items based on the preferences of $n$ heterogeneous agents is a widely studied problem in algorithmic game theory.","If agents have approval preferences over individual items and harmonic utility functions over bundles -- an agent receives $\\sum_{j=1}^t\\frac{1}{j}$ utility if $t$ of her approved items are selected -- then welfare optimisation is captured by a voting rule known as Proportional Approval Voting (PAV).","PAV also satisfies demanding fairness axioms.","However, finding a winning set of items under PAV is NP-hard.","In search of a tractable method with strong fairness guarantees, a bounded local search version of PAV was proposed by Aziz et al.","It proceeds by starting with an arbitrary size-$k$ set $W$ and, at each step, checking if there is a pair of candidates $a\\in W$, $b\\not\\in W$ such that swapping $a$ and $b$ increases the total welfare by at least $\\varepsilon$; if yes, it performs the swap.","Aziz et al.~show that setting $\\varepsilon=\\frac{n}{k^2}$ ensures both the desired fairness guarantees and polynomial running time.","However, they leave it open whether the algorithm converges in polynomial time if $\\varepsilon$ is very small (in particular, if we do not stop until there are no welfare-improving swaps).","We resolve this open question, by showing that if $\\varepsilon$ can be arbitrarily small, the running time of this algorithm may be super-polynomial.","Specifically, we prove a lower bound of~$\\Omega(k^{\\log k})$ if improvements are chosen lexicographically.","To complement our lower bound, we provide an empirical comparison of two variants of local search -- better-response and best-response -- on several real-life data sets and a variety of synthetic data sets.","Our experiments indicate that, empirically, better response exhibits faster running time than best response."],"url":"http://arxiv.org/abs/2408.02300v1"}
{"created":"2024-08-05 08:12:25","title":"Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning","abstract":"Conventional uncertainty-aware temporal difference (TD) learning methods often rely on simplistic assumptions, typically including a zero-mean Gaussian distribution for TD errors. Such oversimplification can lead to inaccurate error representations and compromised uncertainty estimation. In this paper, we introduce a novel framework for generalized Gaussian error modeling in deep reinforcement learning, applicable to both discrete and continuous control settings. Our framework enhances the flexibility of error distribution modeling by incorporating higher-order moments, particularly kurtosis, thereby improving the estimation and mitigation of data-dependent noise, i.e., aleatoric uncertainty. We examine the influence of the shape parameter of the generalized Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form expression that demonstrates an inverse relationship between uncertainty and the shape parameter. Additionally, we propose a theoretically grounded weighting scheme to fully leverage the GGD. To address epistemic uncertainty, we enhance the batch inverse variance weighting by incorporating bias reduction and kurtosis considerations, resulting in improved robustness. Extensive experimental evaluations using policy gradient algorithms demonstrate the consistent efficacy of our method, showcasing significant performance improvements.","sentences":["Conventional uncertainty-aware temporal difference (TD) learning methods often rely on simplistic assumptions, typically including a zero-mean Gaussian distribution for TD errors.","Such oversimplification can lead to inaccurate error representations and compromised uncertainty estimation.","In this paper, we introduce a novel framework for generalized Gaussian error modeling in deep reinforcement learning, applicable to both discrete and continuous control settings.","Our framework enhances the flexibility of error distribution modeling by incorporating higher-order moments, particularly kurtosis, thereby improving the estimation and mitigation of data-dependent noise, i.e., aleatoric uncertainty.","We examine the influence of the shape parameter of the generalized Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form expression that demonstrates an inverse relationship between uncertainty and the shape parameter.","Additionally, we propose a theoretically grounded weighting scheme to fully leverage the GGD.","To address epistemic uncertainty, we enhance the batch inverse variance weighting by incorporating bias reduction and kurtosis considerations, resulting in improved robustness.","Extensive experimental evaluations using policy gradient algorithms demonstrate the consistent efficacy of our method, showcasing significant performance improvements."],"url":"http://arxiv.org/abs/2408.02295v1"}
{"created":"2024-08-05 08:00:30","title":"SelfGeo: Self-supervised and Geodesic-consistent Estimation of Keypoints on Deformable Shapes","abstract":"Unsupervised 3D keypoints estimation from Point Cloud Data (PCD) is a complex task, even more challenging when an object shape is deforming. As keypoints should be semantically and geometrically consistent across all the 3D frames - each keypoint should be anchored to a specific part of the deforming shape irrespective of intrinsic and extrinsic motion. This paper presents, \"SelfGeo\", a self-supervised method that computes persistent 3D keypoints of non-rigid objects from arbitrary PCDs without the need of human annotations. The gist of SelfGeo is to estimate keypoints between frames that respect invariant properties of deforming bodies. Our main contribution is to enforce that keypoints deform along with the shape while keeping constant geodesic distances among them. This principle is then propagated to the design of a set of losses which minimization let emerge repeatable keypoints in specific semantic locations of the non-rigid shape. We show experimentally that the use of geodesic has a clear advantage in challenging dynamic scenes and with different classes of deforming shapes (humans and animals). Code and data are available at: https://github.com/IIT-PAVIS/SelfGeo","sentences":["Unsupervised 3D keypoints estimation from Point Cloud Data (PCD) is a complex task, even more challenging when an object shape is deforming.","As keypoints should be semantically and geometrically consistent across all the 3D frames - each keypoint should be anchored to a specific part of the deforming shape irrespective of intrinsic and extrinsic motion.","This paper presents, \"SelfGeo\", a self-supervised method that computes persistent 3D keypoints of non-rigid objects from arbitrary PCDs without the need of human annotations.","The gist of SelfGeo is to estimate keypoints between frames that respect invariant properties of deforming bodies.","Our main contribution is to enforce that keypoints deform along with the shape while keeping constant geodesic distances among them.","This principle is then propagated to the design of a set of losses which minimization let emerge repeatable keypoints in specific semantic locations of the non-rigid shape.","We show experimentally that the use of geodesic has a clear advantage in challenging dynamic scenes and with different classes of deforming shapes (humans and animals).","Code and data are available at: https://github.com/IIT-PAVIS/SelfGeo"],"url":"http://arxiv.org/abs/2408.02291v1"}
{"created":"2024-08-05 07:30:18","title":"Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost","abstract":"Automated Machine Learning (AutoML) significantly simplifies the deployment of machine learning models by automating tasks from data preprocessing to model selection to ensembling. AutoML systems for tabular data often employ post hoc ensembling, where multiple models are combined to improve predictive accuracy. This typically results in longer inference times, a major limitation in practical deployments. Addressing this, we introduce a hardware-aware ensemble selection approach that integrates inference time into post hoc ensembling. By leveraging an existing framework for ensemble selection with quality diversity optimization, our method evaluates ensemble candidates for their predictive accuracy and hardware efficiency. This dual focus allows for a balanced consideration of accuracy and operational efficiency. Thus, our approach enables practitioners to choose from a Pareto front of accurate and efficient ensembles. Our evaluation using 83 classification datasets shows that our approach sustains competitive accuracy and can significantly improve ensembles' operational efficiency. The results of this study provide a foundation for extending these principles to additional hardware constraints, setting the stage for the development of more resource-efficient AutoML systems.","sentences":["Automated Machine Learning (AutoML) significantly simplifies the deployment of machine learning models by automating tasks from data preprocessing to model selection to ensembling.","AutoML systems for tabular data often employ post hoc ensembling, where multiple models are combined to improve predictive accuracy.","This typically results in longer inference times, a major limitation in practical deployments.","Addressing this, we introduce a hardware-aware ensemble selection approach that integrates inference time into post hoc ensembling.","By leveraging an existing framework for ensemble selection with quality diversity optimization, our method evaluates ensemble candidates for their predictive accuracy and hardware efficiency.","This dual focus allows for a balanced consideration of accuracy and operational efficiency.","Thus, our approach enables practitioners to choose from a Pareto front of accurate and efficient ensembles.","Our evaluation using 83 classification datasets shows that our approach sustains competitive accuracy and can significantly improve ensembles' operational efficiency.","The results of this study provide a foundation for extending these principles to additional hardware constraints, setting the stage for the development of more resource-efficient AutoML systems."],"url":"http://arxiv.org/abs/2408.02280v1"}
{"created":"2024-08-05 07:26:47","title":"DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting","abstract":"Long-term time series forecasting (LTSF) has been widely applied in finance, traffic prediction, and other domains. Recently, patch-based transformers have emerged as a promising approach, segmenting data into sub-level patches that serve as input tokens. However, existing methods mostly rely on predetermined patch lengths, necessitating expert knowledge and posing challenges in capturing diverse characteristics across various scales. Moreover, time series data exhibit diverse variations and fluctuations across different temporal scales, which traditional approaches struggle to model effectively. In this paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm to capture diverse receptive fields and sparse patterns of time series data. In order to build hierarchical receptive fields, we develop a multi-scale Transformer model, coupled with multi-scale sequence extraction, capable of capturing multi-resolution features. Additionally, we introduce a group-aware rotary position encoding technique to enhance intra- and inter-group position awareness among representations across different temporal scales. Our proposed model, named DRFormer, is evaluated on various real-world datasets, and experimental results demonstrate its superiority compared to existing methods. Our code is available at: https://github.com/ruixindingECNU/DRFormer.","sentences":["Long-term time series forecasting (LTSF) has been widely applied in finance, traffic prediction, and other domains.","Recently, patch-based transformers have emerged as a promising approach, segmenting data into sub-level patches that serve as input tokens.","However, existing methods mostly rely on predetermined patch lengths, necessitating expert knowledge and posing challenges in capturing diverse characteristics across various scales.","Moreover, time series data exhibit diverse variations and fluctuations across different temporal scales, which traditional approaches struggle to model effectively.","In this paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm to capture diverse receptive fields and sparse patterns of time series data.","In order to build hierarchical receptive fields, we develop a multi-scale Transformer model, coupled with multi-scale sequence extraction, capable of capturing multi-resolution features.","Additionally, we introduce a group-aware rotary position encoding technique to enhance intra- and inter-group position awareness among representations across different temporal scales.","Our proposed model, named DRFormer, is evaluated on various real-world datasets, and experimental results demonstrate its superiority compared to existing methods.","Our code is available at: https://github.com/ruixindingECNU/DRFormer."],"url":"http://arxiv.org/abs/2408.02279v1"}
{"created":"2024-08-05 07:00:10","title":"COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark","abstract":"Procedural video understanding is gaining attention in the vision and language community. Deep learning-based video analysis requires extensive data. Consequently, existing works often use web videos as training resources, making it challenging to query instructional contents from raw video observations. To address this issue, we propose a new dataset, COM Kitchens. The dataset consists of unedited overhead-view videos captured by smartphones, in which participants performed food preparation based on given recipes. Fixed-viewpoint video datasets often lack environmental diversity due to high camera setup costs. We used modern wide-angle smartphone lenses to cover cooking counters from sink to cooktop in an overhead view, capturing activity without in-person assistance. With this setup, we collected a diverse dataset by distributing smartphones to participants. With this dataset, we propose the novel video-to-text retrieval task Online Recipe Retrieval (OnRR) and new video captioning domain Dense Video Captioning on unedited Overhead-View videos (DVC-OV). Our experiments verified the capabilities and limitations of current web-video-based SOTA methods in handling these tasks.","sentences":["Procedural video understanding is gaining attention in the vision and language community.","Deep learning-based video analysis requires extensive data.","Consequently, existing works often use web videos as training resources, making it challenging to query instructional contents from raw video observations.","To address this issue, we propose a new dataset, COM Kitchens.","The dataset consists of unedited overhead-view videos captured by smartphones, in which participants performed food preparation based on given recipes.","Fixed-viewpoint video datasets often lack environmental diversity due to high camera setup costs.","We used modern wide-angle smartphone lenses to cover cooking counters from sink to cooktop in an overhead view, capturing activity without in-person assistance.","With this setup, we collected a diverse dataset by distributing smartphones to participants.","With this dataset, we propose the novel video-to-text retrieval task Online Recipe Retrieval (OnRR) and new video captioning domain Dense Video Captioning on unedited Overhead-View videos (DVC-OV).","Our experiments verified the capabilities and limitations of current web-video-based SOTA methods in handling these tasks."],"url":"http://arxiv.org/abs/2408.02272v1"}
{"created":"2024-08-05 06:54:36","title":"CHORDination: Evaluating Visual Design Choices in Chord Diagrams for Network Data","abstract":"Chord diagrams are widely used for visualizing data connectivity and flow between nodes in a network. They are effective for representing complex structures through an intuitive and visually appealing circular layout. While previous work has focused on improving aesthetics and interactivity, the influence of fundamental design elements on user perception and information retrieval remains under-explored. In this study, we explored the three primary components of chord diagram anatomy, namely the nodes, circular outline, and arc connections, in three sequential experiment phases. In phase one, we conducted a controlled experiment (N=90) to find the perceptually and information optimized node widths (narrow, medium, wide) and quantities (low, medium, high). This optimal set of node width and quantity sets the foundation for subsequent evaluations and were kept fixed for consistency. In phase two of the study, we conducted an expert design review for identifying the optimal radial tick marks and color gradients. Then in phase three, we evaluated the perceptual and information retrieval performance of the design choices in a controlled experiment (N=24) by comparing four chord diagram designs (baseline, radial tick marks, arc color gradients, both tick marks and color gradients). Results indicated that node width and quantity significantly affected users' information retrieval performance and subjective ratings, whereas the presence of tick marks predominantly influenced subjective experiences. Based on these findings, we discuss the design implications of these visual elements and offer guidance and recommendations for optimizing chord diagram designs in network visualization tasks.","sentences":["Chord diagrams are widely used for visualizing data connectivity and flow between nodes in a network.","They are effective for representing complex structures through an intuitive and visually appealing circular layout.","While previous work has focused on improving aesthetics and interactivity, the influence of fundamental design elements on user perception and information retrieval remains under-explored.","In this study, we explored the three primary components of chord diagram anatomy, namely the nodes, circular outline, and arc connections, in three sequential experiment phases.","In phase one, we conducted a controlled experiment (N=90) to find the perceptually and information optimized node widths (narrow, medium, wide) and quantities (low, medium, high).","This optimal set of node width and quantity sets the foundation for subsequent evaluations and were kept fixed for consistency.","In phase two of the study, we conducted an expert design review for identifying the optimal radial tick marks and color gradients.","Then in phase three, we evaluated the perceptual and information retrieval performance of the design choices in a controlled experiment (N=24) by comparing four chord diagram designs (baseline, radial tick marks, arc color gradients, both tick marks and color gradients).","Results indicated that node width and quantity significantly affected users' information retrieval performance and subjective ratings, whereas the presence of tick marks predominantly influenced subjective experiences.","Based on these findings, we discuss the design implications of these visual elements and offer guidance and recommendations for optimizing chord diagram designs in network visualization tasks."],"url":"http://arxiv.org/abs/2408.02268v1"}
{"created":"2024-08-05 06:47:32","title":"One-Shot Collaborative Data Distillation","abstract":"Large machine-learning training datasets can be distilled into small collections of informative synthetic data samples. These synthetic sets support efficient model learning and reduce the communication cost of data sharing. Thus, high-fidelity distilled data can support the efficient deployment of machine learning applications in distributed network environments. A naive way to construct a synthetic set in a distributed environment is to allow each client to perform local data distillation and to merge local distillations at a central server. However, the quality of the resulting set is impaired by heterogeneity in the distributions of the local data held by clients. To overcome this challenge, we introduce the first collaborative data distillation technique, called CollabDM, which captures the global distribution of the data and requires only a single round of communication between client and server. Our method outperforms the state-of-the-art one-shot learning method on skewed data in distributed learning environments. We also show the promising practical benefits of our method when applied to attack detection in 5G networks.","sentences":["Large machine-learning training datasets can be distilled into small collections of informative synthetic data samples.","These synthetic sets support efficient model learning and reduce the communication cost of data sharing.","Thus, high-fidelity distilled data can support the efficient deployment of machine learning applications in distributed network environments.","A naive way to construct a synthetic set in a distributed environment is to allow each client to perform local data distillation and to merge local distillations at a central server.","However, the quality of the resulting set is impaired by heterogeneity in the distributions of the local data held by clients.","To overcome this challenge, we introduce the first collaborative data distillation technique, called CollabDM, which captures the global distribution of the data and requires only a single round of communication between client and server.","Our method outperforms the state-of-the-art one-shot learning method on skewed data in distributed learning environments.","We also show the promising practical benefits of our method when applied to attack detection in 5G networks."],"url":"http://arxiv.org/abs/2408.02266v1"}
{"created":"2024-08-05 06:37:10","title":"Towards Identifying Code Proficiency through the Analysis of Python Textbooks","abstract":"Python, one of the most prevalent programming languages today, is widely utilized in various domains, including web development, data science, machine learning, and DevOps. Recent scholarly efforts have proposed a methodology to assess Python competence levels, similar to how proficiency in natural languages is evaluated. This method involves assigning levels of competence to Python constructs, for instance, placing simple 'print' statements at the most basic level and abstract base classes at the most advanced. The aim is to gauge the level of proficiency a developer must have to understand a piece of source code. This is particularly crucial for software maintenance and evolution tasks, such as debugging or adding new features. For example, in a code review process, this method could determine the competence level required for reviewers. However, categorizing Python constructs by proficiency levels poses significant challenges. Prior attempts, which relied heavily on expert opinions and developer surveys, have led to considerable discrepancies. In response, this paper presents a new approach to identifying Python competency levels through the systematic analysis of introductory Python programming textbooks. By comparing the sequence in which Python constructs are introduced in these textbooks with the current state of the art, we have uncovered notable discrepancies in the order of introduction of Python constructs. Our study underscores a misalignment in the sequences, demonstrating that pinpointing proficiency levels is not trivial. Insights from the study serve as pivotal steps toward reinforcing the idea that textbooks serve as a valuable source for evaluating developers' proficiency, and particularly in terms of their ability to undertake maintenance and evolution tasks.","sentences":["Python, one of the most prevalent programming languages today, is widely utilized in various domains, including web development, data science, machine learning, and DevOps.","Recent scholarly efforts have proposed a methodology to assess Python competence levels, similar to how proficiency in natural languages is evaluated.","This method involves assigning levels of competence to Python constructs, for instance, placing simple 'print' statements at the most basic level and abstract base classes at the most advanced.","The aim is to gauge the level of proficiency a developer must have to understand a piece of source code.","This is particularly crucial for software maintenance and evolution tasks, such as debugging or adding new features.","For example, in a code review process, this method could determine the competence level required for reviewers.","However, categorizing Python constructs by proficiency levels poses significant challenges.","Prior attempts, which relied heavily on expert opinions and developer surveys, have led to considerable discrepancies.","In response, this paper presents a new approach to identifying Python competency levels through the systematic analysis of introductory Python programming textbooks.","By comparing the sequence in which Python constructs are introduced in these textbooks with the current state of the art, we have uncovered notable discrepancies in the order of introduction of Python constructs.","Our study underscores a misalignment in the sequences, demonstrating that pinpointing proficiency levels is not trivial.","Insights from the study serve as pivotal steps toward reinforcing the idea that textbooks serve as a valuable source for evaluating developers' proficiency, and particularly in terms of their ability to undertake maintenance and evolution tasks."],"url":"http://arxiv.org/abs/2408.02262v1"}
{"created":"2024-08-05 05:56:37","title":"Advancing Post-OCR Correction: A Comparative Study of Synthetic Data","abstract":"This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on model performance. Furthermore, we introduce a novel algorithm that leverages computer vision feature detection algorithms to calculate glyph similarity for constructing post-OCR synthetic data. Through experiments conducted across a variety of languages, including several low-resource ones, we demonstrate that models like ByT5 can significantly reduce Character Error Rates (CER) without the need for manually annotated data, and our proposed synthetic data generation method shows advantages over traditional methods, particularly in low-resource languages.","sentences":["This paper explores the application of synthetic data in the post-OCR domain on multiple fronts by conducting experiments to assess the impact of data volume, augmentation, and synthetic data generation methods on model performance.","Furthermore, we introduce a novel algorithm that leverages computer vision feature detection algorithms to calculate glyph similarity for constructing post-OCR synthetic data.","Through experiments conducted across a variety of languages, including several low-resource ones, we demonstrate that models like ByT5 can significantly reduce Character Error Rates (CER) without the need for manually annotated data, and our proposed synthetic data generation method shows advantages over traditional methods, particularly in low-resource languages."],"url":"http://arxiv.org/abs/2408.02253v1"}
{"created":"2024-08-05 05:48:45","title":"Hierarchical Clustering using Reversible Binary Cellular Automata for High-Dimensional Data","abstract":"This work proposes a hierarchical clustering algorithm for high-dimensional datasets using the cyclic space of reversible finite cellular automata. In cellular automaton (CA) based clustering, if two objects belong to the same cycle, they are closely related and considered as part of the same cluster. However, if a high-dimensional dataset is clustered using the cycles of one CA, closely related objects may belong to different cycles. This paper identifies the relationship between objects in two different cycles based on the median of all elements in each cycle so that they can be grouped in the next stage. Further, to minimize the number of intermediate clusters which in turn reduces the computational cost, a rule selection strategy is taken to find the best rules based on information propagation and cycle structure. After encoding the dataset using frequency-based encoding such that the consecutive data elements maintain a minimum hamming distance in encoded form, our proposed clustering algorithm iterates over three stages to finally cluster the data elements into the desired number of clusters given by user. This algorithm can be applied to various fields, including healthcare, sports, chemical research, agriculture, etc. When verified over standard benchmark datasets with various performance metrics, our algorithm is at par with the existing algorithms with quadratic time complexity.","sentences":["This work proposes a hierarchical clustering algorithm for high-dimensional datasets using the cyclic space of reversible finite cellular automata.","In cellular automaton (CA) based clustering, if two objects belong to the same cycle, they are closely related and considered as part of the same cluster.","However, if a high-dimensional dataset is clustered using the cycles of one CA, closely related objects may belong to different cycles.","This paper identifies the relationship between objects in two different cycles based on the median of all elements in each cycle so that they can be grouped in the next stage.","Further, to minimize the number of intermediate clusters which in turn reduces the computational cost, a rule selection strategy is taken to find the best rules based on information propagation and cycle structure.","After encoding the dataset using frequency-based encoding such that the consecutive data elements maintain a minimum hamming distance in encoded form, our proposed clustering algorithm iterates over three stages to finally cluster the data elements into the desired number of clusters given by user.","This algorithm can be applied to various fields, including healthcare, sports, chemical research, agriculture, etc.","When verified over standard benchmark datasets with various performance metrics, our algorithm is at par with the existing algorithms with quadratic time complexity."],"url":"http://arxiv.org/abs/2408.02250v1"}
{"created":"2024-08-05 05:38:48","title":"AMIDER: A Multidisciplinary Research Database and Its Application to Promote Open Science","abstract":"The AMIDER, Advanced Multidisciplinary Integrated-Database for Exploring new Research, is a newly developed research data catalog to demonstrate an advanced database application. AMIDER is characterized as a multidisciplinary database equipped with a user-friendly web application. Its catalog view displays diverse research data at once beyond any limitation of each individual discipline. Some useful functions, such as a selectable data download, data format conversion, and display of data visual information, are also implemented. Further advanced functions, such as visualization of dataset mutual relationship, are also implemented as a preliminary trial. These characteristics and functions are expected to enhance the accessibility to individual research data, even from non-expertized users, and be helpful for collaborations among diverse scientific fields beyond individual disciplines. Multidisciplinary data management is also one of AMIDER's uniqueness, where various metadata schemas can be mapped to a uniform metadata table, and standardized and self-describing data formats are adopted. AMIDER website (https://amider.rois.ac.jp/) had been launched in April 2024. As of July 2024, over 15,000 metadata in various research fields of polar science have been registered in the database, and approximately 500 visitors are viewing the website every day on average. Expansion of the database to further multidisciplinary scientific fields, not only polar science, is planned, and advanced attempts, such as applying Natural Language Processing (NLP) to metadata, have also been considered.","sentences":["The AMIDER, Advanced Multidisciplinary Integrated-Database for Exploring new Research, is a newly developed research data catalog to demonstrate an advanced database application.","AMIDER is characterized as a multidisciplinary database equipped with a user-friendly web application.","Its catalog view displays diverse research data at once beyond any limitation of each individual discipline.","Some useful functions, such as a selectable data download, data format conversion, and display of data visual information, are also implemented.","Further advanced functions, such as visualization of dataset mutual relationship, are also implemented as a preliminary trial.","These characteristics and functions are expected to enhance the accessibility to individual research data, even from non-expertized users, and be helpful for collaborations among diverse scientific fields beyond individual disciplines.","Multidisciplinary data management is also one of AMIDER's uniqueness, where various metadata schemas can be mapped to a uniform metadata table, and standardized and self-describing data formats are adopted.","AMIDER website (https://amider.rois.ac.jp/) had been launched in April 2024.","As of July 2024, over 15,000 metadata in various research fields of polar science have been registered in the database, and approximately 500 visitors are viewing the website every day on average.","Expansion of the database to further multidisciplinary scientific fields, not only polar science, is planned, and advanced attempts, such as applying Natural Language Processing (NLP) to metadata, have also been considered."],"url":"http://arxiv.org/abs/2408.02246v1"}
{"created":"2024-08-05 05:33:59","title":"Curriculum learning based pre-training using Multi-Modal Contrastive Masked Autoencoders","abstract":"In this paper, we propose a new pre-training method for image understanding tasks under Curriculum Learning (CL) paradigm which leverages RGB-D. The method utilizes Multi-Modal Contrastive Masked Autoencoder and Denoising techniques. Recent approaches either use masked autoencoding (e.g., MultiMAE) or contrastive learning(e.g., Pri3D, or combine them in a single contrastive masked autoencoder architecture such as CMAE and CAV-MAE. However, none of the single contrastive masked autoencoder is applicable to RGB-D datasets. To improve the performance and efficacy of such methods, we propose a new pre-training strategy based on CL. Specifically, in the first stage, we pre-train the model using contrastive learning to learn cross-modal representations. In the second stage, we initialize the modality-specific encoders using the weights from the first stage and then pre-train the model using masked autoencoding and denoising/noise prediction used in diffusion models. Masked autoencoding focuses on reconstructing the missing patches in the input modality using local spatial correlations, while denoising learns high frequency components of the input data. Our approach is scalable, robust and suitable for pre-training with limited RGB-D datasets. Extensive experiments on multiple datasets such as ScanNet, NYUv2 and SUN RGB-D show the efficacy and superior performance of our approach. Specifically, we show an improvement of +1.0% mIoU against Mask3D on ScanNet semantic segmentation. We further demonstrate the effectiveness of our approach in low-data regime by evaluating it for semantic segmentation task against the state-of-the-art methods.","sentences":["In this paper, we propose a new pre-training method for image understanding tasks under Curriculum Learning (CL) paradigm which leverages RGB-D. The method utilizes Multi-Modal Contrastive Masked Autoencoder and Denoising techniques.","Recent approaches either use masked autoencoding (e.g., MultiMAE) or contrastive learning(e.g., Pri3D, or combine them in a single contrastive masked autoencoder architecture such as CMAE and CAV-MAE.","However, none of the single contrastive masked autoencoder is applicable to RGB-D datasets.","To improve the performance and efficacy of such methods, we propose a new pre-training strategy based on CL.","Specifically, in the first stage, we pre-train the model using contrastive learning to learn cross-modal representations.","In the second stage, we initialize the modality-specific encoders using the weights from the first stage and then pre-train the model using masked autoencoding and denoising/noise prediction used in diffusion models.","Masked autoencoding focuses on reconstructing the missing patches in the input modality using local spatial correlations, while denoising learns high frequency components of the input data.","Our approach is scalable, robust and suitable for pre-training with limited RGB-D datasets.","Extensive experiments on multiple datasets such as ScanNet, NYUv2 and SUN RGB-D show the efficacy and superior performance of our approach.","Specifically, we show an improvement of +1.0% mIoU against Mask3D on ScanNet semantic segmentation.","We further demonstrate the effectiveness of our approach in low-data regime by evaluating it for semantic segmentation task against the state-of-the-art methods."],"url":"http://arxiv.org/abs/2408.02245v1"}
{"created":"2024-08-05 05:30:36","title":"Evaluating Vision-Language Models for Zero-Shot Detection, Classification, and Association of Motorcycles, Passengers, and Helmets","abstract":"Motorcycle accidents pose significant risks, particularly when riders and passengers do not wear helmets. This study evaluates the efficacy of an advanced vision-language foundation model, OWLv2, in detecting and classifying various helmet-wearing statuses of motorcycle occupants using video data. We extend the dataset provided by the CVPR AI City Challenge and employ a cascaded model approach for detection and classification tasks, integrating OWLv2 and CNN models. The results highlight the potential of zero-shot learning to address challenges arising from incomplete and biased training datasets, demonstrating the usage of such models in detecting motorcycles, helmet usage, and occupant positions under varied conditions. We have achieved an average precision of 0.5324 for helmet detection and provided precision-recall curves detailing the detection and classification performance. Despite limitations such as low-resolution data and poor visibility, our research shows promising advancements in automated vehicle safety and traffic safety enforcement systems.","sentences":["Motorcycle accidents pose significant risks, particularly when riders and passengers do not wear helmets.","This study evaluates the efficacy of an advanced vision-language foundation model, OWLv2, in detecting and classifying various helmet-wearing statuses of motorcycle occupants using video data.","We extend the dataset provided by the CVPR AI City Challenge and employ a cascaded model approach for detection and classification tasks, integrating OWLv2 and CNN models.","The results highlight the potential of zero-shot learning to address challenges arising from incomplete and biased training datasets, demonstrating the usage of such models in detecting motorcycles, helmet usage, and occupant positions under varied conditions.","We have achieved an average precision of 0.5324 for helmet detection and provided precision-recall curves detailing the detection and classification performance.","Despite limitations such as low-resolution data and poor visibility, our research shows promising advancements in automated vehicle safety and traffic safety enforcement systems."],"url":"http://arxiv.org/abs/2408.02244v1"}
{"created":"2024-08-05 05:27:52","title":"Self-Enhancing Video Data Management System for Compositional Events with Large Language Models [Technical Report]","abstract":"Complex video queries can be answered by decomposing them into modular subtasks. However, existing video data management systems assume the existence of predefined modules for each subtask. We introduce VOCAL-UDF, a novel self-enhancing system that supports compositional queries over videos without the need for predefined modules. VOCAL-UDF automatically identifies and constructs missing modules and encapsulates them as user-defined functions (UDFs), thus expanding its querying capabilities. To achieve this, we formulate a unified UDF model that leverages large language models (LLMs) to aid in new UDF generation. VOCAL-UDF handles a wide range of concepts by supporting both program-based UDFs (i.e., Python functions generated by LLMs) and distilled-model UDFs (lightweight vision models distilled from strong pretrained models). To resolve the inherent ambiguity in user intent, VOCAL-UDF generates multiple candidate UDFs and uses active learning to efficiently select the best one. With the self-enhancing capability, VOCAL-UDF significantly improves query performance across three video datasets.","sentences":["Complex video queries can be answered by decomposing them into modular subtasks.","However, existing video data management systems assume the existence of predefined modules for each subtask.","We introduce VOCAL-UDF, a novel self-enhancing system that supports compositional queries over videos without the need for predefined modules.","VOCAL-UDF automatically identifies and constructs missing modules and encapsulates them as user-defined functions (UDFs), thus expanding its querying capabilities.","To achieve this, we formulate a unified UDF model that leverages large language models (LLMs) to aid in new UDF generation.","VOCAL-UDF handles a wide range of concepts by supporting both program-based UDFs (i.e., Python functions generated by LLMs) and distilled-model UDFs (lightweight vision models distilled from strong pretrained models).","To resolve the inherent ambiguity in user intent, VOCAL-UDF generates multiple candidate UDFs and uses active learning to efficiently select the best one.","With the self-enhancing capability, VOCAL-UDF significantly improves query performance across three video datasets."],"url":"http://arxiv.org/abs/2408.02243v1"}
{"created":"2024-08-05 05:27:19","title":"Methods to improve run time of hydrologic models: opportunities and challenges in the machine learning era","abstract":"The application of Machine Learning (ML) to hydrologic modeling is fledgling. Its applicability to capture the dependencies on watersheds to forecast better within a short period is fascinating. One of the key reasons to adopt ML algorithms over physics-based models is its computational efficiency advantage and flexibility to work with various data sets. The diverse applications, particularly in emergency response and expanding over a large scale, demand the hydrological model in a short time and make researchers adopt data-driven modeling approaches unhesitatingly. In this work, in the era of ML and deep learning (DL), how it can help to improve the overall run time of physics-based model and potential constraints that should be addressed while modeling. This paper covers the opportunities and challenges of adopting ML for hydrological modeling and subsequently how it can help to improve the simulation time of physics-based models and future works that should be addressed.","sentences":["The application of Machine Learning (ML) to hydrologic modeling is fledgling.","Its applicability to capture the dependencies on watersheds to forecast better within a short period is fascinating.","One of the key reasons to adopt ML algorithms over physics-based models is its computational efficiency advantage and flexibility to work with various data sets.","The diverse applications, particularly in emergency response and expanding over a large scale, demand the hydrological model in a short time and make researchers adopt data-driven modeling approaches unhesitatingly.","In this work, in the era of ML and deep learning (DL), how it can help to improve the overall run time of physics-based model and potential constraints that should be addressed while modeling.","This paper covers the opportunities and challenges of adopting ML for hydrological modeling and subsequently how it can help to improve the simulation time of physics-based models and future works that should be addressed."],"url":"http://arxiv.org/abs/2408.02242v1"}
{"created":"2024-08-05 05:23:08","title":"CompositingVis: Exploring Interactions for Creating Composite Visualizations in Immersive Environments","abstract":"Composite visualization represents a widely embraced design that combines multiple visual representations to create an integrated view. However, the traditional approach of creating composite visualizations in immersive environments typically occurs asynchronously outside of the immersive space and is carried out by experienced experts. In this work, we aim to empower users to participate in the creation of composite visualization within immersive environments through embodied interactions. This could provide a flexible and fluid experience with immersive visualization and has the potential to facilitate understanding of the relationship between visualization views. We begin with developing a design space of embodied interactions to create various types of composite visualizations with the consideration of data relationships. Drawing inspiration from people's natural experience of manipulating physical objects, we design interactions \\zq{based on the combination of 3D manipulations} in immersive environments. Building upon the design space, we present a series of case studies showcasing the interaction to create different kinds of composite visualizations in virtual reality. Subsequently, we conduct a user study to evaluate the usability of the derived interaction techniques and user experience of creating composite visualizations through embodied interactions. We find that empowering users to participate in composite visualizations through embodied interactions enables them to flexibly leverage different visualization views for understanding and communicating the relationships between different views, which underscores the potential of several future application scenarios.","sentences":["Composite visualization represents a widely embraced design that combines multiple visual representations to create an integrated view.","However, the traditional approach of creating composite visualizations in immersive environments typically occurs asynchronously outside of the immersive space and is carried out by experienced experts.","In this work, we aim to empower users to participate in the creation of composite visualization within immersive environments through embodied interactions.","This could provide a flexible and fluid experience with immersive visualization and has the potential to facilitate understanding of the relationship between visualization views.","We begin with developing a design space of embodied interactions to create various types of composite visualizations with the consideration of data relationships.","Drawing inspiration from people's natural experience of manipulating physical objects, we design interactions \\zq{based on the combination of 3D manipulations} in immersive environments.","Building upon the design space, we present a series of case studies showcasing the interaction to create different kinds of composite visualizations in virtual reality.","Subsequently, we conduct a user study to evaluate the usability of the derived interaction techniques and user experience of creating composite visualizations through embodied interactions.","We find that empowering users to participate in composite visualizations through embodied interactions enables them to flexibly leverage different visualization views for understanding and communicating the relationships between different views, which underscores the potential of several future application scenarios."],"url":"http://arxiv.org/abs/2408.02240v1"}
{"created":"2024-08-05 05:15:17","title":"BOTS-LM: Training Large Language Models for Setswana","abstract":"In this work we present BOTS-LM, a series of bilingual language models proficient in both Setswana and English. Leveraging recent advancements in data availability and efficient fine-tuning, BOTS-LM achieves performance similar to models significantly larger than itself while maintaining computational efficiency. Our initial release features an 8 billion parameter generative large language model, with upcoming 0.5 billion and 1 billion parameter large language models and a 278 million parameter encoder-only model soon to be released. We find the 8 billion parameter model significantly outperforms Llama-3-70B and Aya 23 on English-Setswana translation tasks, approaching the performance of dedicated machine translation models, while approaching 70B parameter performance on Setswana reasoning as measured by a machine translated subset of the MMLU benchmark. To accompany the BOTS-LM series of language models, we release the largest Setswana web dataset, SetsText, totalling over 267 million tokens. In addition, we release the largest machine translated Setswana dataset, the first and largest synthetic Setswana dataset, training and evaluation code, training logs, and MMLU-tsn, a machine translated subset of MMLU.","sentences":["In this work we present BOTS-LM, a series of bilingual language models proficient in both Setswana and English.","Leveraging recent advancements in data availability and efficient fine-tuning, BOTS-LM achieves performance similar to models significantly larger than itself while maintaining computational efficiency.","Our initial release features an 8 billion parameter generative large language model, with upcoming 0.5 billion and 1 billion parameter large language models and a 278 million parameter encoder-only model soon to be released.","We find the 8 billion parameter model significantly outperforms Llama-3-70B and Aya 23 on English-Setswana translation tasks, approaching the performance of dedicated machine translation models, while approaching 70B parameter performance on Setswana reasoning as measured by a machine translated subset of the MMLU benchmark.","To accompany the BOTS-LM series of language models, we release the largest Setswana web dataset, SetsText, totalling over 267 million tokens.","In addition, we release the largest machine translated Setswana dataset, the first and largest synthetic Setswana dataset, training and evaluation code, training logs, and MMLU-tsn, a machine translated subset of MMLU."],"url":"http://arxiv.org/abs/2408.02239v1"}
{"created":"2024-08-05 04:53:17","title":"A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction","abstract":"Legal charge prediction, an essential task in legal AI, seeks to assign accurate charge labels to case descriptions, attracting significant recent interest. Existing methods primarily employ diverse neural network structures for modeling case descriptions directly, failing to effectively leverage multi-source external knowledge. We propose a prompt learning framework-based method that simultaneously leverages multi-source heterogeneous external knowledge from a legal knowledge base, a conversational LLM, and related legal articles. Specifically, we match knowledge snippets in case descriptions via the legal knowledge base and encapsulate them into the input through a hard prompt template. Additionally, we retrieve legal articles related to a given case description through contrastive learning, and then obtain factual elements within the case description through a conversational LLM. We fuse the embedding vectors of soft prompt tokens with the encoding vector of factual elements to achieve knowledge-enhanced model forward inference. Experimental results show that our method achieved state-of-the-art results on CAIL-2018, the largest legal charge prediction dataset, and our method has lower data dependency. Case studies also demonstrate our method's strong interpretability.","sentences":["Legal charge prediction, an essential task in legal AI, seeks to assign accurate charge labels to case descriptions, attracting significant recent interest.","Existing methods primarily employ diverse neural network structures for modeling case descriptions directly, failing to effectively leverage multi-source external knowledge.","We propose a prompt learning framework-based method that simultaneously leverages multi-source heterogeneous external knowledge from a legal knowledge base, a conversational LLM, and related legal articles.","Specifically, we match knowledge snippets in case descriptions via the legal knowledge base and encapsulate them into the input through a hard prompt template.","Additionally, we retrieve legal articles related to a given case description through contrastive learning, and then obtain factual elements within the case description through a conversational LLM.","We fuse the embedding vectors of soft prompt tokens with the encoding vector of factual elements to achieve knowledge-enhanced model forward inference.","Experimental results show that our method achieved state-of-the-art results on CAIL-2018, the largest legal charge prediction dataset, and our method has lower data dependency.","Case studies also demonstrate our method's strong interpretability."],"url":"http://arxiv.org/abs/2408.02233v1"}
{"created":"2024-08-05 04:10:52","title":"ProCreate, Dont Reproduce! Propulsive Energy Diffusion for Creative Generation","abstract":"In this paper, we propose ProCreate, a simple and easy-to-implement method to improve sample diversity and creativity of diffusion-based image generative models and to prevent training data reproduction. ProCreate operates on a set of reference images and actively propels the generated image embedding away from the reference embeddings during the generation process. We propose FSCG-8 (Few-Shot Creative Generation 8), a few-shot creative generation dataset on eight different categories -- encompassing different concepts, styles, and settings -- in which ProCreate achieves the highest sample diversity and fidelity. Furthermore, we show that ProCreate is effective at preventing replicating training data in a large-scale evaluation using training text prompts. Code and FSCG-8 are available at https://github.com/Agentic-Learning-AI-Lab/procreate-diffusion-public. The project page is available at https://procreate-diffusion.github.io.","sentences":["In this paper, we propose ProCreate, a simple and easy-to-implement method to improve sample diversity and creativity of diffusion-based image generative models and to prevent training data reproduction.","ProCreate operates on a set of reference images and actively propels the generated image embedding away from the reference embeddings during the generation process.","We propose FSCG-8 (Few-Shot Creative Generation 8), a few-shot creative generation dataset on eight different categories -- encompassing different concepts, styles, and settings -- in which ProCreate achieves the highest sample diversity and fidelity.","Furthermore, we show that ProCreate is effective at preventing replicating training data in a large-scale evaluation using training text prompts.","Code and FSCG-8 are available at https://github.com/Agentic-Learning-AI-Lab/procreate-diffusion-public.","The project page is available at https://procreate-diffusion.github.io."],"url":"http://arxiv.org/abs/2408.02226v1"}
{"created":"2024-08-05 03:54:52","title":"Large Language Model Aided QoS Prediction for Service Recommendation","abstract":"Large language models (LLMs) have seen rapid improvement in the recent years, and are used in a wider range of applications. After being trained on large text corpus, LLMs obtain the capability of extracting rich features from textual data. Such capability is potentially useful for the web service recommendation task, where the web users and services have intrinsic attributes that can be described using natural language sentences and are useful for recommendation. In this paper, we explore the possibility and practicality of using LLMs for web service recommendation. We propose the large language model aided QoS prediction (llmQoS) model, which use LLMs to extract useful information from attributes of web users and services via descriptive sentences. This information is then used in combination with the QoS values of historical interactions of users and services, to predict QoS values for any given user-service pair. Our proposed model is shown to overcome the data sparsity issue for QoS prediction. We show that on the WSDream dataset, llmQoS outperforms comparable baseline models consistently.","sentences":["Large language models (LLMs) have seen rapid improvement in the recent years, and are used in a wider range of applications.","After being trained on large text corpus, LLMs obtain the capability of extracting rich features from textual data.","Such capability is potentially useful for the web service recommendation task, where the web users and services have intrinsic attributes that can be described using natural language sentences and are useful for recommendation.","In this paper, we explore the possibility and practicality of using LLMs for web service recommendation.","We propose the large language model aided QoS prediction (llmQoS) model, which use LLMs to extract useful information from attributes of web users and services via descriptive sentences.","This information is then used in combination with the QoS values of historical interactions of users and services, to predict QoS values for any given user-service pair.","Our proposed model is shown to overcome the data sparsity issue for QoS prediction.","We show that on the WSDream dataset, llmQoS outperforms comparable baseline models consistently."],"url":"http://arxiv.org/abs/2408.02223v1"}
{"created":"2024-08-05 03:18:58","title":"Source-Free Domain-Invariant Performance Prediction","abstract":"Accurately estimating model performance poses a significant challenge, particularly in scenarios where the source and target domains follow different data distributions. Most existing performance prediction methods heavily rely on the source data in their estimation process, limiting their applicability in a more realistic setting where only the trained model is accessible. The few methods that do not require source data exhibit considerably inferior performance. In this work, we propose a source-free approach centred on uncertainty-based estimation, using a generative model for calibration in the absence of source data. We establish connections between our approach for unsupervised calibration and temperature scaling. We then employ a gradient-based strategy to evaluate the correctness of the calibrated predictions. Our experiments on benchmark object recognition datasets reveal that existing source-based methods fall short with limited source sample availability. Furthermore, our approach significantly outperforms the current state-of-the-art source-free and source-based methods, affirming its effectiveness in domain-invariant performance estimation.","sentences":["Accurately estimating model performance poses a significant challenge, particularly in scenarios where the source and target domains follow different data distributions.","Most existing performance prediction methods heavily rely on the source data in their estimation process, limiting their applicability in a more realistic setting where only the trained model is accessible.","The few methods that do not require source data exhibit considerably inferior performance.","In this work, we propose a source-free approach centred on uncertainty-based estimation, using a generative model for calibration in the absence of source data.","We establish connections between our approach for unsupervised calibration and temperature scaling.","We then employ a gradient-based strategy to evaluate the correctness of the calibrated predictions.","Our experiments on benchmark object recognition datasets reveal that existing source-based methods fall short with limited source sample availability.","Furthermore, our approach significantly outperforms the current state-of-the-art source-free and source-based methods, affirming its effectiveness in domain-invariant performance estimation."],"url":"http://arxiv.org/abs/2408.02209v1"}
{"created":"2024-08-05 03:15:21","title":"MARCO: A Memory-Augmented Reinforcement Framework for Combinatorial Optimization","abstract":"Neural Combinatorial Optimization (NCO) is an emerging domain where deep learning techniques are employed to address combinatorial optimization problems as a standalone solver. Despite their potential, existing NCO methods often suffer from inefficient search space exploration, frequently leading to local optima entrapment or redundant exploration of previously visited states. This paper introduces a versatile framework, referred to as Memory-Augmented Reinforcement for Combinatorial Optimization (MARCO), that can be used to enhance both constructive and improvement methods in NCO through an innovative memory module. MARCO stores data collected throughout the optimization trajectory and retrieves contextually relevant information at each state. This way, the search is guided by two competing criteria: making the best decision in terms of the quality of the solution and avoiding revisiting already explored solutions. This approach promotes a more efficient use of the available optimization budget. Moreover, thanks to the parallel nature of NCO models, several search threads can run simultaneously, all sharing the same memory module, enabling an efficient collaborative exploration. Empirical evaluations, carried out on the maximum cut, maximum independent set and travelling salesman problems, reveal that the memory module effectively increases the exploration, enabling the model to discover diverse, higher-quality solutions. MARCO achieves good performance in a low computational cost, establishing a promising new direction in the field of NCO.","sentences":["Neural Combinatorial Optimization (NCO) is an emerging domain where deep learning techniques are employed to address combinatorial optimization problems as a standalone solver.","Despite their potential, existing NCO methods often suffer from inefficient search space exploration, frequently leading to local optima entrapment or redundant exploration of previously visited states.","This paper introduces a versatile framework, referred to as Memory-Augmented Reinforcement for Combinatorial Optimization (MARCO), that can be used to enhance both constructive and improvement methods in NCO through an innovative memory module.","MARCO stores data collected throughout the optimization trajectory and retrieves contextually relevant information at each state.","This way, the search is guided by two competing criteria: making the best decision in terms of the quality of the solution and avoiding revisiting already explored solutions.","This approach promotes a more efficient use of the available optimization budget.","Moreover, thanks to the parallel nature of NCO models, several search threads can run simultaneously, all sharing the same memory module, enabling an efficient collaborative exploration.","Empirical evaluations, carried out on the maximum cut, maximum independent set and travelling salesman problems, reveal that the memory module effectively increases the exploration, enabling the model to discover diverse, higher-quality solutions.","MARCO achieves good performance in a low computational cost, establishing a promising new direction in the field of NCO."],"url":"http://arxiv.org/abs/2408.02207v1"}
{"created":"2024-08-05 03:12:30","title":"Large-scale Deployment of Vision-based Tactile Sensors on Multi-fingered Grippers","abstract":"Vision-based Tactile Sensors (VBTSs) show significant promise in that they can leverage image measurements to provide high-spatial-resolution human-like performance. However, current VBTS designs, typically confined to the fingertips of robotic grippers, prove somewhat inadequate, as many grasping and manipulation tasks require multiple contact points with the object. With an end goal of enabling large-scale, multi-surface tactile sensing via VBTSs, our research (i) develops a synchronized image acquisition system with minimal latency,(ii) proposes a modularized VBTS design for easy integration into finger phalanges, and (iii) devises a zero-shot calibration approach to improve data efficiency in the simultaneous calibration of multiple VBTSs. In validating the system within a miniature 3-fingered robotic gripper equipped with 7 VBTSs we demonstrate improved tactile perception performance by covering the contact surfaces of both gripper fingers and palm. Additionally, we show that our VBTS design can be seamlessly integrated into various end-effector morphologies significantly reducing the data requirements for calibration.","sentences":["Vision-based Tactile Sensors (VBTSs) show significant promise in that they can leverage image measurements to provide high-spatial-resolution human-like performance.","However, current VBTS designs, typically confined to the fingertips of robotic grippers, prove somewhat inadequate, as many grasping and manipulation tasks require multiple contact points with the object.","With an end goal of enabling large-scale, multi-surface tactile sensing via VBTSs, our research (i) develops a synchronized image acquisition system with minimal latency,(ii) proposes a modularized VBTS design for easy integration into finger phalanges, and (iii) devises a zero-shot calibration approach to improve data efficiency in the simultaneous calibration of multiple VBTSs.","In validating the system within a miniature 3-fingered robotic gripper equipped with 7 VBTSs we demonstrate improved tactile perception performance by covering the contact surfaces of both gripper fingers and palm.","Additionally, we show that our VBTS design can be seamlessly integrated into various end-effector morphologies significantly reducing the data requirements for calibration."],"url":"http://arxiv.org/abs/2408.02206v1"}
{"created":"2024-08-05 03:05:02","title":"Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)","abstract":"The use of large language models (LLMs) is expanding rapidly, and open-source versions are becoming available, offering users safer and more adaptable options. These models enable users to protect data privacy by eliminating the need to provide data to third parties and can be customized for specific tasks. In this study, we compare the performance of various language models on the Sustainable Development Goal (SDG) mapping task, using the output of GPT-4o as the baseline. The selected open-source models for comparison include Mixtral, LLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more specialized version of GPT-4o, was included to extend the comparison. Given the multi-label nature of the SDG mapping task, we employed metrics such as F1 score, precision, and recall with micro-averaging to evaluate different aspects of the models' performance. These metrics are derived from the confusion matrix to ensure a comprehensive evaluation. We provide a clear observation and analysis of each model's performance by plotting curves based on F1 score, precision, and recall at different thresholds. According to the results of this experiment, LLaMA 2 and Gemma still have significant room for improvement. The other four models do not exhibit particularly large differences in performance. The outputs from all seven models are available on Zenodo: https://doi.org/10.5281/zenodo.12789375.","sentences":["The use of large language models (LLMs) is expanding rapidly, and open-source versions are becoming available, offering users safer and more adaptable options.","These models enable users to protect data privacy by eliminating the need to provide data to third parties and can be customized for specific tasks.","In this study, we compare the performance of various language models on the Sustainable Development Goal (SDG) mapping task, using the output of GPT-4o as the baseline.","The selected open-source models for comparison include Mixtral, LLaMA 2, LLaMA 3, Gemma, and Qwen2.","Additionally, GPT-4o-mini, a more specialized version of GPT-4o, was included to extend the comparison.","Given the multi-label nature of the SDG mapping task, we employed metrics such as F1 score, precision, and recall with micro-averaging to evaluate different aspects of the models' performance.","These metrics are derived from the confusion matrix to ensure a comprehensive evaluation.","We provide a clear observation and analysis of each model's performance by plotting curves based on F1 score, precision, and recall at different thresholds.","According to the results of this experiment, LLaMA 2 and Gemma still have significant room for improvement.","The other four models do not exhibit particularly large differences in performance.","The outputs from all seven models are available on Zenodo: https://doi.org/10.5281/zenodo.12789375."],"url":"http://arxiv.org/abs/2408.02201v1"}
{"created":"2024-08-05 02:50:58","title":"Synergistic Learning with Multi-Task DeepONet for Efficient PDE Problem Solving","abstract":"Multi-task learning (MTL) is an inductive transfer mechanism designed to leverage useful information from multiple tasks to improve generalization performance compared to single-task learning. It has been extensively explored in traditional machine learning to address issues such as data sparsity and overfitting in neural networks. In this work, we apply MTL to problems in science and engineering governed by partial differential equations (PDEs). However, implementing MTL in this context is complex, as it requires task-specific modifications to accommodate various scenarios representing different physical processes. To this end, we present a multi-task deep operator network (MT-DeepONet) to learn solutions across various functional forms of source terms in a PDE and multiple geometries in a single concurrent training session. We introduce modifications in the branch network of the vanilla DeepONet to account for various functional forms of a parameterized coefficient in a PDE. Additionally, we handle parameterized geometries by introducing a binary mask in the branch network and incorporating it into the loss term to improve convergence and generalization to new geometry tasks. Our approach is demonstrated on three benchmark problems: (1) learning different functional forms of the source term in the Fisher equation; (2) learning multiple geometries in a 2D Darcy Flow problem and showcasing better transfer learning capabilities to new geometries; and (3) learning 3D parameterized geometries for a heat transfer problem and demonstrate the ability to predict on new but similar geometries. Our MT-DeepONet framework offers a novel approach to solving PDE problems in engineering and science under a unified umbrella based on synergistic learning that reduces the overall training cost for neural operators.","sentences":["Multi-task learning (MTL) is an inductive transfer mechanism designed to leverage useful information from multiple tasks to improve generalization performance compared to single-task learning.","It has been extensively explored in traditional machine learning to address issues such as data sparsity and overfitting in neural networks.","In this work, we apply MTL to problems in science and engineering governed by partial differential equations (PDEs).","However, implementing MTL in this context is complex, as it requires task-specific modifications to accommodate various scenarios representing different physical processes.","To this end, we present a multi-task deep operator network (MT-DeepONet) to learn solutions across various functional forms of source terms in a PDE and multiple geometries in a single concurrent training session.","We introduce modifications in the branch network of the vanilla DeepONet to account for various functional forms of a parameterized coefficient in a PDE.","Additionally, we handle parameterized geometries by introducing a binary mask in the branch network and incorporating it into the loss term to improve convergence and generalization to new geometry tasks.","Our approach is demonstrated on three benchmark problems: (1) learning different functional forms of the source term in the Fisher equation; (2) learning multiple geometries in a 2D Darcy Flow problem and showcasing better transfer learning capabilities to new geometries; and (3) learning 3D parameterized geometries for a heat transfer problem and demonstrate the ability to predict on new but similar geometries.","Our MT-DeepONet framework offers a novel approach to solving PDE problems in engineering and science under a unified umbrella based on synergistic learning that reduces the overall training cost for neural operators."],"url":"http://arxiv.org/abs/2408.02198v1"}
{"created":"2024-08-05 02:38:48","title":"CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs","abstract":"Large language models (LLMs) have shown great potential in code-related tasks, yet open-source models lag behind their closed-source counterparts. To bridge this performance gap, existing methods generate vast amounts of synthetic data for fine-tuning, leading to inefficiencies in training. Motivated by the need for more effective and efficient training, we propose the Code Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces the Complexity and Diversity Aware Sampling (CDAS) method to select high-quality training data based on complexity and diversity, and the Dynamic Pack padding strategy to reduce computational resource usage by minimizing padding tokens during training. Experimental results demonstrate that CodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data, achieves an 8.6% performance increase on HumanEval, reduces training time by 78%, and decreases peak GPU memory usage by 27%. These findings underscore CodeACT's ability to enhance the performance and efficiency of open-source models. By optimizing both the data selection and training processes, CodeACT offers a comprehensive approach to improving the capabilities of open-source LLMs while significantly reducing computational requirements, addressing the dual challenges of data quality and training efficiency, and paving the way for more resource-efficient and performant models.","sentences":["Large language models (LLMs) have shown great potential in code-related tasks, yet open-source models lag behind their closed-source counterparts.","To bridge this performance gap, existing methods generate vast amounts of synthetic data for fine-tuning, leading to inefficiencies in training.","Motivated by the need for more effective and efficient training, we propose the Code Adaptive Compute-efficient Tuning (CodeACT) framework.","CodeACT introduces the Complexity and Diversity Aware Sampling (CDAS) method to select high-quality training data based on complexity and diversity, and the Dynamic Pack padding strategy to reduce computational resource usage by minimizing padding tokens during training.","Experimental results demonstrate that CodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data, achieves an 8.6% performance increase on HumanEval, reduces training time by 78%, and decreases peak GPU memory usage by 27%.","These findings underscore CodeACT's ability to enhance the performance and efficiency of open-source models.","By optimizing both the data selection and training processes, CodeACT offers a comprehensive approach to improving the capabilities of open-source LLMs while significantly reducing computational requirements, addressing the dual challenges of data quality and training efficiency, and paving the way for more resource-efficient and performant models."],"url":"http://arxiv.org/abs/2408.02193v1"}
{"created":"2024-08-05 01:50:09","title":"AssemAI: Interpretable Image-Based Anomaly Detection for Manufacturing Pipelines","abstract":"Anomaly detection in manufacturing pipelines remains a critical challenge, intensified by the complexity and variability of industrial environments. This paper introduces AssemAI, an interpretable image-based anomaly detection system tailored for smart manufacturing pipelines. Our primary contributions include the creation of a tailored image dataset and the development of a custom object detection model, YOLO-FF, designed explicitly for anomaly detection in manufacturing assembly environments. Utilizing the preprocessed image dataset derived from an industry-focused rocket assembly pipeline, we address the challenge of imbalanced image data and demonstrate the importance of image-based methods in anomaly detection. The proposed approach leverages domain knowledge in data preparation, model development and reasoning. We compare our method against several baselines, including simple CNN and custom Visual Transformer (ViT) models, showcasing the effectiveness of our custom data preparation and pretrained CNN integration. Additionally, we incorporate explainability techniques at both user and model levels, utilizing ontology for user-friendly explanations and SCORE-CAM for in-depth feature and model analysis. Finally, the model was also deployed in a real-time setting. Our results include ablation studies on the baselines, providing a comprehensive evaluation of the proposed system. This work highlights the broader impact of advanced image-based anomaly detection in enhancing the reliability and efficiency of smart manufacturing processes.","sentences":["Anomaly detection in manufacturing pipelines remains a critical challenge, intensified by the complexity and variability of industrial environments.","This paper introduces AssemAI, an interpretable image-based anomaly detection system tailored for smart manufacturing pipelines.","Our primary contributions include the creation of a tailored image dataset and the development of a custom object detection model, YOLO-FF, designed explicitly for anomaly detection in manufacturing assembly environments.","Utilizing the preprocessed image dataset derived from an industry-focused rocket assembly pipeline, we address the challenge of imbalanced image data and demonstrate the importance of image-based methods in anomaly detection.","The proposed approach leverages domain knowledge in data preparation, model development and reasoning.","We compare our method against several baselines, including simple CNN and custom Visual Transformer (ViT) models, showcasing the effectiveness of our custom data preparation and pretrained CNN integration.","Additionally, we incorporate explainability techniques at both user and model levels, utilizing ontology for user-friendly explanations and SCORE-CAM for in-depth feature and model analysis.","Finally, the model was also deployed in a real-time setting.","Our results include ablation studies on the baselines, providing a comprehensive evaluation of the proposed system.","This work highlights the broader impact of advanced image-based anomaly detection in enhancing the reliability and efficiency of smart manufacturing processes."],"url":"http://arxiv.org/abs/2408.02181v1"}
{"created":"2024-08-04 23:12:31","title":"Improvement and Empirical Testing of a Novel Autonomous Microplastics-Collecting Semisubmersible","abstract":"Since their invention, plastics have become ubiquitous in modern societies all around the world, and their impact on the environment has, in recent years, become nearly as well-known. Plastics produced by humans have reached nearly every corner of the world, and throughout their centuries-long lifetimes, plastics continually break down into smaller and smaller particles due to the physical stresses which they are subjected to. These stresses eventually, inevitably, break these plastics down into microplastics -pieces of plastic small enough to be consumed by organisms in bodies of water throughout the globe. These microplastics can very easily bioaccumulate, and have been found everywhere from the Great Lakes to the bloodstreams of humans. The effects of these plastics are poorly understood, however, they have been linked to infertility, halted growth, and a host of other maladies in aquatic organisms. Currently, removal of these plastics has been neglected, with no governmental action to remove them from marine environments, and this project aims to begin prototyping a solution to this issue. A significant percentage of microplastics are found at the surface of waterways, thus trawling in surface waters using an autonomously propelled net is proposed as a way to solve this seemingly intractable issue. By attaching motors and a guidance system to a manta trawl, a device currently used for collecting microorganisms, the process of collecting microplastics in open water can be automated, and thus the work of removing plastics from the environment on a large scale can begin.","sentences":["Since their invention, plastics have become ubiquitous in modern societies all around the world, and their impact on the environment has, in recent years, become nearly as well-known.","Plastics produced by humans have reached nearly every corner of the world, and throughout their centuries-long lifetimes, plastics continually break down into smaller and smaller particles due to the physical stresses which they are subjected to.","These stresses eventually, inevitably, break these plastics down into microplastics -pieces of plastic small enough to be consumed by organisms in bodies of water throughout the globe.","These microplastics can very easily bioaccumulate, and have been found everywhere from the Great Lakes to the bloodstreams of humans.","The effects of these plastics are poorly understood, however, they have been linked to infertility, halted growth, and a host of other maladies in aquatic organisms.","Currently, removal of these plastics has been neglected, with no governmental action to remove them from marine environments, and this project aims to begin prototyping a solution to this issue.","A significant percentage of microplastics are found at the surface of waterways, thus trawling in surface waters using an autonomously propelled net is proposed as a way to solve this seemingly intractable issue.","By attaching motors and a guidance system to a manta trawl, a device currently used for collecting microorganisms, the process of collecting microplastics in open water can be automated, and thus the work of removing plastics from the environment on a large scale can begin."],"url":"http://arxiv.org/abs/2408.02162v1"}
{"created":"2024-08-04 20:56:05","title":"Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey","abstract":"Large Language Models (LLMs) have gained widespread global adoption, showcasing advanced linguistic capabilities across multiple of languages. There is a growing interest in academia to use these models to simulate and study human behaviors. However, it is crucial to acknowledge that an LLM's proficiency in a specific language might not fully encapsulate the norms and values associated with its culture. Concerns have emerged regarding potential biases towards Anglo-centric cultures and values due to the predominance of Western and US-based training data. This study focuses on analyzing the cultural representations of emotions in LLMs, in the specific case of mixed-emotion situations. Our methodology is based on the studies of Miyamoto et al. (2010), which identified distinctive emotional indicators in Japanese and American human responses. We first administer their mixed emotion survey to five different LLMs and analyze their outputs. Second, we experiment with contextual variables to explore variations in responses considering both language and speaker origin. Thirdly, we expand our investigation to encompass additional East Asian and Western European origin languages to gauge their alignment with their respective cultures, anticipating a closer fit. We find that (1) models have limited alignment with the evidence in the literature; (2) written language has greater effect on LLMs' response than information on participants origin; and (3) LLMs responses were found more similar for East Asian languages than Western European languages.","sentences":["Large Language Models (LLMs) have gained widespread global adoption, showcasing advanced linguistic capabilities across multiple of languages.","There is a growing interest in academia to use these models to simulate and study human behaviors.","However, it is crucial to acknowledge that an LLM's proficiency in a specific language might not fully encapsulate the norms and values associated with its culture.","Concerns have emerged regarding potential biases towards Anglo-centric cultures and values due to the predominance of Western and US-based training data.","This study focuses on analyzing the cultural representations of emotions in LLMs, in the specific case of mixed-emotion situations.","Our methodology is based on the studies of Miyamoto et al.","(2010), which identified distinctive emotional indicators in Japanese and American human responses.","We first administer their mixed emotion survey to five different LLMs and analyze their outputs.","Second, we experiment with contextual variables to explore variations in responses considering both language and speaker origin.","Thirdly, we expand our investigation to encompass additional East Asian and Western European origin languages to gauge their alignment with their respective cultures, anticipating a closer fit.","We find that (1) models have limited alignment with the evidence in the literature; (2) written language has greater effect on LLMs' response than information on participants origin; and (3) LLMs responses were found more similar for East Asian languages than Western European languages."],"url":"http://arxiv.org/abs/2408.02143v1"}
{"created":"2024-08-04 20:38:45","title":"VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces","abstract":"In the domain of black-box model extraction, conventional methods reliant on soft labels or surrogate datasets struggle with scaling to high-dimensional input spaces and managing the complexity of an extensive array of interrelated classes. In this work, we present a novel approach that utilizes SHAP (SHapley Additive exPlanations) to enhance synthetic data generation. SHAP quantifies the individual contributions of each input feature towards the victim model's output, facilitating the optimization of an energy-based GAN towards a desirable output. This method significantly boosts performance, achieving a 16.45% increase in the accuracy of image classification models and extending to video classification models with an average improvement of 26.11% and a maximum of 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics 600, and Something-Something V2. We further demonstrate the effectiveness and practical utility of our method under various scenarios, including the availability of top-k prediction probabilities, top-k prediction labels, and top-1 labels.","sentences":["In the domain of black-box model extraction, conventional methods reliant on soft labels or surrogate datasets struggle with scaling to high-dimensional input spaces and managing the complexity of an extensive array of interrelated classes.","In this work, we present a novel approach that utilizes SHAP (SHapley Additive exPlanations) to enhance synthetic data generation.","SHAP quantifies the individual contributions of each input feature towards the victim model's output, facilitating the optimization of an energy-based GAN towards a desirable output.","This method significantly boosts performance, achieving a 16.45% increase in the accuracy of image classification models and extending to video classification models with an average improvement of 26.11% and a maximum of 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics 600, and Something-Something V2.","We further demonstrate the effectiveness and practical utility of our method under various scenarios, including the availability of top-k prediction probabilities, top-k prediction labels, and top-1 labels."],"url":"http://arxiv.org/abs/2408.02140v1"}
{"created":"2024-08-04 20:12:38","title":"A First Look at Chebyshev-Sobolev Series for Digital Ink","abstract":"Considering digital ink as plane curves provides a valuable framework for various applications, including signature verification, note-taking, and mathematical handwriting recognition. These plane curves can be obtained as parameterized pairs of approximating truncated series (x(s), y(s)) determined by sampled points. Earlier work has found that representing these truncated series (polynomials) in a Legendre or Legendre-Sobolev basis has a number of desirable properties. These include compact data representation, meaningful clustering of like symbols in the vector space of polynomial coefficients, linear separability of classes in this space, and highly efficient calculation of variation between curves. In this work, we take a first step at examining the use of Chebyshev-Sobolev series for symbol recognition. The early indication is that this representation may be superior to Legendre-Sobolev representation for some purposes.","sentences":["Considering digital ink as plane curves provides a valuable framework for various applications, including signature verification, note-taking, and mathematical handwriting recognition.","These plane curves can be obtained as parameterized pairs of approximating truncated series (x(s), y(s)) determined by sampled points.","Earlier work has found that representing these truncated series (polynomials) in a Legendre or Legendre-Sobolev basis has a number of desirable properties.","These include compact data representation, meaningful clustering of like symbols in the vector space of polynomial coefficients, linear separability of classes in this space, and highly efficient calculation of variation between curves.","In this work, we take a first step at examining the use of Chebyshev-Sobolev series for symbol recognition.","The early indication is that this representation may be superior to Legendre-Sobolev representation for some purposes."],"url":"http://arxiv.org/abs/2408.02135v1"}
{"created":"2024-08-04 20:02:07","title":"Model Hijacking Attack in Federated Learning","abstract":"Machine learning (ML), driven by prominent paradigms such as centralized and federated learning, has made significant progress in various critical applications ranging from autonomous driving to face recognition. However, its remarkable success has been accompanied by various attacks. Recently, the model hijacking attack has shown that ML models can be hijacked to execute tasks different from their original tasks, which increases both accountability and parasitic computational risks. Nevertheless, thus far, this attack has only focused on centralized learning. In this work, we broaden the scope of this attack to the federated learning domain, where multiple clients collaboratively train a global model without sharing their data. Specifically, we present HijackFL, the first-of-its-kind hijacking attack against the global model in federated learning. The adversary aims to force the global model to perform a different task (called hijacking task) from its original task without the server or benign client noticing. To accomplish this, unlike existing methods that use data poisoning to modify the target model's parameters, HijackFL searches for pixel-level perturbations based on their local model (without modifications) to align hijacking samples with the original ones in the feature space. When performing the hijacking task, the adversary applies these cloaks to the hijacking samples, compelling the global model to identify them as original samples and predict them accordingly. We conduct extensive experiments on four benchmark datasets and three popular models. Empirical results demonstrate that its attack performance outperforms baselines. We further investigate the factors that affect its performance and discuss possible defenses to mitigate its impact.","sentences":["Machine learning (ML), driven by prominent paradigms such as centralized and federated learning, has made significant progress in various critical applications ranging from autonomous driving to face recognition.","However, its remarkable success has been accompanied by various attacks.","Recently, the model hijacking attack has shown that ML models can be hijacked to execute tasks different from their original tasks, which increases both accountability and parasitic computational risks.","Nevertheless, thus far, this attack has only focused on centralized learning.","In this work, we broaden the scope of this attack to the federated learning domain, where multiple clients collaboratively train a global model without sharing their data.","Specifically, we present HijackFL, the first-of-its-kind hijacking attack against the global model in federated learning.","The adversary aims to force the global model to perform a different task (called hijacking task) from its original task without the server or benign client noticing.","To accomplish this, unlike existing methods that use data poisoning to modify the target model's parameters, HijackFL searches for pixel-level perturbations based on their local model (without modifications) to align hijacking samples with the original ones in the feature space.","When performing the hijacking task, the adversary applies these cloaks to the hijacking samples, compelling the global model to identify them as original samples and predict them accordingly.","We conduct extensive experiments on four benchmark datasets and three popular models.","Empirical results demonstrate that its attack performance outperforms baselines.","We further investigate the factors that affect its performance and discuss possible defenses to mitigate its impact."],"url":"http://arxiv.org/abs/2408.02131v1"}
{"created":"2024-08-04 19:54:12","title":"Table Transformers for Imputing Textual Attributes","abstract":"Missing data in tabular dataset is a common issue as the performance of downstream tasks usually depends on the completeness of the training dataset. Previous missing data imputation methods focus on numeric and categorical columns, but we propose a novel end-to-end approach called Table Transformers for Imputing Textual Attributes (TTITA) based on the transformer to impute unstructured textual columns using other columns in the table. We conduct extensive experiments on two Amazon Reviews datasets, and our approach shows competitive performance outperforming baseline models such as recurrent neural networks and Llama2. The performance improvement is more significant when the target sequence has a longer length. Additionally, we incorporated multi-task learning to simultaneously impute for heterogeneous columns, boosting the performance for text imputation. We also qualitatively compare with ChatGPT for realistic applications.","sentences":["Missing data in tabular dataset is a common issue as the performance of downstream tasks usually depends on the completeness of the training dataset.","Previous missing data imputation methods focus on numeric and categorical columns, but we propose a novel end-to-end approach called Table Transformers for Imputing Textual Attributes (TTITA) based on the transformer to impute unstructured textual columns using other columns in the table.","We conduct extensive experiments on two Amazon Reviews datasets, and our approach shows competitive performance outperforming baseline models such as recurrent neural networks and Llama2.","The performance improvement is more significant when the target sequence has a longer length.","Additionally, we incorporated multi-task learning to simultaneously impute for heterogeneous columns, boosting the performance for text imputation.","We also qualitatively compare with ChatGPT for realistic applications."],"url":"http://arxiv.org/abs/2408.02128v1"}
{"created":"2024-08-04 19:44:57","title":"Abstraction in Neural Networks","abstract":"We show how brain networks, modeled as Spiking Neural Networks, can be viewed at different levels of abstraction. Lower levels include complications such as failures of neurons and edges. Higher levels are more abstract, making simplifying assumptions to avoid these complications. We show precise relationships between executions of networks at different levels, which enables us to understand the behavior of lower-level networks in terms of the behavior of higher-level networks.   We express our results using two abstract networks, A1 and A2, one to express firing guarantees and the other to express non-firing guarantees, and one detailed network D. The abstract networks contain reliable neurons and edges, whereas the detailed network has neurons and edges that may fail, subject to some constraints. Here we consider just initial stopping failures. To define these networks, we begin with abstract network A1 and modify it systematically to obtain the other two networks. To obtain A2, we simply lower the firing thresholds of the neurons. To obtain D, we introduce failures of neurons and edges, and incorporate redundancy in the neurons and edges in order to compensate for the failures. We also define corresponding inputs for the networks, and corresponding executions of the networks.   We prove two main theorems, one relating corresponding executions of A1 and D and the other relating corresponding executions of A2 and D. Together, these give both firing and non-firing guarantees for the detailed network D. We also give a third theorem, relating the effects of D on an external reliable actuator neuron to the effects of the abstract networks on the same actuator neuron.","sentences":["We show how brain networks, modeled as Spiking Neural Networks, can be viewed at different levels of abstraction.","Lower levels include complications such as failures of neurons and edges.","Higher levels are more abstract, making simplifying assumptions to avoid these complications.","We show precise relationships between executions of networks at different levels, which enables us to understand the behavior of lower-level networks in terms of the behavior of higher-level networks.   ","We express our results using two abstract networks, A1 and A2, one to express firing guarantees and the other to express non-firing guarantees, and one detailed network D.","The abstract networks contain reliable neurons and edges, whereas the detailed network has neurons and edges that may fail, subject to some constraints.","Here we consider just initial stopping failures.","To define these networks, we begin with abstract network A1 and modify it systematically to obtain the other two networks.","To obtain A2, we simply lower the firing thresholds of the neurons.","To obtain D, we introduce failures of neurons and edges, and incorporate redundancy in the neurons and edges in order to compensate for the failures.","We also define corresponding inputs for the networks, and corresponding executions of the networks.   ","We prove two main theorems, one relating corresponding executions of A1 and D and the other relating corresponding executions of A2 and D. Together, these give both firing and non-firing guarantees for the detailed network D.","We also give a third theorem, relating the effects of D on an external reliable actuator neuron to the effects of the abstract networks on the same actuator neuron."],"url":"http://arxiv.org/abs/2408.02125v1"}
{"created":"2024-08-04 18:51:41","title":"An Abstraction-Preserving Block Matrix Implementation in Maple","abstract":"A Maple implementation of partitioned matrices is described. A recursive block data structure is used, with all operations preserving the block abstraction. These include constructor functions, ring operations such as addition and product, and inversion. The package is demonstrated by calculating the PLU factorization of a block matrix.","sentences":["A Maple implementation of partitioned matrices is described.","A recursive block data structure is used, with all operations preserving the block abstraction.","These include constructor functions, ring operations such as addition and product, and inversion.","The package is demonstrated by calculating the PLU factorization of a block matrix."],"url":"http://arxiv.org/abs/2408.02112v1"}
{"created":"2024-08-04 18:47:55","title":"Understanding Deep Learning via Notions of Rank","abstract":"Despite the extreme popularity of deep learning in science and industry, its formal understanding is limited. This thesis puts forth notions of rank as key for developing a theory of deep learning, focusing on the fundamental aspects of generalization and expressiveness. In particular, we establish that gradient-based training can induce an implicit regularization towards low rank for several neural network architectures, and demonstrate empirically that this phenomenon may facilitate an explanation of generalization over natural data (e.g., audio, images, and text). Then, we characterize the ability of graph neural networks to model interactions via a notion of rank, which is commonly used for quantifying entanglement in quantum physics. A central tool underlying these results is a connection between neural networks and tensor factorizations. Practical implications of our theory for designing explicit regularization schemes and data preprocessing algorithms are presented.","sentences":["Despite the extreme popularity of deep learning in science and industry, its formal understanding is limited.","This thesis puts forth notions of rank as key for developing a theory of deep learning, focusing on the fundamental aspects of generalization and expressiveness.","In particular, we establish that gradient-based training can induce an implicit regularization towards low rank for several neural network architectures, and demonstrate empirically that this phenomenon may facilitate an explanation of generalization over natural data (e.g., audio, images, and text).","Then, we characterize the ability of graph neural networks to model interactions via a notion of rank, which is commonly used for quantifying entanglement in quantum physics.","A central tool underlying these results is a connection between neural networks and tensor factorizations.","Practical implications of our theory for designing explicit regularization schemes and data preprocessing algorithms are presented."],"url":"http://arxiv.org/abs/2408.02111v1"}
{"created":"2024-08-04 17:00:37","title":"Past Movements-Guided Motion Representation Learning for Human Motion Prediction","abstract":"Human motion prediction based on 3D skeleton is a significant challenge in computer vision, primarily focusing on the effective representation of motion. In this paper, we propose a self-supervised learning framework designed to enhance motion representation. This framework consists of two stages: first, the network is pretrained through the self-reconstruction of past sequences, and the guided reconstruction of future sequences based on past movements. We design a velocity-based mask strategy to focus on the joints with large-scale moving. Subsequently, the pretrained network undergoes finetuning for specific tasks. Self-reconstruction, guided by patterns of past motion, substantially improves the model's ability to represent the spatiotemporal relationships among joints but also captures the latent relationships between past and future sequences. This capability is crucial for motion prediction tasks that solely depend on historical motion data. By employing this straightforward yet effective training paradigm, our method outperforms existing \\textit{state-of-the-art} methods, reducing the average prediction errors by 8.8\\% across Human3.6M, 3DPW, and AMASS datasets. The code is available at https://github.com/JunyuShi02/PMG-MRL.","sentences":["Human motion prediction based on 3D skeleton is a significant challenge in computer vision, primarily focusing on the effective representation of motion.","In this paper, we propose a self-supervised learning framework designed to enhance motion representation.","This framework consists of two stages: first, the network is pretrained through the self-reconstruction of past sequences, and the guided reconstruction of future sequences based on past movements.","We design a velocity-based mask strategy to focus on the joints with large-scale moving.","Subsequently, the pretrained network undergoes finetuning for specific tasks.","Self-reconstruction, guided by patterns of past motion, substantially improves the model's ability to represent the spatiotemporal relationships among joints but also captures the latent relationships between past and future sequences.","This capability is crucial for motion prediction tasks that solely depend on historical motion data.","By employing this straightforward yet effective training paradigm, our method outperforms existing \\textit{state-of-the-art} methods, reducing the average prediction errors by 8.8\\% across Human3.6M, 3DPW, and AMASS datasets.","The code is available at https://github.com/JunyuShi02/PMG-MRL."],"url":"http://arxiv.org/abs/2408.02091v1"}
{"created":"2024-08-04 16:59:43","title":"First Order Stochastic Optimization with Oblivious Noise","abstract":"We initiate the study of stochastic optimization with oblivious noise, broadly generalizing the standard heavy-tailed noise setup. In our setting, in addition to random observation noise, the stochastic gradient may be subject to independent oblivious noise, which may not have bounded moments and is not necessarily centered. Specifically, we assume access to a noisy oracle for the stochastic gradient of $f$ at $x$, which returns a vector $\\nabla f(\\gamma, x) + \\xi$, where $\\gamma$ is the bounded variance observation noise and $\\xi$ is the oblivious noise that is independent of $\\gamma$ and $x$. The only assumption we make on the oblivious noise $\\xi$ is that $\\mathbf{Pr}[\\xi = 0] \\ge \\alpha$ for some $\\alpha \\in (0, 1)$. In this setting, it is not information-theoretically possible to recover a single solution close to the target when the fraction of inliers $\\alpha$ is less than $1/2$. Our main result is an efficient list-decodable learner that recovers a small list of candidates, at least one of which is close to the true solution. On the other hand, if $\\alpha = 1-\\epsilon$, where $0< \\epsilon < 1/2$ is sufficiently small constant, the algorithm recovers a single solution. Along the way, we develop a rejection-sampling-based algorithm to perform noisy location estimation, which may be of independent interest.","sentences":["We initiate the study of stochastic optimization with oblivious noise, broadly generalizing the standard heavy-tailed noise setup.","In our setting, in addition to random observation noise, the stochastic gradient may be subject to independent oblivious noise, which may not have bounded moments and is not necessarily centered.","Specifically, we assume access to a noisy oracle for the stochastic gradient of $f$ at $x$, which returns a vector $\\nabla f(\\gamma, x) + \\xi$, where $\\gamma$ is the bounded variance observation noise and $\\xi$ is the oblivious noise that is independent of $\\gamma$ and $x$.","The only assumption we make on the oblivious noise $\\xi$ is that $\\mathbf{Pr}[\\xi = 0] \\ge \\alpha$ for some $\\alpha \\in (0, 1)$.","In this setting, it is not information-theoretically possible to recover a single solution close to the target when the fraction of inliers $\\alpha$ is less than $1/2$. Our main result is an efficient list-decodable learner that recovers a small list of candidates, at least one of which is close to the true solution.","On the other hand, if $\\alpha = 1-\\epsilon$, where $0< \\epsilon < 1/2$ is sufficiently small constant, the algorithm recovers a single solution.","Along the way, we develop a rejection-sampling-based algorithm to perform noisy location estimation, which may be of independent interest."],"url":"http://arxiv.org/abs/2408.02090v1"}
{"created":"2024-08-04 16:54:49","title":"KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving","abstract":"Accurate 3D object detection in autonomous driving is critical yet challenging due to occlusions, varying object scales, and complex urban environments. This paper introduces the RCBEV-KAN algorithm, a pioneering method designed to enhance 3D object detection by fusing multimodal sensor data from cameras, LiDAR, and millimeter-wave radar. Our innovative Bird's Eye View (BEV)-based approach, utilizing a Transformer architecture, significantly boosts detection precision and efficiency by seamlessly integrating diverse data sources, improving spatial relationship handling, and optimizing computational processes. Experimental results show that the RCBEV-KAN model demonstrates superior performance across most detection categories, achieving higher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score (0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8% faster). These results indicate that RCBEV-KAN is more accurate, reliable, and efficient, making it ideal for dynamic and challenging autonomous driving environments.","sentences":["Accurate 3D object detection in autonomous driving is critical yet challenging due to occlusions, varying object scales, and complex urban environments.","This paper introduces the RCBEV-KAN algorithm, a pioneering method designed to enhance 3D object detection by fusing multimodal sensor data from cameras, LiDAR, and millimeter-wave radar.","Our innovative Bird's Eye View (BEV)-based approach, utilizing a Transformer architecture, significantly boosts detection precision and efficiency by seamlessly integrating diverse data sources, improving spatial relationship handling, and optimizing computational processes.","Experimental results show that the RCBEV-KAN model demonstrates superior performance across most detection categories, achieving higher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score (0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8% faster).","These results indicate that RCBEV-KAN is more accurate, reliable, and efficient, making it ideal for dynamic and challenging autonomous driving environments."],"url":"http://arxiv.org/abs/2408.02088v1"}
{"created":"2024-08-04 16:50:07","title":"Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models","abstract":"Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each category, representative methods are elaborated to describe the landscape of relevant research. In addition, comparison between latest methods is conducted on their officially reported results to provide in-depth discussions on their limitations. Finally, we summarize the open challenges and propose the promosing avenues for future studies. All related contents are available at https://github.com/yuleiqin/fantastic-data-engineering.","sentences":["Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference.","Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical.","To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning.","However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism.","To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs.","We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured.","For each category, representative methods are elaborated to describe the landscape of relevant research.","In addition, comparison between latest methods is conducted on their officially reported results to provide in-depth discussions on their limitations.","Finally, we summarize the open challenges and propose the promosing avenues for future studies.","All related contents are available at https://github.com/yuleiqin/fantastic-data-engineering."],"url":"http://arxiv.org/abs/2408.02085v1"}
{"created":"2024-08-04 16:29:13","title":"Secure and Transparent Medical Record Management System Using Python and Blockchain","abstract":"In this paper, we propose a robust health record storage and management system built on blockchain technology to address the challenges faced by traditional healthcare record systems. The primary advantage of employing blockchain in healthcare record management is its ability to provide a secure and decentralized platform. Unlike traditional centralized databases, where a single point of failure can compromise data integrity and security, blockchain distributes data across a network of nodes, ensuring redundancy and resilience against cyber-attacks. This distributed nature of blockchain enhances data security and privacy, crucial considerations when dealing with sensitive health information. Central to our proposed system is the utilization of smart contracts, which are self-executing contracts with predefined rules and conditions. Smart contracts automate processes related to health record management, such as data access, sharing, and updating, based on predefined permissions and protocols. This automation not only streamlines administrative tasks but also reduces the risk of human errors and ensures data accuracy and consistency. Furthermore, our system prioritizes patient empowerment by granting individuals complete control over their health records. Patients can securely access and manage their data using cryptographic keys, granting permission to healthcare providers or other authorized entities as needed. Overall, our proposed health record storage and management system on the blockchain offer significant advantages over traditional systems, including enhanced security, data integrity, transparency, and patient control. By leveraging blockchain technology and smart contracts, healthcare organizations can revolutionize their record management practices, and maintaining secure ecosystems.","sentences":["In this paper, we propose a robust health record storage and management system built on blockchain technology to address the challenges faced by traditional healthcare record systems.","The primary advantage of employing blockchain in healthcare record management is its ability to provide a secure and decentralized platform.","Unlike traditional centralized databases, where a single point of failure can compromise data integrity and security, blockchain distributes data across a network of nodes, ensuring redundancy and resilience against cyber-attacks.","This distributed nature of blockchain enhances data security and privacy, crucial considerations when dealing with sensitive health information.","Central to our proposed system is the utilization of smart contracts, which are self-executing contracts with predefined rules and conditions.","Smart contracts automate processes related to health record management, such as data access, sharing, and updating, based on predefined permissions and protocols.","This automation not only streamlines administrative tasks but also reduces the risk of human errors and ensures data accuracy and consistency.","Furthermore, our system prioritizes patient empowerment by granting individuals complete control over their health records.","Patients can securely access and manage their data using cryptographic keys, granting permission to healthcare providers or other authorized entities as needed.","Overall, our proposed health record storage and management system on the blockchain offer significant advantages over traditional systems, including enhanced security, data integrity, transparency, and patient control.","By leveraging blockchain technology and smart contracts, healthcare organizations can revolutionize their record management practices, and maintaining secure ecosystems."],"url":"http://arxiv.org/abs/2408.02081v1"}
{"created":"2024-08-04 16:09:46","title":"Improving Neural Surface Reconstruction with Feature Priors from Multi-View Image","abstract":"Recent advancements in Neural Surface Reconstruction (NSR) have significantly improved multi-view reconstruction when coupled with volume rendering. However, relying solely on photometric consistency in image space falls short of addressing complexities posed by real-world data, including occlusions and non-Lambertian surfaces. To tackle these challenges, we propose an investigation into feature-level consistent loss, aiming to harness valuable feature priors from diverse pretext visual tasks and overcome current limitations. It is crucial to note the existing gap in determining the most effective pretext visual task for enhancing NSR. In this study, we comprehensively explore multi-view feature priors from seven pretext visual tasks, comprising thirteen methods. Our main goal is to strengthen NSR training by considering a wide range of possibilities. Additionally, we examine the impact of varying feature resolutions and evaluate both pixel-wise and patch-wise consistent losses, providing insights into effective strategies for improving NSR performance. By incorporating pre-trained representations from MVSFormer and QuadTree, our approach can generate variations of MVS-NeuS and Match-NeuS, respectively. Our results, analyzed on DTU and EPFL datasets, reveal that feature priors from image matching and multi-view stereo outperform other pretext tasks. Moreover, we discover that extending patch-wise photometric consistency to the feature level surpasses the performance of pixel-wise approaches. These findings underscore the effectiveness of these techniques in enhancing NSR outcomes.","sentences":["Recent advancements in Neural Surface Reconstruction (NSR) have significantly improved multi-view reconstruction when coupled with volume rendering.","However, relying solely on photometric consistency in image space falls short of addressing complexities posed by real-world data, including occlusions and non-Lambertian surfaces.","To tackle these challenges, we propose an investigation into feature-level consistent loss, aiming to harness valuable feature priors from diverse pretext visual tasks and overcome current limitations.","It is crucial to note the existing gap in determining the most effective pretext visual task for enhancing NSR.","In this study, we comprehensively explore multi-view feature priors from seven pretext visual tasks, comprising thirteen methods.","Our main goal is to strengthen NSR training by considering a wide range of possibilities.","Additionally, we examine the impact of varying feature resolutions and evaluate both pixel-wise and patch-wise consistent losses, providing insights into effective strategies for improving NSR performance.","By incorporating pre-trained representations from MVSFormer and QuadTree, our approach can generate variations of MVS-NeuS and Match-NeuS, respectively.","Our results, analyzed on DTU and EPFL datasets, reveal that feature priors from image matching and multi-view stereo outperform other pretext tasks.","Moreover, we discover that extending patch-wise photometric consistency to the feature level surpasses the performance of pixel-wise approaches.","These findings underscore the effectiveness of these techniques in enhancing NSR outcomes."],"url":"http://arxiv.org/abs/2408.02079v1"}
{"created":"2024-08-04 15:42:34","title":"PromptSAM+: Malware Detection based on Prompt Segment Anything Model","abstract":"Machine learning and deep learning (ML/DL) have been extensively applied in malware detection, and some existing methods demonstrate robust performance. However, several issues persist in the field of malware detection: (1) Existing work often overemphasizes accuracy at the expense of practicality, rarely considering false positive and false negative rates as important metrics. (2) Considering the evolution of malware, the performance of classifiers significantly declines over time, greatly reducing the practicality of malware detectors. (3) Prior ML/DL-based efforts heavily rely on ample labeled data for model training, largely dependent on feature engineering or domain knowledge to build feature databases, making them vulnerable if correct labels are scarce. With the development of computer vision, vision-based malware detection technology has also rapidly evolved. In this paper, we propose a visual malware general enhancement classification framework, `PromptSAM+', based on a large visual network segmentation model, the Prompt Segment Anything Model(named PromptSAM+). Our experimental results indicate that 'PromptSAM+' is effective and efficient in malware detection and classification, achieving high accuracy and low rates of false positives and negatives. The proposed method outperforms the most advanced image-based malware detection technologies on several datasets. 'PromptSAM+' can mitigate aging in existing image-based malware classifiers, reducing the considerable manpower needed for labeling new malware samples through active learning. We conducted experiments on datasets for both Windows and Android platforms, achieving favorable outcomes. Additionally, our ablation experiments on several datasets demonstrate that our model identifies effective modules within the large visual network.","sentences":["Machine learning and deep learning (ML/DL) have been extensively applied in malware detection, and some existing methods demonstrate robust performance.","However, several issues persist in the field of malware detection: (1) Existing work often overemphasizes accuracy at the expense of practicality, rarely considering false positive and false negative rates as important metrics.","(2) Considering the evolution of malware, the performance of classifiers significantly declines over time, greatly reducing the practicality of malware detectors.","(3) Prior ML/DL-based efforts heavily rely on ample labeled data for model training, largely dependent on feature engineering or domain knowledge to build feature databases, making them vulnerable if correct labels are scarce.","With the development of computer vision, vision-based malware detection technology has also rapidly evolved.","In this paper, we propose a visual malware general enhancement classification framework, `PromptSAM+', based on a large visual network segmentation model, the Prompt Segment Anything Model(named PromptSAM+).","Our experimental results indicate that 'PromptSAM+' is effective and efficient in malware detection and classification, achieving high accuracy and low rates of false positives and negatives.","The proposed method outperforms the most advanced image-based malware detection technologies on several datasets.","'PromptSAM+' can mitigate aging in existing image-based malware classifiers, reducing the considerable manpower needed for labeling new malware samples through active learning.","We conducted experiments on datasets for both Windows and Android platforms, achieving favorable outcomes.","Additionally, our ablation experiments on several datasets demonstrate that our model identifies effective modules within the large visual network."],"url":"http://arxiv.org/abs/2408.02066v1"}
{"created":"2024-08-04 15:20:39","title":"ParkingE2E: Camera-based End-to-end Parking Network, from Images to Planning","abstract":"Autonomous parking is a crucial task in the intelligent driving field. Traditional parking algorithms are usually implemented using rule-based schemes. However, these methods are less effective in complex parking scenarios due to the intricate design of the algorithms. In contrast, neural-network-based methods tend to be more intuitive and versatile than the rule-based methods. By collecting a large number of expert parking trajectory data and emulating human strategy via learning-based methods, the parking task can be effectively addressed. In this paper, we employ imitation learning to perform end-to-end planning from RGB images to path planning by imitating human driving trajectories. The proposed end-to-end approach utilizes a target query encoder to fuse images and target features, and a transformer-based decoder to autoregressively predict future waypoints. We conducted extensive experiments in real-world scenarios, and the results demonstrate that the proposed method achieved an average parking success rate of 87.8% across four different real-world garages. Real-vehicle experiments further validate the feasibility and effectiveness of the method proposed in this paper.","sentences":["Autonomous parking is a crucial task in the intelligent driving field.","Traditional parking algorithms are usually implemented using rule-based schemes.","However, these methods are less effective in complex parking scenarios due to the intricate design of the algorithms.","In contrast, neural-network-based methods tend to be more intuitive and versatile than the rule-based methods.","By collecting a large number of expert parking trajectory data and emulating human strategy via learning-based methods, the parking task can be effectively addressed.","In this paper, we employ imitation learning to perform end-to-end planning from RGB images to path planning by imitating human driving trajectories.","The proposed end-to-end approach utilizes a target query encoder to fuse images and target features, and a transformer-based decoder to autoregressively predict future waypoints.","We conducted extensive experiments in real-world scenarios, and the results demonstrate that the proposed method achieved an average parking success rate of 87.8% across four different real-world garages.","Real-vehicle experiments further validate the feasibility and effectiveness of the method proposed in this paper."],"url":"http://arxiv.org/abs/2408.02061v1"}
{"created":"2024-08-04 15:07:44","title":"MedSyn: LLM-based Synthetic Medical Text Generation Framework","abstract":"Generating synthetic text addresses the challenge of data availability in privacy-sensitive domains such as healthcare. This study explores the applicability of synthetic data in real-world medical settings. We introduce MedSyn, a novel medical text generation framework that integrates large language models with a Medical Knowledge Graph (MKG). We use MKG to sample prior medical information for the prompt and generate synthetic clinical notes with GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data through application in the ICD code prediction task. Our research indicates that synthetic data can increase the classification accuracy of vital and challenging codes by up to 17.8% compared to settings without synthetic data. Furthermore, to provide new data for further research in the healthcare domain, we present the largest open-source synthetic dataset of clinical notes for the Russian language, comprising over 41k samples covering 219 ICD-10 codes.","sentences":["Generating synthetic text addresses the challenge of data availability in privacy-sensitive domains such as healthcare.","This study explores the applicability of synthetic data in real-world medical settings.","We introduce MedSyn, a novel medical text generation framework that integrates large language models with a Medical Knowledge Graph (MKG).","We use MKG to sample prior medical information for the prompt and generate synthetic clinical notes with GPT-4 and fine-tuned LLaMA models.","We assess the benefit of synthetic data through application in the ICD code prediction task.","Our research indicates that synthetic data can increase the classification accuracy of vital and challenging codes by up to 17.8% compared to settings without synthetic data.","Furthermore, to provide new data for further research in the healthcare domain, we present the largest open-source synthetic dataset of clinical notes for the Russian language, comprising over 41k samples covering 219 ICD-10 codes."],"url":"http://arxiv.org/abs/2408.02056v1"}
{"created":"2024-08-04 14:57:44","title":"Recovering the state and dynamics of autonomous system with partial states solution using neural networks","abstract":"In this paper we explore the performance of deep hidden physics model (M. Raissi 2018) for autonomous system, this systems do not explicitly depend on time. The dynamics of states are dependent on states itself. Such systems can be found in nature and have applications   in modeling chemical concentrations, population dynamics, n-body problems in physics etc. In this work we are going to see how we can obtain dynamics of states based on solution of limited partial states. The proposed method can find the state and dynamics of which the data is provided in the training, although we do not claim to accurately find the solution of states whose data is not utilized while training.","sentences":["In this paper we explore the performance of deep hidden physics model (M. Raissi 2018) for autonomous system, this systems do not explicitly depend on time.","The dynamics of states are dependent on states itself.","Such systems can be found in nature and have applications   in modeling chemical concentrations, population dynamics, n-body problems in physics etc.","In this work we are going to see how we can obtain dynamics of states based on solution of limited partial states.","The proposed method can find the state and dynamics of which the data is provided in the training, although we do not claim to accurately find the solution of states whose data is not utilized while training."],"url":"http://arxiv.org/abs/2408.02050v1"}
{"created":"2024-08-04 14:57:28","title":"3D Single-object Tracking in Point Clouds with High Temporal Variation","abstract":"The high temporal variation of the point clouds is the key challenge of 3D single-object tracking (3D SOT). Existing approaches rely on the assumption that the shape variation of the point clouds and the motion of the objects across neighboring frames are smooth, failing to cope with high temporal variation data. In this paper, we present a novel framework for 3D SOT in point clouds with high temporal variation, called HVTrack. HVTrack proposes three novel components to tackle the challenges in the high temporal variation scenario: 1) A Relative-Pose-Aware Memory module to handle temporal point cloud shape variations; 2) a Base-Expansion Feature Cross-Attention module to deal with similar object distractions in expanded search areas; 3) a Contextual Point Guided Self-Attention module for suppressing heavy background noise. We construct a dataset with high temporal variation (KITTI-HV) by setting different frame intervals for sampling in the KITTI dataset. On the KITTI-HV with 5 frame intervals, our HVTrack surpasses the state-of-the-art tracker CXTracker by 11.3%/15.7% in Success/Precision.","sentences":["The high temporal variation of the point clouds is the key challenge of 3D single-object tracking (3D SOT).","Existing approaches rely on the assumption that the shape variation of the point clouds and the motion of the objects across neighboring frames are smooth, failing to cope with high temporal variation data.","In this paper, we present a novel framework for 3D SOT in point clouds with high temporal variation, called HVTrack.","HVTrack proposes three novel components to tackle the challenges in the high temporal variation scenario: 1) A Relative-Pose-Aware Memory module to handle temporal point cloud shape variations; 2) a Base-Expansion Feature Cross-Attention module to deal with similar object distractions in expanded search areas; 3) a Contextual Point Guided Self-Attention module for suppressing heavy background noise.","We construct a dataset with high temporal variation (KITTI-HV) by setting different frame intervals for sampling in the KITTI dataset.","On the KITTI-HV with 5 frame intervals, our HVTrack surpasses the state-of-the-art tracker CXTracker by 11.3%/15.7% in Success/Precision."],"url":"http://arxiv.org/abs/2408.02049v1"}
{"created":"2024-08-04 14:35:30","title":"Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages","abstract":"The aspect-based sentiment analysis (ABSA) is a standard NLP task with numerous approaches and benchmarks, where large language models (LLM) represent the current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data in underrepresented languages. On such narrow tasks, small tuned language models can often outperform universal large ones, providing available and cheap solutions.   We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for classification of sentiment towards Russia and Ukraine in the context of the ongoing military conflict. The training/testing dataset was obtained from the academic API from Twitter/X during 2023, narrowed to the languages of the V4 countries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their performance under a variety of settings including translations, sentiment targets, in-context learning and more, using GPT4 as a reference model. We document several interesting phenomena demonstrating, among others, that some models are much better fine-tunable on multilingual Twitter tasks than others, and that they can reach the SOTA level with a very small training set. Finally we identify combinations of settings providing the best results.","sentences":["The aspect-based sentiment analysis (ABSA) is a standard NLP task with numerous approaches and benchmarks, where large language models (LLM) represent the current state-of-the-art.","We focus on ABSA subtasks based on Twitter/X data in underrepresented languages.","On such narrow tasks, small tuned language models can often outperform universal large ones, providing available and cheap solutions.   ","We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for classification of sentiment towards Russia and Ukraine in the context of the ongoing military conflict.","The training/testing dataset was obtained from the academic API from Twitter/X during 2023, narrowed to the languages of the V4 countries (Czech Republic, Slovakia, Poland, Hungary).","Then we measure their performance under a variety of settings including translations, sentiment targets, in-context learning and more, using GPT4 as a reference model.","We document several interesting phenomena demonstrating, among others, that some models are much better fine-tunable on multilingual Twitter tasks than others, and that they can reach the SOTA level with a very small training set.","Finally we identify combinations of settings providing the best results."],"url":"http://arxiv.org/abs/2408.02044v1"}
{"created":"2024-08-04 14:13:04","title":"Distributionally Robust Optimization for Computation Offloading in Aerial Access Networks","abstract":"With the rapid increment of multiple users for data offloading and computation, it is challenging to guarantee the quality of service (QoS) in remote areas. To deal with the challenge, it is promising to combine aerial access networks (AANs) with multi-access edge computing (MEC) equipments to provide computation services with high QoS. However, as for uncertain data sizes of tasks, it is intractable to optimize the offloading decisions and the aerial resources. Hence, in this paper, we consider the AAN to provide MEC services for uncertain tasks. Specifically, we construct the uncertainty sets based on historical data to characterize the possible probability distribution of the uncertain tasks. Then, based on the constructed uncertainty sets, we formulate a distributionally robust optimization problem to minimize the system delay. Next,we relax the problem and reformulate it into a linear programming problem. Accordingly, we design a MEC-based distributionally robust latency optimization algorithm. Finally, simulation results reveal that the proposed algorithm achieves a superior balance between reducing system latency and minimizing energy consumption, as compared to other benchmark mechanisms in the existing literature.","sentences":["With the rapid increment of multiple users for data offloading and computation, it is challenging to guarantee the quality of service (QoS) in remote areas.","To deal with the challenge, it is promising to combine aerial access networks (AANs) with multi-access edge computing (MEC) equipments to provide computation services with high QoS.","However, as for uncertain data sizes of tasks, it is intractable to optimize the offloading decisions and the aerial resources.","Hence, in this paper, we consider the AAN to provide MEC services for uncertain tasks.","Specifically, we construct the uncertainty sets based on historical data to characterize the possible probability distribution of the uncertain tasks.","Then, based on the constructed uncertainty sets, we formulate a distributionally robust optimization problem to minimize the system delay.","Next,we relax the problem and reformulate it into a linear programming problem.","Accordingly, we design a MEC-based distributionally robust latency optimization algorithm.","Finally, simulation results reveal that the proposed algorithm achieves a superior balance between reducing system latency and minimizing energy consumption, as compared to other benchmark mechanisms in the existing literature."],"url":"http://arxiv.org/abs/2408.02037v1"}
{"created":"2024-08-04 14:07:14","title":"LEGO: Self-Supervised Representation Learning for Scene Text Images","abstract":"In recent years, significant progress has been made in scene text recognition by data-driven methods. However, due to the scarcity of annotated real-world data, the training of these methods predominantly relies on synthetic data. The distribution gap between synthetic and real data constrains the further performance improvement of these methods in real-world applications. To tackle this problem, a highly promising approach is to utilize massive amounts of unlabeled real data for self-supervised training, which has been widely proven effective in many NLP and CV tasks. Nevertheless, generic self-supervised methods are unsuitable for scene text images due to their sequential nature. To address this issue, we propose a Local Explicit and Global Order-aware self-supervised representation learning method (LEGO) that accounts for the characteristics of scene text images. Inspired by the human cognitive process of learning words, which involves spelling, reading, and writing, we propose three novel pre-text tasks for LEGO to model sequential, semantic, and structural features, respectively. The entire pre-training process is optimized by using a consistent Text Knowledge Codebook. Extensive experiments validate that LEGO outperforms previous scene text self-supervised methods. The recognizer incorporated with our pre-trained model achieves superior or comparable performance compared to state-of-the-art scene text recognition methods on six benchmarks. Furthermore, we demonstrate that LEGO can achieve superior performance in other text-related tasks.","sentences":["In recent years, significant progress has been made in scene text recognition by data-driven methods.","However, due to the scarcity of annotated real-world data, the training of these methods predominantly relies on synthetic data.","The distribution gap between synthetic and real data constrains the further performance improvement of these methods in real-world applications.","To tackle this problem, a highly promising approach is to utilize massive amounts of unlabeled real data for self-supervised training, which has been widely proven effective in many NLP and CV tasks.","Nevertheless, generic self-supervised methods are unsuitable for scene text images due to their sequential nature.","To address this issue, we propose a Local Explicit and Global Order-aware self-supervised representation learning method (LEGO) that accounts for the characteristics of scene text images.","Inspired by the human cognitive process of learning words, which involves spelling, reading, and writing, we propose three novel pre-text tasks for LEGO to model sequential, semantic, and structural features, respectively.","The entire pre-training process is optimized by using a consistent Text Knowledge Codebook.","Extensive experiments validate that LEGO outperforms previous scene text self-supervised methods.","The recognizer incorporated with our pre-trained model achieves superior or comparable performance compared to state-of-the-art scene text recognition methods on six benchmarks.","Furthermore, we demonstrate that LEGO can achieve superior performance in other text-related tasks."],"url":"http://arxiv.org/abs/2408.02036v1"}
{"created":"2024-08-04 13:51:18","title":"Enhancing Human Action Recognition and Violence Detection Through Deep Learning Audiovisual Fusion","abstract":"This paper proposes a hybrid fusion-based deep learning approach based on two different modalities, audio and video, to improve human activity recognition and violence detection in public places. To take advantage of audiovisual fusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning (HFBDL) are used and compared. Since the objective is to detect and recognize human violence in public places, Real-life violence situation (RLVS) dataset is expanded and used. Simulating results of HFBDL show 96.67\\% accuracy on validation data, which is more accurate than the other state-of-the-art methods on this dataset. To showcase our model's ability in real-world scenarios, another dataset of 54 sounded videos of both violent and non-violent situations was recorded. The model could successfully detect 52 out of 54 videos correctly. The proposed method shows a promising performance on real scenarios. Thus, it can be used for human action recognition and violence detection in public places for security purposes.","sentences":["This paper proposes a hybrid fusion-based deep learning approach based on two different modalities, audio and video, to improve human activity recognition and violence detection in public places.","To take advantage of audiovisual fusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning (HFBDL) are used and compared.","Since the objective is to detect and recognize human violence in public places, Real-life violence situation (RLVS) dataset is expanded and used.","Simulating results of HFBDL show 96.67\\% accuracy on validation data, which is more accurate than the other state-of-the-art methods on this dataset.","To showcase our model's ability in real-world scenarios, another dataset of 54 sounded videos of both violent and non-violent situations was recorded.","The model could successfully detect 52 out of 54 videos correctly.","The proposed method shows a promising performance on real scenarios.","Thus, it can be used for human action recognition and violence detection in public places for security purposes."],"url":"http://arxiv.org/abs/2408.02033v1"}
{"created":"2024-08-04 13:39:57","title":"Mining Path Association Rules in Large Property Graphs (with Appendix)","abstract":"How can we mine frequent path regularities from a graph with edge labels and vertex attributes? The task of association rule mining successfully discovers regular patterns in item sets and substructures. Still, to our best knowledge, this concept has not yet been extended to path patterns in large property graphs. In this paper, we introduce the problem of path association rule mining (PARM). Applied to any \\emph{reachability path} between two vertices within a large graph, PARM discovers regular ways in which path patterns, identified by vertex attributes and edge labels, co-occur with each other. We develop an efficient and scalable algorithm PIONEER that exploits an anti-monotonicity property to effectively prune the search space. Further, we devise approximation techniques and employ parallelization to achieve scalable path association rule mining. Our experimental study using real-world graph data verifies the significance of path association rules and the efficiency of our solutions.","sentences":["How can we mine frequent path regularities from a graph with edge labels and vertex attributes?","The task of association rule mining successfully discovers regular patterns in item sets and substructures.","Still, to our best knowledge, this concept has not yet been extended to path patterns in large property graphs.","In this paper, we introduce the problem of path association rule mining (PARM).","Applied to any \\emph{reachability path} between two vertices within a large graph, PARM discovers regular ways in which path patterns, identified by vertex attributes and edge labels, co-occur with each other.","We develop an efficient and scalable algorithm PIONEER that exploits an anti-monotonicity property to effectively prune the search space.","Further, we devise approximation techniques and employ parallelization to achieve scalable path association rule mining.","Our experimental study using real-world graph data verifies the significance of path association rules and the efficiency of our solutions."],"url":"http://arxiv.org/abs/2408.02029v1"}
{"created":"2024-08-04 13:24:36","title":"Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face Association","abstract":"The innate correlation between a person's face and voice has recently emerged as a compelling area of study, especially within the context of multilingual environments. This paper introduces our novel solution to the Face-Voice Association in Multilingual Environments (FAME) 2024 challenge, focusing on a contrastive learning-based chaining-cluster method to enhance face-voice association. This task involves the challenges of building biometric relations between auditory and visual modality cues and modelling the prosody interdependence between different languages while addressing both intrinsic and extrinsic variability present in the data. To handle these non-trivial challenges, our method employs supervised cross-contrastive (SCC) learning to establish robust associations between voices and faces in multi-language scenarios. Following this, we have specifically designed a chaining-cluster-based post-processing step to mitigate the impact of outliers often found in unconstrained in the wild data. We conducted extensive experiments to investigate the impact of language on face-voice association. The overall results were evaluated on the FAME public evaluation platform, where we achieved 2nd place. The results demonstrate the superior performance of our method, and we validate the robustness and effectiveness of our proposed approach. Code is available at https://github.com/colaudiolab/FAME24_solution.","sentences":["The innate correlation between a person's face and voice has recently emerged as a compelling area of study, especially within the context of multilingual environments.","This paper introduces our novel solution to the Face-Voice Association in Multilingual Environments (FAME) 2024 challenge, focusing on a contrastive learning-based chaining-cluster method to enhance face-voice association.","This task involves the challenges of building biometric relations between auditory and visual modality cues and modelling the prosody interdependence between different languages while addressing both intrinsic and extrinsic variability present in the data.","To handle these non-trivial challenges, our method employs supervised cross-contrastive (SCC) learning to establish robust associations between voices and faces in multi-language scenarios.","Following this, we have specifically designed a chaining-cluster-based post-processing step to mitigate the impact of outliers often found in unconstrained in the wild data.","We conducted extensive experiments to investigate the impact of language on face-voice association.","The overall results were evaluated on the FAME public evaluation platform, where we achieved 2nd place.","The results demonstrate the superior performance of our method, and we validate the robustness and effectiveness of our proposed approach.","Code is available at https://github.com/colaudiolab/FAME24_solution."],"url":"http://arxiv.org/abs/2408.02025v1"}
{"created":"2024-08-04 13:20:01","title":"A Smart City Infrastructure Ontology for Threats, Cybercrime, and Digital Forensic Investigation","abstract":"Cybercrime and the market for cyber-related compromises are becoming attractive revenue sources for state-sponsored actors, cybercriminals and technical individuals affected by financial hardships. Due to burgeoning cybercrime on new technological frontiers, efforts have been made to assist digital forensic investigators (DFI) and law enforcement agencies (LEA) in their investigative efforts.   Forensic tool innovations and ontology developments, such as the Unified Cyber Ontology (UCO) and Cyber-investigation Analysis Standard Expression (CASE), have been proposed to assist DFI and LEA. Although these tools and ontologies are useful, they lack extensive information sharing and tool interoperability features, and the ontologies lack the latest Smart City Infrastructure (SCI) context that was proposed.   To mitigate the weaknesses in both solutions and to ensure a safer cyber-physical environment for all, we propose the Smart City Ontological Paradigm Expression (SCOPE), an expansion profile of the UCO and CASE ontology that implements SCI threat models, SCI digital forensic evidence, attack techniques, patterns and classifications from MITRE.   We showcase how SCOPE could present complex data such as SCI-specific threats, cybercrime, investigation data and incident handling workflows via an incident scenario modelled after publicly reported real-world incidents attributed to Advanced Persistent Threat (APT) groups. We also make SCOPE available to the community so that threats, digital evidence and cybercrime in emerging trends such as SCI can be identified, represented, and shared collaboratively.","sentences":["Cybercrime and the market for cyber-related compromises are becoming attractive revenue sources for state-sponsored actors, cybercriminals and technical individuals affected by financial hardships.","Due to burgeoning cybercrime on new technological frontiers, efforts have been made to assist digital forensic investigators (DFI) and law enforcement agencies (LEA) in their investigative efforts.   ","Forensic tool innovations and ontology developments, such as the Unified Cyber Ontology (UCO) and Cyber-investigation Analysis Standard Expression (CASE), have been proposed to assist DFI and LEA.","Although these tools and ontologies are useful, they lack extensive information sharing and tool interoperability features, and the ontologies lack the latest Smart City Infrastructure (SCI) context that was proposed.   ","To mitigate the weaknesses in both solutions and to ensure a safer cyber-physical environment for all, we propose the Smart City Ontological Paradigm Expression (SCOPE), an expansion profile of the UCO and CASE ontology that implements SCI threat models, SCI digital forensic evidence, attack techniques, patterns and classifications from MITRE.   ","We showcase how SCOPE could present complex data such as SCI-specific threats, cybercrime, investigation data and incident handling workflows via an incident scenario modelled after publicly reported real-world incidents attributed to Advanced Persistent Threat (APT) groups.","We also make SCOPE available to the community so that threats, digital evidence and cybercrime in emerging trends such as SCI can be identified, represented, and shared collaboratively."],"url":"http://arxiv.org/abs/2408.02023v1"}
{"created":"2024-08-04 13:11:49","title":"Personalized Federated Learning on Heterogeneous and Long-Tailed Data via Expert Collaborative Learning","abstract":"Personalized Federated Learning (PFL) aims to acquire customized models for each client without disclosing raw data by leveraging the collective knowledge of distributed clients. However, the data collected in real-world scenarios is likely to follow a long-tailed distribution. For example, in the medical domain, it is more common for the number of general health notes to be much larger than those specifically relatedto certain diseases. The presence of long-tailed data can significantly degrade the performance of PFL models. Additionally, due to the diverse environments in which each client operates, data heterogeneity is also a classic challenge in federated learning. In this paper, we explore the joint problem of global long-tailed distribution and data heterogeneity in PFL and propose a method called Expert Collaborative Learning (ECL) to tackle this problem. Specifically, each client has multiple experts, and each expert has a different training subset, which ensures that each class, especially the minority classes, receives sufficient training. Multiple experts collaborate synergistically to produce the final prediction output. Without special bells and whistles, the vanilla ECL outperforms other state-of-the-art PFL methods on several benchmark datasets under different degrees of data heterogeneity and long-tailed distribution.","sentences":["Personalized Federated Learning (PFL) aims to acquire customized models for each client without disclosing raw data by leveraging the collective knowledge of distributed clients.","However, the data collected in real-world scenarios is likely to follow a long-tailed distribution.","For example, in the medical domain, it is more common for the number of general health notes to be much larger than those specifically relatedto certain diseases.","The presence of long-tailed data can significantly degrade the performance of PFL models.","Additionally, due to the diverse environments in which each client operates, data heterogeneity is also a classic challenge in federated learning.","In this paper, we explore the joint problem of global long-tailed distribution and data heterogeneity in PFL and propose a method called Expert Collaborative Learning (ECL) to tackle this problem.","Specifically, each client has multiple experts, and each expert has a different training subset, which ensures that each class, especially the minority classes, receives sufficient training.","Multiple experts collaborate synergistically to produce the final prediction output.","Without special bells and whistles, the vanilla ECL outperforms other state-of-the-art PFL methods on several benchmark datasets under different degrees of data heterogeneity and long-tailed distribution."],"url":"http://arxiv.org/abs/2408.02019v1"}
{"created":"2024-08-04 13:09:06","title":"Individualized multi-horizon MRI trajectory prediction for Alzheimer's Disease","abstract":"Neurodegeneration as measured through magnetic resonance imaging (MRI) is recognized as a potential biomarker for diagnosing Alzheimer's disease (AD), but is generally considered less specific than amyloid or tau based biomarkers. Due to a large amount of variability in brain anatomy between different individuals, we hypothesize that leveraging MRI time series can help improve specificity, by treating each patient as their own baseline. Here we turn to conditional variational autoencoders to generate individualized MRI predictions given the subject's age, disease status and one previous scan. Using serial imaging data from the Alzheimer's Disease Neuroimaging Initiative, we train a novel architecture to build a latent space distribution which can be sampled from to generate future predictions of changing anatomy. This enables us to extrapolate beyond the dataset and predict MRIs up to 10 years. We evaluated the model on a held-out set from ADNI and an independent dataset (from Open Access Series of Imaging Studies). By comparing to several alternatives, we show that our model produces more individualized images with higher resolution. Further, if an individual already has a follow-up MRI, we demonstrate a usage of our model to compute a likelihood ratio classifier for disease status. In practice, the model may be able to assist in early diagnosis of AD and provide a counterfactual baseline trajectory for treatment effect estimation. Furthermore, it generates a synthetic dataset that can potentially be used for downstream tasks such as anomaly detection and classification.","sentences":["Neurodegeneration as measured through magnetic resonance imaging (MRI) is recognized as a potential biomarker for diagnosing Alzheimer's disease (AD), but is generally considered less specific than amyloid or tau based biomarkers.","Due to a large amount of variability in brain anatomy between different individuals, we hypothesize that leveraging MRI time series can help improve specificity, by treating each patient as their own baseline.","Here we turn to conditional variational autoencoders to generate individualized MRI predictions given the subject's age, disease status and one previous scan.","Using serial imaging data from the Alzheimer's Disease Neuroimaging Initiative, we train a novel architecture to build a latent space distribution which can be sampled from to generate future predictions of changing anatomy.","This enables us to extrapolate beyond the dataset and predict MRIs up to 10 years.","We evaluated the model on a held-out set from ADNI and an independent dataset (from Open Access Series of Imaging Studies).","By comparing to several alternatives, we show that our model produces more individualized images with higher resolution.","Further, if an individual already has a follow-up MRI, we demonstrate a usage of our model to compute a likelihood ratio classifier for disease status.","In practice, the model may be able to assist in early diagnosis of AD and provide a counterfactual baseline trajectory for treatment effect estimation.","Furthermore, it generates a synthetic dataset that can potentially be used for downstream tasks such as anomaly detection and classification."],"url":"http://arxiv.org/abs/2408.02018v1"}
{"created":"2024-08-04 11:59:09","title":"AdaCBM: An Adaptive Concept Bottleneck Model for Explainable and Accurate Diagnosis","abstract":"The integration of vision-language models such as CLIP and Concept Bottleneck Models (CBMs) offers a promising approach to explaining deep neural network (DNN) decisions using concepts understandable by humans, addressing the black-box concern of DNNs. While CLIP provides both explainability and zero-shot classification capability, its pre-training on generic image and text data may limit its classification accuracy and applicability to medical image diagnostic tasks, creating a transfer learning problem. To maintain explainability and address transfer learning needs, CBM methods commonly design post-processing modules after the bottleneck module. However, this way has been ineffective. This paper takes an unconventional approach by re-examining the CBM framework through the lens of its geometrical representation as a simple linear classification system. The analysis uncovers that post-CBM fine-tuning modules merely rescale and shift the classification outcome of the system, failing to fully leverage the system's learning potential. We introduce an adaptive module strategically positioned between CLIP and CBM to bridge the gap between source and downstream domains. This simple yet effective approach enhances classification performance while preserving the explainability afforded by the framework. Our work offers a comprehensive solution that encompasses the entire process, from concept discovery to model training, providing a holistic recipe for leveraging the strengths of GPT, CLIP, and CBM.","sentences":["The integration of vision-language models such as CLIP and Concept Bottleneck Models (CBMs) offers a promising approach to explaining deep neural network (DNN) decisions using concepts understandable by humans, addressing the black-box concern of DNNs.","While CLIP provides both explainability and zero-shot classification capability, its pre-training on generic image and text data may limit its classification accuracy and applicability to medical image diagnostic tasks, creating a transfer learning problem.","To maintain explainability and address transfer learning needs, CBM methods commonly design post-processing modules after the bottleneck module.","However, this way has been ineffective.","This paper takes an unconventional approach by re-examining the CBM framework through the lens of its geometrical representation as a simple linear classification system.","The analysis uncovers that post-CBM fine-tuning modules merely rescale and shift the classification outcome of the system, failing to fully leverage the system's learning potential.","We introduce an adaptive module strategically positioned between CLIP and CBM to bridge the gap between source and downstream domains.","This simple yet effective approach enhances classification performance while preserving the explainability afforded by the framework.","Our work offers a comprehensive solution that encompasses the entire process, from concept discovery to model training, providing a holistic recipe for leveraging the strengths of GPT, CLIP, and CBM."],"url":"http://arxiv.org/abs/2408.02001v1"}
{"created":"2024-08-04 11:51:00","title":"What Happens Without Background? Constructing Foreground-Only Data for Fine-Grained Tasks","abstract":"Fine-grained recognition, a pivotal task in visual signal processing, aims to distinguish between similar subclasses based on discriminative information present in samples. However, prevailing methods often erroneously focus on background areas, neglecting the capture of genuinely effective discriminative information from the subject, thus impeding practical application. To facilitate research into the impact of background noise on models and enhance their ability to concentrate on the subject's discriminative features, we propose an engineered pipeline that leverages the capabilities of SAM and Detic to create fine-grained datasets with only foreground subjects, devoid of background. Extensive cross-experiments validate this approach as a preprocessing step prior to training, enhancing algorithmic performance and holding potential for further modal expansion of the data.","sentences":["Fine-grained recognition, a pivotal task in visual signal processing, aims to distinguish between similar subclasses based on discriminative information present in samples.","However, prevailing methods often erroneously focus on background areas, neglecting the capture of genuinely effective discriminative information from the subject, thus impeding practical application.","To facilitate research into the impact of background noise on models and enhance their ability to concentrate on the subject's discriminative features, we propose an engineered pipeline that leverages the capabilities of SAM and Detic to create fine-grained datasets with only foreground subjects, devoid of background.","Extensive cross-experiments validate this approach as a preprocessing step prior to training, enhancing algorithmic performance and holding potential for further modal expansion of the data."],"url":"http://arxiv.org/abs/2408.01998v1"}
{"created":"2024-08-04 11:46:20","title":"Configuring Safe Spiking Neural Controllers for Cyber-Physical Systems through Formal Verification","abstract":"Spiking Neural Networks (SNNs) are a subclass of neuromorphic models that have great potential to be used as controllers in Cyber-Physical Systems (CPSs) due to their energy efficiency. They can benefit from the prevalent approach of first training an Artificial Neural Network (ANN) and then translating to an SNN with subsequent hyperparameter tuning. The tuning is required to ensure that the resulting SNN is accurate with respect to the ANN in terms of metrics like Mean Squared Error (MSE). However, SNN controllers for safety-critical CPSs must also satisfy safety specifications, which are not guaranteed by the conversion approach. In this paper, we propose a solution which tunes the $temporal$ $window$ hyperparameter of the translated SNN to ensure both accuracy and compliance with the safe range specification that requires the SNN outputs to remain within a safe range. The core verification problem is modelled using mixed-integer linear programming (MILP) and is solved with Gurobi. When the controller fails to meet the range specification, we compute tight bounds on the SNN outputs as feedback for the CPS developer. To mitigate the high computational cost of verification, we integrate data-driven steps to minimize verification calls. Our approach provides designers with the confidence to safely integrate energy-efficient SNN controllers into modern CPSs. We demonstrate our approach with experimental results on five different benchmark neural controllers.","sentences":["Spiking Neural Networks (SNNs) are a subclass of neuromorphic models that have great potential to be used as controllers in Cyber-Physical Systems (CPSs) due to their energy efficiency.","They can benefit from the prevalent approach of first training an Artificial Neural Network (ANN) and then translating to an SNN with subsequent hyperparameter tuning.","The tuning is required to ensure that the resulting SNN is accurate with respect to the ANN in terms of metrics like Mean Squared Error (MSE).","However, SNN controllers for safety-critical CPSs must also satisfy safety specifications, which are not guaranteed by the conversion approach.","In this paper, we propose a solution which tunes the $temporal$ $window$ hyperparameter of the translated SNN to ensure both accuracy and compliance with the safe range specification that requires the SNN outputs to remain within a safe range.","The core verification problem is modelled using mixed-integer linear programming (MILP) and is solved with Gurobi.","When the controller fails to meet the range specification, we compute tight bounds on the SNN outputs as feedback for the CPS developer.","To mitigate the high computational cost of verification, we integrate data-driven steps to minimize verification calls.","Our approach provides designers with the confidence to safely integrate energy-efficient SNN controllers into modern CPSs.","We demonstrate our approach with experimental results on five different benchmark neural controllers."],"url":"http://arxiv.org/abs/2408.01996v1"}
{"created":"2024-08-04 11:25:07","title":"Towards Automatic Hands-on-Keyboard Attack Detection Using LLMs in EDR Solutions","abstract":"Endpoint Detection and Remediation (EDR) platforms are essential for identifying and responding to cyber threats. This study presents a novel approach using Large Language Models (LLMs) to detect Hands-on-Keyboard (HOK) cyberattacks. Our method involves converting endpoint activity data into narrative forms that LLMs can analyze to distinguish between normal operations and potential HOK attacks. We address the challenges of interpreting endpoint data by segmenting narratives into windows and employing a dual training strategy. The results demonstrate that LLM-based models have the potential to outperform traditional machine learning methods, offering a promising direction for enhancing EDR capabilities and apply LLMs in cybersecurity.","sentences":["Endpoint Detection and Remediation (EDR) platforms are essential for identifying and responding to cyber threats.","This study presents a novel approach using Large Language Models (LLMs) to detect Hands-on-Keyboard (HOK) cyberattacks.","Our method involves converting endpoint activity data into narrative forms that LLMs can analyze to distinguish between normal operations and potential HOK attacks.","We address the challenges of interpreting endpoint data by segmenting narratives into windows and employing a dual training strategy.","The results demonstrate that LLM-based models have the potential to outperform traditional machine learning methods, offering a promising direction for enhancing EDR capabilities and apply LLMs in cybersecurity."],"url":"http://arxiv.org/abs/2408.01993v1"}
{"created":"2024-08-04 11:00:43","title":"MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots","abstract":"Wearable systems provide continuous health monitoring and can lead to early detection of potential health issues. However, the lifecycle of wearable systems faces several challenges. First, effective model training for new wearable devices requires substantial labeled data from various subjects collected directly by the wearable. Second, subsequent model updates require further extensive labeled data for retraining. Finally, frequent model updating on the wearable device can decrease the battery life in long-term data monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a meta-learning method to reduce the amount of initial data collection required. Moreover, our approach incorporates a prototypical updating mechanism, simplifying the update process by modifying the class prototype rather than retraining the entire model. We explore the performance of MetaWearS in two case studies, namely, the detection of epileptic seizures and the detection of atrial fibrillation. We show that by fine-tuning with just a few samples, we achieve 70% and 82% AUC for the detection of epileptic seizures and the detection of atrial fibrillation, respectively. Compared to a conventional approach, our proposed method performs better with up to 45% AUC. Furthermore, updating the model with only 16 minutes of additional labeled data increases the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for model updates by 456x and 418x for epileptic seizure and AF detection, respectively.","sentences":["Wearable systems provide continuous health monitoring and can lead to early detection of potential health issues.","However, the lifecycle of wearable systems faces several challenges.","First, effective model training for new wearable devices requires substantial labeled data from various subjects collected directly by the wearable.","Second, subsequent model updates require further extensive labeled data for retraining.","Finally, frequent model updating on the wearable device can decrease the battery life in long-term data monitoring.","Addressing these challenges, in this paper, we propose MetaWearS, a meta-learning method to reduce the amount of initial data collection required.","Moreover, our approach incorporates a prototypical updating mechanism, simplifying the update process by modifying the class prototype rather than retraining the entire model.","We explore the performance of MetaWearS in two case studies, namely, the detection of epileptic seizures and the detection of atrial fibrillation.","We show that by fine-tuning with just a few samples, we achieve 70% and 82% AUC for the detection of epileptic seizures and the detection of atrial fibrillation, respectively.","Compared to a conventional approach, our proposed method performs better with up to 45% AUC.","Furthermore, updating the model with only 16 minutes of additional labeled data increases the AUC by up to 5.3%.","Finally, MetaWearS reduces the energy consumption for model updates by 456x and 418x for epileptic seizure and AF detection, respectively."],"url":"http://arxiv.org/abs/2408.01988v1"}
{"created":"2024-08-04 10:16:11","title":"Multiview learning with twin parametric margin SVM","abstract":"Multiview learning (MVL) seeks to leverage the benefits of diverse perspectives to complement each other, effectively extracting and utilizing the latent information within the dataset. Several twin support vector machine-based MVL (MvTSVM) models have been introduced and demonstrated outstanding performance in various learning tasks. However, MvTSVM-based models face significant challenges in the form of computational complexity due to four matrix inversions, the need to reformulate optimization problems in order to employ kernel-generated surfaces for handling non-linear cases, and the constraint of uniform noise assumption in the training data. Particularly in cases where the data possesses a heteroscedastic error structure, these challenges become even more pronounced. In view of the aforementioned challenges, we propose multiview twin parametric margin support vector machine (MvTPMSVM). MvTPMSVM constructs parametric hyperplanes with the goal of maximizing the parametric margin between two classes, aiming to regulate and manage the impact of the heteroscedastic noise structure existing within the data. The proposed MvTPMSVM model avoids the explicit computation of matrix inversions in the dual formulation, leading to enhanced computational efficiency. We perform an extensive assessment of the MvTPMSVM model using benchmark datasets such as UCI, KEEL, synthetic, and Animals with Attributes (AwA). Our experimental results, coupled with rigorous statistical analyses, confirm the superior generalization capabilities of the proposed MvTPMSVM model compared to the baseline models. The source code of the proposed MvTPMSVM model is available at \\url{https://github.com/mtanveer1/MvTPMSVM}.","sentences":["Multiview learning (MVL) seeks to leverage the benefits of diverse perspectives to complement each other, effectively extracting and utilizing the latent information within the dataset.","Several twin support vector machine-based MVL (MvTSVM) models have been introduced and demonstrated outstanding performance in various learning tasks.","However, MvTSVM-based models face significant challenges in the form of computational complexity due to four matrix inversions, the need to reformulate optimization problems in order to employ kernel-generated surfaces for handling non-linear cases, and the constraint of uniform noise assumption in the training data.","Particularly in cases where the data possesses a heteroscedastic error structure, these challenges become even more pronounced.","In view of the aforementioned challenges, we propose multiview twin parametric margin support vector machine (MvTPMSVM).","MvTPMSVM constructs parametric hyperplanes with the goal of maximizing the parametric margin between two classes, aiming to regulate and manage the impact of the heteroscedastic noise structure existing within the data.","The proposed MvTPMSVM model avoids the explicit computation of matrix inversions in the dual formulation, leading to enhanced computational efficiency.","We perform an extensive assessment of the MvTPMSVM model using benchmark datasets such as UCI, KEEL, synthetic, and Animals with Attributes (AwA).","Our experimental results, coupled with rigorous statistical analyses, confirm the superior generalization capabilities of the proposed MvTPMSVM model compared to the baseline models.","The source code of the proposed MvTPMSVM model is available at \\url{https://github.com/mtanveer1/MvTPMSVM}."],"url":"http://arxiv.org/abs/2408.01981v1"}
{"created":"2024-08-04 09:51:14","title":"Label Augmentation for Neural Networks Robustness","abstract":"Out-of-distribution generalization can be categorized into two types: common perturbations arising from natural variations in the real world and adversarial perturbations that are intentionally crafted to deceive neural networks. While deep neural networks excel in accuracy under the assumption of identical distributions between training and test data, they often encounter out-of-distribution scenarios resulting in a significant decline in accuracy. Data augmentation methods can effectively enhance robustness against common corruptions, but they typically fall short in improving robustness against adversarial perturbations. In this study, we develop Label Augmentation (LA), which enhances robustness against both common and intentional perturbations and improves uncertainty estimation. Our findings indicate a Clean error rate improvement of up to 23.29% when employing LA in comparisons to the baseline. Additionally, it enhances robustness under common corruptions benchmark by up to 24.23%. When tested against FGSM and PGD attacks, improvements in adversarial robustness are noticeable, with enhancements of up to 53.18% for FGSM and 24.46% for PGD attacks.","sentences":["Out-of-distribution generalization can be categorized into two types: common perturbations arising from natural variations in the real world and adversarial perturbations that are intentionally crafted to deceive neural networks.","While deep neural networks excel in accuracy under the assumption of identical distributions between training and test data, they often encounter out-of-distribution scenarios resulting in a significant decline in accuracy.","Data augmentation methods can effectively enhance robustness against common corruptions, but they typically fall short in improving robustness against adversarial perturbations.","In this study, we develop Label Augmentation (LA), which enhances robustness against both common and intentional perturbations and improves uncertainty estimation.","Our findings indicate a Clean error rate improvement of up to 23.29% when employing LA in comparisons to the baseline.","Additionally, it enhances robustness under common corruptions benchmark by up to 24.23%.","When tested against FGSM and PGD attacks, improvements in adversarial robustness are noticeable, with enhancements of up to 53.18% for FGSM and 24.46% for PGD attacks."],"url":"http://arxiv.org/abs/2408.01977v1"}
{"created":"2024-08-04 09:09:35","title":"SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning","abstract":"The ability of humans to rapidly learn new knowledge while retaining old memories poses a significant challenge for current deep learning models. To handle this challenge, we draw inspiration from human memory and learning mechanisms and propose the Self-Reflective Complementary Incremental System (SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and Complementary Memory Module (CMM), SR-CIS features a small model for fast inference and a large model for slow deliberation in CIM, enabled by the Confidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient collaboration. CMM consists of task-specific Short-Term Memory (STM) region and a universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank Adaptive (LoRA) and corresponding prototype weights and biases, it instantiates external storage for parameter and representation memory, thus deconstructing the memory module from the inference module. By storing textual descriptions of images during training and combining them with the Scenario Replay Module (SRM) post-training for memory combination, along with periodic short-to-long-term memory restructuring, SR-CIS achieves stable incremental memory with limited storage requirements. Balancing model plasticity and memory stability under constraints of limited storage and low data resources, SR-CIS surpasses existing competitive baselines on multiple standard and few-shot incremental learning benchmarks.","sentences":["The ability of humans to rapidly learn new knowledge while retaining old memories poses a significant challenge for current deep learning models.","To handle this challenge, we draw inspiration from human memory and learning mechanisms and propose the Self-Reflective Complementary Incremental System (SR-CIS).","Comprising the deconstructed Complementary Inference Module (CIM) and Complementary Memory Module (CMM), SR-CIS features a small model for fast inference and a large model for slow deliberation in CIM, enabled by the Confidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient collaboration.","CMM consists of task-specific Short-Term Memory (STM) region and a universal Long-Term Memory (LTM) region.","By setting task-specific Low-Rank Adaptive (LoRA) and corresponding prototype weights and biases, it instantiates external storage for parameter and representation memory, thus deconstructing the memory module from the inference module.","By storing textual descriptions of images during training and combining them with the Scenario Replay Module (SRM) post-training for memory combination, along with periodic short-to-long-term memory restructuring, SR-CIS achieves stable incremental memory with limited storage requirements.","Balancing model plasticity and memory stability under constraints of limited storage and low data resources, SR-CIS surpasses existing competitive baselines on multiple standard and few-shot incremental learning benchmarks."],"url":"http://arxiv.org/abs/2408.01970v1"}
{"created":"2024-08-04 09:08:55","title":"A multi-task deep learning approach for lane-level pavement performance prediction with segment-level data","abstract":"The elaborate pavement performance prediction is an important premise of implementing preventive maintenance. Our survey reveals that in practice, the pavement performance is usually measured at segment-level, where an unique performance value is obtained for all lanes within one segment of 1km length. It still lacks more elaborate performance analysis at lane-level due to costly data collection and difficulty in prediction modeling. Therefore, this study developed a multi-task deep learning approach to predict the lane-level pavement performance with a large amount of historical segment-level performance measurement data. The unified prediction framework can effectively address inherent correlation and differences across lanes. In specific, the prediction framework firstly employed an Long Short-Term Memory (LSTM) layer to capture the segment-level pavement deterioration pattern. Then multiple task-specific LSTM layers were designed based on number of lanes to capture lane-level differences in pavement performance. Finally, we concatenated multiple task-specific LSTM outputs with auxiliary features for further training and obtained the lane-level predictions after fully connected layer. The aforementioned prediction framework was validated with a real case in China. It revealed a better model performance regardless of one-way 2-lane, 3-lane, and 4-lane scenarios, all lower than 10% in terms of mean absolute percentage error. The proposed prediction framework also outperforms other ensemble learning and shallow machine learning methods in almost every lane.","sentences":["The elaborate pavement performance prediction is an important premise of implementing preventive maintenance.","Our survey reveals that in practice, the pavement performance is usually measured at segment-level, where an unique performance value is obtained for all lanes within one segment of 1km length.","It still lacks more elaborate performance analysis at lane-level due to costly data collection and difficulty in prediction modeling.","Therefore, this study developed a multi-task deep learning approach to predict the lane-level pavement performance with a large amount of historical segment-level performance measurement data.","The unified prediction framework can effectively address inherent correlation and differences across lanes.","In specific, the prediction framework firstly employed an Long Short-Term Memory (LSTM) layer to capture the segment-level pavement deterioration pattern.","Then multiple task-specific LSTM layers were designed based on number of lanes to capture lane-level differences in pavement performance.","Finally, we concatenated multiple task-specific LSTM outputs with auxiliary features for further training and obtained the lane-level predictions after fully connected layer.","The aforementioned prediction framework was validated with a real case in China.","It revealed a better model performance regardless of one-way 2-lane, 3-lane, and 4-lane scenarios, all lower than 10% in terms of mean absolute percentage error.","The proposed prediction framework also outperforms other ensemble learning and shallow machine learning methods in almost every lane."],"url":"http://arxiv.org/abs/2408.01967v1"}
{"created":"2024-08-04 08:44:00","title":"Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification","abstract":"Graph Neural Networks (GNNs) have attracted substantial interest due to their exceptional performance on graph-based data. However, their robustness, especially on heterogeneous graphs, remains underexplored, particularly against adversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion black-box attack method for heterogeneous graphs. By integrating reinforcement learning with a Top-K algorithm to reduce the action space, our method efficiently identifies effective attack strategies to disrupt node classification tasks. We validate the effectiveness of HeteroKRLAttack through experiments on multiple heterogeneous graph datasets, showing significant reductions in classification accuracy compared to baseline methods. An ablation study underscores the critical role of the Top-K algorithm in enhancing attack performance. Our findings highlight potential vulnerabilities in current models and provide guidance for future defense strategies against adversarial attacks on heterogeneous graphs.","sentences":["Graph Neural Networks (GNNs) have attracted substantial interest due to their exceptional performance on graph-based data.","However, their robustness, especially on heterogeneous graphs, remains underexplored, particularly against adversarial attacks.","This paper proposes HeteroKRLAttack, a targeted evasion black-box attack method for heterogeneous graphs.","By integrating reinforcement learning with a Top-K algorithm to reduce the action space, our method efficiently identifies effective attack strategies to disrupt node classification tasks.","We validate the effectiveness of HeteroKRLAttack through experiments on multiple heterogeneous graph datasets, showing significant reductions in classification accuracy compared to baseline methods.","An ablation study underscores the critical role of the Top-K algorithm in enhancing attack performance.","Our findings highlight potential vulnerabilities in current models and provide guidance for future defense strategies against adversarial attacks on heterogeneous graphs."],"url":"http://arxiv.org/abs/2408.01964v1"}
