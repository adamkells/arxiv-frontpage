{"created":"2023-12-11 18:59:58","title":"CAD: Photorealistic 3D Generation via Adversarial Distillation","abstract":"The increased demand for 3D data in AR/VR, robotics and gaming applications, gave rise to powerful generative pipelines capable of synthesizing high-quality 3D objects. Most of these models rely on the Score Distillation Sampling (SDS) algorithm to optimize a 3D representation such that the rendered image maintains a high likelihood as evaluated by a pre-trained diffusion model. However, finding a correct mode in the high-dimensional distribution produced by the diffusion model is challenging and often leads to issues such as over-saturation, over-smoothing, and Janus-like artifacts. In this paper, we propose a novel learning paradigm for 3D synthesis that utilizes pre-trained diffusion models. Instead of focusing on mode-seeking, our method directly models the distribution discrepancy between multi-view renderings and diffusion priors in an adversarial manner, which unlocks the generation of high-fidelity and photorealistic 3D content, conditioned on a single image and prompt. Moreover, by harnessing the latent space of GANs and expressive diffusion model priors, our method facilitates a wide variety of 3D applications including single-view reconstruction, high diversity generation and continuous 3D interpolation in the open domain. The experiments demonstrate the superiority of our pipeline compared to previous works in terms of generation quality and diversity.","sentences":["The increased demand for 3D data in AR/VR, robotics and gaming applications, gave rise to powerful generative pipelines capable of synthesizing high-quality 3D objects.","Most of these models rely on the Score Distillation Sampling (SDS) algorithm to optimize a 3D representation such that the rendered image maintains a high likelihood as evaluated by a pre-trained diffusion model.","However, finding a correct mode in the high-dimensional distribution produced by the diffusion model is challenging and often leads to issues such as over-saturation, over-smoothing, and Janus-like artifacts.","In this paper, we propose a novel learning paradigm for 3D synthesis that utilizes pre-trained diffusion models.","Instead of focusing on mode-seeking, our method directly models the distribution discrepancy between multi-view renderings and diffusion priors in an adversarial manner, which unlocks the generation of high-fidelity and photorealistic 3D content, conditioned on a single image and prompt.","Moreover, by harnessing the latent space of GANs and expressive diffusion model priors, our method facilitates a wide variety of 3D applications including single-view reconstruction, high diversity generation and continuous 3D interpolation in the open domain.","The experiments demonstrate the superiority of our pipeline compared to previous works in terms of generation quality and diversity."],"url":"http://arxiv.org/abs/2312.06663v1"}
{"created":"2023-12-11 18:59:35","title":"Mean estimation in the add-remove model of differential privacy","abstract":"Differential privacy is often studied under two different models of neighboring datasets: the add-remove model and the swap model. While the swap model is used extensively in the academic literature, many practical libraries use the more conservative add-remove model. However, analysis under the add-remove model can be cumbersome, and obtaining results with tight constants requires some additional work. Here, we study the problem of one-dimensional mean estimation under the add-remove model of differential privacy. We propose a new algorithm and show that it is min-max optimal, that it has the correct constant in the leading term of the mean squared error, and that this constant is the same as the optimal algorithm in the swap model. Our results show that, for mean estimation, the add-remove and swap model give nearly identical error even though the add-remove model cannot treat the size of the dataset as public information. In addition, we demonstrate empirically that our proposed algorithm yields a factor of two improvement in mean squared error over algorithms often used in practice.","sentences":["Differential privacy is often studied under two different models of neighboring datasets: the add-remove model and the swap model.","While the swap model is used extensively in the academic literature, many practical libraries use the more conservative add-remove model.","However, analysis under the add-remove model can be cumbersome, and obtaining results with tight constants requires some additional work.","Here, we study the problem of one-dimensional mean estimation under the add-remove model of differential privacy.","We propose a new algorithm and show that it is min-max optimal, that it has the correct constant in the leading term of the mean squared error, and that this constant is the same as the optimal algorithm in the swap model.","Our results show that, for mean estimation, the add-remove and swap model give nearly identical error even though the add-remove model cannot treat the size of the dataset as public information.","In addition, we demonstrate empirically that our proposed algorithm yields a factor of two improvement in mean squared error over algorithms often used in practice."],"url":"http://arxiv.org/abs/2312.06658v1"}
{"created":"2023-12-11 18:59:18","title":"Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior","abstract":"Recently, 3D content creation from text prompts has demonstrated remarkable progress by utilizing 2D and 3D diffusion models. While 3D diffusion models ensure great multi-view consistency, their ability to generate high-quality and diverse 3D assets is hindered by the limited 3D data. In contrast, 2D diffusion models find a distillation approach that achieves excellent generalization and rich details without any 3D data. However, 2D lifting methods suffer from inherent view-agnostic ambiguity thereby leading to serious multi-face Janus issues, where text prompts fail to provide sufficient guidance to learn coherent 3D results. Instead of retraining a costly viewpoint-aware model, we study how to fully exploit easily accessible coarse 3D knowledge to enhance the prompts and guide 2D lifting optimization for refinement. In this paper, we propose Sherpa3D, a new text-to-3D framework that achieves high-fidelity, generalizability, and geometric consistency simultaneously. Specifically, we design a pair of guiding strategies derived from the coarse 3D prior generated by the 3D diffusion model: a structural guidance for geometric fidelity and a semantic guidance for 3D coherence. Employing the two types of guidance, the 2D diffusion model enriches the 3D content with diversified and high-quality results. Extensive experiments show the superiority of our Sherpa3D over the state-of-the-art text-to-3D methods in terms of quality and 3D consistency.","sentences":["Recently, 3D content creation from text prompts has demonstrated remarkable progress by utilizing 2D and 3D diffusion models.","While 3D diffusion models ensure great multi-view consistency, their ability to generate high-quality and diverse 3D assets is hindered by the limited 3D data.","In contrast, 2D diffusion models find a distillation approach that achieves excellent generalization and rich details without any 3D data.","However, 2D lifting methods suffer from inherent view-agnostic ambiguity thereby leading to serious multi-face Janus issues, where text prompts fail to provide sufficient guidance to learn coherent 3D results.","Instead of retraining a costly viewpoint-aware model, we study how to fully exploit easily accessible coarse 3D knowledge to enhance the prompts and guide 2D lifting optimization for refinement.","In this paper, we propose Sherpa3D, a new text-to-3D framework that achieves high-fidelity, generalizability, and geometric consistency simultaneously.","Specifically, we design a pair of guiding strategies derived from the coarse 3D prior generated by the 3D diffusion model: a structural guidance for geometric fidelity and a semantic guidance for 3D coherence.","Employing the two types of guidance, the 2D diffusion model enriches the 3D content with diversified and high-quality results.","Extensive experiments show the superiority of our Sherpa3D over the state-of-the-art text-to-3D methods in terms of quality and 3D consistency."],"url":"http://arxiv.org/abs/2312.06655v1"}
{"created":"2023-12-11 18:59:13","title":"LightSim: Neural Lighting Simulation for Urban Scenes","abstract":"Different outdoor illumination conditions drastically alter the appearance of urban scenes, and they can harm the performance of image-based robot perception systems if not seen during training. Camera simulation provides a cost-effective solution to create a large dataset of images captured under different lighting conditions. Towards this goal, we propose LightSim, a neural lighting camera simulation system that enables diverse, realistic, and controllable data generation. LightSim automatically builds lighting-aware digital twins at scale from collected raw sensor data and decomposes the scene into dynamic actors and static background with accurate geometry, appearance, and estimated scene lighting. These digital twins enable actor insertion, modification, removal, and rendering from a new viewpoint, all in a lighting-aware manner. LightSim then combines physically-based and learnable deferred rendering to perform realistic relighting of modified scenes, such as altering the sun location and modifying the shadows or changing the sun brightness, producing spatially- and temporally-consistent camera videos. Our experiments show that LightSim generates more realistic relighting results than prior work. Importantly, training perception models on data generated by LightSim can significantly improve their performance.","sentences":["Different outdoor illumination conditions drastically alter the appearance of urban scenes, and they can harm the performance of image-based robot perception systems if not seen during training.","Camera simulation provides a cost-effective solution to create a large dataset of images captured under different lighting conditions.","Towards this goal, we propose LightSim, a neural lighting camera simulation system that enables diverse, realistic, and controllable data generation.","LightSim automatically builds lighting-aware digital twins at scale from collected raw sensor data and decomposes the scene into dynamic actors and static background with accurate geometry, appearance, and estimated scene lighting.","These digital twins enable actor insertion, modification, removal, and rendering from a new viewpoint, all in a lighting-aware manner.","LightSim then combines physically-based and learnable deferred rendering to perform realistic relighting of modified scenes, such as altering the sun location and modifying the shadows or changing the sun brightness, producing spatially- and temporally-consistent camera videos.","Our experiments show that LightSim generates more realistic relighting results than prior work.","Importantly, training perception models on data generated by LightSim can significantly improve their performance."],"url":"http://arxiv.org/abs/2312.06654v1"}
{"created":"2023-12-11 18:59:12","title":"Adaptive Human Trajectory Prediction via Latent Corridors","abstract":"Human trajectory prediction is typically posed as a zero-shot generalization problem: a predictor is learnt on a dataset of human motion in training scenes, and then deployed on unseen test scenes. While this paradigm has yielded tremendous progress, it fundamentally assumes that trends in human behavior within the deployment scene are constant over time. As such, current prediction models are unable to adapt to scene-specific transient human behaviors, such as crowds temporarily gathering to see buskers, pedestrians hurrying through the rain and avoiding puddles, or a protest breaking out. We formalize the problem of scene-specific adaptive trajectory prediction and propose a new adaptation approach inspired by prompt tuning called latent corridors. By augmenting the input of any pre-trained human trajectory predictor with learnable image prompts, the predictor can improve in the deployment scene by inferring trends from extremely small amounts of new data (e.g., 2 humans observed for 30 seconds). With less than 0.1% additional model parameters, we see up to 23.9% ADE improvement in MOTSynth simulated data and 16.4% ADE in MOT and Wildtrack real pedestrian data. Qualitatively, we observe that latent corridors imbue predictors with an awareness of scene geometry and scene-specific human behaviors that non-adaptive predictors struggle to capture. The project website can be found at https://neerja.me/atp_latent_corridors/.","sentences":["Human trajectory prediction is typically posed as a zero-shot generalization problem: a predictor is learnt on a dataset of human motion in training scenes, and then deployed on unseen test scenes.","While this paradigm has yielded tremendous progress, it fundamentally assumes that trends in human behavior within the deployment scene are constant over time.","As such, current prediction models are unable to adapt to scene-specific transient human behaviors, such as crowds temporarily gathering to see buskers, pedestrians hurrying through the rain and avoiding puddles, or a protest breaking out.","We formalize the problem of scene-specific adaptive trajectory prediction and propose a new adaptation approach inspired by prompt tuning called latent corridors.","By augmenting the input of any pre-trained human trajectory predictor with learnable image prompts, the predictor can improve in the deployment scene by inferring trends from extremely small amounts of new data (e.g., 2 humans observed for 30 seconds).","With less than 0.1% additional model parameters, we see up to 23.9% ADE improvement in MOTSynth simulated data and 16.4% ADE in MOT and Wildtrack real pedestrian data.","Qualitatively, we observe that latent corridors imbue predictors with an awareness of scene geometry and scene-specific human behaviors that non-adaptive predictors struggle to capture.","The project website can be found at https://neerja.me/atp_latent_corridors/."],"url":"http://arxiv.org/abs/2312.06653v1"}
{"created":"2023-12-11 18:57:20","title":"Computational Copyright: Towards A Royalty Model for AI Music Generation Platforms","abstract":"The advancement of generative AI has given rise to pressing copyright challenges, particularly in music industry. This paper focuses on the economic aspects of these challenges, emphasizing that the economic impact constitutes a central issue in the copyright arena. The complexity of the black-box generative AI technologies not only suggests but necessitates algorithmic solutions. However, such solutions have been largely missing, leading to regulatory challenges in this landscape. We aim to bridge the gap in current approaches by proposing potential royalty models for revenue sharing on AI music generation platforms. Our methodology involves a detailed analysis of existing royalty models in platforms like Spotify and YouTube, and adapting these to the unique context of AI-generated music. A significant challenge we address is the attribution of AI-generated music to influential copyrighted content in the training data. To this end, we present algorithmic solutions employing data attribution techniques. Our experimental results verify the effectiveness of these solutions. This research represents a pioneering effort in integrating technical advancements with economic and legal considerations in the field of generative AI, offering a computational copyright solution for the challenges posed by the opaque nature of AI technologies.","sentences":["The advancement of generative AI has given rise to pressing copyright challenges, particularly in music industry.","This paper focuses on the economic aspects of these challenges, emphasizing that the economic impact constitutes a central issue in the copyright arena.","The complexity of the black-box generative AI technologies not only suggests but necessitates algorithmic solutions.","However, such solutions have been largely missing, leading to regulatory challenges in this landscape.","We aim to bridge the gap in current approaches by proposing potential royalty models for revenue sharing on AI music generation platforms.","Our methodology involves a detailed analysis of existing royalty models in platforms like Spotify and YouTube, and adapting these to the unique context of AI-generated music.","A significant challenge we address is the attribution of AI-generated music to influential copyrighted content in the training data.","To this end, we present algorithmic solutions employing data attribution techniques.","Our experimental results verify the effectiveness of these solutions.","This research represents a pioneering effort in integrating technical advancements with economic and legal considerations in the field of generative AI, offering a computational copyright solution for the challenges posed by the opaque nature of AI technologies."],"url":"http://arxiv.org/abs/2312.06646v1"}
{"created":"2023-12-11 18:51:59","title":"Gated Linear Attention Transformers with Hardware-Efficient Training","abstract":"Transformers with linear attention allow for efficient parallel training but can simultaneously be formulated as an RNN with 2D (matrix-valued) hidden states, thus enjoying linear (with respect to output length) inference complexity. Recent works such as RetNet (Sun et al., 2023) and TransNormerLLM (Qin et al., 2023a) observe that adding a global decay term to the additive RNN update rule greatly improves performance, sometimes outperforming standard Transformers with softmax attention when trained at scale. In this work we show that adding a data-dependent gating mechanism further improves performance. We derive a parallel form of this gated linear attention layer that enables efficient training. However, a straightforward, numerically stable implementation of this parallel form requires generalized matrix multiplications in log-space for numerical stability, and thus cannot take advantage of tensor cores on modern GPUs which are optimized for standard matrix multiplications. We develop a hardware-efficient version of the parallel form that can still make use of tensor cores through block-parallel computations over sequence chunks. Experiments on moderate-scale language modeling (340M-parameter models trained on 15B tokens, 1.3B-parameter models trained on 100B tokens) show that gated linear attention (GLA) Transformers perform competitively against a strong LLaMA-architecture Transformer baseline (Touvron et al., 2023) as well as Mamba (Gu & Dao, 2023), a recently introduced state-space model with a data-dependent state transition mechanism. For training speed, our Triton-based implementation performs comparably to CUDA-optimized FlashAttention-2 (Dao, 2023) under the regular 2048 training length setting, while outperforming FlashAttention-2 when training on longer sequences beyond 4096.","sentences":["Transformers with linear attention allow for efficient parallel training but can simultaneously be formulated as an RNN with 2D (matrix-valued) hidden states, thus enjoying linear (with respect to output length) inference complexity.","Recent works such as RetNet (Sun et al., 2023) and TransNormerLLM (Qin et al., 2023a) observe that adding a global decay term to the additive RNN update rule greatly improves performance, sometimes outperforming standard Transformers with softmax attention when trained at scale.","In this work we show that adding a data-dependent gating mechanism further improves performance.","We derive a parallel form of this gated linear attention layer that enables efficient training.","However, a straightforward, numerically stable implementation of this parallel form requires generalized matrix multiplications in log-space for numerical stability, and thus cannot take advantage of tensor cores on modern GPUs which are optimized for standard matrix multiplications.","We develop a hardware-efficient version of the parallel form that can still make use of tensor cores through block-parallel computations over sequence chunks.","Experiments on moderate-scale language modeling (340M-parameter models trained on 15B tokens, 1.3B-parameter models trained on 100B tokens) show that gated linear attention (GLA) Transformers perform competitively against a strong LLaMA-architecture Transformer baseline (Touvron et al., 2023) as well as Mamba (Gu & Dao, 2023), a recently introduced state-space model with a data-dependent state transition mechanism.","For training speed, our Triton-based implementation performs comparably to CUDA-optimized FlashAttention-2 (Dao, 2023) under the regular 2048 training length setting, while outperforming FlashAttention-2","when training on longer sequences beyond 4096."],"url":"http://arxiv.org/abs/2312.06635v1"}
{"created":"2023-12-11 18:50:09","title":"TMT-VIS: Taxonomy-aware Multi-dataset Joint Training for Video Instance Segmentation","abstract":"Training on large-scale datasets can boost the performance of video instance segmentation while the annotated datasets for VIS are hard to scale up due to the high labor cost. What we possess are numerous isolated filed-specific datasets, thus, it is appealing to jointly train models across the aggregation of datasets to enhance data volume and diversity. However, due to the heterogeneity in category space, as mask precision increases with the data volume, simply utilizing multiple datasets will dilute the attention of models on different taxonomies. Thus, increasing the data scale and enriching taxonomy space while improving classification precision is important. In this work, we analyze that providing extra taxonomy information can help models concentrate on specific taxonomy, and propose our model named Taxonomy-aware Multi-dataset Joint Training for Video Instance Segmentation (TMT-VIS) to address this vital challenge. Specifically, we design a two-stage taxonomy aggregation module that first compiles taxonomy information from input videos and then aggregates these taxonomy priors into instance queries before the transformer decoder. We conduct extensive experimental evaluations on four popular and challenging benchmarks, including YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and UVO. Our model shows significant improvement over the baseline solutions, and sets new state-of-the-art records on all benchmarks. These appealing and encouraging results demonstrate the effectiveness and generality of our approach. The code is available at https://github.com/rkzheng99/TMT-VIS(https://github.com/rkzheng99/TMT-VIS)","sentences":["Training on large-scale datasets can boost the performance of video instance segmentation while the annotated datasets for VIS are hard to scale up due to the high labor cost.","What we possess are numerous isolated filed-specific datasets, thus, it is appealing to jointly train models across the aggregation of datasets to enhance data volume and diversity.","However, due to the heterogeneity in category space, as mask precision increases with the data volume, simply utilizing multiple datasets will dilute the attention of models on different taxonomies.","Thus, increasing the data scale and enriching taxonomy space while improving classification precision is important.","In this work, we analyze that providing extra taxonomy information can help models concentrate on specific taxonomy, and propose our model named Taxonomy-aware Multi-dataset Joint Training for Video Instance Segmentation (TMT-VIS) to address this vital challenge.","Specifically, we design a two-stage taxonomy aggregation module that first compiles taxonomy information from input videos and then aggregates these taxonomy priors into instance queries before the transformer decoder.","We conduct extensive experimental evaluations on four popular and challenging benchmarks, including YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and UVO.","Our model shows significant improvement over the baseline solutions, and sets new state-of-the-art records on all benchmarks.","These appealing and encouraging results demonstrate the effectiveness and generality of our approach.","The code is available at https://github.com/rkzheng99/TMT-VIS(https://github.com/rkzheng99/TMT-VIS)"],"url":"http://arxiv.org/abs/2312.06630v1"}
{"created":"2023-12-11 18:42:18","title":"AttenScribble: Attentive Similarity Learning for Scribble-Supervised Medical Image Segmentation","abstract":"The success of deep networks in medical image segmentation relies heavily on massive labeled training data. However, acquiring dense annotations is a time-consuming process. Weakly-supervised methods normally employ less expensive forms of supervision, among which scribbles started to gain popularity lately thanks to its flexibility. However, due to lack of shape and boundary information, it is extremely challenging to train a deep network on scribbles that generalizes on unlabeled pixels. In this paper, we present a straightforward yet effective scribble supervised learning framework. Inspired by recent advances of transformer based segmentation, we create a pluggable spatial self-attention module which could be attached on top of any internal feature layers of arbitrary fully convolutional network (FCN) backbone. The module infuses global interaction while keeping the efficiency of convolutions. Descended from this module, we construct a similarity metric based on normalized and symmetrized attention. This attentive similarity leads to a novel regularization loss that imposes consistency between segmentation prediction and visual affinity. This attentive similarity loss optimizes the alignment of FCN encoders, attention mapping and model prediction. Ultimately, the proposed FCN+Attention architecture can be trained end-to-end guided by a combination of three learning objectives: partial segmentation loss, a customized masked conditional random fields and the proposed attentive similarity loss. Extensive experiments on public datasets (ACDC and CHAOS) showed that our framework not just out-performs existing state-of-the-art, but also delivers close performance to fully-supervised benchmark. Code will be available upon publication.","sentences":["The success of deep networks in medical image segmentation relies heavily on massive labeled training data.","However, acquiring dense annotations is a time-consuming process.","Weakly-supervised methods normally employ less expensive forms of supervision, among which scribbles started to gain popularity lately thanks to its flexibility.","However, due to lack of shape and boundary information, it is extremely challenging to train a deep network on scribbles that generalizes on unlabeled pixels.","In this paper, we present a straightforward yet effective scribble supervised learning framework.","Inspired by recent advances of transformer based segmentation, we create a pluggable spatial self-attention module which could be attached on top of any internal feature layers of arbitrary fully convolutional network (FCN) backbone.","The module infuses global interaction while keeping the efficiency of convolutions.","Descended from this module, we construct a similarity metric based on normalized and symmetrized attention.","This attentive similarity leads to a novel regularization loss that imposes consistency between segmentation prediction and visual affinity.","This attentive similarity loss optimizes the alignment of FCN encoders, attention mapping and model prediction.","Ultimately, the proposed FCN+Attention architecture can be trained end-to-end guided by a combination of three learning objectives: partial segmentation loss, a customized masked conditional random fields and the proposed attentive similarity loss.","Extensive experiments on public datasets (ACDC and CHAOS) showed that our framework not just out-performs existing state-of-the-art, but also delivers close performance to fully-supervised benchmark.","Code will be available upon publication."],"url":"http://arxiv.org/abs/2312.06614v1"}
{"created":"2023-12-11 18:41:55","title":"Neural Text to Articulate Talk: Deep Text to Audiovisual Speech Synthesis achieving both Auditory and Photo-realism","abstract":"Recent advances in deep learning for sequential data have given rise to fast and powerful models that produce realistic videos of talking humans. The state of the art in talking face generation focuses mainly on lip-syncing, being conditioned on audio clips. However, having the ability to synthesize talking humans from text transcriptions rather than audio is particularly beneficial for many applications and is expected to receive more and more attention, following the recent breakthroughs in large language models. For that, most methods implement a cascaded 2-stage architecture of a text-to-speech module followed by an audio-driven talking face generator, but this ignores the highly complex interplay between audio and visual streams that occurs during speaking. In this paper, we propose the first, to the best of our knowledge, text-driven audiovisual speech synthesizer that uses Transformers and does not follow a cascaded approach. Our method, which we call NEUral Text to ARticulate Talk (NEUTART), is a talking face generator that uses a joint audiovisual feature space, as well as speech-informed 3D facial reconstructions and a lip-reading loss for visual supervision. The proposed model produces photorealistic talking face videos with human-like articulation and well-synced audiovisual streams. Our experiments on audiovisual datasets as well as in-the-wild videos reveal state-of-the-art generation quality both in terms of objective metrics and human evaluation.","sentences":["Recent advances in deep learning for sequential data have given rise to fast and powerful models that produce realistic videos of talking humans.","The state of the art in talking face generation focuses mainly on lip-syncing, being conditioned on audio clips.","However, having the ability to synthesize talking humans from text transcriptions rather than audio is particularly beneficial for many applications and is expected to receive more and more attention, following the recent breakthroughs in large language models.","For that, most methods implement a cascaded 2-stage architecture of a text-to-speech module followed by an audio-driven talking face generator, but this ignores the highly complex interplay between audio and visual streams that occurs during speaking.","In this paper, we propose the first, to the best of our knowledge, text-driven audiovisual speech synthesizer that uses Transformers and does not follow a cascaded approach.","Our method, which we call NEUral Text to ARticulate Talk (NEUTART), is a talking face generator that uses a joint audiovisual feature space, as well as speech-informed 3D facial reconstructions and a lip-reading loss for visual supervision.","The proposed model produces photorealistic talking face videos with human-like articulation and well-synced audiovisual streams.","Our experiments on audiovisual datasets as well as in-the-wild videos reveal state-of-the-art generation quality both in terms of objective metrics and human evaluation."],"url":"http://arxiv.org/abs/2312.06613v1"}
{"created":"2023-12-11 18:28:55","title":"Mitigating Perspective Distortion-induced Shape Ambiguity in Image Crops","abstract":"Objects undergo varying amounts of perspective distortion as they move across a camera's field of view. Models for predicting 3D from a single image often work with crops around the object of interest and ignore the location of the object in the camera's field of view. We note that ignoring this location information further exaggerates the inherent ambiguity in making 3D inferences from 2D images and can prevent models from even fitting to the training data. To mitigate this ambiguity, we propose Intrinsics-Aware Positional Encoding (KPE), which incorporates information about the location of crops in the image and camera intrinsics. Experiments on three popular 3D-from-a-single-image benchmarks: depth prediction on NYU, 3D object detection on KITTI & nuScenes, and predicting 3D shapes of articulated objects on ARCTIC, show the benefits of KPE.","sentences":["Objects undergo varying amounts of perspective distortion as they move across a camera's field of view.","Models for predicting 3D from a single image often work with crops around the object of interest and ignore the location of the object in the camera's field of view.","We note that ignoring this location information further exaggerates the inherent ambiguity in making 3D inferences from 2D images and can prevent models from even fitting to the training data.","To mitigate this ambiguity, we propose Intrinsics-Aware Positional Encoding (KPE), which incorporates information about the location of crops in the image and camera intrinsics.","Experiments on three popular 3D-from-a-single-image benchmarks: depth prediction on NYU, 3D object detection on KITTI & nuScenes, and predicting 3D shapes of articulated objects on ARCTIC, show the benefits of KPE."],"url":"http://arxiv.org/abs/2312.06594v1"}
{"created":"2023-12-11 18:27:42","title":"Flexible visual prompts for in-context learning in computer vision","abstract":"In this work, we address in-context learning (ICL) for the task of image segmentation, introducing a novel approach that adapts a modern Video Object Segmentation (VOS) technique for visual in-context learning. This adaptation is inspired by the VOS method's ability to efficiently and flexibly learn objects from a few examples. Through evaluations across a range of support set sizes and on diverse segmentation datasets, our method consistently surpasses existing techniques. Notably, it excels with data containing classes not encountered during training. Additionally, we propose a technique for support set selection, which involves choosing the most relevant images to include in this set. By employing support set selection, the performance increases for all tested methods without the need for additional training or prompt tuning. The code can be found at https://github.com/v7labs/XMem_ICL/.","sentences":["In this work, we address in-context learning (ICL) for the task of image segmentation, introducing a novel approach that adapts a modern Video Object Segmentation (VOS) technique for visual in-context learning.","This adaptation is inspired by the VOS method's ability to efficiently and flexibly learn objects from a few examples.","Through evaluations across a range of support set sizes and on diverse segmentation datasets, our method consistently surpasses existing techniques.","Notably, it excels with data containing classes not encountered during training.","Additionally, we propose a technique for support set selection, which involves choosing the most relevant images to include in this set.","By employing support set selection, the performance increases for all tested methods without the need for additional training or prompt tuning.","The code can be found at https://github.com/v7labs/XMem_ICL/."],"url":"http://arxiv.org/abs/2312.06592v1"}
{"created":"2023-12-11 18:17:43","title":"Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models","abstract":"Fine-tuning language models~(LMs) on human-generated data remains a prevalent practice. However, the performance of such models is often limited by the quantity and diversity of high-quality human data. In this paper, we explore whether we can go beyond human data on tasks where we have access to scalar feedback, for example, on math problems where one can verify correctness. To do so, we investigate a simple self-training method based on expectation-maximization, which we call ReST$^{EM}$, where we (1) generate samples from the model and filter them using binary feedback, (2) fine-tune the model on these samples, and (3) repeat this process a few times. Testing on advanced MATH reasoning and APPS coding benchmarks using PaLM-2 models, we find that ReST$^{EM}$ scales favorably with model size and significantly surpasses fine-tuning only on human data. Overall, our findings suggest self-training with feedback can substantially reduce dependence on human-generated data.","sentences":["Fine-tuning language models~(LMs) on human-generated data remains a prevalent practice.","However, the performance of such models is often limited by the quantity and diversity of high-quality human data.","In this paper, we explore whether we can go beyond human data on tasks where we have access to scalar feedback, for example, on math problems where one can verify correctness.","To do so, we investigate a simple self-training method based on expectation-maximization, which we call ReST$^{EM}$, where we (1) generate samples from the model and filter them using binary feedback, (2) fine-tune the model on these samples, and (3) repeat this process a few times.","Testing on advanced MATH reasoning and APPS coding benchmarks using PaLM-2 models, we find that ReST$^{EM}$ scales favorably with model size and significantly surpasses fine-tuning only on human data.","Overall, our findings suggest self-training with feedback can substantially reduce dependence on human-generated data."],"url":"http://arxiv.org/abs/2312.06585v1"}
{"created":"2023-12-11 18:15:47","title":"3D Hand Pose Estimation in Egocentric Images in the Wild","abstract":"We present WildHands, a method for 3D hand pose estimation in egocentric images in the wild. This is challenging due to (a) lack of 3D hand pose annotations for images in the wild, and (b) a form of perspective distortion-induced shape ambiguity that arises in the analysis of crops around hands. For the former, we use auxiliary supervision on in-the-wild data in the form of segmentation masks & grasp labels in addition to 3D supervision available in lab datasets. For the latter, we provide spatial cues about the location of the hand crop in the camera's field of view. Our approach achieves the best 3D hand pose on the ARCTIC leaderboard and outperforms FrankMocap, a popular and robust approach for estimating hand pose in the wild, by 45.3% when evaluated on 2D hand pose on our EPIC-HandKps dataset.","sentences":["We present WildHands, a method for 3D hand pose estimation in egocentric images in the wild.","This is challenging due to (a) lack of 3D hand pose annotations for images in the wild, and (b) a form of perspective distortion-induced shape ambiguity that arises in the analysis of crops around hands.","For the former, we use auxiliary supervision on in-the-wild data in the form of segmentation masks & grasp labels in addition to 3D supervision available in lab datasets.","For the latter, we provide spatial cues about the location of the hand crop in the camera's field of view.","Our approach achieves the best 3D hand pose on the ARCTIC leaderboard and outperforms FrankMocap, a popular and robust approach for estimating hand pose in the wild, by 45.3% when evaluated on 2D hand pose on our EPIC-HandKps dataset."],"url":"http://arxiv.org/abs/2312.06583v1"}
{"created":"2023-12-11 18:12:18","title":"Grokking Group Multiplication with Cosets","abstract":"We use the group Fourier transform over the symmetric group $S_n$ to reverse engineer a 1-layer feedforward network that has \"grokked\" the multiplication of $S_5$ and $S_6$. Each model discovers the true subgroup structure of the full group and converges on circuits that decompose the group multiplication into the multiplication of the group's conjugate subgroups. We demonstrate the value of using the symmetries of the data and models to understand their mechanisms and hold up the ``coset circuit'' that the model uses as a fascinating example of the way neural networks implement computations. We also draw attention to current challenges in conducting mechanistic interpretability research by comparing our work to Chughtai et al. [6] which alleges to find a different algorithm for this same problem.","sentences":["We use the group Fourier transform over the symmetric group $S_n$ to reverse engineer a 1-layer feedforward network that has \"grokked\" the multiplication of $S_5$ and $S_6$. Each model discovers the true subgroup structure of the full group and converges on circuits that decompose the group multiplication into the multiplication of the group's conjugate subgroups.","We demonstrate the value of using the symmetries of the data and models to understand their mechanisms and hold up the ``coset circuit'' that the model uses as a fascinating example of the way neural networks implement computations.","We also draw attention to current challenges in conducting mechanistic interpretability research by comparing our work to Chughtai et al.","[6] which alleges to find a different algorithm for this same problem."],"url":"http://arxiv.org/abs/2312.06581v1"}
{"created":"2023-12-11 18:00:27","title":"HyPE-GT: where Graph Transformers meet Hyperbolic Positional Encodings","abstract":"Graph Transformers (GTs) facilitate the comprehension of graph-structured data by calculating the self-attention of node pairs without considering node position information. To address this limitation, we introduce an innovative and efficient framework that introduces Positional Encodings (PEs) into the Transformer, generating a set of learnable positional encodings in the hyperbolic space, a non-Euclidean domain. This approach empowers us to explore diverse options for optimal selection of PEs for specific downstream tasks, leveraging hyperbolic neural networks or hyperbolic graph convolutional networks. Additionally, we repurpose these positional encodings to mitigate the impact of over-smoothing in deep Graph Neural Networks (GNNs). Comprehensive experiments on molecular benchmark datasets, co-author, and co-purchase networks substantiate the effectiveness of hyperbolic positional encodings in enhancing the performance of deep GNNs.","sentences":["Graph Transformers (GTs) facilitate the comprehension of graph-structured data by calculating the self-attention of node pairs without considering node position information.","To address this limitation, we introduce an innovative and efficient framework that introduces Positional Encodings (PEs) into the Transformer, generating a set of learnable positional encodings in the hyperbolic space, a non-Euclidean domain.","This approach empowers us to explore diverse options for optimal selection of PEs for specific downstream tasks, leveraging hyperbolic neural networks or hyperbolic graph convolutional networks.","Additionally, we repurpose these positional encodings to mitigate the impact of over-smoothing in deep Graph Neural Networks (GNNs).","Comprehensive experiments on molecular benchmark datasets, co-author, and co-purchase networks substantiate the effectiveness of hyperbolic positional encodings in enhancing the performance of deep GNNs."],"url":"http://arxiv.org/abs/2312.06576v1"}
{"created":"2023-12-11 17:59:46","title":"EasyVolcap: Accelerating Neural Volumetric Video Research","abstract":"Volumetric video is a technology that digitally records dynamic events such as artistic performances, sporting events, and remote conversations. When acquired, such volumography can be viewed from any viewpoint and timestamp on flat screens, 3D displays, or VR headsets, enabling immersive viewing experiences and more flexible content creation in a variety of applications such as sports broadcasting, video conferencing, gaming, and movie productions. With the recent advances and fast-growing interest in neural scene representations for volumetric video, there is an urgent need for a unified open-source library to streamline the process of volumetric video capturing, reconstruction, and rendering for both researchers and non-professional users to develop various algorithms and applications of this emerging technology. In this paper, we present EasyVolcap, a Python & Pytorch library for accelerating neural volumetric video research with the goal of unifying the process of multi-view data processing, 4D scene reconstruction, and efficient dynamic volumetric video rendering. Our source code is available at https://github.com/zju3dv/EasyVolcap.","sentences":["Volumetric video is a technology that digitally records dynamic events such as artistic performances, sporting events, and remote conversations.","When acquired, such volumography can be viewed from any viewpoint and timestamp on flat screens, 3D displays, or VR headsets, enabling immersive viewing experiences and more flexible content creation in a variety of applications such as sports broadcasting, video conferencing, gaming, and movie productions.","With the recent advances and fast-growing interest in neural scene representations for volumetric video, there is an urgent need for a unified open-source library to streamline the process of volumetric video capturing, reconstruction, and rendering for both researchers and non-professional users to develop various algorithms and applications of this emerging technology.","In this paper, we present EasyVolcap, a Python & Pytorch library for accelerating neural volumetric video research with the goal of unifying the process of multi-view data processing, 4D scene reconstruction, and efficient dynamic volumetric video rendering.","Our source code is available at https://github.com/zju3dv/EasyVolcap."],"url":"http://arxiv.org/abs/2312.06575v1"}
{"created":"2023-12-11 17:58:13","title":"Dissecting the EIP-2930 Optional Access Lists","abstract":"Ethereum introduced Transaction Access Lists (TALs) in 2020 to optimize gas costs during transaction execution. In this work, we present a comprehensive analysis of TALs in Ethereum, focusing on adoption, quality, and gas savings. Analyzing a full month of mainnet data with 31,954,474 transactions, we found that only 1.46% of transactions included a TAL, even though 42.6% of transactions would have benefited from it. On average, access lists can save around 0.29% of gas costs, equivalent to approximately 3,450 ETH (roughly US$ 5 Mio) per year. However, 19.6% of TALs included by transactions contained imperfections, causing almost 11.8% of transactions to pay more gas with TAL than without. We find that these inaccuracies are caused by the unknown state at the time of the TAL computation as well as imperfect TAL computations provided by all major Ethereum clients. We thus compare the gas savings when calculating the TAL at the beginning of the block vs. calculating it on the correct state, to find that the unknown state is a major source of TAL inaccuracies. Finally, we implement an ideal TAL computation for the Erigon client to highlight the cost of these flawed implementations.","sentences":["Ethereum introduced Transaction Access Lists (TALs) in 2020 to optimize gas costs during transaction execution.","In this work, we present a comprehensive analysis of TALs in Ethereum, focusing on adoption, quality, and gas savings.","Analyzing a full month of mainnet data with 31,954,474 transactions, we found that only 1.46% of transactions included a TAL, even though 42.6% of transactions would have benefited from it.","On average, access lists can save around 0.29% of gas costs, equivalent to approximately 3,450 ETH (roughly US$ 5 Mio) per year.","However, 19.6% of TALs included by transactions contained imperfections, causing almost 11.8% of transactions to pay more gas with TAL than without.","We find that these inaccuracies are caused by the unknown state at the time of the TAL computation as well as imperfect TAL computations provided by all major Ethereum clients.","We thus compare the gas savings when calculating the TAL at the beginning of the block vs. calculating it on the correct state, to find that the unknown state is a major source of TAL inaccuracies.","Finally, we implement an ideal TAL computation for the Erigon client to highlight the cost of these flawed implementations."],"url":"http://arxiv.org/abs/2312.06574v1"}
{"created":"2023-12-11 17:51:56","title":"One Size Does not Fit All: Personalised Affordance Design for Social Robots","abstract":"Personalisation is essential to achieve more acceptable and effective results in human-robot interaction. Placing users in the central role, many studies have focused on enhancing the abilities of social robots to perceive and understand users. However, little is known about improving user perceptions and interpretation of a social robot in spoken interactions. The work described in the paper aims to find out what affects the personalisation of affordance of a social robot, namely its appearance, voice and language behaviours. The experimental data presented here is based on an ongoing project. It demonstrates the many and varied ways in which people change their preferences for the affordance of a social robot under different circumstances. It also examines the relationship between such preferences and expectations of characteristics of a social robot, like competence and warmth. It also shows that individuals have different perceptions of the language behaviours of the same robot. These results demonstrate that one-sized personalisation does not fit all. Personalisation should be considered a comprehensive approach, including appropriate affordance design, to suit the user expectations of social roles.","sentences":["Personalisation is essential to achieve more acceptable and effective results in human-robot interaction.","Placing users in the central role, many studies have focused on enhancing the abilities of social robots to perceive and understand users.","However, little is known about improving user perceptions and interpretation of a social robot in spoken interactions.","The work described in the paper aims to find out what affects the personalisation of affordance of a social robot, namely its appearance, voice and language behaviours.","The experimental data presented here is based on an ongoing project.","It demonstrates the many and varied ways in which people change their preferences for the affordance of a social robot under different circumstances.","It also examines the relationship between such preferences and expectations of characteristics of a social robot, like competence and warmth.","It also shows that individuals have different perceptions of the language behaviours of the same robot.","These results demonstrate that one-sized personalisation does not fit all.","Personalisation should be considered a comprehensive approach, including appropriate affordance design, to suit the user expectations of social roles."],"url":"http://arxiv.org/abs/2312.06566v1"}
{"created":"2023-12-11 17:43:58","title":"Deep Photonic Reservoir Computer for Speech Recognition","abstract":"Speech recognition is a critical task in the field of artificial intelligence and has witnessed remarkable advancements thanks to large and complex neural networks, whose training process typically requires massive amounts of labeled data and computationally intensive operations. An alternative paradigm, reservoir computing, is energy efficient and is well adapted to implementation in physical substrates, but exhibits limitations in performance when compared to more resource-intensive machine learning algorithms. In this work we address this challenge by investigating different architectures of interconnected reservoirs, all falling under the umbrella of deep reservoir computing. We propose a photonic-based deep reservoir computer and evaluate its effectiveness on different speech recognition tasks. We show specific design choices that aim to simplify the practical implementation of a reservoir computer while simultaneously achieving high-speed processing of high-dimensional audio signals. Overall, with the present work we hope to help the advancement of low-power and high-performance neuromorphic hardware.","sentences":["Speech recognition is a critical task in the field of artificial intelligence and has witnessed remarkable advancements thanks to large and complex neural networks, whose training process typically requires massive amounts of labeled data and computationally intensive operations.","An alternative paradigm, reservoir computing, is energy efficient and is well adapted to implementation in physical substrates, but exhibits limitations in performance when compared to more resource-intensive machine learning algorithms.","In this work we address this challenge by investigating different architectures of interconnected reservoirs, all falling under the umbrella of deep reservoir computing.","We propose a photonic-based deep reservoir computer and evaluate its effectiveness on different speech recognition tasks.","We show specific design choices that aim to simplify the practical implementation of a reservoir computer while simultaneously achieving high-speed processing of high-dimensional audio signals.","Overall, with the present work we hope to help the advancement of low-power and high-performance neuromorphic hardware."],"url":"http://arxiv.org/abs/2312.06558v1"}
{"created":"2023-12-11 17:40:23","title":"Open Data-Driven Automation of Residential Distribution Grid Modeling with Minimal Data Requirements","abstract":"In the present paper, we introduce a new method for the automated generation of residential distribution grid models based on novel building load estimation methods and a two-stage optimization for the generation of the 20 kV and 400 V grid topologies. Using the introduced load estimation methods, various open or proprietary data sources can be utilized to estimate the load of residential buildings. These data sources include available building footprints from OpenStreetMap, 3D building data from OSM Buildings, and the number of electricity meters per address provided by the respective distribution system operator (DSO).   For the evaluation of the introduced methods, we compare the resulting grid models by utilizing different available data sources for a specific suburban residential area and the real grid topology provided by the DSO. This evaluation yields two key findings: First, the automated 20 kV network generation methodology works well when compared to the real network. Second, the utilization of public 3D building data for load estimation significantly increases the resulting model accuracy compared to 2D data and enables results similar to models based on DSO-supplied meter data. This substantially reduces the dependence on such normally proprietary data.","sentences":["In the present paper, we introduce a new method for the automated generation of residential distribution grid models based on novel building load estimation methods and a two-stage optimization for the generation of the 20 kV and 400 V grid topologies.","Using the introduced load estimation methods, various open or proprietary data sources can be utilized to estimate the load of residential buildings.","These data sources include available building footprints from OpenStreetMap, 3D building data from OSM Buildings, and the number of electricity meters per address provided by the respective distribution system operator (DSO).   ","For the evaluation of the introduced methods, we compare the resulting grid models by utilizing different available data sources for a specific suburban residential area and the real grid topology provided by the DSO.","This evaluation yields two key findings:","First, the automated 20 kV network generation methodology works well when compared to the real network.","Second, the utilization of public 3D building data for load estimation significantly increases the resulting model accuracy compared to 2D data and enables results similar to models based on DSO-supplied meter data.","This substantially reduces the dependence on such normally proprietary data."],"url":"http://arxiv.org/abs/2312.06552v1"}
{"created":"2023-12-11 17:39:00","title":"LLM360: Towards Fully Transparent Open-Source LLMs","abstract":"The recent surge in open-source Large Language Models (LLMs), such as LLaMA, Falcon, and Mistral, provides diverse options for AI practitioners and researchers. However, most LLMs have only released partial artifacts, such as the final model weights or inference code, and technical reports increasingly limit their scope to high-level design choices and surface statistics. These choices hinder progress in the field by degrading transparency into the training of LLMs and forcing teams to rediscover many details in the training process. We present LLM360, an initiative to fully open-source LLMs, which advocates for all training code and data, model checkpoints, and intermediate results to be made available to the community. The goal of LLM360 is to support open and collaborative AI research by making the end-to-end LLM training process transparent and reproducible by everyone. As a first step of LLM360, we release two 7B parameter LLMs pre-trained from scratch, Amber and CrystalCoder, including their training code, data, intermediate checkpoints, and analyses (at https://www.llm360.ai). We are committed to continually pushing the boundaries of LLMs through this open-source effort. More large-scale and stronger models are underway and will be released in the future.","sentences":["The recent surge in open-source Large Language Models (LLMs), such as LLaMA, Falcon, and Mistral, provides diverse options for AI practitioners and researchers.","However, most LLMs have only released partial artifacts, such as the final model weights or inference code, and technical reports increasingly limit their scope to high-level design choices and surface statistics.","These choices hinder progress in the field by degrading transparency into the training of LLMs and forcing teams to rediscover many details in the training process.","We present LLM360, an initiative to fully open-source LLMs, which advocates for all training code and data, model checkpoints, and intermediate results to be made available to the community.","The goal of LLM360 is to support open and collaborative AI research by making the end-to-end LLM training process transparent and reproducible by everyone.","As a first step of LLM360, we release two 7B parameter LLMs pre-trained from scratch, Amber and CrystalCoder, including their training code, data, intermediate checkpoints, and analyses (at https://www.llm360.ai).","We are committed to continually pushing the boundaries of LLMs through this open-source effort.","More large-scale and stronger models are underway and will be released in the future."],"url":"http://arxiv.org/abs/2312.06550v1"}
{"created":"2023-12-11 17:31:46","title":"Unsupervised KPIs-Based Clustering of Jobs in HPC Data Centers","abstract":"Performance analysis is an essential task in High-Performance Computing (HPC) systems and it is applied for different purposes such as anomaly detection, optimal resource allocation, and budget planning. HPC monitoring tasks generate a huge number of Key Performance Indicators (KPIs) to supervise the status of the jobs running in these systems. KPIs give data about CPU usage, memory usage, network (interface) traffic, or other sensors that monitor the hardware. Analyzing this data, it is possible to obtain insightful information about running jobs, such as their characteristics, performance, and failures. The main contribution in this paper is to identify which metric/s (KPIs) is/are the most appropriate to identify/classify different types of jobs according to their behavior in the HPC system. With this aim, we have applied different clustering techniques (partition and hierarchical clustering algorithms) using a real dataset from the Galician Computation Center (CESGA). We have concluded that (i) those metrics (KPIs) related to the Network (interface) traffic monitoring provide the best cohesion and separation to cluster HPC jobs, and (ii) hierarchical clustering algorithms are the most suitable for this task. Our approach was validated using a different real dataset from the same HPC center.","sentences":["Performance analysis is an essential task in High-Performance Computing (HPC) systems and it is applied for different purposes such as anomaly detection, optimal resource allocation, and budget planning.","HPC monitoring tasks generate a huge number of Key Performance Indicators (KPIs) to supervise the status of the jobs running in these systems.","KPIs give data about CPU usage, memory usage, network (interface) traffic, or other sensors that monitor the hardware.","Analyzing this data, it is possible to obtain insightful information about running jobs, such as their characteristics, performance, and failures.","The main contribution in this paper is to identify which metric/s (KPIs) is/are the most appropriate to identify/classify different types of jobs according to their behavior in the HPC system.","With this aim, we have applied different clustering techniques (partition and hierarchical clustering algorithms) using a real dataset from the Galician Computation Center (CESGA).","We have concluded that (i) those metrics (KPIs) related to the Network (interface) traffic monitoring provide the best cohesion and separation to cluster HPC jobs, and (ii) hierarchical clustering algorithms are the most suitable for this task.","Our approach was validated using a different real dataset from the same HPC center."],"url":"http://arxiv.org/abs/2312.06546v1"}
{"created":"2023-12-11 17:13:54","title":"KPIs-Based Clustering and Visualization of HPC jobs: a Feature Reduction Approach","abstract":"High-Performance Computing (HPC) systems need to be constantly monitored to ensure their stability. The monitoring systems collect a tremendous amount of data about different parameters or Key Performance Indicators (KPIs), such as resource usage, IO waiting time, etc. A proper analysis of this data, usually stored as time series, can provide insight in choosing the right management strategies as well as the early detection of issues. In this paper, we introduce a methodology to cluster HPC jobs according to their KPI indicators. Our approach reduces the inherent high dimensionality of the collected data by applying two techniques to the time series: literature-based and variance-based feature extraction. We also define a procedure to visualize the obtained clusters by combining the two previous approaches and the Principal Component Analysis (PCA). Finally, we have validated our contributions on a real data set to conclude that those KPIs related to CPU usage provide the best cohesion and separation for clustering analysis and the good results of our visualization methodology.","sentences":["High-Performance Computing (HPC) systems need to be constantly monitored to ensure their stability.","The monitoring systems collect a tremendous amount of data about different parameters or Key Performance Indicators (KPIs), such as resource usage, IO waiting time, etc.","A proper analysis of this data, usually stored as time series, can provide insight in choosing the right management strategies as well as the early detection of issues.","In this paper, we introduce a methodology to cluster HPC jobs according to their KPI indicators.","Our approach reduces the inherent high dimensionality of the collected data by applying two techniques to the time series: literature-based and variance-based feature extraction.","We also define a procedure to visualize the obtained clusters by combining the two previous approaches and the Principal Component Analysis (PCA).","Finally, we have validated our contributions on a real data set to conclude that those KPIs related to CPU usage provide the best cohesion and separation for clustering analysis and the good results of our visualization methodology."],"url":"http://arxiv.org/abs/2312.06534v1"}
{"created":"2023-12-11 16:52:20","title":"A GAN Approach for Node Embedding in Heterogeneous Graphs Using Subgraph Sampling","abstract":"Our research addresses class imbalance issues in heterogeneous graphs using graph neural networks (GNNs). We propose a novel method combining the strengths of Generative Adversarial Networks (GANs) with GNNs, creating synthetic nodes and edges that effectively balance the dataset. This approach directly targets and rectifies imbalances at the data level. The proposed framework resolves issues such as neglecting graph structures during data generation and creating synthetic structures usable with GNN-based classifiers in downstream tasks. It processes node and edge information concurrently, improving edge balance through node augmentation and subgraph sampling. Additionally, our framework integrates a threshold strategy, aiding in determining optimal edge thresholds during training without time-consuming parameter adjustments. Experiments on the Amazon and Yelp Review datasets highlight the effectiveness of the framework we proposed, especially in minority node identification, where it consistently outperforms baseline models across key performance metrics, demonstrating its potential in the field.","sentences":["Our research addresses class imbalance issues in heterogeneous graphs using graph neural networks (GNNs).","We propose a novel method combining the strengths of Generative Adversarial Networks (GANs) with GNNs, creating synthetic nodes and edges that effectively balance the dataset.","This approach directly targets and rectifies imbalances at the data level.","The proposed framework resolves issues such as neglecting graph structures during data generation and creating synthetic structures usable with GNN-based classifiers in downstream tasks.","It processes node and edge information concurrently, improving edge balance through node augmentation and subgraph sampling.","Additionally, our framework integrates a threshold strategy, aiding in determining optimal edge thresholds during training without time-consuming parameter adjustments.","Experiments on the Amazon and Yelp Review datasets highlight the effectiveness of the framework we proposed, especially in minority node identification, where it consistently outperforms baseline models across key performance metrics, demonstrating its potential in the field."],"url":"http://arxiv.org/abs/2312.06519v1"}
{"created":"2023-12-11 16:46:57","title":"Facilitating Digital Agriculture with Simple Databases","abstract":"As an on-ramp to databases, we offer several well-structured private database templates as open source resources for agriculturalists, particularly those with modest spreadsheet skills. These farmer-oriented Air table databases use simple data-validated forms, with the look and feel of a customized app, to yield operational data that is tidy, machine- and human-readable, editable, and exportable for analysis in other software. Such data can facilitate logistics, provide contextual metadata, and improve enterprise analysis. A recorded workshop explaining how to build a database for activity records is presented. These resources may facilitate infusion of digital agriculture principles through Extension and structured educational programming.","sentences":["As an on-ramp to databases, we offer several well-structured private database templates as open source resources for agriculturalists, particularly those with modest spreadsheet skills.","These farmer-oriented Air table databases use simple data-validated forms, with the look and feel of a customized app, to yield operational data that is tidy, machine- and human-readable, editable, and exportable for analysis in other software.","Such data can facilitate logistics, provide contextual metadata, and improve enterprise analysis.","A recorded workshop explaining how to build a database for activity records is presented.","These resources may facilitate infusion of digital agriculture principles through Extension and structured educational programming."],"url":"http://arxiv.org/abs/2312.06517v1"}
{"created":"2023-12-11 16:31:55","title":"Grounded Question-Answering in Long Egocentric Videos","abstract":"Existing approaches to video understanding, mainly designed for short videos from a third-person perspective, are limited in their applicability in certain fields, such as robotics. In this paper, we delve into open-ended question-answering (QA) in long, egocentric videos, which allows individuals or robots to inquire about their own past visual experiences. This task presents unique challenges, including the complexity of temporally grounding queries within extensive video content, the high resource demands for precise data annotation, and the inherent difficulty of evaluating open-ended answers due to their ambiguous nature. Our proposed approach tackles these challenges by (i) integrating query grounding and answering within a unified model to reduce error propagation; (ii) employing large language models for efficient and scalable data synthesis; and (iii) introducing a close-ended QA task for evaluation, to manage answer ambiguity. Extensive experiments demonstrate the effectiveness of our method, which also achieves state-of-the-art performance on the QAEgo4D and Ego4D-NLQ benchmarks. We plan to publicly release the codes, model, and constructed datasets for future research.","sentences":["Existing approaches to video understanding, mainly designed for short videos from a third-person perspective, are limited in their applicability in certain fields, such as robotics.","In this paper, we delve into open-ended question-answering (QA) in long, egocentric videos, which allows individuals or robots to inquire about their own past visual experiences.","This task presents unique challenges, including the complexity of temporally grounding queries within extensive video content, the high resource demands for precise data annotation, and the inherent difficulty of evaluating open-ended answers due to their ambiguous nature.","Our proposed approach tackles these challenges by (i) integrating query grounding and answering within a unified model to reduce error propagation; (ii) employing large language models for efficient and scalable data synthesis; and (iii) introducing a close-ended QA task for evaluation, to manage answer ambiguity.","Extensive experiments demonstrate the effectiveness of our method, which also achieves state-of-the-art performance on the QAEgo4D and Ego4D-NLQ benchmarks.","We plan to publicly release the codes, model, and constructed datasets for future research."],"url":"http://arxiv.org/abs/2312.06505v1"}
{"created":"2023-12-11 16:27:04","title":"On enforcing dyadic-type homogeneous binary function product constraints in MatBase","abstract":"Homogeneous binary function products are often encountered in the sub-universes modeled by databases, from genealogical trees to sports, from education to healthcare, etc. Their properties must be discovered and enforced by the software applications managing such data to guarantee plausibility. The (Elementary) Mathematical Data Model provides 18 dyadic-type homogeneous binary function product constraint types. MatBase, an intelligent data and knowledge base management system prototype, allows database designers to simply declare them by only clicking corresponding checkboxes and automatically generates code for enforcing them. This paper describes the algorithms that MatBase uses for enforcing all these 18 homogeneous binary function product constraint types, which may also be used by developers not having access to MatBase.","sentences":["Homogeneous binary function products are often encountered in the sub-universes modeled by databases, from genealogical trees to sports, from education to healthcare, etc.","Their properties must be discovered and enforced by the software applications managing such data to guarantee plausibility.","The (Elementary) Mathematical Data Model provides 18 dyadic-type homogeneous binary function product constraint types.","MatBase, an intelligent data and knowledge base management system prototype, allows database designers to simply declare them by only clicking corresponding checkboxes and automatically generates code for enforcing them.","This paper describes the algorithms that MatBase uses for enforcing all these 18 homogeneous binary function product constraint types, which may also be used by developers not having access to MatBase."],"url":"http://arxiv.org/abs/2312.06502v1"}
{"created":"2023-12-11 16:22:58","title":"Integrating micro-learning content in traditional e-learning platforms","abstract":"Lifelong learning requires appropriate solutions, especially for corporate training. Workers usually have difficulty combining training and their normal work. In this context, micro-learning emerges as a suitable solution, since it is based on breaking down new concepts into small fragments or pills of content, which can be consumed in short periods of time. The purpose of this paper is twofold. First, we offer an updated overview of the research on this training paradigm, as well as the different technologies leading to potential commercial solutions. Second, we introduce a proposal to add micro-learning content to more formal distance learning environments (traditional Learning Management Systems or LMS), with the aim of taking advantage of both learning philosophies. Our approach is based on a Service-Oriented Architecture (SOA) that is deployed in the cloud. In order to ensure the full integration of the micro-learning approach in traditional LMSs, we have used two well-known standards in the distance learning field: LTI (Learning Tools Interoperability) and LIS (Learning Information Service). The combination of these two technologies allows the exchange of data with the LMS to monitor the student's activity and results. Finally, we have collected the opinion of lectures from different countries in order to know their thoughts about the potential of this new approach in higher education, obtaining positive feedback.","sentences":["Lifelong learning requires appropriate solutions, especially for corporate training.","Workers usually have difficulty combining training and their normal work.","In this context, micro-learning emerges as a suitable solution, since it is based on breaking down new concepts into small fragments or pills of content, which can be consumed in short periods of time.","The purpose of this paper is twofold.","First, we offer an updated overview of the research on this training paradigm, as well as the different technologies leading to potential commercial solutions.","Second, we introduce a proposal to add micro-learning content to more formal distance learning environments (traditional Learning Management Systems or LMS), with the aim of taking advantage of both learning philosophies.","Our approach is based on a Service-Oriented Architecture (SOA) that is deployed in the cloud.","In order to ensure the full integration of the micro-learning approach in traditional LMSs, we have used two well-known standards in the distance learning field: LTI (Learning Tools Interoperability) and LIS (Learning Information Service).","The combination of these two technologies allows the exchange of data with the LMS to monitor the student's activity and results.","Finally, we have collected the opinion of lectures from different countries in order to know their thoughts about the potential of this new approach in higher education, obtaining positive feedback."],"url":"http://arxiv.org/abs/2312.06500v1"}
{"created":"2023-12-11 16:18:56","title":"Detecting Events in Crowds Through Changes in Geometrical Dimensions of Pedestrians","abstract":"Security is an important topic in our contemporary world, and the ability to automate the detection of any events of interest that can take place in a crowd is of great interest to a population. We hypothesize that the detection of events in videos is correlated with significant changes in pedestrian behaviors. In this paper, we examine three different scenarios of crowd behavior, containing both the cases where an event triggers a change in the behavior of the crowd and two video sequences where the crowd and its motion remain mostly unchanged. With both the videos and the tracking of the individual pedestrians (performed in a pre-processed phase), we use Geomind, a software we developed to extract significant data about the scene, in particular, the geometrical features, personalities, and emotions of each person. We then examine the output, seeking a significant change in the way each person acts as a function of the time, that could be used as a basis to identify events or to model realistic crowd actions. When applied to the games area, our method can use the detected events to find some sort of pattern to be then used in agent simulation. Results indicate that our hypothesis seems valid in the sense that the visually observed events could be automatically detected using GeoMind.","sentences":["Security is an important topic in our contemporary world, and the ability to automate the detection of any events of interest that can take place in a crowd is of great interest to a population.","We hypothesize that the detection of events in videos is correlated with significant changes in pedestrian behaviors.","In this paper, we examine three different scenarios of crowd behavior, containing both the cases where an event triggers a change in the behavior of the crowd and two video sequences where the crowd and its motion remain mostly unchanged.","With both the videos and the tracking of the individual pedestrians (performed in a pre-processed phase), we use Geomind, a software we developed to extract significant data about the scene, in particular, the geometrical features, personalities, and emotions of each person.","We then examine the output, seeking a significant change in the way each person acts as a function of the time, that could be used as a basis to identify events or to model realistic crowd actions.","When applied to the games area, our method can use the detected events to find some sort of pattern to be then used in agent simulation.","Results indicate that our hypothesis seems valid in the sense that the visually observed events could be automatically detected using GeoMind."],"url":"http://arxiv.org/abs/2312.06495v1"}
{"created":"2023-12-11 16:03:31","title":"NetROS-5G: Enhancing Personalization through 5G Network Slicing and Edge Computing in Human-Robot Interactions","abstract":"Robots are increasingly being used in a variety of applications, from manufacturing and healthcare to education and customer service. However, the mobility, power, and price points of these robots often dictate that they do not have sufficient computing power on board to run modern algorithms for personalization in human-robot interaction at desired rates. This can limit the effectiveness of the interaction and limit the potential applications for these robots. 5G connectivity provides a solution to this problem by offering high data rates, bandwidth, and low latency that can facilitate robotics services. Additionally, the widespread availability of cloud computing has made it easy to access almost unlimited computing power at a low cost. Edge computing, which involves placing compute resources closer to the action, can offer even lower latency than cloud computing. In this paper, we explore the potential of combining 5G, edge, and cloud computing to provide improved personalization in human-robot interaction. We design, develop, and demonstrate a new framework, entitled NetROS-5G, to show how the performance gained by utilizing these technologies can overcome network latency and significantly enhance personalization in robotics. Our results show that the integration of 5G network slicing, edge computing, and cloud computing can collectively offer a cost-efficient and superior level of personalization in a modern human-robot interaction scenario.","sentences":["Robots are increasingly being used in a variety of applications, from manufacturing and healthcare to education and customer service.","However, the mobility, power, and price points of these robots often dictate that they do not have sufficient computing power on board to run modern algorithms for personalization in human-robot interaction at desired rates.","This can limit the effectiveness of the interaction and limit the potential applications for these robots.","5G connectivity provides a solution to this problem by offering high data rates, bandwidth, and low latency that can facilitate robotics services.","Additionally, the widespread availability of cloud computing has made it easy to access almost unlimited computing power at a low cost.","Edge computing, which involves placing compute resources closer to the action, can offer even lower latency than cloud computing.","In this paper, we explore the potential of combining 5G, edge, and cloud computing to provide improved personalization in human-robot interaction.","We design, develop, and demonstrate a new framework, entitled NetROS-5G, to show how the performance gained by utilizing these technologies can overcome network latency and significantly enhance personalization in robotics.","Our results show that the integration of 5G network slicing, edge computing, and cloud computing can collectively offer a cost-efficient and superior level of personalization in a modern human-robot interaction scenario."],"url":"http://arxiv.org/abs/2312.06475v1"}
{"created":"2023-12-11 16:02:57","title":"Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic Segmentation","abstract":"For few-shot semantic segmentation, the primary task is to extract class-specific intrinsic information from limited labeled data. However, the semantic ambiguity and inter-class similarity of previous methods limit the accuracy of pixel-level foreground-background classification. To alleviate these issues, we propose the Relevant Intrinsic Feature Enhancement Network (RiFeNet). To improve the semantic consistency of foreground instances, we propose an unlabeled branch as an efficient data utilization method, which teaches the model how to extract intrinsic features robust to intra-class differences. Notably, during testing, the proposed unlabeled branch is excluded without extra unlabeled data and computation. Furthermore, we extend the inter-class variability between foreground and background by proposing a novel multi-level prototype generation and interaction module. The different-grained complementarity between global and local prototypes allows for better distinction between similar categories. The qualitative and quantitative performance of RiFeNet surpasses the state-of-the-art methods on PASCAL-5i and COCO benchmarks.","sentences":["For few-shot semantic segmentation, the primary task is to extract class-specific intrinsic information from limited labeled data.","However, the semantic ambiguity and inter-class similarity of previous methods limit the accuracy of pixel-level foreground-background classification.","To alleviate these issues, we propose the Relevant Intrinsic Feature Enhancement Network (RiFeNet).","To improve the semantic consistency of foreground instances, we propose an unlabeled branch as an efficient data utilization method, which teaches the model how to extract intrinsic features robust to intra-class differences.","Notably, during testing, the proposed unlabeled branch is excluded without extra unlabeled data and computation.","Furthermore, we extend the inter-class variability between foreground and background by proposing a novel multi-level prototype generation and interaction module.","The different-grained complementarity between global and local prototypes allows for better distinction between similar categories.","The qualitative and quantitative performance of RiFeNet surpasses the state-of-the-art methods on PASCAL-5i and COCO benchmarks."],"url":"http://arxiv.org/abs/2312.06474v1"}
{"created":"2023-12-11 15:55:20","title":"Aligning brain functions boosts the decoding of visual semantics in novel subjects","abstract":"Deep learning is leading to major advances in the realm of brain decoding from functional Magnetic Resonance Imaging (fMRI). However, the large inter-subject variability in brain characteristics has limited most studies to train models on one subject at a time. Consequently, this approach hampers the training of deep learning models, which typically requires very large datasets. Here, we propose to boost brain decoding by aligning brain responses to videos and static images across subjects. Compared to the anatomically-aligned baseline, our method improves out-of-subject decoding performance by up to 75%. Moreover, it also outperforms classical single-subject approaches when fewer than 100 minutes of data is available for the tested subject. Furthermore, we propose a new multi-subject alignment method, which obtains comparable results to that of classical single-subject approaches while improving out-of-subject generalization. Finally, we show that this method aligns neural representations in accordance with brain anatomy. Overall, this study lays the foundations for leveraging extensive neuroimaging datasets and enhancing the decoding of individuals with a limited amount of brain recordings.","sentences":["Deep learning is leading to major advances in the realm of brain decoding from functional Magnetic Resonance Imaging (fMRI).","However, the large inter-subject variability in brain characteristics has limited most studies to train models on one subject at a time.","Consequently, this approach hampers the training of deep learning models, which typically requires very large datasets.","Here, we propose to boost brain decoding by aligning brain responses to videos and static images across subjects.","Compared to the anatomically-aligned baseline, our method improves out-of-subject decoding performance by up to 75%.","Moreover, it also outperforms classical single-subject approaches when fewer than 100 minutes of data is available for the tested subject.","Furthermore, we propose a new multi-subject alignment method, which obtains comparable results to that of classical single-subject approaches while improving out-of-subject generalization.","Finally, we show that this method aligns neural representations in accordance with brain anatomy.","Overall, this study lays the foundations for leveraging extensive neuroimaging datasets and enhancing the decoding of individuals with a limited amount of brain recordings."],"url":"http://arxiv.org/abs/2312.06467v1"}
{"created":"2023-12-11 15:47:12","title":"ASF-YOLO: A Novel YOLO Model with Attentional Scale Sequence Fusion for Cell Instance Segmentation","abstract":"We propose a novel Attentional Scale Sequence Fusion based You Only Look Once (YOLO) framework (ASF-YOLO) which combines spatial and scale features for accurate and fast cell instance segmentation. Built on the YOLO segmentation framework, we employ the Scale Sequence Feature Fusion (SSFF) module to enhance the multi-scale information extraction capability of the network, and the Triple Feature Encoder (TPE) module to fuse feature maps of different scales to increase detailed information. We further introduce a Channel and Position Attention Mechanism (CPAM) to integrate both the SSFF and TPE modules, which focus on informative channels and spatial position-related small objects for improved detection and segmentation performance. Experimental validations on two cell datasets show remarkable segmentation accuracy and speed of the proposed ASF-YOLO model. It achieves a box mAP of 0.91, mask mAP of 0.887, and an inference speed of 47.3 FPS on the 2018 Data Science Bowl dataset, outperforming the state-of-the-art methods. The source code is available at https://github.com/mkang315/ASF-YOLO.","sentences":["We propose a novel Attentional Scale Sequence Fusion based You Only Look Once (YOLO) framework (ASF-YOLO) which combines spatial and scale features for accurate and fast cell instance segmentation.","Built on the YOLO segmentation framework, we employ the Scale Sequence Feature Fusion (SSFF) module to enhance the multi-scale information extraction capability of the network, and the Triple Feature Encoder (TPE) module to fuse feature maps of different scales to increase detailed information.","We further introduce a Channel and Position Attention Mechanism (CPAM) to integrate both the SSFF and TPE modules, which focus on informative channels and spatial position-related small objects for improved detection and segmentation performance.","Experimental validations on two cell datasets show remarkable segmentation accuracy and speed of the proposed ASF-YOLO model.","It achieves a box mAP of 0.91, mask mAP of 0.887, and an inference speed of 47.3 FPS on the 2018 Data Science Bowl dataset, outperforming the state-of-the-art methods.","The source code is available at https://github.com/mkang315/ASF-YOLO."],"url":"http://arxiv.org/abs/2312.06458v1"}
{"created":"2023-12-11 15:39:41","title":"Semantic Image Synthesis for Abdominal CT","abstract":"As a new emerging and promising type of generative models, diffusion models have proven to outperform Generative Adversarial Networks (GANs) in multiple tasks, including image synthesis. In this work, we explore semantic image synthesis for abdominal CT using conditional diffusion models, which can be used for downstream applications such as data augmentation. We systematically evaluated the performance of three diffusion models, as well as to other state-of-the-art GAN-based approaches, and studied the different conditioning scenarios for the semantic mask. Experimental results demonstrated that diffusion models were able to synthesize abdominal CT images with better quality. Additionally, encoding the mask and the input separately is more effective than na\\\"ive concatenating.","sentences":["As a new emerging and promising type of generative models, diffusion models have proven to outperform Generative Adversarial Networks (GANs) in multiple tasks, including image synthesis.","In this work, we explore semantic image synthesis for abdominal CT using conditional diffusion models, which can be used for downstream applications such as data augmentation.","We systematically evaluated the performance of three diffusion models, as well as to other state-of-the-art GAN-based approaches, and studied the different conditioning scenarios for the semantic mask.","Experimental results demonstrated that diffusion models were able to synthesize abdominal CT images with better quality.","Additionally, encoding the mask and the input separately is more effective than na\\\"ive concatenating."],"url":"http://arxiv.org/abs/2312.06453v1"}
{"created":"2023-12-11 15:30:46","title":"Optimal Publishing Strategies on a Base Layer","abstract":"A growing number of products use layer 2 solutions to expand the capabilities of primary blockchains like Ethereum, where computation is off-loaded from the root chain, and the results are published to it in bulk. Those include optimistic and zero-knowledge rollups, information oracles, and app-specific chains. This work presents an analysis of layer 2 blockchain strategies determining the optimal times for publishing transactions on the root chain. There is a trade-off between waiting for a better layer 1 gas price and the urgency to finalize layer 2 transactions. We present a model for the problem that captures this trade-off, generalizing previous works, and we analyze the properties of optimal publishing strategies. We show that such optimal strategies hold a computable simple form for a large class of cost functions.","sentences":["A growing number of products use layer 2 solutions to expand the capabilities of primary blockchains like Ethereum, where computation is off-loaded from the root chain, and the results are published to it in bulk.","Those include optimistic and zero-knowledge rollups, information oracles, and app-specific chains.","This work presents an analysis of layer 2 blockchain strategies determining the optimal times for publishing transactions on the root chain.","There is a trade-off between waiting for a better layer 1 gas price and the urgency to finalize layer 2 transactions.","We present a model for the problem that captures this trade-off, generalizing previous works, and we analyze the properties of optimal publishing strategies.","We show that such optimal strategies hold a computable simple form for a large class of cost functions."],"url":"http://arxiv.org/abs/2312.06448v1"}
{"created":"2023-12-11 14:52:43","title":"VisionTraj: A Noise-Robust Trajectory Recovery Framework based on Large-scale Camera Network","abstract":"Trajectory recovery based on the snapshots from the city-wide multi-camera network facilitates urban mobility sensing and driveway optimization. The state-of-the-art solutions devoted to such a vision-based scheme typically incorporate predefined rules or unsupervised iterative feedback, struggling with multi-fold challenges such as lack of open-source datasets for training the whole pipeline, and the vulnerability to the noises from visual inputs. In response to the dilemma, this paper proposes VisionTraj, the first learning-based model that reconstructs vehicle trajectories from snapshots recorded by road network cameras. Coupled with it, we elaborate on two rational vision-trajectory datasets, which produce extensive trajectory data along with corresponding visual snapshots, enabling supervised vision-trajectory interplay extraction. Following the data creation, based on the results from the off-the-shelf multi-modal vehicle clustering, we first re-formulate the trajectory recovery problem as a generative task and introduce the canonical Transformer as the autoregressive backbone. Then, to identify clustering noises (e.g., false positives) with the bound on the snapshots' spatiotemporal dependencies, a GCN-based soft-denoising module is conducted based on the fine- and coarse-grained Re-ID clusters. Additionally, we harness strong semantic information extracted from the tracklet to provide detailed insights into the vehicle's entry and exit actions during trajectory recovery. The denoising and tracklet components can also act as plug-and-play modules to boost baselines. Experimental results on the two hand-crafted datasets show that the proposed VisionTraj achieves a maximum +11.5% improvement against the sub-best model.","sentences":["Trajectory recovery based on the snapshots from the city-wide multi-camera network facilitates urban mobility sensing and driveway optimization.","The state-of-the-art solutions devoted to such a vision-based scheme typically incorporate predefined rules or unsupervised iterative feedback, struggling with multi-fold challenges such as lack of open-source datasets for training the whole pipeline, and the vulnerability to the noises from visual inputs.","In response to the dilemma, this paper proposes VisionTraj, the first learning-based model that reconstructs vehicle trajectories from snapshots recorded by road network cameras.","Coupled with it, we elaborate on two rational vision-trajectory datasets, which produce extensive trajectory data along with corresponding visual snapshots, enabling supervised vision-trajectory interplay extraction.","Following the data creation, based on the results from the off-the-shelf multi-modal vehicle clustering, we first re-formulate the trajectory recovery problem as a generative task and introduce the canonical Transformer as the autoregressive backbone.","Then, to identify clustering noises (e.g., false positives) with the bound on the snapshots' spatiotemporal dependencies, a GCN-based soft-denoising module is conducted based on the fine- and coarse-grained Re-ID clusters.","Additionally, we harness strong semantic information extracted from the tracklet to provide detailed insights into the vehicle's entry and exit actions during trajectory recovery.","The denoising and tracklet components can also act as plug-and-play modules to boost baselines.","Experimental results on the two hand-crafted datasets show that the proposed VisionTraj achieves a maximum +11.5% improvement against the sub-best model."],"url":"http://arxiv.org/abs/2312.06428v1"}
{"created":"2023-12-11 14:49:26","title":"Numeric Truncation Security Predicate","abstract":"Numeric truncation is a widely spread error in software written in languages with static data typing, such as C/C++ or Java. It occurs when the significant bits of the value with a bigger type size are truncated during value conversion to the smaller type. Utilizing one of the most powerful methods for path exploration and automated bug detection called dynamic symbolic execution (DSE), we propose the symbolic security predicate for numeric truncation error detection, developed on top of DSE tool Sydr. Firstly, we execute the program on the data, which does not lead to any errors. During program execution we update symbolic shadow stack and shadow registers to track symbolic sizes of the symbolic variables to avoid false positives. Then, if we meet the instruction, which truncates the symbolic variable, we build the security predicate, try to solve it with the SMT-solver and in case of success save new input file to reproduce the error. We tested our approach on Juliet Dynamic test suite for CWE-197 and achieved 100% accuracy. We approved the workability of our approach by detecting 12 new errors of numeric truncation in 5 different real-world open source projects within OSS-Sydr-Fuzz project. All of the errors were reported, most of the reports were equipped with appropriate fixes, successfully confirmed and applied by project maintainers.","sentences":["Numeric truncation is a widely spread error in software written in languages with static data typing, such as C/C++ or Java.","It occurs when the significant bits of the value with a bigger type size are truncated during value conversion to the smaller type.","Utilizing one of the most powerful methods for path exploration and automated bug detection called dynamic symbolic execution (DSE), we propose the symbolic security predicate for numeric truncation error detection, developed on top of DSE tool Sydr.","Firstly, we execute the program on the data, which does not lead to any errors.","During program execution we update symbolic shadow stack and shadow registers to track symbolic sizes of the symbolic variables to avoid false positives.","Then, if we meet the instruction, which truncates the symbolic variable, we build the security predicate, try to solve it with the SMT-solver and in case of success save new input file to reproduce the error.","We tested our approach on Juliet Dynamic test suite for CWE-197 and achieved 100% accuracy.","We approved the workability of our approach by detecting 12 new errors of numeric truncation in 5 different real-world open source projects within OSS-Sydr-Fuzz project.","All of the errors were reported, most of the reports were equipped with appropriate fixes, successfully confirmed and applied by project maintainers."],"url":"http://arxiv.org/abs/2312.06425v1"}
{"created":"2023-12-11 14:43:23","title":"Localization Is All You Evaluate: Data Leakage in Online Mapping Datasets and How to Fix It","abstract":"Data leakage is a critical issue when training and evaluating any method based on supervised learning. The state-of-the-art methods for online mapping are based on supervised learning and are trained predominantly using two datasets: nuScenes and Argoverse 2. These datasets revisit the same geographic locations across training, validation, and test sets. Specifically, over $80$% of nuScenes and $40$% of Argoverse 2 validation and test samples are located less than $5$ m from a training sample. This allows methods to localize within a memorized implicit map during testing and leads to inflated performance numbers being reported. To reveal the true performance in unseen environments, we introduce geographical splits of the data. Experimental results show significantly lower performance numbers, for some methods dropping with more than $45$ mAP, when retraining and reevaluating existing online mapping models with the proposed split. Additionally, a reassessment of prior design choices reveals diverging conclusions from those based on the original split. Notably, the impact of the lifting method and the support from auxiliary tasks (e.g., depth supervision) on performance appears less substantial or follows a different trajectory than previously perceived. Geographical splits can be found https://github.com/LiljaAdam/geographical-splits","sentences":["Data leakage is a critical issue when training and evaluating any method based on supervised learning.","The state-of-the-art methods for online mapping are based on supervised learning and are trained predominantly using two datasets: nuScenes and Argoverse 2.","These datasets revisit the same geographic locations across training, validation, and test sets.","Specifically, over $80$% of nuScenes and $40$% of Argoverse 2 validation and test samples are located less than $5$ m from a training sample.","This allows methods to localize within a memorized implicit map during testing and leads to inflated performance numbers being reported.","To reveal the true performance in unseen environments, we introduce geographical splits of the data.","Experimental results show significantly lower performance numbers, for some methods dropping with more than $45$ mAP, when retraining and reevaluating existing online mapping models with the proposed split.","Additionally, a reassessment of prior design choices reveals diverging conclusions from those based on the original split.","Notably, the impact of the lifting method and the support from auxiliary tasks (e.g., depth supervision) on performance appears less substantial or follows a different trajectory than previously perceived.","Geographical splits can be found https://github.com/LiljaAdam/geographical-splits"],"url":"http://arxiv.org/abs/2312.06420v1"}
{"created":"2023-12-11 14:27:10","title":"Partial End-to-end Reinforcement Learning for Robustness Against Modelling Error in Autonomous Racing","abstract":"In this paper, we address the issue of increasing the performance of reinforcement learning (RL) solutions for autonomous racing cars when navigating under conditions where practical vehicle modelling errors (commonly known as \\emph{model mismatches}) are present. To address this challenge, we propose a partial end-to-end algorithm that decouples the planning and control tasks. Within this framework, an RL agent generates a trajectory comprising a path and velocity, which is subsequently tracked using a pure pursuit steering controller and a proportional velocity controller, respectively. In contrast, many current learning-based (i.e., reinforcement and imitation learning) algorithms utilise an end-to-end approach whereby a deep neural network directly maps from sensor data to control commands. By leveraging the robustness of a classical controller, our partial end-to-end driving algorithm exhibits better robustness towards model mismatches than standard end-to-end algorithms.","sentences":["In this paper, we address the issue of increasing the performance of reinforcement learning (RL) solutions for autonomous racing cars when navigating under conditions where practical vehicle modelling errors (commonly known as \\emph{model mismatches}) are present.","To address this challenge, we propose a partial end-to-end algorithm that decouples the planning and control tasks.","Within this framework, an RL agent generates a trajectory comprising a path and velocity, which is subsequently tracked using a pure pursuit steering controller and a proportional velocity controller, respectively.","In contrast, many current learning-based (i.e., reinforcement and imitation learning) algorithms utilise an end-to-end approach whereby a deep neural network directly maps from sensor data to control commands.","By leveraging the robustness of a classical controller, our partial end-to-end driving algorithm exhibits better robustness towards model mismatches than standard end-to-end algorithms."],"url":"http://arxiv.org/abs/2312.06406v1"}
{"created":"2023-12-11 14:07:31","title":"NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos","abstract":"In this paper, we aim to model 3D scene dynamics from multi-view videos. Unlike the majority of existing works which usually focus on the common task of novel view synthesis within the training time period, we propose to simultaneously learn the geometry, appearance, and physical velocity of 3D scenes only from video frames, such that multiple desirable applications can be supported, including future frame extrapolation, unsupervised 3D semantic scene decomposition, and dynamic motion transfer. Our method consists of three major components, 1) the keyframe dynamic radiance field, 2) the interframe velocity field, and 3) a joint keyframe and interframe optimization module which is the core of our framework to effectively train both networks. To validate our method, we further introduce two dynamic 3D datasets: 1) Dynamic Object dataset, and 2) Dynamic Indoor Scene dataset. We conduct extensive experiments on multiple datasets, demonstrating the superior performance of our method over all baselines, particularly in the critical tasks of future frame extrapolation and unsupervised 3D semantic scene decomposition.","sentences":["In this paper, we aim to model 3D scene dynamics from multi-view videos.","Unlike the majority of existing works which usually focus on the common task of novel view synthesis within the training time period, we propose to simultaneously learn the geometry, appearance, and physical velocity of 3D scenes only from video frames, such that multiple desirable applications can be supported, including future frame extrapolation, unsupervised 3D semantic scene decomposition, and dynamic motion transfer.","Our method consists of three major components, 1) the keyframe dynamic radiance field, 2) the interframe velocity field, and 3) a joint keyframe and interframe optimization module which is the core of our framework to effectively train both networks.","To validate our method, we further introduce two dynamic 3D datasets: 1) Dynamic Object dataset, and 2) Dynamic Indoor Scene dataset.","We conduct extensive experiments on multiple datasets, demonstrating the superior performance of our method over all baselines, particularly in the critical tasks of future frame extrapolation and unsupervised 3D semantic scene decomposition."],"url":"http://arxiv.org/abs/2312.06398v1"}
{"created":"2023-12-11 14:07:14","title":"MUST: An Effective and Scalable Framework for Multimodal Search of Target Modality","abstract":"We investigate the problem of multimodal search of target modality, where the task involves enhancing a query in a specific target modality by integrating information from auxiliary modalities. The goal is to retrieve relevant objects whose contents in the target modality match the specified multimodal query. The paper first introduces two baseline approaches that integrate techniques from the Database, Information Retrieval, and Computer Vision communities. These baselines either merge the results of separate vector searches for each modality or perform a single-channel vector search by fusing all modalities. However, both baselines have limitations in terms of efficiency and accuracy as they fail to adequately consider the varying importance of fusing information across modalities. To overcome these limitations, the paper proposes a novel framework, called MUST. Our framework employs a hybrid fusion mechanism, combining different modalities at multiple stages. Notably, we leverage vector weight learning to determine the importance of each modality, thereby enhancing the accuracy of joint similarity measurement. Additionally, the proposed framework utilizes a fused proximity graph index, enabling efficient joint search for multimodal queries. MUST offers several other advantageous properties, including pluggable design to integrate any advanced embedding techniques, user flexibility to customize weight preferences, and modularized index construction. Extensive experiments on real-world datasets demonstrate the superiority of MUST over the baselines in terms of both search accuracy and efficiency. Our framework achieves over 10x faster search times while attaining an average of 93% higher accuracy. Furthermore, MUST exhibits scalability to datasets containing more than 10 million data elements.","sentences":["We investigate the problem of multimodal search of target modality, where the task involves enhancing a query in a specific target modality by integrating information from auxiliary modalities.","The goal is to retrieve relevant objects whose contents in the target modality match the specified multimodal query.","The paper first introduces two baseline approaches that integrate techniques from the Database, Information Retrieval, and Computer Vision communities.","These baselines either merge the results of separate vector searches for each modality or perform a single-channel vector search by fusing all modalities.","However, both baselines have limitations in terms of efficiency and accuracy as they fail to adequately consider the varying importance of fusing information across modalities.","To overcome these limitations, the paper proposes a novel framework, called MUST.","Our framework employs a hybrid fusion mechanism, combining different modalities at multiple stages.","Notably, we leverage vector weight learning to determine the importance of each modality, thereby enhancing the accuracy of joint similarity measurement.","Additionally, the proposed framework utilizes a fused proximity graph index, enabling efficient joint search for multimodal queries.","MUST offers several other advantageous properties, including pluggable design to integrate any advanced embedding techniques, user flexibility to customize weight preferences, and modularized index construction.","Extensive experiments on real-world datasets demonstrate the superiority of MUST over the baselines in terms of both search accuracy and efficiency.","Our framework achieves over 10x faster search times while attaining an average of 93% higher accuracy.","Furthermore, MUST exhibits scalability to datasets containing more than 10 million data elements."],"url":"http://arxiv.org/abs/2312.06397v1"}
{"created":"2023-12-11 13:46:33","title":"SciCat: A Curated Dataset of Scientific Software Repositories","abstract":"The proliferation of open-source scientific software for science and research presents opportunities and challenges. In this paper, we introduce the SciCat dataset -- a comprehensive collection of Free-Libre Open Source Software (FLOSS) projects, designed to address the need for a curated repository of scientific and research software. This collection is crucial for understanding the creation of scientific software and aiding in its development. To ensure extensive coverage, our approach involves selecting projects from a pool of 131 million deforked repositories from the World of Code data source. Subsequently, we analyze README.md files using OpenAI's advanced language models. Our classification focuses on software designed for scientific purposes, research-related projects, and research support software. The SciCat dataset aims to become an invaluable tool for researching science-related software, shedding light on emerging trends, prevalent practices, and challenges in the field of scientific software development. Furthermore, it includes data that can be linked to the World of Code, GitHub, and other platforms, providing a solid foundation for conducting comparative studies between scientific and non-scientific software.","sentences":["The proliferation of open-source scientific software for science and research presents opportunities and challenges.","In this paper, we introduce the SciCat dataset -- a comprehensive collection of Free-Libre Open Source Software (FLOSS) projects, designed to address the need for a curated repository of scientific and research software.","This collection is crucial for understanding the creation of scientific software and aiding in its development.","To ensure extensive coverage, our approach involves selecting projects from a pool of 131 million deforked repositories from the World of Code data source.","Subsequently, we analyze README.md files using OpenAI's advanced language models.","Our classification focuses on software designed for scientific purposes, research-related projects, and research support software.","The SciCat dataset aims to become an invaluable tool for researching science-related software, shedding light on emerging trends, prevalent practices, and challenges in the field of scientific software development.","Furthermore, it includes data that can be linked to the World of Code, GitHub, and other platforms, providing a solid foundation for conducting comparative studies between scientific and non-scientific software."],"url":"http://arxiv.org/abs/2312.06382v1"}
{"created":"2023-12-11 13:32:11","title":"UstanceBR: a multimodal language resource for stance prediction","abstract":"This work introduces UstanceBR, a multimodal corpus in the Brazilian Portuguese Twitter domain for target-based stance prediction. The corpus comprises 86.8 k labelled stances towards selected target topics, and extensive network information about the users who published these stances on social media. In this article we describe the corpus multimodal data, and a number of usage examples in both in-domain and zero-shot stance prediction based on text- and network-related information, which are intended to provide initial baseline results for future studies in the field.","sentences":["This work introduces UstanceBR, a multimodal corpus in the Brazilian Portuguese Twitter domain for target-based stance prediction.","The corpus comprises 86.8 k labelled stances towards selected target topics, and extensive network information about the users who published these stances on social media.","In this article we describe the corpus multimodal data, and a number of usage examples in both in-domain and zero-shot stance prediction based on text- and network-related information, which are intended to provide initial baseline results for future studies in the field."],"url":"http://arxiv.org/abs/2312.06374v1"}
{"created":"2023-12-11 13:27:51","title":"BAT: Behavior-Aware Human-Like Trajectory Prediction for Autonomous Driving","abstract":"The ability to accurately predict the trajectory of surrounding vehicles is a critical hurdle to overcome on the journey to fully autonomous vehicles. To address this challenge, we pioneer a novel behavior-aware trajectory prediction model (BAT) that incorporates insights and findings from traffic psychology, human behavior, and decision-making. Our model consists of behavior-aware, interaction-aware, priority-aware, and position-aware modules that perceive and understand the underlying interactions and account for uncertainty and variability in prediction, enabling higher-level learning and flexibility without rigid categorization of driving behavior. Importantly, this approach eliminates the need for manual labeling in the training process and addresses the challenges of non-continuous behavior labeling and the selection of appropriate time windows. We evaluate BAT's performance across the Next Generation Simulation (NGSIM), Highway Drone (HighD), Roundabout Drone (RounD), and Macao Connected Autonomous Driving (MoCAD) datasets, showcasing its superiority over prevailing state-of-the-art (SOTA) benchmarks in terms of prediction accuracy and efficiency. Remarkably, even when trained on reduced portions of the training data (25%), our model outperforms most of the baselines, demonstrating its robustness and efficiency in predicting vehicle trajectories, and the potential to reduce the amount of data required to train autonomous vehicles, especially in corner cases. In conclusion, the behavior-aware model represents a significant advancement in the development of autonomous vehicles capable of predicting trajectories with the same level of proficiency as human drivers. The project page is available at https://github.com/Petrichor625/BATraj-Behavior-aware-Model.","sentences":["The ability to accurately predict the trajectory of surrounding vehicles is a critical hurdle to overcome on the journey to fully autonomous vehicles.","To address this challenge, we pioneer a novel behavior-aware trajectory prediction model (BAT) that incorporates insights and findings from traffic psychology, human behavior, and decision-making.","Our model consists of behavior-aware, interaction-aware, priority-aware, and position-aware modules that perceive and understand the underlying interactions and account for uncertainty and variability in prediction, enabling higher-level learning and flexibility without rigid categorization of driving behavior.","Importantly, this approach eliminates the need for manual labeling in the training process and addresses the challenges of non-continuous behavior labeling and the selection of appropriate time windows.","We evaluate BAT's performance across the Next Generation Simulation (NGSIM), Highway Drone (HighD), Roundabout Drone (RounD), and Macao Connected Autonomous Driving (MoCAD) datasets, showcasing its superiority over prevailing state-of-the-art (SOTA) benchmarks in terms of prediction accuracy and efficiency.","Remarkably, even when trained on reduced portions of the training data (25%), our model outperforms most of the baselines, demonstrating its robustness and efficiency in predicting vehicle trajectories, and the potential to reduce the amount of data required to train autonomous vehicles, especially in corner cases.","In conclusion, the behavior-aware model represents a significant advancement in the development of autonomous vehicles capable of predicting trajectories with the same level of proficiency as human drivers.","The project page is available at https://github.com/Petrichor625/BATraj-Behavior-aware-Model."],"url":"http://arxiv.org/abs/2312.06371v1"}
{"created":"2023-12-11 13:05:54","title":"Intraoperative 2D/3D Image Registration via Differentiable X-ray Rendering","abstract":"Surgical decisions are informed by aligning rapid portable 2D intraoperative images (e.g., X-rays) to a high-fidelity 3D preoperative reference scan (e.g., CT). 2D/3D image registration often fails in practice: conventional optimization methods are prohibitively slow and susceptible to local minima, while neural networks trained on small datasets fail on new patients or require impractical landmark supervision. We present DiffPose, a self-supervised approach that leverages patient-specific simulation and differentiable physics-based rendering to achieve accurate 2D/3D registration without relying on manually labeled data. Preoperatively, a CNN is trained to regress the pose of a randomly oriented synthetic X-ray rendered from the preoperative CT. The CNN then initializes rapid intraoperative test-time optimization that uses the differentiable X-ray renderer to refine the solution. Our work further proposes several geometrically principled methods for sampling camera poses from $\\mathbf{SE}(3)$, for sparse differentiable rendering, and for driving registration in the tangent space $\\mathfrak{se}(3)$ with geodesic and multiscale locality-sensitive losses. DiffPose achieves sub-millimeter accuracy across surgical datasets at intraoperative speeds, improving upon existing unsupervised methods by an order of magnitude and even outperforming supervised baselines. Our code is available at https://github.com/eigenvivek/DiffPose.","sentences":["Surgical decisions are informed by aligning rapid portable 2D intraoperative images (e.g., X-rays) to a high-fidelity 3D preoperative reference scan (e.g., CT).","2D/3D image registration often fails in practice: conventional optimization methods are prohibitively slow and susceptible to local minima, while neural networks trained on small datasets fail on new patients or require impractical landmark supervision.","We present DiffPose, a self-supervised approach that leverages patient-specific simulation and differentiable physics-based rendering to achieve accurate 2D/3D registration without relying on manually labeled data.","Preoperatively, a CNN is trained to regress the pose of a randomly oriented synthetic X-ray rendered from the preoperative CT.","The CNN then initializes rapid intraoperative test-time optimization that uses the differentiable X-ray renderer to refine the solution.","Our work further proposes several geometrically principled methods for sampling camera poses from $\\mathbf{SE}(3)$, for sparse differentiable rendering, and for driving registration in the tangent space $\\mathfrak{se}(3)$ with geodesic and multiscale locality-sensitive losses.","DiffPose achieves sub-millimeter accuracy across surgical datasets at intraoperative speeds, improving upon existing unsupervised methods by an order of magnitude and even outperforming supervised baselines.","Our code is available at https://github.com/eigenvivek/DiffPose."],"url":"http://arxiv.org/abs/2312.06358v1"}
{"created":"2023-12-11 13:03:21","title":"Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes","abstract":"Pre-trained large language models (LLMs) require fine-tuning to improve their responsiveness to natural language instructions. Federated learning (FL) offers a way to perform fine-tuning using the abundant data on end devices without compromising data privacy. Most existing federated fine-tuning methods for LLMs rely on parameter-efficient fine-tuning techniques, which may not reach the performance heights possible with full-parameter tuning. However, the communication overhead associated with full-parameter tuning is prohibitively high for both servers and clients. This work introduces FedKSeed, a novel approach that employs zeroth-order optimization (ZOO) with a set of random seeds. It enables federated full-parameter tuning of billion-sized LLMs directly on devices. Our method significantly reduces transmission requirements between the server and clients to just a few scalar gradients and random seeds, amounting to only a few thousand bytes. Building on this, we develop a strategy to assess the significance of ZOO perturbations for FL, allowing for probability-differentiated seed sampling. This prioritizes perturbations that have a greater impact on model accuracy. Experiments across six scenarios with different LLMs, datasets and data partitions demonstrate that our approach outperforms existing federated LLM fine-tuning methods in terms of both communication efficiency and new task generalization.","sentences":["Pre-trained large language models (LLMs) require fine-tuning to improve their responsiveness to natural language instructions.","Federated learning (FL) offers a way to perform fine-tuning using the abundant data on end devices without compromising data privacy.","Most existing federated fine-tuning methods for LLMs rely on parameter-efficient fine-tuning techniques, which may not reach the performance heights possible with full-parameter tuning.","However, the communication overhead associated with full-parameter tuning is prohibitively high for both servers and clients.","This work introduces FedKSeed, a novel approach that employs zeroth-order optimization (ZOO) with a set of random seeds.","It enables federated full-parameter tuning of billion-sized LLMs directly on devices.","Our method significantly reduces transmission requirements between the server and clients to just a few scalar gradients and random seeds, amounting to only a few thousand bytes.","Building on this, we develop a strategy to assess the significance of ZOO perturbations for FL, allowing for probability-differentiated seed sampling.","This prioritizes perturbations that have a greater impact on model accuracy.","Experiments across six scenarios with different LLMs, datasets and data partitions demonstrate that our approach outperforms existing federated LLM fine-tuning methods in terms of both communication efficiency and new task generalization."],"url":"http://arxiv.org/abs/2312.06353v1"}
{"created":"2023-12-11 12:47:29","title":"RankMatch: A Novel Approach to Semi-Supervised Label Distribution Learning Leveraging Inter-label Correlations","abstract":"This paper introduces RankMatch, an innovative approach for Semi-Supervised Label Distribution Learning (SSLDL). Addressing the challenge of limited labeled data, RankMatch effectively utilizes a small number of labeled examples in conjunction with a larger quantity of unlabeled data, reducing the need for extensive manual labeling in Deep Neural Network (DNN) applications. Specifically, RankMatch introduces an ensemble learning-inspired averaging strategy that creates a pseudo-label distribution from multiple weakly augmented images. This not only stabilizes predictions but also enhances the model's robustness. Beyond this, RankMatch integrates a pairwise relevance ranking (PRR) loss, capturing the complex inter-label correlations and ensuring that the predicted label distributions align with the ground truth.   We establish a theoretical generalization bound for RankMatch, and through extensive experiments, demonstrate its superiority in performance against existing SSLDL methods.","sentences":["This paper introduces RankMatch, an innovative approach for Semi-Supervised Label Distribution Learning (SSLDL).","Addressing the challenge of limited labeled data, RankMatch effectively utilizes a small number of labeled examples in conjunction with a larger quantity of unlabeled data, reducing the need for extensive manual labeling in Deep Neural Network (DNN) applications.","Specifically, RankMatch introduces an ensemble learning-inspired averaging strategy that creates a pseudo-label distribution from multiple weakly augmented images.","This not only stabilizes predictions but also enhances the model's robustness.","Beyond this, RankMatch integrates a pairwise relevance ranking (PRR) loss, capturing the complex inter-label correlations and ensuring that the predicted label distributions align with the ground truth.   ","We establish a theoretical generalization bound for RankMatch, and through extensive experiments, demonstrate its superiority in performance against existing SSLDL methods."],"url":"http://arxiv.org/abs/2312.06343v1"}
{"created":"2023-12-11 12:45:43","title":"Detecting Contextual Network Anomalies with Graph Neural Networks","abstract":"Detecting anomalies on network traffic is a complex task due to the massive amount of traffic flows in today's networks, as well as the highly-dynamic nature of traffic over time. In this paper, we propose the use of Graph Neural Networks (GNN) for network traffic anomaly detection. We formulate the problem as contextual anomaly detection on network traffic measurements, and propose a custom GNN-based solution that detects traffic anomalies on origin-destination flows. In our evaluation, we use real-world data from Abilene (6 months), and make a comparison with other widely used methods for the same task (PCA, EWMA, RNN). The results show that the anomalies detected by our solution are quite complementary to those captured by the baselines (with a max. of 36.33% overlapping anomalies for PCA). Moreover, we manually inspect the anomalies detected by our method, and find that a large portion of them can be visually validated by a network expert (64% with high confidence, 18% with mid confidence, 18% normal traffic). Lastly, we analyze the characteristics of the anomalies through two paradigmatic cases that are quite representative of the bulk of anomalies.","sentences":["Detecting anomalies on network traffic is a complex task due to the massive amount of traffic flows in today's networks, as well as the highly-dynamic nature of traffic over time.","In this paper, we propose the use of Graph Neural Networks (GNN) for network traffic anomaly detection.","We formulate the problem as contextual anomaly detection on network traffic measurements, and propose a custom GNN-based solution that detects traffic anomalies on origin-destination flows.","In our evaluation, we use real-world data from Abilene (6 months), and make a comparison with other widely used methods for the same task (PCA, EWMA, RNN).","The results show that the anomalies detected by our solution are quite complementary to those captured by the baselines (with a max. of 36.33% overlapping anomalies for PCA).","Moreover, we manually inspect the anomalies detected by our method, and find that a large portion of them can be visually validated by a network expert (64% with high confidence, 18% with mid confidence, 18% normal traffic).","Lastly, we analyze the characteristics of the anomalies through two paradigmatic cases that are quite representative of the bulk of anomalies."],"url":"http://arxiv.org/abs/2312.06342v1"}
{"created":"2023-12-11 12:40:16","title":"Adaptive Shape-Servoing for Vision-based Robotic Manipulation with Model Estimation and Performance Regulation","abstract":"This paper introduces a manipulation framework for the elastic rod, including shape representation, sensorimotor-model estimation, and shape controller. Until now, the manipulation of the elastic rod has faced several challenges: 1) shape learning from high-dimensional to low-space dimensional; 2) the modeling of robot manipulation of the elastic rod; 3) the determination of the shape controller. A novel manipulation framework for the elastic rod is presented in this paper, which only uses the input and output data of the system without any prior knowledge of the robot, camera, and object. The proposed approach runs in a model-free manner. For the approximation of the sensorimotor model, adaptive Kalman filtering (AKF) is used as the online estimation. Model-free adaptive control (MFAC) is designed according to the obtained differential model of robot-object configuration and then is combined with the performance regulation requirement to give the final format of the shape controller. Hence, the proposed approach can enhance the autonomous capability of deformation object manipulation. Detailed simulation results are conducted with a single robot manipulation to evaluate the effectiveness of the proposed manipulation framework.","sentences":["This paper introduces a manipulation framework for the elastic rod, including shape representation, sensorimotor-model estimation, and shape controller.","Until now, the manipulation of the elastic rod has faced several challenges: 1) shape learning from high-dimensional to low-space dimensional; 2) the modeling of robot manipulation of the elastic rod; 3) the determination of the shape controller.","A novel manipulation framework for the elastic rod is presented in this paper, which only uses the input and output data of the system without any prior knowledge of the robot, camera, and object.","The proposed approach runs in a model-free manner.","For the approximation of the sensorimotor model, adaptive Kalman filtering (AKF) is used as the online estimation.","Model-free adaptive control (MFAC) is designed according to the obtained differential model of robot-object configuration and then is combined with the performance regulation requirement to give the final format of the shape controller.","Hence, the proposed approach can enhance the autonomous capability of deformation object manipulation.","Detailed simulation results are conducted with a single robot manipulation to evaluate the effectiveness of the proposed manipulation framework."],"url":"http://arxiv.org/abs/2312.06340v1"}
{"created":"2023-12-11 12:35:35","title":"BoschAI @ Causal News Corpus 2023: Robust Cause-Effect Span Extraction using Multi-Layer Sequence Tagging and Data Augmentation","abstract":"Understanding causality is a core aspect of intelligence. The Event Causality Identification with Causal News Corpus Shared Task addresses two aspects of this challenge: Subtask 1 aims at detecting causal relationships in texts, and Subtask 2 requires identifying signal words and the spans that refer to the cause or effect, respectively. Our system, which is based on pre-trained transformers, stacked sequence tagging, and synthetic data augmentation, ranks third in Subtask 1 and wins Subtask 2 with an F1 score of 72.8, corresponding to a margin of 13 pp. to the second-best system.","sentences":["Understanding causality is a core aspect of intelligence.","The Event Causality Identification with Causal News Corpus Shared Task addresses two aspects of this challenge: Subtask 1 aims at detecting causal relationships in texts, and Subtask 2 requires identifying signal words and the spans that refer to the cause or effect, respectively.","Our system, which is based on pre-trained transformers, stacked sequence tagging, and synthetic data augmentation, ranks third in Subtask 1 and wins Subtask 2 with an F1 score of 72.8, corresponding to a margin of 13 pp.","to the second-best system."],"url":"http://arxiv.org/abs/2312.06338v1"}
{"created":"2023-12-11 12:35:17","title":"Deep Imbalanced Learning for Multimodal Emotion Recognition in Conversations","abstract":"The main task of Multimodal Emotion Recognition in Conversations (MERC) is to identify the emotions in modalities, e.g., text, audio, image and video, which is a significant development direction for realizing machine intelligence. However, many data in MERC naturally exhibit an imbalanced distribution of emotion categories, and researchers ignore the negative impact of imbalanced data on emotion recognition. To tackle this problem, we systematically analyze it from three aspects: data augmentation, loss sensitivity, and sampling strategy, and propose the Class Boundary Enhanced Representation Learning (CBERL) model. Concretely, we first design a multimodal generative adversarial network to address the imbalanced distribution of {emotion} categories in raw data. Secondly, a deep joint variational autoencoder is proposed to fuse complementary semantic information across modalities and obtain discriminative feature representations. Finally, we implement a multi-task graph neural network with mask reconstruction and classification optimization to solve the problem of overfitting and underfitting in class boundary learning, and achieve cross-modal emotion recognition. We have conducted extensive experiments on the IEMOCAP and MELD benchmark datasets, and the results show that CBERL has achieved a certain performance improvement in the effectiveness of emotion recognition. Especially on the minority class fear and disgust emotion labels, our model improves the accuracy and F1 value by 10% to 20%.","sentences":["The main task of Multimodal Emotion Recognition in Conversations (MERC) is to identify the emotions in modalities, e.g., text, audio, image and video, which is a significant development direction for realizing machine intelligence.","However, many data in MERC naturally exhibit an imbalanced distribution of emotion categories, and researchers ignore the negative impact of imbalanced data on emotion recognition.","To tackle this problem, we systematically analyze it from three aspects: data augmentation, loss sensitivity, and sampling strategy, and propose the Class Boundary Enhanced Representation Learning (CBERL) model.","Concretely, we first design a multimodal generative adversarial network to address the imbalanced distribution of {emotion} categories in raw data.","Secondly, a deep joint variational autoencoder is proposed to fuse complementary semantic information across modalities and obtain discriminative feature representations.","Finally, we implement a multi-task graph neural network with mask reconstruction and classification optimization to solve the problem of overfitting and underfitting in class boundary learning, and achieve cross-modal emotion recognition.","We have conducted extensive experiments on the IEMOCAP and MELD benchmark datasets, and the results show that CBERL has achieved a certain performance improvement in the effectiveness of emotion recognition.","Especially on the minority class fear and disgust emotion labels, our model improves the accuracy and F1 value by 10% to 20%."],"url":"http://arxiv.org/abs/2312.06337v1"}
{"created":"2023-12-11 12:29:32","title":"Navigating Open Set Scenarios for Skeleton-based Action Recognition","abstract":"In real-world scenarios, human actions often fall outside the distribution of training data, making it crucial for models to recognize known actions and reject unknown ones. However, using pure skeleton data in such open-set conditions poses challenges due to the lack of visual background cues and the distinct sparse structure of body pose sequences. In this paper, we tackle the unexplored Open-Set Skeleton-based Action Recognition (OS-SAR) task and formalize the benchmark on three skeleton-based datasets. We assess the performance of seven established open-set approaches on our task and identify their limits and critical generalization issues when dealing with skeleton information. To address these challenges, we propose a distance-based cross-modality ensemble method that leverages the cross-modal alignment of skeleton joints, bones, and velocities to achieve superior open-set recognition performance. We refer to the key idea as CrossMax - an approach that utilizes a novel cross-modality mean max discrepancy suppression mechanism to align latent spaces during training and a cross-modality distance-based logits refinement method during testing. CrossMax outperforms existing approaches and consistently yields state-of-the-art results across all datasets and backbones. The benchmark, code, and models will be released at https://github.com/KPeng9510/OS-SAR.","sentences":["In real-world scenarios, human actions often fall outside the distribution of training data, making it crucial for models to recognize known actions and reject unknown ones.","However, using pure skeleton data in such open-set conditions poses challenges due to the lack of visual background cues and the distinct sparse structure of body pose sequences.","In this paper, we tackle the unexplored Open-Set Skeleton-based Action Recognition (OS-SAR) task and formalize the benchmark on three skeleton-based datasets.","We assess the performance of seven established open-set approaches on our task and identify their limits and critical generalization issues when dealing with skeleton information.","To address these challenges, we propose a distance-based cross-modality ensemble method that leverages the cross-modal alignment of skeleton joints, bones, and velocities to achieve superior open-set recognition performance.","We refer to the key idea as CrossMax - an approach that utilizes a novel cross-modality mean max discrepancy suppression mechanism to align latent spaces during training and a cross-modality distance-based logits refinement method during testing.","CrossMax outperforms existing approaches and consistently yields state-of-the-art results across all datasets and backbones.","The benchmark, code, and models will be released at https://github.com/KPeng9510/OS-SAR."],"url":"http://arxiv.org/abs/2312.06330v1"}
{"created":"2023-12-11 12:21:45","title":"TPRNN: A Top-Down Pyramidal Recurrent Neural Network for Time Series Forecasting","abstract":"Time series refer to a series of data points indexed in time order, which can be found in various fields, e.g., transportation, healthcare, and finance. Accurate time series forecasting can enhance optimization planning and decision-making support. Time series have multi-scale characteristics, i.e., different temporal patterns at different scales, which presents a challenge for time series forecasting. In this paper, we propose TPRNN, a Top-down Pyramidal Recurrent Neural Network for time series forecasting. We first construct subsequences of different scales from the input, forming a pyramid structure. Then by executing a multi-scale information interaction module from top to bottom, we model both the temporal dependencies of each scale and the influences of subsequences of different scales, resulting in a complete modeling of multi-scale temporal patterns in time series. Experiments on seven real-world datasets demonstrate that TPRNN has achieved the state-of-the-art performance with an average improvement of 8.13% in MSE compared to the best baseline.","sentences":["Time series refer to a series of data points indexed in time order, which can be found in various fields, e.g., transportation, healthcare, and finance.","Accurate time series forecasting can enhance optimization planning and decision-making support.","Time series have multi-scale characteristics, i.e., different temporal patterns at different scales, which presents a challenge for time series forecasting.","In this paper, we propose TPRNN, a Top-down Pyramidal Recurrent Neural Network for time series forecasting.","We first construct subsequences of different scales from the input, forming a pyramid structure.","Then by executing a multi-scale information interaction module from top to bottom, we model both the temporal dependencies of each scale and the influences of subsequences of different scales, resulting in a complete modeling of multi-scale temporal patterns in time series.","Experiments on seven real-world datasets demonstrate that TPRNN has achieved the state-of-the-art performance with an average improvement of 8.13% in MSE compared to the best baseline."],"url":"http://arxiv.org/abs/2312.06328v1"}
{"created":"2023-12-11 12:03:30","title":"SemiSAM: Exploring SAM for Enhancing Semi-Supervised Medical Image Segmentation with Extremely Limited Annotations","abstract":"Semi-supervised learning has attracted much attention due to its less dependence on acquiring abundant annotations from experts compared to fully supervised methods, which is especially important for medical image segmentation which typically requires intensive pixel/voxel-wise labeling by domain experts. Although semi-supervised methods can improve the performance by utilizing unlabeled data, there are still gaps between fully supervised methods under extremely limited annotation scenarios. In this paper, we propose a simple yet efficient strategy to explore the usage of the Segment Anything Model (SAM) for enhancing semi-supervised medical image segmentation. Concretely, the segmentation model trained with domain knowledge provides information for localization and generating input prompts to the SAM. Then the generated pseudo-labels of SAM are utilized as additional supervision to assist in the learning procedure of the semi-supervised framework. Experimental results demonstrate that SAM's assistance significantly enhances the performance of existing semi-supervised frameworks, especially when only one or a few labeled images are available.","sentences":["Semi-supervised learning has attracted much attention due to its less dependence on acquiring abundant annotations from experts compared to fully supervised methods, which is especially important for medical image segmentation which typically requires intensive pixel/voxel-wise labeling by domain experts.","Although semi-supervised methods can improve the performance by utilizing unlabeled data, there are still gaps between fully supervised methods under extremely limited annotation scenarios.","In this paper, we propose a simple yet efficient strategy to explore the usage of the Segment Anything Model (SAM) for enhancing semi-supervised medical image segmentation.","Concretely, the segmentation model trained with domain knowledge provides information for localization and generating input prompts to the SAM.","Then the generated pseudo-labels of SAM are utilized as additional supervision to assist in the learning procedure of the semi-supervised framework.","Experimental results demonstrate that SAM's assistance significantly enhances the performance of existing semi-supervised frameworks, especially when only one or a few labeled images are available."],"url":"http://arxiv.org/abs/2312.06316v1"}
{"created":"2023-12-11 11:31:41","title":"An unsupervised learning approach to evaluate questionnaire data -- what one can learn from violations of measurement invariance","abstract":"In several branches of the social sciences and humanities, surveys based on standardized questionnaires are a prominent research tool. While there are a variety of ways to analyze the data, some standard procedures have become established. When those surveys want to analyze differences in the answer patterns of different groups (e.g., countries, gender, age, ...), these procedures can only be carried out in a meaningful way if there is measurement invariance, i.e., the measured construct has psychometric equivalence across groups. As recently raised as an open problem by Sauerwein et al. (2021), new evaluation methods that work in the absence of measurement invariance are needed.   This paper promotes an unsupervised learning-based approach to such research data by proposing a procedure that works in three phases: data preparation, clustering of questionnaires, and measuring similarity based on the obtained clustering and the properties of each group. We generate synthetic data in three data sets, which allows us to compare our approach with the PCA approach under measurement invariance and under violated measurement invariance. As a main result, we obtain that the approach provides a natural comparison between groups and a natural description of the response patterns of the groups. Moreover, it can be safely applied to a wide variety of data sets, even in the absence of measurement invariance. Finally, this approach allows us to translate (violations of) measurement invariance into a meaningful measure of similarity.","sentences":["In several branches of the social sciences and humanities, surveys based on standardized questionnaires are a prominent research tool.","While there are a variety of ways to analyze the data, some standard procedures have become established.","When those surveys want to analyze differences in the answer patterns of different groups (e.g., countries, gender, age, ...), these procedures can only be carried out in a meaningful way if there is measurement invariance, i.e., the measured construct has psychometric equivalence across groups.","As recently raised as an open problem by Sauerwein et al. (2021), new evaluation methods that work in the absence of measurement invariance are needed.   ","This paper promotes an unsupervised learning-based approach to such research data by proposing a procedure that works in three phases: data preparation, clustering of questionnaires, and measuring similarity based on the obtained clustering and the properties of each group.","We generate synthetic data in three data sets, which allows us to compare our approach with the PCA approach under measurement invariance and under violated measurement invariance.","As a main result, we obtain that the approach provides a natural comparison between groups and a natural description of the response patterns of the groups.","Moreover, it can be safely applied to a wide variety of data sets, even in the absence of measurement invariance.","Finally, this approach allows us to translate (violations of) measurement invariance into a meaningful measure of similarity."],"url":"http://arxiv.org/abs/2312.06309v1"}
{"created":"2023-12-11 11:02:07","title":"Musical Sonification of Daily Physical Activity Data: A Proof of Concept Study","abstract":"Previous research has shown that the temporal dynamics of human activity recorded by accelerometers share a similar structure with music. This opens the possibility to use musical sonification of motion data as a means of raising awareness of an individuals own daily physical activity and promote healthy activity behaviour, granted that human activity and music also share similar temporal structure. In this study a method was developed for quantifying the daily structure of human activity using multigranular temporal segmentation and applying it to produce musical sonifications. To that extent, two accelerometry recordings of physical activity were selected from a dataset, such that one shows more physical activity than the other. These data were segmented in different timescales so that segmentation boundaries at a given timescale have a corresponding boundary at a finer timescale, occurring at the same point in time. These properties are useful to display the hierarchical structure of daily events embedded in larger events, which is akin to musical structure. The segmented physical activity data for one day was mapped to musical sounds, resulting in two short musical pieces, one for each subject. A survey measured the extent to which people would identify the piece corresponding to the most active subject, resulting in a majority of correct answers. We propose that this method has potential to be a valuable and innovative technique for behavioural change. We discuss its potential to aid in interventions for behavioural change towards reducing sedentary behaviour and increasing physical activity.","sentences":["Previous research has shown that the temporal dynamics of human activity recorded by accelerometers share a similar structure with music.","This opens the possibility to use musical sonification of motion data as a means of raising awareness of an individuals own daily physical activity and promote healthy activity behaviour, granted that human activity and music also share similar temporal structure.","In this study a method was developed for quantifying the daily structure of human activity using multigranular temporal segmentation and applying it to produce musical sonifications.","To that extent, two accelerometry recordings of physical activity were selected from a dataset, such that one shows more physical activity than the other.","These data were segmented in different timescales so that segmentation boundaries at a given timescale have a corresponding boundary at a finer timescale, occurring at the same point in time.","These properties are useful to display the hierarchical structure of daily events embedded in larger events, which is akin to musical structure.","The segmented physical activity data for one day was mapped to musical sounds, resulting in two short musical pieces, one for each subject.","A survey measured the extent to which people would identify the piece corresponding to the most active subject, resulting in a majority of correct answers.","We propose that this method has potential to be a valuable and innovative technique for behavioural change.","We discuss its potential to aid in interventions for behavioural change towards reducing sedentary behaviour and increasing physical activity."],"url":"http://arxiv.org/abs/2312.06298v1"}
{"created":"2023-12-11 10:59:23","title":"MMDesign: Multi-Modality Transfer Learning for Generative Protein Design","abstract":"Protein design involves generating protein sequences based on their corresponding protein backbones. While deep generative models show promise for learning protein design directly from data, the lack of publicly available structure-sequence pairings limits their generalization capabilities. Previous efforts of generative protein design have focused on architectural improvements and pseudo-data augmentation to overcome this bottleneck. To further address this challenge, we propose a novel protein design paradigm called MMDesign, which leverages multi-modality transfer learning. To our knowledge, MMDesign is the first framework that combines a pretrained structural module with a pretrained contextual module, using an auto-encoder (AE) based language model to incorporate prior semantic knowledge of protein sequences. We also introduce a cross-layer cross-modal alignment algorithm to enable the structural module to learn long-term temporal information and ensure consistency between structural and contextual modalities. Experimental results, only training with the small CATH dataset, demonstrate that our MMDesign framework consistently outperforms other baselines on various public test sets. To further assess the biological plausibility of the generated protein sequences and data distribution, we present systematic quantitative analysis techniques that provide interpretability and reveal more about the laws of protein design.","sentences":["Protein design involves generating protein sequences based on their corresponding protein backbones.","While deep generative models show promise for learning protein design directly from data, the lack of publicly available structure-sequence pairings limits their generalization capabilities.","Previous efforts of generative protein design have focused on architectural improvements and pseudo-data augmentation to overcome this bottleneck.","To further address this challenge, we propose a novel protein design paradigm called MMDesign, which leverages multi-modality transfer learning.","To our knowledge, MMDesign is the first framework that combines a pretrained structural module with a pretrained contextual module, using an auto-encoder (AE) based language model to incorporate prior semantic knowledge of protein sequences.","We also introduce a cross-layer cross-modal alignment algorithm to enable the structural module to learn long-term temporal information and ensure consistency between structural and contextual modalities.","Experimental results, only training with the small CATH dataset, demonstrate that our MMDesign framework consistently outperforms other baselines on various public test sets.","To further assess the biological plausibility of the generated protein sequences and data distribution, we present systematic quantitative analysis techniques that provide interpretability and reveal more about the laws of protein design."],"url":"http://arxiv.org/abs/2312.06297v1"}
{"created":"2023-12-11 10:57:41","title":"Measuring Approximate Functional Dependencies: a Comparative Study","abstract":"Approximate functional dependencies (AFDs) are functional dependencies (FDs) that \"almost\" hold in a relation. While various measures have been proposed to quantify the level to which an FD holds approximately, they are difficult to compare and it is unclear which measure is preferable when one needs to discover FDs in real-world data, i.e., data that only approximately satisfies the FD. In response, this paper formally and qualitatively compares AFD measures. We obtain a formal comparison through a novel presentation of measures in terms of Shannon and logical entropy. Qualitatively, we perform a sensitivity analysis w.r.t. structural properties of input relations and quantitatively study the effectiveness of AFD measures for ranking AFDs on real world data. Based on this analysis, we give clear recommendations for the AFD measures to use in practice.","sentences":["Approximate functional dependencies (AFDs) are functional dependencies (FDs) that \"almost\" hold in a relation.","While various measures have been proposed to quantify the level to which an FD holds approximately, they are difficult to compare and it is unclear which measure is preferable when one needs to discover FDs in real-world data, i.e., data that only approximately satisfies the FD.","In response, this paper formally and qualitatively compares AFD measures.","We obtain a formal comparison through a novel presentation of measures in terms of Shannon and logical entropy.","Qualitatively, we perform a sensitivity analysis w.r.t.","structural properties of input relations and quantitatively study the effectiveness of AFD measures for ranking AFDs on real world data.","Based on this analysis, we give clear recommendations for the AFD measures to use in practice."],"url":"http://arxiv.org/abs/2312.06296v1"}
{"created":"2023-12-11 10:44:52","title":"Exploiting Label Skews in Federated Learning with Model Concatenation","abstract":"Federated Learning (FL) has emerged as a promising solution to perform deep learning on different data owners without exchanging raw data. However, non-IID data has been a key challenge in FL, which could significantly degrade the accuracy of the final model. Among different non-IID types, label skews have been challenging and common in image classification and other tasks. Instead of averaging the local models in most previous studies, we propose FedConcat, a simple and effective approach that concatenates these local models as the base of the global model to effectively aggregate the local knowledge. To reduce the size of the global model, we adopt the clustering technique to group the clients by their label distributions and collaboratively train a model inside each cluster. We theoretically analyze the advantage of concatenation over averaging by analyzing the information bottleneck of deep neural networks. Experimental results demonstrate that FedConcat achieves significantly higher accuracy than previous state-of-the-art FL methods in various heterogeneous label skew distribution settings and meanwhile has lower communication costs. Our code is publicly available.","sentences":["Federated Learning (FL) has emerged as a promising solution to perform deep learning on different data owners without exchanging raw data.","However, non-IID data has been a key challenge in FL, which could significantly degrade the accuracy of the final model.","Among different non-IID types, label skews have been challenging and common in image classification and other tasks.","Instead of averaging the local models in most previous studies, we propose FedConcat, a simple and effective approach that concatenates these local models as the base of the global model to effectively aggregate the local knowledge.","To reduce the size of the global model, we adopt the clustering technique to group the clients by their label distributions and collaboratively train a model inside each cluster.","We theoretically analyze the advantage of concatenation over averaging by analyzing the information bottleneck of deep neural networks.","Experimental results demonstrate that FedConcat achieves significantly higher accuracy than previous state-of-the-art FL methods in various heterogeneous label skew distribution settings and meanwhile has lower communication costs.","Our code is publicly available."],"url":"http://arxiv.org/abs/2312.06290v1"}
{"created":"2023-12-11 10:39:01","title":"Compensation Sampling for Improved Convergence in Diffusion Models","abstract":"Diffusion models achieve remarkable quality in image generation, but at a cost. Iterative denoising requires many time steps to produce high fidelity images. We argue that the denoising process is crucially limited by an accumulation of the reconstruction error due to an initial inaccurate reconstruction of the target data. This leads to lower quality outputs, and slower convergence. To address this issue, we propose compensation sampling to guide the generation towards the target domain. We introduce a compensation term, implemented as a U-Net, which adds negligible computation overhead during training and, optionally, inference. Our approach is flexible and we demonstrate its application in unconditional generation, face inpainting, and face de-occlusion using benchmark datasets CIFAR-10, CelebA, CelebA-HQ, FFHQ-256, and FSG. Our approach consistently yields state-of-the-art results in terms of image quality, while accelerating the denoising process to converge during training by up to an order of magnitude.","sentences":["Diffusion models achieve remarkable quality in image generation, but at a cost.","Iterative denoising requires many time steps to produce high fidelity images.","We argue that the denoising process is crucially limited by an accumulation of the reconstruction error due to an initial inaccurate reconstruction of the target data.","This leads to lower quality outputs, and slower convergence.","To address this issue, we propose compensation sampling to guide the generation towards the target domain.","We introduce a compensation term, implemented as a U-Net, which adds negligible computation overhead during training and, optionally, inference.","Our approach is flexible and we demonstrate its application in unconditional generation, face inpainting, and face de-occlusion using benchmark datasets CIFAR-10, CelebA, CelebA-HQ, FFHQ-256, and FSG.","Our approach consistently yields state-of-the-art results in terms of image quality, while accelerating the denoising process to converge during training by up to an order of magnitude."],"url":"http://arxiv.org/abs/2312.06285v1"}
{"created":"2023-12-11 10:37:28","title":"Extrapolating tipping points and simulating non-stationary dynamics of complex systems using efficient machine learning","abstract":"Model-free and data-driven prediction of tipping point transitions in nonlinear dynamical systems is a challenging and outstanding task in complex systems science. We propose a novel, fully data-driven machine learning algorithm based on next-generation reservoir computing to extrapolate the bifurcation behavior of nonlinear dynamical systems using stationary training data samples. We show that this method can extrapolate tipping point transitions. Furthermore, it is demonstrated that the trained next-generation reservoir computing architecture can be used to predict non-stationary dynamics with time-varying bifurcation parameters. In doing so, post-tipping point dynamics of unseen parameter regions can be simulated.","sentences":["Model-free and data-driven prediction of tipping point transitions in nonlinear dynamical systems is a challenging and outstanding task in complex systems science.","We propose a novel, fully data-driven machine learning algorithm based on next-generation reservoir computing to extrapolate the bifurcation behavior of nonlinear dynamical systems using stationary training data samples.","We show that this method can extrapolate tipping point transitions.","Furthermore, it is demonstrated that the trained next-generation reservoir computing architecture can be used to predict non-stationary dynamics with time-varying bifurcation parameters.","In doing so, post-tipping point dynamics of unseen parameter regions can be simulated."],"url":"http://arxiv.org/abs/2312.06283v1"}
{"created":"2023-12-11 10:33:19","title":"Regional Correlation Aided Mobile Traffic Prediction with Spatiotemporal Deep Learning","abstract":"Mobile traffic data in urban regions shows differentiated patterns during different hours of the day. The exploitation of these patterns enables highly accurate mobile traffic prediction for proactive network management. However, recent Deep Learning (DL) driven studies have only exploited spatiotemporal features and have ignored the geographical correlations, causing high complexity and erroneous mobile traffic predictions. This paper addresses these limitations by proposing an enhanced mobile traffic prediction scheme that combines the clustering strategy of daily mobile traffic peak time and novel multi Temporal Convolutional Network with a Long Short Term Memory (multi TCN-LSTM) model. The mobile network cells that exhibit peak traffic during the same hour of the day are clustered together. Our experiments on large-scale real-world mobile traffic data show up to 28% performance improvement compared to state-of-the-art studies, which confirms the efficacy and viability of the proposed approach.","sentences":["Mobile traffic data in urban regions shows differentiated patterns during different hours of the day.","The exploitation of these patterns enables highly accurate mobile traffic prediction for proactive network management.","However, recent Deep Learning (DL) driven studies have only exploited spatiotemporal features and have ignored the geographical correlations, causing high complexity and erroneous mobile traffic predictions.","This paper addresses these limitations by proposing an enhanced mobile traffic prediction scheme that combines the clustering strategy of daily mobile traffic peak time and novel multi Temporal Convolutional Network with a Long Short Term Memory (multi TCN-LSTM) model.","The mobile network cells that exhibit peak traffic during the same hour of the day are clustered together.","Our experiments on large-scale real-world mobile traffic data show up to 28% performance improvement compared to state-of-the-art studies, which confirms the efficacy and viability of the proposed approach."],"url":"http://arxiv.org/abs/2312.06279v1"}
{"created":"2023-12-11 10:28:29","title":"Experimental Evaluation of Methods for Estimating Frequency Response Functions of a 6-axes Robot","abstract":"Nonparametric estimates of frequency response functions (FRFs) are often suitable for describing the dynamics of a mechanical system. If treating these estimates as measurement inputs, they can be used for parametric identification of, e.g., a gray-box model. Classical methods for nonparametric FRF estimation of MIMO systems require at least as many experiments as the system has inputs. Local parametric FRF estimation methods have been developed for avoiding multiple experiments. In this paper, these local methods are adapted and applied for estimating the FRFs of a 6-axes robotic manipulator, which is a nonlinear MIMO system operating in closed loop. The aim is to reduce the experiment time and amount of data needed for identification. The resulting FRFs are analyzed in an experimental study and compared to estimates obtained by classical MIMO techniques. It is furthermore shown that an accurate parametric model identification is possible based on local parametric FRF estimates and that the total experiment time can be significantly reduced.","sentences":["Nonparametric estimates of frequency response functions (FRFs) are often suitable for describing the dynamics of a mechanical system.","If treating these estimates as measurement inputs, they can be used for parametric identification of, e.g., a gray-box model.","Classical methods for nonparametric FRF estimation of MIMO systems require at least as many experiments as the system has inputs.","Local parametric FRF estimation methods have been developed for avoiding multiple experiments.","In this paper, these local methods are adapted and applied for estimating the FRFs of a 6-axes robotic manipulator, which is a nonlinear MIMO system operating in closed loop.","The aim is to reduce the experiment time and amount of data needed for identification.","The resulting FRFs are analyzed in an experimental study and compared to estimates obtained by classical MIMO techniques.","It is furthermore shown that an accurate parametric model identification is possible based on local parametric FRF estimates and that the total experiment time can be significantly reduced."],"url":"http://arxiv.org/abs/2312.06276v1"}
{"created":"2023-12-11 10:26:21","title":"DG-TTA: Out-of-domain medical image segmentation through Domain Generalization and Test-Time Adaptation","abstract":"Applying pre-trained medical segmentation models on out-of-domain images often yields predictions of insufficient quality. Several strategies have been proposed to maintain model performance, such as finetuning or unsupervised- and source-free domain adaptation. These strategies set restrictive requirements for data availability. In this study, we propose to combine domain generalization and test-time adaptation to create a highly effective approach for reusing pre-trained models in unseen target domains. Domain-generalized pre-training on source data is used to obtain the best initial performance in the target domain. We introduce the MIND descriptor previously used in image registration tasks as a further technique to achieve generalization and present superior performance for small-scale datasets compared to existing approaches. At test-time, high-quality segmentation for every single unseen scan is ensured by optimizing the model weights for consistency given different image augmentations. That way, our method enables separate use of source and target data and thus removes current data availability barriers. Moreover, the presented method is highly modular as it does not require specific model architectures or prior knowledge of involved domains and labels. We demonstrate this by integrating it into the nnUNet, which is currently the most popular and accurate framework for medical image segmentation. We employ multiple datasets covering abdominal, cardiac, and lumbar spine scans and compose several out-of-domain scenarios in this study. We demonstrate that our method, combined with pre-trained whole-body CT models, can effectively segment MR images with high accuracy in all of the aforementioned scenarios. Open-source code can be found here: https://github.com/multimodallearning/DG-TTA","sentences":["Applying pre-trained medical segmentation models on out-of-domain images often yields predictions of insufficient quality.","Several strategies have been proposed to maintain model performance, such as finetuning or unsupervised- and source-free domain adaptation.","These strategies set restrictive requirements for data availability.","In this study, we propose to combine domain generalization and test-time adaptation to create a highly effective approach for reusing pre-trained models in unseen target domains.","Domain-generalized pre-training on source data is used to obtain the best initial performance in the target domain.","We introduce the MIND descriptor previously used in image registration tasks as a further technique to achieve generalization and present superior performance for small-scale datasets compared to existing approaches.","At test-time, high-quality segmentation for every single unseen scan is ensured by optimizing the model weights for consistency given different image augmentations.","That way, our method enables separate use of source and target data and thus removes current data availability barriers.","Moreover, the presented method is highly modular as it does not require specific model architectures or prior knowledge of involved domains and labels.","We demonstrate this by integrating it into the nnUNet, which is currently the most popular and accurate framework for medical image segmentation.","We employ multiple datasets covering abdominal, cardiac, and lumbar spine scans and compose several out-of-domain scenarios in this study.","We demonstrate that our method, combined with pre-trained whole-body CT models, can effectively segment MR images with high accuracy in all of the aforementioned scenarios.","Open-source code can be found here: https://github.com/multimodallearning/DG-TTA"],"url":"http://arxiv.org/abs/2312.06275v1"}
{"created":"2023-12-11 10:19:55","title":"Regroup Median Loss for Combating Label Noise","abstract":"The deep model training procedure requires large-scale datasets of annotated data. Due to the difficulty of annotating a large number of samples, label noise caused by incorrect annotations is inevitable, resulting in low model performance and poor model generalization. To combat label noise, current methods usually select clean samples based on the small-loss criterion and use these samples for training. Due to some noisy samples similar to clean ones, these small-loss criterion-based methods are still affected by label noise. To address this issue, in this work, we propose Regroup Median Loss (RML) to reduce the probability of selecting noisy samples and correct losses of noisy samples. RML randomly selects samples with the same label as the training samples based on a new loss processing method. Then, we combine the stable mean loss and the robust median loss through a proposed regrouping strategy to obtain robust loss estimation for noisy samples. To further improve the model performance against label noise, we propose a new sample selection strategy and build a semi-supervised method based on RML. Compared to state-of-the-art methods, for both the traditionally trained and semi-supervised models, RML achieves a significant improvement on synthetic and complex real-world datasets. The source code of the paper has been released.","sentences":["The deep model training procedure requires large-scale datasets of annotated data.","Due to the difficulty of annotating a large number of samples, label noise caused by incorrect annotations is inevitable, resulting in low model performance and poor model generalization.","To combat label noise, current methods usually select clean samples based on the small-loss criterion and use these samples for training.","Due to some noisy samples similar to clean ones, these small-loss criterion-based methods are still affected by label noise.","To address this issue, in this work, we propose Regroup Median Loss (RML) to reduce the probability of selecting noisy samples and correct losses of noisy samples.","RML randomly selects samples with the same label as the training samples based on a new loss processing method.","Then, we combine the stable mean loss and the robust median loss through a proposed regrouping strategy to obtain robust loss estimation for noisy samples.","To further improve the model performance against label noise, we propose a new sample selection strategy and build a semi-supervised method based on RML.","Compared to state-of-the-art methods, for both the traditionally trained and semi-supervised models, RML achieves a significant improvement on synthetic and complex real-world datasets.","The source code of the paper has been released."],"url":"http://arxiv.org/abs/2312.06273v1"}
{"created":"2023-12-11 10:04:05","title":"Creating Spoken Dialog Systems in Ultra-Low Resourced Settings","abstract":"Automatic Speech Recognition (ASR) systems are a crucial technology that is used today to design a wide variety of applications, most notably, smart assistants, such as Alexa. ASR systems are essentially dialogue systems that employ Spoken Language Understanding (SLU) to extract meaningful information from speech. The main challenge with designing such systems is that they require a huge amount of labeled clean data to perform competitively, such data is extremely hard to collect and annotate to respective SLU tasks, furthermore, when designing such systems for low resource languages, where data is extremely limited, the severity of the problem intensifies. In this paper, we focus on a fairly popular SLU task, that is, Intent Classification while working with a low resource language, namely, Flemish. Intent Classification is a task concerned with understanding the intents of the user interacting with the system. We build on existing light models for intent classification in Flemish, and our main contribution is applying different augmentation techniques on two levels -- the voice level, and the phonetic transcripts level -- to the existing models to counter the problem of scarce labeled data in low-resource languages. We find that our data augmentation techniques, on both levels, have improved the model performance on a number of tasks.","sentences":["Automatic Speech Recognition (ASR) systems are a crucial technology that is used today to design a wide variety of applications, most notably, smart assistants, such as Alexa.","ASR systems are essentially dialogue systems that employ Spoken Language Understanding (SLU) to extract meaningful information from speech.","The main challenge with designing such systems is that they require a huge amount of labeled clean data to perform competitively, such data is extremely hard to collect and annotate to respective SLU tasks, furthermore, when designing such systems for low resource languages, where data is extremely limited, the severity of the problem intensifies.","In this paper, we focus on a fairly popular SLU task, that is, Intent Classification while working with a low resource language, namely, Flemish.","Intent Classification is a task concerned with understanding the intents of the user interacting with the system.","We build on existing light models for intent classification in Flemish, and our main contribution is applying different augmentation techniques on two levels -- the voice level, and the phonetic transcripts level -- to the existing models to counter the problem of scarce labeled data in low-resource languages.","We find that our data augmentation techniques, on both levels, have improved the model performance on a number of tasks."],"url":"http://arxiv.org/abs/2312.06266v1"}
{"created":"2023-12-11 09:58:46","title":"Survey on Foundation Models for Prognostics and Health Management in Industrial Cyber-Physical Systems","abstract":"Industrial Cyber-Physical Systems (ICPS) integrate the disciplines of computer science, communication technology, and engineering, and have emerged as integral components of contemporary manufacturing and industries. However, ICPS encounters various challenges in long-term operation, including equipment failures, performance degradation, and security threats. To achieve efficient maintenance and management, prognostics and health management (PHM) finds widespread application in ICPS for critical tasks, including failure prediction, health monitoring, and maintenance decision-making. The emergence of large-scale foundation models (LFMs) like BERT and GPT signifies a significant advancement in AI technology, and ChatGPT stands as a remarkable accomplishment within this research paradigm, harboring potential for General Artificial Intelligence. Considering the ongoing enhancement in data acquisition technology and data processing capability, LFMs are anticipated to assume a crucial role in the PHM domain of ICPS. However, at present, a consensus is lacking regarding the application of LFMs to PHM in ICPS, necessitating systematic reviews and roadmaps to elucidate future directions. To bridge this gap, this paper elucidates the key components and recent advances in the underlying model.A comprehensive examination and comprehension of the latest advances in grand modeling for PHM in ICPS can offer valuable references for decision makers and researchers in the industrial field while facilitating further enhancements in the reliability, availability, and safety of ICPS.","sentences":["Industrial Cyber-Physical Systems (ICPS) integrate the disciplines of computer science, communication technology, and engineering, and have emerged as integral components of contemporary manufacturing and industries.","However, ICPS encounters various challenges in long-term operation, including equipment failures, performance degradation, and security threats.","To achieve efficient maintenance and management, prognostics and health management (PHM) finds widespread application in ICPS for critical tasks, including failure prediction, health monitoring, and maintenance decision-making.","The emergence of large-scale foundation models (LFMs) like BERT and GPT signifies a significant advancement in AI technology, and ChatGPT stands as a remarkable accomplishment within this research paradigm, harboring potential for General Artificial Intelligence.","Considering the ongoing enhancement in data acquisition technology and data processing capability, LFMs are anticipated to assume a crucial role in the PHM domain of ICPS.","However, at present, a consensus is lacking regarding the application of LFMs to PHM in ICPS, necessitating systematic reviews and roadmaps to elucidate future directions.","To bridge this gap, this paper elucidates the key components and recent advances in the underlying model.","A comprehensive examination and comprehension of the latest advances in grand modeling for PHM in ICPS can offer valuable references for decision makers and researchers in the industrial field while facilitating further enhancements in the reliability, availability, and safety of ICPS."],"url":"http://arxiv.org/abs/2312.06261v1"}
{"created":"2023-12-11 09:50:52","title":"Modyn: A Platform for Model Training on Dynamic Datasets With Sample-Level Data Selection","abstract":"Machine learning training data is often dynamic in real-world use cases, i.e., data is added or removed and may experience distribution shifts over time. Models must incorporate this evolving training data to improve generalization, adapt to potential distribution shifts, and adhere to privacy regulations. However, the cost of model (re)training is proportional to how often the model trains and on how much data it trains on. While ML research explores these topics in isolation, there is no end-to-end open-source platform to facilitate the exploration of model retraining and data selection policies and the deployment these algorithms efficiently at scale.   We present Modyn, a platform for model training on dynamic datasets that enables sample-level data selection and triggering policies. Modyn orchestrates continuous training pipelines while optimizing the underlying system infrastructure to support fast access to arbitrary data samples for efficient data selection. Modyn's extensible architecture allows users to run training pipelines without modifying the platform code, and enables researchers to effortlessly extend the system. We evaluate Modyn's training throughput, showing that even in memory-bound recommendation systems workloads, Modyn is able to reach 80 to 100 % of the throughput compared to loading big chunks of data locally without sample-level data selection. Additionally, we showcase Modyn's functionality with three different data selection policies.","sentences":["Machine learning training data is often dynamic in real-world use cases, i.e., data is added or removed and may experience distribution shifts over time.","Models must incorporate this evolving training data to improve generalization, adapt to potential distribution shifts, and adhere to privacy regulations.","However, the cost of model (re)training is proportional to how often the model trains and on how much data it trains on.","While ML research explores these topics in isolation, there is no end-to-end open-source platform to facilitate the exploration of model retraining and data selection policies and the deployment these algorithms efficiently at scale.   ","We present Modyn, a platform for model training on dynamic datasets that enables sample-level data selection and triggering policies.","Modyn orchestrates continuous training pipelines while optimizing the underlying system infrastructure to support fast access to arbitrary data samples for efficient data selection.","Modyn's extensible architecture allows users to run training pipelines without modifying the platform code, and enables researchers to effortlessly extend the system.","We evaluate Modyn's training throughput, showing that even in memory-bound recommendation systems workloads, Modyn is able to reach 80 to 100 % of the throughput compared to loading big chunks of data locally without sample-level data selection.","Additionally, we showcase Modyn's functionality with three different data selection policies."],"url":"http://arxiv.org/abs/2312.06254v1"}
{"created":"2023-12-11 09:30:09","title":"Team-related Features in Code Review Prediction Models","abstract":"Modern Code Review (MCR) is an informal tool-assisted quality assurance practice. It relies on the asynchronous communication among the authors of code changes and reviewers, who are developers that provide feedback. However, from candidate developers, some are able to provide better feedback than others given a particular context. The selection of reviewers is thus an important task, which can benefit from automated support. Many approaches have been proposed in this direction, using for example data from code review repositories to recommend reviewers. In this paper, we propose the use of team-related features to improve the performance of predictions that are helpful to build code reviewer recommenders, with our target predictions being the identification of reviewers that would participate in a review and the provided amount of feedback. We evaluate the prediction power of these features, which are related to code ownership, workload, and team relationship. This evaluation was done by carefully addressing challenges imposed by the MCR domain, such as temporal aspects of the dataset and unbalanced classes. Moreover, given that it is currently unknown how much past data is needed for building MCR prediction models with acceptable performance, we explore the amount of past data used to build prediction models. Our results show that, individually, features related to code ownership have the best prediction power. However, based on feature selection, we conclude that all proposed features together with lines of code can make the best predictions for both reviewer participation and amount of feedback. Regarding the amount of past data, the timeframes of 3, 6, 9, and 12 months of data produce similar results. Therefore, models can be trained considering short timeframes, thus reducing the computational costs with negligible impact in the prediction performance ...","sentences":["Modern Code Review (MCR) is an informal tool-assisted quality assurance practice.","It relies on the asynchronous communication among the authors of code changes and reviewers, who are developers that provide feedback.","However, from candidate developers, some are able to provide better feedback than others given a particular context.","The selection of reviewers is thus an important task, which can benefit from automated support.","Many approaches have been proposed in this direction, using for example data from code review repositories to recommend reviewers.","In this paper, we propose the use of team-related features to improve the performance of predictions that are helpful to build code reviewer recommenders, with our target predictions being the identification of reviewers that would participate in a review and the provided amount of feedback.","We evaluate the prediction power of these features, which are related to code ownership, workload, and team relationship.","This evaluation was done by carefully addressing challenges imposed by the MCR domain, such as temporal aspects of the dataset and unbalanced classes.","Moreover, given that it is currently unknown how much past data is needed for building MCR prediction models with acceptable performance, we explore the amount of past data used to build prediction models.","Our results show that, individually, features related to code ownership have the best prediction power.","However, based on feature selection, we conclude that all proposed features together with lines of code can make the best predictions for both reviewer participation and amount of feedback.","Regarding the amount of past data, the timeframes of 3, 6, 9, and 12 months of data produce similar results.","Therefore, models can be trained considering short timeframes, thus reducing the computational costs with negligible impact in the prediction performance ..."],"url":"http://arxiv.org/abs/2312.06244v1"}
{"created":"2023-12-11 09:22:18","title":"Improving Startup Success with Text Analysis","abstract":"Investors are interested in predicting future success of startup companies, preferably using publicly available data which can be gathered using free online sources. Using public-only data has been shown to work, but there is still much room for improvement. Two of the best performing prediction experiments use 17 and 49 features respectively, mostly numeric and categorical in nature. In this paper, we significantly expand and diversify both the sources and the number of features (to 171) to achieve better prediction. Data collected from Crunchbase, the Google Search API, and Twitter (now X) are used to predict whether a company will raise a round of funding within a fixed time horizon. Much of the new features are textual and the Twitter subset include linguistic metrics such as measures of passive voice and parts-of-speech. A total of ten machine learning models are also evaluated for best performance. The adaptable model can be used to predict funding 1-5 years into the future, with a variable cutoff threshold to favor either precision or recall. Prediction with comparable assumptions generally achieves F scores above 0.730 which outperforms previous attempts in the literature (0.531), and does so with fewer examples. Furthermore, we find that the vast majority of the performance impact comes from the top 18 of 171 features which are mostly generic company observations, including the best performing individual feature which is the free-form text description of the company.","sentences":["Investors are interested in predicting future success of startup companies, preferably using publicly available data which can be gathered using free online sources.","Using public-only data has been shown to work, but there is still much room for improvement.","Two of the best performing prediction experiments use 17 and 49 features respectively, mostly numeric and categorical in nature.","In this paper, we significantly expand and diversify both the sources and the number of features (to 171) to achieve better prediction.","Data collected from Crunchbase, the Google Search API, and Twitter (now X) are used to predict whether a company will raise a round of funding within a fixed time horizon.","Much of the new features are textual and the Twitter subset include linguistic metrics such as measures of passive voice and parts-of-speech.","A total of ten machine learning models are also evaluated for best performance.","The adaptable model can be used to predict funding 1-5 years into the future, with a variable cutoff threshold to favor either precision or recall.","Prediction with comparable assumptions generally achieves F scores above 0.730 which outperforms previous attempts in the literature (0.531), and does so with fewer examples.","Furthermore, we find that the vast majority of the performance impact comes from the top 18 of 171 features which are mostly generic company observations, including the best performing individual feature which is the free-form text description of the company."],"url":"http://arxiv.org/abs/2312.06236v1"}
{"created":"2023-12-11 09:17:33","title":"Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks","abstract":"This work focuses on defending against the data poisoning based backdoor attacks, which bring in serious security threats to deep neural networks (DNNs). Specifically, given a untrustworthy training dataset, we aim to filter out potential poisoned samples, \\ie, poisoned sample detection (PSD). The key solution for this task is to find a discriminative metric between clean and poisoned samples, even though there is no information about the potential poisoned samples (\\eg, the attack method, the poisoning ratio). In this work, we develop an innovative detection approach from the perspective of the gradient \\wrt activation (\\ie, activation gradient direction, AGD) of each sample in the backdoored model trained on the untrustworthy dataset. We present an interesting observation that the circular distribution of AGDs among all samples of the target class is much more dispersed than that of one clean class. Motivated by this observation, we firstly design a novel metric called Cosine similarity Variation towards Basis Transition (CVBT) to measure the circular distribution's dispersion of each class. Then, we design a simple yet effective algorithm with identifying the target class(es) using outlier detection on CVBT scores of all classes, followed by progressively filtering of poisoned samples according to the cosine similarities of AGDs between every potential sample and a few additional clean samples. Extensive experiments under various settings verify that given very few clean samples of each class, the proposed method could filter out most poisoned samples, while avoiding filtering out clean samples, verifying its effectiveness on the PSD task. Codes are available at https://github.com/SCLBD/bdzoo2/blob/dev/detection_pretrain/agpd.py.","sentences":["This work focuses on defending against the data poisoning based backdoor attacks, which bring in serious security threats to deep neural networks (DNNs).","Specifically, given a untrustworthy training dataset, we aim to filter out potential poisoned samples, \\ie, poisoned sample detection (PSD).","The key solution for this task is to find a discriminative metric between clean and poisoned samples, even though there is no information about the potential poisoned samples (\\eg, the attack method, the poisoning ratio).","In this work, we develop an innovative detection approach from the perspective of the gradient \\wrt activation (\\ie, activation gradient direction, AGD) of each sample in the backdoored model trained on the untrustworthy dataset.","We present an interesting observation that the circular distribution of AGDs among all samples of the target class is much more dispersed than that of one clean class.","Motivated by this observation, we firstly design a novel metric called Cosine similarity Variation towards Basis Transition (CVBT) to measure the circular distribution's dispersion of each class.","Then, we design a simple yet effective algorithm with identifying the target class(es) using outlier detection on CVBT scores of all classes, followed by progressively filtering of poisoned samples according to the cosine similarities of AGDs between every potential sample and a few additional clean samples.","Extensive experiments under various settings verify that given very few clean samples of each class, the proposed method could filter out most poisoned samples, while avoiding filtering out clean samples, verifying its effectiveness on the PSD task.","Codes are available at https://github.com/SCLBD/bdzoo2/blob/dev/detection_pretrain/agpd.py."],"url":"http://arxiv.org/abs/2312.06230v1"}
{"created":"2023-12-11 09:14:13","title":"Medical Vision Language Pretraining: A survey","abstract":"Medical Vision Language Pretraining (VLP) has recently emerged as a promising solution to the scarcity of labeled data in the medical domain. By leveraging paired/unpaired vision and text datasets through self-supervised learning, models can be trained to acquire vast knowledge and learn robust feature representations. Such pretrained models have the potential to enhance multiple downstream medical tasks simultaneously, reducing the dependency on labeled data. However, despite recent progress and its potential, there is no such comprehensive survey paper that has explored the various aspects and advancements in medical VLP. In this paper, we specifically review existing works through the lens of different pretraining objectives, architectures, downstream evaluation tasks, and datasets utilized for pretraining and downstream tasks. Subsequently, we delve into current challenges in medical VLP, discussing existing and potential solutions, and conclude by highlighting future directions. To the best of our knowledge, this is the first survey focused on medical VLP.","sentences":["Medical Vision Language Pretraining (VLP) has recently emerged as a promising solution to the scarcity of labeled data in the medical domain.","By leveraging paired/unpaired vision and text datasets through self-supervised learning, models can be trained to acquire vast knowledge and learn robust feature representations.","Such pretrained models have the potential to enhance multiple downstream medical tasks simultaneously, reducing the dependency on labeled data.","However, despite recent progress and its potential, there is no such comprehensive survey paper that has explored the various aspects and advancements in medical VLP.","In this paper, we specifically review existing works through the lens of different pretraining objectives, architectures, downstream evaluation tasks, and datasets utilized for pretraining and downstream tasks.","Subsequently, we delve into current challenges in medical VLP, discussing existing and potential solutions, and conclude by highlighting future directions.","To the best of our knowledge, this is the first survey focused on medical VLP."],"url":"http://arxiv.org/abs/2312.06224v1"}
{"created":"2023-12-11 09:10:38","title":"Dance of Channel and Sequence: An Efficient Attention-Based Approach for Multivariate Time Series Forecasting","abstract":"In recent developments, predictive models for multivariate time series analysis have exhibited commendable performance through the adoption of the prevalent principle of channel independence. Nevertheless, it is imperative to acknowledge the intricate interplay among channels, which fundamentally influences the outcomes of multivariate predictions. Consequently, the notion of channel independence, while offering utility to a certain extent, becomes increasingly impractical, leading to information degradation. In response to this pressing concern, we present CSformer, an innovative framework characterized by a meticulously engineered two-stage self-attention mechanism. This mechanism is purposefully designed to enable the segregated extraction of sequence-specific and channel-specific information, while sharing parameters to promote synergy and mutual reinforcement between sequences and channels. Simultaneously, we introduce sequence adapters and channel adapters, ensuring the model's ability to discern salient features across various dimensions. Rigorous experimentation, spanning multiple real-world datasets, underscores the robustness of our approach, consistently establishing its position at the forefront of predictive performance across all datasets. This augmentation substantially enhances the capacity for feature extraction inherent to multivariate time series data, facilitating a more comprehensive exploitation of the available information.","sentences":["In recent developments, predictive models for multivariate time series analysis have exhibited commendable performance through the adoption of the prevalent principle of channel independence.","Nevertheless, it is imperative to acknowledge the intricate interplay among channels, which fundamentally influences the outcomes of multivariate predictions.","Consequently, the notion of channel independence, while offering utility to a certain extent, becomes increasingly impractical, leading to information degradation.","In response to this pressing concern, we present CSformer, an innovative framework characterized by a meticulously engineered two-stage self-attention mechanism.","This mechanism is purposefully designed to enable the segregated extraction of sequence-specific and channel-specific information, while sharing parameters to promote synergy and mutual reinforcement between sequences and channels.","Simultaneously, we introduce sequence adapters and channel adapters, ensuring the model's ability to discern salient features across various dimensions.","Rigorous experimentation, spanning multiple real-world datasets, underscores the robustness of our approach, consistently establishing its position at the forefront of predictive performance across all datasets.","This augmentation substantially enhances the capacity for feature extraction inherent to multivariate time series data, facilitating a more comprehensive exploitation of the available information."],"url":"http://arxiv.org/abs/2312.06220v1"}
{"created":"2023-12-11 08:50:28","title":"Phase-field chemo-mechanical modelling of corrosion-induced cracking in reinforced concrete subjected to non-uniform chloride-induced corrosion","abstract":"A model for corrosion-induced cracking of reinforced concrete subjected to non-uniform chloride-induced corrosion is presented. The gradual corrosion initiation of the steel surface is investigated by simulating chloride transport considering binding. The transport of iron from the steel surface, its subsequent precipitation into rust, and the associated precipitation-induced pressure are explicitly modelled. Model results, obtained through finite element simulations, agree very well with experimental data, showing significantly improved accuracy over uniform corrosion modelling. The results obtained from case studies reveal that crack-facilitated transport of chlorides cannot be neglected, that the size of the anodic region must be considered, and that precipitate accumulation in pores can take years.","sentences":["A model for corrosion-induced cracking of reinforced concrete subjected to non-uniform chloride-induced corrosion is presented.","The gradual corrosion initiation of the steel surface is investigated by simulating chloride transport considering binding.","The transport of iron from the steel surface, its subsequent precipitation into rust, and the associated precipitation-induced pressure are explicitly modelled.","Model results, obtained through finite element simulations, agree very well with experimental data, showing significantly improved accuracy over uniform corrosion modelling.","The results obtained from case studies reveal that crack-facilitated transport of chlorides cannot be neglected, that the size of the anodic region must be considered, and that precipitate accumulation in pores can take years."],"url":"http://arxiv.org/abs/2312.06209v1"}
{"created":"2023-12-11 08:41:50","title":"A Primer on RecoNIC: RDMA-enabled Compute Offloading on SmartNIC","abstract":"Today's data centers consist of thousands of network-connected hosts, each with CPUs and accelerators such as GPUs and FPGAs. These hosts also contain network interface cards (NICs), operating at speeds of 100Gb/s or higher, that are used to communicate with each other. We propose RecoNIC, an FPGA-based RDMA-enabled SmartNIC platform that is designed for compute acceleration while minimizing the overhead associated with data copies (in CPU-centric accelerator systems) by bringing network data as close to computation as possible. Since RDMA is the defacto transport-layer protocol for improved communication in data center workloads, RecoNIC includes an RDMA offload engine for high throughput and low latency data transfers. Developers have the flexibility to design their accelerators using RTL, HLS or Vitis Networking P4 within the RecoNIC's programmable compute blocks. These compute blocks can access host memory as well as memory in remote peers through the RDMA offload engine. Furthermore, the RDMA offload engine is shared by both the host and compute blocks, which makes RecoNIC a very flexible platform. Lastly, we have open-sourced RecoNIC for the research community to enable experimentation with RDMA-based applications and use-cases.","sentences":["Today's data centers consist of thousands of network-connected hosts, each with CPUs and accelerators such as GPUs and FPGAs.","These hosts also contain network interface cards (NICs), operating at speeds of 100Gb/s or higher, that are used to communicate with each other.","We propose RecoNIC, an FPGA-based RDMA-enabled SmartNIC platform that is designed for compute acceleration while minimizing the overhead associated with data copies (in CPU-centric accelerator systems) by bringing network data as close to computation as possible.","Since RDMA is the defacto transport-layer protocol for improved communication in data center workloads, RecoNIC includes an RDMA offload engine for high throughput and low latency data transfers.","Developers have the flexibility to design their accelerators using RTL, HLS or Vitis Networking P4 within the RecoNIC's programmable compute blocks.","These compute blocks can access host memory as well as memory in remote peers through the RDMA offload engine.","Furthermore, the RDMA offload engine is shared by both the host and compute blocks, which makes RecoNIC a very flexible platform.","Lastly, we have open-sourced RecoNIC for the research community to enable experimentation with RDMA-based applications and use-cases."],"url":"http://arxiv.org/abs/2312.06207v1"}
{"created":"2023-12-11 08:39:43","title":"The Journey, Not the Destination: How Data Guides Diffusion Models","abstract":"Diffusion models trained on large datasets can synthesize photo-realistic images of remarkable quality and diversity. However, attributing these images back to the training data-that is, identifying specific training examples which caused an image to be generated-remains a challenge. In this paper, we propose a framework that: (i) provides a formal notion of data attribution in the context of diffusion models, and (ii) allows us to counterfactually validate such attributions. Then, we provide a method for computing these attributions efficiently. Finally, we apply our method to find (and evaluate) such attributions for denoising diffusion probabilistic models trained on CIFAR-10 and latent diffusion models trained on MS COCO. We provide code at https://github.com/MadryLab/journey-TRAK .","sentences":["Diffusion models trained on large datasets can synthesize photo-realistic images of remarkable quality and diversity.","However, attributing these images back to the training data-that is, identifying specific training examples which caused an image to be generated-remains a challenge.","In this paper, we propose a framework that: (i) provides a formal notion of data attribution in the context of diffusion models, and (ii) allows us to counterfactually validate such attributions.","Then, we provide a method for computing these attributions efficiently.","Finally, we apply our method to find (and evaluate) such attributions for denoising diffusion probabilistic models trained on CIFAR-10 and latent diffusion models trained on MS COCO.","We provide code at https://github.com/MadryLab/journey-TRAK ."],"url":"http://arxiv.org/abs/2312.06205v1"}
{"created":"2023-12-11 08:15:49","title":"NutritionVerse-Synth: An Open Access Synthetically Generated 2D Food Scene Dataset for Dietary Intake Estimation","abstract":"Manually tracking nutritional intake via food diaries is error-prone and burdensome. Automated computer vision techniques show promise for dietary monitoring but require large and diverse food image datasets. To address this need, we introduce NutritionVerse-Synth (NV-Synth), a large-scale synthetic food image dataset. NV-Synth contains 84,984 photorealistic meal images rendered from 7,082 dynamically plated 3D scenes. Each scene is captured from 12 viewpoints and includes perfect ground truth annotations such as RGB, depth, semantic, instance, and amodal segmentation masks, bounding boxes, and detailed nutritional information per food item. We demonstrate the diversity of NV-Synth across foods, compositions, viewpoints, and lighting. As the largest open-source synthetic food dataset, NV-Synth highlights the value of physics-based simulations for enabling scalable and controllable generation of diverse photorealistic meal images to overcome data limitations and drive advancements in automated dietary assessment using computer vision. In addition to the dataset, the source code for our data generation framework is also made publicly available at https://saeejithnair.github.io/nvsynth.","sentences":["Manually tracking nutritional intake via food diaries is error-prone and burdensome.","Automated computer vision techniques show promise for dietary monitoring but require large and diverse food image datasets.","To address this need, we introduce NutritionVerse-Synth (NV-Synth), a large-scale synthetic food image dataset.","NV-Synth contains 84,984 photorealistic meal images rendered from 7,082 dynamically plated 3D scenes.","Each scene is captured from 12 viewpoints and includes perfect ground truth annotations such as RGB, depth, semantic, instance, and amodal segmentation masks, bounding boxes, and detailed nutritional information per food item.","We demonstrate the diversity of NV-Synth across foods, compositions, viewpoints, and lighting.","As the largest open-source synthetic food dataset, NV-Synth highlights the value of physics-based simulations for enabling scalable and controllable generation of diverse photorealistic meal images to overcome data limitations and drive advancements in automated dietary assessment using computer vision.","In addition to the dataset, the source code for our data generation framework is also made publicly available at https://saeejithnair.github.io/nvsynth."],"url":"http://arxiv.org/abs/2312.06192v1"}
{"created":"2023-12-11 08:12:01","title":"From Ultra-Fine to Fine: Fine-tuning Ultra-Fine Entity Typing Models to Fine-grained","abstract":"For the task of fine-grained entity typing (FET), due to the use of a large number of entity types, it is usually considered too costly to manually annotating a training dataset that contains an ample number of examples for each type. A common way to address this problem is to use distantly annotated training data that contains incorrect labels. However, the performance of models trained solely with such data can be limited by the errors in the automatic annotation. Recently, there are a few approaches that no longer follow this conventional way. But without using sufficient direct entity typing supervision may also cause them to yield inferior performance. In this paper, we propose a new approach that can avoid the need of creating distantly labeled data whenever there is a new type schema. We first train an entity typing model that have an extremely board type coverage by using the ultra-fine entity typing data. Then, when there is a need to produce a model for a newly designed fine-grained entity type schema. We can simply fine-tune the previously trained model with a small number of examples annotated under this schema. Experimental results show that our approach achieves outstanding performance for FET under the few-shot setting. It can also outperform state-of-the-art weak supervision based methods after fine-tuning the model with only a small size manually annotated training set.","sentences":["For the task of fine-grained entity typing (FET), due to the use of a large number of entity types, it is usually considered too costly to manually annotating a training dataset that contains an ample number of examples for each type.","A common way to address this problem is to use distantly annotated training data that contains incorrect labels.","However, the performance of models trained solely with such data can be limited by the errors in the automatic annotation.","Recently, there are a few approaches that no longer follow this conventional way.","But without using sufficient direct entity typing supervision may also cause them to yield inferior performance.","In this paper, we propose a new approach that can avoid the need of creating distantly labeled data whenever there is a new type schema.","We first train an entity typing model that have an extremely board type coverage by using the ultra-fine entity typing data.","Then, when there is a need to produce a model for a newly designed fine-grained entity type schema.","We can simply fine-tune the previously trained model with a small number of examples annotated under this schema.","Experimental results show that our approach achieves outstanding performance for FET under the few-shot setting.","It can also outperform state-of-the-art weak supervision based methods after fine-tuning the model with only a small size manually annotated training set."],"url":"http://arxiv.org/abs/2312.06188v1"}
{"created":"2023-12-11 07:36:45","title":"Dynamic Weighted Combiner for Mixed-Modal Image Retrieval","abstract":"Mixed-Modal Image Retrieval (MMIR) as a flexible search paradigm has attracted wide attention. However, previous approaches always achieve limited performance, due to two critical factors are seriously overlooked. 1) The contribution of image and text modalities is different, but incorrectly treated equally. 2) There exist inherent labeling noises in describing users' intentions with text in web datasets from diverse real-world scenarios, giving rise to overfitting. We propose a Dynamic Weighted Combiner (DWC) to tackle the above challenges, which includes three merits. First, we propose an Editable Modality De-equalizer (EMD) by taking into account the contribution disparity between modalities, containing two modality feature editors and an adaptive weighted combiner. Second, to alleviate labeling noises and data bias, we propose a dynamic soft-similarity label generator (SSG) to implicitly improve noisy supervision. Finally, to bridge modality gaps and facilitate similarity learning, we propose a CLIP-based mutual enhancement module alternately trained by a mixed-modality contrastive loss. Extensive experiments verify that our proposed model significantly outperforms state-of-the-art methods on real-world datasets. The source code is available at \\url{https://github.com/fuxianghuang1/DWC}.","sentences":["Mixed-Modal Image Retrieval (MMIR) as a flexible search paradigm has attracted wide attention.","However, previous approaches always achieve limited performance, due to two critical factors are seriously overlooked.","1) The contribution of image and text modalities is different, but incorrectly treated equally.","2) There exist inherent labeling noises in describing users' intentions with text in web datasets from diverse real-world scenarios, giving rise to overfitting.","We propose a Dynamic Weighted Combiner (DWC) to tackle the above challenges, which includes three merits.","First, we propose an Editable Modality De-equalizer (EMD) by taking into account the contribution disparity between modalities, containing two modality feature editors and an adaptive weighted combiner.","Second, to alleviate labeling noises and data bias, we propose a dynamic soft-similarity label generator (SSG) to implicitly improve noisy supervision.","Finally, to bridge modality gaps and facilitate similarity learning, we propose a CLIP-based mutual enhancement module alternately trained by a mixed-modality contrastive loss.","Extensive experiments verify that our proposed model significantly outperforms state-of-the-art methods on real-world datasets.","The source code is available at \\url{https://github.com/fuxianghuang1/DWC}."],"url":"http://arxiv.org/abs/2312.06179v1"}
{"created":"2023-12-11 07:20:42","title":"Jointly Explicit and Implicit Cross-Modal Interaction Network for Anterior Chamber Inflammation Diagnosis","abstract":"Uveitis demands the precise diagnosis of anterior chamber inflammation (ACI) for optimal treatment. However, current diagnostic methods only rely on a limited single-modal disease perspective, which leads to poor performance. In this paper, we investigate a promising yet challenging way to fuse multimodal data for ACI diagnosis. Notably, existing fusion paradigms focus on empowering implicit modality interactions (i.e., self-attention and its variants), but neglect to inject explicit modality interactions, especially from clinical knowledge and imaging property. To this end, we propose a jointly Explicit and implicit Cross-Modal Interaction Network (EiCI-Net) for Anterior Chamber Inflammation Diagnosis that uses anterior segment optical coherence tomography (AS-OCT) images, slit-lamp images, and clinical data jointly. Specifically, we first develop CNN-Based Encoders and Tabular Processing Module (TPM) to extract efficient feature representations in different modalities. Then, we devise an Explicit Cross-Modal Interaction Module (ECIM) to generate attention maps as a kind of explicit clinical knowledge based on the tabular feature maps, then integrated them into the slit-lamp feature maps, allowing the CNN-Based Encoder to focus on more effective informativeness of the slit-lamp images. After that, the Implicit Cross-Modal Interaction Module (ICIM), a transformer-based network, further implicitly enhances modality interactions. Finally, we construct a considerable real-world dataset from our collaborative hospital and conduct sufficient experiments to demonstrate the superior performance of our proposed EiCI-Net compared with the state-of-the-art classification methods in various metrics.","sentences":["Uveitis demands the precise diagnosis of anterior chamber inflammation (ACI) for optimal treatment.","However, current diagnostic methods only rely on a limited single-modal disease perspective, which leads to poor performance.","In this paper, we investigate a promising yet challenging way to fuse multimodal data for ACI diagnosis.","Notably, existing fusion paradigms focus on empowering implicit modality interactions (i.e., self-attention and its variants), but neglect to inject explicit modality interactions, especially from clinical knowledge and imaging property.","To this end, we propose a jointly Explicit and implicit Cross-Modal Interaction Network (EiCI-Net) for Anterior Chamber Inflammation Diagnosis that uses anterior segment optical coherence tomography (AS-OCT) images, slit-lamp images, and clinical data jointly.","Specifically, we first develop CNN-Based Encoders and Tabular Processing Module (TPM) to extract efficient feature representations in different modalities.","Then, we devise an Explicit Cross-Modal Interaction Module (ECIM) to generate attention maps as a kind of explicit clinical knowledge based on the tabular feature maps, then integrated them into the slit-lamp feature maps, allowing the CNN-Based Encoder to focus on more effective informativeness of the slit-lamp images.","After that, the Implicit Cross-Modal Interaction Module (ICIM), a transformer-based network, further implicitly enhances modality interactions.","Finally, we construct a considerable real-world dataset from our collaborative hospital and conduct sufficient experiments to demonstrate the superior performance of our proposed EiCI-Net compared with the state-of-the-art classification methods in various metrics."],"url":"http://arxiv.org/abs/2312.06171v1"}
{"created":"2023-12-11 07:16:49","title":"Bag of Tricks: Semi-Supervised Cross-domain Crater Detection with Poor Data Quality","abstract":"With the development of spaceflight and the exploration of extraterrestrial planets, exoplanet crater detection has gradually gained attention. However, with the current scarcity of relevant datasets, high sample background complexity, and large inter-domain differences, few existing detection models can achieve good robustness and generalization across domains by training on data with more background interference. To obtain a better robust model with better cross-domain generalization in the presence of poor data quality, we propose the SCPQ model, in which we first propose a method for fusing shallow information using attention mechanism (FSIAM), which utilizes feature maps fused with deep convolved feature maps after fully extracting the global sensory field of shallow information via the attention mechanism module, which can fully fit the data to obtain a better sense of the domain in the presence of poor data, and thus better multiscale adaptability. Secondly, we propose a pseudo-label and data augment strategy (PDAS) and a smooth hard example mining (SHEM) loss function to improve cross-domain performance. PDAS adopts high-quality pseudo-labeled data from the target domain to the finetune model, and adopts different strong and weak data enhancement strategies for different domains, which mitigates the different distribution of information inherent in the source and target domains, and obtains a better generalization effect. Meanwhile, our proposed SHEM loss function can solve the problem of poor robustness of hard examples due to partial background interference learning during the training process. The SHEM loss function can smooth this interference and has generalization while learning hard examples. Experimental results show that we achieved better performance on the DACD dataset and improved the Recall of cross-domain detection by 24.04\\% over baseline.","sentences":["With the development of spaceflight and the exploration of extraterrestrial planets, exoplanet crater detection has gradually gained attention.","However, with the current scarcity of relevant datasets, high sample background complexity, and large inter-domain differences, few existing detection models can achieve good robustness and generalization across domains by training on data with more background interference.","To obtain a better robust model with better cross-domain generalization in the presence of poor data quality, we propose the SCPQ model, in which we first propose a method for fusing shallow information using attention mechanism (FSIAM), which utilizes feature maps fused with deep convolved feature maps after fully extracting the global sensory field of shallow information via the attention mechanism module, which can fully fit the data to obtain a better sense of the domain in the presence of poor data, and thus better multiscale adaptability.","Secondly, we propose a pseudo-label and data augment strategy (PDAS) and a smooth hard example mining (SHEM) loss function to improve cross-domain performance.","PDAS adopts high-quality pseudo-labeled data from the target domain to the finetune model, and adopts different strong and weak data enhancement strategies for different domains, which mitigates the different distribution of information inherent in the source and target domains, and obtains a better generalization effect.","Meanwhile, our proposed SHEM loss function can solve the problem of poor robustness of hard examples due to partial background interference learning during the training process.","The SHEM loss function can smooth this interference and has generalization while learning hard examples.","Experimental results show that we achieved better performance on the DACD dataset and improved the Recall of cross-domain detection by 24.04\\% over baseline."],"url":"http://arxiv.org/abs/2312.06169v1"}
{"created":"2023-12-11 07:09:32","title":"Implicit Shape Modeling for Anatomical Structure Refinement of Volumetric Medical Images","abstract":"Shape modeling of volumetric medical images is a critical task for quantitative analysis and surgical plans in computer-aided diagnosis. To relieve the burden of expert clinicians, the reconstructed shapes are widely acquired from deep learning models, e.g. Convolutional Neural Networks (CNNs), followed by marching cube algorithm. However, automatically obtaining reconstructed shapes can not always achieve perfect results due to the limited resolution of images and lack of shape prior constraints. In this paper, we design a unified framework for the refinement of medical image segmentation on top of an implicit neural network. Specifically, To learn a sharable shape prior from different instances within the same category in the training phase, the physical information of volumetric medical images are firstly utilized to construct the Physical-Informed Continuous Coordinate Transform (PICCT). PICCT transforms the input data in an aligned manner fed into the implicit shape modeling. To better learn shape representation, we introduce implicit shape constraints on top of the signed distance function (SDF) into the implicit shape modeling of both instances and latent template. For the inference phase, a template interaction module (TIM) is proposed to refine initial results produced by CNNs via deforming deep implicit templates with latent codes. Experimental results on three datasets demonstrated the superiority of our approach in shape refinement. The Chamfer Distance/Earth Mover's Distance achieved by the proposed method are 0.232/0.087 on the Liver dataset, 0.128/0.069 on the Pancreas dataset, and 0.417/0.100 on the Lung Lobe dataset.","sentences":["Shape modeling of volumetric medical images is a critical task for quantitative analysis and surgical plans in computer-aided diagnosis.","To relieve the burden of expert clinicians, the reconstructed shapes are widely acquired from deep learning models, e.g. Convolutional Neural Networks (CNNs), followed by marching cube algorithm.","However, automatically obtaining reconstructed shapes can not always achieve perfect results due to the limited resolution of images and lack of shape prior constraints.","In this paper, we design a unified framework for the refinement of medical image segmentation on top of an implicit neural network.","Specifically, To learn a sharable shape prior from different instances within the same category in the training phase, the physical information of volumetric medical images are firstly utilized to construct the Physical-Informed Continuous Coordinate Transform (PICCT).","PICCT transforms the input data in an aligned manner fed into the implicit shape modeling.","To better learn shape representation, we introduce implicit shape constraints on top of the signed distance function (SDF) into the implicit shape modeling of both instances and latent template.","For the inference phase, a template interaction module (TIM) is proposed to refine initial results produced by CNNs via deforming deep implicit templates with latent codes.","Experimental results on three datasets demonstrated the superiority of our approach in shape refinement.","The Chamfer Distance/Earth Mover's Distance achieved by the proposed method are 0.232/0.087 on the Liver dataset, 0.128/0.069 on the Pancreas dataset, and 0.417/0.100 on the Lung Lobe dataset."],"url":"http://arxiv.org/abs/2312.06164v1"}
{"created":"2023-12-11 06:56:41","title":"Textual Prompt Guided Image Restoration","abstract":"Image restoration has always been a cutting-edge topic in the academic and industrial fields of computer vision. Since degradation signals are often random and diverse, \"all-in-one\" models that can do blind image restoration have been concerned in recent years. Early works require training specialized headers and tails to handle each degradation of concern, which are manually cumbersome. Recent works focus on learning visual prompts from data distribution to identify degradation type. However, the prompts employed in most of models are non-text, lacking sufficient emphasis on the importance of human-in-the-loop. In this paper, an effective textual prompt guided image restoration model has been proposed. In this model, task-specific BERT is fine-tuned to accurately understand user's instructions and generating textual prompt guidance. Depth-wise multi-head transposed attentions and gated convolution modules are designed to bridge the gap between textual prompts and visual features. The proposed model has innovatively introduced semantic prompts into low-level visual domain. It highlights the potential to provide a natural, precise, and controllable way to perform image restoration tasks. Extensive experiments have been done on public denoising, dehazing and deraining datasets. The experiment results demonstrate that, compared with popular state-of-the-art methods, the proposed model can obtain much more superior performance, achieving accurate recognition and removal of degradation without increasing model's complexity. Related source codes and data will be publicly available on github site https://github.com/MoTong-AI-studio/TextPromptIR.","sentences":["Image restoration has always been a cutting-edge topic in the academic and industrial fields of computer vision.","Since degradation signals are often random and diverse, \"all-in-one\" models that can do blind image restoration have been concerned in recent years.","Early works require training specialized headers and tails to handle each degradation of concern, which are manually cumbersome.","Recent works focus on learning visual prompts from data distribution to identify degradation type.","However, the prompts employed in most of models are non-text, lacking sufficient emphasis on the importance of human-in-the-loop.","In this paper, an effective textual prompt guided image restoration model has been proposed.","In this model, task-specific BERT is fine-tuned to accurately understand user's instructions and generating textual prompt guidance.","Depth-wise multi-head transposed attentions and gated convolution modules are designed to bridge the gap between textual prompts and visual features.","The proposed model has innovatively introduced semantic prompts into low-level visual domain.","It highlights the potential to provide a natural, precise, and controllable way to perform image restoration tasks.","Extensive experiments have been done on public denoising, dehazing and deraining datasets.","The experiment results demonstrate that, compared with popular state-of-the-art methods, the proposed model can obtain much more superior performance, achieving accurate recognition and removal of degradation without increasing model's complexity.","Related source codes and data will be publicly available on github site https://github.com/MoTong-AI-studio/TextPromptIR."],"url":"http://arxiv.org/abs/2312.06162v1"}
{"created":"2023-12-11 06:41:14","title":"Open Datasheets: Machine-readable Documentation for Open Datasets and Responsible AI Assessments","abstract":"This paper introduces a no-code, machine-readable documentation framework for open datasets, with a focus on Responsible AI (RAI) considerations. The framework aims to improve the accessibility, comprehensibility, and usability of open datasets, facilitating easier discovery and use, better understanding of content and context, and evaluation of dataset quality and accuracy. The proposed framework is designed to streamline the evaluation of datasets, helping researchers, data scientists, and other open data users quickly identify datasets that meet their needs and/or organizational policies or regulations. The paper also discusses the implementation of the framework and provides recommendations to maximize its potential. The framework is expected to enhance the quality and reliability of data used in research and decision-making, fostering the development of more responsible and trustworthy AI systems.","sentences":["This paper introduces a no-code, machine-readable documentation framework for open datasets, with a focus on Responsible AI (RAI) considerations.","The framework aims to improve the accessibility, comprehensibility, and usability of open datasets, facilitating easier discovery and use, better understanding of content and context, and evaluation of dataset quality and accuracy.","The proposed framework is designed to streamline the evaluation of datasets, helping researchers, data scientists, and other open data users quickly identify datasets that meet their needs and/or organizational policies or regulations.","The paper also discusses the implementation of the framework and provides recommendations to maximize its potential.","The framework is expected to enhance the quality and reliability of data used in research and decision-making, fostering the development of more responsible and trustworthy AI systems."],"url":"http://arxiv.org/abs/2312.06153v1"}
{"created":"2023-12-11 06:22:34","title":"Proxy-based Item Representation for Attribute and Context-aware Recommendation","abstract":"Neural network approaches in recommender systems have shown remarkable success by representing a large set of items as a learnable vector embedding table. However, infrequent items may suffer from inadequate training opportunities, making it difficult to learn meaningful representations. We examine that in attribute and context-aware settings, the poorly learned embeddings of infrequent items impair the recommendation accuracy. To address such an issue, we propose a proxy-based item representation that allows each item to be expressed as a weighted sum of learnable proxy embeddings. Here, the proxy weight is determined by the attributes and context of each item and may incorporate bias terms in case of frequent items to further reflect collaborative signals. The proxy-based method calculates the item representations compositionally, ensuring each representation resides inside a well-trained simplex and, thus, acquires guaranteed quality. Additionally, that the proxy embeddings are shared across all items allows the infrequent items to borrow training signals of frequent items in a unified model structure and end-to-end manner. Our proposed method is a plug-and-play model that can replace the item encoding layer of any neural network-based recommendation model, while consistently improving the recommendation performance with much smaller parameter usage. Experiments conducted on real-world recommendation benchmark datasets demonstrate that our proposed model outperforms state-of-the-art models in terms of recommendation accuracy by up to 17% while using only 10% of the parameters.","sentences":["Neural network approaches in recommender systems have shown remarkable success by representing a large set of items as a learnable vector embedding table.","However, infrequent items may suffer from inadequate training opportunities, making it difficult to learn meaningful representations.","We examine that in attribute and context-aware settings, the poorly learned embeddings of infrequent items impair the recommendation accuracy.","To address such an issue, we propose a proxy-based item representation that allows each item to be expressed as a weighted sum of learnable proxy embeddings.","Here, the proxy weight is determined by the attributes and context of each item and may incorporate bias terms in case of frequent items to further reflect collaborative signals.","The proxy-based method calculates the item representations compositionally, ensuring each representation resides inside a well-trained simplex and, thus, acquires guaranteed quality.","Additionally, that the proxy embeddings are shared across all items allows the infrequent items to borrow training signals of frequent items in a unified model structure and end-to-end manner.","Our proposed method is a plug-and-play model that can replace the item encoding layer of any neural network-based recommendation model, while consistently improving the recommendation performance with much smaller parameter usage.","Experiments conducted on real-world recommendation benchmark datasets demonstrate that our proposed model outperforms state-of-the-art models in terms of recommendation accuracy by up to 17% while using only 10% of the parameters."],"url":"http://arxiv.org/abs/2312.06145v1"}
{"created":"2023-12-11 06:02:56","title":"ICS-Sniper: A Targeted Blackhole Attack on Encrypted ICS Traffic","abstract":"Operational Technology (OT) networks of industrial control systems (ICS) are increasingly connected to the public Internet, which has prompted ICSes to implement strong security measures (e.g., authentication and encryption) to protect end-to-end control communication. Despite the security measures, we show that an Internet adversary in the path of an ICS's communication can cause damage to the ICS without infiltrating it. We present ICS-Sniper, a targeted blackhole attack that analyzes the packet metadata (sizes, timing) to identify the packets carrying critical ICS commands or data, and drops the critical packets to disrupt the ICS's operations. We demonstrate two attacks on an emulation of a Secure Water Treatment (SWaT) plant that can potentially violate the operational safety of the ICS while evading state-of-the-art detection systems.","sentences":["Operational Technology (OT) networks of industrial control systems (ICS) are increasingly connected to the public Internet, which has prompted ICSes to implement strong security measures (e.g., authentication and encryption) to protect end-to-end control communication.","Despite the security measures, we show that an Internet adversary in the path of an ICS's communication can cause damage to the ICS without infiltrating it.","We present ICS-Sniper, a targeted blackhole attack that analyzes the packet metadata (sizes, timing) to identify the packets carrying critical ICS commands or data, and drops the critical packets to disrupt the ICS's operations.","We demonstrate two attacks on an emulation of a Secure Water Treatment (SWaT) plant that can potentially violate the operational safety of the ICS while evading state-of-the-art detection systems."],"url":"http://arxiv.org/abs/2312.06140v1"}
{"created":"2023-12-11 05:46:57","title":"Order Matters in the Presence of Dataset Imbalance for Multilingual Learning","abstract":"In this paper, we empirically study the optimization dynamics of multi-task learning, particularly focusing on those that govern a collection of tasks with significant data imbalance. We present a simple yet effective method of pre-training on high-resource tasks, followed by fine-tuning on a mixture of high/low-resource tasks. We provide a thorough empirical study and analysis of this method's benefits showing that it achieves consistent improvements relative to the performance trade-off profile of standard static weighting. We analyze under what data regimes this method is applicable and show its improvements empirically in neural machine translation (NMT) and multi-lingual language modeling.","sentences":["In this paper, we empirically study the optimization dynamics of multi-task learning, particularly focusing on those that govern a collection of tasks with significant data imbalance.","We present a simple yet effective method of pre-training on high-resource tasks, followed by fine-tuning on a mixture of high/low-resource tasks.","We provide a thorough empirical study and analysis of this method's benefits showing that it achieves consistent improvements relative to the performance trade-off profile of standard static weighting.","We analyze under what data regimes this method is applicable and show its improvements empirically in neural machine translation (NMT) and multi-lingual language modeling."],"url":"http://arxiv.org/abs/2312.06134v1"}
{"created":"2023-12-11 05:33:00","title":"ML-based Modeling to Predict I/O Performance on Different Storage Sub-systems","abstract":"Parallel applications can spend a significant amount of time performing I/O on large-scale supercomputers. Fast near-compute storage accelerators called burst buffers can reduce the time a processor spends performing I/O and mitigate I/O bottlenecks. However, determining if a given application could be accelerated using burst buffers is not straightforward even for storage experts. The relationship between an application's I/O characteristics (such as I/O volume, processes involved, etc.) and the best storage sub-system for it can be complicated. As a result, adapting parallel applications to use burst buffers efficiently is a trial-and-error process. In this work, we present a Python-based tool called PrismIO that enables programmatic analysis of I/O traces. Using PrismIO, we identify bottlenecks on burst buffers and parallel file systems and explain why certain I/O patterns perform poorly. Further, we use machine learning to model the relationship between I/O characteristics and burst buffer selections. We run IOR (an I/O benchmark) with various I/O characteristics on different storage systems and collect performance data. We use the data as the input for training the model. Our model can predict if a file of an application should be placed on BBs for unseen IOR scenarios with an accuracy of 94.47% and for four real applications with an accuracy of 95.86%.","sentences":["Parallel applications can spend a significant amount of time performing I/O on large-scale supercomputers.","Fast near-compute storage accelerators called burst buffers can reduce the time a processor spends performing I/O and mitigate I/O bottlenecks.","However, determining if a given application could be accelerated using burst buffers is not straightforward even for storage experts.","The relationship between an application's I/O characteristics (such as I/O volume, processes involved, etc.) and the best storage sub-system for it can be complicated.","As a result, adapting parallel applications to use burst buffers efficiently is a trial-and-error process.","In this work, we present a Python-based tool called PrismIO that enables programmatic analysis of I/O traces.","Using PrismIO, we identify bottlenecks on burst buffers and parallel file systems and explain why certain I/O patterns perform poorly.","Further, we use machine learning to model the relationship between I/O characteristics and burst buffer selections.","We run IOR (an I/O benchmark) with various I/O characteristics on different storage systems and collect performance data.","We use the data as the input for training the model.","Our model can predict if a file of an application should be placed on BBs for unseen IOR scenarios with an accuracy of 94.47% and for four real applications with an accuracy of 95.86%."],"url":"http://arxiv.org/abs/2312.06131v1"}
{"created":"2023-12-11 05:25:01","title":"Spreeze: High-Throughput Parallel Reinforcement Learning Framework","abstract":"The promotion of large-scale applications of reinforcement learning (RL) requires efficient training computation. While existing parallel RL frameworks encompass a variety of RL algorithms and parallelization techniques, the excessively burdensome communication frameworks hinder the attainment of the hardware's limit for final throughput and training effects on a single desktop. In this paper, we propose Spreeze, a lightweight parallel framework for RL that efficiently utilizes a single desktop hardware resource to approach the throughput limit. We asynchronously parallelize the experience sampling, network update, performance evaluation, and visualization operations, and employ multiple efficient data transmission techniques to transfer various types of data between processes. The framework can automatically adjust the parallelization hyperparameters based on the computing ability of the hardware device in order to perform efficient large-batch updates. Based on the characteristics of the \"Actor-Critic\" RL algorithm, our framework uses dual GPUs to independently update the network of actors and critics in order to further improve throughput. Simulation results show that our framework can achieve up to 15,000Hz experience sampling and 370,000Hz network update frame rate using only a personal desktop computer, which is an order of magnitude higher than other mainstream parallel RL frameworks, resulting in a 73% reduction of training time. Our work on fully utilizing the hardware resources of a single desktop computer is fundamental to enabling efficient large-scale distributed RL training.","sentences":["The promotion of large-scale applications of reinforcement learning (RL) requires efficient training computation.","While existing parallel RL frameworks encompass a variety of RL algorithms and parallelization techniques, the excessively burdensome communication frameworks hinder the attainment of the hardware's limit for final throughput and training effects on a single desktop.","In this paper, we propose Spreeze, a lightweight parallel framework for RL that efficiently utilizes a single desktop hardware resource to approach the throughput limit.","We asynchronously parallelize the experience sampling, network update, performance evaluation, and visualization operations, and employ multiple efficient data transmission techniques to transfer various types of data between processes.","The framework can automatically adjust the parallelization hyperparameters based on the computing ability of the hardware device in order to perform efficient large-batch updates.","Based on the characteristics of the \"Actor-Critic\" RL algorithm, our framework uses dual GPUs to independently update the network of actors and critics in order to further improve throughput.","Simulation results show that our framework can achieve up to 15,000Hz experience sampling and 370,000Hz network update frame rate using only a personal desktop computer, which is an order of magnitude higher than other mainstream parallel RL frameworks, resulting in a 73% reduction of training time.","Our work on fully utilizing the hardware resources of a single desktop computer is fundamental to enabling efficient large-scale distributed RL training."],"url":"http://arxiv.org/abs/2312.06126v1"}
{"created":"2023-12-11 04:49:47","title":"M3SOT: Multi-frame, Multi-field, Multi-space 3D Single Object Tracking","abstract":"3D Single Object Tracking (SOT) stands a forefront task of computer vision, proving essential for applications like autonomous driving. Sparse and occluded data in scene point clouds introduce variations in the appearance of tracked objects, adding complexity to the task. In this research, we unveil M3SOT, a novel 3D SOT framework, which synergizes multiple input frames (template sets), multiple receptive fields (continuous contexts), and multiple solution spaces (distinct tasks) in ONE model. Remarkably, M3SOT pioneers in modeling temporality, contexts, and tasks directly from point clouds, revisiting a perspective on the key factors influencing SOT. To this end, we design a transformer-based network centered on point cloud targets in the search area, aggregating diverse contextual representations and propagating target cues by employing historical frames. As M3SOT spans varied processing perspectives, we've streamlined the network-trimming its depth and optimizing its structure-to ensure a lightweight and efficient deployment for SOT applications. We posit that, backed by practical construction, M3SOT sidesteps the need for complex frameworks and auxiliary components to deliver sterling results. Extensive experiments on benchmarks such as KITTI, nuScenes, and Waymo Open Dataset demonstrate that M3SOT achieves state-of-the-art performance at 38 FPS. Our code and models are available at https://github.com/ywu0912/TeamCode.git.","sentences":["3D Single Object Tracking (SOT) stands a forefront task of computer vision, proving essential for applications like autonomous driving.","Sparse and occluded data in scene point clouds introduce variations in the appearance of tracked objects, adding complexity to the task.","In this research, we unveil M3SOT, a novel 3D SOT framework, which synergizes multiple input frames (template sets), multiple receptive fields (continuous contexts), and multiple solution spaces (distinct tasks) in ONE model.","Remarkably, M3SOT pioneers in modeling temporality, contexts, and tasks directly from point clouds, revisiting a perspective on the key factors influencing SOT.","To this end, we design a transformer-based network centered on point cloud targets in the search area, aggregating diverse contextual representations and propagating target cues by employing historical frames.","As M3SOT spans varied processing perspectives, we've streamlined the network-trimming its depth and optimizing its structure-to ensure a lightweight and efficient deployment for SOT applications.","We posit that, backed by practical construction, M3SOT sidesteps the need for complex frameworks and auxiliary components to deliver sterling results.","Extensive experiments on benchmarks such as KITTI, nuScenes, and Waymo Open Dataset demonstrate that M3SOT achieves state-of-the-art performance at 38 FPS.","Our code and models are available at https://github.com/ywu0912/TeamCode.git."],"url":"http://arxiv.org/abs/2312.06117v1"}
{"created":"2023-12-11 04:47:39","title":"Stellar: Systematic Evaluation of Human-Centric Personalized Text-to-Image Methods","abstract":"In this work, we systematically study the problem of personalized text-to-image generation, where the output image is expected to portray information about specific human subjects. E.g., generating images of oneself appearing at imaginative places, interacting with various items, or engaging in fictional activities. To this end, we focus on text-to-image systems that input a single image of an individual to ground the generation process along with text describing the desired visual context. Our first contribution is to fill the literature gap by curating high-quality, appropriate data for this task. Namely, we introduce a standardized dataset (Stellar) that contains personalized prompts coupled with images of individuals that is an order of magnitude larger than existing relevant datasets and where rich semantic ground-truth annotations are readily available. Having established Stellar to promote cross-systems fine-grained comparisons further, we introduce a rigorous ensemble of specialized metrics that highlight and disentangle fundamental properties such systems should obey. Besides being intuitive, our new metrics correlate significantly more strongly with human judgment than currently used metrics on this task. Last but not least, drawing inspiration from the recent works of ELITE and SDXL, we derive a simple yet efficient, personalized text-to-image baseline that does not require test-time fine-tuning for each subject and which sets quantitatively and in human trials a new SoTA. For more information, please visit our project's website: https://stellar-gen-ai.github.io/.","sentences":["In this work, we systematically study the problem of personalized text-to-image generation, where the output image is expected to portray information about specific human subjects.","E.g., generating images of oneself appearing at imaginative places, interacting with various items, or engaging in fictional activities.","To this end, we focus on text-to-image systems that input a single image of an individual to ground the generation process along with text describing the desired visual context.","Our first contribution is to fill the literature gap by curating high-quality, appropriate data for this task.","Namely, we introduce a standardized dataset (Stellar) that contains personalized prompts coupled with images of individuals that is an order of magnitude larger than existing relevant datasets and where rich semantic ground-truth annotations are readily available.","Having established Stellar to promote cross-systems fine-grained comparisons further, we introduce a rigorous ensemble of specialized metrics that highlight and disentangle fundamental properties such systems should obey.","Besides being intuitive, our new metrics correlate significantly more strongly with human judgment than currently used metrics on this task.","Last but not least, drawing inspiration from the recent works of ELITE and SDXL, we derive a simple yet efficient, personalized text-to-image baseline that does not require test-time fine-tuning for each subject and which sets quantitatively and in human trials a new SoTA.","For more information, please visit our project's website: https://stellar-gen-ai.github.io/."],"url":"http://arxiv.org/abs/2312.06116v1"}
{"created":"2023-12-11 04:33:45","title":"SimMining-3D: Altitude-Aware 3D Object Detection in Complex Mining Environments: A Novel Dataset and ROS-Based Automatic Annotation Pipeline","abstract":"Accurate and efficient object detection is crucial for safe and efficient operation of earth-moving equipment in mining. Traditional 2D image-based methods face limitations in dynamic and complex mine environments. To overcome these challenges, 3D object detection using point cloud data has emerged as a comprehensive approach. However, training models for mining scenarios is challenging due to sensor height variations, viewpoint changes, and the need for diverse annotated datasets. This paper presents novel contributions to address these challenges. We introduce a synthetic dataset SimMining 3D [1] specifically designed for 3D object detection in mining environments. The dataset captures objects and sensors positioned at various heights within mine benches, accurately reflecting authentic mining scenarios. An automatic annotation pipeline through ROS interface reduces manual labor and accelerates dataset creation. We propose evaluation metrics accounting for sensor-to-object height variations and point cloud density, enabling accurate model assessment in mining scenarios. Real data tests validate our models effectiveness in object prediction. Our ablation study emphasizes the importance of altitude and height variation augmentations in improving accuracy and reliability. The publicly accessible synthetic dataset [1] serves as a benchmark for supervised learning and advances object detection techniques in mining with complimentary pointwise annotations for each scene. In conclusion, our work bridges the gap between synthetic and real data, addressing the domain shift challenge in 3D object detection for mining. We envision robust object detection systems enhancing safety and efficiency in mining and related domains.","sentences":["Accurate and efficient object detection is crucial for safe and efficient operation of earth-moving equipment in mining.","Traditional 2D image-based methods face limitations in dynamic and complex mine environments.","To overcome these challenges, 3D object detection using point cloud data has emerged as a comprehensive approach.","However, training models for mining scenarios is challenging due to sensor height variations, viewpoint changes, and the need for diverse annotated datasets.","This paper presents novel contributions to address these challenges.","We introduce a synthetic dataset SimMining 3D","[1] specifically designed for 3D object detection in mining environments.","The dataset captures objects and sensors positioned at various heights within mine benches, accurately reflecting authentic mining scenarios.","An automatic annotation pipeline through ROS interface reduces manual labor and accelerates dataset creation.","We propose evaluation metrics accounting for sensor-to-object height variations and point cloud density, enabling accurate model assessment in mining scenarios.","Real data tests validate our models effectiveness in object prediction.","Our ablation study emphasizes the importance of altitude and height variation augmentations in improving accuracy and reliability.","The publicly accessible synthetic dataset [1] serves as a benchmark for supervised learning and advances object detection techniques in mining with complimentary pointwise annotations for each scene.","In conclusion, our work bridges the gap between synthetic and real data, addressing the domain shift challenge in 3D object detection for mining.","We envision robust object detection systems enhancing safety and efficiency in mining and related domains."],"url":"http://arxiv.org/abs/2312.06113v1"}
{"created":"2023-12-11 04:24:11","title":"AUGCAL: Improving Sim2Rreal Adaptation by Uncertainty Calibration on Augmented Synthetic Images","abstract":"Synthetic data (SIM) drawn from simulators have emerged as a popular alternative for training models where acquiring annotated real-world images is difficult. However, transferring models trained on synthetic images to real-world applications can be challenging due to appearance disparities. A commonly employed solution to counter this SIM2REAL gap is unsupervised domain adaptation, where models are trained using labeled SIM data and unlabeled REAL data. Mispredictions made by such SIM2REAL adapted models are often associated with miscalibration - stemming from overconfident predictions on real data. In this paper, we introduce AUGCAL, a simple training-time patch for unsupervised adaptation that improves SIM2REAL adapted models by - (1) reducing overall miscalibration, (2) reducing overconfidence in incorrect predictions and (3) improving confidence score reliability by better guiding misclassification detection - all while retaining or improving SIM2REAL performance. Given a base SIM2REAL adaptation algorithm, at training time, AUGCAL involves replacing vanilla SIM images with strongly augmented views (AUG intervention) and additionally optimizing for a training time calibration loss on augmented SIM predictions (CAL intervention). We motivate AUGCAL using a brief analytical justification of how to reduce miscalibration on unlabeled REAL data. Through our experiments, we empirically show the efficacy of AUGCAL across multiple adaptation methods, backbones, tasks and shifts.","sentences":["Synthetic data (SIM) drawn from simulators have emerged as a popular alternative for training models where acquiring annotated real-world images is difficult.","However, transferring models trained on synthetic images to real-world applications can be challenging due to appearance disparities.","A commonly employed solution to counter this SIM2REAL gap is unsupervised domain adaptation, where models are trained using labeled SIM data and unlabeled REAL data.","Mispredictions made by such SIM2REAL adapted models are often associated with miscalibration - stemming from overconfident predictions on real data.","In this paper, we introduce AUGCAL, a simple training-time patch for unsupervised adaptation that improves SIM2REAL adapted models by - (1) reducing overall miscalibration, (2) reducing overconfidence in incorrect predictions and (3) improving confidence score reliability by better guiding misclassification detection - all while retaining or improving SIM2REAL performance.","Given a base SIM2REAL adaptation algorithm, at training time, AUGCAL involves replacing vanilla SIM images with strongly augmented views (AUG intervention) and additionally optimizing for a training time calibration loss on augmented SIM predictions (CAL intervention).","We motivate AUGCAL using a brief analytical justification of how to reduce miscalibration on unlabeled REAL data.","Through our experiments, we empirically show the efficacy of AUGCAL across multiple adaptation methods, backbones, tasks and shifts."],"url":"http://arxiv.org/abs/2312.06106v1"}
{"created":"2023-12-11 03:31:54","title":"Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data","abstract":"We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments. The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments. We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments. In the second phase, the recovered noises are matched with the corresponding endogenous variables. For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation. For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets. In the presence of latent confounders, the intervention targets among the observed variables cannot be determined uniquely. We provide a candidate intervention target set which is a superset of the true intervention targets. Our approach improves upon the state of the art as the returned candidate set is always a subset of the target set returned by previous work. Moreover, we do not require restrictive assumptions such as linearity of the causal model or performing invariance tests to learn whether a distribution is changing across environments which could be highly sample inefficient. Our experimental results show the effectiveness of our proposed algorithm in practice.","sentences":["We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments.","The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments.","We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments.","In the second phase, the recovered noises are matched with the corresponding endogenous variables.","For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation.","For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets.","In the presence of latent confounders, the intervention targets among the observed variables cannot be determined uniquely.","We provide a candidate intervention target set which is a superset of the true intervention targets.","Our approach improves upon the state of the art as the returned candidate set is always a subset of the target set returned by previous work.","Moreover, we do not require restrictive assumptions such as linearity of the causal model or performing invariance tests to learn whether a distribution is changing across environments which could be highly sample inefficient.","Our experimental results show the effectiveness of our proposed algorithm in practice."],"url":"http://arxiv.org/abs/2312.06091v1"}
{"created":"2023-12-11 03:28:11","title":"TabMT: Generating tabular data with masked transformers","abstract":"Autoregressive and Masked Transformers are incredibly effective as generative models and classifiers. While these models are most prevalent in NLP, they also exhibit strong performance in other domains, such as vision. This work contributes to the exploration of transformer-based models in synthetic data generation for diverse application domains. In this paper, we present TabMT, a novel Masked Transformer design for generating synthetic tabular data. TabMT effectively addresses the unique challenges posed by heterogeneous data fields and is natively able to handle missing data. Our design leverages improved masking techniques to allow for generation and demonstrates state-of-the-art performance from extremely small to extremely large tabular datasets. We evaluate TabMT for privacy-focused applications and find that it is able to generate high quality data with superior privacy tradeoffs.","sentences":["Autoregressive and Masked Transformers are incredibly effective as generative models and classifiers.","While these models are most prevalent in NLP, they also exhibit strong performance in other domains, such as vision.","This work contributes to the exploration of transformer-based models in synthetic data generation for diverse application domains.","In this paper, we present TabMT, a novel Masked Transformer design for generating synthetic tabular data.","TabMT effectively addresses the unique challenges posed by heterogeneous data fields and is natively able to handle missing data.","Our design leverages improved masking techniques to allow for generation and demonstrates state-of-the-art performance from extremely small to extremely large tabular datasets.","We evaluate TabMT for privacy-focused applications and find that it is able to generate high quality data with superior privacy tradeoffs."],"url":"http://arxiv.org/abs/2312.06089v1"}
{"created":"2023-12-11 03:24:18","title":"HALO-CAT: A Hidden Network Processor with Activation-Localized CIM Architecture and Layer-Penetrative Tiling","abstract":"To address the 'memory wall' problem in NN hardware acceleration, we introduce HALO-CAT, a software-hardware co-design optimized for Hidden Neural Network (HNN) processing. HALO-CAT integrates Layer-Penetrative Tiling (LPT) for algorithmic efficiency, reducing intermediate result sizes. Furthermore, the architecture employs an activation-localized computing-in-memory approach to minimize data movement. This design significantly enhances energy efficiency, achieving a 14.2x reduction in activation memory capacity and a 17.8x decrease in energy consumption, with only a 1.5% loss in accuracy, compared to traditional HNN processors.","sentences":["To address the 'memory wall' problem in NN hardware acceleration, we introduce HALO-CAT, a software-hardware co-design optimized for Hidden Neural Network (HNN) processing.","HALO-CAT integrates Layer-Penetrative Tiling (LPT) for algorithmic efficiency, reducing intermediate result sizes.","Furthermore, the architecture employs an activation-localized computing-in-memory approach to minimize data movement.","This design significantly enhances energy efficiency, achieving a 14.2x reduction in activation memory capacity and a 17.8x decrease in energy consumption, with only a 1.5% loss in accuracy, compared to traditional HNN processors."],"url":"http://arxiv.org/abs/2312.06086v1"}
{"created":"2023-12-11 03:08:18","title":"XAI meets Biology: A Comprehensive Review of Explainable AI in Bioinformatics Applications","abstract":"Artificial intelligence (AI), particularly machine learning and deep learning models, has significantly impacted bioinformatics research by offering powerful tools for analyzing complex biological data. However, the lack of interpretability and transparency of these models presents challenges in leveraging these models for deeper biological insights and for generating testable hypotheses. Explainable AI (XAI) has emerged as a promising solution to enhance the transparency and interpretability of AI models in bioinformatics. This review provides a comprehensive analysis of various XAI techniques and their applications across various bioinformatics domains including DNA, RNA, and protein sequence analysis, structural analysis, gene expression and genome analysis, and bioimaging analysis. We introduce the most pertinent machine learning and XAI methods, then discuss their diverse applications and address the current limitations of available XAI tools. By offering insights into XAI's potential and challenges, this review aims to facilitate its practical implementation in bioinformatics research and help researchers navigate the landscape of XAI tools.","sentences":["Artificial intelligence (AI), particularly machine learning and deep learning models, has significantly impacted bioinformatics research by offering powerful tools for analyzing complex biological data.","However, the lack of interpretability and transparency of these models presents challenges in leveraging these models for deeper biological insights and for generating testable hypotheses.","Explainable AI (XAI) has emerged as a promising solution to enhance the transparency and interpretability of AI models in bioinformatics.","This review provides a comprehensive analysis of various XAI techniques and their applications across various bioinformatics domains including DNA, RNA, and protein sequence analysis, structural analysis, gene expression and genome analysis, and bioimaging analysis.","We introduce the most pertinent machine learning and XAI methods, then discuss their diverse applications and address the current limitations of available XAI tools.","By offering insights into XAI's potential and challenges, this review aims to facilitate its practical implementation in bioinformatics research and help researchers navigate the landscape of XAI tools."],"url":"http://arxiv.org/abs/2312.06082v1"}
{"created":"2023-12-11 03:05:06","title":"A Prediction-Traversal Approach for Compressing Scientific Data on Unstructured Meshes with Bounded Error","abstract":"We explore an error-bounded lossy compression approach for reducing scientific data associated with 2D/3D unstructured meshes. While existing lossy compressors offer a high compression ratio with bounded error for regular grid data, methodologies tailored for unstructured mesh data are lacking; for example, one can compress nodal data as 1D arrays, neglecting the spatial coherency of the mesh nodes. Inspired by the SZ compressor, which predicts and quantizes values in a multidimensional array, we dynamically reorganize nodal data into sequences. Each sequence starts with a seed cell; based on a predefined traversal order, the next cell is added to the sequence if the current cell can predict and quantize the nodal data in the next cell with the given error bound. As a result, one can efficiently compress the quantized nodal data in each sequence until all mesh nodes are traversed. This paper also introduces a suite of novel error metrics, namely continuous mean squared error (CMSE) and continuous peak signal-to-noise ratio (CPSNR), to assess compression results for unstructured mesh data. The continuous error metrics are defined by integrating the error function on all cells, providing objective statistics across nonuniformly distributed nodes/cells in the mesh. We evaluate our methods with several scientific simulations ranging from ocean-climate models and computational fluid dynamics simulations with both traditional and continuous error metrics. We demonstrated superior compression ratios and quality than existing lossy compressors.","sentences":["We explore an error-bounded lossy compression approach for reducing scientific data associated with 2D/3D unstructured meshes.","While existing lossy compressors offer a high compression ratio with bounded error for regular grid data, methodologies tailored for unstructured mesh data are lacking; for example, one can compress nodal data as 1D arrays, neglecting the spatial coherency of the mesh nodes.","Inspired by the SZ compressor, which predicts and quantizes values in a multidimensional array, we dynamically reorganize nodal data into sequences.","Each sequence starts with a seed cell; based on a predefined traversal order, the next cell is added to the sequence if the current cell can predict and quantize the nodal data in the next cell with the given error bound.","As a result, one can efficiently compress the quantized nodal data in each sequence until all mesh nodes are traversed.","This paper also introduces a suite of novel error metrics, namely continuous mean squared error (CMSE) and continuous peak signal-to-noise ratio (CPSNR), to assess compression results for unstructured mesh data.","The continuous error metrics are defined by integrating the error function on all cells, providing objective statistics across nonuniformly distributed nodes/cells in the mesh.","We evaluate our methods with several scientific simulations ranging from ocean-climate models and computational fluid dynamics simulations with both traditional and continuous error metrics.","We demonstrated superior compression ratios and quality than existing lossy compressors."],"url":"http://arxiv.org/abs/2312.06080v1"}
{"created":"2023-12-11 02:52:27","title":"Oracle Character Recognition using Unsupervised Discriminative Consistency Network","abstract":"Ancient history relies on the study of ancient characters. However, real-world scanned oracle characters are difficult to collect and annotate, posing a major obstacle for oracle character recognition (OrCR). Besides, serious abrasion and inter-class similarity also make OrCR more challenging. In this paper, we propose a novel unsupervised domain adaptation method for OrCR, which enables to transfer knowledge from labeled handprinted oracle characters to unlabeled scanned data. We leverage pseudo-labeling to incorporate the semantic information into adaptation and constrain augmentation consistency to make the predictions of scanned samples consistent under different perturbations, leading to the model robustness to abrasion, stain and distortion. Simultaneously, an unsupervised transition loss is proposed to learn more discriminative features on the scanned domain by optimizing both between-class and within-class transition probability. Extensive experiments show that our approach achieves state-of-the-art result on Oracle-241 dataset and substantially outperforms the recently proposed structure-texture separation network by 15.1%.","sentences":["Ancient history relies on the study of ancient characters.","However, real-world scanned oracle characters are difficult to collect and annotate, posing a major obstacle for oracle character recognition (OrCR).","Besides, serious abrasion and inter-class similarity also make OrCR more challenging.","In this paper, we propose a novel unsupervised domain adaptation method for OrCR, which enables to transfer knowledge from labeled handprinted oracle characters to unlabeled scanned data.","We leverage pseudo-labeling to incorporate the semantic information into adaptation and constrain augmentation consistency to make the predictions of scanned samples consistent under different perturbations, leading to the model robustness to abrasion, stain and distortion.","Simultaneously, an unsupervised transition loss is proposed to learn more discriminative features on the scanned domain by optimizing both between-class and within-class transition probability.","Extensive experiments show that our approach achieves state-of-the-art result on Oracle-241 dataset and substantially outperforms the recently proposed structure-texture separation network by 15.1%."],"url":"http://arxiv.org/abs/2312.06075v1"}
{"created":"2023-12-11 02:39:08","title":"A dynamic interactive learning framework for automated 3D medical image segmentation","abstract":"Many deep learning based automated medical image segmentation systems, in reality, face difficulties in deployment due to the cost of massive data annotation and high latency in model iteration. We propose a dynamic interactive learning framework that addresses these challenges by integrating interactive segmentation into end-to-end weak supervised learning with streaming tasks. We develop novel replay and label smoothing schemes that overcome catastrophic forgetting and improve online learning robustness. For each image, our multi-round interactive segmentation module simultaneously optimizes both front-end predictions and deep learning segmenter. In each round, a 3D \"proxy mask\" is propagated from sparse user inputs based on image registration, serving as weak supervision that enable knowledge distillation from the unknown ground truth. In return, the trained segmenter explicitly guides next step's user interventions according to a spatial residual map from consecutive front or back-end predictions. Evaluation on 3D segmentation tasks (NCI-ISBI2013 and BraTS2015) shows that our framework generates online learning performances that match offline training benchmark. In addition, with a 62% reduction in total annotation efforts, our framework produces competitive dice scores comparing to online and offline learning which equipped with full ground truth. Furthermore, such a framework, with its flexibility and responsiveness, could be deployed behind hospital firewall that guarantees data security and easy maintenance.","sentences":["Many deep learning based automated medical image segmentation systems, in reality, face difficulties in deployment due to the cost of massive data annotation and high latency in model iteration.","We propose a dynamic interactive learning framework that addresses these challenges by integrating interactive segmentation into end-to-end weak supervised learning with streaming tasks.","We develop novel replay and label smoothing schemes that overcome catastrophic forgetting and improve online learning robustness.","For each image, our multi-round interactive segmentation module simultaneously optimizes both front-end predictions and deep learning segmenter.","In each round, a 3D \"proxy mask\" is propagated from sparse user inputs based on image registration, serving as weak supervision that enable knowledge distillation from the unknown ground truth.","In return, the trained segmenter explicitly guides next step's user interventions according to a spatial residual map from consecutive front or back-end predictions.","Evaluation on 3D segmentation tasks (NCI-ISBI2013 and BraTS2015) shows that our framework generates online learning performances that match offline training benchmark.","In addition, with a 62% reduction in total annotation efforts, our framework produces competitive dice scores comparing to online and offline learning which equipped with full ground truth.","Furthermore, such a framework, with its flexibility and responsiveness, could be deployed behind hospital firewall that guarantees data security and easy maintenance."],"url":"http://arxiv.org/abs/2312.06072v1"}
{"created":"2023-12-11 02:38:07","title":"Probabilistic Precipitation Downscaling with Optical Flow-Guided Diffusion","abstract":"In climate science and meteorology, local precipitation predictions are limited by the immense computational costs induced by the high spatial resolution that simulation methods require. A common workaround is statistical downscaling (aka superresolution), where a low-resolution prediction is super-resolved using statistical approaches. While traditional computer vision tasks mainly focus on human perception or mean squared error, applications in weather and climate require capturing the conditional distribution of high-resolution patterns given low-resolution patterns so that reliable ensemble averages can be taken. Our approach relies on extending recent video diffusion models to precipitation superresolution: an optical flow on the high-resolution output induces temporally coherent predictions, whereas a temporally-conditioned diffusion model generates residuals that capture the correct noise characteristics and high-frequency patterns. We test our approach on X-SHiELD, an established large-scale climate simulation dataset, and compare against two state-of-the-art baselines, focusing on CRPS, MSE, precipitation distributions, as well as an illustrative case -- the complex terrain of California. Our approach sets a new standard for data-driven precipitation downscaling.","sentences":["In climate science and meteorology, local precipitation predictions are limited by the immense computational costs induced by the high spatial resolution that simulation methods require.","A common workaround is statistical downscaling (aka superresolution), where a low-resolution prediction is super-resolved using statistical approaches.","While traditional computer vision tasks mainly focus on human perception or mean squared error, applications in weather and climate require capturing the conditional distribution of high-resolution patterns given low-resolution patterns so that reliable ensemble averages can be taken.","Our approach relies on extending recent video diffusion models to precipitation superresolution: an optical flow on the high-resolution output induces temporally coherent predictions, whereas a temporally-conditioned diffusion model generates residuals that capture the correct noise characteristics and high-frequency patterns.","We test our approach on X-SHiELD, an established large-scale climate simulation dataset, and compare against two state-of-the-art baselines, focusing on CRPS, MSE, precipitation distributions, as well as an illustrative case -- the complex terrain of California.","Our approach sets a new standard for data-driven precipitation downscaling."],"url":"http://arxiv.org/abs/2312.06071v1"}
{"created":"2023-12-11 02:27:45","title":"Mining Gaze for Contrastive Learning toward Computer-Assisted Diagnosis","abstract":"Obtaining large-scale radiology reports can be difficult for medical images due to various reasons, limiting the effectiveness of contrastive pre-training in the medical image domain and underscoring the need for alternative methods. In this paper, we propose eye-tracking as an alternative to text reports, as it allows for the passive collection of gaze signals without disturbing radiologist's routine diagnosis process. By tracking the gaze of radiologists as they read and diagnose medical images, we can understand their visual attention and clinical reasoning. When a radiologist has similar gazes for two medical images, it may indicate semantic similarity for diagnosis, and these images should be treated as positive pairs when pre-training a computer-assisted diagnosis (CAD) network through contrastive learning. Accordingly, we introduce the Medical contrastive Gaze Image Pre-training (McGIP) as a plug-and-play module for contrastive learning frameworks. McGIP uses radiologist's gaze to guide contrastive pre-training. We evaluate our method using two representative types of medical images and two common types of gaze data. The experimental results demonstrate the practicality of McGIP, indicating its high potential for various clinical scenarios and applications.","sentences":["Obtaining large-scale radiology reports can be difficult for medical images due to various reasons, limiting the effectiveness of contrastive pre-training in the medical image domain and underscoring the need for alternative methods.","In this paper, we propose eye-tracking as an alternative to text reports, as it allows for the passive collection of gaze signals without disturbing radiologist's routine diagnosis process.","By tracking the gaze of radiologists as they read and diagnose medical images, we can understand their visual attention and clinical reasoning.","When a radiologist has similar gazes for two medical images, it may indicate semantic similarity for diagnosis, and these images should be treated as positive pairs when pre-training a computer-assisted diagnosis (CAD) network through contrastive learning.","Accordingly, we introduce the Medical contrastive Gaze Image Pre-training (McGIP) as a plug-and-play module for contrastive learning frameworks.","McGIP uses radiologist's gaze to guide contrastive pre-training.","We evaluate our method using two representative types of medical images and two common types of gaze data.","The experimental results demonstrate the practicality of McGIP, indicating its high potential for various clinical scenarios and applications."],"url":"http://arxiv.org/abs/2312.06069v1"}
{"created":"2023-12-11 01:29:19","title":"METAL: Metamorphic Testing Framework for Analyzing Large-Language Model Qualities","abstract":"Large-Language Models (LLMs) have shifted the paradigm of natural language data processing. However, their black-boxed and probabilistic characteristics can lead to potential risks in the quality of outputs in diverse LLM applications. Recent studies have tested Quality Attributes (QAs), such as robustness or fairness, of LLMs by generating adversarial input texts. However, existing studies have limited their coverage of QAs and tasks in LLMs and are difficult to extend. Additionally, these studies have only used one evaluation metric, Attack Success Rate (ASR), to assess the effectiveness of their approaches. We propose a MEtamorphic Testing for Analyzing LLMs (METAL) framework to address these issues by applying Metamorphic Testing (MT) techniques. This approach facilitates the systematic testing of LLM qualities by defining Metamorphic Relations (MRs), which serve as modularized evaluation metrics. The METAL framework can automatically generate hundreds of MRs from templates that cover various QAs and tasks. In addition, we introduced novel metrics that integrate the ASR method into the semantic qualities of text to assess the effectiveness of MRs accurately. Through the experiments conducted with three prominent LLMs, we have confirmed that the METAL framework effectively evaluates essential QAs on primary LLM tasks and reveals the quality risks in LLMs. Moreover, the newly proposed metrics can guide the optimal MRs for testing each task and suggest the most effective method for generating MRs.","sentences":["Large-Language Models (LLMs) have shifted the paradigm of natural language data processing.","However, their black-boxed and probabilistic characteristics can lead to potential risks in the quality of outputs in diverse LLM applications.","Recent studies have tested Quality Attributes (QAs), such as robustness or fairness, of LLMs by generating adversarial input texts.","However, existing studies have limited their coverage of QAs and tasks in LLMs and are difficult to extend.","Additionally, these studies have only used one evaluation metric, Attack Success Rate (ASR), to assess the effectiveness of their approaches.","We propose a MEtamorphic Testing for Analyzing LLMs (METAL) framework to address these issues by applying Metamorphic Testing (MT) techniques.","This approach facilitates the systematic testing of LLM qualities by defining Metamorphic Relations (MRs), which serve as modularized evaluation metrics.","The METAL framework can automatically generate hundreds of MRs from templates that cover various QAs and tasks.","In addition, we introduced novel metrics that integrate the ASR method into the semantic qualities of text to assess the effectiveness of MRs accurately.","Through the experiments conducted with three prominent LLMs, we have confirmed that the METAL framework effectively evaluates essential QAs on primary LLM tasks and reveals the quality risks in LLMs.","Moreover, the newly proposed metrics can guide the optimal MRs for testing each task and suggest the most effective method for generating MRs."],"url":"http://arxiv.org/abs/2312.06056v1"}
{"created":"2023-12-11 01:23:50","title":"Speaker-Text Retrieval via Contrastive Learning","abstract":"In this study, we introduce a novel cross-modal retrieval task involving speaker descriptions and their corresponding audio samples. Utilizing pre-trained speaker and text encoders, we present a simple learning framework based on contrastive learning. Additionally, we explore the impact of incorporating speaker labels into the training process. Our findings establish the effectiveness of linking speaker and text information for the task for both English and Japanese languages, across diverse data configurations. Additional visual analysis unveils potential nuanced associations between speaker clustering and retrieval performance.","sentences":["In this study, we introduce a novel cross-modal retrieval task involving speaker descriptions and their corresponding audio samples.","Utilizing pre-trained speaker and text encoders, we present a simple learning framework based on contrastive learning.","Additionally, we explore the impact of incorporating speaker labels into the training process.","Our findings establish the effectiveness of linking speaker and text information for the task for both English and Japanese languages, across diverse data configurations.","Additional visual analysis unveils potential nuanced associations between speaker clustering and retrieval performance."],"url":"http://arxiv.org/abs/2312.06055v1"}
{"created":"2023-12-11 00:46:34","title":"Federated Multilinear Principal Component Analysis with Applications in Prognostics","abstract":"Multilinear Principal Component Analysis (MPCA) is a widely utilized method for the dimension reduction of tensor data. However, the integration of MPCA into federated learning remains unexplored in existing research. To tackle this gap, this article proposes a Federated Multilinear Principal Component Analysis (FMPCA) method, which enables multiple users to collaboratively reduce the dimension of their tensor data while keeping each user's data local and confidential. The proposed FMPCA method is guaranteed to have the same performance as traditional MPCA. An application of the proposed FMPCA in industrial prognostics is also demonstrated. Simulated data and a real-world data set are used to validate the performance of the proposed method.","sentences":["Multilinear Principal Component Analysis (MPCA) is a widely utilized method for the dimension reduction of tensor data.","However, the integration of MPCA into federated learning remains unexplored in existing research.","To tackle this gap, this article proposes a Federated Multilinear Principal Component Analysis (FMPCA) method, which enables multiple users to collaboratively reduce the dimension of their tensor data while keeping each user's data local and confidential.","The proposed FMPCA method is guaranteed to have the same performance as traditional MPCA.","An application of the proposed FMPCA in industrial prognostics is also demonstrated.","Simulated data and a real-world data set are used to validate the performance of the proposed method."],"url":"http://arxiv.org/abs/2312.06050v1"}
{"created":"2023-12-10 23:32:55","title":"Multimodality of AI for Education: Towards Artificial General Intelligence","abstract":"This paper presents a comprehensive examination of how multimodal artificial intelligence (AI) approaches are paving the way towards the realization of Artificial General Intelligence (AGI) in educational contexts. It scrutinizes the evolution and integration of AI in educational systems, emphasizing the crucial role of multimodality, which encompasses auditory, visual, kinesthetic, and linguistic modes of learning. This research delves deeply into the key facets of AGI, including cognitive frameworks, advanced knowledge representation, adaptive learning mechanisms, strategic planning, sophisticated language processing, and the integration of diverse multimodal data sources. It critically assesses AGI's transformative potential in reshaping educational paradigms, focusing on enhancing teaching and learning effectiveness, filling gaps in existing methodologies, and addressing ethical considerations and responsible usage of AGI in educational settings. The paper also discusses the implications of multimodal AI's role in education, offering insights into future directions and challenges in AGI development. This exploration aims to provide a nuanced understanding of the intersection between AI, multimodality, and education, setting a foundation for future research and development in AGI.","sentences":["This paper presents a comprehensive examination of how multimodal artificial intelligence (AI) approaches are paving the way towards the realization of Artificial General Intelligence (AGI) in educational contexts.","It scrutinizes the evolution and integration of AI in educational systems, emphasizing the crucial role of multimodality, which encompasses auditory, visual, kinesthetic, and linguistic modes of learning.","This research delves deeply into the key facets of AGI, including cognitive frameworks, advanced knowledge representation, adaptive learning mechanisms, strategic planning, sophisticated language processing, and the integration of diverse multimodal data sources.","It critically assesses AGI's transformative potential in reshaping educational paradigms, focusing on enhancing teaching and learning effectiveness, filling gaps in existing methodologies, and addressing ethical considerations and responsible usage of AGI in educational settings.","The paper also discusses the implications of multimodal AI's role in education, offering insights into future directions and challenges in AGI development.","This exploration aims to provide a nuanced understanding of the intersection between AI, multimodality, and education, setting a foundation for future research and development in AGI."],"url":"http://arxiv.org/abs/2312.06037v1"}
{"created":"2023-12-10 23:13:23","title":"Evaluating the Utility of Model Explanations for Model Development","abstract":"One of the motivations for explainable AI is to allow humans to make better and more informed decisions regarding the use and deployment of AI models. But careful evaluations are needed to assess whether this expectation has been fulfilled. Current evaluations mainly focus on algorithmic properties of explanations, and those that involve human subjects often employ subjective questions to test human's perception of explanation usefulness, without being grounded in objective metrics and measurements. In this work, we evaluate whether explanations can improve human decision-making in practical scenarios of machine learning model development. We conduct a mixed-methods user study involving image data to evaluate saliency maps generated by SmoothGrad, GradCAM, and an oracle explanation on two tasks: model selection and counterfactual simulation. To our surprise, we did not find evidence of significant improvement on these tasks when users were provided with any of the saliency maps, even the synthetic oracle explanation designed to be simple to understand and highly indicative of the answer. Nonetheless, explanations did help users more accurately describe the models. These findings suggest caution regarding the usefulness and potential for misunderstanding in saliency-based explanations.","sentences":["One of the motivations for explainable AI is to allow humans to make better and more informed decisions regarding the use and deployment of AI models.","But careful evaluations are needed to assess whether this expectation has been fulfilled.","Current evaluations mainly focus on algorithmic properties of explanations, and those that involve human subjects often employ subjective questions to test human's perception of explanation usefulness, without being grounded in objective metrics and measurements.","In this work, we evaluate whether explanations can improve human decision-making in practical scenarios of machine learning model development.","We conduct a mixed-methods user study involving image data to evaluate saliency maps generated by SmoothGrad, GradCAM, and an oracle explanation on two tasks: model selection and counterfactual simulation.","To our surprise, we did not find evidence of significant improvement on these tasks when users were provided with any of the saliency maps, even the synthetic oracle explanation designed to be simple to understand and highly indicative of the answer.","Nonetheless, explanations did help users more accurately describe the models.","These findings suggest caution regarding the usefulness and potential for misunderstanding in saliency-based explanations."],"url":"http://arxiv.org/abs/2312.06032v1"}
{"created":"2023-12-10 22:30:03","title":"Exploiting Representation Bias for Data Distillation in Abstractive Text Summarization","abstract":"Abstractive text summarization is surging with the number of training samples to cater to the needs of the deep learning models. These models tend to exploit the training data representations to attain superior performance by improving the quantitative element of the resultant summary. However, increasing the size of the training set may not always be the ideal solution to maximize the performance, and therefore, a need to revisit the quality of training samples and the learning protocol of deep learning models is a must. In this paper, we aim to discretize the vector space of the abstractive text summarization models to understand the characteristics learned between the input embedding space and the models' encoder space. We show that deep models fail to capture the diversity of the input space. Further, the distribution of data points on the encoder space indicates that an unchecked increase in the training samples does not add value; rather, a tear-down of data samples is highly needed to make the models focus on variability and faithfulness. We employ clustering techniques to learn the diversity of a model's sample space and how data points are mapped from the embedding space to the encoder space and vice versa. Further, we devise a metric to filter out redundant data points to make the model more robust and less data hungry. We benchmark our proposed method using quantitative metrics, such as Rouge, and qualitative metrics, such as BERTScore, FEQA and Pyramid score. We also quantify the reasons that inhibit the models from learning the diversity from the varied input samples.","sentences":["Abstractive text summarization is surging with the number of training samples to cater to the needs of the deep learning models.","These models tend to exploit the training data representations to attain superior performance by improving the quantitative element of the resultant summary.","However, increasing the size of the training set may not always be the ideal solution to maximize the performance, and therefore, a need to revisit the quality of training samples and the learning protocol of deep learning models is a must.","In this paper, we aim to discretize the vector space of the abstractive text summarization models to understand the characteristics learned between the input embedding space and the models' encoder space.","We show that deep models fail to capture the diversity of the input space.","Further, the distribution of data points on the encoder space indicates that an unchecked increase in the training samples does not add value; rather, a tear-down of data samples is highly needed to make the models focus on variability and faithfulness.","We employ clustering techniques to learn the diversity of a model's sample space and how data points are mapped from the embedding space to the encoder space and vice versa.","Further, we devise a metric to filter out redundant data points to make the model more robust and less data hungry.","We benchmark our proposed method using quantitative metrics, such as Rouge, and qualitative metrics, such as BERTScore, FEQA and Pyramid score.","We also quantify the reasons that inhibit the models from learning the diversity from the varied input samples."],"url":"http://arxiv.org/abs/2312.06022v1"}
{"created":"2023-12-10 22:28:34","title":"GenDepth: Generalizing Monocular Depth Estimation for Arbitrary Camera Parameters via Ground Plane Embedding","abstract":"Learning-based monocular depth estimation leverages geometric priors present in the training data to enable metric depth perception from a single image, a traditionally ill-posed problem. However, these priors are often specific to a particular domain, leading to limited generalization performance on unseen data. Apart from the well studied environmental domain gap, monocular depth estimation is also sensitive to the domain gap induced by varying camera parameters, an aspect that is often overlooked in current state-of-the-art approaches. This issue is particularly evident in autonomous driving scenarios, where datasets are typically collected with a single vehicle-camera setup, leading to a bias in the training data due to a fixed perspective geometry. In this paper, we challenge this trend and introduce GenDepth, a novel model capable of performing metric depth estimation for arbitrary vehicle-camera setups. To address the lack of data with sufficiently diverse camera parameters, we first create a bespoke synthetic dataset collected with different vehicle-camera systems. Then, we design GenDepth to simultaneously optimize two objectives: (i) equivariance to the camera parameter variations on synthetic data, (ii) transferring the learned equivariance to real-world environmental features using a single real-world dataset with a fixed vehicle-camera system. To achieve this, we propose a novel embedding of camera parameters as the ground plane depth and present a novel architecture that integrates these embeddings with adversarial domain alignment. We validate GenDepth on several autonomous driving datasets, demonstrating its state-of-the-art generalization capability for different vehicle-camera systems.","sentences":["Learning-based monocular depth estimation leverages geometric priors present in the training data to enable metric depth perception from a single image, a traditionally ill-posed problem.","However, these priors are often specific to a particular domain, leading to limited generalization performance on unseen data.","Apart from the well studied environmental domain gap, monocular depth estimation is also sensitive to the domain gap induced by varying camera parameters, an aspect that is often overlooked in current state-of-the-art approaches.","This issue is particularly evident in autonomous driving scenarios, where datasets are typically collected with a single vehicle-camera setup, leading to a bias in the training data due to a fixed perspective geometry.","In this paper, we challenge this trend and introduce GenDepth, a novel model capable of performing metric depth estimation for arbitrary vehicle-camera setups.","To address the lack of data with sufficiently diverse camera parameters, we first create a bespoke synthetic dataset collected with different vehicle-camera systems.","Then, we design GenDepth to simultaneously optimize two objectives: (i) equivariance to the camera parameter variations on synthetic data, (ii) transferring the learned equivariance to real-world environmental features using a single real-world dataset with a fixed vehicle-camera system.","To achieve this, we propose a novel embedding of camera parameters as the ground plane depth and present a novel architecture that integrates these embeddings with adversarial domain alignment.","We validate GenDepth on several autonomous driving datasets, demonstrating its state-of-the-art generalization capability for different vehicle-camera systems."],"url":"http://arxiv.org/abs/2312.06021v1"}
{"created":"2023-12-10 21:44:11","title":"Guardians of Trust: Navigating Data Security in AIOps through Vendor Partnerships","abstract":"Artificial Intelligence for IT Operations (AIOps) is a rapidly growing field that applies artificial intelligence and machine learning to automate and optimize IT operations. AIOps vendors provide services that ingest end-to-end logs, traces, and metrics to offer a full stack observability of IT systems. However, these data sources may contain sensitive information such as internal IP addresses, hostnames, HTTP headers, SQLs, method/argument return values, URLs, personal identifiable information (PII), or confidential business data. Therefore, data security is a crucial concern when working with AIOps vendors. In this article, we will discuss the security features offered by different vendors and how we can adopt best practices to ensure data protection and privacy.","sentences":["Artificial Intelligence for IT Operations (AIOps) is a rapidly growing field that applies artificial intelligence and machine learning to automate and optimize IT operations.","AIOps vendors provide services that ingest end-to-end logs, traces, and metrics to offer a full stack observability of IT systems.","However, these data sources may contain sensitive information such as internal IP addresses, hostnames, HTTP headers, SQLs, method/argument return values, URLs, personal identifiable information (PII), or confidential business data.","Therefore, data security is a crucial concern when working with AIOps vendors.","In this article, we will discuss the security features offered by different vendors and how we can adopt best practices to ensure data protection and privacy."],"url":"http://arxiv.org/abs/2312.06008v1"}
{"created":"2023-12-10 21:33:19","title":"Software issues report for bug fixing process: An empirical study of machine-learning libraries","abstract":"Issue resolution and bug-fixing processes are essential in the development of machine-learning libraries, similar to software development, to ensure well-optimized functions. Understanding the issue resolution and bug-fixing process of machine-learning libraries can help developers identify areas for improvement and optimize their strategies for issue resolution and bug-fixing. However, detailed studies on this topic are lacking. Therefore, we investigated the effectiveness of issue resolution for bug-fixing processes in six machine-learning libraries: Tensorflow, Keras, Theano, Pytorch, Caffe, and Scikit-learn. We addressed seven research questions (RQs) using 16,921 issues extracted from the GitHub repository via the GitHub Rest API. We employed several quantitative methods of data analysis, including correlation, OLS regression, percentage and frequency count, and heatmap to analyze the RQs. We found the following through our empirical investigation: (1) The most common categories of issues that arise in machine-learning libraries are bugs, documentation, optimization, crashes, enhancement, new feature requests, build/CI, support, and performance. (2) Effective strategies for addressing these problems include fixing critical bugs, optimizing performance, and improving documentation. (3) These categorized issues are related to testing and runtime and are common among all six machine-learning libraries. (4) Monitoring the total number of comments on issues can provide insights into the duration of the issues. (5) It is crucial to strike a balance between prioritizing critical issues and addressing other issues in a timely manner. Therefore, this study concludes that efficient issue-tracking processes, effective communication, and collaboration are vital for effective resolution of issues and bug fixing processes in machine-learning libraries.","sentences":["Issue resolution and bug-fixing processes are essential in the development of machine-learning libraries, similar to software development, to ensure well-optimized functions.","Understanding the issue resolution and bug-fixing process of machine-learning libraries can help developers identify areas for improvement and optimize their strategies for issue resolution and bug-fixing.","However, detailed studies on this topic are lacking.","Therefore, we investigated the effectiveness of issue resolution for bug-fixing processes in six machine-learning libraries: Tensorflow, Keras, Theano, Pytorch, Caffe, and Scikit-learn.","We addressed seven research questions (RQs) using 16,921 issues extracted from the GitHub repository via the GitHub Rest API.","We employed several quantitative methods of data analysis, including correlation, OLS regression, percentage and frequency count, and heatmap to analyze the RQs.","We found the following through our empirical investigation: (1) The most common categories of issues that arise in machine-learning libraries are bugs, documentation, optimization, crashes, enhancement, new feature requests, build/CI, support, and performance.","(2) Effective strategies for addressing these problems include fixing critical bugs, optimizing performance, and improving documentation.","(3) These categorized issues are related to testing and runtime and are common among all six machine-learning libraries.","(4) Monitoring the total number of comments on issues can provide insights into the duration of the issues.","(5) It is crucial to strike a balance between prioritizing critical issues and addressing other issues in a timely manner.","Therefore, this study concludes that efficient issue-tracking processes, effective communication, and collaboration are vital for effective resolution of issues and bug fixing processes in machine-learning libraries."],"url":"http://arxiv.org/abs/2312.06005v1"}
{"created":"2023-12-10 21:29:28","title":"Multiplier Optimization via E-Graph Rewriting","abstract":"Multiplier circuits account for significant resource usage in datapath-dominated circuit designs, and RTL designers continue to build bespoke hand-crafted multiplication arrays for their particular application. The construction of an optimized multiplier presents trade-offs between pre-processing to generate a smaller array and array reduction. A data structure known as an e-graph has recently been applied to datapath optimization, where the e-graph's ability to efficiently explore trade-offs has been shown to be crucial. We propose an e-graph based rewriting framework to construct optimized multiplier circuits. Such a framework can express alternative multiplier representations and generate customized circuit designs. We demonstrate that the proposed tool, which we call OptiMult, can reduce the latency of a squarer by up to 46% and reduce the latency of a standard multiplier by up to 9% when compared against logic synthesis instantiated components.","sentences":["Multiplier circuits account for significant resource usage in datapath-dominated circuit designs, and RTL designers continue to build bespoke hand-crafted multiplication arrays for their particular application.","The construction of an optimized multiplier presents trade-offs between pre-processing to generate a smaller array and array reduction.","A data structure known as an e-graph has recently been applied to datapath optimization, where the e-graph's ability to efficiently explore trade-offs has been shown to be crucial.","We propose an e-graph based rewriting framework to construct optimized multiplier circuits.","Such a framework can express alternative multiplier representations and generate customized circuit designs.","We demonstrate that the proposed tool, which we call OptiMult, can reduce the latency of a squarer by up to 46% and reduce the latency of a standard multiplier by up to 9% when compared against logic synthesis instantiated components."],"url":"http://arxiv.org/abs/2312.06004v1"}
{"created":"2023-12-10 20:57:01","title":"mir_ref: A Representation Evaluation Framework for Music Information Retrieval Tasks","abstract":"Music Information Retrieval (MIR) research is increasingly leveraging representation learning to obtain more compact, powerful music audio representations for various downstream MIR tasks. However, current representation evaluation methods are fragmented due to discrepancies in audio and label preprocessing, downstream model and metric implementations, data availability, and computational resources, often leading to inconsistent and limited results. In this work, we introduce mir_ref, an MIR Representation Evaluation Framework focused on seamless, transparent, local-first experiment orchestration to support representation development. It features implementations of a variety of components such as MIR datasets, tasks, embedding models, and tools for result analysis and visualization, while facilitating the implementation of custom components. To demonstrate its utility, we use it to conduct an extensive evaluation of several embedding models across various tasks and datasets, including evaluating their robustness to various audio perturbations and the ease of extracting relevant information from them.","sentences":["Music Information Retrieval (MIR) research is increasingly leveraging representation learning to obtain more compact, powerful music audio representations for various downstream MIR tasks.","However, current representation evaluation methods are fragmented due to discrepancies in audio and label preprocessing, downstream model and metric implementations, data availability, and computational resources, often leading to inconsistent and limited results.","In this work, we introduce mir_ref, an MIR Representation Evaluation Framework focused on seamless, transparent, local-first experiment orchestration to support representation development.","It features implementations of a variety of components such as MIR datasets, tasks, embedding models, and tools for result analysis and visualization, while facilitating the implementation of custom components.","To demonstrate its utility, we use it to conduct an extensive evaluation of several embedding models across various tasks and datasets, including evaluating their robustness to various audio perturbations and the ease of extracting relevant information from them."],"url":"http://arxiv.org/abs/2312.05994v1"}
{"created":"2023-12-10 20:29:58","title":"A Note on the Convergence of Denoising Diffusion Probabilistic Models","abstract":"Diffusion models are one of the most important families of deep generative models. In this note, we derive a quantitative upper bound on the Wasserstein distance between the data-generating distribution and the distribution learned by a diffusion model. Unlike previous works in this field, our result does not make assumptions on the learned score function. Moreover, our bound holds for arbitrary data-generating distributions on bounded instance spaces, even those without a density w.r.t. the Lebesgue measure, and the upper bound does not suffer from exponential dependencies. Our main result builds upon the recent work of Mbacke et al. (2023) and our proofs are elementary.","sentences":["Diffusion models are one of the most important families of deep generative models.","In this note, we derive a quantitative upper bound on the Wasserstein distance between the data-generating distribution and the distribution learned by a diffusion model.","Unlike previous works in this field, our result does not make assumptions on the learned score function.","Moreover, our bound holds for arbitrary data-generating distributions on bounded instance spaces, even those without a density w.r.t.","the Lebesgue measure, and the upper bound does not suffer from exponential dependencies.","Our main result builds upon the recent work of Mbacke et al.","(2023) and our proofs are elementary."],"url":"http://arxiv.org/abs/2312.05989v1"}
{"created":"2023-12-10 19:45:24","title":"NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation","abstract":"We present NovaCOMET, an open commonsense knowledge model, that combines the best aspects of knowledge and general task models. Compared to previous knowledge models, NovaCOMET allows open-format relations enabling direct application to reasoning tasks; compared to general task models like Flan-T5, it explicitly centers knowledge, enabling superior performance for commonsense reasoning.   NovaCOMET leverages the knowledge of opaque proprietary models to create an open knowledge pipeline. First, knowledge is symbolically distilled into NovATOMIC, a publicly-released discrete knowledge graph which can be audited, critiqued, and filtered. Next, we train NovaCOMET on NovATOMIC by fine-tuning an open-source pretrained model. NovaCOMET uses an open-format training objective, replacing the fixed relation sets of past knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs.   The resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like Flan-T5 on a range of commonsense generation tasks. NovaCOMET serves as a counterexample to the contemporary focus on instruction tuning only, demonstrating a distinct advantage to explicitly modeling commonsense knowledge as well.","sentences":["We present NovaCOMET, an open commonsense knowledge model, that combines the best aspects of knowledge and general task models.","Compared to previous knowledge models, NovaCOMET allows open-format relations enabling direct application to reasoning tasks; compared to general task models like Flan-T5, it explicitly centers knowledge, enabling superior performance for commonsense reasoning.   ","NovaCOMET leverages the knowledge of opaque proprietary models to create an open knowledge pipeline.","First, knowledge is symbolically distilled into NovATOMIC, a publicly-released discrete knowledge graph which can be audited, critiqued, and filtered.","Next, we train NovaCOMET on NovATOMIC by fine-tuning an open-source pretrained model.","NovaCOMET uses an open-format training objective, replacing the fixed relation sets of past knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs.   ","The resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like Flan-T5 on a range of commonsense generation tasks.","NovaCOMET serves as a counterexample to the contemporary focus on instruction tuning only, demonstrating a distinct advantage to explicitly modeling commonsense knowledge as well."],"url":"http://arxiv.org/abs/2312.05979v1"}
{"created":"2023-12-10 19:21:33","title":"Learning the Causal Structure of Networked Dynamical Systems under Latent Nodes and Structured Noise","abstract":"This paper considers learning the hidden causal network of a linear networked dynamical system (NDS) from the time series data at some of its nodes -- partial observability. The dynamics of the NDS are driven by colored noise that generates spurious associations across pairs of nodes, rendering the problem much harder. To address the challenge of noise correlation and partial observability, we assign to each pair of nodes a feature vector computed from the time series data of observed nodes. The feature embedding is engineered to yield structural consistency: there exists an affine hyperplane that consistently partitions the set of features, separating the feature vectors corresponding to connected pairs of nodes from those corresponding to disconnected pairs. The causal inference problem is thus addressed via clustering the designed features. We demonstrate with simple baseline supervised methods the competitive performance of the proposed causal inference mechanism under broad connectivity regimes and noise correlation levels, including a real world network. Further, we devise novel technical guarantees of structural consistency for linear NDS under the considered regime.","sentences":["This paper considers learning the hidden causal network of a linear networked dynamical system (NDS) from the time series data at some of its nodes -- partial observability.","The dynamics of the NDS are driven by colored noise that generates spurious associations across pairs of nodes, rendering the problem much harder.","To address the challenge of noise correlation and partial observability, we assign to each pair of nodes a feature vector computed from the time series data of observed nodes.","The feature embedding is engineered to yield structural consistency: there exists an affine hyperplane that consistently partitions the set of features, separating the feature vectors corresponding to connected pairs of nodes from those corresponding to disconnected pairs.","The causal inference problem is thus addressed via clustering the designed features.","We demonstrate with simple baseline supervised methods the competitive performance of the proposed causal inference mechanism under broad connectivity regimes and noise correlation levels, including a real world network.","Further, we devise novel technical guarantees of structural consistency for linear NDS under the considered regime."],"url":"http://arxiv.org/abs/2312.05974v1"}
{"created":"2023-12-10 19:13:34","title":"Activating Frequency and ViT for 3D Point Cloud Quality Assessment without Reference","abstract":"Deep learning-based quality assessments have significantly enhanced perceptual multimedia quality assessment, however it is still in the early stages for 3D visual data such as 3D point clouds (PCs). Due to the high volume of 3D-PCs, such quantities are frequently compressed for transmission and viewing, which may affect perceived quality. Therefore, we propose no-reference quality metric of a given 3D-PC. Comparing to existing methods that mostly focus on geometry or color aspects, we propose integrating frequency magnitudes as indicator of spatial degradation patterns caused by the compression. To map the input attributes to quality score, we use a light-weight hybrid deep model; combined of Deformable Convolutional Network (DCN) and Vision Transformers (ViT). Experiments are carried out on ICIP20 [1], PointXR [2] dataset, and a new big dataset called BASICS [3]. The results show that our approach outperforms state-of-the-art NR-PCQA measures and even some FR-PCQA on PointXR. The implementation code can be found at: https://github.com/o-messai/3D-PCQA","sentences":["Deep learning-based quality assessments have significantly enhanced perceptual multimedia quality assessment, however it is still in the early stages for 3D visual data such as 3D point clouds (PCs).","Due to the high volume of 3D-PCs, such quantities are frequently compressed for transmission and viewing, which may affect perceived quality.","Therefore, we propose no-reference quality metric of a given 3D-PC.","Comparing to existing methods that mostly focus on geometry or color aspects, we propose integrating frequency magnitudes as indicator of spatial degradation patterns caused by the compression.","To map the input attributes to quality score, we use a light-weight hybrid deep model; combined of Deformable Convolutional Network (DCN) and Vision Transformers (ViT).","Experiments are carried out on ICIP20","[1], PointXR","[2] dataset, and a new big dataset called BASICS","[3].","The results show that our approach outperforms state-of-the-art NR-PCQA measures and even some FR-PCQA on PointXR.","The implementation code can be found at: https://github.com/o-messai/3D-PCQA"],"url":"http://arxiv.org/abs/2312.05972v1"}
{"created":"2023-12-10 18:54:16","title":"Jumpstarting Surgical Computer Vision","abstract":"Purpose: General consensus amongst researchers and industry points to a lack of large, representative annotated datasets as the biggest obstacle to progress in the field of surgical data science. Self-supervised learning represents a solution to part of this problem, removing the reliance on annotations. However, the robustness of current self-supervised learning methods to domain shifts remains unclear, limiting our understanding of its utility for leveraging diverse sources of surgical data. Methods: In this work, we employ self-supervised learning to flexibly leverage diverse surgical datasets, thereby learning taskagnostic representations that can be used for various surgical downstream tasks. Based on this approach, to elucidate the impact of pre-training on downstream task performance, we explore 22 different pre-training dataset combinations by modulating three variables: source hospital, type of surgical procedure, and pre-training scale (number of videos). We then finetune the resulting model initializations on three diverse downstream tasks: namely, phase recognition and critical view of safety in laparoscopic cholecystectomy and phase recognition in laparoscopic hysterectomy. Results: Controlled experimentation highlights sizable boosts in performance across various tasks, datasets, and labeling budgets. However, this performance is intricately linked to the composition of the pre-training dataset, robustly proven through several study stages. Conclusion: The composition of pre-training datasets can severely affect the effectiveness of SSL methods for various downstream tasks and should critically inform future data collection efforts to scale the application of SSL methodologies.   Keywords: Self-Supervised Learning, Transfer Learning, Surgical Computer Vision, Endoscopic Videos, Critical View of Safety, Phase Recognition","sentences":["Purpose:","General consensus amongst researchers and industry points to a lack of large, representative annotated datasets as the biggest obstacle to progress in the field of surgical data science.","Self-supervised learning represents a solution to part of this problem, removing the reliance on annotations.","However, the robustness of current self-supervised learning methods to domain shifts remains unclear, limiting our understanding of its utility for leveraging diverse sources of surgical data.","Methods: In this work, we employ self-supervised learning to flexibly leverage diverse surgical datasets, thereby learning taskagnostic representations that can be used for various surgical downstream tasks.","Based on this approach, to elucidate the impact of pre-training on downstream task performance, we explore 22 different pre-training dataset combinations by modulating three variables: source hospital, type of surgical procedure, and pre-training scale (number of videos).","We then finetune the resulting model initializations on three diverse downstream tasks: namely, phase recognition and critical view of safety in laparoscopic cholecystectomy and phase recognition in laparoscopic hysterectomy.","Results: Controlled experimentation highlights sizable boosts in performance across various tasks, datasets, and labeling budgets.","However, this performance is intricately linked to the composition of the pre-training dataset, robustly proven through several study stages.","Conclusion: The composition of pre-training datasets can severely affect the effectiveness of SSL methods for various downstream tasks and should critically inform future data collection efforts to scale the application of SSL methodologies.   ","Keywords: Self-Supervised Learning, Transfer Learning, Surgical Computer Vision, Endoscopic Videos, Critical View of Safety, Phase Recognition"],"url":"http://arxiv.org/abs/2312.05968v1"}
{"created":"2023-12-10 18:49:59","title":"Fake It Till Make It: Federated Learning with Consensus-Oriented Generation","abstract":"In federated learning (FL), data heterogeneity is one key bottleneck that causes model divergence and limits performance. Addressing this, existing methods often regard data heterogeneity as an inherent property and propose to mitigate its adverse effects by correcting models. In this paper, we seek to break this inherent property by generating data to complement the original dataset to fundamentally mitigate heterogeneity level. As a novel attempt from the perspective of data, we propose federated learning with consensus-oriented generation (FedCOG). FedCOG consists of two key components at the client side: complementary data generation, which generates data extracted from the shared global model to complement the original dataset, and knowledge-distillation-based model training, which distills knowledge from global model to local model based on the generated data to mitigate over-fitting the original heterogeneous dataset. FedCOG has two critical advantages: 1) it can be a plug-and-play module to further improve the performance of most existing FL methods, and 2) it is naturally compatible with standard FL protocols such as Secure Aggregation since it makes no modification in communication process. Extensive experiments on classical and real-world FL datasets show that FedCOG consistently outperforms state-of-the-art methods.","sentences":["In federated learning (FL), data heterogeneity is one key bottleneck that causes model divergence and limits performance.","Addressing this, existing methods often regard data heterogeneity as an inherent property and propose to mitigate its adverse effects by correcting models.","In this paper, we seek to break this inherent property by generating data to complement the original dataset to fundamentally mitigate heterogeneity level.","As a novel attempt from the perspective of data, we propose federated learning with consensus-oriented generation (FedCOG).","FedCOG consists of two key components at the client side: complementary data generation, which generates data extracted from the shared global model to complement the original dataset, and knowledge-distillation-based model training, which distills knowledge from global model to local model based on the generated data to mitigate over-fitting the original heterogeneous dataset.","FedCOG has two critical advantages: 1) it can be a plug-and-play module to further improve the performance of most existing FL methods, and 2) it is naturally compatible with standard FL protocols such as Secure Aggregation since it makes no modification in communication process.","Extensive experiments on classical and real-world FL datasets show that FedCOG consistently outperforms state-of-the-art methods."],"url":"http://arxiv.org/abs/2312.05966v1"}
{"created":"2023-12-10 18:43:37","title":"ConSequence: Synthesizing Logically Constrained Sequences for Electronic Health Record Generation","abstract":"Generative models can produce synthetic patient records for analytical tasks when real data is unavailable or limited. However, current methods struggle with adhering to domain-specific knowledge and removing invalid data. We present ConSequence, an effective approach to integrating domain knowledge into sequential generative neural network outputs. Our rule-based formulation includes temporal aggregation and antecedent evaluation modules, ensured by an efficient matrix multiplication formulation, to satisfy hard and soft logical constraints across time steps. Existing constraint methods often fail to guarantee constraint satisfaction, lack the ability to handle temporal constraints, and hinder the learning and computational efficiency of the model. In contrast, our approach efficiently handles all types of constraints with guaranteed logical coherence. We demonstrate ConSequence's effectiveness in generating electronic health records, outperforming competitors in achieving complete temporal and spatial constraint satisfaction without compromising runtime performance or generative quality. Specifically, ConSequence successfully prevents all rule violations while improving the model quality in reducing its test perplexity by 5% and incurring less than a 13% slowdown in generation speed compared to an unconstrained model.","sentences":["Generative models can produce synthetic patient records for analytical tasks when real data is unavailable or limited.","However, current methods struggle with adhering to domain-specific knowledge and removing invalid data.","We present ConSequence, an effective approach to integrating domain knowledge into sequential generative neural network outputs.","Our rule-based formulation includes temporal aggregation and antecedent evaluation modules, ensured by an efficient matrix multiplication formulation, to satisfy hard and soft logical constraints across time steps.","Existing constraint methods often fail to guarantee constraint satisfaction, lack the ability to handle temporal constraints, and hinder the learning and computational efficiency of the model.","In contrast, our approach efficiently handles all types of constraints with guaranteed logical coherence.","We demonstrate ConSequence's effectiveness in generating electronic health records, outperforming competitors in achieving complete temporal and spatial constraint satisfaction without compromising runtime performance or generative quality.","Specifically, ConSequence successfully prevents all rule violations while improving the model quality in reducing its test perplexity by 5% and incurring less than a 13% slowdown in generation speed compared to an unconstrained model."],"url":"http://arxiv.org/abs/2312.05964v1"}
{"created":"2023-12-10 18:27:33","title":"Aikyam: A Video Conferencing Utility for Deaf and Dumb","abstract":"With the advent of the pandemic, the use of video conferencing platforms as a means of communication has greatly increased and with it, so have the remote opportunities. The deaf and dumb have traditionally faced several issues in communication, but now the effect is felt more severely. This paper proposes an all-encompassing video conferencing utility that can be used with existing video conferencing platforms to address these issues. Appropriate semantically correct sentences are generated from the signer's gestures which would be interpreted by the system. Along with an audio to emit this sentence, the user's feed is also used to annotate the sentence. This can be viewed by all participants, thus aiding smooth communication with all parties involved. This utility utilizes a simple LSTM model for classification of gestures. The sentences are constructed by a t5 based model. In order to achieve the required data flow, a virtual camera is used.","sentences":["With the advent of the pandemic, the use of video conferencing platforms as a means of communication has greatly increased and with it, so have the remote opportunities.","The deaf and dumb have traditionally faced several issues in communication, but now the effect is felt more severely.","This paper proposes an all-encompassing video conferencing utility that can be used with existing video conferencing platforms to address these issues.","Appropriate semantically correct sentences are generated from the signer's gestures which would be interpreted by the system.","Along with an audio to emit this sentence, the user's feed is also used to annotate the sentence.","This can be viewed by all participants, thus aiding smooth communication with all parties involved.","This utility utilizes a simple LSTM model for classification of gestures.","The sentences are constructed by a t5 based model.","In order to achieve the required data flow, a virtual camera is used."],"url":"http://arxiv.org/abs/2312.05962v1"}
{"created":"2023-12-10 18:23:40","title":"TransGlow: Attention-augmented Transduction model based on Graph Neural Networks for Water Flow Forecasting","abstract":"The hydrometric prediction of water quantity is useful for a variety of applications, including water management, flood forecasting, and flood control. However, the task is difficult due to the dynamic nature and limited data of water systems. Highly interconnected water systems can significantly affect hydrometric forecasting. Consequently, it is crucial to develop models that represent the relationships between other system components. In recent years, numerous hydrological applications have been studied, including streamflow prediction, flood forecasting, and water quality prediction. Existing methods are unable to model the influence of adjacent regions between pairs of variables. In this paper, we propose a spatiotemporal forecasting model that augments the hidden state in Graph Convolution Recurrent Neural Network (GCRN) encoder-decoder using an efficient version of the attention mechanism. The attention layer allows the decoder to access different parts of the input sequence selectively. Since water systems are interconnected and the connectivity information between the stations is implicit, the proposed model leverages a graph learning module to extract a sparse graph adjacency matrix adaptively based on the data. Spatiotemporal forecasting relies on historical data. In some regions, however, historical data may be limited or incomplete, making it difficult to accurately predict future water conditions. Further, we present a new benchmark dataset of water flow from a network of Canadian stations on rivers, streams, and lakes. Experimental results demonstrate that our proposed model TransGlow significantly outperforms baseline methods by a wide margin.","sentences":["The hydrometric prediction of water quantity is useful for a variety of applications, including water management, flood forecasting, and flood control.","However, the task is difficult due to the dynamic nature and limited data of water systems.","Highly interconnected water systems can significantly affect hydrometric forecasting.","Consequently, it is crucial to develop models that represent the relationships between other system components.","In recent years, numerous hydrological applications have been studied, including streamflow prediction, flood forecasting, and water quality prediction.","Existing methods are unable to model the influence of adjacent regions between pairs of variables.","In this paper, we propose a spatiotemporal forecasting model that augments the hidden state in Graph Convolution Recurrent Neural Network (GCRN) encoder-decoder using an efficient version of the attention mechanism.","The attention layer allows the decoder to access different parts of the input sequence selectively.","Since water systems are interconnected and the connectivity information between the stations is implicit, the proposed model leverages a graph learning module to extract a sparse graph adjacency matrix adaptively based on the data.","Spatiotemporal forecasting relies on historical data.","In some regions, however, historical data may be limited or incomplete, making it difficult to accurately predict future water conditions.","Further, we present a new benchmark dataset of water flow from a network of Canadian stations on rivers, streams, and lakes.","Experimental results demonstrate that our proposed model TransGlow significantly outperforms baseline methods by a wide margin."],"url":"http://arxiv.org/abs/2312.05961v1"}
