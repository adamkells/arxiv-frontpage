{"created":"2024-08-29 17:59:45","title":"SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners","abstract":"We introduce SAM2Point, a preliminary exploration adapting Segment Anything Model 2 (SAM 2) for zero-shot and promptable 3D segmentation. SAM2Point interprets any 3D data as a series of multi-directional videos, and leverages SAM 2 for 3D-space segmentation, without further training or 2D-3D projection. Our framework supports various prompt types, including 3D points, boxes, and masks, and can generalize across diverse scenarios, such as 3D objects, indoor scenes, outdoor environments, and raw sparse LiDAR. Demonstrations on multiple 3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight the robust generalization capabilities of SAM2Point. To our best knowledge, we present the most faithful implementation of SAM in 3D, which may serve as a starting point for future research in promptable 3D segmentation. Online Demo: https://huggingface.co/spaces/ZiyuG/SAM2Point . Code: https://github.com/ZiyuGuo99/SAM2Point .","sentences":["We introduce SAM2Point, a preliminary exploration adapting Segment Anything Model 2 (SAM 2) for zero-shot and promptable 3D segmentation.","SAM2Point interprets any 3D data as a series of multi-directional videos, and leverages SAM 2 for 3D-space segmentation, without further training or 2D-3D projection.","Our framework supports various prompt types, including 3D points, boxes, and masks, and can generalize across diverse scenarios, such as 3D objects, indoor scenes, outdoor environments, and raw sparse LiDAR.","Demonstrations on multiple 3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight the robust generalization capabilities of SAM2Point.","To our best knowledge, we present the most faithful implementation of SAM in 3D, which may serve as a starting point for future research in promptable 3D segmentation.","Online Demo: https://huggingface.co/spaces/ZiyuG/SAM2Point .","Code: https://github.com/ZiyuGuo99/SAM2Point ."],"url":"http://arxiv.org/abs/2408.16768v1"}
{"created":"2024-08-29 17:59:30","title":"CSGO: Content-Style Composition in Text-to-Image Generation","abstract":"The diffusion model has shown exceptional capabilities in controlled image generation, which has further fueled interest in image style transfer. Existing works mainly focus on training free-based methods (e.g., image inversion) due to the scarcity of specific data. In this study, we present a data construction pipeline for content-style-stylized image triplets that generates and automatically cleanses stylized data triplets. Based on this pipeline, we construct a dataset IMAGStyle, the first large-scale style transfer dataset containing 210k image triplets, available for the community to explore and research. Equipped with IMAGStyle, we propose CSGO, a style transfer model based on end-to-end training, which explicitly decouples content and style features employing independent feature injection. The unified CSGO implements image-driven style transfer, text-driven stylized synthesis, and text editing-driven stylized synthesis. Extensive experiments demonstrate the effectiveness of our approach in enhancing style control capabilities in image generation. Additional visualization and access to the source code can be located on the project page: \\url{https://csgo-gen.github.io/}.","sentences":["The diffusion model has shown exceptional capabilities in controlled image generation, which has further fueled interest in image style transfer.","Existing works mainly focus on training free-based methods (e.g., image inversion) due to the scarcity of specific data.","In this study, we present a data construction pipeline for content-style-stylized image triplets that generates and automatically cleanses stylized data triplets.","Based on this pipeline, we construct a dataset IMAGStyle, the first large-scale style transfer dataset containing 210k image triplets, available for the community to explore and research.","Equipped with IMAGStyle, we propose CSGO, a style transfer model based on end-to-end training, which explicitly decouples content and style features employing independent feature injection.","The unified CSGO implements image-driven style transfer, text-driven stylized synthesis, and text editing-driven stylized synthesis.","Extensive experiments demonstrate the effectiveness of our approach in enhancing style control capabilities in image generation.","Additional visualization and access to the source code can be located on the project page: \\url{https://csgo-gen.github.io/}."],"url":"http://arxiv.org/abs/2408.16766v1"}
{"created":"2024-08-29 17:54:14","title":"How Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models","abstract":"The rapid evolution of large language models (LLMs) has transformed the competitive landscape in natural language processing (NLP), particularly for English and other data-rich languages. However, underrepresented languages like Cantonese, spoken by over 85 million people, face significant development gaps, which is particularly concerning given the economic significance of the Guangdong-Hong Kong-Macau Greater Bay Area, and in substantial Cantonese-speaking populations in places like Singapore and North America. Despite its wide use, Cantonese has scant representation in NLP research, especially compared to other languages from similarly developed regions. To bridge these gaps, we outline current Cantonese NLP methods and introduce new benchmarks designed to evaluate LLM performance in factual generation, mathematical logic, complex reasoning, and general knowledge in Cantonese, which aim to advance open-source Cantonese LLM technology. We also propose future research directions and recommended models to enhance Cantonese LLM development.","sentences":["The rapid evolution of large language models (LLMs) has transformed the competitive landscape in natural language processing (NLP), particularly for English and other data-rich languages.","However, underrepresented languages like Cantonese, spoken by over 85 million people, face significant development gaps, which is particularly concerning given the economic significance of the Guangdong-Hong Kong-Macau Greater Bay Area, and in substantial Cantonese-speaking populations in places like Singapore and North America.","Despite its wide use, Cantonese has scant representation in NLP research, especially compared to other languages from similarly developed regions.","To bridge these gaps, we outline current Cantonese NLP methods and introduce new benchmarks designed to evaluate LLM performance in factual generation, mathematical logic, complex reasoning, and general knowledge in Cantonese, which aim to advance open-source Cantonese LLM technology.","We also propose future research directions and recommended models to enhance Cantonese LLM development."],"url":"http://arxiv.org/abs/2408.16756v1"}
{"created":"2024-08-29 17:49:18","title":"Reinforcement Learning without Human Feedback for Last Mile Fine-Tuning of Large Language Models","abstract":"Reinforcement learning is used to align language models with human preference signals after first pre-training the model to predict the next token of text within a large corpus using likelihood maximization. Before being deployed in a specific domain, models are often further fine-tuned on task specific data. Since human preferences are often unavailable for the last step, it is performed using likelihood maximization as that is the typical default method. However, reinforcement learning has other advantages besides facilitating alignment to a human derived reward function. For one, whereas likelihood maximization is a form of imitation learning in which the model is trained on what to do under ideal conditions, reinforcement learning is not limited to demonstrating actions just for optimally reached states and trains a model what to do under a range of scenarios as it explores the policy space. In addition, it also trains a model what not to do, suppressing competitive but poor actions. This work develops a framework for last-mile fine-tuning using reinforcement learning and tests whether it garners performance gains. The experiments center on abstractive summarization, but the framework is general and broadly applicable. Use of the procedure produced significantly better results than likelihood maximization when comparing raw predictions. For the specific data tested, the gap could be bridged by employing post-processing of the maximum likelihood outputs. Nonetheless, the framework offers a new avenue for model optimization in situations where post-processing may be less straightforward or effective, and it can be extended to include more complex classes of undesirable outputs to penalize and train against, such as hallucinations.","sentences":["Reinforcement learning is used to align language models with human preference signals after first pre-training the model to predict the next token of text within a large corpus using likelihood maximization.","Before being deployed in a specific domain, models are often further fine-tuned on task specific data.","Since human preferences are often unavailable for the last step, it is performed using likelihood maximization as that is the typical default method.","However, reinforcement learning has other advantages besides facilitating alignment to a human derived reward function.","For one, whereas likelihood maximization is a form of imitation learning in which the model is trained on what to do under ideal conditions, reinforcement learning is not limited to demonstrating actions just for optimally reached states and trains a model what to do under a range of scenarios as it explores the policy space.","In addition, it also trains a model what not to do, suppressing competitive but poor actions.","This work develops a framework for last-mile fine-tuning using reinforcement learning and tests whether it garners performance gains.","The experiments center on abstractive summarization, but the framework is general and broadly applicable.","Use of the procedure produced significantly better results than likelihood maximization when comparing raw predictions.","For the specific data tested, the gap could be bridged by employing post-processing of the maximum likelihood outputs.","Nonetheless, the framework offers a new avenue for model optimization in situations where post-processing may be less straightforward or effective, and it can be extended to include more complex classes of undesirable outputs to penalize and train against, such as hallucinations."],"url":"http://arxiv.org/abs/2408.16753v1"}
{"created":"2024-08-29 17:43:03","title":"Assessing Large Language Models for Online Extremism Research: Identification, Explanation, and New Knowledge","abstract":"The United States has experienced a significant increase in violent extremism, prompting the need for automated tools to detect and limit the spread of extremist ideology online. This study evaluates the performance of Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-Trained Transformers (GPT) in detecting and classifying online domestic extremist posts. We collected social media posts containing \"far-right\" and \"far-left\" ideological keywords and manually labeled them as extremist or non-extremist. Extremist posts were further classified into one or more of five contributing elements of extremism based on a working definitional framework. The BERT model's performance was evaluated based on training data size and knowledge transfer between categories. We also compared the performance of GPT 3.5 and GPT 4 models using different prompts: na\\\"ive, layperson-definition, role-playing, and professional-definition. Results showed that the best performing GPT models outperformed the best performing BERT models, with more detailed prompts generally yielding better results. However, overly complex prompts may impair performance. Different versions of GPT have unique sensitives to what they consider extremist. GPT 3.5 performed better at classifying far-left extremist posts, while GPT 4 performed better at classifying far-right extremist posts. Large language models, represented by GPT models, hold significant potential for online extremism classification tasks, surpassing traditional BERT models in a zero-shot setting. Future research should explore human-computer interactions in optimizing GPT models for extremist detection and classification tasks to develop more efficient (e.g., quicker, less effort) and effective (e.g., fewer errors or mistakes) methods for identifying extremist content.","sentences":["The United States has experienced a significant increase in violent extremism, prompting the need for automated tools to detect and limit the spread of extremist ideology online.","This study evaluates the performance of Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-Trained Transformers (GPT) in detecting and classifying online domestic extremist posts.","We collected social media posts containing \"far-right\" and \"far-left\" ideological keywords and manually labeled them as extremist or non-extremist.","Extremist posts were further classified into one or more of five contributing elements of extremism based on a working definitional framework.","The BERT model's performance was evaluated based on training data size and knowledge transfer between categories.","We also compared the performance of GPT 3.5 and GPT 4 models using different prompts: na\\\"ive, layperson-definition, role-playing, and professional-definition.","Results showed that the best performing GPT models outperformed the best performing BERT models, with more detailed prompts generally yielding better results.","However, overly complex prompts may impair performance.","Different versions of GPT have unique sensitives to what they consider extremist.","GPT 3.5 performed better at classifying far-left extremist posts, while GPT 4 performed better at classifying far-right extremist posts.","Large language models, represented by GPT models, hold significant potential for online extremism classification tasks, surpassing traditional BERT models in a zero-shot setting.","Future research should explore human-computer interactions in optimizing GPT models for extremist detection and classification tasks to develop more efficient (e.g., quicker, less effort) and effective (e.g., fewer errors or mistakes) methods for identifying extremist content."],"url":"http://arxiv.org/abs/2408.16749v1"}
{"created":"2024-08-29 17:32:35","title":"Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling","abstract":"Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs. In this work, we revisit whether this strategy is compute-optimal under a fixed inference budget (e.g., FLOPs). To do so, we investigate the trade-offs between generating synthetic data using a stronger but more expensive (SE) model versus a weaker but cheaper (WC) model. We evaluate the generated data across three key metrics: coverage, diversity, and false positive rate, and show that the data from WC models may have higher coverage and diversity, but also exhibit higher false positive rates. We then finetune LMs on data from SE and WC models in different settings: knowledge distillation, self-improvement, and a novel weak-to-strong improvement setup where a weaker LM teaches reasoning to a stronger LM. Our findings reveal that models finetuned on WC-generated data consistently outperform those trained on SE-generated data across multiple benchmarks and multiple choices of WC and SE models. These results challenge the prevailing practice of relying on SE models for synthetic data generation, suggesting that WC may be the compute-optimal approach for training advanced LM reasoners.","sentences":["Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs.","In this work, we revisit whether this strategy is compute-optimal under a fixed inference budget (e.g., FLOPs).","To do so, we investigate the trade-offs between generating synthetic data using a stronger but more expensive (SE) model versus a weaker but cheaper (WC) model.","We evaluate the generated data across three key metrics: coverage, diversity, and false positive rate, and show that the data from WC models may have higher coverage and diversity, but also exhibit higher false positive rates.","We then finetune LMs on data from SE and WC models in different settings: knowledge distillation, self-improvement, and a novel weak-to-strong improvement setup where a weaker LM teaches reasoning to a stronger LM.","Our findings reveal that models finetuned on WC-generated data consistently outperform those trained on SE-generated data across multiple benchmarks and multiple choices of WC and SE models.","These results challenge the prevailing practice of relying on SE models for synthetic data generation, suggesting that WC may be the compute-optimal approach for training advanced LM reasoners."],"url":"http://arxiv.org/abs/2408.16737v1"}
{"created":"2024-08-29 17:06:20","title":"ARINC 429 Cyber-vulnerabilities and Voltage Data in a Hardware-in-the-Loop Simulator","abstract":"ARINC 429 is a ubiquitous data bus for civil avionics, enabling reliable communication between devices from disparate manufacturers. However, ARINC 429 lacks any form of encryption or authentication, making it an inherently insecure communication protocol and rendering any connected avionics vulnerable to a range of attacks. We constructed a hardware-in-the-loop simulator with ARINC 429 buses, explored these vulnerabilities, and identified their potential to deny, degrade, or disrupt aircraft capabilities. We performed a denial-of-service attack against a multi-function display via a compromised ARINC 429 bus using commercially available tools, which succeeded in disabling important navigational aids. This proven attack on physical avionics illustrates the risk inherent in ARINC 429 and the need for the ability to detect these attacks. One potential mitigation is an intrusion detection system (IDS) trained on data collected from the electrical properties of the physical bus. Although previous research has demonstrated the feasibility of an IDS on an ARINC 429 bus, no IDS has been trained on data generated by avionics hardware. To facilitate this, we recorded voltage traces and message history generated by avionics and adversarial devices on the ARINC 429 bus. To the best of our knowledge, this is the first publicly available collection of hardware-generated ARINC 429 signal data.","sentences":["ARINC 429 is a ubiquitous data bus for civil avionics, enabling reliable communication between devices from disparate manufacturers.","However, ARINC 429 lacks any form of encryption or authentication, making it an inherently insecure communication protocol and rendering any connected avionics vulnerable to a range of attacks.","We constructed a hardware-in-the-loop simulator with ARINC 429 buses, explored these vulnerabilities, and identified their potential to deny, degrade, or disrupt aircraft capabilities.","We performed a denial-of-service attack against a multi-function display via a compromised ARINC 429 bus using commercially available tools, which succeeded in disabling important navigational aids.","This proven attack on physical avionics illustrates the risk inherent in ARINC 429 and the need for the ability to detect these attacks.","One potential mitigation is an intrusion detection system (IDS) trained on data collected from the electrical properties of the physical bus.","Although previous research has demonstrated the feasibility of an IDS on an ARINC 429 bus, no IDS has been trained on data generated by avionics hardware.","To facilitate this, we recorded voltage traces and message history generated by avionics and adversarial devices on the ARINC 429 bus.","To the best of our knowledge, this is the first publicly available collection of hardware-generated ARINC 429 signal data."],"url":"http://arxiv.org/abs/2408.16714v1"}
{"created":"2024-08-29 17:05:10","title":"Hydrogen reaction rate modeling based on convolutional neural network for large eddy simulation","abstract":"This paper establishes a data-driven modeling framework for lean Hydrogen (H2)-air reaction rates for the Large Eddy Simulation (LES) of turbulent reactive flows. This is particularly challenging since H2 molecules diffuse much faster than heat, leading to large variations in burning rates, thermodiffusive instabilities at the subfilter scale, and complex turbulence-chemistry interactions. Our data-driven approach leverages a Convolutional Neural Network (CNN), trained to approximate filtered burning rates from emulated LES data. First, five different lean premixed turbulent H2-air flame Direct Numerical Simulations (DNSs) are computed each with a unique global equivalence ratio. Second, DNS snapshots are filtered and downsampled to emulate LES data. Third, a CNN is trained to approximate the filtered burning rates as a function of LES scalar quantities: progress variable, local equivalence ratio and flame thickening due to filtering. Finally, the performances of the CNN model are assessed on test solutions never seen during training. The model retrieves burning rates with very high accuracy. It is also tested on two filter and downsampling parameters and two global equivalence ratios between those used during training. For these interpolation cases, the model approximates burning rates with low error even though the cases were not included in the training dataset. This a priori study shows that the proposed data-driven machine learning framework is able to address the challenge of modeling lean premixed H2-air burning rates. It paves the way for a new modeling paradigm for the simulation of carbon-free hydrogen combustion systems.","sentences":["This paper establishes a data-driven modeling framework for lean Hydrogen (H2)-air reaction rates for the Large Eddy Simulation (LES) of turbulent reactive flows.","This is particularly challenging since H2 molecules diffuse much faster than heat, leading to large variations in burning rates, thermodiffusive instabilities at the subfilter scale, and complex turbulence-chemistry interactions.","Our data-driven approach leverages a Convolutional Neural Network (CNN), trained to approximate filtered burning rates from emulated LES data.","First, five different lean premixed turbulent H2-air flame Direct Numerical Simulations (DNSs) are computed each with a unique global equivalence ratio.","Second, DNS snapshots are filtered and downsampled to emulate LES data.","Third, a CNN is trained to approximate the filtered burning rates as a function of LES scalar quantities: progress variable, local equivalence ratio and flame thickening due to filtering.","Finally, the performances of the CNN model are assessed on test solutions never seen during training.","The model retrieves burning rates with very high accuracy.","It is also tested on two filter and downsampling parameters and two global equivalence ratios between those used during training.","For these interpolation cases, the model approximates burning rates with low error even though the cases were not included in the training dataset.","This a priori study shows that the proposed data-driven machine learning framework is able to address the challenge of modeling lean premixed H2-air burning rates.","It paves the way for a new modeling paradigm for the simulation of carbon-free hydrogen combustion systems."],"url":"http://arxiv.org/abs/2408.16709v1"}
{"created":"2024-08-29 16:58:10","title":"One-Shot Learning Meets Depth Diffusion in Multi-Object Videos","abstract":"Creating editable videos that depict complex interactions between multiple objects in various artistic styles has long been a challenging task in filmmaking. Progress is often hampered by the scarcity of data sets that contain paired text descriptions and corresponding videos that showcase these interactions. This paper introduces a novel depth-conditioning approach that significantly advances this field by enabling the generation of coherent and diverse videos from just a single text-video pair using a pre-trained depth-aware Text-to-Image (T2I) model. Our method fine-tunes the pre-trained model to capture continuous motion by employing custom-designed spatial and temporal attention mechanisms. During inference, we use the DDIM inversion to provide structural guidance for video generation. This innovative technique allows for continuously controllable depth in videos, facilitating the generation of multiobject interactions while maintaining the concept generation and compositional strengths of the original T2I model across various artistic styles, such as photorealism, animation, and impressionism.","sentences":["Creating editable videos that depict complex interactions between multiple objects in various artistic styles has long been a challenging task in filmmaking.","Progress is often hampered by the scarcity of data sets that contain paired text descriptions and corresponding videos that showcase these interactions.","This paper introduces a novel depth-conditioning approach that significantly advances this field by enabling the generation of coherent and diverse videos from just a single text-video pair using a pre-trained depth-aware Text-to-Image (T2I) model.","Our method fine-tunes the pre-trained model to capture continuous motion by employing custom-designed spatial and temporal attention mechanisms.","During inference, we use the DDIM inversion to provide structural guidance for video generation.","This innovative technique allows for continuously controllable depth in videos, facilitating the generation of multiobject interactions while maintaining the concept generation and compositional strengths of the original T2I model across various artistic styles, such as photorealism, animation, and impressionism."],"url":"http://arxiv.org/abs/2408.16704v1"}
{"created":"2024-08-29 16:56:40","title":"RoboMNIST: A Multimodal Dataset for Multi-Robot Activity Recognition Using WiFi Sensing, Video, and Audio","abstract":"We introduce a novel dataset for multi-robot activity recognition (MRAR) using two robotic arms integrating WiFi channel state information (CSI), video, and audio data. This multimodal dataset utilizes signals of opportunity, leveraging existing WiFi infrastructure to provide detailed indoor environmental sensing without additional sensor deployment. Data were collected using two Franka Emika robotic arms, complemented by three cameras, three WiFi sniffers to collect CSI, and three microphones capturing distinct yet complementary audio data streams. The combination of CSI, visual, and auditory data can enhance robustness and accuracy in MRAR. This comprehensive dataset enables a holistic understanding of robotic environments, facilitating advanced autonomous operations that mimic human-like perception and interaction. By repurposing ubiquitous WiFi signals for environmental sensing, this dataset offers significant potential aiming to advance robotic perception and autonomous systems. It provides a valuable resource for developing sophisticated decision-making and adaptive capabilities in dynamic environments.","sentences":["We introduce a novel dataset for multi-robot activity recognition (MRAR) using two robotic arms integrating WiFi channel state information (CSI), video, and audio data.","This multimodal dataset utilizes signals of opportunity, leveraging existing WiFi infrastructure to provide detailed indoor environmental sensing without additional sensor deployment.","Data were collected using two Franka Emika robotic arms, complemented by three cameras, three WiFi sniffers to collect CSI, and three microphones capturing distinct yet complementary audio data streams.","The combination of CSI, visual, and auditory data can enhance robustness and accuracy in MRAR.","This comprehensive dataset enables a holistic understanding of robotic environments, facilitating advanced autonomous operations that mimic human-like perception and interaction.","By repurposing ubiquitous WiFi signals for environmental sensing, this dataset offers significant potential aiming to advance robotic perception and autonomous systems.","It provides a valuable resource for developing sophisticated decision-making and adaptive capabilities in dynamic environments."],"url":"http://arxiv.org/abs/2408.16703v1"}
{"created":"2024-08-29 16:56:35","title":"VMC: A Grammar for Visualizing Statistical Model Checks","abstract":"Visualizations play a critical role in validating and improving statistical models. However, the design space of model check visualizations is not well understood, making it difficult for authors to explore and specify effective graphical model checks. VMC defines a model check visualization using four components: (1) samples of distributions of checkable quantities generated from the model, including predictive distributions for new data and distributions of model parameters; (2) transformations on observed data to facilitate comparison; (3) visual representations of distributions; and (4) layouts to facilitate comparing model samples and observed data. We contribute an implementation of VMC as an R package. We validate VMC by reproducing a set of canonical model check examples, and show how using VMC to generate model checks reduces the edit distance between visualizations relative to existing visualization toolkits. The findings of an interview study with three expert modelers who used VMC highlight challenges and opportunities for encouraging exploration of correct, effective model check visualizations.","sentences":["Visualizations play a critical role in validating and improving statistical models.","However, the design space of model check visualizations is not well understood, making it difficult for authors to explore and specify effective graphical model checks.","VMC defines a model check visualization using four components: (1) samples of distributions of checkable quantities generated from the model, including predictive distributions for new data and distributions of model parameters; (2) transformations on observed data to facilitate comparison; (3) visual representations of distributions; and (4) layouts to facilitate comparing model samples and observed data.","We contribute an implementation of VMC as an R package.","We validate VMC by reproducing a set of canonical model check examples, and show how using VMC to generate model checks reduces the edit distance between visualizations relative to existing visualization toolkits.","The findings of an interview study with three expert modelers who used VMC highlight challenges and opportunities for encouraging exploration of correct, effective model check visualizations."],"url":"http://arxiv.org/abs/2408.16702v1"}
{"created":"2024-08-29 16:40:29","title":"Fast and Simple $(1+\u03b5)\u0394$-Edge-Coloring of Dense Graphs","abstract":"Let $\\epsilon \\in (0, 1)$ and $n, \\Delta \\in \\mathbb N$ be such that $\\Delta = \\Omega\\left(\\max\\left\\{\\frac{\\log n}{\\epsilon},\\, \\left(\\frac{1}{\\epsilon}\\log \\frac{1}{\\epsilon}\\right)^2\\right\\}\\right)$. Given an $n$-vertex $m$-edge simple graph $G$ of maximum degree $\\Delta$, we present a randomized $O\\left(m\\,\\log^3 \\Delta\\,/\\,\\epsilon^2\\right)$-time algorithm that computes a proper $(1+\\epsilon)\\Delta$-edge-coloring of $G$ with high probability. This improves upon the best known results for a wide range of the parameters $\\epsilon$, $n$, and $\\Delta$. Our approach combines a flagging strategy from earlier work of the author with a shifting procedure employed by Duan, He, and Zhang for dynamic edge-coloring. The resulting algorithm is simple to implement and may be of practical interest.","sentences":["Let $\\epsilon \\in (0, 1)$ and $n, \\Delta \\in \\mathbb N$ be such that $\\Delta = \\Omega\\left(\\max\\left\\{\\frac{\\log n}{\\epsilon},\\, \\left(\\frac{1}{\\epsilon}\\log \\frac{1}{\\epsilon}\\right)^2\\right\\}\\right)$. Given an $n$-vertex $m$-edge simple graph $G$ of maximum degree $\\Delta$, we present a randomized $O\\left(m\\,\\log^3 \\Delta\\,/\\,\\epsilon^2\\right)$-time algorithm that computes a proper $(1+\\epsilon)\\Delta$-edge-coloring of $G$ with high probability.","This improves upon the best known results for a wide range of the parameters $\\epsilon$, $n$, and $\\Delta$. Our approach combines a flagging strategy from earlier work of the author with a shifting procedure employed by Duan, He, and Zhang for dynamic edge-coloring.","The resulting algorithm is simple to implement and may be of practical interest."],"url":"http://arxiv.org/abs/2408.16692v1"}
{"created":"2024-08-29 16:32:24","title":"CW-CNN & CW-AN: Convolutional Networks and Attention Networks for CW-Complexes","abstract":"We present a novel framework for learning on CW-complex structured data points. Recent advances have discussed CW-complexes as ideal learning representations for problems in cheminformatics. However, there is a lack of available machine learning methods suitable for learning on CW-complexes. In this paper we develop notions of convolution and attention that are well defined for CW-complexes. These notions enable us to create the first neural network that can receive a CW-complex as input. We illustrate and interpret this framework in the context of supervised prediction.","sentences":["We present a novel framework for learning on CW-complex structured data points.","Recent advances have discussed CW-complexes as ideal learning representations for problems in cheminformatics.","However, there is a lack of available machine learning methods suitable for learning on CW-complexes.","In this paper we develop notions of convolution and attention that are well defined for CW-complexes.","These notions enable us to create the first neural network that can receive a CW-complex as input.","We illustrate and interpret this framework in the context of supervised prediction."],"url":"http://arxiv.org/abs/2408.16686v1"}
{"created":"2024-08-29 16:31:05","title":"PartFormer: Awakening Latent Diverse Representation from Vision Transformer for Object Re-Identification","abstract":"Extracting robust feature representation is critical for object re-identification to accurately identify objects across non-overlapping cameras. Although having a strong representation ability, the Vision Transformer (ViT) tends to overfit on most distinct regions of training data, limiting its generalizability and attention to holistic object features. Meanwhile, due to the structural difference between CNN and ViT, fine-grained strategies that effectively address this issue in CNN do not continue to be successful in ViT. To address this issue, by observing the latent diverse representation hidden behind the multi-head attention, we present PartFormer, an innovative adaptation of ViT designed to overcome the granularity limitations in object Re-ID tasks. The PartFormer integrates a Head Disentangling Block (HDB) that awakens the diverse representation of multi-head self-attention without the typical loss of feature richness induced by concatenation and FFN layers post-attention. To avoid the homogenization of attention heads and promote robust part-based feature learning, two head diversity constraints are imposed: attention diversity constraint and correlation diversity constraint. These constraints enable the model to exploit diverse and discriminative feature representations from different attention heads. Comprehensive experiments on various object Re-ID benchmarks demonstrate the superiority of the PartFormer. Specifically, our framework significantly outperforms state-of-the-art by 2.4\\% mAP scores on the most challenging MSMT17 dataset.","sentences":["Extracting robust feature representation is critical for object re-identification to accurately identify objects across non-overlapping cameras.","Although having a strong representation ability, the Vision Transformer (ViT) tends to overfit on most distinct regions of training data, limiting its generalizability and attention to holistic object features.","Meanwhile, due to the structural difference between CNN and ViT, fine-grained strategies that effectively address this issue in CNN do not continue to be successful in ViT. To address this issue, by observing the latent diverse representation hidden behind the multi-head attention, we present PartFormer, an innovative adaptation of ViT designed to overcome the granularity limitations in object Re-ID tasks.","The PartFormer integrates a Head Disentangling Block (HDB) that awakens the diverse representation of multi-head self-attention without the typical loss of feature richness induced by concatenation and FFN layers post-attention.","To avoid the homogenization of attention heads and promote robust part-based feature learning, two head diversity constraints are imposed: attention diversity constraint and correlation diversity constraint.","These constraints enable the model to exploit diverse and discriminative feature representations from different attention heads.","Comprehensive experiments on various object Re-ID benchmarks demonstrate the superiority of the PartFormer.","Specifically, our framework significantly outperforms state-of-the-art by 2.4\\% mAP scores on the most challenging MSMT17 dataset."],"url":"http://arxiv.org/abs/2408.16684v1"}
{"created":"2024-08-29 16:21:00","title":"Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever","abstract":"Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval. ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search. In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data. Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models.","sentences":["Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval.","ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search.","In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data.","Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models."],"url":"http://arxiv.org/abs/2408.16672v1"}
{"created":"2024-08-29 16:21:00","title":"Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity","abstract":"Large language models rely on Supervised Fine-Tuning (SFT) to specialize in downstream tasks. Cross Entropy (CE) loss is the de facto choice in SFT, but it often leads to overfitting and limited output diversity due to its aggressive updates to the data distribution. This paper aim to address these issues by introducing the maximum entropy principle, which favors models with flatter distributions that still effectively capture the data. Specifically, we develop a new distribution matching method called GEM, which solves reverse Kullback-Leibler divergence minimization with an entropy regularizer.   For the SFT of Llama-3-8B models, GEM outperforms CE in several aspects. First, when applied to the UltraFeedback dataset to develop general instruction-following abilities, GEM exhibits reduced overfitting, evidenced by lower perplexity and better performance on the IFEval benchmark. Furthermore, GEM enhances output diversity, leading to performance gains of up to 7 points on math reasoning and code generation tasks using best-of-n sampling, even without domain-specific data. Second, when fine-tuning with domain-specific datasets for math reasoning and code generation, GEM also shows less overfitting and improvements of up to 10 points compared with CE.","sentences":["Large language models rely on Supervised Fine-Tuning (SFT) to specialize in downstream tasks.","Cross Entropy (CE) loss is the de facto choice in SFT, but it often leads to overfitting and limited output diversity due to its aggressive updates to the data distribution.","This paper aim to address these issues by introducing the maximum entropy principle, which favors models with flatter distributions that still effectively capture the data.","Specifically, we develop a new distribution matching method called GEM, which solves reverse Kullback-Leibler divergence minimization with an entropy regularizer.   ","For the SFT of Llama-3-8B models, GEM outperforms CE in several aspects.","First, when applied to the UltraFeedback dataset to develop general instruction-following abilities, GEM exhibits reduced overfitting, evidenced by lower perplexity and better performance on the IFEval benchmark.","Furthermore, GEM enhances output diversity, leading to performance gains of up to 7 points on math reasoning and code generation tasks using best-of-n sampling, even without domain-specific data.","Second, when fine-tuning with domain-specific datasets for math reasoning and code generation, GEM also shows less overfitting and improvements of up to 10 points compared with CE."],"url":"http://arxiv.org/abs/2408.16673v1"}
{"created":"2024-08-29 16:15:01","title":"Iterative Graph Alignment","abstract":"By compressing diverse narratives, LLMs go beyond memorization, achieving intelligence by capturing generalizable causal relationships. However, they suffer from local 'representation gaps' due to insufficient training data diversity, limiting their real-world utility, especially in tasks requiring strict alignment to rules. Traditional alignment methods relying on heavy human annotations are inefficient and unscalable. Recent self-alignment techniques also fall short, as they often depend on self-selection based prompting and memorization-based learning. To address these issues, we introduce Iterative Graph Alignment (IGA), an annotation-free rule-based alignment algorithm. A teacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical graphs and reference answers. The student model (LLM) identifies local knowledge gaps by attempting to align its responses with these references, collaborating with helper models to generate diverse answers. These aligned responses are then used for iterative supervised fine-tuning (SFT). Our evaluations across five rule-based scenarios demonstrate IGP's effectiveness, with a 73.12\\% alignment improvement in Claude Sonnet 3.5, and Llama3-8B-Instruct achieving an 86.20\\% improvement, outperforming Claude Sonnet 3.5 in rule-based alignment.","sentences":["By compressing diverse narratives, LLMs go beyond memorization, achieving intelligence by capturing generalizable causal relationships.","However, they suffer from local 'representation gaps' due to insufficient training data diversity, limiting their real-world utility, especially in tasks requiring strict alignment to rules.","Traditional alignment methods relying on heavy human annotations are inefficient and unscalable.","Recent self-alignment techniques also fall short, as they often depend on self-selection based prompting and memorization-based learning.","To address these issues, we introduce Iterative Graph Alignment (IGA), an annotation-free rule-based alignment algorithm.","A teacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical graphs and reference answers.","The student model (LLM) identifies local knowledge gaps by attempting to align its responses with these references, collaborating with helper models to generate diverse answers.","These aligned responses are then used for iterative supervised fine-tuning (SFT).","Our evaluations across five rule-based scenarios demonstrate IGP's effectiveness, with a 73.12\\% alignment improvement in Claude Sonnet 3.5, and Llama3-8B-Instruct achieving an 86.20\\% improvement, outperforming Claude Sonnet 3.5 in rule-based alignment."],"url":"http://arxiv.org/abs/2408.16667v1"}
{"created":"2024-08-29 16:05:22","title":"Space3D-Bench: Spatial 3D Question Answering Benchmark","abstract":"Answering questions about the spatial properties of the environment poses challenges for existing language and vision foundation models due to a lack of understanding of the 3D world notably in terms of relationships between objects. To push the field forward, multiple 3D Q&A datasets were proposed which, overall, provide a variety of questions, but they individually focus on particular aspects of 3D reasoning or are limited in terms of data modalities. To address this, we present Space3D-Bench - a collection of 1000 general spatial questions and answers related to scenes of the Replica dataset which offers a variety of data modalities: point clouds, posed RGB-D images, navigation meshes and 3D object detections. To ensure that the questions cover a wide range of 3D objectives, we propose an indoor spatial questions taxonomy inspired by geographic information systems and use it to balance the dataset accordingly. Moreover, we provide an assessment system that grades natural language responses based on predefined ground-truth answers by leveraging a Vision Language Model's comprehension of both text and images to compare the responses with ground-truth textual information or relevant visual data. Finally, we introduce a baseline called RAG3D-Chat integrating the world understanding of foundation models with rich context retrieval, achieving an accuracy of 67% on the proposed dataset.","sentences":["Answering questions about the spatial properties of the environment poses challenges for existing language and vision foundation models due to a lack of understanding of the 3D world notably in terms of relationships between objects.","To push the field forward, multiple 3D Q&A datasets were proposed which, overall, provide a variety of questions, but they individually focus on particular aspects of 3D reasoning or are limited in terms of data modalities.","To address this, we present Space3D-Bench - a collection of 1000 general spatial questions and answers related to scenes of the Replica dataset which offers a variety of data modalities: point clouds, posed RGB-D images, navigation meshes and 3D object detections.","To ensure that the questions cover a wide range of 3D objectives, we propose an indoor spatial questions taxonomy inspired by geographic information systems and use it to balance the dataset accordingly.","Moreover, we provide an assessment system that grades natural language responses based on predefined ground-truth answers by leveraging a Vision Language Model's comprehension of both text and images to compare the responses with ground-truth textual information or relevant visual data.","Finally, we introduce a baseline called RAG3D-Chat integrating the world understanding of foundation models with rich context retrieval, achieving an accuracy of 67% on the proposed dataset."],"url":"http://arxiv.org/abs/2408.16662v1"}
{"created":"2024-08-29 16:05:05","title":"Eigen-Cluster VIS: Improving Weakly-supervised Video Instance Segmentation by Leveraging Spatio-temporal Consistency","abstract":"The performance of Video Instance Segmentation (VIS) methods has improved significantly with the advent of transformer networks. However, these networks often face challenges in training due to the high annotation cost. To address this, unsupervised and weakly-supervised methods have been developed to reduce the dependency on annotations. This work introduces a novel weakly-supervised method called Eigen-cluster VIS that, without requiring any mask annotations, achieves competitive accuracy compared to other VIS approaches. This method is based on two key innovations: a Temporal Eigenvalue Loss (TEL) and a clip-level Quality Cluster Coefficient (QCC). The TEL ensures temporal coherence by leveraging the eigenvalues of the Laplacian matrix derived from graph adjacency matrices. By minimizing the mean absolute error (MAE) between the eigenvalues of adjacent frames, this loss function promotes smooth transitions and stable segmentation boundaries over time, reducing temporal discontinuities and improving overall segmentation quality. The QCC employs the K-means method to ensure the quality of spatio-temporal clusters without relying on ground truth masks. Using the Davies-Bouldin score, the QCC provides an unsupervised measure of feature discrimination, allowing the model to self-evaluate and adapt to varying object distributions, enhancing robustness during the testing phase. These enhancements are computationally efficient and straightforward, offering significant performance gains without additional annotated data. The proposed Eigen-Cluster VIS method is evaluated on the YouTube-VIS 2019/2021 and OVIS datasets, demonstrating that it effectively narrows the performance gap between the fully-supervised and weakly-supervised VIS approaches. The code is available on: https://github.com/farnooshar/EigenClusterVIS","sentences":["The performance of Video Instance Segmentation (VIS) methods has improved significantly with the advent of transformer networks.","However, these networks often face challenges in training due to the high annotation cost.","To address this, unsupervised and weakly-supervised methods have been developed to reduce the dependency on annotations.","This work introduces a novel weakly-supervised method called Eigen-cluster VIS that, without requiring any mask annotations, achieves competitive accuracy compared to other VIS approaches.","This method is based on two key innovations: a Temporal Eigenvalue Loss (TEL) and a clip-level Quality Cluster Coefficient (QCC).","The TEL ensures temporal coherence by leveraging the eigenvalues of the Laplacian matrix derived from graph adjacency matrices.","By minimizing the mean absolute error (MAE) between the eigenvalues of adjacent frames, this loss function promotes smooth transitions and stable segmentation boundaries over time, reducing temporal discontinuities and improving overall segmentation quality.","The QCC employs the K-means method to ensure the quality of spatio-temporal clusters without relying on ground truth masks.","Using the Davies-Bouldin score, the QCC provides an unsupervised measure of feature discrimination, allowing the model to self-evaluate and adapt to varying object distributions, enhancing robustness during the testing phase.","These enhancements are computationally efficient and straightforward, offering significant performance gains without additional annotated data.","The proposed Eigen-Cluster VIS method is evaluated on the YouTube-VIS 2019/2021 and OVIS datasets, demonstrating that it effectively narrows the performance gap between the fully-supervised and weakly-supervised VIS approaches.","The code is available on: https://github.com/farnooshar/EigenClusterVIS"],"url":"http://arxiv.org/abs/2408.16661v1"}
{"created":"2024-08-29 15:42:06","title":"3D Pose-Based Temporal Action Segmentation for Figure Skating: A Fine-Grained and Jump Procedure-Aware Annotation Approach","abstract":"Understanding human actions from videos is essential in many domains, including sports. In figure skating, technical judgments are performed by watching skaters' 3D movements, and its part of the judging procedure can be regarded as a Temporal Action Segmentation (TAS) task. TAS tasks in figure skating that automatically assign temporal semantics to video are actively researched. However, there is a lack of datasets and effective methods for TAS tasks requiring 3D pose data. In this study, we first created the FS-Jump3D dataset of complex and dynamic figure skating jumps using optical markerless motion capture. We also propose a new fine-grained figure skating jump TAS dataset annotation method with which TAS models can learn jump procedures. In the experimental results, we validated the usefulness of 3D pose features as input and the fine-grained dataset for the TAS model in figure skating. FS-Jump3D Dataset is available at https://github.com/ryota-skating/FS-Jump3D.","sentences":["Understanding human actions from videos is essential in many domains, including sports.","In figure skating, technical judgments are performed by watching skaters' 3D movements, and its part of the judging procedure can be regarded as a Temporal Action Segmentation (TAS) task.","TAS tasks in figure skating that automatically assign temporal semantics to video are actively researched.","However, there is a lack of datasets and effective methods for TAS tasks requiring 3D pose data.","In this study, we first created the FS-Jump3D dataset of complex and dynamic figure skating jumps using optical markerless motion capture.","We also propose a new fine-grained figure skating jump TAS dataset annotation method with which TAS models can learn jump procedures.","In the experimental results, we validated the usefulness of 3D pose features as input and the fine-grained dataset for the TAS model in figure skating.","FS-Jump3D Dataset is available at https://github.com/ryota-skating/FS-Jump3D."],"url":"http://arxiv.org/abs/2408.16638v1"}
{"created":"2024-08-29 15:39:04","title":"Maelstrom Networks","abstract":"Artificial Neural Networks has struggled to devise a way to incorporate working memory into neural networks. While the ``long term'' memory can be seen as the learned weights, the working memory consists likely more of dynamical activity, that is missing from feed-forward models. Current state of the art models such as transformers tend to ``solve'' this by ignoring working memory entirely and simply process the sequence as an entire piece of data; however this means the network cannot process the sequence in an online fashion, and leads to an immense explosion in memory requirements. Here, inspired by a combination of controls, reservoir computing, deep learning, and recurrent neural networks, we offer an alternative paradigm that combines the strength of recurrent networks, with the pattern matching capability of feed-forward neural networks, which we call the \\textit{Maelstrom Networks} paradigm. This paradigm leaves the recurrent component - the \\textit{Maelstrom} - unlearned, and offloads the learning to a powerful feed-forward network. This allows the network to leverage the strength of feed-forward training without unrolling the network, and allows for the memory to be implemented in new neuromorphic hardware. It endows a neural network with a sequential memory that takes advantage of the inductive bias that data is organized causally in the temporal domain, and imbues the network with a state that represents the agent's ``self'', moving through the environment. This could also lead the way to continual learning, with the network modularized and ``'protected'' from overwrites that come with new data. In addition to aiding in solving these performance problems that plague current non-temporal deep networks, this also could finally lead towards endowing artificial networks with a sense of ``self''.","sentences":["Artificial Neural Networks has struggled to devise a way to incorporate working memory into neural networks.","While the ``long term'' memory can be seen as the learned weights, the working memory consists likely more of dynamical activity, that is missing from feed-forward models.","Current state of the art models such as transformers tend to ``solve'' this by ignoring working memory entirely and simply process the sequence as an entire piece of data; however this means the network cannot process the sequence in an online fashion, and leads to an immense explosion in memory requirements.","Here, inspired by a combination of controls, reservoir computing, deep learning, and recurrent neural networks, we offer an alternative paradigm that combines the strength of recurrent networks, with the pattern matching capability of feed-forward neural networks, which we call the \\textit{Maelstrom Networks} paradigm.","This paradigm leaves the recurrent component - the \\textit{Maelstrom} - unlearned, and offloads the learning to a powerful feed-forward network.","This allows the network to leverage the strength of feed-forward training without unrolling the network, and allows for the memory to be implemented in new neuromorphic hardware.","It endows a neural network with a sequential memory that takes advantage of the inductive bias that data is organized causally in the temporal domain, and imbues the network with a state that represents the agent's ``self'', moving through the environment.","This could also lead the way to continual learning, with the network modularized and ``'protected'' from overwrites that come with new data.","In addition to aiding in solving these performance problems that plague current non-temporal deep networks, this also could finally lead towards endowing artificial networks with a sense of ``self''."],"url":"http://arxiv.org/abs/2408.16632v1"}
{"created":"2024-08-29 15:34:25","title":"MultiMediate'24: Multi-Domain Engagement Estimation","abstract":"Estimating the momentary level of participant's engagement is an important prerequisite for assistive systems that support human interactions. Previous work has addressed this task in within-domain evaluation scenarios, i.e. training and testing on the same dataset. This is in contrast to real-life scenarios where domain shifts between training and testing data frequently occur. With MultiMediate'24, we present the first challenge addressing multi-domain engagement estimation. As training data, we utilise the NOXI database of dyadic novice-expert interactions. In addition to within-domain test data, we add two new test domains. First, we introduce recordings following the NOXI protocol but covering languages that are not present in the NOXI training data. Second, we collected novel engagement annotations on the MPIIGroupInteraction dataset which consists of group discussions between three to four people. In this way, MultiMediate'24 evaluates the ability of approaches to generalise across factors such as language and cultural background, group size, task, and screen-mediated vs. face-to-face interaction. This paper describes the MultiMediate'24 challenge and presents baseline results. In addition, we discuss selected challenge solutions.","sentences":["Estimating the momentary level of participant's engagement is an important prerequisite for assistive systems that support human interactions.","Previous work has addressed this task in within-domain evaluation scenarios, i.e. training and testing on the same dataset.","This is in contrast to real-life scenarios where domain shifts between training and testing data frequently occur.","With MultiMediate'24, we present the first challenge addressing multi-domain engagement estimation.","As training data, we utilise the NOXI database of dyadic novice-expert interactions.","In addition to within-domain test data, we add two new test domains.","First, we introduce recordings following the NOXI protocol but covering languages that are not present in the NOXI training data.","Second, we collected novel engagement annotations on the MPIIGroupInteraction dataset which consists of group discussions between three to four people.","In this way, MultiMediate'24 evaluates the ability of approaches to generalise across factors such as language and cultural background, group size, task, and screen-mediated vs. face-to-face interaction.","This paper describes the MultiMediate'24 challenge and presents baseline results.","In addition, we discuss selected challenge solutions."],"url":"http://arxiv.org/abs/2408.16625v1"}
{"created":"2024-08-29 15:31:51","title":"Turbulence Strength $C_n^2$ Estimation from Video using Physics-based Deep Learning","abstract":"Images captured from a long distance suffer from dynamic image distortion due to turbulent flow of air cells with random temperatures, and thus refractive indices. This phenomenon, known as image dancing, is commonly characterized by its refractive-index structure constant $C_n^2$ as a measure of the turbulence strength. For many applications such as atmospheric forecast model, long-range/astronomy imaging, and aviation safety, optical communication technology, $C_n^2$ estimation is critical for accurately sensing the turbulent environment. Previous methods for $C_n^2$ estimation include estimation from meteorological data (temperature, relative humidity, wind shear, etc.) for single-point measurements, two-ended pathlength measurements from optical scintillometer for path-averaged $C_n^2$, and more recently estimating $C_n^2$ from passive video cameras for low cost and hardware complexity. In this paper, we present a comparative analysis of classical image gradient methods for $C_n^2$ estimation and modern deep learning-based methods leveraging convolutional neural networks. To enable this, we collect a dataset of video capture along with reference scintillometer measurements for ground truth, and we release this unique dataset to the scientific community. We observe that deep learning methods can achieve higher accuracy when trained on similar data, but suffer from generalization errors to other, unseen imagery as compared to classical methods. To overcome this trade-off, we present a novel physics-based network architecture that combines learned convolutional layers with a differentiable image gradient method that maintains high accuracy while being generalizable across image datasets.","sentences":["Images captured from a long distance suffer from dynamic image distortion due to turbulent flow of air cells with random temperatures, and thus refractive indices.","This phenomenon, known as image dancing, is commonly characterized by its refractive-index structure constant $C_n^2$ as a measure of the turbulence strength.","For many applications such as atmospheric forecast model, long-range/astronomy imaging, and aviation safety, optical communication technology, $C_n^2$ estimation is critical for accurately sensing the turbulent environment.","Previous methods for $C_n^2$ estimation include estimation from meteorological data (temperature, relative humidity, wind shear, etc.)","for single-point measurements, two-ended pathlength measurements from optical scintillometer for path-averaged $C_n^2$, and more recently estimating $C_n^2$ from passive video cameras for low cost and hardware complexity.","In this paper, we present a comparative analysis of classical image gradient methods for $C_n^2$ estimation and modern deep learning-based methods leveraging convolutional neural networks.","To enable this, we collect a dataset of video capture along with reference scintillometer measurements for ground truth, and we release this unique dataset to the scientific community.","We observe that deep learning methods can achieve higher accuracy when trained on similar data, but suffer from generalization errors to other, unseen imagery as compared to classical methods.","To overcome this trade-off, we present a novel physics-based network architecture that combines learned convolutional layers with a differentiable image gradient method that maintains high accuracy while being generalizable across image datasets."],"url":"http://arxiv.org/abs/2408.16623v1"}
{"created":"2024-08-29 15:28:01","title":"Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation","abstract":"We construct a two-layered model for learning and generating sequential data that is both computationally fast and competitive with vanilla Tsetlin machines, adding numerous advantages. Through the use of hyperdimensional vector computing (HVC) algebras and Tsetlin machine clause structures, we demonstrate that the combination of both inherits the generality of data encoding and decoding of HVC with the fast interpretable nature of Tsetlin machines to yield a powerful machine learning model. We apply the approach in two areas, namely in forecasting, generating new sequences, and classification. For the latter, we derive results for the entire UCR Time Series Archive and compare with the standard benchmarks to see how well the method competes in time series classification.","sentences":["We construct a two-layered model for learning and generating sequential data that is both computationally fast and competitive with vanilla Tsetlin machines, adding numerous advantages.","Through the use of hyperdimensional vector computing (HVC) algebras and Tsetlin machine clause structures, we demonstrate that the combination of both inherits the generality of data encoding and decoding of HVC with the fast interpretable nature of Tsetlin machines to yield a powerful machine learning model.","We apply the approach in two areas, namely in forecasting, generating new sequences, and classification.","For the latter, we derive results for the entire UCR Time Series Archive and compare with the standard benchmarks to see how well the method competes in time series classification."],"url":"http://arxiv.org/abs/2408.16620v1"}
{"created":"2024-08-29 15:19:06","title":"Data Quality Monitoring through Transfer Learning on Anomaly Detection for the Hadron Calorimeters","abstract":"The proliferation of sensors brings an immense volume of spatio-temporal (ST) data in many domains for various purposes, including monitoring, diagnostics, and prognostics applications. Data curation is a time-consuming process for a large volume of data, making it challenging and expensive to deploy data analytics platforms in new environments. Transfer learning (TL) mechanisms promise to mitigate data sparsity and model complexity by utilizing pre-trained models for a new task. Despite the triumph of TL in fields like computer vision and natural language processing, efforts on complex ST models for anomaly detection (AD) applications are limited. In this study, we present the potential of TL within the context of AD for the Hadron Calorimeter of the Compact Muon Solenoid experiment at CERN. We have transferred the ST AD models trained on data collected from one part of a calorimeter to another. We have investigated different configurations of TL on semi-supervised autoencoders of the ST AD models -- transferring convolutional, graph, and recurrent neural networks of both the encoder and decoder networks. The experiment results demonstrate that TL effectively enhances the model learning accuracy on a target subdetector. The TL achieves promising data reconstruction and AD performance while substantially reducing the trainable parameters of the AD models. It also improves robustness against anomaly contamination in the training data sets of the semi-supervised AD models.","sentences":["The proliferation of sensors brings an immense volume of spatio-temporal (ST) data in many domains for various purposes, including monitoring, diagnostics, and prognostics applications.","Data curation is a time-consuming process for a large volume of data, making it challenging and expensive to deploy data analytics platforms in new environments.","Transfer learning (TL) mechanisms promise to mitigate data sparsity and model complexity by utilizing pre-trained models for a new task.","Despite the triumph of TL in fields like computer vision and natural language processing, efforts on complex ST models for anomaly detection (AD) applications are limited.","In this study, we present the potential of TL within the context of AD for the Hadron Calorimeter of the Compact Muon Solenoid experiment at CERN.","We have transferred the ST AD models trained on data collected from one part of a calorimeter to another.","We have investigated different configurations of TL on semi-supervised autoencoders of the ST AD models -- transferring convolutional, graph, and recurrent neural networks of both the encoder and decoder networks.","The experiment results demonstrate that TL effectively enhances the model learning accuracy on a target subdetector.","The TL achieves promising data reconstruction and AD performance while substantially reducing the trainable parameters of the AD models.","It also improves robustness against anomaly contamination in the training data sets of the semi-supervised AD models."],"url":"http://arxiv.org/abs/2408.16612v1"}
{"created":"2024-08-29 15:09:04","title":"sEMG-Driven Physics-Informed Gated Recurrent Networks for Modeling Upper Limb Multi-Joint Movement Dynamics","abstract":"Exoskeletons and rehabilitation systems offer great potential for enhancing human strength and recovery through advanced human-machine interfaces (HMIs) that adapt to movement dynamics. However, the real-time application of physics-informed neural networks (PINNs) is limited by their reliance on fixed input lengths and surrogate models. This study introduces a novel physics-informed Gated Recurrent Network (PiGRN) designed to predict multi-joint torques using surface electromyography (sEMG) data. The PiGRN model employs a Gated Recurrent Unit (GRU) to convert time-series sEMG inputs into multi-joint kinematics and external loads, which are then integrated into an equation of motion to ensure consistency with physical laws. Experimental validation with sEMG data from five participants performing elbow flexion-extension tasks showed that the PiGRN model accurately predicted joint torques for 10 unfamiliar movements, with RMSE values between 4.02\\% and 11.40\\% and correlation coefficients ranging from 0.87 to 0.98. These findings highlight the PiGRN's potential for real-time exoskeleton and rehabilitation applications. Future research will explore more diverse datasets, improve musculoskeletal models, and investigate unsupervised learning methods.","sentences":["Exoskeletons and rehabilitation systems offer great potential for enhancing human strength and recovery through advanced human-machine interfaces (HMIs) that adapt to movement dynamics.","However, the real-time application of physics-informed neural networks (PINNs) is limited by their reliance on fixed input lengths and surrogate models.","This study introduces a novel physics-informed Gated Recurrent Network (PiGRN) designed to predict multi-joint torques using surface electromyography (sEMG) data.","The PiGRN model employs a Gated Recurrent Unit (GRU) to convert time-series sEMG inputs into multi-joint kinematics and external loads, which are then integrated into an equation of motion to ensure consistency with physical laws.","Experimental validation with sEMG data from five participants performing elbow flexion-extension tasks showed that the PiGRN model accurately predicted joint torques for 10 unfamiliar movements, with RMSE values between 4.02\\% and 11.40\\% and correlation coefficients ranging from 0.87 to 0.98.","These findings highlight the PiGRN's potential for real-time exoskeleton and rehabilitation applications.","Future research will explore more diverse datasets, improve musculoskeletal models, and investigate unsupervised learning methods."],"url":"http://arxiv.org/abs/2408.16599v1"}
{"created":"2024-08-29 14:55:33","title":"High-Dimensional Sparse Data Low-rank Representation via Accelerated Asynchronous Parallel Stochastic Gradient Descent","abstract":"Data characterized by high dimensionality and sparsity are commonly used to describe real-world node interactions. Low-rank representation (LR) can map high-dimensional sparse (HDS) data to low-dimensional feature spaces and infer node interactions via modeling data latent associations. Unfortunately, existing optimization algorithms for LR models are computationally inefficient and slowly convergent on large-scale datasets. To address this issue, this paper proposes an Accelerated Asynchronous Parallel Stochastic Gradient Descent A2PSGD for High-Dimensional Sparse Data Low-rank Representation with three fold-ideas: a) establishing a lock-free scheduler to simultaneously respond to scheduling requests from multiple threads; b) introducing a greedy algorithm-based load balancing strategy for balancing the computational load among threads; c) incorporating Nesterov's accelerated gradient into the learning scheme to accelerate model convergence. Empirical studies show that A2PSGD outperforms existing optimization algorithms for HDS data LR in both accuracy and training time.","sentences":["Data characterized by high dimensionality and sparsity are commonly used to describe real-world node interactions.","Low-rank representation (LR) can map high-dimensional sparse (HDS) data to low-dimensional feature spaces and infer node interactions via modeling data latent associations.","Unfortunately, existing optimization algorithms for LR models are computationally inefficient and slowly convergent on large-scale datasets.","To address this issue, this paper proposes an Accelerated Asynchronous Parallel Stochastic Gradient Descent A2PSGD for High-Dimensional Sparse Data Low-rank Representation with three fold-ideas: a) establishing a lock-free scheduler to simultaneously respond to scheduling requests from multiple threads; b) introducing a greedy algorithm-based load balancing strategy for balancing the computational load among threads; c) incorporating Nesterov's accelerated gradient into the learning scheme to accelerate model convergence.","Empirical studies show that A2PSGD outperforms existing optimization algorithms for HDS data LR in both accuracy and training time."],"url":"http://arxiv.org/abs/2408.16592v1"}
{"created":"2024-08-29 14:44:12","title":"Transformers Meet ACT-R: Repeat-Aware and Sequential Listening Session Recommendation","abstract":"Music streaming services often leverage sequential recommender systems to predict the best music to showcase to users based on past sequences of listening sessions. Nonetheless, most sequential recommendation methods ignore or insufficiently account for repetitive behaviors. This is a crucial limitation for music recommendation, as repeatedly listening to the same song over time is a common phenomenon that can even change the way users perceive this song. In this paper, we introduce PISA (Psychology-Informed Session embedding using ACT-R), a session-level sequential recommender system that overcomes this limitation. PISA employs a Transformer architecture learning embedding representations of listening sessions and users using attention mechanisms inspired by Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics. This approach enables us to capture dynamic and repetitive patterns from user behaviors, allowing us to effectively predict the songs they will listen to in subsequent sessions, whether they are repeated or new ones. We demonstrate the empirical relevance of PISA using both publicly available listening data from Last.fm and proprietary data from Deezer, a global music streaming service, confirming the critical importance of repetition modeling for sequential listening session recommendation. Along with this paper, we publicly release our proprietary dataset to foster future research in this field, as well as the source code of PISA to facilitate its future use.","sentences":["Music streaming services often leverage sequential recommender systems to predict the best music to showcase to users based on past sequences of listening sessions.","Nonetheless, most sequential recommendation methods ignore or insufficiently account for repetitive behaviors.","This is a crucial limitation for music recommendation, as repeatedly listening to the same song over time is a common phenomenon that can even change the way users perceive this song.","In this paper, we introduce PISA (Psychology-Informed Session embedding using ACT-R), a session-level sequential recommender system that overcomes this limitation.","PISA employs a Transformer architecture learning embedding representations of listening sessions and users using attention mechanisms inspired by Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics.","This approach enables us to capture dynamic and repetitive patterns from user behaviors, allowing us to effectively predict the songs they will listen to in subsequent sessions, whether they are repeated or new ones.","We demonstrate the empirical relevance of PISA using both publicly available listening data from Last.fm and proprietary data from Deezer, a global music streaming service, confirming the critical importance of repetition modeling for sequential listening session recommendation.","Along with this paper, we publicly release our proprietary dataset to foster future research in this field, as well as the source code of PISA to facilitate its future use."],"url":"http://arxiv.org/abs/2408.16578v1"}
{"created":"2024-08-29 14:43:42","title":"Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning","abstract":"Learning representations with a high Probability of Necessary and Sufficient Causes (PNS) has been shown to enhance deep learning models' ability. This task involves identifying causal features that are both sufficient (guaranteeing the outcome) and necessary (without which the outcome cannot occur). However, current research predominantly focuses on unimodal data, and extending PNS learning to multimodal settings presents significant challenges. The challenges arise as the conditions for PNS identifiability, Exogeneity and Monotonicity, need to be reconsidered in a multimodal context, where sufficient and necessary causal features are distributed across different modalities. To address this, we first propose conceptualizing multimodal representations as comprising modality-invariant and modality-specific components. We then analyze PNS identifiability for each component, while ensuring non-trivial PNS estimation. Finally, we formulate tractable optimization objectives that enable multimodal models to learn high-PNS representations, thereby enhancing their predictive performance. Experiments demonstrate the effectiveness of our method on both synthetic and real-world data.","sentences":["Learning representations with a high Probability of Necessary and Sufficient Causes (PNS) has been shown to enhance deep learning models' ability.","This task involves identifying causal features that are both sufficient (guaranteeing the outcome) and necessary (without which the outcome cannot occur).","However, current research predominantly focuses on unimodal data, and extending PNS learning to multimodal settings presents significant challenges.","The challenges arise as the conditions for PNS identifiability, Exogeneity and Monotonicity, need to be reconsidered in a multimodal context, where sufficient and necessary causal features are distributed across different modalities.","To address this, we first propose conceptualizing multimodal representations as comprising modality-invariant and modality-specific components.","We then analyze PNS identifiability for each component, while ensuring non-trivial PNS estimation.","Finally, we formulate tractable optimization objectives that enable multimodal models to learn high-PNS representations, thereby enhancing their predictive performance.","Experiments demonstrate the effectiveness of our method on both synthetic and real-world data."],"url":"http://arxiv.org/abs/2408.16577v1"}
{"created":"2024-08-29 14:40:32","title":"An Adaptive Latent Factorization of Tensors Model for Embedding Dynamic Communication Network","abstract":"The Dynamic Communication Network (DCN) describes the interactions over time among various communication nodes, and it is widely used in Big-data applications as a data source. As the number of communication nodes increases and temporal slots accumulate, each node interacts in with only a few nodes in a given temporal slot, the DCN can be represented by an High-Dimensional Sparse (HDS) tensor. In order to extract rich behavioral patterns from an HDS tensor in DCN, this paper proposes an Adaptive Temporal-dependent Tensor low-rank representation (ATT) model. It adopts a three-fold approach: a) designing a temporal-dependent method to reconstruct temporal feature matrix, thereby precisely represent the data by capturing the temporal patterns; b) achieving hyper-parameters adaptation of the model via the Differential Evolutionary Algorithms (DEA) to avoid tedious hyper-parameters tuning; c) employing nonnegative learning schemes for the model parameters to effectively handle an the nonnegativity inherent in HDS data. The experimental results on four real-world DCNs demonstrate that the proposed ATT model significantly outperforms several state-of-the-art models in both prediction errors and convergence rounds.","sentences":["The Dynamic Communication Network (DCN) describes the interactions over time among various communication nodes, and it is widely used in Big-data applications as a data source.","As the number of communication nodes increases and temporal slots accumulate, each node interacts in with only a few nodes in a given temporal slot, the DCN can be represented by an High-Dimensional Sparse (HDS) tensor.","In order to extract rich behavioral patterns from an HDS tensor in DCN, this paper proposes an Adaptive Temporal-dependent Tensor low-rank representation (ATT) model.","It adopts a three-fold approach: a) designing a temporal-dependent method to reconstruct temporal feature matrix, thereby precisely represent the data by capturing the temporal patterns; b) achieving hyper-parameters adaptation of the model via the Differential Evolutionary Algorithms (DEA) to avoid tedious hyper-parameters tuning; c) employing nonnegative learning schemes for the model parameters to effectively handle an the nonnegativity inherent in HDS data.","The experimental results on four real-world DCNs demonstrate that the proposed ATT model significantly outperforms several state-of-the-art models in both prediction errors and convergence rounds."],"url":"http://arxiv.org/abs/2408.16573v1"}
{"created":"2024-08-29 14:35:14","title":"Identifying Terrain Physical Parameters from Vision -- Towards Physical-Parameter-Aware Locomotion and Navigation","abstract":"Identifying the physical properties of the surrounding environment is essential for robotic locomotion and navigation to deal with non-geometric hazards, such as slippery and deformable terrains. It would be of great benefit for robots to anticipate these extreme physical properties before contact; however, estimating environmental physical parameters from vision is still an open challenge. Animals can achieve this by using their prior experience and knowledge of what they have seen and how it felt. In this work, we propose a cross-modal self-supervised learning framework for vision-based environmental physical parameter estimation, which paves the way for future physical-property-aware locomotion and navigation. We bridge the gap between existing policies trained in simulation and identification of physical terrain parameters from vision. We propose to train a physical decoder in simulation to predict friction and stiffness from multi-modal input. The trained network allows the labeling of real-world images with physical parameters in a self-supervised manner to further train a visual network during deployment, which can densely predict the friction and stiffness from image data. We validate our physical decoder in simulation and the real world using a quadruped ANYmal robot, outperforming an existing baseline method. We show that our visual network can predict the physical properties in indoor and outdoor experiments while allowing fast adaptation to new environments.","sentences":["Identifying the physical properties of the surrounding environment is essential for robotic locomotion and navigation to deal with non-geometric hazards, such as slippery and deformable terrains.","It would be of great benefit for robots to anticipate these extreme physical properties before contact; however, estimating environmental physical parameters from vision is still an open challenge.","Animals can achieve this by using their prior experience and knowledge of what they have seen and how it felt.","In this work, we propose a cross-modal self-supervised learning framework for vision-based environmental physical parameter estimation, which paves the way for future physical-property-aware locomotion and navigation.","We bridge the gap between existing policies trained in simulation and identification of physical terrain parameters from vision.","We propose to train a physical decoder in simulation to predict friction and stiffness from multi-modal input.","The trained network allows the labeling of real-world images with physical parameters in a self-supervised manner to further train a visual network during deployment, which can densely predict the friction and stiffness from image data.","We validate our physical decoder in simulation and the real world using a quadruped ANYmal robot, outperforming an existing baseline method.","We show that our visual network can predict the physical properties in indoor and outdoor experiments while allowing fast adaptation to new environments."],"url":"http://arxiv.org/abs/2408.16567v1"}
{"created":"2024-08-29 14:34:46","title":"Approximation Algorithms for Correlated Knapsack Orienteering","abstract":"We consider the {\\em correlated knapsack orienteering} (CSKO) problem: we are given a travel budget $B$, processing-time budget $W$, finite metric space $(V,d)$ with root $\\rho\\in V$, where each vertex is associated with a job with possibly correlated random size and random reward that become known only when the job completes. Random variables are independent across different vertices. The goal is to compute a $\\rho$-rooted path of length at most $B$, in a possibly adaptive fashion, that maximizes the reward collected from jobs that processed by time $W$. To our knowledge, CSKO has not been considered before, though prior work has considered the uncorrelated problem, {\\em stochastic knapsack orienteering}, and {\\em correlated orienteering}, which features only one budget constraint on the {\\em sum} of travel-time and processing-times.   We show that the {\\em adaptivity gap of CSKO is not a constant, and is at least $\\Omega\\bigl(\\max\\sqrt{\\log{B}},\\sqrt{\\log\\log{W}}\\}\\bigr)$}. Complementing this, we devise {\\em non-adaptive} algorithms that obtain: (a) $O(\\log\\log W)$-approximation in quasi-polytime; and (b) $O(\\log W)$-approximation in polytime. We obtain similar guarantees for CSKO with cancellations, wherein a job can be cancelled before its completion time, foregoing its reward. We also consider the special case of CSKO, wherein job sizes are weighted Bernoulli distributions, and more generally where the distributions are supported on at most two points (2-CSKO). Although weighted Bernoulli distributions suffice to yield an $\\Omega(\\sqrt{\\log\\log B})$ adaptivity-gap lower bound for (uncorrelated) {\\em stochastic orienteering}, we show that they are easy instances for CSKO. We develop non-adaptive algorithms that achieve $O(1)$-approximation in polytime for weighted Bernoulli distributions, and in $(n+\\log B)^{O(\\log W)}$-time for the more general case of 2-CSKO.","sentences":["We consider the {\\em correlated knapsack orienteering} (CSKO) problem: we are given a travel budget $B$, processing-time budget $W$, finite metric space $(V,d)$ with root $\\rho\\in V$, where each vertex is associated with a job with possibly correlated random size and random reward that become known only when the job completes.","Random variables are independent across different vertices.","The goal is to compute a $\\rho$-rooted path of length at most $B$, in a possibly adaptive fashion, that maximizes the reward collected from jobs that processed by time $W$. To our knowledge, CSKO has not been considered before, though prior work has considered the uncorrelated problem, {\\em stochastic knapsack orienteering}, and {\\em correlated orienteering}, which features only one budget constraint on the {\\em sum} of travel-time and processing-times.   ","We show that the {\\em adaptivity gap of CSKO is not a constant, and is at least $\\Omega\\bigl(\\max\\sqrt{\\log{B}},\\sqrt{\\log\\log{W}}\\}\\bigr)$}.","Complementing this, we devise {\\em non-adaptive} algorithms that obtain: (a) $O(\\log\\log W)$-approximation in quasi-polytime; and (b) $O(\\log W)$-approximation in polytime.","We obtain similar guarantees for CSKO with cancellations, wherein a job can be cancelled before its completion time, foregoing its reward.","We also consider the special case of CSKO, wherein job sizes are weighted Bernoulli distributions, and more generally where the distributions are supported on at most two points (2-CSKO).","Although weighted Bernoulli distributions suffice to yield an $\\Omega(\\sqrt{\\log\\log B})$ adaptivity-gap lower bound for (uncorrelated) {\\em stochastic orienteering}, we show that they are easy instances for CSKO.","We develop non-adaptive algorithms that achieve $O(1)$-approximation in polytime for weighted Bernoulli distributions, and in $(n+\\log B)^{O(\\log W)}$-time for the more general case of 2-CSKO."],"url":"http://arxiv.org/abs/2408.16566v1"}
{"created":"2024-08-29 14:30:56","title":"Human-Inspired Audio-Visual Speech Recognition: Spike Activity, Cueing Interaction and Causal Processing","abstract":"Humans naturally perform audiovisual speech recognition (AVSR), enhancing the accuracy and robustness by integrating auditory and visual information. Spiking neural networks (SNNs), which mimic the brain's information-processing mechanisms, are well-suited for emulating the human capability of AVSR. Despite their potential, research on SNNs for AVSR is scarce, with most existing audio-visual multimodal methods focused on object or digit recognition. These models simply integrate features from both modalities, neglecting their unique characteristics and interactions. Additionally, they often rely on future information for current processing, which increases recognition latency and limits real-time applicability. Inspired by human speech perception, this paper proposes a novel human-inspired SNN named HI-AVSNN for AVSR, incorporating three key characteristics: cueing interaction, causal processing and spike activity. For cueing interaction, we propose a visual-cued auditory attention module (VCA2M) that leverages visual cues to guide attention to auditory features. We achieve causal processing by aligning the SNN's temporal dimension with that of visual and auditory features and applying temporal masking to utilize only past and current information. To implement spike activity, in addition to using SNNs, we leverage the event camera to capture lip movement as spikes, mimicking the human retina and providing efficient visual data. We evaluate HI-AVSNN on an audiovisual speech recognition dataset combining the DVS-Lip dataset with its corresponding audio samples. Experimental results demonstrate the superiority of our proposed fusion method, outperforming existing audio-visual SNN fusion methods and achieving a 2.27% improvement in accuracy over the only existing SNN-based AVSR method.","sentences":["Humans naturally perform audiovisual speech recognition (AVSR), enhancing the accuracy and robustness by integrating auditory and visual information.","Spiking neural networks (SNNs), which mimic the brain's information-processing mechanisms, are well-suited for emulating the human capability of AVSR.","Despite their potential, research on SNNs for AVSR is scarce, with most existing audio-visual multimodal methods focused on object or digit recognition.","These models simply integrate features from both modalities, neglecting their unique characteristics and interactions.","Additionally, they often rely on future information for current processing, which increases recognition latency and limits real-time applicability.","Inspired by human speech perception, this paper proposes a novel human-inspired SNN named HI-AVSNN for AVSR, incorporating three key characteristics: cueing interaction, causal processing and spike activity.","For cueing interaction, we propose a visual-cued auditory attention module (VCA2M) that leverages visual cues to guide attention to auditory features.","We achieve causal processing by aligning the SNN's temporal dimension with that of visual and auditory features and applying temporal masking to utilize only past and current information.","To implement spike activity, in addition to using SNNs, we leverage the event camera to capture lip movement as spikes, mimicking the human retina and providing efficient visual data.","We evaluate HI-AVSNN on an audiovisual speech recognition dataset combining the DVS-Lip dataset with its corresponding audio samples.","Experimental results demonstrate the superiority of our proposed fusion method, outperforming existing audio-visual SNN fusion methods and achieving a 2.27% improvement in accuracy over the only existing SNN-based AVSR method."],"url":"http://arxiv.org/abs/2408.16564v1"}
{"created":"2024-08-29 14:02:47","title":"Spurfies: Sparse Surface Reconstruction using Local Geometry Priors","abstract":"We introduce Spurfies, a novel method for sparse-view surface reconstruction that disentangles appearance and geometry information to utilize local geometry priors trained on synthetic data. Recent research heavily focuses on 3D reconstruction using dense multi-view setups, typically requiring hundreds of images. However, these methods often struggle with few-view scenarios. Existing sparse-view reconstruction techniques often rely on multi-view stereo networks that need to learn joint priors for geometry and appearance from a large amount of data. In contrast, we introduce a neural point representation that disentangles geometry and appearance to train a local geometry prior using a subset of the synthetic ShapeNet dataset only. During inference, we utilize this surface prior as additional constraint for surface and appearance reconstruction from sparse input views via differentiable volume rendering, restricting the space of possible solutions. We validate the effectiveness of our method on the DTU dataset and demonstrate that it outperforms previous state of the art by 35% in surface quality while achieving competitive novel view synthesis quality. Moreover, in contrast to previous works, our method can be applied to larger, unbounded scenes, such as Mip-NeRF 360.","sentences":["We introduce Spurfies, a novel method for sparse-view surface reconstruction that disentangles appearance and geometry information to utilize local geometry priors trained on synthetic data.","Recent research heavily focuses on 3D reconstruction using dense multi-view setups, typically requiring hundreds of images.","However, these methods often struggle with few-view scenarios.","Existing sparse-view reconstruction techniques often rely on multi-view stereo networks that need to learn joint priors for geometry and appearance from a large amount of data.","In contrast, we introduce a neural point representation that disentangles geometry and appearance to train a local geometry prior using a subset of the synthetic ShapeNet dataset only.","During inference, we utilize this surface prior as additional constraint for surface and appearance reconstruction from sparse input views via differentiable volume rendering, restricting the space of possible solutions.","We validate the effectiveness of our method on the DTU dataset and demonstrate that it outperforms previous state of the art by 35% in surface quality while achieving competitive novel view synthesis quality.","Moreover, in contrast to previous works, our method can be applied to larger, unbounded scenes, such as Mip-NeRF 360."],"url":"http://arxiv.org/abs/2408.16544v1"}
{"created":"2024-08-29 13:52:28","title":"SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks","abstract":"Graph Neural Networks (GNNs) have demonstrated commendable performance for graph-structured data. Yet, GNNs are often vulnerable to adversarial structural attacks as embedding generation relies on graph topology. Existing efforts are dedicated to purifying the maliciously modified structure or applying adaptive aggregation, thereby enhancing the robustness against adversarial structural attacks. It is inevitable for a defender to consume heavy computational costs due to lacking prior knowledge about modified structures. To this end, we propose an efficient defense method, called Simple and Fast Robust Graph Neural Network (SFR-GNN), supported by mutual information theory. The SFR-GNN first pre-trains a GNN model using node attributes and then fine-tunes it over the modified graph in the manner of contrastive learning, which is free of purifying modified structures and adaptive aggregation, thus achieving great efficiency gains. Consequently, SFR-GNN exhibits a 24%--162% speedup compared to advanced robust models, demonstrating superior robustness for node classification tasks.","sentences":["Graph Neural Networks (GNNs) have demonstrated commendable performance for graph-structured data.","Yet, GNNs are often vulnerable to adversarial structural attacks as embedding generation relies on graph topology.","Existing efforts are dedicated to purifying the maliciously modified structure or applying adaptive aggregation, thereby enhancing the robustness against adversarial structural attacks.","It is inevitable for a defender to consume heavy computational costs due to lacking prior knowledge about modified structures.","To this end, we propose an efficient defense method, called Simple and Fast Robust Graph Neural Network (SFR-GNN), supported by mutual information theory.","The SFR-GNN first pre-trains a GNN model using node attributes and then fine-tunes it over the modified graph in the manner of contrastive learning, which is free of purifying modified structures and adaptive aggregation, thus achieving great efficiency gains.","Consequently, SFR-GNN exhibits a 24%--162% speedup compared to advanced robust models, demonstrating superior robustness for node classification tasks."],"url":"http://arxiv.org/abs/2408.16537v1"}
{"created":"2024-08-29 13:31:15","title":"Towards Modality-agnostic Label-efficient Segmentation with Entropy-Regularized Distribution Alignment","abstract":"Label-efficient segmentation aims to perform effective segmentation on input data using only sparse and limited ground-truth labels for training. This topic is widely studied in 3D point cloud segmentation due to the difficulty of annotating point clouds densely, while it is also essential for cost-effective segmentation on 2D images. Until recently, pseudo-labels have been widely employed to facilitate training with limited ground-truth labels, and promising progress has been witnessed in both the 2D and 3D segmentation. However, existing pseudo-labeling approaches could suffer heavily from the noises and variations in unlabelled data, which would result in significant discrepancies between generated pseudo-labels and current model predictions during training. We analyze that this can further confuse and affect the model learning process, which shows to be a shared problem in label-efficient learning across both 2D and 3D modalities. To address this issue, we propose a novel learning strategy to regularize the pseudo-labels generated for training, thus effectively narrowing the gaps between pseudo-labels and model predictions. More specifically, our method introduces an Entropy Regularization loss and a Distribution Alignment loss for label-efficient learning, resulting in an ERDA learning strategy. Interestingly, by using KL distance to formulate the distribution alignment loss, ERDA reduces to a deceptively simple cross-entropy-based loss which optimizes both the pseudo-label generation module and the segmentation model simultaneously. In addition, we innovate in the pseudo-label generation to make our ERDA consistently effective across both 2D and 3D data modalities for segmentation. Enjoying simplicity and more modality-agnostic pseudo-label generation, our method has shown outstanding performance in fully utilizing all unlabeled data points for training across ...","sentences":["Label-efficient segmentation aims to perform effective segmentation on input data using only sparse and limited ground-truth labels for training.","This topic is widely studied in 3D point cloud segmentation due to the difficulty of annotating point clouds densely, while it is also essential for cost-effective segmentation on 2D images.","Until recently, pseudo-labels have been widely employed to facilitate training with limited ground-truth labels, and promising progress has been witnessed in both the 2D and 3D segmentation.","However, existing pseudo-labeling approaches could suffer heavily from the noises and variations in unlabelled data, which would result in significant discrepancies between generated pseudo-labels and current model predictions during training.","We analyze that this can further confuse and affect the model learning process, which shows to be a shared problem in label-efficient learning across both 2D and 3D modalities.","To address this issue, we propose a novel learning strategy to regularize the pseudo-labels generated for training, thus effectively narrowing the gaps between pseudo-labels and model predictions.","More specifically, our method introduces an Entropy Regularization loss and a Distribution Alignment loss for label-efficient learning, resulting in an ERDA learning strategy.","Interestingly, by using KL distance to formulate the distribution alignment loss, ERDA reduces to a deceptively simple cross-entropy-based loss which optimizes both the pseudo-label generation module and the segmentation model simultaneously.","In addition, we innovate in the pseudo-label generation to make our ERDA consistently effective across both 2D and 3D data modalities for segmentation.","Enjoying simplicity and more modality-agnostic pseudo-label generation, our method has shown outstanding performance in fully utilizing all unlabeled data points for training across ..."],"url":"http://arxiv.org/abs/2408.16520v1"}
{"created":"2024-08-29 13:28:52","title":"CNIMA: A Universal Evaluation Framework and Automated Approach for Assessing Second Language Dialogues","abstract":"We develop CNIMA (Chinese Non-Native Interactivity Measurement and Automation), a Chinese-as-a-second-language labelled dataset with 10K dialogues. We annotate CNIMA using an evaluation framework -- originally introduced for English-as-a-second-language dialogues -- that assesses micro-level features (e.g.\\ backchannels) and macro-level interactivity labels (e.g.\\ topic management) and test the framework's transferability from English to Chinese. We found the framework robust across languages and revealed universal and language-specific relationships between micro-level and macro-level features. Next, we propose an approach to automate the evaluation and find strong performance, creating a new tool for automated second language assessment. Our system can be adapted to other languages easily as it uses large language models and as such does not require large-scale annotated training data.","sentences":["We develop CNIMA (Chinese Non-Native Interactivity Measurement and Automation), a Chinese-as-a-second-language labelled dataset with 10K dialogues.","We annotate CNIMA using an evaluation framework -- originally introduced for English-as-a-second-language dialogues -- that assesses micro-level features (e.g.\\ backchannels) and macro-level interactivity labels (e.g.\\ topic management) and test the framework's transferability from English to Chinese.","We found the framework robust across languages and revealed universal and language-specific relationships between micro-level and macro-level features.","Next, we propose an approach to automate the evaluation and find strong performance, creating a new tool for automated second language assessment.","Our system can be adapted to other languages easily as it uses large language models and as such does not require large-scale annotated training data."],"url":"http://arxiv.org/abs/2408.16518v1"}
{"created":"2024-08-29 13:01:42","title":"LLMs vs Established Text Augmentation Techniques for Classification: When do the Benefits Outweight the Costs?","abstract":"The generative large language models (LLMs) are increasingly being used for data augmentation tasks, where text samples are LLM-paraphrased and then used for classifier fine-tuning. However, a research that would confirm a clear cost-benefit advantage of LLMs over more established augmentation methods is largely missing. To study if (and when) is the LLM-based augmentation advantageous, we compared the effects of recent LLM augmentation methods with established ones on 6 datasets, 3 classifiers and 2 fine-tuning methods. We also varied the number of seeds and collected samples to better explore the downstream model accuracy space. Finally, we performed a cost-benefit analysis and show that LLM-based methods are worthy of deployment only when very small number of seeds is used. Moreover, in many cases, established methods lead to similar or better model accuracies.","sentences":["The generative large language models (LLMs) are increasingly being used for data augmentation tasks, where text samples are LLM-paraphrased and then used for classifier fine-tuning.","However, a research that would confirm a clear cost-benefit advantage of LLMs over more established augmentation methods is largely missing.","To study if (and when) is the LLM-based augmentation advantageous, we compared the effects of recent LLM augmentation methods with established ones on 6 datasets, 3 classifiers and 2 fine-tuning methods.","We also varied the number of seeds and collected samples to better explore the downstream model accuracy space.","Finally, we performed a cost-benefit analysis and show that LLM-based methods are worthy of deployment only when very small number of seeds is used.","Moreover, in many cases, established methods lead to similar or better model accuracies."],"url":"http://arxiv.org/abs/2408.16502v1"}
{"created":"2024-08-29 12:59:12","title":"CogVLM2: Visual Language Models for Image and Video Understanding","abstract":"Beginning with VisualGLM and CogVLM, we are continuously exploring VLMs in pursuit of enhanced vision-language fusion, efficient higher-resolution architecture, and broader modalities and applications. Here we propose the CogVLM2 family, a new generation of visual language models for image and video understanding including CogVLM2, CogVLM2-Video and GLM-4V. As an image understanding model, CogVLM2 inherits the visual expert architecture with improved training recipes in both pre-training and post-training stages, supporting input resolution up to $1344 \\times 1344$ pixels. As a video understanding model, CogVLM2-Video integrates multi-frame input with timestamps and proposes automated temporal grounding data construction. Notably, CogVLM2 family has achieved state-of-the-art results on benchmarks like MMBench, MM-Vet, TextVQA, MVBench and VCGBench. All models are open-sourced in https://github.com/THUDM/CogVLM2 and https://github.com/THUDM/GLM-4, contributing to the advancement of the field.","sentences":["Beginning with VisualGLM and CogVLM, we are continuously exploring VLMs in pursuit of enhanced vision-language fusion, efficient higher-resolution architecture, and broader modalities and applications.","Here we propose the CogVLM2 family, a new generation of visual language models for image and video understanding including CogVLM2, CogVLM2-Video and GLM-4V. As an image understanding model, CogVLM2 inherits the visual expert architecture with improved training recipes in both pre-training and post-training stages, supporting input resolution up to $1344 \\times 1344$ pixels.","As a video understanding model, CogVLM2-Video integrates multi-frame input with timestamps and proposes automated temporal grounding data construction.","Notably, CogVLM2 family has achieved state-of-the-art results on benchmarks like MMBench, MM-Vet, TextVQA, MVBench and VCGBench.","All models are open-sourced in https://github.com/THUDM/CogVLM2 and https://github.com/THUDM/GLM-4, contributing to the advancement of the field."],"url":"http://arxiv.org/abs/2408.16500v1"}
{"created":"2024-08-29 12:34:01","title":"Adapting Vision-Language Models to Open Classes via Test-Time Prompt Tuning","abstract":"Adapting pre-trained models to open classes is a challenging problem in machine learning. Vision-language models fully explore the knowledge of text modality, demonstrating strong zero-shot recognition performance, which is naturally suited for various open-set problems. More recently, some research focuses on fine-tuning such models to downstream tasks. Prompt tuning methods achieved huge improvements by learning context vectors on few-shot data. However, through the evaluation under open-set adaptation setting with the test data including new classes, we find that there exists a dilemma that learned prompts have worse generalization abilities than hand-crafted prompts. In this paper, we consider combining the advantages of both and come up with a test-time prompt tuning approach, which leverages the maximum concept matching (MCM) scores as dynamic weights to generate an input-conditioned prompt for each image during test. Through extensive experiments on 11 different datasets, we show that our proposed method outperforms all comparison methods on average considering both base and new classes. The code is available at https://github.com/gaozhengqing/TTPT","sentences":["Adapting pre-trained models to open classes is a challenging problem in machine learning.","Vision-language models fully explore the knowledge of text modality, demonstrating strong zero-shot recognition performance, which is naturally suited for various open-set problems.","More recently, some research focuses on fine-tuning such models to downstream tasks.","Prompt tuning methods achieved huge improvements by learning context vectors on few-shot data.","However, through the evaluation under open-set adaptation setting with the test data including new classes, we find that there exists a dilemma that learned prompts have worse generalization abilities than hand-crafted prompts.","In this paper, we consider combining the advantages of both and come up with a test-time prompt tuning approach, which leverages the maximum concept matching (MCM) scores as dynamic weights to generate an input-conditioned prompt for each image during test.","Through extensive experiments on 11 different datasets, we show that our proposed method outperforms all comparison methods on average considering both base and new classes.","The code is available at https://github.com/gaozhengqing/TTPT"],"url":"http://arxiv.org/abs/2408.16486v1"}
{"created":"2024-08-29 12:18:04","title":"Self-Alignment: Improving Alignment of Cultural Values in LLMs via In-Context Learning","abstract":"Improving the alignment of Large Language Models (LLMs) with respect to the cultural values that they encode has become an increasingly important topic. In this work, we study whether we can exploit existing knowledge about cultural values at inference time to adjust model responses to cultural value probes. We present a simple and inexpensive method that uses a combination of in-context learning (ICL) and human survey data, and show that we can improve the alignment to cultural values across 5 models that include both English-centric and multilingual LLMs. Importantly, we show that our method could prove useful in test languages other than English and can improve alignment to the cultural values that correspond to a range of culturally diverse countries.","sentences":["Improving the alignment of Large Language Models (LLMs) with respect to the cultural values that they encode has become an increasingly important topic.","In this work, we study whether we can exploit existing knowledge about cultural values at inference time to adjust model responses to cultural value probes.","We present a simple and inexpensive method that uses a combination of in-context learning (ICL) and human survey data, and show that we can improve the alignment to cultural values across 5 models that include both English-centric and multilingual LLMs.","Importantly, we show that our method could prove useful in test languages other than English and can improve alignment to the cultural values that correspond to a range of culturally diverse countries."],"url":"http://arxiv.org/abs/2408.16482v1"}
{"created":"2024-08-29 12:16:13","title":"Fostering Creative Visualisation Skills Through Data-Art Exhibitions","abstract":"Data-art exhibitions offer a unique and real-world setting to foster creative visualisation skills among students. They serve as real-world platform for students to display their work, bridging the gap between classroom learning and professional practice. Students must develop a technical solution, grasp the context, and produce work that is appropriate for public presentation. This scenario helps to encourage innovative thinking, engagement with the topic, and helps to enhance technical proficiency. We present our implementation of a data-art exhibition within a computing curriculum, for third-year degree-level students. Students create art-based visualisations from selected datasets and present their work in a public exhibition. We have used this initiative over the course of two academic years with different cohorts, and reflect on its impact on student learning and creativity.","sentences":["Data-art exhibitions offer a unique and real-world setting to foster creative visualisation skills among students.","They serve as real-world platform for students to display their work, bridging the gap between classroom learning and professional practice.","Students must develop a technical solution, grasp the context, and produce work that is appropriate for public presentation.","This scenario helps to encourage innovative thinking, engagement with the topic, and helps to enhance technical proficiency.","We present our implementation of a data-art exhibition within a computing curriculum, for third-year degree-level students.","Students create art-based visualisations from selected datasets and present their work in a public exhibition.","We have used this initiative over the course of two academic years with different cohorts, and reflect on its impact on student learning and creativity."],"url":"http://arxiv.org/abs/2408.16479v1"}
{"created":"2024-08-29 12:15:10","title":"MICDrop: Masking Image and Depth Features via Complementary Dropout for Domain-Adaptive Semantic Segmentation","abstract":"Unsupervised Domain Adaptation (UDA) is the task of bridging the domain gap between a labeled source domain, e.g., synthetic data, and an unlabeled target domain. We observe that current UDA methods show inferior results on fine structures and tend to oversegment objects with ambiguous appearance. To address these shortcomings, we propose to leverage geometric information, i.e., depth predictions, as depth discontinuities often coincide with segmentation boundaries. We show that naively incorporating depth into current UDA methods does not fully exploit the potential of this complementary information. To this end, we present MICDrop, which learns a joint feature representation by masking image encoder features while inversely masking depth encoder features. With this simple yet effective complementary masking strategy, we enforce the use of both modalities when learning the joint feature representation. To aid this process, we propose a feature fusion module to improve both global as well as local information sharing while being robust to errors in the depth predictions. We show that our method can be plugged into various recent UDA methods and consistently improve results across standard UDA benchmarks, obtaining new state-of-the-art performances.","sentences":["Unsupervised Domain Adaptation (UDA) is the task of bridging the domain gap between a labeled source domain, e.g., synthetic data, and an unlabeled target domain.","We observe that current UDA methods show inferior results on fine structures and tend to oversegment objects with ambiguous appearance.","To address these shortcomings, we propose to leverage geometric information, i.e., depth predictions, as depth discontinuities often coincide with segmentation boundaries.","We show that naively incorporating depth into current UDA methods does not fully exploit the potential of this complementary information.","To this end, we present MICDrop, which learns a joint feature representation by masking image encoder features while inversely masking depth encoder features.","With this simple yet effective complementary masking strategy, we enforce the use of both modalities when learning the joint feature representation.","To aid this process, we propose a feature fusion module to improve both global as well as local information sharing while being robust to errors in the depth predictions.","We show that our method can be plugged into various recent UDA methods and consistently improve results across standard UDA benchmarks, obtaining new state-of-the-art performances."],"url":"http://arxiv.org/abs/2408.16478v1"}
{"created":"2024-08-29 12:01:21","title":"CooTest: An Automated Testing Approach for V2X Communication Systems","abstract":"Perceiving the complex driving environment precisely is crucial to the safe operation of autonomous vehicles. With the tremendous advancement of deep learning and communication technology, Vehicle-to-Everything (V2X) collaboration has the potential to address limitations in sensing distant objects and occlusion for a single-agent perception system. However, despite spectacular progress, several communication challenges can undermine the effectiveness of multi-vehicle cooperative perception. The low interpretability of Deep Neural Networks (DNNs) and the high complexity of communication mechanisms make conventional testing techniques inapplicable for the cooperative perception of autonomous driving systems (ADS). Besides, the existing testing techniques, depending on manual data collection and labeling, become time-consuming and prohibitively expensive.   In this paper, we design and implement CooTest, the first automated testing tool of the V2X-oriented cooperative perception module. CooTest devises the V2X-specific metamorphic relation and equips communication and weather transformation operators that can reflect the impact of the various cooperative driving factors to produce transformed scenes. Furthermore, we adopt a V2X-oriented guidance strategy for the transformed scene generation process and improve testing efficiency. We experiment CooTest with multiple cooperative perception models with different fusion schemes to evaluate its performance on different tasks. The experiment results show that CooTest can effectively detect erroneous behaviors under various V2X-oriented driving conditions. Also, the results confirm that CooTest can improve detection average precision and decrease misleading cooperation errors by retraining with the generated scenes.","sentences":["Perceiving the complex driving environment precisely is crucial to the safe operation of autonomous vehicles.","With the tremendous advancement of deep learning and communication technology, Vehicle-to-Everything (V2X) collaboration has the potential to address limitations in sensing distant objects and occlusion for a single-agent perception system.","However, despite spectacular progress, several communication challenges can undermine the effectiveness of multi-vehicle cooperative perception.","The low interpretability of Deep Neural Networks (DNNs) and the high complexity of communication mechanisms make conventional testing techniques inapplicable for the cooperative perception of autonomous driving systems (ADS).","Besides, the existing testing techniques, depending on manual data collection and labeling, become time-consuming and prohibitively expensive.   ","In this paper, we design and implement CooTest, the first automated testing tool of the V2X-oriented cooperative perception module.","CooTest devises the V2X-specific metamorphic relation and equips communication and weather transformation operators that can reflect the impact of the various cooperative driving factors to produce transformed scenes.","Furthermore, we adopt a V2X-oriented guidance strategy for the transformed scene generation process and improve testing efficiency.","We experiment CooTest with multiple cooperative perception models with different fusion schemes to evaluate its performance on different tasks.","The experiment results show that CooTest can effectively detect erroneous behaviors under various V2X-oriented driving conditions.","Also, the results confirm that CooTest can improve detection average precision and decrease misleading cooperation errors by retraining with the generated scenes."],"url":"http://arxiv.org/abs/2408.16470v1"}
{"created":"2024-08-29 11:51:41","title":"An Exploratory Deep Learning Approach for Predicting Subsequent Suicidal Acts in Chinese Psychological Support Hotlines","abstract":"Psychological support hotlines are an effective suicide prevention measure that typically relies on professionals using suicide risk assessment scales to predict individual risk scores. However, the accuracy of scale-based predictive methods for suicide risk assessment can vary widely depending on the expertise of the operator. This limitation underscores the need for more reliable methods, prompting this research's innovative exploration of the use of artificial intelligence to improve the accuracy and efficiency of suicide risk prediction within the context of psychological support hotlines. The study included data from 1,549 subjects from 2015-2017 in China who contacted a psychological support hotline. Each participant was followed for 12 months to identify instances of suicidal behavior. We proposed a novel multi-task learning method that uses the large-scale pre-trained model Whisper for feature extraction and fits psychological scales while predicting the risk of suicide. The proposed method yields a 2.4\\% points improvement in F1-score compared to the traditional manual approach based on the psychological scales. Our model demonstrated superior performance compared to the other eight popular models. To our knowledge, this study is the first to apply deep learning to long-term speech data to predict suicide risk in China, indicating grate potential for clinical applications. The source code is publicly available at: \\url{https://github.com/songchangwei/Suicide-Risk-Prediction}.","sentences":["Psychological support hotlines are an effective suicide prevention measure that typically relies on professionals using suicide risk assessment scales to predict individual risk scores.","However, the accuracy of scale-based predictive methods for suicide risk assessment can vary widely depending on the expertise of the operator.","This limitation underscores the need for more reliable methods, prompting this research's innovative exploration of the use of artificial intelligence to improve the accuracy and efficiency of suicide risk prediction within the context of psychological support hotlines.","The study included data from 1,549 subjects from 2015-2017 in China who contacted a psychological support hotline.","Each participant was followed for 12 months to identify instances of suicidal behavior.","We proposed a novel multi-task learning method that uses the large-scale pre-trained model Whisper for feature extraction and fits psychological scales while predicting the risk of suicide.","The proposed method yields a 2.4\\% points improvement in F1-score compared to the traditional manual approach based on the psychological scales.","Our model demonstrated superior performance compared to the other eight popular models.","To our knowledge, this study is the first to apply deep learning to long-term speech data to predict suicide risk in China, indicating grate potential for clinical applications.","The source code is publicly available at: \\url{https://github.com/songchangwei/Suicide-Risk-Prediction}."],"url":"http://arxiv.org/abs/2408.16463v1"}
{"created":"2024-08-29 11:19:57","title":"Is text normalization relevant for classifying medieval charters?","abstract":"This study examines the impact of historical text normalization on the classification of medieval charters, specifically focusing on document dating and locating. Using a data set of Middle High German charters from a digital archive, we evaluate various classifiers, including traditional and transformer-based models, with and without normalization. Our results indicate that the given normalization minimally improves locating tasks but reduces accuracy for dating, implying that original texts contain crucial features that normalization may obscure. We find that support vector machines and gradient boosting outperform other models, questioning the efficiency of transformers for this use case. Results suggest a selective approach to historical text normalization, emphasizing the significance of preserving some textual characteristics that are critical for classification tasks in document analysis.","sentences":["This study examines the impact of historical text normalization on the classification of medieval charters, specifically focusing on document dating and locating.","Using a data set of Middle High German charters from a digital archive, we evaluate various classifiers, including traditional and transformer-based models, with and without normalization.","Our results indicate that the given normalization minimally improves locating tasks but reduces accuracy for dating, implying that original texts contain crucial features that normalization may obscure.","We find that support vector machines and gradient boosting outperform other models, questioning the efficiency of transformers for this use case.","Results suggest a selective approach to historical text normalization, emphasizing the significance of preserving some textual characteristics that are critical for classification tasks in document analysis."],"url":"http://arxiv.org/abs/2408.16446v1"}
{"created":"2024-08-29 11:07:48","title":"Integrating Features for Recognizing Human Activities through Optimized Parameters in Graph Convolutional Networks and Transformer Architectures","abstract":"Human activity recognition is a major field of study that employs computer vision, machine vision, and deep learning techniques to categorize human actions. The field of deep learning has made significant progress, with architectures that are extremely effective at capturing human dynamics. This study emphasizes the influence of feature fusion on the accuracy of activity recognition. This technique addresses the limitation of conventional models, which face difficulties in identifying activities because of their limited capacity to understand spatial and temporal features. The technique employs sensory data obtained from four publicly available datasets: HuGaDB, PKU-MMD, LARa, and TUG. The accuracy and F1-score of two deep learning models, specifically a Transformer model and a Parameter-Optimized Graph Convolutional Network (PO-GCN), were evaluated using these datasets. The feature fusion technique integrated the final layer features from both models and inputted them into a classifier. Empirical evidence demonstrates that PO-GCN outperforms standard models in activity recognition. HuGaDB demonstrated a 2.3% improvement in accuracy and a 2.2% increase in F1-score. TUG showed a 5% increase in accuracy and a 0.5% rise in F1-score. On the other hand, LARa and PKU-MMD achieved lower accuracies of 64% and 69% respectively. This indicates that the integration of features enhanced the performance of both the Transformer model and PO-GCN.","sentences":["Human activity recognition is a major field of study that employs computer vision, machine vision, and deep learning techniques to categorize human actions.","The field of deep learning has made significant progress, with architectures that are extremely effective at capturing human dynamics.","This study emphasizes the influence of feature fusion on the accuracy of activity recognition.","This technique addresses the limitation of conventional models, which face difficulties in identifying activities because of their limited capacity to understand spatial and temporal features.","The technique employs sensory data obtained from four publicly available datasets: HuGaDB, PKU-MMD, LARa, and TUG.","The accuracy and F1-score of two deep learning models, specifically a Transformer model and a Parameter-Optimized Graph Convolutional Network (PO-GCN), were evaluated using these datasets.","The feature fusion technique integrated the final layer features from both models and inputted them into a classifier.","Empirical evidence demonstrates that PO-GCN outperforms standard models in activity recognition.","HuGaDB demonstrated a 2.3% improvement in accuracy and a 2.2% increase in F1-score.","TUG showed a 5% increase in accuracy and a 0.5% rise in F1-score.","On the other hand, LARa and PKU-MMD achieved lower accuracies of 64% and 69% respectively.","This indicates that the integration of features enhanced the performance of both the Transformer model and PO-GCN."],"url":"http://arxiv.org/abs/2408.16442v1"}
{"created":"2024-08-29 10:44:59","title":"Do Recommender Systems Promote Local Music? A Reproducibility Study Using Music Streaming Data","abstract":"This paper examines the influence of recommender systems on local music representation, discussing prior findings from an empirical study on the LFM-2b public dataset. This prior study argued that different recommender systems exhibit algorithmic biases shifting music consumption either towards or against local content. However, LFM-2b users do not reflect the diverse audience of music streaming services. To assess the robustness of this study's conclusions, we conduct a comparative analysis using proprietary listening data from a global music streaming service, which we publicly release alongside this paper. We observe significant differences in local music consumption patterns between our dataset and LFM-2b, suggesting that caution should be exercised when drawing conclusions on local music based solely on LFM-2b. Moreover, we show that the algorithmic biases exhibited in the original work vary in our dataset, and that several unexplored model parameters can significantly influence these biases and affect the study's conclusion on both datasets. Finally, we discuss the complexity of accurately labeling local music, emphasizing the risk of misleading conclusions due to unreliable, biased, or incomplete labels. To encourage further research and ensure reproducibility, we have publicly shared our dataset and code.","sentences":["This paper examines the influence of recommender systems on local music representation, discussing prior findings from an empirical study on the LFM-2b public dataset.","This prior study argued that different recommender systems exhibit algorithmic biases shifting music consumption either towards or against local content.","However, LFM-2b users do not reflect the diverse audience of music streaming services.","To assess the robustness of this study's conclusions, we conduct a comparative analysis using proprietary listening data from a global music streaming service, which we publicly release alongside this paper.","We observe significant differences in local music consumption patterns between our dataset and LFM-2b, suggesting that caution should be exercised when drawing conclusions on local music based solely on LFM-2b.","Moreover, we show that the algorithmic biases exhibited in the original work vary in our dataset, and that several unexplored model parameters can significantly influence these biases and affect the study's conclusion on both datasets.","Finally, we discuss the complexity of accurately labeling local music, emphasizing the risk of misleading conclusions due to unreliable, biased, or incomplete labels.","To encourage further research and ensure reproducibility, we have publicly shared our dataset and code."],"url":"http://arxiv.org/abs/2408.16430v1"}
{"created":"2024-08-29 10:43:55","title":"Gradient-free variational learning with conditional mixture networks","abstract":"Balancing computational efficiency with robust predictive performance is crucial in supervised learning, especially for critical applications. Standard deep learning models, while accurate and scalable, often lack probabilistic features like calibrated predictions and uncertainty quantification. Bayesian methods address these issues but can be computationally expensive as model and data complexity increase. Previous work shows that fast variational methods can reduce the compute requirements of Bayesian methods by eliminating the need for gradient computation or sampling, but are often limited to simple models. We demonstrate that conditional mixture networks (CMNs), a probabilistic variant of the mixture-of-experts (MoE) model, are suitable for fast, gradient-free inference and can solve complex classification tasks. CMNs employ linear experts and a softmax gating network. By exploiting conditional conjugacy and P\\'olya-Gamma augmentation, we furnish Gaussian likelihoods for the weights of both the linear experts and the gating network. This enables efficient variational updates using coordinate ascent variational inference (CAVI), avoiding traditional gradient-based optimization. We validate this approach by training two-layer CMNs on standard benchmarks from the UCI repository. Our method, CAVI-CMN, achieves competitive and often superior predictive accuracy compared to maximum likelihood estimation (MLE) with backpropagation, while maintaining competitive runtime and full posterior distributions over all model parameters. Moreover, as input size or the number of experts increases, computation time scales competitively with MLE and other gradient-based solutions like black-box variational inference (BBVI), making CAVI-CMN a promising tool for deep, fast, and gradient-free Bayesian networks.","sentences":["Balancing computational efficiency with robust predictive performance is crucial in supervised learning, especially for critical applications.","Standard deep learning models, while accurate and scalable, often lack probabilistic features like calibrated predictions and uncertainty quantification.","Bayesian methods address these issues but can be computationally expensive as model and data complexity increase.","Previous work shows that fast variational methods can reduce the compute requirements of Bayesian methods by eliminating the need for gradient computation or sampling, but are often limited to simple models.","We demonstrate that conditional mixture networks (CMNs), a probabilistic variant of the mixture-of-experts (MoE) model, are suitable for fast, gradient-free inference and can solve complex classification tasks.","CMNs employ linear experts and a softmax gating network.","By exploiting conditional conjugacy and P\\'olya-Gamma augmentation, we furnish Gaussian likelihoods for the weights of both the linear experts and the gating network.","This enables efficient variational updates using coordinate ascent variational inference (CAVI), avoiding traditional gradient-based optimization.","We validate this approach by training two-layer CMNs on standard benchmarks from the UCI repository.","Our method, CAVI-CMN, achieves competitive and often superior predictive accuracy compared to maximum likelihood estimation (MLE) with backpropagation, while maintaining competitive runtime and full posterior distributions over all model parameters.","Moreover, as input size or the number of experts increases, computation time scales competitively with MLE and other gradient-based solutions like black-box variational inference (BBVI), making CAVI-CMN a promising tool for deep, fast, and gradient-free Bayesian networks."],"url":"http://arxiv.org/abs/2408.16429v1"}
{"created":"2024-08-29 10:35:07","title":"A Comparative Study of Hyperparameter Tuning Methods","abstract":"The study emphasizes the challenge of finding the optimal trade-off between bias and variance, especially as hyperparameter optimization increases in complexity. Through empirical analysis, three hyperparameter tuning algorithms Tree-structured Parzen Estimator (TPE), Genetic Search, and Random Search are evaluated across regression and classification tasks. The results show that nonlinear models, with properly tuned hyperparameters, significantly outperform linear models. Interestingly, Random Search excelled in regression tasks, while TPE was more effective for classification tasks. This suggests that there is no one-size-fits-all solution, as different algorithms perform better depending on the task and model type. The findings underscore the importance of selecting the appropriate tuning method and highlight the computational challenges involved in optimizing machine learning models, particularly as search spaces expand.","sentences":["The study emphasizes the challenge of finding the optimal trade-off between bias and variance, especially as hyperparameter optimization increases in complexity.","Through empirical analysis, three hyperparameter tuning algorithms Tree-structured Parzen Estimator (TPE), Genetic Search, and Random Search are evaluated across regression and classification tasks.","The results show that nonlinear models, with properly tuned hyperparameters, significantly outperform linear models.","Interestingly, Random Search excelled in regression tasks, while TPE was more effective for classification tasks.","This suggests that there is no one-size-fits-all solution, as different algorithms perform better depending on the task and model type.","The findings underscore the importance of selecting the appropriate tuning method and highlight the computational challenges involved in optimizing machine learning models, particularly as search spaces expand."],"url":"http://arxiv.org/abs/2408.16425v1"}
{"created":"2024-08-29 10:30:01","title":"CollectionLocator Level 1: Metadata-Based Search for Collections in Federated Biobanks","abstract":"Biobanks are indispensable resources for medical research collecting biological material and associated data and making them available for research projects and medical studies. For that, the biobank data has to meet certain criteria which can be formulated as adherence to the FAIR (findable, accessible, interoperable and reusable) principles.   We developed a tool, CollectionLocator, which aims at increasing the FAIR compliance of biobank data by supporting researchers in identifying which biobank and which collection are likely to contain cases (material and data) satisfying the requirements of a defined research project when the detailed sample data is not available due to privacy restrictions. The CollectionLocator is based on an ontology-based metadata model to address the enormous heterogeneities and ensure the privacy of the donors of the biological samples and the data. Furthermore, the CollectionLocator represents the data and metadata quality of the collections such that the quality requirements of the requester can be matched with the quality of the available data. The concept of CollectionLocator is evaluated with a proof-of-concept implementation.","sentences":["Biobanks are indispensable resources for medical research collecting biological material and associated data and making them available for research projects and medical studies.","For that, the biobank data has to meet certain criteria which can be formulated as adherence to the FAIR (findable, accessible, interoperable and reusable) principles.   ","We developed a tool, CollectionLocator, which aims at increasing the FAIR compliance of biobank data by supporting researchers in identifying which biobank and which collection are likely to contain cases (material and data) satisfying the requirements of a defined research project when the detailed sample data is not available due to privacy restrictions.","The CollectionLocator is based on an ontology-based metadata model to address the enormous heterogeneities and ensure the privacy of the donors of the biological samples and the data.","Furthermore, the CollectionLocator represents the data and metadata quality of the collections such that the quality requirements of the requester can be matched with the quality of the available data.","The concept of CollectionLocator is evaluated with a proof-of-concept implementation."],"url":"http://arxiv.org/abs/2408.16422v1"}
{"created":"2024-08-29 10:20:05","title":"Text-Enhanced Zero-Shot Action Recognition: A training-free approach","abstract":"Vision-language models (VLMs) have demonstrated remarkable performance across various visual tasks, leveraging joint learning of visual and textual representations. While these models excel in zero-shot image tasks, their application to zero-shot video action recognition (ZSVAR) remains challenging due to the dynamic and temporal nature of actions. Existing methods for ZS-VAR typically require extensive training on specific datasets, which can be resource-intensive and may introduce domain biases. In this work, we propose Text-Enhanced Action Recognition (TEAR), a simple approach to ZS-VAR that is training-free and does not require the availability of training data or extensive computational resources. Drawing inspiration from recent findings in vision and language literature, we utilize action descriptors for decomposition and contextual information to enhance zero-shot action recognition. Through experiments on UCF101, HMDB51, and Kinetics-600 datasets, we showcase the effectiveness and applicability of our proposed approach in addressing the challenges of ZS-VAR.","sentences":["Vision-language models (VLMs) have demonstrated remarkable performance across various visual tasks, leveraging joint learning of visual and textual representations.","While these models excel in zero-shot image tasks, their application to zero-shot video action recognition (ZSVAR) remains challenging due to the dynamic and temporal nature of actions.","Existing methods for ZS-VAR typically require extensive training on specific datasets, which can be resource-intensive and may introduce domain biases.","In this work, we propose Text-Enhanced Action Recognition (TEAR), a simple approach to ZS-VAR that is training-free and does not require the availability of training data or extensive computational resources.","Drawing inspiration from recent findings in vision and language literature, we utilize action descriptors for decomposition and contextual information to enhance zero-shot action recognition.","Through experiments on UCF101, HMDB51, and Kinetics-600 datasets, we showcase the effectiveness and applicability of our proposed approach in addressing the challenges of ZS-VAR."],"url":"http://arxiv.org/abs/2408.16412v1"}
{"created":"2024-08-29 10:01:45","title":"JINet: easy and secure private data analysis for everyone","abstract":"JINet is a web browser-based platform intended to democratise access to advanced clinical and genomic data analysis software. It hosts numerous data analysis applications that are run in the safety of each User's web browser, without the data ever leaving their machine. JINet promotes collaboration, standardisation and reproducibility by sharing scripts rather than data and creating a self-sustaining community around it in which Users and data analysis tools developers interact thanks to JINets interoperability primitives.","sentences":["JINet is a web browser-based platform intended to democratise access to advanced clinical and genomic data analysis software.","It hosts numerous data analysis applications that are run in the safety of each User's web browser, without the data ever leaving their machine.","JINet promotes collaboration, standardisation and reproducibility by sharing scripts rather than data and creating a self-sustaining community around it in which Users and data analysis tools developers interact thanks to JINets interoperability primitives."],"url":"http://arxiv.org/abs/2408.16402v1"}
{"created":"2024-08-29 09:57:55","title":"IBO: Inpainting-Based Occlusion to Enhance Explainable Artificial Intelligence Evaluation in Histopathology","abstract":"Histopathological image analysis is crucial for accurate cancer diagnosis and treatment planning. While deep learning models, especially convolutional neural networks, have advanced this field, their \"black-box\" nature raises concerns about interpretability and trustworthiness. Explainable Artificial Intelligence (XAI) techniques aim to address these concerns, but evaluating their effectiveness remains challenging. A significant issue with current occlusion-based XAI methods is that they often generate Out-of-Distribution (OoD) samples, leading to inaccurate evaluations. In this paper, we introduce Inpainting-Based Occlusion (IBO), a novel occlusion strategy that utilizes a Denoising Diffusion Probabilistic Model to inpaint occluded regions in histopathological images. By replacing cancerous areas with realistic, non-cancerous tissue, IBO minimizes OoD artifacts and preserves data integrity. We evaluate our method on the CAMELYON16 dataset through two phases: first, by assessing perceptual similarity using the Learned Perceptual Image Patch Similarity (LPIPS) metric, and second, by quantifying the impact on model predictions through Area Under the Curve (AUC) analysis. Our results demonstrate that IBO significantly improves perceptual fidelity, achieving nearly twice the improvement in LPIPS scores compared to the best existing occlusion strategy. Additionally, IBO increased the precision of XAI performance prediction from 42% to 71% compared to traditional methods. These results demonstrate IBO's potential to provide more reliable evaluations of XAI techniques, benefiting histopathology and other applications. The source code for this study is available at https://github.com/a-fsh-r/IBO.","sentences":["Histopathological image analysis is crucial for accurate cancer diagnosis and treatment planning.","While deep learning models, especially convolutional neural networks, have advanced this field, their \"black-box\" nature raises concerns about interpretability and trustworthiness.","Explainable Artificial Intelligence (XAI) techniques aim to address these concerns, but evaluating their effectiveness remains challenging.","A significant issue with current occlusion-based XAI methods is that they often generate Out-of-Distribution (OoD) samples, leading to inaccurate evaluations.","In this paper, we introduce Inpainting-Based Occlusion (IBO), a novel occlusion strategy that utilizes a Denoising Diffusion Probabilistic Model to inpaint occluded regions in histopathological images.","By replacing cancerous areas with realistic, non-cancerous tissue, IBO minimizes OoD artifacts and preserves data integrity.","We evaluate our method on the CAMELYON16 dataset through two phases: first, by assessing perceptual similarity using the Learned Perceptual Image Patch Similarity (LPIPS) metric, and second, by quantifying the impact on model predictions through Area Under the Curve (AUC) analysis.","Our results demonstrate that IBO significantly improves perceptual fidelity, achieving nearly twice the improvement in LPIPS scores compared to the best existing occlusion strategy.","Additionally, IBO increased the precision of XAI performance prediction from 42% to 71% compared to traditional methods.","These results demonstrate IBO's potential to provide more reliable evaluations of XAI techniques, benefiting histopathology and other applications.","The source code for this study is available at https://github.com/a-fsh-r/IBO."],"url":"http://arxiv.org/abs/2408.16395v1"}
{"created":"2024-08-29 09:54:46","title":"TempoKGAT: A Novel Graph Attention Network Approach for Temporal Graph Analysis","abstract":"Graph neural networks (GNN) have shown significant capabilities in handling structured data, yet their application to dynamic, temporal data remains limited. This paper presents a new type of graph attention network, called TempoKGAT, which combines time-decaying weight and a selective neighbor aggregation mechanism on the spatial domain, which helps uncover latent patterns in the graph data. In this approach, a top-k neighbor selection based on the edge weights is introduced to represent the evolving features of the graph data. We evaluated the performance of our TempoKGAT on multiple datasets from the traffic, energy, and health sectors involving spatio-temporal data. We compared the performance of our approach to several state-of-the-art methods found in the literature on several open-source datasets. Our method shows superior accuracy on all datasets. These results indicate that TempoKGAT builds on existing methodologies to optimize prediction accuracy and provide new insights into model interpretation in temporal contexts.","sentences":["Graph neural networks (GNN) have shown significant capabilities in handling structured data, yet their application to dynamic, temporal data remains limited.","This paper presents a new type of graph attention network, called TempoKGAT, which combines time-decaying weight and a selective neighbor aggregation mechanism on the spatial domain, which helps uncover latent patterns in the graph data.","In this approach, a top-k neighbor selection based on the edge weights is introduced to represent the evolving features of the graph data.","We evaluated the performance of our TempoKGAT on multiple datasets from the traffic, energy, and health sectors involving spatio-temporal data.","We compared the performance of our approach to several state-of-the-art methods found in the literature on several open-source datasets.","Our method shows superior accuracy on all datasets.","These results indicate that TempoKGAT builds on existing methodologies to optimize prediction accuracy and provide new insights into model interpretation in temporal contexts."],"url":"http://arxiv.org/abs/2408.16391v1"}
{"created":"2024-08-29 09:41:17","title":"TG-PhyNN: An Enhanced Physically-Aware Graph Neural Network framework for forecasting Spatio-Temporal Data","abstract":"Accurately forecasting dynamic processes on graphs, such as traffic flow or disease spread, remains a challenge. While Graph Neural Networks (GNNs) excel at modeling and forecasting spatio-temporal data, they often lack the ability to directly incorporate underlying physical laws. This work presents TG-PhyNN, a novel Temporal Graph Physics-Informed Neural Network framework. TG-PhyNN leverages the power of GNNs for graph-based modeling while simultaneously incorporating physical constraints as a guiding principle during training. This is achieved through a two-step prediction strategy that enables the calculation of physical equation derivatives within the GNN architecture. Our findings demonstrate that TG-PhyNN significantly outperforms traditional forecasting models (e.g., GRU, LSTM, GAT) on real-world spatio-temporal datasets like PedalMe (traffic flow), COVID-19 spread, and Chickenpox outbreaks. These datasets are all governed by well-defined physical principles, which TG-PhyNN effectively exploits to offer more reliable and accurate forecasts in various domains where physical processes govern the dynamics of data. This paves the way for improved forecasting in areas like traffic flow prediction, disease outbreak prediction, and potentially other fields where physics plays a crucial role.","sentences":["Accurately forecasting dynamic processes on graphs, such as traffic flow or disease spread, remains a challenge.","While Graph Neural Networks (GNNs) excel at modeling and forecasting spatio-temporal data, they often lack the ability to directly incorporate underlying physical laws.","This work presents TG-PhyNN, a novel Temporal Graph Physics-Informed Neural Network framework.","TG-PhyNN leverages the power of GNNs for graph-based modeling while simultaneously incorporating physical constraints as a guiding principle during training.","This is achieved through a two-step prediction strategy that enables the calculation of physical equation derivatives within the GNN architecture.","Our findings demonstrate that TG-PhyNN significantly outperforms traditional forecasting models (e.g., GRU, LSTM, GAT) on real-world spatio-temporal datasets like PedalMe (traffic flow), COVID-19 spread, and Chickenpox outbreaks.","These datasets are all governed by well-defined physical principles, which TG-PhyNN effectively exploits to offer more reliable and accurate forecasts in various domains where physical processes govern the dynamics of data.","This paves the way for improved forecasting in areas like traffic flow prediction, disease outbreak prediction, and potentially other fields where physics plays a crucial role."],"url":"http://arxiv.org/abs/2408.16379v1"}
{"created":"2024-08-29 09:38:04","title":"ESPARGOS: Phase-Coherent WiFi CSI Datasets for Wireless Sensing Research","abstract":"The use of WiFi signals to sense the physical environment is gaining popularity, with some common applications being motion detection and transmitter localization. Standard-compliant WiFi provides a cost effective, easy and backward-compatible approach to Joint Communication and Sensing and enables a seamless transfer of results from experiments to practical applications. However, most WiFi sensing research is conducted on channel state information (CSI) data from current-generation devices, which are usually not meant for sensing applications and thus lack sufficient spatial diversity or phase synchronization. With ESPARGOS, we previously developed a phase-coherent, real-time capable many-antenna WiFi channel sounder specifically for wireless sensing. We describe how we use ESPARGOS to capture large CSI datasets that we make publicly available. The datasets are extensively documented and labeled, for example with information from reference positioning systems, enabling data-driven and machine learning-based research.","sentences":["The use of WiFi signals to sense the physical environment is gaining popularity, with some common applications being motion detection and transmitter localization.","Standard-compliant WiFi provides a cost effective, easy and backward-compatible approach to Joint Communication and Sensing and enables a seamless transfer of results from experiments to practical applications.","However, most WiFi sensing research is conducted on channel state information (CSI) data from current-generation devices, which are usually not meant for sensing applications and thus lack sufficient spatial diversity or phase synchronization.","With ESPARGOS, we previously developed a phase-coherent, real-time capable many-antenna WiFi channel sounder specifically for wireless sensing.","We describe how we use ESPARGOS to capture large CSI datasets that we make publicly available.","The datasets are extensively documented and labeled, for example with information from reference positioning systems, enabling data-driven and machine learning-based research."],"url":"http://arxiv.org/abs/2408.16377v1"}
{"created":"2024-08-29 09:34:17","title":"EasyChauffeur: A Baseline Advancing Simplicity and Efficiency on Waymax","abstract":"Recent advancements in deep-learning-based driving planners have primarily focused on elaborate network engineering, yielding limited improvements. This paper diverges from conventional approaches by exploring three fundamental yet underinvestigated aspects: training policy, data efficiency, and evaluation robustness. We introduce EasyChauffeur, a reproducible and effective planner for both imitation learning (IL) and reinforcement learning (RL) on Waymax, a GPU-accelerated simulator. Notably, our findings indicate that the incorporation of on-policy RL significantly boosts performance and data efficiency. To further enhance this efficiency, we propose SNE-Sampling, a novel method that selectively samples data from the encoder's latent space, substantially improving EasyChauffeur's performance with RL. Additionally, we identify a deficiency in current evaluation methods, which fail to accurately assess the robustness of different planners due to significant performance drops from minor changes in the ego vehicle's initial state. In response, we propose Ego-Shifting, a new evaluation setting for assessing planners' robustness. Our findings advocate for a shift from a primary focus on network architectures to adopting a holistic approach encompassing training strategies, data efficiency, and robust evaluation methods.","sentences":["Recent advancements in deep-learning-based driving planners have primarily focused on elaborate network engineering, yielding limited improvements.","This paper diverges from conventional approaches by exploring three fundamental yet underinvestigated aspects: training policy, data efficiency, and evaluation robustness.","We introduce EasyChauffeur, a reproducible and effective planner for both imitation learning (IL) and reinforcement learning (RL) on Waymax, a GPU-accelerated simulator.","Notably, our findings indicate that the incorporation of on-policy RL significantly boosts performance and data efficiency.","To further enhance this efficiency, we propose SNE-Sampling, a novel method that selectively samples data from the encoder's latent space, substantially improving EasyChauffeur's performance with RL.","Additionally, we identify a deficiency in current evaluation methods, which fail to accurately assess the robustness of different planners due to significant performance drops from minor changes in the ego vehicle's initial state.","In response, we propose Ego-Shifting, a new evaluation setting for assessing planners' robustness.","Our findings advocate for a shift from a primary focus on network architectures to adopting a holistic approach encompassing training strategies, data efficiency, and robust evaluation methods."],"url":"http://arxiv.org/abs/2408.16375v1"}
{"created":"2024-08-29 09:28:05","title":"Efficient Multi-agent Navigation with Lightweight DRL Policy","abstract":"In this article, we present an end-to-end collision avoidance policy based on deep reinforcement learning (DRL) for multi-agent systems, demonstrating encouraging outcomes in real-world applications. In particular, our policy calculates the control commands of the agent based on the raw LiDAR observation. In addition, the number of parameters of the proposed basic model is 140,000, and the size of the parameter file is 3.5 MB, which allows the robot to calculate the actions from the CPU alone. We propose a multi-agent training platform based on a physics-based simulator to further bridge the gap between simulation and the real world. The policy is trained on a policy-gradients-based RL algorithm in a dense and messy training environment. A novel reward function is introduced to address the issue of agents choosing suboptimal actions in some common scenarios. Although the data used for training is exclusively from the simulation platform, the policy can be successfully transferred and deployed in real-world robots. Finally, our policy effectively responds to intentional obstructions and avoids collisions. The website is available at \\url{https://sites.google.com/view/xingrong2024efficient/%E9%A6%96%E9%A1%B5}.","sentences":["In this article, we present an end-to-end collision avoidance policy based on deep reinforcement learning (DRL) for multi-agent systems, demonstrating encouraging outcomes in real-world applications.","In particular, our policy calculates the control commands of the agent based on the raw LiDAR observation.","In addition, the number of parameters of the proposed basic model is 140,000, and the size of the parameter file is 3.5 MB, which allows the robot to calculate the actions from the CPU alone.","We propose a multi-agent training platform based on a physics-based simulator to further bridge the gap between simulation and the real world.","The policy is trained on a policy-gradients-based RL algorithm in a dense and messy training environment.","A novel reward function is introduced to address the issue of agents choosing suboptimal actions in some common scenarios.","Although the data used for training is exclusively from the simulation platform, the policy can be successfully transferred and deployed in real-world robots.","Finally, our policy effectively responds to intentional obstructions and avoids collisions.","The website is available at \\url{https://sites.google.com/view/xingrong2024efficient/%E9%A6%96%E9%A1%B5}."],"url":"http://arxiv.org/abs/2408.16370v1"}
{"created":"2024-08-29 08:31:26","title":"Virtual Fieldwork in Immersive Environments using Game Engines","abstract":"Fieldwork still is the first and foremost source of insight in many disciplines of the geosciences. Virtual fieldwork is an approach meant to enable scientists trained in fieldwork to apply these skills to a virtual representation of outcrops that are inaccessible to humans e.g. due to being located on the seafloor. For this purpose we develop a virtual fieldwork software in the game engine and 3D creation tool Unreal Engine. This software is developed specifically for a large, spatially immersive environment as well as virtual reality using head-mounted displays. It contains multiple options for quantitative measurements of visualized 3D model data. We visualize three distinct real-world datasets gathered by different photogrammetric and bathymetric methods as use cases and gather initial feedback from domain experts.","sentences":["Fieldwork still is the first and foremost source of insight in many disciplines of the geosciences.","Virtual fieldwork is an approach meant to enable scientists trained in fieldwork to apply these skills to a virtual representation of outcrops that are inaccessible to humans e.g. due to being located on the seafloor.","For this purpose we develop a virtual fieldwork software in the game engine and 3D creation tool Unreal Engine.","This software is developed specifically for a large, spatially immersive environment as well as virtual reality using head-mounted displays.","It contains multiple options for quantitative measurements of visualized 3D model data.","We visualize three distinct real-world datasets gathered by different photogrammetric and bathymetric methods as use cases and gather initial feedback from domain experts."],"url":"http://arxiv.org/abs/2408.16346v1"}
{"created":"2024-08-29 08:30:33","title":"The Unreasonable Ineffectiveness of Nucleus Sampling on Mitigating Text Memorization","abstract":"This work analyses the text memorization behavior of large language models (LLMs) when subjected to nucleus sampling. Stochastic decoding methods like nucleus sampling are typically applied to overcome issues such as monotonous and repetitive text generation, which are often observed with maximization-based decoding techniques. We hypothesize that nucleus sampling might also reduce the occurrence of memorization patterns, because it could lead to the selection of tokens outside the memorized sequence. To test this hypothesis we create a diagnostic dataset with a known distribution of duplicates that gives us some control over the likelihood of memorization of certain parts of the training data. Our analysis of two GPT-Neo models fine-tuned on this dataset interestingly shows that (i) an increase of the nucleus size reduces memorization only modestly, and (ii) even when models do not engage in \"hard\" memorization -- a verbatim reproduction of training samples -- they may still display \"soft\" memorization whereby they generate outputs that echo the training data but without a complete one-by-one resemblance.","sentences":["This work analyses the text memorization behavior of large language models (LLMs) when subjected to nucleus sampling.","Stochastic decoding methods like nucleus sampling are typically applied to overcome issues such as monotonous and repetitive text generation, which are often observed with maximization-based decoding techniques.","We hypothesize that nucleus sampling might also reduce the occurrence of memorization patterns, because it could lead to the selection of tokens outside the memorized sequence.","To test this hypothesis we create a diagnostic dataset with a known distribution of duplicates that gives us some control over the likelihood of memorization of certain parts of the training data.","Our analysis of two GPT-Neo models fine-tuned on this dataset interestingly shows that (i) an increase of the nucleus size reduces memorization only modestly, and (ii) even when models do not engage in \"hard\" memorization -- a verbatim reproduction of training samples -- they may still display \"soft\" memorization whereby they generate outputs that echo the training data but without a complete one-by-one resemblance."],"url":"http://arxiv.org/abs/2408.16345v1"}
{"created":"2024-08-29 08:26:00","title":"Toward Robust Early Detection of Alzheimer's Disease via an Integrated Multimodal Learning Approach","abstract":"Alzheimer's Disease (AD) is a complex neurodegenerative disorder marked by memory loss, executive dysfunction, and personality changes. Early diagnosis is challenging due to subtle symptoms and varied presentations, often leading to misdiagnosis with traditional unimodal diagnostic methods due to their limited scope. This study introduces an advanced multimodal classification model that integrates clinical, cognitive, neuroimaging, and EEG data to enhance diagnostic accuracy. The model incorporates a feature tagger with a tabular data coding architecture and utilizes the TimesBlock module to capture intricate temporal patterns in Electroencephalograms (EEG) data. By employing Cross-modal Attention Aggregation module, the model effectively fuses Magnetic Resonance Imaging (MRI) spatial information with EEG temporal data, significantly improving the distinction between AD, Mild Cognitive Impairment, and Normal Cognition. Simultaneously, we have constructed the first AD classification dataset that includes three modalities: EEG, MRI, and tabular data. Our innovative approach aims to facilitate early diagnosis and intervention, potentially slowing the progression of AD. The source code and our private ADMC dataset are available at https://github.com/JustlfC03/MSTNet.","sentences":["Alzheimer's Disease (AD) is a complex neurodegenerative disorder marked by memory loss, executive dysfunction, and personality changes.","Early diagnosis is challenging due to subtle symptoms and varied presentations, often leading to misdiagnosis with traditional unimodal diagnostic methods due to their limited scope.","This study introduces an advanced multimodal classification model that integrates clinical, cognitive, neuroimaging, and EEG data to enhance diagnostic accuracy.","The model incorporates a feature tagger with a tabular data coding architecture and utilizes the TimesBlock module to capture intricate temporal patterns in Electroencephalograms (EEG) data.","By employing Cross-modal Attention Aggregation module, the model effectively fuses Magnetic Resonance Imaging (MRI) spatial information with EEG temporal data, significantly improving the distinction between AD, Mild Cognitive Impairment, and Normal Cognition.","Simultaneously, we have constructed the first AD classification dataset that includes three modalities: EEG, MRI, and tabular data.","Our innovative approach aims to facilitate early diagnosis and intervention, potentially slowing the progression of AD.","The source code and our private ADMC dataset are available at https://github.com/JustlfC03/MSTNet."],"url":"http://arxiv.org/abs/2408.16343v1"}
{"created":"2024-08-29 08:12:18","title":"Self-Improving Diffusion Models with Synthetic Data","abstract":"The artificial intelligence (AI) world is running out of real data for training increasingly large generative models, resulting in accelerating pressure to train on synthetic data. Unfortunately, training new generative models with synthetic data from current or past generation models creates an autophagous (self-consuming) loop that degrades the quality and/or diversity of the synthetic data in what has been termed model autophagy disorder (MAD) and model collapse. Current thinking around model autophagy recommends that synthetic data is to be avoided for model training lest the system deteriorate into MADness. In this paper, we take a different tack that treats synthetic data differently from real data. Self-IMproving diffusion models with Synthetic data (SIMS) is a new training concept for diffusion models that uses self-synthesized data to provide negative guidance during the generation process to steer a model's generative process away from the non-ideal synthetic data manifold and towards the real data distribution. We demonstrate that SIMS is capable of self-improvement; it establishes new records based on the Fr\\'echet inception distance (FID) metric for CIFAR-10 and ImageNet-64 generation and achieves competitive results on FFHQ-64 and ImageNet-512. Moreover, SIMS is, to the best of our knowledge, the first prophylactic generative AI algorithm that can be iteratively trained on self-generated synthetic data without going MAD. As a bonus, SIMS can adjust a diffusion model's synthetic data distribution to match any desired in-domain target distribution to help mitigate biases and ensure fairness.","sentences":["The artificial intelligence (AI) world is running out of real data for training increasingly large generative models, resulting in accelerating pressure to train on synthetic data.","Unfortunately, training new generative models with synthetic data from current or past generation models creates an autophagous (self-consuming) loop that degrades the quality and/or diversity of the synthetic data in what has been termed model autophagy disorder (MAD) and model collapse.","Current thinking around model autophagy recommends that synthetic data is to be avoided for model training lest the system deteriorate into MADness.","In this paper, we take a different tack that treats synthetic data differently from real data.","Self-IMproving diffusion models with Synthetic data (SIMS) is a new training concept for diffusion models that uses self-synthesized data to provide negative guidance during the generation process to steer a model's generative process away from the non-ideal synthetic data manifold and towards the real data distribution.","We demonstrate that SIMS is capable of self-improvement; it establishes new records based on the Fr\\'echet inception distance (FID) metric for CIFAR-10 and ImageNet-64 generation and achieves competitive results on FFHQ-64 and ImageNet-512.","Moreover, SIMS is, to the best of our knowledge, the first prophylactic generative AI algorithm that can be iteratively trained on self-generated synthetic data without going MAD.","As a bonus, SIMS can adjust a diffusion model's synthetic data distribution to match any desired in-domain target distribution to help mitigate biases and ensure fairness."],"url":"http://arxiv.org/abs/2408.16333v1"}
{"created":"2024-08-29 08:02:09","title":"Critic-CoT: Boosting the reasoning abilities of large language model via Chain-of-thoughts Critic","abstract":"Self-critic has become an important mechanism for enhancing the reasoning performance of LLMs. However, current approaches mainly involve basic prompts without further training, which tend to be over-simplified, leading to limited accuracy.Moreover, there is a lack of in-depth investigation of the relationship between LLM's ability to criticism and its task-solving performance.To address these issues, we propose Critic-CoT, a novel framework that pushes LLMs toward System-2-like critic capability, via step-wise CoT reasoning format and distant-supervision data construction, without the need for human annotation. Experiments on GSM8K and MATH show that via filtering out invalid solutions or iterative refinement, our enhanced model boosts task-solving performance, which demonstrates the effectiveness of our method. Further, we find that training on critique and refinement alone improves the generation. We hope our work could shed light on future research on improving the reasoning and critic ability of LLMs.","sentences":["Self-critic has become an important mechanism for enhancing the reasoning performance of LLMs.","However, current approaches mainly involve basic prompts without further training, which tend to be over-simplified, leading to limited accuracy.","Moreover, there is a lack of in-depth investigation of the relationship between LLM's ability to criticism and its task-solving performance.","To address these issues, we propose Critic-CoT, a novel framework that pushes LLMs toward System-2-like critic capability, via step-wise CoT reasoning format and distant-supervision data construction, without the need for human annotation.","Experiments on GSM8K and MATH show that via filtering out invalid solutions or iterative refinement, our enhanced model boosts task-solving performance, which demonstrates the effectiveness of our method.","Further, we find that training on critique and refinement alone improves the generation.","We hope our work could shed light on future research on improving the reasoning and critic ability of LLMs."],"url":"http://arxiv.org/abs/2408.16326v1"}
{"created":"2024-08-29 07:48:55","title":"Minimising changes to audit when updating decision trees","abstract":"Interpretable models are important, but what happens when the model is updated on new training data? We propose an algorithm for updating a decision tree while minimising the number of changes to the tree that a human would need to audit. We achieve this via a greedy approach that incorporates the number of changes to the tree as part of the objective function. We compare our algorithm to existing methods and show that it sits in a sweet spot between final accuracy and number of changes to audit.","sentences":["Interpretable models are important, but what happens when the model is updated on new training data?","We propose an algorithm for updating a decision tree while minimising the number of changes to the tree that a human would need to audit.","We achieve this via a greedy approach that incorporates the number of changes to the tree as part of the objective function.","We compare our algorithm to existing methods and show that it sits in a sweet spot between final accuracy and number of changes to audit."],"url":"http://arxiv.org/abs/2408.16321v1"}
{"created":"2024-08-29 07:32:30","title":"Passenger hazard perception based on EEG signals for highly automated driving vehicles","abstract":"Enhancing the safety of autonomous vehicles is crucial, especially given recent accidents involving automated systems. As passengers in these vehicles, humans' sensory perception and decision-making can be integrated with autonomous systems to improve safety. This study explores neural mechanisms in passenger-vehicle interactions, leading to the development of a Passenger Cognitive Model (PCM) and the Passenger EEG Decoding Strategy (PEDS). Central to PEDS is a novel Convolutional Recurrent Neural Network (CRNN) that captures spatial and temporal EEG data patterns. The CRNN, combined with stacking algorithms, achieves an accuracy of $85.0\\% \\pm 3.18\\%$. Our findings highlight the predictive power of pre-event EEG data, enhancing the detection of hazardous scenarios and offering a network-driven framework for safer autonomous vehicles.","sentences":["Enhancing the safety of autonomous vehicles is crucial, especially given recent accidents involving automated systems.","As passengers in these vehicles, humans' sensory perception and decision-making can be integrated with autonomous systems to improve safety.","This study explores neural mechanisms in passenger-vehicle interactions, leading to the development of a Passenger Cognitive Model (PCM) and the Passenger EEG Decoding Strategy (PEDS).","Central to PEDS is a novel Convolutional Recurrent Neural Network (CRNN) that captures spatial and temporal EEG data patterns.","The CRNN, combined with stacking algorithms, achieves an accuracy of $85.0\\% \\pm 3.18\\%$.","Our findings highlight the predictive power of pre-event EEG data, enhancing the detection of hazardous scenarios and offering a network-driven framework for safer autonomous vehicles."],"url":"http://arxiv.org/abs/2408.16315v1"}
{"created":"2024-08-29 07:32:01","title":"ResVG: Enhancing Relation and Semantic Understanding in Multiple Instances for Visual Grounding","abstract":"Visual grounding aims to localize the object referred to in an image based on a natural language query. Although progress has been made recently, accurately localizing target objects within multiple-instance distractions (multiple objects of the same category as the target) remains a significant challenge. Existing methods demonstrate a significant performance drop when there are multiple distractions in an image, indicating an insufficient understanding of the fine-grained semantics and spatial relationships between objects. In this paper, we propose a novel approach, the Relation and Semantic-sensitive Visual Grounding (ResVG) model, to address this issue. Firstly, we enhance the model's understanding of fine-grained semantics by injecting semantic prior information derived from text queries into the model. This is achieved by leveraging text-to-image generation models to produce images representing the semantic attributes of target objects described in queries. Secondly, we tackle the lack of training samples with multiple distractions by introducing a relation-sensitive data augmentation method. This method generates additional training data by synthesizing images containing multiple objects of the same category and pseudo queries based on their spatial relationships. The proposed ReSVG model significantly improves the model's ability to comprehend both object semantics and spatial relations, leading to enhanced performance in visual grounding tasks, particularly in scenarios with multiple-instance distractions. We conduct extensive experiments to validate the effectiveness of our methods on five datasets. Code is available at https://github.com/minghangz/ResVG.","sentences":["Visual grounding aims to localize the object referred to in an image based on a natural language query.","Although progress has been made recently, accurately localizing target objects within multiple-instance distractions (multiple objects of the same category as the target) remains a significant challenge.","Existing methods demonstrate a significant performance drop when there are multiple distractions in an image, indicating an insufficient understanding of the fine-grained semantics and spatial relationships between objects.","In this paper, we propose a novel approach, the Relation and Semantic-sensitive Visual Grounding (ResVG) model, to address this issue.","Firstly, we enhance the model's understanding of fine-grained semantics by injecting semantic prior information derived from text queries into the model.","This is achieved by leveraging text-to-image generation models to produce images representing the semantic attributes of target objects described in queries.","Secondly, we tackle the lack of training samples with multiple distractions by introducing a relation-sensitive data augmentation method.","This method generates additional training data by synthesizing images containing multiple objects of the same category and pseudo queries based on their spatial relationships.","The proposed ReSVG model significantly improves the model's ability to comprehend both object semantics and spatial relations, leading to enhanced performance in visual grounding tasks, particularly in scenarios with multiple-instance distractions.","We conduct extensive experiments to validate the effectiveness of our methods on five datasets.","Code is available at https://github.com/minghangz/ResVG."],"url":"http://arxiv.org/abs/2408.16314v1"}
{"created":"2024-08-29 07:22:16","title":"FA-YOLO: Research On Efficient Feature Selection YOLO Improved Algorithm Based On FMDS and AGMF Modules","abstract":"Over the past few years, the YOLO series of models has emerged as one of the dominant methodologies in the realm of object detection. Many studies have advanced these baseline models by modifying their architectures, enhancing data quality, and developing new loss functions. However, current models still exhibit deficiencies in processing feature maps, such as overlooking the fusion of cross-scale features and a static fusion approach that lacks the capability for dynamic feature adjustment. To address these issues, this paper introduces an efficient Fine-grained Multi-scale Dynamic Selection Module (FMDS Module), which applies a more effective dynamic feature selection and fusion method on fine-grained multi-scale feature maps, significantly enhancing the detection accuracy of small, medium, and large-sized targets in complex environments. Furthermore, this paper proposes an Adaptive Gated Multi-branch Focus Fusion Module (AGMF Module), which utilizes multiple parallel branches to perform complementary fusion of various features captured by the gated unit branch, FMDS Module branch, and TripletAttention branch. This approach further enhances the comprehensiveness, diversity, and integrity of feature fusion. This paper has integrated the FMDS Module, AGMF Module, into Yolov9 to develop a novel object detection model named FA-YOLO. Extensive experimental results show that under identical experimental conditions, FA-YOLO achieves an outstanding 66.1% mean Average Precision (mAP) on the PASCAL VOC 2007 dataset, representing 1.0% improvement over YOLOv9's 65.1%. Additionally, the detection accuracies of FA-YOLO for small, medium, and large targets are 44.1%, 54.6%, and 70.8%, respectively, showing improvements of 2.0%, 3.1%, and 0.9% compared to YOLOv9's 42.1%, 51.5%, and 69.9%.","sentences":["Over the past few years, the YOLO series of models has emerged as one of the dominant methodologies in the realm of object detection.","Many studies have advanced these baseline models by modifying their architectures, enhancing data quality, and developing new loss functions.","However, current models still exhibit deficiencies in processing feature maps, such as overlooking the fusion of cross-scale features and a static fusion approach that lacks the capability for dynamic feature adjustment.","To address these issues, this paper introduces an efficient Fine-grained Multi-scale Dynamic Selection Module (FMDS Module), which applies a more effective dynamic feature selection and fusion method on fine-grained multi-scale feature maps, significantly enhancing the detection accuracy of small, medium, and large-sized targets in complex environments.","Furthermore, this paper proposes an Adaptive Gated Multi-branch Focus Fusion Module (AGMF Module), which utilizes multiple parallel branches to perform complementary fusion of various features captured by the gated unit branch, FMDS Module branch, and TripletAttention branch.","This approach further enhances the comprehensiveness, diversity, and integrity of feature fusion.","This paper has integrated the FMDS Module, AGMF Module, into Yolov9 to develop a novel object detection model named FA-YOLO.","Extensive experimental results show that under identical experimental conditions, FA-YOLO achieves an outstanding 66.1% mean Average Precision (mAP) on the PASCAL VOC 2007 dataset, representing 1.0% improvement over YOLOv9's 65.1%.","Additionally, the detection accuracies of FA-YOLO for small, medium, and large targets are 44.1%, 54.6%, and 70.8%, respectively, showing improvements of 2.0%, 3.1%, and 0.9% compared to YOLOv9's 42.1%, 51.5%, and 69.9%."],"url":"http://arxiv.org/abs/2408.16313v1"}
{"created":"2024-08-29 07:16:28","title":"Bootstrap Segmentation Foundation Model under Distribution Shift via Object-Centric Learning","abstract":"Foundation models have made incredible strides in achieving zero-shot or few-shot generalization, leveraging prompt engineering to mimic the problem-solving approach of human intelligence. However, when it comes to some foundation models like Segment Anything, there is still a challenge in performing well on out-of-distribution data, including camouflaged and medical images. Inconsistent prompting strategies during fine-tuning and testing further compound the issue, leading to decreased performance. Drawing inspiration from how human cognition processes new environments, we introduce SlotSAM, a method that reconstructs features from the encoder in a self-supervised manner to create object-centric representations. These representations are then integrated into the foundation model, bolstering its object-level perceptual capabilities while reducing the impact of distribution-related variables. The beauty of SlotSAM lies in its simplicity and adaptability to various tasks, making it a versatile solution that significantly enhances the generalization abilities of foundation models. Through limited parameter fine-tuning in a bootstrap manner, our approach paves the way for improved generalization in novel environments. The code is available at github.com/lytang63/SlotSAM.","sentences":["Foundation models have made incredible strides in achieving zero-shot or few-shot generalization, leveraging prompt engineering to mimic the problem-solving approach of human intelligence.","However, when it comes to some foundation models like Segment Anything, there is still a challenge in performing well on out-of-distribution data, including camouflaged and medical images.","Inconsistent prompting strategies during fine-tuning and testing further compound the issue, leading to decreased performance.","Drawing inspiration from how human cognition processes new environments, we introduce SlotSAM, a method that reconstructs features from the encoder in a self-supervised manner to create object-centric representations.","These representations are then integrated into the foundation model, bolstering its object-level perceptual capabilities while reducing the impact of distribution-related variables.","The beauty of SlotSAM lies in its simplicity and adaptability to various tasks, making it a versatile solution that significantly enhances the generalization abilities of foundation models.","Through limited parameter fine-tuning in a bootstrap manner, our approach paves the way for improved generalization in novel environments.","The code is available at github.com/lytang63/SlotSAM."],"url":"http://arxiv.org/abs/2408.16310v1"}
{"created":"2024-08-29 07:12:37","title":"Safe Bayesian Optimization for High-Dimensional Control Systems via Additive Gaussian Processes","abstract":"Controller tuning and optimization have been among the most fundamental problems in robotics and mechatronic systems. The traditional methodology is usually model-based, but its performance heavily relies on an accurate mathematical model of the system. In control applications with complex dynamics, obtaining a precise model is often challenging, leading us towards a data-driven approach. While optimizing a single controller has been explored by various researchers, it remains a challenge to obtain the optimal controller parameters safely and efficiently when multiple controllers are involved. In this paper, we propose a high-dimensional safe Bayesian optimization method based on additive Gaussian processes to optimize multiple controllers simultaneously and safely. Additive Gaussian kernels replace the traditional squared-exponential kernels or Mat\\'ern kernels, enhancing the efficiency with which Gaussian processes update information on unknown functions. Experimental results on a permanent magnet synchronous motor (PMSM) demonstrate that compared to existing safe Bayesian optimization algorithms, our method can obtain optimal parameters more efficiently while ensuring safety.","sentences":["Controller tuning and optimization have been among the most fundamental problems in robotics and mechatronic systems.","The traditional methodology is usually model-based, but its performance heavily relies on an accurate mathematical model of the system.","In control applications with complex dynamics, obtaining a precise model is often challenging, leading us towards a data-driven approach.","While optimizing a single controller has been explored by various researchers, it remains a challenge to obtain the optimal controller parameters safely and efficiently when multiple controllers are involved.","In this paper, we propose a high-dimensional safe Bayesian optimization method based on additive Gaussian processes to optimize multiple controllers simultaneously and safely.","Additive Gaussian kernels replace the traditional squared-exponential kernels or Mat\\'ern kernels, enhancing the efficiency with which Gaussian processes update information on unknown functions.","Experimental results on a permanent magnet synchronous motor (PMSM) demonstrate that compared to existing safe Bayesian optimization algorithms, our method can obtain optimal parameters more efficiently while ensuring safety."],"url":"http://arxiv.org/abs/2408.16307v1"}
{"created":"2024-08-29 07:11:09","title":"Understanding Privacy Norms through Web Forms","abstract":"Web forms are one of the primary ways to collect personal information online, yet they are relatively under-studied. Unlike web tracking, data collection through web forms is explicit and contextualized. Users (i) are asked to input specific personal information types, and (ii) know the specific context (i.e., on which website and for what purpose). For web forms to be trusted by users, they must meet the common sense standards of appropriate data collection practices within a particular context (i.e., privacy norms). In this paper, we extract the privacy norms embedded within web forms through a measurement study. First, we build a specialized crawler to discover web forms on websites. We run it on 11,500 popular websites, and we create a dataset of 293K web forms. Second, to process data of this scale, we develop a cost-efficient way to annotate web forms with form types and personal information types, using text classifiers trained with assistance of large language models (LLMs). Third, by analyzing the annotated dataset, we reveal common patterns of data collection practices. We find that (i) these patterns are explained by functional necessities and legal obligations, thus reflecting privacy norms, and that (ii) deviations from the observed norms often signal unnecessary data collection. In addition, we analyze the privacy policies that accompany web forms. We show that, despite their wide adoption and use, there is a disconnect between privacy policy disclosures and the observed privacy norms.","sentences":["Web forms are one of the primary ways to collect personal information online, yet they are relatively under-studied.","Unlike web tracking, data collection through web forms is explicit and contextualized.","Users (i) are asked to input specific personal information types, and (ii) know the specific context (i.e., on which website and for what purpose).","For web forms to be trusted by users, they must meet the common sense standards of appropriate data collection practices within a particular context (i.e., privacy norms).","In this paper, we extract the privacy norms embedded within web forms through a measurement study.","First, we build a specialized crawler to discover web forms on websites.","We run it on 11,500 popular websites, and we create a dataset of 293K web forms.","Second, to process data of this scale, we develop a cost-efficient way to annotate web forms with form types and personal information types, using text classifiers trained with assistance of large language models (LLMs).","Third, by analyzing the annotated dataset, we reveal common patterns of data collection practices.","We find that (i) these patterns are explained by functional necessities and legal obligations, thus reflecting privacy norms, and that (ii) deviations from the observed norms often signal unnecessary data collection.","In addition, we analyze the privacy policies that accompany web forms.","We show that, despite their wide adoption and use, there is a disconnect between privacy policy disclosures and the observed privacy norms."],"url":"http://arxiv.org/abs/2408.16304v1"}
{"created":"2024-08-29 06:57:45","title":"A Distance Similarity-based Genetic Optimization Algorithm for Satellite Ground Network Planning Considering Feeding Mode","abstract":"With the rapid development of the satellite industry, the information transmission network based on communication satellites has gradually become a major and important part of the future satellite ground integration network. However, the low transmission efficiency of the satellite data relay back mission has become a problem that is currently constraining the construction of the system and needs to be solved urgently. Effectively planning the task of satellite ground networking by reasonably scheduling resources is crucial for the efficient transmission of task data. In this paper, we hope to provide a task execution scheme that maximizes the profit of the networking task for satellite ground network planning considering feeding mode (SGNPFM). To solve the SGNPFM problem, a mixed-integer planning model with the objective of maximizing the gain of the link-building task is constructed, which considers various constraints of the satellite in the feed-switching mode. Based on the problem characteristics, we propose a distance similarity-based genetic optimization algorithm (DSGA), which considers the state characteristics between the tasks and introduces a weighted Euclidean distance method to determine the similarity between the tasks. To obtain more high-quality solutions, different similarity evaluation methods are designed to assist the algorithm in intelligently screening individuals. The DSGA also uses an adaptive crossover strategy based on similarity mechanism, which guides the algorithm to achieve efficient population search. In addition, a task scheduling algorithm considering the feed-switching mode is designed for decoding the algorithm to generate a high-quality scheme. The results of simulation experiments show that the DSGA can effectively solve the SGNPFM problem.","sentences":["With the rapid development of the satellite industry, the information transmission network based on communication satellites has gradually become a major and important part of the future satellite ground integration network.","However, the low transmission efficiency of the satellite data relay back mission has become a problem that is currently constraining the construction of the system and needs to be solved urgently.","Effectively planning the task of satellite ground networking by reasonably scheduling resources is crucial for the efficient transmission of task data.","In this paper, we hope to provide a task execution scheme that maximizes the profit of the networking task for satellite ground network planning considering feeding mode (SGNPFM).","To solve the SGNPFM problem, a mixed-integer planning model with the objective of maximizing the gain of the link-building task is constructed, which considers various constraints of the satellite in the feed-switching mode.","Based on the problem characteristics, we propose a distance similarity-based genetic optimization algorithm (DSGA), which considers the state characteristics between the tasks and introduces a weighted Euclidean distance method to determine the similarity between the tasks.","To obtain more high-quality solutions, different similarity evaluation methods are designed to assist the algorithm in intelligently screening individuals.","The DSGA also uses an adaptive crossover strategy based on similarity mechanism, which guides the algorithm to achieve efficient population search.","In addition, a task scheduling algorithm considering the feed-switching mode is designed for decoding the algorithm to generate a high-quality scheme.","The results of simulation experiments show that the DSGA can effectively solve the SGNPFM problem."],"url":"http://arxiv.org/abs/2408.16300v1"}
{"created":"2024-08-29 06:56:59","title":"Online Probabilistic Metric Embedding: A General Framework for Bypassing Inherent Bounds","abstract":"Probabilistic metric embedding into trees is a powerful technique for designing online algorithms. The standard approach is to embed the entire underlying metric into a tree metric and then solve the problem on the latter. The overhead in the competitive ratio depends on the expected distortion of the embedding, which is logarithmic in $n$, the size of the underlying metric. For many online applications, such as online network design problems, it is natural to ask if it is possible to construct such embeddings in an online fashion such that the distortion would be a polylogarithmic function of $k$, the number of terminals.   Our first main contribution is answering this question negatively, exhibiting a \\emph{lower bound} of $\\tilde{\\Omega}(\\log k \\log \\Phi)$, where $\\Phi$ is the aspect ratio of the set of terminals, showing that a simple modification of the probabilistic embedding into trees of Bartal (FOCS 1996), which has expected distortion of $O(\\log k \\log \\Phi)$, is \\emph{nearly-tight}. Unfortunately, this may result in a very bad dependence in terms of $k$, namely, a power of $k$.   Our second main contribution is a general framework for bypassing this limitation. We show that for a large class of online problems this online probabilistic embedding can still be used to devise an algorithm with $O(\\min\\{\\log k\\log (k\\lambda),\\log^3 k\\})$ overhead in the competitive ratio, where $k$ is the current number of terminals, and $\\lambda$ is a measure of subadditivity of the cost function, which is at most $r$, the current number of requests. In particular, this implies the first algorithms with competitive ratio $\\operatorname{polylog}(k)$ for online subadditive network design (buy-at-bulk network design being a special case), and $\\operatorname{polylog}(k,r)$ for online group Steiner forest.","sentences":["Probabilistic metric embedding into trees is a powerful technique for designing online algorithms.","The standard approach is to embed the entire underlying metric into a tree metric and then solve the problem on the latter.","The overhead in the competitive ratio depends on the expected distortion of the embedding, which is logarithmic in $n$, the size of the underlying metric.","For many online applications, such as online network design problems, it is natural to ask if it is possible to construct such embeddings in an online fashion such that the distortion would be a polylogarithmic function of $k$, the number of terminals.   ","Our first main contribution is answering this question negatively, exhibiting a \\emph{lower bound} of $\\tilde{\\Omega}(\\log k \\log \\Phi)$, where $\\Phi$ is the aspect ratio of the set of terminals, showing that a simple modification of the probabilistic embedding into trees of Bartal (FOCS 1996), which has expected distortion of $O(\\log k \\log \\Phi)$, is \\emph{nearly-tight}.","Unfortunately, this may result in a very bad dependence in terms of $k$, namely, a power of $k$.   Our second main contribution is a general framework for bypassing this limitation.","We show that for a large class of online problems this online probabilistic embedding can still be used to devise an algorithm with $O(\\min\\{\\log k\\log (k\\lambda),\\log^3 k\\})$ overhead in the competitive ratio, where $k$ is the current number of terminals, and $\\lambda$ is a measure of subadditivity of the cost function, which is at most $r$, the current number of requests.","In particular, this implies the first algorithms with competitive ratio $\\operatorname{polylog}(k)$ for online subadditive network design (buy-at-bulk network design being a special case), and $\\operatorname{polylog}(k,r)$ for online group Steiner forest."],"url":"http://arxiv.org/abs/2408.16298v1"}
{"created":"2024-08-29 06:54:03","title":"Rethinking Sparse Lexical Representations for Image Retrieval in the Age of Rising Multi-Modal Large Language Models","abstract":"In this paper, we rethink sparse lexical representations for image retrieval. By utilizing multi-modal large language models (M-LLMs) that support visual prompting, we can extract image features and convert them into textual data, enabling us to utilize efficient sparse retrieval algorithms employed in natural language processing for image retrieval tasks. To assist the LLM in extracting image features, we apply data augmentation techniques for key expansion and analyze the impact with a metric for relevance between images and textual data. We empirically show the superior precision and recall performance of our image retrieval method compared to conventional vision-language model-based methods on the MS-COCO, PASCAL VOC, and NUS-WIDE datasets in a keyword-based image retrieval scenario, where keywords serve as search queries. We also demonstrate that the retrieval performance can be improved by iteratively incorporating keywords into search queries.","sentences":["In this paper, we rethink sparse lexical representations for image retrieval.","By utilizing multi-modal large language models (M-LLMs) that support visual prompting, we can extract image features and convert them into textual data, enabling us to utilize efficient sparse retrieval algorithms employed in natural language processing for image retrieval tasks.","To assist the LLM in extracting image features, we apply data augmentation techniques for key expansion and analyze the impact with a metric for relevance between images and textual data.","We empirically show the superior precision and recall performance of our image retrieval method compared to conventional vision-language model-based methods on the MS-COCO, PASCAL VOC, and NUS-WIDE datasets in a keyword-based image retrieval scenario, where keywords serve as search queries.","We also demonstrate that the retrieval performance can be improved by iteratively incorporating keywords into search queries."],"url":"http://arxiv.org/abs/2408.16296v1"}
{"created":"2024-08-29 06:49:20","title":"Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems","abstract":"Language models have demonstrated remarkable performance in solving reasoning tasks; however, even the strongest models still occasionally make reasoning mistakes. Recently, there has been active research aimed at improving reasoning accuracy, particularly by using pretrained language models to \"self-correct\" their mistakes via multi-round prompting. In this paper, we follow this line of work but focus on understanding the usefulness of incorporating \"error-correction\" data directly into the pretraining stage. This data consists of erroneous solution steps immediately followed by their corrections. Using a synthetic math dataset, we show promising results: this type of pretrain data can help language models achieve higher reasoning accuracy directly (i.e., through simple auto-regression, without multi-round prompting) compared to pretraining on the same amount of error-free data. We also delve into many details, such as (1) how this approach differs from beam search, (2) how such data can be prepared, (3) whether masking is needed on the erroneous tokens, (4) the amount of error required, (5) whether such data can be deferred to the fine-tuning stage, and many others.","sentences":["Language models have demonstrated remarkable performance in solving reasoning tasks; however, even the strongest models still occasionally make reasoning mistakes.","Recently, there has been active research aimed at improving reasoning accuracy, particularly by using pretrained language models to \"self-correct\" their mistakes via multi-round prompting.","In this paper, we follow this line of work but focus on understanding the usefulness of incorporating \"error-correction\" data directly into the pretraining stage.","This data consists of erroneous solution steps immediately followed by their corrections.","Using a synthetic math dataset, we show promising results: this type of pretrain data can help language models achieve higher reasoning accuracy directly (i.e., through simple auto-regression, without multi-round prompting) compared to pretraining on the same amount of error-free data.","We also delve into many details, such as (1) how this approach differs from beam search, (2) how such data can be prepared, (3) whether masking is needed on the erroneous tokens, (4) the amount of error required, (5) whether such data can be deferred to the fine-tuning stage, and many others."],"url":"http://arxiv.org/abs/2408.16293v1"}
{"created":"2024-08-29 06:48:07","title":"Flexible framework for generating synthetic electrocardiograms and photoplethysmograms","abstract":"By generating synthetic biosignals, the quantity and variety of health data can be increased. This is especially useful when training machine learning models by enabling data augmentation and introduction of more physiologically plausible variation to the data. For these purposes, we have developed a synthetic biosignal model for two signal modalities, electrocardiography (ECG) and photoplethysmography (PPG). The model produces realistic signals that account for physiological effects such as breathing modulation and changes in heart rate due to physical stress. Arrhythmic signals can be generated with beat intervals extracted from real measurements. The model also includes a flexible approach to adding different kinds of noise and signal artifacts. The noise is generated from power spectral densities extracted from both measured noisy signals and modeled power spectra. Importantly, the model also automatically produces labels for noise, segmentation (e.g. P and T waves, QRS complex, for electrocardiograms), and artifacts. We assessed how this comprehensive model can be used in practice to improve the performance of models trained on ECG or PPG data. For example, we trained an LSTM to detect ECG R-peaks using both real ECG signals from the MIT-BIH arrythmia set and our new generator. The F1 score of the model was 0.83 using real data, in comparison to 0.98 using our generator. In addition, the model can be used for example in signal segmentation, quality detection and bench-marking detection algorithms. The model code has been released in \\url{https://github.com/UTU-Health-Research/framework_for_synthetic_biosignals}","sentences":["By generating synthetic biosignals, the quantity and variety of health data can be increased.","This is especially useful when training machine learning models by enabling data augmentation and introduction of more physiologically plausible variation to the data.","For these purposes, we have developed a synthetic biosignal model for two signal modalities, electrocardiography (ECG) and photoplethysmography (PPG).","The model produces realistic signals that account for physiological effects such as breathing modulation and changes in heart rate due to physical stress.","Arrhythmic signals can be generated with beat intervals extracted from real measurements.","The model also includes a flexible approach to adding different kinds of noise and signal artifacts.","The noise is generated from power spectral densities extracted from both measured noisy signals and modeled power spectra.","Importantly, the model also automatically produces labels for noise, segmentation (e.g. P and T waves, QRS complex, for electrocardiograms), and artifacts.","We assessed how this comprehensive model can be used in practice to improve the performance of models trained on ECG or PPG data.","For example, we trained an LSTM to detect ECG R-peaks using both real ECG signals from the MIT-BIH arrythmia set and our new generator.","The F1 score of the model was 0.83 using real data, in comparison to 0.98 using our generator.","In addition, the model can be used for example in signal segmentation, quality detection and bench-marking detection algorithms.","The model code has been released in \\url{https://github.com/UTU-Health-Research/framework_for_synthetic_biosignals}"],"url":"http://arxiv.org/abs/2408.16291v1"}
{"created":"2024-08-29 06:40:01","title":"OpenFGL: A Comprehensive Benchmarks for Federated Graph Learning","abstract":"Federated graph learning (FGL) has emerged as a promising distributed training paradigm for graph neural networks across multiple local systems without direct data sharing. This approach is particularly beneficial in privacy-sensitive scenarios and offers a new perspective on addressing scalability challenges in large-scale graph learning. Despite the proliferation of FGL, the diverse motivations from practical applications, spanning various research backgrounds and experimental settings, pose a significant challenge to fair evaluation. To fill this gap, we propose OpenFGL, a unified benchmark designed for the primary FGL scenarios: Graph-FL and Subgraph-FL. Specifically, OpenFGL includes 38 graph datasets from 16 application domains, 8 federated data simulation strategies that emphasize graph properties, and 5 graph-based downstream tasks. Additionally, it offers 18 recently proposed SOTA FGL algorithms through a user-friendly API, enabling a thorough comparison and comprehensive evaluation of their effectiveness, robustness, and efficiency. Empirical results demonstrate the ability of FGL while also revealing its potential limitations, offering valuable insights for future exploration in this thriving field.","sentences":["Federated graph learning (FGL) has emerged as a promising distributed training paradigm for graph neural networks across multiple local systems without direct data sharing.","This approach is particularly beneficial in privacy-sensitive scenarios and offers a new perspective on addressing scalability challenges in large-scale graph learning.","Despite the proliferation of FGL, the diverse motivations from practical applications, spanning various research backgrounds and experimental settings, pose a significant challenge to fair evaluation.","To fill this gap, we propose OpenFGL, a unified benchmark designed for the primary FGL scenarios: Graph-FL and Subgraph-FL.","Specifically, OpenFGL includes 38 graph datasets from 16 application domains, 8 federated data simulation strategies that emphasize graph properties, and 5 graph-based downstream tasks.","Additionally, it offers 18 recently proposed SOTA FGL algorithms through a user-friendly API, enabling a thorough comparison and comprehensive evaluation of their effectiveness, robustness, and efficiency.","Empirical results demonstrate the ability of FGL while also revealing its potential limitations, offering valuable insights for future exploration in this thriving field."],"url":"http://arxiv.org/abs/2408.16288v1"}
{"created":"2024-08-29 06:38:55","title":"Measuring the Accuracy of Automatic Speech Recognition Solutions","abstract":"For d/Deaf and hard of hearing (DHH) people, captioning is an essential accessibility tool. Significant developments in artificial intelligence (AI) mean that Automatic Speech Recognition (ASR) is now a part of many popular applications. This makes creating captions easy and broadly available - but transcription needs high levels of accuracy to be accessible. Scientific publications and industry report very low error rates, claiming AI has reached human parity or even outperforms manual transcription. At the same time the DHH community reports serious issues with the accuracy and reliability of ASR. There seems to be a mismatch between technical innovations and the real-life experience for people who depend on transcription. Independent and comprehensive data is needed to capture the state of ASR. We measured the performance of eleven common ASR services with recordings of Higher Education lectures. We evaluated the influence of technical conditions like streaming, the use of vocabularies, and differences between languages. Our results show that accuracy ranges widely between vendors and for the individual audio samples. We also measured a significant lower quality for streaming ASR, which is used for live events. Our study shows that despite the recent improvements of ASR, common services lack reliability in accuracy.","sentences":["For d/Deaf and hard of hearing (DHH) people, captioning is an essential accessibility tool.","Significant developments in artificial intelligence (AI) mean that Automatic Speech Recognition (ASR) is now a part of many popular applications.","This makes creating captions easy and broadly available - but transcription needs high levels of accuracy to be accessible.","Scientific publications and industry report very low error rates, claiming AI has reached human parity or even outperforms manual transcription.","At the same time the DHH community reports serious issues with the accuracy and reliability of ASR.","There seems to be a mismatch between technical innovations and the real-life experience for people who depend on transcription.","Independent and comprehensive data is needed to capture the state of ASR.","We measured the performance of eleven common ASR services with recordings of Higher Education lectures.","We evaluated the influence of technical conditions like streaming, the use of vocabularies, and differences between languages.","Our results show that accuracy ranges widely between vendors and for the individual audio samples.","We also measured a significant lower quality for streaming ASR, which is used for live events.","Our study shows that despite the recent improvements of ASR, common services lack reliability in accuracy."],"url":"http://arxiv.org/abs/2408.16287v1"}
{"created":"2024-08-29 06:27:42","title":"Enhancing Customer Churn Prediction in Telecommunications: An Adaptive Ensemble Learning Approach","abstract":"Customer churn, the discontinuation of services by existing customers, poses a significant challenge to the telecommunications industry. This paper proposes a novel adaptive ensemble learning framework for highly accurate customer churn prediction. The framework integrates multiple base models, including XGBoost, LightGBM, LSTM, a Multi-Layer Perceptron (MLP) neural network, and Support Vector Machine (SVM). These models are strategically combined using a stacking ensemble method, further enhanced by meta-feature generation from base model predictions. A rigorous data preprocessing pipeline, coupled with a multi-faceted feature engineering approach, optimizes model performance. The framework is evaluated on three publicly available telecom churn datasets, demonstrating substantial accuracy improvements over state-of-the-art techniques. The research achieves a remarkable 99.28% accuracy, signifying a major advancement in churn prediction.The implications of this research for developing proactive customer retention strategies withinthe telecommunications industry are discussed.","sentences":["Customer churn, the discontinuation of services by existing customers, poses a significant challenge to the telecommunications industry.","This paper proposes a novel adaptive ensemble learning framework for highly accurate customer churn prediction.","The framework integrates multiple base models, including XGBoost, LightGBM, LSTM, a Multi-Layer Perceptron (MLP) neural network, and Support Vector Machine (SVM).","These models are strategically combined using a stacking ensemble method, further enhanced by meta-feature generation from base model predictions.","A rigorous data preprocessing pipeline, coupled with a multi-faceted feature engineering approach, optimizes model performance.","The framework is evaluated on three publicly available telecom churn datasets, demonstrating substantial accuracy improvements over state-of-the-art techniques.","The research achieves a remarkable 99.28% accuracy, signifying a major advancement in churn prediction.","The implications of this research for developing proactive customer retention strategies withinthe telecommunications industry are discussed."],"url":"http://arxiv.org/abs/2408.16284v1"}
{"created":"2024-08-29 06:18:15","title":"Double-decker: Productive Backscatter Communication Using a Single Commodity Receiver","abstract":"Backscatter communication has attracted significant attention for Internet-of-Things applications due to its ultra-low-power consumption. The state-of-the-art backscatter systems no longer require dedicated carrier generators and leverage ambient signals as carriers. However, there is an emerging challenge: most prior systems need dual receivers to capture the original and backscattered signals at the same time for tag data demodulation. This is not conducive to the widespread deployment of backscatter communication. To address this problem, we present double-decker, a novel backscatter system that only requires a single commercial device for backscatter communication. The key technology of double-decker is to divide the carrier OFDM symbols into two parts, which are pilot symbols and data symbols. Pilot symbols can be used as reference signals for tag data demodulation, thus getting rid of the dependence on the dual receiver structure. We have built an FPGA prototype and conducted extensive experiments. Empirical results show that when the excitation signal is 802.11g, double-decker achieves a tag data rate of 35.2kbps and a productive data rate of 38kbps, respectively. The communication range of double-decker is up to 28m in LOS deployment and 24m in NLOS deployment.","sentences":["Backscatter communication has attracted significant attention for Internet-of-Things applications due to its ultra-low-power consumption.","The state-of-the-art backscatter systems no longer require dedicated carrier generators and leverage ambient signals as carriers.","However, there is an emerging challenge: most prior systems need dual receivers to capture the original and backscattered signals at the same time for tag data demodulation.","This is not conducive to the widespread deployment of backscatter communication.","To address this problem, we present double-decker, a novel backscatter system that only requires a single commercial device for backscatter communication.","The key technology of double-decker is to divide the carrier OFDM symbols into two parts, which are pilot symbols and data symbols.","Pilot symbols can be used as reference signals for tag data demodulation, thus getting rid of the dependence on the dual receiver structure.","We have built an FPGA prototype and conducted extensive experiments.","Empirical results show that when the excitation signal is 802.11g, double-decker achieves a tag data rate of 35.2kbps and a productive data rate of 38kbps, respectively.","The communication range of double-decker is up to 28m in LOS deployment and 24m in NLOS deployment."],"url":"http://arxiv.org/abs/2408.16280v1"}
{"created":"2024-08-29 05:56:35","title":"Web Service QoS Prediction via Extended Canonical Polyadic-based Tensor Network","abstract":"Today, numerous web services with similar functionalities are available on the Internet. Users often evaluate the Quality of Service (QoS) to choose the best option among them. Predicting the QoS values of these web services is a significant challenge in the field of web services. A Canonical Polyadic (CP)-based tensor network model has proven to be efficient for predicting dynamic QoS data. However, current CP-based tensor network models do not consider the correlation of users and services in the low-dimensional latent feature space, thereby limiting model's prediction capability. To tackle this issue, this paper proposes an Extended Canonical polyadic-based Tensor Network (ECTN) model. It models the correlation of users and services via building a relation dimension between user feature and service feature in low-dimensional space, and then designs an extended CP decomposition structure to improve prediction accuracy. Experiments are conducted on two public dynamic QoS data, and the results show that compared with state-of-the-art QoS prediction models, the ECTN obtains higher prediction accuracy.","sentences":["Today, numerous web services with similar functionalities are available on the Internet.","Users often evaluate the Quality of Service (QoS) to choose the best option among them.","Predicting the QoS values of these web services is a significant challenge in the field of web services.","A Canonical Polyadic (CP)-based tensor network model has proven to be efficient for predicting dynamic QoS data.","However, current CP-based tensor network models do not consider the correlation of users and services in the low-dimensional latent feature space, thereby limiting model's prediction capability.","To tackle this issue, this paper proposes an Extended Canonical polyadic-based Tensor Network (ECTN) model.","It models the correlation of users and services via building a relation dimension between user feature and service feature in low-dimensional space, and then designs an extended CP decomposition structure to improve prediction accuracy.","Experiments are conducted on two public dynamic QoS data, and the results show that compared with state-of-the-art QoS prediction models, the ECTN obtains higher prediction accuracy."],"url":"http://arxiv.org/abs/2408.16278v1"}
{"created":"2024-08-29 05:33:59","title":"SAU: A Dual-Branch Network to Enhance Long-Tailed Recognition via Generative Models","abstract":"Long-tailed distributions in image recognition pose a considerable challenge due to the severe imbalance between a few dominant classes with numerous examples and many minority classes with few samples. Recently, the use of large generative models to create synthetic data for image classification has been realized, but utilizing synthetic data to address the challenge of long-tailed recognition remains relatively unexplored. In this work, we proposed the use of synthetic data as a complement to long-tailed datasets to eliminate the impact of data imbalance. To tackle this real-synthetic mixed dataset, we designed a two-branch model that contains Synthetic-Aware and Unaware branches (SAU). The core ideas are (1) a synthetic-unaware branch for classification that mixes real and synthetic data and treats all data equally without distinguishing between them. (2) A synthetic-aware branch for improving the robustness of the feature extractor by distinguishing between real and synthetic data and learning their discrepancies. Extensive experimental results demonstrate that our method can improve the accuracy of long-tailed image recognition. Notably, our approach achieves state-of-the-art Top-1 accuracy and significantly surpasses other methods on CIFAR-10-LT and CIFAR-100-LT datasets across various imbalance factors. Our code is available at https://github.com/lgX1123/gm4lt.","sentences":["Long-tailed distributions in image recognition pose a considerable challenge due to the severe imbalance between a few dominant classes with numerous examples and many minority classes with few samples.","Recently, the use of large generative models to create synthetic data for image classification has been realized, but utilizing synthetic data to address the challenge of long-tailed recognition remains relatively unexplored.","In this work, we proposed the use of synthetic data as a complement to long-tailed datasets to eliminate the impact of data imbalance.","To tackle this real-synthetic mixed dataset, we designed a two-branch model that contains Synthetic-Aware and Unaware branches (SAU).","The core ideas are (1) a synthetic-unaware branch for classification that mixes real and synthetic data and treats all data equally without distinguishing between them.","(2) A synthetic-aware branch for improving the robustness of the feature extractor by distinguishing between real and synthetic data and learning their discrepancies.","Extensive experimental results demonstrate that our method can improve the accuracy of long-tailed image recognition.","Notably, our approach achieves state-of-the-art Top-1 accuracy and significantly surpasses other methods on CIFAR-10-LT and CIFAR-100-LT datasets across various imbalance factors.","Our code is available at https://github.com/lgX1123/gm4lt."],"url":"http://arxiv.org/abs/2408.16273v1"}
{"created":"2024-08-29 05:32:03","title":"Beyond Uncertainty: Evidential Deep Learning for Robust Video Temporal Grounding","abstract":"Existing Video Temporal Grounding (VTG) models excel in accuracy but often overlook open-world challenges posed by open-vocabulary queries and untrimmed videos. This leads to unreliable predictions for noisy, corrupted, and out-of-distribution data. Adapting VTG models to dynamically estimate uncertainties based on user input can address this issue. To this end, we introduce SRAM, a robust network module that benefits from a two-stage cross-modal alignment task. More importantly, it integrates Deep Evidential Regression (DER) to explicitly and thoroughly quantify uncertainty during training, thus allowing the model to say \"I do not know\" in scenarios beyond its handling capacity. However, the direct application of traditional DER theory and its regularizer reveals structural flaws, leading to unintended constraints in VTG tasks. In response, we develop a simple yet effective Geom-regularizer that enhances the uncertainty learning framework from the ground up. To the best of our knowledge, this marks the first successful attempt of DER in VTG. Our extensive quantitative and qualitative results affirm the effectiveness, robustness, and interpretability of our modules and the uncertainty learning paradigm in VTG tasks. The code will be made available.","sentences":["Existing Video Temporal Grounding (VTG) models excel in accuracy but often overlook open-world challenges posed by open-vocabulary queries and untrimmed videos.","This leads to unreliable predictions for noisy, corrupted, and out-of-distribution data.","Adapting VTG models to dynamically estimate uncertainties based on user input can address this issue.","To this end, we introduce SRAM, a robust network module that benefits from a two-stage cross-modal alignment task.","More importantly, it integrates Deep Evidential Regression (DER) to explicitly and thoroughly quantify uncertainty during training, thus allowing the model to say \"I do not know\" in scenarios beyond its handling capacity.","However, the direct application of traditional DER theory and its regularizer reveals structural flaws, leading to unintended constraints in VTG tasks.","In response, we develop a simple yet effective Geom-regularizer that enhances the uncertainty learning framework from the ground up.","To the best of our knowledge, this marks the first successful attempt of DER in VTG.","Our extensive quantitative and qualitative results affirm the effectiveness, robustness, and interpretability of our modules and the uncertainty learning paradigm in VTG tasks.","The code will be made available."],"url":"http://arxiv.org/abs/2408.16272v1"}
{"created":"2024-08-29 05:13:01","title":"UDD: Dataset Distillation via Mining Underutilized Regions","abstract":"Dataset distillation synthesizes a small dataset such that a model trained on this set approximates the performance of the original dataset. Recent studies on dataset distillation focused primarily on the design of the optimization process, with methods such as gradient matching, feature alignment, and training trajectory matching. However, little attention has been given to the issue of underutilized regions in synthetic images. In this paper, we propose UDD, a novel approach to identify and exploit the underutilized regions to make them informative and discriminate, and thus improve the utilization of the synthetic dataset. Technically, UDD involves two underutilized regions searching policies for different conditions, i.e., response-based policy and data jittering-based policy. Compared with previous works, such two policies are utilization-sensitive, equipping with the ability to dynamically adjust the underutilized regions during the training process. Additionally, we analyze the current model optimization problem and design a category-wise feature contrastive loss, which can enhance the distinguishability of different categories and alleviate the shortcomings of the existing multi-formation methods. Experimentally, our method improves the utilization of the synthetic dataset and outperforms the state-of-the-art methods on various datasets, such as MNIST, FashionMNIST, SVHN, CIFAR-10, and CIFAR-100. For example, the improvements on CIFAR-10 and CIFAR-100 are 4.0\\% and 3.7\\% over the next best method with IPC=1, by mining the underutilized regions.","sentences":["Dataset distillation synthesizes a small dataset such that a model trained on this set approximates the performance of the original dataset.","Recent studies on dataset distillation focused primarily on the design of the optimization process, with methods such as gradient matching, feature alignment, and training trajectory matching.","However, little attention has been given to the issue of underutilized regions in synthetic images.","In this paper, we propose UDD, a novel approach to identify and exploit the underutilized regions to make them informative and discriminate, and thus improve the utilization of the synthetic dataset.","Technically, UDD involves two underutilized regions searching policies for different conditions, i.e., response-based policy and data jittering-based policy.","Compared with previous works, such two policies are utilization-sensitive, equipping with the ability to dynamically adjust the underutilized regions during the training process.","Additionally, we analyze the current model optimization problem and design a category-wise feature contrastive loss, which can enhance the distinguishability of different categories and alleviate the shortcomings of the existing multi-formation methods.","Experimentally, our method improves the utilization of the synthetic dataset and outperforms the state-of-the-art methods on various datasets, such as MNIST, FashionMNIST, SVHN, CIFAR-10, and CIFAR-100.","For example, the improvements on CIFAR-10 and CIFAR-100 are 4.0\\% and 3.7\\% over the next best method with IPC=1, by mining the underutilized regions."],"url":"http://arxiv.org/abs/2408.16268v1"}
{"created":"2024-08-29 05:05:02","title":"Improving Diffusion-based Data Augmentation with Inversion Spherical Interpolation","abstract":"Data Augmentation (DA), \\ie, synthesizing faithful and diverse samples to expand the original training set, is a prevalent and effective strategy to improve various visual recognition tasks. With the powerful image generation ability, diffusion-based DA has shown strong performance gains on different benchmarks. In this paper, we analyze today's diffusion-based DA methods, and argue that they cannot take account of both faithfulness and diversity, which are two critical keys for generating high-quality samples and boosting final classification performance. To this end, we propose a novel Diffusion-based Inversion Interpolation DA method: Diff-II. Specifically, Diff-II consists of three main steps: 1) Category concepts learning: Learning concept embeddings for each category. 2) Inversion interpolation: Calculating the inversion for each image, and conducting spherical interpolation for two randomly sampled inversions from the same category. 3) Two-stage denoising: Using different prompts to generate synthesized images in a coarse-to-fine manner. Extensive experiments on multiple image classification tasks (\\eg, few-shot, long-tailed, and out-of-distribution classification) have demonstrated its effectiveness over state-of-the-art diffusion-based DA methods.","sentences":["Data Augmentation (DA), \\ie, synthesizing faithful and diverse samples to expand the original training set, is a prevalent and effective strategy to improve various visual recognition tasks.","With the powerful image generation ability, diffusion-based DA has shown strong performance gains on different benchmarks.","In this paper, we analyze today's diffusion-based DA methods, and argue that they cannot take account of both faithfulness and diversity, which are two critical keys for generating high-quality samples and boosting final classification performance.","To this end, we propose a novel Diffusion-based Inversion Interpolation DA method: Diff-II.","Specifically, Diff-II consists of three main steps:","1) Category concepts learning:","Learning concept embeddings for each category.","2) Inversion interpolation: Calculating the inversion for each image, and conducting spherical interpolation for two randomly sampled inversions from the same category.","3) Two-stage denoising: Using different prompts to generate synthesized images in a coarse-to-fine manner.","Extensive experiments on multiple image classification tasks (\\eg, few-shot, long-tailed, and out-of-distribution classification) have demonstrated its effectiveness over state-of-the-art diffusion-based DA methods."],"url":"http://arxiv.org/abs/2408.16266v1"}
{"created":"2024-08-29 05:04:25","title":"Low Saturation Confidence Distribution-based Test-Time Adaptation for Cross-Domain Remote Sensing Image Classification","abstract":"Although the Unsupervised Domain Adaptation (UDA) method has improved the effect of remote sensing image classification tasks, most of them are still limited by access to the source domain (SD) data. Designs such as Source-free Domain Adaptation (SFDA) solve the challenge of a lack of SD data, however, they still rely on a large amount of target domain data and thus cannot achieve fast adaptations, which seriously hinders their further application in broader scenarios. The real-world applications of cross-domain remote sensing image classification require a balance of speed and accuracy at the same time. Therefore, we propose a novel and comprehensive test time adaptation (TTA) method -- Low Saturation Confidence Distribution Test Time Adaptation (LSCD-TTA), which is the first attempt to solve such scenarios through the idea of TTA. LSCD-TTA specifically considers the distribution characteristics of remote sensing images, including three main parts that concentrate on different optimization directions: First, low saturation distribution (LSD) considers the dominance of low-confidence samples during the later TTA stage. Second, weak-category cross-entropy (WCCE) increases the weight of categories that are more difficult to classify with less prior knowledge. Finally, diverse categories confidence (DIV) comprehensively considers the category diversity to alleviate the deviation of the sample distribution. By weighting the abovementioned three modules, the model can widely, quickly and accurately adapt to the target domain without much prior target distributions, repeated data access, and manual annotation. We evaluate LSCD-TTA on three remote-sensing image datasets. The experimental results show that LSCD-TTA achieves a significant gain of 4.96%-10.51% with Resnet-50 and 5.33%-12.49% with Resnet-101 in average accuracy compared to other state-of-the-art DA and TTA methods.","sentences":["Although the Unsupervised Domain Adaptation (UDA) method has improved the effect of remote sensing image classification tasks, most of them are still limited by access to the source domain (SD) data.","Designs such as Source-free Domain Adaptation (SFDA) solve the challenge of a lack of SD data, however, they still rely on a large amount of target domain data and thus cannot achieve fast adaptations, which seriously hinders their further application in broader scenarios.","The real-world applications of cross-domain remote sensing image classification require a balance of speed and accuracy at the same time.","Therefore, we propose a novel and comprehensive test time adaptation (TTA) method -- Low Saturation Confidence Distribution Test Time Adaptation (LSCD-TTA), which is the first attempt to solve such scenarios through the idea of TTA.","LSCD-TTA specifically considers the distribution characteristics of remote sensing images, including three main parts that concentrate on different optimization directions: First, low saturation distribution (LSD) considers the dominance of low-confidence samples during the later TTA stage.","Second, weak-category cross-entropy (WCCE) increases the weight of categories that are more difficult to classify with less prior knowledge.","Finally, diverse categories confidence (DIV) comprehensively considers the category diversity to alleviate the deviation of the sample distribution.","By weighting the abovementioned three modules, the model can widely, quickly and accurately adapt to the target domain without much prior target distributions, repeated data access, and manual annotation.","We evaluate LSCD-TTA on three remote-sensing image datasets.","The experimental results show that LSCD-TTA achieves a significant gain of 4.96%-10.51% with Resnet-50 and 5.33%-12.49% with Resnet-101 in average accuracy compared to other state-of-the-art DA and TTA methods."],"url":"http://arxiv.org/abs/2408.16265v1"}
{"created":"2024-08-29 04:46:49","title":"Evaluating Time-Series Training Dataset through Lens of Spectrum in Deep State Space Models","abstract":"This study investigates a method to evaluate time-series datasets in terms of the performance of deep neural networks (DNNs) with state space models (deep SSMs) trained on the dataset. SSMs have attracted attention as components inside DNNs to address time-series data. Since deep SSMs have powerful representation capacities, training datasets play a crucial role in solving a new task. However, the effectiveness of training datasets cannot be known until deep SSMs are actually trained on them. This can increase the cost of data collection for new tasks, as a trial-and-error process of data collection and time-consuming training are needed to achieve the necessary performance. To advance the practical use of deep SSMs, the metric of datasets to estimate the performance early in the training can be one key element. To this end, we introduce the concept of data evaluation methods used in system identification. In system identification of linear dynamical systems, the effectiveness of datasets is evaluated by using the spectrum of input signals. We introduce this concept to deep SSMs, which are nonlinear dynamical systems. We propose the K-spectral metric, which is the sum of the top-K spectra of signals inside deep SSMs, by focusing on the fact that each layer of a deep SSM can be regarded as a linear dynamical system. Our experiments show that the K-spectral metric has a large absolute value of the correlation coefficient with the performance and can be used to evaluate the quality of training datasets.","sentences":["This study investigates a method to evaluate time-series datasets in terms of the performance of deep neural networks (DNNs) with state space models (deep SSMs) trained on the dataset.","SSMs have attracted attention as components inside DNNs to address time-series data.","Since deep SSMs have powerful representation capacities, training datasets play a crucial role in solving a new task.","However, the effectiveness of training datasets cannot be known until deep SSMs are actually trained on them.","This can increase the cost of data collection for new tasks, as a trial-and-error process of data collection and time-consuming training are needed to achieve the necessary performance.","To advance the practical use of deep SSMs, the metric of datasets to estimate the performance early in the training can be one key element.","To this end, we introduce the concept of data evaluation methods used in system identification.","In system identification of linear dynamical systems, the effectiveness of datasets is evaluated by using the spectrum of input signals.","We introduce this concept to deep SSMs, which are nonlinear dynamical systems.","We propose the K-spectral metric, which is the sum of the top-K spectra of signals inside deep SSMs, by focusing on the fact that each layer of a deep SSM can be regarded as a linear dynamical system.","Our experiments show that the K-spectral metric has a large absolute value of the correlation coefficient with the performance and can be used to evaluate the quality of training datasets."],"url":"http://arxiv.org/abs/2408.16261v1"}
{"created":"2024-08-29 04:46:37","title":"A General Framework for Optimizing and Learning Nash Equilibrium","abstract":"One key in real-life Nash equilibrium applications is to calibrate players' cost functions. To leverage the approximation ability of neural networks, we proposed a general framework for optimizing and learning Nash equilibrium using neural networks to estimate players' cost functions. Depending on the availability of data, we propose two approaches (a) the two-stage approach: we need the data pair of players' strategy and relevant function value to first learn the players' cost functions by monotonic neural networks or graph neural networks, and then solve the Nash equilibrium with the learned neural networks; (b) the joint approach: we use the data of partial true observation of the equilibrium and contextual information (e.g., weather) to optimize and learn Nash equilibrium simultaneously. The problem is formulated as an optimization problem with equilibrium constraints and solved using a modified Backpropagation Algorithm. The proposed methods are validated in numerical experiments.","sentences":["One key in real-life Nash equilibrium applications is to calibrate players' cost functions.","To leverage the approximation ability of neural networks, we proposed a general framework for optimizing and learning Nash equilibrium using neural networks to estimate players' cost functions.","Depending on the availability of data, we propose two approaches (a) the two-stage approach: we need the data pair of players' strategy and relevant function value to first learn the players' cost functions by monotonic neural networks or graph neural networks, and then solve the Nash equilibrium with the learned neural networks; (b) the joint approach: we use the data of partial true observation of the equilibrium and contextual information (e.g., weather) to optimize and learn Nash equilibrium simultaneously.","The problem is formulated as an optimization problem with equilibrium constraints and solved using a modified Backpropagation Algorithm.","The proposed methods are validated in numerical experiments."],"url":"http://arxiv.org/abs/2408.16260v1"}
{"created":"2024-08-29 04:35:36","title":"Coalitions of AI-based Methods Predict 15-Year Risks of Breast Cancer Metastasis Using Real-World Clinical Data with AUC up to 0.9","abstract":"Breast cancer is one of the two cancers responsible for the most deaths in women, with about 42,000 deaths each year in the US. That there are over 300,000 breast cancers newly diagnosed each year suggests that only a fraction of the cancers result in mortality. Thus, most of the women undergo seemingly curative treatment for localized cancers, but a significant later succumb to metastatic disease for which current treatments are only temporizing for the vast majority. The current prognostic metrics are of little actionable value for 4 of the 5 women seemingly cured after local treatment, and many women are exposed to morbid and even mortal adjuvant therapies unnecessarily, with these adjuvant therapies reducing metastatic recurrence by only a third. Thus, there is a need for better prognostics to target aggressive treatment at those who are likely to relapse and spare those who were actually cured. While there is a plethora of molecular and tumor-marker assays in use and under-development to detect recurrence early, these are time consuming, expensive and still often un-validated as to actionable prognostic utility. A different approach would use large data techniques to determine clinical and histopathological parameters that would provide accurate prognostics using existing data. Herein, we report on machine learning, together with grid search and Bayesian Networks to develop algorithms that present a AUC of up to 0.9 in ROC analyses, using only extant data. Such algorithms could be rapidly translated to clinical management as they do not require testing beyond routine tumor evaluations.","sentences":["Breast cancer is one of the two cancers responsible for the most deaths in women, with about 42,000 deaths each year in the US.","That there are over 300,000 breast cancers newly diagnosed each year suggests that only a fraction of the cancers result in mortality.","Thus, most of the women undergo seemingly curative treatment for localized cancers, but a significant later succumb to metastatic disease for which current treatments are only temporizing for the vast majority.","The current prognostic metrics are of little actionable value for 4 of the 5 women seemingly cured after local treatment, and many women are exposed to morbid and even mortal adjuvant therapies unnecessarily, with these adjuvant therapies reducing metastatic recurrence by only a third.","Thus, there is a need for better prognostics to target aggressive treatment at those who are likely to relapse and spare those who were actually cured.","While there is a plethora of molecular and tumor-marker assays in use and under-development to detect recurrence early, these are time consuming, expensive and still often un-validated as to actionable prognostic utility.","A different approach would use large data techniques to determine clinical and histopathological parameters that would provide accurate prognostics using existing data.","Herein, we report on machine learning, together with grid search and Bayesian Networks to develop algorithms that present a AUC of up to 0.9 in ROC analyses, using only extant data.","Such algorithms could be rapidly translated to clinical management as they do not require testing beyond routine tumor evaluations."],"url":"http://arxiv.org/abs/2408.16256v1"}
{"created":"2024-08-29 04:22:35","title":"Neural Network-Assisted Hybrid Model Based Message Passing for Parametric Holographic MIMO Near Field Channel Estimation","abstract":"Holographic multiple-input and multiple-output (HMIMO) is a promising technology with the potential to achieve high energy and spectral efficiencies, enhance system capacity and diversity, etc. In this work, we address the challenge of HMIMO near field (NF) channel estimation, which is complicated by the intricate model introduced by the dyadic Green's function. Despite its complexity, the channel model is governed by a limited set of parameters. This makes parametric channel estimation highly attractive, offering substantial performance enhancements and enabling the extraction of valuable sensing parameters, such as user locations, which are particularly beneficial in mobile networks. However, the relationship between these parameters and channel gains is nonlinear and compounded by integration, making the estimation a formidable task. To tackle this problem, we propose a novel neural network (NN) assisted hybrid method. With the assistance of NNs, we first develop a novel hybrid channel model with a significantly simplified expression compared to the original one, thereby enabling parametric channel estimation. Using the readily available training data derived from the original channel model, the NNs in the hybrid channel model can be effectively trained offline. Then, building upon this hybrid channel model, we formulate the parametric channel estimation problem with a probabilistic framework and design a factor graph representation for Bayesian estimation. Leveraging the factor graph representation and unitary approximate message passing (UAMP), we develop an effective message passing-based Bayesian channel estimation algorithm. Extensive simulations demonstrate the superior performance of the proposed method.","sentences":["Holographic multiple-input and multiple-output (HMIMO) is a promising technology with the potential to achieve high energy and spectral efficiencies, enhance system capacity and diversity, etc.","In this work, we address the challenge of HMIMO near field (NF) channel estimation, which is complicated by the intricate model introduced by the dyadic Green's function.","Despite its complexity, the channel model is governed by a limited set of parameters.","This makes parametric channel estimation highly attractive, offering substantial performance enhancements and enabling the extraction of valuable sensing parameters, such as user locations, which are particularly beneficial in mobile networks.","However, the relationship between these parameters and channel gains is nonlinear and compounded by integration, making the estimation a formidable task.","To tackle this problem, we propose a novel neural network (NN) assisted hybrid method.","With the assistance of NNs, we first develop a novel hybrid channel model with a significantly simplified expression compared to the original one, thereby enabling parametric channel estimation.","Using the readily available training data derived from the original channel model, the NNs in the hybrid channel model can be effectively trained offline.","Then, building upon this hybrid channel model, we formulate the parametric channel estimation problem with a probabilistic framework and design a factor graph representation for Bayesian estimation.","Leveraging the factor graph representation and unitary approximate message passing (UAMP), we develop an effective message passing-based Bayesian channel estimation algorithm.","Extensive simulations demonstrate the superior performance of the proposed method."],"url":"http://arxiv.org/abs/2408.16251v1"}
{"created":"2024-08-29 03:58:19","title":"PACiM: A Sparsity-Centric Hybrid Compute-in-Memory Architecture via Probabilistic Approximation","abstract":"Approximate computing emerges as a promising approach to enhance the efficiency of compute-in-memory (CiM) systems in deep neural network processing. However, traditional approximate techniques often significantly trade off accuracy for power efficiency, and fail to reduce data transfer between main memory and CiM banks, which dominates power consumption. This paper introduces a novel probabilistic approximate computation (PAC) method that leverages statistical techniques to approximate multiply-and-accumulation (MAC) operations, reducing approximation error by 4X compared to existing approaches. PAC enables efficient sparsity-based computation in CiM systems by simplifying complex MAC vector computations into scalar calculations. Moreover, PAC enables sparsity encoding and eliminates the LSB activations transmission, significantly reducing data reads and writes. This sets PAC apart from traditional approximate computing techniques, minimizing not only computation power but also memory accesses by 50%, thereby boosting system-level efficiency. We developed PACiM, a sparsity-centric architecture that fully exploits sparsity to reduce bit-serial cycles by 81% and achieves a peak 8b/8b efficiency of 14.63 TOPS/W in 65 nm CMOS while maintaining high accuracy of 93.85/72.36/66.02% on CIFAR-10/CIFAR-100/ImageNet benchmarks using a ResNet-18 model, demonstrating the effectiveness of our PAC methodology.","sentences":["Approximate computing emerges as a promising approach to enhance the efficiency of compute-in-memory (CiM) systems in deep neural network processing.","However, traditional approximate techniques often significantly trade off accuracy for power efficiency, and fail to reduce data transfer between main memory and CiM banks, which dominates power consumption.","This paper introduces a novel probabilistic approximate computation (PAC) method that leverages statistical techniques to approximate multiply-and-accumulation (MAC) operations, reducing approximation error by 4X compared to existing approaches.","PAC enables efficient sparsity-based computation in CiM systems by simplifying complex MAC vector computations into scalar calculations.","Moreover, PAC enables sparsity encoding and eliminates the LSB activations transmission, significantly reducing data reads and writes.","This sets PAC apart from traditional approximate computing techniques, minimizing not only computation power but also memory accesses by 50%, thereby boosting system-level efficiency.","We developed PACiM, a sparsity-centric architecture that fully exploits sparsity to reduce bit-serial cycles by 81% and achieves a peak 8b/8b efficiency of 14.63 TOPS/W in 65 nm CMOS while maintaining high accuracy of 93.85/72.36/66.02% on CIFAR-10/CIFAR-100/ImageNet benchmarks using a ResNet-18 model, demonstrating the effectiveness of our PAC methodology."],"url":"http://arxiv.org/abs/2408.16246v1"}
{"created":"2024-08-29 03:34:39","title":"Efficient Transfer Learning Framework for Cross-Domain Click-Through Rate Prediction","abstract":"Natural content and advertisement coexist in industrial recommendation systems but differ in data distribution. Concretely, traffic related to the advertisement is considerably sparser compared to that of natural content, which motivates the development of transferring knowledge from the richer source natural content domain to the sparser advertising domain. The challenges include the inefficiencies arising from the management of extensive source data and the problem of 'catastrophic forgetting' that results from the CTR model's daily updating. To this end, we propose a novel tri-level asynchronous framework, i.e., Efficient Transfer Learning Framework for Cross-Domain Click-Through Rate Prediction (E-CDCTR), to transfer comprehensive knowledge of natural content to advertisement CTR models. This framework consists of three key components: Tiny Pre-training Model ((TPM), which trains a tiny CTR model with several basic features on long-term natural data; Complete Pre-training Model (CPM), which trains a CTR model holding network structure and input features the same as target advertisement on short-term natural data; Advertisement CTR model (A-CTR), which derives its parameter initialization from CPM together with multiple historical embeddings from TPM as extra feature and then fine-tunes on advertisement data. TPM provides richer representations of user and item for both the CPM and A-CTR, effectively alleviating the forgetting problem inherent in the daily updates. CPM further enhances the advertisement model by providing knowledgeable initialization, thereby alleviating the data sparsity challenges typically encountered by advertising CTR models. Such a tri-level cross-domain transfer learning framework offers an efficient solution to address both data sparsity and `catastrophic forgetting', yielding remarkable improvements.","sentences":["Natural content and advertisement coexist in industrial recommendation systems but differ in data distribution.","Concretely, traffic related to the advertisement is considerably sparser compared to that of natural content, which motivates the development of transferring knowledge from the richer source natural content domain to the sparser advertising domain.","The challenges include the inefficiencies arising from the management of extensive source data and the problem of 'catastrophic forgetting' that results from the CTR model's daily updating.","To this end, we propose a novel tri-level asynchronous framework, i.e., Efficient Transfer Learning Framework for Cross-Domain Click-Through Rate Prediction (E-CDCTR), to transfer comprehensive knowledge of natural content to advertisement CTR models.","This framework consists of three key components: Tiny Pre-training Model ((TPM), which trains a tiny CTR model with several basic features on long-term natural data; Complete Pre-training Model (CPM), which trains a CTR model holding network structure and input features the same as target advertisement on short-term natural data; Advertisement CTR model (A-CTR), which derives its parameter initialization from CPM together with multiple historical embeddings from TPM as extra feature and then fine-tunes on advertisement data.","TPM provides richer representations of user and item for both the CPM and A-CTR, effectively alleviating the forgetting problem inherent in the daily updates.","CPM further enhances the advertisement model by providing knowledgeable initialization, thereby alleviating the data sparsity challenges typically encountered by advertising CTR models.","Such a tri-level cross-domain transfer learning framework offers an efficient solution to address both data sparsity and `catastrophic forgetting', yielding remarkable improvements."],"url":"http://arxiv.org/abs/2408.16238v1"}
{"created":"2024-08-29 03:28:13","title":"MQRLD: A Multimodal Data Retrieval Platform with Query-aware Feature Representation and Learned Index Based on Data Lake","abstract":"Multimodal data has become a crucial element in the realm of big data analytics, driving advancements in data exploration, data mining, and empowering artificial intelligence applications. To support high-quality retrieval for these cutting-edge applications, a robust data retrieval platform should meet the requirements for transparent data storage, rich hybrid queries, effective feature representation, and high query efficiency. However, among the existing platforms, traditional schema-on-write systems, multi-model databases, vector databases, and data lakes, which are the primary options for multimodal data retrieval, are difficult to fulfill these requirements simultaneously. Therefore, there is an urgent need to develop a more versatile multimodal data retrieval platform to address these issues.   In this paper, we introduce a Multimodal Data Retrieval Platform with Query-aware Feature Representation and Learned Index based on Data Lake (MQRLD). It leverages the transparent storage capabilities of data lakes, integrates the multimodal open API to provide a unified interface that supports rich hybrid queries, introduces a query-aware multimodal data feature representation strategy to obtain effective features, and offers high-dimensional learned indexes to optimize data query. We conduct a comparative analysis of the query performance of MQRLD against other methods for rich hybrid queries. Our results underscore the superior efficiency of MQRLD in handling multimodal data retrieval tasks, demonstrating its potential to significantly improve retrieval performance in complex environments. We also clarify some potential concerns in the discussion.","sentences":["Multimodal data has become a crucial element in the realm of big data analytics, driving advancements in data exploration, data mining, and empowering artificial intelligence applications.","To support high-quality retrieval for these cutting-edge applications, a robust data retrieval platform should meet the requirements for transparent data storage, rich hybrid queries, effective feature representation, and high query efficiency.","However, among the existing platforms, traditional schema-on-write systems, multi-model databases, vector databases, and data lakes, which are the primary options for multimodal data retrieval, are difficult to fulfill these requirements simultaneously.","Therefore, there is an urgent need to develop a more versatile multimodal data retrieval platform to address these issues.   ","In this paper, we introduce a Multimodal Data Retrieval Platform with Query-aware Feature Representation and Learned Index based on Data Lake (MQRLD).","It leverages the transparent storage capabilities of data lakes, integrates the multimodal open API to provide a unified interface that supports rich hybrid queries, introduces a query-aware multimodal data feature representation strategy to obtain effective features, and offers high-dimensional learned indexes to optimize data query.","We conduct a comparative analysis of the query performance of MQRLD against other methods for rich hybrid queries.","Our results underscore the superior efficiency of MQRLD in handling multimodal data retrieval tasks, demonstrating its potential to significantly improve retrieval performance in complex environments.","We also clarify some potential concerns in the discussion."],"url":"http://arxiv.org/abs/2408.16237v1"}
{"created":"2024-08-29 03:26:14","title":"Neural Spectral Decomposition for Dataset Distillation","abstract":"In this paper, we propose Neural Spectrum Decomposition, a generic decomposition framework for dataset distillation. Unlike previous methods, we consider the entire dataset as a high-dimensional observation that is low-rank across all dimensions. We aim to discover the low-rank representation of the entire dataset and perform distillation efficiently. Toward this end, we learn a set of spectrum tensors and transformation matrices, which, through simple matrix multiplication, reconstruct the data distribution. Specifically, a spectrum tensor can be mapped back to the image space by a transformation matrix, and efficient information sharing during the distillation learning process is achieved through pairwise combinations of different spectrum vectors and transformation matrices. Furthermore, we integrate a trajectory matching optimization method guided by a real distribution. Our experimental results demonstrate that our approach achieves state-of-the-art performance on benchmarks, including CIFAR10, CIFAR100, Tiny Imagenet, and ImageNet Subset. Our code are available at \\url{https://github.com/slyang2021/NSD}.","sentences":["In this paper, we propose Neural Spectrum Decomposition, a generic decomposition framework for dataset distillation.","Unlike previous methods, we consider the entire dataset as a high-dimensional observation that is low-rank across all dimensions.","We aim to discover the low-rank representation of the entire dataset and perform distillation efficiently.","Toward this end, we learn a set of spectrum tensors and transformation matrices, which, through simple matrix multiplication, reconstruct the data distribution.","Specifically, a spectrum tensor can be mapped back to the image space by a transformation matrix, and efficient information sharing during the distillation learning process is achieved through pairwise combinations of different spectrum vectors and transformation matrices.","Furthermore, we integrate a trajectory matching optimization method guided by a real distribution.","Our experimental results demonstrate that our approach achieves state-of-the-art performance on benchmarks, including CIFAR10, CIFAR100, Tiny Imagenet, and ImageNet Subset.","Our code are available at \\url{https://github.com/slyang2021/NSD}."],"url":"http://arxiv.org/abs/2408.16236v1"}
{"created":"2024-08-29 03:23:51","title":"LMT-GP: Combined Latent Mean-Teacher and Gaussian Process for Semi-supervised Low-light Image Enhancement","abstract":"While recent low-light image enhancement (LLIE) methods have made significant advancements, they still face challenges in terms of low visual quality and weak generalization ability when applied to complex scenarios. To address these issues, we propose a semi-supervised method based on latent mean-teacher and Gaussian process, named LMT-GP. We first design a latent mean-teacher framework that integrates both labeled and unlabeled data, as well as their latent vectors, into model training. Meanwhile, we use a mean-teacher-assisted Gaussian process learning strategy to establish a connection between the latent and pseudo-latent vectors obtained from the labeled and unlabeled data. To guide the learning process, we utilize an assisted Gaussian process regression (GPR) loss function. Furthermore, we design a pseudo-label adaptation module (PAM) to ensure the reliability of the network learning. To demonstrate our method's generalization ability and effectiveness, we apply it to multiple LLIE datasets and high-level vision tasks. Experiment results demonstrate that our method achieves high generalization performance and image quality. The code is available at https://github.com/HFUT-CV/LMT-GP.","sentences":["While recent low-light image enhancement (LLIE) methods have made significant advancements, they still face challenges in terms of low visual quality and weak generalization ability when applied to complex scenarios.","To address these issues, we propose a semi-supervised method based on latent mean-teacher and Gaussian process, named LMT-GP.","We first design a latent mean-teacher framework that integrates both labeled and unlabeled data, as well as their latent vectors, into model training.","Meanwhile, we use a mean-teacher-assisted Gaussian process learning strategy to establish a connection between the latent and pseudo-latent vectors obtained from the labeled and unlabeled data.","To guide the learning process, we utilize an assisted Gaussian process regression (GPR) loss function.","Furthermore, we design a pseudo-label adaptation module (PAM) to ensure the reliability of the network learning.","To demonstrate our method's generalization ability and effectiveness, we apply it to multiple LLIE datasets and high-level vision tasks.","Experiment results demonstrate that our method achieves high generalization performance and image quality.","The code is available at https://github.com/HFUT-CV/LMT-GP."],"url":"http://arxiv.org/abs/2408.16235v1"}
{"created":"2024-08-29 02:43:20","title":"LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models","abstract":"Recent advances in large vision-language models (VLMs) typically employ vision encoders based on the Vision Transformer (ViT) architecture. The division of the images into patches by ViT results in a fragmented perception, thereby hindering the visual understanding capabilities of VLMs. In this paper, we propose an innovative enhancement to address this limitation by introducing a Scene Graph Expression (SGE) module in VLMs. This module extracts and structurally expresses the complex semantic information within images, thereby improving the foundational perception and understanding abilities of VLMs. Extensive experiments demonstrate that integrating our SGE module significantly enhances the VLM's performance in vision-language tasks, indicating its effectiveness in preserving intricate semantic details and facilitating better visual understanding. Code and data would be available.","sentences":["Recent advances in large vision-language models (VLMs) typically employ vision encoders based on the Vision Transformer (ViT) architecture.","The division of the images into patches by ViT results in a fragmented perception, thereby hindering the visual understanding capabilities of VLMs.","In this paper, we propose an innovative enhancement to address this limitation by introducing a Scene Graph Expression (SGE) module in VLMs.","This module extracts and structurally expresses the complex semantic information within images, thereby improving the foundational perception and understanding abilities of VLMs.","Extensive experiments demonstrate that integrating our SGE module significantly enhances the VLM's performance in vision-language tasks, indicating its effectiveness in preserving intricate semantic details and facilitating better visual understanding.","Code and data would be available."],"url":"http://arxiv.org/abs/2408.16224v1"}
{"created":"2024-08-29 02:25:12","title":"Training-free Video Temporal Grounding using Large-scale Pre-trained Models","abstract":"Video temporal grounding aims to identify video segments within untrimmed videos that are most relevant to a given natural language query. Existing video temporal localization models rely on specific datasets for training and have high data collection costs, but they exhibit poor generalization capability under the across-dataset and out-of-distribution (OOD) settings. In this paper, we propose a Training-Free Video Temporal Grounding (TFVTG) approach that leverages the ability of pre-trained large models. A naive baseline is to enumerate proposals in the video and use the pre-trained visual language models (VLMs) to select the best proposal according to the vision-language alignment. However, most existing VLMs are trained on image-text pairs or trimmed video clip-text pairs, making it struggle to (1) grasp the relationship and distinguish the temporal boundaries of multiple events within the same video; (2) comprehend and be sensitive to the dynamic transition of events (the transition from one event to another) in the video. To address these issues, we propose leveraging large language models (LLMs) to analyze multiple sub-events contained in the query text and analyze the temporal order and relationships between these events. Secondly, we split a sub-event into dynamic transition and static status parts and propose the dynamic and static scoring functions using VLMs to better evaluate the relevance between the event and the description. Finally, for each sub-event description, we use VLMs to locate the top-k proposals and leverage the order and relationships between sub-events provided by LLMs to filter and integrate these proposals. Our method achieves the best performance on zero-shot video temporal grounding on Charades-STA and ActivityNet Captions datasets without any training and demonstrates better generalization capabilities in cross-dataset and OOD settings.","sentences":["Video temporal grounding aims to identify video segments within untrimmed videos that are most relevant to a given natural language query.","Existing video temporal localization models rely on specific datasets for training and have high data collection costs, but they exhibit poor generalization capability under the across-dataset and out-of-distribution (OOD) settings.","In this paper, we propose a Training-Free Video Temporal Grounding (TFVTG) approach that leverages the ability of pre-trained large models.","A naive baseline is to enumerate proposals in the video and use the pre-trained visual language models (VLMs) to select the best proposal according to the vision-language alignment.","However, most existing VLMs are trained on image-text pairs or trimmed video clip-text pairs, making it struggle to (1) grasp the relationship and distinguish the temporal boundaries of multiple events within the same video; (2) comprehend and be sensitive to the dynamic transition of events (the transition from one event to another) in the video.","To address these issues, we propose leveraging large language models (LLMs) to analyze multiple sub-events contained in the query text and analyze the temporal order and relationships between these events.","Secondly, we split a sub-event into dynamic transition and static status parts and propose the dynamic and static scoring functions using VLMs to better evaluate the relevance between the event and the description.","Finally, for each sub-event description, we use VLMs to locate the top-k proposals and leverage the order and relationships between sub-events provided by LLMs to filter and integrate these proposals.","Our method achieves the best performance on zero-shot video temporal grounding on Charades-STA and ActivityNet Captions datasets without any training and demonstrates better generalization capabilities in cross-dataset and OOD settings."],"url":"http://arxiv.org/abs/2408.16219v1"}
{"created":"2024-08-29 02:21:11","title":"Targeted Cause Discovery with Data-Driven Learning","abstract":"We propose a novel machine learning approach for inferring causal variables of a target variable from observations. Our goal is to identify both direct and indirect causes within a system, thereby efficiently regulating the target variable when the difficulty and cost of intervening on each causal variable vary. Our method employs a neural network trained to identify causality through supervised learning on simulated data. By implementing a local-inference strategy, we achieve linear complexity with respect to the number of variables, efficiently scaling up to thousands of variables. Empirical results demonstrate the effectiveness of our method in identifying causal relationships within large-scale gene regulatory networks, outperforming existing causal discovery methods that primarily focus on direct causality. We validate our model's generalization capability across novel graph structures and generating mechanisms, including gene regulatory networks of E. coli and the human K562 cell line. Implementation codes are available at https://github.com/snu-mllab/Targeted-Cause-Discovery.","sentences":["We propose a novel machine learning approach for inferring causal variables of a target variable from observations.","Our goal is to identify both direct and indirect causes within a system, thereby efficiently regulating the target variable when the difficulty and cost of intervening on each causal variable vary.","Our method employs a neural network trained to identify causality through supervised learning on simulated data.","By implementing a local-inference strategy, we achieve linear complexity with respect to the number of variables, efficiently scaling up to thousands of variables.","Empirical results demonstrate the effectiveness of our method in identifying causal relationships within large-scale gene regulatory networks, outperforming existing causal discovery methods that primarily focus on direct causality.","We validate our model's generalization capability across novel graph structures and generating mechanisms, including gene regulatory networks of E. coli and the human K562 cell line.","Implementation codes are available at https://github.com/snu-mllab/Targeted-Cause-Discovery."],"url":"http://arxiv.org/abs/2408.16218v1"}
{"created":"2024-08-29 02:05:39","title":"From cart to truck: meaning shift through words in English in the last two centuries","abstract":"This onomasiological study uses diachronic word embeddings to explore how different words represented the same concepts over time, using historical word data from 1800 to 2000. We identify shifts in energy, transport, entertainment, and computing domains, revealing connections between language and societal changes.   Our approach consisted in using diachronic word embeddings trained using word2vec with skipgram and aligning them using orthogonal Procrustes. We discuss possible difficulties linked to the relationships the method identifies. Moreover, we look at the ethical aspects of interpreting results, highlighting the need for expert insights to understand the method's significance.","sentences":["This onomasiological study uses diachronic word embeddings to explore how different words represented the same concepts over time, using historical word data from 1800 to 2000.","We identify shifts in energy, transport, entertainment, and computing domains, revealing connections between language and societal changes.   ","Our approach consisted in using diachronic word embeddings trained using word2vec with skipgram and aligning them using orthogonal Procrustes.","We discuss possible difficulties linked to the relationships the method identifies.","Moreover, we look at the ethical aspects of interpreting results, highlighting the need for expert insights to understand the method's significance."],"url":"http://arxiv.org/abs/2408.16209v1"}
{"created":"2024-08-29 01:57:57","title":"RMMI: Enhanced Obstacle Avoidance for Reactive Mobile Manipulation using an Implicit Neural Map","abstract":"We introduce RMMI, a novel reactive control framework for mobile manipulators operating in complex, static environments. Our approach leverages a neural Signed Distance Field (SDF) to model intricate environment details and incorporates this representation as inequality constraints within a Quadratic Program (QP) to coordinate robot joint and base motion. A key contribution is the introduction of an active collision avoidance cost term that maximises the total robot distance to obstacles during the motion. We first evaluate our approach in a simulated reaching task, outperforming previous methods that rely on representing both the robot and the scene as a set of primitive geometries. Compared with the baseline, we improved the task success rate by 25% in total, which includes increases of 10% by using the active collision cost. We also demonstrate our approach on a real-world platform, showing its effectiveness in reaching target poses in cluttered and confined spaces using environment models built directly from sensor data. For additional details and experiment videos, visit https://rmmi.github.io/.","sentences":["We introduce RMMI, a novel reactive control framework for mobile manipulators operating in complex, static environments.","Our approach leverages a neural Signed Distance Field (SDF) to model intricate environment details and incorporates this representation as inequality constraints within a Quadratic Program (QP) to coordinate robot joint and base motion.","A key contribution is the introduction of an active collision avoidance cost term that maximises the total robot distance to obstacles during the motion.","We first evaluate our approach in a simulated reaching task, outperforming previous methods that rely on representing both the robot and the scene as a set of primitive geometries.","Compared with the baseline, we improved the task success rate by 25% in total, which includes increases of 10% by using the active collision cost.","We also demonstrate our approach on a real-world platform, showing its effectiveness in reaching target poses in cluttered and confined spaces using environment models built directly from sensor data.","For additional details and experiment videos, visit https://rmmi.github.io/."],"url":"http://arxiv.org/abs/2408.16206v1"}
{"created":"2024-08-29 01:50:13","title":"Revisit Micro-batch Clipping: Adaptive Data Pruning via Gradient Manipulation","abstract":"Micro-batch clipping, a gradient clipping method, has recently shown potential in enhancing auto-speech recognition (ASR) model performance. However, the underlying mechanism behind this improvement remains mysterious, particularly the observation that only certain micro-batch sizes are beneficial. In this paper, we make the first attempt to explain this phenomenon. Inspired by recent data pruning research, we assume that specific training samples may impede model convergence during certain training phases. Under this assumption, the convergence analysis shows that micro-batch clipping can improve the convergence rate asymptotically at the cost of an additional constant bias that does not diminish with more training iterations. The bias is dependent on a few factors and can be minimized at specific micro-batch size, thereby elucidating the existence of the sweet-spot micro-batch size observed previously. We also verify the effectiveness of micro-batch clipping beyond speech models on vision and language models, and show promising performance gains in these domains. An exploration of potential limitations shows that micro-batch clipping is less effective when training data originates from multiple distinct domains.","sentences":["Micro-batch clipping, a gradient clipping method, has recently shown potential in enhancing auto-speech recognition (ASR) model performance.","However, the underlying mechanism behind this improvement remains mysterious, particularly the observation that only certain micro-batch sizes are beneficial.","In this paper, we make the first attempt to explain this phenomenon.","Inspired by recent data pruning research, we assume that specific training samples may impede model convergence during certain training phases.","Under this assumption, the convergence analysis shows that micro-batch clipping can improve the convergence rate asymptotically at the cost of an additional constant bias that does not diminish with more training iterations.","The bias is dependent on a few factors and can be minimized at specific micro-batch size, thereby elucidating the existence of the sweet-spot micro-batch size observed previously.","We also verify the effectiveness of micro-batch clipping beyond speech models on vision and language models, and show promising performance gains in these domains.","An exploration of potential limitations shows that micro-batch clipping is less effective when training data originates from multiple distinct domains."],"url":"http://arxiv.org/abs/2408.16204v1"}
{"created":"2024-08-29 01:47:09","title":"Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey","abstract":"Short-Term Electricity-Load Forecasting (STELF) refers to the prediction of the immediate demand (in the next few hours to several days) for the power system. Various external factors, such as weather changes and the emergence of new electricity consumption scenarios, can impact electricity demand, causing load data to fluctuate and become non-linear, which increases the complexity and difficulty of STELF. In the past decade, deep learning has been applied to STELF, modeling and predicting electricity demand with high accuracy, and contributing significantly to the development of STELF. This paper provides a comprehensive survey on deep-learning-based STELF over the past ten years. It examines the entire forecasting process, including data pre-processing, feature extraction, deep-learning modeling and optimization, and results evaluation. This paper also identifies some research challenges and potential research directions to be further investigated in future work.","sentences":["Short-Term Electricity-Load Forecasting (STELF) refers to the prediction of the immediate demand (in the next few hours to several days) for the power system.","Various external factors, such as weather changes and the emergence of new electricity consumption scenarios, can impact electricity demand, causing load data to fluctuate and become non-linear, which increases the complexity and difficulty of STELF.","In the past decade, deep learning has been applied to STELF, modeling and predicting electricity demand with high accuracy, and contributing significantly to the development of STELF.","This paper provides a comprehensive survey on deep-learning-based STELF over the past ten years.","It examines the entire forecasting process, including data pre-processing, feature extraction, deep-learning modeling and optimization, and results evaluation.","This paper also identifies some research challenges and potential research directions to be further investigated in future work."],"url":"http://arxiv.org/abs/2408.16202v1"}
{"created":"2024-08-29 01:46:37","title":"Uni-3DAD: GAN-Inversion Aided Universal 3D Anomaly Detection on Model-free Products","abstract":"Anomaly detection is a long-standing challenge in manufacturing systems. Traditionally, anomaly detection has relied on human inspectors. However, 3D point clouds have gained attention due to their robustness to environmental factors and their ability to represent geometric data. Existing 3D anomaly detection methods generally fall into two categories. One compares scanned 3D point clouds with design files, assuming these files are always available. However, such assumptions are often violated in many real-world applications where model-free products exist, such as fresh produce (i.e., ``Cookie\", ``Potato\", etc.), dentures, bone, etc. The other category compares patches of scanned 3D point clouds with a library of normal patches named memory bank. However, those methods usually fail to detect incomplete shapes, which is a fairly common defect type (i.e., missing pieces of different products). The main challenge is that missing areas in 3D point clouds represent the absence of scanned points. This makes it infeasible to compare the missing region with existing point cloud patches in the memory bank. To address these two challenges, we proposed a unified, unsupervised 3D anomaly detection framework capable of identifying all types of defects on model-free products. Our method integrates two detection modules: a feature-based detection module and a reconstruction-based detection module. Feature-based detection covers geometric defects, such as dents, holes, and cracks, while the reconstruction-based method detects missing regions. Additionally, we employ a One-class Support Vector Machine (OCSVM) to fuse the detection results from both modules. The results demonstrate that (1) our proposed method outperforms the state-of-the-art methods in identifying incomplete shapes and (2) it still maintains comparable performance with the SOTA methods in detecting all other types of anomalies.","sentences":["Anomaly detection is a long-standing challenge in manufacturing systems.","Traditionally, anomaly detection has relied on human inspectors.","However, 3D point clouds have gained attention due to their robustness to environmental factors and their ability to represent geometric data.","Existing 3D anomaly detection methods generally fall into two categories.","One compares scanned 3D point clouds with design files, assuming these files are always available.","However, such assumptions are often violated in many real-world applications where model-free products exist, such as fresh produce (i.e., ``Cookie\", ``Potato\", etc.), dentures, bone, etc.","The other category compares patches of scanned 3D point clouds with a library of normal patches named memory bank.","However, those methods usually fail to detect incomplete shapes, which is a fairly common defect type (i.e., missing pieces of different products).","The main challenge is that missing areas in 3D point clouds represent the absence of scanned points.","This makes it infeasible to compare the missing region with existing point cloud patches in the memory bank.","To address these two challenges, we proposed a unified, unsupervised 3D anomaly detection framework capable of identifying all types of defects on model-free products.","Our method integrates two detection modules: a feature-based detection module and a reconstruction-based detection module.","Feature-based detection covers geometric defects, such as dents, holes, and cracks, while the reconstruction-based method detects missing regions.","Additionally, we employ a One-class Support Vector Machine (OCSVM) to fuse the detection results from both modules.","The results demonstrate that (1) our proposed method outperforms the state-of-the-art methods in identifying incomplete shapes and (2) it still maintains comparable performance with the SOTA methods in detecting all other types of anomalies."],"url":"http://arxiv.org/abs/2408.16201v1"}
{"created":"2024-08-29 01:25:36","title":"DLM-VMTL:A Double Layer Mapper for heterogeneous data video Multi-task prompt learning","abstract":"In recent years, the parameters of backbones of Video Understanding tasks continue to increase and even reach billion-level. Whether fine-tuning a specific task on the Video Foundation Model or pre-training the model designed for the specific task, incurs a lot of overhead. How to make these models play other values than their own tasks becomes a worthy question. Multi-Task Learning(MTL) makes the visual task acquire the rich shareable knowledge from other tasks while joint training. It is fully explored in Image Recognition tasks especially dense predict tasks. Nevertheless, it is rarely used in video domain due to the lack of multi-labels video data. In this paper, a heterogenous data video multi-task prompt learning (VMTL) method is proposed to address above problem. It's different from it in image domain, a Double-Layers Mapper(DLM) is proposed to extract the shareable knowledge into visual promptS and align it with representation of primary task. Extensive experiments prove that our DLM-VMTL performs better than baselines on 6 different video understanding tasks and 11 datasets.","sentences":["In recent years, the parameters of backbones of Video Understanding tasks continue to increase and even reach billion-level.","Whether fine-tuning a specific task on the Video Foundation Model or pre-training the model designed for the specific task, incurs a lot of overhead.","How to make these models play other values than their own tasks becomes a worthy question.","Multi-Task Learning(MTL) makes the visual task acquire the rich shareable knowledge from other tasks while joint training.","It is fully explored in Image Recognition tasks especially dense predict tasks.","Nevertheless, it is rarely used in video domain due to the lack of multi-labels video data.","In this paper, a heterogenous data video multi-task prompt learning (VMTL) method is proposed to address above problem.","It's different from it in image domain, a Double-Layers Mapper(DLM) is proposed to extract the shareable knowledge into visual promptS and align it with representation of primary task.","Extensive experiments prove that our DLM-VMTL performs better than baselines on 6 different video understanding tasks and 11 datasets."],"url":"http://arxiv.org/abs/2408.16195v1"}
{"created":"2024-08-29 01:09:30","title":"Variational Mode-Driven Graph Convolutional Network for Spatiotemporal Traffic Forecasting","abstract":"This paper focuses on spatio-temporal (ST) traffic prediction traffic using graph neural networks. Given that ST data consists of non-stationary and complex time events, interpreting and predicting such trends is comparatively complicated. Representation of ST data in modes helps us infer behavior and assess the impact of noise on prediction applications. We propose a framework that decomposes ST data into modes using the variational mode decomposition (VMD) method, which is then fed into the neural network for forecasting future states. This hybrid approach is known as a variational mode graph convolutional network (VMGCN). Instead of exhaustively searching for the number of modes, they are determined using the reconstruction loss from the real-time application data. We also study the significance of each mode and the impact of bandwidth constraints on different horizon predictions in traffic flow data. We evaluate the performance of our proposed network on the LargeST dataset for both short and long-term predictions. Our framework yields better results compared to state-of-the-art methods.","sentences":["This paper focuses on spatio-temporal (ST) traffic prediction traffic using graph neural networks.","Given that ST data consists of non-stationary and complex time events, interpreting and predicting such trends is comparatively complicated.","Representation of ST data in modes helps us infer behavior and assess the impact of noise on prediction applications.","We propose a framework that decomposes ST data into modes using the variational mode decomposition (VMD) method, which is then fed into the neural network for forecasting future states.","This hybrid approach is known as a variational mode graph convolutional network (VMGCN).","Instead of exhaustively searching for the number of modes, they are determined using the reconstruction loss from the real-time application data.","We also study the significance of each mode and the impact of bandwidth constraints on different horizon predictions in traffic flow data.","We evaluate the performance of our proposed network on the LargeST dataset for both short and long-term predictions.","Our framework yields better results compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2408.16191v1"}
{"created":"2024-08-29 01:06:51","title":"Estimating Dynamic Flow Features in Groups of Tracked Objects","abstract":"Interpreting motion captured in image sequences is crucial for a wide range of computer vision applications. Typical estimation approaches include optical flow (OF), which approximates the apparent motion instantaneously in a scene, and multiple object tracking (MOT), which tracks the motion of subjects over time. Often, the motion of objects in a scene is governed by some underlying dynamical system which could be inferred by analyzing the motion of groups of objects. Standard motion analyses, however, are not designed to intuit flow dynamics from trajectory data, making such measurements difficult in practice. The goal of this work is to extend gradient-based dynamical systems analyses to real-world applications characterized by complex, feature-rich image sequences with imperfect tracers. The tracer trajectories are tracked using deep vision networks and gradients are approximated using Lagrangian gradient regression (LGR), a tool designed to estimate spatial gradients from sparse data. From gradients, dynamical features such as regions of coherent rotation and transport barriers are identified. The proposed approach is affordably implemented and enables advanced studies including the motion analysis of two distinct object classes in a single image sequence. Two examples of the method are presented on data sets for which standard gradient-based analyses do not apply.","sentences":["Interpreting motion captured in image sequences is crucial for a wide range of computer vision applications.","Typical estimation approaches include optical flow (OF), which approximates the apparent motion instantaneously in a scene, and multiple object tracking (MOT), which tracks the motion of subjects over time.","Often, the motion of objects in a scene is governed by some underlying dynamical system which could be inferred by analyzing the motion of groups of objects.","Standard motion analyses, however, are not designed to intuit flow dynamics from trajectory data, making such measurements difficult in practice.","The goal of this work is to extend gradient-based dynamical systems analyses to real-world applications characterized by complex, feature-rich image sequences with imperfect tracers.","The tracer trajectories are tracked using deep vision networks and gradients are approximated using Lagrangian gradient regression (LGR), a tool designed to estimate spatial gradients from sparse data.","From gradients, dynamical features such as regions of coherent rotation and transport barriers are identified.","The proposed approach is affordably implemented and enables advanced studies including the motion analysis of two distinct object classes in a single image sequence.","Two examples of the method are presented on data sets for which standard gradient-based analyses do not apply."],"url":"http://arxiv.org/abs/2408.16190v1"}
{"created":"2024-08-29 00:53:21","title":"Real-Time Energy Pricing in New Zealand: An Evolving Stream Analysis","abstract":"This paper introduces a group of novel datasets representing real-time time-series and streaming data of energy prices in New Zealand, sourced from the Electricity Market Information (EMI) website maintained by the New Zealand government. The datasets are intended to address the scarcity of proper datasets for streaming regression learning tasks. We conduct extensive analyses and experiments on these datasets, covering preprocessing techniques, regression tasks, prediction intervals, concept drift detection, and anomaly detection. Our experiments demonstrate the datasets' utility and highlight the challenges and opportunities for future research in energy price forecasting.","sentences":["This paper introduces a group of novel datasets representing real-time time-series and streaming data of energy prices in New Zealand, sourced from the Electricity Market Information (EMI) website maintained by the New Zealand government.","The datasets are intended to address the scarcity of proper datasets for streaming regression learning tasks.","We conduct extensive analyses and experiments on these datasets, covering preprocessing techniques, regression tasks, prediction intervals, concept drift detection, and anomaly detection.","Our experiments demonstrate the datasets' utility and highlight the challenges and opportunities for future research in energy price forecasting."],"url":"http://arxiv.org/abs/2408.16187v1"}
{"created":"2024-08-28 23:39:50","title":"LLM-assisted Labeling Function Generation for Semantic Type Detection","abstract":"Detecting semantic types of columns in data lake tables is an important application. A key bottleneck in semantic type detection is the availability of human annotation due to the inherent complexity of data lakes. In this paper, we propose using programmatic weak supervision to assist in annotating the training data for semantic type detection by leveraging labeling functions. One challenge in this process is the difficulty of manually writing labeling functions due to the large volume and low quality of the data lake table datasets. To address this issue, we explore employing Large Language Models (LLMs) for labeling function generation and introduce several prompt engineering strategies for this purpose. We conduct experiments on real-world web table datasets. Based on the initial results, we perform extensive analysis and provide empirical insights and future directions for researchers in this field.","sentences":["Detecting semantic types of columns in data lake tables is an important application.","A key bottleneck in semantic type detection is the availability of human annotation due to the inherent complexity of data lakes.","In this paper, we propose using programmatic weak supervision to assist in annotating the training data for semantic type detection by leveraging labeling functions.","One challenge in this process is the difficulty of manually writing labeling functions due to the large volume and low quality of the data lake table datasets.","To address this issue, we explore employing Large Language Models (LLMs) for labeling function generation and introduce several prompt engineering strategies for this purpose.","We conduct experiments on real-world web table datasets.","Based on the initial results, we perform extensive analysis and provide empirical insights and future directions for researchers in this field."],"url":"http://arxiv.org/abs/2408.16173v1"}
{"created":"2024-08-28 23:20:17","title":"Simulating realistic short tandem repeat capillary electrophoretic signal using a generative adversarial network","abstract":"DNA profiles are made up from multiple series of electrophoretic signal measuring fluorescence over time. Typically, human DNA analysts 'read' DNA profiles using their experience to distinguish instrument noise, artefactual signal, and signal corresponding to DNA fragments of interest. Recent work has developed an artificial neural network, ANN, to carry out the task of classifying fluorescence types into categories in DNA profile electrophoretic signal. But the creation of the necessarily large amount of labelled training data for the ANN is time consuming and expensive, and a limiting factor in the ability to robustly train the ANN. If realistic, prelabelled, training data could be simulated then this would remove the barrier to training an ANN with high efficacy. Here we develop a generative adversarial network, GAN, modified from the pix2pix GAN to achieve this task. With 1078 DNA profiles we train the GAN and achieve the ability to simulate DNA profile information, and then use the generator from the GAN as a 'realism filter' that applies the noise and artefact elements exhibited in typical electrophoretic signal.","sentences":["DNA profiles are made up from multiple series of electrophoretic signal measuring fluorescence over time.","Typically, human DNA analysts 'read' DNA profiles using their experience to distinguish instrument noise, artefactual signal, and signal corresponding to DNA fragments of interest.","Recent work has developed an artificial neural network, ANN, to carry out the task of classifying fluorescence types into categories in DNA profile electrophoretic signal.","But the creation of the necessarily large amount of labelled training data for the ANN is time consuming and expensive, and a limiting factor in the ability to robustly train the ANN.","If realistic, prelabelled, training data could be simulated then this would remove the barrier to training an ANN with high efficacy.","Here we develop a generative adversarial network, GAN, modified from the pix2pix GAN to achieve this task.","With 1078 DNA profiles we train the GAN and achieve the ability to simulate DNA profile information, and then use the generator from the GAN as a 'realism filter' that applies the noise and artefact elements exhibited in typical electrophoretic signal."],"url":"http://arxiv.org/abs/2408.16169v1"}
{"created":"2024-08-28 23:20:03","title":"LeMON: Learning to Learn Multi-Operator Networks","abstract":"Single-operator learning involves training a deep neural network to learn a specific operator, whereas recent work in multi-operator learning uses an operator embedding structure to train a single neural network on data from multiple operators. Thus, multi-operator learning is capable of predicting a range of operators within one model. In this work, we propose pretraining and fine-tuning strategies for solving PDEs using multi-operator learning. One key aspect is that by increasing the number of families of operators used in pretraining, a PDE foundation model can be fine-tuned to downstream tasks involving new PDEs with a limited number of samples, thus outperforming single operator neural networks. Specifically, a multi-operator learning model pre-trained with data from diverse PDE families can predict unseen operators after fine-tuning with only a limited number of operators from the new family, enabling them to serve as a data-free PDE solver. We also show that the proposed training and fine-tuning method is able to predict new operators in zero-shot prediction without samples. Additionally, we introduce a PDE-agnostic meta-learning algorithm to improve the adaptability of the model to various PDEs by providing a better parameter initialization process. To address the needs of applications with limited computing resources, we explore low-rank adaptation methods that reduce computational costs while enhancing solver accuracy. Lastly, by examining the scaling law with respect to the number of operator families, we establish and highlight its potential for broad adaptation in PDE-solving tasks.","sentences":["Single-operator learning involves training a deep neural network to learn a specific operator, whereas recent work in multi-operator learning uses an operator embedding structure to train a single neural network on data from multiple operators.","Thus, multi-operator learning is capable of predicting a range of operators within one model.","In this work, we propose pretraining and fine-tuning strategies for solving PDEs using multi-operator learning.","One key aspect is that by increasing the number of families of operators used in pretraining, a PDE foundation model can be fine-tuned to downstream tasks involving new PDEs with a limited number of samples, thus outperforming single operator neural networks.","Specifically, a multi-operator learning model pre-trained with data from diverse PDE families can predict unseen operators after fine-tuning with only a limited number of operators from the new family, enabling them to serve as a data-free PDE solver.","We also show that the proposed training and fine-tuning method is able to predict new operators in zero-shot prediction without samples.","Additionally, we introduce a PDE-agnostic meta-learning algorithm to improve the adaptability of the model to various PDEs by providing a better parameter initialization process.","To address the needs of applications with limited computing resources, we explore low-rank adaptation methods that reduce computational costs while enhancing solver accuracy.","Lastly, by examining the scaling law with respect to the number of operator families, we establish and highlight its potential for broad adaptation in PDE-solving tasks."],"url":"http://arxiv.org/abs/2408.16168v1"}
{"created":"2024-08-28 23:15:46","title":"Free Lunch in the Forest: Functionally-Identical Pruning of Boosted Tree Ensembles","abstract":"Tree ensembles, including boosting methods, are highly effective and widely used for tabular data. However, large ensembles lack interpretability and require longer inference times. We introduce a method to prune a tree ensemble into a reduced version that is \"functionally identical\" to the original model. In other words, our method guarantees that the prediction function stays unchanged for any possible input. As a consequence, this pruning algorithm is lossless for any aggregated metric. We formalize the problem of functionally identical pruning on ensembles, introduce an exact optimization model, and provide a fast yet highly effective method to prune large ensembles. Our algorithm iteratively prunes considering a finite set of points, which is incrementally augmented using an adversarial model. In multiple computational experiments, we show that our approach is a \"free lunch\", significantly reducing the ensemble size without altering the model's behavior. Thus, we can preserve state-of-the-art performance at a fraction of the original model's size.","sentences":["Tree ensembles, including boosting methods, are highly effective and widely used for tabular data.","However, large ensembles lack interpretability and require longer inference times.","We introduce a method to prune a tree ensemble into a reduced version that is \"functionally identical\" to the original model.","In other words, our method guarantees that the prediction function stays unchanged for any possible input.","As a consequence, this pruning algorithm is lossless for any aggregated metric.","We formalize the problem of functionally identical pruning on ensembles, introduce an exact optimization model, and provide a fast yet highly effective method to prune large ensembles.","Our algorithm iteratively prunes considering a finite set of points, which is incrementally augmented using an adversarial model.","In multiple computational experiments, we show that our approach is a \"free lunch\", significantly reducing the ensemble size without altering the model's behavior.","Thus, we can preserve state-of-the-art performance at a fraction of the original model's size."],"url":"http://arxiv.org/abs/2408.16167v1"}
{"created":"2024-08-28 23:00:57","title":"Sparse Recovery for Overcomplete Frames: Sensing Matrices and Recovery Guarantees","abstract":"Signal models formed as linear combinations of few atoms from an over-complete dictionary or few frame vectors from a redundant frame have become central to many applications in high dimensional signal processing and data analysis. A core question is, by exploiting the intrinsic low dimensional structure of the signal, how to design the sensing process and decoder in a way that the number of measurements is essentially close to the complexity of the signal set. This chapter provides a survey of important results in answering this question, with an emphasis on a basis pursuit like convex optimization decoder that admits a wide range of random sensing matrices. The results are quite established in the case signals are sparse in an orthonormal basis, while the case with frame sparse signals is much less explored. In addition to presenting the latest results on recovery guarantee and how few random heavier-tailed measurements fulfill these recovery guarantees, this chapter also aims to provide some insights in proof techniques. We also take the opportunity of this book chapter to publish an interesting result (Theorem 3.10) about a restricted isometry like property related to a frame.","sentences":["Signal models formed as linear combinations of few atoms from an over-complete dictionary or few frame vectors from a redundant frame have become central to many applications in high dimensional signal processing and data analysis.","A core question is, by exploiting the intrinsic low dimensional structure of the signal, how to design the sensing process and decoder in a way that the number of measurements is essentially close to the complexity of the signal set.","This chapter provides a survey of important results in answering this question, with an emphasis on a basis pursuit like convex optimization decoder that admits a wide range of random sensing matrices.","The results are quite established in the case signals are sparse in an orthonormal basis, while the case with frame sparse signals is much less explored.","In addition to presenting the latest results on recovery guarantee and how few random heavier-tailed measurements fulfill these recovery guarantees, this chapter also aims to provide some insights in proof techniques.","We also take the opportunity of this book chapter to publish an interesting result (Theorem 3.10) about a restricted isometry like property related to a frame."],"url":"http://arxiv.org/abs/2408.16166v1"}
{"created":"2024-08-28 22:45:15","title":"CLPNets: Coupled Lie-Poisson Neural Networks for Multi-Part Hamiltonian Systems with Symmetries","abstract":"To accurately compute data-based prediction of Hamiltonian systems, especially the long-term evolution of such systems, it is essential to utilize methods that preserve the structure of the equations over time. We consider a case that is particularly challenging for data-based methods: systems with interacting parts that do not reduce to pure momentum evolution. Such systems are essential in scientific computations. For example, any discretization of a continuum elastic rod can be viewed as interacting elements that can move and rotate in space, with each discrete element moving on the group of rotations and translations $SE(3)$.   We develop a novel method of data-based computation and complete phase space learning of such systems. We follow the original framework of \\emph{SympNets} (Jin et al, 2020) building the neural network from canonical phase space mappings, and transformations that preserve the Lie-Poisson structure (\\emph{LPNets}) as in (Eldred et al, 2024). We derive a novel system of mappings that are built into neural networks for coupled systems. We call such networks Coupled Lie-Poisson Neural Networks, or \\emph{CLPNets}. We consider increasingly complex examples for the applications of CLPNets: rotation of two rigid bodies about a common axis, the free rotation of two rigid bodies, and finally the evolution of two connected and interacting $SE(3)$ components. Our method preserves all Casimir invariants of each system to machine precision, irrespective of the quality of the training data, and preserves energy to high accuracy. Our method also shows good resistance to the curse of dimensionality, requiring only a few thousand data points for all cases studied, with the effective dimension varying from three to eighteen. Additionally, the method is highly economical in memory requirements, requiring only about 200 parameters for the most complex case considered.","sentences":["To accurately compute data-based prediction of Hamiltonian systems, especially the long-term evolution of such systems, it is essential to utilize methods that preserve the structure of the equations over time.","We consider a case that is particularly challenging for data-based methods: systems with interacting parts that do not reduce to pure momentum evolution.","Such systems are essential in scientific computations.","For example, any discretization of a continuum elastic rod can be viewed as interacting elements that can move and rotate in space, with each discrete element moving on the group of rotations and translations $SE(3)$.   We develop a novel method of data-based computation and complete phase space learning of such systems.","We follow the original framework of \\emph{SympNets} (Jin et al, 2020) building the neural network from canonical phase space mappings, and transformations that preserve the Lie-Poisson structure (\\emph{LPNets}) as in (Eldred et al, 2024).","We derive a novel system of mappings that are built into neural networks for coupled systems.","We call such networks Coupled Lie-Poisson Neural Networks, or \\emph{CLPNets}.","We consider increasingly complex examples for the applications of CLPNets: rotation of two rigid bodies about a common axis, the free rotation of two rigid bodies, and finally the evolution of two connected and interacting $SE(3)$ components.","Our method preserves all Casimir invariants of each system to machine precision, irrespective of the quality of the training data, and preserves energy to high accuracy.","Our method also shows good resistance to the curse of dimensionality, requiring only a few thousand data points for all cases studied, with the effective dimension varying from three to eighteen.","Additionally, the method is highly economical in memory requirements, requiring only about 200 parameters for the most complex case considered."],"url":"http://arxiv.org/abs/2408.16160v1"}
{"created":"2024-08-28 22:14:44","title":"Does Data-Efficient Generalization Exacerbate Bias in Foundation Models?","abstract":"Foundation models have emerged as robust models with label efficiency in diverse domains. In medical imaging, these models contribute to the advancement of medical diagnoses due to the difficulty in obtaining labeled data. However, it is unclear whether using a large amount of unlabeled data, biased by the presence of sensitive attributes during pre-training, influences the fairness of the model. This research examines the bias in the Foundation model (RetFound) when it is applied to fine-tune the Brazilian Multilabel Ophthalmological Dataset (BRSET), which has a different population than the pre-training dataset. The model evaluation, in comparison with supervised learning, shows that the Foundation Model has the potential to reduce the gap between the maximum AUC and minimum AUC evaluations across gender and age groups. However, in a data-efficient generalization, the model increases the bias when the data amount decreases. These findings suggest that when deploying a Foundation Model in real-life scenarios with limited data, the possibility of fairness issues should be considered.","sentences":["Foundation models have emerged as robust models with label efficiency in diverse domains.","In medical imaging, these models contribute to the advancement of medical diagnoses due to the difficulty in obtaining labeled data.","However, it is unclear whether using a large amount of unlabeled data, biased by the presence of sensitive attributes during pre-training, influences the fairness of the model.","This research examines the bias in the Foundation model (RetFound) when it is applied to fine-tune the Brazilian Multilabel Ophthalmological Dataset (BRSET), which has a different population than the pre-training dataset.","The model evaluation, in comparison with supervised learning, shows that the Foundation Model has the potential to reduce the gap between the maximum AUC and minimum AUC evaluations across gender and age groups.","However, in a data-efficient generalization, the model increases the bias when the data amount decreases.","These findings suggest that when deploying a Foundation Model in real-life scenarios with limited data, the possibility of fairness issues should be considered."],"url":"http://arxiv.org/abs/2408.16154v1"}
{"created":"2024-08-28 21:28:45","title":"Improving the Prediction of Individual Engagement in Recommendations Using Cognitive Models","abstract":"For public health programs with limited resources, the ability to predict how behaviors change over time and in response to interventions is crucial for deciding when and to whom interventions should be allocated. Using data from a real-world maternal health program, we demonstrate how a cognitive model based on Instance-Based Learning (IBL) Theory can augment existing purely computational approaches. Our findings show that, compared to general time-series forecasters (e.g., LSTMs), IBL models, which reflect human decision-making processes, better predict the dynamics of individuals' states. Additionally, IBL provides estimates of the volatility in individuals' states and their sensitivity to interventions, which can improve the efficiency of training of other time series models.","sentences":["For public health programs with limited resources, the ability to predict how behaviors change over time and in response to interventions is crucial for deciding when and to whom interventions should be allocated.","Using data from a real-world maternal health program, we demonstrate how a cognitive model based on Instance-Based Learning (IBL) Theory can augment existing purely computational approaches.","Our findings show that, compared to general time-series forecasters (e.g., LSTMs), IBL models, which reflect human decision-making processes, better predict the dynamics of individuals' states.","Additionally, IBL provides estimates of the volatility in individuals' states and their sensitivity to interventions, which can improve the efficiency of training of other time series models."],"url":"http://arxiv.org/abs/2408.16147v1"}
{"created":"2024-08-28 21:24:27","title":"DrowzEE-G-Mamba: Leveraging EEG and State Space Models for Driver Drowsiness Detection","abstract":"Driver drowsiness is identified as a critical factor in road accidents, necessitating robust detection systems to enhance road safety. This study proposes a driver drowsiness detection system, DrowzEE-G-Mamba, that combines Electroencephalography (EEG) with State Space Models (SSMs). EEG data, known for its sensitivity to alertness, is used to model driver state transitions between alert and drowsy. Compared to traditional methods, DrowzEE-G-Mamba achieves significantly improved detection rates and reduced false positives. Notably, it achieves a peak accuracy of 83.24% on the SEED-VIG dataset, surpassing existing techniques. The system maintains high accuracy across varying complexities, making it suitable for real-time applications with limited resources. This robustness is attributed to the combination of channel-split, channel-concatenation, and channel-shuffle operations within the architecture, optimizing information flow from EEG data. Additionally, the integration of convolutional layers and SSMs facilitates comprehensive analysis, capturing both local features and long-range dependencies in the EEG signals. These findings suggest the potential of DrowzEE-G-Mamba for enhancing road safety through accurate drowsiness detection. It also paves the way for developing powerful SSM-based AI algorithms in Brain-Computer Interface applications.","sentences":["Driver drowsiness is identified as a critical factor in road accidents, necessitating robust detection systems to enhance road safety.","This study proposes a driver drowsiness detection system, DrowzEE-G-Mamba, that combines Electroencephalography (EEG) with State Space Models (SSMs).","EEG data, known for its sensitivity to alertness, is used to model driver state transitions between alert and drowsy.","Compared to traditional methods, DrowzEE-G-Mamba achieves significantly improved detection rates and reduced false positives.","Notably, it achieves a peak accuracy of 83.24% on the SEED-VIG dataset, surpassing existing techniques.","The system maintains high accuracy across varying complexities, making it suitable for real-time applications with limited resources.","This robustness is attributed to the combination of channel-split, channel-concatenation, and channel-shuffle operations within the architecture, optimizing information flow from EEG data.","Additionally, the integration of convolutional layers and SSMs facilitates comprehensive analysis, capturing both local features and long-range dependencies in the EEG signals.","These findings suggest the potential of DrowzEE-G-Mamba for enhancing road safety through accurate drowsiness detection.","It also paves the way for developing powerful SSM-based AI algorithms in Brain-Computer Interface applications."],"url":"http://arxiv.org/abs/2408.16145v1"}
{"created":"2024-08-28 20:56:35","title":"Thinner Latent Spaces: Detecting dimension and imposing invariance through autoencoder gradient constraints","abstract":"Conformal Autoencoders are a neural network architecture that imposes orthogonality conditions between the gradients of latent variables towards achieving disentangled representations of data. In this letter we show that orthogonality relations within the latent layer of the network can be leveraged to infer the intrinsic dimensionality of nonlinear manifold data sets (locally characterized by the dimension of their tangent space), while simultaneously computing encoding and decoding (embedding) maps. We outline the relevant theory relying on differential geometry, and describe the corresponding gradient-descent optimization algorithm. The method is applied to standard data sets and we highlight its applicability, advantages, and shortcomings. In addition, we demonstrate that the same computational technology can be used to build coordinate invariance to local group actions when defined only on a (reduced) submanifold of the embedding space.","sentences":["Conformal Autoencoders are a neural network architecture that imposes orthogonality conditions between the gradients of latent variables towards achieving disentangled representations of data.","In this letter we show that orthogonality relations within the latent layer of the network can be leveraged to infer the intrinsic dimensionality of nonlinear manifold data sets (locally characterized by the dimension of their tangent space), while simultaneously computing encoding and decoding (embedding) maps.","We outline the relevant theory relying on differential geometry, and describe the corresponding gradient-descent optimization algorithm.","The method is applied to standard data sets and we highlight its applicability, advantages, and shortcomings.","In addition, we demonstrate that the same computational technology can be used to build coordinate invariance to local group actions when defined only on a (reduced) submanifold of the embedding space."],"url":"http://arxiv.org/abs/2408.16138v1"}
{"created":"2024-08-28 20:35:38","title":"Using Backbone Foundation Model for Evaluating Fairness in Chest Radiography Without Demographic Data","abstract":"Ensuring consistent performance across diverse populations and incorporating fairness into machine learning models are crucial for advancing medical image diagnostics and promoting equitable healthcare. However, many databases do not provide protected attributes or contain unbalanced representations of demographic groups, complicating the evaluation of model performance across different demographics and the application of bias mitigation techniques that rely on these attributes. This study aims to investigate the effectiveness of using the backbone of Foundation Models as an embedding extractor for creating groups that represent protected attributes, such as gender and age. We propose utilizing these groups in different stages of bias mitigation, including pre-processing, in-processing, and evaluation. Using databases in and out-of-distribution scenarios, it is possible to identify that the method can create groups that represent gender in both databases and reduce in 4.44% the difference between the gender attribute in-distribution and 6.16% in out-of-distribution. However, the model lacks robustness in handling age attributes, underscoring the need for more fundamentally fair and robust Foundation models. These findings suggest a role in promoting fairness assessment in scenarios where we lack knowledge of attributes, contributing to the development of more equitable medical diagnostics.","sentences":["Ensuring consistent performance across diverse populations and incorporating fairness into machine learning models are crucial for advancing medical image diagnostics and promoting equitable healthcare.","However, many databases do not provide protected attributes or contain unbalanced representations of demographic groups, complicating the evaluation of model performance across different demographics and the application of bias mitigation techniques that rely on these attributes.","This study aims to investigate the effectiveness of using the backbone of Foundation Models as an embedding extractor for creating groups that represent protected attributes, such as gender and age.","We propose utilizing these groups in different stages of bias mitigation, including pre-processing, in-processing, and evaluation.","Using databases in and out-of-distribution scenarios, it is possible to identify that the method can create groups that represent gender in both databases and reduce in 4.44% the difference between the gender attribute in-distribution and 6.16% in out-of-distribution.","However, the model lacks robustness in handling age attributes, underscoring the need for more fundamentally fair and robust Foundation models.","These findings suggest a role in promoting fairness assessment in scenarios where we lack knowledge of attributes, contributing to the development of more equitable medical diagnostics."],"url":"http://arxiv.org/abs/2408.16130v1"}
{"created":"2024-08-28 20:26:34","title":"Improving Generalization of Speech Separation in Real-World Scenarios: Strategies in Simulation, Optimization, and Evaluation","abstract":"Achieving robust speech separation for overlapping speakers in various acoustic environments with noise and reverberation remains an open challenge. Although existing datasets are available to train separators for specific scenarios, they do not effectively generalize across diverse real-world scenarios. In this paper, we present a novel data simulation pipeline that produces diverse training data from a range of acoustic environments and content, and propose new training paradigms to improve quality of a general speech separation model. Specifically, we first introduce AC-SIM, a data simulation pipeline that incorporates broad variations in both content and acoustics. Then we integrate multiple training objectives into the permutation invariant training (PIT) to enhance separation quality and generalization of the trained model. Finally, we conduct comprehensive objective and human listening experiments across separation architectures and benchmarks to validate our methods, demonstrating substantial improvement of generalization on both non-homologous and real-world test sets.","sentences":["Achieving robust speech separation for overlapping speakers in various acoustic environments with noise and reverberation remains an open challenge.","Although existing datasets are available to train separators for specific scenarios, they do not effectively generalize across diverse real-world scenarios.","In this paper, we present a novel data simulation pipeline that produces diverse training data from a range of acoustic environments and content, and propose new training paradigms to improve quality of a general speech separation model.","Specifically, we first introduce AC-SIM, a data simulation pipeline that incorporates broad variations in both content and acoustics.","Then we integrate multiple training objectives into the permutation invariant training (PIT) to enhance separation quality and generalization of the trained model.","Finally, we conduct comprehensive objective and human listening experiments across separation architectures and benchmarks to validate our methods, demonstrating substantial improvement of generalization on both non-homologous and real-world test sets."],"url":"http://arxiv.org/abs/2408.16126v1"}
