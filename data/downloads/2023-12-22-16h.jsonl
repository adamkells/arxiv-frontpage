{"created":"2023-12-21 18:59:57","title":"3D Pose Estimation of Two Interacting Hands from a Monocular Event Camera","abstract":"3D hand tracking from a monocular video is a very challenging problem due to hand interactions, occlusions, left-right hand ambiguity, and fast motion. Most existing methods rely on RGB inputs, which have severe limitations under low-light conditions and suffer from motion blur. In contrast, event cameras capture local brightness changes instead of full image frames and do not suffer from the described effects. Unfortunately, existing image-based techniques cannot be directly applied to events due to significant differences in the data modalities. In response to these challenges, this paper introduces the first framework for 3D tracking of two fast-moving and interacting hands from a single monocular event camera. Our approach tackles the left-right hand ambiguity with a novel semi-supervised feature-wise attention mechanism and integrates an intersection loss to fix hand collisions. To facilitate advances in this research domain, we release a new synthetic large-scale dataset of two interacting hands, Ev2Hands-S, and a new real benchmark with real event streams and ground-truth 3D annotations, Ev2Hands-R. Our approach outperforms existing methods in terms of the 3D reconstruction accuracy and generalises to real data under severe light conditions.","sentences":["3D hand tracking from a monocular video is a very challenging problem due to hand interactions, occlusions, left-right hand ambiguity, and fast motion.","Most existing methods rely on RGB inputs, which have severe limitations under low-light conditions and suffer from motion blur.","In contrast, event cameras capture local brightness changes instead of full image frames and do not suffer from the described effects.","Unfortunately, existing image-based techniques cannot be directly applied to events due to significant differences in the data modalities.","In response to these challenges, this paper introduces the first framework for 3D tracking of two fast-moving and interacting hands from a single monocular event camera.","Our approach tackles the left-right hand ambiguity with a novel semi-supervised feature-wise attention mechanism and integrates an intersection loss to fix hand collisions.","To facilitate advances in this research domain, we release a new synthetic large-scale dataset of two interacting hands, Ev2Hands-S, and a new real benchmark with real event streams and ground-truth 3D annotations, Ev2Hands-R. Our approach outperforms existing methods in terms of the 3D reconstruction accuracy and generalises to real data under severe light conditions."],"url":"http://arxiv.org/abs/2312.14157v1"}
{"created":"2023-12-21 18:59:30","title":"Virtual Pets: Animatable Animal Generation in 3D Scenes","abstract":"Toward unlocking the potential of generative models in immersive 4D experiences, we introduce Virtual Pet, a novel pipeline to model realistic and diverse motions for target animal species within a 3D environment. To circumvent the limited availability of 3D motion data aligned with environmental geometry, we leverage monocular internet videos and extract deformable NeRF representations for the foreground and static NeRF representations for the background. For this, we develop a reconstruction strategy, encompassing species-level shared template learning and per-video fine-tuning. Utilizing the reconstructed data, we then train a conditional 3D motion model to learn the trajectory and articulation of foreground animals in the context of 3D backgrounds. We showcase the efficacy of our pipeline with comprehensive qualitative and quantitative evaluations using cat videos. We also demonstrate versatility across unseen cats and indoor environments, producing temporally coherent 4D outputs for enriched virtual experiences.","sentences":["Toward unlocking the potential of generative models in immersive 4D experiences, we introduce Virtual Pet, a novel pipeline to model realistic and diverse motions for target animal species within a 3D environment.","To circumvent the limited availability of 3D motion data aligned with environmental geometry, we leverage monocular internet videos and extract deformable NeRF representations for the foreground and static NeRF representations for the background.","For this, we develop a reconstruction strategy, encompassing species-level shared template learning and per-video fine-tuning.","Utilizing the reconstructed data, we then train a conditional 3D motion model to learn the trajectory and articulation of foreground animals in the context of 3D backgrounds.","We showcase the efficacy of our pipeline with comprehensive qualitative and quantitative evaluations using cat videos.","We also demonstrate versatility across unseen cats and indoor environments, producing temporally coherent 4D outputs for enriched virtual experiences."],"url":"http://arxiv.org/abs/2312.14154v1"}
{"created":"2023-12-21 18:59:12","title":"DriveLM: Driving with Graph Visual Question Answering","abstract":"We study how vision-language models (VLMs) trained on web-scale data can be integrated into end-to-end driving systems to boost generalization and enable interactivity with human users. While recent approaches adapt VLMs to driving via single-round visual question answering (VQA), human drivers reason about decisions in multiple steps. Starting from the localization of key objects, humans estimate object interactions before taking actions. The key insight is that with our proposed task, Graph VQA, where we model graph-structured reasoning through perception, prediction and planning question-answer pairs, we obtain a suitable proxy task to mimic the human reasoning process. We instantiate datasets (DriveLM-Data) built upon nuScenes and CARLA, and propose a VLM-based baseline approach (DriveLM-Agent) for jointly performing Graph VQA and end-to-end driving. The experiments demonstrate that Graph VQA provides a simple, principled framework for reasoning about a driving scene, and DriveLM-Data provides a challenging benchmark for this task. Our DriveLM-Agent baseline performs end-to-end autonomous driving competitively in comparison to state-of-the-art driving-specific architectures. Notably, its benefits are pronounced when it is evaluated zero-shot on unseen objects or sensor configurations. We hope this work can be the starting point to shed new light on how to apply VLMs for autonomous driving. To facilitate future research, all code, data, and models are available to the public.","sentences":["We study how vision-language models (VLMs) trained on web-scale data can be integrated into end-to-end driving systems to boost generalization and enable interactivity with human users.","While recent approaches adapt VLMs to driving via single-round visual question answering (VQA), human drivers reason about decisions in multiple steps.","Starting from the localization of key objects, humans estimate object interactions before taking actions.","The key insight is that with our proposed task, Graph VQA, where we model graph-structured reasoning through perception, prediction and planning question-answer pairs, we obtain a suitable proxy task to mimic the human reasoning process.","We instantiate datasets (DriveLM-Data) built upon nuScenes and CARLA, and propose a VLM-based baseline approach (DriveLM-Agent) for jointly performing Graph VQA and end-to-end driving.","The experiments demonstrate that Graph VQA provides a simple, principled framework for reasoning about a driving scene, and DriveLM-Data provides a challenging benchmark for this task.","Our DriveLM-Agent baseline performs end-to-end autonomous driving competitively in comparison to state-of-the-art driving-specific architectures.","Notably, its benefits are pronounced when it is evaluated zero-shot on unseen objects or sensor configurations.","We hope this work can be the starting point to shed new light on how to apply VLMs for autonomous driving.","To facilitate future research, all code, data, and models are available to the public."],"url":"http://arxiv.org/abs/2312.14150v1"}
{"created":"2023-12-21 18:59:06","title":"TagAlign: Improving Vision-Language Alignment with Multi-Tag Classification","abstract":"The crux of learning vision-language models is to extract semantically aligned information from visual and linguistic data. Existing attempts usually face the problem of coarse alignment, \\textit{e.g.}, the vision encoder struggles in localizing an attribute-specified object. In this work, we propose an embarrassingly simple approach to better align image and text features with no need of additional data formats other than image-text pairs. Concretely, given an image and its paired text, we manage to parse objects (\\textit{e.g.}, cat) and attributes (\\textit{e.g.}, black) from the description, which are highly likely to exist in the image. It is noteworthy that the parsing pipeline is fully automatic and thus enjoys good scalability. With these parsed semantics as supervision signals, we can complement the commonly used image-text contrastive loss with the multi-tag classification loss. Extensive experimental results on a broad suite of semantic segmentation datasets substantiate the average 3.65\\% improvement of our framework over existing alternatives. Furthermore, the visualization results indicate that attribute supervision makes vision-language models accurately localize attribute-specified objects. Project page can be found at https://qinying-liu.github.io/Tag-Align/","sentences":["The crux of learning vision-language models is to extract semantically aligned information from visual and linguistic data.","Existing attempts usually face the problem of coarse alignment, \\textit{e.g.}, the vision encoder struggles in localizing an attribute-specified object.","In this work, we propose an embarrassingly simple approach to better align image and text features with no need of additional data formats other than image-text pairs.","Concretely, given an image and its paired text, we manage to parse objects (\\textit{e.g.}, cat) and attributes (\\textit{e.g.}, black) from the description, which are highly likely to exist in the image.","It is noteworthy that the parsing pipeline is fully automatic and thus enjoys good scalability.","With these parsed semantics as supervision signals, we can complement the commonly used image-text contrastive loss with the multi-tag classification loss.","Extensive experimental results on a broad suite of semantic segmentation datasets substantiate the average 3.65\\% improvement of our framework over existing alternatives.","Furthermore, the visualization results indicate that attribute supervision makes vision-language models accurately localize attribute-specified objects.","Project page can be found at https://qinying-liu.github.io/Tag-Align/"],"url":"http://arxiv.org/abs/2312.14149v1"}
{"created":"2023-12-21 18:49:22","title":"WellFactor: Patient Profiling using Integrative Embedding of Healthcare Data","abstract":"In the rapidly evolving healthcare industry, platforms now have access to not only traditional medical records, but also diverse data sets encompassing various patient interactions, such as those from healthcare web portals. To address this rich diversity of data, we introduce WellFactor: a method that derives patient profiles by integrating information from these sources. Central to our approach is the utilization of constrained low-rank approximation. WellFactor is optimized to handle the sparsity that is often inherent in healthcare data. Moreover, by incorporating task-specific label information, our method refines the embedding results, offering a more informed perspective on patients. One important feature of WellFactor is its ability to compute embeddings for new, previously unobserved patient data instantaneously, eliminating the need to revisit the entire data set or recomputing the embedding. Comprehensive evaluations on real-world healthcare data demonstrate WellFactor's effectiveness. It produces better results compared to other existing methods in classification performance, yields meaningful clustering of patients, and delivers consistent results in patient similarity searches and predictions.","sentences":["In the rapidly evolving healthcare industry, platforms now have access to not only traditional medical records, but also diverse data sets encompassing various patient interactions, such as those from healthcare web portals.","To address this rich diversity of data, we introduce WellFactor: a method that derives patient profiles by integrating information from these sources.","Central to our approach is the utilization of constrained low-rank approximation.","WellFactor is optimized to handle the sparsity that is often inherent in healthcare data.","Moreover, by incorporating task-specific label information, our method refines the embedding results, offering a more informed perspective on patients.","One important feature of WellFactor is its ability to compute embeddings for new, previously unobserved patient data instantaneously, eliminating the need to revisit the entire data set or recomputing the embedding.","Comprehensive evaluations on real-world healthcare data demonstrate WellFactor's effectiveness.","It produces better results compared to other existing methods in classification performance, yields meaningful clustering of patients, and delivers consistent results in patient similarity searches and predictions."],"url":"http://arxiv.org/abs/2312.14129v1"}
{"created":"2023-12-21 18:47:12","title":"Entropic Open-set Active Learning","abstract":"Active Learning (AL) aims to enhance the performance of deep models by selecting the most informative samples for annotation from a pool of unlabeled data. Despite impressive performance in closed-set settings, most AL methods fail in real-world scenarios where the unlabeled data contains unknown categories. Recently, a few studies have attempted to tackle the AL problem for the open-set setting. However, these methods focus more on selecting known samples and do not efficiently utilize unknown samples obtained during AL rounds. In this work, we propose an Entropic Open-set AL (EOAL) framework which leverages both known and unknown distributions effectively to select informative samples during AL rounds. Specifically, our approach employs two different entropy scores. One measures the uncertainty of a sample with respect to the known-class distributions. The other measures the uncertainty of the sample with respect to the unknown-class distributions. By utilizing these two entropy scores we effectively separate the known and unknown samples from the unlabeled data resulting in better sampling. Through extensive experiments, we show that the proposed method outperforms existing state-of-the-art methods on CIFAR-10, CIFAR-100, and TinyImageNet datasets. Code is available at \\url{https://github.com/bardisafa/EOAL}.","sentences":["Active Learning (AL) aims to enhance the performance of deep models by selecting the most informative samples for annotation from a pool of unlabeled data.","Despite impressive performance in closed-set settings, most AL methods fail in real-world scenarios where the unlabeled data contains unknown categories.","Recently, a few studies have attempted to tackle the AL problem for the open-set setting.","However, these methods focus more on selecting known samples and do not efficiently utilize unknown samples obtained during AL rounds.","In this work, we propose an Entropic Open-set AL (EOAL) framework which leverages both known and unknown distributions effectively to select informative samples during AL rounds.","Specifically, our approach employs two different entropy scores.","One measures the uncertainty of a sample with respect to the known-class distributions.","The other measures the uncertainty of the sample with respect to the unknown-class distributions.","By utilizing these two entropy scores we effectively separate the known and unknown samples from the unlabeled data resulting in better sampling.","Through extensive experiments, we show that the proposed method outperforms existing state-of-the-art methods on CIFAR-10, CIFAR-100, and TinyImageNet datasets.","Code is available at \\url{https://github.com/bardisafa/EOAL}."],"url":"http://arxiv.org/abs/2312.14126v1"}
{"created":"2023-12-21 17:52:12","title":"LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding","abstract":"Recently, Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have shown promise in instruction following and 2D image understanding. While these models are powerful, they have not yet been developed to comprehend the more challenging 3D physical scenes, especially when it comes to the sparse outdoor LiDAR data. In this paper, we introduce LiDAR-LLM, which takes raw LiDAR data as input and harnesses the remarkable reasoning capabilities of LLMs to gain a comprehensive understanding of outdoor 3D scenes. The central insight of our LiDAR-LLM is the reformulation of 3D outdoor scene cognition as a language modeling problem, encompassing tasks such as 3D captioning, 3D grounding, 3D question answering, etc. Specifically, due to the scarcity of 3D LiDAR-text pairing data, we introduce a three-stage training strategy and generate relevant datasets, progressively aligning the 3D modality with the language embedding space of LLM. Furthermore, we design a View-Aware Transformer (VAT) to connect the 3D encoder with the LLM, which effectively bridges the modality gap and enhances the LLM's spatial orientation comprehension of visual features. Our experiments show that LiDAR-LLM possesses favorable capabilities to comprehend various instructions regarding 3D scenes and engage in complex spatial reasoning. LiDAR-LLM attains a 40.9 BLEU-1 on the 3D captioning task and achieves a 63.1\\% classification accuracy and a 14.3\\% BEV mIoU on the 3D grounding task. Web page: https://sites.google.com/view/lidar-llm","sentences":["Recently, Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have shown promise in instruction following and 2D image understanding.","While these models are powerful, they have not yet been developed to comprehend the more challenging 3D physical scenes, especially when it comes to the sparse outdoor LiDAR data.","In this paper, we introduce LiDAR-LLM, which takes raw LiDAR data as input and harnesses the remarkable reasoning capabilities of LLMs to gain a comprehensive understanding of outdoor 3D scenes.","The central insight of our LiDAR-LLM is the reformulation of 3D outdoor scene cognition as a language modeling problem, encompassing tasks such as 3D captioning, 3D grounding, 3D question answering, etc.","Specifically, due to the scarcity of 3D LiDAR-text pairing data, we introduce a three-stage training strategy and generate relevant datasets, progressively aligning the 3D modality with the language embedding space of LLM.","Furthermore, we design a View-Aware Transformer (VAT) to connect the 3D encoder with the LLM, which effectively bridges the modality gap and enhances the LLM's spatial orientation comprehension of visual features.","Our experiments show that LiDAR-LLM possesses favorable capabilities to comprehend various instructions regarding 3D scenes and engage in complex spatial reasoning.","LiDAR-LLM attains a 40.9 BLEU-1 on the 3D captioning task and achieves a 63.1\\% classification accuracy and a 14.3\\% BEV mIoU on the 3D grounding task.","Web page: https://sites.google.com/view/lidar-llm"],"url":"http://arxiv.org/abs/2312.14074v1"}
{"created":"2023-12-21 17:41:35","title":"Polynomial Time Convergence of the Iterative Evaluation of Datalogo Programs","abstract":"Datalogo is an extension of Datalog that allows for aggregation and recursion over an arbitrary commutative semiring. Like Datalog, Datalogo programs can be evaluated via the natural iterative algorithm until a fixed point is reached. However unlike Datalog, the natural iterative evaluation of some Datalogo programs over some semirings may not converge. It is known that the commutative semirings for which the iterative evaluation of Datalogo programs is guaranteed to converge are exactly those semirings that are stable~\\cite{Khamis0PSW22}. Previously, the best known upper bound on the number of iterations until convergence over $p$-stable semirings is $\\sum_{i=1}^n (p+2)^i = \\Theta(p^n)$ steps, where $n$ is (essentially) the output size. We establish that, in fact, the natural iterative evaluation of a Datalogoprogram over a $p$-stable semiring converges within a polynomial number of iterations. In particular our upper bound is $O( \\sigma p n^2( n^2 \\lg \\lambda + \\lg \\sigma))$ where $\\sigma$ is the number of elements in the semiring present in either the input databases or the Datalogo program, and $\\lambda$ is the maximum number of terms in any product in the Datalogo program.","sentences":["Datalogo is an extension of Datalog that allows for aggregation and recursion over an arbitrary commutative semiring.","Like Datalog, Datalogo programs can be evaluated via the natural iterative algorithm until a fixed point is reached.","However unlike Datalog, the natural iterative evaluation of some Datalogo programs over some semirings may not converge.","It is known that the commutative semirings for which the iterative evaluation of Datalogo programs is guaranteed to converge are exactly those semirings that are stable~\\cite{Khamis0PSW22}.","Previously, the best known upper bound on the number of iterations until convergence over $p$-stable semirings is $\\sum_{i=1}^n (p+2)^i = \\Theta(p^n)$ steps, where $n$ is (essentially) the output size.","We establish that, in fact, the natural iterative evaluation of a Datalogoprogram over a $p$-stable semiring converges within a polynomial number of iterations.","In particular our upper bound is $O( \\sigma p n^2( n^2 \\lg \\lambda + \\lg \\sigma))$ where $\\sigma$ is the number of elements in the semiring present in either the input databases or the Datalogo program, and $\\lambda$ is the maximum number of terms in any product in the Datalogo program."],"url":"http://arxiv.org/abs/2312.14063v1"}
{"created":"2023-12-21 17:23:49","title":"Dual Attention U-Net with Feature Infusion: Pushing the Boundaries of Multiclass Defect Segmentation","abstract":"The proposed architecture, Dual Attentive U-Net with Feature Infusion (DAU-FI Net), addresses challenges in semantic segmentation, particularly on multiclass imbalanced datasets with limited samples. DAU-FI Net integrates multiscale spatial-channel attention mechanisms and feature injection to enhance precision in object localization. The core employs a multiscale depth-separable convolution block, capturing localized patterns across scales. This block is complemented by a spatial-channel squeeze and excitation (scSE) attention unit, modeling inter-dependencies between channels and spatial regions in feature maps. Additionally, additive attention gates refine segmentation by connecting encoder-decoder pathways.   To augment the model, engineered features using Gabor filters for textural analysis, Sobel and Canny filters for edge detection are injected guided by semantic masks to expand the feature space strategically. Comprehensive experiments on a challenging sewer pipe and culvert defect dataset and a benchmark dataset validate DAU-FI Net's capabilities. Ablation studies highlight incremental benefits from attention blocks and feature injection. DAU-FI Net achieves state-of-the-art mean Intersection over Union (IoU) of 95.6% and 98.8% on the defect test set and benchmark respectively, surpassing prior methods by 8.9% and 12.6%, respectively. Ablation studies highlight incremental benefits from attention blocks and feature injection. The proposed architecture provides a robust solution, advancing semantic segmentation for multiclass problems with limited training data. Our sewer-culvert defects dataset, featuring pixel-level annotations, opens avenues for further research in this crucial domain. Overall, this work delivers key innovations in architecture, attention, and feature engineering to elevate semantic segmentation efficacy.","sentences":["The proposed architecture, Dual Attentive U-Net with Feature Infusion (DAU-FI Net), addresses challenges in semantic segmentation, particularly on multiclass imbalanced datasets with limited samples.","DAU-FI Net integrates multiscale spatial-channel attention mechanisms and feature injection to enhance precision in object localization.","The core employs a multiscale depth-separable convolution block, capturing localized patterns across scales.","This block is complemented by a spatial-channel squeeze and excitation (scSE) attention unit, modeling inter-dependencies between channels and spatial regions in feature maps.","Additionally, additive attention gates refine segmentation by connecting encoder-decoder pathways.   ","To augment the model, engineered features using Gabor filters for textural analysis, Sobel and Canny filters for edge detection are injected guided by semantic masks to expand the feature space strategically.","Comprehensive experiments on a challenging sewer pipe and culvert defect dataset and a benchmark dataset validate DAU-FI Net's capabilities.","Ablation studies highlight incremental benefits from attention blocks and feature injection.","DAU-FI Net achieves state-of-the-art mean Intersection over Union (IoU) of 95.6% and 98.8% on the defect test set and benchmark respectively, surpassing prior methods by 8.9% and 12.6%, respectively.","Ablation studies highlight incremental benefits from attention blocks and feature injection.","The proposed architecture provides a robust solution, advancing semantic segmentation for multiclass problems with limited training data.","Our sewer-culvert defects dataset, featuring pixel-level annotations, opens avenues for further research in this crucial domain.","Overall, this work delivers key innovations in architecture, attention, and feature engineering to elevate semantic segmentation efficacy."],"url":"http://arxiv.org/abs/2312.14053v1"}
{"created":"2023-12-21 17:06:30","title":"Balancing Specialization and Adaptation in a Transforming Scientific Landscape","abstract":"How scientists navigate between the need to capitalize on their prior knowledge by specializing, and the urge to adapt to evolving research opportunities? Drawing from diverse perspectives on adaptation, in particular from institutional change and cultural evolution, this paper proposes a Bayesian model of the evolution of scientists' research portfolios in response to transformations in their field. The model relies on scientific abstracts and authorship data to evaluate the influence of intellectual, social, and institutional resources on scientists' trajectories within a cohort of $2\\,195$ high-energy physicists between 2000 and 2019. The reallocation of research efforts in response to the incentives to adapt is shown to be mainly structured by learning costs, thus maximizing the utility of the scientific capital disseminated among scientists. Two dimensions of social capital, namely ``diversity'' and ``power'', have opposite effects on the magnitude of change in scientists' research interests: while ``diversity'' disrupts and expands research interests, ``power'' stabilizes physicists' research agendas -- as does institutional stability. Social capital plays a more crucial role in shifts between cognitively distant research areas.","sentences":["How scientists navigate between the need to capitalize on their prior knowledge by specializing, and the urge to adapt to evolving research opportunities?","Drawing from diverse perspectives on adaptation, in particular from institutional change and cultural evolution, this paper proposes a Bayesian model of the evolution of scientists' research portfolios in response to transformations in their field.","The model relies on scientific abstracts and authorship data to evaluate the influence of intellectual, social, and institutional resources on scientists' trajectories within a cohort of $2\\,195$ high-energy physicists between 2000 and 2019.","The reallocation of research efforts in response to the incentives to adapt is shown to be mainly structured by learning costs, thus maximizing the utility of the scientific capital disseminated among scientists.","Two dimensions of social capital, namely ``diversity'' and ``power'', have opposite effects on the magnitude of change in scientists' research interests: while ``diversity'' disrupts and expands research interests, ``power'' stabilizes physicists' research agendas -- as does institutional stability.","Social capital plays a more crucial role in shifts between cognitively distant research areas."],"url":"http://arxiv.org/abs/2312.14040v1"}
{"created":"2023-12-21 17:03:25","title":"Total variation in popular rap vocals from 2009-2023: extension of the analysis by Georgieva, Ripolles & McFee","abstract":"Pitch variability in rap vocals is overlooked in favor of the genre's uniquely dynamic rhythmic properties. We present an analysis of fundamental frequency (F0) variation in rap vocals over the past 14 years, focusing on song examples that represent the state of modern rap music. Our analysis aims at identifying meaningful trends over time, and is in turn a continuation of the 2023 analysis by Georgieva, Ripolles & McFee. They found rap to be an outlier with larger F0 variation compared to other genres, but with a declining trend since the genre's inception. However, they only analyzed data through 2010. Our analysis looks beyond 2010. We once again observe rap's large F0 variation, but with a decelerated decline in recent years.","sentences":["Pitch variability in rap vocals is overlooked in favor of the genre's uniquely dynamic rhythmic properties.","We present an analysis of fundamental frequency (F0) variation in rap vocals over the past 14 years, focusing on song examples that represent the state of modern rap music.","Our analysis aims at identifying meaningful trends over time, and is in turn a continuation of the 2023 analysis by Georgieva, Ripolles & McFee.","They found rap to be an outlier with larger F0 variation compared to other genres, but with a declining trend since the genre's inception.","However, they only analyzed data through 2010.","Our analysis looks beyond 2010.","We once again observe rap's large F0 variation, but with a decelerated decline in recent years."],"url":"http://arxiv.org/abs/2312.14036v1"}
{"created":"2023-12-21 16:59:41","title":"Phylogenetic tree distance computation over succinct representations","abstract":"There are several tools available to infer phylogenetic trees, which depict the evolutionary relationships among biological entities such as viral and bacterial strains in infectious outbreaks, or cancerous cells in tumor progression trees. These tools rely on several inference methods available to produce phylogenetic trees, with resulting trees not being unique. Thus, methods for comparing phylogenies that are capable of revealing where two phylogenetic trees agree or differ are required. An approach is then to compute a similarity or dissimilarity measure between trees, with the Robinson- Foulds distance being one of the most used, and which can be computed in linear time and space. Nevertheless, given the large and increasing volume of phylogenetic data, phylogenetic trees are becoming very large with hundreds of thousands of leafs. In this context, space requirements become an issue both while computing tree distances and while storing trees. We propose then an efficient implementation of the Robinson-Foulds distance over trees succinct representations. Our implementation generalizes also the Robinson-Foulds distances to labelled phylogenetic trees, i.e., trees containing labels on all nodes, instead of only on leaves. Experimental results show that we are able to still achieve linear time while requiring less space. Our implementation is available as an open-source tool at https://github.com/pedroparedesbranco/TreeDiff.","sentences":["There are several tools available to infer phylogenetic trees, which depict the evolutionary relationships among biological entities such as viral and bacterial strains in infectious outbreaks, or cancerous cells in tumor progression trees.","These tools rely on several inference methods available to produce phylogenetic trees, with resulting trees not being unique.","Thus, methods for comparing phylogenies that are capable of revealing where two phylogenetic trees agree or differ are required.","An approach is then to compute a similarity or dissimilarity measure between trees, with the Robinson- Foulds distance being one of the most used, and which can be computed in linear time and space.","Nevertheless, given the large and increasing volume of phylogenetic data, phylogenetic trees are becoming very large with hundreds of thousands of leafs.","In this context, space requirements become an issue both while computing tree distances and while storing trees.","We propose then an efficient implementation of the Robinson-Foulds distance over trees succinct representations.","Our implementation generalizes also the Robinson-Foulds distances to labelled phylogenetic trees, i.e., trees containing labels on all nodes, instead of only on leaves.","Experimental results show that we are able to still achieve linear time while requiring less space.","Our implementation is available as an open-source tool at https://github.com/pedroparedesbranco/TreeDiff."],"url":"http://arxiv.org/abs/2312.14029v1"}
{"created":"2023-12-21 16:54:09","title":"Geometric Awareness in Neural Fields for 3D Human Registration","abstract":"Aligning a template to 3D human point clouds is a long-standing problem crucial for tasks like animation, reconstruction, and enabling supervised learning pipelines. Recent data-driven methods leverage predicted surface correspondences; however, they are not robust to varied poses or distributions. In contrast, industrial solutions often rely on expensive manual annotations or multi-view capturing systems. Recently, neural fields have shown promising results, but their purely data-driven nature lacks geometric awareness, often resulting in a trivial misalignment of the template registration. In this work, we propose two solutions: LoVD, a novel neural field model that predicts the direction towards the localized SMPL vertices on the target surface; and INT, the first self-supervised task dedicated to neural fields that, at test time, refines the backbone, exploiting the target geometry. We combine them into INLoVD, a robust 3D Human body registration pipeline trained on a large MoCap dataset. INLoVD is efficient (takes less than a minute), solidly achieves the state of the art over public benchmarks, and provides unprecedented generalization on out-of-distribution data. We will release code and checkpoints in \\url{url}.","sentences":["Aligning a template to 3D human point clouds is a long-standing problem crucial for tasks like animation, reconstruction, and enabling supervised learning pipelines.","Recent data-driven methods leverage predicted surface correspondences; however, they are not robust to varied poses or distributions.","In contrast, industrial solutions often rely on expensive manual annotations or multi-view capturing systems.","Recently, neural fields have shown promising results, but their purely data-driven nature lacks geometric awareness, often resulting in a trivial misalignment of the template registration.","In this work, we propose two solutions: LoVD, a novel neural field model that predicts the direction towards the localized SMPL vertices on the target surface; and INT, the first self-supervised task dedicated to neural fields that, at test time, refines the backbone, exploiting the target geometry.","We combine them into INLoVD, a robust 3D Human body registration pipeline trained on a large MoCap dataset.","INLoVD is efficient (takes less than a minute), solidly achieves the state of the art over public benchmarks, and provides unprecedented generalization on out-of-distribution data.","We will release code and checkpoints in \\url{url}."],"url":"http://arxiv.org/abs/2312.14024v1"}
{"created":"2023-12-21 16:52:41","title":"BANSpEmo: A Bangla Emotional Speech Recognition Dataset","abstract":"In the field of audio and speech analysis, the ability to identify emotions from acoustic signals is essential. Human-computer interaction (HCI) and behavioural analysis are only a few of the many areas where the capacity to distinguish emotions from speech signals has an extensive range of applications. Here, we are introducing BanSpEmo, a corpus of emotional speech that only consists of audio recordings and has been created specifically for the Bangla language. This corpus contains 792 audio recordings over a duration of more than 1 hour and 23 minutes. 22 native speakers took part in the recording of two sets of sentences that represent the six desired emotions. The data set consists of 12 Bangla sentences which are uttered in 6 emotions as Disgust, Happy, Sad, Surprised, Anger, and Fear. This corpus is not also gender balanced. Ten individuals who either have experience in related field or have acting experience took part in the assessment of this corpus. It has a balanced number of audio recordings in each emotion class. BanSpEmo can be considered as a useful resource to promote emotion and speech recognition research and related applications in the Bangla language. The dataset can be found here: https://data.mendeley.com/datasets/rdwn4bs5ky and might be employed for academic research.","sentences":["In the field of audio and speech analysis, the ability to identify emotions from acoustic signals is essential.","Human-computer interaction (HCI) and behavioural analysis are only a few of the many areas where the capacity to distinguish emotions from speech signals has an extensive range of applications.","Here, we are introducing BanSpEmo, a corpus of emotional speech that only consists of audio recordings and has been created specifically for the Bangla language.","This corpus contains 792 audio recordings over a duration of more than 1 hour and 23 minutes.","22 native speakers took part in the recording of two sets of sentences that represent the six desired emotions.","The data set consists of 12 Bangla sentences which are uttered in 6 emotions as Disgust, Happy, Sad, Surprised, Anger, and Fear.","This corpus is not also gender balanced.","Ten individuals who either have experience in related field or have acting experience took part in the assessment of this corpus.","It has a balanced number of audio recordings in each emotion class.","BanSpEmo can be considered as a useful resource to promote emotion and speech recognition research and related applications in the Bangla language.","The dataset can be found here: https://data.mendeley.com/datasets/rdwn4bs5ky and might be employed for academic research."],"url":"http://arxiv.org/abs/2312.14020v1"}
{"created":"2023-12-21 16:35:11","title":"Deep Learning Based Face Recognition Method using Siamese Network","abstract":"Achieving state-of-the-art results in face verification systems typically hinges on the availability of labeled face training data, a resource that often proves challenging to acquire in substantial quantities. In this research endeavor, we proposed employing Siamese networks for face recognition, eliminating the need for labeled face images. We achieve this by strategically leveraging negative samples alongside nearest neighbor counterparts, thereby establishing positive and negative pairs through an unsupervised methodology. The architectural framework adopts a VGG encoder, trained as a double branch siamese network. Our primary aim is to circumvent the necessity for labeled face image data, thus proposing the generation of training pairs in an entirely unsupervised manner. Positive training data are selected within a dataset based on their highest cosine similarity scores with a designated anchor, while negative training data are culled in a parallel fashion, though drawn from an alternate dataset. During training, the proposed siamese network conducts binary classification via cross-entropy loss. Subsequently, during the testing phase, we directly extract face verification scores from the network's output layer. Experimental results reveal that the proposed unsupervised system delivers a performance on par with a similar but fully supervised baseline.","sentences":["Achieving state-of-the-art results in face verification systems typically hinges on the availability of labeled face training data, a resource that often proves challenging to acquire in substantial quantities.","In this research endeavor, we proposed employing Siamese networks for face recognition, eliminating the need for labeled face images.","We achieve this by strategically leveraging negative samples alongside nearest neighbor counterparts, thereby establishing positive and negative pairs through an unsupervised methodology.","The architectural framework adopts a VGG encoder, trained as a double branch siamese network.","Our primary aim is to circumvent the necessity for labeled face image data, thus proposing the generation of training pairs in an entirely unsupervised manner.","Positive training data are selected within a dataset based on their highest cosine similarity scores with a designated anchor, while negative training data are culled in a parallel fashion, though drawn from an alternate dataset.","During training, the proposed siamese network conducts binary classification via cross-entropy loss.","Subsequently, during the testing phase, we directly extract face verification scores from the network's output layer.","Experimental results reveal that the proposed unsupervised system delivers a performance on par with a similar but fully supervised baseline."],"url":"http://arxiv.org/abs/2312.14001v1"}
{"created":"2023-12-21 16:28:08","title":"Open-Set: ID Card Presentation Attack Detection using Neural Transfer Style","abstract":"The accurate detection of ID card Presentation Attacks (PA) is becoming increasingly important due to the rising number of online/remote services that require the presentation of digital photographs of ID cards for digital onboarding or authentication. Furthermore, cybercriminals are continuously searching for innovative ways to fool authentication systems to gain unauthorized access to these services. Although advances in neural network design and training have pushed image classification to the state of the art, one of the main challenges faced by the development of fraud detection systems is the curation of representative datasets for training and evaluation. The handcrafted creation of representative presentation attack samples often requires expertise and is very time-consuming, thus an automatic process of obtaining high-quality data is highly desirable. This work explores ID card Presentation Attack Instruments (PAI) in order to improve the generation of samples with four Generative Adversarial Networks (GANs) based image translation models and analyses the effectiveness of the generated data for training fraud detection systems. Using open-source data, we show that synthetic attack presentations are an adequate complement for additional real attack presentations, where we obtain an EER performance increase of 0.63% points for print attacks and a loss of 0.29% for screen capture attacks.","sentences":["The accurate detection of ID card Presentation Attacks (PA) is becoming increasingly important due to the rising number of online/remote services that require the presentation of digital photographs of ID cards for digital onboarding or authentication.","Furthermore, cybercriminals are continuously searching for innovative ways to fool authentication systems to gain unauthorized access to these services.","Although advances in neural network design and training have pushed image classification to the state of the art, one of the main challenges faced by the development of fraud detection systems is the curation of representative datasets for training and evaluation.","The handcrafted creation of representative presentation attack samples often requires expertise and is very time-consuming, thus an automatic process of obtaining high-quality data is highly desirable.","This work explores ID card Presentation Attack Instruments (PAI) in order to improve the generation of samples with four Generative Adversarial Networks (GANs) based image translation models and analyses the effectiveness of the generated data for training fraud detection systems.","Using open-source data, we show that synthetic attack presentations are an adequate complement for additional real attack presentations, where we obtain an EER performance increase of 0.63% points for print attacks and a loss of 0.29% for screen capture attacks."],"url":"http://arxiv.org/abs/2312.13993v1"}
{"created":"2023-12-21 16:18:33","title":"R\u00e9nyi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration","abstract":"Pufferfish privacy is a flexible generalization of differential privacy that allows to model arbitrary secrets and adversary's prior knowledge about the data. Unfortunately, designing general and tractable Pufferfish mechanisms that do not compromise utility is challenging. Furthermore, this framework does not provide the composition guarantees needed for a direct use in iterative machine learning algorithms. To mitigate these issues, we introduce a R\\'enyi divergence-based variant of Pufferfish and show that it allows us to extend the applicability of the Pufferfish framework. We first generalize the Wasserstein mechanism to cover a wide range of noise distributions and introduce several ways to improve its utility. We also derive stronger guarantees against out-of-distribution adversaries. Finally, as an alternative to composition, we prove privacy amplification results for contractive noisy iterations and showcase the first use of Pufferfish in private convex optimization. A common ingredient underlying our results is the use and extension of shift reduction lemmas.","sentences":["Pufferfish privacy is a flexible generalization of differential privacy that allows to model arbitrary secrets and adversary's prior knowledge about the data.","Unfortunately, designing general and tractable Pufferfish mechanisms that do not compromise utility is challenging.","Furthermore, this framework does not provide the composition guarantees needed for a direct use in iterative machine learning algorithms.","To mitigate these issues, we introduce a R\\'enyi divergence-based variant of Pufferfish and show that it allows us to extend the applicability of the Pufferfish framework.","We first generalize the Wasserstein mechanism to cover a wide range of noise distributions and introduce several ways to improve its utility.","We also derive stronger guarantees against out-of-distribution adversaries.","Finally, as an alternative to composition, we prove privacy amplification results for contractive noisy iterations and showcase the first use of Pufferfish in private convex optimization.","A common ingredient underlying our results is the use and extension of shift reduction lemmas."],"url":"http://arxiv.org/abs/2312.13985v1"}
{"created":"2023-12-21 16:10:33","title":"Carve3D: Improving Multi-view Reconstruction Consistency for Diffusion Models with RL Finetuning","abstract":"Recent advancements in the text-to-3D task leverage finetuned text-to-image diffusion models to generate multi-view images, followed by NeRF reconstruction. Yet, existing supervised finetuned (SFT) diffusion models still suffer from multi-view inconsistency and the resulting NeRF artifacts. Although training longer with SFT improves consistency, it also causes distribution shift, which reduces diversity and realistic details. We argue that the SFT of multi-view diffusion models resembles the instruction finetuning stage of the LLM alignment pipeline and can benefit from RL finetuning (RLFT) methods. Essentially, RLFT methods optimize models beyond their SFT data distribution by using their own outputs, effectively mitigating distribution shift. To this end, we introduce Carve3D, a RLFT method coupled with the Multi-view Reconstruction Consistency (MRC) metric, to improve the consistency of multi-view diffusion models. To compute MRC on a set of multi-view images, we compare them with their corresponding renderings of the reconstructed NeRF at the same viewpoints. We validate the robustness of MRC with extensive experiments conducted under controlled inconsistency levels. We enhance the base RLFT algorithm to stabilize the training process, reduce distribution shift, and identify scaling laws. Through qualitative and quantitative experiments, along with a user study, we demonstrate Carve3D's improved multi-view consistency, the resulting superior NeRF reconstruction quality, and minimal distribution shift compared to longer SFT. Project webpage: https://desaixie.github.io/carve-3d.","sentences":["Recent advancements in the text-to-3D task leverage finetuned text-to-image diffusion models to generate multi-view images, followed by NeRF reconstruction.","Yet, existing supervised finetuned (SFT) diffusion models still suffer from multi-view inconsistency and the resulting NeRF artifacts.","Although training longer with SFT improves consistency, it also causes distribution shift, which reduces diversity and realistic details.","We argue that the SFT of multi-view diffusion models resembles the instruction finetuning stage of the LLM alignment pipeline and can benefit from RL finetuning (RLFT) methods.","Essentially, RLFT methods optimize models beyond their SFT data distribution by using their own outputs, effectively mitigating distribution shift.","To this end, we introduce Carve3D, a RLFT method coupled with the Multi-view Reconstruction Consistency (MRC) metric, to improve the consistency of multi-view diffusion models.","To compute MRC on a set of multi-view images, we compare them with their corresponding renderings of the reconstructed NeRF at the same viewpoints.","We validate the robustness of MRC with extensive experiments conducted under controlled inconsistency levels.","We enhance the base RLFT algorithm to stabilize the training process, reduce distribution shift, and identify scaling laws.","Through qualitative and quantitative experiments, along with a user study, we demonstrate Carve3D's improved multi-view consistency, the resulting superior NeRF reconstruction quality, and minimal distribution shift compared to longer SFT.","Project webpage: https://desaixie.github.io/carve-3d."],"url":"http://arxiv.org/abs/2312.13980v1"}
{"created":"2023-12-21 16:06:44","title":"Metalearning with Very Few Samples Per Task","abstract":"Metalearning and multitask learning are two frameworks for solving a group of related learning tasks more efficiently than we could hope to solve each of the individual tasks on their own. In multitask learning, we are given a fixed set of related learning tasks and need to output one accurate model per task, whereas in metalearning we are given tasks that are drawn i.i.d. from a metadistribution and need to output some common information that can be easily specialized to new, previously unseen tasks from the metadistribution.   In this work, we consider a binary classification setting where tasks are related by a shared representation, that is, every task $P$ of interest can be solved by a classifier of the form $f_{P} \\circ h$ where $h \\in H$ is a map from features to some representation space that is shared across tasks, and $f_{P} \\in F$ is a task-specific classifier from the representation space to labels. The main question we ask in this work is how much data do we need to metalearn a good representation? Here, the amount of data is measured in terms of both the number of tasks $t$ that we need to see and the number of samples $n$ per task. We focus on the regime where the number of samples per task is extremely small. Our main result shows that, in a distribution-free setting where the feature vectors are in $\\mathbb{R}^d$, the representation is a linear map from $\\mathbb{R}^d \\to \\mathbb{R}^k$, and the task-specific classifiers are halfspaces in $\\mathbb{R}^k$, we can metalearn a representation with error $\\varepsilon$ using just $n = k+2$ samples per task, and $d \\cdot (1/\\varepsilon)^{O(k)}$ tasks. Learning with so few samples per task is remarkable because metalearning would be impossible with $k+1$ samples per task, and because we cannot even hope to learn an accurate task-specific classifier with just $k+2$ samples per task.","sentences":["Metalearning and multitask learning are two frameworks for solving a group of related learning tasks more efficiently than we could hope to solve each of the individual tasks on their own.","In multitask learning, we are given a fixed set of related learning tasks and need to output one accurate model per task, whereas in metalearning we are given tasks that are drawn i.i.d. from a metadistribution and need to output some common information that can be easily specialized to new, previously unseen tasks from the metadistribution.   ","In this work, we consider a binary classification setting where tasks are related by a shared representation, that is, every task $P$ of interest can be solved by a classifier of the form $f_{P} \\circ h$ where $h \\in H$ is a map from features to some representation space that is shared across tasks, and $f_{P} \\in F$ is a task-specific classifier from the representation space to labels.","The main question we ask in this work is how much data do we need to metalearn a good representation?","Here, the amount of data is measured in terms of both the number of tasks $t$ that we need to see and the number of samples $n$ per task.","We focus on the regime where the number of samples per task is extremely small.","Our main result shows that, in a distribution-free setting where the feature vectors are in $\\mathbb{R}^d$, the representation is a linear map from $\\mathbb{R}^d \\to \\mathbb{R}^k$, and the task-specific classifiers are halfspaces in $\\mathbb{R}^k$, we can metalearn a representation with error $\\varepsilon$ using just $n = k+2$ samples per task, and $d \\cdot (1/\\varepsilon)^{O(k)}$ tasks.","Learning with so few samples per task is remarkable because metalearning would be impossible with $k+1$ samples per task, and because we cannot even hope to learn an accurate task-specific classifier with just $k+2$ samples per task."],"url":"http://arxiv.org/abs/2312.13978v1"}
{"created":"2023-12-21 16:03:07","title":"A Joint Communication and Computation Design for Semantic Wireless Communication with Probability Graph","abstract":"In this paper, we delve into the challenge of optimizing joint communication and computation for semantic communication over wireless networks using a probability graph framework. In the considered model, the base station (BS) extracts the small-sized compressed semantic information through removing redundant messages based on the stored knowledge base. Specifically, the knowledge base is encapsulated in a probability graph that encapsulates statistical relations. At the user side, the compressed information is accurately deduced using the same probability graph employed by the BS. While this approach introduces an additional computational overhead for semantic information extraction, it significantly curtails communication resource consumption by transmitting concise data. We derive both communication and computation cost models based on the inference process of the probability graph. Building upon these models, we introduce a joint communication and computation resource allocation problem aimed at minimizing the overall energy consumption of the network, while accounting for latency, power, and semantic constraints. To address this problem, we obtain a closed-form solution for transmission power under a fixed semantic compression ratio. Subsequently, we propose an efficient linear search-based algorithm to attain the optimal solution for the considered problem with low computational complexity. Simulation results underscore the effectiveness of our proposed system, showcasing notable improvements compared to conventional non-semantic schemes.","sentences":["In this paper, we delve into the challenge of optimizing joint communication and computation for semantic communication over wireless networks using a probability graph framework.","In the considered model, the base station (BS) extracts the small-sized compressed semantic information through removing redundant messages based on the stored knowledge base.","Specifically, the knowledge base is encapsulated in a probability graph that encapsulates statistical relations.","At the user side, the compressed information is accurately deduced using the same probability graph employed by the BS.","While this approach introduces an additional computational overhead for semantic information extraction, it significantly curtails communication resource consumption by transmitting concise data.","We derive both communication and computation cost models based on the inference process of the probability graph.","Building upon these models, we introduce a joint communication and computation resource allocation problem aimed at minimizing the overall energy consumption of the network, while accounting for latency, power, and semantic constraints.","To address this problem, we obtain a closed-form solution for transmission power under a fixed semantic compression ratio.","Subsequently, we propose an efficient linear search-based algorithm to attain the optimal solution for the considered problem with low computational complexity.","Simulation results underscore the effectiveness of our proposed system, showcasing notable improvements compared to conventional non-semantic schemes."],"url":"http://arxiv.org/abs/2312.13975v1"}
{"created":"2023-12-21 15:38:41","title":"Typhoon: Thai Large Language Models","abstract":"Typhoon is a series of Thai large language models (LLMs) developed specifically for the Thai language. This technical report presents challenges and insights in developing Thai LLMs, including data preparation, pretraining, instruction-tuning, and evaluation. As one of the challenges of low-resource languages is the amount of pretraining data, we apply continual training to transfer existing world knowledge from a strong LLM. To evaluate the Thai knowledge encapsulated in each model from the pretraining stage, we develop ThaiExam, a benchmark based on examinations for high-school students and investment professionals in Thailand. In addition, we fine-tune Typhoon to follow Thai instructions, and we evaluate instruction-tuned models on Thai instruction datasets as well as translation, summarization, and question-answering tasks. Experimental results on a suite of Thai benchmarks show that Typhoon outperforms all open-source Thai language models, and its performance is on par with GPT-3.5 in Thai while having only 7 billion parameters and being 2.62 times more efficient in tokenizing Thai text.","sentences":["Typhoon is a series of Thai large language models (LLMs) developed specifically for the Thai language.","This technical report presents challenges and insights in developing Thai LLMs, including data preparation, pretraining, instruction-tuning, and evaluation.","As one of the challenges of low-resource languages is the amount of pretraining data, we apply continual training to transfer existing world knowledge from a strong LLM.","To evaluate the Thai knowledge encapsulated in each model from the pretraining stage, we develop ThaiExam, a benchmark based on examinations for high-school students and investment professionals in Thailand.","In addition, we fine-tune Typhoon to follow Thai instructions, and we evaluate instruction-tuned models on Thai instruction datasets as well as translation, summarization, and question-answering tasks.","Experimental results on a suite of Thai benchmarks show that Typhoon outperforms all open-source Thai language models, and its performance is on par with GPT-3.5 in Thai while having only 7 billion parameters and being 2.62 times more efficient in tokenizing Thai text."],"url":"http://arxiv.org/abs/2312.13951v1"}
{"created":"2023-12-21 15:32:49","title":"Controllable 3D Face Generation with Conditional Style Code Diffusion","abstract":"Generating photorealistic 3D faces from given conditions is a challenging task. Existing methods often rely on time-consuming one-by-one optimization approaches, which are not efficient for modeling the same distribution content, e.g., faces. Additionally, an ideal controllable 3D face generation model should consider both facial attributes and expressions. Thus we propose a novel approach called TEx-Face(TExt & Expression-to-Face) that addresses these challenges by dividing the task into three components, i.e., 3D GAN Inversion, Conditional Style Code Diffusion, and 3D Face Decoding. For 3D GAN inversion, we introduce two methods which aim to enhance the representation of style codes and alleviate 3D inconsistencies. Furthermore, we design a style code denoiser to incorporate multiple conditions into the style code and propose a data augmentation strategy to address the issue of insufficient paired visual-language data. Extensive experiments conducted on FFHQ, CelebA-HQ, and CelebA-Dialog demonstrate the promising performance of our TEx-Face in achieving the efficient and controllable generation of photorealistic 3D faces. The code will be available at https://github.com/sxl142/TEx-Face.","sentences":["Generating photorealistic 3D faces from given conditions is a challenging task.","Existing methods often rely on time-consuming one-by-one optimization approaches, which are not efficient for modeling the same distribution content, e.g., faces.","Additionally, an ideal controllable 3D face generation model should consider both facial attributes and expressions.","Thus we propose a novel approach called TEx-Face(TExt & Expression-to-Face) that addresses these challenges by dividing the task into three components, i.e., 3D GAN Inversion, Conditional Style Code Diffusion, and 3D Face Decoding.","For 3D GAN inversion, we introduce two methods which aim to enhance the representation of style codes and alleviate 3D inconsistencies.","Furthermore, we design a style code denoiser to incorporate multiple conditions into the style code and propose a data augmentation strategy to address the issue of insufficient paired visual-language data.","Extensive experiments conducted on FFHQ, CelebA-HQ, and CelebA-Dialog demonstrate the promising performance of our TEx-Face in achieving the efficient and controllable generation of photorealistic 3D faces.","The code will be available at https://github.com/sxl142/TEx-Face."],"url":"http://arxiv.org/abs/2312.13941v1"}
{"created":"2023-12-21 15:32:46","title":"Stairway to heaven: designing for an embodied experience with satellite data","abstract":"This paper explores the design of an interactive installation in a science center which facilitates an embodied experience with satellite data. This addresses a central concern for experience design in museums, which is the question of how to integrate technologies well in the visitor experience, sometimes referred to as \"experience blend\". We present the design and evaluation of a visualization triggered by movement in a physical staircase to let visitors explore data about satellites at different orbits. The evaluation demonstrates strong experience blend, and points towards similar design opportunities for other institutions interested in finding new uses for mundane pathways through their buildings.","sentences":["This paper explores the design of an interactive installation in a science center which facilitates an embodied experience with satellite data.","This addresses a central concern for experience design in museums, which is the question of how to integrate technologies well in the visitor experience, sometimes referred to as \"experience blend\".","We present the design and evaluation of a visualization triggered by movement in a physical staircase to let visitors explore data about satellites at different orbits.","The evaluation demonstrates strong experience blend, and points towards similar design opportunities for other institutions interested in finding new uses for mundane pathways through their buildings."],"url":"http://arxiv.org/abs/2312.13940v1"}
{"created":"2023-12-21 15:28:02","title":"Structured Probabilistic Coding","abstract":"This paper presents a new supervised representation learning framework, namely Structured Probabilistic Coding (SPC), to learn compact and informative representations from input related to the target task. SPC is an encoder-only probabilistic coding technology with a structured regularization from the target label space. By extracting compact and informative representations from input related to the target task, SPC can enhance the generalization ability of pre-trained language models for better language understanding. Specifically, the hidden representation is encoded into a Gaussian distribution space, while maximizing the prior entropy of latent representations concerning label space. This technique can simultaneously perform information encoding and task prediction in one module to more fully utilize the effective information from input data, and use variational inference in the output space to reduce randomness and uncertainty. To better control the probability distribution in the latent space, a structured regularization is proposed to promote class-level uniformity in the latent space. With the regularization term, SPC can preserve the Gaussian distribution structure of latent code as well as better cover the hidden space with class uniformly. We conduct evaluations on 12 natural language understanding tasks. The results show that our SPC can effectively improve the performance of pre-trained language models for various classification and regression tasks. Experiments demonstrate that SPC can enhance the generalization capability, robustness to label noise, and clustering quality of output representations.","sentences":["This paper presents a new supervised representation learning framework, namely Structured Probabilistic Coding (SPC), to learn compact and informative representations from input related to the target task.","SPC is an encoder-only probabilistic coding technology with a structured regularization from the target label space.","By extracting compact and informative representations from input related to the target task, SPC can enhance the generalization ability of pre-trained language models for better language understanding.","Specifically, the hidden representation is encoded into a Gaussian distribution space, while maximizing the prior entropy of latent representations concerning label space.","This technique can simultaneously perform information encoding and task prediction in one module to more fully utilize the effective information from input data, and use variational inference in the output space to reduce randomness and uncertainty.","To better control the probability distribution in the latent space, a structured regularization is proposed to promote class-level uniformity in the latent space.","With the regularization term, SPC can preserve the Gaussian distribution structure of latent code as well as better cover the hidden space with class uniformly.","We conduct evaluations on 12 natural language understanding tasks.","The results show that our SPC can effectively improve the performance of pre-trained language models for various classification and regression tasks.","Experiments demonstrate that SPC can enhance the generalization capability, robustness to label noise, and clustering quality of output representations."],"url":"http://arxiv.org/abs/2312.13933v1"}
{"created":"2023-12-21 15:26:26","title":"Joint Sensing and Task-Oriented Communications with Image and Wireless Data Modalities for Dynamic Spectrum Access","abstract":"This paper introduces a deep learning approach to dynamic spectrum access, leveraging the synergy of multi-modal image and spectrum data for the identification of potential transmitters. We consider an edge device equipped with a camera that is taking images of potential objects such as vehicles that may harbor transmitters. Recognizing the computational constraints and trust issues associated with on-device computation, we propose a collaborative system wherein the edge device communicates selectively processed information to a trusted receiver acting as a fusion center, where a decision is made to identify whether a potential transmitter is present, or not. To achieve this, we employ task-oriented communications, utilizing an encoder at the transmitter for joint source coding, channel coding, and modulation. This architecture efficiently transmits essential information of reduced dimension for object classification. Simultaneously, the transmitted signals may reflect off objects and return to the transmitter, allowing for the collection of target sensing data. Then the collected sensing data undergoes a second round of encoding at the transmitter, with the reduced-dimensional information communicated back to the fusion center through task-oriented communications. On the receiver side, a decoder performs the task of identifying a transmitter by fusing data received through joint sensing and task-oriented communications. The two encoders at the transmitter and the decoder at the receiver are jointly trained, enabling a seamless integration of image classification and wireless signal detection. Using AWGN and Rayleigh channel models, we demonstrate the effectiveness of the proposed approach, showcasing high accuracy in transmitter identification across diverse channel conditions while sustaining low latency in decision making.","sentences":["This paper introduces a deep learning approach to dynamic spectrum access, leveraging the synergy of multi-modal image and spectrum data for the identification of potential transmitters.","We consider an edge device equipped with a camera that is taking images of potential objects such as vehicles that may harbor transmitters.","Recognizing the computational constraints and trust issues associated with on-device computation, we propose a collaborative system wherein the edge device communicates selectively processed information to a trusted receiver acting as a fusion center, where a decision is made to identify whether a potential transmitter is present, or not.","To achieve this, we employ task-oriented communications, utilizing an encoder at the transmitter for joint source coding, channel coding, and modulation.","This architecture efficiently transmits essential information of reduced dimension for object classification.","Simultaneously, the transmitted signals may reflect off objects and return to the transmitter, allowing for the collection of target sensing data.","Then the collected sensing data undergoes a second round of encoding at the transmitter, with the reduced-dimensional information communicated back to the fusion center through task-oriented communications.","On the receiver side, a decoder performs the task of identifying a transmitter by fusing data received through joint sensing and task-oriented communications.","The two encoders at the transmitter and the decoder at the receiver are jointly trained, enabling a seamless integration of image classification and wireless signal detection.","Using AWGN and Rayleigh channel models, we demonstrate the effectiveness of the proposed approach, showcasing high accuracy in transmitter identification across diverse channel conditions while sustaining low latency in decision making."],"url":"http://arxiv.org/abs/2312.13931v1"}
{"created":"2023-12-21 15:12:12","title":"Fed-CO$_{2}$: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning","abstract":"Federated Learning (FL) has emerged as a promising distributed learning paradigm that enables multiple clients to learn a global model collaboratively without sharing their private data. However, the effectiveness of FL is highly dependent on the quality of the data that is being used for training. In particular, data heterogeneity issues, such as label distribution skew and feature skew, can significantly impact the performance of FL. Previous studies in FL have primarily focused on addressing label distribution skew data heterogeneity, while only a few recent works have made initial progress in tackling feature skew issues. Notably, these two forms of data heterogeneity have been studied separately and have not been well explored within a unified FL framework. To address this gap, we propose Fed-CO$_{2}$, a universal FL framework that handles both label distribution skew and feature skew within a \\textbf{C}ooperation mechanism between the \\textbf{O}nline and \\textbf{O}ffline models. Specifically, the online model learns general knowledge that is shared among all clients, while the offline model is trained locally to learn the specialized knowledge of each individual client. To further enhance model cooperation in the presence of feature shifts, we design an intra-client knowledge transfer mechanism that reinforces mutual learning between the online and offline models, and an inter-client knowledge transfer mechanism to increase the models' domain generalization ability. Extensive experiments show that our Fed-CO$_{2}$ outperforms a wide range of existing personalized federated learning algorithms in terms of handling label distribution skew and feature skew, both individually and collectively. The empirical results are supported by our convergence analyses in a simplified setting.","sentences":["Federated Learning (FL) has emerged as a promising distributed learning paradigm that enables multiple clients to learn a global model collaboratively without sharing their private data.","However, the effectiveness of FL is highly dependent on the quality of the data that is being used for training.","In particular, data heterogeneity issues, such as label distribution skew and feature skew, can significantly impact the performance of FL.","Previous studies in FL have primarily focused on addressing label distribution skew data heterogeneity, while only a few recent works have made initial progress in tackling feature skew issues.","Notably, these two forms of data heterogeneity have been studied separately and have not been well explored within a unified FL framework.","To address this gap, we propose Fed-CO$_{2}$, a universal FL framework that handles both label distribution skew and feature skew within a \\textbf{C}ooperation mechanism between the \\textbf{O}nline and \\textbf{O}ffline models.","Specifically, the online model learns general knowledge that is shared among all clients, while the offline model is trained locally to learn the specialized knowledge of each individual client.","To further enhance model cooperation in the presence of feature shifts, we design an intra-client knowledge transfer mechanism that reinforces mutual learning between the online and offline models, and an inter-client knowledge transfer mechanism to increase the models' domain generalization ability.","Extensive experiments show that our Fed-CO$_{2}$ outperforms a wide range of existing personalized federated learning algorithms in terms of handling label distribution skew and feature skew, both individually and collectively.","The empirical results are supported by our convergence analyses in a simplified setting."],"url":"http://arxiv.org/abs/2312.13923v1"}
{"created":"2023-12-21 15:07:51","title":"Age of Actuation and Timeliness: Semantics in a Wireless Power Transfer System","abstract":"In this paper, we investigate a model relevant to semantics-aware goal-oriented communications, and we propose a new metric that incorporates the utilization of information in addition to its timelines. Specifically, we consider the transmission of observations from an external process to a battery-powered receiver through status updates. These updates inform the receiver about the process status and enable actuation if sufficient energy is available to achieve a goal. We focus on a wireless power transfer (WPT) model, where the receiver receives energy from a dedicated power transmitter and occasionally from the data transmitter when they share a common channel. We analyze the Age of Information (AoI) and propose a new metric, the \\textit{Age of Actuation (AoA), which is relevant when the receiver utilizes the status updates to perform actions in a timely manner}. We provide analytical characterizations of the average AoA and the violation probability of the AoA, demonstrating that AoA generalizes AoI. Moreover, we introduce and analytically characterize the \\textit{Probability of Missing Actuation (PoMA)}; this metric becomes relevant also \\textit{to quantify the incurred cost of a missed action}. We formulate unconstrained and constrained optimization problems for all the metrics and present numerical evaluations of our analytical results. This proposed set of metrics goes beyond the traditional timeliness metrics since the synergy of different flows is now considered.","sentences":["In this paper, we investigate a model relevant to semantics-aware goal-oriented communications, and we propose a new metric that incorporates the utilization of information in addition to its timelines.","Specifically, we consider the transmission of observations from an external process to a battery-powered receiver through status updates.","These updates inform the receiver about the process status and enable actuation if sufficient energy is available to achieve a goal.","We focus on a wireless power transfer (WPT) model, where the receiver receives energy from a dedicated power transmitter and occasionally from the data transmitter when they share a common channel.","We analyze the Age of Information (AoI) and propose a new metric, the \\textit{Age of Actuation (AoA), which is relevant when the receiver utilizes the status updates to perform actions in a timely manner}.","We provide analytical characterizations of the average AoA and the violation probability of the AoA, demonstrating that AoA generalizes AoI.","Moreover, we introduce and analytically characterize the \\textit{Probability of Missing Actuation (PoMA)}; this metric becomes relevant also \\textit{to quantify the incurred cost of a missed action}.","We formulate unconstrained and constrained optimization problems for all the metrics and present numerical evaluations of our analytical results.","This proposed set of metrics goes beyond the traditional timeliness metrics since the synergy of different flows is now considered."],"url":"http://arxiv.org/abs/2312.13919v1"}
{"created":"2023-12-21 15:00:06","title":"Solving Long-run Average Reward Robust MDPs via Stochastic Games","abstract":"Markov decision processes (MDPs) provide a standard framework for sequential decision making under uncertainty. However, transition probabilities in MDPs are often estimated from data and MDPs do not take data uncertainty into account. Robust Markov decision processes (RMDPs) address this shortcoming of MDPs by assigning to each transition an uncertainty set rather than a single probability value. The goal of solving RMDPs is then to find a policy which maximizes the worst-case performance over the uncertainty sets. In this work, we consider polytopic RMDPs in which all uncertainty sets are polytopes and study the problem of solving long-run average reward polytopic RMDPs. Our focus is on computational complexity aspects and efficient algorithms. We present a novel perspective on this problem and show that it can be reduced to solving long-run average reward turn-based stochastic games with finite state and action spaces. This reduction allows us to derive several important consequences that were hitherto not known to hold for polytopic RMDPs. First, we derive new computational complexity bounds for solving long-run average reward polytopic RMDPs, showing for the first time that the threshold decision problem for them is in NP coNP and that they admit a randomized algorithm with sub-exponential expected runtime. Second, we present Robust Polytopic Policy Iteration (RPPI), a novel policy iteration algorithm for solving long-run average reward polytopic RMDPs. Our experimental evaluation shows that RPPI is much more efficient in solving long-run average reward polytopic RMDPs compared to state-of-the-art methods based on value iteration.","sentences":["Markov decision processes (MDPs) provide a standard framework for sequential decision making under uncertainty.","However, transition probabilities in MDPs are often estimated from data and MDPs do not take data uncertainty into account.","Robust Markov decision processes (RMDPs) address this shortcoming of MDPs by assigning to each transition an uncertainty set rather than a single probability value.","The goal of solving RMDPs is then to find a policy which maximizes the worst-case performance over the uncertainty sets.","In this work, we consider polytopic RMDPs in which all uncertainty sets are polytopes and study the problem of solving long-run average reward polytopic RMDPs.","Our focus is on computational complexity aspects and efficient algorithms.","We present a novel perspective on this problem and show that it can be reduced to solving long-run average reward turn-based stochastic games with finite state and action spaces.","This reduction allows us to derive several important consequences that were hitherto not known to hold for polytopic RMDPs.","First, we derive new computational complexity bounds for solving long-run average reward polytopic RMDPs, showing for the first time that the threshold decision problem for them is in NP coNP and that they admit a randomized algorithm with sub-exponential expected runtime.","Second, we present Robust Polytopic Policy Iteration (RPPI), a novel policy iteration algorithm for solving long-run average reward polytopic RMDPs.","Our experimental evaluation shows that RPPI is much more efficient in solving long-run average reward polytopic RMDPs compared to state-of-the-art methods based on value iteration."],"url":"http://arxiv.org/abs/2312.13912v1"}
{"created":"2023-12-21 14:55:21","title":"Multi-Agent Probabilistic Ensembles with Trajectory Sampling for Connected Autonomous Vehicles","abstract":"Autonomous Vehicles (AVs) have attracted significant attention in recent years and Reinforcement Learning (RL) has shown remarkable performance in improving the autonomy of vehicles. In that regard, the widely adopted Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs (CAVs), contingent on the readiness of a significant amount of data samples for training. Nevertheless, it might be infeasible in practice and possibly lead to learning instability. In contrast, Model-Based RL (MBRL) manifests itself in sample-efficient learning, but the asymptotic performance of MBRL might lag behind the state-of-the-art MFRL algorithms. Furthermore, most studies for CAVs are limited to the decision-making of a single AV only, thus underscoring the performance due to the absence of communications. In this study, we try to address the decision-making problem of multiple CAVs with limited communications and propose a decentralized Multi-Agent Probabilistic Ensembles with Trajectory Sampling algorithm MA-PETS. In particular, in order to better capture the uncertainty of the unknown environment, MA-PETS leverages Probabilistic Ensemble (PE) neural networks to learn from communicated samples among neighboring CAVs. Afterwards, MA-PETS capably develops Trajectory Sampling (TS)-based model-predictive control for decision-making. On this basis, we derive the multi-agent group regret bound affected by the number of agents within the communication range and mathematically validate that incorporating effective information exchange among agents into the multi-agent learning scheme contributes to reducing the group regret bound in the worst case. Finally, we empirically demonstrate the superiority of MA-PETS in terms of the sample efficiency comparable to MFBL.","sentences":["Autonomous Vehicles (AVs) have attracted significant attention in recent years and Reinforcement Learning (RL) has shown remarkable performance in improving the autonomy of vehicles.","In that regard, the widely adopted Model-Free RL (MFRL) promises to solve decision-making tasks in connected AVs (CAVs), contingent on the readiness of a significant amount of data samples for training.","Nevertheless, it might be infeasible in practice and possibly lead to learning instability.","In contrast, Model-Based RL (MBRL) manifests itself in sample-efficient learning, but the asymptotic performance of MBRL might lag behind the state-of-the-art MFRL algorithms.","Furthermore, most studies for CAVs are limited to the decision-making of a single AV only, thus underscoring the performance due to the absence of communications.","In this study, we try to address the decision-making problem of multiple CAVs with limited communications and propose a decentralized Multi-Agent Probabilistic Ensembles with Trajectory Sampling algorithm MA-PETS.","In particular, in order to better capture the uncertainty of the unknown environment, MA-PETS leverages Probabilistic Ensemble (PE) neural networks to learn from communicated samples among neighboring CAVs.","Afterwards, MA-PETS capably develops Trajectory Sampling (TS)-based model-predictive control for decision-making.","On this basis, we derive the multi-agent group regret bound affected by the number of agents within the communication range and mathematically validate that incorporating effective information exchange among agents into the multi-agent learning scheme contributes to reducing the group regret bound in the worst case.","Finally, we empirically demonstrate the superiority of MA-PETS in terms of the sample efficiency comparable to MFBL."],"url":"http://arxiv.org/abs/2312.13910v1"}
{"created":"2023-12-21 14:51:23","title":"EfficientPPS: Part-aware Panoptic Segmentation of Transparent Objects for Robotic Manipulation","abstract":"The use of autonomous robots for assistance tasks in hospitals has the potential to free up qualified staff and im-prove patient care. However, the ubiquity of deformable and transparent objects in hospital settings poses signif-icant challenges to vision-based perception systems. We present EfficientPPS, a neural architecture for part-aware panoptic segmentation that provides robots with semantically rich visual information for grasping and ma-nipulation tasks. We also present an unsupervised data collection and labelling method to reduce the need for human involvement in the training process. EfficientPPS is evaluated on a dataset containing real-world hospital objects and demonstrated to be robust and efficient in grasping transparent transfusion bags with a collaborative robot arm.","sentences":["The use of autonomous robots for assistance tasks in hospitals has the potential to free up qualified staff and im-prove patient care.","However, the ubiquity of deformable and transparent objects in hospital settings poses signif-icant challenges to vision-based perception systems.","We present EfficientPPS, a neural architecture for part-aware panoptic segmentation that provides robots with semantically rich visual information for grasping and ma-nipulation tasks.","We also present an unsupervised data collection and labelling method to reduce the need for human involvement in the training process.","EfficientPPS is evaluated on a dataset containing real-world hospital objects and demonstrated to be robust and efficient in grasping transparent transfusion bags with a collaborative robot arm."],"url":"http://arxiv.org/abs/2312.13906v1"}
{"created":"2023-12-21 14:51:04","title":"Domain-Specific Fine-Tuning of Large Language Models for Interactive Robot Programming","abstract":"Industrial robots are applied in a widening range of industries, but robot programming mostly remains a task limited to programming experts. We propose a natural language-based assistant for programming of advanced, industrial robotic applications and investigate strategies for domain-specific fine-tuning of foundation models with limited data and compute.","sentences":["Industrial robots are applied in a widening range of industries, but robot programming mostly remains a task limited to programming experts.","We propose a natural language-based assistant for programming of advanced, industrial robotic applications and investigate strategies for domain-specific fine-tuning of foundation models with limited data and compute."],"url":"http://arxiv.org/abs/2312.13905v1"}
{"created":"2023-12-21 14:43:31","title":"EnergiBridge: Empowering Software Sustainability through Cross-Platform Energy Measurement","abstract":"In the continually evolving realm of software engineering, the need to address software energy consumption has gained increasing prominence. However, the absence of a platform-independent tool that facilitates straightforward energy measurements remains a notable gap. This paper presents EnergiBridge, a cross-platform measurement utility that provides support for Linux, Windows, and MacOS, as well as Intel, AMD, and Apple ARM CPU architectures. In essence, EnergiBridge serves as a bridge between energy-conscious software engineering and the diverse software environments in which it operates. It encourages a broader community to make informed decisions, minimize energy consumption, and reduce the environmental impact of software systems.   By simplifying software energy measurements, EnergiBridge offers a valuable resource to make green software development more lightweight, education more inclusive, and research more reproducible. Through the evaluation, we highlight EnergiBridge's ability to gather energy data across diverse platforms and hardware configurations.   EnergiBridge is publicly available on GitHub: https://github.com/tdurieux/EnergiBridge, and a demonstration video can be viewed at: https://youtu.be/-gPJurKFraE.","sentences":["In the continually evolving realm of software engineering, the need to address software energy consumption has gained increasing prominence.","However, the absence of a platform-independent tool that facilitates straightforward energy measurements remains a notable gap.","This paper presents EnergiBridge, a cross-platform measurement utility that provides support for Linux, Windows, and MacOS, as well as Intel, AMD, and Apple ARM CPU architectures.","In essence, EnergiBridge serves as a bridge between energy-conscious software engineering and the diverse software environments in which it operates.","It encourages a broader community to make informed decisions, minimize energy consumption, and reduce the environmental impact of software systems.   ","By simplifying software energy measurements, EnergiBridge offers a valuable resource to make green software development more lightweight, education more inclusive, and research more reproducible.","Through the evaluation, we highlight EnergiBridge's ability to gather energy data across diverse platforms and hardware configurations.   ","EnergiBridge is publicly available on GitHub: https://github.com/tdurieux/EnergiBridge, and a demonstration video can be viewed at: https://youtu.be/-gPJurKFraE."],"url":"http://arxiv.org/abs/2312.13897v1"}
{"created":"2023-12-21 14:42:42","title":"Comparative Evaluation of Anomaly Detection Methods for Fraud Detection in Online Credit Card Payments","abstract":"This study explores the application of anomaly detection (AD) methods in imbalanced learning tasks, focusing on fraud detection using real online credit card payment data. We assess the performance of several recent AD methods and compare their effectiveness against standard supervised learning methods. Offering evidence of distribution shift within our dataset, we analyze its impact on the tested models' performances. Our findings reveal that LightGBM exhibits significantly superior performance across all evaluated metrics but suffers more from distribution shifts than AD methods. Furthermore, our investigation reveals that LightGBM also captures the majority of frauds detected by AD methods. This observation challenges the potential benefits of ensemble methods to combine supervised, and AD approaches to enhance performance. In summary, this research provides practical insights into the utility of these techniques in real-world scenarios, showing LightGBM's superiority in fraud detection while highlighting challenges related to distribution shifts.","sentences":["This study explores the application of anomaly detection (AD) methods in imbalanced learning tasks, focusing on fraud detection using real online credit card payment data.","We assess the performance of several recent AD methods and compare their effectiveness against standard supervised learning methods.","Offering evidence of distribution shift within our dataset, we analyze its impact on the tested models' performances.","Our findings reveal that LightGBM exhibits significantly superior performance across all evaluated metrics but suffers more from distribution shifts than AD methods.","Furthermore, our investigation reveals that LightGBM also captures the majority of frauds detected by AD methods.","This observation challenges the potential benefits of ensemble methods to combine supervised, and AD approaches to enhance performance.","In summary, this research provides practical insights into the utility of these techniques in real-world scenarios, showing LightGBM's superiority in fraud detection while highlighting challenges related to distribution shifts."],"url":"http://arxiv.org/abs/2312.13896v1"}
{"created":"2023-12-21 14:38:12","title":"A Summarized History-based Dialogue System for Amnesia-Free Prompt Updates","abstract":"In today's society, information overload presents challenges in providing optimal recommendations. Consequently, the importance of dialogue systems that can discern and provide the necessary information through dialogue is increasingly recognized. However, some concerns existing dialogue systems rely on pre-trained models and need help to cope with real-time or insufficient information. To address these concerns, models that allow the addition of missing information to dialogue robots are being proposed. Yet, maintaining the integrity of previous conversation history while integrating new data remains a formidable challenge. This paper presents a novel system for dialogue robots designed to remember user-specific characteristics by retaining past conversation history even as new information is added.","sentences":["In today's society, information overload presents challenges in providing optimal recommendations.","Consequently, the importance of dialogue systems that can discern and provide the necessary information through dialogue is increasingly recognized.","However, some concerns existing dialogue systems rely on pre-trained models and need help to cope with real-time or insufficient information.","To address these concerns, models that allow the addition of missing information to dialogue robots are being proposed.","Yet, maintaining the integrity of previous conversation history while integrating new data remains a formidable challenge.","This paper presents a novel system for dialogue robots designed to remember user-specific characteristics by retaining past conversation history even as new information is added."],"url":"http://arxiv.org/abs/2312.13891v1"}
{"created":"2023-12-21 14:26:57","title":"Diversifying Knowledge Enhancement of Biomedical Language Models using Adapter Modules and Knowledge Graphs","abstract":"Recent advances in natural language processing (NLP) owe their success to pre-training language models on large amounts of unstructured data. Still, there is an increasing effort to combine the unstructured nature of LMs with structured knowledge and reasoning. Particularly in the rapidly evolving field of biomedical NLP, knowledge-enhanced language models (KELMs) have emerged as promising tools to bridge the gap between large language models and domain-specific knowledge, considering the available biomedical knowledge graphs (KGs) curated by experts over the decades. In this paper, we develop an approach that uses lightweight adapter modules to inject structured biomedical knowledge into pre-trained language models (PLMs). We use two large KGs, the biomedical knowledge system UMLS and the novel biochemical ontology OntoChem, with two prominent biomedical PLMs, PubMedBERT and BioLinkBERT. The approach includes partitioning knowledge graphs into smaller subgraphs, fine-tuning adapter modules for each subgraph, and combining the knowledge in a fusion layer. We test the performance on three downstream tasks: document classification,question answering, and natural language inference. We show that our methodology leads to performance improvements in several instances while keeping requirements in computing power low. Finally, we provide a detailed interpretation of the results and report valuable insights for future work.","sentences":["Recent advances in natural language processing (NLP) owe their success to pre-training language models on large amounts of unstructured data.","Still, there is an increasing effort to combine the unstructured nature of LMs with structured knowledge and reasoning.","Particularly in the rapidly evolving field of biomedical NLP, knowledge-enhanced language models (KELMs) have emerged as promising tools to bridge the gap between large language models and domain-specific knowledge, considering the available biomedical knowledge graphs (KGs) curated by experts over the decades.","In this paper, we develop an approach that uses lightweight adapter modules to inject structured biomedical knowledge into pre-trained language models (PLMs).","We use two large KGs, the biomedical knowledge system UMLS and the novel biochemical ontology OntoChem, with two prominent biomedical PLMs, PubMedBERT and BioLinkBERT.","The approach includes partitioning knowledge graphs into smaller subgraphs, fine-tuning adapter modules for each subgraph, and combining the knowledge in a fusion layer.","We test the performance on three downstream tasks: document classification,question answering, and natural language inference.","We show that our methodology leads to performance improvements in several instances while keeping requirements in computing power low.","Finally, we provide a detailed interpretation of the results and report valuable insights for future work."],"url":"http://arxiv.org/abs/2312.13881v1"}
{"created":"2023-12-21 14:20:06","title":"Capture the Flag: Uncovering Data Insights with Large Language Models","abstract":"The extraction of a small number of relevant insights from vast amounts of data is a crucial component of data-driven decision-making. However, accomplishing this task requires considerable technical skills, domain expertise, and human labor. This study explores the potential of using Large Language Models (LLMs) to automate the discovery of insights in data, leveraging recent advances in reasoning and code generation techniques. We propose a new evaluation methodology based on a \"capture the flag\" principle, measuring the ability of such models to recognize meaningful and pertinent information (flags) in a dataset. We further propose two proof-of-concept agents, with different inner workings, and compare their ability to capture such flags in a real-world sales dataset. While the work reported here is preliminary, our results are sufficiently interesting to mandate future exploration by the community.","sentences":["The extraction of a small number of relevant insights from vast amounts of data is a crucial component of data-driven decision-making.","However, accomplishing this task requires considerable technical skills, domain expertise, and human labor.","This study explores the potential of using Large Language Models (LLMs) to automate the discovery of insights in data, leveraging recent advances in reasoning and code generation techniques.","We propose a new evaluation methodology based on a \"capture the flag\" principle, measuring the ability of such models to recognize meaningful and pertinent information (flags) in a dataset.","We further propose two proof-of-concept agents, with different inner workings, and compare their ability to capture such flags in a real-world sales dataset.","While the work reported here is preliminary, our results are sufficiently interesting to mandate future exploration by the community."],"url":"http://arxiv.org/abs/2312.13876v1"}
{"created":"2023-12-21 13:42:08","title":"Image Clustering using Restricted Boltzman Machine","abstract":"In various verification systems, Restricted Boltzmann Machines (RBMs) have demonstrated their efficacy in both front-end and back-end processes. In this work, we propose the use of RBMs to the image clustering tasks. RBMs are trained to convert images into image embeddings. We employ the conventional bottom-up Agglomerative Hierarchical Clustering (AHC) technique. To address the challenge of limited test face image data, we introduce Agglomerative Hierarchical Clustering based Method for Image Clustering using Restricted Boltzmann Machine (AHC-RBM) with two major steps. Initially, a universal RBM model is trained using all available training dataset. Subsequently, we train an adapted RBM model using the data from each test image. Finally, RBM vectors which is the embedding vector is generated by concatenating the visible-to-hidden weight matrices of these adapted models, and the bias vectors. These vectors effectively preserve class-specific information and are utilized in image clustering tasks. Our experimental results, conducted on two benchmark image datasets (MS-Celeb-1M and DeepFashion), demonstrate that our proposed approach surpasses well-known clustering algorithms such as k-means, spectral clustering, and approximate Rank-order.","sentences":["In various verification systems, Restricted Boltzmann Machines (RBMs) have demonstrated their efficacy in both front-end and back-end processes.","In this work, we propose the use of RBMs to the image clustering tasks.","RBMs are trained to convert images into image embeddings.","We employ the conventional bottom-up Agglomerative Hierarchical Clustering (AHC) technique.","To address the challenge of limited test face image data, we introduce Agglomerative Hierarchical Clustering based Method for Image Clustering using Restricted Boltzmann Machine (AHC-RBM) with two major steps.","Initially, a universal RBM model is trained using all available training dataset.","Subsequently, we train an adapted RBM model using the data from each test image.","Finally, RBM vectors which is the embedding vector is generated by concatenating the visible-to-hidden weight matrices of these adapted models, and the bias vectors.","These vectors effectively preserve class-specific information and are utilized in image clustering tasks.","Our experimental results, conducted on two benchmark image datasets (MS-Celeb-1M and DeepFashion), demonstrate that our proposed approach surpasses well-known clustering algorithms such as k-means, spectral clustering, and approximate Rank-order."],"url":"http://arxiv.org/abs/2312.13845v1"}
{"created":"2023-12-21 13:05:09","title":"How Does Connecting Online Activities to Advertising Inferences Impact Privacy Perceptions?","abstract":"Data dashboards are designed to help users manage data collected about them. However, prior work showed that exposure to some dashboards, notably Google's My Activity dashboard, results in significant decreases in perceived concern and increases in perceived benefit from data collection, contrary to expectations. We theorize that this result is due to the fact that data dashboards currently do not sufficiently \"connect the dots\" of the data food chain, that is, by connecting data collection with the use of that data. To evaluate this, we designed a study where participants assigned advertising interest labels to their own real activities, effectively acting as a behavioral advertising engine to \"connect the dots.\" When comparing pre- and post-labeling task responses, we find no significant difference in concern with Google's data collection practices, which indicates that participants' priors are maintained after more exposure to the data food chain (differing from prior work), suggesting that data dashboards that offer deeper perspectives of how data collection is used have potential. However, these gains are offset when participants are exposed to their true interest labels inferred by Google. Concern for data collection dropped significantly as participants viewed Google's labeling as generic compared to their own more specific labeling. This presents a possible new paradox that must be overcome when designing data dashboards, the generic paradox, which occurs when users misalign individual, generic inferences from collected data as benign compared to the totality and specificity of many generic inferences made about them.","sentences":["Data dashboards are designed to help users manage data collected about them.","However, prior work showed that exposure to some dashboards, notably Google's My Activity dashboard, results in significant decreases in perceived concern and increases in perceived benefit from data collection, contrary to expectations.","We theorize that this result is due to the fact that data dashboards currently do not sufficiently \"connect the dots\" of the data food chain, that is, by connecting data collection with the use of that data.","To evaluate this, we designed a study where participants assigned advertising interest labels to their own real activities, effectively acting as a behavioral advertising engine to \"connect the dots.\"","When comparing pre- and post-labeling task responses, we find no significant difference in concern with Google's data collection practices, which indicates that participants' priors are maintained after more exposure to the data food chain (differing from prior work), suggesting that data dashboards that offer deeper perspectives of how data collection is used have potential.","However, these gains are offset when participants are exposed to their true interest labels inferred by Google.","Concern for data collection dropped significantly as participants viewed Google's labeling as generic compared to their own more specific labeling.","This presents a possible new paradox that must be overcome when designing data dashboards, the generic paradox, which occurs when users misalign individual, generic inferences from collected data as benign compared to the totality and specificity of many generic inferences made about them."],"url":"http://arxiv.org/abs/2312.13813v1"}
{"created":"2023-12-21 12:46:36","title":"A Dense Subframe-based SLAM Framework with Side-scan Sonar","abstract":"Side-scan sonar (SSS) is a lightweight acoustic sensor that is commonly deployed on autonomous underwater vehicles (AUVs) to provide high-resolution seafloor images. However, leveraging side-scan images for simultaneous localization and mapping (SLAM) presents a notable challenge, primarily due to the difficulty of establishing sufficient amount of accurate correspondences between these images. To address this, we introduce a novel subframe-based dense SLAM framework utilizing side-scan sonar data, enabling effective dense matching in overlapping regions of paired side-scan images. With each image being evenly divided into subframes, we propose a robust estimation pipeline to estimate the relative pose between each paired subframes, by using a good inlier set identified from dense correspondences. These relative poses are then integrated as edge constraints in a factor graph to optimize the AUV pose trajectory.   The proposed framework is evaluated on three real datasets collected by a Hugin AUV. Among one of them includes manually-annotated keypoint correspondences as ground truth and is used for evaluation of pose trajectory. We also present a feasible way of evaluating mapping quality against multi-beam echosounder (MBES) data without the influence of pose. Experimental results demonstrate that our approach effectively mitigates drift from the dead-reckoning (DR) system and enables quasi-dense bathymetry reconstruction. An open-source implementation of this work is available.","sentences":["Side-scan sonar (SSS) is a lightweight acoustic sensor that is commonly deployed on autonomous underwater vehicles (AUVs) to provide high-resolution seafloor images.","However, leveraging side-scan images for simultaneous localization and mapping (SLAM) presents a notable challenge, primarily due to the difficulty of establishing sufficient amount of accurate correspondences between these images.","To address this, we introduce a novel subframe-based dense SLAM framework utilizing side-scan sonar data, enabling effective dense matching in overlapping regions of paired side-scan images.","With each image being evenly divided into subframes, we propose a robust estimation pipeline to estimate the relative pose between each paired subframes, by using a good inlier set identified from dense correspondences.","These relative poses are then integrated as edge constraints in a factor graph to optimize the AUV pose trajectory.   ","The proposed framework is evaluated on three real datasets collected by a Hugin AUV.","Among one of them includes manually-annotated keypoint correspondences as ground truth and is used for evaluation of pose trajectory.","We also present a feasible way of evaluating mapping quality against multi-beam echosounder (MBES) data without the influence of pose.","Experimental results demonstrate that our approach effectively mitigates drift from the dead-reckoning (DR) system and enables quasi-dense bathymetry reconstruction.","An open-source implementation of this work is available."],"url":"http://arxiv.org/abs/2312.13802v1"}
{"created":"2023-12-21 12:14:31","title":"Few Shot Part Segmentation Reveals Compositional Logic for Industrial Anomaly Detection","abstract":"Logical anomalies (LA) refer to data violating underlying logical constraints e.g., the quantity, arrangement, or composition of components within an image. Detecting accurately such anomalies requires models to reason about various component types through segmentation. However, curation of pixel-level annotations for semantic segmentation is both time-consuming and expensive. Although there are some prior few-shot or unsupervised co-part segmentation algorithms, they often fail on images with industrial object. These images have components with similar textures and shapes, and a precise differentiation proves challenging. In this study, we introduce a novel component segmentation model for LA detection that leverages a few labeled samples and unlabeled images sharing logical constraints. To ensure consistent segmentation across unlabeled images, we employ a histogram matching loss in conjunction with an entropy loss. As segmentation predictions play a crucial role, we propose to enhance both local and global sample validity detection by capturing key aspects from visual semantics via three memory banks: class histograms, component composition embeddings and patch-level representations. For effective LA detection, we propose an adaptive scaling strategy to standardize anomaly scores from different memory banks in inference. Extensive experiments on the public benchmark MVTec LOCO AD reveal our method achieves 98.1% AUROC in LA detection vs. 89.6% from competing methods.","sentences":["Logical anomalies (LA) refer to data violating underlying logical constraints e.g., the quantity, arrangement, or composition of components within an image.","Detecting accurately such anomalies requires models to reason about various component types through segmentation.","However, curation of pixel-level annotations for semantic segmentation is both time-consuming and expensive.","Although there are some prior few-shot or unsupervised co-part segmentation algorithms, they often fail on images with industrial object.","These images have components with similar textures and shapes, and a precise differentiation proves challenging.","In this study, we introduce a novel component segmentation model for LA detection that leverages a few labeled samples and unlabeled images sharing logical constraints.","To ensure consistent segmentation across unlabeled images, we employ a histogram matching loss in conjunction with an entropy loss.","As segmentation predictions play a crucial role, we propose to enhance both local and global sample validity detection by capturing key aspects from visual semantics via three memory banks: class histograms, component composition embeddings and patch-level representations.","For effective LA detection, we propose an adaptive scaling strategy to standardize anomaly scores from different memory banks in inference.","Extensive experiments on the public benchmark MVTec LOCO AD reveal our method achieves 98.1% AUROC in LA detection vs. 89.6% from competing methods."],"url":"http://arxiv.org/abs/2312.13783v1"}
{"created":"2023-12-21 11:55:10","title":"On Task Performance and Model Calibration with Supervised and Self-Ensembled In-Context Learning","abstract":"Following the standard supervised fine-tuning (SFT) paradigm, in-context learning (ICL) has become an efficient approach propelled by the recent advancements in large language models (LLMs), yielding promising performance across various tasks in few-shot data setups. However, both paradigms are prone to suffer from the critical problem of overconfidence (i.e., miscalibration), especially in such limited data setups. In this work, we deliver an in-depth analysis of the behavior across different choices of learning methods from the perspective of both performance and calibration, as well as their interplay. Through extensive controlled experiments, we find that simultaneous gains for both task performance and calibration are difficult to achieve, and the problem of miscalibration exists across all learning methods in low-resource scenarios.To address this challenging trade-off between performance and calibration, we then investigate the potential of self-ensembling techniques applied at different modeling stages (e.g., variations of in-context examples or variations in prompts or different ensembling strategies). We justify the feasibility of self-ensembling on SFT in addition to ICL, to make the predictions more calibrated and have comparable or even better performance. Our work sheds light on which learning paradigm to choose and how to enhance both task performance and calibration of LLMs.","sentences":["Following the standard supervised fine-tuning (SFT) paradigm, in-context learning (ICL) has become an efficient approach propelled by the recent advancements in large language models (LLMs), yielding promising performance across various tasks in few-shot data setups.","However, both paradigms are prone to suffer from the critical problem of overconfidence (i.e., miscalibration), especially in such limited data setups.","In this work, we deliver an in-depth analysis of the behavior across different choices of learning methods from the perspective of both performance and calibration, as well as their interplay.","Through extensive controlled experiments, we find that simultaneous gains for both task performance and calibration are difficult to achieve, and the problem of miscalibration exists across all learning methods in low-resource scenarios.","To address this challenging trade-off between performance and calibration, we then investigate the potential of self-ensembling techniques applied at different modeling stages (e.g., variations of in-context examples or variations in prompts or different ensembling strategies).","We justify the feasibility of self-ensembling on SFT in addition to ICL, to make the predictions more calibrated and have comparable or even better performance.","Our work sheds light on which learning paradigm to choose and how to enhance both task performance and calibration of LLMs."],"url":"http://arxiv.org/abs/2312.13772v1"}
{"created":"2023-12-21 11:48:43","title":"Counting Problems in Trees, with Applications to Fixed Points of Cellular Automata","abstract":"Cellular automata are synchronous discrete dynamical systems used to describe complex dynamic behaviors. The dynamic is based on local interactions between the components, these are defined by a finite graph with an initial node coloring with two colors. In each step, all nodes change their current color synchronously to the least/most frequent color in their neighborhood and in case of a tie, keep their current color. After a finite number of rounds these systems either reach a fixed point or enter a 2-cycle. The problem of counting the number of fixed points for cellular automata is #P-complete. In this paper we consider cellular automata defined by a tree. We propose an algorithm with run-time $O(n\\Delta)$ to count the number of fixed points, here $\\Delta$ is the maximal degree of the tree. We also prove upper and lower bounds for the number of fixed points. Furthermore, we obtain corresponding results for pure cycles, i.e., instances where each node changes its color in every round. We provide examples demonstrating that the bounds are sharp. The results are proved for the minority and the majority model.","sentences":["Cellular automata are synchronous discrete dynamical systems used to describe complex dynamic behaviors.","The dynamic is based on local interactions between the components, these are defined by a finite graph with an initial node coloring with two colors.","In each step, all nodes change their current color synchronously to the least/most frequent color in their neighborhood and in case of a tie, keep their current color.","After a finite number of rounds these systems either reach a fixed point or enter a 2-cycle.","The problem of counting the number of fixed points for cellular automata is #P-complete.","In this paper we consider cellular automata defined by a tree.","We propose an algorithm with run-time $O(n\\Delta)$ to count the number of fixed points, here $\\Delta$ is the maximal degree of the tree.","We also prove upper and lower bounds for the number of fixed points.","Furthermore, we obtain corresponding results for pure cycles, i.e., instances where each node changes its color in every round.","We provide examples demonstrating that the bounds are sharp.","The results are proved for the minority and the majority model."],"url":"http://arxiv.org/abs/2312.13769v1"}
{"created":"2023-12-21 11:41:02","title":"Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models","abstract":"Text-guided diffusion models have revolutionized image and video generation and have also been successfully used for optimization-based 3D object synthesis. Here, we instead focus on the underexplored text-to-4D setting and synthesize dynamic, animated 3D objects using score distillation methods with an additional temporal dimension. Compared to previous work, we pursue a novel compositional generation-based approach, and combine text-to-image, text-to-video, and 3D-aware multiview diffusion models to provide feedback during 4D object optimization, thereby simultaneously enforcing temporal consistency, high-quality visual appearance and realistic geometry. Our method, called Align Your Gaussians (AYG), leverages dynamic 3D Gaussian Splatting with deformation fields as 4D representation. Crucial to AYG is a novel method to regularize the distribution of the moving 3D Gaussians and thereby stabilize the optimization and induce motion. We also propose a motion amplification mechanism as well as a new autoregressive synthesis scheme to generate and combine multiple 4D sequences for longer generation. These techniques allow us to synthesize vivid dynamic scenes, outperform previous work qualitatively and quantitatively and achieve state-of-the-art text-to-4D performance. Due to the Gaussian 4D representation, different 4D animations can be seamlessly combined, as we demonstrate. AYG opens up promising avenues for animation, simulation and digital content creation as well as synthetic data generation.","sentences":["Text-guided diffusion models have revolutionized image and video generation and have also been successfully used for optimization-based 3D object synthesis.","Here, we instead focus on the underexplored text-to-4D setting and synthesize dynamic, animated 3D objects using score distillation methods with an additional temporal dimension.","Compared to previous work, we pursue a novel compositional generation-based approach, and combine text-to-image, text-to-video, and 3D-aware multiview diffusion models to provide feedback during 4D object optimization, thereby simultaneously enforcing temporal consistency, high-quality visual appearance and realistic geometry.","Our method, called Align Your Gaussians (AYG), leverages dynamic 3D Gaussian Splatting with deformation fields as 4D representation.","Crucial to AYG is a novel method to regularize the distribution of the moving 3D Gaussians and thereby stabilize the optimization and induce motion.","We also propose a motion amplification mechanism as well as a new autoregressive synthesis scheme to generate and combine multiple 4D sequences for longer generation.","These techniques allow us to synthesize vivid dynamic scenes, outperform previous work qualitatively and quantitatively and achieve state-of-the-art text-to-4D performance.","Due to the Gaussian 4D representation, different 4D animations can be seamlessly combined, as we demonstrate.","AYG opens up promising avenues for animation, simulation and digital content creation as well as synthetic data generation."],"url":"http://arxiv.org/abs/2312.13763v1"}
{"created":"2023-12-21 11:30:02","title":"Video Recognition in Portrait Mode","abstract":"The creation of new datasets often presents new challenges for video recognition and can inspire novel ideas while addressing these challenges. While existing datasets mainly comprise landscape mode videos, our paper seeks to introduce portrait mode videos to the research community and highlight the unique challenges associated with this video format. With the growing popularity of smartphones and social media applications, recognizing portrait mode videos is becoming increasingly important. To this end, we have developed the first dataset dedicated to portrait mode video recognition, namely PortraitMode-400. The taxonomy of PortraitMode-400 was constructed in a data-driven manner, comprising 400 fine-grained categories, and rigorous quality assurance was implemented to ensure the accuracy of human annotations. In addition to the new dataset, we conducted a comprehensive analysis of the impact of video format (portrait mode versus landscape mode) on recognition accuracy and spatial bias due to the different formats. Furthermore, we designed extensive experiments to explore key aspects of portrait mode video recognition, including the choice of data augmentation, evaluation procedure, the importance of temporal information, and the role of audio modality. Building on the insights from our experimental results and the introduction of PortraitMode-400, our paper aims to inspire further research efforts in this emerging research area.","sentences":["The creation of new datasets often presents new challenges for video recognition and can inspire novel ideas while addressing these challenges.","While existing datasets mainly comprise landscape mode videos, our paper seeks to introduce portrait mode videos to the research community and highlight the unique challenges associated with this video format.","With the growing popularity of smartphones and social media applications, recognizing portrait mode videos is becoming increasingly important.","To this end, we have developed the first dataset dedicated to portrait mode video recognition, namely PortraitMode-400.","The taxonomy of PortraitMode-400 was constructed in a data-driven manner, comprising 400 fine-grained categories, and rigorous quality assurance was implemented to ensure the accuracy of human annotations.","In addition to the new dataset, we conducted a comprehensive analysis of the impact of video format (portrait mode versus landscape mode) on recognition accuracy and spatial bias due to the different formats.","Furthermore, we designed extensive experiments to explore key aspects of portrait mode video recognition, including the choice of data augmentation, evaluation procedure, the importance of temporal information, and the role of audio modality.","Building on the insights from our experimental results and the introduction of PortraitMode-400, our paper aims to inspire further research efforts in this emerging research area."],"url":"http://arxiv.org/abs/2312.13746v1"}
{"created":"2023-12-21 11:07:51","title":"An Approach to Abstract Multi-stage Cyberattack Data Generation for ML-Based IDS in Smart Grids","abstract":"Power grids are becoming more digitized, resulting in new opportunities for the grid operation but also new challenges, such as new threats from the cyber-domain. To address these challenges, cybersecurity solutions are being considered in the form of preventive, detective, and reactive measures. Machine learning-based intrusion detection systems are used as part of detection efforts to detect and defend against cyberattacks. However, training and testing data for these systems are often not available or suitable for use in machine learning models for detecting multi-stage cyberattacks in smart grids. In this paper, we propose a method to generate synthetic data using a graph-based approach for training machine learning models in smart grids. We use an abstract form of multi-stage cyberattacks defined via graph formulations and simulate the propagation behavior of attacks in the network. Within the selected scenarios, we observed promising results, but a larger number of scenarios need to be studied to draw a more informed conclusion about the suitability of synthesized data.","sentences":["Power grids are becoming more digitized, resulting in new opportunities for the grid operation but also new challenges, such as new threats from the cyber-domain.","To address these challenges, cybersecurity solutions are being considered in the form of preventive, detective, and reactive measures.","Machine learning-based intrusion detection systems are used as part of detection efforts to detect and defend against cyberattacks.","However, training and testing data for these systems are often not available or suitable for use in machine learning models for detecting multi-stage cyberattacks in smart grids.","In this paper, we propose a method to generate synthetic data using a graph-based approach for training machine learning models in smart grids.","We use an abstract form of multi-stage cyberattacks defined via graph formulations and simulate the propagation behavior of attacks in the network.","Within the selected scenarios, we observed promising results, but a larger number of scenarios need to be studied to draw a more informed conclusion about the suitability of synthesized data."],"url":"http://arxiv.org/abs/2312.13737v1"}
{"created":"2023-12-21 10:23:18","title":"Conciliating Privacy and Utility in Data Releases via Individual Differential Privacy and Microaggregation","abstract":"$\\epsilon$-Differential privacy (DP) is a well-known privacy model that offers strong privacy guarantees. However, when applied to data releases, DP significantly deteriorates the analytical utility of the protected outcomes. To keep data utility at reasonable levels, practical applications of DP to data releases have used weak privacy parameters (large $\\epsilon$), which dilute the privacy guarantees of DP. In this work, we tackle this issue by using an alternative formulation of the DP privacy guarantees, named $\\epsilon$-individual differential privacy (iDP), which causes less data distortion while providing the same protection as DP to subjects. We enforce iDP in data releases by relying on attribute masking plus a pre-processing step based on data microaggregation. The goal of this step is to reduce the sensitivity to record changes, which determines the amount of noise required to enforce iDP (and DP). Specifically, we propose data microaggregation strategies designed for iDP whose sensitivities are significantly lower than those used in DP. As a result, we obtain iDP-protected data with significantly better utility than with DP. We report on experiments that show how our approach can provide strong privacy (small $\\epsilon$) while yielding protected data that do not significantly degrade the accuracy of secondary data analysis.","sentences":["$\\epsilon$-Differential privacy (DP) is a well-known privacy model that offers strong privacy guarantees.","However, when applied to data releases, DP significantly deteriorates the analytical utility of the protected outcomes.","To keep data utility at reasonable levels, practical applications of DP to data releases have used weak privacy parameters (large $\\epsilon$), which dilute the privacy guarantees of DP.","In this work, we tackle this issue by using an alternative formulation of the DP privacy guarantees, named $\\epsilon$-individual differential privacy (iDP), which causes less data distortion while providing the same protection as DP to subjects.","We enforce iDP in data releases by relying on attribute masking plus a pre-processing step based on data microaggregation.","The goal of this step is to reduce the sensitivity to record changes, which determines the amount of noise required to enforce iDP (and DP).","Specifically, we propose data microaggregation strategies designed for iDP whose sensitivities are significantly lower than those used in DP.","As a result, we obtain iDP-protected data with significantly better utility than with DP.","We report on experiments that show how our approach can provide strong privacy (small $\\epsilon$) while yielding protected data that do not significantly degrade the accuracy of secondary data analysis."],"url":"http://arxiv.org/abs/2312.13712v1"}
{"created":"2023-12-21 10:23:16","title":"A Learning oriented DLP System based on Classification Model","abstract":"Data is the key asset for organizations and data sharing is lifeline for organization growth; which may lead to data loss. Data leakage is the most critical issue being faced by organizations. In order to mitigate the data leakage issues data leakage prevention systems (DLPSs) are deployed at various levels by the organizations. DLPSs are capable to protect all kind of data i.e. DAR, DIM/DIT, DIU. Statistical analysis, regular expression, data fingerprinting are common approaches exercised in DLP system. Out of these techniques; statistical analysis approach is most appropriate for proposed DLP model of data security. This paper defines a statistical DLP model for document classification. Model uses various statistical approaches like TF-IDF (Term Frequency- Inverse Document Frequency) a renowned term count/weighing function, Vectorization, Gradient boosting document classification etc. to classify the documents before allowing any access to it. Machine learning is used to test and train the model. Proposed model also introduces an extremely efficient and more accurate approach; IGBCA (Improvised Gradient Boosting Classification Algorithm); for document classification, to prevent them from possible data leakage. Results depicts that proposed model can classify documents with high accuracy and on basis of which data can be prevented from being loss.","sentences":["Data is the key asset for organizations and data sharing is lifeline for organization growth; which may lead to data loss.","Data leakage is the most critical issue being faced by organizations.","In order to mitigate the data leakage issues data leakage prevention systems (DLPSs) are deployed at various levels by the organizations.","DLPSs are capable to protect all kind of data i.e. DAR, DIM/DIT, DIU.","Statistical analysis, regular expression, data fingerprinting are common approaches exercised in DLP system.","Out of these techniques; statistical analysis approach is most appropriate for proposed DLP model of data security.","This paper defines a statistical DLP model for document classification.","Model uses various statistical approaches like TF-IDF (Term Frequency- Inverse Document Frequency) a renowned term count/weighing function, Vectorization, Gradient boosting document classification etc. to classify the documents before allowing any access to it.","Machine learning is used to test and train the model.","Proposed model also introduces an extremely efficient and more accurate approach; IGBCA (Improvised Gradient Boosting Classification Algorithm); for document classification, to prevent them from possible data leakage.","Results depicts that proposed model can classify documents with high accuracy and on basis of which data can be prevented from being loss."],"url":"http://arxiv.org/abs/2312.13711v1"}
{"created":"2023-12-21 10:14:27","title":"A Forecasting-Based DLP Approach for Data Security","abstract":"Sensitive data leakage is the major growing problem being faced by enterprises in this technical era. Data leakage causes severe threats for organization of data safety which badly affects the reputation of organizations. Data leakage is the flow of sensitive data/information from any data holder to an unauthorized destination. Data leak prevention (DLP) is set of techniques that try to alleviate the threats which may hinder data security. DLP unveils guilty user responsible for data leakage and ensures that user without appropriate permission cannot access sensitive data and also provides protection to sensitive data if sensitive data is shared accidentally. In this paper, data leakage prevention (DLP) model is used to restrict/grant data access permission to user, based on the forecast of their access to data. This study provides a DLP solution using data statistical analysis to forecast the data access possibilities of any user in future based on the access to data in the past. The proposed approach makes use of renowned simple piecewise linear function for learning/training to model. The results show that the proposed DLP approach with high level of precision can correctly classify between users even in cases of extreme data access.","sentences":["Sensitive data leakage is the major growing problem being faced by enterprises in this technical era.","Data leakage causes severe threats for organization of data safety which badly affects the reputation of organizations.","Data leakage is the flow of sensitive data/information from any data holder to an unauthorized destination.","Data leak prevention (DLP) is set of techniques that try to alleviate the threats which may hinder data security.","DLP unveils guilty user responsible for data leakage and ensures that user without appropriate permission cannot access sensitive data and also provides protection to sensitive data if sensitive data is shared accidentally.","In this paper, data leakage prevention (DLP) model is used to restrict/grant data access permission to user, based on the forecast of their access to data.","This study provides a DLP solution using data statistical analysis to forecast the data access possibilities of any user in future based on the access to data in the past.","The proposed approach makes use of renowned simple piecewise linear function for learning/training to model.","The results show that the proposed DLP approach with high level of precision can correctly classify between users even in cases of extreme data access."],"url":"http://arxiv.org/abs/2312.13704v1"}
{"created":"2023-12-21 10:02:17","title":"Adapt & Align: Continual Learning with Generative Models Latent Space Alignment","abstract":"In this work, we introduce Adapt & Align, a method for continual learning of neural networks by aligning latent representations in generative models. Neural Networks suffer from abrupt loss in performance when retrained with additional training data from different distributions. At the same time, training with additional data without access to the previous examples rarely improves the model's performance. In this work, we propose a new method that mitigates those problems by employing generative models and splitting the process of their update into two parts. In the first one, we train a local generative model using only data from a new task. In the second phase, we consolidate latent representations from the local model with a global one that encodes knowledge of all past experiences. We introduce our approach with Variational Auteoncoders and Generative Adversarial Networks. Moreover, we show how we can use those generative models as a general method for continual knowledge consolidation that can be used in downstream tasks such as classification.","sentences":["In this work, we introduce Adapt & Align, a method for continual learning of neural networks by aligning latent representations in generative models.","Neural Networks suffer from abrupt loss in performance when retrained with additional training data from different distributions.","At the same time, training with additional data without access to the previous examples rarely improves the model's performance.","In this work, we propose a new method that mitigates those problems by employing generative models and splitting the process of their update into two parts.","In the first one, we train a local generative model using only data from a new task.","In the second phase, we consolidate latent representations from the local model with a global one that encodes knowledge of all past experiences.","We introduce our approach with Variational Auteoncoders and Generative Adversarial Networks.","Moreover, we show how we can use those generative models as a general method for continual knowledge consolidation that can be used in downstream tasks such as classification."],"url":"http://arxiv.org/abs/2312.13699v1"}
{"created":"2023-12-21 09:54:18","title":"Investigation of Multi-stage Attack and Defense Simulation for Data Synthesis","abstract":"The power grid is a critical infrastructure that plays a vital role in modern society. Its availability is of utmost importance, as a loss can endanger human lives. However, with the increasing digitalization of the power grid, it also becomes vulnerable to new cyberattacks that can compromise its availability. To counter these threats, intrusion detection systems are developed and deployed to detect cyberattacks targeting the power grid. Among intrusion detection systems, anomaly detection models based on machine learning have shown potential in detecting unknown attack vectors. However, the scarcity of data for training these models remains a challenge due to confidentiality concerns. To overcome this challenge, this study proposes a model for generating synthetic data of multi-stage cyber attacks in the power grid, using attack trees to model the attacker's sequence of steps and a game-theoretic approach to incorporate the defender's actions. This model aims to create diverse attack data on which machine learning algorithms can be trained.","sentences":["The power grid is a critical infrastructure that plays a vital role in modern society.","Its availability is of utmost importance, as a loss can endanger human lives.","However, with the increasing digitalization of the power grid, it also becomes vulnerable to new cyberattacks that can compromise its availability.","To counter these threats, intrusion detection systems are developed and deployed to detect cyberattacks targeting the power grid.","Among intrusion detection systems, anomaly detection models based on machine learning have shown potential in detecting unknown attack vectors.","However, the scarcity of data for training these models remains a challenge due to confidentiality concerns.","To overcome this challenge, this study proposes a model for generating synthetic data of multi-stage cyber attacks in the power grid, using attack trees to model the attacker's sequence of steps and a game-theoretic approach to incorporate the defender's actions.","This model aims to create diverse attack data on which machine learning algorithms can be trained."],"url":"http://arxiv.org/abs/2312.13697v1"}
{"created":"2023-12-21 09:45:13","title":"Data Transformation to Construct a Dataset for Generating Entity-Relationship Model from Natural Language","abstract":"In order to reduce the manual cost of designing ER models, recent approaches have been proposed to address the task of NL2ERM, i.e., automatically generating entity-relationship (ER) models from natural language (NL) utterances such as software requirements. These approaches are typically rule-based ones, which rely on rigid heuristic rules; these approaches cannot generalize well to various linguistic ways of describing the same requirement. Despite having better generalization capability than rule-based approaches, deep-learning-based models are lacking for NL2ERM due to lacking a large-scale dataset. To address this issue, in this paper, we report our insight that there exists a high similarity between the task of NL2ERM and the increasingly popular task of text-to-SQL, and propose a data transformation algorithm that transforms the existing data of text-to-SQL into the data of NL2ERM. We apply our data transformation algorithm on Spider, one of the most popular text-to-SQL datasets, and we also collect some data entries with different NL types, to obtain a large-scale NL2ERM dataset. Because NL2ERM can be seen as a special information extraction (IE) task, we train two state-of-the-art IE models on our dataset. The experimental results show that both the two models achieve high performance and outperform existing baselines.","sentences":["In order to reduce the manual cost of designing ER models, recent approaches have been proposed to address the task of NL2ERM, i.e., automatically generating entity-relationship (ER) models from natural language (NL) utterances such as software requirements.","These approaches are typically rule-based ones, which rely on rigid heuristic rules; these approaches cannot generalize well to various linguistic ways of describing the same requirement.","Despite having better generalization capability than rule-based approaches, deep-learning-based models are lacking for NL2ERM due to lacking a large-scale dataset.","To address this issue, in this paper, we report our insight that there exists a high similarity between the task of NL2ERM and the increasingly popular task of text-to-SQL, and propose a data transformation algorithm that transforms the existing data of text-to-SQL into the data of NL2ERM.","We apply our data transformation algorithm on Spider, one of the most popular text-to-SQL datasets, and we also collect some data entries with different NL types, to obtain a large-scale NL2ERM dataset.","Because NL2ERM can be seen as a special information extraction (IE) task, we train two state-of-the-art IE models on our dataset.","The experimental results show that both the two models achieve high performance and outperform existing baselines."],"url":"http://arxiv.org/abs/2312.13694v1"}
{"created":"2023-12-21 09:11:03","title":"A Constraint Programming Model for Scheduling the Unloading of Trains in Ports: Extended","abstract":"In this paper, we propose a model to schedule the next 24 hours of operations in a bulk cargo port to unload bulk cargo trains onto stockpiles. It is a problem that includes multiple parts such as splitting long trains into shorter ones and the routing of bulk material through a configurable network of conveyors to the stockpiles. Managing such trains (up to three kilometers long) also requires specialized equipment. The real world nature of the problem specification implies the necessity to manage heterogeneous data. Indeed, when new equipment is added (e.g. dumpers) or a new type of wagon comes in use, older or different equipment will still be in use as well. All these details need to be accounted for. In fact, avoiding a full deadlock of the facility after a new but ineffective schedule is produced. In this paper, we provide a detailed presentation of this real world problem and its associated data. This allows us to propose an effective constraint programming model to solve this problem. We also discuss the model design and the different implementations of the propagators that we used in practice. Finally, we show how this model, coupled with a large neighborhood search, was able to find 24 hour schedules efficiently.","sentences":["In this paper, we propose a model to schedule the next 24 hours of operations in a bulk cargo port to unload bulk cargo trains onto stockpiles.","It is a problem that includes multiple parts such as splitting long trains into shorter ones and the routing of bulk material through a configurable network of conveyors to the stockpiles.","Managing such trains (up to three kilometers long) also requires specialized equipment.","The real world nature of the problem specification implies the necessity to manage heterogeneous data.","Indeed, when new equipment is added (e.g. dumpers) or a new type of wagon comes in use, older or different equipment will still be in use as well.","All these details need to be accounted for.","In fact, avoiding a full deadlock of the facility after a new but ineffective schedule is produced.","In this paper, we provide a detailed presentation of this real world problem and its associated data.","This allows us to propose an effective constraint programming model to solve this problem.","We also discuss the model design and the different implementations of the propagators that we used in practice.","Finally, we show how this model, coupled with a large neighborhood search, was able to find 24 hour schedules efficiently."],"url":"http://arxiv.org/abs/2312.13682v1"}
{"created":"2023-12-21 08:50:41","title":"Text2Analysis: A Benchmark of Table Question Answering with Advanced Data Analysis and Unclear Queries","abstract":"Tabular data analysis is crucial in various fields, and large language models show promise in this area. However, current research mostly focuses on rudimentary tasks like Text2SQL and TableQA, neglecting advanced analysis like forecasting and chart generation. To address this gap, we developed the Text2Analysis benchmark, incorporating advanced analysis tasks that go beyond the SQL-compatible operations and require more in-depth analysis. We also develop five innovative and effective annotation methods, harnessing the capabilities of large language models to enhance data quality and quantity. Additionally, we include unclear queries that resemble real-world user questions to test how well models can understand and tackle such challenges. Finally, we collect 2249 query-result pairs with 347 tables. We evaluate five state-of-the-art models using three different metrics and the results show that our benchmark presents introduces considerable challenge in the field of tabular data analysis, paving the way for more advanced research opportunities.","sentences":["Tabular data analysis is crucial in various fields, and large language models show promise in this area.","However, current research mostly focuses on rudimentary tasks like Text2SQL and TableQA, neglecting advanced analysis like forecasting and chart generation.","To address this gap, we developed the Text2Analysis benchmark, incorporating advanced analysis tasks that go beyond the SQL-compatible operations and require more in-depth analysis.","We also develop five innovative and effective annotation methods, harnessing the capabilities of large language models to enhance data quality and quantity.","Additionally, we include unclear queries that resemble real-world user questions to test how well models can understand and tackle such challenges.","Finally, we collect 2249 query-result pairs with 347 tables.","We evaluate five state-of-the-art models using three different metrics and the results show that our benchmark presents introduces considerable challenge in the field of tabular data analysis, paving the way for more advanced research opportunities."],"url":"http://arxiv.org/abs/2312.13671v1"}
{"created":"2023-12-21 08:40:05","title":"DENIS-SDN: Software-Defined Network Slicing Solution for Dense and Ultra-Dense IoT Networks","abstract":"Traditional Wireless Sensor Networks protocols used in Internet of Things Networks (IoTNs) today face challenges in high- and ultra-density network topology conditions. New networking paradigms like Software-Defined Networks (SDN) have emerged as an up-and-coming approach to address IoT application requirements through implementing global protocol strategies and network programmability. This paper proposes a divide-and-conquer solution that aims to improve the PDR in ultra-dense IoT (UDIoT) network environments using network slicing. As such, we develop and evaluate DENIS-SDN, an open-source SDN solution for UDIoT Network environments consisting of a modular SDN controller and an OpenFlow-like data-plane protocol. DENIS-SDN utilizes our Network Density Control mechanism based on operational specification requirements, which address the challenges UDIoT network deployments pose, including interference, congestion, resource management, control, and quality of service (QoS) performance issues. To achieve this, it divides dense IoT networks into either logically sliced sub-networks separating nodes using routing rules or physically sliced sub-networks separating nodes into different radio channels. We provide evaluation results over realistic scenarios demonstrating improved PDR performance up to 4.8% for logically and up to 11.6% for physically sliced network scenarios.","sentences":["Traditional Wireless Sensor Networks protocols used in Internet of Things Networks (IoTNs) today face challenges in high- and ultra-density network topology conditions.","New networking paradigms like Software-Defined Networks (SDN) have emerged as an up-and-coming approach to address IoT application requirements through implementing global protocol strategies and network programmability.","This paper proposes a divide-and-conquer solution that aims to improve the PDR in ultra-dense IoT (UDIoT) network environments using network slicing.","As such, we develop and evaluate DENIS-SDN, an open-source SDN solution for UDIoT Network environments consisting of a modular SDN controller and an OpenFlow-like data-plane protocol.","DENIS-SDN utilizes our Network Density Control mechanism based on operational specification requirements, which address the challenges UDIoT network deployments pose, including interference, congestion, resource management, control, and quality of service (QoS) performance issues.","To achieve this, it divides dense IoT networks into either logically sliced sub-networks separating nodes using routing rules or physically sliced sub-networks separating nodes into different radio channels.","We provide evaluation results over realistic scenarios demonstrating improved PDR performance up to 4.8% for logically and up to 11.6% for physically sliced network scenarios."],"url":"http://arxiv.org/abs/2312.13662v1"}
{"created":"2023-12-21 08:13:40","title":"Theoretical analysis of git bisect","abstract":"In this paper, we consider the problem of finding a regression in a version control system (VCS), such as \\texttt{git}. The set of versions is modelled by a Directed Acyclic Graph (DAG) where vertices represent versions of the software, and arcs are the changes between different versions. We assume that somewhere in the DAG, a bug was introduced, which persists in all of its subsequent versions. It is possible to query a vertex to check whether the corresponding version carries the bug. Given a DAG and a bugged vertex, the Regression Search Problem consists in finding the first vertex containing the bug in a minimum number of queries in the worst-case scenario. This problem is known to be NP-complete. We study the algorithm used in \\texttt{git} to address this problem, known as \\texttt{git bisect}. We prove that in a general setting, \\texttt{git bisect} can use an exponentially larger number of queries than an optimal algorithm. We also consider the restriction where all vertices have indegree at most 2 (i.e. where merges are made between at most two branches at a time in the VCS), and prove that in this case, \\texttt{git bisect} is a $\\frac{1}{\\log_2(3/2)}$-approximation algorithm, and that this bound is tight. We also provide a better approximation algorithm for this case. Finally, we give an alternative proof of the NP-completeness of the Regression Search Problem, via a variation with bounded indegree.","sentences":["In this paper, we consider the problem of finding a regression in a version control system (VCS), such as \\texttt{git}.","The set of versions is modelled by a Directed Acyclic Graph (DAG) where vertices represent versions of the software, and arcs are the changes between different versions.","We assume that somewhere in the DAG, a bug was introduced, which persists in all of its subsequent versions.","It is possible to query a vertex to check whether the corresponding version carries the bug.","Given a DAG and a bugged vertex, the Regression Search Problem consists in finding the first vertex containing the bug in a minimum number of queries in the worst-case scenario.","This problem is known to be NP-complete.","We study the algorithm used in \\texttt{git} to address this problem, known as \\texttt{git bisect}.","We prove that in a general setting, \\texttt{git bisect} can use an exponentially larger number of queries than an optimal algorithm.","We also consider the restriction where all vertices have indegree at most 2 (i.e. where merges are made between at most two branches at a time in the VCS), and prove that in this case, \\texttt{git bisect} is a $\\frac{1}{\\log_2(3/2)}$-approximation algorithm, and that this bound is tight.","We also provide a better approximation algorithm for this case.","Finally, we give an alternative proof of the NP-completeness of the Regression Search Problem, via a variation with bounded indegree."],"url":"http://arxiv.org/abs/2312.13644v1"}
{"created":"2023-12-21 07:49:27","title":"Multi-Modal Domain Adaptation Across Video Scenes for Temporal Video Grounding","abstract":"Temporal Video Grounding (TVG) aims to localize the temporal boundary of a specific segment in an untrimmed video based on a given language query. Since datasets in this domain are often gathered from limited video scenes, models tend to overfit to scene-specific factors, which leads to suboptimal performance when encountering new scenes in real-world applications. In a new scene, the fine-grained annotations are often insufficient due to the expensive labor cost, while the coarse-grained video-query pairs are easier to obtain. Thus, to address this issue and enhance model performance on new scenes, we explore the TVG task in an unsupervised domain adaptation (UDA) setting across scenes for the first time, where the video-query pairs in the source scene (domain) are labeled with temporal boundaries, while those in the target scene are not. Under the UDA setting, we introduce a novel Adversarial Multi-modal Domain Adaptation (AMDA) method to adaptively adjust the model's scene-related knowledge by incorporating insights from the target data. Specifically, we tackle the domain gap by utilizing domain discriminators, which help identify valuable scene-related features effective across both domains. Concurrently, we mitigate the semantic gap between different modalities by aligning video-query pairs with related semantics. Furthermore, we employ a mask-reconstruction approach to enhance the understanding of temporal semantics within a scene. Extensive experiments on Charades-STA, ActivityNet Captions, and YouCook2 demonstrate the effectiveness of our proposed method.","sentences":["Temporal Video Grounding (TVG) aims to localize the temporal boundary of a specific segment in an untrimmed video based on a given language query.","Since datasets in this domain are often gathered from limited video scenes, models tend to overfit to scene-specific factors, which leads to suboptimal performance when encountering new scenes in real-world applications.","In a new scene, the fine-grained annotations are often insufficient due to the expensive labor cost, while the coarse-grained video-query pairs are easier to obtain.","Thus, to address this issue and enhance model performance on new scenes, we explore the TVG task in an unsupervised domain adaptation (UDA) setting across scenes for the first time, where the video-query pairs in the source scene (domain) are labeled with temporal boundaries, while those in the target scene are not.","Under the UDA setting, we introduce a novel Adversarial Multi-modal Domain Adaptation (AMDA) method to adaptively adjust the model's scene-related knowledge by incorporating insights from the target data.","Specifically, we tackle the domain gap by utilizing domain discriminators, which help identify valuable scene-related features effective across both domains.","Concurrently, we mitigate the semantic gap between different modalities by aligning video-query pairs with related semantics.","Furthermore, we employ a mask-reconstruction approach to enhance the understanding of temporal semantics within a scene.","Extensive experiments on Charades-STA, ActivityNet Captions, and YouCook2 demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2312.13633v1"}
{"created":"2023-12-21 07:38:59","title":"Where and How to Attack? A Causality-Inspired Recipe for Generating Counterfactual Adversarial Examples","abstract":"Deep neural networks (DNNs) have been demonstrated to be vulnerable to well-crafted \\emph{adversarial examples}, which are generated through either well-conceived $\\mathcal{L}_p$-norm restricted or unrestricted attacks. Nevertheless, the majority of those approaches assume that adversaries can modify any features as they wish, and neglect the causal generating process of the data, which is unreasonable and unpractical. For instance, a modification in income would inevitably impact features like the debt-to-income ratio within a banking system. By considering the underappreciated causal generating process, first, we pinpoint the source of the vulnerability of DNNs via the lens of causality, then give theoretical results to answer \\emph{where to attack}. Second, considering the consequences of the attack interventions on the current state of the examples to generate more realistic adversarial examples, we propose CADE, a framework that can generate \\textbf{C}ounterfactual \\textbf{AD}versarial \\textbf{E}xamples to answer \\emph{how to attack}. The empirical results demonstrate CADE's effectiveness, as evidenced by its competitive performance across diverse attack scenarios, including white-box, transfer-based, and random intervention attacks.","sentences":["Deep neural networks (DNNs) have been demonstrated to be vulnerable to well-crafted \\emph{adversarial examples}, which are generated through either well-conceived $\\mathcal{L}_p$-norm restricted or unrestricted attacks.","Nevertheless, the majority of those approaches assume that adversaries can modify any features as they wish, and neglect the causal generating process of the data, which is unreasonable and unpractical.","For instance, a modification in income would inevitably impact features like the debt-to-income ratio within a banking system.","By considering the underappreciated causal generating process, first, we pinpoint the source of the vulnerability of DNNs via the lens of causality, then give theoretical results to answer \\emph{where to attack}.","Second, considering the consequences of the attack interventions on the current state of the examples to generate more realistic adversarial examples, we propose CADE, a framework that can generate \\textbf{C}ounterfactual \\textbf{AD}versarial \\textbf{E}xamples to answer \\emph{how to attack}.","The empirical results demonstrate CADE's effectiveness, as evidenced by its competitive performance across diverse attack scenarios, including white-box, transfer-based, and random intervention attacks."],"url":"http://arxiv.org/abs/2312.13628v1"}
{"created":"2023-12-21 07:22:25","title":"A Comprehensive End-to-End Computer Vision Framework for Restoration and Recognition of Low-Quality Engineering Drawings","abstract":"The digitization of engineering drawings is crucial for efficient reuse, distribution, and archiving. Existing computer vision approaches for digitizing engineering drawings typically assume the input drawings have high quality. However, in reality, engineering drawings are often blurred and distorted due to improper scanning, storage, and transmission, which may jeopardize the effectiveness of existing approaches. This paper focuses on restoring and recognizing low-quality engineering drawings, where an end-to-end framework is proposed to improve the quality of the drawings and identify the graphical symbols on them. The framework uses K-means clustering to classify different engineering drawing patches into simple and complex texture patches based on their gray level co-occurrence matrix statistics. Computer vision operations and a modified Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) model are then used to improve the quality of the two types of patches, respectively. A modified Faster Region-based Convolutional Neural Network (Faster R-CNN) model is used to recognize the quality-enhanced graphical symbols. Additionally, a multi-stage task-driven collaborative learning strategy is proposed to train the modified ESRGAN and Faster R-CNN models to improve the resolution of engineering drawings in the direction that facilitates graphical symbol recognition, rather than human visual perception. A synthetic data generation method is also proposed to construct quality-degraded samples for training the framework. Experiments on real-world electrical diagrams show that the proposed framework achieves an accuracy of 98.98% and a recall of 99.33%, demonstrating its superiority over previous approaches. Moreover, the framework is integrated into a widely-used power system software application to showcase its practicality.","sentences":["The digitization of engineering drawings is crucial for efficient reuse, distribution, and archiving.","Existing computer vision approaches for digitizing engineering drawings typically assume the input drawings have high quality.","However, in reality, engineering drawings are often blurred and distorted due to improper scanning, storage, and transmission, which may jeopardize the effectiveness of existing approaches.","This paper focuses on restoring and recognizing low-quality engineering drawings, where an end-to-end framework is proposed to improve the quality of the drawings and identify the graphical symbols on them.","The framework uses K-means clustering to classify different engineering drawing patches into simple and complex texture patches based on their gray level co-occurrence matrix statistics.","Computer vision operations and a modified Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) model are then used to improve the quality of the two types of patches, respectively.","A modified Faster Region-based Convolutional Neural Network (Faster R-CNN) model is used to recognize the quality-enhanced graphical symbols.","Additionally, a multi-stage task-driven collaborative learning strategy is proposed to train the modified ESRGAN and Faster R-CNN models to improve the resolution of engineering drawings in the direction that facilitates graphical symbol recognition, rather than human visual perception.","A synthetic data generation method is also proposed to construct quality-degraded samples for training the framework.","Experiments on real-world electrical diagrams show that the proposed framework achieves an accuracy of 98.98% and a recall of 99.33%, demonstrating its superiority over previous approaches.","Moreover, the framework is integrated into a widely-used power system software application to showcase its practicality."],"url":"http://arxiv.org/abs/2312.13620v1"}
{"created":"2023-12-21 07:05:21","title":"Navigating the Structured What-If Spaces: Counterfactual Generation via Structured Diffusion","abstract":"Generating counterfactual explanations is one of the most effective approaches for uncovering the inner workings of black-box neural network models and building user trust. While remarkable strides have been made in generative modeling using diffusion models in domains like vision, their utility in generating counterfactual explanations in structured modalities remains unexplored. In this paper, we introduce Structured Counterfactual Diffuser or SCD, the first plug-and-play framework leveraging diffusion for generating counterfactual explanations in structured data. SCD learns the underlying data distribution via a diffusion model which is then guided at test time to generate counterfactuals for any arbitrary black-box model, input, and desired prediction. Our experiments show that our counterfactuals not only exhibit high plausibility compared to the existing state-of-the-art but also show significantly better proximity and diversity.","sentences":["Generating counterfactual explanations is one of the most effective approaches for uncovering the inner workings of black-box neural network models and building user trust.","While remarkable strides have been made in generative modeling using diffusion models in domains like vision, their utility in generating counterfactual explanations in structured modalities remains unexplored.","In this paper, we introduce Structured Counterfactual Diffuser or SCD, the first plug-and-play framework leveraging diffusion for generating counterfactual explanations in structured data.","SCD learns the underlying data distribution via a diffusion model which is then guided at test time to generate counterfactuals for any arbitrary black-box model, input, and desired prediction.","Our experiments show that our counterfactuals not only exhibit high plausibility compared to the existing state-of-the-art but also show significantly better proximity and diversity."],"url":"http://arxiv.org/abs/2312.13616v1"}
{"created":"2023-12-21 07:01:18","title":"Topology Learning for Heterogeneous Decentralized Federated Learning over Unreliable D2D Networks","abstract":"With the proliferation of intelligent mobile devices in wireless device-to-device (D2D) networks, decentralized federated learning (DFL) has attracted significant interest. Compared to centralized federated learning (CFL), DFL mitigates the risk of central server failures due to communication bottlenecks. However, DFL faces several challenges, such as the severe heterogeneity of data distributions in diverse environments, and the transmission outages and package errors caused by the adoption of the User Datagram Protocol (UDP) in D2D networks. These challenges often degrade the convergence of training DFL models. To address these challenges, we conduct a thorough theoretical convergence analysis for DFL and derive a convergence bound. By defining a novel quantity named unreliable links-aware neighborhood discrepancy in this convergence bound, we formulate a tractable optimization objective, and develop a novel Topology Learning method considering the Representation Discrepancy and Unreliable Links in DFL, named ToLRDUL. Intensive experiments under both feature skew and label skew settings have validated the effectiveness of our proposed method, demonstrating improved convergence speed and test accuracy, consistent with our theoretical findings.","sentences":["With the proliferation of intelligent mobile devices in wireless device-to-device (D2D) networks, decentralized federated learning (DFL) has attracted significant interest.","Compared to centralized federated learning (CFL), DFL mitigates the risk of central server failures due to communication bottlenecks.","However, DFL faces several challenges, such as the severe heterogeneity of data distributions in diverse environments, and the transmission outages and package errors caused by the adoption of the User Datagram Protocol (UDP) in D2D networks.","These challenges often degrade the convergence of training DFL models.","To address these challenges, we conduct a thorough theoretical convergence analysis for DFL and derive a convergence bound.","By defining a novel quantity named unreliable links-aware neighborhood discrepancy in this convergence bound, we formulate a tractable optimization objective, and develop a novel Topology Learning method considering the Representation Discrepancy and Unreliable Links in DFL, named ToLRDUL.","Intensive experiments under both feature skew and label skew settings have validated the effectiveness of our proposed method, demonstrating improved convergence speed and test accuracy, consistent with our theoretical findings."],"url":"http://arxiv.org/abs/2312.13611v1"}
{"created":"2023-12-21 06:51:34","title":"Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation","abstract":"Counter-argument generation -- a captivating area in computational linguistics -- seeks to craft statements that offer opposing views. While most research has ventured into paragraph-level generation, sentence-level counter-argument generation beckons with its unique constraints and brevity-focused challenges. Furthermore, the diverse nature of counter-arguments poses challenges for evaluating model performance solely based on n-gram-based metrics. In this paper, we present the ArgTersely benchmark for sentence-level counter-argument generation, drawing from a manually annotated dataset from the ChangeMyView debate forum. We also propose Arg-LlaMA for generating high-quality counter-argument. For better evaluation, we trained a BERT-based evaluator Arg-Judge with human preference data. We conducted comparative experiments involving various baselines such as LlaMA, Alpaca, GPT-3, and others. The results show the competitiveness of our proposed framework and evaluator in counter-argument generation tasks. Code and data are available at https://github.com/amazingljy1206/ArgTersely.","sentences":["Counter-argument generation -- a captivating area in computational linguistics -- seeks to craft statements that offer opposing views.","While most research has ventured into paragraph-level generation, sentence-level counter-argument generation beckons with its unique constraints and brevity-focused challenges.","Furthermore, the diverse nature of counter-arguments poses challenges for evaluating model performance solely based on n-gram-based metrics.","In this paper, we present the ArgTersely benchmark for sentence-level counter-argument generation, drawing from a manually annotated dataset from the ChangeMyView debate forum.","We also propose Arg-LlaMA for generating high-quality counter-argument.","For better evaluation, we trained a BERT-based evaluator Arg-Judge with human preference data.","We conducted comparative experiments involving various baselines such as LlaMA, Alpaca, GPT-3, and others.","The results show the competitiveness of our proposed framework and evaluator in counter-argument generation tasks.","Code and data are available at https://github.com/amazingljy1206/ArgTersely."],"url":"http://arxiv.org/abs/2312.13608v1"}
{"created":"2023-12-21 06:28:02","title":"Peer-to-Peer Learning + Consensus with Non-IID Data","abstract":"Peer-to-peer deep learning algorithms are enabling distributed edge devices to collaboratively train deep neural networks without exchanging raw training data or relying on a central server. Peer-to-Peer Learning (P2PL) and other algorithms based on Distributed Local-Update Stochastic/mini-batch Gradient Descent (local DSGD) rely on interleaving epochs of training with distributed consensus steps. This process leads to model parameter drift/divergence amongst participating devices in both IID and non-IID settings. We observe that model drift results in significant oscillations in test performance evaluated after local training and consensus phases. We then identify factors that amplify performance oscillations and demonstrate that our novel approach, P2PL with Affinity, dampens test performance oscillations in non-IID settings without incurring any additional communication cost.","sentences":["Peer-to-peer deep learning algorithms are enabling distributed edge devices to collaboratively train deep neural networks without exchanging raw training data or relying on a central server.","Peer-to-Peer Learning (P2PL) and other algorithms based on Distributed Local-Update Stochastic/mini-batch Gradient Descent (local DSGD) rely on interleaving epochs of training with distributed consensus steps.","This process leads to model parameter drift/divergence amongst participating devices in both IID and non-IID settings.","We observe that model drift results in significant oscillations in test performance evaluated after local training and consensus phases.","We then identify factors that amplify performance oscillations and demonstrate that our novel approach, P2PL with Affinity, dampens test performance oscillations in non-IID settings without incurring any additional communication cost."],"url":"http://arxiv.org/abs/2312.13602v1"}
{"created":"2023-12-21 05:49:32","title":"Hierarchical Optimization of Metaheuristic Algorithms and Federated Learning for Enhanced Capacity Management and Load Balancing in HetNets","abstract":"This research introduces a revolutionary paradigm for HetNet management, presenting an innovative algorithmic framework that transcends traditional notions of network capacity enhancement. Our exploration delves into the intricate interplay among distinct components, weaving together metaheuristic algorithms, Neural Networks optimization, and Federated Learning approaches. The primary focus is on optimizing capacity in IoT-based heterogeneous networks while ensuring impeccable coverage and data reliability. Employing multi-layer optimization methods, we propose a dynamic model for optimal transmission strategy, strategically allocating replicas within cloud computing environments to curtail data access costs. Our algorithm not only discerns optimal data replication locations but also navigates the delicate balance between spectral efficiency and ergodic capacity in cellular IoT networks with small cells using on/off control. The orchestrated interplay between metaheuristic algorithms, Neural Networks optimization, and Federated Learning orchestrates resource reallocation, attaining an optimal balance between spectral efficiency, power utility, and ergodic capacity based on Quality of Service (QoS) requirements. Simulation results corroborate the efficacy of our approach, showcasing enhanced tradeoffs between spectral efficiency and total ergodic capacity with diminished outage probability compared to prevailing algorithms across diverse scenarios.","sentences":["This research introduces a revolutionary paradigm for HetNet management, presenting an innovative algorithmic framework that transcends traditional notions of network capacity enhancement.","Our exploration delves into the intricate interplay among distinct components, weaving together metaheuristic algorithms, Neural Networks optimization, and Federated Learning approaches.","The primary focus is on optimizing capacity in IoT-based heterogeneous networks while ensuring impeccable coverage and data reliability.","Employing multi-layer optimization methods, we propose a dynamic model for optimal transmission strategy, strategically allocating replicas within cloud computing environments to curtail data access costs.","Our algorithm not only discerns optimal data replication locations but also navigates the delicate balance between spectral efficiency and ergodic capacity in cellular IoT networks with small cells using on/off control.","The orchestrated interplay between metaheuristic algorithms, Neural Networks optimization, and Federated Learning orchestrates resource reallocation, attaining an optimal balance between spectral efficiency, power utility, and ergodic capacity based on Quality of Service (QoS) requirements.","Simulation results corroborate the efficacy of our approach, showcasing enhanced tradeoffs between spectral efficiency and total ergodic capacity with diminished outage probability compared to prevailing algorithms across diverse scenarios."],"url":"http://arxiv.org/abs/2312.13592v1"}
{"created":"2023-12-21 03:51:08","title":"The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction","abstract":"Transformer-based Large Language Models (LLMs) have become a fixture in modern machine learning. Correspondingly, significant resources are allocated towards research that aims to further advance this technology, typically resulting in models of increasing size that are trained on increasing amounts of data. This work, however, demonstrates the surprising result that it is often possible to significantly improve the performance of LLMs by selectively removing higher-order components of their weight matrices. This simple intervention, which we call LAyer-SElective Rank reduction (LASER), can be done on a model after training has completed, and requires no additional parameters or data. We show extensive experiments demonstrating the generality of this finding across language models and datasets, and provide in-depth analyses offering insights into both when LASER is effective and the mechanism by which it operates.","sentences":["Transformer-based Large Language Models (LLMs) have become a fixture in modern machine learning.","Correspondingly, significant resources are allocated towards research that aims to further advance this technology, typically resulting in models of increasing size that are trained on increasing amounts of data.","This work, however, demonstrates the surprising result that it is often possible to significantly improve the performance of LLMs by selectively removing higher-order components of their weight matrices.","This simple intervention, which we call LAyer-SElective Rank reduction (LASER), can be done on a model after training has completed, and requires no additional parameters or data.","We show extensive experiments demonstrating the generality of this finding across language models and datasets, and provide in-depth analyses offering insights into both when LASER is effective and the mechanism by which it operates."],"url":"http://arxiv.org/abs/2312.13558v1"}
{"created":"2023-12-21 03:46:29","title":"CR-SAM: Curvature Regularized Sharpness-Aware Minimization","abstract":"The capacity to generalize to future unseen data stands as one of the utmost crucial attributes of deep neural networks. Sharpness-Aware Minimization (SAM) aims to enhance the generalizability by minimizing worst-case loss using one-step gradient ascent as an approximation. However, as training progresses, the non-linearity of the loss landscape increases, rendering one-step gradient ascent less effective. On the other hand, multi-step gradient ascent will incur higher training cost. In this paper, we introduce a normalized Hessian trace to accurately measure the curvature of loss landscape on {\\em both} training and test sets. In particular, to counter excessive non-linearity of loss landscape, we propose Curvature Regularized SAM (CR-SAM), integrating the normalized Hessian trace as a SAM regularizer. Additionally, we present an efficient way to compute the trace via finite differences with parallelism. Our theoretical analysis based on PAC-Bayes bounds establishes the regularizer's efficacy in reducing generalization error. Empirical evaluation on CIFAR and ImageNet datasets shows that CR-SAM consistently enhances classification performance for ResNet and Vision Transformer (ViT) models across various datasets. Our code is available at https://github.com/TrustAIoT/CR-SAM.","sentences":["The capacity to generalize to future unseen data stands as one of the utmost crucial attributes of deep neural networks.","Sharpness-Aware Minimization (SAM) aims to enhance the generalizability by minimizing worst-case loss using one-step gradient ascent as an approximation.","However, as training progresses, the non-linearity of the loss landscape increases, rendering one-step gradient ascent less effective.","On the other hand, multi-step gradient ascent will incur higher training cost.","In this paper, we introduce a normalized Hessian trace to accurately measure the curvature of loss landscape on {\\em both} training and test sets.","In particular, to counter excessive non-linearity of loss landscape, we propose Curvature Regularized SAM (CR-SAM), integrating the normalized Hessian trace as a SAM regularizer.","Additionally, we present an efficient way to compute the trace via finite differences with parallelism.","Our theoretical analysis based on PAC-Bayes bounds establishes the regularizer's efficacy in reducing generalization error.","Empirical evaluation on CIFAR and ImageNet datasets shows that CR-SAM consistently enhances classification performance for ResNet and Vision Transformer (ViT) models across various datasets.","Our code is available at https://github.com/TrustAIoT/CR-SAM."],"url":"http://arxiv.org/abs/2312.13555v1"}
{"created":"2023-12-21 03:34:08","title":"Time Lower Bounds for the Metropolis Process and Simulated Annealing","abstract":"The Metropolis process (MP) and Simulated Annealing (SA) are stochastic local search heuristics that are often used in solving combinatorial optimization problems. Despite significant interest, there are very few theoretical results regarding the quality of approximation obtained by MP and SA (with polynomially many iterations) for NP-hard optimization problems.   We provide rigorous lower bounds for MP and SA with respect to the classical maximum independent set problem when the algorithms are initialized from the empty set. We establish the existence of a family of graphs for which both MP and SA fail to find approximate solutions in polynomial time. More specifically, we show that for any $\\varepsilon \\in (0,1)$ there are $n$-vertex graphs for which the probability SA (when limited to polynomially many iterations) will approximate the optimal solution within ratio $\\Omega\\left(\\frac{1}{n^{1-\\varepsilon}}\\right)$ is exponentially small. Our lower bounds extend to graphs of constant average degree $d$, illustrating the failure of MP to achieve an approximation ratio of $\\Omega\\left(\\frac{\\log (d)}{d}\\right)$ in polynomial time. In some cases, our impossibility results also go beyond Simulated Annealing and apply even when the temperature is chosen adaptively. Finally, we prove time lower bounds when the inputs to these algorithms are bipartite graphs, and even trees, which are known to admit polynomial-time algorithms for the independent set problem.","sentences":["The Metropolis process (MP) and Simulated Annealing (SA) are stochastic local search heuristics that are often used in solving combinatorial optimization problems.","Despite significant interest, there are very few theoretical results regarding the quality of approximation obtained by MP and SA (with polynomially many iterations) for NP-hard optimization problems.   ","We provide rigorous lower bounds for MP and SA with respect to the classical maximum independent set problem when the algorithms are initialized from the empty set.","We establish the existence of a family of graphs for which both MP and SA fail to find approximate solutions in polynomial time.","More specifically, we show that for any $\\varepsilon \\in (0,1)$ there are $n$-vertex graphs for which the probability SA (when limited to polynomially many iterations) will approximate the optimal solution within ratio $\\Omega\\left(\\frac{1}{n^{1-\\varepsilon}}\\right)$ is exponentially small.","Our lower bounds extend to graphs of constant average degree $d$, illustrating the failure of MP to achieve an approximation ratio of $\\Omega\\left(\\frac{\\log (d)}{d}\\right)$ in polynomial time.","In some cases, our impossibility results also go beyond Simulated Annealing and apply even when the temperature is chosen adaptively.","Finally, we prove time lower bounds when the inputs to these algorithms are bipartite graphs, and even trees, which are known to admit polynomial-time algorithms for the independent set problem."],"url":"http://arxiv.org/abs/2312.13554v1"}
{"created":"2023-12-21 02:50:15","title":"The Fuse XORier Lookup Table: Exploration, Implementation, and Revision of Probabilistic Sets and Maps","abstract":"This paper presents an exploration, implementations, and revisions of probabilistic sets and maps, specifically focusing on Bloomier filters and related data structures. The paper introduces the Fuse XORier Lookup Table (FXLT), an enhanced version of the Bloomier Filter incorporating spatial coupling, linear construction, and optimizations. The authors provide implementations in C and Python, comparing the FXLT's performance with other data structures like bloom filters, XOR filters, binary fuse filters, hash tables, and red-black trees. The FXLT demonstrates improvements in both space and time efficiency over traditional Bloomier Filters and appears competitive with hash tables for large datasets.","sentences":["This paper presents an exploration, implementations, and revisions of probabilistic sets and maps, specifically focusing on Bloomier filters and related data structures.","The paper introduces the Fuse XORier Lookup Table (FXLT), an enhanced version of the Bloomier Filter incorporating spatial coupling, linear construction, and optimizations.","The authors provide implementations in C and Python, comparing the FXLT's performance with other data structures like bloom filters, XOR filters, binary fuse filters, hash tables, and red-black trees.","The FXLT demonstrates improvements in both space and time efficiency over traditional Bloomier Filters and appears competitive with hash tables for large datasets."],"url":"http://arxiv.org/abs/2312.13541v1"}
{"created":"2023-12-21 02:37:56","title":"Domain Adaptive Graph Classification","abstract":"Despite the remarkable accomplishments of graph neural networks (GNNs), they typically rely on task-specific labels, posing potential challenges in terms of their acquisition. Existing work have been made to address this issue through the lens of unsupervised domain adaptation, wherein labeled source graphs are utilized to enhance the learning process for target data. However, the simultaneous exploration of graph topology and reduction of domain disparities remains a substantial hurdle. In this paper, we introduce the Dual Adversarial Graph Representation Learning (DAGRL), which explore the graph topology from dual branches and mitigate domain discrepancies via dual adversarial learning. Our method encompasses a dual-pronged structure, consisting of a graph convolutional network branch and a graph kernel branch, which enables us to capture graph semantics from both implicit and explicit perspectives. Moreover, our approach incorporates adaptive perturbations into the dual branches, which align the source and target distribution to address domain discrepancies. Extensive experiments on a wild range graph classification datasets demonstrate the effectiveness of our proposed method.","sentences":["Despite the remarkable accomplishments of graph neural networks (GNNs), they typically rely on task-specific labels, posing potential challenges in terms of their acquisition.","Existing work have been made to address this issue through the lens of unsupervised domain adaptation, wherein labeled source graphs are utilized to enhance the learning process for target data.","However, the simultaneous exploration of graph topology and reduction of domain disparities remains a substantial hurdle.","In this paper, we introduce the Dual Adversarial Graph Representation Learning (DAGRL), which explore the graph topology from dual branches and mitigate domain discrepancies via dual adversarial learning.","Our method encompasses a dual-pronged structure, consisting of a graph convolutional network branch and a graph kernel branch, which enables us to capture graph semantics from both implicit and explicit perspectives.","Moreover, our approach incorporates adaptive perturbations into the dual branches, which align the source and target distribution to address domain discrepancies.","Extensive experiments on a wild range graph classification datasets demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2312.13536v1"}
{"created":"2023-12-21 02:28:29","title":"Automated Clinical Coding for Outpatient Departments","abstract":"Computerised clinical coding approaches aim to automate the process of assigning a set of codes to medical records. While there is active research pushing the state of the art on clinical coding for hospitalized patients, the outpatient setting -- where doctors tend to non-hospitalised patients -- is overlooked. Although both settings can be formalised as a multi-label classification task, they present unique and distinct challenges, which raises the question of whether the success of inpatient clinical coding approaches translates to the outpatient setting. This paper is the first to investigate how well state-of-the-art deep learning-based clinical coding approaches work in the outpatient setting at hospital scale. To this end, we collect a large outpatient dataset comprising over 7 million notes documenting over half a million patients. We adapt four state-of-the-art clinical coding approaches to this setting and evaluate their potential to assist coders. We find evidence that clinical coding in outpatient settings can benefit from more innovations in popular inpatient coding benchmarks. A deeper analysis of the factors contributing to the success -- amount and form of data and choice of document representation -- reveals the presence of easy-to-solve examples, the coding of which can be completely automated with a low error rate.","sentences":["Computerised clinical coding approaches aim to automate the process of assigning a set of codes to medical records.","While there is active research pushing the state of the art on clinical coding for hospitalized patients, the outpatient setting -- where doctors tend to non-hospitalised patients -- is overlooked.","Although both settings can be formalised as a multi-label classification task, they present unique and distinct challenges, which raises the question of whether the success of inpatient clinical coding approaches translates to the outpatient setting.","This paper is the first to investigate how well state-of-the-art deep learning-based clinical coding approaches work in the outpatient setting at hospital scale.","To this end, we collect a large outpatient dataset comprising over 7 million notes documenting over half a million patients.","We adapt four state-of-the-art clinical coding approaches to this setting and evaluate their potential to assist coders.","We find evidence that clinical coding in outpatient settings can benefit from more innovations in popular inpatient coding benchmarks.","A deeper analysis of the factors contributing to the success -- amount and form of data and choice of document representation -- reveals the presence of easy-to-solve examples, the coding of which can be completely automated with a low error rate."],"url":"http://arxiv.org/abs/2312.13533v1"}
{"created":"2023-12-21 02:14:41","title":"HW-V2W-Map: Hardware Vulnerability to Weakness Mapping Framework for Root Cause Analysis with GPT-assisted Mitigation Suggestion","abstract":"The escalating complexity of modern computing frameworks has resulted in a surge in the cybersecurity vulnerabilities reported to the National Vulnerability Database (NVD) by practitioners. Despite the fact that the stature of NVD is one of the most significant databases for the latest insights into vulnerabilities, extracting meaningful trends from such a large amount of unstructured data is still challenging without the application of suitable technological methodologies. Previous efforts have mostly concentrated on software vulnerabilities; however, a holistic strategy incorporates approaches for mitigating vulnerabilities, score prediction, and a knowledge-generating system that may extract relevant insights from the Common Weakness Enumeration (CWE) and Common Vulnerability Exchange (CVE) databases is notably absent. As the number of hardware attacks on Internet of Things (IoT) devices continues to rapidly increase, we present the Hardware Vulnerability to Weakness Mapping (HW-V2W-Map) Framework, which is a Machine Learning (ML) framework focusing on hardware vulnerabilities and IoT security. The architecture that we have proposed incorporates an Ontology-driven Storytelling framework, which automates the process of updating the ontology in order to recognize patterns and evolution of vulnerabilities over time and provides approaches for mitigating the vulnerabilities. The repercussions of vulnerabilities can be mitigated as a result of this, and conversely, future exposures can be predicted and prevented. Furthermore, our proposed framework utilized Generative Pre-trained Transformer (GPT) Large Language Models (LLMs) to provide mitigation suggestions.","sentences":["The escalating complexity of modern computing frameworks has resulted in a surge in the cybersecurity vulnerabilities reported to the National Vulnerability Database (NVD) by practitioners.","Despite the fact that the stature of NVD is one of the most significant databases for the latest insights into vulnerabilities, extracting meaningful trends from such a large amount of unstructured data is still challenging without the application of suitable technological methodologies.","Previous efforts have mostly concentrated on software vulnerabilities; however, a holistic strategy incorporates approaches for mitigating vulnerabilities, score prediction, and a knowledge-generating system that may extract relevant insights from the Common Weakness Enumeration (CWE) and Common Vulnerability Exchange (CVE) databases is notably absent.","As the number of hardware attacks on Internet of Things (IoT) devices continues to rapidly increase, we present the Hardware Vulnerability to Weakness Mapping (HW-V2W-Map) Framework, which is a Machine Learning (ML) framework focusing on hardware vulnerabilities and IoT security.","The architecture that we have proposed incorporates an Ontology-driven Storytelling framework, which automates the process of updating the ontology in order to recognize patterns and evolution of vulnerabilities over time and provides approaches for mitigating the vulnerabilities.","The repercussions of vulnerabilities can be mitigated as a result of this, and conversely, future exposures can be predicted and prevented.","Furthermore, our proposed framework utilized Generative Pre-trained Transformer (GPT) Large Language Models (LLMs) to provide mitigation suggestions."],"url":"http://arxiv.org/abs/2312.13530v1"}
{"created":"2023-12-21 01:59:30","title":"New Tools for Peak Memory Scheduling","abstract":"We study scheduling of computation graphs to minimize peak memory consumption, an increasingly critical task due to the surge in popularity of large deep-learning models. This problem corresponds to the weighted version of the classical one-shot black pebbling game. We propose the notion of a dominant schedule to capture the idea of finding the ``best'' schedule for a subgraph and introduce new tools to compute and utilize dominant schedules. Surprisingly, we show that despite the strong requirements, a dominant schedule exists for any computation graph; and, moreover, that it is possible to compute the dominant schedule efficiently whenever we can find optimal schedules efficiently for a particular class of graphs (under mild technical conditions).   We apply these new tools to analyze trees and series-parallel graphs. We show that the weighted one-shot black pebbling game is strongly NP-complete even when the graph is an out-tree -- or simpler still, a pumpkin, one of the simplest series-parallel graphs. On the positive side, we design a fixed-parameter tractable algorithm to find a dominant schedule (hence also a peak memory minimizing schedule) for series-parallel graphs when parameterized by the out-degree. This algorithm runs in time $2^{O(d \\log d)} \\cdot poly(n)$ for series-parallel graphs with $n$ nodes and maximum out-degree $d$; for pumpkins, we can improve the dependence on $d$ to $O(2^d \\cdot poly(n))$.","sentences":["We study scheduling of computation graphs to minimize peak memory consumption, an increasingly critical task due to the surge in popularity of large deep-learning models.","This problem corresponds to the weighted version of the classical one-shot black pebbling game.","We propose the notion of a dominant schedule to capture the idea of finding the ``best'' schedule for a subgraph and introduce new tools to compute and utilize dominant schedules.","Surprisingly, we show that despite the strong requirements, a dominant schedule exists for any computation graph; and, moreover, that it is possible to compute the dominant schedule efficiently whenever we can find optimal schedules efficiently for a particular class of graphs (under mild technical conditions).   ","We apply these new tools to analyze trees and series-parallel graphs.","We show that the weighted one-shot black pebbling game is strongly NP-complete even when the graph is an out-tree -- or simpler still, a pumpkin, one of the simplest series-parallel graphs.","On the positive side, we design a fixed-parameter tractable algorithm to find a dominant schedule (hence also a peak memory minimizing schedule) for series-parallel graphs when parameterized by the out-degree.","This algorithm runs in time $2^{O(d \\log d)}","\\cdot poly(n)$ for series-parallel graphs with $n$ nodes and maximum out-degree $d$; for pumpkins, we can improve the dependence on $d$ to $O(2^d \\cdot poly(n))$."],"url":"http://arxiv.org/abs/2312.13526v1"}
{"created":"2023-12-21 01:50:02","title":"Secure Information Embedding in Images with Hybrid Firefly Algorithm","abstract":"Various methods have been proposed to secure access to sensitive information over time, such as the many cryptographic methods in use to facilitate secure communications on the internet. But other methods like steganography have been overlooked which may be more suitable in cases where the act of transmission of sensitive information itself should remain a secret. Multiple techniques that are commonly discussed for such scenarios suffer from low capacity and high distortion in the output signal. This research introduces a novel steganographic approach for concealing a confidential portable document format (PDF) document within a host image by employing the Hybrid Firefly algorithm (HFA) proposed to select the pixel arrangement. This algorithm combines two widely used optimization algorithms to improve their performance. The suggested methodology utilizes the HFA algorithm to conduct a search for optimal pixel placements in the spatial domain. The purpose of this search is to accomplish two main goals: increasing the host image's capacity and reducing distortion. Moreover, the proposed approach intends to reduce the time required for the embedding procedure. The findings indicate a decrease in image distortion and an accelerated rate of convergence in the search process. The resultant embeddings exhibit robustness against steganalytic assaults, hence rendering the identification of the embedded data a formidable undertaking.","sentences":["Various methods have been proposed to secure access to sensitive information over time, such as the many cryptographic methods in use to facilitate secure communications on the internet.","But other methods like steganography have been overlooked which may be more suitable in cases where the act of transmission of sensitive information itself should remain a secret.","Multiple techniques that are commonly discussed for such scenarios suffer from low capacity and high distortion in the output signal.","This research introduces a novel steganographic approach for concealing a confidential portable document format (PDF) document within a host image by employing the Hybrid Firefly algorithm (HFA) proposed to select the pixel arrangement.","This algorithm combines two widely used optimization algorithms to improve their performance.","The suggested methodology utilizes the HFA algorithm to conduct a search for optimal pixel placements in the spatial domain.","The purpose of this search is to accomplish two main goals: increasing the host image's capacity and reducing distortion.","Moreover, the proposed approach intends to reduce the time required for the embedding procedure.","The findings indicate a decrease in image distortion and an accelerated rate of convergence in the search process.","The resultant embeddings exhibit robustness against steganalytic assaults, hence rendering the identification of the embedded data a formidable undertaking."],"url":"http://arxiv.org/abs/2312.13519v1"}
{"created":"2023-12-21 01:23:09","title":"An integrated framework for accelerating reactive flow simulation using GPU and machine learning models","abstract":"Recent progress in artificial intelligence (AI) and high-performance computing (HPC) have brought potentially game-changing opportunities in accelerating reactive flow simulations. In this study, we introduce an open-source computational fluid dynamics (CFD) framework that integrates the strengths of machine learning (ML) and graphics processing unit (GPU) to demonstrate their combined capability. Within this framework, all computational operations are solely executed on GPU, including ML-accelerated chemistry integration, fully-implicit solving of PDEs, and computation of thermal and transport properties, thereby eliminating the CPU-GPU memory copy overhead. Optimisations both within the kernel functions and during the kernel launch process are conducted to enhance computational performance. Strategies such as static data reorganisation and dynamic data allocation are adopted to reduce the GPU memory footprint. The computational performance is evaluated in two turbulent flame benchmarks using quasi-DNS and LES modelling, respectively. Remarkably, while maintaining a similar level of accuracy to the conventional CPU/CVODE-based solver, the GPU/ML-accelerated approach shows an overall speedup of over two orders of magnitude for both cases. This result highlights that high-fidelity turbulent combustion simulation with finite-rate chemistry that requires normally hundreds of CPUs can now be performed on portable devices such as laptops with a medium-end GPU.","sentences":["Recent progress in artificial intelligence (AI) and high-performance computing (HPC) have brought potentially game-changing opportunities in accelerating reactive flow simulations.","In this study, we introduce an open-source computational fluid dynamics (CFD) framework that integrates the strengths of machine learning (ML) and graphics processing unit (GPU) to demonstrate their combined capability.","Within this framework, all computational operations are solely executed on GPU, including ML-accelerated chemistry integration, fully-implicit solving of PDEs, and computation of thermal and transport properties, thereby eliminating the CPU-GPU memory copy overhead.","Optimisations both within the kernel functions and during the kernel launch process are conducted to enhance computational performance.","Strategies such as static data reorganisation and dynamic data allocation are adopted to reduce the GPU memory footprint.","The computational performance is evaluated in two turbulent flame benchmarks using quasi-DNS and LES modelling, respectively.","Remarkably, while maintaining a similar level of accuracy to the conventional CPU/CVODE-based solver, the GPU/ML-accelerated approach shows an overall speedup of over two orders of magnitude for both cases.","This result highlights that high-fidelity turbulent combustion simulation with finite-rate chemistry that requires normally hundreds of CPUs can now be performed on portable devices such as laptops with a medium-end GPU."],"url":"http://arxiv.org/abs/2312.13513v1"}
{"created":"2023-12-21 01:12:44","title":"Symmetry-enforcing neural networks with applications to constitutive modeling","abstract":"The use of machine learning techniques to homogenize the effective behavior of arbitrary microstructures has been shown to be not only efficient but also accurate. In a recent work, we demonstrated how to combine state-of-the-art micromechanical modeling and advanced machine learning techniques to homogenize complex microstructures exhibiting non-linear and history dependent behaviors. The resulting homogenized model, termed smart constitutive law (SCL), enables the adoption of microstructurally informed constitutive laws into finite element solvers at a fraction of the computational cost required by traditional concurrent multiscale approaches. In this work, the capabilities of SCLs are expanded via the introduction of a novel methodology that enforces material symmetries at the neuron level, applicable across various neural network architectures. This approach utilizes tensor-based features in neural networks, facilitating the concise and accurate representation of symmetry-preserving operations, and is general enough to be extend to problems beyond constitutive modeling. Details on the construction of these tensor-based neural networks and their application in learning constitutive laws are presented for both elastic and inelastic materials. The superiority of this approach over traditional neural networks is demonstrated in scenarios with limited data and strong symmetries, through comprehensive testing on various materials, including isotropic neo-Hookean materials and tensegrity lattice metamaterials. This work is concluded by a discussion on the potential of this methodology to discover symmetry bases in materials and by an outline of future research directions.","sentences":["The use of machine learning techniques to homogenize the effective behavior of arbitrary microstructures has been shown to be not only efficient but also accurate.","In a recent work, we demonstrated how to combine state-of-the-art micromechanical modeling and advanced machine learning techniques to homogenize complex microstructures exhibiting non-linear and history dependent behaviors.","The resulting homogenized model, termed smart constitutive law (SCL), enables the adoption of microstructurally informed constitutive laws into finite element solvers at a fraction of the computational cost required by traditional concurrent multiscale approaches.","In this work, the capabilities of SCLs are expanded via the introduction of a novel methodology that enforces material symmetries at the neuron level, applicable across various neural network architectures.","This approach utilizes tensor-based features in neural networks, facilitating the concise and accurate representation of symmetry-preserving operations, and is general enough to be extend to problems beyond constitutive modeling.","Details on the construction of these tensor-based neural networks and their application in learning constitutive laws are presented for both elastic and inelastic materials.","The superiority of this approach over traditional neural networks is demonstrated in scenarios with limited data and strong symmetries, through comprehensive testing on various materials, including isotropic neo-Hookean materials and tensegrity lattice metamaterials.","This work is concluded by a discussion on the potential of this methodology to discover symmetry bases in materials and by an outline of future research directions."],"url":"http://arxiv.org/abs/2312.13511v1"}
{"created":"2023-12-21 00:44:45","title":"InfoVisDial: An Informative Visual Dialogue Dataset by Bridging Large Multimodal and Language Models","abstract":"In this paper, we build a visual dialogue dataset, named InfoVisDial, which provides rich informative answers in each round even with external knowledge related to the visual content. Different from existing datasets where the answer is compact and short, InfoVisDial contains long free-form answers with rich information in each round of dialogue. For effective data collection, the key idea is to bridge the large-scale multimodal model (e.g., GIT) and the language models (e.g., GPT-3). GIT can describe the image content even with scene text, while GPT-3 can generate informative dialogue based on the image description and appropriate prompting techniques. With such automatic pipeline, we can readily generate informative visual dialogue data at scale. Then, we ask human annotators to rate the generated dialogues to filter the low-quality conversations.Human analyses show that InfoVisDial covers informative and diverse dialogue topics: $54.4\\%$ of the dialogue rounds are related to image scene texts, and $36.7\\%$ require external knowledge. Each round's answer is also long and open-ended: $87.3\\%$ of answers are unique with an average length of $8.9$, compared with $27.37\\%$ and $2.9$ in VisDial. Last, we propose a strong baseline by adapting the GIT model for the visual dialogue task and fine-tune the model on InfoVisDial. Hopefully, our work can motivate more effort on this direction.","sentences":["In this paper, we build a visual dialogue dataset, named InfoVisDial, which provides rich informative answers in each round even with external knowledge related to the visual content.","Different from existing datasets where the answer is compact and short, InfoVisDial contains long free-form answers with rich information in each round of dialogue.","For effective data collection, the key idea is to bridge the large-scale multimodal model (e.g., GIT) and the language models (e.g., GPT-3).","GIT can describe the image content even with scene text, while GPT-3 can generate informative dialogue based on the image description and appropriate prompting techniques.","With such automatic pipeline, we can readily generate informative visual dialogue data at scale.","Then, we ask human annotators to rate the generated dialogues to filter the low-quality conversations.","Human analyses show that InfoVisDial covers informative and diverse dialogue topics: $54.4\\%$ of the dialogue rounds are related to image scene texts, and $36.7\\%$ require external knowledge.","Each round's answer is also long and open-ended: $87.3\\%$ of answers are unique with an average length of $8.9$, compared with $27.37\\%$ and $2.9$ in VisDial.","Last, we propose a strong baseline by adapting the GIT model for the visual dialogue task and fine-tune the model on InfoVisDial.","Hopefully, our work can motivate more effort on this direction."],"url":"http://arxiv.org/abs/2312.13503v1"}
{"created":"2023-12-21 00:31:54","title":"Federated Continual Novel Class Learning","abstract":"In a privacy-focused era, Federated Learning (FL) has emerged as a promising machine learning technique. However, most existing FL studies assume that the data distribution remains nearly fixed over time, while real-world scenarios often involve dynamic and continual changes. To equip FL systems with continual model evolution capabilities, we focus on an important problem called Federated Continual Novel Class Learning (FedCN) in this work. The biggest challenge in FedCN is to merge and align novel classes that are discovered and learned by different clients without compromising privacy. To address this, we propose a Global Alignment Learning (GAL) framework that can accurately estimate the global novel class number and provide effective guidance for local training from a global perspective, all while maintaining privacy protection. Specifically, GAL first locates high-density regions in the representation space through a bi-level clustering mechanism to estimate the novel class number, with which the global prototypes corresponding to novel classes can be constructed. Then, GAL uses a novel semantic weighted loss to capture all possible correlations between these prototypes and the training data for mitigating the impact of pseudo-label noise and data heterogeneity. Extensive experiments on various datasets demonstrate GAL's superior performance over state-of-the-art novel class discovery methods. In particular, GAL achieves significant improvements in novel-class performance, increasing the accuracy by 5.1% to 10.6% in the case of one novel class learning stage and by 7.8% to 17.9% in the case of two novel class learning stages, without sacrificing known-class performance. Moreover, GAL is shown to be effective in equipping a variety of different mainstream FL algorithms with novel class discovery and learning capability, highlighting its potential for many real-world applications.","sentences":["In a privacy-focused era, Federated Learning (FL) has emerged as a promising machine learning technique.","However, most existing FL studies assume that the data distribution remains nearly fixed over time, while real-world scenarios often involve dynamic and continual changes.","To equip FL systems with continual model evolution capabilities, we focus on an important problem called Federated Continual Novel Class Learning (FedCN) in this work.","The biggest challenge in FedCN is to merge and align novel classes that are discovered and learned by different clients without compromising privacy.","To address this, we propose a Global Alignment Learning (GAL) framework that can accurately estimate the global novel class number and provide effective guidance for local training from a global perspective, all while maintaining privacy protection.","Specifically, GAL first locates high-density regions in the representation space through a bi-level clustering mechanism to estimate the novel class number, with which the global prototypes corresponding to novel classes can be constructed.","Then, GAL uses a novel semantic weighted loss to capture all possible correlations between these prototypes and the training data for mitigating the impact of pseudo-label noise and data heterogeneity.","Extensive experiments on various datasets demonstrate GAL's superior performance over state-of-the-art novel class discovery methods.","In particular, GAL achieves significant improvements in novel-class performance, increasing the accuracy by 5.1% to 10.6% in the case of one novel class learning stage and by 7.8% to 17.9% in the case of two novel class learning stages, without sacrificing known-class performance.","Moreover, GAL is shown to be effective in equipping a variety of different mainstream FL algorithms with novel class discovery and learning capability, highlighting its potential for many real-world applications."],"url":"http://arxiv.org/abs/2312.13500v1"}
{"created":"2023-12-21 00:16:21","title":"Decoupling Representation and Knowledge for Few-Shot Intent Classification and Slot Filling","abstract":"Few-shot intent classification and slot filling are important but challenging tasks due to the scarcity of finely labeled data. Therefore, current works first train a model on source domains with sufficiently labeled data, and then transfer the model to target domains where only rarely labeled data is available. However, experience transferring as a whole usually suffers from gaps that exist among source domains and target domains. For instance, transferring domain-specific-knowledge-related experience is difficult. To tackle this problem, we propose a new method that explicitly decouples the transferring of general-semantic-representation-related experience and the domain-specific-knowledge-related experience. Specifically, for domain-specific-knowledge-related experience, we design two modules to capture intent-slot relation and slot-slot relation respectively. Extensive experiments on Snips and FewJoint datasets show that our method achieves state-of-the-art performance. The method improves the joint accuracy metric from 27.72% to 42.20% in the 1-shot setting, and from 46.54% to 60.79% in the 5-shot setting.","sentences":["Few-shot intent classification and slot filling are important but challenging tasks due to the scarcity of finely labeled data.","Therefore, current works first train a model on source domains with sufficiently labeled data, and then transfer the model to target domains where only rarely labeled data is available.","However, experience transferring as a whole usually suffers from gaps that exist among source domains and target domains.","For instance, transferring domain-specific-knowledge-related experience is difficult.","To tackle this problem, we propose a new method that explicitly decouples the transferring of general-semantic-representation-related experience and the domain-specific-knowledge-related experience.","Specifically, for domain-specific-knowledge-related experience, we design two modules to capture intent-slot relation and slot-slot relation respectively.","Extensive experiments on Snips and FewJoint datasets show that our method achieves state-of-the-art performance.","The method improves the joint accuracy metric from 27.72% to 42.20% in the 1-shot setting, and from 46.54% to 60.79% in the 5-shot setting."],"url":"http://arxiv.org/abs/2312.13495v1"}
{"created":"2023-12-21 00:14:46","title":"Visual Tomography: Physically Faithful Volumetric Models of Partially Translucent Objects","abstract":"When created faithfully from real-world data, Digital 3D representations of objects can be useful for human or computer-assisted analysis. Such models can also serve for generating training data for machine learning approaches in settings where data is difficult to obtain or where too few training data exists, e.g. by providing novel views or images in varying conditions. While the vast amount of visual 3D reconstruction approaches focus on non-physical models, textured object surfaces or shapes, in this contribution we propose a volumetric reconstruction approach that obtains a physical model including the interior of partially translucent objects such as plankton or insects. Our technique photographs the object under different poses in front of a bright white light source and computes absorption and scattering per voxel. It can be interpreted as visual tomography that we solve by inverse raytracing. We additionally suggest a method to convert non-physical NeRF media into a physically-based volumetric grid for initialization and illustrate the usefulness of the approach using two real-world plankton validation sets, the lab-scanned models being finally also relighted and virtually submerged in a scenario with augmented medium and illumination conditions. Please visit the project homepage at www.marine.informatik.uni-kiel.de/go/vito","sentences":["When created faithfully from real-world data, Digital 3D representations of objects can be useful for human or computer-assisted analysis.","Such models can also serve for generating training data for machine learning approaches in settings where data is difficult to obtain or where too few training data exists, e.g. by providing novel views or images in varying conditions.","While the vast amount of visual 3D reconstruction approaches focus on non-physical models, textured object surfaces or shapes, in this contribution we propose a volumetric reconstruction approach that obtains a physical model including the interior of partially translucent objects such as plankton or insects.","Our technique photographs the object under different poses in front of a bright white light source and computes absorption and scattering per voxel.","It can be interpreted as visual tomography that we solve by inverse raytracing.","We additionally suggest a method to convert non-physical NeRF media into a physically-based volumetric grid for initialization and illustrate the usefulness of the approach using two real-world plankton validation sets, the lab-scanned models being finally also relighted and virtually submerged in a scenario with augmented medium and illumination conditions.","Please visit the project homepage at www.marine.informatik.uni-kiel.de/go/vito"],"url":"http://arxiv.org/abs/2312.13494v1"}
{"created":"2023-12-20 23:54:18","title":"Dimension-Accuracy Tradeoffs in Contrastive Embeddings for Triplets, Terminals & Top-k Nearest Neighbors","abstract":"Metric embeddings traditionally study how to map $n$ items to a target metric space such that distance lengths are not heavily distorted; but what if we only care to preserve the relative order of the distances (and not their length)? In this paper, we are motivated by the following basic question: given triplet comparisons of the form ``item $i$ is closer to item $j$ than to item $k$,'' can we find low-dimensional Euclidean representations for the $n$ items that respect those distance comparisons? Such order-preserving embeddings naturally arise in important applications and have been studied since the 1950s, under the name of ordinal or non-metric embeddings. Our main results are:   1. Nearly-Tight Bounds on Triplet Dimension: We introduce the natural concept of triplet dimension of a dataset, and surprisingly, we show that in order for an ordinal embedding to be triplet-preserving, its dimension needs to grow as $\\frac n2$ in the worst case. This is optimal (up to constant) as $n-1$ dimensions always suffice.   2. Tradeoffs for Dimension vs (Ordinal) Relaxation: We then relax the requirement that every triplet should be exactly preserved and present almost tight lower bounds for the maximum ratio between distances whose relative order was inverted by the embedding; this ratio is known as (ordinal) relaxation in the literature and serves as a counterpart to (metric) distortion.   3. New Bounds on Terminal and Top-$k$-NNs Embeddings: Going beyond triplets, we then study two well-motivated scenarios where we care about preserving specific sets of distances (not necessarily triplets). The first scenario is Terminal Ordinal Embeddings and the second scenario is top-$k$-NNs Ordinal Embeddings.   To the best of our knowledge, these are some of the first tradeoffs on triplet-preserving ordinal embeddings and the first study of Terminal and Top-$k$-NNs Ordinal Embeddings.","sentences":["Metric embeddings traditionally study how to map $n$ items to a target metric space such that distance lengths are not heavily distorted; but what if we only care to preserve the relative order of the distances (and not their length)?","In this paper, we are motivated by the following basic question: given triplet comparisons of the form ``item $i$ is closer to item $j$ than to item $k$,'' can we find low-dimensional Euclidean representations for the $n$ items that respect those distance comparisons?","Such order-preserving embeddings naturally arise in important applications and have been studied since the 1950s, under the name of ordinal or non-metric embeddings.","Our main results are:   1.","Nearly-Tight Bounds on Triplet Dimension",": We introduce the natural concept of triplet dimension of a dataset, and surprisingly, we show that in order for an ordinal embedding to be triplet-preserving, its dimension needs to grow as $\\frac n2$ in the worst case.","This is optimal (up to constant) as $n-1$ dimensions always suffice.   ","2.","Tradeoffs for Dimension vs (Ordinal) Relaxation: We then relax the requirement that every triplet should be exactly preserved and present almost tight lower bounds for the maximum ratio between distances whose relative order was inverted by the embedding; this ratio is known as (ordinal) relaxation in the literature and serves as a counterpart to (metric) distortion.   ","3.","New Bounds on Terminal and Top-$k$-NNs Embeddings: Going beyond triplets, we then study two well-motivated scenarios where we care about preserving specific sets of distances (not necessarily triplets).","The first scenario is Terminal Ordinal Embeddings and the second scenario is top-$k$-NNs Ordinal Embeddings.   ","To the best of our knowledge, these are some of the first tradeoffs on triplet-preserving ordinal embeddings and the first study of Terminal and Top-$k$-NNs Ordinal Embeddings."],"url":"http://arxiv.org/abs/2312.13490v1"}
{"created":"2023-12-20 23:52:53","title":"Embedded Shape Matching in Photogrammetry Data for Modeling Making Knowledge","abstract":"In three-dimensional models obtained by photogrammetry of existing structures, all of the shapes that the eye can select cannot always find their equivalents in the geometric components of the model. However, the matching of meaningful parts and assemblages with the records acquired with rapid and detailed documentation methods will provide an advantage for the creation of information models of existing structures. While aiming to produce answers to this problem and in order to overcome the difficulties of pattern recognition in three-dimensional models, we used two-dimensional samples obtained by projection. Processing techniques such as ambient occlusion, curvature and normal maps are commonly used in modern computer graphics applications that enable the representation of three-dimensional surface properties in two-dimensional data sets. The method we propose is based on the recognition of patterns through these mappings instead of the usual light-based visualization. The first stage of the application is photogrammetric capture of a few examples of Zeugma mosaics and three-dimensional digital modeling of a set of Seljuk era brick walls based on knowledge obtained through architectural history literature. The second stage covers the creation of digital models byprocessing the surface representation obtained from this data using Alice Vision, OpenCV-Python, and Autodesk Maya to include information on aspects of the making of the walls. What is envisioned for the next stages is that the mapping data contributes and supports the knowledge for rule-based design and making processesof cultural heritage.","sentences":["In three-dimensional models obtained by photogrammetry of existing structures, all of the shapes that the eye can select cannot always find their equivalents in the geometric components of the model.","However, the matching of meaningful parts and assemblages with the records acquired with rapid and detailed documentation methods will provide an advantage for the creation of information models of existing structures.","While aiming to produce answers to this problem and in order to overcome the difficulties of pattern recognition in three-dimensional models, we used two-dimensional samples obtained by projection.","Processing techniques such as ambient occlusion, curvature and normal maps are commonly used in modern computer graphics applications that enable the representation of three-dimensional surface properties in two-dimensional data sets.","The method we propose is based on the recognition of patterns through these mappings instead of the usual light-based visualization.","The first stage of the application is photogrammetric capture of a few examples of Zeugma mosaics and three-dimensional digital modeling of a set of Seljuk era brick walls based on knowledge obtained through architectural history literature.","The second stage covers the creation of digital models byprocessing the surface representation obtained from this data using Alice Vision, OpenCV-Python, and Autodesk Maya to include information on aspects of the making of the walls.","What is envisioned for the next stages is that the mapping data contributes and supports the knowledge for rule-based design and making processesof cultural heritage."],"url":"http://arxiv.org/abs/2312.13489v1"}
{"created":"2023-12-20 23:45:06","title":"Meta-Learning with Versatile Loss Geometries for Fast Adaptation Using Mirror Descent","abstract":"Utilizing task-invariant prior knowledge extracted from related tasks, meta-learning is a principled framework that empowers learning a new task especially when data records are limited. A fundamental challenge in meta-learning is how to quickly \"adapt\" the extracted prior in order to train a task-specific model within a few optimization steps. Existing approaches deal with this challenge using a preconditioner that enhances convergence of the per-task training process. Though effective in representing locally a quadratic training loss, these simple linear preconditioners can hardly capture complex loss geometries. The present contribution addresses this limitation by learning a nonlinear mirror map, which induces a versatile distance metric to enable capturing and optimizing a wide range of loss geometries, hence facilitating the per-task training. Numerical tests on few-shot learning datasets demonstrate the superior expressiveness and convergence of the advocated approach.","sentences":["Utilizing task-invariant prior knowledge extracted from related tasks, meta-learning is a principled framework that empowers learning a new task especially when data records are limited.","A fundamental challenge in meta-learning is how to quickly \"adapt\" the extracted prior in order to train a task-specific model within a few optimization steps.","Existing approaches deal with this challenge using a preconditioner that enhances convergence of the per-task training process.","Though effective in representing locally a quadratic training loss, these simple linear preconditioners can hardly capture complex loss geometries.","The present contribution addresses this limitation by learning a nonlinear mirror map, which induces a versatile distance metric to enable capturing and optimizing a wide range of loss geometries, hence facilitating the per-task training.","Numerical tests on few-shot learning datasets demonstrate the superior expressiveness and convergence of the advocated approach."],"url":"http://arxiv.org/abs/2312.13486v1"}
{"created":"2023-12-20 22:24:51","title":"Efficient Communication in Federated Learning Using Floating-Point Lossy Compression","abstract":"In the expanding realm of machine learning (ML) within edge computing, the efficient exchange of information in federated learning (FL) environments is paramount. FL's decentralized nature often leads to significant communication bottlenecks, particularly in settings where resources are limited. Traditional data compression techniques, such as quantization and pruning, provide partial solutions but can compromise model performance or necessitate costly retraining. Our paper addresses this issue through \\textit{FedSZ}, a novel lossy compression-based FL framework. \\textit{FedSZ} is designed to minimize the size of local model updates without impacting model performance. Our framework features a compression pipeline integrating data partitioning, lossy and lossless model parameters, metadata compression, and efficient serialization. We conduct a thorough evaluation of \\textit{FedSZ} utilizing a variety of lossy compressors, among which SZ2 emerged as the most effective, consistently performing well across diverse neural network architectures, including AlexNet, MobileNetV2, and ResNet50, and datasets such as CIFAR-10, Caltech101, and FMNIST. A relative error bound of 1E-2 balances compression and data integrity, achieving compression ratios ranging from $5.55\\mbox{--}12.61\\times$. Furthermore, we observed that the runtime overhead introduced by \\textit{FedSZ} is minimal, at less than $4.7\\%$, compared to a significant reduction in network transfer times, which we noted to exceed $13.3\\times$ reduction or saving of over $100$s in edge networks operating at 10Mbps. Our findings firmly establish the efficacy of \\textit{FedSZ}, offering valuable insights for achieving an optimal balance between communication efficiency and model performance in FL settings, particularly in edge computing environments.","sentences":["In the expanding realm of machine learning (ML) within edge computing, the efficient exchange of information in federated learning (FL) environments is paramount.","FL's decentralized nature often leads to significant communication bottlenecks, particularly in settings where resources are limited.","Traditional data compression techniques, such as quantization and pruning, provide partial solutions but can compromise model performance or necessitate costly retraining.","Our paper addresses this issue through \\textit{FedSZ}, a novel lossy compression-based FL framework.","\\textit{FedSZ} is designed to minimize the size of local model updates without impacting model performance.","Our framework features a compression pipeline integrating data partitioning, lossy and lossless model parameters, metadata compression, and efficient serialization.","We conduct a thorough evaluation of \\textit{FedSZ} utilizing a variety of lossy compressors, among which SZ2 emerged as the most effective, consistently performing well across diverse neural network architectures, including AlexNet, MobileNetV2, and ResNet50, and datasets such as CIFAR-10, Caltech101, and FMNIST.","A relative error bound of 1E-2 balances compression and data integrity, achieving compression ratios ranging from $5.55\\mbox{--}12.61\\times$. Furthermore, we observed that the runtime overhead introduced by \\textit{FedSZ} is minimal, at less than $4.7\\%$, compared to a significant reduction in network transfer times, which we noted to exceed $13.3\\times$ reduction or saving of over $100$s in edge networks operating at 10Mbps.","Our findings firmly establish the efficacy of \\textit{FedSZ}, offering valuable insights for achieving an optimal balance between communication efficiency and model performance in FL settings, particularly in edge computing environments."],"url":"http://arxiv.org/abs/2312.13461v1"}
{"created":"2023-12-20 22:13:45","title":"MixEHR-SurG: a joint proportional hazard and guided topic model for inferring mortality-associated topics from electronic health records","abstract":"Objective: To improve survival analysis using EHR data, we aim to develop a supervised topic model called MixEHR-SurG to simultaneously integrate heterogeneous EHR data and model survival hazard.   Materials and Methods: Our technical contributions are three-folds: (1) integrating EHR topic inference with Cox proportional hazards likelihood; (2) inferring patient-specific topic hyperparameters using the PheCode concepts such that each topic can be identified with exactly one PheCode-associated phenotype; (3) multi-modal survival topic inference. This leads to a highly interpretable survival and guided topic model that can infer PheCode-specific phenotype topics associated with patient mortality. We evaluated MixEHR-G using a simulated dataset and two real-world EHR datasets: the Quebec Congenital Heart Disease (CHD) data consisting of 8,211 subjects with 75,187 outpatient claim data of 1,767 unique ICD codes; the MIMIC-III consisting of 1,458 subjects with multi-modal EHR records.   Results: Compared to the baselines, MixEHR-G achieved a superior dynamic AUROC for mortality prediction, with a mean AUROC score of 0.89 in the simulation dataset and a mean AUROC of 0.645 on the CHD dataset. Qualitatively, MixEHR-G associates severe cardiac conditions with high mortality risk among the CHD patients after the first heart failure hospitalization and critical brain injuries with increased mortality among the MIMIC-III patients after their ICU discharge.   Conclusion: The integration of the Cox proportional hazards model and EHR topic inference in MixEHR-SurG led to not only competitive mortality prediction but also meaningful phenotype topics for systematic survival analysis. The software is available at GitHub: https://github.com/li-lab-mcgill/MixEHR-SurG.","sentences":["Objective: To improve survival analysis using EHR data, we aim to develop a supervised topic model called MixEHR-SurG to simultaneously integrate heterogeneous EHR data and model survival hazard.   ","Materials and Methods: Our technical contributions are three-folds: (1) integrating EHR topic inference with Cox proportional hazards likelihood; (2) inferring patient-specific topic hyperparameters using the PheCode concepts such that each topic can be identified with exactly one PheCode-associated phenotype; (3) multi-modal survival topic inference.","This leads to a highly interpretable survival and guided topic model that can infer PheCode-specific phenotype topics associated with patient mortality.","We evaluated MixEHR-G using a simulated dataset and two real-world EHR datasets: the Quebec Congenital Heart Disease (CHD) data consisting of 8,211 subjects with 75,187 outpatient claim data of 1,767 unique ICD codes; the MIMIC-III consisting of 1,458 subjects with multi-modal EHR records.   ","Results: Compared to the baselines, MixEHR-G achieved a superior dynamic AUROC for mortality prediction, with a mean AUROC score of 0.89 in the simulation dataset and a mean AUROC of 0.645 on the CHD dataset.","Qualitatively, MixEHR-G associates severe cardiac conditions with high mortality risk among the CHD patients after the first heart failure hospitalization and critical brain injuries with increased mortality among the MIMIC-III patients after their ICU discharge.   ","Conclusion: The integration of the Cox proportional hazards model and EHR topic inference in MixEHR-SurG led to not only competitive mortality prediction but also meaningful phenotype topics for systematic survival analysis.","The software is available at GitHub: https://github.com/li-lab-mcgill/MixEHR-SurG."],"url":"http://arxiv.org/abs/2312.13454v1"}
{"created":"2023-12-20 21:58:45","title":"Building Lane-Level Maps from Aerial Images","abstract":"Detecting lane lines from sensors is becoming an increasingly significant part of autonomous driving systems. However, less development has been made on high-definition lane-level mapping based on aerial images, which could automatically build and update offline maps for auto-driving systems. To this end, our work focuses on extracting fine-level detailed lane lines together with their topological structures. This task is challenging since it requires large amounts of data covering different lane types, terrain and regions. In this paper, we introduce for the first time a large-scale aerial image dataset built for lane detection, with high-quality polyline lane annotations on high-resolution images of around 80 kilometers of road. Moreover, we developed a baseline deep learning lane detection method from aerial images, called AerialLaneNet, consisting of two stages. The first stage is to produce coarse-grained results at point level, and the second stage exploits the coarse-grained results and feature to perform the vertex-matching task, producing fine-grained lanes with topology. The experiments show our approach achieves significant improvement compared with the state-of-the-art methods on our new dataset. Our code and new dataset are available at https://github.com/Jiawei-Yao0812/AerialLaneNet.","sentences":["Detecting lane lines from sensors is becoming an increasingly significant part of autonomous driving systems.","However, less development has been made on high-definition lane-level mapping based on aerial images, which could automatically build and update offline maps for auto-driving systems.","To this end, our work focuses on extracting fine-level detailed lane lines together with their topological structures.","This task is challenging since it requires large amounts of data covering different lane types, terrain and regions.","In this paper, we introduce for the first time a large-scale aerial image dataset built for lane detection, with high-quality polyline lane annotations on high-resolution images of around 80 kilometers of road.","Moreover, we developed a baseline deep learning lane detection method from aerial images, called AerialLaneNet, consisting of two stages.","The first stage is to produce coarse-grained results at point level, and the second stage exploits the coarse-grained results and feature to perform the vertex-matching task, producing fine-grained lanes with topology.","The experiments show our approach achieves significant improvement compared with the state-of-the-art methods on our new dataset.","Our code and new dataset are available at https://github.com/Jiawei-Yao0812/AerialLaneNet."],"url":"http://arxiv.org/abs/2312.13449v1"}
{"created":"2023-12-20 21:30:55","title":"MGAug: Multimodal Geometric Augmentation in Latent Spaces of Image Deformations","abstract":"Geometric transformations have been widely used to augment the size of training images. Existing methods often assume a unimodal distribution of the underlying transformations between images, which limits their power when data with multimodal distributions occur. In this paper, we propose a novel model, Multimodal Geometric Augmentation (MGAug), that for the first time generates augmenting transformations in a multimodal latent space of geometric deformations. To achieve this, we first develop a deep network that embeds the learning of latent geometric spaces of diffeomorphic transformations (a.k.a. diffeomorphisms) in a variational autoencoder (VAE). A mixture of multivariate Gaussians is formulated in the tangent space of diffeomorphisms and serves as a prior to approximate the hidden distribution of image transformations. We then augment the original training dataset by deforming images using randomly sampled transformations from the learned multimodal latent space of VAE. To validate the efficiency of our model, we jointly learn the augmentation strategy with two distinct domain-specific tasks: multi-class classification on 2D synthetic datasets and segmentation on real 3D brain magnetic resonance images (MRIs). We also compare MGAug with state-of-the-art transformation-based image augmentation algorithms. Experimental results show that our proposed approach outperforms all baselines by significantly improved prediction accuracy. Our code is publicly available at https://github.com/tonmoy-hossain/MGAug.","sentences":["Geometric transformations have been widely used to augment the size of training images.","Existing methods often assume a unimodal distribution of the underlying transformations between images, which limits their power when data with multimodal distributions occur.","In this paper, we propose a novel model, Multimodal Geometric Augmentation (MGAug), that for the first time generates augmenting transformations in a multimodal latent space of geometric deformations.","To achieve this, we first develop a deep network that embeds the learning of latent geometric spaces of diffeomorphic transformations (a.k.a. diffeomorphisms) in a variational autoencoder (VAE).","A mixture of multivariate Gaussians is formulated in the tangent space of diffeomorphisms and serves as a prior to approximate the hidden distribution of image transformations.","We then augment the original training dataset by deforming images using randomly sampled transformations from the learned multimodal latent space of VAE.","To validate the efficiency of our model, we jointly learn the augmentation strategy with two distinct domain-specific tasks: multi-class classification on 2D synthetic datasets and segmentation on real 3D brain magnetic resonance images (MRIs).","We also compare MGAug with state-of-the-art transformation-based image augmentation algorithms.","Experimental results show that our proposed approach outperforms all baselines by significantly improved prediction accuracy.","Our code is publicly available at https://github.com/tonmoy-hossain/MGAug."],"url":"http://arxiv.org/abs/2312.13440v1"}
{"created":"2023-12-20 21:28:35","title":"A General Model for Aggregating Annotations Across Simple, Complex, and Multi-Object Annotation Tasks","abstract":"Human annotations are vital to supervised learning, yet annotators often disagree on the correct label, especially as annotation tasks increase in complexity. A strategy to improve label quality is to ask multiple annotators to label the same item and aggregate their labels. Many aggregation models have been proposed for categorical or numerical annotation tasks, but far less work has considered more complex annotation tasks involving open-ended, multivariate, or structured responses. While a variety of bespoke models have been proposed for specific tasks, our work is the first to introduce aggregation methods that generalize across many diverse complex tasks, including sequence labeling, translation, syntactic parsing, ranking, bounding boxes, and keypoints. This generality is achieved by devising a task-agnostic method to model distances between labels rather than the labels themselves.   This article extends our prior work with investigation of three new research questions. First, how do complex annotation properties impact aggregation accuracy? Second, how should a task owner navigate the many modeling choices to maximize aggregation accuracy? Finally, what diagnoses can verify that aggregation models are specified correctly for the given data? To understand how various factors impact accuracy and to inform model selection, we conduct simulation studies and experiments on real, complex datasets. Regarding testing, we introduce unit tests for aggregation models and present a suite of such tests to ensure that a given model is not mis-specified and exhibits expected behavior.   Beyond investigating these research questions above, we discuss the foundational concept of annotation complexity, present a new aggregation model as a bridge between traditional models and our own, and contribute a new semi-supervised learning method for complex label aggregation that outperforms prior work.","sentences":["Human annotations are vital to supervised learning, yet annotators often disagree on the correct label, especially as annotation tasks increase in complexity.","A strategy to improve label quality is to ask multiple annotators to label the same item and aggregate their labels.","Many aggregation models have been proposed for categorical or numerical annotation tasks, but far less work has considered more complex annotation tasks involving open-ended, multivariate, or structured responses.","While a variety of bespoke models have been proposed for specific tasks, our work is the first to introduce aggregation methods that generalize across many diverse complex tasks, including sequence labeling, translation, syntactic parsing, ranking, bounding boxes, and keypoints.","This generality is achieved by devising a task-agnostic method to model distances between labels rather than the labels themselves.   ","This article extends our prior work with investigation of three new research questions.","First, how do complex annotation properties impact aggregation accuracy?","Second, how should a task owner navigate the many modeling choices to maximize aggregation accuracy?","Finally, what diagnoses can verify that aggregation models are specified correctly for the given data?","To understand how various factors impact accuracy and to inform model selection, we conduct simulation studies and experiments on real, complex datasets.","Regarding testing, we introduce unit tests for aggregation models and present a suite of such tests to ensure that a given model is not mis-specified and exhibits expected behavior.   ","Beyond investigating these research questions above, we discuss the foundational concept of annotation complexity, present a new aggregation model as a bridge between traditional models and our own, and contribute a new semi-supervised learning method for complex label aggregation that outperforms prior work."],"url":"http://arxiv.org/abs/2312.13437v1"}
{"created":"2023-12-20 21:20:23","title":"Zero-1-to-3: Domain-level Zero-shot Cognitive Diagnosis via One Batch of Early-bird Students towards Three Diagnostic Objectives","abstract":"Cognitive diagnosis seeks to estimate the cognitive states of students by exploring their logged practice quiz data. It plays a pivotal role in personalized learning guidance within intelligent education systems. In this paper, we focus on an important, practical, yet often underexplored task: domain-level zero-shot cognitive diagnosis (DZCD), which arises due to the absence of student practice logs in newly launched domains. Recent cross-domain diagnostic models have been demonstrated to be a promising strategy for DZCD. These methods primarily focus on how to transfer student states across domains. However, they might inadvertently incorporate non-transferable information into student representations, thereby limiting the efficacy of knowledge transfer. To tackle this, we propose Zero-1-to-3, a domain-level zero-shot cognitive diagnosis framework via one batch of early-bird students towards three diagnostic objectives. Our approach initiates with pre-training a diagnosis model with dual regularizers, which decouples student states into domain-shared and domain-specific parts. The shared cognitive signals can be transferred to the target domain, enriching the cognitive priors for the new domain, which ensures the cognitive state propagation objective. Subsequently, we devise a strategy to generate simulated practice logs for cold-start students through analyzing the behavioral patterns from early-bird students, fulfilling the domain-adaption goal. Consequently, we refine the cognitive states of cold-start students as diagnostic outcomes via virtual data, aligning with the diagnosis-oriented goal. Finally, extensive experiments on six real-world datasets highlight the efficacy of our model for DZCD and its practical application in question recommendation.","sentences":["Cognitive diagnosis seeks to estimate the cognitive states of students by exploring their logged practice quiz data.","It plays a pivotal role in personalized learning guidance within intelligent education systems.","In this paper, we focus on an important, practical, yet often underexplored task: domain-level zero-shot cognitive diagnosis (DZCD), which arises due to the absence of student practice logs in newly launched domains.","Recent cross-domain diagnostic models have been demonstrated to be a promising strategy for DZCD.","These methods primarily focus on how to transfer student states across domains.","However, they might inadvertently incorporate non-transferable information into student representations, thereby limiting the efficacy of knowledge transfer.","To tackle this, we propose Zero-1-to-3, a domain-level zero-shot cognitive diagnosis framework via one batch of early-bird students towards three diagnostic objectives.","Our approach initiates with pre-training a diagnosis model with dual regularizers, which decouples student states into domain-shared and domain-specific parts.","The shared cognitive signals can be transferred to the target domain, enriching the cognitive priors for the new domain, which ensures the cognitive state propagation objective.","Subsequently, we devise a strategy to generate simulated practice logs for cold-start students through analyzing the behavioral patterns from early-bird students, fulfilling the domain-adaption goal.","Consequently, we refine the cognitive states of cold-start students as diagnostic outcomes via virtual data, aligning with the diagnosis-oriented goal.","Finally, extensive experiments on six real-world datasets highlight the efficacy of our model for DZCD and its practical application in question recommendation."],"url":"http://arxiv.org/abs/2312.13434v1"}
{"created":"2023-12-20 21:18:16","title":"Towards Distributed Semi-speculative Adaptive Anisotropic Parallel Mesh Generation","abstract":"This paper presents the foundational elements of a distributed memory method for mesh generation that is designed to leverage concurrency offered by large-scale computing. To achieve this goal, meshing functionality is separated from performance aspects by utilizing a separate entity for each - a shared memory mesh generation code called CDT3D and PREMA for parallel runtime support. Although CDT3D is designed for scalability, lessons are presented regarding additional measures that were taken to enable the code's integration into the distributed memory method as a black box. In the presented method, an initial mesh is data decomposed and subdomains are distributed amongst the nodes of a high-performance computing (HPC) cluster. Meshing operations within CDT3D utilize a speculative execution model, enabling the strict adaptation of subdomains' interior elements. Interface elements undergo several iterations of shifting so that they are adapted when their data dependencies are resolved. PREMA aids in this endeavor by providing asynchronous message passing between encapsulations of data, work load balancing, and migration capabilities all within a globally addressable namespace. PREMA also assists in establishing data dependencies between subdomains, thus enabling \"neighborhoods\" of subdomains to work independently of each other in performing interface shifts and adaptation. Preliminary results show that the presented method is able to produce meshes of comparable quality to those generated by the original shared memory CDT3D code. Given the costly overhead of collective communication seen by existing state-of-the-art software, relative communication performance of the presented distributed memory method also shows that its emphasis on avoiding global synchronization presents a potentially viable solution in achieving scalability when targeting large configurations of cores.","sentences":["This paper presents the foundational elements of a distributed memory method for mesh generation that is designed to leverage concurrency offered by large-scale computing.","To achieve this goal, meshing functionality is separated from performance aspects by utilizing a separate entity for each - a shared memory mesh generation code called CDT3D and PREMA for parallel runtime support.","Although CDT3D is designed for scalability, lessons are presented regarding additional measures that were taken to enable the code's integration into the distributed memory method as a black box.","In the presented method, an initial mesh is data decomposed and subdomains are distributed amongst the nodes of a high-performance computing (HPC) cluster.","Meshing operations within CDT3D utilize a speculative execution model, enabling the strict adaptation of subdomains' interior elements.","Interface elements undergo several iterations of shifting so that they are adapted when their data dependencies are resolved.","PREMA aids in this endeavor by providing asynchronous message passing between encapsulations of data, work load balancing, and migration capabilities all within a globally addressable namespace.","PREMA also assists in establishing data dependencies between subdomains, thus enabling \"neighborhoods\" of subdomains to work independently of each other in performing interface shifts and adaptation.","Preliminary results show that the presented method is able to produce meshes of comparable quality to those generated by the original shared memory CDT3D code.","Given the costly overhead of collective communication seen by existing state-of-the-art software, relative communication performance of the presented distributed memory method also shows that its emphasis on avoiding global synchronization presents a potentially viable solution in achieving scalability when targeting large configurations of cores."],"url":"http://arxiv.org/abs/2312.13433v1"}
{"created":"2023-12-20 21:14:28","title":"BRYT: Data Rich Analytics Based Computer Architecture for A New Paradigm of Chip Design to Supplant Moore's Law","abstract":"This paper introduces a new paradigm of chip design for the semi-conductor industry called Data-Rich Analytics Based Computer Architecture (BRYT). The goal is to enable monitoring chip hardware behavior in the field, at real-time speeds with no slowdowns, with minimal power overheads and obtain insights on chip behavior and workloads. The paradigm is motivated by the end of Moore's Law and Dennard Scaling which necessitates architectural efficiency as the means for improved capability for the next decade or two. This paper implements the first version of the paradigm with a system architecture and the concept of an analYtics Processing Unit (YPU). We perform 4 case studies, and implement an RTL level prototype. Across the case studies we show a YPU with area overhead <3% at 7nm, and overall power consumption of <25 mW is able to create previously inconceivable data PICS stacks of arbitrary programs, evaluating instruction prefetchers in the wild before deployment, fine-grained cycle-by-cycle utilization of hardware modules, and histograms of tensor-value distributions of DL models.","sentences":["This paper introduces a new paradigm of chip design for the semi-conductor industry called Data-Rich Analytics Based Computer Architecture (BRYT).","The goal is to enable monitoring chip hardware behavior in the field, at real-time speeds with no slowdowns, with minimal power overheads and obtain insights on chip behavior and workloads.","The paradigm is motivated by the end of Moore's Law and Dennard Scaling which necessitates architectural efficiency as the means for improved capability for the next decade or two.","This paper implements the first version of the paradigm with a system architecture and the concept of an analYtics Processing Unit (YPU).","We perform 4 case studies, and implement an RTL level prototype.","Across the case studies we show a YPU with area overhead <3% at 7nm, and overall power consumption of <25 mW is able to create previously inconceivable data PICS stacks of arbitrary programs, evaluating instruction prefetchers in the wild before deployment, fine-grained cycle-by-cycle utilization of hardware modules, and histograms of tensor-value distributions of DL models."],"url":"http://arxiv.org/abs/2312.13428v1"}
{"created":"2023-12-20 21:13:46","title":"R2D2: Reducing Redundancy and Duplication in Data Lakes","abstract":"Enterprise data lakes often suffer from substantial amounts of duplicate and redundant data, with data volumes ranging from terabytes to petabytes. This leads to both increased storage costs and unnecessarily high maintenance costs for these datasets. In this work, we focus on identifying and reducing redundancy in enterprise data lakes by addressing the problem of 'dataset containment'. To the best of our knowledge, this is one of the first works that addresses table-level containment at a large scale.   We propose R2D2: a three-step hierarchical pipeline that efficiently identifies almost all instances of containment by progressively reducing the search space in the data lake. It first builds (i) a schema containment graph, followed by (ii) statistical min-max pruning, and finally, (iii) content level pruning. We further propose minimizing the total storage and access costs by optimally identifying redundant datasets that can be deleted (and reconstructed on demand) while respecting latency constraints.   We implement our system on Azure Databricks clusters using Apache Spark for enterprise data stored in ADLS Gen2, and on AWS clusters for open-source data. In contrast to existing modified baselines that are inaccurate or take several days to run, our pipeline can process an enterprise customer data lake at the TB scale in approximately 5 hours with high accuracy. We present theoretical results as well as extensive empirical validation on both enterprise (scale of TBs) and open-source datasets (scale of MBs - GBs), which showcase the effectiveness of our pipeline.","sentences":["Enterprise data lakes often suffer from substantial amounts of duplicate and redundant data, with data volumes ranging from terabytes to petabytes.","This leads to both increased storage costs and unnecessarily high maintenance costs for these datasets.","In this work, we focus on identifying and reducing redundancy in enterprise data lakes by addressing the problem of 'dataset containment'.","To the best of our knowledge, this is one of the first works that addresses table-level containment at a large scale.   ","We propose R2D2: a three-step hierarchical pipeline that efficiently identifies almost all instances of containment by progressively reducing the search space in the data lake.","It first builds (i) a schema containment graph, followed by (ii) statistical min-max pruning, and finally, (iii) content level pruning.","We further propose minimizing the total storage and access costs by optimally identifying redundant datasets that can be deleted (and reconstructed on demand) while respecting latency constraints.   ","We implement our system on Azure Databricks clusters using Apache Spark for enterprise data stored in ADLS Gen2, and on AWS clusters for open-source data.","In contrast to existing modified baselines that are inaccurate or take several days to run, our pipeline can process an enterprise customer data lake at the TB scale in approximately 5 hours with high accuracy.","We present theoretical results as well as extensive empirical validation on both enterprise (scale of TBs) and open-source datasets (scale of MBs - GBs), which showcase the effectiveness of our pipeline."],"url":"http://arxiv.org/abs/2312.13427v1"}
{"created":"2023-12-20 21:02:09","title":"VADIS -- a VAriable Detection, Interlinking and Summarization system","abstract":"The VADIS system addresses the demand of providing enhanced information access in the domain of the social sciences. This is achieved by allowing users to search and use survey variables in context of their underlying research data and scholarly publications which have been interlinked with each other.","sentences":["The VADIS system addresses the demand of providing enhanced information access in the domain of the social sciences.","This is achieved by allowing users to search and use survey variables in context of their underlying research data and scholarly publications which have been interlinked with each other."],"url":"http://arxiv.org/abs/2312.13423v1"}
{"created":"2023-12-20 20:06:36","title":"Packed-Ensemble Surrogate Models for Fluid Flow Estimation Arround Airfoil Geometries","abstract":"Physical based simulations can be very time and computationally demanding tasks. One way of accelerating these processes is by making use of data-driven surrogate models that learn from existing simulations. Ensembling methods are particularly relevant in this domain as their smoothness properties coincide with the smoothness of physical phenomena. The drawback is that they can remain costly. This research project focused on studying Packed-Ensembles that generalize Deep Ensembles but remain faster to train. Several models have been trained and compared in terms of multiple important metrics. PE(8,4,1) has been identified as the clear winner in this particular task, beating down its Deep Ensemble conterpart while accelerating the training time by 25%.","sentences":["Physical based simulations can be very time and computationally demanding tasks.","One way of accelerating these processes is by making use of data-driven surrogate models that learn from existing simulations.","Ensembling methods are particularly relevant in this domain as their smoothness properties coincide with the smoothness of physical phenomena.","The drawback is that they can remain costly.","This research project focused on studying Packed-Ensembles that generalize Deep Ensembles but remain faster to train.","Several models have been trained and compared in terms of multiple important metrics.","PE(8,4,1) has been identified as the clear winner in this particular task, beating down its Deep Ensemble conterpart while accelerating the training time by 25%."],"url":"http://arxiv.org/abs/2312.13403v1"}
{"created":"2023-12-20 20:04:45","title":"Time is Encoded in the Weights of Finetuned Language Models","abstract":"We present time vectors, a simple tool to customize language models to new time periods. Time vectors are created by finetuning a language model on data from a single time (e.g., a year or month), and then subtracting the weights of the original pretrained model. This vector specifies a direction in weight space that, as our experiments show, improves performance on text from that time period. Time vectors specialized to adjacent time periods appear to be positioned closer together in a manifold. Using this structure, we interpolate between time vectors to induce new models that perform better on intervening and future time periods, without any additional training. We demonstrate the consistency of our findings across different tasks, domains, model sizes, and time scales. Our results suggest that time is encoded in the weight space of finetuned models.","sentences":["We present time vectors, a simple tool to customize language models to new time periods.","Time vectors are created by finetuning a language model on data from a single time (e.g., a year or month), and then subtracting the weights of the original pretrained model.","This vector specifies a direction in weight space that, as our experiments show, improves performance on text from that time period.","Time vectors specialized to adjacent time periods appear to be positioned closer together in a manifold.","Using this structure, we interpolate between time vectors to induce new models that perform better on intervening and future time periods, without any additional training.","We demonstrate the consistency of our findings across different tasks, domains, model sizes, and time scales.","Our results suggest that time is encoded in the weight space of finetuned models."],"url":"http://arxiv.org/abs/2312.13401v1"}
{"created":"2023-12-20 19:59:47","title":"Design Systems for Closing Gaps with Rheotomic Surfaces and Allometry","abstract":"This study aims to present a material based, second order design method that makes the rapid creation of bridging structures in order to connect two or more horizontal planes which are currently separated and three design instances created via such method. The first element of the presented method is a generative system that creates circulation surfaces through the interpolation of the curves defined on the current surfaces, and also creates the structural volumes via rheotomic (minimal) surfaces. The second constituent is the instantiation of the exposed variable, connected to a displacement algorithm inspired by allometry based on user input, contextual data, or simulation results. The method was created with applicability through additive manufacturing in consideration. The design process - similar to manufacturing - proceeds in a vertical manner, in order to reduce the generation of support geometry as much as possible. The system includes a raster data input viable for simulation results, feeding the accumulation variable in order to modify material amount or quality with the aim of improving structural performance where stress is greater. Through the application of the method, three physical models which connect different horizontal planes were obtained. The models can be evaluated with digital of physical simulations, and results can be utilized in an iterative manner, improving the results by each recursion.","sentences":["This study aims to present a material based, second order design method that makes the rapid creation of bridging structures in order to connect two or more horizontal planes which are currently separated and three design instances created via such method.","The first element of the presented method is a generative system that creates circulation surfaces through the interpolation of the curves defined on the current surfaces, and also creates the structural volumes via rheotomic (minimal) surfaces.","The second constituent is the instantiation of the exposed variable, connected to a displacement algorithm inspired by allometry based on user input, contextual data, or simulation results.","The method was created with applicability through additive manufacturing in consideration.","The design process - similar to manufacturing - proceeds in a vertical manner, in order to reduce the generation of support geometry as much as possible.","The system includes a raster data input viable for simulation results, feeding the accumulation variable in order to modify material amount or quality with the aim of improving structural performance where stress is greater.","Through the application of the method, three physical models which connect different horizontal planes were obtained.","The models can be evaluated with digital of physical simulations, and results can be utilized in an iterative manner, improving the results by each recursion."],"url":"http://arxiv.org/abs/2312.13398v1"}
{"created":"2023-12-20 19:55:31","title":"Generating Forms via Informed Motion, a Flight Inspired Method Based on Wind and Topography Data","abstract":"Generative systems are becoming a crucial part of current design practice. There exist gaps however, between the digital processes, field data and designer's input. To solve this problem, multiple processes were developed in order to generate emergent and self-organizing design solutions that combine the designer's input with surface models acquired via photogrammetry and generative design tools. Different generative design methods were utilized for trials, including surface scattering based on UV coordinates, animation snapshots (similar to long exposure photography) and a particle swarm algorithm on arbitrary data, interpolated within GIS software. A large volume of adaptive forms that are complex, yet responsive to changes in parameters, user input, topography and/or various spatial data were acquired. Resulting outputs were rendered and projection mapped onto the original physical model and evaluated for further iterations.","sentences":["Generative systems are becoming a crucial part of current design practice.","There exist gaps however, between the digital processes, field data and designer's input.","To solve this problem, multiple processes were developed in order to generate emergent and self-organizing design solutions that combine the designer's input with surface models acquired via photogrammetry and generative design tools.","Different generative design methods were utilized for trials, including surface scattering based on UV coordinates, animation snapshots (similar to long exposure photography) and a particle swarm algorithm on arbitrary data, interpolated within GIS software.","A large volume of adaptive forms that are complex, yet responsive to changes in parameters, user input, topography and/or various spatial data were acquired.","Resulting outputs were rendered and projection mapped onto the original physical model and evaluated for further iterations."],"url":"http://arxiv.org/abs/2312.13394v1"}
{"created":"2023-12-20 19:20:26","title":"ORBSLAM3-Enhanced Autonomous Toy Drones: Pioneering Indoor Exploration","abstract":"Navigating toy drones through uncharted GPS-denied indoor spaces poses significant difficulties due to their reliance on GPS for location determination. In such circumstances, the necessity for achieving proper navigation is a primary concern. In response to this formidable challenge, we introduce a real-time autonomous indoor exploration system tailored for drones equipped with a monocular \\emph{RGB} camera.   Our system utilizes \\emph{ORB-SLAM3}, a state-of-the-art vision feature-based SLAM, to handle both the localization of toy drones and the mapping of unmapped indoor terrains. Aside from the practicability of \\emph{ORB-SLAM3}, the generated maps are represented as sparse point clouds, making them prone to the presence of outlier data. To address this challenge, we propose an outlier removal algorithm with provable guarantees. Furthermore, our system incorporates a novel exit detection algorithm, ensuring continuous exploration by the toy drone throughout the unfamiliar indoor environment. We also transform the sparse point to ensure proper path planning using existing path planners.   To validate the efficacy and efficiency of our proposed system, we conducted offline and real-time experiments on the autonomous exploration of indoor spaces. The results from these endeavors demonstrate the effectiveness of our methods.","sentences":["Navigating toy drones through uncharted GPS-denied indoor spaces poses significant difficulties due to their reliance on GPS for location determination.","In such circumstances, the necessity for achieving proper navigation is a primary concern.","In response to this formidable challenge, we introduce a real-time autonomous indoor exploration system tailored for drones equipped with a monocular \\emph{RGB} camera.   ","Our system utilizes \\emph{ORB-SLAM3}, a state-of-the-art vision feature-based SLAM, to handle both the localization of toy drones and the mapping of unmapped indoor terrains.","Aside from the practicability of \\emph{ORB-SLAM3}, the generated maps are represented as sparse point clouds, making them prone to the presence of outlier data.","To address this challenge, we propose an outlier removal algorithm with provable guarantees.","Furthermore, our system incorporates a novel exit detection algorithm, ensuring continuous exploration by the toy drone throughout the unfamiliar indoor environment.","We also transform the sparse point to ensure proper path planning using existing path planners.   ","To validate the efficacy and efficiency of our proposed system, we conducted offline and real-time experiments on the autonomous exploration of indoor spaces.","The results from these endeavors demonstrate the effectiveness of our methods."],"url":"http://arxiv.org/abs/2312.13385v1"}
{"created":"2023-12-20 19:11:19","title":"Fed-QSSL: A Framework for Personalized Federated Learning under Bitwidth and Data Heterogeneity","abstract":"Motivated by high resource costs of centralized machine learning schemes as well as data privacy concerns, federated learning (FL) emerged as an efficient alternative that relies on aggregating locally trained models rather than collecting clients' potentially private data. In practice, available resources and data distributions vary from one client to another, creating an inherent system heterogeneity that leads to deterioration of the performance of conventional FL algorithms. In this work, we present a federated quantization-based self-supervised learning scheme (Fed-QSSL) designed to address heterogeneity in FL systems. At clients' side, to tackle data heterogeneity we leverage distributed self-supervised learning while utilizing low-bit quantization to satisfy constraints imposed by local infrastructure and limited communication resources. At server's side, Fed-QSSL deploys de-quantization, weighted aggregation and re-quantization, ultimately creating models personalized to both data distribution as well as specific infrastructure of each client's device. We validated the proposed algorithm on real world datasets, demonstrating its efficacy, and theoretically analyzed impact of low-bit training on the convergence and robustness of the learned models.","sentences":["Motivated by high resource costs of centralized machine learning schemes as well as data privacy concerns, federated learning (FL) emerged as an efficient alternative that relies on aggregating locally trained models rather than collecting clients' potentially private data.","In practice, available resources and data distributions vary from one client to another, creating an inherent system heterogeneity that leads to deterioration of the performance of conventional FL algorithms.","In this work, we present a federated quantization-based self-supervised learning scheme (Fed-QSSL) designed to address heterogeneity in FL systems.","At clients' side, to tackle data heterogeneity we leverage distributed self-supervised learning while utilizing low-bit quantization to satisfy constraints imposed by local infrastructure and limited communication resources.","At server's side, Fed-QSSL deploys de-quantization, weighted aggregation and re-quantization, ultimately creating models personalized to both data distribution as well as specific infrastructure of each client's device.","We validated the proposed algorithm on real world datasets, demonstrating its efficacy, and theoretically analyzed impact of low-bit training on the convergence and robustness of the learned models."],"url":"http://arxiv.org/abs/2312.13380v1"}
{"created":"2023-12-20 18:26:59","title":"Transparency and Privacy: The Role of Explainable AI and Federated Learning in Financial Fraud Detection","abstract":"Fraudulent transactions and how to detect them remain a significant problem for financial institutions around the world. The need for advanced fraud detection systems to safeguard assets and maintain customer trust is paramount for financial institutions, but some factors make the development of effective and efficient fraud detection systems a challenge. One of such factors is the fact that fraudulent transactions are rare and that many transaction datasets are imbalanced; that is, there are fewer significant samples of fraudulent transactions than legitimate ones. This data imbalance can affect the performance or reliability of the fraud detection model. Moreover, due to the data privacy laws that all financial institutions are subject to follow, sharing customer data to facilitate a higher-performing centralized model is impossible. Furthermore, the fraud detection technique should be transparent so that it does not affect the user experience. Hence, this research introduces a novel approach using Federated Learning (FL) and Explainable AI (XAI) to address these challenges. FL enables financial institutions to collaboratively train a model to detect fraudulent transactions without directly sharing customer data, thereby preserving data privacy and confidentiality. Meanwhile, the integration of XAI ensures that the predictions made by the model can be understood and interpreted by human experts, adding a layer of transparency and trust to the system. Experimental results, based on realistic transaction datasets, reveal that the FL-based fraud detection system consistently demonstrates high performance metrics. This study grounds FL's potential as an effective and privacy-preserving tool in the fight against fraud.","sentences":["Fraudulent transactions and how to detect them remain a significant problem for financial institutions around the world.","The need for advanced fraud detection systems to safeguard assets and maintain customer trust is paramount for financial institutions, but some factors make the development of effective and efficient fraud detection systems a challenge.","One of such factors is the fact that fraudulent transactions are rare and that many transaction datasets are imbalanced; that is, there are fewer significant samples of fraudulent transactions than legitimate ones.","This data imbalance can affect the performance or reliability of the fraud detection model.","Moreover, due to the data privacy laws that all financial institutions are subject to follow, sharing customer data to facilitate a higher-performing centralized model is impossible.","Furthermore, the fraud detection technique should be transparent so that it does not affect the user experience.","Hence, this research introduces a novel approach using Federated Learning (FL) and Explainable AI (XAI) to address these challenges.","FL enables financial institutions to collaboratively train a model to detect fraudulent transactions without directly sharing customer data, thereby preserving data privacy and confidentiality.","Meanwhile, the integration of XAI ensures that the predictions made by the model can be understood and interpreted by human experts, adding a layer of transparency and trust to the system.","Experimental results, based on realistic transaction datasets, reveal that the FL-based fraud detection system consistently demonstrates high performance metrics.","This study grounds FL's potential as an effective and privacy-preserving tool in the fight against fraud."],"url":"http://arxiv.org/abs/2312.13334v1"}
