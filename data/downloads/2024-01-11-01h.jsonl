{"created":"2024-01-08 18:59:31","title":"Dr$^2$Net: Dynamic Reversible Dual-Residual Networks for Memory-Efficient Finetuning","abstract":"Large pretrained models are increasingly crucial in modern computer vision tasks. These models are typically used in downstream tasks by end-to-end finetuning, which is highly memory-intensive for tasks with high-resolution data, e.g., video understanding, small object detection, and point cloud analysis. In this paper, we propose Dynamic Reversible Dual-Residual Networks, or Dr$^2$Net, a novel family of network architectures that acts as a surrogate network to finetune a pretrained model with substantially reduced memory consumption. Dr$^2$Net contains two types of residual connections, one maintaining the residual structure in the pretrained models, and the other making the network reversible. Due to its reversibility, intermediate activations, which can be reconstructed from output, are cleared from memory during training. We use two coefficients on either type of residual connections respectively, and introduce a dynamic training strategy that seamlessly transitions the pretrained model to a reversible network with much higher numerical precision. We evaluate Dr$^2$Net on various pretrained models and various tasks, and show that it can reach comparable performance to conventional finetuning but with significantly less memory usage.","sentences":["Large pretrained models are increasingly crucial in modern computer vision tasks.","These models are typically used in downstream tasks by end-to-end finetuning, which is highly memory-intensive for tasks with high-resolution data, e.g., video understanding, small object detection, and point cloud analysis.","In this paper, we propose Dynamic Reversible Dual-Residual Networks, or Dr$^2$Net, a novel family of network architectures that acts as a surrogate network to finetune a pretrained model with substantially reduced memory consumption.","Dr$^2$Net contains two types of residual connections, one maintaining the residual structure in the pretrained models, and the other making the network reversible.","Due to its reversibility, intermediate activations, which can be reconstructed from output, are cleared from memory during training.","We use two coefficients on either type of residual connections respectively, and introduce a dynamic training strategy that seamlessly transitions the pretrained model to a reversible network with much higher numerical precision.","We evaluate Dr$^2$Net on various pretrained models and various tasks, and show that it can reach comparable performance to conventional finetuning but with significantly less memory usage."],"url":"http://arxiv.org/abs/2401.04105v1"}
{"created":"2024-01-08 18:56:33","title":"AGG: Amortized Generative 3D Gaussians for Single Image to 3D","abstract":"Given the growing need for automatic 3D content creation pipelines, various 3D representations have been studied to generate 3D objects from a single image. Due to its superior rendering efficiency, 3D Gaussian splatting-based models have recently excelled in both 3D reconstruction and generation. 3D Gaussian splatting approaches for image to 3D generation are often optimization-based, requiring many computationally expensive score-distillation steps. To overcome these challenges, we introduce an Amortized Generative 3D Gaussian framework (AGG) that instantly produces 3D Gaussians from a single image, eliminating the need for per-instance optimization. Utilizing an intermediate hybrid representation, AGG decomposes the generation of 3D Gaussian locations and other appearance attributes for joint optimization. Moreover, we propose a cascaded pipeline that first generates a coarse representation of the 3D data and later upsamples it with a 3D Gaussian super-resolution module. Our method is evaluated against existing optimization-based 3D Gaussian frameworks and sampling-based pipelines utilizing other 3D representations, where AGG showcases competitive generation abilities both qualitatively and quantitatively while being several orders of magnitude faster. Project page: https://ir1d.github.io/AGG/","sentences":["Given the growing need for automatic 3D content creation pipelines, various 3D representations have been studied to generate 3D objects from a single image.","Due to its superior rendering efficiency, 3D Gaussian splatting-based models have recently excelled in both 3D reconstruction and generation.","3D Gaussian splatting approaches for image to 3D generation are often optimization-based, requiring many computationally expensive score-distillation steps.","To overcome these challenges, we introduce an Amortized Generative 3D Gaussian framework (AGG) that instantly produces 3D Gaussians from a single image, eliminating the need for per-instance optimization.","Utilizing an intermediate hybrid representation, AGG decomposes the generation of 3D Gaussian locations and other appearance attributes for joint optimization.","Moreover, we propose a cascaded pipeline that first generates a coarse representation of the 3D data and later upsamples it with a 3D Gaussian super-resolution module.","Our method is evaluated against existing optimization-based 3D Gaussian frameworks and sampling-based pipelines utilizing other 3D representations, where AGG showcases competitive generation abilities both qualitatively and quantitatively while being several orders of magnitude faster.","Project page: https://ir1d.github.io/AGG/"],"url":"http://arxiv.org/abs/2401.04099v1"}
{"created":"2024-01-08 18:27:57","title":"Security and Privacy Issues in Cloud Storage","abstract":"Even with the vast potential that cloud computing has, so far, it has not been adopted by the consumers with the enthusiasm and pace that it be worthy; this is a very reason statement why consumers still hesitated of using cloud computing for their sensitive data and the threats that prevent the consumers from shifting to use cloud computing in general and cloud storage in particular. The cloud computing inherits the traditional potential security and privacy threats besides its own issues due to its unique structures. Some threats related to cloud computing are the insider malicious attacks from the employees that even sometime the provider unconscious about, the lack of transparency of agreement between consumer and provider, data loss, traffic hijacking, shared technology and insecure application interface. Such threats need remedies to make the consumer use its features in secure way. In this review, we spot the light on the most security and privacy issues which can be attributed as gaps that sometimes the consumers or even the enterprises are not aware of. We also define the parties that involve in scenario of cloud computing that also may attack the entire cloud systems. We also show the consequences of these threats.","sentences":["Even with the vast potential that cloud computing has, so far, it has not been adopted by the consumers with the enthusiasm and pace that it be worthy; this is a very reason statement why consumers still hesitated of using cloud computing for their sensitive data and the threats that prevent the consumers from shifting to use cloud computing in general and cloud storage in particular.","The cloud computing inherits the traditional potential security and privacy threats besides its own issues due to its unique structures.","Some threats related to cloud computing are the insider malicious attacks from the employees that even sometime the provider unconscious about, the lack of transparency of agreement between consumer and provider, data loss, traffic hijacking, shared technology and insecure application interface.","Such threats need remedies to make the consumer use its features in secure way.","In this review, we spot the light on the most security and privacy issues which can be attributed as gaps that sometimes the consumers or even the enterprises are not aware of.","We also define the parties that involve in scenario of cloud computing that also may attack the entire cloud systems.","We also show the consequences of these threats."],"url":"http://arxiv.org/abs/2401.04076v1"}
{"created":"2024-01-08 18:18:02","title":"Fun with Flags: Robust Principal Directions via Flag Manifolds","abstract":"Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \\ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations. The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types. Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold. Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds.","sentences":["Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning.","In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \\ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously.","We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error.","We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold.","To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds.","We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations.","The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types.","Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold.","Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds."],"url":"http://arxiv.org/abs/2401.04071v1"}
{"created":"2024-01-08 18:01:09","title":"Variance Reduction in Ratio Metrics for Efficient Online Experiments","abstract":"Online controlled experiments, such as A/B-tests, are commonly used by modern tech companies to enable continuous system improvements. Despite their paramount importance, A/B-tests are expensive: by their very definition, a percentage of traffic is assigned an inferior system variant. To ensure statistical significance on top-level metrics, online experiments typically run for several weeks. Even then, a considerable amount of experiments will lead to inconclusive results (i.e. false negatives, or type-II error). The main culprit for this inefficiency is the variance of the online metrics. Variance reduction techniques have been proposed in the literature, but their direct applicability to commonly used ratio metrics (e.g. click-through rate or user retention) is limited.   In this work, we successfully apply variance reduction techniques to ratio metrics on a large-scale short-video platform: ShareChat. Our empirical results show that we can either improve A/B-test confidence in 77% of cases, or can retain the same level of confidence with 30% fewer data points. Importantly, we show that the common approach of including as many covariates as possible in regression is counter-productive, highlighting that control variates based on Gradient-Boosted Decision Tree predictors are most effective. We discuss the practicalities of implementing these methods at scale and showcase the cost reduction they beget.","sentences":["Online controlled experiments, such as A/B-tests, are commonly used by modern tech companies to enable continuous system improvements.","Despite their paramount importance, A/B-tests are expensive: by their very definition, a percentage of traffic is assigned an inferior system variant.","To ensure statistical significance on top-level metrics, online experiments typically run for several weeks.","Even then, a considerable amount of experiments will lead to inconclusive results (i.e. false negatives, or type-II error).","The main culprit for this inefficiency is the variance of the online metrics.","Variance reduction techniques have been proposed in the literature, but their direct applicability to commonly used ratio metrics (e.g. click-through rate or user retention) is limited.   ","In this work, we successfully apply variance reduction techniques to ratio metrics on a large-scale short-video platform: ShareChat.","Our empirical results show that we can either improve A/B-test confidence in 77% of cases, or can retain the same level of confidence with 30% fewer data points.","Importantly, we show that the common approach of including as many covariates as possible in regression is counter-productive, highlighting that control variates based on Gradient-Boosted Decision Tree predictors are most effective.","We discuss the practicalities of implementing these methods at scale and showcase the cost reduction they beget."],"url":"http://arxiv.org/abs/2401.04062v1"}
{"created":"2024-01-08 17:45:01","title":"The Role of Text in Visualizations: How Annotations Shape Perceptions of Bias and Influence Predictions","abstract":"This paper investigates the role of text in visualizations, specifically the impact of text position, semantic content, and biased wording. Two empirical studies were conducted based on two tasks (predicting data trends and appraising bias) using two visualization types (bar and line charts). While the addition of text had a minimal effect on how people perceive data trends, there was a significant impact on how biased they perceive the authors to be. This finding revealed a relationship between the degree of bias in textual information and the perception of the authors' bias. Exploratory analyses support an interaction between a person's prediction and the degree of bias they perceived. This paper also develops a crowdsourced method for creating chart annotations that range from neutral to highly biased. This research highlights the need for designers to mitigate potential polarization of readers' opinions based on how authors' ideas are expressed.","sentences":["This paper investigates the role of text in visualizations, specifically the impact of text position, semantic content, and biased wording.","Two empirical studies were conducted based on two tasks (predicting data trends and appraising bias) using two visualization types (bar and line charts).","While the addition of text had a minimal effect on how people perceive data trends, there was a significant impact on how biased they perceive the authors to be.","This finding revealed a relationship between the degree of bias in textual information and the perception of the authors' bias.","Exploratory analyses support an interaction between a person's prediction and the degree of bias they perceived.","This paper also develops a crowdsourced method for creating chart annotations that range from neutral to highly biased.","This research highlights the need for designers to mitigate potential polarization of readers' opinions based on how authors' ideas are expressed."],"url":"http://arxiv.org/abs/2401.04052v1"}
{"created":"2024-01-08 17:44:43","title":"Empirical Analysis of Efficient Fine-Tuning Methods for Large Pre-Trained Language Models","abstract":"Fine-tuning large pre-trained language models for downstream tasks remains a critical challenge in natural language processing. This paper presents an empirical analysis comparing two efficient fine-tuning methods - BitFit and adapter modules - to standard full model fine-tuning. Experiments conducted on GLUE benchmark datasets (MRPC, COLA, STS-B) reveal several key insights. The BitFit approach, which trains only bias terms and task heads, matches full fine-tuning performance across varying amounts of training data and time constraints. It demonstrates remarkable stability even with only 30\\% of data, outperforming full fine-tuning at intermediate data levels. Adapter modules exhibit high variability, with inconsistent gains over default models. The findings indicate BitFit offers an attractive balance between performance and parameter efficiency. Our work provides valuable perspectives on model tuning, emphasizing robustness and highlighting BitFit as a promising alternative for resource-constrained or streaming task settings. The analysis offers actionable guidelines for efficient adaptation of large pre-trained models, while illustrating open challenges in stabilizing techniques like adapter modules.","sentences":["Fine-tuning large pre-trained language models for downstream tasks remains a critical challenge in natural language processing.","This paper presents an empirical analysis comparing two efficient fine-tuning methods - BitFit and adapter modules - to standard full model fine-tuning.","Experiments conducted on GLUE benchmark datasets (MRPC, COLA, STS-B) reveal several key insights.","The BitFit approach, which trains only bias terms and task heads, matches full fine-tuning performance across varying amounts of training data and time constraints.","It demonstrates remarkable stability even with only 30\\% of data, outperforming full fine-tuning at intermediate data levels.","Adapter modules exhibit high variability, with inconsistent gains over default models.","The findings indicate BitFit offers an attractive balance between performance and parameter efficiency.","Our work provides valuable perspectives on model tuning, emphasizing robustness and highlighting BitFit as a promising alternative for resource-constrained or streaming task settings.","The analysis offers actionable guidelines for efficient adaptation of large pre-trained models, while illustrating open challenges in stabilizing techniques like adapter modules."],"url":"http://arxiv.org/abs/2401.04051v1"}
{"created":"2024-01-08 17:17:08","title":"Digital Twin for Autonomous Surface Vessels for Safe Maritime Navigation","abstract":"Autonomous surface vessels (ASVs) play an increasingly important role in the safety and sustainability of open sea operations. Since most maritime accidents are related to human failure, intelligent algorithms for autonomous collision avoidance and path following can drastically reduce the risk in the maritime sector. A DT is a virtual representative of a real physical system and can enhance the situational awareness (SITAW) of such an ASV to generate optimal decisions. This work builds on an existing DT framework for ASVs and demonstrates foundations for enabling predictive, prescriptive, and autonomous capabilities. In this context, sophisticated target tracking approaches are crucial for estimating and predicting the position and motion of other dynamic objects. The applied tracking method is enabled by real-time automatic identification system (AIS) data and synthetic light detection and ranging (Lidar) measurements. To guarantee safety during autonomous operations, we applied a predictive safety filter, based on the concept of nonlinear model predictive control (NMPC). The approaches are implemented into a DT built with the Unity game engine. As a result, this work demonstrates the potential of a DT capable of making predictions, playing through various what-if scenarios, and providing optimal control decisions according to its enhanced SITAW.","sentences":["Autonomous surface vessels (ASVs) play an increasingly important role in the safety and sustainability of open sea operations.","Since most maritime accidents are related to human failure, intelligent algorithms for autonomous collision avoidance and path following can drastically reduce the risk in the maritime sector.","A DT is a virtual representative of a real physical system and can enhance the situational awareness (SITAW) of such an ASV to generate optimal decisions.","This work builds on an existing DT framework for ASVs and demonstrates foundations for enabling predictive, prescriptive, and autonomous capabilities.","In this context, sophisticated target tracking approaches are crucial for estimating and predicting the position and motion of other dynamic objects.","The applied tracking method is enabled by real-time automatic identification system (AIS) data and synthetic light detection and ranging (Lidar) measurements.","To guarantee safety during autonomous operations, we applied a predictive safety filter, based on the concept of nonlinear model predictive control (NMPC).","The approaches are implemented into a DT built with the Unity game engine.","As a result, this work demonstrates the potential of a DT capable of making predictions, playing through various what-if scenarios, and providing optimal control decisions according to its enhanced SITAW."],"url":"http://arxiv.org/abs/2401.04032v1"}
{"created":"2024-01-08 17:07:37","title":"IDoFew: Intermediate Training Using Dual-Clustering in Language Models for Few Labels Text Classification","abstract":"Language models such as Bidirectional Encoder Representations from Transformers (BERT) have been very effective in various Natural Language Processing (NLP) and text mining tasks including text classification. However, some tasks still pose challenges for these models, including text classification with limited labels. This can result in a cold-start problem. Although some approaches have attempted to address this problem through single-stage clustering as an intermediate training step coupled with a pre-trained language model, which generates pseudo-labels to improve classification, these methods are often error-prone due to the limitations of the clustering algorithms. To overcome this, we have developed a novel two-stage intermediate clustering with subsequent fine-tuning that models the pseudo-labels reliably, resulting in reduced prediction errors. The key novelty in our model, IDoFew, is that the two-stage clustering coupled with two different clustering algorithms helps exploit the advantages of the complementary algorithms that reduce the errors in generating reliable pseudo-labels for fine-tuning. Our approach has shown significant improvements compared to strong comparative models.","sentences":["Language models such as Bidirectional Encoder Representations from Transformers (BERT) have been very effective in various Natural Language Processing (NLP) and text mining tasks including text classification.","However, some tasks still pose challenges for these models, including text classification with limited labels.","This can result in a cold-start problem.","Although some approaches have attempted to address this problem through single-stage clustering as an intermediate training step coupled with a pre-trained language model, which generates pseudo-labels to improve classification, these methods are often error-prone due to the limitations of the clustering algorithms.","To overcome this, we have developed a novel two-stage intermediate clustering with subsequent fine-tuning that models the pseudo-labels reliably, resulting in reduced prediction errors.","The key novelty in our model, IDoFew, is that the two-stage clustering coupled with two different clustering algorithms helps exploit the advantages of the complementary algorithms that reduce the errors in generating reliable pseudo-labels for fine-tuning.","Our approach has shown significant improvements compared to strong comparative models."],"url":"http://arxiv.org/abs/2401.04025v1"}
{"created":"2024-01-08 17:02:25","title":"Efficient Multiscale Multimodal Bottleneck Transformer for Audio-Video Classification","abstract":"In recent years, researchers combine both audio and video signals to deal with challenges where actions are not well represented or captured by visual cues. However, how to effectively leverage the two modalities is still under development. In this work, we develop a multiscale multimodal Transformer (MMT) that leverages hierarchical representation learning. Particularly, MMT is composed of a novel multiscale audio Transformer (MAT) and a multiscale video Transformer [43]. To learn a discriminative cross-modality fusion, we further design multimodal supervised contrastive objectives called audio-video contrastive loss (AVC) and intra-modal contrastive loss (IMC) that robustly align the two modalities. MMT surpasses previous state-of-the-art approaches by 7.3% and 2.1% on Kinetics-Sounds and VGGSound in terms of the top-1 accuracy without external training data. Moreover, the proposed MAT significantly outperforms AST [28] by 22.2%, 4.4% and 4.7% on three public benchmark datasets, and is about 3% more efficient based on the number of FLOPs and 9.8% more efficient based on GPU memory usage.","sentences":["In recent years, researchers combine both audio and video signals to deal with challenges where actions are not well represented or captured by visual cues.","However, how to effectively leverage the two modalities is still under development.","In this work, we develop a multiscale multimodal Transformer (MMT) that leverages hierarchical representation learning.","Particularly, MMT is composed of a novel multiscale audio Transformer (MAT) and a multiscale video Transformer [43].","To learn a discriminative cross-modality fusion, we further design multimodal supervised contrastive objectives called audio-video contrastive loss (AVC) and intra-modal contrastive loss (IMC) that robustly align the two modalities.","MMT surpasses previous state-of-the-art approaches by 7.3% and 2.1% on Kinetics-Sounds and VGGSound in terms of the top-1 accuracy without external training data.","Moreover, the proposed MAT significantly outperforms AST","[28] by 22.2%, 4.4% and 4.7% on three public benchmark datasets, and is about 3% more efficient based on the number of FLOPs and 9.8% more efficient based on GPU memory usage."],"url":"http://arxiv.org/abs/2401.04023v1"}
{"created":"2024-01-08 17:02:12","title":"Identifying Fabricated Networks within Authorship-for-Sale Enterprises","abstract":"Fabricated papers do not just need text, images, and data, they also require a fabricated or partially fabricated network of authors. Most `authors' on a fabricated paper have not been associated with the research, but rather are added through a transaction. This lack of deeper connection means that there is a low likelihood that co-authors on fabricated papers will ever appear together on the same paper more than once. This paper constructs a model that encodes some of the key characteristics of this activity in an `authorship-for-sale' network with the aim to create a robust method to detect this type of activity. A characteristic network fingerprint arises from this model that provides a robust statistical approach to the detection of paper-mill networks. The model suggested in this paper detects networks that have a statistically significant overlap with other approaches that principally rely on textual analysis for the detection of fraudulent papers. Researchers connected to networks identified using the methodology outlined in this paper are shown to be connected with 37% of papers identified through the tortured-phrase and clay-feet methods deployed in the Problematic Paper Screener website. Finally, methods to limit the expansion and propagation of these networks is discussed both in technological and social terms.","sentences":["Fabricated papers do not just need text, images, and data, they also require a fabricated or partially fabricated network of authors.","Most `authors' on a fabricated paper have not been associated with the research, but rather are added through a transaction.","This lack of deeper connection means that there is a low likelihood that co-authors on fabricated papers will ever appear together on the same paper more than once.","This paper constructs a model that encodes some of the key characteristics of this activity in an `authorship-for-sale' network with the aim to create a robust method to detect this type of activity.","A characteristic network fingerprint arises from this model that provides a robust statistical approach to the detection of paper-mill networks.","The model suggested in this paper detects networks that have a statistically significant overlap with other approaches that principally rely on textual analysis for the detection of fraudulent papers.","Researchers connected to networks identified using the methodology outlined in this paper are shown to be connected with 37% of papers identified through the tortured-phrase and clay-feet methods deployed in the Problematic Paper Screener website.","Finally, methods to limit the expansion and propagation of these networks is discussed both in technological and social terms."],"url":"http://arxiv.org/abs/2401.04022v1"}
{"created":"2024-01-08 16:55:33","title":"On the Long-Term behavior of $k$-tuples Frequencies in Mutation Systems","abstract":"In response to the evolving landscape of data storage, researchers have increasingly explored non-traditional platforms, with DNA-based storage emerging as a cutting-edge solution. Our work is motivated by the potential of in-vivo DNA storage, known for its capacity to store vast amounts of information efficiently and confidentially within an organism's native DNA. While promising, in-vivo DNA storage faces challenges, including susceptibility to errors introduced by mutations. To understand the long-term behavior of such mutation systems, we investigate the frequency of $k$-tuples after multiple mutation applications.   Drawing inspiration from related works, we generalize results from the study of mutation systems, particularly focusing on the frequency of $k$-tuples. In this work, we provide a broad analysis through the construction of a specialized matrix and the identification of its eigenvectors. In the context of substitution and duplication systems, we leverage previous results on almost sure convergence, equating the expected frequency to the limiting frequency. Moreover, we demonstrate convergence in probability under certain assumptions.","sentences":["In response to the evolving landscape of data storage, researchers have increasingly explored non-traditional platforms, with DNA-based storage emerging as a cutting-edge solution.","Our work is motivated by the potential of in-vivo DNA storage, known for its capacity to store vast amounts of information efficiently and confidentially within an organism's native DNA.","While promising, in-vivo DNA storage faces challenges, including susceptibility to errors introduced by mutations.","To understand the long-term behavior of such mutation systems, we investigate the frequency of $k$-tuples after multiple mutation applications.   ","Drawing inspiration from related works, we generalize results from the study of mutation systems, particularly focusing on the frequency of $k$-tuples.","In this work, we provide a broad analysis through the construction of a specialized matrix and the identification of its eigenvectors.","In the context of substitution and duplication systems, we leverage previous results on almost sure convergence, equating the expected frequency to the limiting frequency.","Moreover, we demonstrate convergence in probability under certain assumptions."],"url":"http://arxiv.org/abs/2401.04020v1"}
{"created":"2024-01-08 16:44:21","title":"MX: Enhancing RISC-V's Vector ISA for Ultra-Low Overhead, Energy-Efficient Matrix Multiplication","abstract":"Dense Matrix Multiplication (MatMul) is arguably one of the most ubiquitous compute-intensive kernels, spanning linear algebra, DSP, graphics, and machine learning applications. Thus, MatMul optimization is crucial not only in high-performance processors but also in embedded low-power platforms. Several Instruction Set Architectures (ISAs) have recently included matrix extensions to improve MatMul performance and efficiency at the cost of added matrix register files and units. In this paper, we propose Matrix eXtension (MX), a lightweight approach that builds upon the open-source RISC-V Vector (RVV) ISA to boost MatMul energy efficiency. Instead of adding expensive dedicated hardware, MX uses the pre-existing vector register file and functional units to create a hybrid vector/matrix engine at a negligible area cost (< 3%), which comes from a compact near-FPU tile buffer for higher data reuse, and no clock frequency overhead. We implement MX on a compact and highly energy-optimized RVV processor and evaluate it in both a Dual- and 64-Core cluster in a 12-nm technology node. MX boosts the Dual-Core's energy efficiency by 10% for a double-precision 64x64x64 matrix multiplication with the same FPU utilization (~97%) and by 25% on the 64-Core cluster for the same benchmark on 32-bit data, with a 56% performance gain.","sentences":["Dense Matrix Multiplication (MatMul) is arguably one of the most ubiquitous compute-intensive kernels, spanning linear algebra, DSP, graphics, and machine learning applications.","Thus, MatMul optimization is crucial not only in high-performance processors but also in embedded low-power platforms.","Several Instruction Set Architectures (ISAs) have recently included matrix extensions to improve MatMul performance and efficiency at the cost of added matrix register files and units.","In this paper, we propose Matrix eXtension (MX), a lightweight approach that builds upon the open-source RISC-V Vector (RVV) ISA to boost MatMul energy efficiency.","Instead of adding expensive dedicated hardware, MX uses the pre-existing vector register file and functional units to create a hybrid vector/matrix engine at a negligible area cost (< 3%), which comes from a compact near-FPU tile buffer for higher data reuse, and no clock frequency overhead.","We implement MX on a compact and highly energy-optimized RVV processor and evaluate it in both a Dual- and 64-Core cluster in a 12-nm technology node.","MX boosts the Dual-Core's energy efficiency by 10% for a double-precision 64x64x64 matrix multiplication with the same FPU utilization (~97%) and by 25% on the 64-Core cluster for the same benchmark on 32-bit data, with a 56% performance gain."],"url":"http://arxiv.org/abs/2401.04012v1"}
{"created":"2024-01-08 16:37:55","title":"Task-Oriented Active Learning of Model Preconditions for Inaccurate Dynamics Models","abstract":"When planning with an inaccurate dynamics model, a practical strategy is to restrict planning to regions of state-action space where the model is accurate: also known as a model precondition. Empirical real-world trajectory data is valuable for defining data-driven model preconditions regardless of the model form (analytical, simulator, learned, etc...). However, real-world data is often expensive and dangerous to collect. In order to achieve data efficiency, this paper presents an algorithm for actively selecting trajectories to learn a model precondition for an inaccurate pre-specified dynamics model. Our proposed techniques address challenges arising from the sequential nature of trajectories, and potential benefit of prioritizing task-relevant data. The experimental analysis shows how algorithmic properties affect performance in three planning scenarios: icy gridworld, simulated plant watering, and real-world plant watering. Results demonstrate an improvement of approximately 80% after only four real-world trajectories when using our proposed techniques.","sentences":["When planning with an inaccurate dynamics model, a practical strategy is to restrict planning to regions of state-action space where the model is accurate: also known as a model precondition.","Empirical real-world trajectory data is valuable for defining data-driven model preconditions regardless of the model form (analytical, simulator, learned, etc...).","However, real-world data is often expensive and dangerous to collect.","In order to achieve data efficiency, this paper presents an algorithm for actively selecting trajectories to learn a model precondition for an inaccurate pre-specified dynamics model.","Our proposed techniques address challenges arising from the sequential nature of trajectories, and potential benefit of prioritizing task-relevant data.","The experimental analysis shows how algorithmic properties affect performance in three planning scenarios: icy gridworld, simulated plant watering, and real-world plant watering.","Results demonstrate an improvement of approximately 80% after only four real-world trajectories when using our proposed techniques."],"url":"http://arxiv.org/abs/2401.04007v1"}
{"created":"2024-01-08 16:36:47","title":"Generative adversarial wavelet neural operator: Application to fault detection and isolation of multivariate time series data","abstract":"Fault detection and isolation in complex systems are critical to ensure reliable and efficient operation. However, traditional fault detection methods often struggle with issues such as nonlinearity and multivariate characteristics of the time series variables. This article proposes a generative adversarial wavelet neural operator (GAWNO) as a novel unsupervised deep learning approach for fault detection and isolation of multivariate time series processes.The GAWNO combines the strengths of wavelet neural operators and generative adversarial networks (GANs) to effectively capture both the temporal distributions and the spatial dependencies among different variables of an underlying system. The approach of fault detection and isolation using GAWNO consists of two main stages. In the first stage, the GAWNO is trained on a dataset of normal operating conditions to learn the underlying data distribution. In the second stage, a reconstruction error-based threshold approach using the trained GAWNO is employed to detect and isolate faults based on the discrepancy values. We validate the proposed approach using the Tennessee Eastman Process (TEP) dataset and Avedore wastewater treatment plant (WWTP) and N2O emissions named as WWTPN2O datasets. Overall, we showcase that the idea of harnessing the power of wavelet analysis, neural operators, and generative models in a single framework to detect and isolate faults has shown promising results compared to various well-established baselines in the literature.","sentences":["Fault detection and isolation in complex systems are critical to ensure reliable and efficient operation.","However, traditional fault detection methods often struggle with issues such as nonlinearity and multivariate characteristics of the time series variables.","This article proposes a generative adversarial wavelet neural operator (GAWNO) as a novel unsupervised deep learning approach for fault detection and isolation of multivariate time series processes.","The GAWNO combines the strengths of wavelet neural operators and generative adversarial networks (GANs) to effectively capture both the temporal distributions and the spatial dependencies among different variables of an underlying system.","The approach of fault detection and isolation using GAWNO consists of two main stages.","In the first stage, the GAWNO is trained on a dataset of normal operating conditions to learn the underlying data distribution.","In the second stage, a reconstruction error-based threshold approach using the trained GAWNO is employed to detect and isolate faults based on the discrepancy values.","We validate the proposed approach using the Tennessee Eastman Process (TEP) dataset and Avedore wastewater treatment plant (WWTP) and N2O emissions named as WWTPN2O datasets.","Overall, we showcase that the idea of harnessing the power of wavelet analysis, neural operators, and generative models in a single framework to detect and isolate faults has shown promising results compared to various well-established baselines in the literature."],"url":"http://arxiv.org/abs/2401.04004v1"}
{"created":"2024-01-08 16:15:43","title":"Behavioural Cloning in VizDoom","abstract":"This paper describes methods for training autonomous agents to play the game \"Doom 2\" through Imitation Learning (IL) using only pixel data as input. We also explore how Reinforcement Learning (RL) compares to IL for humanness by comparing camera movement and trajectory data. Through behavioural cloning, we examine the ability of individual models to learn varying behavioural traits. We attempt to mimic the behaviour of real players with different play styles, and find we can train agents that behave aggressively, passively, or simply more human-like than traditional AIs. We propose these methods of introducing more depth and human-like behaviour to agents in video games. The trained IL agents perform on par with the average players in our dataset, whilst outperforming the worst players. While performance was not as strong as common RL approaches, it provides much stronger human-like behavioural traits to the agent.","sentences":["This paper describes methods for training autonomous agents to play the game \"Doom 2\" through Imitation Learning (IL) using only pixel data as input.","We also explore how Reinforcement Learning (RL) compares to IL for humanness by comparing camera movement and trajectory data.","Through behavioural cloning, we examine the ability of individual models to learn varying behavioural traits.","We attempt to mimic the behaviour of real players with different play styles, and find we can train agents that behave aggressively, passively, or simply more human-like than traditional AIs.","We propose these methods of introducing more depth and human-like behaviour to agents in video games.","The trained IL agents perform on par with the average players in our dataset, whilst outperforming the worst players.","While performance was not as strong as common RL approaches, it provides much stronger human-like behavioural traits to the agent."],"url":"http://arxiv.org/abs/2401.03993v1"}
{"created":"2024-01-08 15:29:23","title":"Comparing Data-Driven and Mechanistic Models for Predicting Phenology in Deciduous Broadleaf Forests","abstract":"Understanding the future climate is crucial for informed policy decisions on climate change prevention and mitigation. Earth system models play an important role in predicting future climate, requiring accurate representation of complex sub-processes that span multiple time scales and spatial scales. One such process that links seasonal and interannual climate variability to cyclical biological events is tree phenology in deciduous broadleaf forests. Phenological dates, such as the start and end of the growing season, are critical for understanding the exchange of carbon and water between the biosphere and the atmosphere. Mechanistic prediction of these dates is challenging. Hybrid modelling, which integrates data-driven approaches into complex models, offers a solution. In this work, as a first step towards this goal, train a deep neural network to predict a phenological index from meteorological time series. We find that this approach outperforms traditional process-based models. This highlights the potential of data-driven methods to improve climate predictions. We also analyze which variables and aspects of the time series influence the predicted onset of the season, in order to gain a better understanding of the advantages and limitations of our model.","sentences":["Understanding the future climate is crucial for informed policy decisions on climate change prevention and mitigation.","Earth system models play an important role in predicting future climate, requiring accurate representation of complex sub-processes that span multiple time scales and spatial scales.","One such process that links seasonal and interannual climate variability to cyclical biological events is tree phenology in deciduous broadleaf forests.","Phenological dates, such as the start and end of the growing season, are critical for understanding the exchange of carbon and water between the biosphere and the atmosphere.","Mechanistic prediction of these dates is challenging.","Hybrid modelling, which integrates data-driven approaches into complex models, offers a solution.","In this work, as a first step towards this goal, train a deep neural network to predict a phenological index from meteorological time series.","We find that this approach outperforms traditional process-based models.","This highlights the potential of data-driven methods to improve climate predictions.","We also analyze which variables and aspects of the time series influence the predicted onset of the season, in order to gain a better understanding of the advantages and limitations of our model."],"url":"http://arxiv.org/abs/2401.03960v1"}
{"created":"2024-01-08 15:21:21","title":"TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series","abstract":"Large Pretrained models for Zero/Few-shot learning excel in language and vision domains but encounter challenges in multivariate time series (TS) due to the diverse nature and scarcity of publicly available pretraining data. Consequently, there has been a recent surge in utilizing pretrained large language models (LLMs) with various adaptations for time series forecasting. These approaches employ cross-domain transfer learning, yielding highly impressive results. However, these models are typically very large ($\\sim$ billion parameters), exhibit slow execution, and do not consider cross-channel correlations. To address this, we present Multi-level Tiny Time Mixers (TTM), a significantly smaller model based on the lightweight TSMixer architecture. TTM marks the first success in developing tiny pretrained models ($\\le$1 million parameters), exclusively trained on public TS data with effective transfer learning capabilities. To tackle the complexity of pretraining on multiple datasets with varied temporal resolutions, we introduce several novel enhancements such as adaptive patching, dataset augmentation via downsampling, and resolution prefix tuning. Moreover, we employ a multi-level modeling strategy to effectively model channel correlations and incorporate exogenous signals during finetuning, a crucial capability lacking in existing benchmarks. TTM excels in few/zero-shot forecasting, demonstrating significant accuracy gains (12-38%) over existing benchmarks. Further, it achieves a remarkable 14-106X reduction in model parameters, enabling 54-65X faster training/inference as compared to the LLM-TS benchmarks. In fact, TTM's zero-shot results often surpass the few-shot results in many benchmarks, highlighting the efficacy of our approach. Code and Pretrained Models will be open-sourced.","sentences":["Large Pretrained models for Zero/Few-shot learning excel in language and vision domains but encounter challenges in multivariate time series (TS) due to the diverse nature and scarcity of publicly available pretraining data.","Consequently, there has been a recent surge in utilizing pretrained large language models (LLMs) with various adaptations for time series forecasting.","These approaches employ cross-domain transfer learning, yielding highly impressive results.","However, these models are typically very large ($\\sim$ billion parameters), exhibit slow execution, and do not consider cross-channel correlations.","To address this, we present Multi-level Tiny Time Mixers (TTM), a significantly smaller model based on the lightweight TSMixer architecture.","TTM marks the first success in developing tiny pretrained models ($\\le$1 million parameters), exclusively trained on public TS data with effective transfer learning capabilities.","To tackle the complexity of pretraining on multiple datasets with varied temporal resolutions, we introduce several novel enhancements such as adaptive patching, dataset augmentation via downsampling, and resolution prefix tuning.","Moreover, we employ a multi-level modeling strategy to effectively model channel correlations and incorporate exogenous signals during finetuning, a crucial capability lacking in existing benchmarks.","TTM excels in few/zero-shot forecasting, demonstrating significant accuracy gains (12-38%) over existing benchmarks.","Further, it achieves a remarkable 14-106X reduction in model parameters, enabling 54-65X faster training/inference as compared to the LLM-TS benchmarks.","In fact, TTM's zero-shot results often surpass the few-shot results in many benchmarks, highlighting the efficacy of our approach.","Code and Pretrained Models will be open-sourced."],"url":"http://arxiv.org/abs/2401.03955v1"}
{"created":"2024-01-08 14:57:22","title":"Recovering the 3D UUV Position using UAV Imagery in Shallow-Water Environments","abstract":"In this paper we propose a novel approach aimed at recovering the 3D position of an UUV from UAV imagery in shallow-water environments. Through combination of UAV and UUV measurements, we show that our method can be utilized as an accurate and cost-effective alternative when compared to acoustic sensing methods, typically required to obtain ground truth information in underwater localization problems. Furthermore, our approach allows for a seamless conversion to geo-referenced coordinates which can be utilized for navigation purposes. To validate our method, we present the results with data collected through a simulation environment and field experiments, demonstrating the ability to successfully recover the UUV position with sub-meter accuracy.","sentences":["In this paper we propose a novel approach aimed at recovering the 3D position of an UUV from UAV imagery in shallow-water environments.","Through combination of UAV and UUV measurements, we show that our method can be utilized as an accurate and cost-effective alternative when compared to acoustic sensing methods, typically required to obtain ground truth information in underwater localization problems.","Furthermore, our approach allows for a seamless conversion to geo-referenced coordinates which can be utilized for navigation purposes.","To validate our method, we present the results with data collected through a simulation environment and field experiments, demonstrating the ability to successfully recover the UUV position with sub-meter accuracy."],"url":"http://arxiv.org/abs/2401.03938v1"}
{"created":"2024-01-08 14:45:15","title":"Using reinforcement learning to improve drone-based inference of greenhouse gas fluxes","abstract":"Accurate mapping of greenhouse gas fluxes at the Earth's surface is essential for the validation and calibration of climate models. In this study, we present a framework for surface flux estimation with drones. Our approach uses data assimilation (DA) to infer fluxes from drone-based observations, and reinforcement learning (RL) to optimize the drone's sampling strategy. Herein, we demonstrate that a RL-trained drone can quantify a CO2 hotspot more accurately than a drone sampling along a predefined flight path that traverses the emission plume. We find that information-based reward functions can match the performance of an error-based reward function that quantifies the difference between the estimated surface flux and the true value. Reward functions based on information gain and information entropy can motivate actions that increase the drone's confidence in its updated belief, without requiring knowledge of the true surface flux. These findings provide valuable insights for further development of the framework for the mapping of more complex surface flux fields.","sentences":["Accurate mapping of greenhouse gas fluxes at the Earth's surface is essential for the validation and calibration of climate models.","In this study, we present a framework for surface flux estimation with drones.","Our approach uses data assimilation (DA) to infer fluxes from drone-based observations, and reinforcement learning (RL) to optimize the drone's sampling strategy.","Herein, we demonstrate that a RL-trained drone can quantify a CO2 hotspot more accurately than a drone sampling along a predefined flight path that traverses the emission plume.","We find that information-based reward functions can match the performance of an error-based reward function that quantifies the difference between the estimated surface flux and the true value.","Reward functions based on information gain and information entropy can motivate actions that increase the drone's confidence in its updated belief, without requiring knowledge of the true surface flux.","These findings provide valuable insights for further development of the framework for the mapping of more complex surface flux fields."],"url":"http://arxiv.org/abs/2401.03932v1"}
{"created":"2024-01-08 14:39:21","title":"Rastro-DM: data mining with a trail","abstract":"This paper proposes a methodology for documenting data mining (DM) projects, Rastro-DM (Trail Data Mining), with a focus not on the model that is generated, but on the processes behind its construction, in order to leave a trail (Rastro in Portuguese) of planned actions, training completed, results obtained, and lessons learned. The proposed practices are complementary to structuring methodologies of DM, such as CRISP-DM, which establish a methodological and paradigmatic framework for the DM process. The application of best practices and their benefits is illustrated in a project called 'Cladop' that was created for the classification of PDF documents associated with the investigative process of damages to the Brazilian Federal Public Treasury. Building the Rastro-DM kit in the context of a project is a small step that can lead to an institutional leap to be achieved by sharing and using the trail across the enterprise.","sentences":["This paper proposes a methodology for documenting data mining (DM) projects, Rastro-DM (Trail Data Mining), with a focus not on the model that is generated, but on the processes behind its construction, in order to leave a trail (Rastro in Portuguese) of planned actions, training completed, results obtained, and lessons learned.","The proposed practices are complementary to structuring methodologies of DM, such as CRISP-DM, which establish a methodological and paradigmatic framework for the DM process.","The application of best practices and their benefits is illustrated in a project called 'Cladop' that was created for the classification of PDF documents associated with the investigative process of damages to the Brazilian Federal Public Treasury.","Building the Rastro-DM kit in the context of a project is a small step that can lead to an institutional leap to be achieved by sharing and using the trail across the enterprise."],"url":"http://arxiv.org/abs/2401.03925v1"}
{"created":"2024-01-08 14:21:02","title":"D3PRefiner: A Diffusion-based Denoise Method for 3D Human Pose Refinement","abstract":"Three-dimensional (3D) human pose estimation using a monocular camera has gained increasing attention due to its ease of implementation and the abundance of data available from daily life. However, owing to the inherent depth ambiguity in images, the accuracy of existing monocular camera-based 3D pose estimation methods remains unsatisfactory, and the estimated 3D poses usually include much noise. By observing the histogram of this noise, we find each dimension of the noise follows a certain distribution, which indicates the possibility for a neural network to learn the mapping between noisy poses and ground truth poses. In this work, in order to obtain more accurate 3D poses, a Diffusion-based 3D Pose Refiner (D3PRefiner) is proposed to refine the output of any existing 3D pose estimator. We first introduce a conditional multivariate Gaussian distribution to model the distribution of noisy 3D poses, using paired 2D poses and noisy 3D poses as conditions to achieve greater accuracy. Additionally, we leverage the architecture of current diffusion models to convert the distribution of noisy 3D poses into ground truth 3D poses. To evaluate the effectiveness of the proposed method, two state-of-the-art sequence-to-sequence 3D pose estimators are used as basic 3D pose estimation models, and the proposed method is evaluated on different types of 2D poses and different lengths of the input sequence. Experimental results demonstrate the proposed architecture can significantly improve the performance of current sequence-to-sequence 3D pose estimators, with a reduction of at least 10.3% in the mean per joint position error (MPJPE) and at least 11.0% in the Procrustes MPJPE (P-MPJPE).","sentences":["Three-dimensional (3D) human pose estimation using a monocular camera has gained increasing attention due to its ease of implementation and the abundance of data available from daily life.","However, owing to the inherent depth ambiguity in images, the accuracy of existing monocular camera-based 3D pose estimation methods remains unsatisfactory, and the estimated 3D poses usually include much noise.","By observing the histogram of this noise, we find each dimension of the noise follows a certain distribution, which indicates the possibility for a neural network to learn the mapping between noisy poses and ground truth poses.","In this work, in order to obtain more accurate 3D poses, a Diffusion-based 3D Pose Refiner (D3PRefiner) is proposed to refine the output of any existing 3D pose estimator.","We first introduce a conditional multivariate Gaussian distribution to model the distribution of noisy 3D poses, using paired 2D poses and noisy 3D poses as conditions to achieve greater accuracy.","Additionally, we leverage the architecture of current diffusion models to convert the distribution of noisy 3D poses into ground truth 3D poses.","To evaluate the effectiveness of the proposed method, two state-of-the-art sequence-to-sequence 3D pose estimators are used as basic 3D pose estimation models, and the proposed method is evaluated on different types of 2D poses and different lengths of the input sequence.","Experimental results demonstrate the proposed architecture can significantly improve the performance of current sequence-to-sequence 3D pose estimators, with a reduction of at least 10.3% in the mean per joint position error (MPJPE) and at least 11.0% in the Procrustes MPJPE (P-MPJPE)."],"url":"http://arxiv.org/abs/2401.03914v1"}
{"created":"2024-01-08 14:16:55","title":"A Wasserstein Graph Distance Based on Distributions of Probabilistic Node Embeddings","abstract":"Distance measures between graphs are important primitives for a variety of learning tasks. In this work, we describe an unsupervised, optimal transport based approach to define a distance between graphs. Our idea is to derive representations of graphs as Gaussian mixture models, fitted to distributions of sampled node embeddings over the same space. The Wasserstein distance between these Gaussian mixture distributions then yields an interpretable and easily computable distance measure, which can further be tailored for the comparison at hand by choosing appropriate embeddings. We propose two embeddings for this framework and show that under certain assumptions about the shape of the resulting Gaussian mixture components, further computational improvements of this Wasserstein distance can be achieved. An empirical validation of our findings on synthetic data and real-world Functional Brain Connectivity networks shows promising performance compared to existing embedding methods.","sentences":["Distance measures between graphs are important primitives for a variety of learning tasks.","In this work, we describe an unsupervised, optimal transport based approach to define a distance between graphs.","Our idea is to derive representations of graphs as Gaussian mixture models, fitted to distributions of sampled node embeddings over the same space.","The Wasserstein distance between these Gaussian mixture distributions then yields an interpretable and easily computable distance measure, which can further be tailored for the comparison at hand by choosing appropriate embeddings.","We propose two embeddings for this framework and show that under certain assumptions about the shape of the resulting Gaussian mixture components, further computational improvements of this Wasserstein distance can be achieved.","An empirical validation of our findings on synthetic data and real-world Functional Brain Connectivity networks shows promising performance compared to existing embedding methods."],"url":"http://arxiv.org/abs/2401.03913v2"}
{"created":"2024-01-08 13:52:59","title":"Ultra-Dense Cell-Free Massive MIMO for 6G: Technical Overview and Open Questions","abstract":"Ultra-dense cell-free massive multiple-input multiple-output (CF-MMIMO) has emerged as a promising technology expected to meet the future ubiquitous connectivity requirements and ever-growing data traffic demands in 6G. This article provides a contemporary overview of ultra-dense CF-MMIMO networks, and addresses important unresolved questions on their future deployment. We first present a comprehensive survey of state-of-the-art research on CF-MMIMO and ultra-dense networks. Then, we discuss the key challenges of CF-MMIMO under ultra-dense scenarios such as low-complexity architecture and processing, low-complexity/scalable resource allocation, fronthaul limitation, massive access, synchronization, and channel acquisition. Finally, we answer key open questions, considering different design comparisons and discussing suitable methods dealing with the key challenges of ultra-dense CF-MMIMO. The discussion aims to provide a valuable roadmap for interesting future research directions in this area, facilitating the development of CF-MMIMO MIMO for 6G.","sentences":["Ultra-dense cell-free massive multiple-input multiple-output (CF-MMIMO) has emerged as a promising technology expected to meet the future ubiquitous connectivity requirements and ever-growing data traffic demands in 6G. This article provides a contemporary overview of ultra-dense CF-MMIMO networks, and addresses important unresolved questions on their future deployment.","We first present a comprehensive survey of state-of-the-art research on CF-MMIMO and ultra-dense networks.","Then, we discuss the key challenges of CF-MMIMO under ultra-dense scenarios such as low-complexity architecture and processing, low-complexity/scalable resource allocation, fronthaul limitation, massive access, synchronization, and channel acquisition.","Finally, we answer key open questions, considering different design comparisons and discussing suitable methods dealing with the key challenges of ultra-dense CF-MMIMO.","The discussion aims to provide a valuable roadmap for interesting future research directions in this area, facilitating the development of CF-MMIMO MIMO for 6G."],"url":"http://arxiv.org/abs/2401.03898v1"}
