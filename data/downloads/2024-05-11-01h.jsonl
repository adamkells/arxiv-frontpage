{"created":"2024-05-09 17:55:16","title":"Self-Supervised Learning of Time Series Representation via Diffusion Process and Imputation-Interpolation-Forecasting Mask","abstract":"Time Series Representation Learning (TSRL) focuses on generating informative representations for various Time Series (TS) modeling tasks. Traditional Self-Supervised Learning (SSL) methods in TSRL fall into four main categories: reconstructive, adversarial, contrastive, and predictive, each with a common challenge of sensitivity to noise and intricate data nuances. Recently, diffusion-based methods have shown advanced generative capabilities. However, they primarily target specific application scenarios like imputation and forecasting, leaving a gap in leveraging diffusion models for generic TSRL. Our work, Time Series Diffusion Embedding (TSDE), bridges this gap as the first diffusion-based SSL TSRL approach. TSDE segments TS data into observed and masked parts using an Imputation-Interpolation-Forecasting (IIF) mask. It applies a trainable embedding function, featuring dual-orthogonal Transformer encoders with a crossover mechanism, to the observed part. We train a reverse diffusion process conditioned on the embeddings, designed to predict noise added to the masked part. Extensive experiments demonstrate TSDE's superiority in imputation, interpolation, forecasting, anomaly detection, classification, and clustering. We also conduct an ablation study, present embedding visualizations, and compare inference speed, further substantiating TSDE's efficiency and validity in learning representations of TS data.","sentences":["Time Series Representation Learning (TSRL) focuses on generating informative representations for various Time Series (TS) modeling tasks.","Traditional Self-Supervised Learning (SSL) methods in TSRL fall into four main categories: reconstructive, adversarial, contrastive, and predictive, each with a common challenge of sensitivity to noise and intricate data nuances.","Recently, diffusion-based methods have shown advanced generative capabilities.","However, they primarily target specific application scenarios like imputation and forecasting, leaving a gap in leveraging diffusion models for generic TSRL.","Our work, Time Series Diffusion Embedding (TSDE), bridges this gap as the first diffusion-based SSL TSRL approach.","TSDE segments TS data into observed and masked parts using an Imputation-Interpolation-Forecasting (IIF) mask.","It applies a trainable embedding function, featuring dual-orthogonal Transformer encoders with a crossover mechanism, to the observed part.","We train a reverse diffusion process conditioned on the embeddings, designed to predict noise added to the masked part.","Extensive experiments demonstrate TSDE's superiority in imputation, interpolation, forecasting, anomaly detection, classification, and clustering.","We also conduct an ablation study, present embedding visualizations, and compare inference speed, further substantiating TSDE's efficiency and validity in learning representations of TS data."],"url":"http://arxiv.org/abs/2405.05959v1"}
{"created":"2024-05-09 17:53:28","title":"OpenBA-V2: Reaching 77.3% High Compression Ratio with Fast Multi-Stage Pruning","abstract":"Large Language Models (LLMs) have played an important role in many fields due to their powerful capabilities.However, their massive number of parameters leads to high deployment requirements and incurs significant inference costs, which impedes their practical applications. Training smaller models is an effective way to address this problem. Therefore, we introduce OpenBA-V2, a 3.4B model derived from multi-stage compression and continual pre-training from the original 15B OpenBA model. OpenBA-V2 utilizes more data, more flexible training objectives, and techniques such as layer pruning, neural pruning, and vocabulary pruning to achieve a compression rate of 77.3\\% with minimal performance loss. OpenBA-V2 demonstrates competitive performance compared to other open-source models of similar size, achieving results close to or on par with the 15B OpenBA model in downstream tasks such as common sense reasoning and Named Entity Recognition (NER). OpenBA-V2 illustrates that LLMs can be compressed into smaller ones with minimal performance loss by employing advanced training objectives and data strategies, which may help deploy LLMs in resource-limited scenarios.","sentences":["Large Language Models (LLMs) have played an important role in many fields due to their powerful capabilities.","However, their massive number of parameters leads to high deployment requirements and incurs significant inference costs, which impedes their practical applications.","Training smaller models is an effective way to address this problem.","Therefore, we introduce OpenBA-V2, a 3.4B model derived from multi-stage compression and continual pre-training from the original 15B OpenBA model.","OpenBA-V2 utilizes more data, more flexible training objectives, and techniques such as layer pruning, neural pruning, and vocabulary pruning to achieve a compression rate of 77.3\\% with minimal performance loss.","OpenBA-V2 demonstrates competitive performance compared to other open-source models of similar size, achieving results close to or on par with the 15B OpenBA model in downstream tasks such as common sense reasoning and Named Entity Recognition (NER).","OpenBA-V2 illustrates that LLMs can be compressed into smaller ones with minimal performance loss by employing advanced training objectives and data strategies, which may help deploy LLMs in resource-limited scenarios."],"url":"http://arxiv.org/abs/2405.05957v1"}
{"created":"2024-05-09 17:52:42","title":"Probing Multimodal LLMs as World Models for Driving","abstract":"We provide a sober look at the application of Multimodal Large Language Models (MLLMs) within the domain of autonomous driving and challenge/verify some common assumptions, focusing on their ability to reason and interpret dynamic driving scenarios through sequences of images/frames in a closed-loop control environment. Despite the significant advancements in MLLMs like GPT-4V, their performance in complex, dynamic driving environments remains largely untested and presents a wide area of exploration. We conduct a comprehensive experimental study to evaluate the capability of various MLLMs as world models for driving from the perspective of a fixed in-car camera. Our findings reveal that, while these models proficiently interpret individual images, they struggle significantly with synthesizing coherent narratives or logical sequences across frames depicting dynamic behavior. The experiments demonstrate considerable inaccuracies in predicting (i) basic vehicle dynamics (forward/backward, acceleration/deceleration, turning right or left), (ii) interactions with other road actors (e.g., identifying speeding cars or heavy traffic), (iii) trajectory planning, and (iv) open-set dynamic scene reasoning, suggesting biases in the models' training data. To enable this experimental study we introduce a specialized simulator, DriveSim, designed to generate diverse driving scenarios, providing a platform for evaluating MLLMs in the realms of driving. Additionally, we contribute the full open-source code and a new dataset, \"Eval-LLM-Drive\", for evaluating MLLMs in driving. Our results highlight a critical gap in the current capabilities of state-of-the-art MLLMs, underscoring the need for enhanced foundation models to improve their applicability in real-world dynamic environments.","sentences":["We provide a sober look at the application of Multimodal Large Language Models (MLLMs) within the domain of autonomous driving and challenge/verify some common assumptions, focusing on their ability to reason and interpret dynamic driving scenarios through sequences of images/frames in a closed-loop control environment.","Despite the significant advancements in MLLMs like GPT-4V, their performance in complex, dynamic driving environments remains largely untested and presents a wide area of exploration.","We conduct a comprehensive experimental study to evaluate the capability of various MLLMs as world models for driving from the perspective of a fixed in-car camera.","Our findings reveal that, while these models proficiently interpret individual images, they struggle significantly with synthesizing coherent narratives or logical sequences across frames depicting dynamic behavior.","The experiments demonstrate considerable inaccuracies in predicting (i) basic vehicle dynamics (forward/backward, acceleration/deceleration, turning right or left), (ii) interactions with other road actors (e.g., identifying speeding cars or heavy traffic), (iii) trajectory planning, and (iv) open-set dynamic scene reasoning, suggesting biases in the models' training data.","To enable this experimental study we introduce a specialized simulator, DriveSim, designed to generate diverse driving scenarios, providing a platform for evaluating MLLMs in the realms of driving.","Additionally, we contribute the full open-source code and a new dataset, \"Eval-LLM-Drive\", for evaluating MLLMs in driving.","Our results highlight a critical gap in the current capabilities of state-of-the-art MLLMs, underscoring the need for enhanced foundation models to improve their applicability in real-world dynamic environments."],"url":"http://arxiv.org/abs/2405.05956v1"}
{"created":"2024-05-09 17:44:29","title":"New Algorithms and Lower Bounds for Streaming Tournaments","abstract":"We study fundamental directed graph (digraph) problems in the streaming model. An initial investigation by Chakrabarti, Ghosh, McGregor, and Vorotnikova [SODA'20] on streaming digraphs showed that while most of these problems are provably hard in general, some of them become tractable when restricted to the well-studied class of tournament graphs where every pair of nodes shares exactly one directed edge. Thus, we focus on tournaments and improve the state of the art for multiple problems in terms of both upper and lower bounds.   Our primary upper bound is a deterministic single-pass semi-streaming algorithm (using $\\tilde{O}(n)$ space for $n$-node graphs, where $\\tilde{O}(.)$ hides polylog$(n)$ factors) for decomposing a tournament into strongly connected components (SCC). it improves upon the previously best-known algorithm by Baweja, Jia, and Woodruff [ITCS'22] in terms of both space and passes: for $p\\geq 1$, they used $(p+1)$-passes and $\\tilde{O}(n^{1+1/p})$-space. We further extend our algorithm to digraphs that are close to tournaments and establish tight bounds demonstrating that the problem's complexity grows smoothly with the \"distance\" from tournaments. Applying our framework, we obtain improved tournament algorithms for $s,t$-reachability, strong connectivity, Hamiltonian paths and cycles, and feedback arc set.   On the other hand, we prove the first $\\Omega(n^2)$-space lower bounds for this class, exhibiting that some well-studied problems -- such as (exact) feedback arc set on tournaments (FAST) and $s,t$-distance -- remain hard here. We obtain a generalized lower bound on space-approximation tradeoffs for FAST: any single-pass $(1\\pm \\varepsilon)$-approximation algorithm requires $\\Omega(n/\\sqrt{\\varepsilon})$ space. As a whole, our collection of results contributes significantly to the growing literature on streaming digraphs.","sentences":["We study fundamental directed graph (digraph) problems in the streaming model.","An initial investigation by Chakrabarti, Ghosh, McGregor, and Vorotnikova [SODA'20] on streaming digraphs showed that while most of these problems are provably hard in general, some of them become tractable when restricted to the well-studied class of tournament graphs where every pair of nodes shares exactly one directed edge.","Thus, we focus on tournaments and improve the state of the art for multiple problems in terms of both upper and lower bounds.   ","Our primary upper bound is a deterministic single-pass semi-streaming algorithm (using $\\tilde{O}(n)$ space for $n$-node graphs, where $\\tilde{O}(.)$ hides polylog$(n)$ factors) for decomposing a tournament into strongly connected components (SCC).","it improves upon the previously best-known algorithm by Baweja, Jia, and Woodruff","[ITCS'22] in terms of both space and passes: for $p\\geq 1$, they used $(p+1)$-passes and $\\tilde{O}(n^{1+1/p})$-space.","We further extend our algorithm to digraphs that are close to tournaments and establish tight bounds demonstrating that the problem's complexity grows smoothly with the \"distance\" from tournaments.","Applying our framework, we obtain improved tournament algorithms for $s,t$-reachability, strong connectivity, Hamiltonian paths and cycles, and feedback arc set.   ","On the other hand, we prove the first $\\Omega(n^2)$-space lower bounds for this class, exhibiting that some well-studied problems -- such as (exact) feedback arc set on tournaments (FAST) and $s,t$-distance -- remain hard here.","We obtain a generalized lower bound on space-approximation tradeoffs for FAST: any single-pass $(1\\pm \\varepsilon)$-approximation algorithm requires $\\Omega(n/\\sqrt{\\varepsilon})$ space.","As a whole, our collection of results contributes significantly to the growing literature on streaming digraphs."],"url":"http://arxiv.org/abs/2405.05952v1"}
{"created":"2024-05-09 17:40:09","title":"Federated Combinatorial Multi-Agent Multi-Armed Bandits","abstract":"This paper introduces a federated learning framework tailored for online combinatorial optimization with bandit feedback. In this setting, agents select subsets of arms, observe noisy rewards for these subsets without accessing individual arm information, and can cooperate and share information at specific intervals. Our framework transforms any offline resilient single-agent $(\\alpha-\\epsilon)$-approximation algorithm, having a complexity of $\\tilde{\\mathcal{O}}(\\frac{\\psi}{\\epsilon^\\beta})$, where the logarithm is omitted, for some function $\\psi$ and constant $\\beta$, into an online multi-agent algorithm with $m$ communicating agents and an $\\alpha$-regret of no more than $\\tilde{\\mathcal{O}}(m^{-\\frac{1}{3+\\beta}} \\psi^\\frac{1}{3+\\beta} T^\\frac{2+\\beta}{3+\\beta})$. This approach not only eliminates the $\\epsilon$ approximation error but also ensures sublinear growth with respect to the time horizon $T$ and demonstrates a linear speedup with an increasing number of communicating agents. Additionally, the algorithm is notably communication-efficient, requiring only a sublinear number of communication rounds, quantified as $\\tilde{\\mathcal{O}}\\left(\\psi T^\\frac{\\beta}{\\beta+1}\\right)$. Furthermore, the framework has been successfully applied to online stochastic submodular maximization using various offline algorithms, yielding the first results for both single-agent and multi-agent settings and recovering specialized single-agent theoretical guarantees. We empirically validate our approach to a stochastic data summarization problem, illustrating the effectiveness of the proposed framework, even in single-agent scenarios.","sentences":["This paper introduces a federated learning framework tailored for online combinatorial optimization with bandit feedback.","In this setting, agents select subsets of arms, observe noisy rewards for these subsets without accessing individual arm information, and can cooperate and share information at specific intervals.","Our framework transforms any offline resilient single-agent $(\\alpha-\\epsilon)$-approximation algorithm, having a complexity of $\\tilde{\\mathcal{O}}(\\frac{\\psi}{\\epsilon^\\beta})$, where the logarithm is omitted, for some function $\\psi$ and constant $\\beta$, into an online multi-agent algorithm with $m$ communicating agents and an $\\alpha$-regret of no more than $\\tilde{\\mathcal{O}}(m^{-\\frac{1}{3+\\beta}} \\psi^\\frac{1}{3+\\beta} T^\\frac{2+\\beta}{3+\\beta})$. This approach not only eliminates the $\\epsilon$ approximation error but also ensures sublinear growth with respect to the time horizon $T$ and demonstrates a linear speedup with an increasing number of communicating agents.","Additionally, the algorithm is notably communication-efficient, requiring only a sublinear number of communication rounds, quantified as $\\tilde{\\mathcal{O}}\\left(\\psi T^\\frac{\\beta}{\\beta+1}\\right)$.","Furthermore, the framework has been successfully applied to online stochastic submodular maximization using various offline algorithms, yielding the first results for both single-agent and multi-agent settings and recovering specialized single-agent theoretical guarantees.","We empirically validate our approach to a stochastic data summarization problem, illustrating the effectiveness of the proposed framework, even in single-agent scenarios."],"url":"http://arxiv.org/abs/2405.05950v1"}
{"created":"2024-05-09 17:37:20","title":"CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts","abstract":"Recent advancements in Multimodal Large Language Models (LLMs) have focused primarily on scaling by increasing text-image pair data and enhancing LLMs to improve performance on multimodal tasks. However, these scaling approaches are computationally expensive and overlook the significance of improving model capabilities from the vision side. Inspired by the successful applications of Mixture-of-Experts (MoE) in LLMs, which improves model scalability during training while keeping inference costs similar to those of smaller models, we propose CuMo. CuMo incorporates Co-upcycled Top-K sparsely-gated Mixture-of-experts blocks into both the vision encoder and the MLP connector, thereby enhancing the multimodal LLMs with minimal additional activated parameters during inference. CuMo first pre-trains the MLP blocks and then initializes each expert in the MoE block from the pre-trained MLP block during the visual instruction tuning stage. Auxiliary losses are used to ensure a balanced loading of experts. CuMo outperforms state-of-the-art multimodal LLMs across various VQA and visual-instruction-following benchmarks using models within each model size group, all while training exclusively on open-sourced datasets. The code and model weights for CuMo are open-sourced at https://github.com/SHI-Labs/CuMo.","sentences":["Recent advancements in Multimodal Large Language Models (LLMs) have focused primarily on scaling by increasing text-image pair data and enhancing LLMs to improve performance on multimodal tasks.","However, these scaling approaches are computationally expensive and overlook the significance of improving model capabilities from the vision side.","Inspired by the successful applications of Mixture-of-Experts (MoE) in LLMs, which improves model scalability during training while keeping inference costs similar to those of smaller models, we propose CuMo.","CuMo incorporates Co-upcycled Top-K sparsely-gated Mixture-of-experts blocks into both the vision encoder and the MLP connector, thereby enhancing the multimodal LLMs with minimal additional activated parameters during inference.","CuMo first pre-trains the MLP blocks and then initializes each expert in the MoE block from the pre-trained MLP block during the visual instruction tuning stage.","Auxiliary losses are used to ensure a balanced loading of experts.","CuMo outperforms state-of-the-art multimodal LLMs across various VQA and visual-instruction-following benchmarks using models within each model size group, all while training exclusively on open-sourced datasets.","The code and model weights for CuMo are open-sourced at https://github.com/SHI-Labs/CuMo."],"url":"http://arxiv.org/abs/2405.05949v1"}
{"created":"2024-05-09 17:36:23","title":"A Survey on Visualization Approaches in Political Science for Social and Political Factors: Progress to Date and Future Opportunities","abstract":"Politics is the set of activities related to strategic decision-making in groups. Political scientists study the strategic interactions between states, institutions, politicians, and citizens; they seek to understand the causes and consequences of those decisions and interactions. While some decisions might alleviate social problems, others might lead to disasters such as war and conflict. Data visualization approaches have the potential to assist political scientists in their studies by providing visual contexts. However, political researchers' perspectives on data visualization are unclear. This paper examines political scientists' perspectives on visualization and how they apply data visualization in their research. We discovered a growing trend in the use of graphs in political science journals. However, we also found a knowledge gap between the political science and visualization domains, such as effective visualization techniques for tasks and the use of color studied by visualization researchers. To reduce this gap, we survey visualization techniques applicable to the political scientists' research and report the visual analytics systems implemented for and evaluated by political scientists. At the end of this paper, we present an outline of future opportunities, including research topics and methodologies, for multidisciplinary research in political science and data analytics. Through this paper, we expect visualization researchers to get a better grasp of the political science domain, as well as broaden the possibility of future visualization approaches from a multidisciplinary perspective.","sentences":["Politics is the set of activities related to strategic decision-making in groups.","Political scientists study the strategic interactions between states, institutions, politicians, and citizens; they seek to understand the causes and consequences of those decisions and interactions.","While some decisions might alleviate social problems, others might lead to disasters such as war and conflict.","Data visualization approaches have the potential to assist political scientists in their studies by providing visual contexts.","However, political researchers' perspectives on data visualization are unclear.","This paper examines political scientists' perspectives on visualization and how they apply data visualization in their research.","We discovered a growing trend in the use of graphs in political science journals.","However, we also found a knowledge gap between the political science and visualization domains, such as effective visualization techniques for tasks and the use of color studied by visualization researchers.","To reduce this gap, we survey visualization techniques applicable to the political scientists' research and report the visual analytics systems implemented for and evaluated by political scientists.","At the end of this paper, we present an outline of future opportunities, including research topics and methodologies, for multidisciplinary research in political science and data analytics.","Through this paper, we expect visualization researchers to get a better grasp of the political science domain, as well as broaden the possibility of future visualization approaches from a multidisciplinary perspective."],"url":"http://arxiv.org/abs/2405.05947v1"}
{"created":"2024-05-09 17:35:16","title":"Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers","abstract":"Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details. In this technical report, we introduce the Lumina-T2X family - a series of Flow-based Large Diffusion Transformers (Flag-DiT) equipped with zero-initialized attention, as a unified framework designed to transform noise into images, videos, multi-view 3D objects, and audio clips conditioned on text instructions. By tokenizing the latent spatial-temporal space and incorporating learnable placeholders such as [nextline] and [nextframe] tokens, Lumina-T2X seamlessly unifies the representations of different modalities across various spatial-temporal resolutions. This unified approach enables training within a single framework for different modalities and allows for flexible generation of multimodal data at any resolution, aspect ratio, and length during inference. Advanced techniques like RoPE, RMSNorm, and flow matching enhance the stability, flexibility, and scalability of Flag-DiT, enabling models of Lumina-T2X to scale up to 7 billion parameters and extend the context window to 128K tokens. This is particularly beneficial for creating ultra-high-definition images with our Lumina-T2I model and long 720p videos with our Lumina-T2V model. Remarkably, Lumina-T2I, powered by a 5-billion-parameter Flag-DiT, requires only 35% of the training computational costs of a 600-million-parameter naive DiT. Our further comprehensive analysis underscores Lumina-T2X's preliminary capability in resolution extrapolation, high-resolution editing, generating consistent 3D views, and synthesizing videos with seamless transitions. We expect that the open-sourcing of Lumina-T2X will further foster creativity, transparency, and diversity in the generative AI community.","sentences":["Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details.","In this technical report, we introduce the Lumina-T2X family - a series of Flow-based Large Diffusion Transformers (Flag-DiT) equipped with zero-initialized attention, as a unified framework designed to transform noise into images, videos, multi-view 3D objects, and audio clips conditioned on text instructions.","By tokenizing the latent spatial-temporal space and incorporating learnable placeholders such as [nextline] and [nextframe] tokens, Lumina-T2X seamlessly unifies the representations of different modalities across various spatial-temporal resolutions.","This unified approach enables training within a single framework for different modalities and allows for flexible generation of multimodal data at any resolution, aspect ratio, and length during inference.","Advanced techniques like RoPE, RMSNorm, and flow matching enhance the stability, flexibility, and scalability of Flag-DiT, enabling models of Lumina-T2X to scale up to 7 billion parameters and extend the context window to 128K tokens.","This is particularly beneficial for creating ultra-high-definition images with our Lumina-T2I model and long 720p videos with our Lumina-T2V model.","Remarkably, Lumina-T2I, powered by a 5-billion-parameter Flag-DiT, requires only 35% of the training computational costs of a 600-million-parameter naive DiT. Our further comprehensive analysis underscores Lumina-T2X's preliminary capability in resolution extrapolation, high-resolution editing, generating consistent 3D views, and synthesizing videos with seamless transitions.","We expect that the open-sourcing of Lumina-T2X will further foster creativity, transparency, and diversity in the generative AI community."],"url":"http://arxiv.org/abs/2405.05945v1"}
{"created":"2024-05-09 17:32:39","title":"Improved Evolutionary Algorithms for Submodular Maximization with Cost Constraints","abstract":"We present an evolutionary algorithm evo-SMC for the problem of Submodular Maximization under Cost constraints (SMC). Our algorithm achieves $1/2$-approximation with a high probability $1-1/n$ within $\\mathcal{O}(n^2K_{\\beta})$ iterations, where $K_{\\beta}$ denotes the maximum size of a feasible solution set with cost constraint $\\beta$. To the best of our knowledge, this is the best approximation guarantee offered by evolutionary algorithms for this problem. We further refine evo-SMC, and develop {\\sc st-evo-SMC}. This stochastic version yields a significantly faster algorithm while maintaining the approximation ratio of $1/2$, with probability $1-\\epsilon$. The required number of iterations reduces to $\\mathcal{O}(nK_{\\beta}\\log{(1/\\epsilon)}/p)$, where the user defined parameters $p \\in (0,1]$ represents the stochasticity probability, and $\\epsilon \\in (0,1]$ denotes the error threshold. Finally, the empirical evaluations carried out through extensive experimentation substantiate the efficiency and effectiveness of our proposed algorithms. Our algorithms consistently outperform existing methods, producing higher-quality solutions.","sentences":["We present an evolutionary algorithm evo-SMC for the problem of Submodular Maximization under Cost constraints (SMC).","Our algorithm achieves $1/2$-approximation with a high probability $1-1/n$ within $\\mathcal{O}(n^2K_{\\beta})$ iterations, where $K_{\\beta}$ denotes the maximum size of a feasible solution set with cost constraint $\\beta$. To the best of our knowledge, this is the best approximation guarantee offered by evolutionary algorithms for this problem.","We further refine evo-SMC, and develop {\\sc st-evo-SMC}.","This stochastic version yields a significantly faster algorithm while maintaining the approximation ratio of $1/2$, with probability $1-\\epsilon$. The required number of iterations reduces to $\\mathcal{O}(nK_{\\beta}\\log{(1/\\epsilon)}/p)$, where the user defined parameters $p \\in (0,1]$ represents the stochasticity probability, and $\\epsilon \\in (0,1]$ denotes the error threshold.","Finally, the empirical evaluations carried out through extensive experimentation substantiate the efficiency and effectiveness of our proposed algorithms.","Our algorithms consistently outperform existing methods, producing higher-quality solutions."],"url":"http://arxiv.org/abs/2405.05942v1"}
{"created":"2024-05-09 17:16:54","title":"Theoretical Guarantees of Data Augmented Last Layer Retraining Methods","abstract":"Ensuring fair predictions across many distinct subpopulations in the training data can be prohibitive for large models. Recently, simple linear last layer retraining strategies, in combination with data augmentation methods such as upweighting, downsampling and mixup, have been shown to achieve state-of-the-art performance for worst-group accuracy, which quantifies accuracy for the least prevalent subpopulation. For linear last layer retraining and the abovementioned augmentations, we present the optimal worst-group accuracy when modeling the distribution of the latent representations (input to the last layer) as Gaussian for each subpopulation. We evaluate and verify our results for both synthetic and large publicly available datasets.","sentences":["Ensuring fair predictions across many distinct subpopulations in the training data can be prohibitive for large models.","Recently, simple linear last layer retraining strategies, in combination with data augmentation methods such as upweighting, downsampling and mixup, have been shown to achieve state-of-the-art performance for worst-group accuracy, which quantifies accuracy for the least prevalent subpopulation.","For linear last layer retraining and the abovementioned augmentations, we present the optimal worst-group accuracy when modeling the distribution of the latent representations (input to the last layer) as Gaussian for each subpopulation.","We evaluate and verify our results for both synthetic and large publicly available datasets."],"url":"http://arxiv.org/abs/2405.05934v1"}
{"created":"2024-05-09 17:15:09","title":"FuXi-ENS: A machine learning model for medium-range ensemble weather forecasting","abstract":"Ensemble weather forecasting is essential for weather predictions and mitigating the impacts of extreme weather events. Constructing an ensemble prediction system (EPS) based on conventional numerical weather prediction (NWP) models is highly computationally expensive. Machine learning (ML) models have emerged as valuable tools for deterministic weather forecasts, providing forecasts with significantly reduced computational requirements and even surpassing the forecast performance of traditional NWP models. However, challenges arise when applying ML models to ensemble forecasting. Recent ML models, such as GenCast and SEEDS model, rely on the ERA5 Ensemble of Data Assimilations (EDA) or two operational NWP ensemble members for forecast generation. The spatial resolution of 1{\\deg} or 2{\\deg} in these models is often considered too coarse for many applications. To overcome these limitations, we introduce FuXi-ENS, an advanced ML model designed to deliver 6-hourly global ensemble weather forecasts up to 15 days. This model runs at a significantly improved spatial resolution of 0.25{\\deg}, incorporating 5 upper-air atmospheric variables at 13 pressure levels, along with 13 surface variables. By leveraging the inherent probabilistic nature of Variational AutoEncoder (VAE), FuXi-ENS optimizes a loss function that combines the continuous ranked probability score (CRPS) and the KL divergence between the predicted and target distribution. This innovative approach represents an advancement over the traditional use of L1 loss combined with the KL loss in standard VAE models when VAE for ensemble weather forecasts. Evaluation results demonstrate that FuXi-ENS outperforms ensemble forecasts from the European Centre for Medium-Range Weather Forecasts (ECMWF), a world leading NWP model, on 98.1% of 360 variable and forecast lead time combinations on CRPS.","sentences":["Ensemble weather forecasting is essential for weather predictions and mitigating the impacts of extreme weather events.","Constructing an ensemble prediction system (EPS) based on conventional numerical weather prediction (NWP) models is highly computationally expensive.","Machine learning (ML) models have emerged as valuable tools for deterministic weather forecasts, providing forecasts with significantly reduced computational requirements and even surpassing the forecast performance of traditional NWP models.","However, challenges arise when applying ML models to ensemble forecasting.","Recent ML models, such as GenCast and SEEDS model, rely on the ERA5 Ensemble of Data Assimilations (EDA) or two operational NWP ensemble members for forecast generation.","The spatial resolution of 1{\\deg} or 2{\\deg} in these models is often considered too coarse for many applications.","To overcome these limitations, we introduce FuXi-ENS, an advanced ML model designed to deliver 6-hourly global ensemble weather forecasts up to 15 days.","This model runs at a significantly improved spatial resolution of 0.25{\\deg}, incorporating 5 upper-air atmospheric variables at 13 pressure levels, along with 13 surface variables.","By leveraging the inherent probabilistic nature of Variational AutoEncoder (VAE), FuXi-ENS optimizes a loss function that combines the continuous ranked probability score (CRPS) and the KL divergence between the predicted and target distribution.","This innovative approach represents an advancement over the traditional use of L1 loss combined with the KL loss in standard VAE models when VAE for ensemble weather forecasts.","Evaluation results demonstrate that FuXi-ENS outperforms ensemble forecasts from the European Centre for Medium-Range Weather Forecasts (ECMWF), a world leading NWP model, on 98.1% of 360 variable and forecast lead time combinations on CRPS."],"url":"http://arxiv.org/abs/2405.05925v1"}
{"created":"2024-05-09 16:22:24","title":"Exploiting Autoencoder's Weakness to Generate Pseudo Anomalies","abstract":"Due to the rare occurrence of anomalous events, a typical approach to anomaly detection is to train an autoencoder (AE) with normal data only so that it learns the patterns or representations of the normal training data. At test time, the trained AE is expected to well reconstruct normal but to poorly reconstruct anomalous data. However, contrary to the expectation, anomalous data is often well reconstructed as well. In order to further separate the reconstruction quality between normal and anomalous data, we propose creating pseudo anomalies from learned adaptive noise by exploiting the aforementioned weakness of AE, i.e., reconstructing anomalies too well. The generated noise is added to the normal data to create pseudo anomalies. Extensive experiments on Ped2, Avenue, ShanghaiTech, CIFAR-10, and KDDCUP datasets demonstrate the effectiveness and generic applicability of our approach in improving the discriminative capability of AEs for anomaly detection.","sentences":["Due to the rare occurrence of anomalous events, a typical approach to anomaly detection is to train an autoencoder (AE) with normal data only so that it learns the patterns or representations of the normal training data.","At test time, the trained AE is expected to well reconstruct normal but to poorly reconstruct anomalous data.","However, contrary to the expectation, anomalous data is often well reconstructed as well.","In order to further separate the reconstruction quality between normal and anomalous data, we propose creating pseudo anomalies from learned adaptive noise by exploiting the aforementioned weakness of AE, i.e., reconstructing anomalies too well.","The generated noise is added to the normal data to create pseudo anomalies.","Extensive experiments on Ped2, Avenue, ShanghaiTech, CIFAR-10, and KDDCUP datasets demonstrate the effectiveness and generic applicability of our approach in improving the discriminative capability of AEs for anomaly detection."],"url":"http://arxiv.org/abs/2405.05886v1"}
{"created":"2024-05-09 16:00:20","title":"Selecting the Most Conflicting Pair of Candidates","abstract":"We study committee elections from a perspective of finding the most conflicting candidates, that is, candidates that imply the largest amount of conflict, as per voter preferences. By proposing basic axioms to capture this objective, we show that none of the prominent multiwinner voting rules meet them. Consequently, we design committee voting rules compliant with our desiderata, introducing conflictual voting rules. A subsequent deepened analysis sheds more light on how they operate. Our investigation identifies various aspects of conflict, for which we come up with relevant axioms and quantitative measures, which may be of independent interest. We support our theoretical study with experiments on both real-life and synthetic data.","sentences":["We study committee elections from a perspective of finding the most conflicting candidates, that is, candidates that imply the largest amount of conflict, as per voter preferences.","By proposing basic axioms to capture this objective, we show that none of the prominent multiwinner voting rules meet them.","Consequently, we design committee voting rules compliant with our desiderata, introducing conflictual voting rules.","A subsequent deepened analysis sheds more light on how they operate.","Our investigation identifies various aspects of conflict, for which we come up with relevant axioms and quantitative measures, which may be of independent interest.","We support our theoretical study with experiments on both real-life and synthetic data."],"url":"http://arxiv.org/abs/2405.05870v1"}
{"created":"2024-05-09 15:53:43","title":"Faster Linear Systems and Matrix Norm Approximation via Multi-level Sketched Preconditioning","abstract":"We present a new class of preconditioned iterative methods for solving linear systems of the form $Ax = b$. Our methods are based on constructing a low-rank Nystr\\\"om approximation to $A$ using sparse random sketching. This approximation is used to construct a preconditioner, which itself is inverted quickly using additional levels of random sketching and preconditioning. We prove that the convergence of our methods depends on a natural average condition number of $A$, which improves as the rank of the Nystr\\\"om approximation increases. Concretely, this allows us to obtain faster runtimes for a number of fundamental linear algebraic problems:   1. We show how to solve any $n\\times n$ linear system that is well-conditioned except for $k$ outlying large singular values in $\\tilde{O}(n^{2.065} + k^\\omega)$ time, improving on a recent result of [Derezi\\'nski, Yang, STOC 2024] for all $k \\gtrsim n^{0.78}$.   2. We give the first $\\tilde{O}(n^2 + {d_\\lambda}^{\\omega}$) time algorithm for solving a regularized linear system $(A + \\lambda I)x = b$, where $A$ is positive semidefinite with effective dimension $d_\\lambda$. This problem arises in applications like Gaussian process regression.   3. We give faster algorithms for approximating Schatten $p$-norms and other matrix norms. For example, for the Schatten 1 (nuclear) norm, we give an algorithm that runs in $\\tilde{O}(n^{2.11})$ time, improving on an $\\tilde{O}(n^{2.18})$ method of [Musco et al., ITCS 2018].   Interestingly, previous state-of-the-art algorithms for most of the problems above relied on stochastic iterative methods, like stochastic coordinate and gradient descent. Our work takes a completely different approach, instead leveraging tools from matrix sketching.","sentences":["We present a new class of preconditioned iterative methods for solving linear systems of the form $Ax = b$. Our methods are based on constructing a low-rank Nystr\\\"om approximation to $A$ using sparse random sketching.","This approximation is used to construct a preconditioner, which itself is inverted quickly using additional levels of random sketching and preconditioning.","We prove that the convergence of our methods depends on a natural average condition number of $A$, which improves as the rank of the Nystr\\\"om approximation increases.","Concretely, this allows us to obtain faster runtimes for a number of fundamental linear algebraic problems:   1.","We show how to solve any $n\\times n$ linear system that is well-conditioned except for $k$ outlying large singular values in $\\tilde{O}(n^{2.065} + k^\\omega)$ time, improving on a recent result of [Derezi\\'nski, Yang, STOC 2024] for all $k \\gtrsim n^{0.78}$.   2.","We give the first $\\tilde{O}(n^2 + {d_\\lambda}^{\\omega}$) time algorithm for solving a regularized linear system $(A + \\lambda I)x","= b$, where $A$ is positive semidefinite with effective dimension $d_\\lambda$. This problem arises in applications like Gaussian process regression.   ","3.","We give faster algorithms for approximating Schatten $p$-norms and other matrix norms.","For example, for the Schatten 1 (nuclear) norm, we give an algorithm that runs in $\\tilde{O}(n^{2.11})$ time, improving on an $\\tilde{O}(n^{2.18})$ method of [Musco et al., ITCS 2018].   ","Interestingly, previous state-of-the-art algorithms for most of the problems above relied on stochastic iterative methods, like stochastic coordinate and gradient descent.","Our work takes a completely different approach, instead leveraging tools from matrix sketching."],"url":"http://arxiv.org/abs/2405.05865v1"}
{"created":"2024-05-09 15:48:39","title":"ExACT: An End-to-End Autonomous Excavator System Using Action Chunking With Transformers","abstract":"Excavators are crucial for diverse tasks such as construction and mining, while autonomous excavator systems enhance safety and efficiency, address labor shortages, and improve human working conditions. Different from the existing modularized approaches, this paper introduces ExACT, an end-to-end autonomous excavator system that processes raw LiDAR, camera data, and joint positions to control excavator valves directly. Utilizing the Action Chunking with Transformers (ACT) architecture, ExACT employs imitation learning to take observations from multi-modal sensors as inputs and generate actionable sequences. In our experiment, we build a simulator based on the captured real-world data to model the relations between excavator valve states and joint velocities. With a few human-operated demonstration data trajectories, ExACT demonstrates the capability of completing different excavation tasks, including reaching, digging and dumping through imitation learning in validations with the simulator. To the best of our knowledge, ExACT represents the first instance towards building an end-to-end autonomous excavator system via imitation learning methods with a minimal set of human demonstrations. The video about this work can be accessed at https://youtu.be/NmzR_Rf-aEk.","sentences":["Excavators are crucial for diverse tasks such as construction and mining, while autonomous excavator systems enhance safety and efficiency, address labor shortages, and improve human working conditions.","Different from the existing modularized approaches, this paper introduces ExACT, an end-to-end autonomous excavator system that processes raw LiDAR, camera data, and joint positions to control excavator valves directly.","Utilizing the Action Chunking with Transformers (ACT) architecture, ExACT employs imitation learning to take observations from multi-modal sensors as inputs and generate actionable sequences.","In our experiment, we build a simulator based on the captured real-world data to model the relations between excavator valve states and joint velocities.","With a few human-operated demonstration data trajectories, ExACT demonstrates the capability of completing different excavation tasks, including reaching, digging and dumping through imitation learning in validations with the simulator.","To the best of our knowledge, ExACT represents the first instance towards building an end-to-end autonomous excavator system via imitation learning methods with a minimal set of human demonstrations.","The video about this work can be accessed at https://youtu.be/NmzR_Rf-aEk."],"url":"http://arxiv.org/abs/2405.05861v1"}
{"created":"2024-05-09 15:48:07","title":"The Perspectivist Paradigm Shift: Assumptions and Challenges of Capturing Human Labels","abstract":"Longstanding data labeling practices in machine learning involve collecting and aggregating labels from multiple annotators. But what should we do when annotators disagree? Though annotator disagreement has long been seen as a problem to minimize, new perspectivist approaches challenge this assumption by treating disagreement as a valuable source of information. In this position paper, we examine practices and assumptions surrounding the causes of disagreement--some challenged by perspectivist approaches, and some that remain to be addressed--as well as practical and normative challenges for work operating under these assumptions. We conclude with recommendations for the data labeling pipeline and avenues for future research engaging with subjectivity and disagreement.","sentences":["Longstanding data labeling practices in machine learning involve collecting and aggregating labels from multiple annotators.","But what should we do when annotators disagree?","Though annotator disagreement has long been seen as a problem to minimize, new perspectivist approaches challenge this assumption by treating disagreement as a valuable source of information.","In this position paper, we examine practices and assumptions surrounding the causes of disagreement--some challenged by perspectivist approaches, and some that remain to be addressed--as well as practical and normative challenges for work operating under these assumptions.","We conclude with recommendations for the data labeling pipeline and avenues for future research engaging with subjectivity and disagreement."],"url":"http://arxiv.org/abs/2405.05860v1"}
{"created":"2024-05-09 15:39:54","title":"Pre-trained Text-to-Image Diffusion Models Are Versatile Representation Learners for Control","abstract":"Embodied AI agents require a fine-grained understanding of the physical world mediated through visual and language inputs. Such capabilities are difficult to learn solely from task-specific data. This has led to the emergence of pre-trained vision-language models as a tool for transferring representations learned from internet-scale data to downstream tasks and new domains. However, commonly used contrastively trained representations such as in CLIP have been shown to fail at enabling embodied agents to gain a sufficiently fine-grained scene understanding -- a capability vital for control. To address this shortcoming, we consider representations from pre-trained text-to-image diffusion models, which are explicitly optimized to generate images from text prompts and as such, contain text-conditioned representations that reflect highly fine-grained visuo-spatial information. Using pre-trained text-to-image diffusion models, we construct Stable Control Representations which allow learning downstream control policies that generalize to complex, open-ended environments. We show that policies learned using Stable Control Representations are competitive with state-of-the-art representation learning approaches across a broad range of simulated control settings, encompassing challenging manipulation and navigation tasks. Most notably, we show that Stable Control Representations enable learning policies that exhibit state-of-the-art performance on OVMM, a difficult open-vocabulary navigation benchmark.","sentences":["Embodied AI agents require a fine-grained understanding of the physical world mediated through visual and language inputs.","Such capabilities are difficult to learn solely from task-specific data.","This has led to the emergence of pre-trained vision-language models as a tool for transferring representations learned from internet-scale data to downstream tasks and new domains.","However, commonly used contrastively trained representations such as in CLIP have been shown to fail at enabling embodied agents to gain a sufficiently fine-grained scene understanding -- a capability vital for control.","To address this shortcoming, we consider representations from pre-trained text-to-image diffusion models, which are explicitly optimized to generate images from text prompts and as such, contain text-conditioned representations that reflect highly fine-grained visuo-spatial information.","Using pre-trained text-to-image diffusion models, we construct Stable Control Representations which allow learning downstream control policies that generalize to complex, open-ended environments.","We show that policies learned using Stable Control Representations are competitive with state-of-the-art representation learning approaches across a broad range of simulated control settings, encompassing challenging manipulation and navigation tasks.","Most notably, we show that Stable Control Representations enable learning policies that exhibit state-of-the-art performance on OVMM, a difficult open-vocabulary navigation benchmark."],"url":"http://arxiv.org/abs/2405.05852v1"}
{"created":"2024-05-09 15:34:15","title":"Learned feature representations are biased by complexity, learning order, position, and more","abstract":"Representation learning, and interpreting learned representations, are key areas of focus in machine learning and neuroscience. Both fields generally use representations as a means to understand or improve a system's computations. In this work, however, we explore surprising dissociations between representation and computation that may pose challenges for such efforts. We create datasets in which we attempt to match the computational role that different features play, while manipulating other properties of the features or the data. We train various deep learning architectures to compute these multiple abstract features about their inputs. We find that their learned feature representations are systematically biased towards representing some features more strongly than others, depending upon extraneous properties such as feature complexity, the order in which features are learned, and the distribution of features over the inputs. For example, features that are simpler to compute or learned first tend to be represented more strongly and densely than features that are more complex or learned later, even if all features are learned equally well. We also explore how these biases are affected by architectures, optimizers, and training regimes (e.g., in transformers, features decoded earlier in the output sequence also tend to be represented more strongly). Our results help to characterize the inductive biases of gradient-based representation learning. These results also highlight a key challenge for interpretability $-$ or for comparing the representations of models and brains $-$ disentangling extraneous biases from the computationally important aspects of a system's internal representations.","sentences":["Representation learning, and interpreting learned representations, are key areas of focus in machine learning and neuroscience.","Both fields generally use representations as a means to understand or improve a system's computations.","In this work, however, we explore surprising dissociations between representation and computation that may pose challenges for such efforts.","We create datasets in which we attempt to match the computational role that different features play, while manipulating other properties of the features or the data.","We train various deep learning architectures to compute these multiple abstract features about their inputs.","We find that their learned feature representations are systematically biased towards representing some features more strongly than others, depending upon extraneous properties such as feature complexity, the order in which features are learned, and the distribution of features over the inputs.","For example, features that are simpler to compute or learned first tend to be represented more strongly and densely than features that are more complex or learned later, even if all features are learned equally well.","We also explore how these biases are affected by architectures, optimizers, and training regimes (e.g., in transformers, features decoded earlier in the output sequence also tend to be represented more strongly).","Our results help to characterize the inductive biases of gradient-based representation learning.","These results also highlight a key challenge for interpretability $-$ or for comparing the representations of models and brains $-$ disentangling extraneous biases from the computationally important aspects of a system's internal representations."],"url":"http://arxiv.org/abs/2405.05847v1"}
{"created":"2024-05-09 15:23:38","title":"Self-Supervised Pre-training with Symmetric Superimposition Modeling for Scene Text Recognition","abstract":"In text recognition, self-supervised pre-training emerges as a good solution to reduce dependence on expansive annotated real data. Previous studies primarily focus on local visual representation by leveraging mask image modeling or sequence contrastive learning. However, they omit modeling the linguistic information in text images, which is crucial for recognizing text. To simultaneously capture local character features and linguistic information in visual space, we propose Symmetric Superimposition Modeling (SSM). The objective of SSM is to reconstruct the direction-specific pixel and feature signals from the symmetrically superimposed input. Specifically, we add the original image with its inverted views to create the symmetrically superimposed inputs. At the pixel level, we reconstruct the original and inverted images to capture character shapes and texture-level linguistic context. At the feature level, we reconstruct the feature of the same original image and inverted image with different augmentations to model the semantic-level linguistic context and the local character discrimination. In our design, we disrupt the character shape and linguistic rules. Consequently, the dual-level reconstruction facilitates understanding character shapes and linguistic information from the perspective of visual texture and feature semantics. Experiments on various text recognition benchmarks demonstrate the effectiveness and generality of SSM, with 4.1% average performance gains and 86.6% new state-of-the-art average word accuracy on Union14M benchmarks.","sentences":["In text recognition, self-supervised pre-training emerges as a good solution to reduce dependence on expansive annotated real data.","Previous studies primarily focus on local visual representation by leveraging mask image modeling or sequence contrastive learning.","However, they omit modeling the linguistic information in text images, which is crucial for recognizing text.","To simultaneously capture local character features and linguistic information in visual space, we propose Symmetric Superimposition Modeling (SSM).","The objective of SSM is to reconstruct the direction-specific pixel and feature signals from the symmetrically superimposed input.","Specifically, we add the original image with its inverted views to create the symmetrically superimposed inputs.","At the pixel level, we reconstruct the original and inverted images to capture character shapes and texture-level linguistic context.","At the feature level, we reconstruct the feature of the same original image and inverted image with different augmentations to model the semantic-level linguistic context and the local character discrimination.","In our design, we disrupt the character shape and linguistic rules.","Consequently, the dual-level reconstruction facilitates understanding character shapes and linguistic information from the perspective of visual texture and feature semantics.","Experiments on various text recognition benchmarks demonstrate the effectiveness and generality of SSM, with 4.1% average performance gains and 86.6% new state-of-the-art average word accuracy on Union14M benchmarks."],"url":"http://arxiv.org/abs/2405.05841v1"}
{"created":"2024-05-09 15:15:34","title":"Informed Decision-Making through Advancements in Open Set Recognition and Unknown Sample Detection","abstract":"Machine learning-based techniques open up many opportunities and improvements to derive deeper and more practical insights from data that can help businesses make informed decisions. However, the majority of these techniques focus on the conventional closed-set scenario, in which the label spaces for the training and test sets are identical. Open set recognition (OSR) aims to bring classification tasks in a situation that is more like reality, which focuses on classifying the known classes as well as handling unknown classes effectively. In such an open-set problem the gathered samples in the training set cannot encompass all the classes and the system needs to identify unknown samples at test time. On the other hand, building an accurate and comprehensive model in a real dynamic environment presents a number of obstacles, because it is prohibitively expensive to train for every possible example of unknown items, and the model may fail when tested in testbeds. This study provides an algorithm exploring a new representation of feature space to improve classification in OSR tasks. The efficacy and efficiency of business processes and decision-making can be improved by integrating OSR, which offers more precise and insightful predictions of outcomes. We demonstrate the performance of the proposed method on three established datasets. The results indicate that the proposed model outperforms the baseline methods in accuracy and F1-score.","sentences":["Machine learning-based techniques open up many opportunities and improvements to derive deeper and more practical insights from data that can help businesses make informed decisions.","However, the majority of these techniques focus on the conventional closed-set scenario, in which the label spaces for the training and test sets are identical.","Open set recognition (OSR) aims to bring classification tasks in a situation that is more like reality, which focuses on classifying the known classes as well as handling unknown classes effectively.","In such an open-set problem the gathered samples in the training set cannot encompass all the classes and the system needs to identify unknown samples at test time.","On the other hand, building an accurate and comprehensive model in a real dynamic environment presents a number of obstacles, because it is prohibitively expensive to train for every possible example of unknown items, and the model may fail when tested in testbeds.","This study provides an algorithm exploring a new representation of feature space to improve classification in OSR tasks.","The efficacy and efficiency of business processes and decision-making can be improved by integrating OSR, which offers more precise and insightful predictions of outcomes.","We demonstrate the performance of the proposed method on three established datasets.","The results indicate that the proposed model outperforms the baseline methods in accuracy and F1-score."],"url":"http://arxiv.org/abs/2405.05836v1"}
{"created":"2024-05-09 15:02:26","title":"MAD-ICP: It Is All About Matching Data -- Robust and Informed LiDAR Odometry","abstract":"LiDAR odometry is the task of estimating the ego-motion of the sensor from sequential laser scans. This problem has been addressed by the community for more than two decades, and many effective solutions are available nowadays. Most of these systems implicitly rely on assumptions about the operating environment, the sensor used, and motion pattern. When these assumptions are violated, several well-known systems tend to perform poorly. This paper presents a LiDAR odometry system that can overcome these limitations and operate well under different operating conditions while achieving performance comparable with domain-specific methods. Our algorithm follows the well-known ICP paradigm that leverages a PCA-based kd-tree implementation that is used to extract structural information about the clouds being registered and to compute the minimization metric for the alignment. The drift is bound by managing the local map based on the estimated uncertainty of the tracked pose. To benefit the community, we release an open-source C++ anytime real-time implementation.","sentences":["LiDAR odometry is the task of estimating the ego-motion of the sensor from sequential laser scans.","This problem has been addressed by the community for more than two decades, and many effective solutions are available nowadays.","Most of these systems implicitly rely on assumptions about the operating environment, the sensor used, and motion pattern.","When these assumptions are violated, several well-known systems tend to perform poorly.","This paper presents a LiDAR odometry system that can overcome these limitations and operate well under different operating conditions while achieving performance comparable with domain-specific methods.","Our algorithm follows the well-known ICP paradigm that leverages a PCA-based kd-tree implementation that is used to extract structural information about the clouds being registered and to compute the minimization metric for the alignment.","The drift is bound by managing the local map based on the estimated uncertainty of the tracked pose.","To benefit the community, we release an open-source C++","anytime real-time implementation."],"url":"http://arxiv.org/abs/2405.05828v1"}
{"created":"2024-05-09 14:56:49","title":"Fine-grained Analysis and Faster Algorithms for Iteratively Solving Linear Systems","abstract":"While effective in practice, iterative methods for solving large systems of linear equations can be significantly affected by problem-dependent condition number quantities. This makes characterizing their time complexity challenging, particularly when we wish to make comparisons between deterministic and stochastic methods, that may or may not rely on preconditioning and/or fast matrix multiplication. In this work, we consider a fine-grained notion of complexity for iterative linear solvers which we call the spectral tail condition number, $\\kappa_\\ell$, defined as the ratio between the $\\ell$th largest and the smallest singular value of the matrix representing the system.   Concretely, we prove the following main algorithmic result: Given an $n\\times n$ matrix $A$ and a vector $b$, we can find $\\tilde{x}$ such that $\\|A\\tilde{x}-b\\|\\leq\\epsilon\\|b\\|$ in time $\\tilde{O}(\\kappa_\\ell\\cdot n^2\\log 1/\\epsilon)$ for any $\\ell = O(n^{\\frac1{\\omega-1}})=O(n^{0.729})$, where $\\omega \\approx 2.372$ is the current fast matrix multiplication exponent. This guarantee is achieved by Sketch-and-Project with Nesterov's acceleration. Some of the implications of our result, and of the use of $\\kappa_\\ell$, include direct improvement over a fine-grained analysis of the Conjugate Gradient method, suggesting a stronger separation between deterministic and stochastic iterative solvers; and relating the complexity of iterative solvers to the ongoing algorithmic advances in fast matrix multiplication, since the bound on $\\ell$ improves with $\\omega$.   Our main technical contributions are new sharp characterizations for the first and second moments of the random projection matrix that commonly arises in sketching algorithms, building on a combination of techniques from combinatorial sampling via determinantal point processes and Gaussian universality results from random matrix theory.","sentences":["While effective in practice, iterative methods for solving large systems of linear equations can be significantly affected by problem-dependent condition number quantities.","This makes characterizing their time complexity challenging, particularly when we wish to make comparisons between deterministic and stochastic methods, that may or may not rely on preconditioning and/or fast matrix multiplication.","In this work, we consider a fine-grained notion of complexity for iterative linear solvers which we call the spectral tail condition number, $\\kappa_\\ell$, defined as the ratio between the $\\ell$th largest and the smallest singular value of the matrix representing the system.   ","Concretely, we prove the following main algorithmic result: Given an $n\\times n$ matrix $A$ and a vector $b$, we can find $\\tilde{x}$ such that $\\|A\\tilde{x}-b\\|\\leq\\epsilon\\|b\\|$ in time $\\tilde{O}(\\kappa_\\ell\\cdot n^2\\log 1/\\epsilon)$ for any $\\ell = O(n^{\\frac1{\\omega-1}})=O(n^{0.729})$, where $\\omega \\approx 2.372$ is the current fast matrix multiplication exponent.","This guarantee is achieved by Sketch-and-Project with Nesterov's acceleration.","Some of the implications of our result, and of the use of $\\kappa_\\ell$, include direct improvement over a fine-grained analysis of the Conjugate Gradient method, suggesting a stronger separation between deterministic and stochastic iterative solvers; and relating the complexity of iterative solvers to the ongoing algorithmic advances in fast matrix multiplication, since the bound on $\\ell$ improves with $\\omega$.   Our main technical contributions are new sharp characterizations for the first and second moments of the random projection matrix that commonly arises in sketching algorithms, building on a combination of techniques from combinatorial sampling via determinantal point processes and Gaussian universality results from random matrix theory."],"url":"http://arxiv.org/abs/2405.05818v1"}
{"created":"2024-05-09 14:47:15","title":"Fast and Controllable Post-training Sparsity: Learning Optimal Sparsity Allocation with Global Constraint in Minutes","abstract":"Neural network sparsity has attracted many research interests due to its similarity to biological schemes and high energy efficiency. However, existing methods depend on long-time training or fine-tuning, which prevents large-scale applications. Recently, some works focusing on post-training sparsity (PTS) have emerged. They get rid of the high training cost but usually suffer from distinct accuracy degradation due to neglect of the reasonable sparsity rate at each layer. Previous methods for finding sparsity rates mainly focus on the training-aware scenario, which usually fails to converge stably under the PTS setting with limited data and much less training cost. In this paper, we propose a fast and controllable post-training sparsity (FCPTS) framework. By incorporating a differentiable bridge function and a controllable optimization objective, our method allows for rapid and accurate sparsity allocation learning in minutes, with the added assurance of convergence to a predetermined global sparsity rate. Equipped with these techniques, we can surpass the state-of-the-art methods by a large margin, e.g., over 30\\% improvement for ResNet-50 on ImageNet under the sparsity rate of 80\\%. Our plug-and-play code and supplementary materials are open-sourced at https://github.com/ModelTC/FCPTS.","sentences":["Neural network sparsity has attracted many research interests due to its similarity to biological schemes and high energy efficiency.","However, existing methods depend on long-time training or fine-tuning, which prevents large-scale applications.","Recently, some works focusing on post-training sparsity (PTS) have emerged.","They get rid of the high training cost but usually suffer from distinct accuracy degradation due to neglect of the reasonable sparsity rate at each layer.","Previous methods for finding sparsity rates mainly focus on the training-aware scenario, which usually fails to converge stably under the PTS setting with limited data and much less training cost.","In this paper, we propose a fast and controllable post-training sparsity (FCPTS) framework.","By incorporating a differentiable bridge function and a controllable optimization objective, our method allows for rapid and accurate sparsity allocation learning in minutes, with the added assurance of convergence to a predetermined global sparsity rate.","Equipped with these techniques, we can surpass the state-of-the-art methods by a large margin, e.g., over 30\\% improvement for ResNet-50 on ImageNet under the sparsity rate of 80\\%.","Our plug-and-play code and supplementary materials are open-sourced at https://github.com/ModelTC/FCPTS."],"url":"http://arxiv.org/abs/2405.05808v1"}
{"created":"2024-05-09 14:43:09","title":"NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM","abstract":"Implicit neural representations and neural render- ing have gained increasing attention for bathymetry estimation from sidescan sonar (SSS). These methods incorporate multiple observations of the same place from SSS data to constrain the elevation estimate, converging to a globally-consistent bathymetric model. However, the quality and precision of the bathymetric estimate are limited by the positioning accuracy of the autonomous underwater vehicle (AUV) equipped with the sonar. The global positioning estimate of the AUV relying on dead reckoning (DR) has an unbounded error due to the absence of a geo-reference system like GPS underwater. To address this challenge, we propose in this letter a modern and scalable framework, NeuRSS, for SSS SLAM based on DR and loop closures (LCs) over large timescales, with an elevation prior provided by the bathymetric estimate using neural rendering from SSS. This framework is an iterative procedure that improves localization and bathymetric mapping. Initially, the bathymetry estimated from SSS using the DR estimate, though crude, can provide an important elevation prior in the nonlinear least-squares (NLS) optimization that estimates the relative pose between two loop-closure vertices in a pose graph. Subsequently, the global pose estimate from the SLAM component improves the positioning estimate of the vehicle, thus improving the bathymetry estimation. We validate our localization and mapping approach on two large surveys collected with a surface vessel and an AUV, respectively. We evaluate their localization results against the ground truth and compare the bathymetry estimation against data collected with multibeam echo sounders (MBES).","sentences":["Implicit neural representations and neural render- ing have gained increasing attention for bathymetry estimation from sidescan sonar (SSS).","These methods incorporate multiple observations of the same place from SSS data to constrain the elevation estimate, converging to a globally-consistent bathymetric model.","However, the quality and precision of the bathymetric estimate are limited by the positioning accuracy of the autonomous underwater vehicle (AUV) equipped with the sonar.","The global positioning estimate of the AUV relying on dead reckoning (DR) has an unbounded error due to the absence of a geo-reference system like GPS underwater.","To address this challenge, we propose in this letter a modern and scalable framework, NeuRSS, for SSS SLAM based on DR and loop closures (LCs) over large timescales, with an elevation prior provided by the bathymetric estimate using neural rendering from SSS.","This framework is an iterative procedure that improves localization and bathymetric mapping.","Initially, the bathymetry estimated from SSS using the DR estimate, though crude, can provide an important elevation prior in the nonlinear least-squares (NLS) optimization that estimates the relative pose between two loop-closure vertices in a pose graph.","Subsequently, the global pose estimate from the SLAM component improves the positioning estimate of the vehicle, thus improving the bathymetry estimation.","We validate our localization and mapping approach on two large surveys collected with a surface vessel and an AUV, respectively.","We evaluate their localization results against the ground truth and compare the bathymetry estimation against data collected with multibeam echo sounders (MBES)."],"url":"http://arxiv.org/abs/2405.05807v1"}
{"created":"2024-05-09 14:25:25","title":"Enhancing Suicide Risk Detection on Social Media through Semi-Supervised Deep Label Smoothing","abstract":"Suicide is a prominent issue in society. Unfortunately, many people at risk for suicide do not receive the support required. Barriers to people receiving support include social stigma and lack of access to mental health care. With the popularity of social media, people have turned to online forums, such as Reddit to express their feelings and seek support. This provides the opportunity to support people with the aid of artificial intelligence. Social media posts can be classified, using text classification, to help connect people with professional help. However, these systems fail to account for the inherent uncertainty in classifying mental health conditions. Unlike other areas of healthcare, mental health conditions have no objective measurements of disease often relying on expert opinion. Thus when formulating deep learning problems involving mental health, using hard, binary labels does not accurately represent the true nature of the data. In these settings, where human experts may disagree, fuzzy or soft labels may be more appropriate. The current work introduces a novel label smoothing method which we use to capture any uncertainty within the data. We test our approach on a five-label multi-class classification problem. We show, our semi-supervised deep label smoothing method improves classification accuracy above the existing state of the art. Where existing research reports an accuracy of 43\\% on the Reddit C-SSRS dataset, using empirical experiments to evaluate our novel label smoothing method, we improve upon this existing benchmark to 52\\%. These improvements in model performance have the potential to better support those experiencing mental distress. Future work should explore the use of probabilistic methods in both natural language processing and quantifying contributions of both epistemic and aleatoric uncertainty in noisy datasets.","sentences":["Suicide is a prominent issue in society.","Unfortunately, many people at risk for suicide do not receive the support required.","Barriers to people receiving support include social stigma and lack of access to mental health care.","With the popularity of social media, people have turned to online forums, such as Reddit to express their feelings and seek support.","This provides the opportunity to support people with the aid of artificial intelligence.","Social media posts can be classified, using text classification, to help connect people with professional help.","However, these systems fail to account for the inherent uncertainty in classifying mental health conditions.","Unlike other areas of healthcare, mental health conditions have no objective measurements of disease often relying on expert opinion.","Thus when formulating deep learning problems involving mental health, using hard, binary labels does not accurately represent the true nature of the data.","In these settings, where human experts may disagree, fuzzy or soft labels may be more appropriate.","The current work introduces a novel label smoothing method which we use to capture any uncertainty within the data.","We test our approach on a five-label multi-class classification problem.","We show, our semi-supervised deep label smoothing method improves classification accuracy above the existing state of the art.","Where existing research reports an accuracy of 43\\% on the Reddit C-SSRS dataset, using empirical experiments to evaluate our novel label smoothing method, we improve upon this existing benchmark to 52\\%.","These improvements in model performance have the potential to better support those experiencing mental distress.","Future work should explore the use of probabilistic methods in both natural language processing and quantifying contributions of both epistemic and aleatoric uncertainty in noisy datasets."],"url":"http://arxiv.org/abs/2405.05795v1"}
{"created":"2024-05-09 14:17:26","title":"RoboHop: Segment-based Topological Map Representation for Open-World Visual Navigation","abstract":"Mapping is crucial for spatial reasoning, planning and robot navigation. Existing approaches range from metric, which require precise geometry-based optimization, to purely topological, where image-as-node based graphs lack explicit object-level reasoning and interconnectivity. In this paper, we propose a novel topological representation of an environment based on \"image segments\", which are semantically meaningful and open-vocabulary queryable, conferring several advantages over previous works based on pixel-level features. Unlike 3D scene graphs, we create a purely topological graph with segments as nodes, where edges are formed by a) associating segment-level descriptors between pairs of consecutive images and b) connecting neighboring segments within an image using their pixel centroids. This unveils a \"continuous sense of a place\", defined by inter-image persistence of segments along with their intra-image neighbours. It further enables us to represent and update segment-level descriptors through neighborhood aggregation using graph convolution layers, which improves robot localization based on segment-level retrieval. Using real-world data, we show how our proposed map representation can be used to i) generate navigation plans in the form of \"hops over segments\" and ii) search for target objects using natural language queries describing spatial relations of objects. Furthermore, we quantitatively analyze data association at the segment level, which underpins inter-image connectivity during mapping and segment-level localization when revisiting the same place. Finally, we show preliminary trials on segment-level `hopping' based zero-shot real-world navigation. Project page with supplementary details: oravus.github.io/RoboHop/","sentences":["Mapping is crucial for spatial reasoning, planning and robot navigation.","Existing approaches range from metric, which require precise geometry-based optimization, to purely topological, where image-as-node based graphs lack explicit object-level reasoning and interconnectivity.","In this paper, we propose a novel topological representation of an environment based on \"image segments\", which are semantically meaningful and open-vocabulary queryable, conferring several advantages over previous works based on pixel-level features.","Unlike 3D scene graphs, we create a purely topological graph with segments as nodes, where edges are formed by a) associating segment-level descriptors between pairs of consecutive images and b) connecting neighboring segments within an image using their pixel centroids.","This unveils a \"continuous sense of a place\", defined by inter-image persistence of segments along with their intra-image neighbours.","It further enables us to represent and update segment-level descriptors through neighborhood aggregation using graph convolution layers, which improves robot localization based on segment-level retrieval.","Using real-world data, we show how our proposed map representation can be used to i) generate navigation plans in the form of \"hops over segments\" and ii) search for target objects using natural language queries describing spatial relations of objects.","Furthermore, we quantitatively analyze data association at the segment level, which underpins inter-image connectivity during mapping and segment-level localization when revisiting the same place.","Finally, we show preliminary trials on segment-level `hopping' based zero-shot real-world navigation.","Project page with supplementary details: oravus.github.io/RoboHop/"],"url":"http://arxiv.org/abs/2405.05792v1"}
{"created":"2024-05-09 14:15:00","title":"A Robust eLORETA Technique for Localization of Brain Sources in the Presence of Forward Model Uncertainties","abstract":"In this paper, we present a robust version of the well-known exact low-resolution electromagnetic tomography (eLORETA) technique, named ReLORETA, to localize brain sources in the presence of different forward model uncertainties. Methods: We first assume that the true lead field matrix is a transformation of the existing lead field matrix distorted by uncertainties and propose an iterative approach to estimate this transformation accurately. Major sources of the forward model uncertainties, including differences in geometry, conductivity, and source space resolution between the real and simulated head models, and misaligned electrode positions, are then simulated to test the proposed method. Results: ReLORETA and eLORETA are applied to simulated focal sources in different regions of the brain and the presence of various noise levels as well as real data from a patient with focal epilepsy. The results show that ReLORETA is considerably more robust and accurate than eLORETA in all cases. Conclusion: Having successfully dealt with the forward model uncertainties, ReLORETA proved to be a promising method for real-world clinical applications. Significance: eLORETA is one of the localization techniques that could be used to study brain activity for medical applications such as determining the epileptogenic zone in patients with medically refractory epilepsy. However, the major limitation of eLORETA is sensitivity to the uncertainties in the forward model. Since this problem can substantially undermine its performance in real-world applications where the exact lead field matrix is unknown, developing a more robust method capable of dealing with these uncertainties is of significant interest.","sentences":["In this paper, we present a robust version of the well-known exact low-resolution electromagnetic tomography (eLORETA) technique, named ReLORETA, to localize brain sources in the presence of different forward model uncertainties.","Methods: We first assume that the true lead field matrix is a transformation of the existing lead field matrix distorted by uncertainties and propose an iterative approach to estimate this transformation accurately.","Major sources of the forward model uncertainties, including differences in geometry, conductivity, and source space resolution between the real and simulated head models, and misaligned electrode positions, are then simulated to test the proposed method.","Results: ReLORETA and eLORETA are applied to simulated focal sources in different regions of the brain and the presence of various noise levels as well as real data from a patient with focal epilepsy.","The results show that ReLORETA is considerably more robust and accurate than eLORETA in all cases.","Conclusion: Having successfully dealt with the forward model uncertainties, ReLORETA proved to be a promising method for real-world clinical applications.","Significance: eLORETA is one of the localization techniques that could be used to study brain activity for medical applications such as determining the epileptogenic zone in patients with medically refractory epilepsy.","However, the major limitation of eLORETA is sensitivity to the uncertainties in the forward model.","Since this problem can substantially undermine its performance in real-world applications where the exact lead field matrix is unknown, developing a more robust method capable of dealing with these uncertainties is of significant interest."],"url":"http://arxiv.org/abs/2405.05790v1"}
{"created":"2024-05-09 14:12:41","title":"High-Performance Privacy-Preserving Matrix Completion for Trajectory Recovery","abstract":"Matrix completion has important applications in trajectory recovery and mobile social networks. However, sending raw data containing personal, sensitive information to cloud computing nodes may lead to privacy exposure issue.The privacy-preserving matrix completion is a useful approach to perform matrix completion while preserving privacy. In this paper, we propose a high-performance method for privacy-preserving matrix completion. First,we use a lightweight encryption scheme to encrypt the raw data and then perform matrix completion using alternating direction method of multipliers (ADMM). Then,the complemented matrix is decrypted and compared with the original matrix to calculate the error. This method has faster speed with higher accuracy. The results of numerical experiments reveal that the proposed method is faster than other algorithms.","sentences":["Matrix completion has important applications in trajectory recovery and mobile social networks.","However, sending raw data containing personal, sensitive information to cloud computing nodes may lead to privacy exposure issue.","The privacy-preserving matrix completion is a useful approach to perform matrix completion while preserving privacy.","In this paper, we propose a high-performance method for privacy-preserving matrix completion.","First,we use a lightweight encryption scheme to encrypt the raw data and then perform matrix completion using alternating direction method of multipliers (ADMM).","Then,the complemented matrix is decrypted and compared with the original matrix to calculate the error.","This method has faster speed with higher accuracy.","The results of numerical experiments reveal that the proposed method is faster than other algorithms."],"url":"http://arxiv.org/abs/2405.05789v1"}
{"created":"2024-05-09 14:09:36","title":"FusionTransNet for Smart Urban Mobility: Spatiotemporal Traffic Forecasting Through Multimodal Network Integration","abstract":"This study develops FusionTransNet, a framework designed for Origin-Destination (OD) flow predictions within smart and multimodal urban transportation systems. Urban transportation complexity arises from the spatiotemporal interactions among various traffic modes. Motivated by analyzing multimodal data from Shenzhen, a framework that can dissect complicated spatiotemporal interactions between these modes, from the microscopic local level to the macroscopic city-wide perspective, is essential. The framework contains three core components: the Intra-modal Learning Module, the Inter-modal Learning Module, and the Prediction Decoder. The Intra-modal Learning Module is designed to analyze spatial dependencies within individual transportation modes, facilitating a granular understanding of single-mode spatiotemporal dynamics. The Inter-modal Learning Module extends this analysis, integrating data across different modes to uncover cross-modal interdependencies, by breaking down the interactions at both local and global scales. Finally, the Prediction Decoder synthesizes insights from the preceding modules to generate accurate OD flow predictions, translating complex multimodal interactions into forecasts. Empirical evaluations conducted in metropolitan contexts, including Shenzhen and New York, demonstrate FusionTransNet's superior predictive accuracy compared to existing state-of-the-art methods. The implication of this study extends beyond urban transportation, as the method for transferring information across different spatiotemporal graphs at both local and global scales can be instrumental in other spatial systems, such as supply chain logistics and epidemics spreading.","sentences":["This study develops FusionTransNet, a framework designed for Origin-Destination (OD) flow predictions within smart and multimodal urban transportation systems.","Urban transportation complexity arises from the spatiotemporal interactions among various traffic modes.","Motivated by analyzing multimodal data from Shenzhen, a framework that can dissect complicated spatiotemporal interactions between these modes, from the microscopic local level to the macroscopic city-wide perspective, is essential.","The framework contains three core components: the Intra-modal Learning Module, the Inter-modal Learning Module, and the Prediction Decoder.","The Intra-modal Learning Module is designed to analyze spatial dependencies within individual transportation modes, facilitating a granular understanding of single-mode spatiotemporal dynamics.","The Inter-modal Learning Module extends this analysis, integrating data across different modes to uncover cross-modal interdependencies, by breaking down the interactions at both local and global scales.","Finally, the Prediction Decoder synthesizes insights from the preceding modules to generate accurate OD flow predictions, translating complex multimodal interactions into forecasts.","Empirical evaluations conducted in metropolitan contexts, including Shenzhen and New York, demonstrate FusionTransNet's superior predictive accuracy compared to existing state-of-the-art methods.","The implication of this study extends beyond urban transportation, as the method for transferring information across different spatiotemporal graphs at both local and global scales can be instrumental in other spatial systems, such as supply chain logistics and epidemics spreading."],"url":"http://arxiv.org/abs/2405.05786v1"}
{"created":"2024-05-09 14:03:52","title":"Link Stealing Attacks Against Inductive Graph Neural Networks","abstract":"A graph neural network (GNN) is a type of neural network that is specifically designed to process graph-structured data. Typically, GNNs can be implemented in two settings, including the transductive setting and the inductive setting. In the transductive setting, the trained model can only predict the labels of nodes that were observed at the training time. In the inductive setting, the trained model can be generalized to new nodes/graphs. Due to its flexibility, the inductive setting is the most popular GNN setting at the moment. Previous work has shown that transductive GNNs are vulnerable to a series of privacy attacks. However, a comprehensive privacy analysis of inductive GNN models is still missing. This paper fills the gap by conducting a systematic privacy analysis of inductive GNNs through the lens of link stealing attacks, one of the most popular attacks that are specifically designed for GNNs. We propose two types of link stealing attacks, i.e., posterior-only attacks and combined attacks. We define threat models of the posterior-only attacks with respect to node topology and the combined attacks by considering combinations of posteriors, node attributes, and graph features. Extensive evaluation on six real-world datasets demonstrates that inductive GNNs leak rich information that enables link stealing attacks with advantageous properties. Even attacks with no knowledge about graph structures can be effective. We also show that our attacks are robust to different node similarities and different graph features. As a counterpart, we investigate two possible defenses and discover they are ineffective against our attacks, which calls for more effective defenses.","sentences":["A graph neural network (GNN) is a type of neural network that is specifically designed to process graph-structured data.","Typically, GNNs can be implemented in two settings, including the transductive setting and the inductive setting.","In the transductive setting, the trained model can only predict the labels of nodes that were observed at the training time.","In the inductive setting, the trained model can be generalized to new nodes/graphs.","Due to its flexibility, the inductive setting is the most popular GNN setting at the moment.","Previous work has shown that transductive GNNs are vulnerable to a series of privacy attacks.","However, a comprehensive privacy analysis of inductive GNN models is still missing.","This paper fills the gap by conducting a systematic privacy analysis of inductive GNNs through the lens of link stealing attacks, one of the most popular attacks that are specifically designed for GNNs.","We propose two types of link stealing attacks, i.e., posterior-only attacks and combined attacks.","We define threat models of the posterior-only attacks with respect to node topology and the combined attacks by considering combinations of posteriors, node attributes, and graph features.","Extensive evaluation on six real-world datasets demonstrates that inductive GNNs leak rich information that enables link stealing attacks with advantageous properties.","Even attacks with no knowledge about graph structures can be effective.","We also show that our attacks are robust to different node similarities and different graph features.","As a counterpart, we investigate two possible defenses and discover they are ineffective against our attacks, which calls for more effective defenses."],"url":"http://arxiv.org/abs/2405.05784v1"}
{"created":"2024-05-09 13:57:28","title":"Neural Network Learning of Black-Scholes Equation for Option Pricing","abstract":"One of the most discussed problems in the financial world is stock option pricing. The Black-Scholes Equation is a Parabolic Partial Differential Equation which provides an option pricing model. The present work proposes an approach based on Neural Networks to solve the Black-Scholes Equations. Real-world data from the stock options market were used as the initial boundary to solve the Black-Scholes Equation. In particular, times series of call options prices of Brazilian companies Petrobras and Vale were employed. The results indicate that the network can learn to solve the Black-Sholes Equation for a specific real-world stock options time series. The experimental results showed that the Neural network option pricing based on the Black-Sholes Equation solution can reach an option pricing forecasting more accurate than the traditional Black-Sholes analytical solutions. The experimental results making it possible to use this methodology to make short-term call option price forecasts in options markets.","sentences":["One of the most discussed problems in the financial world is stock option pricing.","The Black-Scholes Equation is a Parabolic Partial Differential Equation which provides an option pricing model.","The present work proposes an approach based on Neural Networks to solve the Black-Scholes Equations.","Real-world data from the stock options market were used as the initial boundary to solve the Black-Scholes Equation.","In particular, times series of call options prices of Brazilian companies Petrobras and Vale were employed.","The results indicate that the network can learn to solve the Black-Sholes Equation for a specific real-world stock options time series.","The experimental results showed that the Neural network option pricing based on the Black-Sholes Equation solution can reach an option pricing forecasting more accurate than the traditional Black-Sholes analytical solutions.","The experimental results making it possible to use this methodology to make short-term call option price forecasts in options markets."],"url":"http://arxiv.org/abs/2405.05780v1"}
{"created":"2024-05-09 13:54:22","title":"Towards a More Inclusive AI: Progress and Perspectives in Large Language Model Training for the S\u00e1mi Language","abstract":"S\\'ami, an indigenous language group comprising multiple languages, faces digital marginalization due to the limited availability of data and sophisticated language models designed for its linguistic intricacies. This work focuses on increasing technological participation for the S\\'ami language. We draw the attention of the ML community towards the language modeling problem of Ultra Low Resource (ULR) languages. ULR languages are those for which the amount of available textual resources is very low, and the speaker count for them is also very low. ULRLs are also not supported by mainstream Large Language Models (LLMs) like ChatGPT, due to which gathering artificial training data for them becomes even more challenging. Mainstream AI foundational model development has given less attention to this category of languages. Generally, these languages have very few speakers, making it hard to find them. However, it is important to develop foundational models for these ULR languages to promote inclusion and the tangible abilities and impact of LLMs. To this end, we have compiled the available S\\'ami language resources from the web to create a clean dataset for training language models. In order to study the behavior of modern LLM models with ULR languages (S\\'ami), we have experimented with different kinds of LLMs, mainly at the order of $\\sim$ seven billion parameters. We have also explored the effect of multilingual LLM training for ULRLs. We found that the decoder-only models under a sequential multilingual training scenario perform better than joint multilingual training, whereas multilingual training with high semantic overlap, in general, performs better than training from scratch.This is the first study on the S\\'ami language for adapting non-statistical language models that use the latest developments in the field of natural language processing (NLP).","sentences":["S\\'ami, an indigenous language group comprising multiple languages, faces digital marginalization due to the limited availability of data and sophisticated language models designed for its linguistic intricacies.","This work focuses on increasing technological participation for the S\\'ami language.","We draw the attention of the ML community towards the language modeling problem of Ultra Low Resource (ULR) languages.","ULR languages are those for which the amount of available textual resources is very low, and the speaker count for them is also very low.","ULRLs are also not supported by mainstream Large Language Models (LLMs) like ChatGPT, due to which gathering artificial training data for them becomes even more challenging.","Mainstream AI foundational model development has given less attention to this category of languages.","Generally, these languages have very few speakers, making it hard to find them.","However, it is important to develop foundational models for these ULR languages to promote inclusion and the tangible abilities and impact of LLMs.","To this end, we have compiled the available S\\'ami language resources from the web to create a clean dataset for training language models.","In order to study the behavior of modern LLM models with ULR languages (S\\'ami), we have experimented with different kinds of LLMs, mainly at the order of $\\sim$ seven billion parameters.","We have also explored the effect of multilingual LLM training for ULRLs.","We found that the decoder-only models under a sequential multilingual training scenario perform better than joint multilingual training, whereas multilingual training with high semantic overlap, in general, performs better than training from scratch.","This is the first study on the S\\'ami language for adapting non-statistical language models that use the latest developments in the field of natural language processing (NLP)."],"url":"http://arxiv.org/abs/2405.05777v1"}
{"created":"2024-05-09 13:45:04","title":"Exploring Text-Guided Single Image Editing for Remote Sensing Images","abstract":"Artificial Intelligence Generative Content (AIGC) technologies have significantly influenced the remote sensing domain, particularly in the realm of image generation. However, remote sensing image editing, an equally vital research area, has not garnered sufficient attention. Different from text-guided editing in natural images, which relies on extensive text-image paired data for semantic correlation, the application scenarios of remote sensing image editing are often extreme, such as forest on fire, so it is difficult to obtain sufficient paired samples. At the same time, the lack of remote sensing semantics and the ambiguity of text also restrict the further application of image editing in remote sensing field. To solve above problems, this letter proposes a diffusion based method to fulfill stable and controllable remote sensing image editing with text guidance. Our method avoids the use of a large number of paired image, and can achieve good image editing results using only a single image. The quantitative evaluation system including CLIP score and subjective evaluation metrics shows that our method has better editing effect on remote sensing images than the existing image editing model.","sentences":["Artificial Intelligence Generative Content (AIGC) technologies have significantly influenced the remote sensing domain, particularly in the realm of image generation.","However, remote sensing image editing, an equally vital research area, has not garnered sufficient attention.","Different from text-guided editing in natural images, which relies on extensive text-image paired data for semantic correlation, the application scenarios of remote sensing image editing are often extreme, such as forest on fire, so it is difficult to obtain sufficient paired samples.","At the same time, the lack of remote sensing semantics and the ambiguity of text also restrict the further application of image editing in remote sensing field.","To solve above problems, this letter proposes a diffusion based method to fulfill stable and controllable remote sensing image editing with text guidance.","Our method avoids the use of a large number of paired image, and can achieve good image editing results using only a single image.","The quantitative evaluation system including CLIP score and subjective evaluation metrics shows that our method has better editing effect on remote sensing images than the existing image editing model."],"url":"http://arxiv.org/abs/2405.05769v1"}
{"created":"2024-05-09 13:44:04","title":"Large Language Model-Aided Evolutionary Search for Constrained Multiobjective Optimization","abstract":"Evolutionary algorithms excel in solving complex optimization problems, especially those with multiple objectives. However, their stochastic nature can sometimes hinder rapid convergence to the global optima, particularly in scenarios involving constraints. In this study, we employ a large language model (LLM) to enhance evolutionary search for solving constrained multi-objective optimization problems. Our aim is to speed up the convergence of the evolutionary population. To achieve this, we finetune the LLM through tailored prompt engineering, integrating information concerning both objective values and constraint violations of solutions. This process enables the LLM to grasp the relationship between well-performing and poorly performing solutions based on the provided input data. Solution's quality is assessed based on their constraint violations and objective-based performance. By leveraging the refined LLM, it can be used as a search operator to generate superior-quality solutions. Experimental evaluations across various test benchmarks illustrate that LLM-aided evolutionary search can significantly accelerate the population's convergence speed and stands out competitively against cutting-edge evolutionary algorithms.","sentences":["Evolutionary algorithms excel in solving complex optimization problems, especially those with multiple objectives.","However, their stochastic nature can sometimes hinder rapid convergence to the global optima, particularly in scenarios involving constraints.","In this study, we employ a large language model (LLM) to enhance evolutionary search for solving constrained multi-objective optimization problems.","Our aim is to speed up the convergence of the evolutionary population.","To achieve this, we finetune the LLM through tailored prompt engineering, integrating information concerning both objective values and constraint violations of solutions.","This process enables the LLM to grasp the relationship between well-performing and poorly performing solutions based on the provided input data.","Solution's quality is assessed based on their constraint violations and objective-based performance.","By leveraging the refined LLM, it can be used as a search operator to generate superior-quality solutions.","Experimental evaluations across various test benchmarks illustrate that LLM-aided evolutionary search can significantly accelerate the population's convergence speed and stands out competitively against cutting-edge evolutionary algorithms."],"url":"http://arxiv.org/abs/2405.05767v1"}
{"created":"2024-05-09 13:37:18","title":"DP-MDM: Detail-Preserving MR Reconstruction via Multiple Diffusion Models","abstract":"Detail features of magnetic resonance images play a cru-cial role in accurate medical diagnosis and treatment, as they capture subtle changes that pose challenges for doc-tors when performing precise judgments. However, the widely utilized naive diffusion model has limitations, as it fails to accurately capture more intricate details. To en-hance the quality of MRI reconstruction, we propose a comprehensive detail-preserving reconstruction method using multiple diffusion models to extract structure and detail features in k-space domain instead of image do-main. Moreover, virtual binary modal masks are utilized to refine the range of values in k-space data through highly adaptive center windows, which allows the model to focus its attention more efficiently. Last but not least, an inverted pyramid structure is employed, where the top-down image information gradually decreases, ena-bling a cascade representation. The framework effective-ly represents multi-scale sampled data, taking into ac-count the sparsity of the inverted pyramid architecture, and utilizes cascade training data distribution to repre-sent multi-scale data. Through a step-by-step refinement approach, the method refines the approximation of de-tails. Finally, the proposed method was evaluated by con-ducting experiments on clinical and public datasets. The results demonstrate that the proposed method outper-forms other methods.","sentences":["Detail features of magnetic resonance images play a cru-cial role in accurate medical diagnosis and treatment, as they capture subtle changes that pose challenges for doc-tors when performing precise judgments.","However, the widely utilized naive diffusion model has limitations, as it fails to accurately capture more intricate details.","To en-hance the quality of MRI reconstruction, we propose a comprehensive detail-preserving reconstruction method using multiple diffusion models to extract structure and detail features in k-space domain instead of image do-main.","Moreover, virtual binary modal masks are utilized to refine the range of values in k-space data through highly adaptive center windows, which allows the model to focus its attention more efficiently.","Last but not least, an inverted pyramid structure is employed, where the top-down image information gradually decreases, ena-bling a cascade representation.","The framework effective-ly represents multi-scale sampled data, taking into ac-count the sparsity of the inverted pyramid architecture, and utilizes cascade training data distribution to repre-sent multi-scale data.","Through a step-by-step refinement approach, the method refines the approximation of de-tails.","Finally, the proposed method was evaluated by con-ducting experiments on clinical and public datasets.","The results demonstrate that the proposed method outper-forms other methods."],"url":"http://arxiv.org/abs/2405.05763v1"}
{"created":"2024-05-09 13:27:22","title":"Exploring the Potential of Human-LLM Synergy in Advancing Qualitative Analysis: A Case Study on Mental-Illness Stigma","abstract":"Qualitative analysis is a challenging, yet crucial aspect of advancing research in the field of Human-Computer Interaction (HCI). Recent studies show that large language models (LLMs) can perform qualitative coding within existing schemes, but their potential for collaborative human-LLM discovery and new insight generation in qualitative analysis is still underexplored. To bridge this gap and advance qualitative analysis by harnessing the power of LLMs, we propose CHALET, a novel methodology that leverages the human-LLM collaboration paradigm to facilitate conceptualization and empower qualitative research. The CHALET approach involves LLM-supported data collection, performing both human and LLM deductive coding to identify disagreements, and performing collaborative inductive coding on these disagreement cases to derive new conceptual insights. We validated the effectiveness of CHALET through its application to the attribution model of mental-illness stigma, uncovering implicit stigmatization themes on cognitive, emotional and behavioral dimensions. We discuss the implications for future research, methodology, and the transdisciplinary opportunities CHALET presents for the HCI community and beyond.","sentences":["Qualitative analysis is a challenging, yet crucial aspect of advancing research in the field of Human-Computer Interaction (HCI).","Recent studies show that large language models (LLMs) can perform qualitative coding within existing schemes, but their potential for collaborative human-LLM discovery and new insight generation in qualitative analysis is still underexplored.","To bridge this gap and advance qualitative analysis by harnessing the power of LLMs, we propose CHALET, a novel methodology that leverages the human-LLM collaboration paradigm to facilitate conceptualization and empower qualitative research.","The CHALET approach involves LLM-supported data collection, performing both human and LLM deductive coding to identify disagreements, and performing collaborative inductive coding on these disagreement cases to derive new conceptual insights.","We validated the effectiveness of CHALET through its application to the attribution model of mental-illness stigma, uncovering implicit stigmatization themes on cognitive, emotional and behavioral dimensions.","We discuss the implications for future research, methodology, and the transdisciplinary opportunities CHALET presents for the HCI community and beyond."],"url":"http://arxiv.org/abs/2405.05758v1"}
{"created":"2024-05-09 13:23:09","title":"Design and Implementation of Energy-Efficient Wireless Tire Sensing System with Delay Analysis for Intelligent Vehicles","abstract":"The growing prevalence of Internet of Things (IoT) technologies has led to a rise in the popularity of intelligent vehicles that incorporate a range of sensors to monitor various aspects, such as driving speed, fuel usage, distance proximity and tire anomalies. Nowadays, real-time tire sensing systems play important roles for intelligent vehicles in increasing mileage, reducing fuel consumption, improving driving safety, and reducing the potential for traffic accidents. However, the current tire sensing system drains a significant vehicle' energy and lacks effective collection of sensing data, which may not guarantee the immediacy of driving safety. Thus, this paper designs an energy-efficient wireless tire sensing system (WTSS), which leverages energy-saving techniques to significantly reduce power consumption while ensuring data retrieval delays during real-time monitoring. Additionally, we mathematically analyze the worst-case transmission delay and sensor reception ratio of the system to ensure the immediacy based on the collision probabilities of sensor transmissions. This system has been implemented and verified by the simulation and field train experiments. These results show that the proposed scheme provides enhanced performance in energy efficiency up to 76.5% in average and identifies the worst transmission delay accurately.","sentences":["The growing prevalence of Internet of Things (IoT) technologies has led to a rise in the popularity of intelligent vehicles that incorporate a range of sensors to monitor various aspects, such as driving speed, fuel usage, distance proximity and tire anomalies.","Nowadays, real-time tire sensing systems play important roles for intelligent vehicles in increasing mileage, reducing fuel consumption, improving driving safety, and reducing the potential for traffic accidents.","However, the current tire sensing system drains a significant vehicle' energy and lacks effective collection of sensing data, which may not guarantee the immediacy of driving safety.","Thus, this paper designs an energy-efficient wireless tire sensing system (WTSS), which leverages energy-saving techniques to significantly reduce power consumption while ensuring data retrieval delays during real-time monitoring.","Additionally, we mathematically analyze the worst-case transmission delay and sensor reception ratio of the system to ensure the immediacy based on the collision probabilities of sensor transmissions.","This system has been implemented and verified by the simulation and field train experiments.","These results show that the proposed scheme provides enhanced performance in energy efficiency up to 76.5% in average and identifies the worst transmission delay accurately."],"url":"http://arxiv.org/abs/2405.05757v1"}
{"created":"2024-05-09 13:14:06","title":"NeRFFaceSpeech: One-shot Audio-diven 3D Talking Head Synthesis via Generative Prior","abstract":"Audio-driven talking head generation is advancing from 2D to 3D content. Notably, Neural Radiance Field (NeRF) is in the spotlight as a means to synthesize high-quality 3D talking head outputs. Unfortunately, this NeRF-based approach typically requires a large number of paired audio-visual data for each identity, thereby limiting the scalability of the method. Although there have been attempts to generate audio-driven 3D talking head animations with a single image, the results are often unsatisfactory due to insufficient information on obscured regions in the image. In this paper, we mainly focus on addressing the overlooked aspect of 3D consistency in the one-shot, audio-driven domain, where facial animations are synthesized primarily in front-facing perspectives. We propose a novel method, NeRFFaceSpeech, which enables to produce high-quality 3D-aware talking head. Using prior knowledge of generative models combined with NeRF, our method can craft a 3D-consistent facial feature space corresponding to a single image. Our spatial synchronization method employs audio-correlated vertex dynamics of a parametric face model to transform static image features into dynamic visuals through ray deformation, ensuring realistic 3D facial motion. Moreover, we introduce LipaintNet that can replenish the lacking information in the inner-mouth area, which can not be obtained from a given single image. The network is trained in a self-supervised manner by utilizing the generative capabilities without additional data. The comprehensive experiments demonstrate the superiority of our method in generating audio-driven talking heads from a single image with enhanced 3D consistency compared to previous approaches. In addition, we introduce a quantitative way of measuring the robustness of a model against pose changes for the first time, which has been possible only qualitatively.","sentences":["Audio-driven talking head generation is advancing from 2D to 3D content.","Notably, Neural Radiance Field (NeRF) is in the spotlight as a means to synthesize high-quality 3D talking head outputs.","Unfortunately, this NeRF-based approach typically requires a large number of paired audio-visual data for each identity, thereby limiting the scalability of the method.","Although there have been attempts to generate audio-driven 3D talking head animations with a single image, the results are often unsatisfactory due to insufficient information on obscured regions in the image.","In this paper, we mainly focus on addressing the overlooked aspect of 3D consistency in the one-shot, audio-driven domain, where facial animations are synthesized primarily in front-facing perspectives.","We propose a novel method, NeRFFaceSpeech, which enables to produce high-quality 3D-aware talking head.","Using prior knowledge of generative models combined with NeRF, our method can craft a 3D-consistent facial feature space corresponding to a single image.","Our spatial synchronization method employs audio-correlated vertex dynamics of a parametric face model to transform static image features into dynamic visuals through ray deformation, ensuring realistic 3D facial motion.","Moreover, we introduce LipaintNet that can replenish the lacking information in the inner-mouth area, which can not be obtained from a given single image.","The network is trained in a self-supervised manner by utilizing the generative capabilities without additional data.","The comprehensive experiments demonstrate the superiority of our method in generating audio-driven talking heads from a single image with enhanced 3D consistency compared to previous approaches.","In addition, we introduce a quantitative way of measuring the robustness of a model against pose changes for the first time, which has been possible only qualitatively."],"url":"http://arxiv.org/abs/2405.05749v1"}
{"created":"2024-05-09 12:52:22","title":"Optimal Baseline Corrections for Off-Policy Contextual Bandits","abstract":"The off-policy learning paradigm allows for recommender systems and general ranking applications to be framed as decision-making problems, where we aim to learn decision policies that optimize an unbiased offline estimate of an online reward metric. With unbiasedness comes potentially high variance, and prevalent methods exist to reduce estimation variance. These methods typically make use of control variates, either additive (i.e., baseline corrections or doubly robust methods) or multiplicative (i.e., self-normalisation). Our work unifies these approaches by proposing a single framework built on their equivalence in learning scenarios. The foundation of our framework is the derivation of an equivalent baseline correction for all of the existing control variates. Consequently, our framework enables us to characterize the variance-optimal unbiased estimator and provide a closed-form solution for it. This optimal estimator brings significantly improved performance in both evaluation and learning, and minimizes data requirements. Empirical observations corroborate our theoretical findings.","sentences":["The off-policy learning paradigm allows for recommender systems and general ranking applications to be framed as decision-making problems, where we aim to learn decision policies that optimize an unbiased offline estimate of an online reward metric.","With unbiasedness comes potentially high variance, and prevalent methods exist to reduce estimation variance.","These methods typically make use of control variates, either additive (i.e., baseline corrections or doubly robust methods) or multiplicative (i.e., self-normalisation).","Our work unifies these approaches by proposing a single framework built on their equivalence in learning scenarios.","The foundation of our framework is the derivation of an equivalent baseline correction for all of the existing control variates.","Consequently, our framework enables us to characterize the variance-optimal unbiased estimator and provide a closed-form solution for it.","This optimal estimator brings significantly improved performance in both evaluation and learning, and minimizes data requirements.","Empirical observations corroborate our theoretical findings."],"url":"http://arxiv.org/abs/2405.05736v1"}
{"created":"2024-05-09 12:35:57","title":"Private Online Community Detection for Censored Block Models","abstract":"We study the private online change detection problem for dynamic communities, using a censored block model (CBM). Focusing on the notion of edge differential privacy (DP), we seek to understand the fundamental tradeoffs between the privacy budget, detection delay, and exact community recovery of community labels. We establish the theoretical lower bound on the delay in detecting changes privately and propose an algorithm capable of identifying changes in the community structure, while maintaining user privacy. Further, we provide theoretical guarantees for the effectiveness of our proposed method by showing necessary and sufficient conditions on change detection and exact recovery under edge DP. Simulation and real data examples are provided to validate the proposed method.","sentences":["We study the private online change detection problem for dynamic communities, using a censored block model (CBM).","Focusing on the notion of edge differential privacy (DP), we seek to understand the fundamental tradeoffs between the privacy budget, detection delay, and exact community recovery of community labels.","We establish the theoretical lower bound on the delay in detecting changes privately and propose an algorithm capable of identifying changes in the community structure, while maintaining user privacy.","Further, we provide theoretical guarantees for the effectiveness of our proposed method by showing necessary and sufficient conditions on change detection and exact recovery under edge DP.","Simulation and real data examples are provided to validate the proposed method."],"url":"http://arxiv.org/abs/2405.05724v1"}
{"created":"2024-05-09 12:34:34","title":"A Newton Method for Hausdorff Approximations of the Pareto Front within Multi-objective Evolutionary Algorithms","abstract":"A common goal in evolutionary multi-objective optimization is to find suitable finite-size approximations of the Pareto front of a given multi-objective optimization problem. While many multi-objective evolutionary algorithms have proven to be very efficient in finding good Pareto front approximations, they may need quite a few resources or may even fail to obtain optimal or nearly approximations. Hereby, optimality is implicitly defined by the chosen performance indicator. In this work, we propose a set-based Newton method for Hausdorff approximations of the Pareto front to be used within multi-objective evolutionary algorithms. To this end, we first generalize the previously proposed Newton step for the performance indicator for the treatment of constrained problems for general reference sets. To approximate the target Pareto front, we propose a particular strategy for generating the reference set that utilizes the data gathered by the evolutionary algorithm during its run. Finally, we show the benefit of the Newton method as a post-processing step on several benchmark test functions and different base evolutionary algorithms.","sentences":["A common goal in evolutionary multi-objective optimization is to find suitable finite-size approximations of the Pareto front of a given multi-objective optimization problem.","While many multi-objective evolutionary algorithms have proven to be very efficient in finding good Pareto front approximations, they may need quite a few resources or may even fail to obtain optimal or nearly approximations.","Hereby, optimality is implicitly defined by the chosen performance indicator.","In this work, we propose a set-based Newton method for Hausdorff approximations of the Pareto front to be used within multi-objective evolutionary algorithms.","To this end, we first generalize the previously proposed Newton step for the performance indicator for the treatment of constrained problems for general reference sets.","To approximate the target Pareto front, we propose a particular strategy for generating the reference set that utilizes the data gathered by the evolutionary algorithm during its run.","Finally, we show the benefit of the Newton method as a post-processing step on several benchmark test functions and different base evolutionary algorithms."],"url":"http://arxiv.org/abs/2405.05721v1"}
{"created":"2024-05-09 12:03:38","title":"Detecting Statements in Text: A Domain-Agnostic Few-Shot Solution","abstract":"Many tasks related to Computational Social Science and Web Content Analysis involve classifying pieces of text based on the claims they contain. State-of-the-art approaches usually involve fine-tuning models on large annotated datasets, which are costly to produce. In light of this, we propose and release a qualitative and versatile few-shot learning methodology as a common paradigm for any claim-based textual classification task. This methodology involves defining the classes as arbitrarily sophisticated taxonomies of claims, and using Natural Language Inference models to obtain the textual entailment between these and a corpus of interest. The performance of these models is then boosted by annotating a minimal sample of data points, dynamically sampled using the well-established statistical heuristic of Probabilistic Bisection. We illustrate this methodology in the context of three tasks: climate change contrarianism detection, topic/stance classification and depression-relates symptoms detection. This approach rivals traditional pre-train/fine-tune approaches while drastically reducing the need for data annotation.","sentences":["Many tasks related to Computational Social Science and Web Content Analysis involve classifying pieces of text based on the claims they contain.","State-of-the-art approaches usually involve fine-tuning models on large annotated datasets, which are costly to produce.","In light of this, we propose and release a qualitative and versatile few-shot learning methodology as a common paradigm for any claim-based textual classification task.","This methodology involves defining the classes as arbitrarily sophisticated taxonomies of claims, and using Natural Language Inference models to obtain the textual entailment between these and a corpus of interest.","The performance of these models is then boosted by annotating a minimal sample of data points, dynamically sampled using the well-established statistical heuristic of Probabilistic Bisection.","We illustrate this methodology in the context of three tasks: climate change contrarianism detection, topic/stance classification and depression-relates symptoms detection.","This approach rivals traditional pre-train/fine-tune approaches while drastically reducing the need for data annotation."],"url":"http://arxiv.org/abs/2405.05705v1"}
{"created":"2024-05-09 11:38:23","title":"Evaluating Dialect Robustness of Language Models via Conversation Understanding","abstract":"With an evergrowing number of LLMs reporting superlative performance for English, their ability to perform equitably for different dialects of English (i.e., dialect robustness) needs to be ascertained. Specifically, we use English language (US English or Indian English) conversations between humans who play the word-guessing game of `taboo'. We formulate two evaluative tasks: target word prediction (TWP) (i.e.predict the masked target word in a conversation) and target word selection (TWS) (i.e., select the most likely masked target word in a conversation, from among a set of candidate words). Extending MD3, an existing dialectic dataset of taboo-playing conversations, we introduce M-MD3, a target-word-masked version of MD3 with the USEng and IndEng subsets. We add two subsets: AITrans (where dialectic information is removed from IndEng) and AIGen (where LLMs are prompted to generate conversations). Our evaluation uses pre-trained and fine-tuned versions of two closed-source (GPT-4/3.5) and two open-source LLMs (Mistral and Gemma). LLMs perform significantly better for US English than Indian English for both TWP and TWS, for all settings. While GPT-based models perform the best, the comparatively smaller models work more equitably for short conversations (<8 turns). Our results on AIGen and AITrans (the best and worst-performing subset) respectively show that LLMs may learn a dialect of their own based on the composition of the training data, and that dialect robustness is indeed a challenging task. Our evaluation methodology exhibits a novel way to examine attributes of language models using pre-existing dialogue datasets.","sentences":["With an evergrowing number of LLMs reporting superlative performance for English, their ability to perform equitably for different dialects of English (i.e., dialect robustness) needs to be ascertained.","Specifically, we use English language (US English or Indian English) conversations between humans who play the word-guessing game of `taboo'.","We formulate two evaluative tasks: target word prediction (TWP) (i.e.predict the masked target word in a conversation) and target word selection (TWS) (i.e., select the most likely masked target word in a conversation, from among a set of candidate words).","Extending MD3, an existing dialectic dataset of taboo-playing conversations, we introduce M-MD3, a target-word-masked version of MD3 with the USEng and IndEng subsets.","We add two subsets: AITrans (where dialectic information is removed from IndEng) and AIGen (where LLMs are prompted to generate conversations).","Our evaluation uses pre-trained and fine-tuned versions of two closed-source (GPT-4/3.5) and two open-source LLMs (Mistral and Gemma).","LLMs perform significantly better for US English than Indian English for both TWP and TWS, for all settings.","While GPT-based models perform the best, the comparatively smaller models work more equitably for short conversations (<8 turns).","Our results on AIGen and AITrans (the best and worst-performing subset) respectively show that LLMs may learn a dialect of their own based on the composition of the training data, and that dialect robustness is indeed a challenging task.","Our evaluation methodology exhibits a novel way to examine attributes of language models using pre-existing dialogue datasets."],"url":"http://arxiv.org/abs/2405.05688v1"}
{"created":"2024-05-09 09:41:19","title":"Letter to the Editor: What are the legal and ethical considerations of submitting radiology reports to ChatGPT?","abstract":"This letter critically examines the recent article by Infante et al. assessing the utility of large language models (LLMs) like GPT-4, Perplexity, and Bard in identifying urgent findings in emergency radiology reports. While acknowledging the potential of LLMs in generating labels for computer vision, concerns are raised about the ethical implications of using patient data without explicit approval, highlighting the necessity of stringent data protection measures under GDPR.","sentences":["This letter critically examines the recent article by Infante et al. assessing the utility of large language models (LLMs) like GPT-4, Perplexity, and Bard in identifying urgent findings in emergency radiology reports.","While acknowledging the potential of LLMs in generating labels for computer vision, concerns are raised about the ethical implications of using patient data without explicit approval, highlighting the necessity of stringent data protection measures under GDPR."],"url":"http://arxiv.org/abs/2405.05647v1"}
{"created":"2024-05-09 09:27:28","title":"Supercomputers as a Continous Medium","abstract":"As supercomputers' complexity has grown, the traditional boundaries between processor, memory, network, and accelerators have blurred, making a homogeneous computer model, in which the overall computer system is modeled as a continuous medium with homogeneously distributed computational power, memory, and data movement transfer capabilities, an intriguing and powerful abstraction. By applying a homogeneous computer model to algorithms with a given I/O complexity, we recover from first principles, other discrete computer models, such as the roofline model, parallel computing laws, such as Amdahl's and Gustafson's laws, and phenomenological observations, such as super-linear speedup. One of the homogeneous computer model's distinctive advantages is the capability of directly linking the performance limits of an application to the physical properties of a classical computer system. Applying the homogeneous computer model to supercomputers, such as Frontier, Fugaku, and the Nvidia DGX GH200, shows that applications, such as Conjugate Gradient (CG) and Fast Fourier Transforms (FFT), are rapidly approaching the fundamental classical computational limits, where the performance of even denser systems in terms of compute and memory are fundamentally limited by the speed of light.","sentences":["As supercomputers' complexity has grown, the traditional boundaries between processor, memory, network, and accelerators have blurred, making a homogeneous computer model, in which the overall computer system is modeled as a continuous medium with homogeneously distributed computational power, memory, and data movement transfer capabilities, an intriguing and powerful abstraction.","By applying a homogeneous computer model to algorithms with a given I/O complexity, we recover from first principles, other discrete computer models, such as the roofline model, parallel computing laws, such as Amdahl's and Gustafson's laws, and phenomenological observations, such as super-linear speedup.","One of the homogeneous computer model's distinctive advantages is the capability of directly linking the performance limits of an application to the physical properties of a classical computer system.","Applying the homogeneous computer model to supercomputers, such as Frontier, Fugaku, and the Nvidia DGX GH200, shows that applications, such as Conjugate Gradient (CG) and Fast Fourier Transforms (FFT), are rapidly approaching the fundamental classical computational limits, where the performance of even denser systems in terms of compute and memory are fundamentally limited by the speed of light."],"url":"http://arxiv.org/abs/2405.05639v1"}
{"created":"2024-05-09 08:35:21","title":"Rectified Gaussian kernel multi-view k-means clustering","abstract":"In this paper, we show two new variants of multi-view k-means (MVKM) algorithms to address multi-view data. The general idea is to outline the distance between $h$-th view data points $x_i^h$ and $h$-th view cluster centers $a_k^h$ in a different manner of centroid-based approach. Unlike other methods, our proposed methods learn the multi-view data by calculating the similarity using Euclidean norm in the space of Gaussian-kernel, namely as multi-view k-means with exponent distance (MVKM-ED). By simultaneously aligning the stabilizer parameter $p$ and kernel coefficients $\\beta^h$, the compression of Gaussian-kernel based weighted distance in Euclidean norm reduce the sensitivity of MVKM-ED. To this end, this paper designated as Gaussian-kernel multi-view k-means (GKMVKM) clustering algorithm. Numerical evaluation of five real-world multi-view data demonstrates the robustness and efficiency of our proposed MVKM-ED and GKMVKM approaches.","sentences":["In this paper, we show two new variants of multi-view k-means (MVKM) algorithms to address multi-view data.","The general idea is to outline the distance between $h$-th view data points $x_i^h$ and $h$-th view cluster centers $a_k^h$ in a different manner of centroid-based approach.","Unlike other methods, our proposed methods learn the multi-view data by calculating the similarity using Euclidean norm in the space of Gaussian-kernel, namely as multi-view k-means with exponent distance (MVKM-ED).","By simultaneously aligning the stabilizer parameter $p$ and kernel coefficients $\\beta^h$, the compression of Gaussian-kernel based weighted distance in Euclidean norm reduce the sensitivity of MVKM-ED.","To this end, this paper designated as Gaussian-kernel multi-view k-means (GKMVKM) clustering algorithm.","Numerical evaluation of five real-world multi-view data demonstrates the robustness and efficiency of our proposed MVKM-ED and GKMVKM approaches."],"url":"http://arxiv.org/abs/2405.05619v1"}
{"created":"2024-05-09 08:32:55","title":"An Automatic Prompt Generation System for Tabular Data Tasks","abstract":"Efficient processing of tabular data is important in various industries, especially when working with datasets containing a large number of columns. Large language models (LLMs) have demonstrated their ability on several tasks through carefully crafted prompts. However, creating effective prompts for tabular datasets is challenging due to the structured nature of the data and the need to manage numerous columns. This paper presents an innovative auto-prompt generation system suitable for multiple LLMs, with minimal training. It proposes two novel methods; 1) A Reinforcement Learning-based algorithm for identifying and sequencing task-relevant columns 2) Cell-level similarity-based approach for enhancing few-shot example selection. Our approach has been extensively tested across 66 datasets, demonstrating improved performance in three downstream tasks: data imputation, error detection, and entity matching using two distinct LLMs; Google flan-t5-xxl and Mixtral 8x7B.","sentences":["Efficient processing of tabular data is important in various industries, especially when working with datasets containing a large number of columns.","Large language models (LLMs) have demonstrated their ability on several tasks through carefully crafted prompts.","However, creating effective prompts for tabular datasets is challenging due to the structured nature of the data and the need to manage numerous columns.","This paper presents an innovative auto-prompt generation system suitable for multiple LLMs, with minimal training.","It proposes two novel methods; 1) A Reinforcement Learning-based algorithm for identifying and sequencing task-relevant columns 2) Cell-level similarity-based approach for enhancing few-shot example selection.","Our approach has been extensively tested across 66 datasets, demonstrating improved performance in three downstream tasks: data imputation, error detection, and entity matching using two distinct LLMs; Google flan-t5-xxl and Mixtral 8x7B."],"url":"http://arxiv.org/abs/2405.05618v1"}
{"created":"2024-05-09 08:15:31","title":"Privacy-Preserving Edge Federated Learning for Intelligent Mobile-Health Systems","abstract":"Machine Learning (ML) algorithms are generally designed for scenarios in which all data is stored in one data center, where the training is performed. However, in many applications, e.g., in the healthcare domain, the training data is distributed among several entities, e.g., different hospitals or patients' mobile devices/sensors. At the same time, transferring the data to a central location for learning is certainly not an option, due to privacy concerns and legal issues, and in certain cases, because of the communication and computation overheads. Federated Learning (FL) is the state-of-the-art collaborative ML approach for training an ML model across multiple parties holding local data samples, without sharing them. However, enabling learning from distributed data over such edge Internet of Things (IoT) systems (e.g., mobile-health and wearable technologies, involving sensitive personal/medical data) in a privacy-preserving fashion presents a major challenge mainly due to their stringent resource constraints, i.e., limited computing capacity, communication bandwidth, memory storage, and battery lifetime. In this paper, we propose a privacy-preserving edge FL framework for resource-constrained mobile-health and wearable technologies over the IoT infrastructure. We evaluate our proposed framework extensively and provide the implementation of our technique on Amazon's AWS cloud platform based on the seizure detection application in epilepsy monitoring using wearable technologies.","sentences":["Machine Learning (ML) algorithms are generally designed for scenarios in which all data is stored in one data center, where the training is performed.","However, in many applications, e.g., in the healthcare domain, the training data is distributed among several entities, e.g., different hospitals or patients' mobile devices/sensors.","At the same time, transferring the data to a central location for learning is certainly not an option, due to privacy concerns and legal issues, and in certain cases, because of the communication and computation overheads.","Federated Learning (FL) is the state-of-the-art collaborative ML approach for training an ML model across multiple parties holding local data samples, without sharing them.","However, enabling learning from distributed data over such edge Internet of Things (IoT) systems (e.g., mobile-health and wearable technologies, involving sensitive personal/medical data) in a privacy-preserving fashion presents a major challenge mainly due to their stringent resource constraints, i.e., limited computing capacity, communication bandwidth, memory storage, and battery lifetime.","In this paper, we propose a privacy-preserving edge FL framework for resource-constrained mobile-health and wearable technologies over the IoT infrastructure.","We evaluate our proposed framework extensively and provide the implementation of our technique on Amazon's AWS cloud platform based on the seizure detection application in epilepsy monitoring using wearable technologies."],"url":"http://arxiv.org/abs/2405.05611v1"}
{"created":"2024-05-09 07:55:41","title":"Minimal Perspective Autocalibration","abstract":"We introduce a new family of minimal problems for reconstruction from multiple views. Our primary focus is a novel approach to autocalibration, a long-standing problem in computer vision. Traditional approaches to this problem, such as those based on Kruppa's equations or the modulus constraint, rely explicitly on the knowledge of multiple fundamental matrices or a projective reconstruction. In contrast, we consider a novel formulation involving constraints on image points, the unknown depths of 3D points, and a partially specified calibration matrix $K$. For $2$ and $3$ views, we present a comprehensive taxonomy of minimal autocalibration problems obtained by relaxing some of these constraints. These problems are organized into classes according to the number of views and any assumed prior knowledge of $K$. Within each class, we determine problems with the fewest -- or a relatively small number of -- solutions. From this zoo of problems, we devise three practical solvers. Experiments with synthetic and real data and interfacing our solvers with COLMAP demonstrate that we achieve superior accuracy compared to state-of-the-art calibration methods. The code is available at https://github.com/andreadalcin/MinimalPerspectiveAutocalibration","sentences":["We introduce a new family of minimal problems for reconstruction from multiple views.","Our primary focus is a novel approach to autocalibration, a long-standing problem in computer vision.","Traditional approaches to this problem, such as those based on Kruppa's equations or the modulus constraint, rely explicitly on the knowledge of multiple fundamental matrices or a projective reconstruction.","In contrast, we consider a novel formulation involving constraints on image points, the unknown depths of 3D points, and a partially specified calibration matrix $K$. For $2$ and $3$ views, we present a comprehensive taxonomy of minimal autocalibration problems obtained by relaxing some of these constraints.","These problems are organized into classes according to the number of views and any assumed prior knowledge of $K$. Within each class, we determine problems with the fewest -- or a relatively small number of -- solutions.","From this zoo of problems, we devise three practical solvers.","Experiments with synthetic and real data and interfacing our solvers with COLMAP demonstrate that we achieve superior accuracy compared to state-of-the-art calibration methods.","The code is available at https://github.com/andreadalcin/MinimalPerspectiveAutocalibration"],"url":"http://arxiv.org/abs/2405.05605v1"}
{"created":"2024-05-09 07:47:05","title":"Efficient Algorithms for Top-k Stabbing Queries on Weighted Interval Data (Full Version)","abstract":"Intervals have been generated in many applications (e.g., temporal databases), and they are often associated with weights, such as prices. This paper addresses the problem of processing top-k weighted stabbing queries on interval data. Given a set of weighted intervals, a query value, and a result size k, this problem finds the k intervals that are stabbed by the query value and have the largest weights. Although this problem finds practical applications (e.g., purchase, vehicle, and cryptocurrency analysis), it has not been well studied. A state-of-the-art algorithm for this problem incurs O(nlogk) time, where n is the number of intervals, so it is not scalable to large n. We solve this inefficiency issue and propose an algorithm that runs in O(sqrt(n)logn + k) time. Furthermore, we propose an O(logn + k) algorithm to further accelerate the search efficiency. Experiments on two real large datasets demonstrate that our algorithms are faster than existing algorithms.","sentences":["Intervals have been generated in many applications (e.g., temporal databases), and they are often associated with weights, such as prices.","This paper addresses the problem of processing top-k weighted stabbing queries on interval data.","Given a set of weighted intervals, a query value, and a result size k, this problem finds the k intervals that are stabbed by the query value and have the largest weights.","Although this problem finds practical applications (e.g., purchase, vehicle, and cryptocurrency analysis), it has not been well studied.","A state-of-the-art algorithm for this problem incurs O(nlogk) time, where n is the number of intervals, so it is not scalable to large n. We solve this inefficiency issue and propose an algorithm that runs in O(sqrt(n)logn + k) time.","Furthermore, we propose an O(logn + k) algorithm to further accelerate the search efficiency.","Experiments on two real large datasets demonstrate that our algorithms are faster than existing algorithms."],"url":"http://arxiv.org/abs/2405.05601v1"}
{"created":"2024-05-09 07:24:28","title":"Model Inversion Robustness: Can Transfer Learning Help?","abstract":"Model Inversion (MI) attacks aim to reconstruct private training data by abusing access to machine learning models. Contemporary MI attacks have achieved impressive attack performance, posing serious threats to privacy. Meanwhile, all existing MI defense methods rely on regularization that is in direct conflict with the training objective, resulting in noticeable degradation in model utility. In this work, we take a different perspective, and propose a novel and simple Transfer Learning-based Defense against Model Inversion (TL-DMI) to render MI-robust models. Particularly, by leveraging TL, we limit the number of layers encoding sensitive information from private training dataset, thereby degrading the performance of MI attack. We conduct an analysis using Fisher Information to justify our method. Our defense is remarkably simple to implement. Without bells and whistles, we show in extensive experiments that TL-DMI achieves state-of-the-art (SOTA) MI robustness. Our code, pre-trained models, demo and inverted data are available at: https://hosytuyen.github.io/projects/TL-DMI","sentences":["Model Inversion (MI) attacks aim to reconstruct private training data by abusing access to machine learning models.","Contemporary MI attacks have achieved impressive attack performance, posing serious threats to privacy.","Meanwhile, all existing MI defense methods rely on regularization that is in direct conflict with the training objective, resulting in noticeable degradation in model utility.","In this work, we take a different perspective, and propose a novel and simple Transfer Learning-based Defense against Model Inversion (TL-DMI) to render MI-robust models.","Particularly, by leveraging TL, we limit the number of layers encoding sensitive information from private training dataset, thereby degrading the performance of MI attack.","We conduct an analysis using Fisher Information to justify our method.","Our defense is remarkably simple to implement.","Without bells and whistles, we show in extensive experiments that TL-DMI achieves state-of-the-art (SOTA) MI robustness.","Our code, pre-trained models, demo and inverted data are available at: https://hosytuyen.github.io/projects/TL-DMI"],"url":"http://arxiv.org/abs/2405.05588v1"}
{"created":"2024-05-09 07:10:47","title":"Intelligent EC Rearview Mirror: Enhancing Driver Safety with Dynamic Glare Mitigation via Cloud Edge Collaboration","abstract":"Sudden glare from trailing vehicles significantly increases driving safety risks. Existing anti-glare technologies such as electronic, manually-adjusted, and electrochromic rearview mirrors, are expensive and lack effective adaptability in different lighting conditions. To address these issues, our research introduces an intelligent rearview mirror system utilizing novel all-liquid electrochromic technology. This system integrates IoT with ensemble and federated learning within a cloud edge collaboration framework, dynamically controlling voltage to effectively eliminate glare and maintain clear visibility. Utilizing an ensemble learning model, it automatically adjusts mirror transmittance based on light intensity, achieving a low RMSE of 0.109 on the test set. Furthermore, the system leverages federated learning for distributed data training across devices, which enhances privacy and updates the cloud model continuously. Distinct from conventional methods, our experiment utilizes the Schmidt-Clausen and Bindels de Boer 9-point scale with TOPSIS for comprehensive evaluation of rearview mirror glare. Designed to be convenient and costeffective, this system demonstrates how IoT and AI can significantly enhance rearview mirror anti-glare performance.","sentences":["Sudden glare from trailing vehicles significantly increases driving safety risks.","Existing anti-glare technologies such as electronic, manually-adjusted, and electrochromic rearview mirrors, are expensive and lack effective adaptability in different lighting conditions.","To address these issues, our research introduces an intelligent rearview mirror system utilizing novel all-liquid electrochromic technology.","This system integrates IoT with ensemble and federated learning within a cloud edge collaboration framework, dynamically controlling voltage to effectively eliminate glare and maintain clear visibility.","Utilizing an ensemble learning model, it automatically adjusts mirror transmittance based on light intensity, achieving a low RMSE of 0.109 on the test set.","Furthermore, the system leverages federated learning for distributed data training across devices, which enhances privacy and updates the cloud model continuously.","Distinct from conventional methods, our experiment utilizes the Schmidt-Clausen and Bindels de Boer 9-point scale with TOPSIS for comprehensive evaluation of rearview mirror glare.","Designed to be convenient and costeffective, this system demonstrates how IoT and AI can significantly enhance rearview mirror anti-glare performance."],"url":"http://arxiv.org/abs/2405.05579v1"}
{"created":"2024-05-09 06:45:11","title":"Poisoning-based Backdoor Attacks for Arbitrary Target Label with Positive Triggers","abstract":"Poisoning-based backdoor attacks expose vulnerabilities in the data preparation stage of deep neural network (DNN) training. The DNNs trained on the poisoned dataset will be embedded with a backdoor, making them behave well on clean data while outputting malicious predictions whenever a trigger is applied. To exploit the abundant information contained in the input data to output label mapping, our scheme utilizes the network trained from the clean dataset as a trigger generator to produce poisons that significantly raise the success rate of backdoor attacks versus conventional approaches. Specifically, we provide a new categorization of triggers inspired by the adversarial technique and develop a multi-label and multi-payload Poisoning-based backdoor attack with Positive Triggers (PPT), which effectively moves the input closer to the target label on benign classifiers. After the classifier is trained on the poisoned dataset, we can generate an input-label-aware trigger to make the infected classifier predict any given input to any target label with a high possibility. Under both dirty- and clean-label settings, we show empirically that the proposed attack achieves a high attack success rate without sacrificing accuracy across various datasets, including SVHN, CIFAR10, GTSRB, and Tiny ImageNet. Furthermore, the PPT attack can elude a variety of classical backdoor defenses, proving its effectiveness.","sentences":["Poisoning-based backdoor attacks expose vulnerabilities in the data preparation stage of deep neural network (DNN) training.","The DNNs trained on the poisoned dataset will be embedded with a backdoor, making them behave well on clean data while outputting malicious predictions whenever a trigger is applied.","To exploit the abundant information contained in the input data to output label mapping, our scheme utilizes the network trained from the clean dataset as a trigger generator to produce poisons that significantly raise the success rate of backdoor attacks versus conventional approaches.","Specifically, we provide a new categorization of triggers inspired by the adversarial technique and develop a multi-label and multi-payload Poisoning-based backdoor attack with Positive Triggers (PPT), which effectively moves the input closer to the target label on benign classifiers.","After the classifier is trained on the poisoned dataset, we can generate an input-label-aware trigger to make the infected classifier predict any given input to any target label with a high possibility.","Under both dirty- and clean-label settings, we show empirically that the proposed attack achieves a high attack success rate without sacrificing accuracy across various datasets, including SVHN, CIFAR10, GTSRB, and Tiny ImageNet.","Furthermore, the PPT attack can elude a variety of classical backdoor defenses, proving its effectiveness."],"url":"http://arxiv.org/abs/2405.05573v1"}
{"created":"2024-05-09 06:40:39","title":"From Human Judgements to Predictive Models: Unravelling Acceptability in Code-Mixed Sentences","abstract":"Current computational approaches for analysing or generating code-mixed sentences do not explicitly model \"naturalness\" or \"acceptability\" of code-mixed sentences, but rely on training corpora to reflect distribution of acceptable code-mixed sentences. Modelling human judgement for the acceptability of code-mixed text can help in distinguishing natural code-mixed text and enable quality-controlled generation of code-mixed text. To this end, we construct Cline - a dataset containing human acceptability judgements for English-Hindi (en-hi) code-mixed text. Cline is the largest of its kind with 16,642 sentences, consisting of samples sourced from two sources: synthetically generated code-mixed text and samples collected from online social media. Our analysis establishes that popular code-mixing metrics such as CMI, Number of Switch Points, Burstines, which are used to filter/curate/compare code-mixed corpora have low correlation with human acceptability judgements, underlining the necessity of our dataset. Experiments using Cline demonstrate that simple Multilayer Perceptron (MLP) models trained solely on code-mixing metrics are outperformed by fine-tuned pre-trained Multilingual Large Language Models (MLLMs). Specifically, XLM-Roberta and Bernice outperform IndicBERT across different configurations in challenging data settings. Comparison with ChatGPT's zero and fewshot capabilities shows that MLLMs fine-tuned on larger data outperform ChatGPT, providing scope for improvement in code-mixed tasks. Zero-shot transfer from English-Hindi to English-Telugu acceptability judgments using our model checkpoints proves superior to random baselines, enabling application to other code-mixed language pairs and providing further avenues of research. We publicly release our human-annotated dataset, trained checkpoints, code-mix corpus, and code for data generation and model training.","sentences":["Current computational approaches for analysing or generating code-mixed sentences do not explicitly model \"naturalness\" or \"acceptability\" of code-mixed sentences, but rely on training corpora to reflect distribution of acceptable code-mixed sentences.","Modelling human judgement for the acceptability of code-mixed text can help in distinguishing natural code-mixed text and enable quality-controlled generation of code-mixed text.","To this end, we construct Cline - a dataset containing human acceptability judgements for English-Hindi (en-hi) code-mixed text.","Cline is the largest of its kind with 16,642 sentences, consisting of samples sourced from two sources: synthetically generated code-mixed text and samples collected from online social media.","Our analysis establishes that popular code-mixing metrics such as CMI, Number of Switch Points, Burstines, which are used to filter/curate/compare code-mixed corpora have low correlation with human acceptability judgements, underlining the necessity of our dataset.","Experiments using Cline demonstrate that simple Multilayer Perceptron (MLP) models trained solely on code-mixing metrics are outperformed by fine-tuned pre-trained Multilingual Large Language Models (MLLMs).","Specifically, XLM-Roberta and Bernice outperform IndicBERT across different configurations in challenging data settings.","Comparison with ChatGPT's zero and fewshot capabilities shows that MLLMs fine-tuned on larger data outperform ChatGPT, providing scope for improvement in code-mixed tasks.","Zero-shot transfer from English-Hindi to English-Telugu acceptability judgments using our model checkpoints proves superior to random baselines, enabling application to other code-mixed language pairs and providing further avenues of research.","We publicly release our human-annotated dataset, trained checkpoints, code-mix corpus, and code for data generation and model training."],"url":"http://arxiv.org/abs/2405.05572v1"}
{"created":"2024-05-09 06:11:58","title":"Perfect Subset Privacy in Polynomial Computation","abstract":"Delegating large-scale computations to service providers is a common practice which raises privacy concerns. This paper studies information-theoretic privacy-preserving delegation of data to a service provider, who may further delegate the computation to auxiliary worker nodes, in order to compute a polynomial over that data at a later point in time. We study techniques which are compatible with robust management of distributed computation systems, an area known as coded computing. Privacy in coded computing, however, has traditionally addressed the problem of colluding workers, and assumed that the server that administrates the computation is trusted. This viewpoint of privacy does not accurately reflect real-world privacy concerns, since normally, the service provider as a whole (i.e., the administrator and the worker nodes) form one cohesive entity which itself poses a privacy risk. This paper aims to shift the focus of privacy in coded computing to safeguarding the privacy of the user against the service provider as a whole, instead of merely against colluding workers inside the service provider. To this end, we leverage the recently defined notion of perfect subset privacy, which guarantees zero information leakage from all subsets of the data up to a certain size. Using known techniques from Reed-Muller decoding, we provide a scheme which enables polynomial computation with perfect subset privacy in straggler-free systems. Furthermore, by studying information super-sets in Reed-Muller codes, which may be of independent interest, we extend the previous scheme to tolerate straggling worker nodes inside the service provider.","sentences":["Delegating large-scale computations to service providers is a common practice which raises privacy concerns.","This paper studies information-theoretic privacy-preserving delegation of data to a service provider, who may further delegate the computation to auxiliary worker nodes, in order to compute a polynomial over that data at a later point in time.","We study techniques which are compatible with robust management of distributed computation systems, an area known as coded computing.","Privacy in coded computing, however, has traditionally addressed the problem of colluding workers, and assumed that the server that administrates the computation is trusted.","This viewpoint of privacy does not accurately reflect real-world privacy concerns, since normally, the service provider as a whole (i.e., the administrator and the worker nodes) form one cohesive entity which itself poses a privacy risk.","This paper aims to shift the focus of privacy in coded computing to safeguarding the privacy of the user against the service provider as a whole, instead of merely against colluding workers inside the service provider.","To this end, we leverage the recently defined notion of perfect subset privacy, which guarantees zero information leakage from all subsets of the data up to a certain size.","Using known techniques from Reed-Muller decoding, we provide a scheme which enables polynomial computation with perfect subset privacy in straggler-free systems.","Furthermore, by studying information super-sets in Reed-Muller codes, which may be of independent interest, we extend the previous scheme to tolerate straggling worker nodes inside the service provider."],"url":"http://arxiv.org/abs/2405.05567v1"}
{"created":"2024-05-09 05:45:18","title":"Review-based Recommender Systems: A Survey of Approaches, Challenges and Future Perspectives","abstract":"Recommender systems play a pivotal role in helping users navigate an overwhelming selection of products and services. On online platforms, users have the opportunity to share feedback in various modes, including numerical ratings, textual reviews, and likes/dislikes. Traditional recommendation systems rely on users explicit ratings or implicit interactions (e.g. likes, clicks, shares, saves) to learn user preferences and item characteristics. Beyond these numerical ratings, textual reviews provide insights into users fine-grained preferences and item features. Analyzing these reviews is crucial for enhancing the performance and interpretability of personalized recommendation results. In recent years, review-based recommender systems have emerged as a significant sub-field in this domain. In this paper, we provide a comprehensive overview of the developments in review-based recommender systems over recent years, highlighting the importance of reviews in recommender systems, as well as the challenges associated with extracting features from reviews and integrating them into ratings. Specifically, we present a categorization of these systems and summarize the state-of-the-art methods, analyzing their unique features, effectiveness, and limitations. Finally, we propose potential directions for future research, including the integration of multi-modal data, multi-criteria rating information, and ethical considerations.","sentences":["Recommender systems play a pivotal role in helping users navigate an overwhelming selection of products and services.","On online platforms, users have the opportunity to share feedback in various modes, including numerical ratings, textual reviews, and likes/dislikes.","Traditional recommendation systems rely on users explicit ratings or implicit interactions (e.g. likes, clicks, shares, saves) to learn user preferences and item characteristics.","Beyond these numerical ratings, textual reviews provide insights into users fine-grained preferences and item features.","Analyzing these reviews is crucial for enhancing the performance and interpretability of personalized recommendation results.","In recent years, review-based recommender systems have emerged as a significant sub-field in this domain.","In this paper, we provide a comprehensive overview of the developments in review-based recommender systems over recent years, highlighting the importance of reviews in recommender systems, as well as the challenges associated with extracting features from reviews and integrating them into ratings.","Specifically, we present a categorization of these systems and summarize the state-of-the-art methods, analyzing their unique features, effectiveness, and limitations.","Finally, we propose potential directions for future research, including the integration of multi-modal data, multi-criteria rating information, and ethical considerations."],"url":"http://arxiv.org/abs/2405.05562v1"}
{"created":"2024-05-09 05:10:44","title":"Investigating Interaction Modes and User Agency in Human-LLM Collaboration for Domain-Specific Data Analysis","abstract":"Despite demonstrating robust capabilities in performing tasks related to general-domain data-operation tasks, Large Language Models (LLMs) may exhibit shortcomings when applied to domain-specific tasks. We consider the design of domain-specific AI-powered data analysis tools from two dimensions: interaction and user agency. We implemented two design probes that fall on the two ends of the two dimensions: an open-ended high agency (OHA) prototype and a structured low agency (SLA) prototype. We conducted an interview study with nine data scientists to investigate (1) how users perceived the LLM outputs for data analysis assistance, and (2) how the two test design probes, OHA and SLA, affected user behavior, performance, and perceptions. Our study revealed insights regarding participants' interactions with LLMs, how they perceived the results, and their desire for explainability concerning LLM outputs, along with a noted need for collaboration with other users, and how they envisioned the utility of LLMs in their workflow.","sentences":["Despite demonstrating robust capabilities in performing tasks related to general-domain data-operation tasks, Large Language Models (LLMs) may exhibit shortcomings when applied to domain-specific tasks.","We consider the design of domain-specific AI-powered data analysis tools from two dimensions: interaction and user agency.","We implemented two design probes that fall on the two ends of the two dimensions: an open-ended high agency (OHA) prototype and a structured low agency (SLA) prototype.","We conducted an interview study with nine data scientists to investigate (1) how users perceived the LLM outputs for data analysis assistance, and (2) how the two test design probes, OHA and SLA, affected user behavior, performance, and perceptions.","Our study revealed insights regarding participants' interactions with LLMs, how they perceived the results, and their desire for explainability concerning LLM outputs, along with a noted need for collaboration with other users, and how they envisioned the utility of LLMs in their workflow."],"url":"http://arxiv.org/abs/2405.05548v1"}
{"created":"2024-05-09 05:09:37","title":"Data reification in a concurrent rely-guarantee algebra","abstract":"Specifications of significant systems can be made short and perspicuous by using abstract data types; data reification can provide a clear, stepwise, development history of programs that use more efficient concrete representations. Data reification (or \"refinement\") techniques for sequential programs are well established. This paper applies these ideas to concurrency, in particular, an algebraic theory supporting rely-guarantee reasoning about concurrency. A concurrent version of the Galler-Fischer equivalence relation data structure is used as an example.","sentences":["Specifications of significant systems can be made short and perspicuous by using abstract data types; data reification can provide a clear, stepwise, development history of programs that use more efficient concrete representations.","Data reification (or \"refinement\") techniques for sequential programs are well established.","This paper applies these ideas to concurrency, in particular, an algebraic theory supporting rely-guarantee reasoning about concurrency.","A concurrent version of the Galler-Fischer equivalence relation data structure is used as an example."],"url":"http://arxiv.org/abs/2405.05546v1"}
{"created":"2024-05-09 05:06:50","title":"Partially Ordered Sets Corresponding to the Partition Problem","abstract":"The partition problem is a well-known basic NP-complete problem. We mainly consider the optimization version of it in this paper. The problem has been investigated from various perspectives for a long time and can be solved efficiently in practice. Hence, we might say that the only remaining task is to decide whether the problem can be solved in polynomial time in the number $n$ of given integers.   We propose two partially ordered sets (posets) and present a novel methodology for solving the partition problem. The first poset is order-isomorphic to a well-known poset whose structures are related to the solutions of the subset sum problem, while the second is a subposet of the first and plays a crucial role in this paper. We first show several properties of the two posets, such as size, height and width (the largest size of a subset consisting of incomparable elements). Both widths are the same and $O(2^n / n^{3/2})$ for $n$ congruent to $0$ or $3$ (mod $4$). This fact indicates the hardness of the partition problem. We then prove that in general all the candidate solutions correspond to the elements of the second poset, whose size is $2^{n} - 2 \\binom{n}{\\lfloor n/2 \\rfloor}$. Since a partition corresponds to two elements of the poset, the number of the candidate partitions is half of it, that is, $2^{n-1} - \\binom{n}{\\lfloor n/2 \\rfloor}$. We finally prove that the candidate solutions can be reduced based on the partial order. In particular, we give several polynomially solvable cases by considering the minimal elements of the second poset.   Our approach offers a valuable tool for structural analysis of the partition problem and provides a new perspective on the P versus NP problem.","sentences":["The partition problem is a well-known basic NP-complete problem.","We mainly consider the optimization version of it in this paper.","The problem has been investigated from various perspectives for a long time and can be solved efficiently in practice.","Hence, we might say that the only remaining task is to decide whether the problem can be solved in polynomial time in the number $n$ of given integers.   ","We propose two partially ordered sets (posets) and present a novel methodology for solving the partition problem.","The first poset is order-isomorphic to a well-known poset whose structures are related to the solutions of the subset sum problem, while the second is a subposet of the first and plays a crucial role in this paper.","We first show several properties of the two posets, such as size, height and width (the largest size of a subset consisting of incomparable elements).","Both widths are the same and $O(2^n / n^{3/2})$ for $n$ congruent to $0$ or $3$ (mod $4$).","This fact indicates the hardness of the partition problem.","We then prove that in general all the candidate solutions correspond to the elements of the second poset, whose size is $2^{n} - 2 \\binom{n}{\\lfloor n/2 \\rfloor}$. Since a partition corresponds to two elements of the poset, the number of the candidate partitions is half of it, that is, $2^{n-1} - \\binom{n}{\\lfloor","n/2 \\rfloor}$. We finally prove that the candidate solutions can be reduced based on the partial order.","In particular, we give several polynomially solvable cases by considering the minimal elements of the second poset.   ","Our approach offers a valuable tool for structural analysis of the partition problem and provides a new perspective on the P versus NP problem."],"url":"http://arxiv.org/abs/2405.05544v1"}
{"created":"2024-05-09 04:58:27","title":"Predicting Cognitive Load Using Sensor Data in a Literacy Game","abstract":"Educational games are being increasingly used to support self-paced learning. However, educators and system designers often face challenges in monitoring student affect and cognitive load. Existing assessments in game-based learning environments (GBLEs) tend to focus more on outcomes rather than processes, potentially overlooking key aspects of the learning journey that include learner affect and cognitive load. To address this issue, we collected data and trained a model to track learner cognitive load while they used an online literacy game for English. We collected affect-related physiological data and pupil data during gameplay to enable the development of models that identify these latent characteristics of learner processes. Our model indicates the feasibility of using these data to track cognitive load in GBLEs. Our multimodal model distinguished different levels of cognitive load, achieving the highest Kappa (.417) and accuracy (70%). Our model reveals the importance of including affect-related features (i.e., EDA and heart rate) when predicting cognitive load and extends recent findings suggesting the benefit of using multiple channels when modeling latent aspects of learner processes. Findings also suggest that cognitive load tracking could now be used to facilitate the creation of personalized learning experiences.","sentences":["Educational games are being increasingly used to support self-paced learning.","However, educators and system designers often face challenges in monitoring student affect and cognitive load.","Existing assessments in game-based learning environments (GBLEs) tend to focus more on outcomes rather than processes, potentially overlooking key aspects of the learning journey that include learner affect and cognitive load.","To address this issue, we collected data and trained a model to track learner cognitive load while they used an online literacy game for English.","We collected affect-related physiological data and pupil data during gameplay to enable the development of models that identify these latent characteristics of learner processes.","Our model indicates the feasibility of using these data to track cognitive load in GBLEs.","Our multimodal model distinguished different levels of cognitive load, achieving the highest Kappa (.417) and accuracy (70%).","Our model reveals the importance of including affect-related features (i.e., EDA and heart rate) when predicting cognitive load and extends recent findings suggesting the benefit of using multiple channels when modeling latent aspects of learner processes.","Findings also suggest that cognitive load tracking could now be used to facilitate the creation of personalized learning experiences."],"url":"http://arxiv.org/abs/2405.05543v1"}
{"created":"2024-05-09 04:23:31","title":"How Good Are Multi-dimensional Learned Indices? An Experimental Survey","abstract":"Efficient indexing is fundamental for multi-dimensional data management and analytics. An emerging tendency is to directly learn the storage layout of multi-dimensional data by simple machine learning models, yielding the concept of Learned Index. Compared with the conventional indices used for decades (e.g., kd-tree and R-tree variants), learned indices are empirically shown to be both space- and time-efficient on modern architectures. However, there lacks a comprehensive evaluation of existing multi-dimensional learned indices under a unified benchmark, which makes it difficult to decide the suitable index for specific data and queries and further prevents the deployment of learned indices in real application scenarios. In this paper, we present the first in-depth empirical study to answer the question of how good multi-dimensional learned indices are. Six recently published indices are evaluated under a unified experimental configuration including index implementation, datasets, query workloads, and evaluation metrics. We thoroughly investigate the evaluation results and discuss the findings that may provide insights for future learned index design.","sentences":["Efficient indexing is fundamental for multi-dimensional data management and analytics.","An emerging tendency is to directly learn the storage layout of multi-dimensional data by simple machine learning models, yielding the concept of Learned Index.","Compared with the conventional indices used for decades (e.g., kd-tree and R-tree variants), learned indices are empirically shown to be both space- and time-efficient on modern architectures.","However, there lacks a comprehensive evaluation of existing multi-dimensional learned indices under a unified benchmark, which makes it difficult to decide the suitable index for specific data and queries and further prevents the deployment of learned indices in real application scenarios.","In this paper, we present the first in-depth empirical study to answer the question of how good multi-dimensional learned indices are.","Six recently published indices are evaluated under a unified experimental configuration including index implementation, datasets, query workloads, and evaluation metrics.","We thoroughly investigate the evaluation results and discuss the findings that may provide insights for future learned index design."],"url":"http://arxiv.org/abs/2405.05536v1"}
{"created":"2024-05-09 04:21:52","title":"Reconfiguration of Multisets with Applications to Bin Packing","abstract":"We use the reconfiguration framework to analyze problems that involve the rearrangement of items among groups. In various applications, a group of items could correspond to the files or jobs assigned to a particular machine, and the goal of rearrangement could be improving efficiency or increasing locality.   To cover problems arising in a wide range of application areas, we define the general Repacking problem as the rearrangement of multisets of multisets. We present hardness results for the general case and algorithms for various classes of instances that arise in real-life scenarios. By limiting the total size of items in each multiset, our results can be viewed as an offline approach to Bin Packing, in which each bin is represented as a multiset.   In addition to providing the first results on reconfiguration of multisets, our contributions open up several research avenues: the interplay between reconfiguration and online algorithms and parallel algorithms; the use of the tools of linear programming in reconfiguration; and, in the longer term, a focus on resources in reconfiguration.","sentences":["We use the reconfiguration framework to analyze problems that involve the rearrangement of items among groups.","In various applications, a group of items could correspond to the files or jobs assigned to a particular machine, and the goal of rearrangement could be improving efficiency or increasing locality.   ","To cover problems arising in a wide range of application areas, we define the general Repacking problem as the rearrangement of multisets of multisets.","We present hardness results for the general case and algorithms for various classes of instances that arise in real-life scenarios.","By limiting the total size of items in each multiset, our results can be viewed as an offline approach to Bin Packing, in which each bin is represented as a multiset.   ","In addition to providing the first results on reconfiguration of multisets, our contributions open up several research avenues: the interplay between reconfiguration and online algorithms and parallel algorithms; the use of the tools of linear programming in reconfiguration; and, in the longer term, a focus on resources in reconfiguration."],"url":"http://arxiv.org/abs/2405.05535v1"}
{"created":"2024-05-09 03:48:57","title":"Tomur: Traffic-Aware Performance Prediction of On-NIC Network Functions with Multi-Resource Contention","abstract":"Network function (NF) offloading on SmartNICs has been widely used in modern data centers, offering benefits in host resource saving and programmability. Co-running NFs on the same SmartNICs can cause performance interference due to onboard resource contention. Therefore, to meet performance SLAs while ensuring efficient resource management, operators need mechanisms to predict NF performance under such contention. However, existing solutions lack SmartNIC-specific knowledge and exhibit limited traffic awareness, leading to poor accuracy for on-NIC NFs. This paper proposes Tomur, a novel performance predictive system for on-NIC NFs. Tomur builds upon the key observation that co-located NFs contend for multiple resources, including onboard accelerators and the memory subsystem. It also facilitates traffic awareness according to the behaviors of individual resources to maintain accuracy as the external traffic attributes vary. Evaluation using BlueField-2 SmartNIC shows that Tomur improves the prediction accuracy by 78.8% and reduces SLA violations by 92.2% compared to state-of-the-art approaches, and enables new practical usecases.","sentences":["Network function (NF) offloading on SmartNICs has been widely used in modern data centers, offering benefits in host resource saving and programmability.","Co-running NFs on the same SmartNICs can cause performance interference due to onboard resource contention.","Therefore, to meet performance SLAs while ensuring efficient resource management, operators need mechanisms to predict NF performance under such contention.","However, existing solutions lack SmartNIC-specific knowledge and exhibit limited traffic awareness, leading to poor accuracy for on-NIC NFs.","This paper proposes Tomur, a novel performance predictive system for on-NIC NFs.","Tomur builds upon the key observation that co-located NFs contend for multiple resources, including onboard accelerators and the memory subsystem.","It also facilitates traffic awareness according to the behaviors of individual resources to maintain accuracy as the external traffic attributes vary.","Evaluation using BlueField-2 SmartNIC shows that Tomur improves the prediction accuracy by 78.8% and reduces SLA violations by 92.2% compared to state-of-the-art approaches, and enables new practical usecases."],"url":"http://arxiv.org/abs/2405.05529v1"}
{"created":"2024-05-09 03:34:09","title":"Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview","abstract":"Neural Radiance Fields (NeRF) have emerged as a powerful paradigm for 3D scene representation, offering high-fidelity renderings and reconstructions from a set of sparse and unstructured sensor data. In the context of autonomous robotics, where perception and understanding of the environment are pivotal, NeRF holds immense promise for improving performance. In this paper, we present a comprehensive survey and analysis of the state-of-the-art techniques for utilizing NeRF to enhance the capabilities of autonomous robots. We especially focus on the perception, localization and navigation, and decision-making modules of autonomous robots and delve into tasks crucial for autonomous operation, including 3D reconstruction, segmentation, pose estimation, simultaneous localization and mapping (SLAM), navigation and planning, and interaction. Our survey meticulously benchmarks existing NeRF-based methods, providing insights into their strengths and limitations. Moreover, we explore promising avenues for future research and development in this domain. Notably, we discuss the integration of advanced techniques such as 3D Gaussian splatting (3DGS), large language models (LLM), and generative AIs, envisioning enhanced reconstruction efficiency, scene understanding, decision-making capabilities. This survey serves as a roadmap for researchers seeking to leverage NeRFs to empower autonomous robots, paving the way for innovative solutions that can navigate and interact seamlessly in complex environments.","sentences":["Neural Radiance Fields (NeRF) have emerged as a powerful paradigm for 3D scene representation, offering high-fidelity renderings and reconstructions from a set of sparse and unstructured sensor data.","In the context of autonomous robotics, where perception and understanding of the environment are pivotal, NeRF holds immense promise for improving performance.","In this paper, we present a comprehensive survey and analysis of the state-of-the-art techniques for utilizing NeRF to enhance the capabilities of autonomous robots.","We especially focus on the perception, localization and navigation, and decision-making modules of autonomous robots and delve into tasks crucial for autonomous operation, including 3D reconstruction, segmentation, pose estimation, simultaneous localization and mapping (SLAM), navigation and planning, and interaction.","Our survey meticulously benchmarks existing NeRF-based methods, providing insights into their strengths and limitations.","Moreover, we explore promising avenues for future research and development in this domain.","Notably, we discuss the integration of advanced techniques such as 3D Gaussian splatting (3DGS), large language models (LLM), and generative AIs, envisioning enhanced reconstruction efficiency, scene understanding, decision-making capabilities.","This survey serves as a roadmap for researchers seeking to leverage NeRFs to empower autonomous robots, paving the way for innovative solutions that can navigate and interact seamlessly in complex environments."],"url":"http://arxiv.org/abs/2405.05526v1"}
{"created":"2024-05-09 03:28:16","title":"Ditto: Quantization-aware Secure Inference of Transformers upon MPC","abstract":"Due to the rising privacy concerns on sensitive client data and trained models like Transformers, secure multi-party computation (MPC) techniques are employed to enable secure inference despite attendant overhead. Existing works attempt to reduce the overhead using more MPC-friendly non-linear function approximations. However, the integration of quantization widely used in plaintext inference into the MPC domain remains unclear. To bridge this gap, we propose the framework named Ditto to enable more efficient quantization-aware secure Transformer inference. Concretely, we first incorporate an MPC-friendly quantization into Transformer inference and employ a quantization-aware distillation procedure to maintain the model utility. Then, we propose novel MPC primitives to support the type conversions that are essential in quantization and implement the quantization-aware MPC execution of secure quantized inference. This approach significantly decreases both computation and communication overhead, leading to improvements in overall efficiency. We conduct extensive experiments on Bert and GPT2 models to evaluate the performance of Ditto. The results demonstrate that Ditto is about $3.14\\sim 4.40\\times$ faster than MPCFormer (ICLR 2023) and $1.44\\sim 2.35\\times$ faster than the state-of-the-art work PUMA with negligible utility degradation.","sentences":["Due to the rising privacy concerns on sensitive client data and trained models like Transformers, secure multi-party computation (MPC) techniques are employed to enable secure inference despite attendant overhead.","Existing works attempt to reduce the overhead using more MPC-friendly non-linear function approximations.","However, the integration of quantization widely used in plaintext inference into the MPC domain remains unclear.","To bridge this gap, we propose the framework named Ditto to enable more efficient quantization-aware secure Transformer inference.","Concretely, we first incorporate an MPC-friendly quantization into Transformer inference and employ a quantization-aware distillation procedure to maintain the model utility.","Then, we propose novel MPC primitives to support the type conversions that are essential in quantization and implement the quantization-aware MPC execution of secure quantized inference.","This approach significantly decreases both computation and communication overhead, leading to improvements in overall efficiency.","We conduct extensive experiments on Bert and GPT2 models to evaluate the performance of Ditto.","The results demonstrate that Ditto is about $3.14\\sim 4.40\\times$ faster than MPCFormer (ICLR 2023) and $1.44\\sim 2.35\\times$ faster than the state-of-the-art work PUMA with negligible utility degradation."],"url":"http://arxiv.org/abs/2405.05525v1"}
{"created":"2024-05-09 03:27:28","title":"Universal Adversarial Perturbations for Vision-Language Pre-trained Models","abstract":"Vision-language pre-trained (VLP) models have been the foundation of numerous vision-language tasks. Given their prevalence, it be- comes imperative to assess their adversarial robustness, especially when deploying them in security-crucial real-world applications. Traditionally, adversarial perturbations generated for this assessment target specific VLP models, datasets, and/or downstream tasks. This practice suffers from low transferability and additional computation costs when transitioning to new scenarios.   In this work, we thoroughly investigate whether VLP models are commonly sensitive to imperceptible perturbations of a specific pattern for the image modality. To this end, we propose a novel black-box method to generate Universal Adversarial Perturbations (UAPs), which is so called the Effective and T ransferable Universal Adversarial Attack (ETU), aiming to mislead a variety of existing VLP models in a range of downstream tasks. The ETU comprehensively takes into account the characteristics of UAPs and the intrinsic cross-modal interactions to generate effective UAPs. Under this regime, the ETU encourages both global and local utilities of UAPs. This benefits the overall utility while reducing interactions between UAP units, improving the transferability. To further enhance the effectiveness and transferability of UAPs, we also design a novel data augmentation method named ScMix. ScMix consists of self-mix and cross-mix data transformations, which can effectively increase the multi-modal data diversity while preserving the semantics of the original data. Through comprehensive experiments on various downstream tasks, VLP models, and datasets, we demonstrate that the proposed method is able to achieve effective and transferrable universal adversarial attacks.","sentences":["Vision-language pre-trained (VLP) models have been the foundation of numerous vision-language tasks.","Given their prevalence, it be- comes imperative to assess their adversarial robustness, especially when deploying them in security-crucial real-world applications.","Traditionally, adversarial perturbations generated for this assessment target specific VLP models, datasets, and/or downstream tasks.","This practice suffers from low transferability and additional computation costs when transitioning to new scenarios.   ","In this work, we thoroughly investigate whether VLP models are commonly sensitive to imperceptible perturbations of a specific pattern for the image modality.","To this end, we propose a novel black-box method to generate Universal Adversarial Perturbations (UAPs), which is so called the Effective and T ransferable Universal Adversarial Attack (ETU), aiming to mislead a variety of existing VLP models in a range of downstream tasks.","The ETU comprehensively takes into account the characteristics of UAPs and the intrinsic cross-modal interactions to generate effective UAPs.","Under this regime, the ETU encourages both global and local utilities of UAPs.","This benefits the overall utility while reducing interactions between UAP units, improving the transferability.","To further enhance the effectiveness and transferability of UAPs, we also design a novel data augmentation method named ScMix.","ScMix consists of self-mix and cross-mix data transformations, which can effectively increase the multi-modal data diversity while preserving the semantics of the original data.","Through comprehensive experiments on various downstream tasks, VLP models, and datasets, we demonstrate that the proposed method is able to achieve effective and transferrable universal adversarial attacks."],"url":"http://arxiv.org/abs/2405.05524v1"}
{"created":"2024-05-09 03:23:47","title":"Prompt When the Animal is: Temporal Animal Behavior Grounding with Positional Recovery Training","abstract":"Temporal grounding is crucial in multimodal learning, but it poses challenges when applied to animal behavior data due to the sparsity and uniform distribution of moments. To address these challenges, we propose a novel Positional Recovery Training framework (Port), which prompts the model with the start and end times of specific animal behaviors during training. Specifically, Port enhances the baseline model with a Recovering part to predict flipped label sequences and align distributions with a Dual-alignment method. This allows the model to focus on specific temporal regions prompted by ground-truth information. Extensive experiments on the Animal Kingdom dataset demonstrate the effectiveness of Port, achieving an IoU@0.3 of 38.52. It emerges as one of the top performers in the sub-track of MMVRAC in ICME 2024 Grand Challenges.","sentences":["Temporal grounding is crucial in multimodal learning, but it poses challenges when applied to animal behavior data due to the sparsity and uniform distribution of moments.","To address these challenges, we propose a novel Positional Recovery Training framework (Port), which prompts the model with the start and end times of specific animal behaviors during training.","Specifically, Port enhances the baseline model with a Recovering part to predict flipped label sequences and align distributions with a Dual-alignment method.","This allows the model to focus on specific temporal regions prompted by ground-truth information.","Extensive experiments on the Animal Kingdom dataset demonstrate the effectiveness of Port, achieving an IoU@0.3 of 38.52.","It emerges as one of the top performers in the sub-track of MMVRAC in ICME 2024 Grand Challenges."],"url":"http://arxiv.org/abs/2405.05523v1"}
{"created":"2024-05-09 02:33:14","title":"Cross-Care: Assessing the Healthcare Implications of Pre-training Data on Language Model Bias","abstract":"Large language models (LLMs) are increasingly essential in processing natural languages, yet their application is frequently compromised by biases and inaccuracies originating in their training data. In this study, we introduce Cross-Care, the first benchmark framework dedicated to assessing biases and real world knowledge in LLMs, specifically focusing on the representation of disease prevalence across diverse demographic groups. We systematically evaluate how demographic biases embedded in pre-training corpora like $ThePile$ influence the outputs of LLMs. We expose and quantify discrepancies by juxtaposing these biases against actual disease prevalences in various U.S. demographic groups. Our results highlight substantial misalignment between LLM representation of disease prevalence and real disease prevalence rates across demographic subgroups, indicating a pronounced risk of bias propagation and a lack of real-world grounding for medical applications of LLMs. Furthermore, we observe that various alignment methods minimally resolve inconsistencies in the models' representation of disease prevalence across different languages. For further exploration and analysis, we make all data and a data visualization tool available at: www.crosscare.net.","sentences":["Large language models (LLMs) are increasingly essential in processing natural languages, yet their application is frequently compromised by biases and inaccuracies originating in their training data.","In this study, we introduce Cross-Care, the first benchmark framework dedicated to assessing biases and real world knowledge in LLMs, specifically focusing on the representation of disease prevalence across diverse demographic groups.","We systematically evaluate how demographic biases embedded in pre-training corpora like $ThePile$ influence the outputs of LLMs.","We expose and quantify discrepancies by juxtaposing these biases against actual disease prevalences in various U.S. demographic groups.","Our results highlight substantial misalignment between LLM representation of disease prevalence and real disease prevalence rates across demographic subgroups, indicating a pronounced risk of bias propagation and a lack of real-world grounding for medical applications of LLMs.","Furthermore, we observe that various alignment methods minimally resolve inconsistencies in the models' representation of disease prevalence across different languages.","For further exploration and analysis, we make all data and a data visualization tool available at: www.crosscare.net."],"url":"http://arxiv.org/abs/2405.05506v1"}
{"created":"2024-05-09 02:11:01","title":"Multi-Scale Dilated Convolution Network for Long-Term Time Series Forecasting","abstract":"Accurate forecasting of long-term time series has important applications for decision making and planning. However, it remains challenging to capture the long-term dependencies in time series data. To better extract long-term dependencies, We propose Multi Scale Dilated Convolution Network (MSDCN), a method that utilizes a shallow dilated convolution architecture to capture the period and trend characteristics of long time series. We design different convolution blocks with exponentially growing dilations and varying kernel sizes to sample time series data at different scales. Furthermore, we utilize traditional autoregressive model to capture the linear relationships within the data. To validate the effectiveness of the proposed approach, we conduct experiments on eight challenging long-term time series forecasting benchmark datasets. The experimental results show that our approach outperforms the prior state-of-the-art approaches and shows significant inference speed improvements compared to several strong baseline methods.","sentences":["Accurate forecasting of long-term time series has important applications for decision making and planning.","However, it remains challenging to capture the long-term dependencies in time series data.","To better extract long-term dependencies, We propose Multi Scale Dilated Convolution Network (MSDCN), a method that utilizes a shallow dilated convolution architecture to capture the period and trend characteristics of long time series.","We design different convolution blocks with exponentially growing dilations and varying kernel sizes to sample time series data at different scales.","Furthermore, we utilize traditional autoregressive model to capture the linear relationships within the data.","To validate the effectiveness of the proposed approach, we conduct experiments on eight challenging long-term time series forecasting benchmark datasets.","The experimental results show that our approach outperforms the prior state-of-the-art approaches and shows significant inference speed improvements compared to several strong baseline methods."],"url":"http://arxiv.org/abs/2405.05499v1"}
{"created":"2024-05-09 00:37:38","title":"BSL: Navigation Method Considering Blind Spots Based on ROS Navigation Stack and Blind Spots Layer for Mobile Robot","abstract":"This paper proposes a navigation method considering blind spots based on the robot operating system (ROS) navigation stack and blind spots layer (BSL) for a wheeled mobile robot. In this paper, environmental information is recognized using a laser range finder (LRF) and RGB-D cameras. Blind spots occur when corners or obstacles are present in the environment, and may lead to collisions if a human or object moves toward the robot from these blind spots. To prevent such collisions, this paper proposes a navigation method considering blind spots based on the local cost map layer of the BSL for the wheeled mobile robot. Blind spots are estimated by utilizing environmental data collected through RGB-D cameras. The navigation method that takes these blind spots into account is achieved through the implementation of the BSL and a local path planning method that employs an enhanced cost function of dynamic window approach. The effectiveness of the proposed method was further demonstrated through simulations and experiments.","sentences":["This paper proposes a navigation method considering blind spots based on the robot operating system (ROS) navigation stack and blind spots layer (BSL) for a wheeled mobile robot.","In this paper, environmental information is recognized using a laser range finder (LRF) and RGB-D cameras.","Blind spots occur when corners or obstacles are present in the environment, and may lead to collisions if a human or object moves toward the robot from these blind spots.","To prevent such collisions, this paper proposes a navigation method considering blind spots based on the local cost map layer of the BSL for the wheeled mobile robot.","Blind spots are estimated by utilizing environmental data collected through RGB-D cameras.","The navigation method that takes these blind spots into account is achieved through the implementation of the BSL and a local path planning method that employs an enhanced cost function of dynamic window approach.","The effectiveness of the proposed method was further demonstrated through simulations and experiments."],"url":"http://arxiv.org/abs/2405.05479v1"}
{"created":"2024-05-09 00:31:59","title":"Using Machine Translation to Augment Multilingual Classification","abstract":"An all-too-present bottleneck for text classification model development is the need to annotate training data and this need is multiplied for multilingual classifiers. Fortunately, contemporary machine translation models are both easily accessible and have dependable translation quality, making it possible to translate labeled training data from one language into another. Here, we explore the effects of using machine translation to fine-tune a multilingual model for a classification task across multiple languages. We also investigate the benefits of using a novel technique, originally proposed in the field of image captioning, to account for potential negative effects of tuning models on translated data. We show that translated data are of sufficient quality to tune multilingual classifiers and that this novel loss technique is able to offer some improvement over models tuned without it.","sentences":["An all-too-present bottleneck for text classification model development is the need to annotate training data and this need is multiplied for multilingual classifiers.","Fortunately, contemporary machine translation models are both easily accessible and have dependable translation quality, making it possible to translate labeled training data from one language into another.","Here, we explore the effects of using machine translation to fine-tune a multilingual model for a classification task across multiple languages.","We also investigate the benefits of using a novel technique, originally proposed in the field of image captioning, to account for potential negative effects of tuning models on translated data.","We show that translated data are of sufficient quality to tune multilingual classifiers and that this novel loss technique is able to offer some improvement over models tuned without it."],"url":"http://arxiv.org/abs/2405.05478v1"}
{"created":"2024-05-09 00:20:28","title":"(Dis)placed Contributions: Uncovering Hidden Hurdles to Collaborative Writing Involving Non-Native Speakers, Native Speakers, and AI-Powered Editing Tools","abstract":"Content creation today often takes place via collaborative writing. A longstanding interest of CSCW research lies in understanding and promoting the coordination between co-writers. However, little attention has been paid to individuals who write in their non-native language and to co-writer groups involving them. We present a mixed-method study that fills the above gap. Our participants included 32 co-writer groups, each consisting of one native speaker (NS) of English and one non-native speaker (NNS) with limited proficiency. They performed collaborative writing adopting two different workflows: half of the groups began with NNSs taking the first editing turn and half had NNSs act after NSs. Our data revealed a \"late-mover disadvantage\" exclusively experienced by NNSs: an NNS's ideational contributions to the joint document were suppressed when their editing turn was placed after an NS's turn, as opposed to ahead of it. Surprisingly, editing help provided by AI-powered tools did not exempt NNSs from being disadvantaged. Instead, it triggered NSs' overestimation of NNSs' English proficiency and agency displayed in the writing, introducing unintended tensions into the collaboration. These findings shed light on the fair assessment and effective promotion of a co-writer's contributions in language diverse settings. In particular, they underscore the necessity of disentangling contributions made to the ideational, expressional, and lexical aspects of the joint writing.","sentences":["Content creation today often takes place via collaborative writing.","A longstanding interest of CSCW research lies in understanding and promoting the coordination between co-writers.","However, little attention has been paid to individuals who write in their non-native language and to co-writer groups involving them.","We present a mixed-method study that fills the above gap.","Our participants included 32 co-writer groups, each consisting of one native speaker (NS) of English and one non-native speaker (NNS) with limited proficiency.","They performed collaborative writing adopting two different workflows: half of the groups began with NNSs taking the first editing turn and half had NNSs act after NSs.","Our data revealed a \"late-mover disadvantage\" exclusively experienced by NNSs: an NNS's ideational contributions to the joint document were suppressed when their editing turn was placed after an NS's turn, as opposed to ahead of it.","Surprisingly, editing help provided by AI-powered tools did not exempt NNSs from being disadvantaged.","Instead, it triggered NSs' overestimation of NNSs' English proficiency and agency displayed in the writing, introducing unintended tensions into the collaboration.","These findings shed light on the fair assessment and effective promotion of a co-writer's contributions in language diverse settings.","In particular, they underscore the necessity of disentangling contributions made to the ideational, expressional, and lexical aspects of the joint writing."],"url":"http://arxiv.org/abs/2405.05474v1"}
{"created":"2024-05-09 00:00:27","title":"PLLM-CS: Pre-trained Large Language Model (LLM) for Cyber Threat Detection in Satellite Networks","abstract":"Satellite networks are vital in facilitating communication services for various critical infrastructures. These networks can seamlessly integrate with a diverse array of systems. However, some of these systems are vulnerable due to the absence of effective intrusion detection systems, which can be attributed to limited research and the high costs associated with deploying, fine-tuning, monitoring, and responding to security breaches. To address these challenges, we propose a pretrained Large Language Model for Cyber Security , for short PLLM-CS, which is a variant of pre-trained Transformers [1], which includes a specialized module for transforming network data into contextually suitable inputs. This transformation enables the proposed LLM to encode contextual information within the cyber data. To validate the efficacy of the proposed method, we conducted empirical experiments using two publicly available network datasets, UNSW_NB 15 and TON_IoT, both providing Internet of Things (IoT)-based traffic data. Our experiments demonstrate that proposed LLM method outperforms state-of-the-art techniques such as BiLSTM, GRU, and CNN. Notably, the PLLM-CS method achieves an outstanding accuracy level of 100% on the UNSW_NB 15 dataset, setting a new standard for benchmark performance in this domain.","sentences":["Satellite networks are vital in facilitating communication services for various critical infrastructures.","These networks can seamlessly integrate with a diverse array of systems.","However, some of these systems are vulnerable due to the absence of effective intrusion detection systems, which can be attributed to limited research and the high costs associated with deploying, fine-tuning, monitoring, and responding to security breaches.","To address these challenges, we propose a pretrained Large Language Model for Cyber Security , for short PLLM-CS, which is a variant of pre-trained Transformers [1], which includes a specialized module for transforming network data into contextually suitable inputs.","This transformation enables the proposed LLM to encode contextual information within the cyber data.","To validate the efficacy of the proposed method, we conducted empirical experiments using two publicly available network datasets, UNSW_NB 15 and TON_IoT, both providing Internet of Things (IoT)-based traffic data.","Our experiments demonstrate that proposed LLM method outperforms state-of-the-art techniques such as BiLSTM, GRU, and CNN.","Notably, the PLLM-CS method achieves an outstanding accuracy level of 100% on the UNSW_NB 15 dataset, setting a new standard for benchmark performance in this domain."],"url":"http://arxiv.org/abs/2405.05469v1"}
{"created":"2024-05-08 23:52:37","title":"Model-Free Robust $\u03c6$-Divergence Reinforcement Learning Using Both Offline and Online Data","abstract":"The robust $\\phi$-regularized Markov Decision Process (RRMDP) framework focuses on designing control policies that are robust against parameter uncertainties due to mismatches between the simulator (nominal) model and real-world settings. This work makes two important contributions. First, we propose a model-free algorithm called Robust $\\phi$-regularized fitted Q-iteration (RPQ) for learning an $\\epsilon$-optimal robust policy that uses only the historical data collected by rolling out a behavior policy (with robust exploratory requirement) on the nominal model. To the best of our knowledge, we provide the first unified analysis for a class of $\\phi$-divergences achieving robust optimal policies in high-dimensional systems with general function approximation. Second, we introduce the hybrid robust $\\phi$-regularized reinforcement learning framework to learn an optimal robust policy using both historical data and online sampling. Towards this framework, we propose a model-free algorithm called Hybrid robust Total-variation-regularized Q-iteration (HyTQ: pronounced height-Q). To the best of our knowledge, we provide the first improved out-of-data-distribution assumption in large-scale problems with general function approximation under the hybrid robust $\\phi$-regularized reinforcement learning framework. Finally, we provide theoretical guarantees on the performance of the learned policies of our algorithms on systems with arbitrary large state space.","sentences":["The robust $\\phi$-regularized Markov Decision Process (RRMDP) framework focuses on designing control policies that are robust against parameter uncertainties due to mismatches between the simulator (nominal) model and real-world settings.","This work makes two important contributions.","First, we propose a model-free algorithm called Robust $\\phi$-regularized fitted Q-iteration (RPQ) for learning an $\\epsilon$-optimal robust policy that uses only the historical data collected by rolling out a behavior policy (with robust exploratory requirement) on the nominal model.","To the best of our knowledge, we provide the first unified analysis for a class of $\\phi$-divergences achieving robust optimal policies in high-dimensional systems with general function approximation.","Second, we introduce the hybrid robust $\\phi$-regularized reinforcement learning framework to learn an optimal robust policy using both historical data and online sampling.","Towards this framework, we propose a model-free algorithm called Hybrid robust Total-variation-regularized Q-iteration (HyTQ: pronounced height-Q).","To the best of our knowledge, we provide the first improved out-of-data-distribution assumption in large-scale problems with general function approximation under the hybrid robust $\\phi$-regularized reinforcement learning framework.","Finally, we provide theoretical guarantees on the performance of the learned policies of our algorithms on systems with arbitrary large state space."],"url":"http://arxiv.org/abs/2405.05468v1"}
{"created":"2024-05-08 23:50:54","title":"AFEN: Respiratory Disease Classification using Ensemble Learning","abstract":"We present AFEN (Audio Feature Ensemble Learning), a model that leverages Convolutional Neural Networks (CNN) and XGBoost in an ensemble learning fashion to perform state-of-the-art audio classification for a range of respiratory diseases. We use a meticulously selected mix of audio features which provide the salient attributes of the data and allow for accurate classification. The extracted features are then used as an input to two separate model classifiers 1) a multi-feature CNN classifier and 2) an XGBoost Classifier. The outputs of the two models are then fused with the use of soft voting. Thus, by exploiting ensemble learning, we achieve increased robustness and accuracy. We evaluate the performance of the model on a database of 920 respiratory sounds, which undergoes data augmentation techniques to increase the diversity of the data and generalizability of the model. We empirically verify that AFEN sets a new state-of-the-art using Precision and Recall as metrics, while decreasing training time by 60%.","sentences":["We present AFEN (Audio Feature Ensemble Learning), a model that leverages Convolutional Neural Networks (CNN) and XGBoost in an ensemble learning fashion to perform state-of-the-art audio classification for a range of respiratory diseases.","We use a meticulously selected mix of audio features which provide the salient attributes of the data and allow for accurate classification.","The extracted features are then used as an input to two separate model classifiers 1) a multi-feature CNN classifier and 2) an XGBoost Classifier.","The outputs of the two models are then fused with the use of soft voting.","Thus, by exploiting ensemble learning, we achieve increased robustness and accuracy.","We evaluate the performance of the model on a database of 920 respiratory sounds, which undergoes data augmentation techniques to increase the diversity of the data and generalizability of the model.","We empirically verify that AFEN sets a new state-of-the-art using Precision and Recall as metrics, while decreasing training time by 60%."],"url":"http://arxiv.org/abs/2405.05467v1"}
{"created":"2024-05-08 22:28:57","title":"Large Language Model Enhanced Machine Learning Estimators for Classification","abstract":"Pre-trained large language models (LLM) have emerged as a powerful tool for simulating various scenarios and generating output given specific instructions and multimodal input. In this work, we analyze the specific use of LLM to enhance a classical supervised machine learning method for classification problems. We propose a few approaches to integrate LLM into a classical machine learning estimator to further enhance the prediction performance. We examine the performance of the proposed approaches through both standard supervised learning binary classification tasks, and a transfer learning task where the test data observe distribution changes compared to the training data. Numerical experiments using four publicly available datasets are conducted and suggest that using LLM to enhance classical machine learning estimators can provide significant improvement on prediction performance.","sentences":["Pre-trained large language models (LLM) have emerged as a powerful tool for simulating various scenarios and generating output given specific instructions and multimodal input.","In this work, we analyze the specific use of LLM to enhance a classical supervised machine learning method for classification problems.","We propose a few approaches to integrate LLM into a classical machine learning estimator to further enhance the prediction performance.","We examine the performance of the proposed approaches through both standard supervised learning binary classification tasks, and a transfer learning task where the test data observe distribution changes compared to the training data.","Numerical experiments using four publicly available datasets are conducted and suggest that using LLM to enhance classical machine learning estimators can provide significant improvement on prediction performance."],"url":"http://arxiv.org/abs/2405.05445v1"}
{"created":"2024-05-08 22:00:35","title":"How Generalizable Is My Behavior Cloning Policy? A Statistical Approach to Trustworthy Performance Evaluation","abstract":"With the rise of stochastic generative models in robot policy learning, end-to-end visuomotor policies are increasingly successful at solving complex tasks by learning from human demonstrations. Nevertheless, since real-world evaluation costs afford users only a small number of policy rollouts, it remains a challenge to accurately gauge the performance of such policies. This is exacerbated by distribution shifts causing unpredictable changes in performance during deployment. To rigorously evaluate behavior cloning policies, we present a framework that provides a tight lower-bound on robot performance in an arbitrary environment, using a minimal number of experimental policy rollouts. Notably, by applying the standard stochastic ordering to robot performance distributions, we provide a worst-case bound on the entire distribution of performance (via bounds on the cumulative distribution function) for a given task. We build upon established statistical results to ensure that the bounds hold with a user-specified confidence level and tightness, and are constructed from as few policy rollouts as possible. In experiments we evaluate policies for visuomotor manipulation in both simulation and hardware. Specifically, we (i) empirically validate the guarantees of the bounds in simulated manipulation settings, (ii) find the degree to which a learned policy deployed on hardware generalizes to new real-world environments, and (iii) rigorously compare two policies tested in out-of-distribution settings. Our experimental data, code, and implementation of confidence bounds are open-source.","sentences":["With the rise of stochastic generative models in robot policy learning, end-to-end visuomotor policies are increasingly successful at solving complex tasks by learning from human demonstrations.","Nevertheless, since real-world evaluation costs afford users only a small number of policy rollouts, it remains a challenge to accurately gauge the performance of such policies.","This is exacerbated by distribution shifts causing unpredictable changes in performance during deployment.","To rigorously evaluate behavior cloning policies, we present a framework that provides a tight lower-bound on robot performance in an arbitrary environment, using a minimal number of experimental policy rollouts.","Notably, by applying the standard stochastic ordering to robot performance distributions, we provide a worst-case bound on the entire distribution of performance (via bounds on the cumulative distribution function) for a given task.","We build upon established statistical results to ensure that the bounds hold with a user-specified confidence level and tightness, and are constructed from as few policy rollouts as possible.","In experiments we evaluate policies for visuomotor manipulation in both simulation and hardware.","Specifically, we (i) empirically validate the guarantees of the bounds in simulated manipulation settings, (ii) find the degree to which a learned policy deployed on hardware generalizes to new real-world environments, and (iii) rigorously compare two policies tested in out-of-distribution settings.","Our experimental data, code, and implementation of confidence bounds are open-source."],"url":"http://arxiv.org/abs/2405.05439v1"}
{"created":"2024-05-08 21:23:01","title":"Towards Invariant Time Series Forecasting in Smart Cities","abstract":"In the transformative landscape of smart cities, the integration of the cutting-edge web technologies into time series forecasting presents a pivotal opportunity to enhance urban planning, sustainability, and economic growth. The advancement of deep neural networks has significantly improved forecasting performance. However, a notable challenge lies in the ability of these models to generalize well to out-of-distribution (OOD) time series data. The inherent spatial heterogeneity and domain shifts across urban environments create hurdles that prevent models from adapting and performing effectively in new urban environments. To tackle this problem, we propose a solution to derive invariant representations for more robust predictions under different urban environments instead of relying on spurious correlation across urban environments for better generalizability. Through extensive experiments on both synthetic and real-world data, we demonstrate that our proposed method outperforms traditional time series forecasting models when tackling domain shifts in changing urban environments. The effectiveness and robustness of our method can be extended to diverse fields including climate modeling, urban planning, and smart city resource management.","sentences":["In the transformative landscape of smart cities, the integration of the cutting-edge web technologies into time series forecasting presents a pivotal opportunity to enhance urban planning, sustainability, and economic growth.","The advancement of deep neural networks has significantly improved forecasting performance.","However, a notable challenge lies in the ability of these models to generalize well to out-of-distribution (OOD) time series data.","The inherent spatial heterogeneity and domain shifts across urban environments create hurdles that prevent models from adapting and performing effectively in new urban environments.","To tackle this problem, we propose a solution to derive invariant representations for more robust predictions under different urban environments instead of relying on spurious correlation across urban environments for better generalizability.","Through extensive experiments on both synthetic and real-world data, we demonstrate that our proposed method outperforms traditional time series forecasting models when tackling domain shifts in changing urban environments.","The effectiveness and robustness of our method can be extended to diverse fields including climate modeling, urban planning, and smart city resource management."],"url":"http://arxiv.org/abs/2405.05430v1"}
{"created":"2024-05-08 21:18:02","title":"Adversary-Guided Motion Retargeting for Skeleton Anonymization","abstract":"Skeleton-based motion visualization is a rising field in computer vision, especially in the case of virtual reality (VR). With further advancements in human-pose estimation and skeleton extracting sensors, more and more applications that utilize skeleton data have come about. These skeletons may appear to be anonymous but they contain embedded personally identifiable information (PII). In this paper we present a new anonymization technique that is based on motion retargeting, utilizing adversary classifiers to further remove PII embedded in the skeleton. Motion retargeting is effective in anonymization as it transfers the movement of the user onto the a dummy skeleton. In doing so, any PII linked to the skeleton will be based on the dummy skeleton instead of the user we are protecting. We propose a Privacy-centric Deep Motion Retargeting model (PMR) which aims to further clear the retargeted skeleton of PII through adversarial learning. In our experiments, PMR achieves motion retargeting utility performance on par with state of the art models while also reducing the performance of privacy attacks.","sentences":["Skeleton-based motion visualization is a rising field in computer vision, especially in the case of virtual reality (VR).","With further advancements in human-pose estimation and skeleton extracting sensors, more and more applications that utilize skeleton data have come about.","These skeletons may appear to be anonymous but they contain embedded personally identifiable information (PII).","In this paper we present a new anonymization technique that is based on motion retargeting, utilizing adversary classifiers to further remove PII embedded in the skeleton.","Motion retargeting is effective in anonymization as it transfers the movement of the user onto the a dummy skeleton.","In doing so, any PII linked to the skeleton will be based on the dummy skeleton instead of the user we are protecting.","We propose a Privacy-centric Deep Motion Retargeting model (PMR) which aims to further clear the retargeted skeleton of PII through adversarial learning.","In our experiments, PMR achieves motion retargeting utility performance on par with state of the art models while also reducing the performance of privacy attacks."],"url":"http://arxiv.org/abs/2405.05428v1"}
{"created":"2024-05-08 20:49:34","title":"Latent Variable Double Gaussian Process Model for Decoding Complex Neural Data","abstract":"Non-parametric models, such as Gaussian Processes (GP), show promising results in the analysis of complex data. Their applications in neuroscience data have recently gained traction. In this research, we introduce a novel neural decoder model built upon GP models. The core idea is that two GPs generate neural data and their associated labels using a set of low- dimensional latent variables. Under this modeling assumption, the latent variables represent the underlying manifold or essential features present in the neural data. When GPs are trained, the latent variable can be inferred from neural data to decode the labels with a high accuracy. We demonstrate an application of this decoder model in a verbal memory experiment dataset and show that the decoder accuracy in predicting stimulus significantly surpasses the state-of-the-art decoder models. The preceding performance of this model highlights the importance of utilizing non-parametric models in the analysis of neuroscience data.","sentences":["Non-parametric models, such as Gaussian Processes (GP), show promising results in the analysis of complex data.","Their applications in neuroscience data have recently gained traction.","In this research, we introduce a novel neural decoder model built upon GP models.","The core idea is that two GPs generate neural data and their associated labels using a set of low- dimensional latent variables.","Under this modeling assumption, the latent variables represent the underlying manifold or essential features present in the neural data.","When GPs are trained, the latent variable can be inferred from neural data to decode the labels with a high accuracy.","We demonstrate an application of this decoder model in a verbal memory experiment dataset and show that the decoder accuracy in predicting stimulus significantly surpasses the state-of-the-art decoder models.","The preceding performance of this model highlights the importance of utilizing non-parametric models in the analysis of neuroscience data."],"url":"http://arxiv.org/abs/2405.05424v1"}
{"created":"2024-05-08 20:46:36","title":"EarthMatch: Iterative Coregistration for Fine-grained Localization of Astronaut Photography","abstract":"Precise, pixel-wise geolocalization of astronaut photography is critical to unlocking the potential of this unique type of remotely sensed Earth data, particularly for its use in disaster management and climate change research. Recent works have established the Astronaut Photography Localization task, but have either proved too costly for mass deployment or generated too coarse a localization. Thus, we present EarthMatch, an iterative homography estimation method that produces fine-grained localization of astronaut photographs while maintaining an emphasis on speed. We refocus the astronaut photography benchmark, AIMS, on the geolocalization task itself, and prove our method's efficacy on this dataset. In addition, we offer a new, fair method for image matcher comparison, and an extensive evaluation of different matching models within our localization pipeline. Our method will enable fast and accurate localization of the 4.5 million and growing collection of astronaut photography of Earth. Webpage with code and data at https://earthloc-and-earthmatch.github.io","sentences":["Precise, pixel-wise geolocalization of astronaut photography is critical to unlocking the potential of this unique type of remotely sensed Earth data, particularly for its use in disaster management and climate change research.","Recent works have established the Astronaut Photography Localization task, but have either proved too costly for mass deployment or generated too coarse a localization.","Thus, we present EarthMatch, an iterative homography estimation method that produces fine-grained localization of astronaut photographs while maintaining an emphasis on speed.","We refocus the astronaut photography benchmark, AIMS, on the geolocalization task itself, and prove our method's efficacy on this dataset.","In addition, we offer a new, fair method for image matcher comparison, and an extensive evaluation of different matching models within our localization pipeline.","Our method will enable fast and accurate localization of the 4.5 million and growing collection of astronaut photography of Earth.","Webpage with code and data at https://earthloc-and-earthmatch.github.io"],"url":"http://arxiv.org/abs/2405.05422v1"}
{"created":"2024-05-08 20:33:32","title":"Digital Evolution: Novo Nordisk's Shift to Ontology-Based Data Management","abstract":"Biomedical data is growing exponentially, and managing it is increasingly challenging. While Findable, Accessible, Interoperable and Reusable (FAIR) data principles provide guidance, their adoption has proven difficult, especially in larger enterprises like pharmaceutical companies. In this manuscript, we describe how we leverage an Ontology-Based Data Management (OBDM) strategy for digital transformation in Novo Nordisk Research & Early Development. Here, we include both our technical blueprint and our approach for organizational change management. We further discuss how such an OBDM ecosystem plays a pivotal role in the organizations digital aspirations for data federation and discovery fuelled by artificial intelligence. Our aim for this paper is to share the lessons learned in order to foster dialogue with parties navigating similar waters while collectively advancing the efforts in the fields of data management, semantics and data driven drug discovery.","sentences":["Biomedical data is growing exponentially, and managing it is increasingly challenging.","While Findable, Accessible, Interoperable and Reusable (FAIR) data principles provide guidance, their adoption has proven difficult, especially in larger enterprises like pharmaceutical companies.","In this manuscript, we describe how we leverage an Ontology-Based Data Management (OBDM) strategy for digital transformation in Novo Nordisk Research & Early Development.","Here, we include both our technical blueprint and our approach for organizational change management.","We further discuss how such an OBDM ecosystem plays a pivotal role in the organizations digital aspirations for data federation and discovery fuelled by artificial intelligence.","Our aim for this paper is to share the lessons learned in order to foster dialogue with parties navigating similar waters while collectively advancing the efforts in the fields of data management, semantics and data driven drug discovery."],"url":"http://arxiv.org/abs/2405.05413v1"}
{"created":"2024-05-08 20:23:24","title":"Initialization is Critical to Whether Transformers Fit Composite Functions by Inference or Memorizing","abstract":"Transformers have shown impressive capabilities across various tasks, but their performance on compositional problems remains a topic of debate. In this work, we investigate the mechanisms of how transformers behave on unseen compositional tasks using anchor functions. We discover that the parameter initialization scale plays a critical role in determining whether the model learns inferential solutions, which capture the underlying compositional primitives, or symmetric solutions, which simply memorize mappings without understanding the compositional structure. By analyzing the information flow and vector representations within the model, we reveal the distinct mechanisms underlying these solution types. We further find that inferential solutions exhibit low complexity bias, which we hypothesize is a key factor enabling them to learn individual mappings for single anchors. Building upon our understanding of these mechanisms, we can predict the learning behavior of models with different initialization scales when faced with data of varying inferential complexity. Our findings provide valuable insights into the role of initialization scale in shaping the type of solution learned by transformers and their ability to learn and generalize compositional functions.","sentences":["Transformers have shown impressive capabilities across various tasks, but their performance on compositional problems remains a topic of debate.","In this work, we investigate the mechanisms of how transformers behave on unseen compositional tasks using anchor functions.","We discover that the parameter initialization scale plays a critical role in determining whether the model learns inferential solutions, which capture the underlying compositional primitives, or symmetric solutions, which simply memorize mappings without understanding the compositional structure.","By analyzing the information flow and vector representations within the model, we reveal the distinct mechanisms underlying these solution types.","We further find that inferential solutions exhibit low complexity bias, which we hypothesize is a key factor enabling them to learn individual mappings for single anchors.","Building upon our understanding of these mechanisms, we can predict the learning behavior of models with different initialization scales when faced with data of varying inferential complexity.","Our findings provide valuable insights into the role of initialization scale in shaping the type of solution learned by transformers and their ability to learn and generalize compositional functions."],"url":"http://arxiv.org/abs/2405.05409v1"}
{"created":"2024-05-08 20:03:12","title":"ASPIRE: Iterative Amortized Posterior Inference for Bayesian Inverse Problems","abstract":"Due to their uncertainty quantification, Bayesian solutions to inverse problems are the framework of choice in applications that are risk averse. These benefits come at the cost of computations that are in general, intractable. New advances in machine learning and variational inference (VI) have lowered the computational barrier by learning from examples. Two VI paradigms have emerged that represent different tradeoffs: amortized and non-amortized. Amortized VI can produce fast results but due to generalizing to many observed datasets it produces suboptimal inference results. Non-amortized VI is slower at inference but finds better posterior approximations since it is specialized towards a single observed dataset. Current amortized VI techniques run into a sub-optimality wall that can not be improved without more expressive neural networks or extra training data. We present a solution that enables iterative improvement of amortized posteriors that uses the same networks architectures and training data. The benefits of our method requires extra computations but these remain frugal since they are based on physics-hybrid methods and summary statistics. Importantly, these computations remain mostly offline thus our method maintains cheap and reusable online evaluation while bridging the approximation gap these two paradigms. We denote our proposed method ASPIRE - Amortized posteriors with Summaries that are Physics-based and Iteratively REfined. We first validate our method on a stylized problem with a known posterior then demonstrate its practical use on a high-dimensional and nonlinear transcranial medical imaging problem with ultrasound. Compared with the baseline and previous methods from the literature our method stands out as an computationally efficient and high-fidelity method for posterior inference.","sentences":["Due to their uncertainty quantification, Bayesian solutions to inverse problems are the framework of choice in applications that are risk averse.","These benefits come at the cost of computations that are in general, intractable.","New advances in machine learning and variational inference (VI) have lowered the computational barrier by learning from examples.","Two VI paradigms have emerged that represent different tradeoffs: amortized and non-amortized.","Amortized VI can produce fast results but due to generalizing to many observed datasets it produces suboptimal inference results.","Non-amortized VI is slower at inference but finds better posterior approximations since it is specialized towards a single observed dataset.","Current amortized VI techniques run into a sub-optimality wall that can not be improved without more expressive neural networks or extra training data.","We present a solution that enables iterative improvement of amortized posteriors that uses the same networks architectures and training data.","The benefits of our method requires extra computations but these remain frugal since they are based on physics-hybrid methods and summary statistics.","Importantly, these computations remain mostly offline thus our method maintains cheap and reusable online evaluation while bridging the approximation gap these two paradigms.","We denote our proposed method ASPIRE - Amortized posteriors with Summaries that are Physics-based and Iteratively REfined.","We first validate our method on a stylized problem with a known posterior then demonstrate its practical use on a high-dimensional and nonlinear transcranial medical imaging problem with ultrasound.","Compared with the baseline and previous methods from the literature our method stands out as an computationally efficient and high-fidelity method for posterior inference."],"url":"http://arxiv.org/abs/2405.05398v1"}
{"created":"2024-05-08 19:00:21","title":"Certifying Euclidean Sections and Finding Planted Sparse Vectors Beyond the $\\sqrt{n}$ Dimension Threshold","abstract":"We consider the task of certifying that a random $d$-dimensional subspace $X$ in $\\mathbb{R}^n$ is well-spread - every vector $x \\in X$ satisfies $c\\sqrt{n} \\|x\\|_2 \\leq \\|x\\|_1 \\leq \\sqrt{n}\\|x\\|_2$. In a seminal work, Barak et. al. showed a polynomial-time certification algorithm when $d \\leq O(\\sqrt{n})$. On the other hand, when $d \\gg \\sqrt{n}$, the certification task is information-theoretically possible but there is evidence that it is computationally hard [MW21,Cd22], a phenomenon known as the information-computation gap.   In this paper, we give subexponential-time certification algorithms in the $d \\gg \\sqrt{n}$ regime. Our algorithm runs in time $\\exp(\\widetilde{O}(n^{\\varepsilon}))$ when $d \\leq \\widetilde{O}(n^{(1+\\varepsilon)/2})$, establishing a smooth trade-off between runtime and the dimension.   Our techniques naturally extend to the related planted problem, where the task is to recover a sparse vector planted in a random subspace. Our algorithm achieves the same runtime and dimension trade-off for this task.","sentences":["We consider the task of certifying that a random $d$-dimensional subspace $X$ in $\\mathbb{R}^n$ is well-spread - every vector $x \\in X$ satisfies $c\\sqrt{n} \\|x\\|_2 \\leq \\|x\\|_1 \\leq \\sqrt{n}\\|x\\|_2$.","In a seminal work, Barak et.","al. showed a polynomial-time certification algorithm when $d \\leq O(\\sqrt{n})$.","On the other hand, when $d \\gg \\sqrt{n}$, the certification task is information-theoretically possible but there is evidence that it is computationally hard","[MW21,Cd22], a phenomenon known as the information-computation gap.   ","In this paper, we give subexponential-time certification algorithms in the $d \\gg \\sqrt{n}$ regime.","Our algorithm runs in time $\\exp(\\widetilde{O}(n^{\\varepsilon}))$ when","$d \\leq \\widetilde{O}(n^{(1+\\varepsilon)/2})$, establishing a smooth trade-off between runtime and the dimension.   ","Our techniques naturally extend to the related planted problem, where the task is to recover a sparse vector planted in a random subspace.","Our algorithm achieves the same runtime and dimension trade-off for this task."],"url":"http://arxiv.org/abs/2405.05373v1"}
{"created":"2024-05-08 18:27:37","title":"Offline Model-Based Optimization via Policy-Guided Gradient Search","abstract":"Offline optimization is an emerging problem in many experimental engineering domains including protein, drug or aircraft design, where online experimentation to collect evaluation data is too expensive or dangerous. To avoid that, one has to optimize an unknown function given only its offline evaluation at a fixed set of inputs. A naive solution to this problem is to learn a surrogate model of the unknown function and optimize this surrogate instead. However, such a naive optimizer is prone to erroneous overestimation of the surrogate (possibly due to over-fitting on a biased sample of function evaluation) on inputs outside the offline dataset. Prior approaches addressing this challenge have primarily focused on learning robust surrogate models. However, their search strategies are derived from the surrogate model rather than the actual offline data. To fill this important gap, we introduce a new learning-to-search perspective for offline optimization by reformulating it as an offline reinforcement learning problem. Our proposed policy-guided gradient search approach explicitly learns the best policy for a given surrogate model created from the offline data. Our empirical results on multiple benchmarks demonstrate that the learned optimization policy can be combined with existing offline surrogates to significantly improve the optimization performance.","sentences":["Offline optimization is an emerging problem in many experimental engineering domains including protein, drug or aircraft design, where online experimentation to collect evaluation data is too expensive or dangerous.","To avoid that, one has to optimize an unknown function given only its offline evaluation at a fixed set of inputs.","A naive solution to this problem is to learn a surrogate model of the unknown function and optimize this surrogate instead.","However, such a naive optimizer is prone to erroneous overestimation of the surrogate (possibly due to over-fitting on a biased sample of function evaluation) on inputs outside the offline dataset.","Prior approaches addressing this challenge have primarily focused on learning robust surrogate models.","However, their search strategies are derived from the surrogate model rather than the actual offline data.","To fill this important gap, we introduce a new learning-to-search perspective for offline optimization by reformulating it as an offline reinforcement learning problem.","Our proposed policy-guided gradient search approach explicitly learns the best policy for a given surrogate model created from the offline data.","Our empirical results on multiple benchmarks demonstrate that the learned optimization policy can be combined with existing offline surrogates to significantly improve the optimization performance."],"url":"http://arxiv.org/abs/2405.05349v1"}
{"created":"2024-05-08 18:20:03","title":"QuaLLM: An LLM-based Framework to Extract Quantitative Insights from Online Forums","abstract":"Online discussion forums provide crucial data to understand the concerns of a wide range of real-world communities. However, the typical qualitative and quantitative methods used to analyze those data, such as thematic analysis and topic modeling, are infeasible to scale or require significant human effort to translate outputs to human readable forms. This study introduces QuaLLM, a novel LLM-based framework to analyze and extract quantitative insights from text data on online forums. The framework consists of a novel prompting methodology and evaluation strategy. We applied this framework to analyze over one million comments from two Reddit's rideshare worker communities, marking the largest study of its type. We uncover significant worker concerns regarding AI and algorithmic platform decisions, responding to regulatory calls about worker insights. In short, our work sets a new precedent for AI-assisted quantitative data analysis to surface concerns from online forums.","sentences":["Online discussion forums provide crucial data to understand the concerns of a wide range of real-world communities.","However, the typical qualitative and quantitative methods used to analyze those data, such as thematic analysis and topic modeling, are infeasible to scale or require significant human effort to translate outputs to human readable forms.","This study introduces QuaLLM, a novel LLM-based framework to analyze and extract quantitative insights from text data on online forums.","The framework consists of a novel prompting methodology and evaluation strategy.","We applied this framework to analyze over one million comments from two Reddit's rideshare worker communities, marking the largest study of its type.","We uncover significant worker concerns regarding AI and algorithmic platform decisions, responding to regulatory calls about worker insights.","In short, our work sets a new precedent for AI-assisted quantitative data analysis to surface concerns from online forums."],"url":"http://arxiv.org/abs/2405.05345v1"}
{"created":"2024-05-08 18:16:37","title":"Distributed Least Squares in Small Space via Sketching and Bias Reduction","abstract":"Matrix sketching is a powerful tool for reducing the size of large data matrices. Yet there are fundamental limitations to this size reduction when we want to recover an accurate estimator for a task such as least square regression. We show that these limitations can be circumvented in the distributed setting by designing sketching methods that minimize the bias of the estimator, rather than its error. In particular, we give a sparse sketching method running in optimal space and current matrix multiplication time, which recovers a nearly-unbiased least squares estimator using two passes over the data. This leads to new communication-efficient distributed averaging algorithms for least squares and related tasks, which directly improve on several prior approaches. Our key novelty is a new bias analysis for sketched least squares, giving a sharp characterization of its dependence on the sketch sparsity. The techniques include new higher-moment restricted Bai-Silverstein inequalities, which are of independent interest to the non-asymptotic analysis of deterministic equivalents for random matrices that arise from sketching.","sentences":["Matrix sketching is a powerful tool for reducing the size of large data matrices.","Yet there are fundamental limitations to this size reduction when we want to recover an accurate estimator for a task such as least square regression.","We show that these limitations can be circumvented in the distributed setting by designing sketching methods that minimize the bias of the estimator, rather than its error.","In particular, we give a sparse sketching method running in optimal space and current matrix multiplication time, which recovers a nearly-unbiased least squares estimator using two passes over the data.","This leads to new communication-efficient distributed averaging algorithms for least squares and related tasks, which directly improve on several prior approaches.","Our key novelty is a new bias analysis for sketched least squares, giving a sharp characterization of its dependence on the sketch sparsity.","The techniques include new higher-moment restricted Bai-Silverstein inequalities, which are of independent interest to the non-asymptotic analysis of deterministic equivalents for random matrices that arise from sketching."],"url":"http://arxiv.org/abs/2405.05343v1"}
