{"created":"2023-12-13 18:59:58","title":"SAM-guided Graph Cut for 3D Instance Segmentation","abstract":"This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information. Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation. However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data. Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework. The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation. Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem. The superpoint graph is constructed based on 2D segmentation models, where node features are obtained from multi-view image features and edge weights are computed based on multi-view segmentation results, enabling the better generalization ability. To process the graph, we train a graph neural network using pseudo 3D labels from 2D segmentation models. Experimental results on the ScanNet, ScanNet++ and KITTI-360 datasets demonstrate that our method achieves robust segmentation performance and can generalize across different types of scenes. Our project page is available at https://zju3dv.github.io/sam_graph.","sentences":["This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information.","Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation.","However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data.","Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework.","The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation.","In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation.","Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem.","The superpoint graph is constructed based on 2D segmentation models, where node features are obtained from multi-view image features and edge weights are computed based on multi-view segmentation results, enabling the better generalization ability.","To process the graph, we train a graph neural network using pseudo 3D labels from 2D segmentation models.","Experimental results on the ScanNet, ScanNet++ and KITTI-360 datasets demonstrate that our method achieves robust segmentation performance and can generalize across different types of scenes.","Our project page is available at https://zju3dv.github.io/sam_graph."],"url":"http://arxiv.org/abs/2312.08372v1"}
{"created":"2023-12-13 18:56:13","title":"View-Dependent Octree-based Mesh Extraction in Unbounded Scenes for Procedural Synthetic Data","abstract":"Procedural synthetic data generation has received increasing attention in computer vision. Procedural signed distance functions (SDFs) are a powerful tool for modeling large-scale detailed scenes, but existing mesh extraction methods have artifacts or performance profiles that limit their use for synthetic data. We propose OcMesher, a mesh extraction algorithm that efficiently handles high-detail unbounded scenes with perfect view-consistency, with easy export to downstream real-time engines. The main novelty of our solution is an algorithm to construct an octree based on a given SDF and multiple camera views. We performed extensive experiments, and show our solution produces better synthetic data for training and evaluation of computer vision models.","sentences":["Procedural synthetic data generation has received increasing attention in computer vision.","Procedural signed distance functions (SDFs) are a powerful tool for modeling large-scale detailed scenes, but existing mesh extraction methods have artifacts or performance profiles that limit their use for synthetic data.","We propose OcMesher, a mesh extraction algorithm that efficiently handles high-detail unbounded scenes with perfect view-consistency, with easy export to downstream real-time engines.","The main novelty of our solution is an algorithm to construct an octree based on a given SDF and multiple camera views.","We performed extensive experiments, and show our solution produces better synthetic data for training and evaluation of computer vision models."],"url":"http://arxiv.org/abs/2312.08364v1"}
{"created":"2023-12-13 18:51:34","title":"Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF","abstract":"In practice, preference learning from human feedback depends on incomplete data with hidden context. Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model. This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria. We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count. We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility. Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function. A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF. As a step towards mitigating these problems, we introduce a class of methods called distributional preference learning (DPL). DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context. Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability. Our code and data are available at https://github.com/cassidylaidlaw/hidden-context","sentences":["In practice, preference learning from human feedback depends on incomplete data with hidden context.","Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model.","This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria.","We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count.","We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility.","Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function.","A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF.","As a step towards mitigating these problems, we introduce a class of methods called distributional preference learning (DPL).","DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context.","Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability.","Our code and data are available at https://github.com/cassidylaidlaw/hidden-context"],"url":"http://arxiv.org/abs/2312.08358v1"}
{"created":"2023-12-13 18:11:37","title":"LD-SDM: Language-Driven Hierarchical Species Distribution Modeling","abstract":"We focus on the problem of species distribution modeling using global-scale presence-only data. Most previous studies have mapped the range of a given species using geographical and environmental features alone. To capture a stronger implicit relationship between species, we encode the taxonomic hierarchy of species using a large language model. This enables range mapping for any taxonomic rank and unseen species without additional supervision. Further, we propose a novel proximity-aware evaluation metric that enables evaluating species distribution models using any pixel-level representation of ground-truth species range map. The proposed metric penalizes the predictions of a model based on its proximity to the ground truth. We describe the effectiveness of our model by systematically evaluating on the task of species range prediction, zero-shot prediction and geo-feature regression against the state-of-the-art. Results show our model outperforms the strong baselines when trained with a variety of multi-label learning losses.","sentences":["We focus on the problem of species distribution modeling using global-scale presence-only data.","Most previous studies have mapped the range of a given species using geographical and environmental features alone.","To capture a stronger implicit relationship between species, we encode the taxonomic hierarchy of species using a large language model.","This enables range mapping for any taxonomic rank and unseen species without additional supervision.","Further, we propose a novel proximity-aware evaluation metric that enables evaluating species distribution models using any pixel-level representation of ground-truth species range map.","The proposed metric penalizes the predictions of a model based on its proximity to the ground truth.","We describe the effectiveness of our model by systematically evaluating on the task of species range prediction, zero-shot prediction and geo-feature regression against the state-of-the-art.","Results show our model outperforms the strong baselines when trained with a variety of multi-label learning losses."],"url":"http://arxiv.org/abs/2312.08334v1"}
{"created":"2023-12-13 17:27:17","title":"FASTEN: Towards a FAult-tolerant and STorage EfficieNt Cloud: Balancing Between Replication and Deduplication","abstract":"With the surge in cloud storage adoption, enterprises face challenges managing data duplication and exponential data growth. Deduplication mitigates redundancy, yet maintaining redundancy ensures high availability, incurring storage costs. Balancing these aspects is a significant research concern. We propose FASTEN, a distributed cloud storage scheme ensuring efficiency, security, and high availability. FASTEN achieves fault tolerance by dispersing data subsets optimally across servers and maintains redundancy for high availability. Experimental results show FASTEN's effectiveness in fault tolerance, cost reduction, batch auditing, and file and block-level deduplication. It outperforms existing systems with low time complexity, strong fault tolerance, and commendable deduplication performance.","sentences":["With the surge in cloud storage adoption, enterprises face challenges managing data duplication and exponential data growth.","Deduplication mitigates redundancy, yet maintaining redundancy ensures high availability, incurring storage costs.","Balancing these aspects is a significant research concern.","We propose FASTEN, a distributed cloud storage scheme ensuring efficiency, security, and high availability.","FASTEN achieves fault tolerance by dispersing data subsets optimally across servers and maintains redundancy for high availability.","Experimental results show FASTEN's effectiveness in fault tolerance, cost reduction, batch auditing, and file and block-level deduplication.","It outperforms existing systems with low time complexity, strong fault tolerance, and commendable deduplication performance."],"url":"http://arxiv.org/abs/2312.08309v1"}
{"created":"2023-12-13 17:26:30","title":"ConChain: A Scheme for Contention-free and Attack Resilient BlockChain","abstract":"Although blockchains have become widely popular for their use in cryptocurrencies, they are now becoming pervasive as more traditional applications adopt blockchain to ensure data security. Despite being a secured network, blockchains have some tradeoffs such as high latency, low throughput, and transaction failures. One of the core problems behind these is improper management of \"conflicting transactions\", which is also known as \"contention\". When there is a large pool of pending transactions in a blockchain and some of them are conflicting, a situation of contention occurs, and as a result, the latency of the network increases, and a substantial amount of resources are wasted which results in low throughput and transaction failures. In this paper, we proposed ConChain, a novel blockchain scheme that combines transaction parallelism and an intelligent dependency manager to minimize conflicting transactions in blockchain networks as well as improve performance. ConChain is also capable of ensuring proper defense against major attacks due to contention.","sentences":["Although blockchains have become widely popular for their use in cryptocurrencies, they are now becoming pervasive as more traditional applications adopt blockchain to ensure data security.","Despite being a secured network, blockchains have some tradeoffs such as high latency, low throughput, and transaction failures.","One of the core problems behind these is improper management of \"conflicting transactions\", which is also known as \"contention\".","When there is a large pool of pending transactions in a blockchain and some of them are conflicting, a situation of contention occurs, and as a result, the latency of the network increases, and a substantial amount of resources are wasted which results in low throughput and transaction failures.","In this paper, we proposed ConChain, a novel blockchain scheme that combines transaction parallelism and an intelligent dependency manager to minimize conflicting transactions in blockchain networks as well as improve performance.","ConChain is also capable of ensuring proper defense against major attacks due to contention."],"url":"http://arxiv.org/abs/2312.08305v1"}
{"created":"2023-12-13 17:15:12","title":"Conceptualizing Suicidal Behavior: Utilizing Explanations of Predicted Outcomes to Analyze Longitudinal Social Media Data","abstract":"The COVID-19 pandemic has escalated mental health crises worldwide, with social isolation and economic instability contributing to a rise in suicidal behavior. Suicide can result from social factors such as shame, abuse, abandonment, and mental health conditions like depression, Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), anxiety disorders, and bipolar disorders. As these conditions develop, signs of suicidal ideation may manifest in social media interactions. Analyzing social media data using artificial intelligence (AI) techniques can help identify patterns of suicidal behavior, providing invaluable insights for suicide prevention agencies, professionals, and broader community awareness initiatives. Machine learning algorithms for this purpose require large volumes of accurately labeled data. Previous research has not fully explored the potential of incorporating explanations in analyzing and labeling longitudinal social media data. In this study, we employed a model explanation method, Layer Integrated Gradients, on top of a fine-tuned state-of-the-art language model, to assign each token from Reddit users' posts an attribution score for predicting suicidal ideation. By extracting and analyzing attributions of tokens from the data, we propose a methodology for preliminary screening of social media posts for suicidal ideation without using large language models during inference.","sentences":["The COVID-19 pandemic has escalated mental health crises worldwide, with social isolation and economic instability contributing to a rise in suicidal behavior.","Suicide can result from social factors such as shame, abuse, abandonment, and mental health conditions like depression, Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), anxiety disorders, and bipolar disorders.","As these conditions develop, signs of suicidal ideation may manifest in social media interactions.","Analyzing social media data using artificial intelligence (AI) techniques can help identify patterns of suicidal behavior, providing invaluable insights for suicide prevention agencies, professionals, and broader community awareness initiatives.","Machine learning algorithms for this purpose require large volumes of accurately labeled data.","Previous research has not fully explored the potential of incorporating explanations in analyzing and labeling longitudinal social media data.","In this study, we employed a model explanation method, Layer Integrated Gradients, on top of a fine-tuned state-of-the-art language model, to assign each token from Reddit users' posts an attribution score for predicting suicidal ideation.","By extracting and analyzing attributions of tokens from the data, we propose a methodology for preliminary screening of social media posts for suicidal ideation without using large language models during inference."],"url":"http://arxiv.org/abs/2312.08299v1"}
{"created":"2023-12-13 17:13:08","title":"Venn: Resource Management Across Federated Learning Jobs","abstract":"In recent years, federated learning (FL) has emerged as a promising approach for machine learning (ML) and data science across distributed edge devices. With the increasing popularity of FL, resource contention between multiple FL jobs training on the same device population is increasing as well. Scheduling edge resources among multiple FL jobs is different from GPU scheduling for cloud ML because of the ephemeral nature and planetary scale of participating devices as well as the overlapping resource requirements of diverse FL jobs. Existing resource managers for FL jobs opt for random assignment of devices to FL jobs for simplicity and scalability, which leads to poor performance. In this paper, we present Venn, an FL resource manager, that efficiently schedules ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing their average job completion time (JCT). Venn formulates the Intersection Resource Scheduling (IRS) problem to identify complex resource contention among multiple FL jobs. Then, Venn proposes a contention-aware scheduling heuristic to minimize the average scheduling delay. Furthermore, it proposes a resource-aware device-to-job matching heuristic that focuses on optimizing response collection time by mitigating stragglers. Our evaluation shows that, compared to the state-of-the-art FL resource managers, Venn improves the average JCT by up to 1.88X.","sentences":["In recent years, federated learning (FL) has emerged as a promising approach for machine learning (ML) and data science across distributed edge devices.","With the increasing popularity of FL, resource contention between multiple FL jobs training on the same device population is increasing as well.","Scheduling edge resources among multiple FL jobs is different from GPU scheduling for cloud ML because of the ephemeral nature and planetary scale of participating devices as well as the overlapping resource requirements of diverse FL jobs.","Existing resource managers for FL jobs opt for random assignment of devices to FL jobs for simplicity and scalability, which leads to poor performance.","In this paper, we present Venn, an FL resource manager, that efficiently schedules ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing their average job completion time (JCT).","Venn formulates the Intersection Resource Scheduling (IRS) problem to identify complex resource contention among multiple FL jobs.","Then, Venn proposes a contention-aware scheduling heuristic to minimize the average scheduling delay.","Furthermore, it proposes a resource-aware device-to-job matching heuristic that focuses on optimizing response collection time by mitigating stragglers.","Our evaluation shows that, compared to the state-of-the-art FL resource managers, Venn improves the average JCT by up to 1.88X."],"url":"http://arxiv.org/abs/2312.08298v1"}
{"created":"2023-12-13 17:04:16","title":"Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting","abstract":"Deep learning models are known to suffer from the problem of bias, and researchers have been exploring methods to address this issue. However, most of these methods require prior knowledge of the bias and are not always practical. In this paper, we focus on a more practical setting with no prior information about the bias. Generally, in this setting, there are a large number of bias-aligned samples that cause the model to produce biased predictions and a few bias-conflicting samples that do not conform to the bias. If the training data is limited, the influence of the bias-aligned samples may become even stronger on the model predictions, and we experimentally demonstrate that existing debiasing techniques suffer severely in such cases. In this paper, we examine the effects of unknown bias in small dataset regimes and present a novel approach to mitigate this issue. The proposed approach directly addresses the issue of the extremely low occurrence of bias-conflicting samples in limited data settings through the synthesis of hybrid samples that can be used to reduce the effect of bias. We perform extensive experiments on several benchmark datasets and experimentally demonstrate the effectiveness of our proposed approach in addressing any unknown bias in the presence of limited data. Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a bias-conflicting sample ratio of 0.05.","sentences":["Deep learning models are known to suffer from the problem of bias, and researchers have been exploring methods to address this issue.","However, most of these methods require prior knowledge of the bias and are not always practical.","In this paper, we focus on a more practical setting with no prior information about the bias.","Generally, in this setting, there are a large number of bias-aligned samples that cause the model to produce biased predictions and a few bias-conflicting samples that do not conform to the bias.","If the training data is limited, the influence of the bias-aligned samples may become even stronger on the model predictions, and we experimentally demonstrate that existing debiasing techniques suffer severely in such cases.","In this paper, we examine the effects of unknown bias in small dataset regimes and present a novel approach to mitigate this issue.","The proposed approach directly addresses the issue of the extremely low occurrence of bias-conflicting samples in limited data settings through the synthesis of hybrid samples that can be used to reduce the effect of bias.","We perform extensive experiments on several benchmark datasets and experimentally demonstrate the effectiveness of our proposed approach in addressing any unknown bias in the presence of limited data.","Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a bias-conflicting sample ratio of 0.05."],"url":"http://arxiv.org/abs/2312.08288v1"}
{"created":"2023-12-13 17:04:09","title":"On the verification of Embeddings using Hybrid Markov Logic","abstract":"The standard approach to verify representations learned by Deep Neural Networks is to use them in specific tasks such as classification or regression, and measure their performance based on accuracy in such tasks. However, in many cases, we would want to verify more complex properties of a learned representation. To do this, we propose a framework based on a probabilistic first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we specify properties over embeddings mixed with symbolic domain knowledge. We present an approach to learn parameters for the properties within this framework. Further, we develop a verification method to test embeddings in this framework by encoding this task as a Mixed Integer Linear Program for which we can leverage existing state-of-the-art solvers. We illustrate verification in Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems to demonstrate the generality of our approach.","sentences":["The standard approach to verify representations learned by Deep Neural Networks is to use them in specific tasks such as classification or regression, and measure their performance based on accuracy in such tasks.","However, in many cases, we would want to verify more complex properties of a learned representation.","To do this, we propose a framework based on a probabilistic first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we specify properties over embeddings mixed with symbolic domain knowledge.","We present an approach to learn parameters for the properties within this framework.","Further, we develop a verification method to test embeddings in this framework by encoding this task as a Mixed Integer Linear Program for which we can leverage existing state-of-the-art solvers.","We illustrate verification in Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems to demonstrate the generality of our approach."],"url":"http://arxiv.org/abs/2312.08287v1"}
{"created":"2023-12-13 16:13:23","title":"A Survey of Generative AI for Intelligent Transportation Systems","abstract":"Intelligent transportation systems play a crucial role in modern traffic management and optimization, greatly improving traffic efficiency and safety. With the rapid development of generative artificial intelligence (Generative AI) technologies in the fields of image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems, such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty. In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in intelligent transportation systems. First, we introduce the principles of different generative AI techniques, and their potential applications. Then, we classify tasks in intelligent transportation systems into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making. We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks. Finally, we summarize the challenges faced in applying generative AI to intelligent transportation systems, and discuss future research directions based on different application scenarios.","sentences":["Intelligent transportation systems play a crucial role in modern traffic management and optimization, greatly improving traffic efficiency and safety.","With the rapid development of generative artificial intelligence (Generative AI) technologies in the fields of image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems, such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty.","In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in intelligent transportation systems.","First, we introduce the principles of different generative AI techniques, and their potential applications.","Then, we classify tasks in intelligent transportation systems into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making.","We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks.","Finally, we summarize the challenges faced in applying generative AI to intelligent transportation systems, and discuss future research directions based on different application scenarios."],"url":"http://arxiv.org/abs/2312.08248v1"}
{"created":"2023-12-13 15:58:40","title":"From Brussels Effect to Gravity Assists: Understanding the Evolution of the GDPR-Inspired Personal Information Protection Law in China","abstract":"This paper explores the evolution of China's Personal Information Protection Law (PIPL) and situates it within the context of global data protection development. It draws inspiration from the theory of 'Brussels Effect' and its precedents, that describes the extraterritorial influence of EU regulations. Our objective is not to provide a commentary on China's legal development but to illuminate the intricate dynamics between the Chinese law and the EU's GDPR. It is argued that the trajectory of China's Personal Information Protection Law calls into question the applicability of the Brussels Effect: while the GDPR's imprint on the PIPL is evident, a deeper analysis unveils China's nuanced, non-linear adoption that diverges from many assumptions of the Brussels Effect and similar theories. The evolution of the GDPR-inspired PIPL is not as a straightforward outcome of the Brussels Effect but as a nuanced, intricate interplay of external influence and domestic dynamics. We introduce a complementary theory of 'gravity assist' which portrays China's strategic instrumentalisation of the GDPR as a template to shape its unique data protection landscape. Our conceptual framework highlights how China navigates through a patchwork of internal considerations, international standards, and strategic choices, ultimately sculpting a data protection regime that has a similar appearance to the GDPR but aligns with its distinct political, cultural and legal landscape. This reveals much about how China takes in the foundational premises of data protection that are inherently built in Europe's cherishment of the rule of law, democracy and human rights on the one hand, and the evaluation of data protection as a fundamental right.","sentences":["This paper explores the evolution of China's Personal Information Protection Law (PIPL) and situates it within the context of global data protection development.","It draws inspiration from the theory of 'Brussels Effect' and its precedents, that describes the extraterritorial influence of EU regulations.","Our objective is not to provide a commentary on China's legal development but to illuminate the intricate dynamics between the Chinese law and the EU's GDPR.","It is argued that the trajectory of China's Personal Information Protection Law calls into question the applicability of the Brussels Effect: while the GDPR's imprint on the PIPL is evident, a deeper analysis unveils China's nuanced, non-linear adoption that diverges from many assumptions of the Brussels Effect and similar theories.","The evolution of the GDPR-inspired PIPL is not as a straightforward outcome of the Brussels Effect but as a nuanced, intricate interplay of external influence and domestic dynamics.","We introduce a complementary theory of 'gravity assist' which portrays China's strategic instrumentalisation of the GDPR as a template to shape its unique data protection landscape.","Our conceptual framework highlights how China navigates through a patchwork of internal considerations, international standards, and strategic choices, ultimately sculpting a data protection regime that has a similar appearance to the GDPR but aligns with its distinct political, cultural and legal landscape.","This reveals much about how China takes in the foundational premises of data protection that are inherently built in Europe's cherishment of the rule of law, democracy and human rights on the one hand, and the evaluation of data protection as a fundamental right."],"url":"http://arxiv.org/abs/2312.08237v1"}
{"created":"2023-12-13 15:57:06","title":"Analysis of Psychographic Indicators via LIWC and Their Correlation with CTR for Instagram Ads","abstract":"The online advertising industry continues to grow and accounts for over 40% of global advertising spending. Online display advertising consists of images and text, and advertisers maximize sales revenue by contacting consumers through advertisements and encouraging them to make purchases. In today's society, where products are becoming more homogenized and needs are diversifying, appealing to consumer psychology through advertisements is becoming increasingly important. However, it is not sufficiently clear what kind of appeal influences consumer psychology. In this study, we quantified the appeal of the text in advertisements for health products and cosmetics, which were actually delivered in Instagram advertisements (one of display advertisements), by applying linguistic inquiry and word count (LIWC). The correlation between click-through rate (CTR) and the text was analyzed. The results showed that negative appeals that arouse consumer anxiety and a sense of crisis were related to CTR.","sentences":["The online advertising industry continues to grow and accounts for over 40% of global advertising spending.","Online display advertising consists of images and text, and advertisers maximize sales revenue by contacting consumers through advertisements and encouraging them to make purchases.","In today's society, where products are becoming more homogenized and needs are diversifying, appealing to consumer psychology through advertisements is becoming increasingly important.","However, it is not sufficiently clear what kind of appeal influences consumer psychology.","In this study, we quantified the appeal of the text in advertisements for health products and cosmetics, which were actually delivered in Instagram advertisements (one of display advertisements), by applying linguistic inquiry and word count (LIWC).","The correlation between click-through rate (CTR) and the text was analyzed.","The results showed that negative appeals that arouse consumer anxiety and a sense of crisis were related to CTR."],"url":"http://arxiv.org/abs/2312.08235v1"}
{"created":"2023-12-13 15:56:24","title":"Beyond the Label Itself: Latent Labels Enhance Semi-supervised Point Cloud Panoptic Segmentation","abstract":"As the exorbitant expense of labeling autopilot datasets and the growing trend of utilizing unlabeled data, semi-supervised segmentation on point clouds becomes increasingly imperative. Intuitively, finding out more ``unspoken words'' (i.e., latent instance information) beyond the label itself should be helpful to improve performance. In this paper, we discover two types of latent labels behind the displayed label embedded in LiDAR and image data. First, in the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able to augment more yet reliable samples for training. Second, in the Image Branch, we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse the information of instance position and scale, which is from a 2D pre-trained detector and a type of latent label obtained from 3D to 2D projection. Finally, the two latent labels are embedded into the multi-modal panoptic segmentation network. The ablation of the IPSL module demonstrates its robust adaptability, and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that our model outperforms the state-of-the-art method, LaserMix.","sentences":["As the exorbitant expense of labeling autopilot datasets and the growing trend of utilizing unlabeled data, semi-supervised segmentation on point clouds becomes increasingly imperative.","Intuitively, finding out more ``unspoken words'' (i.e., latent instance information) beyond the label itself should be helpful to improve performance.","In this paper, we discover two types of latent labels behind the displayed label embedded in LiDAR and image data.","First, in the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able to augment more yet reliable samples for training.","Second, in the Image Branch, we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse the information of instance position and scale, which is from a 2D pre-trained detector and a type of latent label obtained from 3D to 2D projection.","Finally, the two latent labels are embedded into the multi-modal panoptic segmentation network.","The ablation of the IPSL module demonstrates its robust adaptability, and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that our model outperforms the state-of-the-art method, LaserMix."],"url":"http://arxiv.org/abs/2312.08234v1"}
{"created":"2023-12-13 15:48:50","title":"Partial Symmetry Detection for 3D Geometry using Contrastive Learning with Geodesic Point Cloud Patches","abstract":"Symmetry detection, especially partial and extrinsic symmetry, is essential for various downstream tasks, like 3D geometry completion, segmentation, compression and structure-aware shape encoding or generation. In order to detect partial extrinsic symmetries, we propose to learn rotation, reflection, translation and scale invariant local shape features for geodesic point cloud patches via contrastive learning, which are robust across multiple classes and generalize over different datasets. We show that our approach is able to extract multiple valid solutions for this ambiguous problem. Furthermore, we introduce a novel benchmark test for partial extrinsic symmetry detection to evaluate our method. Lastly, we incorporate the detected symmetries together with a region growing algorithm to demonstrate a downstream task with the goal of computing symmetry-aware partitions of 3D shapes. To our knowledge, we are the first to propose a self-supervised data-driven method for partial extrinsic symmetry detection.","sentences":["Symmetry detection, especially partial and extrinsic symmetry, is essential for various downstream tasks, like 3D geometry completion, segmentation, compression and structure-aware shape encoding or generation.","In order to detect partial extrinsic symmetries, we propose to learn rotation, reflection, translation and scale invariant local shape features for geodesic point cloud patches via contrastive learning, which are robust across multiple classes and generalize over different datasets.","We show that our approach is able to extract multiple valid solutions for this ambiguous problem.","Furthermore, we introduce a novel benchmark test for partial extrinsic symmetry detection to evaluate our method.","Lastly, we incorporate the detected symmetries together with a region growing algorithm to demonstrate a downstream task with the goal of computing symmetry-aware partitions of 3D shapes.","To our knowledge, we are the first to propose a self-supervised data-driven method for partial extrinsic symmetry detection."],"url":"http://arxiv.org/abs/2312.08230v1"}
{"created":"2023-12-13 15:30:29","title":"Accelerated Event-Based Feature Detection and Compression for Surveillance Video Systems","abstract":"The strong temporal consistency of surveillance video enables compelling compression performance with traditional methods, but downstream vision applications operate on decoded image frames with a high data rate. Since it is not straightforward for applications to extract information on temporal redundancy from the compressed video representations, we propose a novel system which conveys temporal redundancy within a sparse decompressed representation. We leverage a video representation framework called ADDER to transcode framed videos to sparse, asynchronous intensity samples. We introduce mechanisms for content adaptation, lossy compression, and asynchronous forms of classical vision algorithms. We evaluate our system on the VIRAT surveillance video dataset, and we show a median 43.7% speed improvement in FAST feature detection compared to OpenCV. We run the same algorithm as OpenCV, but only process pixels that receive new asynchronous events, rather than process every pixel in an image frame. Our work paves the way for upcoming neuromorphic sensors and is amenable to future applications with spiking neural networks.","sentences":["The strong temporal consistency of surveillance video enables compelling compression performance with traditional methods, but downstream vision applications operate on decoded image frames with a high data rate.","Since it is not straightforward for applications to extract information on temporal redundancy from the compressed video representations, we propose a novel system which conveys temporal redundancy within a sparse decompressed representation.","We leverage a video representation framework called ADDER to transcode framed videos to sparse, asynchronous intensity samples.","We introduce mechanisms for content adaptation, lossy compression, and asynchronous forms of classical vision algorithms.","We evaluate our system on the VIRAT surveillance video dataset, and we show a median 43.7% speed improvement in FAST feature detection compared to OpenCV.","We run the same algorithm as OpenCV, but only process pixels that receive new asynchronous events, rather than process every pixel in an image frame.","Our work paves the way for upcoming neuromorphic sensors and is amenable to future applications with spiking neural networks."],"url":"http://arxiv.org/abs/2312.08213v1"}
{"created":"2023-12-13 15:08:54","title":"SPD-DDPM: Denoising Diffusion Probabilistic Models in the Symmetric Positive Definite Space","abstract":"Symmetric positive definite~(SPD) matrices have shown important value and applications in statistics and machine learning, such as FMRI analysis and traffic prediction. Previous works on SPD matrices mostly focus on discriminative models, where predictions are made directly on $E(X|y)$, where $y$ is a vector and $X$ is an SPD matrix. However, these methods are challenging to handle for large-scale data, as they need to access and process the whole data. In this paper, inspired by denoising diffusion probabilistic model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by introducing Gaussian distribution in the SPD space to estimate $E(X|y)$. Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly without giving $y$. On the one hand, the model conditionally learns $p(X|y)$ and utilizes the mean of samples to obtain $E(X|y)$ as a prediction. On the other hand, the model unconditionally learns the probability distribution of the data $p(X)$ and generates samples that conform to this distribution. Furthermore, we propose a new SPD net which is much deeper than the previous networks and allows for the inclusion of conditional factors. Experiment results on toy data and real taxi data demonstrate that our models effectively fit the data distribution both unconditionally and unconditionally and provide accurate predictions.","sentences":["Symmetric positive definite~(SPD) matrices have shown important value and applications in statistics and machine learning, such as FMRI analysis and traffic prediction.","Previous works on SPD matrices mostly focus on discriminative models, where predictions are made directly on $E(X|y)$, where $y$ is a vector and $X$ is an SPD matrix.","However, these methods are challenging to handle for large-scale data, as they need to access and process the whole data.","In this paper, inspired by denoising diffusion probabilistic model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by introducing Gaussian distribution in the SPD space to estimate $E(X|y)$. Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly without giving $y$. On the one hand, the model conditionally learns $p(X|y)$ and utilizes the mean of samples to obtain $E(X|y)$ as a prediction.","On the other hand, the model unconditionally learns the probability distribution of the data $p(X)$ and generates samples that conform to this distribution.","Furthermore, we propose a new SPD net which is much deeper than the previous networks and allows for the inclusion of conditional factors.","Experiment results on toy data and real taxi data demonstrate that our models effectively fit the data distribution both unconditionally and unconditionally and provide accurate predictions."],"url":"http://arxiv.org/abs/2312.08200v1"}
{"created":"2023-12-13 15:03:27","title":"Towards Model-Based Data Acquisition for Subjective Multi-Task NLP Problems","abstract":"Data annotated by humans is a source of knowledge by describing the peculiarities of the problem and therefore fueling the decision process of the trained model. Unfortunately, the annotation process for subjective natural language processing (NLP) problems like offensiveness or emotion detection is often very expensive and time-consuming. One of the inevitable risks is to spend some of the funds and annotator effort on annotations that do not provide any additional knowledge about the specific task. To minimize these costs, we propose a new model-based approach that allows the selection of tasks annotated individually for each text in a multi-task scenario. The experiments carried out on three datasets, dozens of NLP tasks, and thousands of annotations show that our method allows up to 40% reduction in the number of annotations with negligible loss of knowledge. The results also emphasize the need to collect a diverse amount of data required to efficiently train a model, depending on the subjectivity of the annotation task. We also focused on measuring the relation between subjective tasks by evaluating the model in single-task and multi-task scenarios. Moreover, for some datasets, training only on the labels predicted by our model improved the efficiency of task selection as a self-supervised learning regularization technique.","sentences":["Data annotated by humans is a source of knowledge by describing the peculiarities of the problem and therefore fueling the decision process of the trained model.","Unfortunately, the annotation process for subjective natural language processing (NLP) problems like offensiveness or emotion detection is often very expensive and time-consuming.","One of the inevitable risks is to spend some of the funds and annotator effort on annotations that do not provide any additional knowledge about the specific task.","To minimize these costs, we propose a new model-based approach that allows the selection of tasks annotated individually for each text in a multi-task scenario.","The experiments carried out on three datasets, dozens of NLP tasks, and thousands of annotations show that our method allows up to 40% reduction in the number of annotations with negligible loss of knowledge.","The results also emphasize the need to collect a diverse amount of data required to efficiently train a model, depending on the subjectivity of the annotation task.","We also focused on measuring the relation between subjective tasks by evaluating the model in single-task and multi-task scenarios.","Moreover, for some datasets, training only on the labels predicted by our model improved the efficiency of task selection as a self-supervised learning regularization technique."],"url":"http://arxiv.org/abs/2312.08198v1"}
{"created":"2023-12-13 14:36:08","title":"ASC: Adaptive Scale Feature Map Compression for Deep Neural Network","abstract":"Deep-learning accelerators are increasingly in demand; however, their performance is constrained by the size of the feature map, leading to high bandwidth requirements and large buffer sizes. We propose an adaptive scale feature map compression technique leveraging the unique properties of the feature map. This technique adopts independent channel indexing given the weak channel correlation and utilizes a cubical-like block shape to benefit from strong local correlations. The method further optimizes compression using a switchable endpoint mode and adaptive scale interpolation to handle unimodal data distributions, both with and without outliers. This results in 4$\\times$ and up to 7.69$\\times$ compression rates for 16-bit data in constant and variable bitrates, respectively. Our hardware design minimizes area cost by adjusting interpolation scales, which facilitates hardware sharing among interpolation points. Additionally, we introduce a threshold concept for straightforward interpolation, preventing the need for intricate hardware. The TSMC 28nm implementation showcases an equivalent gate count of 6135 for the 8-bit version. Furthermore, the hardware architecture scales effectively, with only a sublinear increase in area cost. Achieving a 32$\\times$ throughput increase meets the theoretical bandwidth of DDR5-6400 at just 7.65$\\times$ the hardware cost.","sentences":["Deep-learning accelerators are increasingly in demand; however, their performance is constrained by the size of the feature map, leading to high bandwidth requirements and large buffer sizes.","We propose an adaptive scale feature map compression technique leveraging the unique properties of the feature map.","This technique adopts independent channel indexing given the weak channel correlation and utilizes a cubical-like block shape to benefit from strong local correlations.","The method further optimizes compression using a switchable endpoint mode and adaptive scale interpolation to handle unimodal data distributions, both with and without outliers.","This results in 4$\\times$ and up to 7.69$\\times$ compression rates for 16-bit data in constant and variable bitrates, respectively.","Our hardware design minimizes area cost by adjusting interpolation scales, which facilitates hardware sharing among interpolation points.","Additionally, we introduce a threshold concept for straightforward interpolation, preventing the need for intricate hardware.","The TSMC 28nm implementation showcases an equivalent gate count of 6135 for the 8-bit version.","Furthermore, the hardware architecture scales effectively, with only a sublinear increase in area cost.","Achieving a 32$\\times$ throughput increase meets the theoretical bandwidth of DDR5-6400 at just 7.65$\\times$ the hardware cost."],"url":"http://arxiv.org/abs/2312.08176v1"}
{"created":"2023-12-13 14:12:52","title":"Towards Evaluating the Security of Wearable Devices in the Internet of Medical Things","abstract":"The Internet of Medical Things (IoMT) offers a promising solution to improve patient health and reduce human error. Wearable smart infusion pumps that accurately administer medication and integrate with electronic health records are an example of technology that can improve healthcare. They can even alert healthcare professionals or remote servers during operational failure, preventing distressing incidents. However, as the number of connected medical devices increases, the risk of cyber threats also increases. Wearable medication devices based on IoT attached to patients' bodies are prone to significant cyber threats. Being connected to the Internet exposes these devices to potential harm, which could disrupt or degrade device performance and harm patients. To ensure patient safety and well-being, it is crucial to establish secure data authentication for internet-connected medical devices. It is also important to note that the wearability option of such devices might downgrade the computational resources, making them more susceptible to security risks. This paper implements a security approach to a wearable infusion pump. We discuss practical challenges in implementing security-enabled devices and propose initial solutions to mitigate cyber threats.","sentences":["The Internet of Medical Things (IoMT) offers a promising solution to improve patient health and reduce human error.","Wearable smart infusion pumps that accurately administer medication and integrate with electronic health records are an example of technology that can improve healthcare.","They can even alert healthcare professionals or remote servers during operational failure, preventing distressing incidents.","However, as the number of connected medical devices increases, the risk of cyber threats also increases.","Wearable medication devices based on IoT attached to patients' bodies are prone to significant cyber threats.","Being connected to the Internet exposes these devices to potential harm, which could disrupt or degrade device performance and harm patients.","To ensure patient safety and well-being, it is crucial to establish secure data authentication for internet-connected medical devices.","It is also important to note that the wearability option of such devices might downgrade the computational resources, making them more susceptible to security risks.","This paper implements a security approach to a wearable infusion pump.","We discuss practical challenges in implementing security-enabled devices and propose initial solutions to mitigate cyber threats."],"url":"http://arxiv.org/abs/2312.08160v1"}
{"created":"2023-12-13 14:10:50","title":"Distributed Quantum Learning with co-Management in a Multi-tenant Quantum System","abstract":"The rapid advancement of quantum computing has pushed classical designs into the quantum domain, breaking physical boundaries for computing-intensive and data-hungry applications. Given its immense potential, quantum-based computing systems have attracted increasing attention with the hope that some systems may provide a quantum speedup. For example, variational quantum algorithms have been proposed for quantum neural networks to train deep learning models on qubits, achieving promising results. Existing quantum learning architectures and systems rely on single, monolithic quantum machines with abundant and stable resources, such as qubits. However, fabricating a large, monolithic quantum device is considerably more challenging than producing an array of smaller devices. In this paper, we investigate a distributed quantum system that combines multiple quantum machines into a unified system. We propose DQuLearn, which divides a quantum learning task into multiple subtasks. Each subtask can be executed distributively on individual quantum machines, with the results looping back to classical machines for subsequent training iterations. Additionally, our system supports multiple concurrent clients and dynamically manages their circuits according to the runtime status of quantum workers. Through extensive experiments, we demonstrate that DQuLearn achieves similar accuracies with significant runtime reduction, by up to 68.7% and an increase per-second circuit processing speed, by up to 3.99 times, in a 4-worker multi-tenant setting.","sentences":["The rapid advancement of quantum computing has pushed classical designs into the quantum domain, breaking physical boundaries for computing-intensive and data-hungry applications.","Given its immense potential, quantum-based computing systems have attracted increasing attention with the hope that some systems may provide a quantum speedup.","For example, variational quantum algorithms have been proposed for quantum neural networks to train deep learning models on qubits, achieving promising results.","Existing quantum learning architectures and systems rely on single, monolithic quantum machines with abundant and stable resources, such as qubits.","However, fabricating a large, monolithic quantum device is considerably more challenging than producing an array of smaller devices.","In this paper, we investigate a distributed quantum system that combines multiple quantum machines into a unified system.","We propose DQuLearn, which divides a quantum learning task into multiple subtasks.","Each subtask can be executed distributively on individual quantum machines, with the results looping back to classical machines for subsequent training iterations.","Additionally, our system supports multiple concurrent clients and dynamically manages their circuits according to the runtime status of quantum workers.","Through extensive experiments, we demonstrate that DQuLearn achieves similar accuracies with significant runtime reduction, by up to 68.7% and an increase per-second circuit processing speed, by up to 3.99 times, in a 4-worker multi-tenant setting."],"url":"http://arxiv.org/abs/2312.08158v1"}
{"created":"2023-12-13 14:10:12","title":"Okapi: A Lightweight Architecture for Secure Speculation Exploiting Locality of Memory Accesses","abstract":"This paper introduces Okapi, an innovative hardware/software cross-layer architecture designed to mitigate Transient Execution Side Channel (TES) attacks, including Spectre variants, in modern computing systems. A key contribution of Okapi is a set of security features building upon each other to offer various trade-offs between performance and security. At its core, Okapi allows for speculative data accesses if the targeted memory region has already been accessed non-speculatively before in the same trust domain. It delays first-time accesses until the speculation is resolved.   Okapi stands out for its flexibility in security implementation. For environments with less stringent security needs, Okapi's features can be deactivated to eliminate performance overhead. When activated, the hardware modifications alone provide robust protection against transient execution attacks at a thread-level granularity, including all universal read gadgets like Spectre-PHT and Spectre-BTB. This incurs an average performance overhead of only 3.6 % for the SPEC CPU2017 benchmark suite.   On top, Okapi introduces the OkapiReset instruction for additional software-level security support. This instruction, which can be manually inserted by developers or automatically via a compiler extension, allows for fully secure speculation and for trust domain sizes smaller than a thread. While the manual insertion of OkapiReset incurs an additional 0.6 % performance overhead, the automated compiler extension approach results in a 23.1 % overhead for making a cryptographic library fully secure. With an approximate 0.4 % hardware overhead, Okapi provides a highly scalable and adaptable solution for secure speculation in state-of-the-art processor design.","sentences":["This paper introduces Okapi, an innovative hardware/software cross-layer architecture designed to mitigate Transient Execution Side Channel (TES) attacks, including Spectre variants, in modern computing systems.","A key contribution of Okapi is a set of security features building upon each other to offer various trade-offs between performance and security.","At its core, Okapi allows for speculative data accesses if the targeted memory region has already been accessed non-speculatively before in the same trust domain.","It delays first-time accesses until the speculation is resolved.   ","Okapi stands out for its flexibility in security implementation.","For environments with less stringent security needs, Okapi's features can be deactivated to eliminate performance overhead.","When activated, the hardware modifications alone provide robust protection against transient execution attacks at a thread-level granularity, including all universal read gadgets like Spectre-PHT and Spectre-BTB.","This incurs an average performance overhead of only 3.6 % for the SPEC CPU2017 benchmark suite.   ","On top, Okapi introduces the OkapiReset instruction for additional software-level security support.","This instruction, which can be manually inserted by developers or automatically via a compiler extension, allows for fully secure speculation and for trust domain sizes smaller than a thread.","While the manual insertion of OkapiReset incurs an additional 0.6 % performance overhead, the automated compiler extension approach results in a 23.1 % overhead for making a cryptographic library fully secure.","With an approximate 0.4 % hardware overhead, Okapi provides a highly scalable and adaptable solution for secure speculation in state-of-the-art processor design."],"url":"http://arxiv.org/abs/2312.08156v1"}
{"created":"2023-12-13 14:01:58","title":"Active learning with biased non-response to label requests","abstract":"Active learning can improve the efficiency of training prediction models by identifying the most informative new labels to acquire. However, non-response to label requests can impact active learning's effectiveness in real-world contexts. We conceptualise this degradation by considering the type of non-response present in the data, demonstrating that biased non-response is particularly detrimental to model performance. We argue that this sort of non-response is particularly likely in contexts where the labelling process, by nature, relies on user interactions. To mitigate the impact of biased non-response, we propose a cost-based correction to the sampling strategy--the Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly, be applied to any active learning algorithm. Through experiments, we demonstrate that our method successfully reduces the harm from labelling non-response in many settings. However, we also characterise settings where the non-response bias in the annotations remains detrimental under UCB-EU for particular sampling methods and data generating processes. Finally, we evaluate our method on a real-world dataset from e-commerce platform Taobao. We show that UCB-EU yields substantial performance improvements to conversion models that are trained on clicked impressions. Most generally, this research serves to both better conceptualise the interplay between types of non-response and model improvements via active learning, and to provide a practical, easy to implement correction that helps mitigate model degradation.","sentences":["Active learning can improve the efficiency of training prediction models by identifying the most informative new labels to acquire.","However, non-response to label requests can impact active learning's effectiveness in real-world contexts.","We conceptualise this degradation by considering the type of non-response present in the data, demonstrating that biased non-response is particularly detrimental to model performance.","We argue that this sort of non-response is particularly likely in contexts where the labelling process, by nature, relies on user interactions.","To mitigate the impact of biased non-response, we propose a cost-based correction to the sampling strategy--the Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly, be applied to any active learning algorithm.","Through experiments, we demonstrate that our method successfully reduces the harm from labelling non-response in many settings.","However, we also characterise settings where the non-response bias in the annotations remains detrimental under UCB-EU for particular sampling methods and data generating processes.","Finally, we evaluate our method on a real-world dataset from e-commerce platform Taobao.","We show that UCB-EU yields substantial performance improvements to conversion models that are trained on clicked impressions.","Most generally, this research serves to both better conceptualise the interplay between types of non-response and model improvements via active learning, and to provide a practical, easy to implement correction that helps mitigate model degradation."],"url":"http://arxiv.org/abs/2312.08150v1"}
{"created":"2023-12-13 13:55:36","title":"High-accuracy Vision-Based Attitude Estimation System for Air-Bearing Spacecraft Simulators","abstract":"Air-bearing platforms for simulating the rotational dynamics of satellites require highly precise ground truth systems. Unfortunately, commercial motion capture systems used for this scope are complex and expensive. This paper shows a novel and versatile method to compute the attitude of rotational air-bearing platforms using a monocular camera and sets of fiducial markers. The work proposes a geometry-based iterative algorithm that is significantly more accurate than other literature methods that involve the solution of the Perspective-n-Point problem. Additionally, auto-calibration procedures to perform a preliminary estimation of the system parameters are shown. The developed methodology is deployed onto a Raspberry Pi 4 micro-computer and tested with a set of LED markers. Data obtained with this setup are compared against computer simulations of the same system to understand and validate the attitude estimation performances. Simulation results show expected 1-sigma accuracies in the order of $\\sim$ 12 arcsec and $\\sim$ 37 arcsec for about- and cross-boresight rotations of the platform, and average latency times of 6 ms.","sentences":["Air-bearing platforms for simulating the rotational dynamics of satellites require highly precise ground truth systems.","Unfortunately, commercial motion capture systems used for this scope are complex and expensive.","This paper shows a novel and versatile method to compute the attitude of rotational air-bearing platforms using a monocular camera and sets of fiducial markers.","The work proposes a geometry-based iterative algorithm that is significantly more accurate than other literature methods that involve the solution of the Perspective-n-Point problem.","Additionally, auto-calibration procedures to perform a preliminary estimation of the system parameters are shown.","The developed methodology is deployed onto a Raspberry Pi 4 micro-computer and tested with a set of LED markers.","Data obtained with this setup are compared against computer simulations of the same system to understand and validate the attitude estimation performances.","Simulation results show expected 1-sigma accuracies in the order of $\\sim$ 12 arcsec and $\\sim$ 37 arcsec for about- and cross-boresight rotations of the platform, and average latency times of 6 ms."],"url":"http://arxiv.org/abs/2312.08146v1"}
{"created":"2023-12-13 13:46:14","title":"Efficient Representation of the Activation Space in Deep Neural Networks","abstract":"The representations of the activation space of deep neural networks (DNNs) are widely utilized for tasks like natural language processing, anomaly detection and speech recognition. Due to the diverse nature of these tasks and the large size of DNNs, an efficient and task-independent representation of activations becomes crucial. Empirical p-values have been used to quantify the relative strength of an observed node activation compared to activations created by already-known inputs. Nonetheless, keeping raw data for these calculations increases memory resource consumption and raises privacy concerns. To this end, we propose a model-agnostic framework for creating representations of activations in DNNs using node-specific histograms to compute p-values of observed activations without retaining already-known inputs. Our proposed approach demonstrates promising potential when validated with multiple network architectures across various downstream tasks and compared with the kernel density estimates and brute-force empirical baselines. In addition, the framework reduces memory usage by 30% with up to 4 times faster p-value computing time while maintaining state of-the-art detection power in downstream tasks such as the detection of adversarial attacks and synthesized content. Moreover, as we do not persist raw data at inference time, we could potentially reduce susceptibility to attacks and privacy issues.","sentences":["The representations of the activation space of deep neural networks (DNNs) are widely utilized for tasks like natural language processing, anomaly detection and speech recognition.","Due to the diverse nature of these tasks and the large size of DNNs, an efficient and task-independent representation of activations becomes crucial.","Empirical p-values have been used to quantify the relative strength of an observed node activation compared to activations created by already-known inputs.","Nonetheless, keeping raw data for these calculations increases memory resource consumption and raises privacy concerns.","To this end, we propose a model-agnostic framework for creating representations of activations in DNNs using node-specific histograms to compute p-values of observed activations without retaining already-known inputs.","Our proposed approach demonstrates promising potential when validated with multiple network architectures across various downstream tasks and compared with the kernel density estimates and brute-force empirical baselines.","In addition, the framework reduces memory usage by 30% with up to 4 times faster p-value computing time while maintaining state of-the-art detection power in downstream tasks such as the detection of adversarial attacks and synthesized content.","Moreover, as we do not persist raw data at inference time, we could potentially reduce susceptibility to attacks and privacy issues."],"url":"http://arxiv.org/abs/2312.08143v1"}
{"created":"2023-12-13 13:36:14","title":"MToP: A MATLAB Optimization Platform for Evolutionary Multitasking","abstract":"Evolutionary multitasking (EMT) has been attracting much attention over the past years. It aims to handle multiple optimization tasks simultaneously within limited computing resources assisted by inter-task knowledge transfer techniques. Numerous multitask evolutionary algorithms (MTEAs) for solving multitask optimization (MTO) problems have been proposed in the EMT field, but there lacks a comprehensive software platform to help researchers evaluate MTEA performance on benchmark MTO problems as well as explore real-world applications. To address this issue, we introduce the first open-source optimization platform, named MTO-Platform (MToP), for EMT. It incorporates more than 30 MTEAs, more than 150 MTO problem cases with real-world applications, and more than 10 performance metrics. Moreover, for comparing MTEAs with traditional evolutionary algorithms, we modified more than 30 popular single-task evolutionary algorithms to be able to solve MTO problems in MToP. MToP is a user-friendly tool with a graphical user interface that makes it easy to analyze results, export data, and plot schematics. More importantly, MToP is extensible, allowing users to develop new algorithms and define new problems. The source code of MToP is available at https://github.com/intLyc/MTO-Platform.","sentences":["Evolutionary multitasking (EMT) has been attracting much attention over the past years.","It aims to handle multiple optimization tasks simultaneously within limited computing resources assisted by inter-task knowledge transfer techniques.","Numerous multitask evolutionary algorithms (MTEAs) for solving multitask optimization (MTO) problems have been proposed in the EMT field, but there lacks a comprehensive software platform to help researchers evaluate MTEA performance on benchmark MTO problems as well as explore real-world applications.","To address this issue, we introduce the first open-source optimization platform, named MTO-Platform (MToP), for EMT.","It incorporates more than 30 MTEAs, more than 150 MTO problem cases with real-world applications, and more than 10 performance metrics.","Moreover, for comparing MTEAs with traditional evolutionary algorithms, we modified more than 30 popular single-task evolutionary algorithms to be able to solve MTO problems in MToP. MToP is a user-friendly tool with a graphical user interface that makes it easy to analyze results, export data, and plot schematics.","More importantly, MToP is extensible, allowing users to develop new algorithms and define new problems.","The source code of MToP is available at https://github.com/intLyc/MTO-Platform."],"url":"http://arxiv.org/abs/2312.08134v1"}
{"created":"2023-12-13 13:27:09","title":"Random relay selection based heuristic optimization model for the scheduling and effective resource allocation in the cognitive radio network","abstract":"Cognitive Radio Network (CRN) provides effective capabilities for resource allocation with the valuable spectrum resources in the network. It provides the effective allocation of resources to the unlicensed users or Secondary Users (SUs) to access the spectrum those are unused by the licensed users or Primary Users (Pus). This paper develops an Optimal Relay Selection scheme with the spectrum-sharing scheme in CRN. The proposed Cross-Layer Spider Swarm Shifting is implemented in CRN for the optimal relay selection with Spider Swarm Optimization (SSO). The shortest path is estimated with the data shifting model for the data transmission path in the CRN. This study examines a cognitive relay network (CRN) with interference restrictions imposed by a mobile end user (MU). Half-duplex communication is used in the proposed system model between a single primary user (PU) and a single secondary user (SU). Between the SU source and SU destination, an amplify and forward (AF) relaying mechanism is also used. While other nodes (SU Source, SU relays, and PU) are supposed to be immobile in this scenario, the mobile end user (SU destination) is assumed to travel at high vehicle speeds. The suggested method achieves variety by placing a selection combiner at the SU destination and dynamically selecting the optimal relay for transmission based on the greatest signal-to-noise (SNR) ratio. The performance of the proposed Cross-Layer Spider Swarm Shifting model is compared with the Spectrum Sharing Optimization with QoS Guarantee (SSO-QG). The comparative analysis expressed that the proposed Cross-Layer Spider Swarm Shifting model delay is reduced by 15% compared with SSO-QG. Additionally, the proposed Cross-Layer Spider Swarm Shifting exhibits the improved network performance of ~25% higher throughput compared with SSO-QG.","sentences":["Cognitive Radio Network (CRN) provides effective capabilities for resource allocation with the valuable spectrum resources in the network.","It provides the effective allocation of resources to the unlicensed users or Secondary Users (SUs) to access the spectrum those are unused by the licensed users or Primary Users (Pus).","This paper develops an Optimal Relay Selection scheme with the spectrum-sharing scheme in CRN.","The proposed Cross-Layer Spider Swarm Shifting is implemented in CRN for the optimal relay selection with Spider Swarm Optimization (SSO).","The shortest path is estimated with the data shifting model for the data transmission path in the CRN.","This study examines a cognitive relay network (CRN) with interference restrictions imposed by a mobile end user (MU).","Half-duplex communication is used in the proposed system model between a single primary user (PU) and a single secondary user (SU).","Between the SU source and SU destination, an amplify and forward (AF) relaying mechanism is also used.","While other nodes (SU Source, SU relays, and PU) are supposed to be immobile in this scenario, the mobile end user (SU destination) is assumed to travel at high vehicle speeds.","The suggested method achieves variety by placing a selection combiner at the SU destination and dynamically selecting the optimal relay for transmission based on the greatest signal-to-noise (SNR) ratio.","The performance of the proposed Cross-Layer Spider Swarm Shifting model is compared with the Spectrum Sharing Optimization with QoS Guarantee (SSO-QG).","The comparative analysis expressed that the proposed Cross-Layer Spider Swarm Shifting model delay is reduced by 15% compared with SSO-QG.","Additionally, the proposed Cross-Layer Spider Swarm Shifting exhibits the improved network performance of ~25% higher throughput compared with SSO-QG."],"url":"http://arxiv.org/abs/2312.08127v1"}
{"created":"2023-12-13 12:54:34","title":"Causal Optimal Transport of Abstractions","abstract":"Causal abstraction (CA) theory establishes formal criteria for relating multiple structural causal models (SCMs) at different levels of granularity by defining maps between them. These maps have significant relevance for real-world challenges such as synthesizing causal evidence from multiple experimental environments, learning causally consistent representations at different resolutions, and linking interventions across multiple SCMs. In this work, we propose COTA, the first method to learn abstraction maps from observational and interventional data without assuming complete knowledge of the underlying SCMs. In particular, we introduce a multi-marginal Optimal Transport (OT) formulation that enforces do-calculus causal constraints, together with a cost function that relies on interventional information. We extensively evaluate COTA on synthetic and real world problems, and showcase its advantages over non-causal, independent and aggregated COTA formulations. Finally, we demonstrate the efficiency of our method as a data augmentation tool by comparing it against the state-of-the-art CA learning framework, which assumes fully specified SCMs, on a real-world downstream task.","sentences":["Causal abstraction (CA) theory establishes formal criteria for relating multiple structural causal models (SCMs) at different levels of granularity by defining maps between them.","These maps have significant relevance for real-world challenges such as synthesizing causal evidence from multiple experimental environments, learning causally consistent representations at different resolutions, and linking interventions across multiple SCMs.","In this work, we propose COTA, the first method to learn abstraction maps from observational and interventional data without assuming complete knowledge of the underlying SCMs.","In particular, we introduce a multi-marginal Optimal Transport (OT) formulation that enforces do-calculus causal constraints, together with a cost function that relies on interventional information.","We extensively evaluate COTA on synthetic and real world problems, and showcase its advantages over non-causal, independent and aggregated COTA formulations.","Finally, we demonstrate the efficiency of our method as a data augmentation tool by comparing it against the state-of-the-art CA learning framework, which assumes fully specified SCMs, on a real-world downstream task."],"url":"http://arxiv.org/abs/2312.08107v1"}
{"created":"2023-12-13 12:39:25","title":"Machine Learning for the Multi-Dimensional Bin Packing Problem: Literature Review and Empirical Evaluation","abstract":"The Bin Packing Problem (BPP) is a well-established combinatorial optimization (CO) problem. Since it has many applications in our daily life, e.g. logistics and resource allocation, people are seeking efficient bin packing algorithms. On the other hand, researchers have been making constant advances in machine learning (ML), which is famous for its efficiency. In this article, we first formulate BPP, introducing its variants and practical constraints. Then, a comprehensive survey on ML for multi-dimensional BPP is provided. We further collect some public benchmarks of 3D BPP, and evaluate some online methods on the Cutting Stock Dataset. Finally, we share our perspective on challenges and future directions in BPP. To the best of our knowledge, this is the first systematic review of ML-related methods for BPP.","sentences":["The Bin Packing Problem (BPP) is a well-established combinatorial optimization (CO) problem.","Since it has many applications in our daily life, e.g. logistics and resource allocation, people are seeking efficient bin packing algorithms.","On the other hand, researchers have been making constant advances in machine learning (ML), which is famous for its efficiency.","In this article, we first formulate BPP, introducing its variants and practical constraints.","Then, a comprehensive survey on ML for multi-dimensional BPP is provided.","We further collect some public benchmarks of 3D BPP, and evaluate some online methods on the Cutting Stock Dataset.","Finally, we share our perspective on challenges and future directions in BPP.","To the best of our knowledge, this is the first systematic review of ML-related methods for BPP."],"url":"http://arxiv.org/abs/2312.08103v1"}
{"created":"2023-12-13 12:36:03","title":"Security aspects in Smart Meters: Analysis and Prevention","abstract":"Smart meters are of the basic elements in the so-called Smart Grid. These devices, connected to the Internet, keep bidirectional communication with other devices in the Smart Grid structure to allow remote readings and maintenance. As any other device connected to a network, smart meters become vulnerable to attacks with different purposes, like stealing data or altering readings. Nowadays, it is becoming more and more popular to buy and plug-and-play smart meters, additionally to those installed by the energy providers, to directly monitor the energy consumption at home. This option inherently entails security risks that are under the responsibility of householders. In this paper, we focus on an open solution based on Smartpi 2.0 devices with two purposes. On the one hand, we propose a network configuration and different data flows to exchange data (energy readings) in the home. These flows are designed to support collaborative among the devices in order to prevent external attacks and attempts of corrupting the data. On the other hand, we check the vulnerability by performing two kind of attacks (denial of service and stealing and changing data by using a malware). We conclude that, as expected, these devices are vulnerable to these attacks, but we provide mechanisms to detect both of them and to solve, by applying cooperation techniques","sentences":["Smart meters are of the basic elements in the so-called Smart Grid.","These devices, connected to the Internet, keep bidirectional communication with other devices in the Smart Grid structure to allow remote readings and maintenance.","As any other device connected to a network, smart meters become vulnerable to attacks with different purposes, like stealing data or altering readings.","Nowadays, it is becoming more and more popular to buy and plug-and-play smart meters, additionally to those installed by the energy providers, to directly monitor the energy consumption at home.","This option inherently entails security risks that are under the responsibility of householders.","In this paper, we focus on an open solution based on Smartpi 2.0 devices with two purposes.","On the one hand, we propose a network configuration and different data flows to exchange data (energy readings) in the home.","These flows are designed to support collaborative among the devices in order to prevent external attacks and attempts of corrupting the data.","On the other hand, we check the vulnerability by performing two kind of attacks (denial of service and stealing and changing data by using a malware).","We conclude that, as expected, these devices are vulnerable to these attacks, but we provide mechanisms to detect both of them and to solve, by applying cooperation techniques"],"url":"http://arxiv.org/abs/2312.08101v1"}
{"created":"2023-12-13 12:28:37","title":"An Incentive Mechanism for Federated Learning Based on Multiple Resource Exchange","abstract":"Federated Learning (FL) is a distributed machine learning paradigm that addresses privacy concerns in machine learning and still guarantees high test accuracy. However, achieving the necessary accuracy by having all clients participate in FL is impractical, given the constraints of client local computing resource. In this paper, we introduce a multi-user collaborative computing framework, categorizing users into two roles: model owners (MOs) and data owner (DOs). Without resorting to monetary incentives, an MO can encourage more DOs to join in FL by allowing the DOs to offload extra local computing tasks to the MO for execution. This exchange of \"data\" for \"computing resources\" streamlines the incentives for clients to engage more effectively in FL. We formulate the interaction between MO and DOs as an optimization problem, and the objective is to effectively utilize the communication and computing resource of the MO and DOs to minimize the time to complete an FL task. The proposed problem is a mixed integer nonlinear programming (MINLP) with high computational complexity. We first decompose it into two distinct subproblems, namely the client selection problem and the resource allocation problem to segregate the integer variables from the continuous variables. Then, an effective iterative algorithm is proposed to solve problem. Simulation results demonstrate that the proposed collaborative computing framework can achieve an accuracy of more than 95\\% while minimizing the overall time to complete an FL task.","sentences":["Federated Learning (FL) is a distributed machine learning paradigm that addresses privacy concerns in machine learning and still guarantees high test accuracy.","However, achieving the necessary accuracy by having all clients participate in FL is impractical, given the constraints of client local computing resource.","In this paper, we introduce a multi-user collaborative computing framework, categorizing users into two roles: model owners (MOs) and data owner (DOs).","Without resorting to monetary incentives, an MO can encourage more DOs to join in FL by allowing the DOs to offload extra local computing tasks to the MO for execution.","This exchange of \"data\" for \"computing resources\" streamlines the incentives for clients to engage more effectively in FL.","We formulate the interaction between MO and DOs as an optimization problem, and the objective is to effectively utilize the communication and computing resource of the MO and DOs to minimize the time to complete an FL task.","The proposed problem is a mixed integer nonlinear programming (MINLP) with high computational complexity.","We first decompose it into two distinct subproblems, namely the client selection problem and the resource allocation problem to segregate the integer variables from the continuous variables.","Then, an effective iterative algorithm is proposed to solve problem.","Simulation results demonstrate that the proposed collaborative computing framework can achieve an accuracy of more than 95\\% while minimizing the overall time to complete an FL task."],"url":"http://arxiv.org/abs/2312.08096v1"}
{"created":"2023-12-13 12:24:34","title":"3DGEN: A GAN-based approach for generating novel 3D models from image data","abstract":"The recent advances in text and image synthesis show a great promise for the future of generative models in creative fields. However, a less explored area is the one of 3D model generation, with a lot of potential applications to game design, video production, and physical product design. In our paper, we present 3DGEN, a model that leverages the recent work on both Neural Radiance Fields for object reconstruction and GAN-based image generation. We show that the proposed architecture can generate plausible meshes for objects of the same category as the training images and compare the resulting meshes with the state-of-the-art baselines, leading to visible uplifts in generation quality.","sentences":["The recent advances in text and image synthesis show a great promise for the future of generative models in creative fields.","However, a less explored area is the one of 3D model generation, with a lot of potential applications to game design, video production, and physical product design.","In our paper, we present 3DGEN, a model that leverages the recent work on both Neural Radiance Fields for object reconstruction and GAN-based image generation.","We show that the proposed architecture can generate plausible meshes for objects of the same category as the training images and compare the resulting meshes with the state-of-the-art baselines, leading to visible uplifts in generation quality."],"url":"http://arxiv.org/abs/2312.08094v1"}
{"created":"2023-12-13 12:17:16","title":"A hybrid analysis of LBSN data to early detect anomalies in crowd dynamics","abstract":"Undoubtedly, Location-based Social Networks (LBSNs) provide an interesting source of geo-located data that we have previously used to obtain patterns of the dynamics of crowds throughout urban areas. According to our previous results, activity in LBSNs reflects the real activity in the city. Therefore, unexpected behaviors in the social media activity are a trustful evidence of unexpected changes of the activity in the city. In this paper we introduce a hybrid solution to early detect these changes based on applying a combination of two approaches, the use of entropy analysis and clustering techniques, on the data gathered from LBSNs. In particular, we have performed our experiments over a data set collected from Instagram for seven months in New York City, obtaining promising results.","sentences":["Undoubtedly, Location-based Social Networks (LBSNs) provide an interesting source of geo-located data that we have previously used to obtain patterns of the dynamics of crowds throughout urban areas.","According to our previous results, activity in LBSNs reflects the real activity in the city.","Therefore, unexpected behaviors in the social media activity are a trustful evidence of unexpected changes of the activity in the city.","In this paper we introduce a hybrid solution to early detect these changes based on applying a combination of two approaches, the use of entropy analysis and clustering techniques, on the data gathered from LBSNs.","In particular, we have performed our experiments over a data set collected from Instagram for seven months in New York City, obtaining promising results."],"url":"http://arxiv.org/abs/2312.08092v1"}
{"created":"2023-12-13 12:01:32","title":"Solving Bayesian Inverse Problems With Expensive Likelihoods Using Constrained Gaussian Processes and Active Learning","abstract":"Solving inverse problems using Bayesian methods can become prohibitively expensive when likelihood evaluations involve complex and large scale numerical models. A common approach to circumvent this issue is to approximate the forward model or the likelihood function with a surrogate model. But also there, due to limited computational resources, only a few training points are available in many practically relevant cases. Thus, it can be advantageous to model the additional uncertainties of the surrogate in order to incorporate the epistemic uncertainty due to limited data. In this paper, we develop a novel approach to approximate the log likelihood by a constrained Gaussian process based on prior knowledge about its boundedness. This improves the accuracy of the surrogate approximation without increasing the number of training samples. Additionally, we introduce a formulation to integrate the epistemic uncertainty due to limited training points into the posterior density approximation. This is combined with a state of the art active learning strategy for selecting training points, which allows to approximate posterior densities in higher dimensions very efficiently. We demonstrate the fast convergence of our approach for a benchmark problem and infer a random field that is discretized by 30 parameters using only about 1000 model evaluations. In a practically relevant example, the parameters of a reduced lung model are calibrated based on flow observations over time and voltage measurements from a coupled electrical impedance tomography simulation.","sentences":["Solving inverse problems using Bayesian methods can become prohibitively expensive when likelihood evaluations involve complex and large scale numerical models.","A common approach to circumvent this issue is to approximate the forward model or the likelihood function with a surrogate model.","But also there, due to limited computational resources, only a few training points are available in many practically relevant cases.","Thus, it can be advantageous to model the additional uncertainties of the surrogate in order to incorporate the epistemic uncertainty due to limited data.","In this paper, we develop a novel approach to approximate the log likelihood by a constrained Gaussian process based on prior knowledge about its boundedness.","This improves the accuracy of the surrogate approximation without increasing the number of training samples.","Additionally, we introduce a formulation to integrate the epistemic uncertainty due to limited training points into the posterior density approximation.","This is combined with a state of the art active learning strategy for selecting training points, which allows to approximate posterior densities in higher dimensions very efficiently.","We demonstrate the fast convergence of our approach for a benchmark problem and infer a random field that is discretized by 30 parameters using only about 1000 model evaluations.","In a practically relevant example, the parameters of a reduced lung model are calibrated based on flow observations over time and voltage measurements from a coupled electrical impedance tomography simulation."],"url":"http://arxiv.org/abs/2312.08085v1"}
{"created":"2023-12-13 11:20:09","title":"A Novel Metric for Measuring Data Quality in Classification Applications (extended version)","abstract":"Data quality is a key element for building and optimizing good learning models. Despite many attempts to characterize data quality, there is still a need for rigorous formalization and an efficient measure of the quality from available observations. Indeed, without a clear understanding of the training and testing processes, it is hard to evaluate the intrinsic performance of a model. Besides, tools allowing to measure data quality specific to machine learning are still lacking. In this paper, we introduce and explain a novel metric to measure data quality. This metric is based on the correlated evolution between the classification performance and the deterioration of data. The proposed method has the major advantage of being model-independent. Furthermore, we provide an interpretation of each criterion and examples of assessment levels. We confirm the utility of the proposed metric with intensive numerical experiments and detail some illustrative cases with controlled and interpretable qualities.","sentences":["Data quality is a key element for building and optimizing good learning models.","Despite many attempts to characterize data quality, there is still a need for rigorous formalization and an efficient measure of the quality from available observations.","Indeed, without a clear understanding of the training and testing processes, it is hard to evaluate the intrinsic performance of a model.","Besides, tools allowing to measure data quality specific to machine learning are still lacking.","In this paper, we introduce and explain a novel metric to measure data quality.","This metric is based on the correlated evolution between the classification performance and the deterioration of data.","The proposed method has the major advantage of being model-independent.","Furthermore, we provide an interpretation of each criterion and examples of assessment levels.","We confirm the utility of the proposed metric with intensive numerical experiments and detail some illustrative cases with controlled and interpretable qualities."],"url":"http://arxiv.org/abs/2312.08066v1"}
{"created":"2023-12-13 11:03:07","title":"Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source Supervision","abstract":"Ancient artifacts are an important medium for cultural preservation and restoration. However, many physical copies of artifacts are either damaged or lost, leaving a blank space in archaeological and historical studies that calls for artifact image generation techniques. Despite the significant advancements in open-domain text-to-image synthesis, existing approaches fail to capture the important domain knowledge presented in the textual description, resulting in errors in recreated images such as incorrect shapes and patterns. In this paper, we propose a novel knowledge-aware artifact image synthesis approach that brings lost historical objects accurately into their visual forms. We use a pretrained diffusion model as backbone and introduce three key techniques to enhance the text-to-image generation framework: 1) we construct prompts with explicit archaeological knowledge elicited from large language models (LLMs); 2) we incorporate additional textual guidance to correlated historical expertise in a contrastive manner; 3) we introduce further visual-semantic constraints on edge and perceptual features that enable our model to learn more intricate visual details of the artifacts. Compared to existing approaches, our proposed model produces higher-quality artifact images that align better with the implicit details and historical knowledge contained within written documents, thus achieving significant improvements across automatic metrics and in human evaluation. Our code and data are available at https://github.com/danielwusg/artifact_diffusion.","sentences":["Ancient artifacts are an important medium for cultural preservation and restoration.","However, many physical copies of artifacts are either damaged or lost, leaving a blank space in archaeological and historical studies that calls for artifact image generation techniques.","Despite the significant advancements in open-domain text-to-image synthesis, existing approaches fail to capture the important domain knowledge presented in the textual description, resulting in errors in recreated images such as incorrect shapes and patterns.","In this paper, we propose a novel knowledge-aware artifact image synthesis approach that brings lost historical objects accurately into their visual forms.","We use a pretrained diffusion model as backbone and introduce three key techniques to enhance the text-to-image generation framework: 1) we construct prompts with explicit archaeological knowledge elicited from large language models (LLMs); 2) we incorporate additional textual guidance to correlated historical expertise in a contrastive manner; 3) we introduce further visual-semantic constraints on edge and perceptual features that enable our model to learn more intricate visual details of the artifacts.","Compared to existing approaches, our proposed model produces higher-quality artifact images that align better with the implicit details and historical knowledge contained within written documents, thus achieving significant improvements across automatic metrics and in human evaluation.","Our code and data are available at https://github.com/danielwusg/artifact_diffusion."],"url":"http://arxiv.org/abs/2312.08056v1"}
{"created":"2023-12-13 11:02:19","title":"Breaking the Silence: the Threats of Using LLMs in Software Engineering","abstract":"Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization. Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs. This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings. In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns. The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation.","sentences":["Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization.","Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs.","This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings.","In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns.","The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation."],"url":"http://arxiv.org/abs/2312.08055v1"}
{"created":"2023-12-13 10:59:54","title":"Explainable Trajectory Representation through Dictionary Learning","abstract":"Trajectory representation learning on a network enhances our understanding of vehicular traffic patterns and benefits numerous downstream applications. Existing approaches using classic machine learning or deep learning embed trajectories as dense vectors, which lack interpretability and are inefficient to store and analyze in downstream tasks. In this paper, an explainable trajectory representation learning framework through dictionary learning is proposed. Given a collection of trajectories on a network, it extracts a compact dictionary of commonly used subpaths called \"pathlets\", which optimally reconstruct each trajectory by simple concatenations. The resulting representation is naturally sparse and encodes strong spatial semantics. Theoretical analysis of our proposed algorithm is conducted to provide a probabilistic bound on the estimation error of the optimal dictionary. A hierarchical dictionary learning scheme is also proposed to ensure the algorithm's scalability on large networks, leading to a multi-scale trajectory representation. Our framework is evaluated on two large-scale real-world taxi datasets. Compared to previous work, the dictionary learned by our method is more compact and has better reconstruction rate for new trajectories. We also demonstrate the promising performance of this method in downstream tasks including trip time prediction task and data compression.","sentences":["Trajectory representation learning on a network enhances our understanding of vehicular traffic patterns and benefits numerous downstream applications.","Existing approaches using classic machine learning or deep learning embed trajectories as dense vectors, which lack interpretability and are inefficient to store and analyze in downstream tasks.","In this paper, an explainable trajectory representation learning framework through dictionary learning is proposed.","Given a collection of trajectories on a network, it extracts a compact dictionary of commonly used subpaths called \"pathlets\", which optimally reconstruct each trajectory by simple concatenations.","The resulting representation is naturally sparse and encodes strong spatial semantics.","Theoretical analysis of our proposed algorithm is conducted to provide a probabilistic bound on the estimation error of the optimal dictionary.","A hierarchical dictionary learning scheme is also proposed to ensure the algorithm's scalability on large networks, leading to a multi-scale trajectory representation.","Our framework is evaluated on two large-scale real-world taxi datasets.","Compared to previous work, the dictionary learned by our method is more compact and has better reconstruction rate for new trajectories.","We also demonstrate the promising performance of this method in downstream tasks including trip time prediction task and data compression."],"url":"http://arxiv.org/abs/2312.08052v1"}
{"created":"2023-12-13 10:40:15","title":"Leveraging User Simulation to Develop and Evaluate Conversational Information Access Agents","abstract":"We observe a change in the way users access information, that is, the rise of conversational information access (CIA) agents. However, the automatic evaluation of these agents remains an open challenge. Moreover, the training of CIA agents is cumbersome as it mostly relies on conversational corpora, expert knowledge, and reinforcement learning. User simulation has been identified as a promising solution to tackle automatic evaluation and has been previously used in reinforcement learning. In this research, we investigate how user simulation can be leveraged in the context of CIA. We organize the work in three parts. We begin with the identification of requirements for user simulators for training and evaluating CIA agents and compare existing types of simulator regarding these. Then, we plan to combine these different types of simulators into a new hybrid simulator. Finally, we aim to extend simulators to handle more complex information seeking scenarios.","sentences":["We observe a change in the way users access information, that is, the rise of conversational information access (CIA) agents.","However, the automatic evaluation of these agents remains an open challenge.","Moreover, the training of CIA agents is cumbersome as it mostly relies on conversational corpora, expert knowledge, and reinforcement learning.","User simulation has been identified as a promising solution to tackle automatic evaluation and has been previously used in reinforcement learning.","In this research, we investigate how user simulation can be leveraged in the context of CIA.","We organize the work in three parts.","We begin with the identification of requirements for user simulators for training and evaluating CIA agents and compare existing types of simulator regarding these.","Then, we plan to combine these different types of simulators into a new hybrid simulator.","Finally, we aim to extend simulators to handle more complex information seeking scenarios."],"url":"http://arxiv.org/abs/2312.08041v1"}
{"created":"2023-12-13 10:35:28","title":"Combined Approximations for Uniform Operational Consistent Query Answering","abstract":"Operational consistent query answering (CQA) is a recent framework for CQA based on revised definitions of repairs, which are built by applying a sequence of operations (e.g., fact deletions) starting from an inconsistent database until we reach a database that is consistent w.r.t. the given set of constraints. It has been recently shown that there are efficient approximations for computing the percentage of repairs, as well as of sequences of operations leading to repairs, that entail a given query when we focus on primary keys, conjunctive queries, and assuming the query is fixed (i.e., in data complexity). However, it has been left open whether such approximations exist when the query is part of the input (i.e., in combined complexity). We show that this is the case when we focus on self-join-free conjunctive queries of bounded generelized hypertreewidth. We also show that it is unlikely that efficient approximation schemes exist once we give up one of the adopted syntactic restrictions, i.e., self-join-freeness or bounding the generelized hypertreewidth. Towards the desired approximation schemes, we introduce a novel counting complexity class, called SpanTL, show that each problem in SpanTL admits an efficient approximation scheme by using a recent approximability result in the context of tree automata, and then place the problems of interest in SpanTL.","sentences":["Operational consistent query answering (CQA) is a recent framework for CQA based on revised definitions of repairs, which are built by applying a sequence of operations (e.g., fact deletions) starting from an inconsistent database until we reach a database that is consistent w.r.t.","the given set of constraints.","It has been recently shown that there are efficient approximations for computing the percentage of repairs, as well as of sequences of operations leading to repairs, that entail a given query when we focus on primary keys, conjunctive queries, and assuming the query is fixed (i.e., in data complexity).","However, it has been left open whether such approximations exist when the query is part of the input (i.e., in combined complexity).","We show that this is the case when we focus on self-join-free conjunctive queries of bounded generelized hypertreewidth.","We also show that it is unlikely that efficient approximation schemes exist once we give up one of the adopted syntactic restrictions, i.e., self-join-freeness or bounding the generelized hypertreewidth.","Towards the desired approximation schemes, we introduce a novel counting complexity class, called SpanTL, show that each problem in SpanTL admits an efficient approximation scheme by using a recent approximability result in the context of tree automata, and then place the problems of interest in SpanTL."],"url":"http://arxiv.org/abs/2312.08038v1"}
{"created":"2023-12-13 10:19:58","title":"Beyond Top-Class Agreement: Using Divergences to Forecast Performance under Distribution Shift","abstract":"Knowing if a model will generalize to data 'in the wild' is crucial for safe deployment. To this end, we study model disagreement notions that consider the full predictive distribution - specifically disagreement based on Hellinger distance, Jensen-Shannon and Kullback-Leibler divergence. We find that divergence-based scores provide better test error estimates and detection rates on out-of-distribution data compared to their top-1 counterparts. Experiments involve standard vision and foundation models.","sentences":["Knowing if a model will generalize to data 'in the wild' is crucial for safe deployment.","To this end, we study model disagreement notions that consider the full predictive distribution - specifically disagreement based on Hellinger distance, Jensen-Shannon and Kullback-Leibler divergence.","We find that divergence-based scores provide better test error estimates and detection rates on out-of-distribution data compared to their top-1 counterparts.","Experiments involve standard vision and foundation models."],"url":"http://arxiv.org/abs/2312.08033v1"}
{"created":"2023-12-13 10:06:15","title":"Incremental Learning of Full-Pose Via-Point Movement Primitives on Riemannian Manifolds","abstract":"Movement primitives (MPs) are compact representations of robot skills that can be learned from demonstrations and combined into complex behaviors. However, merely equipping robots with a fixed set of innate MPs is insufficient to deploy them in dynamic and unpredictable environments. Instead, the full potential of MPs remains to be attained via adaptable, large-scale MP libraries. In this paper, we propose a set of seven fundamental operations to incrementally learn, improve, and re-organize MP libraries. To showcase their applicability, we provide explicit formulations of the spatial operations for libraries composed of Via-Point Movement Primitives (VMPs). By building on Riemannian manifold theory, our approach enables the incremental learning of all parameters of position and orientation VMPs within a library. Moreover, our approach stores a fixed number of parameters, thus complying with the essential principles of incremental learning. We evaluate our approach to incrementally learn a VMP library from motion capture data provided sequentially.","sentences":["Movement primitives (MPs) are compact representations of robot skills that can be learned from demonstrations and combined into complex behaviors.","However, merely equipping robots with a fixed set of innate MPs is insufficient to deploy them in dynamic and unpredictable environments.","Instead, the full potential of MPs remains to be attained via adaptable, large-scale MP libraries.","In this paper, we propose a set of seven fundamental operations to incrementally learn, improve, and re-organize MP libraries.","To showcase their applicability, we provide explicit formulations of the spatial operations for libraries composed of Via-Point Movement Primitives (VMPs).","By building on Riemannian manifold theory, our approach enables the incremental learning of all parameters of position and orientation VMPs within a library.","Moreover, our approach stores a fixed number of parameters, thus complying with the essential principles of incremental learning.","We evaluate our approach to incrementally learn a VMP library from motion capture data provided sequentially."],"url":"http://arxiv.org/abs/2312.08030v1"}
{"created":"2023-12-13 10:04:06","title":"ClusterDDPM: An EM clustering framework with Denoising Diffusion Probabilistic Models","abstract":"Variational autoencoder (VAE) and generative adversarial networks (GAN) have found widespread applications in clustering and have achieved significant success. However, the potential of these approaches may be limited due to VAE's mediocre generation capability or GAN's well-known instability during adversarial training. In contrast, denoising diffusion probabilistic models (DDPMs) represent a new and promising class of generative models that may unlock fresh dimensions in clustering. In this study, we introduce an innovative expectation-maximization (EM) framework for clustering using DDPMs. In the E-step, we aim to derive a mixture of Gaussian priors for the subsequent M-step. In the M-step, our focus lies in learning clustering-friendly latent representations for the data by employing the conditional DDPM and matching the distribution of latent representations to the mixture of Gaussian priors. We present a rigorous theoretical analysis of the optimization process in the M-step, proving that the optimizations are equivalent to maximizing the lower bound of the Q function within the vanilla EM framework under certain constraints. Comprehensive experiments validate the advantages of the proposed framework, showcasing superior performance in clustering, unsupervised conditional generation and latent representation learning.","sentences":["Variational autoencoder (VAE) and generative adversarial networks (GAN) have found widespread applications in clustering and have achieved significant success.","However, the potential of these approaches may be limited due to VAE's mediocre generation capability or GAN's well-known instability during adversarial training.","In contrast, denoising diffusion probabilistic models (DDPMs) represent a new and promising class of generative models that may unlock fresh dimensions in clustering.","In this study, we introduce an innovative expectation-maximization (EM) framework for clustering using DDPMs.","In the E-step, we aim to derive a mixture of Gaussian priors for the subsequent M-step.","In the M-step, our focus lies in learning clustering-friendly latent representations for the data by employing the conditional DDPM and matching the distribution of latent representations to the mixture of Gaussian priors.","We present a rigorous theoretical analysis of the optimization process in the M-step, proving that the optimizations are equivalent to maximizing the lower bound of the Q function within the vanilla EM framework under certain constraints.","Comprehensive experiments validate the advantages of the proposed framework, showcasing superior performance in clustering, unsupervised conditional generation and latent representation learning."],"url":"http://arxiv.org/abs/2312.08029v1"}
{"created":"2023-12-13 09:49:15","title":"Generalized Deepfakes Detection with Reconstructed-Blended Images and Multi-scale Feature Reconstruction Network","abstract":"The growing diversity of digital face manipulation techniques has led to an urgent need for a universal and robust detection technology to mitigate the risks posed by malicious forgeries. We present a blended-based detection approach that has robust applicability to unseen datasets. It combines a method for generating synthetic training samples, i.e., reconstructed blended images, that incorporate potential deepfake generator artifacts and a detection model, a multi-scale feature reconstruction network, for capturing the generic boundary artifacts and noise distribution anomalies brought about by digital face manipulations. Experiments demonstrated that this approach results in better performance in both cross-manipulation detection and cross-dataset detection on unseen data.","sentences":["The growing diversity of digital face manipulation techniques has led to an urgent need for a universal and robust detection technology to mitigate the risks posed by malicious forgeries.","We present a blended-based detection approach that has robust applicability to unseen datasets.","It combines a method for generating synthetic training samples, i.e., reconstructed blended images, that incorporate potential deepfake generator artifacts and a detection model, a multi-scale feature reconstruction network, for capturing the generic boundary artifacts and noise distribution anomalies brought about by digital face manipulations.","Experiments demonstrated that this approach results in better performance in both cross-manipulation detection and cross-dataset detection on unseen data."],"url":"http://arxiv.org/abs/2312.08020v1"}
{"created":"2023-12-13 09:45:58","title":"AdapEdit: Spatio-Temporal Guided Adaptive Editing Algorithm for Text-Based Continuity-Sensitive Image Editing","abstract":"With the great success of text-conditioned diffusion models in creative text-to-image generation, various text-driven image editing approaches have attracted the attentions of many researchers. However, previous works mainly focus on discreteness-sensitive instructions such as adding, removing or replacing specific objects, background elements or global styles (i.e., hard editing), while generally ignoring subject-binding but semantically fine-changing continuity-sensitive instructions such as actions, poses or adjectives, and so on (i.e., soft editing), which hampers generative AI from generating user-customized visual contents. To mitigate this predicament, we propose a spatio-temporal guided adaptive editing algorithm AdapEdit, which realizes adaptive image editing by introducing a soft-attention strategy to dynamically vary the guiding degree from the editing conditions to visual pixels from both temporal and spatial perspectives. Note our approach has a significant advantage in preserving model priors and does not require model training, fine-tuning, extra data, or optimization. We present our results over a wide variety of raw images and editing instructions, demonstrating competitive performance and showing it significantly outperforms the previous approaches.","sentences":["With the great success of text-conditioned diffusion models in creative text-to-image generation, various text-driven image editing approaches have attracted the attentions of many researchers.","However, previous works mainly focus on discreteness-sensitive instructions such as adding, removing or replacing specific objects, background elements or global styles (i.e., hard editing), while generally ignoring subject-binding but semantically fine-changing continuity-sensitive instructions such as actions, poses or adjectives, and so on (i.e., soft editing), which hampers generative AI from generating user-customized visual contents.","To mitigate this predicament, we propose a spatio-temporal guided adaptive editing algorithm AdapEdit, which realizes adaptive image editing by introducing a soft-attention strategy to dynamically vary the guiding degree from the editing conditions to visual pixels from both temporal and spatial perspectives.","Note our approach has a significant advantage in preserving model priors and does not require model training, fine-tuning, extra data, or optimization.","We present our results over a wide variety of raw images and editing instructions, demonstrating competitive performance and showing it significantly outperforms the previous approaches."],"url":"http://arxiv.org/abs/2312.08019v1"}
{"created":"2023-12-13 09:39:32","title":"Secure Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless MEC Networks","abstract":"This paper proposes a blockchain-secured deep reinforcement learning (BC-DRL) optimization framework for {data management and} resource allocation in decentralized {wireless mobile edge computing (MEC)} networks. In our framework, {we design a low-latency reputation-based proof-of-stake (RPoS) consensus protocol to select highly reliable blockchain-enabled BSs to securely store MEC user requests and prevent data tampering attacks.} {We formulate the MEC resource allocation optimization as a constrained Markov decision process that balances minimum processing latency and denial-of-service (DoS) probability}. {We use the MEC aggregated features as the DRL input to significantly reduce the high-dimensionality input of the remaining service processing time for individual MEC requests. Our designed constrained DRL effectively attains the optimal resource allocations that are adapted to the dynamic DoS requirements. We provide extensive simulation results and analysis to} validate that our BC-DRL framework achieves higher security, reliability, and resource utilization efficiency than benchmark blockchain consensus protocols and {MEC} resource allocation algorithms.","sentences":["This paper proposes a blockchain-secured deep reinforcement learning (BC-DRL) optimization framework for {data management and} resource allocation in decentralized {wireless mobile edge computing (MEC)} networks.","In our framework, {we design a low-latency reputation-based proof-of-stake (RPoS) consensus protocol to select highly reliable blockchain-enabled BSs to securely store MEC user requests and prevent data tampering attacks.}","{We formulate the MEC resource allocation optimization as a constrained Markov decision process that balances minimum processing latency and denial-of-service (DoS) probability}.","{We use the MEC aggregated features as the DRL input to significantly reduce the high-dimensionality input of the remaining service processing time for individual MEC requests.","Our designed constrained DRL effectively attains the optimal resource allocations that are adapted to the dynamic DoS requirements.","We provide extensive simulation results and analysis to} validate that our BC-DRL framework achieves higher security, reliability, and resource utilization efficiency than benchmark blockchain consensus protocols and {MEC} resource allocation algorithms."],"url":"http://arxiv.org/abs/2312.08016v1"}
{"created":"2023-12-13 09:33:08","title":"EZ-CLIP: Efficient Zeroshot Video Action Recognition","abstract":"Recent advancements in large-scale pre-training of visual-language models on paired image-text data have demonstrated impressive generalization capabilities for zero-shot tasks. Building on this success, efforts have been made to adapt these image-based visual-language models, such as CLIP, for videos extending their zero-shot capabilities to the video domain. While these adaptations have shown promising results, they come at a significant computational cost and struggle with effectively modeling the crucial temporal aspects inherent to the video domain. In this study, we present EZ-CLIP, a simple and efficient adaptation of CLIP that addresses these challenges. EZ-CLIP leverages temporal visual prompting for seamless temporal adaptation, requiring no fundamental alterations to the core CLIP architecture while preserving its remarkable generalization abilities. Moreover, we introduce a novel learning objective that guides the temporal visual prompts to focus on capturing motion, thereby enhancing its learning capabilities from video data. We conducted extensive experiments on five different benchmark datasets, thoroughly evaluating EZ-CLIP for zero-shot learning and base-to-novel video action recognition, and also demonstrating its potential for few-shot generalization.Impressively, with a mere 5.2 million learnable parameters (as opposed to the 71.1 million in the prior best model), EZ-CLIP can be efficiently trained on a single GPU, outperforming existing approaches in several evaluations.","sentences":["Recent advancements in large-scale pre-training of visual-language models on paired image-text data have demonstrated impressive generalization capabilities for zero-shot tasks.","Building on this success, efforts have been made to adapt these image-based visual-language models, such as CLIP, for videos extending their zero-shot capabilities to the video domain.","While these adaptations have shown promising results, they come at a significant computational cost and struggle with effectively modeling the crucial temporal aspects inherent to the video domain.","In this study, we present EZ-CLIP, a simple and efficient adaptation of CLIP that addresses these challenges.","EZ-CLIP leverages temporal visual prompting for seamless temporal adaptation, requiring no fundamental alterations to the core CLIP architecture while preserving its remarkable generalization abilities.","Moreover, we introduce a novel learning objective that guides the temporal visual prompts to focus on capturing motion, thereby enhancing its learning capabilities from video data.","We conducted extensive experiments on five different benchmark datasets, thoroughly evaluating EZ-CLIP for zero-shot learning and base-to-novel video action recognition, and also demonstrating its potential for few-shot generalization.","Impressively, with a mere 5.2 million learnable parameters (as opposed to the 71.1 million in the prior best model), EZ-CLIP can be efficiently trained on a single GPU, outperforming existing approaches in several evaluations."],"url":"http://arxiv.org/abs/2312.08010v1"}
{"created":"2023-12-13 09:32:50","title":"Semi-Supervised Class-Agnostic Motion Prediction with Pseudo Label Regeneration and BEVMix","abstract":"Class-agnostic motion prediction methods aim to comprehend motion within open-world scenarios, holding significance for autonomous driving systems. However, training a high-performance model in a fully-supervised manner always requires substantial amounts of manually annotated data, which can be both expensive and time-consuming to obtain. To address this challenge, our study explores the potential of semi-supervised learning (SSL) for class-agnostic motion prediction. Our SSL framework adopts a consistency-based self-training paradigm, enabling the model to learn from unlabeled data by generating pseudo labels through test-time inference. To improve the quality of pseudo labels, we propose a novel motion selection and re-generation module. This module effectively selects reliable pseudo labels and re-generates unreliable ones. Furthermore, we propose two data augmentation strategies: temporal sampling and BEVMix. These strategies facilitate consistency regularization in SSL. Experiments conducted on nuScenes demonstrate that our SSL method can surpass the self-supervised approach by a large margin by utilizing only a tiny fraction of labeled data. Furthermore, our method exhibits comparable performance to weakly and some fully supervised methods. These results highlight the ability of our method to strike a favorable balance between annotation costs and performance. Code will be available at https://github.com/kwwcv/SSMP.","sentences":["Class-agnostic motion prediction methods aim to comprehend motion within open-world scenarios, holding significance for autonomous driving systems.","However, training a high-performance model in a fully-supervised manner always requires substantial amounts of manually annotated data, which can be both expensive and time-consuming to obtain.","To address this challenge, our study explores the potential of semi-supervised learning (SSL) for class-agnostic motion prediction.","Our SSL framework adopts a consistency-based self-training paradigm, enabling the model to learn from unlabeled data by generating pseudo labels through test-time inference.","To improve the quality of pseudo labels, we propose a novel motion selection and re-generation module.","This module effectively selects reliable pseudo labels and re-generates unreliable ones.","Furthermore, we propose two data augmentation strategies: temporal sampling and BEVMix.","These strategies facilitate consistency regularization in SSL.","Experiments conducted on nuScenes demonstrate that our SSL method can surpass the self-supervised approach by a large margin by utilizing only a tiny fraction of labeled data.","Furthermore, our method exhibits comparable performance to weakly and some fully supervised methods.","These results highlight the ability of our method to strike a favorable balance between annotation costs and performance.","Code will be available at https://github.com/kwwcv/SSMP."],"url":"http://arxiv.org/abs/2312.08009v1"}
{"created":"2023-12-13 09:29:45","title":"Unveiling Parts Beyond Objects:Towards Finer-Granularity Referring Expression Segmentation","abstract":"Referring expression segmentation (RES) aims at segmenting the foreground masks of the entities that match the descriptive natural language expression. Previous datasets and methods for classic RES task heavily rely on the prior assumption that one expression must refer to object-level targets. In this paper, we take a step further to finer-grained part-level RES task. To promote the object-level RES task towards finer-grained vision-language understanding, we put forward a new multi-granularity referring expression segmentation (MRES) task and construct an evaluation benchmark called RefCOCOm by manual annotations. By employing our automatic model-assisted data engine, we build the largest visual grounding dataset namely MRES-32M, which comprises over 32.2M high-quality masks and captions on the provided 1M images. Besides, a simple yet strong model named UniRES is designed to accomplish the unified object-level and part-level grounding task. Extensive experiments on our RefCOCOm for MRES and three datasets (i.e., RefCOCO(+/g) for classic RES task demonstrate the superiority of our method over previous state-of-the-art methods. To foster future research into fine-grained visual grounding, our benchmark RefCOCOm, the MRES-32M dataset and model UniRES will be publicly available at https://github.com/Rubics-Xuan/MRES","sentences":["Referring expression segmentation (RES) aims at segmenting the foreground masks of the entities that match the descriptive natural language expression.","Previous datasets and methods for classic RES task heavily rely on the prior assumption that one expression must refer to object-level targets.","In this paper, we take a step further to finer-grained part-level RES task.","To promote the object-level RES task towards finer-grained vision-language understanding, we put forward a new multi-granularity referring expression segmentation (MRES) task and construct an evaluation benchmark called RefCOCOm","by manual annotations.","By employing our automatic model-assisted data engine, we build the largest visual grounding dataset namely MRES-32M, which comprises over 32.2M high-quality masks and captions on the provided 1M images.","Besides, a simple yet strong model named UniRES is designed to accomplish the unified object-level and part-level grounding task.","Extensive experiments on our RefCOCOm for MRES and three datasets (i.e., RefCOCO(+/g) for classic RES task demonstrate the superiority of our method over previous state-of-the-art methods.","To foster future research into fine-grained visual grounding, our benchmark RefCOCOm, the MRES-32M dataset and model UniRES will be publicly available at https://github.com/Rubics-Xuan/MRES"],"url":"http://arxiv.org/abs/2312.08007v1"}
{"created":"2023-12-13 09:04:14","title":"On the privacy of federated Clustering: A Cryptographic View","abstract":"The privacy concern in federated clustering has attracted considerable attention in past decades. Many privacy-preserving clustering algorithms leverage cryptographic techniques like homomorphic encryption or secure multiparty computation, to guarantee full privacy, i.e., no additional information is leaked other than the final output. However, given the iterative nature of clustering algorithms, consistently encrypting intermediate outputs, such as centroids, hampers efficiency. This paper delves into this intricate trade-off, questioning the necessity of continuous encryption in iterative algorithms. Using the federated K-means clustering as an example, we mathematically formulate the problem of reconstructing input private data from the intermediate centroids as a classical cryptographic problem called hidden subset sum problem (HSSP)-extended from an NP-complete problem called subset sum problem (SSP). Through an in-depth analysis, we show that existing lattice-based HSSP attacks fail in reconstructing the private data given the knowledge of intermediate centroids, thus it is secure to reveal them for the sake of efficiency. To the best of our knowledge, our work is the first to cast federated clustering's privacy concerns as a cryptographic problem HSSP such that a concrete and rigorous analysis can be conducted.","sentences":["The privacy concern in federated clustering has attracted considerable attention in past decades.","Many privacy-preserving clustering algorithms leverage cryptographic techniques like homomorphic encryption or secure multiparty computation, to guarantee full privacy, i.e., no additional information is leaked other than the final output.","However, given the iterative nature of clustering algorithms, consistently encrypting intermediate outputs, such as centroids, hampers efficiency.","This paper delves into this intricate trade-off, questioning the necessity of continuous encryption in iterative algorithms.","Using the federated K-means clustering as an example, we mathematically formulate the problem of reconstructing input private data from the intermediate centroids as a classical cryptographic problem called hidden subset sum problem (HSSP)-extended from an NP-complete problem called subset sum problem (SSP).","Through an in-depth analysis, we show that existing lattice-based HSSP attacks fail in reconstructing the private data given the knowledge of intermediate centroids, thus it is secure to reveal them for the sake of efficiency.","To the best of our knowledge, our work is the first to cast federated clustering's privacy concerns as a cryptographic problem HSSP such that a concrete and rigorous analysis can be conducted."],"url":"http://arxiv.org/abs/2312.07992v1"}
{"created":"2023-12-13 08:53:37","title":"Time Series Diffusion Method: A Denoising Diffusion Probabilistic Model for Vibration Signal Generation","abstract":"Diffusion models have demonstrated robust data generation capabilities in various research fields. In this paper, a Time Series Diffusion Method (TSDM) is proposed for vibration signal generation, leveraging the foundational principles of diffusion models. The TSDM uses an improved U-net architecture with attention block to effectively segment and extract features from one-dimensional time series data. It operates based on forward diffusion and reverse denoising processes for time-series generation. Experimental validation is conducted using single-frequency, multi-frequency datasets, and bearing fault datasets. The results show that TSDM can accurately generate the single-frequency and multi-frequency features in the time series and retain the basic frequency features for the diffusion generation results of the bearing fault series. Finally, TSDM is applied to the small sample fault diagnosis of three public bearing fault datasets, and the results show that the accuracy of small sample fault diagnosis of the three datasets is improved by 32.380%, 18.355% and 9.298% at most, respectively","sentences":["Diffusion models have demonstrated robust data generation capabilities in various research fields.","In this paper, a Time Series Diffusion Method (TSDM) is proposed for vibration signal generation, leveraging the foundational principles of diffusion models.","The TSDM uses an improved U-net architecture with attention block to effectively segment and extract features from one-dimensional time series data.","It operates based on forward diffusion and reverse denoising processes for time-series generation.","Experimental validation is conducted using single-frequency, multi-frequency datasets, and bearing fault datasets.","The results show that TSDM can accurately generate the single-frequency and multi-frequency features in the time series and retain the basic frequency features for the diffusion generation results of the bearing fault series.","Finally, TSDM is applied to the small sample fault diagnosis of three public bearing fault datasets, and the results show that the accuracy of small sample fault diagnosis of the three datasets is improved by 32.380%, 18.355% and 9.298% at most, respectively"],"url":"http://arxiv.org/abs/2312.07981v1"}
{"created":"2023-12-13 08:45:57","title":"Challenges of YOLO Series for Object Detection in Extremely Heavy Rain: CALRA Simulator based Synthetic Evaluation Dat a set","abstract":"Recently, as many studies of autonomous vehicles have been achieved for levels 4 and 5, there has been also increasing interest in the advancement of perception, decision, and control technologies, which are the three major aspects of autonomous vehicles. As for the perception technologies achieving reliable maneuvering of autonomous vehicles, object detection by using diverse sensors (e.g., LiDAR, radar, and camera) should be prioritized. These sensors require to detect objects accurately and quickly in diverse weather conditions, but they tend to have challenges to consistently detect objects in bad weather conditions with rain, snow, or fog. Thus, in this study, based on the experimentally obtained raindrop data from precipitation conditions, we constructed a novel dataset that could test diverse network model in various precipitation conditions through the CARLA simulator. Consequently, based on our novel dataset, YOLO series, a one-stage-detector, was used to quantitatively verify how much object detection performance could be decreased under various precipitation conditions from normal to extreme heavy rain situations.","sentences":["Recently, as many studies of autonomous vehicles have been achieved for levels 4 and 5, there has been also increasing interest in the advancement of perception, decision, and control technologies, which are the three major aspects of autonomous vehicles.","As for the perception technologies achieving reliable maneuvering of autonomous vehicles, object detection by using diverse sensors (e.g., LiDAR, radar, and camera) should be prioritized.","These sensors require to detect objects accurately and quickly in diverse weather conditions, but they tend to have challenges to consistently detect objects in bad weather conditions with rain, snow, or fog.","Thus, in this study, based on the experimentally obtained raindrop data from precipitation conditions, we constructed a novel dataset that could test diverse network model in various precipitation conditions through the CARLA simulator.","Consequently, based on our novel dataset, YOLO series, a one-stage-detector, was used to quantitatively verify how much object detection performance could be decreased under various precipitation conditions from normal to extreme heavy rain situations."],"url":"http://arxiv.org/abs/2312.07976v1"}
{"created":"2023-12-13 08:33:50","title":"Divide and Conquer: Hybrid Pre-training for Person Search","abstract":"Large-scale pre-training has proven to be an effective method for improving performance across different tasks. Current person search methods use ImageNet pre-trained models for feature extraction, yet it is not an optimal solution due to the gap between the pre-training task and person search task (as a downstream task). Therefore, in this paper, we focus on pre-training for person search, which involves detecting and re-identifying individuals simultaneously. Although labeled data for person search is scarce, datasets for two sub-tasks person detection and re-identification are relatively abundant. To this end, we propose a hybrid pre-training framework specifically designed for person search using sub-task data only. It consists of a hybrid learning paradigm that handles data with different kinds of supervisions, and an intra-task alignment module that alleviates domain discrepancy under limited resources. To the best of our knowledge, this is the first work that investigates how to support full-task pre-training using sub-task data. Extensive experiments demonstrate that our pre-trained model can achieve significant improvements across diverse protocols, such as person search method, fine-tuning data, pre-training data and model backbone. For example, our model improves ResNet50 based NAE by 10.3% relative improvement w.r.t. mAP. Our code and pre-trained models are released for plug-and-play usage to the person search community.","sentences":["Large-scale pre-training has proven to be an effective method for improving performance across different tasks.","Current person search methods use ImageNet pre-trained models for feature extraction, yet it is not an optimal solution due to the gap between the pre-training task and person search task (as a downstream task).","Therefore, in this paper, we focus on pre-training for person search, which involves detecting and re-identifying individuals simultaneously.","Although labeled data for person search is scarce, datasets for two sub-tasks person detection and re-identification are relatively abundant.","To this end, we propose a hybrid pre-training framework specifically designed for person search using sub-task data only.","It consists of a hybrid learning paradigm that handles data with different kinds of supervisions, and an intra-task alignment module that alleviates domain discrepancy under limited resources.","To the best of our knowledge, this is the first work that investigates how to support full-task pre-training using sub-task data.","Extensive experiments demonstrate that our pre-trained model can achieve significant improvements across diverse protocols, such as person search method, fine-tuning data, pre-training data and model backbone.","For example, our model improves ResNet50 based NAE by 10.3% relative improvement w.r.t.","mAP.","Our code and pre-trained models are released for plug-and-play usage to the person search community."],"url":"http://arxiv.org/abs/2312.07970v1"}
{"created":"2023-12-13 08:28:55","title":"A multi-sourced data and agent-based approach for complementing Time Use Surveys in the context of residential human activity and load curve simulation","abstract":"To address the major issues associated with using Time-Use Survey (TUS) for simulating residential load curves, we present the SMACH approach, which combines qualitative and quantitative data with agent-based simulation. Our model consists of autonomous agents assigned with daily tasks. The agents try to accomplish their assigned tasks to the best of their abilities. Quantitative data are used to generate tasks assignments. Qualitative studies allow us to define how agents select, based on plausible cognitive principles, the tasks to accomplish depending on the context. Our results show a better representation of weekdays and weekends, a more flexible association of tasks with appliances, and an improved simulation of load curves compared to real data. Highlights $\\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in activity and energy simulation $\\bullet$ Presentation of complementary data both qualitative and quantitative used to complement TUS data $\\bullet$ Proposition of an agent-based approach that balances these limitations","sentences":["To address the major issues associated with using Time-Use Survey (TUS) for simulating residential load curves, we present the SMACH approach, which combines qualitative and quantitative data with agent-based simulation.","Our model consists of autonomous agents assigned with daily tasks.","The agents try to accomplish their assigned tasks to the best of their abilities.","Quantitative data are used to generate tasks assignments.","Qualitative studies allow us to define how agents select, based on plausible cognitive principles, the tasks to accomplish depending on the context.","Our results show a better representation of weekdays and weekends, a more flexible association of tasks with appliances, and an improved simulation of load curves compared to real data.","Highlights $\\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in activity and energy simulation $\\bullet$ Presentation of complementary data both qualitative and quantitative used to complement TUS data $\\bullet$ Proposition of an agent-based approach that balances these limitations"],"url":"http://arxiv.org/abs/2312.07966v1"}
{"created":"2023-12-13 08:18:49","title":"Three-Filters-to-Normal+: Revisiting Discontinuity Discrimination in Depth-to-Normal Translation","abstract":"This article introduces three-filters-to-normal+ (3F2N+), an extension of our previous work three-filters-to-normal (3F2N), with a specific focus on incorporating discontinuity discrimination capability into surface normal estimators (SNEs). 3F2N+ achieves this capability by utilizing a novel discontinuity discrimination module (DDM), which combines depth curvature minimization and correlation coefficient maximization through conditional random fields (CRFs). To evaluate the robustness of SNEs on noisy data, we create a large-scale synthetic surface normal (SSN) dataset containing 20 scenarios (ten indoor scenarios and ten outdoor scenarios with and without random Gaussian noise added to depth images). Extensive experiments demonstrate that 3F2N+ achieves greater performance than all other geometry-based surface normal estimators, with average angular errors of 7.85$^\\circ$, 8.95$^\\circ$, 9.25$^\\circ$, and 11.98$^\\circ$ on the clean-indoor, clean-outdoor, noisy-indoor, and noisy-outdoor datasets, respectively. We conduct three additional experiments to demonstrate the effectiveness of incorporating our proposed 3F2N+ into downstream robot perception tasks, including freespace detection, 6D object pose estimation, and point cloud completion. Our source code and datasets are publicly available at https://mias.group/3F2Nplus.","sentences":["This article introduces three-filters-to-normal+ (3F2N+), an extension of our previous work three-filters-to-normal (3F2N), with a specific focus on incorporating discontinuity discrimination capability into surface normal estimators (SNEs).","3F2N+ achieves this capability by utilizing a novel discontinuity discrimination module (DDM), which combines depth curvature minimization and correlation coefficient maximization through conditional random fields (CRFs).","To evaluate the robustness of SNEs on noisy data, we create a large-scale synthetic surface normal (SSN) dataset containing 20 scenarios (ten indoor scenarios and ten outdoor scenarios with and without random Gaussian noise added to depth images).","Extensive experiments demonstrate that 3F2N+ achieves greater performance than all other geometry-based surface normal estimators, with average angular errors of 7.85$^\\circ$, 8.95$^\\circ$, 9.25$^\\circ$, and 11.98$^\\circ$ on the clean-indoor, clean-outdoor, noisy-indoor, and noisy-outdoor datasets, respectively.","We conduct three additional experiments to demonstrate the effectiveness of incorporating our proposed 3F2N+ into downstream robot perception tasks, including freespace detection, 6D object pose estimation, and point cloud completion.","Our source code and datasets are publicly available at https://mias.group/3F2Nplus."],"url":"http://arxiv.org/abs/2312.07964v1"}
{"created":"2023-12-13 08:17:00","title":"Robust Few-Shot Named Entity Recognition with Boundary Discrimination and Correlation Purification","abstract":"Few-shot named entity recognition (NER) aims to recognize novel named entities in low-resource domains utilizing existing knowledge. However, the present few-shot NER models assume that the labeled data are all clean without noise or outliers, and there are few works focusing on the robustness of the cross-domain transfer learning ability to textual adversarial attacks in Few-shot NER. In this work, we comprehensively explore and assess the robustness of few-shot NER models under textual adversarial attack scenario, and found the vulnerability of existing few-shot NER models. Furthermore, we propose a robust two-stage few-shot NER method with Boundary Discrimination and Correlation Purification (BDCP). Specifically, in the span detection stage, the entity boundary discriminative module is introduced to provide a highly distinguishing boundary representation space to detect entity spans. In the entity typing stage, the correlations between entities and contexts are purified by minimizing the interference information and facilitating correlation generalization to alleviate the perturbations caused by textual adversarial attacks. In addition, we construct adversarial examples for few-shot NER based on public datasets Few-NERD and Cross-Dataset. Comprehensive evaluations on those two groups of few-shot NER datasets containing adversarial examples demonstrate the robustness and superiority of the proposed method.","sentences":["Few-shot named entity recognition (NER) aims to recognize novel named entities in low-resource domains utilizing existing knowledge.","However, the present few-shot NER models assume that the labeled data are all clean without noise or outliers, and there are few works focusing on the robustness of the cross-domain transfer learning ability to textual adversarial attacks in Few-shot NER.","In this work, we comprehensively explore and assess the robustness of few-shot NER models under textual adversarial attack scenario, and found the vulnerability of existing few-shot NER models.","Furthermore, we propose a robust two-stage few-shot NER method with Boundary Discrimination and Correlation Purification (BDCP).","Specifically, in the span detection stage, the entity boundary discriminative module is introduced to provide a highly distinguishing boundary representation space to detect entity spans.","In the entity typing stage, the correlations between entities and contexts are purified by minimizing the interference information and facilitating correlation generalization to alleviate the perturbations caused by textual adversarial attacks.","In addition, we construct adversarial examples for few-shot NER based on public datasets Few-NERD and Cross-Dataset.","Comprehensive evaluations on those two groups of few-shot NER datasets containing adversarial examples demonstrate the robustness and superiority of the proposed method."],"url":"http://arxiv.org/abs/2312.07961v1"}
{"created":"2023-12-13 07:57:40","title":"Semantic-aware Data Augmentation for Text-to-image Synthesis","abstract":"Data augmentation has been recently leveraged as an effective regularizer in various vision-language deep neural networks. However, in text-to-image synthesis (T2Isyn), current augmentation wisdom still suffers from the semantic mismatch between augmented paired data. Even worse, semantic collapse may occur when generated images are less semantically constrained. In this paper, we develop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to T2Isyn. In particular, we propose to augment texts in the semantic space via an Implicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with a specifically designed Image Semantic Regularization Loss ($L_r$) as Generated Image Semantic Conservation, to cope well with semantic mismatch and collapse. As one major contribution, we theoretically show that $ITA$ can certify better text-image consistency while $L_r$ regularizing the semantics of generated images would avoid semantic collapse and enhance image quality. Extensive experiments validate that SADA enhances text-image consistency and improves image quality significantly in T2Isyn models across various backbones. Especially, incorporating SADA during the tuning process of Stable Diffusion models also yields performance improvements.","sentences":["Data augmentation has been recently leveraged as an effective regularizer in various vision-language deep neural networks.","However, in text-to-image synthesis (T2Isyn), current augmentation wisdom still suffers from the semantic mismatch between augmented paired data.","Even worse, semantic collapse may occur when generated images are less semantically constrained.","In this paper, we develop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to T2Isyn.","In particular, we propose to augment texts in the semantic space via an Implicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with a specifically designed Image Semantic Regularization Loss ($L_r$) as Generated Image Semantic Conservation, to cope well with semantic mismatch and collapse.","As one major contribution, we theoretically show that $ITA$ can certify better text-image consistency while $L_r$ regularizing the semantics of generated images would avoid semantic collapse and enhance image quality.","Extensive experiments validate that SADA enhances text-image consistency and improves image quality significantly in T2Isyn models across various backbones.","Especially, incorporating SADA during the tuning process of Stable Diffusion models also yields performance improvements."],"url":"http://arxiv.org/abs/2312.07951v1"}
{"created":"2023-12-13 07:53:06","title":"Zero-Knowledge Proof of Traffic: A Deterministic and Privacy-Preserving Cross Verification Mechanism for Cooperative Perception Data","abstract":"Cooperative perception is crucial for connected automated vehicles in intelligent transportation systems (ITSs); however, ensuring the authenticity of perception data remains a challenge as the vehicles cannot verify events that they do not witness independently. Various studies have been conducted on establishing the authenticity of data, such as trust-based statistical methods and plausibility-based methods. However, these methods are limited as they require prior knowledge such as previous sender behaviors or predefined rules to evaluate the authenticity. To overcome this limitation, this study proposes a novel approach called zero-knowledge Proof of Traffic (zk-PoT), which involves generating cryptographic proofs to the traffic observations. Multiple independent proofs regarding the same vehicle can be deterministically cross-verified by any receivers without relying on ground truth, probabilistic, or plausibility evaluations. Additionally, no private information is compromised during the entire procedure. A full on-board unit software stack that reflects the behavior of zk-PoT is implemented within a specifically designed simulator called Flowsim. A comprehensive experimental analysis is then conducted using synthesized city-scale simulations, which demonstrates that zk-PoT's cross-verification ratio ranges between 80 % to 96 %, and 80 % of the verification is achieved in 2 s, with a protocol overhead of approximately 25 %. Furthermore, the analyses of various attacks indicate that most of the attacks could be prevented, and some, such as collusion attacks, can be mitigated. The proposed approach can be incorporated into existing works, including the European Telecommunications Standards Institute (ETSI) and the International Organization for Standardization (ISO) ITS standards, without disrupting the backward compatibility.","sentences":["Cooperative perception is crucial for connected automated vehicles in intelligent transportation systems (ITSs); however, ensuring the authenticity of perception data remains a challenge as the vehicles cannot verify events that they do not witness independently.","Various studies have been conducted on establishing the authenticity of data, such as trust-based statistical methods and plausibility-based methods.","However, these methods are limited as they require prior knowledge such as previous sender behaviors or predefined rules to evaluate the authenticity.","To overcome this limitation, this study proposes a novel approach called zero-knowledge Proof of Traffic (zk-PoT), which involves generating cryptographic proofs to the traffic observations.","Multiple independent proofs regarding the same vehicle can be deterministically cross-verified by any receivers without relying on ground truth, probabilistic, or plausibility evaluations.","Additionally, no private information is compromised during the entire procedure.","A full on-board unit software stack that reflects the behavior of zk-PoT is implemented within a specifically designed simulator called Flowsim.","A comprehensive experimental analysis is then conducted using synthesized city-scale simulations, which demonstrates that zk-PoT's cross-verification ratio ranges between 80 % to 96 %, and 80 % of the verification is achieved in 2 s, with a protocol overhead of approximately 25 %.","Furthermore, the analyses of various attacks indicate that most of the attacks could be prevented, and some, such as collusion attacks, can be mitigated.","The proposed approach can be incorporated into existing works, including the European Telecommunications Standards Institute (ETSI) and the International Organization for Standardization (ISO) ITS standards, without disrupting the backward compatibility."],"url":"http://arxiv.org/abs/2312.07948v1"}
{"created":"2023-12-13 07:51:21","title":"Incremental Computation: What Is the Essence?","abstract":"Incremental computation aims to compute more efficiently on changed input by reusing previously computed results. We give a high-level overview of works on incremental computation, and highlight the essence underlying all of them, which we call incrementalization -- the discrete counterpart of differentiation in calculus. We review the gist of a systematic method for incrementalization, and a systematic method centered around it, called Iterate-Incrementalize-Implement, for program design and optimization, as well as algorithm design and optimization. At a meta-level, with historical contexts and for future directions, we stress the power of high-level data, control, and module abstractions in developing new and better algorithms and programs as well as their precise complexities.","sentences":["Incremental computation aims to compute more efficiently on changed input by reusing previously computed results.","We give a high-level overview of works on incremental computation, and highlight the essence underlying all of them, which we call incrementalization -- the discrete counterpart of differentiation in calculus.","We review the gist of a systematic method for incrementalization, and a systematic method centered around it, called Iterate-Incrementalize-Implement, for program design and optimization, as well as algorithm design and optimization.","At a meta-level, with historical contexts and for future directions, we stress the power of high-level data, control, and module abstractions in developing new and better algorithms and programs as well as their precise complexities."],"url":"http://arxiv.org/abs/2312.07946v1"}
{"created":"2023-12-13 07:38:34","title":"Learning Diffusions under Uncertainty","abstract":"To infer a diffusion network based on observations from historical diffusion processes, existing approaches assume that observation data contain exact occurrence time of each node infection, or at least the eventual infection statuses of nodes in each diffusion process. They determine potential influence relationships between nodes by identifying frequent sequences, or statistical correlations, among node infections. In some real-world settings, such as the spread of epidemics, tracing exact infection times is often infeasible due to a high cost; even obtaining precise infection statuses of nodes is a challenging task, since observable symptoms such as headache only partially reveal a node's true status. In this work, we investigate how to effectively infer a diffusion network from observation data with uncertainty. Provided with only probabilistic information about node infection statuses, we formulate the problem of diffusion network inference as a constrained nonlinear regression w.r.t. the probabilistic data. An alternating maximization method is designed to solve this regression problem iteratively, and the improvement of solution quality in each iteration can be theoretically guaranteed. Empirical studies are conducted on both synthetic and real-world networks, and the results verify the effectiveness and efficiency of our approach.","sentences":["To infer a diffusion network based on observations from historical diffusion processes, existing approaches assume that observation data contain exact occurrence time of each node infection, or at least the eventual infection statuses of nodes in each diffusion process.","They determine potential influence relationships between nodes by identifying frequent sequences, or statistical correlations, among node infections.","In some real-world settings, such as the spread of epidemics, tracing exact infection times is often infeasible due to a high cost; even obtaining precise infection statuses of nodes is a challenging task, since observable symptoms such as headache only partially reveal a node's true status.","In this work, we investigate how to effectively infer a diffusion network from observation data with uncertainty.","Provided with only probabilistic information about node infection statuses, we formulate the problem of diffusion network inference as a constrained nonlinear regression w.r.t.","the probabilistic data.","An alternating maximization method is designed to solve this regression problem iteratively, and the improvement of solution quality in each iteration can be theoretically guaranteed.","Empirical studies are conducted on both synthetic and real-world networks, and the results verify the effectiveness and efficiency of our approach."],"url":"http://arxiv.org/abs/2312.07942v1"}
{"created":"2023-12-13 07:30:19","title":"BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics","abstract":"The recently emerging text-to-motion advances have spired numerous attempts for convenient and interactive human motion generation. Yet, existing methods are largely limited to generating body motions only without considering the rich two-hand motions, let alone handling various conditions like body dynamics or texts. To break the data bottleneck, we propose BOTH57M, a novel multi-modal dataset for two-hand motion generation. Our dataset includes accurate motion tracking for the human body and hands and provides pair-wised finger-level hand annotations and body descriptions. We further provide a strong baseline method, BOTH2Hands, for the novel task: generating vivid two-hand motions from both implicit body dynamics and explicit text prompts. We first warm up two parallel body-to-hand and text-to-hand diffusion models and then utilize the cross-attention transformer for motion blending. Extensive experiments and cross-validations demonstrate the effectiveness of our approach and dataset for generating convincing two-hand motions from the hybrid body-and-textual conditions. Our dataset and code will be disseminated to the community for future research.","sentences":["The recently emerging text-to-motion advances have spired numerous attempts for convenient and interactive human motion generation.","Yet, existing methods are largely limited to generating body motions only without considering the rich two-hand motions, let alone handling various conditions like body dynamics or texts.","To break the data bottleneck, we propose BOTH57M, a novel multi-modal dataset for two-hand motion generation.","Our dataset includes accurate motion tracking for the human body and hands and provides pair-wised finger-level hand annotations and body descriptions.","We further provide a strong baseline method, BOTH2Hands, for the novel task: generating vivid two-hand motions from both implicit body dynamics and explicit text prompts.","We first warm up two parallel body-to-hand and text-to-hand diffusion models and then utilize the cross-attention transformer for motion blending.","Extensive experiments and cross-validations demonstrate the effectiveness of our approach and dataset for generating convincing two-hand motions from the hybrid body-and-textual conditions.","Our dataset and code will be disseminated to the community for future research."],"url":"http://arxiv.org/abs/2312.07937v1"}
{"created":"2023-12-13 07:20:27","title":"Levenshtein Distance Embedding with Poisson Regression for DNA Storage","abstract":"Efficient computation or approximation of Levenshtein distance, a widely-used metric for evaluating sequence similarity, has attracted significant attention with the emergence of DNA storage and other biological applications. Sequence embedding, which maps Levenshtein distance to a conventional distance between embedding vectors, has emerged as a promising solution. In this paper, a novel neural network-based sequence embedding technique using Poisson regression is proposed. We first provide a theoretical analysis of the impact of embedding dimension on model performance and present a criterion for selecting an appropriate embedding dimension. Under this embedding dimension, the Poisson regression is introduced by assuming the Levenshtein distance between sequences of fixed length following a Poisson distribution, which naturally aligns with the definition of Levenshtein distance. Moreover, from the perspective of the distribution of embedding distances, Poisson regression approximates the negative log likelihood of the chi-squared distribution and offers advancements in removing the skewness. Through comprehensive experiments on real DNA storage data, we demonstrate the superior performance of the proposed method compared to state-of-the-art approaches.","sentences":["Efficient computation or approximation of Levenshtein distance, a widely-used metric for evaluating sequence similarity, has attracted significant attention with the emergence of DNA storage and other biological applications.","Sequence embedding, which maps Levenshtein distance to a conventional distance between embedding vectors, has emerged as a promising solution.","In this paper, a novel neural network-based sequence embedding technique using Poisson regression is proposed.","We first provide a theoretical analysis of the impact of embedding dimension on model performance and present a criterion for selecting an appropriate embedding dimension.","Under this embedding dimension, the Poisson regression is introduced by assuming the Levenshtein distance between sequences of fixed length following a Poisson distribution, which naturally aligns with the definition of Levenshtein distance.","Moreover, from the perspective of the distribution of embedding distances, Poisson regression approximates the negative log likelihood of the chi-squared distribution and offers advancements in removing the skewness.","Through comprehensive experiments on real DNA storage data, we demonstrate the superior performance of the proposed method compared to state-of-the-art approaches."],"url":"http://arxiv.org/abs/2312.07931v1"}
{"created":"2023-12-13 06:35:39","title":"BinGo: Identifying Security Patches in Binary Code with Graph Representation Learning","abstract":"A timely software update is vital to combat the increasing security vulnerabilities. However, some software vendors may secretly patch their vulnerabilities without creating CVE entries or even describing the security issue in their change log. Thus, it is critical to identify these hidden security patches and defeat potential N-day attacks. Researchers have employed various machine learning techniques to identify security patches in open-source software, leveraging the syntax and semantic features of the software changes and commit messages. However, all these solutions cannot be directly applied to the binary code, whose instructions and program flow may dramatically vary due to different compilation configurations. In this paper, we propose BinGo, a new security patch detection system for binary code. The main idea is to present the binary code as code property graphs to enable a comprehensive understanding of program flow and perform a language model over each basic block of binary code to catch the instruction semantics. BinGo consists of four phases, namely, patch data pre-processing, graph extraction, embedding generation, and graph representation learning. Due to the lack of an existing binary security patch dataset, we construct such a dataset by compiling the pre-patch and post-patch source code of the Linux kernel. Our experimental results show BinGo can achieve up to 80.77% accuracy in identifying security patches between two neighboring versions of binary code. Moreover, BinGo can effectively reduce the false positives and false negatives caused by the different compilers and optimization levels.","sentences":["A timely software update is vital to combat the increasing security vulnerabilities.","However, some software vendors may secretly patch their vulnerabilities without creating CVE entries or even describing the security issue in their change log.","Thus, it is critical to identify these hidden security patches and defeat potential N-day attacks.","Researchers have employed various machine learning techniques to identify security patches in open-source software, leveraging the syntax and semantic features of the software changes and commit messages.","However, all these solutions cannot be directly applied to the binary code, whose instructions and program flow may dramatically vary due to different compilation configurations.","In this paper, we propose BinGo, a new security patch detection system for binary code.","The main idea is to present the binary code as code property graphs to enable a comprehensive understanding of program flow and perform a language model over each basic block of binary code to catch the instruction semantics.","BinGo consists of four phases, namely, patch data pre-processing, graph extraction, embedding generation, and graph representation learning.","Due to the lack of an existing binary security patch dataset, we construct such a dataset by compiling the pre-patch and post-patch source code of the Linux kernel.","Our experimental results show BinGo can achieve up to 80.77% accuracy in identifying security patches between two neighboring versions of binary code.","Moreover, BinGo can effectively reduce the false positives and false negatives caused by the different compilers and optimization levels."],"url":"http://arxiv.org/abs/2312.07921v1"}
{"created":"2023-12-13 06:22:02","title":"On Designing Multi-UAV aided Wireless Powered Dynamic Communication via Hierarchical Deep Reinforcement Learning","abstract":"This paper proposes a novel design on the wireless powered communication network (WPCN) in dynamic environments under the assistance of multiple unmanned aerial vehicles (UAVs). Unlike the existing studies, where the low-power wireless nodes (WNs) often conform to the coherent harvest-then-transmit protocol, under our newly proposed double-threshold based WN type updating rule, each WN can dynamically and repeatedly update its WN type as an E-node for non-linear energy harvesting over time slots or an I-node for transmitting data over sub-slots. To maximize the total transmission data size of all the WNs over T slots, each of the UAVs individually determines its trajectory and binary wireless energy transmission (WET) decisions over times slots and its binary wireless data collection (WDC) decisions over sub-slots, under the constraints of each UAV's limited on-board energy and each WN's node type updating rule. However, due to the UAVs' tightly-coupled trajectories with their WET and WDC decisions, as well as each WN's time-varying battery energy, this problem is difficult to solve optimally. We then propose a new multi-agent based hierarchical deep reinforcement learning (MAHDRL) framework with two tiers to solve the problem efficiently, where the soft actor critic (SAC) policy is designed in tier-1 to determine each UAV's continuous trajectory and binary WET decision over time slots, and the deep-Q learning (DQN) policy is designed in tier-2 to determine each UAV's binary WDC decisions over sub-slots under the given UAV trajectory from tier-1. Both of the SAC policy and the DQN policy are executed distributively at each UAV. Finally, extensive simulation results are provided to validate the outweighed performance of the proposed MAHDRL approach over various state-of-the-art benchmarks.","sentences":["This paper proposes a novel design on the wireless powered communication network (WPCN) in dynamic environments under the assistance of multiple unmanned aerial vehicles (UAVs).","Unlike the existing studies, where the low-power wireless nodes (WNs) often conform to the coherent harvest-then-transmit protocol, under our newly proposed double-threshold based WN type updating rule, each WN can dynamically and repeatedly update its WN type as an E-node for non-linear energy harvesting over time slots or an I-node for transmitting data over sub-slots.","To maximize the total transmission data size of all the WNs over T slots, each of the UAVs individually determines its trajectory and binary wireless energy transmission (WET) decisions over times slots and its binary wireless data collection (WDC) decisions over sub-slots, under the constraints of each UAV's limited on-board energy and each WN's node type updating rule.","However, due to the UAVs' tightly-coupled trajectories with their WET and WDC decisions, as well as each WN's time-varying battery energy, this problem is difficult to solve optimally.","We then propose a new multi-agent based hierarchical deep reinforcement learning (MAHDRL) framework with two tiers to solve the problem efficiently, where the soft actor critic (SAC) policy is designed in tier-1 to determine each UAV's continuous trajectory and binary WET decision over time slots, and the deep-Q learning (DQN) policy is designed in tier-2 to determine each UAV's binary WDC decisions over sub-slots under the given UAV trajectory from tier-1.","Both of the SAC policy and the DQN policy are executed distributively at each UAV.","Finally, extensive simulation results are provided to validate the outweighed performance of the proposed MAHDRL approach over various state-of-the-art benchmarks."],"url":"http://arxiv.org/abs/2312.07917v1"}
{"created":"2023-12-13 06:11:42","title":"A Survey of Text Watermarking in the Era of Large Language Models","abstract":"In recent years, significant advancements have been made in the text generation capabilities of Large Language Models (LLMs), demonstrating exceptional performance in downstream tasks such as abstract summarization, dialogue generation, and data-to-text conversion. However, their generative abilities also pose risks such as the rapid spread of fake news, infringement of datasets/LLM copyrights, and challenges to academic integrity. Text watermarking technology emerges as a potential solution. By embedding invisible yet detectable patterns in generated texts, it helps in tracking and verifying text origins, thus preventing misuse and piracy.   This survey aims to comprehensively summarize current text watermarking technologies, covering three main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their success rate, impact on text quality, robustness, and unforgeability; (3) potential applications of text watermarking technologys. This survey aims to help researchers thoroughly understanding the text watermarking technologies, thereby fostering further development.","sentences":["In recent years, significant advancements have been made in the text generation capabilities of Large Language Models (LLMs), demonstrating exceptional performance in downstream tasks such as abstract summarization, dialogue generation, and data-to-text conversion.","However, their generative abilities also pose risks such as the rapid spread of fake news, infringement of datasets/LLM copyrights, and challenges to academic integrity.","Text watermarking technology emerges as a potential solution.","By embedding invisible yet detectable patterns in generated texts, it helps in tracking and verifying text origins, thus preventing misuse and piracy.   ","This survey aims to comprehensively summarize current text watermarking technologies, covering three main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their success rate, impact on text quality, robustness, and unforgeability; (3) potential applications of text watermarking technologys.","This survey aims to help researchers thoroughly understanding the text watermarking technologies, thereby fostering further development."],"url":"http://arxiv.org/abs/2312.07913v1"}
{"created":"2023-12-13 05:15:57","title":"Artificial Intelligence Studies in Cartography: A Review and Synthesis of Methods, Applications, and Ethics","abstract":"The past decade has witnessed the rapid development of geospatial artificial intelligence (GeoAI) primarily due to the ground-breaking achievements in deep learning and machine learning. A growing number of scholars from cartography have demonstrated successfully that GeoAI can accelerate previously complex cartographic design tasks and even enable cartographic creativity in new ways. Despite the promise of GeoAI, researchers and practitioners have growing concerns about the ethical issues of GeoAI for cartography. In this paper, we conducted a systematic content analysis and narrative synthesis of research studies integrating GeoAI and cartography to summarize current research and development trends regarding the usage of GeoAI for cartographic design. Based on this review and synthesis, we first identify dimensions of GeoAI methods for cartography such as data sources, data formats, map evaluations, and six contemporary GeoAI models, each of which serves a variety of cartographic tasks. These models include decision trees, knowledge graph and semantic web technologies, deep convolutional neural networks, generative adversarial networks, graph neural networks, and reinforcement learning. Further, we summarize seven cartographic design applications where GeoAI have been effectively employed: generalization, symbolization, typography, map reading, map interpretation, map analysis, and map production. We also raise five potential ethical challenges that need to be addressed in the integration of GeoAI for cartography: commodification, responsibility, privacy, bias, and (together) transparency, explainability, and provenance. We conclude by identifying four potential research directions for future cartographic research with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI for cartography.","sentences":["The past decade has witnessed the rapid development of geospatial artificial intelligence (GeoAI) primarily due to the ground-breaking achievements in deep learning and machine learning.","A growing number of scholars from cartography have demonstrated successfully that GeoAI can accelerate previously complex cartographic design tasks and even enable cartographic creativity in new ways.","Despite the promise of GeoAI, researchers and practitioners have growing concerns about the ethical issues of GeoAI for cartography.","In this paper, we conducted a systematic content analysis and narrative synthesis of research studies integrating GeoAI and cartography to summarize current research and development trends regarding the usage of GeoAI for cartographic design.","Based on this review and synthesis, we first identify dimensions of GeoAI methods for cartography such as data sources, data formats, map evaluations, and six contemporary GeoAI models, each of which serves a variety of cartographic tasks.","These models include decision trees, knowledge graph and semantic web technologies, deep convolutional neural networks, generative adversarial networks, graph neural networks, and reinforcement learning.","Further, we summarize seven cartographic design applications where GeoAI have been effectively employed: generalization, symbolization, typography, map reading, map interpretation, map analysis, and map production.","We also raise five potential ethical challenges that need to be addressed in the integration of GeoAI for cartography: commodification, responsibility, privacy, bias, and (together) transparency, explainability, and provenance.","We conclude by identifying four potential research directions for future cartographic research with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI for cartography."],"url":"http://arxiv.org/abs/2312.07901v1"}
{"created":"2023-12-13 05:08:17","title":"Ensuring End-to-End Security with Fine-grained Access Control for Connected and Autonomous Vehicles","abstract":"As advanced V2X applications emerge in the connected and autonomous vehicle (CAV), the data communications between in-vehicle end-devices and outside nodes increase, which make the end-to-end (E2E) security to in-vehicle end-devices as the urgent issue to be handled. However, the E2E security with fine-grained access control still remains as a challenging issue for resource-constrained end-devices since the existing security solutions require complicated key management and high resource consumption. Therefore, we propose a practical and secure vehicular communication protocol for the E2E security based on a new attribute-based encryption (ABE) scheme. In our scheme, the outsourced computation is provided for encryption, and the computation cost for decryption constantly remains small, regardless of the number of attributes. The policy privacy can be ensured by the proposed ABE to support privacy-sensitive V2X applications, and the existing identity-based signature for outsourced signing is newly reconstructed. Our scheme achieves the confidentiality, message authentication, identity anonymity, unlinkability, traceability, and reconfigurable outsourced computation, and we also show the practical feasibility of our protocol via the performance evaluation.","sentences":["As advanced V2X applications emerge in the connected and autonomous vehicle (CAV), the data communications between in-vehicle end-devices and outside nodes increase, which make the end-to-end (E2E) security to in-vehicle end-devices as the urgent issue to be handled.","However, the E2E security with fine-grained access control still remains as a challenging issue for resource-constrained end-devices since the existing security solutions require complicated key management and high resource consumption.","Therefore, we propose a practical and secure vehicular communication protocol for the E2E security based on a new attribute-based encryption (ABE) scheme.","In our scheme, the outsourced computation is provided for encryption, and the computation cost for decryption constantly remains small, regardless of the number of attributes.","The policy privacy can be ensured by the proposed ABE to support privacy-sensitive V2X applications, and the existing identity-based signature for outsourced signing is newly reconstructed.","Our scheme achieves the confidentiality, message authentication, identity anonymity, unlinkability, traceability, and reconfigurable outsourced computation, and we also show the practical feasibility of our protocol via the performance evaluation."],"url":"http://arxiv.org/abs/2312.07898v1"}
{"created":"2023-12-13 04:14:22","title":"Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models","abstract":"Incremental Learning (IL) has been a long-standing problem in both vision and Natural Language Processing (NLP) communities. In recent years, as Pre-trained Language Models (PLMs) have achieved remarkable progress in various NLP downstream tasks, utilizing PLMs as backbones has become a common practice in recent research of IL in NLP. Most assume that catastrophic forgetting is the biggest obstacle to achieving superior IL performance and propose various techniques to overcome this issue. However, we find that this assumption is problematic. Specifically, we revisit more than 20 methods on four classification tasks (Text Classification, Intent Classification, Relation Extraction, and Named Entity Recognition) under the two most popular IL settings (Class-Incremental and Task-Incremental) and reveal that most of them severely underestimate the inherent anti-forgetting ability of PLMs. Based on the observation, we propose a frustratingly easy method called SEQ* for IL with PLMs. The results show that SEQ* has competitive or superior performance compared to state-of-the-art (SOTA) IL methods and requires considerably less trainable parameters and training time. These findings urge us to revisit the IL with PLMs and encourage future studies to have a fundamental understanding of the catastrophic forgetting in PLMs. The data, code and scripts are publicly available at https://github.com/zzz47zzz/pretrained-lm-for-incremental-learning.","sentences":["Incremental Learning (IL) has been a long-standing problem in both vision and Natural Language Processing (NLP) communities.","In recent years, as Pre-trained Language Models (PLMs) have achieved remarkable progress in various NLP downstream tasks, utilizing PLMs as backbones has become a common practice in recent research of IL in NLP.","Most assume that catastrophic forgetting is the biggest obstacle to achieving superior IL performance and propose various techniques to overcome this issue.","However, we find that this assumption is problematic.","Specifically, we revisit more than 20 methods on four classification tasks (Text Classification, Intent Classification, Relation Extraction, and Named Entity Recognition) under the two most popular IL settings (Class-Incremental and Task-Incremental) and reveal that most of them severely underestimate the inherent anti-forgetting ability of PLMs.","Based on the observation, we propose a frustratingly easy method called SEQ* for IL with PLMs.","The results show that SEQ* has competitive or superior performance compared to state-of-the-art (SOTA) IL methods and requires considerably less trainable parameters and training time.","These findings urge us to revisit the IL with PLMs and encourage future studies to have a fundamental understanding of the catastrophic forgetting in PLMs.","The data, code and scripts are publicly available at https://github.com/zzz47zzz/pretrained-lm-for-incremental-learning."],"url":"http://arxiv.org/abs/2312.07887v1"}
{"created":"2023-12-13 04:08:59","title":"Modality Plug-and-Play: Elastic Modality Adaptation in Multimodal LLMs for Embodied AI","abstract":"Large Language Models (LLMs) are capable of reasoning over diverse input data modalities through pre-trained encoders. However, the growing diversity of input data modalities prevents incorporating all modalities into LLMs, especially when LLMs are deployed on resource-constrained edge devices for embodied AI applications. Instead, a better option is to adaptively involve only the useful modalities at runtime, depending on the current environmental contexts and task requirements. For such modality adaptation, existing work adopts fixed connections between encoders and the LLM's input layer, leading to high training cost at runtime and ineffective cross-modal interaction. In this paper, we address these limitations by presenting mPnP-LLM, a new technique that allows fully elastic, automated and prompt runtime modality adaptation, by connecting unimodal encoders to a flexible set of last LLM blocks and making such latent connections fully trainable at runtime. Experiments over the nuScenes-QA dataset show that mPnP-LLM can achieve up to 3.7x FLOPs reduction and 30% GPU memory usage reduction, while retaining on-par accuracy with the existing schemes. Under the same compute budget, mPnP-LLM improves the task accuracy by up to 4% compared to the best existing scheme.","sentences":["Large Language Models (LLMs) are capable of reasoning over diverse input data modalities through pre-trained encoders.","However, the growing diversity of input data modalities prevents incorporating all modalities into LLMs, especially when LLMs are deployed on resource-constrained edge devices for embodied AI applications.","Instead, a better option is to adaptively involve only the useful modalities at runtime, depending on the current environmental contexts and task requirements.","For such modality adaptation, existing work adopts fixed connections between encoders and the LLM's input layer, leading to high training cost at runtime and ineffective cross-modal interaction.","In this paper, we address these limitations by presenting mPnP-LLM, a new technique that allows fully elastic, automated and prompt runtime modality adaptation, by connecting unimodal encoders to a flexible set of last LLM blocks and making such latent connections fully trainable at runtime.","Experiments over the nuScenes-QA dataset show that mPnP-LLM can achieve up to 3.7x FLOPs reduction and 30% GPU memory usage reduction, while retaining on-par accuracy with the existing schemes.","Under the same compute budget, mPnP-LLM improves the task accuracy by up to 4% compared to the best existing scheme."],"url":"http://arxiv.org/abs/2312.07886v1"}
{"created":"2023-12-13 03:33:16","title":"Enhance Sketch Recognition's Explainability via Semantic Component-Level Parsing","abstract":"Free-hand sketches are appealing for humans as a universal tool to depict the visual world. Humans can recognize varied sketches of a category easily by identifying the concurrence and layout of the intrinsic semantic components of the category, since humans draw free-hand sketches based a common consensus that which types of semantic components constitute each sketch category. For example, an airplane should at least have a fuselage and wings. Based on this analysis, a semantic component-level memory module is constructed and embedded in the proposed structured sketch recognition network in this paper. The memory keys representing semantic components of each sketch category can be self-learned and enhance the recognition network's explainability. Our proposed networks can deal with different situations of sketch recognition, i.e., with or without semantic components labels of strokes. Experiments on the SPG and SketchIME datasets demonstrate the memory module's flexibility and the recognition network's explainability. The code and data are available at https://github.com/GuangmingZhu/SketchESC.","sentences":["Free-hand sketches are appealing for humans as a universal tool to depict the visual world.","Humans can recognize varied sketches of a category easily by identifying the concurrence and layout of the intrinsic semantic components of the category, since humans draw free-hand sketches based a common consensus that which types of semantic components constitute each sketch category.","For example, an airplane should at least have a fuselage and wings.","Based on this analysis, a semantic component-level memory module is constructed and embedded in the proposed structured sketch recognition network in this paper.","The memory keys representing semantic components of each sketch category can be self-learned and enhance the recognition network's explainability.","Our proposed networks can deal with different situations of sketch recognition, i.e., with or without semantic components labels of strokes.","Experiments on the SPG and SketchIME datasets demonstrate the memory module's flexibility and the recognition network's explainability.","The code and data are available at https://github.com/GuangmingZhu/SketchESC."],"url":"http://arxiv.org/abs/2312.07875v1"}
{"created":"2023-12-13 03:08:48","title":"BESTMVQA: A Benchmark Evaluation System for Medical Visual Question Answering","abstract":"Medical Visual Question Answering (Med-VQA) is a very important task in healthcare industry, which answers a natural language question with a medical image. Existing VQA techniques in information systems can be directly applied to solving the task. However, they often suffer from (i) the data insufficient problem, which makes it difficult to train the state of the arts (SOTAs) for the domain-specific task, and (ii) the reproducibility problem, that many existing models have not been thoroughly evaluated in a unified experimental setup. To address these issues, this paper develops a Benchmark Evaluation SysTem for Medical Visual Question Answering, denoted by BESTMVQA. Given self-collected clinical data, our system provides a useful tool for users to automatically build Med-VQA datasets, which helps overcoming the data insufficient problem. Users also can conveniently select a wide spectrum of SOTA models from our model library to perform a comprehensive empirical study. With simple configurations, our system automatically trains and evaluates the selected models over a benchmark dataset, and reports the comprehensive results for users to develop new techniques or perform medical practice. Limitations of existing work are overcome (i) by the data generation tool, which automatically constructs new datasets from unstructured clinical data, and (ii) by evaluating SOTAs on benchmark datasets in a unified experimental setup. The demonstration video of our system can be found at https://youtu.be/QkEeFlu1x4A. Our code and data will be available soon.","sentences":["Medical Visual Question Answering (Med-VQA) is a very important task in healthcare industry, which answers a natural language question with a medical image.","Existing VQA techniques in information systems can be directly applied to solving the task.","However, they often suffer from (i) the data insufficient problem, which makes it difficult to train the state of the arts (SOTAs) for the domain-specific task, and (ii) the reproducibility problem, that many existing models have not been thoroughly evaluated in a unified experimental setup.","To address these issues, this paper develops a Benchmark Evaluation SysTem for Medical Visual Question Answering, denoted by BESTMVQA.","Given self-collected clinical data, our system provides a useful tool for users to automatically build Med-VQA datasets, which helps overcoming the data","insufficient problem.","Users also can conveniently select a wide spectrum of SOTA models from our model library to perform a comprehensive empirical study.","With simple configurations, our system automatically trains and evaluates the selected models over a benchmark dataset, and reports the comprehensive results for users to develop new techniques or perform medical practice.","Limitations of existing work are overcome (i) by the data generation tool, which automatically constructs new datasets from unstructured clinical data, and (ii) by evaluating SOTAs on benchmark datasets in a unified experimental setup.","The demonstration video of our system can be found at https://youtu.be/QkEeFlu1x4A. Our code and data will be available soon."],"url":"http://arxiv.org/abs/2312.07867v1"}
{"created":"2023-12-13 03:02:55","title":"MMSE Design of RIS-aided Communications","abstract":"Consider a communication system in which a single antenna user equipment exchanges information with a multi-antenna base station via a reconfigurable intelligent surface (RIS) in the presence of spatially correlated channels and electromagnetic interference (EMI). To exploit the attractive advantages of RIS technology, accurate configuration of its reflecting elements is crucial. In this paper, we use statistical knowledge of channels and EMI to optimize the RIS elements for i) accurate channel estimation and ii) reliable data transmission. In both cases, our goal is to determine the RIS coefficients that minimize the mean square error, resulting in the formulation of two non-convex problems that share the same structure. To solve these two problems, we present an alternating optimization approach that reliably converges to a locally optimal solution. The incorporation of the diagonally scaled steepest descent algorithm, derived from Newton's method, ensures fast convergence with manageable complexity. Numerical results demonstrate the effectiveness of the proposed method under various propagation conditions. Notably, it shows significant advantages over existing alternatives that depend on a sub-optimal configuration of the RIS and are derived on the basis of different criteria.","sentences":["Consider a communication system in which a single antenna user equipment exchanges information with a multi-antenna base station via a reconfigurable intelligent surface (RIS) in the presence of spatially correlated channels and electromagnetic interference (EMI).","To exploit the attractive advantages of RIS technology, accurate configuration of its reflecting elements is crucial.","In this paper, we use statistical knowledge of channels and EMI to optimize the RIS elements for i) accurate channel estimation and ii) reliable data transmission.","In both cases, our goal is to determine the RIS coefficients that minimize the mean square error, resulting in the formulation of two non-convex problems that share the same structure.","To solve these two problems, we present an alternating optimization approach that reliably converges to a locally optimal solution.","The incorporation of the diagonally scaled steepest descent algorithm, derived from Newton's method, ensures fast convergence with manageable complexity.","Numerical results demonstrate the effectiveness of the proposed method under various propagation conditions.","Notably, it shows significant advantages over existing alternatives that depend on a sub-optimal configuration of the RIS and are derived on the basis of different criteria."],"url":"http://arxiv.org/abs/2312.07864v1"}
{"created":"2023-12-13 02:59:37","title":"GraphGuard: Detecting and Counteracting Training Data Misuse in Graph Neural Networks","abstract":"The emergence of Graph Neural Networks (GNNs) in graph data analysis and their deployment on Machine Learning as a Service platforms have raised critical concerns about data misuse during model training. This situation is further exacerbated due to the lack of transparency in local training processes, potentially leading to the unauthorized accumulation of large volumes of graph data, thereby infringing on the intellectual property rights of data owners. Existing methodologies often address either data misuse detection or mitigation, and are primarily designed for local GNN models rather than cloud-based MLaaS platforms. These limitations call for an effective and comprehensive solution that detects and mitigates data misuse without requiring exact training data while respecting the proprietary nature of such data. This paper introduces a pioneering approach called GraphGuard, to tackle these challenges. We propose a training-data-free method that not only detects graph data misuse but also mitigates its impact via targeted unlearning, all without relying on the original training data. Our innovative misuse detection technique employs membership inference with radioactive data, enhancing the distinguishability between member and non-member data distributions. For mitigation, we utilize synthetic graphs that emulate the characteristics previously learned by the target model, enabling effective unlearning even in the absence of exact graph data. We conduct comprehensive experiments utilizing four real-world graph datasets to demonstrate the efficacy of GraphGuard in both detection and unlearning. We show that GraphGuard attains a near-perfect detection rate of approximately 100% across these datasets with various GNN models. In addition, it performs unlearning by eliminating the impact of the unlearned graph with a marginal decrease in accuracy (less than 5%).","sentences":["The emergence of Graph Neural Networks (GNNs) in graph data analysis and their deployment on Machine Learning as a Service platforms have raised critical concerns about data misuse during model training.","This situation is further exacerbated due to the lack of transparency in local training processes, potentially leading to the unauthorized accumulation of large volumes of graph data, thereby infringing on the intellectual property rights of data owners.","Existing methodologies often address either data misuse detection or mitigation, and are primarily designed for local GNN models rather than cloud-based MLaaS platforms.","These limitations call for an effective and comprehensive solution that detects and mitigates data misuse without requiring exact training data while respecting the proprietary nature of such data.","This paper introduces a pioneering approach called GraphGuard, to tackle these challenges.","We propose a training-data-free method that not only detects graph data misuse but also mitigates its impact via targeted unlearning, all without relying on the original training data.","Our innovative misuse detection technique employs membership inference with radioactive data, enhancing the distinguishability between member and non-member data distributions.","For mitigation, we utilize synthetic graphs that emulate the characteristics previously learned by the target model, enabling effective unlearning even in the absence of exact graph data.","We conduct comprehensive experiments utilizing four real-world graph datasets to demonstrate the efficacy of GraphGuard in both detection and unlearning.","We show that GraphGuard attains a near-perfect detection rate of approximately 100% across these datasets with various GNN models.","In addition, it performs unlearning by eliminating the impact of the unlearned graph with a marginal decrease in accuracy (less than 5%)."],"url":"http://arxiv.org/abs/2312.07861v1"}
{"created":"2023-12-13 02:57:30","title":"Data-Dependent Higher-Order Clique Selection for Artery-Vein Segmentation by Energy Minimization","abstract":"We propose a novel segmentation method based on energy minimization of higher-order potentials. We introduce higher-order terms into the energy to incorporate prior knowledge on the shape of the segments. The terms encourage certain sets of pixels to be entirely in one segment or the other. The sets can for instance be smooth curves in order to help delineate pulmonary vessels, which are known to run in almost straight lines. The higher-order terms can be converted to submodular first-order terms by adding auxiliary variables, which can then be globally minimized using graph cuts. We also determine the weight of these terms, or the degree of the aforementioned encouragement, in a principled way by learning from training data with the ground truth. We demonstrate the effectiveness of the method in a real-world application in fully-automatic pulmonary artery-vein segmentation in CT images.","sentences":["We propose a novel segmentation method based on energy minimization of higher-order potentials.","We introduce higher-order terms into the energy to incorporate prior knowledge on the shape of the segments.","The terms encourage certain sets of pixels to be entirely in one segment or the other.","The sets can for instance be smooth curves in order to help delineate pulmonary vessels, which are known to run in almost straight lines.","The higher-order terms can be converted to submodular first-order terms by adding auxiliary variables, which can then be globally minimized using graph cuts.","We also determine the weight of these terms, or the degree of the aforementioned encouragement, in a principled way by learning from training data with the ground truth.","We demonstrate the effectiveness of the method in a real-world application in fully-automatic pulmonary artery-vein segmentation in CT images."],"url":"http://arxiv.org/abs/2312.07860v1"}
{"created":"2023-12-13 02:56:26","title":"Invariant Graph Transformer","abstract":"Rationale discovery is defined as finding a subset of the input data that maximally supports the prediction of downstream tasks. In graph machine learning context, graph rationale is defined to locate the critical subgraph in the given graph topology, which fundamentally determines the prediction results. In contrast to the rationale subgraph, the remaining subgraph is named the environment subgraph. Graph rationalization can enhance the model performance as the mapping between the graph rationale and prediction label is viewed as invariant, by assumption. To ensure the discriminative power of the extracted rationale subgraphs, a key technique named \"intervention\" is applied. The core idea of intervention is that given any changing environment subgraphs, the semantics from the rationale subgraph is invariant, which guarantees the correct prediction result. However, most, if not all, of the existing rationalization works on graph data develop their intervention strategies on the graph level, which is coarse-grained. In this paper, we propose well-tailored intervention strategies on graph data. Our idea is driven by the development of Transformer models, whose self-attention module provides rich interactions between input nodes. Based on the self-attention module, our proposed invariant graph Transformer (IGT) can achieve fine-grained, more specifically, node-level and virtual node-level intervention. Our comprehensive experiments involve 7 real-world datasets, and the proposed IGT shows significant performance advantages compared to 13 baseline methods.","sentences":["Rationale discovery is defined as finding a subset of the input data that maximally supports the prediction of downstream tasks.","In graph machine learning context, graph rationale is defined to locate the critical subgraph in the given graph topology, which fundamentally determines the prediction results.","In contrast to the rationale subgraph, the remaining subgraph is named the environment subgraph.","Graph rationalization can enhance the model performance as the mapping between the graph rationale and prediction label is viewed as invariant, by assumption.","To ensure the discriminative power of the extracted rationale subgraphs, a key technique named \"intervention\" is applied.","The core idea of intervention is that given any changing environment subgraphs, the semantics from the rationale subgraph is invariant, which guarantees the correct prediction result.","However, most, if not all, of the existing rationalization works on graph data develop their intervention strategies on the graph level, which is coarse-grained.","In this paper, we propose well-tailored intervention strategies on graph data.","Our idea is driven by the development of Transformer models, whose self-attention module provides rich interactions between input nodes.","Based on the self-attention module, our proposed invariant graph Transformer (IGT) can achieve fine-grained, more specifically, node-level and virtual node-level intervention.","Our comprehensive experiments involve 7 real-world datasets, and the proposed IGT shows significant performance advantages compared to 13 baseline methods."],"url":"http://arxiv.org/abs/2312.07859v1"}
{"created":"2023-12-13 02:41:25","title":"Recording provenance of workflow runs with RO-Crate","abstract":"Recording the provenance of scientific computation results is key to the support of traceability, reproducibility and quality assessment of data products. Several data models have been explored to address this need, providing representations of workflow plans and their executions as well as means of packaging the resulting information for archiving and sharing. However, existing approaches tend to lack interoperable adoption across workflow management systems. In this work we present Workflow Run RO-Crate, an extension of RO-Crate (Research Object Crate) and Schema.org to capture the provenance of the execution of computational workflows at different levels of granularity and bundle together all their associated products (inputs, outputs, code, etc.). The model is supported by a diverse, open community that runs regular meetings, discussing development, maintenance and adoption aspects. Workflow Run RO-Crate is already implemented by several workflow management systems, allowing interoperable comparisons between workflow runs from heterogeneous systems. We describe the model, its alignment to standards such as W3C PROV, and its implementation in six workflow systems. Finally, we illustrate the application of Workflow Run RO-Crate in two use cases of machine learning in the digital image analysis domain.   A corresponding RO-Crate for this article is at https://w3id.org/ro/doi/10.5281/zenodo.10368989","sentences":["Recording the provenance of scientific computation results is key to the support of traceability, reproducibility and quality assessment of data products.","Several data models have been explored to address this need, providing representations of workflow plans and their executions as well as means of packaging the resulting information for archiving and sharing.","However, existing approaches tend to lack interoperable adoption across workflow management systems.","In this work we present Workflow Run RO-Crate, an extension of RO-Crate (Research Object Crate) and Schema.org to capture the provenance of the execution of computational workflows at different levels of granularity and bundle together all their associated products (inputs, outputs, code, etc.).","The model is supported by a diverse, open community that runs regular meetings, discussing development, maintenance and adoption aspects.","Workflow Run RO-Crate is already implemented by several workflow management systems, allowing interoperable comparisons between workflow runs from heterogeneous systems.","We describe the model, its alignment to standards such as W3C PROV, and its implementation in six workflow systems.","Finally, we illustrate the application of Workflow Run RO-Crate in two use cases of machine learning in the digital image analysis domain.   ","A corresponding RO-Crate for this article is at https://w3id.org/ro/doi/10.5281/zenodo.10368989"],"url":"http://arxiv.org/abs/2312.07852v1"}
{"created":"2023-12-13 02:39:10","title":"Noise in the reverse process improves the approximation capabilities of diffusion models","abstract":"In Score based Generative Modeling (SGMs), the state-of-the-art in generative modeling, stochastic reverse processes are known to perform better than their deterministic counterparts. This paper delves into the heart of this phenomenon, comparing neural ordinary differential equations (ODEs) and neural stochastic differential equations (SDEs) as reverse processes. We use a control theoretic perspective by posing the approximation of the reverse process as a trajectory tracking problem. We analyze the ability of neural SDEs to approximate trajectories of the Fokker-Planck equation, revealing the advantages of stochasticity. First, neural SDEs exhibit a powerful regularizing effect, enabling $L^2$ norm trajectory approximation surpassing the Wasserstein metric approximation achieved by neural ODEs under similar conditions, even when the reference vector field or score function is not Lipschitz. Applying this result, we establish the class of distributions that can be sampled using score matching in SGMs, relaxing the Lipschitz requirement on the gradient of the data distribution in existing literature. Second, we show that this approximation property is preserved when network width is limited to the input dimension of the network. In this limited width case, the weights act as control inputs, framing our analysis as a controllability problem for neural SDEs in probability density space. This sheds light on how noise helps to steer the system towards the desired solution and illuminates the empirical success of stochasticity in generative modeling.","sentences":["In Score based Generative Modeling (SGMs), the state-of-the-art in generative modeling, stochastic reverse processes are known to perform better than their deterministic counterparts.","This paper delves into the heart of this phenomenon, comparing neural ordinary differential equations (ODEs) and neural stochastic differential equations (SDEs) as reverse processes.","We use a control theoretic perspective by posing the approximation of the reverse process as a trajectory tracking problem.","We analyze the ability of neural SDEs to approximate trajectories of the Fokker-Planck equation, revealing the advantages of stochasticity.","First, neural SDEs exhibit a powerful regularizing effect, enabling $L^2$ norm trajectory approximation surpassing the Wasserstein metric approximation achieved by neural ODEs under similar conditions, even when the reference vector field or score function is not Lipschitz.","Applying this result, we establish the class of distributions that can be sampled using score matching in SGMs, relaxing the Lipschitz requirement on the gradient of the data distribution in existing literature.","Second, we show that this approximation property is preserved when network width is limited to the input dimension of the network.","In this limited width case, the weights act as control inputs, framing our analysis as a controllability problem for neural SDEs in probability density space.","This sheds light on how noise helps to steer the system towards the desired solution and illuminates the empirical success of stochasticity in generative modeling."],"url":"http://arxiv.org/abs/2312.07851v1"}
{"created":"2023-12-13 02:35:57","title":"Large Language Model Enhanced Multi-Agent Systems for 6G Communications","abstract":"The rapid development of the Large Language Model (LLM) presents huge opportunities for 6G communications, e.g., network optimization and management by allowing users to input task requirements to LLMs by nature language. However, directly applying native LLMs in 6G encounters various challenges, such as a lack of private communication data and knowledge, limited logical reasoning, evaluation, and refinement abilities. Integrating LLMs with the capabilities of retrieval, planning, memory, evaluation and reflection in agents can greatly enhance the potential of LLMs for 6G communications. To this end, we propose a multi-agent system with customized communication knowledge and tools for solving communication related tasks using natural language, comprising three components: (1) Multi-agent Data Retrieval (MDR), which employs the condensate and inference agents to refine and summarize communication knowledge from the knowledge base, expanding the knowledge boundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning (MCP), which utilizes multiple planning agents to generate feasible solutions for the communication related task from different perspectives based on the retrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which utilizes the evaluation agent to assess the solutions, and applies the reflexion agent and refinement agent to provide improvement suggestions for current solutions. Finally, we validate the effectiveness of the proposed multi-agent system by designing a semantic communication system, as a case study of 6G communications.","sentences":["The rapid development of the Large Language Model (LLM) presents huge opportunities for 6G communications, e.g., network optimization and management by allowing users to input task requirements to LLMs by nature language.","However, directly applying native LLMs in 6G encounters various challenges, such as a lack of private communication data and knowledge, limited logical reasoning, evaluation, and refinement abilities.","Integrating LLMs with the capabilities of retrieval, planning, memory, evaluation and reflection in agents can greatly enhance the potential of LLMs for 6G communications.","To this end, we propose a multi-agent system with customized communication knowledge and tools for solving communication related tasks using natural language, comprising three components: (1) Multi-agent Data Retrieval (MDR), which employs the condensate and inference agents to refine and summarize communication knowledge from the knowledge base, expanding the knowledge boundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning (MCP), which utilizes multiple planning agents to generate feasible solutions for the communication related task from different perspectives based on the retrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which utilizes the evaluation agent to assess the solutions, and applies the reflexion agent and refinement agent to provide improvement suggestions for current solutions.","Finally, we validate the effectiveness of the proposed multi-agent system by designing a semantic communication system, as a case study of 6G communications."],"url":"http://arxiv.org/abs/2312.07850v1"}
{"created":"2023-12-13 02:20:42","title":"Foundation Models in Robotics: Applications, Challenges, and the Future","abstract":"We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper (Preliminary release. We are committed to further enhancing and updating this work to ensure its quality and relevance) can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models","sentences":["We survey applications of pretrained foundation models in robotics.","Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications.","In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data.","Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control.","For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition.","However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution.","In this survey, we study recent papers that have used or built foundation models to solve robotics problems.","We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control.","We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements.","The GitHub project corresponding to this paper (Preliminary release.","We are committed to further enhancing and updating this work to ensure its quality and relevance) can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models"],"url":"http://arxiv.org/abs/2312.07843v1"}
{"created":"2023-12-13 02:04:41","title":"Synthetic Data: Can We Trust Statistical Estimators?","abstract":"The increasing interest in data sharing makes synthetic data appealing. However, the analysis of synthetic data raises a unique set of methodological challenges. In this work, we highlight the importance of inferential utility and provide empirical evidence against naive inference from synthetic data (that handles these as if they were really observed). We argue that the rate of false-positive findings (type 1 error) will be unacceptably high, even when the estimates are unbiased. One of the reasons is the underestimation of the true standard error, which may even progressively increase with larger sample sizes due to slower convergence. This is especially problematic for deep generative models. Before publishing synthetic data, it is essential to develop statistical inference tools for such data.","sentences":["The increasing interest in data sharing makes synthetic data appealing.","However, the analysis of synthetic data raises a unique set of methodological challenges.","In this work, we highlight the importance of inferential utility and provide empirical evidence against naive inference from synthetic data (that handles these as if they were really observed).","We argue that the rate of false-positive findings (type 1 error) will be unacceptably high, even when the estimates are unbiased.","One of the reasons is the underestimation of the true standard error, which may even progressively increase with larger sample sizes due to slower convergence.","This is especially problematic for deep generative models.","Before publishing synthetic data, it is essential to develop statistical inference tools for such data."],"url":"http://arxiv.org/abs/2312.07837v1"}
{"created":"2023-12-13 01:57:11","title":"Video Dynamics Prior: An Internal Learning Approach for Robust Video Enhancements","abstract":"In this paper, we present a novel robust framework for low-level vision tasks, including denoising, object removal, frame interpolation, and super-resolution, that does not require any external training data corpus. Our proposed approach directly learns the weights of neural modules by optimizing over the corrupted test sequence, leveraging the spatio-temporal coherence and internal statistics of videos. Furthermore, we introduce a novel spatial pyramid loss that leverages the property of spatio-temporal patch recurrence in a video across the different scales of the video. This loss enhances robustness to unstructured noise in both the spatial and temporal domains. This further results in our framework being highly robust to degradation in input frames and yields state-of-the-art results on downstream tasks such as denoising, object removal, and frame interpolation. To validate the effectiveness of our approach, we conduct qualitative and quantitative evaluations on standard video datasets such as DAVIS, UCF-101, and VIMEO90K-T.","sentences":["In this paper, we present a novel robust framework for low-level vision tasks, including denoising, object removal, frame interpolation, and super-resolution, that does not require any external training data corpus.","Our proposed approach directly learns the weights of neural modules by optimizing over the corrupted test sequence, leveraging the spatio-temporal coherence and internal statistics of videos.","Furthermore, we introduce a novel spatial pyramid loss that leverages the property of spatio-temporal patch recurrence in a video across the different scales of the video.","This loss enhances robustness to unstructured noise in both the spatial and temporal domains.","This further results in our framework being highly robust to degradation in input frames and yields state-of-the-art results on downstream tasks such as denoising, object removal, and frame interpolation.","To validate the effectiveness of our approach, we conduct qualitative and quantitative evaluations on standard video datasets such as DAVIS, UCF-101, and VIMEO90K-T."],"url":"http://arxiv.org/abs/2312.07835v1"}
{"created":"2023-12-13 01:40:21","title":"Stable Rivers: A Case Study in the Application of Text-to-Image Generative Models for Earth Sciences","abstract":"Text-to-image (TTI) generative models can be used to generate photorealistic images from a given text-string input. These models offer great potential to mitigate challenges to the uptake of machine learning in the earth sciences. However, the rapid increase in their use has raised questions about fairness and biases, with most research to-date focusing on social and cultural areas rather than domain-specific considerations. We conducted a case study for the earth sciences, focusing on the field of fluvial geomorphology, where we evaluated subject-area specific biases in the training data and downstream model performance of Stable Diffusion (v1.5). In addition to perpetuating Western biases, we found that the training data over-represented scenic locations, such as famous rivers and waterfalls, and showed serious under- and over-representation of many morphological and environmental terms. Despite biased training data, we found that with careful prompting, the Stable Diffusion model was able to generate photorealistic synthetic river images reproducing many important environmental and morphological characteristics. Furthermore, conditional control techniques, such as the use of condition maps with ControlNet were effective for providing additional constraints on output images. Despite great potential for the use of TTI models in the earth sciences field, we advocate for caution in sensitive applications, and advocate for domain-specific reviews of training data and image generation biases to mitigate perpetuation of existing biases.","sentences":["Text-to-image (TTI) generative models can be used to generate photorealistic images from a given text-string input.","These models offer great potential to mitigate challenges to the uptake of machine learning in the earth sciences.","However, the rapid increase in their use has raised questions about fairness and biases, with most research to-date focusing on social and cultural areas rather than domain-specific considerations.","We conducted a case study for the earth sciences, focusing on the field of fluvial geomorphology, where we evaluated subject-area specific biases in the training data and downstream model performance of Stable Diffusion (v1.5).","In addition to perpetuating Western biases, we found that the training data over-represented scenic locations, such as famous rivers and waterfalls, and showed serious under- and over-representation of many morphological and environmental terms.","Despite biased training data, we found that with careful prompting, the Stable Diffusion model was able to generate photorealistic synthetic river images reproducing many important environmental and morphological characteristics.","Furthermore, conditional control techniques, such as the use of condition maps with ControlNet were effective for providing additional constraints on output images.","Despite great potential for the use of TTI models in the earth sciences field, we advocate for caution in sensitive applications, and advocate for domain-specific reviews of training data and image generation biases to mitigate perpetuation of existing biases."],"url":"http://arxiv.org/abs/2312.07833v1"}
{"created":"2023-12-13 01:27:53","title":"Approximate Fully Dynamic Directed Densest Subgraph","abstract":"We give a fully dynamic algorithm maintaining a $(1-\\varepsilon)$-approximate directed densest subgraph in $\\tilde{O}(\\log^3(n)/\\varepsilon^6)$ amortized time or $\\tilde{O}(\\log^4(n)/\\varepsilon^7)$ per edge update (where $\\tilde{O}$ hides $\\log\\log$ factors), based on earlier work by Chekuri and Quanrud [arXiv:2210.02611]. This result improves on earlier work done by Sawlani and Wang [arXiv:1907.03037], which guarantees $O(\\log^5(n)/\\varepsilon^7)$ worst case time for edge insertions and deletions.","sentences":["We give a fully dynamic algorithm maintaining a $(1-\\varepsilon)$-approximate directed densest subgraph in $\\tilde{O}(\\log^3(n)/\\varepsilon^6)$ amortized time or $\\tilde{O}(\\log^4(n)/\\varepsilon^7)$ per edge update (where $\\tilde{O}$ hides $\\log\\log$ factors), based on earlier work by Chekuri and Quanrud [arXiv:2210.02611].","This result improves on earlier work done by Sawlani and Wang [arXiv:1907.03037], which guarantees $O(\\log^5(n)/\\varepsilon^7)$ worst case time for edge insertions and deletions."],"url":"http://arxiv.org/abs/2312.07827v1"}
{"created":"2023-12-12 23:51:07","title":"Uncertainty Visualization via Low-Dimensional Posterior Projections","abstract":"In ill-posed inverse problems, it is commonly desirable to obtain insight into the full spectrum of plausible solutions, rather than extracting only a single reconstruction. Information about the plausible solutions and their likelihoods is encoded in the posterior distribution. However, for high-dimensional data, this distribution is challenging to visualize. In this work, we introduce a new approach for estimating and visualizing posteriors by employing energy-based models (EBMs) over low-dimensional subspaces. Specifically, we train a conditional EBM that receives an input measurement and a set of directions that span some low-dimensional subspace of solutions, and outputs the probability density function of the posterior within that space. We demonstrate the effectiveness of our method across a diverse range of datasets and image restoration problems, showcasing its strength in uncertainty quantification and visualization. As we show, our method outperforms a baseline that projects samples from a diffusion-based posterior sampler, while being orders of magnitude faster. Furthermore, it is more accurate than a baseline that assumes a Gaussian posterior.","sentences":["In ill-posed inverse problems, it is commonly desirable to obtain insight into the full spectrum of plausible solutions, rather than extracting only a single reconstruction.","Information about the plausible solutions and their likelihoods is encoded in the posterior distribution.","However, for high-dimensional data, this distribution is challenging to visualize.","In this work, we introduce a new approach for estimating and visualizing posteriors by employing energy-based models (EBMs) over low-dimensional subspaces.","Specifically, we train a conditional EBM that receives an input measurement and a set of directions that span some low-dimensional subspace of solutions, and outputs the probability density function of the posterior within that space.","We demonstrate the effectiveness of our method across a diverse range of datasets and image restoration problems, showcasing its strength in uncertainty quantification and visualization.","As we show, our method outperforms a baseline that projects samples from a diffusion-based posterior sampler, while being orders of magnitude faster.","Furthermore, it is more accurate than a baseline that assumes a Gaussian posterior."],"url":"http://arxiv.org/abs/2312.07804v1"}
{"created":"2023-12-12 23:41:59","title":"Estimation of embedding vectors in high dimensions","abstract":"Embeddings are a basic initial feature extraction step in many machine learning models, particularly in natural language processing. An embedding attempts to map data tokens to a low-dimensional space where similar tokens are mapped to vectors that are close to one another by some metric in the embedding space. A basic question is how well can such embedding be learned? To study this problem, we consider a simple probability model for discrete data where there is some \"true\" but unknown embedding where the correlation of random variables is related to the similarity of the embeddings. Under this model, it is shown that the embeddings can be learned by a variant of low-rank approximate message passing (AMP) method. The AMP approach enables precise predictions of the accuracy of the estimation in certain high-dimensional limits. In particular, the methodology provides insight on the relations of key parameters such as the number of samples per value, the frequency of the terms, and the strength of the embedding correlation on the probability distribution. Our theoretical findings are validated by simulations on both synthetic data and real text data.","sentences":["Embeddings are a basic initial feature extraction step in many machine learning models, particularly in natural language processing.","An embedding attempts to map data tokens to a low-dimensional space where similar tokens are mapped to vectors that are close to one another by some metric in the embedding space.","A basic question is how well can such embedding be learned?","To study this problem, we consider a simple probability model for discrete data where there is some \"true\" but unknown embedding where the correlation of random variables is related to the similarity of the embeddings.","Under this model, it is shown that the embeddings can be learned by a variant of low-rank approximate message passing (AMP) method.","The AMP approach enables precise predictions of the accuracy of the estimation in certain high-dimensional limits.","In particular, the methodology provides insight on the relations of key parameters such as the number of samples per value, the frequency of the terms, and the strength of the embedding correlation on the probability distribution.","Our theoretical findings are validated by simulations on both synthetic data and real text data."],"url":"http://arxiv.org/abs/2312.07802v1"}
{"created":"2023-12-12 23:15:07","title":"Characteristic Circuits","abstract":"In many real-world scenarios, it is crucial to be able to reliably and efficiently reason under uncertainty while capturing complex relationships in data. Probabilistic circuits (PCs), a prominent family of tractable probabilistic models, offer a remedy to this challenge by composing simple, tractable distributions into a high-dimensional probability distribution. However, learning PCs on heterogeneous data is challenging and densities of some parametric distributions are not available in closed form, limiting their potential use. We introduce characteristic circuits (CCs), a family of tractable probabilistic models providing a unified formalization of distributions over heterogeneous data in the spectral domain. The one-to-one relationship between characteristic functions and probability measures enables us to learn high-dimensional distributions on heterogeneous data domains and facilitates efficient probabilistic inference even when no closed-form density function is available. We show that the structure and parameters of CCs can be learned efficiently from the data and find that CCs outperform state-of-the-art density estimators for heterogeneous data domains on common benchmark data sets.","sentences":["In many real-world scenarios, it is crucial to be able to reliably and efficiently reason under uncertainty while capturing complex relationships in data.","Probabilistic circuits (PCs), a prominent family of tractable probabilistic models, offer a remedy to this challenge by composing simple, tractable distributions into a high-dimensional probability distribution.","However, learning PCs on heterogeneous data is challenging and densities of some parametric distributions are not available in closed form, limiting their potential use.","We introduce characteristic circuits (CCs), a family of tractable probabilistic models providing a unified formalization of distributions over heterogeneous data in the spectral domain.","The one-to-one relationship between characteristic functions and probability measures enables us to learn high-dimensional distributions on heterogeneous data domains and facilitates efficient probabilistic inference even when no closed-form density function is available.","We show that the structure and parameters of CCs can be learned efficiently from the data and find that CCs outperform state-of-the-art density estimators for heterogeneous data domains on common benchmark data sets."],"url":"http://arxiv.org/abs/2312.07790v1"}
{"created":"2023-12-12 22:57:54","title":"A Data-driven Method for Safety-critical Control: Designing Control Barrier Functions from State Constraints","abstract":"This paper addresses the challenge of integrating explicit hard constraints into the control barrier function (CBF) framework for ensuring safety in autonomous systems, including robots. We propose a novel data-driven method to derive CBFs from these hard constraints in practical scenarios. Our approach assumes that the forward invariant safe set is either a subset or equal to the constrained set. The process consists of two main steps. First, we randomly sample states within the constraint boundaries and identify inputs meeting the time derivative criteria of the hard constraint; this iterative process converges using the Jaccard index. Next, we formulate CBFs that enclose the safe set using the sampled boundaries. This enables the creation of a control-invariant safe set, approaching the maximum attainable level of control invariance. This approach, therefore, addresses the complexities posed by complex autonomous systems with constrained control input spaces, culminating in a control-invariant safe set that closely approximates the maximal control invariant set.","sentences":["This paper addresses the challenge of integrating explicit hard constraints into the control barrier function (CBF) framework for ensuring safety in autonomous systems, including robots.","We propose a novel data-driven method to derive CBFs from these hard constraints in practical scenarios.","Our approach assumes that the forward invariant safe set is either a subset or equal to the constrained set.","The process consists of two main steps.","First, we randomly sample states within the constraint boundaries and identify inputs meeting the time derivative criteria of the hard constraint; this iterative process converges using the Jaccard index.","Next, we formulate CBFs that enclose the safe set using the sampled boundaries.","This enables the creation of a control-invariant safe set, approaching the maximum attainable level of control invariance.","This approach, therefore, addresses the complexities posed by complex autonomous systems with constrained control input spaces, culminating in a control-invariant safe set that closely approximates the maximal control invariant set."],"url":"http://arxiv.org/abs/2312.07786v1"}
{"created":"2023-12-12 22:49:24","title":"Combining propensity score methods with variational autoencoders for generating synthetic data in presence of latent sub-groups","abstract":"In settings requiring synthetic data generation based on a clinical cohort, e.g., due to data protection regulations, heterogeneity across individuals might be a nuisance that we need to control or faithfully preserve. The sources of such heterogeneity might be known, e.g., as indicated by sub-groups labels, or might be unknown and thus reflected only in properties of distributions, such as bimodality or skewness. We investigate how such heterogeneity can be preserved and controlled when obtaining synthetic data from variational autoencoders (VAEs), i.e., a generative deep learning technique that utilizes a low-dimensional latent representation. To faithfully reproduce unknown heterogeneity reflected in marginal distributions, we propose to combine VAEs with pre-transformations. For dealing with known heterogeneity due to sub-groups, we complement VAEs with models for group membership, specifically from propensity score regression. The evaluation is performed with a realistic simulation design that features sub-groups and challenging marginal distributions. The proposed approach faithfully recovers the latter, compared to synthetic data approaches that focus purely on marginal distributions. Propensity scores add complementary information, e.g., when visualized in the latent space, and enable sampling of synthetic data with or without sub-group specific characteristics. We also illustrate the proposed approach with real data from an international stroke trial that exhibits considerable distribution differences between study sites, in addition to bimodality. These results indicate that describing heterogeneity by statistical approaches, such as propensity score regression, might be more generally useful for complementing generative deep learning for obtaining synthetic data that faithfully reflects structure from clinical cohorts.","sentences":["In settings requiring synthetic data generation based on a clinical cohort, e.g., due to data protection regulations, heterogeneity across individuals might be a nuisance that we need to control or faithfully preserve.","The sources of such heterogeneity might be known, e.g., as indicated by sub-groups labels, or might be unknown and thus reflected only in properties of distributions, such as bimodality or skewness.","We investigate how such heterogeneity can be preserved and controlled when obtaining synthetic data from variational autoencoders (VAEs), i.e., a generative deep learning technique that utilizes a low-dimensional latent representation.","To faithfully reproduce unknown heterogeneity reflected in marginal distributions, we propose to combine VAEs with pre-transformations.","For dealing with known heterogeneity due to sub-groups, we complement VAEs with models for group membership, specifically from propensity score regression.","The evaluation is performed with a realistic simulation design that features sub-groups and challenging marginal distributions.","The proposed approach faithfully recovers the latter, compared to synthetic data approaches that focus purely on marginal distributions.","Propensity scores add complementary information, e.g., when visualized in the latent space, and enable sampling of synthetic data with or without sub-group specific characteristics.","We also illustrate the proposed approach with real data from an international stroke trial that exhibits considerable distribution differences between study sites, in addition to bimodality.","These results indicate that describing heterogeneity by statistical approaches, such as propensity score regression, might be more generally useful for complementing generative deep learning for obtaining synthetic data that faithfully reflects structure from clinical cohorts."],"url":"http://arxiv.org/abs/2312.07781v1"}
{"created":"2023-12-12 22:47:42","title":"Tell, don't show: Declarative facts influence how LLMs generalize","abstract":"We examine how large language models (LLMs) generalize from abstract declarative statements in their training data. As an illustration, consider an LLM that is prompted to generate weather reports for London in 2050. One possibility is that the temperatures in the reports match the mean and variance of reports from 2023 (i.e. matching the statistics of pretraining). Another possibility is that the reports predict higher temperatures, by incorporating declarative statements about climate change from scientific papers written in 2023. An example of such a declarative statement is \"global temperatures will increase by $1^{\\circ} \\mathrm{C}$ by 2050\".   To test the influence of abstract declarative statements, we construct tasks in which LLMs are finetuned on both declarative and procedural information. We find that declarative statements influence model predictions, even when they conflict with procedural information. In particular, finetuning on a declarative statement $S$ increases the model likelihood for logical consequences of $S$. The effect of declarative statements is consistent across three domains: aligning an AI assistant, predicting weather, and predicting demographic features. Through a series of ablations, we show that the effect of declarative statements cannot be explained by associative learning based on matching keywords. Nevertheless, the effect of declarative statements on model likelihoods is small in absolute terms and increases surprisingly little with model size (i.e. from 330 million to 175 billion parameters). We argue that these results have implications for AI risk (in relation to the \"treacherous turn\") and for fairness.","sentences":["We examine how large language models (LLMs) generalize from abstract declarative statements in their training data.","As an illustration, consider an LLM that is prompted to generate weather reports for London in 2050.","One possibility is that the temperatures in the reports match the mean and variance of reports from 2023 (i.e. matching the statistics of pretraining).","Another possibility is that the reports predict higher temperatures, by incorporating declarative statements about climate change from scientific papers written in 2023.","An example of such a declarative statement is \"global temperatures will increase by $1^{\\circ} \\mathrm{C}$ by 2050\".   ","To test the influence of abstract declarative statements, we construct tasks in which LLMs are finetuned on both declarative and procedural information.","We find that declarative statements influence model predictions, even when they conflict with procedural information.","In particular, finetuning on a declarative statement $S$ increases the model likelihood for logical consequences of $S$. The effect of declarative statements is consistent across three domains: aligning an AI assistant, predicting weather, and predicting demographic features.","Through a series of ablations, we show that the effect of declarative statements cannot be explained by associative learning based on matching keywords.","Nevertheless, the effect of declarative statements on model likelihoods is small in absolute terms and increases surprisingly little with model size (i.e. from 330 million to 175 billion parameters).","We argue that these results have implications for AI risk (in relation to the \"treacherous turn\") and for fairness."],"url":"http://arxiv.org/abs/2312.07779v1"}
{"created":"2023-12-12 22:27:29","title":"Incremental hierarchical text clustering methods: a review","abstract":"The growth in Internet usage has contributed to a large volume of continuously available data, and has created the need for automatic and efficient organization of the data. In this context, text clustering techniques are significant because they aim to organize documents according to their characteristics. More specifically, hierarchical and incremental clustering techniques can organize dynamic data in a hierarchical form, thus guaranteeing that this organization is updated and its exploration is facilitated. Based on the relevance and contemporary nature of the field, this study aims to analyze various hierarchical and incremental clustering techniques; the main contribution of this research is the organization and comparison of the techniques used by studies published between 2010 and 2018 that aimed to texts documents clustering. We describe the principal concepts related to the challenge and the different characteristics of these published works in order to provide a better understanding of the research in this field.","sentences":["The growth in Internet usage has contributed to a large volume of continuously available data, and has created the need for automatic and efficient organization of the data.","In this context, text clustering techniques are significant because they aim to organize documents according to their characteristics.","More specifically, hierarchical and incremental clustering techniques can organize dynamic data in a hierarchical form, thus guaranteeing that this organization is updated and its exploration is facilitated.","Based on the relevance and contemporary nature of the field, this study aims to analyze various hierarchical and incremental clustering techniques; the main contribution of this research is the organization and comparison of the techniques used by studies published between 2010 and 2018 that aimed to texts documents clustering.","We describe the principal concepts related to the challenge and the different characteristics of these published works in order to provide a better understanding of the research in this field."],"url":"http://arxiv.org/abs/2312.07769v1"}
{"created":"2023-12-12 22:23:04","title":"Spatial Knowledge-Infused Hierarchical Learning: An Application in Flood Mapping on Earth Imagery","abstract":"Deep learning for Earth imagery plays an increasingly important role in geoscience applications such as agriculture, ecology, and natural disaster management. Still, progress is often hindered by the limited training labels. Given Earth imagery with limited training labels, a base deep neural network model, and a spatial knowledge base with label constraints, our problem is to infer the full labels while training the neural network. The problem is challenging due to the sparse and noisy input labels, spatial uncertainty within the label inference process, and high computational costs associated with a large number of sample locations. Existing works on neuro-symbolic models focus on integrating symbolic logic into neural networks (e.g., loss function, model architecture, and training label augmentation), but these methods do not fully address the challenges of spatial data (e.g., spatial uncertainty, the trade-off between spatial granularity and computational costs). To bridge this gap, we propose a novel Spatial Knowledge-Infused Hierarchical Learning (SKI-HL) framework that iteratively infers sample labels within a multi-resolution hierarchy. Our framework consists of a module to selectively infer labels in different resolutions based on spatial uncertainty and a module to train neural network parameters with uncertainty-aware multi-instance learning. Extensive experiments on real-world flood mapping datasets show that the proposed model outperforms several baseline methods. The code is available at \\url{https://github.com/ZelinXu2000/SKI-HL}.","sentences":["Deep learning for Earth imagery plays an increasingly important role in geoscience applications such as agriculture, ecology, and natural disaster management.","Still, progress is often hindered by the limited training labels.","Given Earth imagery with limited training labels, a base deep neural network model, and a spatial knowledge base with label constraints, our problem is to infer the full labels while training the neural network.","The problem is challenging due to the sparse and noisy input labels, spatial uncertainty within the label inference process, and high computational costs associated with a large number of sample locations.","Existing works on neuro-symbolic models focus on integrating symbolic logic into neural networks (e.g., loss function, model architecture, and training label augmentation), but these methods do not fully address the challenges of spatial data (e.g., spatial uncertainty, the trade-off between spatial granularity and computational costs).","To bridge this gap, we propose a novel Spatial Knowledge-Infused Hierarchical Learning (SKI-HL) framework that iteratively infers sample labels within a multi-resolution hierarchy.","Our framework consists of a module to selectively infer labels in different resolutions based on spatial uncertainty and a module to train neural network parameters with uncertainty-aware multi-instance learning.","Extensive experiments on real-world flood mapping datasets show that the proposed model outperforms several baseline methods.","The code is available at \\url{https://github.com/ZelinXu2000/SKI-HL}."],"url":"http://arxiv.org/abs/2312.07767v1"}
{"created":"2023-12-12 22:10:38","title":"Interpretable factorization of clinical questionnaires to identify latent factors of psychopathology","abstract":"Psychiatry research seeks to understand the manifestations of psychopathology in behavior, as measured in questionnaire data, by identifying a small number of latent factors that explain them. While factor analysis is the traditional tool for this purpose, the resulting factors may not be interpretable, and may also be subject to confounding variables. Moreover, missing data are common, and explicit imputation is often required. To overcome these limitations, we introduce interpretability constrained questionnaire factorization (ICQF), a non-negative matrix factorization method with regularization tailored for questionnaire data. Our method aims to promote factor interpretability and solution stability. We provide an optimization procedure with theoretical convergence guarantees, and an automated procedure to detect latent dimensionality accurately. We validate these procedures using realistic synthetic data. We demonstrate the effectiveness of our method in a widely used general-purpose questionnaire, in two independent datasets (the Healthy Brain Network and Adolescent Brain Cognitive Development studies). Specifically, we show that ICQF improves interpretability, as defined by domain experts, while preserving diagnostic information across a range of disorders, and outperforms competing methods for smaller dataset sizes. This suggests that the regularization in our method matches domain characteristics. The python implementation for ICQF is available at \\url{https://github.com/jefferykclam/ICQF}.","sentences":["Psychiatry research seeks to understand the manifestations of psychopathology in behavior, as measured in questionnaire data, by identifying a small number of latent factors that explain them.","While factor analysis is the traditional tool for this purpose, the resulting factors may not be interpretable, and may also be subject to confounding variables.","Moreover, missing data are common, and explicit imputation is often required.","To overcome these limitations, we introduce interpretability constrained questionnaire factorization (ICQF), a non-negative matrix factorization method with regularization tailored for questionnaire data.","Our method aims to promote factor interpretability and solution stability.","We provide an optimization procedure with theoretical convergence guarantees, and an automated procedure to detect latent dimensionality accurately.","We validate these procedures using realistic synthetic data.","We demonstrate the effectiveness of our method in a widely used general-purpose questionnaire, in two independent datasets (the Healthy Brain Network and Adolescent Brain Cognitive Development studies).","Specifically, we show that ICQF improves interpretability, as defined by domain experts, while preserving diagnostic information across a range of disorders, and outperforms competing methods for smaller dataset sizes.","This suggests that the regularization in our method matches domain characteristics.","The python implementation for ICQF is available at \\url{https://github.com/jefferykclam/ICQF}."],"url":"http://arxiv.org/abs/2312.07762v1"}
{"created":"2023-12-12 21:49:26","title":"Polynomial-based Self-Attention for Table Representation learning","abstract":"Structured data, which constitutes a significant portion of existing data types, has been a long-standing research topic in the field of machine learning. Various representation learning methods for tabular data have been proposed, ranging from encoder-decoder structures to Transformers. Among these, Transformer-based methods have achieved state-of-the-art performance not only in tabular data but also in various other fields, including computer vision and natural language processing. However, recent studies have revealed that self-attention, a key component of Transformers, can lead to an oversmoothing issue. We show that Transformers for tabular data also face this problem, and to address the problem, we propose a novel matrix polynomial-based self-attention layer as a substitute for the original self-attention layer, which enhances model scalability. In our experiments with three representative table learning models equipped with our proposed layer, we illustrate that the layer effectively mitigates the oversmoothing problem and enhances the representation performance of the existing methods, outperforming the state-of-the-art table representation methods.","sentences":["Structured data, which constitutes a significant portion of existing data types, has been a long-standing research topic in the field of machine learning.","Various representation learning methods for tabular data have been proposed, ranging from encoder-decoder structures to Transformers.","Among these, Transformer-based methods have achieved state-of-the-art performance not only in tabular data but also in various other fields, including computer vision and natural language processing.","However, recent studies have revealed that self-attention, a key component of Transformers, can lead to an oversmoothing issue.","We show that Transformers for tabular data also face this problem, and to address the problem, we propose a novel matrix polynomial-based self-attention layer as a substitute for the original self-attention layer, which enhances model scalability.","In our experiments with three representative table learning models equipped with our proposed layer, we illustrate that the layer effectively mitigates the oversmoothing problem and enhances the representation performance of the existing methods, outperforming the state-of-the-art table representation methods."],"url":"http://arxiv.org/abs/2312.07753v1"}
{"created":"2023-12-12 21:22:07","title":"FULL-W2V: Fully Exploiting Data Reuse for W2V on GPU-Accelerated Systems","abstract":"Word2Vec remains one of the highly-impactful innovations in the field of Natural Language Processing (NLP) that represents latent grammatical and syntactical information in human text with dense vectors in a low dimension. Word2Vec has high computational cost due to the algorithm's inherent sequentiality, intensive memory accesses, and the large vocabularies it represents. While prior studies have investigated technologies to explore parallelism and improve memory system performance, they struggle to effectively gain throughput on powerful GPUs.   We identify memory data access and latency as the primary bottleneck in prior works on GPUs, which prevents highly optimized kernels from attaining the architecture's peak performance. We present a novel algorithm, FULL-W2V, which maximally exploits the opportunities for data reuse in the W2V algorithm and leverages GPU architecture and resources to reduce access to low memory levels and improve temporal locality. FULL-W2V is capable of reducing accesses to GPU global memory significantly, e.g., by more than 89\\%, compared to prior state-of-the-art GPU implementations, resulting in significant performance improvement that scales across successive hardware generations. Our prototype implementation achieves 2.97X speedup when ported from Nvidia Pascal P100 to Volta V100 cards, and outperforms the state-of-the-art by 5.72X on V100 cards with the same embedding quality. In-depth analysis indicates that the reduction of memory accesses through register and shared memory caching and high-throughput shared memory reduction leads to a significantly improved arithmetic intensity. FULL-W2V can potentially benefit many applications in NLP and other domains.","sentences":["Word2Vec remains one of the highly-impactful innovations in the field of Natural Language Processing (NLP) that represents latent grammatical and syntactical information in human text with dense vectors in a low dimension.","Word2Vec has high computational cost due to the algorithm's inherent sequentiality, intensive memory accesses, and the large vocabularies it represents.","While prior studies have investigated technologies to explore parallelism and improve memory system performance, they struggle to effectively gain throughput on powerful GPUs.   ","We identify memory data access and latency as the primary bottleneck in prior works on GPUs, which prevents highly optimized kernels from attaining the architecture's peak performance.","We present a novel algorithm, FULL-W2V, which maximally exploits the opportunities for data reuse in the W2V algorithm and leverages GPU architecture and resources to reduce access to low memory levels and improve temporal locality.","FULL-W2V is capable of reducing accesses to GPU global memory significantly, e.g., by more than 89\\%, compared to prior state-of-the-art GPU implementations, resulting in significant performance improvement that scales across successive hardware generations.","Our prototype implementation achieves 2.97X speedup when ported from Nvidia Pascal P100 to Volta V100 cards, and outperforms the state-of-the-art by 5.72X on V100 cards with the same embedding quality.","In-depth analysis indicates that the reduction of memory accesses through register and shared memory caching and high-throughput shared memory reduction leads to a significantly improved arithmetic intensity.","FULL-W2V can potentially benefit many applications in NLP and other domains."],"url":"http://arxiv.org/abs/2312.07743v1"}
{"created":"2023-12-12 20:52:27","title":"A Response to Glaze Purification via IMPRESS","abstract":"Recent work proposed a new mechanism to remove protective perturbation added by Glaze in order to again enable mimicry of art styles from images protected by Glaze. Despite promising results shown in the original paper, our own tests with the authors' code demonstrated several limitations of the proposed purification approach. The main limitations are 1) purification has a limited effect when tested on artists that are not well-known historical artists already embedded in original training data, 2) problems in evaluation metrics, and 3) collateral damage on mimicry result for clean images. We believe these limitations should be carefully considered in order to understand real world usability of the purification attack.","sentences":["Recent work proposed a new mechanism to remove protective perturbation added by Glaze in order to again enable mimicry of art styles from images protected by Glaze.","Despite promising results shown in the original paper, our own tests with the authors' code demonstrated several limitations of the proposed purification approach.","The main limitations are 1) purification has a limited effect when tested on artists that are not well-known historical artists already embedded in original training data, 2) problems in evaluation metrics, and 3) collateral damage on mimicry result for clean images.","We believe these limitations should be carefully considered in order to understand real world usability of the purification attack."],"url":"http://arxiv.org/abs/2312.07731v1"}
{"created":"2023-12-12 20:40:04","title":"Restorebot: Towards an Autonomous Robotics Platform for Degraded Rangeland Restoration","abstract":"Degraded rangelands undergo continual shifts in the appearance and distribution of plant life. The nature of these changes however is subtle: between seasons seedlings sprout up and some flourish while others perish, meanwhile, over multiple seasons they experience fluctuating precipitation volumes and can be grazed by livestock. The nature of these conditioning variables makes it difficult for ecologists to quantify the efficacy of intervention techniques under study. To support these observation and intervention tasks, we develop RestoreBot: a mobile robotic platform designed for gathering data in degraded rangelands for the purpose of data collection and intervention in order to support revegetation. Over the course of multiple deployments, we outline the opportunities and challenges of autonomous data collection for revegetation and the importance of further effort in this area. Specifically, we identify that localization, mapping, data association, and terrain assessment remain open problems for deployment, but that recent advances in computer vision, sensing, and autonomy offer promising prospects for autonomous revegetation.","sentences":["Degraded rangelands undergo continual shifts in the appearance and distribution of plant life.","The nature of these changes however is subtle: between seasons seedlings sprout up and some flourish while others perish, meanwhile, over multiple seasons they experience fluctuating precipitation volumes and can be grazed by livestock.","The nature of these conditioning variables makes it difficult for ecologists to quantify the efficacy of intervention techniques under study.","To support these observation and intervention tasks, we develop RestoreBot: a mobile robotic platform designed for gathering data in degraded rangelands for the purpose of data collection and intervention in order to support revegetation.","Over the course of multiple deployments, we outline the opportunities and challenges of autonomous data collection for revegetation and the importance of further effort in this area.","Specifically, we identify that localization, mapping, data association, and terrain assessment remain open problems for deployment, but that recent advances in computer vision, sensing, and autonomy offer promising prospects for autonomous revegetation."],"url":"http://arxiv.org/abs/2312.07724v1"}
{"created":"2023-12-12 20:36:36","title":"Automated Behavioral Analysis Using Instance Segmentation","abstract":"Animal behavior analysis plays a crucial role in various fields, such as life science and biomedical research. However, the scarcity of available data and the high cost associated with obtaining a large number of labeled datasets pose significant challenges. In this research, we propose a novel approach that leverages instance segmentation-based transfer learning to address these issues. By capitalizing on fine-tuning the classification head of the instance segmentation network, we enable the tracking of multiple animals and facilitate behavior analysis in laboratory-recorded videos. To demonstrate the effectiveness of our method, we conducted a series of experiments, revealing that our approach achieves exceptional performance levels, comparable to human capabilities, across a diverse range of animal behavior analysis tasks. Moreover, we emphasize the practicality of our solution, as it requires only a small number of labeled images for training. To facilitate the adoption and further development of our method, we have developed an open-source implementation named Annolid (An annotation and instance segmentation-based multiple animal tracking and behavior analysis package). The codebase is publicly available on GitHub at https://github.com/cplab/annolid. This resource serves as a valuable asset for researchers and practitioners interested in advancing animal behavior analysis through state-of-the-art techniques.","sentences":["Animal behavior analysis plays a crucial role in various fields, such as life science and biomedical research.","However, the scarcity of available data and the high cost associated with obtaining a large number of labeled datasets pose significant challenges.","In this research, we propose a novel approach that leverages instance segmentation-based transfer learning to address these issues.","By capitalizing on fine-tuning the classification head of the instance segmentation network, we enable the tracking of multiple animals and facilitate behavior analysis in laboratory-recorded videos.","To demonstrate the effectiveness of our method, we conducted a series of experiments, revealing that our approach achieves exceptional performance levels, comparable to human capabilities, across a diverse range of animal behavior analysis tasks.","Moreover, we emphasize the practicality of our solution, as it requires only a small number of labeled images for training.","To facilitate the adoption and further development of our method, we have developed an open-source implementation named Annolid (An annotation and instance segmentation-based multiple animal tracking and behavior analysis package).","The codebase is publicly available on GitHub at https://github.com/cplab/annolid.","This resource serves as a valuable asset for researchers and practitioners interested in advancing animal behavior analysis through state-of-the-art techniques."],"url":"http://arxiv.org/abs/2312.07723v1"}
{"created":"2023-12-12 20:28:11","title":"Saturn Platform: Foundation Model Operations and Generative AI for Financial Services","abstract":"Saturn is an innovative platform that assists Foundation Model (FM) building and its integration with IT operations (Ops). It is custom-made to meet the requirements of data scientists, enabling them to effectively create and implement FMs while enhancing collaboration within their technical domain. By offering a wide range of tools and features, Saturn streamlines and automates different stages of FM development, making it an invaluable asset for data science teams. This white paper introduces prospective applications of generative AI models derived from FMs in the financial sector.","sentences":["Saturn is an innovative platform that assists Foundation Model (FM) building and its integration with IT operations (Ops).","It is custom-made to meet the requirements of data scientists, enabling them to effectively create and implement FMs while enhancing collaboration within their technical domain.","By offering a wide range of tools and features, Saturn streamlines and automates different stages of FM development, making it an invaluable asset for data science teams.","This white paper introduces prospective applications of generative AI models derived from FMs in the financial sector."],"url":"http://arxiv.org/abs/2312.07721v1"}
{"created":"2023-12-12 20:09:07","title":"Near-Optimal Differentially Private k-Core Decomposition","abstract":"Recent work by Dhulipala, Liu, Raskhodnikova, Shi, Shun, and Yu~\\cite{DLRSSY22} initiated the study of the $k$-core decomposition problem under differential privacy. They show that approximate $k$-core numbers can be output while guaranteeing differential privacy, while only incurring a multiplicative error of $(2 +\\eta)$ (for any constant $\\eta >0$) and additive error of $\\poly(\\log(n))/\\eps$. In this paper, we revisit this problem. Our main result is an $\\eps$-edge differentially private algorithm for $k$-core decomposition which outputs the core numbers with no multiplicative error and $O(\\text{log}(n)/\\eps)$ additive error. This improves upon previous work by a factor of 2 in the multiplicative error, while giving near-optimal additive error.   With a little additional work, this implies improved algorithms for densest subgraph and low out-degree ordering under differential privacy. For low out-degree ordering, we give an $\\eps$-edge differentially private algorithm which outputs an implicit orientation such that the out-degree of each vertex is at most $d+O(\\log{n}/{\\eps})$, where $d$ is the degeneracy of the graph. This improves upon the best known guarantees for the problem by a factor of $4$ and gives near-optimal additive error. For densest subgraph, we give an $\\eps$-edge differentially private algorithm outputting a subset of nodes that induces a subgraph of density at least ${D^*}/{2}-O(\\text{log}(n)/\\eps)$, where $D^*$ is the density for the optimal subgraph.","sentences":["Recent work by Dhulipala, Liu, Raskhodnikova, Shi, Shun, and Yu~\\cite{DLRSSY22} initiated the study of the $k$-core decomposition problem under differential privacy.","They show that approximate $k$-core numbers can be output while guaranteeing differential privacy, while only incurring a multiplicative error of $(2 +\\eta)$ (for any constant $\\eta >0$) and additive error of $\\poly(\\log(n))/\\eps$. In this paper, we revisit this problem.","Our main result is an $\\eps$-edge differentially private algorithm for $k$-core decomposition which outputs the core numbers with no multiplicative error and $O(\\text{log}(n)/\\eps)$ additive error.","This improves upon previous work by a factor of 2 in the multiplicative error, while giving near-optimal additive error.   ","With a little additional work, this implies improved algorithms for densest subgraph and low out-degree ordering under differential privacy.","For low out-degree ordering, we give an $\\eps$-edge differentially private algorithm which outputs an implicit orientation such that the out-degree of each vertex is at most $d+O(\\log{n}/{\\eps})$, where $d$ is the degeneracy of the graph.","This improves upon the best known guarantees for the problem by a factor of $4$ and gives near-optimal additive error.","For densest subgraph, we give an $\\eps$-edge differentially private algorithm outputting a subset of nodes that induces a subgraph of density at least ${D^*}/{2}-O(\\text{log}(n)/\\eps)$, where $D^*$ is the density for the optimal subgraph."],"url":"http://arxiv.org/abs/2312.07706v1"}
{"created":"2023-12-12 19:39:40","title":"GP+: A Python Library for Kernel-based learning via Gaussian Processes","abstract":"In this paper we introduce GP+, an open-source library for kernel-based learning via Gaussian processes (GPs) which are powerful statistical models that are completely characterized by their parametric covariance and mean functions. GP+ is built on PyTorch and provides a user-friendly and object-oriented tool for probabilistic learning and inference. As we demonstrate with a host of examples, GP+ has a few unique advantages over other GP modeling libraries. We achieve these advantages primarily by integrating nonlinear manifold learning techniques with GPs' covariance and mean functions. As part of introducing GP+, in this paper we also make methodological contributions that (1) enable probabilistic data fusion and inverse parameter estimation, and (2) equip GPs with parsimonious parametric mean functions which span mixed feature spaces that have both categorical and quantitative variables. We demonstrate the impact of these contributions in the context of Bayesian optimization, multi-fidelity modeling, sensitivity analysis, and calibration of computer models.","sentences":["In this paper we introduce GP+, an open-source library for kernel-based learning via Gaussian processes (GPs) which are powerful statistical models that are completely characterized by their parametric covariance and mean functions.","GP+ is built on PyTorch and provides a user-friendly and object-oriented tool for probabilistic learning and inference.","As we demonstrate with a host of examples, GP+ has a few unique advantages over other GP modeling libraries.","We achieve these advantages primarily by integrating nonlinear manifold learning techniques with GPs' covariance and mean functions.","As part of introducing GP+, in this paper we also make methodological contributions that (1) enable probabilistic data fusion and inverse parameter estimation, and (2) equip GPs with parsimonious parametric mean functions which span mixed feature spaces that have both categorical and quantitative variables.","We demonstrate the impact of these contributions in the context of Bayesian optimization, multi-fidelity modeling, sensitivity analysis, and calibration of computer models."],"url":"http://arxiv.org/abs/2312.07694v1"}
{"created":"2023-12-12 19:23:54","title":"An Online, Adaptive and Unsupervised Regression Framework with Drift Detection for Label Scarcity Contexts","abstract":"In scenarios where obtaining real-time labels proves challenging, conventional approaches may result in sub-optimal performance. This paper presents an optimal strategy for streaming contexts with limited labeled data, introducing an adaptive technique for unsupervised regression. The proposed method leverages a sparse set of initial labels and introduces an innovative drift detection mechanism to enable dynamic model adaptations in response to evolving patterns in the data. To enhance adaptability, we integrate the ADWIN (ADaptive WINdowing) algorithm with error generalization based on Root Mean Square Error (RMSE). ADWIN facilitates real-time drift detection, while RMSE provides a robust measure of model prediction accuracy. This combination enables our multivariate method to effectively navigate the challenges of streaming data, continuously adapting to changing patterns while maintaining a high level of predictive precision. Finally, we evaluate the performance of our multivariate method across various public datasets, comparing it to non-adapting baselines. Through comprehensive assessments, we demonstrate the superior efficacy of our adaptive regression technique for tasks where obtaining labels in real-time is a significant challenge. The results underscore the method's capacity to outperform traditional approaches and highlight its potential in scenarios characterized by label scarcity and evolving data patterns.","sentences":["In scenarios where obtaining real-time labels proves challenging, conventional approaches may result in sub-optimal performance.","This paper presents an optimal strategy for streaming contexts with limited labeled data, introducing an adaptive technique for unsupervised regression.","The proposed method leverages a sparse set of initial labels and introduces an innovative drift detection mechanism to enable dynamic model adaptations in response to evolving patterns in the data.","To enhance adaptability, we integrate the ADWIN (ADaptive WINdowing) algorithm with error generalization based on Root Mean Square Error (RMSE).","ADWIN facilitates real-time drift detection, while RMSE provides a robust measure of model prediction accuracy.","This combination enables our multivariate method to effectively navigate the challenges of streaming data, continuously adapting to changing patterns while maintaining a high level of predictive precision.","Finally, we evaluate the performance of our multivariate method across various public datasets, comparing it to non-adapting baselines.","Through comprehensive assessments, we demonstrate the superior efficacy of our adaptive regression technique for tasks where obtaining labels in real-time is a significant challenge.","The results underscore the method's capacity to outperform traditional approaches and highlight its potential in scenarios characterized by label scarcity and evolving data patterns."],"url":"http://arxiv.org/abs/2312.07682v1"}
{"created":"2023-12-12 19:22:07","title":"I Open at the Close: A Deep Reinforcement Learning Evaluation of Open Streets Initiatives","abstract":"The open streets initiative \"opens\" streets to pedestrians and bicyclists by closing them to cars and trucks. The initiative, adopted by many cities across North America, increases community space in urban environments. But could open streets also make cities safer and less congested? We study this question by framing the choice of which streets to open as a reinforcement learning problem. In order to simulate the impact of opening streets, we first compare models for predicting vehicle collisions given network and temporal data. We find that a recurrent graph neural network, leveraging the graph structure and the short-term temporal dependence of the data, gives the best predictive performance. Then, with the ability to simulate collisions and traffic, we frame a reinforcement learning problem to find which streets to open. We compare the streets in the NYC Open Streets program to those proposed by a Q-learning algorithm. We find that the streets proposed by the Q-learning algorithm have reliably better outcomes, while streets in the program have similar outcomes to randomly selected streets. We present our work as a step toward principally choosing which streets to open for safer and less congested cities. All our code and data are available on Github.","sentences":["The open streets initiative \"opens\" streets to pedestrians and bicyclists by closing them to cars and trucks.","The initiative, adopted by many cities across North America, increases community space in urban environments.","But could open streets also make cities safer and less congested?","We study this question by framing the choice of which streets to open as a reinforcement learning problem.","In order to simulate the impact of opening streets, we first compare models for predicting vehicle collisions given network and temporal data.","We find that a recurrent graph neural network, leveraging the graph structure and the short-term temporal dependence of the data, gives the best predictive performance.","Then, with the ability to simulate collisions and traffic, we frame a reinforcement learning problem to find which streets to open.","We compare the streets in the NYC Open Streets program to those proposed by a Q-learning algorithm.","We find that the streets proposed by the Q-learning algorithm have reliably better outcomes, while streets in the program have similar outcomes to randomly selected streets.","We present our work as a step toward principally choosing which streets to open for safer and less congested cities.","All our code and data are available on Github."],"url":"http://arxiv.org/abs/2312.07680v1"}
{"created":"2023-12-12 19:00:04","title":"CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor","abstract":"Existing open-vocabulary image segmentation methods require a fine-tuning step on mask annotations and/or image-text datasets. Mask labels are labor-intensive, which limits the number of categories in segmentation datasets. As a result, the open-vocabulary capacity of pre-trained VLMs is severely reduced after fine-tuning. However, without fine-tuning, VLMs trained under weak image-text supervision tend to make suboptimal mask predictions when there are text queries referring to non-existing concepts in the image. To alleviate these issues, we introduce a novel recurrent framework that progressively filters out irrelevant texts and enhances mask quality without training efforts. The recurrent unit is a two-stage segmenter built upon a VLM with frozen weights. Thus, our model retains the VLM's broad vocabulary space and strengthens its segmentation capability. Experimental results show that our method outperforms not only the training-free counterparts, but also those fine-tuned with millions of additional data samples, and sets new state-of-the-art records for both zero-shot semantic and referring image segmentation tasks. Specifically, we improve the current record by 28.8, 16.0, and 6.9 mIoU on Pascal VOC, COCO Object, and Pascal Context.","sentences":["Existing open-vocabulary image segmentation methods require a fine-tuning step on mask annotations and/or image-text datasets.","Mask labels are labor-intensive, which limits the number of categories in segmentation datasets.","As a result, the open-vocabulary capacity of pre-trained VLMs is severely reduced after fine-tuning.","However, without fine-tuning, VLMs trained under weak image-text supervision tend to make suboptimal mask predictions when there are text queries referring to non-existing concepts in the image.","To alleviate these issues, we introduce a novel recurrent framework that progressively filters out irrelevant texts and enhances mask quality without training efforts.","The recurrent unit is a two-stage segmenter built upon a VLM with frozen weights.","Thus, our model retains the VLM's broad vocabulary space and strengthens its segmentation capability.","Experimental results show that our method outperforms not only the training-free counterparts, but also those fine-tuned with millions of additional data samples, and sets new state-of-the-art records for both zero-shot semantic and referring image segmentation tasks.","Specifically, we improve the current record by 28.8, 16.0, and 6.9 mIoU on Pascal VOC, COCO Object, and Pascal Context."],"url":"http://arxiv.org/abs/2312.07661v1"}
{"created":"2023-12-12 18:59:21","title":"Anatomically Constrained Implicit Face Models","abstract":"Coordinate based implicit neural representations have gained rapid popularity in recent years as they have been successfully used in image, geometry and scene modeling tasks. In this work, we present a novel use case for such implicit representations in the context of learning anatomically constrained face models. Actor specific anatomically constrained face models are the state of the art in both facial performance capture and performance retargeting. Despite their practical success, these anatomical models are slow to evaluate and often require extensive data capture to be built. We propose the anatomical implicit face model; an ensemble of implicit neural networks that jointly learn to model the facial anatomy and the skin surface with high-fidelity, and can readily be used as a drop in replacement to conventional blendshape models. Given an arbitrary set of skin surface meshes of an actor and only a neutral shape with estimated skull and jaw bones, our method can recover a dense anatomical substructure which constrains every point on the facial surface. We demonstrate the usefulness of our approach in several tasks ranging from shape fitting, shape editing, and performance retargeting.","sentences":["Coordinate based implicit neural representations have gained rapid popularity in recent years as they have been successfully used in image, geometry and scene modeling tasks.","In this work, we present a novel use case for such implicit representations in the context of learning anatomically constrained face models.","Actor specific anatomically constrained face models are the state of the art in both facial performance capture and performance retargeting.","Despite their practical success, these anatomical models are slow to evaluate and often require extensive data capture to be built.","We propose the anatomical implicit face model; an ensemble of implicit neural networks that jointly learn to model the facial anatomy and the skin surface with high-fidelity, and can readily be used as a drop in replacement to conventional blendshape models.","Given an arbitrary set of skin surface meshes of an actor and only a neutral shape with estimated skull and jaw bones, our method can recover a dense anatomical substructure which constrains every point on the facial surface.","We demonstrate the usefulness of our approach in several tasks ranging from shape fitting, shape editing, and performance retargeting."],"url":"http://arxiv.org/abs/2312.07538v1"}
{"created":"2023-12-12 18:59:06","title":"Improved Frequency Estimation Algorithms with and without Predictions","abstract":"Estimating frequencies of elements appearing in a data stream is a key task in large-scale data analysis. Popular sketching approaches to this problem (e.g., CountMin and CountSketch) come with worst-case guarantees that probabilistically bound the error of the estimated frequencies for any possible input. The work of Hsu et al. (2019) introduced the idea of using machine learning to tailor sketching algorithms to the specific data distribution they are being run on. In particular, their learning-augmented frequency estimation algorithm uses a learned heavy-hitter oracle which predicts which elements will appear many times in the stream. We give a novel algorithm, which in some parameter regimes, already theoretically outperforms the learning based algorithm of Hsu et al. without the use of any predictions. Augmenting our algorithm with heavy-hitter predictions further reduces the error and improves upon the state of the art. Empirically, our algorithms achieve superior performance in all experiments compared to prior approaches.","sentences":["Estimating frequencies of elements appearing in a data stream is a key task in large-scale data analysis.","Popular sketching approaches to this problem (e.g., CountMin and CountSketch) come with worst-case guarantees that probabilistically bound the error of the estimated frequencies for any possible input.","The work of Hsu et al. (2019) introduced the idea of using machine learning to tailor sketching algorithms to the specific data distribution they are being run on.","In particular, their learning-augmented frequency estimation algorithm uses a learned heavy-hitter oracle which predicts which elements will appear many times in the stream.","We give a novel algorithm, which in some parameter regimes, already theoretically outperforms the learning based algorithm of Hsu et al.","without the use of any predictions.","Augmenting our algorithm with heavy-hitter predictions further reduces the error and improves upon the state of the art.","Empirically, our algorithms achieve superior performance in all experiments compared to prior approaches."],"url":"http://arxiv.org/abs/2312.07535v1"}
{"created":"2023-12-12 18:58:18","title":"VILA: On Pre-training for Visual Language Models","abstract":"Visual language models (VLMs) rapidly progressed with the recent success of large language models. There have been growing efforts on visual instruction tuning to extend the LLM with visual inputs, but lacks an in-depth study of the visual language pre-training process, where the model learns to perform joint modeling on both modalities. In this work, we examine the design options for VLM pre-training by augmenting LLM towards VLM through step-by-step controllable comparisons. We introduce three main findings: (1) freezing LLMs during pre-training can achieve decent zero-shot performance, but lack in-context learning capability, which requires unfreezing the LLM; (2) interleaved pre-training data is beneficial whereas image-text pairs alone are not optimal; (3) re-blending text-only instruction data to image-text data during instruction fine-tuning not only remedies the degradation of text-only tasks, but also boosts VLM task accuracy. With an enhanced pre-training recipe we build VILA, a Visual Language model family that consistently outperforms the state-of-the-art models, e.g., LLaVA-1.5, across main benchmarks without bells and whistles. Multi-modal pre-training also helps unveil appealing properties of VILA, including multi-image reasoning, enhanced in-context learning, and better world knowledge.","sentences":["Visual language models (VLMs) rapidly progressed with the recent success of large language models.","There have been growing efforts on visual instruction tuning to extend the LLM with visual inputs, but lacks an in-depth study of the visual language pre-training process, where the model learns to perform joint modeling on both modalities.","In this work, we examine the design options for VLM pre-training by augmenting LLM towards VLM through step-by-step controllable comparisons.","We introduce three main findings: (1) freezing LLMs during pre-training can achieve decent zero-shot performance, but lack in-context learning capability, which requires unfreezing the LLM; (2) interleaved pre-training data is beneficial whereas image-text pairs alone are not optimal; (3) re-blending text-only instruction data to image-text data during instruction fine-tuning not only remedies the degradation of text-only tasks, but also boosts VLM task accuracy.","With an enhanced pre-training recipe we build VILA, a Visual Language model family that consistently outperforms the state-of-the-art models, e.g., LLaVA-1.5, across main benchmarks without bells and whistles.","Multi-modal pre-training also helps unveil appealing properties of VILA, including multi-image reasoning, enhanced in-context learning, and better world knowledge."],"url":"http://arxiv.org/abs/2312.07533v1"}
{"created":"2023-12-12 18:57:46","title":"WHAM: Reconstructing World-grounded Humans with Accurate 3D Motion","abstract":"The estimation of 3D human motion from video has progressed rapidly but current methods still have several key limitations. First, most methods estimate the human in camera coordinates. Second, prior work on estimating humans in global coordinates often assumes a flat ground plane and produces foot sliding. Third, the most accurate methods rely on computationally expensive optimization pipelines, limiting their use to offline applications. Finally, existing video-based methods are surprisingly less accurate than single-frame methods. We address these limitations with WHAM (World-grounded Humans with Accurate Motion), which accurately and efficiently reconstructs 3D human motion in a global coordinate system from video. WHAM learns to lift 2D keypoint sequences to 3D using motion capture data and fuses this with video features, integrating motion context and visual information. WHAM exploits camera angular velocity estimated from a SLAM method together with human motion to estimate the body's global trajectory. We combine this with a contact-aware trajectory refinement method that lets WHAM capture human motion in diverse conditions, such as climbing stairs. WHAM outperforms all existing 3D human motion recovery methods across multiple in-the-wild benchmarks. Code will be available for research purposes at http://wham.is.tue.mpg.de/","sentences":["The estimation of 3D human motion from video has progressed rapidly but current methods still have several key limitations.","First, most methods estimate the human in camera coordinates.","Second, prior work on estimating humans in global coordinates often assumes a flat ground plane and produces foot sliding.","Third, the most accurate methods rely on computationally expensive optimization pipelines, limiting their use to offline applications.","Finally, existing video-based methods are surprisingly less accurate than single-frame methods.","We address these limitations with WHAM (World-grounded Humans with Accurate Motion), which accurately and efficiently reconstructs 3D human motion in a global coordinate system from video.","WHAM learns to lift 2D keypoint sequences to 3D using motion capture data and fuses this with video features, integrating motion context and visual information.","WHAM exploits camera angular velocity estimated from a SLAM method together with human motion to estimate the body's global trajectory.","We combine this with a contact-aware trajectory refinement method that lets WHAM capture human motion in diverse conditions, such as climbing stairs.","WHAM outperforms all existing 3D human motion recovery methods across multiple in-the-wild benchmarks.","Code will be available for research purposes at http://wham.is.tue.mpg.de/"],"url":"http://arxiv.org/abs/2312.07531v1"}
{"created":"2023-12-12 18:57:25","title":"Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance","abstract":"Weakly supervised 3D object detection aims to learn a 3D detector with lower annotation cost, e.g., 2D labels. Unlike prior work which still relies on few accurate 3D annotations, we propose a framework to study how to leverage constraints between 2D and 3D domains without requiring any 3D labels. Specifically, we employ visual data from three perspectives to establish connections between 2D and 3D domains. First, we design a feature-level constraint to align LiDAR and image features based on object-aware regions. Second, the output-level constraint is developed to enforce the overlap between 2D and projected 3D box estimations. Finally, the training-level constraint is utilized by producing accurate and consistent 3D pseudo-labels that align with the visual data. We conduct extensive experiments on the KITTI dataset to validate the effectiveness of the proposed three constraints. Without using any 3D labels, our method achieves favorable performance against state-of-the-art approaches and is competitive with the method that uses 500-frame 3D annotations. Code and models will be made publicly available at https://github.com/kuanchihhuang/VG-W3D.","sentences":["Weakly supervised 3D object detection aims to learn a 3D detector with lower annotation cost, e.g., 2D labels.","Unlike prior work which still relies on few accurate 3D annotations, we propose a framework to study how to leverage constraints between 2D and 3D domains without requiring any 3D labels.","Specifically, we employ visual data from three perspectives to establish connections between 2D and 3D domains.","First, we design a feature-level constraint to align LiDAR and image features based on object-aware regions.","Second, the output-level constraint is developed to enforce the overlap between 2D and projected 3D box estimations.","Finally, the training-level constraint is utilized by producing accurate and consistent 3D pseudo-labels that align with the visual data.","We conduct extensive experiments on the KITTI dataset to validate the effectiveness of the proposed three constraints.","Without using any 3D labels, our method achieves favorable performance against state-of-the-art approaches and is competitive with the method that uses 500-frame 3D annotations.","Code and models will be made publicly available at https://github.com/kuanchihhuang/VG-W3D."],"url":"http://arxiv.org/abs/2312.07530v1"}
{"created":"2023-12-12 18:56:14","title":"Topological Obstructions and How to Avoid Them","abstract":"Incorporating geometric inductive biases into models can aid interpretability and generalization, but encoding to a specific geometric structure can be challenging due to the imposed topological constraints. In this paper, we theoretically and empirically characterize obstructions to training encoders with geometric latent spaces. We show that local optima can arise due to singularities (e.g. self-intersection) or due to an incorrect degree or winding number. We then discuss how normalizing flows can potentially circumvent these obstructions by defining multimodal variational distributions. Inspired by this observation, we propose a new flow-based model that maps data points to multimodal distributions over geometric spaces and empirically evaluate our model on 2 domains. We observe improved stability during training and a higher chance of converging to a homeomorphic encoder.","sentences":["Incorporating geometric inductive biases into models can aid interpretability and generalization, but encoding to a specific geometric structure can be challenging due to the imposed topological constraints.","In this paper, we theoretically and empirically characterize obstructions to training encoders with geometric latent spaces.","We show that local optima can arise due to singularities (e.g. self-intersection) or due to an incorrect degree or winding number.","We then discuss how normalizing flows can potentially circumvent these obstructions by defining multimodal variational distributions.","Inspired by this observation, we propose a new flow-based model that maps data points to multimodal distributions over geometric spaces and empirically evaluate our model on 2 domains.","We observe improved stability during training and a higher chance of converging to a homeomorphic encoder."],"url":"http://arxiv.org/abs/2312.07529v1"}
{"created":"2023-12-12 18:48:25","title":"Search Optimization with Query Likelihood Boosting and Two-Level Approximate Search for Edge Devices","abstract":"We present a novel search optimization solution for approximate nearest neighbor (ANN) search on resource-constrained edge devices. Traditional ANN approaches fall short in meeting the specific demands of real-world scenarios, e.g., skewed query likelihood distribution and search on large-scale indices with a low latency and small footprint. To address these limitations, we introduce two key components: a Query Likelihood Boosted Tree (QLBT) to optimize average search latency for frequently used small datasets, and a two-level approximate search algorithm to enable efficient retrieval with large datasets on edge devices. We perform thorough evaluation on simulated and real data and demonstrate QLBT can significantly reduce latency by 15% on real data and our two-level search algorithm successfully achieve deployable accuracy and latency on a 10 million dataset for edge devices. In addition, we provide a comprehensive protocol for configuring and optimizing on-device search algorithm through extensive empirical studies.","sentences":["We present a novel search optimization solution for approximate nearest neighbor (ANN) search on resource-constrained edge devices.","Traditional ANN approaches fall short in meeting the specific demands of real-world scenarios, e.g., skewed query likelihood distribution and search on large-scale indices with a low latency and small footprint.","To address these limitations, we introduce two key components: a Query Likelihood Boosted Tree (QLBT) to optimize average search latency for frequently used small datasets, and a two-level approximate search algorithm to enable efficient retrieval with large datasets on edge devices.","We perform thorough evaluation on simulated and real data and demonstrate QLBT can significantly reduce latency by 15% on real data and our two-level search algorithm successfully achieve deployable accuracy and latency on a 10 million dataset for edge devices.","In addition, we provide a comprehensive protocol for configuring and optimizing on-device search algorithm through extensive empirical studies."],"url":"http://arxiv.org/abs/2312.07517v1"}
