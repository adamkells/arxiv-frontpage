{"created":"2024-05-15 17:57:56","title":"BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation","abstract":"The systematic evaluation and understanding of computer vision models under varying conditions require large amounts of data with comprehensive and customized labels, which real-world vision datasets rarely satisfy. While current synthetic data generators offer a promising alternative, particularly for embodied AI tasks, they often fall short for computer vision tasks due to low asset and rendering quality, limited diversity, and unrealistic physical properties. We introduce the BEHAVIOR Vision Suite (BVS), a set of tools and assets to generate fully customized synthetic data for systematic evaluation of computer vision models, based on the newly developed embodied AI benchmark, BEHAVIOR-1K. BVS supports a large number of adjustable parameters at the scene level (e.g., lighting, object placement), the object level (e.g., joint configuration, attributes such as \"filled\" and \"folded\"), and the camera level (e.g., field of view, focal length). Researchers can arbitrarily vary these parameters during data generation to perform controlled experiments. We showcase three example application scenarios: systematically evaluating the robustness of models across different continuous axes of domain shift, evaluating scene understanding models on the same set of images, and training and evaluating simulation-to-real transfer for a novel vision task: unary and binary state prediction. Project website: https://behavior-vision-suite.github.io/","sentences":["The systematic evaluation and understanding of computer vision models under varying conditions require large amounts of data with comprehensive and customized labels, which real-world vision datasets rarely satisfy.","While current synthetic data generators offer a promising alternative, particularly for embodied AI tasks, they often fall short for computer vision tasks due to low asset and rendering quality, limited diversity, and unrealistic physical properties.","We introduce the BEHAVIOR Vision Suite (BVS), a set of tools and assets to generate fully customized synthetic data for systematic evaluation of computer vision models, based on the newly developed embodied AI benchmark, BEHAVIOR-1K. BVS supports a large number of adjustable parameters at the scene level (e.g., lighting, object placement), the object level (e.g., joint configuration, attributes such as \"filled\" and \"folded\"), and the camera level (e.g., field of view, focal length).","Researchers can arbitrarily vary these parameters during data generation to perform controlled experiments.","We showcase three example application scenarios: systematically evaluating the robustness of models across different continuous axes of domain shift, evaluating scene understanding models on the same set of images, and training and evaluating simulation-to-real transfer for a novel vision task: unary and binary state prediction.","Project website: https://behavior-vision-suite.github.io/"],"url":"http://arxiv.org/abs/2405.09546v1"}
{"created":"2024-05-15 17:56:49","title":"Classifying geospatial objects from multiview aerial imagery using semantic meshes","abstract":"Aerial imagery is increasingly used in Earth science and natural resource management as a complement to labor-intensive ground-based surveys. Aerial systems can collect overlapping images that provide multiple views of each location from different perspectives. However, most prediction approaches (e.g. for tree species classification) use a single, synthesized top-down \"orthomosaic\" image as input that contains little to no information about the vertical aspects of objects and may include processing artifacts. We propose an alternate approach that generates predictions directly on the raw images and accurately maps these predictions into geospatial coordinates using semantic meshes. This method$\\unicode{x2013}$released as a user-friendly open-source toolkit$\\unicode{x2013}$enables analysts to use the highest quality data for predictions, capture information about the sides of objects, and leverage multiple viewpoints of each location for added robustness. We demonstrate the value of this approach on a new benchmark dataset of four forest sites in the western U.S. that consists of drone images, photogrammetry results, predicted tree locations, and species classification data derived from manual surveys. We show that our proposed multiview method improves classification accuracy from 53% to 75% relative to an orthomosaic baseline on a challenging cross-site tree species classification task.","sentences":["Aerial imagery is increasingly used in Earth science and natural resource management as a complement to labor-intensive ground-based surveys.","Aerial systems can collect overlapping images that provide multiple views of each location from different perspectives.","However, most prediction approaches (e.g. for tree species classification) use a single, synthesized top-down \"orthomosaic\" image as input that contains little to no information about the vertical aspects of objects and may include processing artifacts.","We propose an alternate approach that generates predictions directly on the raw images and accurately maps these predictions into geospatial coordinates using semantic meshes.","This method$\\unicode{x2013}$released as a user-friendly open-source toolkit$\\unicode{x2013}$enables analysts to use the highest quality data for predictions, capture information about the sides of objects, and leverage multiple viewpoints of each location for added robustness.","We demonstrate the value of this approach on a new benchmark dataset of four forest sites in the western U.S. that consists of drone images, photogrammetry results, predicted tree locations, and species classification data derived from manual surveys.","We show that our proposed multiview method improves classification accuracy from 53% to 75% relative to an orthomosaic baseline on a challenging cross-site tree species classification task."],"url":"http://arxiv.org/abs/2405.09544v1"}
{"created":"2024-05-15 16:58:35","title":"QueryNER: Segmentation of E-commerce Queries","abstract":"We present QueryNER, a manually-annotated dataset and accompanying model for e-commerce query segmentation. Prior work in sequence labeling for e-commerce has largely addressed aspect-value extraction which focuses on extracting portions of a product title or query for narrowly defined aspects. Our work instead focuses on the goal of dividing a query into meaningful chunks with broadly applicable types. We report baseline tagging results and conduct experiments comparing token and entity dropping for null and low recall query recovery. Challenging test sets are created using automatic transformations and show how simple data augmentation techniques can make the models more robust to noise. We make the QueryNER dataset publicly available.","sentences":["We present QueryNER, a manually-annotated dataset and accompanying model for e-commerce query segmentation.","Prior work in sequence labeling for e-commerce has largely addressed aspect-value extraction which focuses on extracting portions of a product title or query for narrowly defined aspects.","Our work instead focuses on the goal of dividing a query into meaningful chunks with broadly applicable types.","We report baseline tagging results and conduct experiments comparing token and entity dropping for null and low recall query recovery.","Challenging test sets are created using automatic transformations and show how simple data augmentation techniques can make the models more robust to noise.","We make the QueryNER dataset publicly available."],"url":"http://arxiv.org/abs/2405.09507v1"}
{"created":"2024-05-15 16:53:30","title":"Initial Algebras Unchained -- A Novel Initial Algebra Construction Formalized in Agda","abstract":"The initial algebra for an endofunctor F provides a recursion and induction scheme for data structures whose constructors are described by F. The initial-algebra construction by Ad\\'amek (1974) starts with the initial object (e.g. the empty set) and successively applies the functor until a fixed point is reached, an idea inspired by Kleene's fixed point theorem. Depending on the functor of interest, this may require transfinitely many steps indexed by ordinal numbers until termination.   We provide a new initial algebra construction which is not based on an ordinal-indexed chain. Instead, our construction is loosely inspired by Pataraia's fixed point theorem and forms the colimit of all finite recursive coalgebras. This is reminiscent of the construction of the rational fixed point of an endofunctor that forms the colimit of all finite coalgebras. For our main correctness theorem, we assume the given endofunctor is accessible on a (weak form of) locally presentable category. Our proofs are constructive and fully formalized in Agda.","sentences":["The initial algebra for an endofunctor F provides a recursion and induction scheme for data structures whose constructors are described by F. The initial-algebra construction by Ad\\'amek (1974) starts with the initial object (e.g. the empty set) and successively applies the functor until a fixed point is reached, an idea inspired by Kleene's fixed point theorem.","Depending on the functor of interest, this may require transfinitely many steps indexed by ordinal numbers until termination.   ","We provide a new initial algebra construction which is not based on an ordinal-indexed chain.","Instead, our construction is loosely inspired by Pataraia's fixed point theorem and forms the colimit of all finite recursive coalgebras.","This is reminiscent of the construction of the rational fixed point of an endofunctor that forms the colimit of all finite coalgebras.","For our main correctness theorem, we assume the given endofunctor is accessible on a (weak form of) locally presentable category.","Our proofs are constructive and fully formalized in Agda."],"url":"http://arxiv.org/abs/2405.09504v1"}
{"created":"2024-05-15 16:44:54","title":"ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using Wikidata","abstract":"We introduce ParaNames, a massively multilingual parallel name resource consisting of 140 million names spanning over 400 languages. Names are provided for 16.8 million entities, and each entity is mapped from a complex type hierarchy to a standard type (PER/LOC/ORG). Using Wikidata as a source, we create the largest resource of this type to date. We describe our approach to filtering and standardizing the data to provide the best quality possible. ParaNames is useful for multilingual language processing, both in defining tasks for name translation/transliteration and as supplementary data for tasks such as named entity recognition and linking. We demonstrate the usefulness of ParaNames on two tasks. First, we perform canonical name translation between English and 17 other languages. Second, we use it as a gazetteer for multilingual named entity recognition, obtaining performance improvements on all 10 languages evaluated.","sentences":["We introduce ParaNames, a massively multilingual parallel name resource consisting of 140 million names spanning over 400 languages.","Names are provided for 16.8 million entities, and each entity is mapped from a complex type hierarchy to a standard type (PER/LOC/ORG).","Using Wikidata as a source, we create the largest resource of this type to date.","We describe our approach to filtering and standardizing the data to provide the best quality possible.","ParaNames is useful for multilingual language processing, both in defining tasks for name translation/transliteration and as supplementary data for tasks such as named entity recognition and linking.","We demonstrate the usefulness of ParaNames on two tasks.","First, we perform canonical name translation between English and 17 other languages.","Second, we use it as a gazetteer for multilingual named entity recognition, obtaining performance improvements on all 10 languages evaluated."],"url":"http://arxiv.org/abs/2405.09496v1"}
{"created":"2024-05-15 16:22:46","title":"DemOpts: Fairness corrections in COVID-19 case prediction models","abstract":"COVID-19 forecasting models have been used to inform decision making around resource allocation and intervention decisions e.g., hospital beds or stay-at-home orders. State of the art deep learning models often use multimodal data such as mobility or socio-demographic data to enhance COVID-19 case prediction models. Nevertheless, related work has revealed under-reporting bias in COVID-19 cases as well as sampling bias in mobility data for certain minority racial and ethnic groups, which could in turn affect the fairness of the COVID-19 predictions along race labels. In this paper, we show that state of the art deep learning models output mean prediction errors that are significantly different across racial and ethnic groups; and which could, in turn, support unfair policy decisions. We also propose a novel de-biasing method, DemOpts, to increase the fairness of deep learning based forecasting models trained on potentially biased datasets. Our results show that DemOpts can achieve better error parity that other state of the art de-biasing approaches, thus effectively reducing the differences in the mean error distributions across more racial and ethnic groups.","sentences":["COVID-19 forecasting models have been used to inform decision making around resource allocation and intervention decisions e.g., hospital beds or stay-at-home orders.","State of the art deep learning models often use multimodal data such as mobility or socio-demographic data to enhance COVID-19 case prediction models.","Nevertheless, related work has revealed under-reporting bias in COVID-19 cases as well as sampling bias in mobility data for certain minority racial and ethnic groups, which could in turn affect the fairness of the COVID-19 predictions along race labels.","In this paper, we show that state of the art deep learning models output mean prediction errors that are significantly different across racial and ethnic groups; and which could, in turn, support unfair policy decisions.","We also propose a novel de-biasing method, DemOpts, to increase the fairness of deep learning based forecasting models trained on potentially biased datasets.","Our results show that DemOpts can achieve better error parity that other state of the art de-biasing approaches, thus effectively reducing the differences in the mean error distributions across more racial and ethnic groups."],"url":"http://arxiv.org/abs/2405.09483v1"}
{"created":"2024-05-15 15:58:21","title":"Flashback: Enhancing Proposer-Builder Design with Future-Block Auctions in Proof-of-Stake Ethereum","abstract":"Maximal extractable value (MEV) in which block proposers unethically gain profits by manipulating the order in which transactions are included within a block, is a key challenge facing blockchains such as Ethereum today. Left unchecked, MEV can lead to a centralization of stake distribution thereby ultimately compromising the security of blockchain consensus. To preserve proposer decentralization (and hence security) of the blockchain, Ethereum has advocated for a proposer-builder separation (PBS) in which the functionality of transaction ordering is separated from proposers and assigned to separate entities called builders. Builders accept transaction bundles from searchers, who compete to find the most profitable bundles. Builders then bid completed blocks to proposers, who accept the most profitable blocks for publication. The auction mechanisms used between searchers, builders and proposers are crucial to the overall health of the blockchain. In this paper, we consider PBS design in Ethereum as a game between searchers, builders and proposers. A key novelty in our design is the inclusion of future block proposers, as all proposers of an epoch are decided ahead of time in proof-of-stake (PoS) Ethereum within the game model. Our analysis shows the existence of alternative auction mechanisms that result in a better (more profitable) equilibrium to players compared to state-of-the-art. Experimental evaluations based on synthetic and real-world data traces corroborate the analysis. Our results highlight that a rethinking of auction mechanism designs is necessary in PoS Ethereum to prevent disruption.","sentences":["Maximal extractable value (MEV) in which block proposers unethically gain profits by manipulating the order in which transactions are included within a block, is a key challenge facing blockchains such as Ethereum today.","Left unchecked, MEV can lead to a centralization of stake distribution thereby ultimately compromising the security of blockchain consensus.","To preserve proposer decentralization (and hence security) of the blockchain, Ethereum has advocated for a proposer-builder separation (PBS) in which the functionality of transaction ordering is separated from proposers and assigned to separate entities called builders.","Builders accept transaction bundles from searchers, who compete to find the most profitable bundles.","Builders then bid completed blocks to proposers, who accept the most profitable blocks for publication.","The auction mechanisms used between searchers, builders and proposers are crucial to the overall health of the blockchain.","In this paper, we consider PBS design in Ethereum as a game between searchers, builders and proposers.","A key novelty in our design is the inclusion of future block proposers, as all proposers of an epoch are decided ahead of time in proof-of-stake (PoS) Ethereum within the game model.","Our analysis shows the existence of alternative auction mechanisms that result in a better (more profitable) equilibrium to players compared to state-of-the-art.","Experimental evaluations based on synthetic and real-world data traces corroborate the analysis.","Our results highlight that a rethinking of auction mechanism designs is necessary in PoS Ethereum to prevent disruption."],"url":"http://arxiv.org/abs/2405.09465v1"}
{"created":"2024-05-15 15:56:18","title":"Gaze-DETR: Using Expert Gaze to Reduce False Positives in Vulvovaginal Candidiasis Screening","abstract":"Accurate detection of vulvovaginal candidiasis is critical for women's health, yet its sparse distribution and visually ambiguous characteristics pose significant challenges for accurate identification by pathologists and neural networks alike. Our eye-tracking data reveals that areas garnering sustained attention - yet not marked by experts after deliberation - are often aligned with false positives of neural networks. Leveraging this finding, we introduce Gaze-DETR, a pioneering method that integrates gaze data to enhance neural network precision by diminishing false positives. Gaze-DETR incorporates a universal gaze-guided warm-up protocol applicable across various detection methods and a gaze-guided rectification strategy specifically designed for DETR-based models. Our comprehensive tests confirm that Gaze-DETR surpasses existing leading methods, showcasing remarkable improvements in detection accuracy and generalizability.","sentences":["Accurate detection of vulvovaginal candidiasis is critical for women's health, yet its sparse distribution and visually ambiguous characteristics pose significant challenges for accurate identification by pathologists and neural networks alike.","Our eye-tracking data reveals that areas garnering sustained attention - yet not marked by experts after deliberation - are often aligned with false positives of neural networks.","Leveraging this finding, we introduce Gaze-DETR, a pioneering method that integrates gaze data to enhance neural network precision by diminishing false positives.","Gaze-DETR incorporates a universal gaze-guided warm-up protocol applicable across various detection methods and a gaze-guided rectification strategy specifically designed for DETR-based models.","Our comprehensive tests confirm that Gaze-DETR surpasses existing leading methods, showcasing remarkable improvements in detection accuracy and generalizability."],"url":"http://arxiv.org/abs/2405.09463v1"}
{"created":"2024-05-15 15:48:11","title":"Kuramoto Oscillators and Swarms on Manifolds for Geometry Informed Machine Learning","abstract":"We propose the idea of using Kuramoto models (including their higher-dimensional generalizations) for machine learning over non-Euclidean data sets. These models are systems of matrix ODE's describing collective motions (swarming dynamics) of abstract particles (generalized oscillators) on spheres, homogeneous spaces and Lie groups. Such models have been extensively studied from the beginning of XXI century both in statistical physics and control theory. They provide a suitable framework for encoding maps between various manifolds and are capable of learning over spherical and hyperbolic geometries. In addition, they can learn coupled actions of transformation groups (such as special orthogonal, unitary and Lorentz groups). Furthermore, we overview families of probability distributions that provide appropriate statistical models for probabilistic modeling and inference in Geometric Deep Learning. We argue in favor of using statistical models which arise in different Kuramoto models in the continuum limit of particles. The most convenient families of probability distributions are those which are invariant with respect to actions of certain symmetry groups.","sentences":["We propose the idea of using Kuramoto models (including their higher-dimensional generalizations) for machine learning over non-Euclidean data sets.","These models are systems of matrix ODE's describing collective motions (swarming dynamics) of abstract particles (generalized oscillators) on spheres, homogeneous spaces and Lie groups.","Such models have been extensively studied from the beginning of XXI century both in statistical physics and control theory.","They provide a suitable framework for encoding maps between various manifolds and are capable of learning over spherical and hyperbolic geometries.","In addition, they can learn coupled actions of transformation groups (such as special orthogonal, unitary and Lorentz groups).","Furthermore, we overview families of probability distributions that provide appropriate statistical models for probabilistic modeling and inference in Geometric Deep Learning.","We argue in favor of using statistical models which arise in different Kuramoto models in the continuum limit of particles.","The most convenient families of probability distributions are those which are invariant with respect to actions of certain symmetry groups."],"url":"http://arxiv.org/abs/2405.09453v1"}
{"created":"2024-05-15 15:39:35","title":"Desk-AId: Humanitarian Aid Desk Assessment with Geospatial AI for Predicting Landmine Areas","abstract":"The process of clearing areas, namely demining, starts by assessing and prioritizing potential hazardous areas (i.e., desk assessment) to go under thorough investigation of experts, who confirm the risk and proceed with the mines clearance operations. This paper presents Desk-AId that supports the desk assessment phase by estimating landmine risks using geospatial data and socioeconomic information. Desk-AId uses a Geospatial AI approach specialized to landmines. The approach includes mixed data sampling strategies and context-enrichment by historical conflicts and key multi-domain facilities (e.g., buildings, roads, health sites). The proposed system addresses the issue of having only ground-truth for confirmed hazardous areas by implementing a new hard-negative data sampling strategy, where negative points are sampled in the vicinity of hazardous areas. Experiments validate Desk-Aid in two domains for landmine risk assessment: 1) country-wide, and 2) uncharted study areas). The proposed approach increases the estimation accuracies up to 92%, for different classification models such as RandomForest (RF), Feedforward Neural Networks (FNN), and Graph Neural Networks (GNN).","sentences":["The process of clearing areas, namely demining, starts by assessing and prioritizing potential hazardous areas (i.e., desk assessment) to go under thorough investigation of experts, who confirm the risk and proceed with the mines clearance operations.","This paper presents Desk-AId that supports the desk assessment phase by estimating landmine risks using geospatial data and socioeconomic information.","Desk-AId uses a Geospatial AI approach specialized to landmines.","The approach includes mixed data sampling strategies and context-enrichment by historical conflicts and key multi-domain facilities (e.g., buildings, roads, health sites).","The proposed system addresses the issue of having only ground-truth for confirmed hazardous areas by implementing a new hard-negative data sampling strategy, where negative points are sampled in the vicinity of hazardous areas.","Experiments validate Desk-Aid in two domains for landmine risk assessment: 1) country-wide, and 2) uncharted study areas).","The proposed approach increases the estimation accuracies up to 92%, for different classification models such as RandomForest (RF), Feedforward Neural Networks (FNN), and Graph Neural Networks (GNN)."],"url":"http://arxiv.org/abs/2405.09444v1"}
{"created":"2024-05-15 15:20:18","title":"Physics-Informed Neural Network for Multirotor Slung Load Systems Modeling","abstract":"Recent advances in aerial robotics have enabled the use of multirotor vehicles for autonomous payload transportation. Resorting only to classical methods to reliably model a quadrotor carrying a cable-slung load poses significant challenges. On the other hand, purely data-driven learning methods do not comply by design with the problem's physical constraints, especially in states that are not densely represented in training data. In this work, we explore the use of physics informed neural networks to learn an end-to-end model of the multirotor-slung-load system and, at a given time, estimate a sequence of the future system states. An LSTM encoder decoder with an attention mechanism is used to capture the dynamics of the system. To guarantee the cohesiveness between the multiple predicted states of the system, we propose the use of a physics-based term in the loss function, which includes a discretized physical model derived from first principles together with slack variables that allow for a small mismatch between expected and predicted values. To train the model, a dataset using a real-world quadrotor carrying a slung load was curated and is made available. Prediction results are presented and corroborate the feasibility of the approach. The proposed method outperforms both the first principles physical model and a comparable neural network model trained without the physics regularization proposed.","sentences":["Recent advances in aerial robotics have enabled the use of multirotor vehicles for autonomous payload transportation.","Resorting only to classical methods to reliably model a quadrotor carrying a cable-slung load poses significant challenges.","On the other hand, purely data-driven learning methods do not comply by design with the problem's physical constraints, especially in states that are not densely represented in training data.","In this work, we explore the use of physics informed neural networks to learn an end-to-end model of the multirotor-slung-load system and, at a given time, estimate a sequence of the future system states.","An LSTM encoder decoder with an attention mechanism is used to capture the dynamics of the system.","To guarantee the cohesiveness between the multiple predicted states of the system, we propose the use of a physics-based term in the loss function, which includes a discretized physical model derived from first principles together with slack variables that allow for a small mismatch between expected and predicted values.","To train the model, a dataset using a real-world quadrotor carrying a slung load was curated and is made available.","Prediction results are presented and corroborate the feasibility of the approach.","The proposed method outperforms both the first principles physical model and a comparable neural network model trained without the physics regularization proposed."],"url":"http://arxiv.org/abs/2405.09428v1"}
{"created":"2024-05-15 15:17:04","title":"MicroPython Testbed for Federated Learning Algorithms","abstract":"Recently, Python Testbed for Federated Learning Algorithms emerged as a low code and generative large language models amenable framework for developing decentralized and distributed applications, primarily targeting edge systems, by nonprofessional programmers with the help of emerging artificial intelligence tools. This light framework is written in pure Python to be easy to install and to fit into a small IoT memory. It supports formally verified generic centralized and decentralized federated learning algorithms, as well as the peer-to-peer data exchange used in time division multiplexing communication, and its current main limitation is that all the application instances can run only on a single PC. This paper presents the MicroPyton Testbed for Federated Learning Algorithms, the new framework that overcomes its predecessor's limitation such that individual application instances may run on different network nodes like PCs and IoTs, primarily in edge systems. The new framework carries on the pure Python ideal, is based on asynchronous I/O abstractions, and runs on MicroPython, and therefore is a great match for IoTs and devices in edge systems. The new framework was experimentally validated on a wireless network comprising PCs and Raspberry Pi Pico W boards, by using application examples originally developed for the predecessor framework.","sentences":["Recently, Python Testbed for Federated Learning Algorithms emerged as a low code and generative large language models amenable framework for developing decentralized and distributed applications, primarily targeting edge systems, by nonprofessional programmers with the help of emerging artificial intelligence tools.","This light framework is written in pure Python to be easy to install and to fit into a small IoT memory.","It supports formally verified generic centralized and decentralized federated learning algorithms, as well as the peer-to-peer data exchange used in time division multiplexing communication, and its current main limitation is that all the application instances can run only on a single PC.","This paper presents the MicroPyton Testbed for Federated Learning Algorithms, the new framework that overcomes its predecessor's limitation such that individual application instances may run on different network nodes like PCs and IoTs, primarily in edge systems.","The new framework carries on the pure Python ideal, is based on asynchronous I/O abstractions, and runs on MicroPython, and therefore is a great match for IoTs and devices in edge systems.","The new framework was experimentally validated on a wireless network comprising PCs and Raspberry Pi Pico W boards, by using application examples originally developed for the predecessor framework."],"url":"http://arxiv.org/abs/2405.09423v1"}
{"created":"2024-05-15 15:07:31","title":"Distinguishing Tor From Other Encrypted Network Traffic Through Character Analysis","abstract":"For journalists reporting from a totalitarian regime, whistleblowers and resistance fighters, the anonymous use of cloud services on the Internet can be vital for survival. The Tor network provides a free and widely used anonymization service for everyone. However, there are different approaches to distinguishing Tor from non-Tor encrypted network traffic, most recently only due to the (relative) frequencies of hex digits in a single encrypted payload packet. While conventional data traffic is usually encrypted once, but at least three times in the case of Tor due to the structure and principle of the Tor network, we have examined to what extent the number of encryptions contributes to being able to distinguish Tor from non-Tor encrypted data traffic.","sentences":["For journalists reporting from a totalitarian regime, whistleblowers and resistance fighters, the anonymous use of cloud services on the Internet can be vital for survival.","The Tor network provides a free and widely used anonymization service for everyone.","However, there are different approaches to distinguishing Tor from non-Tor encrypted network traffic, most recently only due to the (relative) frequencies of hex digits in a single encrypted payload packet.","While conventional data traffic is usually encrypted once, but at least three times in the case of Tor due to the structure and principle of the Tor network, we have examined to what extent the number of encryptions contributes to being able to distinguish Tor from non-Tor encrypted data traffic."],"url":"http://arxiv.org/abs/2405.09412v1"}
{"created":"2024-05-15 15:04:27","title":"Real-World Federated Learning in Radiology: Hurdles to overcome and Benefits to gain","abstract":"Objective: Federated Learning (FL) enables collaborative model training while keeping data locally. Currently, most FL studies in radiology are conducted in simulated environments due to numerous hurdles impeding its translation into practice. The few existing real-world FL initiatives rarely communicate specific measures taken to overcome these hurdles, leaving behind a significant knowledge gap. Minding efforts to implement real-world FL, there is a notable lack of comprehensive assessment comparing FL to less complex alternatives. Materials & Methods: We extensively reviewed FL literature, categorizing insights along with our findings according to their nature and phase while establishing a FL initiative, summarized to a comprehensive guide. We developed our own FL infrastructure within the German Radiological Cooperative Network (RACOON) and demonstrated its functionality by training FL models on lung pathology segmentation tasks across six university hospitals. We extensively evaluated FL against less complex alternatives in three distinct evaluation scenarios. Results: The proposed guide outlines essential steps, identified hurdles, and proposed solutions for establishing successful FL initiatives conducting real-world experiments. Our experimental results show that FL outperforms less complex alternatives in all evaluation scenarios, justifying the effort required to translate FL into real-world applications. Discussion & Conclusion: Our proposed guide aims to aid future FL researchers in circumventing pitfalls and accelerating translation of FL into radiological applications. Our results underscore the value of efforts needed to translate FL into real-world applications by demonstrating advantageous performance over alternatives, and emphasize the importance of strategic organization, robust management of distributed data and infrastructure in real-world settings.","sentences":["Objective: Federated Learning (FL) enables collaborative model training while keeping data locally.","Currently, most FL studies in radiology are conducted in simulated environments due to numerous hurdles impeding its translation into practice.","The few existing real-world FL initiatives rarely communicate specific measures taken to overcome these hurdles, leaving behind a significant knowledge gap.","Minding efforts to implement real-world FL, there is a notable lack of comprehensive assessment comparing FL to less complex alternatives.","Materials & Methods: We extensively reviewed FL literature, categorizing insights along with our findings according to their nature and phase while establishing a FL initiative, summarized to a comprehensive guide.","We developed our own FL infrastructure within the German Radiological Cooperative Network (RACOON) and demonstrated its functionality by training FL models on lung pathology segmentation tasks across six university hospitals.","We extensively evaluated FL against less complex alternatives in three distinct evaluation scenarios.","Results:","The proposed guide outlines essential steps, identified hurdles, and proposed solutions for establishing successful FL initiatives conducting real-world experiments.","Our experimental results show that FL outperforms less complex alternatives in all evaluation scenarios, justifying the effort required to translate FL into real-world applications.","Discussion & Conclusion: Our proposed guide aims to aid future FL researchers in circumventing pitfalls and accelerating translation of FL into radiological applications.","Our results underscore the value of efforts needed to translate FL into real-world applications by demonstrating advantageous performance over alternatives, and emphasize the importance of strategic organization, robust management of distributed data and infrastructure in real-world settings."],"url":"http://arxiv.org/abs/2405.09409v1"}
{"created":"2024-05-15 14:59:26","title":"Identity Overlap Between Face Recognition Train/Test Data: Causing Optimistic Bias in Accuracy Measurement","abstract":"A fundamental tenet of pattern recognition is that overlap between training and testing sets causes an optimistic accuracy estimate. Deep CNNs for face recognition are trained for N-way classification of the identities in the training set. Accuracy is commonly estimated as average 10-fold classification accuracy on image pairs from test sets such as LFW, CALFW, CPLFW, CFP-FP and AgeDB-30. Because train and test sets have been independently assembled, images and identities in any given test set may also be present in any given training set. In particular, our experiments reveal a surprising degree of identity and image overlap between the LFW family of test sets and the MS1MV2 training set. Our experiments also reveal identity label noise in MS1MV2. We compare accuracy achieved with same-size MS1MV2 subsets that are identity-disjoint and not identity-disjoint with LFW, to reveal the size of the optimistic bias. Using more challenging test sets from the LFW family, we find that the size of the optimistic bias is larger for more challenging test sets. Our results highlight the lack of and the need for identity-disjoint train and test methodology in face recognition research.","sentences":["A fundamental tenet of pattern recognition is that overlap between training and testing sets causes an optimistic accuracy estimate.","Deep CNNs for face recognition are trained for N-way classification of the identities in the training set.","Accuracy is commonly estimated as average 10-fold classification accuracy on image pairs from test sets such as LFW, CALFW, CPLFW, CFP-FP and AgeDB-30.","Because train and test sets have been independently assembled, images and identities in any given test set may also be present in any given training set.","In particular, our experiments reveal a surprising degree of identity and image overlap between the LFW family of test sets and the MS1MV2 training set.","Our experiments also reveal identity label noise in MS1MV2.","We compare accuracy achieved with same-size MS1MV2 subsets that are identity-disjoint and not identity-disjoint with LFW, to reveal the size of the optimistic bias.","Using more challenging test sets from the LFW family, we find that the size of the optimistic bias is larger for more challenging test sets.","Our results highlight the lack of and the need for identity-disjoint train and test methodology in face recognition research."],"url":"http://arxiv.org/abs/2405.09403v1"}
{"created":"2024-05-15 14:51:46","title":"Encrypted Container File: Design and Implementation of a Hybrid-Encrypted Multi-Recipient File Structure","abstract":"Modern software engineering trends towards Cloud-native software development by international teams of developers. Cloud-based version management services, such as GitHub, are used for the source code and other artifacts created during the development process. However, using such a service usually means that every developer has access to all data stored on the platform. Particularly, if the developers belong to different companies or organizations, it would be desirable for sensitive files to be encrypted in such a way that these can only be decrypted again by a group of previously defined people. In this paper, we examine currently available tools that address this problem, but which have certain shortcomings. We then present our own solution, Encrypted Container Files (ECF), for this problem, eliminating the deficiencies found in the other tools.","sentences":["Modern software engineering trends towards Cloud-native software development by international teams of developers.","Cloud-based version management services, such as GitHub, are used for the source code and other artifacts created during the development process.","However, using such a service usually means that every developer has access to all data stored on the platform.","Particularly, if the developers belong to different companies or organizations, it would be desirable for sensitive files to be encrypted in such a way that these can only be decrypted again by a group of previously defined people.","In this paper, we examine currently available tools that address this problem, but which have certain shortcomings.","We then present our own solution, Encrypted Container Files (ECF), for this problem, eliminating the deficiencies found in the other tools."],"url":"http://arxiv.org/abs/2405.09398v1"}
{"created":"2024-05-15 14:50:46","title":"SA-FedLora: Adaptive Parameter Allocation for Efficient Federated Learning with LoRA Tuning","abstract":"Fine-tuning large-scale pre-trained models via transfer learning is an emerging important paradigm for a wide range of downstream tasks, with performance heavily reliant on extensive data. Federated learning (FL), as a distributed framework, provides a secure solution to train models on local datasets while safeguarding raw sensitive data. However, FL networks encounter high communication costs due to the massive parameters of large-scale pre-trained models, necessitating parameter-efficient methods. Notably, parameter efficient fine tuning, such as Low-Rank Adaptation (LoRA), has shown remarkable success in fine-tuning pre-trained models. However, prior research indicates that the fixed parameter budget may be prone to the overfitting or slower convergence. To address this challenge, we propose a Simulated Annealing-based Federated Learning with LoRA tuning (SA-FedLoRA) approach by reducing trainable parameters. Specifically, SA-FedLoRA comprises two stages: initiating and annealing. (1) In the initiating stage, we implement a parameter regularization approach during the early rounds of aggregation, aiming to mitigate client drift and accelerate the convergence for the subsequent tuning. (2) In the annealing stage, we allocate higher parameter budget during the early 'heating' phase and then gradually shrink the budget until the 'cooling' phase. This strategy not only facilitates convergence to the global optimum but also reduces communication costs. Experimental results demonstrate that SA-FedLoRA is an efficient FL, achieving superior performance to FedAvg and significantly reducing communication parameters by up to 93.62%.","sentences":["Fine-tuning large-scale pre-trained models via transfer learning is an emerging important paradigm for a wide range of downstream tasks, with performance heavily reliant on extensive data.","Federated learning (FL), as a distributed framework, provides a secure solution to train models on local datasets while safeguarding raw sensitive data.","However, FL networks encounter high communication costs due to the massive parameters of large-scale pre-trained models, necessitating parameter-efficient methods.","Notably, parameter efficient fine tuning, such as Low-Rank Adaptation (LoRA), has shown remarkable success in fine-tuning pre-trained models.","However, prior research indicates that the fixed parameter budget may be prone to the overfitting or slower convergence.","To address this challenge, we propose a Simulated Annealing-based Federated Learning with LoRA tuning (SA-FedLoRA) approach by reducing trainable parameters.","Specifically, SA-FedLoRA comprises two stages: initiating and annealing.","(1) In the initiating stage, we implement a parameter regularization approach during the early rounds of aggregation, aiming to mitigate client drift and accelerate the convergence for the subsequent tuning.","(2) In the annealing stage, we allocate higher parameter budget during the early 'heating' phase and then gradually shrink the budget until the 'cooling' phase.","This strategy not only facilitates convergence to the global optimum but also reduces communication costs.","Experimental results demonstrate that SA-FedLoRA is an efficient FL, achieving superior performance to FedAvg and significantly reducing communication parameters by up to 93.62%."],"url":"http://arxiv.org/abs/2405.09394v1"}
{"created":"2024-05-15 14:50:38","title":"Counting overlapping pairs of strings","abstract":"A correlation is a binary vector that encodes all possible positions of overlaps of two words, where an overlap for an ordered pair of words (u,v) occurs if a suffix of word u matches a prefix of word v. As multiple pairs can have the same correlation, it is relevant to count how many pairs of words share the same correlation depending on the alphabet size and word length n. We exhibit recurrences to compute the number of such pairs -- which is termed population size -- for any correlation; for this, we exploit a relationship between overlaps of two words and self-overlap of one word. This theorem allows us to compute the number of pairs with a longest overlap of a given length and to show that the expected length of the longest border of two words asymptotically diverges, which solves two open questions raised by Gabric in 2022. Finally, we also provide bounds for the asymptotic of the population ratio of any correlation. Given the importance of word overlaps in areas like word combinatorics, bioinformatics, and digital communication, our results may ease analyses of algorithms for string processing, code design, or genome assembly.","sentences":["A correlation is a binary vector that encodes all possible positions of overlaps of two words, where an overlap for an ordered pair of words (u,v) occurs if a suffix of word u matches a prefix of word v. As multiple pairs can have the same correlation, it is relevant to count how many pairs of words share the same correlation depending on the alphabet size and word length n. We exhibit recurrences to compute the number of such pairs -- which is termed population size -- for any correlation; for this, we exploit a relationship between overlaps of two words and self-overlap of one word.","This theorem allows us to compute the number of pairs with a longest overlap of a given length and to show that the expected length of the longest border of two words asymptotically diverges, which solves two open questions raised by Gabric in 2022.","Finally, we also provide bounds for the asymptotic of the population ratio of any correlation.","Given the importance of word overlaps in areas like word combinatorics, bioinformatics, and digital communication, our results may ease analyses of algorithms for string processing, code design, or genome assembly."],"url":"http://arxiv.org/abs/2405.09393v1"}
{"created":"2024-05-15 14:20:37","title":"Diffusion-based Contrastive Learning for Sequential Recommendation","abstract":"Contrastive learning has been effectively applied to alleviate the data sparsity issue and enhance recommendation performance.The majority of existing methods employ random augmentation to generate augmented views of original sequences. The learning objective then aims to minimize the distance between representations of different views for the same user. However, these random augmentation strategies (e.g., mask or substitution) neglect the semantic consistency of different augmented views for the same user, leading to semantically inconsistent sequences with similar representations. Furthermore, most augmentation methods fail to utilize context information, which is critical for understanding sequence semantics. To address these limitations, we introduce a diffusion-based contrastive learning approach for sequential recommendation. Specifically, given a user sequence, we first select some positions and then leverage context information to guide the generation of alternative items via a guided diffusion model. By repeating this approach, we can get semantically consistent augmented views for the same user, which are used to improve the effectiveness of contrastive learning. To maintain cohesion between the representation spaces of both the diffusion model and the recommendation model, we train the entire framework in an end-to-end fashion with shared item embeddings. Extensive experiments on five benchmark datasets demonstrate the superiority of our proposed method.","sentences":["Contrastive learning has been effectively applied to alleviate the data sparsity issue and enhance recommendation performance.","The majority of existing methods employ random augmentation to generate augmented views of original sequences.","The learning objective then aims to minimize the distance between representations of different views for the same user.","However, these random augmentation strategies (e.g., mask or substitution) neglect the semantic consistency of different augmented views for the same user, leading to semantically inconsistent sequences with similar representations.","Furthermore, most augmentation methods fail to utilize context information, which is critical for understanding sequence semantics.","To address these limitations, we introduce a diffusion-based contrastive learning approach for sequential recommendation.","Specifically, given a user sequence, we first select some positions and then leverage context information to guide the generation of alternative items via a guided diffusion model.","By repeating this approach, we can get semantically consistent augmented views for the same user, which are used to improve the effectiveness of contrastive learning.","To maintain cohesion between the representation spaces of both the diffusion model and the recommendation model, we train the entire framework in an end-to-end fashion with shared item embeddings.","Extensive experiments on five benchmark datasets demonstrate the superiority of our proposed method."],"url":"http://arxiv.org/abs/2405.09369v1"}
{"created":"2024-05-15 14:17:44","title":"SARATR-X: A Foundation Model for Synthetic Aperture Radar Images Target Recognition","abstract":"Synthetic aperture radar (SAR) is essential in actively acquiring information for Earth observation. SAR Automatic Target Recognition (ATR) focuses on detecting and classifying various target categories under different image conditions. The current deep learning-based SAR ATR methods are typically designed for specific datasets and applications. Various target characteristics, scene background information, and sensor parameters across ATR datasets challenge the generalization of those methods. This paper aims to achieve general SAR ATR based on a foundation model with Self-Supervised Learning (SSL). Our motivation is to break through the specific dataset and condition limitations and obtain universal perceptual capabilities across the target, scene, and sensor. A foundation model named SARATR-X is proposed with the following four aspects: pre-training dataset, model backbone, SSL, and evaluation task. First, we integrated 14 datasets with various target categories and imaging conditions as a pre-training dataset. Second, different model backbones were discussed to find the most suitable approaches for remote-sensing images. Third, we applied two-stage training and SAR gradient features to ensure the diversity and scalability of SARATR-X. Finally, SARATR-X has achieved competitive and superior performance on 5 datasets with 8 task settings, which shows that the foundation model can achieve universal SAR ATR. We believe it is time to embrace fundamental models for SAR image interpretation in the era of increasing big data.","sentences":["Synthetic aperture radar (SAR) is essential in actively acquiring information for Earth observation.","SAR Automatic Target Recognition (ATR) focuses on detecting and classifying various target categories under different image conditions.","The current deep learning-based SAR ATR methods are typically designed for specific datasets and applications.","Various target characteristics, scene background information, and sensor parameters across ATR datasets challenge the generalization of those methods.","This paper aims to achieve general SAR ATR based on a foundation model with Self-Supervised Learning (SSL).","Our motivation is to break through the specific dataset and condition limitations and obtain universal perceptual capabilities across the target, scene, and sensor.","A foundation model named SARATR-X is proposed with the following four aspects: pre-training dataset, model backbone, SSL, and evaluation task.","First, we integrated 14 datasets with various target categories and imaging conditions as a pre-training dataset.","Second, different model backbones were discussed to find the most suitable approaches for remote-sensing images.","Third, we applied two-stage training and SAR gradient features to ensure the diversity and scalability of SARATR-X. Finally, SARATR-X has achieved competitive and superior performance on 5 datasets with 8 task settings, which shows that the foundation model can achieve universal SAR ATR.","We believe it is time to embrace fundamental models for SAR image interpretation in the era of increasing big data."],"url":"http://arxiv.org/abs/2405.09365v1"}
{"created":"2024-05-15 14:13:35","title":"The Unfairness of $\\varepsilon$-Fairness","abstract":"Fairness in decision-making processes is often quantified using probabilistic metrics. However, these metrics may not fully capture the real-world consequences of unfairness. In this article, we adopt a utility-based approach to more accurately measure the real-world impacts of decision-making process. In particular, we show that if the concept of $\\varepsilon$-fairness is employed, it can possibly lead to outcomes that are maximally unfair in the real-world context. Additionally, we address the common issue of unavailable data on false negatives by proposing a reduced setting that still captures essential fairness considerations. We illustrate our findings with two real-world examples: college admissions and credit risk assessment. Our analysis reveals that while traditional probability-based evaluations might suggest fairness, a utility-based approach uncovers the necessary actions to truly achieve equality. For instance, in the college admission case, we find that enhancing completion rates is crucial for ensuring fairness. Summarizing, this paper highlights the importance of considering the real-world context when evaluating fairness.","sentences":["Fairness in decision-making processes is often quantified using probabilistic metrics.","However, these metrics may not fully capture the real-world consequences of unfairness.","In this article, we adopt a utility-based approach to more accurately measure the real-world impacts of decision-making process.","In particular, we show that if the concept of $\\varepsilon$-fairness is employed, it can possibly lead to outcomes that are maximally unfair in the real-world context.","Additionally, we address the common issue of unavailable data on false negatives by proposing a reduced setting that still captures essential fairness considerations.","We illustrate our findings with two real-world examples: college admissions and credit risk assessment.","Our analysis reveals that while traditional probability-based evaluations might suggest fairness, a utility-based approach uncovers the necessary actions to truly achieve equality.","For instance, in the college admission case, we find that enhancing completion rates is crucial for ensuring fairness.","Summarizing, this paper highlights the importance of considering the real-world context when evaluating fairness."],"url":"http://arxiv.org/abs/2405.09360v1"}
{"created":"2024-05-15 13:45:33","title":"Progressive Depth Decoupling and Modulating for Flexible Depth Completion","abstract":"Image-guided depth completion aims at generating a dense depth map from sparse LiDAR data and RGB image. Recent methods have shown promising performance by reformulating it as a classification problem with two sub-tasks: depth discretization and probability prediction. They divide the depth range into several discrete depth values as depth categories, serving as priors for scene depth distributions. However, previous depth discretization methods are easy to be impacted by depth distribution variations across different scenes, resulting in suboptimal scene depth distribution priors. To address the above problem, we propose a progressive depth decoupling and modulating network, which incrementally decouples the depth range into bins and adaptively generates multi-scale dense depth maps in multiple stages. Specifically, we first design a Bins Initializing Module (BIM) to construct the seed bins by exploring the depth distribution information within a sparse depth map, adapting variations of depth distribution. Then, we devise an incremental depth decoupling branch to progressively refine the depth distribution information from global to local. Meanwhile, an adaptive depth modulating branch is developed to progressively improve the probability representation from coarse-grained to fine-grained. And the bi-directional information interactions are proposed to strengthen the information interaction between those two branches (sub-tasks) for promoting information complementation in each branch. Further, we introduce a multi-scale supervision mechanism to learn the depth distribution information in latent features and enhance the adaptation capability across different scenes. Experimental results on public datasets demonstrate that our method outperforms the state-of-the-art methods. The code will be open-sourced at [this https URL](https://github.com/Cisse-away/PDDM).","sentences":["Image-guided depth completion aims at generating a dense depth map from sparse LiDAR data and RGB image.","Recent methods have shown promising performance by reformulating it as a classification problem with two sub-tasks: depth discretization and probability prediction.","They divide the depth range into several discrete depth values as depth categories, serving as priors for scene depth distributions.","However, previous depth discretization methods are easy to be impacted by depth distribution variations across different scenes, resulting in suboptimal scene depth distribution priors.","To address the above problem, we propose a progressive depth decoupling and modulating network, which incrementally decouples the depth range into bins and adaptively generates multi-scale dense depth maps in multiple stages.","Specifically, we first design a Bins Initializing Module (BIM) to construct the seed bins by exploring the depth distribution information within a sparse depth map, adapting variations of depth distribution.","Then, we devise an incremental depth decoupling branch to progressively refine the depth distribution information from global to local.","Meanwhile, an adaptive depth modulating branch is developed to progressively improve the probability representation from coarse-grained to fine-grained.","And the bi-directional information interactions are proposed to strengthen the information interaction between those two branches (sub-tasks) for promoting information complementation in each branch.","Further, we introduce a multi-scale supervision mechanism to learn the depth distribution information in latent features and enhance the adaptation capability across different scenes.","Experimental results on public datasets demonstrate that our method outperforms the state-of-the-art methods.","The code will be open-sourced at [this https URL](https://github.com/Cisse-away/PDDM)."],"url":"http://arxiv.org/abs/2405.09342v1"}
{"created":"2024-05-15 13:41:54","title":"Interval Selection in Sliding Windows","abstract":"We initiate the study of the Interval Selection problem in the (streaming) sliding window model of computation.   In this problem, an algorithm receives a potentially infinite stream of intervals on the line, and the objective is to maintain at every moment an approximation to a largest possible subset of disjoint intervals among the $L$ most recent intervals, for some integer $L$.   We give the following results:   - In the unit-length intervals case, we give a $2$-approximation sliding window algorithm with space $\\tilde{\\mathrm{O}}(|OPT|)$, and we show that any sliding window algorithm that computes a $(2-\\varepsilon)$-approximation requires space $\\Omega(L)$, for any $\\varepsilon > 0$.   - In the arbitrary-length case, we give a $(\\frac{11}{3}+\\varepsilon)$-approximation sliding window algorithm with space $\\tilde{\\mathrm{O}}(|OPT|)$, for any constant $\\varepsilon > 0$, which constitutes our main result.   We also show that space $\\Omega(L)$ is needed for algorithms that compute a $(2.5-\\varepsilon)$-approximation, for any $\\varepsilon > 0$.   Our main technical contribution is an improvement over the smooth histogram technique, which consists of running independent copies of a traditional streaming algorithm with different start times. By employing the one-pass $2$-approximation streaming algorithm by Cabello and P\\'{e}rez-Lantero [Theor. Comput. Sci. '17] for \\textsf{Interval Selection} on arbitrary-length intervals as the underlying algorithm, the smooth histogram technique immediately yields a $(4+\\varepsilon)$-approximation in this setting. Our improvement is obtained by forwarding the structure of the intervals identified in a run to the subsequent run, which constrains the shape of an optimal solution and allows us to target optimal intervals differently.","sentences":["We initiate the study of the Interval Selection problem in the (streaming) sliding window model of computation.   ","In this problem, an algorithm receives a potentially infinite stream of intervals on the line, and the objective is to maintain at every moment an approximation to a largest possible subset of disjoint intervals among the $L$ most recent intervals, for some integer $L$.   ","We give the following results:   -","In the unit-length intervals case, we give a $2$-approximation sliding window algorithm with space $\\tilde{\\mathrm{O}}(|OPT|)$, and we show that any sliding window algorithm that computes a $(2-\\varepsilon)$-approximation requires space $\\Omega(L)$, for any $\\varepsilon > 0$.   -","In the arbitrary-length case, we give a $(\\frac{11}{3}+\\varepsilon)$-approximation sliding window algorithm with space $\\tilde{\\mathrm{O}}(|OPT|)$, for any constant $\\varepsilon > 0$, which constitutes our main result.   ","We also show that space $\\Omega(L)$ is needed for algorithms that compute a $(2.5-\\varepsilon)$-approximation, for any $\\varepsilon > 0$.   Our main technical contribution is an improvement over the smooth histogram technique, which consists of running independent copies of a traditional streaming algorithm with different start times.","By employing the one-pass $2$-approximation streaming algorithm by Cabello and P\\'{e}rez-Lantero [Theor.","Comput.","Sci. '17] for \\textsf{Interval Selection} on arbitrary-length intervals as the underlying algorithm, the smooth histogram technique immediately yields a $(4+\\varepsilon)$-approximation in this setting.","Our improvement is obtained by forwarding the structure of the intervals identified in a run to the subsequent run, which constrains the shape of an optimal solution and allows us to target optimal intervals differently."],"url":"http://arxiv.org/abs/2405.09338v1"}
{"created":"2024-05-15 13:36:43","title":"Prompting-based Synthetic Data Generation for Few-Shot Question Answering","abstract":"Although language models (LMs) have boosted the performance of Question Answering, they still need plenty of data. Data annotation, in contrast, is a time-consuming process. This especially applies to Question Answering, where possibly large documents have to be parsed and annotated with questions and their corresponding answers. Furthermore, Question Answering models often only work well for the domain they were trained on. Since annotation is costly, we argue that domain-agnostic knowledge from LMs, such as linguistic understanding, is sufficient to create a well-curated dataset. With this motivation, we show that using large language models can improve Question Answering performance on various datasets in the few-shot setting compared to state-of-the-art approaches. For this, we perform data generation leveraging the Prompting framework, suggesting that language models contain valuable task-agnostic knowledge that can be used beyond the common pre-training/fine-tuning scheme. As a result, we consistently outperform previous approaches on few-shot Question Answering.","sentences":["Although language models (LMs) have boosted the performance of Question Answering, they still need plenty of data.","Data annotation, in contrast, is a time-consuming process.","This especially applies to Question Answering, where possibly large documents have to be parsed and annotated with questions and their corresponding answers.","Furthermore, Question Answering models often only work well for the domain they were trained on.","Since annotation is costly, we argue that domain-agnostic knowledge from LMs, such as linguistic understanding, is sufficient to create a well-curated dataset.","With this motivation, we show that using large language models can improve Question Answering performance on various datasets in the few-shot setting compared to state-of-the-art approaches.","For this, we perform data generation leveraging the Prompting framework, suggesting that language models contain valuable task-agnostic knowledge that can be used beyond the common pre-training/fine-tuning scheme.","As a result, we consistently outperform previous approaches on few-shot Question Answering."],"url":"http://arxiv.org/abs/2405.09335v1"}
{"created":"2024-05-15 13:33:23","title":"Application of Gated Recurrent Units for CT Trajectory Optimization","abstract":"Recent advances in computed tomography (CT) imaging, especially with dual-robot systems, have introduced new challenges for scan trajectory optimization. This paper presents a novel approach using Gated Recurrent Units (GRUs) to optimize CT scan trajectories. Our approach exploits the flexibility of robotic CT systems to select projections that enhance image quality by improving resolution and contrast while reducing scan time. We focus on cone-beam CT and employ several projection-based metrics, including absorption, pixel intensities, contrast-to-noise ratio, and data completeness. The GRU network aims to minimize data redundancy and maximize completeness with a limited number of projections. We validate our method using simulated data of a test specimen, focusing on a specific voxel of interest. The results show that the GRU-optimized scan trajectories can outperform traditional circular CT trajectories in terms of image quality metrics. For the used specimen, SSIM improves from 0.38 to 0.49 and CNR increases from 6.97 to 9.08. This finding suggests that the application of GRU in CT scan trajectory optimization can lead to more efficient, cost-effective, and high-quality imaging solutions.","sentences":["Recent advances in computed tomography (CT) imaging, especially with dual-robot systems, have introduced new challenges for scan trajectory optimization.","This paper presents a novel approach using Gated Recurrent Units (GRUs) to optimize CT scan trajectories.","Our approach exploits the flexibility of robotic CT systems to select projections that enhance image quality by improving resolution and contrast while reducing scan time.","We focus on cone-beam CT and employ several projection-based metrics, including absorption, pixel intensities, contrast-to-noise ratio, and data completeness.","The GRU network aims to minimize data redundancy and maximize completeness with a limited number of projections.","We validate our method using simulated data of a test specimen, focusing on a specific voxel of interest.","The results show that the GRU-optimized scan trajectories can outperform traditional circular CT trajectories in terms of image quality metrics.","For the used specimen, SSIM improves from 0.38 to 0.49 and CNR increases from 6.97 to 9.08.","This finding suggests that the application of GRU in CT scan trajectory optimization can lead to more efficient, cost-effective, and high-quality imaging solutions."],"url":"http://arxiv.org/abs/2405.09333v1"}
{"created":"2024-05-15 13:32:59","title":"BARO: Robust Root Cause Analysis for Microservices via Multivariate Bayesian Online Change Point Detection","abstract":"Detecting failures and identifying their root causes promptly and accurately is crucial for ensuring the availability of microservice systems. A typical failure troubleshooting pipeline for microservices consists of two phases: anomaly detection and root cause analysis. While various existing works on root cause analysis require accurate anomaly detection, there is no guarantee of accurate estimation with anomaly detection techniques. Inaccurate anomaly detection results can significantly affect the root cause localization results. To address this challenge, we propose BARO, an end-to-end approach that integrates anomaly detection and root cause analysis for effectively troubleshooting failures in microservice systems. BARO leverages the Multivariate Bayesian Online Change Point Detection technique to model the dependency within multivariate time-series metrics data, enabling it to detect anomalies more accurately. BARO also incorporates a novel nonparametric statistical hypothesis testing technique for robustly identifying root causes, which is less sensitive to the accuracy of anomaly detection compared to existing works. Our comprehensive experiments conducted on three popular benchmark microservice systems demonstrate that BARO consistently outperforms state-of-the-art approaches in both anomaly detection and root cause analysis.","sentences":["Detecting failures and identifying their root causes promptly and accurately is crucial for ensuring the availability of microservice systems.","A typical failure troubleshooting pipeline for microservices consists of two phases: anomaly detection and root cause analysis.","While various existing works on root cause analysis require accurate anomaly detection, there is no guarantee of accurate estimation with anomaly detection techniques.","Inaccurate anomaly detection results can significantly affect the root cause localization results.","To address this challenge, we propose BARO, an end-to-end approach that integrates anomaly detection and root cause analysis for effectively troubleshooting failures in microservice systems.","BARO leverages the Multivariate Bayesian Online Change Point Detection technique to model the dependency within multivariate time-series metrics data, enabling it to detect anomalies more accurately.","BARO also incorporates a novel nonparametric statistical hypothesis testing technique for robustly identifying root causes, which is less sensitive to the accuracy of anomaly detection compared to existing works.","Our comprehensive experiments conducted on three popular benchmark microservice systems demonstrate that BARO consistently outperforms state-of-the-art approaches in both anomaly detection and root cause analysis."],"url":"http://arxiv.org/abs/2405.09330v1"}
{"created":"2024-05-15 13:19:43","title":"Transfer Learning in Pre-Trained Large Language Models for Malware Detection Based on System Calls","abstract":"In the current cybersecurity landscape, protecting military devices such as communication and battlefield management systems against sophisticated cyber attacks is crucial. Malware exploits vulnerabilities through stealth methods, often evading traditional detection mechanisms such as software signatures. The application of ML/DL in vulnerability detection has been extensively explored in the literature. However, current ML/DL vulnerability detection methods struggle with understanding the context and intent behind complex attacks. Integrating large language models (LLMs) with system call analysis offers a promising approach to enhance malware detection. This work presents a novel framework leveraging LLMs to classify malware based on system call data. The framework uses transfer learning to adapt pre-trained LLMs for malware detection. By retraining LLMs on a dataset of benign and malicious system calls, the models are refined to detect signs of malware activity. Experiments with a dataset of over 1TB of system calls demonstrate that models with larger context sizes, such as BigBird and Longformer, achieve superior accuracy and F1-Score of approximately 0.86. The results highlight the importance of context size in improving detection rates and underscore the trade-offs between computational complexity and performance. This approach shows significant potential for real-time detection in high-stakes environments, offering a robust solution to evolving cyber threats.","sentences":["In the current cybersecurity landscape, protecting military devices such as communication and battlefield management systems against sophisticated cyber attacks is crucial.","Malware exploits vulnerabilities through stealth methods, often evading traditional detection mechanisms such as software signatures.","The application of ML/DL in vulnerability detection has been extensively explored in the literature.","However, current ML/DL vulnerability detection methods struggle with understanding the context and intent behind complex attacks.","Integrating large language models (LLMs) with system call analysis offers a promising approach to enhance malware detection.","This work presents a novel framework leveraging LLMs to classify malware based on system call data.","The framework uses transfer learning to adapt pre-trained LLMs for malware detection.","By retraining LLMs on a dataset of benign and malicious system calls, the models are refined to detect signs of malware activity.","Experiments with a dataset of over 1TB of system calls demonstrate that models with larger context sizes, such as BigBird and Longformer, achieve superior accuracy and F1-Score of approximately 0.86.","The results highlight the importance of context size in improving detection rates and underscore the trade-offs between computational complexity and performance.","This approach shows significant potential for real-time detection in high-stakes environments, offering a robust solution to evolving cyber threats."],"url":"http://arxiv.org/abs/2405.09318v1"}
{"created":"2024-05-15 13:14:05","title":"Themis: Automatic and Efficient Deep Learning System Testing with Strong Fault Detection Capability","abstract":"Deep Learning Systems (DLSs) have been widely applied in safety-critical tasks such as autopilot. However, when a perturbed input is fed into a DLS for inference, the DLS often has incorrect outputs (i.e., faults). DLS testing techniques (e.g., DeepXplore) detect such faults by generating perturbed inputs to explore data flows that induce faults. Since a DLS often has infinitely many data flows, existing techniques require developers to manually specify a set of activation values in a DLS's neurons for exploring fault-inducing data flows. Unfortunately, recent studies show that such manual effort is tedious and can detect only a tiny proportion of fault-inducing data flows.   In this paper, we present Themis, the first automatic DLS testing system, which attains strong fault detection capability by ensuring a full coverage of fault-inducing data flows at a high probability. Themis carries a new workflow for automatically and systematically revealing data flows whose internal neurons' outputs vary substantially when the inputs are slightly perturbed, as these data flows are likely fault-inducing. We evaluated Themis on ten different DLSs and found that on average the number of faults detected by Themis was 3.78X more than four notable DLS testing techniques. By retraining all evaluated DLSs with the detected faults, Themis also increased (regained) these DLSs' accuracies on average 14.7X higher than all baselines.","sentences":["Deep Learning Systems (DLSs) have been widely applied in safety-critical tasks such as autopilot.","However, when a perturbed input is fed into a DLS for inference, the DLS often has incorrect outputs (i.e., faults).","DLS testing techniques (e.g., DeepXplore) detect such faults by generating perturbed inputs to explore data flows that induce faults.","Since a DLS often has infinitely many data flows, existing techniques require developers to manually specify a set of activation values in a DLS's neurons for exploring fault-inducing data flows.","Unfortunately, recent studies show that such manual effort is tedious and can detect only a tiny proportion of fault-inducing data flows.   ","In this paper, we present Themis, the first automatic DLS testing system, which attains strong fault detection capability by ensuring a full coverage of fault-inducing data flows at a high probability.","Themis carries a new workflow for automatically and systematically revealing data flows whose internal neurons' outputs vary substantially when the inputs are slightly perturbed, as these data flows are likely fault-inducing.","We evaluated Themis on ten different DLSs and found that on average the number of faults detected by Themis was 3.78X more than four notable DLS testing techniques.","By retraining all evaluated DLSs with the detected faults, Themis also increased (regained) these DLSs' accuracies on average 14.7X higher than all baselines."],"url":"http://arxiv.org/abs/2405.09314v1"}
{"created":"2024-05-15 13:11:28","title":"Agnostic Active Learning of Single Index Models with Linear Sample Complexity","abstract":"We study active learning methods for single index models of the form $F({\\mathbf x}) = f(\\langle {\\mathbf w}, {\\mathbf x}\\rangle)$, where $f:\\mathbb{R} \\to \\mathbb{R}$ and ${\\mathbf x,\\mathbf w} \\in \\mathbb{R}^d$. In addition to their theoretical interest as simple examples of non-linear neural networks, single index models have received significant recent attention due to applications in scientific machine learning like surrogate modeling for partial differential equations (PDEs). Such applications require sample-efficient active learning methods that are robust to adversarial noise. I.e., that work even in the challenging agnostic learning setting.   We provide two main results on agnostic active learning of single index models. First, when $f$ is known and Lipschitz, we show that $\\tilde{O}(d)$ samples collected via {statistical leverage score sampling} are sufficient to learn a near-optimal single index model. Leverage score sampling is simple to implement, efficient, and already widely used for actively learning linear models. Our result requires no assumptions on the data distribution, is optimal up to log factors, and improves quadratically on a recent ${O}(d^{2})$ bound of \\cite{gajjar2023active}. Second, we show that $\\tilde{O}(d)$ samples suffice even in the more difficult setting when $f$ is \\emph{unknown}. Our results leverage tools from high dimensional probability, including Dudley's inequality and dual Sudakov minoration, as well as a novel, distribution-aware discretization of the class of Lipschitz functions.","sentences":["We study active learning methods for single index models of the form $F({\\mathbf x})","= f(\\langle {\\mathbf w}, {\\mathbf x}\\rangle)$, where $f:\\mathbb{R} \\to \\mathbb{R}$ and ${\\mathbf x,\\mathbf w} \\in \\mathbb{R}^d$.","In addition to their theoretical interest as simple examples of non-linear neural networks, single index models have received significant recent attention due to applications in scientific machine learning like surrogate modeling for partial differential equations (PDEs).","Such applications require sample-efficient active learning methods that are robust to adversarial noise.","I.e., that work even in the challenging agnostic learning setting.   ","We provide two main results on agnostic active learning of single index models.","First, when $f$ is known and Lipschitz, we show that $\\tilde{O}(d)$ samples collected via {statistical leverage score sampling} are sufficient to learn a near-optimal single index model.","Leverage score sampling is simple to implement, efficient, and already widely used for actively learning linear models.","Our result requires no assumptions on the data distribution, is optimal up to log factors, and improves quadratically on a recent ${O}(d^{2})$ bound of \\cite{gajjar2023active}.","Second, we show that $\\tilde{O}(d)$ samples suffice even in the more difficult setting when $f$ is \\emph{unknown}.","Our results leverage tools from high dimensional probability, including Dudley's inequality and dual Sudakov minoration, as well as a novel, distribution-aware discretization of the class of Lipschitz functions."],"url":"http://arxiv.org/abs/2405.09312v1"}
{"created":"2024-05-15 13:03:41","title":"TimeX++: Learning Time-Series Explanations with Information Bottleneck","abstract":"Explaining deep learning models operating on time series data is crucial in various applications of interest which require interpretable and transparent insights from time series signals. In this work, we investigate this problem from an information theoretic perspective and show that most existing measures of explainability may suffer from trivial solutions and distributional shift issues. To address these issues, we introduce a simple yet practical objective function for time series explainable learning. The design of the objective function builds upon the principle of information bottleneck (IB), and modifies the IB objective function to avoid trivial solutions and distributional shift issues. We further present TimeX++, a novel explanation framework that leverages a parametric network to produce explanation-embedded instances that are both in-distributed and label-preserving. We evaluate TimeX++ on both synthetic and real-world datasets comparing its performance against leading baselines, and validate its practical efficacy through case studies in a real-world environmental application. Quantitative and qualitative evaluations show that TimeX++ outperforms baselines across all datasets, demonstrating a substantial improvement in explanation quality for time series data. The source code is available at \\url{https://github.com/zichuan-liu/TimeXplusplus}.","sentences":["Explaining deep learning models operating on time series data is crucial in various applications of interest which require interpretable and transparent insights from time series signals.","In this work, we investigate this problem from an information theoretic perspective and show that most existing measures of explainability may suffer from trivial solutions and distributional shift issues.","To address these issues, we introduce a simple yet practical objective function for time series explainable learning.","The design of the objective function builds upon the principle of information bottleneck (IB), and modifies the IB objective function to avoid trivial solutions and distributional shift issues.","We further present TimeX++, a novel explanation framework that leverages a parametric network to produce explanation-embedded instances that are both in-distributed and label-preserving.","We evaluate TimeX++ on both synthetic and real-world datasets comparing its performance against leading baselines, and validate its practical efficacy through case studies in a real-world environmental application.","Quantitative and qualitative evaluations show that TimeX++ outperforms baselines across all datasets, demonstrating a substantial improvement in explanation quality for time series data.","The source code is available at \\url{https://github.com/zichuan-liu/TimeXplusplus}."],"url":"http://arxiv.org/abs/2405.09308v1"}
{"created":"2024-05-15 12:49:57","title":"Gradient Boosted Filters For Signal Processing","abstract":"Gradient boosted decision trees have achieved remarkable success in several domains, particularly those that work with static tabular data. However, the application of gradient boosted models to signal processing is underexplored. In this work, we introduce gradient boosted filters for dynamic data, by employing Hammerstein systems in place of decision trees. We discuss the relationship of our approach to the Volterra series, providing the theoretical underpinning for its application. We demonstrate the effective generalizability of our approach with examples.","sentences":["Gradient boosted decision trees have achieved remarkable success in several domains, particularly those that work with static tabular data.","However, the application of gradient boosted models to signal processing is underexplored.","In this work, we introduce gradient boosted filters for dynamic data, by employing Hammerstein systems in place of decision trees.","We discuss the relationship of our approach to the Volterra series, providing the theoretical underpinning for its application.","We demonstrate the effective generalizability of our approach with examples."],"url":"http://arxiv.org/abs/2405.09305v1"}
{"created":"2024-05-15 12:11:28","title":"MVBIND: Self-Supervised Music Recommendation For Videos Via Embedding Space Binding","abstract":"Recent years have witnessed the rapid development of short videos, which usually contain both visual and audio modalities. Background music is important to the short videos, which can significantly influence the emotions of the viewers. However, at present, the background music of short videos is generally chosen by the video producer, and there is a lack of automatic music recommendation methods for short videos. This paper introduces MVBind, an innovative Music-Video embedding space Binding model for cross-modal retrieval. MVBind operates as a self-supervised approach, acquiring inherent knowledge of intermodal relationships directly from data, without the need of manual annotations. Additionally, to compensate the lack of a corresponding musical-visual pair dataset for short videos, we construct a dataset, SVM-10K(Short Video with Music-10K), which mainly consists of meticulously selected short videos. On this dataset, MVBind manifests significantly improved performance compared to other baseline methods. The constructed dataset and code will be released to facilitate future research.","sentences":["Recent years have witnessed the rapid development of short videos, which usually contain both visual and audio modalities.","Background music is important to the short videos, which can significantly influence the emotions of the viewers.","However, at present, the background music of short videos is generally chosen by the video producer, and there is a lack of automatic music recommendation methods for short videos.","This paper introduces MVBind, an innovative Music-Video embedding space Binding model for cross-modal retrieval.","MVBind operates as a self-supervised approach, acquiring inherent knowledge of intermodal relationships directly from data, without the need of manual annotations.","Additionally, to compensate the lack of a corresponding musical-visual pair dataset for short videos, we construct a dataset, SVM-10K(Short Video with Music-10K), which mainly consists of meticulously selected short videos.","On this dataset, MVBind manifests significantly improved performance compared to other baseline methods.","The constructed dataset and code will be released to facilitate future research."],"url":"http://arxiv.org/abs/2405.09286v1"}
{"created":"2024-05-15 12:03:28","title":"Localized Attractor Computations for Infinite-State Games (Full Version)","abstract":"Infinite-state games are a commonly used model for the synthesis of reactive systems with unbounded data domains. Symbolic methods for solving such games need to be able to construct intricate arguments to establish the existence of winning strategies. Often, large problem instances require prohibitively complex arguments. Therefore, techniques that identify smaller and simpler sub-problems and exploit the respective results for the given game-solving task are highly desirable. In this paper, we propose the first such technique for infinite-state games. The main idea is to enhance symbolic game-solving with the results of localized attractor computations performed in sub-games. The crux of our approach lies in identifying useful sub-games by computing permissive winning strategy templates in finite abstractions of the infinite-state game. The experimental evaluation of our method demonstrates that it outperforms existing techniques and is applicable to infinite-state games beyond the state of the art.","sentences":["Infinite-state games are a commonly used model for the synthesis of reactive systems with unbounded data domains.","Symbolic methods for solving such games need to be able to construct intricate arguments to establish the existence of winning strategies.","Often, large problem instances require prohibitively complex arguments.","Therefore, techniques that identify smaller and simpler sub-problems and exploit the respective results for the given game-solving task are highly desirable.","In this paper, we propose the first such technique for infinite-state games.","The main idea is to enhance symbolic game-solving with the results of localized attractor computations performed in sub-games.","The crux of our approach lies in identifying useful sub-games by computing permissive winning strategy templates in finite abstractions of the infinite-state game.","The experimental evaluation of our method demonstrates that it outperforms existing techniques and is applicable to infinite-state games beyond the state of the art."],"url":"http://arxiv.org/abs/2405.09281v1"}
{"created":"2024-05-15 11:46:47","title":"Dual-Segment Clustering Strategy for Federated Learning in Heterogeneous Environments","abstract":"Federated learning (FL) is a distributed machine learning paradigm with high efficiency and low communication load, only transmitting parameters or gradients of network. However, the non-independent and identically distributed (Non-IID) data characteristic has a negative impact on this paradigm. Furthermore, the heterogeneity of communication quality will significantly affect the accuracy of parameter transmission, causing a degradation in the performance of the FL system or even preventing its convergence. This letter proposes a dual-segment clustering (DSC) strategy, which first clusters the clients according to the heterogeneous communication conditions and then performs a second clustering by the sample size and label distribution, so as to solve the problem of data and communication heterogeneity. Experimental results show that the DSC strategy proposed in this letter can improve the convergence rate of FL, and has superiority on accuracy in a heterogeneous environment compared with the classical algorithm of cluster.","sentences":["Federated learning (FL) is a distributed machine learning paradigm with high efficiency and low communication load, only transmitting parameters or gradients of network.","However, the non-independent and identically distributed (Non-IID) data characteristic has a negative impact on this paradigm.","Furthermore, the heterogeneity of communication quality will significantly affect the accuracy of parameter transmission, causing a degradation in the performance of the FL system or even preventing its convergence.","This letter proposes a dual-segment clustering (DSC) strategy, which first clusters the clients according to the heterogeneous communication conditions and then performs a second clustering by the sample size and label distribution, so as to solve the problem of data and communication heterogeneity.","Experimental results show that the DSC strategy proposed in this letter can improve the convergence rate of FL, and has superiority on accuracy in a heterogeneous environment compared with the classical algorithm of cluster."],"url":"http://arxiv.org/abs/2405.09276v1"}
{"created":"2024-05-15 11:42:41","title":"Fair Generalized Linear Mixed Models","abstract":"When using machine learning for automated prediction, it is important to account for fairness in the prediction. Fairness in machine learning aims to ensure that biases in the data and model inaccuracies do not lead to discriminatory decisions. E.g., predictions from fair machine learning models should not discriminate against sensitive variables such as sexual orientation and ethnicity. The training data often in obtained from social surveys. In social surveys, oftentimes the data collection process is a strata sampling, e.g. due to cost restrictions. In strata samples, the assumption of independence between the observation is not fulfilled. Hence, if the machine learning models do not account for the strata correlations, the results may be biased. Especially high is the bias in cases where the strata assignment is correlated to the variable of interest. We present in this paper an algorithm that can handle both problems simultaneously, and we demonstrate the impact of stratified sampling on the quality of fair machine learning predictions in a reproducible simulation study.","sentences":["When using machine learning for automated prediction, it is important to account for fairness in the prediction.","Fairness in machine learning aims to ensure that biases in the data and model inaccuracies do not lead to discriminatory decisions.","E.g., predictions from fair machine learning models should not discriminate against sensitive variables such as sexual orientation and ethnicity.","The training data often in obtained from social surveys.","In social surveys, oftentimes the data collection process is a strata sampling, e.g. due to cost restrictions.","In strata samples, the assumption of independence between the observation is not fulfilled.","Hence, if the machine learning models do not account for the strata correlations, the results may be biased.","Especially high is the bias in cases where the strata assignment is correlated to the variable of interest.","We present in this paper an algorithm that can handle both problems simultaneously, and we demonstrate the impact of stratified sampling on the quality of fair machine learning predictions in a reproducible simulation study."],"url":"http://arxiv.org/abs/2405.09273v1"}
{"created":"2024-05-15 11:33:07","title":"Dance Any Beat: Blending Beats with Visuals in Dance Video Generation","abstract":"The task of generating dance from music is crucial, yet current methods, which mainly produce joint sequences, lead to outputs that lack intuitiveness and complicate data collection due to the necessity for precise joint annotations. We introduce a Dance Any Beat Diffusion model, namely DabFusion, that employs music as a conditional input to directly create dance videos from still images, utilizing conditional image-to-video generation principles. This approach pioneers the use of music as a conditioning factor in image-to-video synthesis. Our method unfolds in two stages: training an auto-encoder to predict latent optical flow between reference and driving frames, eliminating the need for joint annotation, and training a U-Net-based diffusion model to produce these latent optical flows guided by music rhythm encoded by CLAP. Although capable of producing high-quality dance videos, the baseline model struggles with rhythm alignment. We enhance the model by adding beat information, improving synchronization. We introduce a 2D motion-music alignment score (2D-MM Align) for quantitative assessment. Evaluated on the AIST++ dataset, our enhanced model shows marked improvements in 2D-MM Align score and established metrics. Video results can be found on our project page: https://DabFusion.github.io.","sentences":["The task of generating dance from music is crucial, yet current methods, which mainly produce joint sequences, lead to outputs that lack intuitiveness and complicate data collection due to the necessity for precise joint annotations.","We introduce a Dance Any Beat Diffusion model, namely DabFusion, that employs music as a conditional input to directly create dance videos from still images, utilizing conditional image-to-video generation principles.","This approach pioneers the use of music as a conditioning factor in image-to-video synthesis.","Our method unfolds in two stages: training an auto-encoder to predict latent optical flow between reference and driving frames, eliminating the need for joint annotation, and training a U-Net-based diffusion model to produce these latent optical flows guided by music rhythm encoded by CLAP.","Although capable of producing high-quality dance videos, the baseline model struggles with rhythm alignment.","We enhance the model by adding beat information, improving synchronization.","We introduce a 2D motion-music alignment score (2D-MM Align) for quantitative assessment.","Evaluated on the AIST++ dataset, our enhanced model shows marked improvements in 2D-MM Align score and established metrics.","Video results can be found on our project page: https://DabFusion.github.io."],"url":"http://arxiv.org/abs/2405.09266v1"}
{"created":"2024-05-15 11:28:49","title":"Quantum Computing Education for Computer Science Students: Bridging the Gap with Layered Learning and Intuitive Analogies","abstract":"Quantum computing presents a transformative potential for the world of computing. However, integrating this technology into the curriculum for computer science students who lack prior exposure to quantum mechanics and advanced mathematics remains a challenging task. This paper proposes a scaffolded learning approach aimed at equipping computer science students with essential quantum principles. By introducing foundational quantum concepts through relatable analogies and a layered learning approach based on classical computation, this approach seeks to bridge the gap between classical and quantum computing. This differs from previous approaches which build quantum computing fundamentals from the prerequisite of linear algebra and mathematics. The paper offers a considered set of intuitive analogies for foundation quantum concepts including entanglement, superposition, quantum data structures and quantum algorithms. These analogies coupled with a computing-based layered learning approach, lay the groundwork for a comprehensive teaching methodology tailored for undergraduate third level computer science students.","sentences":["Quantum computing presents a transformative potential for the world of computing.","However, integrating this technology into the curriculum for computer science students who lack prior exposure to quantum mechanics and advanced mathematics remains a challenging task.","This paper proposes a scaffolded learning approach aimed at equipping computer science students with essential quantum principles.","By introducing foundational quantum concepts through relatable analogies and a layered learning approach based on classical computation, this approach seeks to bridge the gap between classical and quantum computing.","This differs from previous approaches which build quantum computing fundamentals from the prerequisite of linear algebra and mathematics.","The paper offers a considered set of intuitive analogies for foundation quantum concepts including entanglement, superposition, quantum data structures and quantum algorithms.","These analogies coupled with a computing-based layered learning approach, lay the groundwork for a comprehensive teaching methodology tailored for undergraduate third level computer science students."],"url":"http://arxiv.org/abs/2405.09265v1"}
{"created":"2024-05-15 11:27:28","title":"A Quantum of QUIC: Dissecting Cryptography with Post-Quantum Insights","abstract":"QUIC is a new network protocol standardized in 2021. It was designed to replace the TCP/TLS stack and is based on UDP. The most current web standard HTTP/3 is specifically designed to use QUIC as transport protocol. QUIC claims to provide secure and fast transport with low-latency connection establishment, flow and congestion control, reliable delivery, and stream multiplexing. To achieve the security goals, QUIC enforces the usage of TLS 1.3. It uses authenticated encryption with additional data (AEAD) algorithms to not only protect the payload but also parts of the header. The handshake relies on asymmetric cryptography, which will be broken with the introduction of powerful quantum computers, making the use of post-quantum cryptography inevitable. This paper presents a detailed evaluation of the impact of cryptography on QUIC performance. The high-performance QUIC implementations LSQUIC, quiche, and MsQuic are evaluated under different aspects. We break symmetric cryptography down to the different security features. To be able to isolate the impact of cryptography, we implemented a NOOP AEAD algorithm which leaves plaintext unaltered. We show that QUIC performance increases by 10 to 20% when removing packet protection. The header protection has negligible impact on performance, especially for AES ciphers. We integrate post-quantum cryptographic algorithms into QUIC, demonstrating its feasibility without major changes to the QUIC libraries by using a TLS library that implements post-quantum algorithms. Kyber, Dilithium, and FALCON are promising candidates for post-quantum secure QUIC, as they have a low impact on the handshake duration. Algorithms like SPHINCS+ with larger key sizes or more complex calculations significantly impact the handshake duration and cause additional issues in our measurements.","sentences":["QUIC is a new network protocol standardized in 2021.","It was designed to replace the TCP/TLS stack and is based on UDP.","The most current web standard HTTP/3 is specifically designed to use QUIC as transport protocol.","QUIC claims to provide secure and fast transport with low-latency connection establishment, flow and congestion control, reliable delivery, and stream multiplexing.","To achieve the security goals, QUIC enforces the usage of TLS 1.3.","It uses authenticated encryption with additional data (AEAD) algorithms to not only protect the payload but also parts of the header.","The handshake relies on asymmetric cryptography, which will be broken with the introduction of powerful quantum computers, making the use of post-quantum cryptography inevitable.","This paper presents a detailed evaluation of the impact of cryptography on QUIC performance.","The high-performance QUIC implementations LSQUIC, quiche, and MsQuic are evaluated under different aspects.","We break symmetric cryptography down to the different security features.","To be able to isolate the impact of cryptography, we implemented a NOOP AEAD algorithm which leaves plaintext unaltered.","We show that QUIC performance increases by 10 to 20% when removing packet protection.","The header protection has negligible impact on performance, especially for AES ciphers.","We integrate post-quantum cryptographic algorithms into QUIC, demonstrating its feasibility without major changes to the QUIC libraries by using a TLS library that implements post-quantum algorithms.","Kyber, Dilithium, and FALCON are promising candidates for post-quantum secure QUIC, as they have a low impact on the handshake duration.","Algorithms like SPHINCS+ with larger key sizes or more complex calculations significantly impact the handshake duration and cause additional issues in our measurements."],"url":"http://arxiv.org/abs/2405.09264v1"}
{"created":"2024-05-15 10:04:44","title":"Perception-Inspired Graph Convolution for Music Understanding Tasks","abstract":"We propose a new graph convolutional block, called MusGConv, specifically designed for the efficient processing of musical score data and motivated by general perceptual principles. It focuses on two fundamental dimensions of music, pitch and rhythm, and considers both relative and absolute representations of these components. We evaluate our approach on four different musical understanding problems: monophonic voice separation, harmonic analysis, cadence detection, and composer identification which, in abstract terms, translate to different graph learning problems, namely, node classification, link prediction, and graph classification. Our experiments demonstrate that MusGConv improves the performance on three of the aforementioned tasks while being conceptually very simple and efficient. We interpret this as evidence that it is beneficial to include perception-informed processing of fundamental musical concepts when developing graph network applications on musical score data.","sentences":["We propose a new graph convolutional block, called MusGConv, specifically designed for the efficient processing of musical score data and motivated by general perceptual principles.","It focuses on two fundamental dimensions of music, pitch and rhythm, and considers both relative and absolute representations of these components.","We evaluate our approach on four different musical understanding problems: monophonic voice separation, harmonic analysis, cadence detection, and composer identification which, in abstract terms, translate to different graph learning problems, namely, node classification, link prediction, and graph classification.","Our experiments demonstrate that MusGConv improves the performance on three of the aforementioned tasks while being conceptually very simple and efficient.","We interpret this as evidence that it is beneficial to include perception-informed processing of fundamental musical concepts when developing graph network applications on musical score data."],"url":"http://arxiv.org/abs/2405.09224v1"}
{"created":"2024-05-15 10:04:19","title":"Word Alignment as Preference for Machine Translation","abstract":"The problem of hallucination and omission, a long-standing problem in machine translation (MT), is more pronounced when a large language model (LLM) is used in MT because an LLM itself is susceptible to these phenomena. In this work, we mitigate the problem in an LLM-based MT model by guiding it to better word alignment. We first study the correlation between word alignment and the phenomena of hallucination and omission in MT. Then we propose to utilize word alignment as preference to optimize the LLM-based MT model. The preference data are constructed by selecting chosen and rejected translations from multiple MT tools. Subsequently, direct preference optimization is used to optimize the LLM-based model towards the preference signal. Given the absence of evaluators specifically designed for hallucination and omission in MT, we further propose selecting hard instances and utilizing GPT-4 to directly evaluate the performance of the models in mitigating these issues. We verify the rationality of these designed evaluation methods by experiments, followed by extensive results demonstrating the effectiveness of word alignment-based preference optimization to mitigate hallucination and omission.","sentences":["The problem of hallucination and omission, a long-standing problem in machine translation (MT), is more pronounced when a large language model (LLM) is used in MT because an LLM itself is susceptible to these phenomena.","In this work, we mitigate the problem in an LLM-based MT model by guiding it to better word alignment.","We first study the correlation between word alignment and the phenomena of hallucination and omission in MT.","Then we propose to utilize word alignment as preference to optimize the LLM-based MT model.","The preference data are constructed by selecting chosen and rejected translations from multiple MT tools.","Subsequently, direct preference optimization is used to optimize the LLM-based model towards the preference signal.","Given the absence of evaluators specifically designed for hallucination and omission in MT, we further propose selecting hard instances and utilizing GPT-4 to directly evaluate the performance of the models in mitigating these issues.","We verify the rationality of these designed evaluation methods by experiments, followed by extensive results demonstrating the effectiveness of word alignment-based preference optimization to mitigate hallucination and omission."],"url":"http://arxiv.org/abs/2405.09223v1"}
{"created":"2024-05-15 10:02:47","title":"Bridging the gap in online hate speech detection: a comparative analysis of BERT and traditional models for homophobic content identification on X/Twitter","abstract":"Our study addresses a significant gap in online hate speech detection research by focusing on homophobia, an area often neglected in sentiment analysis research. Utilising advanced sentiment analysis models, particularly BERT, and traditional machine learning methods, we developed a nuanced approach to identify homophobic content on X/Twitter. This research is pivotal due to the persistent underrepresentation of homophobia in detection models. Our findings reveal that while BERT outperforms traditional methods, the choice of validation technique can impact model performance. This underscores the importance of contextual understanding in detecting nuanced hate speech. By releasing the largest open-source labelled English dataset for homophobia detection known to us, an analysis of various models' performance and our strongest BERT-based model, we aim to enhance online safety and inclusivity. Future work will extend to broader LGBTQIA+ hate speech detection, addressing the challenges of sourcing diverse datasets. Through this endeavour, we contribute to the larger effort against online hate, advocating for a more inclusive digital landscape. Our study not only offers insights into the effective detection of homophobic content by improving on previous research results, but it also lays groundwork for future advancements in hate speech analysis.","sentences":["Our study addresses a significant gap in online hate speech detection research by focusing on homophobia, an area often neglected in sentiment analysis research.","Utilising advanced sentiment analysis models, particularly BERT, and traditional machine learning methods, we developed a nuanced approach to identify homophobic content on X/Twitter.","This research is pivotal due to the persistent underrepresentation of homophobia in detection models.","Our findings reveal that while BERT outperforms traditional methods, the choice of validation technique can impact model performance.","This underscores the importance of contextual understanding in detecting nuanced hate speech.","By releasing the largest open-source labelled English dataset for homophobia detection known to us, an analysis of various models' performance and our strongest BERT-based model, we aim to enhance online safety and inclusivity.","Future work will extend to broader LGBTQIA+ hate speech detection, addressing the challenges of sourcing diverse datasets.","Through this endeavour, we contribute to the larger effort against online hate, advocating for a more inclusive digital landscape.","Our study not only offers insights into the effective detection of homophobic content by improving on previous research results, but it also lays groundwork for future advancements in hate speech analysis."],"url":"http://arxiv.org/abs/2405.09221v1"}
{"created":"2024-05-15 09:25:24","title":"Extended time Petri nets","abstract":"In many complex systems that can be modeled using Petri nets time can be a very important factor which should be taken into account during creation and analysis of the model. Time data can describe starting moments of some actions or their duration before their immediate effects start to influence some other areas of the modeled system. Places in a Petri net often describe static components of the system, but they can also describe states. Such a state can have time restrictions, for example, telling how long it can influence other elements in the model. Time values describing some system may be inconsistent or incomplete, which can cause problems during the creation of the model. In this paper, a new extension of time Petri nets is proposed, which allows the creation of models with different types of time data, which previously were possible to be properly used in separate types of well-known time Petri nets. The proposed new time Petri net solves this problem by integrating different aspects of already existing time Petri nets into one unified net.","sentences":["In many complex systems that can be modeled using Petri nets time can be a very important factor which should be taken into account during creation and analysis of the model.","Time data can describe starting moments of some actions or their duration before their immediate effects start to influence some other areas of the modeled system.","Places in a Petri net often describe static components of the system, but they can also describe states.","Such a state can have time restrictions, for example, telling how long it can influence other elements in the model.","Time values describing some system may be inconsistent or incomplete, which can cause problems during the creation of the model.","In this paper, a new extension of time Petri nets is proposed, which allows the creation of models with different types of time data, which previously were possible to be properly used in separate types of well-known time Petri nets.","The proposed new time Petri net solves this problem by integrating different aspects of already existing time Petri nets into one unified net."],"url":"http://arxiv.org/abs/2405.09208v1"}
{"created":"2024-05-15 09:23:21","title":"Lens functions for exploring UMAP Projections with Domain Knowledge","abstract":"Dimensionality reduction algorithms are often used to visualise high-dimensional data. Previously, studies have used prior information to enhance or suppress expected patterns in projections. In this paper, we adapt such techniques for domain knowledge guided interactive exploration. Inspired by Mapper and STAD, we present three types of lens functions for UMAP, a state-of-the-art dimensionality reduction algorithm. Lens functions enable analysts to adapt projections to their questions, revealing otherwise hidden patterns. They filter the modelled connectivity to explore the interaction between manually selected features and the data's structure, creating configurable perspectives each potentially revealing new insights. The effectiveness of the lens functions is demonstrated in two use cases and their computational cost is analysed in a synthetic benchmark. Our implementation is available in an open-source Python package: https://github.com/vda-lab/lensed_umap.","sentences":["Dimensionality reduction algorithms are often used to visualise high-dimensional data.","Previously, studies have used prior information to enhance or suppress expected patterns in projections.","In this paper, we adapt such techniques for domain knowledge guided interactive exploration.","Inspired by Mapper and STAD, we present three types of lens functions for UMAP, a state-of-the-art dimensionality reduction algorithm.","Lens functions enable analysts to adapt projections to their questions, revealing otherwise hidden patterns.","They filter the modelled connectivity to explore the interaction between manually selected features and the data's structure, creating configurable perspectives each potentially revealing new insights.","The effectiveness of the lens functions is demonstrated in two use cases and their computational cost is analysed in a synthetic benchmark.","Our implementation is available in an open-source Python package: https://github.com/vda-lab/lensed_umap."],"url":"http://arxiv.org/abs/2405.09204v1"}
{"created":"2024-05-15 09:02:17","title":"Flexible image analysis for law enforcement agencies with deep neural networks to determine: where, who and what","abstract":"Due to the increasing need for effective security measures and the integration of cameras in commercial products, a hugeamount of visual data is created today. Law enforcement agencies (LEAs) are inspecting images and videos to findradicalization, propaganda for terrorist organizations and illegal products on darknet markets. This is time consuming.Instead of an undirected search, LEAs would like to adapt to new crimes and threats, and focus only on data from specificlocations, persons or objects, which requires flexible interpretation of image content. Visual concept detection with deepconvolutional neural networks (CNNs) is a crucial component to understand the image content. This paper has fivecontributions. The first contribution allows image-based geo-localization to estimate the origin of an image. CNNs andgeotagged images are used to create a model that determines the location of an image by its pixel values. The secondcontribution enables analysis of fine-grained concepts to distinguish sub-categories in a generic concept. The proposedmethod encompasses data acquisition and cleaning and concept hierarchies. The third contribution is the recognition ofperson attributes (e.g., glasses or moustache) to enable query by textual description for a person. The person-attributeproblem is treated as a specific sub-task of concept classification. The fourth contribution is an intuitive image annotationtool based on active learning. Active learning allows users to define novel concepts flexibly and train CNNs with minimalannotation effort. The fifth contribution increases the flexibility for LEAs in the query definition by using query expansion.Query expansion maps user queries to known and detectable concepts. Therefore, no prior knowledge of the detectableconcepts is required for the users. The methods are validated on data with varying locations (popular and non-touristiclocations), varying person attributes (CelebA dataset), and varying number of annotations.","sentences":["Due to the increasing need for effective security measures and the integration of cameras in commercial products, a hugeamount of visual data is created today.","Law enforcement agencies (LEAs) are inspecting images and videos to findradicalization, propaganda for terrorist organizations and illegal products on darknet markets.","This is time consuming.","Instead of an undirected search, LEAs would like to adapt to new crimes and threats, and focus only on data from specificlocations, persons or objects, which requires flexible interpretation of image content.","Visual concept detection with deepconvolutional neural networks (CNNs) is a crucial component to understand the image content.","This paper has fivecontributions.","The first contribution allows image-based geo-localization to estimate the origin of an image.","CNNs andgeotagged images are used to create a model that determines the location of an image by its pixel values.","The secondcontribution enables analysis of fine-grained concepts to distinguish sub-categories in a generic concept.","The proposedmethod encompasses data acquisition and cleaning and concept hierarchies.","The third contribution is the recognition ofperson attributes (e.g., glasses or moustache) to enable query by textual description for a person.","The person-attributeproblem is treated as a specific sub-task of concept classification.","The fourth contribution is an intuitive image annotationtool based on active learning.","Active learning allows users to define novel concepts flexibly and train CNNs with minimalannotation effort.","The fifth contribution increases the flexibility for LEAs in the query definition by using query expansion.","Query expansion maps user queries to known and detectable concepts.","Therefore, no prior knowledge of the detectableconcepts is required for the users.","The methods are validated on data with varying locations (popular and non-touristiclocations), varying person attributes (CelebA dataset), and varying number of annotations."],"url":"http://arxiv.org/abs/2405.09194v1"}
{"created":"2024-05-15 08:53:47","title":"Advancing Explainable AI with Causal Analysis in Large-Scale Fuzzy Cognitive Maps","abstract":"In the quest for accurate and interpretable AI models, eXplainable AI (XAI) has become crucial. Fuzzy Cognitive Maps (FCMs) stand out as an advanced XAI method because of their ability to synergistically combine and exploit both expert knowledge and data-driven insights, providing transparency and intrinsic interpretability. This letter introduces and investigates the \"Total Causal Effect Calculation for FCMs\" (TCEC-FCM) algorithm, an innovative approach that, for the first time, enables the efficient calculation of total causal effects among concepts in large-scale FCMs by leveraging binary search and graph traversal techniques, thereby overcoming the challenge of exhaustive causal path exploration that hinder existing methods. We evaluate the proposed method across various synthetic FCMs that demonstrate TCEC-FCM's superior performance over exhaustive methods, marking a significant advancement in causal effect analysis within FCMs, thus broadening their usability for modern complex XAI applications.","sentences":["In the quest for accurate and interpretable AI models, eXplainable AI (XAI) has become crucial.","Fuzzy Cognitive Maps (FCMs) stand out as an advanced XAI method because of their ability to synergistically combine and exploit both expert knowledge and data-driven insights, providing transparency and intrinsic interpretability.","This letter introduces and investigates the \"Total Causal Effect Calculation for FCMs\" (TCEC-FCM) algorithm, an innovative approach that, for the first time, enables the efficient calculation of total causal effects among concepts in large-scale FCMs by leveraging binary search and graph traversal techniques, thereby overcoming the challenge of exhaustive causal path exploration that hinder existing methods.","We evaluate the proposed method across various synthetic FCMs that demonstrate TCEC-FCM's superior performance over exhaustive methods, marking a significant advancement in causal effect analysis within FCMs, thus broadening their usability for modern complex XAI applications."],"url":"http://arxiv.org/abs/2405.09190v1"}
{"created":"2024-05-15 08:35:15","title":"Shacl4Bib: custom validation of library data","abstract":"The Shapes Constraint Language (SHACL) is a formal language for validating RDF graphs against a set of conditions. Following this idea and implementing a subset of the language, the Metadata Quality Assessment Framework provides Shacl4Bib: a mechanism to define SHACL-like rules for data sources in non-RDF based formats, such as XML, CSV and JSON. QA catalogue extends this concept further to MARC21, UNIMARC and PICA data. The criteria can be defined either with YAML or JSON configuration files or with Java code. Libraries can validate their data against criteria expressed in a unified language, that improves the clarity and the reusability of custom validation processes.","sentences":["The Shapes Constraint Language (SHACL) is a formal language for validating RDF graphs against a set of conditions.","Following this idea and implementing a subset of the language, the Metadata Quality Assessment Framework provides Shacl4Bib: a mechanism to define SHACL-like rules for data sources in non-RDF based formats, such as XML, CSV and JSON.","QA catalogue extends this concept further to MARC21, UNIMARC and PICA data.","The criteria can be defined either with YAML or JSON configuration files or with Java code.","Libraries can validate their data against criteria expressed in a unified language, that improves the clarity and the reusability of custom validation processes."],"url":"http://arxiv.org/abs/2405.09177v1"}
{"created":"2024-05-15 07:32:43","title":"Adapting Abstract Meaning Representation Parsing to the Clinical Narrative -- the SPRING THYME parser","abstract":"This paper is dedicated to the design and evaluation of the first AMR parser tailored for clinical notes. Our objective was to facilitate the precise transformation of the clinical notes into structured AMR expressions, thereby enhancing the interpretability and usability of clinical text data at scale. Leveraging the colon cancer dataset from the Temporal Histories of Your Medical Events (THYME) corpus, we adapted a state-of-the-art AMR parser utilizing continuous training. Our approach incorporates data augmentation techniques to enhance the accuracy of AMR structure predictions. Notably, through this learning strategy, our parser achieved an impressive F1 score of 88% on the THYME corpus's colon cancer dataset. Moreover, our research delved into the efficacy of data required for domain adaptation within the realm of clinical notes, presenting domain adaptation data requirements for AMR parsing. This exploration not only underscores the parser's robust performance but also highlights its potential in facilitating a deeper understanding of clinical narratives through structured semantic representations.","sentences":["This paper is dedicated to the design and evaluation of the first AMR parser tailored for clinical notes.","Our objective was to facilitate the precise transformation of the clinical notes into structured AMR expressions, thereby enhancing the interpretability and usability of clinical text data at scale.","Leveraging the colon cancer dataset from the Temporal Histories of Your Medical Events (THYME) corpus, we adapted a state-of-the-art AMR parser utilizing continuous training.","Our approach incorporates data augmentation techniques to enhance the accuracy of AMR structure predictions.","Notably, through this learning strategy, our parser achieved an impressive F1 score of 88% on the THYME corpus's colon cancer dataset.","Moreover, our research delved into the efficacy of data required for domain adaptation within the realm of clinical notes, presenting domain adaptation data requirements for AMR parsing.","This exploration not only underscores the parser's robust performance but also highlights its potential in facilitating a deeper understanding of clinical narratives through structured semantic representations."],"url":"http://arxiv.org/abs/2405.09153v1"}
{"created":"2024-05-15 07:20:27","title":"A Hierarchically Feature Reconstructed Autoencoder for Unsupervised Anomaly Detection","abstract":"Anomaly detection and localization without any manual annotations and prior knowledge is a challenging task under the setting of unsupervised learning. The existing works achieve excellent performance in the anomaly detection, but with complex networks or cumbersome pipelines. To address this issue, this paper explores a simple but effective architecture in the anomaly detection. It consists of a well pre-trained encoder to extract hierarchical feature representations and a decoder to reconstruct these intermediate features from the encoder. In particular, it does not require any data augmentations and anomalous images for training. The anomalies can be detected when the decoder fails to reconstruct features well, and then errors of hierarchical feature reconstruction are aggregated into an anomaly map to achieve anomaly localization. The difference comparison between those features of encoder and decode lead to more accurate and robust localization results than the comparison in single feature or pixel-by-pixel comparison in the conventional works. Experiment results show that the proposed method outperforms the state-of-the-art methods on MNIST, Fashion-MNIST, CIFAR-10, and MVTec Anomaly Detection datasets on both anomaly detection and localization.","sentences":["Anomaly detection and localization without any manual annotations and prior knowledge is a challenging task under the setting of unsupervised learning.","The existing works achieve excellent performance in the anomaly detection, but with complex networks or cumbersome pipelines.","To address this issue, this paper explores a simple but effective architecture in the anomaly detection.","It consists of a well pre-trained encoder to extract hierarchical feature representations and a decoder to reconstruct these intermediate features from the encoder.","In particular, it does not require any data augmentations and anomalous images for training.","The anomalies can be detected when the decoder fails to reconstruct features well, and then errors of hierarchical feature reconstruction are aggregated into an anomaly map to achieve anomaly localization.","The difference comparison between those features of encoder and decode lead to more accurate and robust localization results than the comparison in single feature or pixel-by-pixel comparison in the conventional works.","Experiment results show that the proposed method outperforms the state-of-the-art methods on MNIST, Fashion-MNIST, CIFAR-10, and MVTec Anomaly Detection datasets on both anomaly detection and localization."],"url":"http://arxiv.org/abs/2405.09148v1"}
{"created":"2024-05-15 07:17:06","title":"Evaluation scheme for children-centered language interaction competence of AI-driven robots","abstract":"This article explores the evaluation method for the language communication proficiency of AI-driven robots engaging in interactive communication with children. The utilization of AI-driven robots in children's everyday communication is swiftly advancing, underscoring the importance of evaluating these robots'language communication skills. Based on 11 Chinese families' interviews and thematic analysis of the comment text from shopping websites, a framework is introduced in the article to assess five key dimensions of child-robot language communication: interactivity, specificity, development, sociality, and safety. We draw on the concept of \"children's agency\", viewing children as active participants in shaping society and cultural life alongside adults. Therefore, this article places particular emphasis on collecting data related to children. Whether through survey interviews or direct interactive experiments, we treat children as an independent object for data collection. The study involved empirical research following the mentioned framework, which involved capturing interaction videos in natural conversation settings among children from 6 families. Analysis was performed on quantitative data obtained from video recordings, alongside questionnaires and interviews carried out by parents acting as participants or observers. We found that the presence or absence of parents during children's interactions with robots can impact the evaluation of robots'language communication abilities. Ultimately, this article proposes an enhanced comprehensive evaluation framework incorporating insights from parents and children, supported by empirical evidence and inter-rater consistency assessments, showcasing the scheme's efficacy.","sentences":["This article explores the evaluation method for the language communication proficiency of AI-driven robots engaging in interactive communication with children.","The utilization of AI-driven robots in children's everyday communication is swiftly advancing, underscoring the importance of evaluating these robots'language communication skills.","Based on 11 Chinese families' interviews and thematic analysis of the comment text from shopping websites, a framework is introduced in the article to assess five key dimensions of child-robot language communication: interactivity, specificity, development, sociality, and safety.","We draw on the concept of \"children's agency\", viewing children as active participants in shaping society and cultural life alongside adults.","Therefore, this article places particular emphasis on collecting data related to children.","Whether through survey interviews or direct interactive experiments, we treat children as an independent object for data collection.","The study involved empirical research following the mentioned framework, which involved capturing interaction videos in natural conversation settings among children from 6 families.","Analysis was performed on quantitative data obtained from video recordings, alongside questionnaires and interviews carried out by parents acting as participants or observers.","We found that the presence or absence of parents during children's interactions with robots can impact the evaluation of robots'language communication abilities.","Ultimately, this article proposes an enhanced comprehensive evaluation framework incorporating insights from parents and children, supported by empirical evidence and inter-rater consistency assessments, showcasing the scheme's efficacy."],"url":"http://arxiv.org/abs/2405.09144v1"}
{"created":"2024-05-15 07:13:08","title":"Tree-Packing Revisited: Faster Fully Dynamic Min-Cut and Arboricity","abstract":"A tree-packing is a collection of spanning trees of a graph. It has been a useful tool for computing the minimum cut in static, dynamic, and distributed settings. In particular, [Thorup, Comb. 2007] used them to obtain his dynamic min-cut algorithm with $\\tilde O(\\lambda^{14.5}\\sqrt{n})$ worst-case update time. We reexamine this relationship, showing that we need to maintain fewer spanning trees for such a result; we show that we only need to pack $\\Theta(\\lambda^3 \\log m)$ greedy trees to guarantee a 1-respecting cut or a trivial cut in some contracted graph.   Based on this structural result, we then provide a deterministic algorithm for fully dynamic exact min-cut, that has $\\tilde O(\\lambda^{5.5}\\sqrt{n})$ worst-case update time, for min-cut value bounded by $\\lambda$. In particular, this also leads to an algorithm for general fully dynamic exact min-cut with $\\tilde O(m^{1-1/12})$ amortized update time, improving upon $\\tilde O(m^{1-1/31})$ [Goranci et al., SODA 2023].   We also give the first fully dynamic algorithm that maintains a $(1+\\varepsilon)$-approximation of the fractional arboricity -- which is strictly harder than the integral arboricity. Our algorithm is deterministic and has $O(\\alpha \\log^6m/\\varepsilon^4)$ amortized update time, for arboricity at most $\\alpha$. We extend these results to a Monte Carlo algorithm with $O(\\text{poly}(\\log m,\\varepsilon^{-1}))$ amortized update time against an adaptive adversary. Our algorithms work on multi-graphs as well.   Both result are obtained by exploring the connection between the min-cut/arboricity and (greedy) tree-packing. We investigate tree-packing in a broader sense; including a lower bound for greedy tree-packing, which - to the best of our knowledge - is the first progress on this topic since [Thorup, Comb. 2007].","sentences":["A tree-packing is a collection of spanning trees of a graph.","It has been a useful tool for computing the minimum cut in static, dynamic, and distributed settings.","In particular, [Thorup, Comb. 2007] used them to obtain his dynamic min-cut algorithm with $\\tilde O(\\lambda^{14.5}\\sqrt{n})$ worst-case update time.","We reexamine this relationship, showing that we need to maintain fewer spanning trees for such a result; we show that we only need to pack $\\Theta(\\lambda^3 \\log m)$ greedy trees to guarantee a 1-respecting cut or a trivial cut in some contracted graph.   ","Based on this structural result, we then provide a deterministic algorithm for fully dynamic exact min-cut, that has $\\tilde O(\\lambda^{5.5}\\sqrt{n})$ worst-case update time, for min-cut value bounded by $\\lambda$. In particular, this also leads to an algorithm for general fully dynamic exact min-cut with $\\tilde O(m^{1-1/12})$ amortized update time, improving upon $\\tilde O(m^{1","-1/31})$","[Goranci et al., SODA 2023].   ","We also give the first fully dynamic algorithm that maintains a $(1+\\varepsilon)$-approximation of the fractional arboricity -- which is strictly harder than the integral arboricity.","Our algorithm is deterministic and has $O(\\alpha \\log^6m/\\varepsilon^4)$ amortized update time, for arboricity at most $\\alpha$. We extend these results to a Monte Carlo algorithm with $O(\\text{poly}(\\log m,\\varepsilon^{-1}))$ amortized update time against an adaptive adversary.","Our algorithms work on multi-graphs as well.   ","Both result are obtained by exploring the connection between the min-cut/arboricity and (greedy) tree-packing.","We investigate tree-packing in a broader sense; including a lower bound for greedy tree-packing, which - to the best of our knowledge - is the first progress on this topic since [Thorup, Comb. 2007]."],"url":"http://arxiv.org/abs/2405.09141v1"}
{"created":"2024-05-15 06:57:18","title":"Overcoming Domain Drift in Online Continual Learning","abstract":"Online Continual Learning (OCL) empowers machine learning models to acquire new knowledge online across a sequence of tasks. However, OCL faces a significant challenge: catastrophic forgetting, wherein the model learned in previous tasks is substantially overwritten upon encountering new tasks, leading to a biased forgetting of prior knowledge. Moreover, the continual doman drift in sequential learning tasks may entail the gradual displacement of the decision boundaries in the learned feature space, rendering the learned knowledge susceptible to forgetting. To address the above problem, in this paper, we propose a novel rehearsal strategy, termed Drift-Reducing Rehearsal (DRR), to anchor the domain of old tasks and reduce the negative transfer effects. First, we propose to select memory for more representative samples guided by constructed centroids in a data stream. Then, to keep the model from domain chaos in drifting, a two-level angular cross-task Contrastive Margin Loss (CML) is proposed, to encourage the intra-class and intra-task compactness, and increase the inter-class and inter-task discrepancy. Finally, to further suppress the continual domain drift, we present an optional Centorid Distillation Loss (CDL) on the rehearsal memory to anchor the knowledge in feature space for each previous old task. Extensive experimental results on four benchmark datasets validate that the proposed DRR can effectively mitigate the continual domain drift and achieve the state-of-the-art (SOTA) performance in OCL.","sentences":["Online Continual Learning (OCL) empowers machine learning models to acquire new knowledge online across a sequence of tasks.","However, OCL faces a significant challenge: catastrophic forgetting, wherein the model learned in previous tasks is substantially overwritten upon encountering new tasks, leading to a biased forgetting of prior knowledge.","Moreover, the continual doman drift in sequential learning tasks may entail the gradual displacement of the decision boundaries in the learned feature space, rendering the learned knowledge susceptible to forgetting.","To address the above problem, in this paper, we propose a novel rehearsal strategy, termed Drift-Reducing Rehearsal (DRR), to anchor the domain of old tasks and reduce the negative transfer effects.","First, we propose to select memory for more representative samples guided by constructed centroids in a data stream.","Then, to keep the model from domain chaos in drifting, a two-level angular cross-task Contrastive Margin Loss (CML) is proposed, to encourage the intra-class and intra-task compactness, and increase the inter-class and inter-task discrepancy.","Finally, to further suppress the continual domain drift, we present an optional Centorid Distillation Loss (CDL) on the rehearsal memory to anchor the knowledge in feature space for each previous old task.","Extensive experimental results on four benchmark datasets validate that the proposed DRR can effectively mitigate the continual domain drift and achieve the state-of-the-art (SOTA) performance in OCL."],"url":"http://arxiv.org/abs/2405.09133v1"}
{"created":"2024-05-15 06:46:53","title":"Contextual Integrity Games","abstract":"The contextual integrity model is a widely accepted way of analyzing the plurality of norms that are colloquially called \"privacy norms\". Contextual integrity systematically describes such norms by distinguishing the type of data concerned, the three social agents involved (subject, sender, and recipient) and the transmission principle governing the transfer of information. It allows analyzing privacy norms in terms of their impact on the interaction of those agents with one another.   This paper places contextual integrity in a strict game theoretic framework. When such description is possible it has three key advantages: Firstly, it allows indisputable utilitarian justification of some privacy norms. Secondly, it better relates privacy to topics which are well understood by stakeholders whose education is predominantly quantitative, such as engineers and economists. Thirdly, it is an absolute necessity when describing ethical constraints to machines such as AI agents.   In addition to describing games which capture paradigmatic informational norms, the paper also analyzes cases in which the game, per se, does not encourage normative behavior. The paper discusses two main forms of mechanisms which can be applied to the game in such cases, and shows that they reflect accepted privacy regulation and technologies.","sentences":["The contextual integrity model is a widely accepted way of analyzing the plurality of norms that are colloquially called \"privacy norms\".","Contextual integrity systematically describes such norms by distinguishing the type of data concerned, the three social agents involved (subject, sender, and recipient) and the transmission principle governing the transfer of information.","It allows analyzing privacy norms in terms of their impact on the interaction of those agents with one another.   ","This paper places contextual integrity in a strict game theoretic framework.","When such description is possible it has three key advantages: Firstly, it allows indisputable utilitarian justification of some privacy norms.","Secondly, it better relates privacy to topics which are well understood by stakeholders whose education is predominantly quantitative, such as engineers and economists.","Thirdly, it is an absolute necessity when describing ethical constraints to machines such as AI agents.   ","In addition to describing games which capture paradigmatic informational norms, the paper also analyzes cases in which the game, per se, does not encourage normative behavior.","The paper discusses two main forms of mechanisms which can be applied to the game in such cases, and shows that they reflect accepted privacy regulation and technologies."],"url":"http://arxiv.org/abs/2405.09130v1"}
{"created":"2024-05-15 06:41:43","title":"HAAP: Vision-context Hierarchical Attention Autoregressive with Adaptive Permutation for Scene Text Recognition","abstract":"Internal Language Model (LM)-based methods use permutation language modeling (PLM) to solve the error correction caused by conditional independence in external LM-based methods. However, random permutations of human interference cause fit oscillations in the model training, and Iterative Refinement (IR) operation to improve multimodal information decoupling also introduces additional overhead. To address these issues, this paper proposes the Hierarchical Attention autoregressive Model with Adaptive Permutation (HAAP) to enhance the location-context-image interaction capability, improving autoregressive generalization with internal LM. First, we propose Implicit Permutation Neurons (IPN) to generate adaptive attention masks to dynamically exploit token dependencies. The adaptive masks increase the diversity of training data and prevent model dependency on a specific order. It reduces the training overhead of PLM while avoiding training fit oscillations. Second, we develop Cross-modal Hierarchical Attention mechanism (CHA) to couple context and image features. This processing establishes rich positional semantic dependencies between context and image while avoiding IR. Extensive experimental results show the proposed HAAP achieves state-of-the-art (SOTA) performance in terms of accuracy, complexity, and latency on several datasets.","sentences":["Internal Language Model (LM)-based methods use permutation language modeling (PLM) to solve the error correction caused by conditional independence in external LM-based methods.","However, random permutations of human interference cause fit oscillations in the model training, and Iterative Refinement (IR) operation to improve multimodal information decoupling also introduces additional overhead.","To address these issues, this paper proposes the Hierarchical Attention autoregressive Model with Adaptive Permutation (HAAP) to enhance the location-context-image interaction capability, improving autoregressive generalization with internal LM.","First, we propose Implicit Permutation Neurons (IPN) to generate adaptive attention masks to dynamically exploit token dependencies.","The adaptive masks increase the diversity of training data and prevent model dependency on a specific order.","It reduces the training overhead of PLM while avoiding training fit oscillations.","Second, we develop Cross-modal Hierarchical Attention mechanism (CHA) to couple context and image features.","This processing establishes rich positional semantic dependencies between context and image while avoiding IR.","Extensive experimental results show the proposed HAAP achieves state-of-the-art (SOTA) performance in terms of accuracy, complexity, and latency on several datasets."],"url":"http://arxiv.org/abs/2405.09125v1"}
{"created":"2024-05-15 06:01:40","title":"Enhancing Function Name Prediction using Votes-Based Name Tokenization and Multi-Task Learning","abstract":"Reverse engineers would acquire valuable insights from descriptive function names, which are absent in publicly released binaries. Recent advances in binary function name prediction using data-driven machine learning show promise. However, existing approaches encounter difficulties in capturing function semantics in diverse optimized binaries and fail to reserve the meaning of labels in function names. We propose Epitome, a framework that enhances function name prediction using votes-based name tokenization and multi-task learning, specifically tailored for different compilation optimization binaries. Epitome learns comprehensive function semantics by pre-trained assembly language model and graph neural network, incorporating function semantics similarity prediction task, to maximize the similarity of function semantics in the context of different compilation optimization levels. In addition, we present two data preprocessing methods to improve the comprehensibility of function names. We evaluate the performance of Epitome using 2,597,346 functions extracted from binaries compiled with 5 optimizations (O0-Os) for 4 architectures (x64, x86, ARM, and MIPS). Epitome outperforms the state-of-the-art function name prediction tool by up to 44.34%, 64.16%, and 54.44% in precision, recall, and F1 score, while also exhibiting superior generalizability.","sentences":["Reverse engineers would acquire valuable insights from descriptive function names, which are absent in publicly released binaries.","Recent advances in binary function name prediction using data-driven machine learning show promise.","However, existing approaches encounter difficulties in capturing function semantics in diverse optimized binaries and fail to reserve the meaning of labels in function names.","We propose Epitome, a framework that enhances function name prediction using votes-based name tokenization and multi-task learning, specifically tailored for different compilation optimization binaries.","Epitome learns comprehensive function semantics by pre-trained assembly language model and graph neural network, incorporating function semantics similarity prediction task, to maximize the similarity of function semantics in the context of different compilation optimization levels.","In addition, we present two data preprocessing methods to improve the comprehensibility of function names.","We evaluate the performance of Epitome using 2,597,346 functions extracted from binaries compiled with 5 optimizations (O0-Os) for 4 architectures (x64, x86, ARM, and MIPS).","Epitome outperforms the state-of-the-art function name prediction tool by up to 44.34%, 64.16%, and 54.44% in precision, recall, and F1 score, while also exhibiting superior generalizability."],"url":"http://arxiv.org/abs/2405.09112v1"}
{"created":"2024-05-15 05:57:20","title":"CarDreamer: Open-Source Learning Platform for World Model based Autonomous Driving","abstract":"To safely navigate intricate real-world scenarios, autonomous vehicles must be able to adapt to diverse road conditions and anticipate future events. World model (WM) based reinforcement learning (RL) has emerged as a promising approach by learning and predicting the complex dynamics of various environments. Nevertheless, to the best of our knowledge, there does not exist an accessible platform for training and testing such algorithms in sophisticated driving environments. To fill this void, we introduce CarDreamer, the first open-source learning platform designed specifically for developing WM based autonomous driving algorithms. It comprises three key components: 1) World model backbone: CarDreamer has integrated some state-of-the-art WMs, which simplifies the reproduction of RL algorithms. The backbone is decoupled from the rest and communicates using the standard Gym interface, so that users can easily integrate and test their own algorithms. 2) Built-in tasks: CarDreamer offers a comprehensive set of highly configurable driving tasks which are compatible with Gym interfaces and are equipped with empirically optimized reward functions. 3) Task development suite: This suite streamlines the creation of driving tasks, enabling easy definition of traffic flows and vehicle routes, along with automatic collection of multi-modal observation data. A visualization server allows users to trace real-time agent driving videos and performance metrics through a browser. Furthermore, we conduct extensive experiments using built-in tasks to evaluate the performance and potential of WMs in autonomous driving. Thanks to the richness and flexibility of CarDreamer, we also systematically study the impact of observation modality, observability, and sharing of vehicle intentions on AV safety and efficiency. All code and documents are accessible on https://github.com/ucd-dare/CarDreamer.","sentences":["To safely navigate intricate real-world scenarios, autonomous vehicles must be able to adapt to diverse road conditions and anticipate future events.","World model (WM) based reinforcement learning (RL) has emerged as a promising approach by learning and predicting the complex dynamics of various environments.","Nevertheless, to the best of our knowledge, there does not exist an accessible platform for training and testing such algorithms in sophisticated driving environments.","To fill this void, we introduce CarDreamer, the first open-source learning platform designed specifically for developing WM based autonomous driving algorithms.","It comprises three key components: 1) World model backbone: CarDreamer has integrated some state-of-the-art WMs, which simplifies the reproduction of RL algorithms.","The backbone is decoupled from the rest and communicates using the standard Gym interface, so that users can easily integrate and test their own algorithms.","2) Built-in tasks: CarDreamer offers a comprehensive set of highly configurable driving tasks which are compatible with Gym interfaces and are equipped with empirically optimized reward functions.","3) Task development suite: This suite streamlines the creation of driving tasks, enabling easy definition of traffic flows and vehicle routes, along with automatic collection of multi-modal observation data.","A visualization server allows users to trace real-time agent driving videos and performance metrics through a browser.","Furthermore, we conduct extensive experiments using built-in tasks to evaluate the performance and potential of WMs in autonomous driving.","Thanks to the richness and flexibility of CarDreamer, we also systematically study the impact of observation modality, observability, and sharing of vehicle intentions on AV safety and efficiency.","All code and documents are accessible on https://github.com/ucd-dare/CarDreamer."],"url":"http://arxiv.org/abs/2405.09111v1"}
{"created":"2024-05-15 05:20:16","title":"Adaptive Koopman Embedding for Robust Control of Complex Dynamical Systems","abstract":"The discovery of linear embedding is the key to the synthesis of linear control techniques for nonlinear systems. In recent years, while Koopman operator theory has become a prominent approach for learning these linear embeddings through data-driven methods, these algorithms often exhibit limitations in generalizability beyond the distribution captured by training data and are not robust to changes in the nominal system dynamics induced by intrinsic or environmental factors. To overcome these limitations, this study presents an adaptive Koopman architecture capable of responding to the changes in system dynamics online. The proposed framework initially employs an autoencoder-based neural network that utilizes input-output information from the nominal system to learn the corresponding Koopman embedding offline. Subsequently, we augment this nominal Koopman architecture with a feed-forward neural network that learns to modify the nominal dynamics in response to any deviation between the predicted and observed lifted states, leading to improved generalization and robustness to a wide range of uncertainties and disturbances compared to contemporary methods. Extensive tracking control simulations, which are undertaken by integrating the proposed scheme within a Model Predictive Control framework, are used to highlight its robustness against measurement noise, disturbances, and parametric variations in system dynamics.","sentences":["The discovery of linear embedding is the key to the synthesis of linear control techniques for nonlinear systems.","In recent years, while Koopman operator theory has become a prominent approach for learning these linear embeddings through data-driven methods, these algorithms often exhibit limitations in generalizability beyond the distribution captured by training data and are not robust to changes in the nominal system dynamics induced by intrinsic or environmental factors.","To overcome these limitations, this study presents an adaptive Koopman architecture capable of responding to the changes in system dynamics online.","The proposed framework initially employs an autoencoder-based neural network that utilizes input-output information from the nominal system to learn the corresponding Koopman embedding offline.","Subsequently, we augment this nominal Koopman architecture with a feed-forward neural network that learns to modify the nominal dynamics in response to any deviation between the predicted and observed lifted states, leading to improved generalization and robustness to a wide range of uncertainties and disturbances compared to contemporary methods.","Extensive tracking control simulations, which are undertaken by integrating the proposed scheme within a Model Predictive Control framework, are used to highlight its robustness against measurement noise, disturbances, and parametric variations in system dynamics."],"url":"http://arxiv.org/abs/2405.09101v1"}
{"created":"2024-05-15 05:13:20","title":"Optimizing Sensor Network Design for Multiple Coverage","abstract":"Sensor placement optimization methods have been studied extensively. They can be applied to a wide range of applications, including surveillance of known environments, optimal locations for 5G towers, and placement of missile defense systems. However, few works explore the robustness and efficiency of the resulting sensor network concerning sensor failure or adversarial attacks. This paper addresses this issue by optimizing for the least number of sensors to achieve multiple coverage of non-simply connected domains by a prescribed number of sensors. We introduce a new objective function for the greedy (next-best-view) algorithm to design efficient and robust sensor networks and derive theoretical bounds on the network's optimality. We further introduce a Deep Learning model to accelerate the algorithm for near real-time computations. The Deep Learning model requires the generation of training examples. Correspondingly, we show that understanding the geometric properties of the training data set provides important insights into the performance and training process of deep learning techniques. Finally, we demonstrate that a simple parallel version of the greedy approach using a simpler objective can be highly competitive.","sentences":["Sensor placement optimization methods have been studied extensively.","They can be applied to a wide range of applications, including surveillance of known environments, optimal locations for 5G towers, and placement of missile defense systems.","However, few works explore the robustness and efficiency of the resulting sensor network concerning sensor failure or adversarial attacks.","This paper addresses this issue by optimizing for the least number of sensors to achieve multiple coverage of non-simply connected domains by a prescribed number of sensors.","We introduce a new objective function for the greedy (next-best-view) algorithm to design efficient and robust sensor networks and derive theoretical bounds on the network's optimality.","We further introduce a Deep Learning model to accelerate the algorithm for near real-time computations.","The Deep Learning model requires the generation of training examples.","Correspondingly, we show that understanding the geometric properties of the training data set provides important insights into the performance and training process of deep learning techniques.","Finally, we demonstrate that a simple parallel version of the greedy approach using a simpler objective can be highly competitive."],"url":"http://arxiv.org/abs/2405.09096v1"}
{"created":"2024-05-15 04:01:47","title":"Enhancing Airline Customer Satisfaction: A Machine Learning and Causal Analysis Approach","abstract":"This study explores the enhancement of customer satisfaction in the airline industry, a critical factor for retaining customers and building brand reputation, which are vital for revenue growth. Utilizing a combination of machine learning and causal inference methods, we examine the specific impact of service improvements on customer satisfaction, with a focus on the online boarding pass experience. Through detailed data analysis involving several predictive and causal models, we demonstrate that improvements in the digital aspects of customer service significantly elevate overall customer satisfaction. This paper highlights how airlines can strategically leverage these insights to make data-driven decisions that enhance customer experiences and, consequently, their market competitiveness.","sentences":["This study explores the enhancement of customer satisfaction in the airline industry, a critical factor for retaining customers and building brand reputation, which are vital for revenue growth.","Utilizing a combination of machine learning and causal inference methods, we examine the specific impact of service improvements on customer satisfaction, with a focus on the online boarding pass experience.","Through detailed data analysis involving several predictive and causal models, we demonstrate that improvements in the digital aspects of customer service significantly elevate overall customer satisfaction.","This paper highlights how airlines can strategically leverage these insights to make data-driven decisions that enhance customer experiences and, consequently, their market competitiveness."],"url":"http://arxiv.org/abs/2405.09076v1"}
{"created":"2024-05-15 03:26:01","title":"Naturalistic Music Decoding from EEG Data via Latent Diffusion Models","abstract":"In this article, we explore the potential of using latent diffusion models, a family of powerful generative models, for the task of reconstructing naturalistic music from electroencephalogram (EEG) recordings. Unlike simpler music with limited timbres, such as MIDI-generated tunes or monophonic pieces, the focus here is on intricate music featuring a diverse array of instruments, voices, and effects, rich in harmonics and timbre. This study represents an initial foray into achieving general music reconstruction of high-quality using non-invasive EEG data, employing an end-to-end training approach directly on raw data without the need for manual pre-processing and channel selection. We train our models on the public NMED-T dataset and perform quantitative evaluation proposing neural embedding-based metrics. We additionally perform song classification based on the generated tracks. Our work contributes to the ongoing research in neural decoding and brain-computer interfaces, offering insights into the feasibility of using EEG data for complex auditory information reconstruction.","sentences":["In this article, we explore the potential of using latent diffusion models, a family of powerful generative models, for the task of reconstructing naturalistic music from electroencephalogram (EEG) recordings.","Unlike simpler music with limited timbres, such as MIDI-generated tunes or monophonic pieces, the focus here is on intricate music featuring a diverse array of instruments, voices, and effects, rich in harmonics and timbre.","This study represents an initial foray into achieving general music reconstruction of high-quality using non-invasive EEG data, employing an end-to-end training approach directly on raw data without the need for manual pre-processing and channel selection.","We train our models on the public NMED-T dataset and perform quantitative evaluation proposing neural embedding-based metrics.","We additionally perform song classification based on the generated tracks.","Our work contributes to the ongoing research in neural decoding and brain-computer interfaces, offering insights into the feasibility of using EEG data for complex auditory information reconstruction."],"url":"http://arxiv.org/abs/2405.09062v1"}
{"created":"2024-05-15 03:04:05","title":"A safety realignment framework via subspace-oriented model fusion for large language models","abstract":"The current safeguard mechanisms for large language models (LLMs) are indeed susceptible to jailbreak attacks, making them inherently fragile. Even the process of fine-tuning on apparently benign data for downstream tasks can jeopardize safety. One potential solution is to conduct safety fine-tuning subsequent to downstream fine-tuning. However, there's a risk of catastrophic forgetting during safety fine-tuning, where LLMs may regain safety measures but lose the task-specific knowledge acquired during downstream fine-tuning. In this paper, we introduce a safety realignment framework through subspace-oriented model fusion (SOMF), aiming to combine the safeguard capabilities of initially aligned model and the current fine-tuned model into a realigned model. Our approach begins by disentangling all task vectors from the weights of each fine-tuned model. We then identify safety-related regions within these vectors by subspace masking techniques. Finally, we explore the fusion of the initial safely aligned LLM with all task vectors based on the identified safety subspace. We validate that our safety realignment framework satisfies the safety requirements of a single fine-tuned model as well as multiple models during their fusion. Our findings confirm that SOMF preserves safety without notably compromising performance on downstream tasks, including instruction following in Chinese, English, and Hindi, as well as problem-solving capabilities in Code and Math.","sentences":["The current safeguard mechanisms for large language models (LLMs) are indeed susceptible to jailbreak attacks, making them inherently fragile.","Even the process of fine-tuning on apparently benign data for downstream tasks can jeopardize safety.","One potential solution is to conduct safety fine-tuning subsequent to downstream fine-tuning.","However, there's a risk of catastrophic forgetting during safety fine-tuning, where LLMs may regain safety measures but lose the task-specific knowledge acquired during downstream fine-tuning.","In this paper, we introduce a safety realignment framework through subspace-oriented model fusion (SOMF), aiming to combine the safeguard capabilities of initially aligned model and the current fine-tuned model into a realigned model.","Our approach begins by disentangling all task vectors from the weights of each fine-tuned model.","We then identify safety-related regions within these vectors by subspace masking techniques.","Finally, we explore the fusion of the initial safely aligned LLM with all task vectors based on the identified safety subspace.","We validate that our safety realignment framework satisfies the safety requirements of a single fine-tuned model as well as multiple models during their fusion.","Our findings confirm that SOMF preserves safety without notably compromising performance on downstream tasks, including instruction following in Chinese, English, and Hindi, as well as problem-solving capabilities in Code and Math."],"url":"http://arxiv.org/abs/2405.09055v1"}
{"created":"2024-05-15 02:54:11","title":"Perception Without Vision for Trajectory Prediction: Ego Vehicle Dynamics as Scene Representation for Efficient Active Learning in Autonomous Driving","abstract":"This study investigates the use of trajectory and dynamic state information for efficient data curation in autonomous driving machine learning tasks. We propose methods for clustering trajectory-states and sampling strategies in an active learning framework, aiming to reduce annotation and data costs while maintaining model performance. Our approach leverages trajectory information to guide data selection, promoting diversity in the training data. We demonstrate the effectiveness of our methods on the trajectory prediction task using the nuScenes dataset, showing consistent performance gains over random sampling across different data pool sizes, and even reaching sub-baseline displacement errors at just 50% of the data cost. Our results suggest that sampling typical data initially helps overcome the ''cold start problem,'' while introducing novelty becomes more beneficial as the training pool size increases. By integrating trajectory-state-informed active learning, we demonstrate that more efficient and robust autonomous driving systems are possible and practical using low-cost data curation strategies.","sentences":["This study investigates the use of trajectory and dynamic state information for efficient data curation in autonomous driving machine learning tasks.","We propose methods for clustering trajectory-states and sampling strategies in an active learning framework, aiming to reduce annotation and data costs while maintaining model performance.","Our approach leverages trajectory information to guide data selection, promoting diversity in the training data.","We demonstrate the effectiveness of our methods on the trajectory prediction task using the nuScenes dataset, showing consistent performance gains over random sampling across different data pool sizes, and even reaching sub-baseline displacement errors at just 50% of the data cost.","Our results suggest that sampling typical data initially helps overcome the ''cold start problem,'' while introducing novelty becomes more beneficial as the training pool size increases.","By integrating trajectory-state-informed active learning, we demonstrate that more efficient and robust autonomous driving systems are possible and practical using low-cost data curation strategies."],"url":"http://arxiv.org/abs/2405.09049v1"}
{"created":"2024-05-15 02:19:34","title":"SMART: Towards Pre-trained Missing-Aware Model for Patient Health Status Prediction","abstract":"Electronic health record (EHR) data has emerged as a valuable resource for analyzing patient health status. However, the prevalence of missing data in EHR poses significant challenges to existing methods, leading to spurious correlations and suboptimal predictions. While various imputation techniques have been developed to address this issue, they often obsess unnecessary details and may introduce additional noise when making clinical predictions. To tackle this problem, we propose SMART, a Self-Supervised Missing-Aware RepresenTation Learning approach for patient health status prediction, which encodes missing information via elaborated attentions and learns to impute missing values through a novel self-supervised pre-training approach that reconstructs missing data representations in the latent space. By adopting missing-aware attentions and focusing on learning higher-order representations, SMART promotes better generalization and robustness to missing data. We validate the effectiveness of SMART through extensive experiments on six EHR tasks, demonstrating its superiority over state-of-the-art methods.","sentences":["Electronic health record (EHR) data has emerged as a valuable resource for analyzing patient health status.","However, the prevalence of missing data in EHR poses significant challenges to existing methods, leading to spurious correlations and suboptimal predictions.","While various imputation techniques have been developed to address this issue, they often obsess unnecessary details and may introduce additional noise when making clinical predictions.","To tackle this problem, we propose SMART, a Self-Supervised Missing-Aware RepresenTation Learning approach for patient health status prediction, which encodes missing information via elaborated attentions and learns to impute missing values through a novel self-supervised pre-training approach that reconstructs missing data representations in the latent space.","By adopting missing-aware attentions and focusing on learning higher-order representations, SMART promotes better generalization and robustness to missing data.","We validate the effectiveness of SMART through extensive experiments on six EHR tasks, demonstrating its superiority over state-of-the-art methods."],"url":"http://arxiv.org/abs/2405.09039v1"}
{"created":"2024-05-15 02:13:51","title":"Unmasking Efficiency: Learning Salient Sparse Models in Non-IID Federated Learning","abstract":"In this work, we propose Salient Sparse Federated Learning (SSFL), a streamlined approach for sparse federated learning with efficient communication. SSFL identifies a sparse subnetwork prior to training, leveraging parameter saliency scores computed separately on local client data in non-IID scenarios, and then aggregated, to determine a global mask. Only the sparse model weights are communicated each round between the clients and the server. We validate SSFL's effectiveness using standard non-IID benchmarks, noting marked improvements in the sparsity--accuracy trade-offs. Finally, we deploy our method in a real-world federated learning framework and report improvement in communication time.","sentences":["In this work, we propose Salient Sparse Federated Learning (SSFL), a streamlined approach for sparse federated learning with efficient communication.","SSFL identifies a sparse subnetwork prior to training, leveraging parameter saliency scores computed separately on local client data in non-IID scenarios, and then aggregated, to determine a global mask.","Only the sparse model weights are communicated each round between the clients and the server.","We validate SSFL's effectiveness using standard non-IID benchmarks, noting marked improvements in the sparsity--accuracy trade-offs.","Finally, we deploy our method in a real-world federated learning framework and report improvement in communication time."],"url":"http://arxiv.org/abs/2405.09037v1"}
{"created":"2024-05-15 01:29:28","title":"Dynamic Loss Decay based Robust Oriented Object Detection on Remote Sensing Images with Noisy Labels","abstract":"The ambiguous appearance, tiny scale, and fine-grained classes of objects in remote sensing imagery inevitably lead to the noisy annotations in category labels of detection dataset. However, the effects and treatments of the label noises are underexplored in modern oriented remote sensing object detectors. To address this issue, we propose a robust oriented remote sensing object detection method through dynamic loss decay (DLD) mechanism, inspired by the two phase ``early-learning'' and ``memorization'' learning dynamics of deep neural networks on clean and noisy samples. To be specific, we first observe the end point of early learning phase termed as EL, after which the models begin to memorize the false labels that significantly degrade the detection accuracy. Secondly, under the guidance of the training indicator, the losses of each sample are ranked in descending order, and we adaptively decay the losses of the top K largest ones (bad samples) in the following epochs. Because these large losses are of high confidence to be calculated with wrong labels. Experimental results show that the method achieves excellent noise resistance performance tested on multiple public datasets such as HRSC2016 and DOTA-v1.0/v2.0 with synthetic category label noise. Our solution also has won the 2st place in the \"fine-grained object detection based on sub-meter remote sensing imagery\" track with noisy labels of 2023 National Big Data and Computing Intelligence Challenge.","sentences":["The ambiguous appearance, tiny scale, and fine-grained classes of objects in remote sensing imagery inevitably lead to the noisy annotations in category labels of detection dataset.","However, the effects and treatments of the label noises are underexplored in modern oriented remote sensing object detectors.","To address this issue, we propose a robust oriented remote sensing object detection method through dynamic loss decay (DLD) mechanism, inspired by the two phase ``early-learning'' and ``memorization'' learning dynamics of deep neural networks on clean and noisy samples.","To be specific, we first observe the end point of early learning phase termed as EL, after which the models begin to memorize the false labels that significantly degrade the detection accuracy.","Secondly, under the guidance of the training indicator, the losses of each sample are ranked in descending order, and we adaptively decay the losses of the top K largest ones (bad samples) in the following epochs.","Because these large losses are of high confidence to be calculated with wrong labels.","Experimental results show that the method achieves excellent noise resistance performance tested on multiple public datasets such as HRSC2016 and DOTA-v1.0/v2.0 with synthetic category label noise.","Our solution also has won the 2st place in the \"fine-grained object detection based on sub-meter remote sensing imagery\" track with noisy labels of 2023 National Big Data and Computing Intelligence Challenge."],"url":"http://arxiv.org/abs/2405.09024v1"}
{"created":"2024-05-15 01:22:30","title":"Deep Learning in Earthquake Engineering: A Comprehensive Review","abstract":"This article surveys the growing interest in utilizing Deep Learning (DL) as a powerful tool to address challenging problems in earthquake engineering. Despite decades of advancement in domain knowledge, issues such as uncertainty in earthquake occurrence, unpredictable seismic loads, nonlinear structural responses, and community engagement remain difficult to tackle using domain-specific methods. DL offers promising solutions by leveraging its data-driven capacity for nonlinear mapping, sequential data modeling, automatic feature extraction, dimensionality reduction, optimal decision-making, etc. However, the literature lacks a comprehensive review that systematically covers a consistent scope intersecting DL and earthquake engineering. To bridge the gap, the article first discusses methodological advances to elucidate various applicable DL techniques, such as multi-layer perceptron (MLP), convolutional neural network (CNN), recurrent neural network (RNN), generative adversarial network (GAN), autoencoder (AE), transfer learning (TL), reinforcement learning (RL), and graph neural network (GNN). A thorough research landscape is then disclosed by exploring various DL applications across different research topics, including vision-based seismic damage assessment and structural characterization, seismic demand and damage state prediction, seismic response history prediction, regional seismic risk assessment and community resilience, ground motion (GM) for engineering use, seismic response control, and the inverse problem of system/damage identification. Suitable DL techniques for each research topic are identified, emphasizing the preeminence of CNN for vision-based tasks, RNN for sequential data, RL for community resilience, and unsupervised learning for GM analysis. The article also discusses opportunities and challenges for leveraging DL in earthquake engineering research and practice.","sentences":["This article surveys the growing interest in utilizing Deep Learning (DL) as a powerful tool to address challenging problems in earthquake engineering.","Despite decades of advancement in domain knowledge, issues such as uncertainty in earthquake occurrence, unpredictable seismic loads, nonlinear structural responses, and community engagement remain difficult to tackle using domain-specific methods.","DL offers promising solutions by leveraging its data-driven capacity for nonlinear mapping, sequential data modeling, automatic feature extraction, dimensionality reduction, optimal decision-making, etc.","However, the literature lacks a comprehensive review that systematically covers a consistent scope intersecting DL and earthquake engineering.","To bridge the gap, the article first discusses methodological advances to elucidate various applicable DL techniques, such as multi-layer perceptron (MLP), convolutional neural network (CNN), recurrent neural network (RNN), generative adversarial network (GAN), autoencoder (AE), transfer learning (TL), reinforcement learning (RL), and graph neural network (GNN).","A thorough research landscape is then disclosed by exploring various DL applications across different research topics, including vision-based seismic damage assessment and structural characterization, seismic demand and damage state prediction, seismic response history prediction, regional seismic risk assessment and community resilience, ground motion (GM) for engineering use, seismic response control, and the inverse problem of system/damage identification.","Suitable DL techniques for each research topic are identified, emphasizing the preeminence of CNN for vision-based tasks, RNN for sequential data, RL for community resilience, and unsupervised learning for GM analysis.","The article also discusses opportunities and challenges for leveraging DL in earthquake engineering research and practice."],"url":"http://arxiv.org/abs/2405.09021v1"}
{"created":"2024-05-15 00:54:40","title":"A Japanese-Chinese Parallel Corpus Using Crowdsourcing for Web Mining","abstract":"Using crowdsourcing, we collected more than 10,000 URL pairs (parallel top page pairs) of bilingual websites that contain parallel documents and created a Japanese-Chinese parallel corpus of 4.6M sentence pairs from these websites. We used a Japanese-Chinese bilingual dictionary of 160K word pairs for document and sentence alignment. We then used high-quality 1.2M Japanese-Chinese sentence pairs to train a parallel corpus filter based on statistical language models and word translation probabilities. We compared the translation accuracy of the model trained on these 4.6M sentence pairs with that of the model trained on Japanese-Chinese sentence pairs from CCMatrix (12.4M), a parallel corpus from global web mining. Although our corpus is only one-third the size of CCMatrix, we found that the accuracy of the two models was comparable and confirmed that it is feasible to use crowdsourcing for web mining of parallel data.","sentences":["Using crowdsourcing, we collected more than 10,000 URL pairs (parallel top page pairs) of bilingual websites that contain parallel documents and created a Japanese-Chinese parallel corpus of 4.6M sentence pairs from these websites.","We used a Japanese-Chinese bilingual dictionary of 160K word pairs for document and sentence alignment.","We then used high-quality 1.2M Japanese-Chinese sentence pairs to train a parallel corpus filter based on statistical language models and word translation probabilities.","We compared the translation accuracy of the model trained on these 4.6M sentence pairs with that of the model trained on Japanese-Chinese sentence pairs from CCMatrix (12.4M), a parallel corpus from global web mining.","Although our corpus is only one-third the size of CCMatrix, we found that the accuracy of the two models was comparable and confirmed that it is feasible to use crowdsourcing for web mining of parallel data."],"url":"http://arxiv.org/abs/2405.09017v1"}
{"created":"2024-05-15 00:43:19","title":"Feature-based Federated Transfer Learning: Communication Efficiency, Robustness and Privacy","abstract":"In this paper, we propose feature-based federated transfer learning as a novel approach to improve communication efficiency by reducing the uplink payload by multiple orders of magnitude compared to that of existing approaches in federated learning and federated transfer learning. Specifically, in the proposed feature-based federated learning, we design the extracted features and outputs to be uploaded instead of parameter updates. For this distributed learning model, we determine the required payload and provide comparisons with the existing schemes. Subsequently, we analyze the robustness of feature-based federated transfer learning against packet loss, data insufficiency, and quantization. Finally, we address privacy considerations by defining and analyzing label privacy leakage and feature privacy leakage, and investigating mitigating approaches. For all aforementioned analyses, we evaluate the performance of the proposed learning scheme via experiments on an image classification task and a natural language processing task to demonstrate its effectiveness.","sentences":["In this paper, we propose feature-based federated transfer learning as a novel approach to improve communication efficiency by reducing the uplink payload by multiple orders of magnitude compared to that of existing approaches in federated learning and federated transfer learning.","Specifically, in the proposed feature-based federated learning, we design the extracted features and outputs to be uploaded instead of parameter updates.","For this distributed learning model, we determine the required payload and provide comparisons with the existing schemes.","Subsequently, we analyze the robustness of feature-based federated transfer learning against packet loss, data insufficiency, and quantization.","Finally, we address privacy considerations by defining and analyzing label privacy leakage and feature privacy leakage, and investigating mitigating approaches.","For all aforementioned analyses, we evaluate the performance of the proposed learning scheme via experiments on an image classification task and a natural language processing task to demonstrate its effectiveness."],"url":"http://arxiv.org/abs/2405.09014v1"}
{"created":"2024-05-15 00:31:01","title":"Symmetric-Difference (Degeneracy) and Signed Tree Models","abstract":"We introduce a dense counterpart of graph degeneracy, which extends the recently-proposed invariant symmetric difference. We say that a graph has sd-degeneracy (for symmetric-difference degeneracy) at most $d$ if it admits an elimination order of its vertices where a vertex $u$ can be removed whenever it has a $d$-twin, i.e., another vertex $v$ such that at most $d$ vertices outside $\\{u,v\\}$ are neighbors of exactly one of $u, v$. The family of graph classes of bounded sd-degeneracy is a superset of that of graph classes of bounded degeneracy or of bounded flip-width, and more generally, of bounded symmetric difference. Unlike most graph parameters, sd-degeneracy is not hereditary: it may be strictly smaller on a graph than on some of its induced subgraphs. In particular, every $n$-vertex graph is an induced subgraph of some $O(n^2)$-vertex graph of sd-degeneracy 1. In spite of this and the breadth of classes of bounded sd-degeneracy, we devise $\\tilde{O}(\\sqrt n)$-bit adjacency labeling schemes for them, which are optimal up to the hidden polylogarithmic factor. This is attained on some even more general classes, consisting of graphs $G$ whose vertices bijectively map to the leaves of a tree $T$, where transversal edges and anti-edges added to $T$ define the edge set of $G$. We call such graph representations signed tree models as they extend the so-called tree models (or twin-decompositions) developed in the context of twin-width, by adding transversal anti-edges. While computing the degeneracy of an input graph can be done in linear time, we show that deciding whether its symmetric difference is at most 8 is co-NP-complete, and whether its sd-degeneracy is at most 1 is NP-complete.","sentences":["We introduce a dense counterpart of graph degeneracy, which extends the recently-proposed invariant symmetric difference.","We say that a graph has sd-degeneracy (for symmetric-difference degeneracy) at most $d$ if it admits an elimination order of its vertices where a vertex $u$ can be removed whenever it has a $d$-twin, i.e., another vertex $v$ such that at most $d$ vertices outside $\\{u,v\\}$ are neighbors of exactly one of $u, v$.","The family of graph classes of bounded sd-degeneracy is a superset of that of graph classes of bounded degeneracy or of bounded flip-width, and more generally, of bounded symmetric difference.","Unlike most graph parameters, sd-degeneracy is not hereditary: it may be strictly smaller on a graph than on some of its induced subgraphs.","In particular, every $n$-vertex graph is an induced subgraph of some $O(n^2)$-vertex graph of sd-degeneracy 1.","In spite of this and the breadth of classes of bounded sd-degeneracy, we devise $\\tilde{O}(\\sqrt n)$-bit adjacency labeling schemes for them, which are optimal up to the hidden polylogarithmic factor.","This is attained on some even more general classes, consisting of graphs $G$ whose vertices bijectively map to the leaves of a tree $T$, where transversal edges and anti-edges added to $T$ define the edge set of $G$. We call such graph representations signed tree models as they extend the so-called tree models (or twin-decompositions) developed in the context of twin-width, by adding transversal anti-edges.","While computing the degeneracy of an input graph can be done in linear time, we show that deciding whether its symmetric difference is at most 8 is co-NP-complete, and whether its sd-degeneracy is at most 1 is NP-complete."],"url":"http://arxiv.org/abs/2405.09011v1"}
{"created":"2024-05-15 00:30:10","title":"On Low Field Size Constructions of Access-Optimal Convertible Codes","abstract":"Most large-scale storage systems employ erasure coding to provide resilience against disk failures. Recent work has shown that tuning this redundancy to changes in disk failure rates leads to substantial storage savings. This process requires code conversion, wherein data encoded using an $[n^{I\\mskip-2mu},k^{I\\mskip-2mu}]$ initial code has to be transformed into data encoded using an $[n^{F\\mskip-2mu},k^{F\\mskip-2mu}]$ final code, a resource-intensive operation. Convertible codes are a class of codes that enable efficient code conversion while maintaining other desirable properties. In this paper, we focus on the access cost of conversion (total number of code symbols accessed in the conversion process) and on an important subclass of conversions known as the merge regime (combining multiple initial codewords into a single final codeword).   In this setting, explicit constructions are known for systematic access-optimal Maximum Distance Separable (MDS) convertible codes for all parameters in the merge regime. However, the existing construction for a key subset of these parameters, which makes use of Vandermonde parity matrices, requires a large field size making it unsuitable for practical applications. In this paper, we provide (1) sharper bounds on the minimum field size requirement for such codes, and (2) explicit constructions for low field sizes for several parameter ranges. In doing so, we provide a proof of super-regularity of specially designed classes of Vandermonde matrices that could be of independent interest.","sentences":["Most large-scale storage systems employ erasure coding to provide resilience against disk failures.","Recent work has shown that tuning this redundancy to changes in disk failure rates leads to substantial storage savings.","This process requires code conversion, wherein data encoded using an $[n^{I\\mskip-2mu},k^{I\\mskip-2mu}]$ initial code has to be transformed into data encoded using an $[n^{F\\mskip-2mu},k^{F\\mskip-2mu}]$ final code, a resource-intensive operation.","Convertible codes are a class of codes that enable efficient code conversion while maintaining other desirable properties.","In this paper, we focus on the access cost of conversion (total number of code symbols accessed in the conversion process) and on an important subclass of conversions known as the merge regime (combining multiple initial codewords into a single final codeword).   ","In this setting, explicit constructions are known for systematic access-optimal Maximum Distance Separable (MDS) convertible codes for all parameters in the merge regime.","However, the existing construction for a key subset of these parameters, which makes use of Vandermonde parity matrices, requires a large field size making it unsuitable for practical applications.","In this paper, we provide (1) sharper bounds on the minimum field size requirement for such codes, and (2) explicit constructions for low field sizes for several parameter ranges.","In doing so, we provide a proof of super-regularity of specially designed classes of Vandermonde matrices that could be of independent interest."],"url":"http://arxiv.org/abs/2405.09010v1"}
{"created":"2024-05-15 00:25:51","title":"Ahead of the Count: An Algorithm for Probabilistic Prediction of Instant Runoff (IRV) Elections","abstract":"How can we probabilistically predict the winner in a ranked-choice election without all ballots being counted? In this study, we introduce a novel algorithm designed to predict outcomes in Instant Runoff Voting (IRV) elections. The algorithm takes as input a set of discrete probability distributions describing vote totals for each candidate ranking and calculates the probability that each candidate will win the election. In fact, we calculate all possible sequences of eliminations that might occur in the IRV rounds and assign a probability to each.   The discrete probability distributions can be arbitrary and, in applications, could be measured empirically from pre-election polling data or from partial vote tallies of an in-progress election.   The algorithm is effective for elections with a small number of candidates (five or fewer), with fast execution on typical consumer computers. The run-time is short enough for our method to be used for real-time election night modeling where new predictions are made continuously as more and more vote information becomes available. We demonstrate the algorithm in abstract examples, and also using real data from the 2022 Alaska state elections to simulate election-night predictions and also predictions of election recounts.","sentences":["How can we probabilistically predict the winner in a ranked-choice election without all ballots being counted?","In this study, we introduce a novel algorithm designed to predict outcomes in Instant Runoff Voting (IRV) elections.","The algorithm takes as input a set of discrete probability distributions describing vote totals for each candidate ranking and calculates the probability that each candidate will win the election.","In fact, we calculate all possible sequences of eliminations that might occur in the IRV rounds and assign a probability to each.   ","The discrete probability distributions can be arbitrary and, in applications, could be measured empirically from pre-election polling data or from partial vote tallies of an in-progress election.   ","The algorithm is effective for elections with a small number of candidates (five or fewer), with fast execution on typical consumer computers.","The run-time is short enough for our method to be used for real-time election night modeling where new predictions are made continuously as more and more vote information becomes available.","We demonstrate the algorithm in abstract examples, and also using real data from the 2022 Alaska state elections to simulate election-night predictions and also predictions of election recounts."],"url":"http://arxiv.org/abs/2405.09009v1"}
{"created":"2024-05-14 23:41:44","title":"LLM-Assisted Rule Based Machine Translation for Low/No-Resource Languages","abstract":"We propose a new paradigm for machine translation that is particularly useful for no-resource languages (those without any publicly available bilingual or monolingual corpora): LLM-RBMT (LLM-Assisted Rule Based Machine Translation). Using the LLM-RBMT paradigm, we design the first language education/revitalization-oriented machine translator for Owens Valley Paiute (OVP), a critically endangered Indigenous American language for which there is virtually no publicly available data. We present a detailed evaluation of the translator's components: a rule-based sentence builder, an OVP to English translator, and an English to OVP translator. We also discuss the potential of the paradigm, its limitations, and the many avenues for future research that it opens up.","sentences":["We propose a new paradigm for machine translation that is particularly useful for no-resource languages (those without any publicly available bilingual or monolingual corpora): LLM-RBMT (LLM-Assisted Rule Based Machine Translation).","Using the LLM-RBMT paradigm, we design the first language education/revitalization-oriented machine translator for Owens Valley Paiute (OVP), a critically endangered Indigenous American language for which there is virtually no publicly available data.","We present a detailed evaluation of the translator's components: a rule-based sentence builder, an OVP to English translator, and an English to OVP translator.","We also discuss the potential of the paradigm, its limitations, and the many avenues for future research that it opens up."],"url":"http://arxiv.org/abs/2405.08997v2"}
{"created":"2024-05-14 21:20:27","title":"Wearable Sensor-Based Few-Shot Continual Learning on Hand Gestures for Motor-Impaired Individuals via Latent Embedding Exploitation","abstract":"Hand gestures can provide a natural means of human-computer interaction and enable people who cannot speak to communicate efficiently. Existing hand gesture recognition methods heavily depend on pre-defined gestures, however, motor-impaired individuals require new gestures tailored to each individual's gesture motion and style. Gesture samples collected from different persons have distribution shifts due to their health conditions, the severity of the disability, motion patterns of the arms, etc. In this paper, we introduce the Latent Embedding Exploitation (LEE) mechanism in our replay-based Few-Shot Continual Learning (FSCL) framework that significantly improves the performance of fine-tuning a model for out-of-distribution data. Our method produces a diversified latent feature space by leveraging a preserved latent embedding known as \\textit{gesture prior knowledge}, along with \\textit{intra-gesture divergence} derived from two additional embeddings. Thus, the model can capture latent statistical structure in highly variable gestures with limited samples. We conduct an experimental evaluation using the SmartWatch Gesture and the Motion Gesture datasets. The proposed method results in an average test accuracy of 57.0\\%, 64.6\\%, and 69.3\\% by using one, three, and five samples for six different gestures. Our method helps motor-impaired persons leverage wearable devices, and their unique styles of movement can be learned and applied in human-computer interaction and social communication.","sentences":["Hand gestures can provide a natural means of human-computer interaction and enable people who cannot speak to communicate efficiently.","Existing hand gesture recognition methods heavily depend on pre-defined gestures, however, motor-impaired individuals require new gestures tailored to each individual's gesture motion and style.","Gesture samples collected from different persons have distribution shifts due to their health conditions, the severity of the disability, motion patterns of the arms, etc.","In this paper, we introduce the Latent Embedding Exploitation (LEE) mechanism in our replay-based Few-Shot Continual Learning (FSCL) framework that significantly improves the performance of fine-tuning a model for out-of-distribution data.","Our method produces a diversified latent feature space by leveraging a preserved latent embedding known as \\textit{gesture prior knowledge}, along with \\textit{intra-gesture divergence} derived from two additional embeddings.","Thus, the model can capture latent statistical structure in highly variable gestures with limited samples.","We conduct an experimental evaluation using the SmartWatch Gesture and the Motion Gesture datasets.","The proposed method results in an average test accuracy of 57.0\\%, 64.6\\%, and 69.3\\% by using one, three, and five samples for six different gestures.","Our method helps motor-impaired persons leverage wearable devices, and their unique styles of movement can be learned and applied in human-computer interaction and social communication."],"url":"http://arxiv.org/abs/2405.08969v1"}
{"created":"2024-05-14 21:01:12","title":"Bird's-Eye View to Street-View: A Survey","abstract":"In recent years, street view imagery has grown to become one of the most important sources of geospatial data collection and urban analytics, which facilitates generating meaningful insights and assisting in decision-making. Synthesizing a street-view image from its corresponding satellite image is a challenging task due to the significant differences in appearance and viewpoint between the two domains. In this study, we screened 20 recent research papers to provide a thorough review of the state-of-the-art of how street-view images are synthesized from their corresponding satellite counterparts. The main findings are: (i) novel deep learning techniques are required for synthesizing more realistic and accurate street-view images; (ii) more datasets need to be collected for public usage; and (iii) more specific evaluation metrics need to be investigated for evaluating the generated images appropriately. We conclude that, due to applying outdated deep learning techniques, the recent literature failed to generate detailed and diverse street-view images.","sentences":["In recent years, street view imagery has grown to become one of the most important sources of geospatial data collection and urban analytics, which facilitates generating meaningful insights and assisting in decision-making.","Synthesizing a street-view image from its corresponding satellite image is a challenging task due to the significant differences in appearance and viewpoint between the two domains.","In this study, we screened 20 recent research papers to provide a thorough review of the state-of-the-art of how street-view images are synthesized from their corresponding satellite counterparts.","The main findings are: (i) novel deep learning techniques are required for synthesizing more realistic and accurate street-view images; (ii) more datasets need to be collected for public usage; and (iii) more specific evaluation metrics need to be investigated for evaluating the generated images appropriately.","We conclude that, due to applying outdated deep learning techniques, the recent literature failed to generate detailed and diverse street-view images."],"url":"http://arxiv.org/abs/2405.08961v1"}
{"created":"2024-05-14 20:46:14","title":"Zero-Shot Transfer of Neural ODEs","abstract":"Autonomous systems often encounter environments and scenarios beyond the scope of their training data, which underscores a critical challenge: the need to generalize and adapt to unseen scenarios in real time. This challenge necessitates new mathematical and algorithmic tools that enable adaptation and zero-shot transfer. To this end, we leverage the theory of function encoders, which enables zero-shot transfer by combining the flexibility of neural networks with the mathematical principles of Hilbert spaces. Using this theory, we first present a method for learning a space of dynamics spanned by a set of neural ODE basis functions. After training, the proposed approach can rapidly identify dynamics in the learned space using an efficient inner product calculation. Critically, this calculation requires no gradient calculations or retraining during the online phase. This method enables zero-shot transfer for autonomous systems at runtime and opens the door for a new class of adaptable control algorithms. We demonstrate state-of-the-art system modeling accuracy for two MuJoCo robot environments and show that the learned models can be used for more efficient MPC control of a quadrotor.","sentences":["Autonomous systems often encounter environments and scenarios beyond the scope of their training data, which underscores a critical challenge: the need to generalize and adapt to unseen scenarios in real time.","This challenge necessitates new mathematical and algorithmic tools that enable adaptation and zero-shot transfer.","To this end, we leverage the theory of function encoders, which enables zero-shot transfer by combining the flexibility of neural networks with the mathematical principles of Hilbert spaces.","Using this theory, we first present a method for learning a space of dynamics spanned by a set of neural ODE basis functions.","After training, the proposed approach can rapidly identify dynamics in the learned space using an efficient inner product calculation.","Critically, this calculation requires no gradient calculations or retraining during the online phase.","This method enables zero-shot transfer for autonomous systems at runtime and opens the door for a new class of adaptable control algorithms.","We demonstrate state-of-the-art system modeling accuracy for two MuJoCo robot environments and show that the learned models can be used for more efficient MPC control of a quadrotor."],"url":"http://arxiv.org/abs/2405.08954v1"}
{"created":"2024-05-14 20:28:09","title":"Analyzing Nursing Assistant Attitudes Towards Empathic Geriatric Caregiving Using Quantitative Ethnography","abstract":"An emergent challenge in geriatric care is improving the quality of care, which requires insight from stakeholders. Qualitative methods offer detailed insights, but they can be biased and have limited generalizability, while quantitative methods may miss nuances. Network-based approaches, such as quantitative ethnography (QE), can bridge this methodological gap. By leveraging the strengths of both methods, QE provides profound insights into need finding interviews. In this paper, to better understand geriatric care attitudes, we interviewed ten nursing assistants, used QE to analyze the data, and compared their daily activities in real life with training experiences. A two-sample t-test with a large effect size (Cohen's d=1.63) indicated a significant difference between real-life and training activities. The findings suggested incorporating more empathetic training scenarios into the future design of our geriatric care simulation. The results have implications for human-computer interaction and human factors. This is illustrated by presenting an example of using QE to analyze expert interviews with nursing assistants as caregivers to inform subsequent design processes.","sentences":["An emergent challenge in geriatric care is improving the quality of care, which requires insight from stakeholders.","Qualitative methods offer detailed insights, but they can be biased and have limited generalizability, while quantitative methods may miss nuances.","Network-based approaches, such as quantitative ethnography (QE), can bridge this methodological gap.","By leveraging the strengths of both methods, QE provides profound insights into need finding interviews.","In this paper, to better understand geriatric care attitudes, we interviewed ten nursing assistants, used QE to analyze the data, and compared their daily activities in real life with training experiences.","A two-sample t-test with a large effect size (Cohen's d=1.63) indicated a significant difference between real-life and training activities.","The findings suggested incorporating more empathetic training scenarios into the future design of our geriatric care simulation.","The results have implications for human-computer interaction and human factors.","This is illustrated by presenting an example of using QE to analyze expert interviews with nursing assistants as caregivers to inform subsequent design processes."],"url":"http://arxiv.org/abs/2405.08948v1"}
{"created":"2024-05-14 20:09:25","title":"Pointwise Lipschitz Continuous Graph Algorithms via Proximal Gradient Analysis","abstract":"In many real-world applications, it is prohibitively expensive to drastically change the solution to a problem after a small perturbation in the environment. Therefore, the stability of an algorithm is a very desirable property. In this paper, we study the class of pointwise Lipschitz continuous algorithms as introduced in the recent work of Kumabe and Yoshida [KY23b, FOCS'23]. The Lipschitz constant of an algorithm, intuitively, bounds the ratio of the changes in its output (measured in $\\ell_1$ distance) over the perturbations of its input. Prior to our work, most of the attention was focused on the weighted setting whereas only the maximum bipartite matching and the minimum spanning tree problems were studied in the unweighted which is our focus.   In this paper, we give a general and simple framework for bounding the Lipschitz constant of algorithms measured through the unweighted $\\ell_1$ distance of their outputs. Our approach consists of three main steps. First, we consider a natural continuous relaxation of the underlying graph problem by adding a smooth and strongly convex regularizer to the objective function. Then, we give upper bounds on the $\\ell_1$ distance of the optimal solutions of the convex programs, under small perturbations of the weights, via a stability analysis of the trajectory of the proximal gradient method. Finally, we present new problem-specific rounding techniques to obtain integral solutions to several graph problems that approximately maintain the stability guarantees of the fractional solutions. We apply our framework to a number of problems including minimum $s$-$t$ cut, multiway cut, densest subgraph, maximum ($b$-)matching, and packing integer programs. To complement our algorithms, we show the tightness of our results for certain problems by establishing matching lower bounds.","sentences":["In many real-world applications, it is prohibitively expensive to drastically change the solution to a problem after a small perturbation in the environment.","Therefore, the stability of an algorithm is a very desirable property.","In this paper, we study the class of pointwise Lipschitz continuous algorithms as introduced in the recent work of Kumabe and Yoshida","[KY23b, FOCS'23].","The Lipschitz constant of an algorithm, intuitively, bounds the ratio of the changes in its output (measured in $\\ell_1$ distance) over the perturbations of its input.","Prior to our work, most of the attention was focused on the weighted setting whereas only the maximum bipartite matching and the minimum spanning tree problems were studied in the unweighted which is our focus.   ","In this paper, we give a general and simple framework for bounding the Lipschitz constant of algorithms measured through the unweighted $\\ell_1$ distance of their outputs.","Our approach consists of three main steps.","First, we consider a natural continuous relaxation of the underlying graph problem by adding a smooth and strongly convex regularizer to the objective function.","Then, we give upper bounds on the $\\ell_1$ distance of the optimal solutions of the convex programs, under small perturbations of the weights, via a stability analysis of the trajectory of the proximal gradient method.","Finally, we present new problem-specific rounding techniques to obtain integral solutions to several graph problems that approximately maintain the stability guarantees of the fractional solutions.","We apply our framework to a number of problems including minimum $s$-$t$ cut, multiway cut, densest subgraph, maximum ($b$-)matching, and packing integer programs.","To complement our algorithms, we show the tightness of our results for certain problems by establishing matching lower bounds."],"url":"http://arxiv.org/abs/2405.08938v1"}
{"created":"2024-05-14 19:53:20","title":"Self-supervised vision-langage alignment of deep learning representations for bone X-rays analysis","abstract":"This paper proposes leveraging vision-language pretraining on bone X-rays paired with French reports to address downstream tasks of interest on bone radiography. A practical processing pipeline is introduced to anonymize and process French medical reports. Pretraining then consists in the self-supervised alignment of visual and textual embedding spaces derived from deep model encoders. The resulting image encoder is then used to handle various downstream tasks, including quantification of osteoarthritis, estimation of bone age on pediatric wrists, bone fracture and anomaly detection. Our approach demonstrates competitive performance on downstream tasks, compared to alternatives requiring a significantly larger amount of human expert annotations. Our work stands as the first study to integrate French reports to shape the embedding space devoted to bone X-Rays representations, capitalizing on the large quantity of paired images and reports data available in an hospital. By relying on generic vision-laguage deep models in a language-specific scenario, it contributes to the deployement of vision models for wider healthcare applications.","sentences":["This paper proposes leveraging vision-language pretraining on bone X-rays paired with French reports to address downstream tasks of interest on bone radiography.","A practical processing pipeline is introduced to anonymize and process French medical reports.","Pretraining then consists in the self-supervised alignment of visual and textual embedding spaces derived from deep model encoders.","The resulting image encoder is then used to handle various downstream tasks, including quantification of osteoarthritis, estimation of bone age on pediatric wrists, bone fracture and anomaly detection.","Our approach demonstrates competitive performance on downstream tasks, compared to alternatives requiring a significantly larger amount of human expert annotations.","Our work stands as the first study to integrate French reports to shape the embedding space devoted to bone X-Rays representations, capitalizing on the large quantity of paired images and reports data available in an hospital.","By relying on generic vision-laguage deep models in a language-specific scenario, it contributes to the deployement of vision models for wider healthcare applications."],"url":"http://arxiv.org/abs/2405.08932v1"}
{"created":"2024-05-14 19:50:08","title":"A QPTAS for Facility Location on Unit Disk graphs","abstract":"We study the classic \\textsc{(Uncapacitated) Facility Location} problem on Unit Disk Graphs (UDGs). For a given point set $P$ in the plane, the unit disk graph UDG(P) on $P$ has vertex set $P$ and an edge between two distinct points $p, q \\in P$ if and only if their Euclidean distance $|pq|$ is at most 1. The weight of the edge $pq$ is equal to their distance $|pq|$. An instance of \\fl on UDG(P) consists of a set $C\\subseteq P$ of clients and a set $F\\subseteq P$ of facilities, each having an opening cost $f_i$. The goal is to pick a subset $F'\\subseteq F$ to open while minimizing $\\sum_{i\\in F'} f_i + \\sum_{v\\in C} d(v,F')$, where $d(v,F')$ is the distance of $v$ to nearest facility in $F'$ through UDG(P).   In this paper, we present the first Quasi-Polynomial Time Approximation Schemes (QPTAS) for the problem. While approximation schemes are well-established for facility location problems on sparse geometric graphs (such as planar graphs), there is a lack of such results for dense graphs. Specifically, prior to this study, to the best of our knowledge, there was no approximation scheme for any facility location problem on UDGs in the general setting.","sentences":["We study the classic \\textsc{(Uncapacitated) Facility Location} problem on Unit Disk Graphs (UDGs).","For a given point set $P$ in the plane, the unit disk graph UDG(P) on $P$ has vertex set $P$ and an edge between two distinct points $p, q \\in P$ if and only if their Euclidean distance $|pq|$ is at most 1.","The weight of the edge $pq$ is equal to their distance $|pq|$. An instance of \\fl on UDG(P) consists of a set $C\\subseteq P$ of clients and a set $F\\subseteq P$ of facilities, each having an opening cost $f_i$. The goal is to pick a subset $F'\\subseteq F$ to open while minimizing $\\sum_{i\\in F'} f_i","+ \\sum_{v\\in C} d(v,F')$, where $d(v,F')$ is the distance of $v$ to nearest facility in $F'$ through UDG(P).   ","In this paper, we present the first Quasi-Polynomial Time Approximation Schemes (QPTAS) for the problem.","While approximation schemes are well-established for facility location problems on sparse geometric graphs (such as planar graphs), there is a lack of such results for dense graphs.","Specifically, prior to this study, to the best of our knowledge, there was no approximation scheme for any facility location problem on UDGs in the general setting."],"url":"http://arxiv.org/abs/2405.08931v1"}
{"created":"2024-05-14 19:47:18","title":"Expanderizing Higher Order Random Walks","abstract":"We study a variant of the down-up and up-down walks over an $n$-partite simplicial complex, which we call expanderized higher order random walks -- where the sequence of updated coordinates correspond to the sequence of vertices visited by a random walk over an auxiliary expander graph $H$. When $H$ is the clique, this random walk reduces to the usual down-up walk and when $H$ is the directed cycle, this random walk reduces to the well-known systematic scan Glauber dynamics. We show that whenever the usual higher order random walks satisfy a log-Sobolev inequality or a Poincar\\'e inequality, the expanderized walks satisfy the same inequalities with a loss of quality related to the two-sided expansion of the auxillary graph $H$. Our construction can be thought as a higher order random walk generalization of the derandomized squaring algorithm of Rozenman and Vadhan. We show that when initiated with an expander graph our expanderized random walks have mixing time $O(n \\log n)$ for sampling a uniformly random list colorings of a graph $G$ of maximum degree $\\Delta = O(1)$ where each vertex has at least $(11/6 - \\epsilon) \\Delta$ and at most $O(\\Delta)$ colors and $O\\left( \\frac{n \\log n}{(1 - \\| J\\|)^2}\\right)$ for sampling the Ising model with a PSD interaction matrix $J \\in R^{n \\times n}$ satisfying $\\| J \\| \\le 1$ and the external field $h \\in R^n$-- here the $O(\\bullet)$ notation hides a constant that depends linearly on the largest entry of $h$. As expander graphs can be very sparse, this decreases the amount of randomness required to simulate the down-up walks by a logarithmic factor. We also prove some simple results which enable us to argue about log-Sobolev constants of higher order random walks and provide a simple and self-contained analysis of local-to-global $\\Phi$-entropy contraction in simplicial complexes -- giving simpler proofs for many pre-existing results.","sentences":["We study a variant of the down-up and up-down walks over an $n$-partite simplicial complex, which we call expanderized higher order random walks -- where the sequence of updated coordinates correspond to the sequence of vertices visited by a random walk over an auxiliary expander graph $H$. When $H$ is the clique, this random walk reduces to the usual down-up walk and when $H$ is the directed cycle, this random walk reduces to the well-known systematic scan Glauber dynamics.","We show that whenever the usual higher order random walks satisfy a log-Sobolev inequality or a Poincar\\'e inequality, the expanderized walks satisfy the same inequalities with a loss of quality related to the two-sided expansion of the auxillary graph $H$. Our construction can be thought as a higher order random walk generalization of the derandomized squaring algorithm of Rozenman and Vadhan.","We show that when initiated with an expander graph our expanderized random walks have mixing time $O(n \\log n)$ for sampling a uniformly random list colorings of a graph $G$ of maximum degree $\\Delta = O(1)$ where each vertex has at least $(11/6 - \\epsilon) \\Delta$ and at most $O(\\Delta)$ colors and $O\\left( \\frac{n \\log n}{(1 - \\| J\\|)^2}\\right)$ for sampling the Ising model with a PSD interaction matrix $J \\in R^{n \\times n}$ satisfying $\\| J \\| \\le 1$ and the external field $h \\in R^n$-- here the $O(\\bullet)$ notation hides a constant that depends linearly on the largest entry of $h$. As expander graphs can be very sparse, this decreases the amount of randomness required to simulate the down-up walks by a logarithmic factor.","We also prove some simple results which enable us to argue about log-Sobolev constants of higher order random walks and provide a simple and self-contained analysis of local-to-global $\\Phi$-entropy contraction in simplicial complexes -- giving simpler proofs for many pre-existing results."],"url":"http://arxiv.org/abs/2405.08927v1"}
{"created":"2024-05-14 19:06:24","title":"CLIP with Quality Captions: A Strong Pretraining for Vision Tasks","abstract":"CLIP models perform remarkably well on zero-shot classification and retrieval tasks. But recent studies have shown that learnt representations in CLIP are not well suited for dense prediction tasks like object detection, semantic segmentation or depth estimation. More recently, multi-stage training methods for CLIP models was introduced to mitigate the weak performance of CLIP on downstream tasks. In this work, we find that simply improving the quality of captions in image-text datasets improves the quality of CLIP's visual representations, resulting in significant improvement on downstream dense prediction vision tasks. In fact, we find that CLIP pretraining with good quality captions can surpass recent supervised, self-supervised and weakly supervised pretraining methods. We show that when CLIP model with ViT-B/16 as image encoder is trained on well aligned image-text pairs it obtains 12.1% higher mIoU and 11.5% lower RMSE on semantic segmentation and depth estimation tasks over recent state-of-the-art Masked Image Modeling (MIM) pretraining methods like Masked Autoencoder (MAE). We find that mobile architectures also benefit significantly from CLIP pretraining. A recent mobile vision architecture, MCi2, with CLIP pretraining obtains similar performance as Swin-L, pretrained on ImageNet-22k for semantic segmentation task while being 6.1$\\times$ smaller. Moreover, we show that improving caption quality results in $10\\times$ data efficiency when finetuning for dense prediction tasks.","sentences":["CLIP models perform remarkably well on zero-shot classification and retrieval tasks.","But recent studies have shown that learnt representations in CLIP are not well suited for dense prediction tasks like object detection, semantic segmentation or depth estimation.","More recently, multi-stage training methods for CLIP models was introduced to mitigate the weak performance of CLIP on downstream tasks.","In this work, we find that simply improving the quality of captions in image-text datasets improves the quality of CLIP's visual representations, resulting in significant improvement on downstream dense prediction vision tasks.","In fact, we find that CLIP pretraining with good quality captions can surpass recent supervised, self-supervised and weakly supervised pretraining methods.","We show that when CLIP model with ViT-B/16 as image encoder is trained on well aligned image-text pairs it obtains 12.1% higher mIoU and 11.5% lower RMSE on semantic segmentation and depth estimation tasks over recent state-of-the-art Masked Image Modeling (MIM) pretraining methods like Masked Autoencoder (MAE).","We find that mobile architectures also benefit significantly from CLIP pretraining.","A recent mobile vision architecture, MCi2, with CLIP pretraining obtains similar performance as Swin-L, pretrained on ImageNet-22k for semantic segmentation task while being 6.1$\\times$ smaller.","Moreover, we show that improving caption quality results in $10\\times$ data efficiency when finetuning for dense prediction tasks."],"url":"http://arxiv.org/abs/2405.08911v1"}
{"created":"2024-05-14 19:02:33","title":"ADA-Track: End-to-End Multi-Camera 3D Multi-Object Tracking with Alternating Detection and Association","abstract":"Many query-based approaches for 3D Multi-Object Tracking (MOT) adopt the tracking-by-attention paradigm, utilizing track queries for identity-consistent detection and object queries for identity-agnostic track spawning. Tracking-by-attention, however, entangles detection and tracking queries in one embedding for both the detection and tracking task, which is sub-optimal. Other approaches resemble the tracking-by-detection paradigm, detecting objects using decoupled track and detection queries followed by a subsequent association. These methods, however, do not leverage synergies between the detection and association task. Combining the strengths of both paradigms, we introduce ADA-Track, a novel end-to-end framework for 3D MOT from multi-view cameras. We introduce a learnable data association module based on edge-augmented cross-attention, leveraging appearance and geometric features. Furthermore, we integrate this association module into the decoder layer of a DETR-based 3D detector, enabling simultaneous DETR-like query-to-image cross-attention for detection and query-to-query cross-attention for data association. By stacking these decoder layers, queries are refined for the detection and association task alternately, effectively harnessing the task dependencies. We evaluate our method on the nuScenes dataset and demonstrate the advantage of our approach compared to the two previous paradigms. Code is available at https://github.com/dsx0511/ADA-Track.","sentences":["Many query-based approaches for 3D Multi-Object Tracking (MOT) adopt the tracking-by-attention paradigm, utilizing track queries for identity-consistent detection and object queries for identity-agnostic track spawning.","Tracking-by-attention, however, entangles detection and tracking queries in one embedding for both the detection and tracking task, which is sub-optimal.","Other approaches resemble the tracking-by-detection paradigm, detecting objects using decoupled track and detection queries followed by a subsequent association.","These methods, however, do not leverage synergies between the detection and association task.","Combining the strengths of both paradigms, we introduce ADA-Track, a novel end-to-end framework for 3D MOT from multi-view cameras.","We introduce a learnable data association module based on edge-augmented cross-attention, leveraging appearance and geometric features.","Furthermore, we integrate this association module into the decoder layer of a DETR-based 3D detector, enabling simultaneous DETR-like query-to-image cross-attention for detection and query-to-query cross-attention for data association.","By stacking these decoder layers, queries are refined for the detection and association task alternately, effectively harnessing the task dependencies.","We evaluate our method on the nuScenes dataset and demonstrate the advantage of our approach compared to the two previous paradigms.","Code is available at https://github.com/dsx0511/ADA-Track."],"url":"http://arxiv.org/abs/2405.08909v1"}
{"created":"2024-05-14 18:47:04","title":"fNIRS Analysis of Interaction Techniques in Touchscreen-Based Educational Gaming","abstract":"Touchscreens are becoming increasingly widespread in educational games, enhancing the quality of learner experience. Traditional metrics are often used to evaluate various input modalities, including hand and stylus. However, there exists a gap in understanding the cognitive impacts of these modalities during educational gameplay, which can be addressed through brain signal analysis to gain deeper insights into the underlying cognitive function and necessary brain resources for each condition. This facilitates a more precise comparison between conditions. In this study, we compared the brain signal and user experience of using hands and stylus on touchscreens while playing an educational game by analyzing hemodynamic response and self-reported measures. Participants engaged in a Unity-based educational quiz game using both hand and stylus on a touchscreen in a counterbalanced within-subject design. Oxygenated and deoxygenated hemoglobin data were collected using fNIRS, alongside quiz performance scores and standardized and customized user experience questionnaire ratings. Our findings show almost the same performance level with both input modalities, however, the hand requires less oxygen flow which suggests a lower cognitive effort than using a stylus while playing the educational game. Although the result shows that the stylus condition required more neural involvement than the hand condition, there is no significant difference between the use of both input modalities. However, there is a statistically significant difference in self-reported measures that support the findings mentioned above, favoring the hand that enhances understanding of modality effects in interactive educational environments.","sentences":["Touchscreens are becoming increasingly widespread in educational games, enhancing the quality of learner experience.","Traditional metrics are often used to evaluate various input modalities, including hand and stylus.","However, there exists a gap in understanding the cognitive impacts of these modalities during educational gameplay, which can be addressed through brain signal analysis to gain deeper insights into the underlying cognitive function and necessary brain resources for each condition.","This facilitates a more precise comparison between conditions.","In this study, we compared the brain signal and user experience of using hands and stylus on touchscreens while playing an educational game by analyzing hemodynamic response and self-reported measures.","Participants engaged in a Unity-based educational quiz game using both hand and stylus on a touchscreen in a counterbalanced within-subject design.","Oxygenated and deoxygenated hemoglobin data were collected using fNIRS, alongside quiz performance scores and standardized and customized user experience questionnaire ratings.","Our findings show almost the same performance level with both input modalities, however, the hand requires less oxygen flow which suggests a lower cognitive effort than using a stylus while playing the educational game.","Although the result shows that the stylus condition required more neural involvement than the hand condition, there is no significant difference between the use of both input modalities.","However, there is a statistically significant difference in self-reported measures that support the findings mentioned above, favoring the hand that enhances understanding of modality effects in interactive educational environments."],"url":"http://arxiv.org/abs/2405.08906v1"}
{"created":"2024-05-14 18:10:46","title":"RS-Reg: Probabilistic and Robust Certified Regression Through Randomized Smoothing","abstract":"Randomized smoothing has shown promising certified robustness against adversaries in classification tasks. Despite such success with only zeroth-order access to base models, randomized smoothing has not been extended to a general form of regression. By defining robustness in regression tasks flexibly through probabilities, we demonstrate how to establish upper bounds on input data point perturbation (using the $\\ell_2$ norm) for a user-specified probability of observing valid outputs. Furthermore, we showcase the asymptotic property of a basic averaging function in scenarios where the regression model operates without any constraint. We then derive a certified upper bound of the input perturbations when dealing with a family of regression models where the outputs are bounded. Our simulations verify the validity of the theoretical results and reveal the advantages and limitations of simple smoothing functions, i.e., averaging, in regression tasks. The code is publicly available at \\url{https://github.com/arekavandi/Certified_Robust_Regression}.","sentences":["Randomized smoothing has shown promising certified robustness against adversaries in classification tasks.","Despite such success with only zeroth-order access to base models, randomized smoothing has not been extended to a general form of regression.","By defining robustness in regression tasks flexibly through probabilities, we demonstrate how to establish upper bounds on input data point perturbation (using the $\\ell_2$ norm) for a user-specified probability of observing valid outputs.","Furthermore, we showcase the asymptotic property of a basic averaging function in scenarios where the regression model operates without any constraint.","We then derive a certified upper bound of the input perturbations when dealing with a family of regression models where the outputs are bounded.","Our simulations verify the validity of the theoretical results and reveal the advantages and limitations of simple smoothing functions, i.e., averaging, in regression tasks.","The code is publicly available at \\url{https://github.com/arekavandi/Certified_Robust_Regression}."],"url":"http://arxiv.org/abs/2405.08892v1"}
