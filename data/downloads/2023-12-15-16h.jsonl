{"created":"2023-12-13 18:59:58","title":"SAM-guided Graph Cut for 3D Instance Segmentation","abstract":"This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information. Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation. However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data. Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework. The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation. Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem. The superpoint graph is constructed based on 2D segmentation models, where node features are obtained from multi-view image features and edge weights are computed based on multi-view segmentation results, enabling the better generalization ability. To process the graph, we train a graph neural network using pseudo 3D labels from 2D segmentation models. Experimental results on the ScanNet, ScanNet++ and KITTI-360 datasets demonstrate that our method achieves robust segmentation performance and can generalize across different types of scenes. Our project page is available at https://zju3dv.github.io/sam_graph.","sentences":["This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information.","Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation.","However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data.","Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework.","The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation.","In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation.","Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem.","The superpoint graph is constructed based on 2D segmentation models, where node features are obtained from multi-view image features and edge weights are computed based on multi-view segmentation results, enabling the better generalization ability.","To process the graph, we train a graph neural network using pseudo 3D labels from 2D segmentation models.","Experimental results on the ScanNet, ScanNet++ and KITTI-360 datasets demonstrate that our method achieves robust segmentation performance and can generalize across different types of scenes.","Our project page is available at https://zju3dv.github.io/sam_graph."],"url":"http://arxiv.org/abs/2312.08372v1"}
{"created":"2023-12-13 18:56:13","title":"View-Dependent Octree-based Mesh Extraction in Unbounded Scenes for Procedural Synthetic Data","abstract":"Procedural synthetic data generation has received increasing attention in computer vision. Procedural signed distance functions (SDFs) are a powerful tool for modeling large-scale detailed scenes, but existing mesh extraction methods have artifacts or performance profiles that limit their use for synthetic data. We propose OcMesher, a mesh extraction algorithm that efficiently handles high-detail unbounded scenes with perfect view-consistency, with easy export to downstream real-time engines. The main novelty of our solution is an algorithm to construct an octree based on a given SDF and multiple camera views. We performed extensive experiments, and show our solution produces better synthetic data for training and evaluation of computer vision models.","sentences":["Procedural synthetic data generation has received increasing attention in computer vision.","Procedural signed distance functions (SDFs) are a powerful tool for modeling large-scale detailed scenes, but existing mesh extraction methods have artifacts or performance profiles that limit their use for synthetic data.","We propose OcMesher, a mesh extraction algorithm that efficiently handles high-detail unbounded scenes with perfect view-consistency, with easy export to downstream real-time engines.","The main novelty of our solution is an algorithm to construct an octree based on a given SDF and multiple camera views.","We performed extensive experiments, and show our solution produces better synthetic data for training and evaluation of computer vision models."],"url":"http://arxiv.org/abs/2312.08364v1"}
{"created":"2023-12-13 18:51:34","title":"Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF","abstract":"In practice, preference learning from human feedback depends on incomplete data with hidden context. Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model. This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria. We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count. We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility. Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function. A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF. As a step towards mitigating these problems, we introduce a class of methods called distributional preference learning (DPL). DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context. Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability. Our code and data are available at https://github.com/cassidylaidlaw/hidden-context","sentences":["In practice, preference learning from human feedback depends on incomplete data with hidden context.","Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model.","This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria.","We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count.","We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility.","Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function.","A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF.","As a step towards mitigating these problems, we introduce a class of methods called distributional preference learning (DPL).","DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context.","Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability.","Our code and data are available at https://github.com/cassidylaidlaw/hidden-context"],"url":"http://arxiv.org/abs/2312.08358v1"}
{"created":"2023-12-13 18:11:37","title":"LD-SDM: Language-Driven Hierarchical Species Distribution Modeling","abstract":"We focus on the problem of species distribution modeling using global-scale presence-only data. Most previous studies have mapped the range of a given species using geographical and environmental features alone. To capture a stronger implicit relationship between species, we encode the taxonomic hierarchy of species using a large language model. This enables range mapping for any taxonomic rank and unseen species without additional supervision. Further, we propose a novel proximity-aware evaluation metric that enables evaluating species distribution models using any pixel-level representation of ground-truth species range map. The proposed metric penalizes the predictions of a model based on its proximity to the ground truth. We describe the effectiveness of our model by systematically evaluating on the task of species range prediction, zero-shot prediction and geo-feature regression against the state-of-the-art. Results show our model outperforms the strong baselines when trained with a variety of multi-label learning losses.","sentences":["We focus on the problem of species distribution modeling using global-scale presence-only data.","Most previous studies have mapped the range of a given species using geographical and environmental features alone.","To capture a stronger implicit relationship between species, we encode the taxonomic hierarchy of species using a large language model.","This enables range mapping for any taxonomic rank and unseen species without additional supervision.","Further, we propose a novel proximity-aware evaluation metric that enables evaluating species distribution models using any pixel-level representation of ground-truth species range map.","The proposed metric penalizes the predictions of a model based on its proximity to the ground truth.","We describe the effectiveness of our model by systematically evaluating on the task of species range prediction, zero-shot prediction and geo-feature regression against the state-of-the-art.","Results show our model outperforms the strong baselines when trained with a variety of multi-label learning losses."],"url":"http://arxiv.org/abs/2312.08334v1"}
{"created":"2023-12-13 17:27:17","title":"FASTEN: Towards a FAult-tolerant and STorage EfficieNt Cloud: Balancing Between Replication and Deduplication","abstract":"With the surge in cloud storage adoption, enterprises face challenges managing data duplication and exponential data growth. Deduplication mitigates redundancy, yet maintaining redundancy ensures high availability, incurring storage costs. Balancing these aspects is a significant research concern. We propose FASTEN, a distributed cloud storage scheme ensuring efficiency, security, and high availability. FASTEN achieves fault tolerance by dispersing data subsets optimally across servers and maintains redundancy for high availability. Experimental results show FASTEN's effectiveness in fault tolerance, cost reduction, batch auditing, and file and block-level deduplication. It outperforms existing systems with low time complexity, strong fault tolerance, and commendable deduplication performance.","sentences":["With the surge in cloud storage adoption, enterprises face challenges managing data duplication and exponential data growth.","Deduplication mitigates redundancy, yet maintaining redundancy ensures high availability, incurring storage costs.","Balancing these aspects is a significant research concern.","We propose FASTEN, a distributed cloud storage scheme ensuring efficiency, security, and high availability.","FASTEN achieves fault tolerance by dispersing data subsets optimally across servers and maintains redundancy for high availability.","Experimental results show FASTEN's effectiveness in fault tolerance, cost reduction, batch auditing, and file and block-level deduplication.","It outperforms existing systems with low time complexity, strong fault tolerance, and commendable deduplication performance."],"url":"http://arxiv.org/abs/2312.08309v1"}
{"created":"2023-12-13 17:26:30","title":"ConChain: A Scheme for Contention-free and Attack Resilient BlockChain","abstract":"Although blockchains have become widely popular for their use in cryptocurrencies, they are now becoming pervasive as more traditional applications adopt blockchain to ensure data security. Despite being a secured network, blockchains have some tradeoffs such as high latency, low throughput, and transaction failures. One of the core problems behind these is improper management of \"conflicting transactions\", which is also known as \"contention\". When there is a large pool of pending transactions in a blockchain and some of them are conflicting, a situation of contention occurs, and as a result, the latency of the network increases, and a substantial amount of resources are wasted which results in low throughput and transaction failures. In this paper, we proposed ConChain, a novel blockchain scheme that combines transaction parallelism and an intelligent dependency manager to minimize conflicting transactions in blockchain networks as well as improve performance. ConChain is also capable of ensuring proper defense against major attacks due to contention.","sentences":["Although blockchains have become widely popular for their use in cryptocurrencies, they are now becoming pervasive as more traditional applications adopt blockchain to ensure data security.","Despite being a secured network, blockchains have some tradeoffs such as high latency, low throughput, and transaction failures.","One of the core problems behind these is improper management of \"conflicting transactions\", which is also known as \"contention\".","When there is a large pool of pending transactions in a blockchain and some of them are conflicting, a situation of contention occurs, and as a result, the latency of the network increases, and a substantial amount of resources are wasted which results in low throughput and transaction failures.","In this paper, we proposed ConChain, a novel blockchain scheme that combines transaction parallelism and an intelligent dependency manager to minimize conflicting transactions in blockchain networks as well as improve performance.","ConChain is also capable of ensuring proper defense against major attacks due to contention."],"url":"http://arxiv.org/abs/2312.08305v1"}
{"created":"2023-12-13 17:15:12","title":"Conceptualizing Suicidal Behavior: Utilizing Explanations of Predicted Outcomes to Analyze Longitudinal Social Media Data","abstract":"The COVID-19 pandemic has escalated mental health crises worldwide, with social isolation and economic instability contributing to a rise in suicidal behavior. Suicide can result from social factors such as shame, abuse, abandonment, and mental health conditions like depression, Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), anxiety disorders, and bipolar disorders. As these conditions develop, signs of suicidal ideation may manifest in social media interactions. Analyzing social media data using artificial intelligence (AI) techniques can help identify patterns of suicidal behavior, providing invaluable insights for suicide prevention agencies, professionals, and broader community awareness initiatives. Machine learning algorithms for this purpose require large volumes of accurately labeled data. Previous research has not fully explored the potential of incorporating explanations in analyzing and labeling longitudinal social media data. In this study, we employed a model explanation method, Layer Integrated Gradients, on top of a fine-tuned state-of-the-art language model, to assign each token from Reddit users' posts an attribution score for predicting suicidal ideation. By extracting and analyzing attributions of tokens from the data, we propose a methodology for preliminary screening of social media posts for suicidal ideation without using large language models during inference.","sentences":["The COVID-19 pandemic has escalated mental health crises worldwide, with social isolation and economic instability contributing to a rise in suicidal behavior.","Suicide can result from social factors such as shame, abuse, abandonment, and mental health conditions like depression, Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), anxiety disorders, and bipolar disorders.","As these conditions develop, signs of suicidal ideation may manifest in social media interactions.","Analyzing social media data using artificial intelligence (AI) techniques can help identify patterns of suicidal behavior, providing invaluable insights for suicide prevention agencies, professionals, and broader community awareness initiatives.","Machine learning algorithms for this purpose require large volumes of accurately labeled data.","Previous research has not fully explored the potential of incorporating explanations in analyzing and labeling longitudinal social media data.","In this study, we employed a model explanation method, Layer Integrated Gradients, on top of a fine-tuned state-of-the-art language model, to assign each token from Reddit users' posts an attribution score for predicting suicidal ideation.","By extracting and analyzing attributions of tokens from the data, we propose a methodology for preliminary screening of social media posts for suicidal ideation without using large language models during inference."],"url":"http://arxiv.org/abs/2312.08299v1"}
{"created":"2023-12-13 17:13:08","title":"Venn: Resource Management Across Federated Learning Jobs","abstract":"In recent years, federated learning (FL) has emerged as a promising approach for machine learning (ML) and data science across distributed edge devices. With the increasing popularity of FL, resource contention between multiple FL jobs training on the same device population is increasing as well. Scheduling edge resources among multiple FL jobs is different from GPU scheduling for cloud ML because of the ephemeral nature and planetary scale of participating devices as well as the overlapping resource requirements of diverse FL jobs. Existing resource managers for FL jobs opt for random assignment of devices to FL jobs for simplicity and scalability, which leads to poor performance. In this paper, we present Venn, an FL resource manager, that efficiently schedules ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing their average job completion time (JCT). Venn formulates the Intersection Resource Scheduling (IRS) problem to identify complex resource contention among multiple FL jobs. Then, Venn proposes a contention-aware scheduling heuristic to minimize the average scheduling delay. Furthermore, it proposes a resource-aware device-to-job matching heuristic that focuses on optimizing response collection time by mitigating stragglers. Our evaluation shows that, compared to the state-of-the-art FL resource managers, Venn improves the average JCT by up to 1.88X.","sentences":["In recent years, federated learning (FL) has emerged as a promising approach for machine learning (ML) and data science across distributed edge devices.","With the increasing popularity of FL, resource contention between multiple FL jobs training on the same device population is increasing as well.","Scheduling edge resources among multiple FL jobs is different from GPU scheduling for cloud ML because of the ephemeral nature and planetary scale of participating devices as well as the overlapping resource requirements of diverse FL jobs.","Existing resource managers for FL jobs opt for random assignment of devices to FL jobs for simplicity and scalability, which leads to poor performance.","In this paper, we present Venn, an FL resource manager, that efficiently schedules ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing their average job completion time (JCT).","Venn formulates the Intersection Resource Scheduling (IRS) problem to identify complex resource contention among multiple FL jobs.","Then, Venn proposes a contention-aware scheduling heuristic to minimize the average scheduling delay.","Furthermore, it proposes a resource-aware device-to-job matching heuristic that focuses on optimizing response collection time by mitigating stragglers.","Our evaluation shows that, compared to the state-of-the-art FL resource managers, Venn improves the average JCT by up to 1.88X."],"url":"http://arxiv.org/abs/2312.08298v1"}
{"created":"2023-12-13 17:04:16","title":"Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting","abstract":"Deep learning models are known to suffer from the problem of bias, and researchers have been exploring methods to address this issue. However, most of these methods require prior knowledge of the bias and are not always practical. In this paper, we focus on a more practical setting with no prior information about the bias. Generally, in this setting, there are a large number of bias-aligned samples that cause the model to produce biased predictions and a few bias-conflicting samples that do not conform to the bias. If the training data is limited, the influence of the bias-aligned samples may become even stronger on the model predictions, and we experimentally demonstrate that existing debiasing techniques suffer severely in such cases. In this paper, we examine the effects of unknown bias in small dataset regimes and present a novel approach to mitigate this issue. The proposed approach directly addresses the issue of the extremely low occurrence of bias-conflicting samples in limited data settings through the synthesis of hybrid samples that can be used to reduce the effect of bias. We perform extensive experiments on several benchmark datasets and experimentally demonstrate the effectiveness of our proposed approach in addressing any unknown bias in the presence of limited data. Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a bias-conflicting sample ratio of 0.05.","sentences":["Deep learning models are known to suffer from the problem of bias, and researchers have been exploring methods to address this issue.","However, most of these methods require prior knowledge of the bias and are not always practical.","In this paper, we focus on a more practical setting with no prior information about the bias.","Generally, in this setting, there are a large number of bias-aligned samples that cause the model to produce biased predictions and a few bias-conflicting samples that do not conform to the bias.","If the training data is limited, the influence of the bias-aligned samples may become even stronger on the model predictions, and we experimentally demonstrate that existing debiasing techniques suffer severely in such cases.","In this paper, we examine the effects of unknown bias in small dataset regimes and present a novel approach to mitigate this issue.","The proposed approach directly addresses the issue of the extremely low occurrence of bias-conflicting samples in limited data settings through the synthesis of hybrid samples that can be used to reduce the effect of bias.","We perform extensive experiments on several benchmark datasets and experimentally demonstrate the effectiveness of our proposed approach in addressing any unknown bias in the presence of limited data.","Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a bias-conflicting sample ratio of 0.05."],"url":"http://arxiv.org/abs/2312.08288v1"}
{"created":"2023-12-13 17:04:09","title":"On the verification of Embeddings using Hybrid Markov Logic","abstract":"The standard approach to verify representations learned by Deep Neural Networks is to use them in specific tasks such as classification or regression, and measure their performance based on accuracy in such tasks. However, in many cases, we would want to verify more complex properties of a learned representation. To do this, we propose a framework based on a probabilistic first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we specify properties over embeddings mixed with symbolic domain knowledge. We present an approach to learn parameters for the properties within this framework. Further, we develop a verification method to test embeddings in this framework by encoding this task as a Mixed Integer Linear Program for which we can leverage existing state-of-the-art solvers. We illustrate verification in Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems to demonstrate the generality of our approach.","sentences":["The standard approach to verify representations learned by Deep Neural Networks is to use them in specific tasks such as classification or regression, and measure their performance based on accuracy in such tasks.","However, in many cases, we would want to verify more complex properties of a learned representation.","To do this, we propose a framework based on a probabilistic first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we specify properties over embeddings mixed with symbolic domain knowledge.","We present an approach to learn parameters for the properties within this framework.","Further, we develop a verification method to test embeddings in this framework by encoding this task as a Mixed Integer Linear Program for which we can leverage existing state-of-the-art solvers.","We illustrate verification in Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems to demonstrate the generality of our approach."],"url":"http://arxiv.org/abs/2312.08287v1"}
{"created":"2023-12-13 16:13:23","title":"A Survey of Generative AI for Intelligent Transportation Systems","abstract":"Intelligent transportation systems play a crucial role in modern traffic management and optimization, greatly improving traffic efficiency and safety. With the rapid development of generative artificial intelligence (Generative AI) technologies in the fields of image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems, such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty. In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in intelligent transportation systems. First, we introduce the principles of different generative AI techniques, and their potential applications. Then, we classify tasks in intelligent transportation systems into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making. We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks. Finally, we summarize the challenges faced in applying generative AI to intelligent transportation systems, and discuss future research directions based on different application scenarios.","sentences":["Intelligent transportation systems play a crucial role in modern traffic management and optimization, greatly improving traffic efficiency and safety.","With the rapid development of generative artificial intelligence (Generative AI) technologies in the fields of image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems, such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty.","In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in intelligent transportation systems.","First, we introduce the principles of different generative AI techniques, and their potential applications.","Then, we classify tasks in intelligent transportation systems into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making.","We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks.","Finally, we summarize the challenges faced in applying generative AI to intelligent transportation systems, and discuss future research directions based on different application scenarios."],"url":"http://arxiv.org/abs/2312.08248v1"}
{"created":"2023-12-13 15:58:40","title":"From Brussels Effect to Gravity Assists: Understanding the Evolution of the GDPR-Inspired Personal Information Protection Law in China","abstract":"This paper explores the evolution of China's Personal Information Protection Law (PIPL) and situates it within the context of global data protection development. It draws inspiration from the theory of 'Brussels Effect' and its precedents, that describes the extraterritorial influence of EU regulations. Our objective is not to provide a commentary on China's legal development but to illuminate the intricate dynamics between the Chinese law and the EU's GDPR. It is argued that the trajectory of China's Personal Information Protection Law calls into question the applicability of the Brussels Effect: while the GDPR's imprint on the PIPL is evident, a deeper analysis unveils China's nuanced, non-linear adoption that diverges from many assumptions of the Brussels Effect and similar theories. The evolution of the GDPR-inspired PIPL is not as a straightforward outcome of the Brussels Effect but as a nuanced, intricate interplay of external influence and domestic dynamics. We introduce a complementary theory of 'gravity assist' which portrays China's strategic instrumentalisation of the GDPR as a template to shape its unique data protection landscape. Our conceptual framework highlights how China navigates through a patchwork of internal considerations, international standards, and strategic choices, ultimately sculpting a data protection regime that has a similar appearance to the GDPR but aligns with its distinct political, cultural and legal landscape. This reveals much about how China takes in the foundational premises of data protection that are inherently built in Europe's cherishment of the rule of law, democracy and human rights on the one hand, and the evaluation of data protection as a fundamental right.","sentences":["This paper explores the evolution of China's Personal Information Protection Law (PIPL) and situates it within the context of global data protection development.","It draws inspiration from the theory of 'Brussels Effect' and its precedents, that describes the extraterritorial influence of EU regulations.","Our objective is not to provide a commentary on China's legal development but to illuminate the intricate dynamics between the Chinese law and the EU's GDPR.","It is argued that the trajectory of China's Personal Information Protection Law calls into question the applicability of the Brussels Effect: while the GDPR's imprint on the PIPL is evident, a deeper analysis unveils China's nuanced, non-linear adoption that diverges from many assumptions of the Brussels Effect and similar theories.","The evolution of the GDPR-inspired PIPL is not as a straightforward outcome of the Brussels Effect but as a nuanced, intricate interplay of external influence and domestic dynamics.","We introduce a complementary theory of 'gravity assist' which portrays China's strategic instrumentalisation of the GDPR as a template to shape its unique data protection landscape.","Our conceptual framework highlights how China navigates through a patchwork of internal considerations, international standards, and strategic choices, ultimately sculpting a data protection regime that has a similar appearance to the GDPR but aligns with its distinct political, cultural and legal landscape.","This reveals much about how China takes in the foundational premises of data protection that are inherently built in Europe's cherishment of the rule of law, democracy and human rights on the one hand, and the evaluation of data protection as a fundamental right."],"url":"http://arxiv.org/abs/2312.08237v1"}
{"created":"2023-12-13 15:57:06","title":"Analysis of Psychographic Indicators via LIWC and Their Correlation with CTR for Instagram Ads","abstract":"The online advertising industry continues to grow and accounts for over 40% of global advertising spending. Online display advertising consists of images and text, and advertisers maximize sales revenue by contacting consumers through advertisements and encouraging them to make purchases. In today's society, where products are becoming more homogenized and needs are diversifying, appealing to consumer psychology through advertisements is becoming increasingly important. However, it is not sufficiently clear what kind of appeal influences consumer psychology. In this study, we quantified the appeal of the text in advertisements for health products and cosmetics, which were actually delivered in Instagram advertisements (one of display advertisements), by applying linguistic inquiry and word count (LIWC). The correlation between click-through rate (CTR) and the text was analyzed. The results showed that negative appeals that arouse consumer anxiety and a sense of crisis were related to CTR.","sentences":["The online advertising industry continues to grow and accounts for over 40% of global advertising spending.","Online display advertising consists of images and text, and advertisers maximize sales revenue by contacting consumers through advertisements and encouraging them to make purchases.","In today's society, where products are becoming more homogenized and needs are diversifying, appealing to consumer psychology through advertisements is becoming increasingly important.","However, it is not sufficiently clear what kind of appeal influences consumer psychology.","In this study, we quantified the appeal of the text in advertisements for health products and cosmetics, which were actually delivered in Instagram advertisements (one of display advertisements), by applying linguistic inquiry and word count (LIWC).","The correlation between click-through rate (CTR) and the text was analyzed.","The results showed that negative appeals that arouse consumer anxiety and a sense of crisis were related to CTR."],"url":"http://arxiv.org/abs/2312.08235v1"}
{"created":"2023-12-13 15:56:24","title":"Beyond the Label Itself: Latent Labels Enhance Semi-supervised Point Cloud Panoptic Segmentation","abstract":"As the exorbitant expense of labeling autopilot datasets and the growing trend of utilizing unlabeled data, semi-supervised segmentation on point clouds becomes increasingly imperative. Intuitively, finding out more ``unspoken words'' (i.e., latent instance information) beyond the label itself should be helpful to improve performance. In this paper, we discover two types of latent labels behind the displayed label embedded in LiDAR and image data. First, in the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able to augment more yet reliable samples for training. Second, in the Image Branch, we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse the information of instance position and scale, which is from a 2D pre-trained detector and a type of latent label obtained from 3D to 2D projection. Finally, the two latent labels are embedded into the multi-modal panoptic segmentation network. The ablation of the IPSL module demonstrates its robust adaptability, and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that our model outperforms the state-of-the-art method, LaserMix.","sentences":["As the exorbitant expense of labeling autopilot datasets and the growing trend of utilizing unlabeled data, semi-supervised segmentation on point clouds becomes increasingly imperative.","Intuitively, finding out more ``unspoken words'' (i.e., latent instance information) beyond the label itself should be helpful to improve performance.","In this paper, we discover two types of latent labels behind the displayed label embedded in LiDAR and image data.","First, in the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able to augment more yet reliable samples for training.","Second, in the Image Branch, we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse the information of instance position and scale, which is from a 2D pre-trained detector and a type of latent label obtained from 3D to 2D projection.","Finally, the two latent labels are embedded into the multi-modal panoptic segmentation network.","The ablation of the IPSL module demonstrates its robust adaptability, and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that our model outperforms the state-of-the-art method, LaserMix."],"url":"http://arxiv.org/abs/2312.08234v1"}
{"created":"2023-12-13 15:48:50","title":"Partial Symmetry Detection for 3D Geometry using Contrastive Learning with Geodesic Point Cloud Patches","abstract":"Symmetry detection, especially partial and extrinsic symmetry, is essential for various downstream tasks, like 3D geometry completion, segmentation, compression and structure-aware shape encoding or generation. In order to detect partial extrinsic symmetries, we propose to learn rotation, reflection, translation and scale invariant local shape features for geodesic point cloud patches via contrastive learning, which are robust across multiple classes and generalize over different datasets. We show that our approach is able to extract multiple valid solutions for this ambiguous problem. Furthermore, we introduce a novel benchmark test for partial extrinsic symmetry detection to evaluate our method. Lastly, we incorporate the detected symmetries together with a region growing algorithm to demonstrate a downstream task with the goal of computing symmetry-aware partitions of 3D shapes. To our knowledge, we are the first to propose a self-supervised data-driven method for partial extrinsic symmetry detection.","sentences":["Symmetry detection, especially partial and extrinsic symmetry, is essential for various downstream tasks, like 3D geometry completion, segmentation, compression and structure-aware shape encoding or generation.","In order to detect partial extrinsic symmetries, we propose to learn rotation, reflection, translation and scale invariant local shape features for geodesic point cloud patches via contrastive learning, which are robust across multiple classes and generalize over different datasets.","We show that our approach is able to extract multiple valid solutions for this ambiguous problem.","Furthermore, we introduce a novel benchmark test for partial extrinsic symmetry detection to evaluate our method.","Lastly, we incorporate the detected symmetries together with a region growing algorithm to demonstrate a downstream task with the goal of computing symmetry-aware partitions of 3D shapes.","To our knowledge, we are the first to propose a self-supervised data-driven method for partial extrinsic symmetry detection."],"url":"http://arxiv.org/abs/2312.08230v1"}
{"created":"2023-12-13 15:30:29","title":"Accelerated Event-Based Feature Detection and Compression for Surveillance Video Systems","abstract":"The strong temporal consistency of surveillance video enables compelling compression performance with traditional methods, but downstream vision applications operate on decoded image frames with a high data rate. Since it is not straightforward for applications to extract information on temporal redundancy from the compressed video representations, we propose a novel system which conveys temporal redundancy within a sparse decompressed representation. We leverage a video representation framework called ADDER to transcode framed videos to sparse, asynchronous intensity samples. We introduce mechanisms for content adaptation, lossy compression, and asynchronous forms of classical vision algorithms. We evaluate our system on the VIRAT surveillance video dataset, and we show a median 43.7% speed improvement in FAST feature detection compared to OpenCV. We run the same algorithm as OpenCV, but only process pixels that receive new asynchronous events, rather than process every pixel in an image frame. Our work paves the way for upcoming neuromorphic sensors and is amenable to future applications with spiking neural networks.","sentences":["The strong temporal consistency of surveillance video enables compelling compression performance with traditional methods, but downstream vision applications operate on decoded image frames with a high data rate.","Since it is not straightforward for applications to extract information on temporal redundancy from the compressed video representations, we propose a novel system which conveys temporal redundancy within a sparse decompressed representation.","We leverage a video representation framework called ADDER to transcode framed videos to sparse, asynchronous intensity samples.","We introduce mechanisms for content adaptation, lossy compression, and asynchronous forms of classical vision algorithms.","We evaluate our system on the VIRAT surveillance video dataset, and we show a median 43.7% speed improvement in FAST feature detection compared to OpenCV.","We run the same algorithm as OpenCV, but only process pixels that receive new asynchronous events, rather than process every pixel in an image frame.","Our work paves the way for upcoming neuromorphic sensors and is amenable to future applications with spiking neural networks."],"url":"http://arxiv.org/abs/2312.08213v1"}
{"created":"2023-12-13 15:08:54","title":"SPD-DDPM: Denoising Diffusion Probabilistic Models in the Symmetric Positive Definite Space","abstract":"Symmetric positive definite~(SPD) matrices have shown important value and applications in statistics and machine learning, such as FMRI analysis and traffic prediction. Previous works on SPD matrices mostly focus on discriminative models, where predictions are made directly on $E(X|y)$, where $y$ is a vector and $X$ is an SPD matrix. However, these methods are challenging to handle for large-scale data, as they need to access and process the whole data. In this paper, inspired by denoising diffusion probabilistic model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by introducing Gaussian distribution in the SPD space to estimate $E(X|y)$. Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly without giving $y$. On the one hand, the model conditionally learns $p(X|y)$ and utilizes the mean of samples to obtain $E(X|y)$ as a prediction. On the other hand, the model unconditionally learns the probability distribution of the data $p(X)$ and generates samples that conform to this distribution. Furthermore, we propose a new SPD net which is much deeper than the previous networks and allows for the inclusion of conditional factors. Experiment results on toy data and real taxi data demonstrate that our models effectively fit the data distribution both unconditionally and unconditionally and provide accurate predictions.","sentences":["Symmetric positive definite~(SPD) matrices have shown important value and applications in statistics and machine learning, such as FMRI analysis and traffic prediction.","Previous works on SPD matrices mostly focus on discriminative models, where predictions are made directly on $E(X|y)$, where $y$ is a vector and $X$ is an SPD matrix.","However, these methods are challenging to handle for large-scale data, as they need to access and process the whole data.","In this paper, inspired by denoising diffusion probabilistic model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by introducing Gaussian distribution in the SPD space to estimate $E(X|y)$. Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly without giving $y$. On the one hand, the model conditionally learns $p(X|y)$ and utilizes the mean of samples to obtain $E(X|y)$ as a prediction.","On the other hand, the model unconditionally learns the probability distribution of the data $p(X)$ and generates samples that conform to this distribution.","Furthermore, we propose a new SPD net which is much deeper than the previous networks and allows for the inclusion of conditional factors.","Experiment results on toy data and real taxi data demonstrate that our models effectively fit the data distribution both unconditionally and unconditionally and provide accurate predictions."],"url":"http://arxiv.org/abs/2312.08200v1"}
{"created":"2023-12-13 15:03:27","title":"Towards Model-Based Data Acquisition for Subjective Multi-Task NLP Problems","abstract":"Data annotated by humans is a source of knowledge by describing the peculiarities of the problem and therefore fueling the decision process of the trained model. Unfortunately, the annotation process for subjective natural language processing (NLP) problems like offensiveness or emotion detection is often very expensive and time-consuming. One of the inevitable risks is to spend some of the funds and annotator effort on annotations that do not provide any additional knowledge about the specific task. To minimize these costs, we propose a new model-based approach that allows the selection of tasks annotated individually for each text in a multi-task scenario. The experiments carried out on three datasets, dozens of NLP tasks, and thousands of annotations show that our method allows up to 40% reduction in the number of annotations with negligible loss of knowledge. The results also emphasize the need to collect a diverse amount of data required to efficiently train a model, depending on the subjectivity of the annotation task. We also focused on measuring the relation between subjective tasks by evaluating the model in single-task and multi-task scenarios. Moreover, for some datasets, training only on the labels predicted by our model improved the efficiency of task selection as a self-supervised learning regularization technique.","sentences":["Data annotated by humans is a source of knowledge by describing the peculiarities of the problem and therefore fueling the decision process of the trained model.","Unfortunately, the annotation process for subjective natural language processing (NLP) problems like offensiveness or emotion detection is often very expensive and time-consuming.","One of the inevitable risks is to spend some of the funds and annotator effort on annotations that do not provide any additional knowledge about the specific task.","To minimize these costs, we propose a new model-based approach that allows the selection of tasks annotated individually for each text in a multi-task scenario.","The experiments carried out on three datasets, dozens of NLP tasks, and thousands of annotations show that our method allows up to 40% reduction in the number of annotations with negligible loss of knowledge.","The results also emphasize the need to collect a diverse amount of data required to efficiently train a model, depending on the subjectivity of the annotation task.","We also focused on measuring the relation between subjective tasks by evaluating the model in single-task and multi-task scenarios.","Moreover, for some datasets, training only on the labels predicted by our model improved the efficiency of task selection as a self-supervised learning regularization technique."],"url":"http://arxiv.org/abs/2312.08198v1"}
{"created":"2023-12-13 14:36:08","title":"ASC: Adaptive Scale Feature Map Compression for Deep Neural Network","abstract":"Deep-learning accelerators are increasingly in demand; however, their performance is constrained by the size of the feature map, leading to high bandwidth requirements and large buffer sizes. We propose an adaptive scale feature map compression technique leveraging the unique properties of the feature map. This technique adopts independent channel indexing given the weak channel correlation and utilizes a cubical-like block shape to benefit from strong local correlations. The method further optimizes compression using a switchable endpoint mode and adaptive scale interpolation to handle unimodal data distributions, both with and without outliers. This results in 4$\\times$ and up to 7.69$\\times$ compression rates for 16-bit data in constant and variable bitrates, respectively. Our hardware design minimizes area cost by adjusting interpolation scales, which facilitates hardware sharing among interpolation points. Additionally, we introduce a threshold concept for straightforward interpolation, preventing the need for intricate hardware. The TSMC 28nm implementation showcases an equivalent gate count of 6135 for the 8-bit version. Furthermore, the hardware architecture scales effectively, with only a sublinear increase in area cost. Achieving a 32$\\times$ throughput increase meets the theoretical bandwidth of DDR5-6400 at just 7.65$\\times$ the hardware cost.","sentences":["Deep-learning accelerators are increasingly in demand; however, their performance is constrained by the size of the feature map, leading to high bandwidth requirements and large buffer sizes.","We propose an adaptive scale feature map compression technique leveraging the unique properties of the feature map.","This technique adopts independent channel indexing given the weak channel correlation and utilizes a cubical-like block shape to benefit from strong local correlations.","The method further optimizes compression using a switchable endpoint mode and adaptive scale interpolation to handle unimodal data distributions, both with and without outliers.","This results in 4$\\times$ and up to 7.69$\\times$ compression rates for 16-bit data in constant and variable bitrates, respectively.","Our hardware design minimizes area cost by adjusting interpolation scales, which facilitates hardware sharing among interpolation points.","Additionally, we introduce a threshold concept for straightforward interpolation, preventing the need for intricate hardware.","The TSMC 28nm implementation showcases an equivalent gate count of 6135 for the 8-bit version.","Furthermore, the hardware architecture scales effectively, with only a sublinear increase in area cost.","Achieving a 32$\\times$ throughput increase meets the theoretical bandwidth of DDR5-6400 at just 7.65$\\times$ the hardware cost."],"url":"http://arxiv.org/abs/2312.08176v1"}
{"created":"2023-12-13 14:12:52","title":"Towards Evaluating the Security of Wearable Devices in the Internet of Medical Things","abstract":"The Internet of Medical Things (IoMT) offers a promising solution to improve patient health and reduce human error. Wearable smart infusion pumps that accurately administer medication and integrate with electronic health records are an example of technology that can improve healthcare. They can even alert healthcare professionals or remote servers during operational failure, preventing distressing incidents. However, as the number of connected medical devices increases, the risk of cyber threats also increases. Wearable medication devices based on IoT attached to patients' bodies are prone to significant cyber threats. Being connected to the Internet exposes these devices to potential harm, which could disrupt or degrade device performance and harm patients. To ensure patient safety and well-being, it is crucial to establish secure data authentication for internet-connected medical devices. It is also important to note that the wearability option of such devices might downgrade the computational resources, making them more susceptible to security risks. This paper implements a security approach to a wearable infusion pump. We discuss practical challenges in implementing security-enabled devices and propose initial solutions to mitigate cyber threats.","sentences":["The Internet of Medical Things (IoMT) offers a promising solution to improve patient health and reduce human error.","Wearable smart infusion pumps that accurately administer medication and integrate with electronic health records are an example of technology that can improve healthcare.","They can even alert healthcare professionals or remote servers during operational failure, preventing distressing incidents.","However, as the number of connected medical devices increases, the risk of cyber threats also increases.","Wearable medication devices based on IoT attached to patients' bodies are prone to significant cyber threats.","Being connected to the Internet exposes these devices to potential harm, which could disrupt or degrade device performance and harm patients.","To ensure patient safety and well-being, it is crucial to establish secure data authentication for internet-connected medical devices.","It is also important to note that the wearability option of such devices might downgrade the computational resources, making them more susceptible to security risks.","This paper implements a security approach to a wearable infusion pump.","We discuss practical challenges in implementing security-enabled devices and propose initial solutions to mitigate cyber threats."],"url":"http://arxiv.org/abs/2312.08160v1"}
{"created":"2023-12-13 14:10:50","title":"Distributed Quantum Learning with co-Management in a Multi-tenant Quantum System","abstract":"The rapid advancement of quantum computing has pushed classical designs into the quantum domain, breaking physical boundaries for computing-intensive and data-hungry applications. Given its immense potential, quantum-based computing systems have attracted increasing attention with the hope that some systems may provide a quantum speedup. For example, variational quantum algorithms have been proposed for quantum neural networks to train deep learning models on qubits, achieving promising results. Existing quantum learning architectures and systems rely on single, monolithic quantum machines with abundant and stable resources, such as qubits. However, fabricating a large, monolithic quantum device is considerably more challenging than producing an array of smaller devices. In this paper, we investigate a distributed quantum system that combines multiple quantum machines into a unified system. We propose DQuLearn, which divides a quantum learning task into multiple subtasks. Each subtask can be executed distributively on individual quantum machines, with the results looping back to classical machines for subsequent training iterations. Additionally, our system supports multiple concurrent clients and dynamically manages their circuits according to the runtime status of quantum workers. Through extensive experiments, we demonstrate that DQuLearn achieves similar accuracies with significant runtime reduction, by up to 68.7% and an increase per-second circuit processing speed, by up to 3.99 times, in a 4-worker multi-tenant setting.","sentences":["The rapid advancement of quantum computing has pushed classical designs into the quantum domain, breaking physical boundaries for computing-intensive and data-hungry applications.","Given its immense potential, quantum-based computing systems have attracted increasing attention with the hope that some systems may provide a quantum speedup.","For example, variational quantum algorithms have been proposed for quantum neural networks to train deep learning models on qubits, achieving promising results.","Existing quantum learning architectures and systems rely on single, monolithic quantum machines with abundant and stable resources, such as qubits.","However, fabricating a large, monolithic quantum device is considerably more challenging than producing an array of smaller devices.","In this paper, we investigate a distributed quantum system that combines multiple quantum machines into a unified system.","We propose DQuLearn, which divides a quantum learning task into multiple subtasks.","Each subtask can be executed distributively on individual quantum machines, with the results looping back to classical machines for subsequent training iterations.","Additionally, our system supports multiple concurrent clients and dynamically manages their circuits according to the runtime status of quantum workers.","Through extensive experiments, we demonstrate that DQuLearn achieves similar accuracies with significant runtime reduction, by up to 68.7% and an increase per-second circuit processing speed, by up to 3.99 times, in a 4-worker multi-tenant setting."],"url":"http://arxiv.org/abs/2312.08158v1"}
{"created":"2023-12-13 14:10:12","title":"Okapi: A Lightweight Architecture for Secure Speculation Exploiting Locality of Memory Accesses","abstract":"This paper introduces Okapi, an innovative hardware/software cross-layer architecture designed to mitigate Transient Execution Side Channel (TES) attacks, including Spectre variants, in modern computing systems. A key contribution of Okapi is a set of security features building upon each other to offer various trade-offs between performance and security. At its core, Okapi allows for speculative data accesses if the targeted memory region has already been accessed non-speculatively before in the same trust domain. It delays first-time accesses until the speculation is resolved.   Okapi stands out for its flexibility in security implementation. For environments with less stringent security needs, Okapi's features can be deactivated to eliminate performance overhead. When activated, the hardware modifications alone provide robust protection against transient execution attacks at a thread-level granularity, including all universal read gadgets like Spectre-PHT and Spectre-BTB. This incurs an average performance overhead of only 3.6 % for the SPEC CPU2017 benchmark suite.   On top, Okapi introduces the OkapiReset instruction for additional software-level security support. This instruction, which can be manually inserted by developers or automatically via a compiler extension, allows for fully secure speculation and for trust domain sizes smaller than a thread. While the manual insertion of OkapiReset incurs an additional 0.6 % performance overhead, the automated compiler extension approach results in a 23.1 % overhead for making a cryptographic library fully secure. With an approximate 0.4 % hardware overhead, Okapi provides a highly scalable and adaptable solution for secure speculation in state-of-the-art processor design.","sentences":["This paper introduces Okapi, an innovative hardware/software cross-layer architecture designed to mitigate Transient Execution Side Channel (TES) attacks, including Spectre variants, in modern computing systems.","A key contribution of Okapi is a set of security features building upon each other to offer various trade-offs between performance and security.","At its core, Okapi allows for speculative data accesses if the targeted memory region has already been accessed non-speculatively before in the same trust domain.","It delays first-time accesses until the speculation is resolved.   ","Okapi stands out for its flexibility in security implementation.","For environments with less stringent security needs, Okapi's features can be deactivated to eliminate performance overhead.","When activated, the hardware modifications alone provide robust protection against transient execution attacks at a thread-level granularity, including all universal read gadgets like Spectre-PHT and Spectre-BTB.","This incurs an average performance overhead of only 3.6 % for the SPEC CPU2017 benchmark suite.   ","On top, Okapi introduces the OkapiReset instruction for additional software-level security support.","This instruction, which can be manually inserted by developers or automatically via a compiler extension, allows for fully secure speculation and for trust domain sizes smaller than a thread.","While the manual insertion of OkapiReset incurs an additional 0.6 % performance overhead, the automated compiler extension approach results in a 23.1 % overhead for making a cryptographic library fully secure.","With an approximate 0.4 % hardware overhead, Okapi provides a highly scalable and adaptable solution for secure speculation in state-of-the-art processor design."],"url":"http://arxiv.org/abs/2312.08156v1"}
{"created":"2023-12-13 14:01:58","title":"Active learning with biased non-response to label requests","abstract":"Active learning can improve the efficiency of training prediction models by identifying the most informative new labels to acquire. However, non-response to label requests can impact active learning's effectiveness in real-world contexts. We conceptualise this degradation by considering the type of non-response present in the data, demonstrating that biased non-response is particularly detrimental to model performance. We argue that this sort of non-response is particularly likely in contexts where the labelling process, by nature, relies on user interactions. To mitigate the impact of biased non-response, we propose a cost-based correction to the sampling strategy--the Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly, be applied to any active learning algorithm. Through experiments, we demonstrate that our method successfully reduces the harm from labelling non-response in many settings. However, we also characterise settings where the non-response bias in the annotations remains detrimental under UCB-EU for particular sampling methods and data generating processes. Finally, we evaluate our method on a real-world dataset from e-commerce platform Taobao. We show that UCB-EU yields substantial performance improvements to conversion models that are trained on clicked impressions. Most generally, this research serves to both better conceptualise the interplay between types of non-response and model improvements via active learning, and to provide a practical, easy to implement correction that helps mitigate model degradation.","sentences":["Active learning can improve the efficiency of training prediction models by identifying the most informative new labels to acquire.","However, non-response to label requests can impact active learning's effectiveness in real-world contexts.","We conceptualise this degradation by considering the type of non-response present in the data, demonstrating that biased non-response is particularly detrimental to model performance.","We argue that this sort of non-response is particularly likely in contexts where the labelling process, by nature, relies on user interactions.","To mitigate the impact of biased non-response, we propose a cost-based correction to the sampling strategy--the Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly, be applied to any active learning algorithm.","Through experiments, we demonstrate that our method successfully reduces the harm from labelling non-response in many settings.","However, we also characterise settings where the non-response bias in the annotations remains detrimental under UCB-EU for particular sampling methods and data generating processes.","Finally, we evaluate our method on a real-world dataset from e-commerce platform Taobao.","We show that UCB-EU yields substantial performance improvements to conversion models that are trained on clicked impressions.","Most generally, this research serves to both better conceptualise the interplay between types of non-response and model improvements via active learning, and to provide a practical, easy to implement correction that helps mitigate model degradation."],"url":"http://arxiv.org/abs/2312.08150v1"}
{"created":"2023-12-13 13:55:36","title":"High-accuracy Vision-Based Attitude Estimation System for Air-Bearing Spacecraft Simulators","abstract":"Air-bearing platforms for simulating the rotational dynamics of satellites require highly precise ground truth systems. Unfortunately, commercial motion capture systems used for this scope are complex and expensive. This paper shows a novel and versatile method to compute the attitude of rotational air-bearing platforms using a monocular camera and sets of fiducial markers. The work proposes a geometry-based iterative algorithm that is significantly more accurate than other literature methods that involve the solution of the Perspective-n-Point problem. Additionally, auto-calibration procedures to perform a preliminary estimation of the system parameters are shown. The developed methodology is deployed onto a Raspberry Pi 4 micro-computer and tested with a set of LED markers. Data obtained with this setup are compared against computer simulations of the same system to understand and validate the attitude estimation performances. Simulation results show expected 1-sigma accuracies in the order of $\\sim$ 12 arcsec and $\\sim$ 37 arcsec for about- and cross-boresight rotations of the platform, and average latency times of 6 ms.","sentences":["Air-bearing platforms for simulating the rotational dynamics of satellites require highly precise ground truth systems.","Unfortunately, commercial motion capture systems used for this scope are complex and expensive.","This paper shows a novel and versatile method to compute the attitude of rotational air-bearing platforms using a monocular camera and sets of fiducial markers.","The work proposes a geometry-based iterative algorithm that is significantly more accurate than other literature methods that involve the solution of the Perspective-n-Point problem.","Additionally, auto-calibration procedures to perform a preliminary estimation of the system parameters are shown.","The developed methodology is deployed onto a Raspberry Pi 4 micro-computer and tested with a set of LED markers.","Data obtained with this setup are compared against computer simulations of the same system to understand and validate the attitude estimation performances.","Simulation results show expected 1-sigma accuracies in the order of $\\sim$ 12 arcsec and $\\sim$ 37 arcsec for about- and cross-boresight rotations of the platform, and average latency times of 6 ms."],"url":"http://arxiv.org/abs/2312.08146v1"}
{"created":"2023-12-13 13:46:14","title":"Efficient Representation of the Activation Space in Deep Neural Networks","abstract":"The representations of the activation space of deep neural networks (DNNs) are widely utilized for tasks like natural language processing, anomaly detection and speech recognition. Due to the diverse nature of these tasks and the large size of DNNs, an efficient and task-independent representation of activations becomes crucial. Empirical p-values have been used to quantify the relative strength of an observed node activation compared to activations created by already-known inputs. Nonetheless, keeping raw data for these calculations increases memory resource consumption and raises privacy concerns. To this end, we propose a model-agnostic framework for creating representations of activations in DNNs using node-specific histograms to compute p-values of observed activations without retaining already-known inputs. Our proposed approach demonstrates promising potential when validated with multiple network architectures across various downstream tasks and compared with the kernel density estimates and brute-force empirical baselines. In addition, the framework reduces memory usage by 30% with up to 4 times faster p-value computing time while maintaining state of-the-art detection power in downstream tasks such as the detection of adversarial attacks and synthesized content. Moreover, as we do not persist raw data at inference time, we could potentially reduce susceptibility to attacks and privacy issues.","sentences":["The representations of the activation space of deep neural networks (DNNs) are widely utilized for tasks like natural language processing, anomaly detection and speech recognition.","Due to the diverse nature of these tasks and the large size of DNNs, an efficient and task-independent representation of activations becomes crucial.","Empirical p-values have been used to quantify the relative strength of an observed node activation compared to activations created by already-known inputs.","Nonetheless, keeping raw data for these calculations increases memory resource consumption and raises privacy concerns.","To this end, we propose a model-agnostic framework for creating representations of activations in DNNs using node-specific histograms to compute p-values of observed activations without retaining already-known inputs.","Our proposed approach demonstrates promising potential when validated with multiple network architectures across various downstream tasks and compared with the kernel density estimates and brute-force empirical baselines.","In addition, the framework reduces memory usage by 30% with up to 4 times faster p-value computing time while maintaining state of-the-art detection power in downstream tasks such as the detection of adversarial attacks and synthesized content.","Moreover, as we do not persist raw data at inference time, we could potentially reduce susceptibility to attacks and privacy issues."],"url":"http://arxiv.org/abs/2312.08143v1"}
{"created":"2023-12-13 13:36:14","title":"MToP: A MATLAB Optimization Platform for Evolutionary Multitasking","abstract":"Evolutionary multitasking (EMT) has been attracting much attention over the past years. It aims to handle multiple optimization tasks simultaneously within limited computing resources assisted by inter-task knowledge transfer techniques. Numerous multitask evolutionary algorithms (MTEAs) for solving multitask optimization (MTO) problems have been proposed in the EMT field, but there lacks a comprehensive software platform to help researchers evaluate MTEA performance on benchmark MTO problems as well as explore real-world applications. To address this issue, we introduce the first open-source optimization platform, named MTO-Platform (MToP), for EMT. It incorporates more than 30 MTEAs, more than 150 MTO problem cases with real-world applications, and more than 10 performance metrics. Moreover, for comparing MTEAs with traditional evolutionary algorithms, we modified more than 30 popular single-task evolutionary algorithms to be able to solve MTO problems in MToP. MToP is a user-friendly tool with a graphical user interface that makes it easy to analyze results, export data, and plot schematics. More importantly, MToP is extensible, allowing users to develop new algorithms and define new problems. The source code of MToP is available at https://github.com/intLyc/MTO-Platform.","sentences":["Evolutionary multitasking (EMT) has been attracting much attention over the past years.","It aims to handle multiple optimization tasks simultaneously within limited computing resources assisted by inter-task knowledge transfer techniques.","Numerous multitask evolutionary algorithms (MTEAs) for solving multitask optimization (MTO) problems have been proposed in the EMT field, but there lacks a comprehensive software platform to help researchers evaluate MTEA performance on benchmark MTO problems as well as explore real-world applications.","To address this issue, we introduce the first open-source optimization platform, named MTO-Platform (MToP), for EMT.","It incorporates more than 30 MTEAs, more than 150 MTO problem cases with real-world applications, and more than 10 performance metrics.","Moreover, for comparing MTEAs with traditional evolutionary algorithms, we modified more than 30 popular single-task evolutionary algorithms to be able to solve MTO problems in MToP. MToP is a user-friendly tool with a graphical user interface that makes it easy to analyze results, export data, and plot schematics.","More importantly, MToP is extensible, allowing users to develop new algorithms and define new problems.","The source code of MToP is available at https://github.com/intLyc/MTO-Platform."],"url":"http://arxiv.org/abs/2312.08134v1"}
{"created":"2023-12-13 13:27:09","title":"Random relay selection based heuristic optimization model for the scheduling and effective resource allocation in the cognitive radio network","abstract":"Cognitive Radio Network (CRN) provides effective capabilities for resource allocation with the valuable spectrum resources in the network. It provides the effective allocation of resources to the unlicensed users or Secondary Users (SUs) to access the spectrum those are unused by the licensed users or Primary Users (Pus). This paper develops an Optimal Relay Selection scheme with the spectrum-sharing scheme in CRN. The proposed Cross-Layer Spider Swarm Shifting is implemented in CRN for the optimal relay selection with Spider Swarm Optimization (SSO). The shortest path is estimated with the data shifting model for the data transmission path in the CRN. This study examines a cognitive relay network (CRN) with interference restrictions imposed by a mobile end user (MU). Half-duplex communication is used in the proposed system model between a single primary user (PU) and a single secondary user (SU). Between the SU source and SU destination, an amplify and forward (AF) relaying mechanism is also used. While other nodes (SU Source, SU relays, and PU) are supposed to be immobile in this scenario, the mobile end user (SU destination) is assumed to travel at high vehicle speeds. The suggested method achieves variety by placing a selection combiner at the SU destination and dynamically selecting the optimal relay for transmission based on the greatest signal-to-noise (SNR) ratio. The performance of the proposed Cross-Layer Spider Swarm Shifting model is compared with the Spectrum Sharing Optimization with QoS Guarantee (SSO-QG). The comparative analysis expressed that the proposed Cross-Layer Spider Swarm Shifting model delay is reduced by 15% compared with SSO-QG. Additionally, the proposed Cross-Layer Spider Swarm Shifting exhibits the improved network performance of ~25% higher throughput compared with SSO-QG.","sentences":["Cognitive Radio Network (CRN) provides effective capabilities for resource allocation with the valuable spectrum resources in the network.","It provides the effective allocation of resources to the unlicensed users or Secondary Users (SUs) to access the spectrum those are unused by the licensed users or Primary Users (Pus).","This paper develops an Optimal Relay Selection scheme with the spectrum-sharing scheme in CRN.","The proposed Cross-Layer Spider Swarm Shifting is implemented in CRN for the optimal relay selection with Spider Swarm Optimization (SSO).","The shortest path is estimated with the data shifting model for the data transmission path in the CRN.","This study examines a cognitive relay network (CRN) with interference restrictions imposed by a mobile end user (MU).","Half-duplex communication is used in the proposed system model between a single primary user (PU) and a single secondary user (SU).","Between the SU source and SU destination, an amplify and forward (AF) relaying mechanism is also used.","While other nodes (SU Source, SU relays, and PU) are supposed to be immobile in this scenario, the mobile end user (SU destination) is assumed to travel at high vehicle speeds.","The suggested method achieves variety by placing a selection combiner at the SU destination and dynamically selecting the optimal relay for transmission based on the greatest signal-to-noise (SNR) ratio.","The performance of the proposed Cross-Layer Spider Swarm Shifting model is compared with the Spectrum Sharing Optimization with QoS Guarantee (SSO-QG).","The comparative analysis expressed that the proposed Cross-Layer Spider Swarm Shifting model delay is reduced by 15% compared with SSO-QG.","Additionally, the proposed Cross-Layer Spider Swarm Shifting exhibits the improved network performance of ~25% higher throughput compared with SSO-QG."],"url":"http://arxiv.org/abs/2312.08127v1"}
{"created":"2023-12-13 12:54:34","title":"Causal Optimal Transport of Abstractions","abstract":"Causal abstraction (CA) theory establishes formal criteria for relating multiple structural causal models (SCMs) at different levels of granularity by defining maps between them. These maps have significant relevance for real-world challenges such as synthesizing causal evidence from multiple experimental environments, learning causally consistent representations at different resolutions, and linking interventions across multiple SCMs. In this work, we propose COTA, the first method to learn abstraction maps from observational and interventional data without assuming complete knowledge of the underlying SCMs. In particular, we introduce a multi-marginal Optimal Transport (OT) formulation that enforces do-calculus causal constraints, together with a cost function that relies on interventional information. We extensively evaluate COTA on synthetic and real world problems, and showcase its advantages over non-causal, independent and aggregated COTA formulations. Finally, we demonstrate the efficiency of our method as a data augmentation tool by comparing it against the state-of-the-art CA learning framework, which assumes fully specified SCMs, on a real-world downstream task.","sentences":["Causal abstraction (CA) theory establishes formal criteria for relating multiple structural causal models (SCMs) at different levels of granularity by defining maps between them.","These maps have significant relevance for real-world challenges such as synthesizing causal evidence from multiple experimental environments, learning causally consistent representations at different resolutions, and linking interventions across multiple SCMs.","In this work, we propose COTA, the first method to learn abstraction maps from observational and interventional data without assuming complete knowledge of the underlying SCMs.","In particular, we introduce a multi-marginal Optimal Transport (OT) formulation that enforces do-calculus causal constraints, together with a cost function that relies on interventional information.","We extensively evaluate COTA on synthetic and real world problems, and showcase its advantages over non-causal, independent and aggregated COTA formulations.","Finally, we demonstrate the efficiency of our method as a data augmentation tool by comparing it against the state-of-the-art CA learning framework, which assumes fully specified SCMs, on a real-world downstream task."],"url":"http://arxiv.org/abs/2312.08107v1"}
{"created":"2023-12-13 12:39:25","title":"Machine Learning for the Multi-Dimensional Bin Packing Problem: Literature Review and Empirical Evaluation","abstract":"The Bin Packing Problem (BPP) is a well-established combinatorial optimization (CO) problem. Since it has many applications in our daily life, e.g. logistics and resource allocation, people are seeking efficient bin packing algorithms. On the other hand, researchers have been making constant advances in machine learning (ML), which is famous for its efficiency. In this article, we first formulate BPP, introducing its variants and practical constraints. Then, a comprehensive survey on ML for multi-dimensional BPP is provided. We further collect some public benchmarks of 3D BPP, and evaluate some online methods on the Cutting Stock Dataset. Finally, we share our perspective on challenges and future directions in BPP. To the best of our knowledge, this is the first systematic review of ML-related methods for BPP.","sentences":["The Bin Packing Problem (BPP) is a well-established combinatorial optimization (CO) problem.","Since it has many applications in our daily life, e.g. logistics and resource allocation, people are seeking efficient bin packing algorithms.","On the other hand, researchers have been making constant advances in machine learning (ML), which is famous for its efficiency.","In this article, we first formulate BPP, introducing its variants and practical constraints.","Then, a comprehensive survey on ML for multi-dimensional BPP is provided.","We further collect some public benchmarks of 3D BPP, and evaluate some online methods on the Cutting Stock Dataset.","Finally, we share our perspective on challenges and future directions in BPP.","To the best of our knowledge, this is the first systematic review of ML-related methods for BPP."],"url":"http://arxiv.org/abs/2312.08103v1"}
{"created":"2023-12-13 12:36:03","title":"Security aspects in Smart Meters: Analysis and Prevention","abstract":"Smart meters are of the basic elements in the so-called Smart Grid. These devices, connected to the Internet, keep bidirectional communication with other devices in the Smart Grid structure to allow remote readings and maintenance. As any other device connected to a network, smart meters become vulnerable to attacks with different purposes, like stealing data or altering readings. Nowadays, it is becoming more and more popular to buy and plug-and-play smart meters, additionally to those installed by the energy providers, to directly monitor the energy consumption at home. This option inherently entails security risks that are under the responsibility of householders. In this paper, we focus on an open solution based on Smartpi 2.0 devices with two purposes. On the one hand, we propose a network configuration and different data flows to exchange data (energy readings) in the home. These flows are designed to support collaborative among the devices in order to prevent external attacks and attempts of corrupting the data. On the other hand, we check the vulnerability by performing two kind of attacks (denial of service and stealing and changing data by using a malware). We conclude that, as expected, these devices are vulnerable to these attacks, but we provide mechanisms to detect both of them and to solve, by applying cooperation techniques","sentences":["Smart meters are of the basic elements in the so-called Smart Grid.","These devices, connected to the Internet, keep bidirectional communication with other devices in the Smart Grid structure to allow remote readings and maintenance.","As any other device connected to a network, smart meters become vulnerable to attacks with different purposes, like stealing data or altering readings.","Nowadays, it is becoming more and more popular to buy and plug-and-play smart meters, additionally to those installed by the energy providers, to directly monitor the energy consumption at home.","This option inherently entails security risks that are under the responsibility of householders.","In this paper, we focus on an open solution based on Smartpi 2.0 devices with two purposes.","On the one hand, we propose a network configuration and different data flows to exchange data (energy readings) in the home.","These flows are designed to support collaborative among the devices in order to prevent external attacks and attempts of corrupting the data.","On the other hand, we check the vulnerability by performing two kind of attacks (denial of service and stealing and changing data by using a malware).","We conclude that, as expected, these devices are vulnerable to these attacks, but we provide mechanisms to detect both of them and to solve, by applying cooperation techniques"],"url":"http://arxiv.org/abs/2312.08101v1"}
{"created":"2023-12-13 12:28:37","title":"An Incentive Mechanism for Federated Learning Based on Multiple Resource Exchange","abstract":"Federated Learning (FL) is a distributed machine learning paradigm that addresses privacy concerns in machine learning and still guarantees high test accuracy. However, achieving the necessary accuracy by having all clients participate in FL is impractical, given the constraints of client local computing resource. In this paper, we introduce a multi-user collaborative computing framework, categorizing users into two roles: model owners (MOs) and data owner (DOs). Without resorting to monetary incentives, an MO can encourage more DOs to join in FL by allowing the DOs to offload extra local computing tasks to the MO for execution. This exchange of \"data\" for \"computing resources\" streamlines the incentives for clients to engage more effectively in FL. We formulate the interaction between MO and DOs as an optimization problem, and the objective is to effectively utilize the communication and computing resource of the MO and DOs to minimize the time to complete an FL task. The proposed problem is a mixed integer nonlinear programming (MINLP) with high computational complexity. We first decompose it into two distinct subproblems, namely the client selection problem and the resource allocation problem to segregate the integer variables from the continuous variables. Then, an effective iterative algorithm is proposed to solve problem. Simulation results demonstrate that the proposed collaborative computing framework can achieve an accuracy of more than 95\\% while minimizing the overall time to complete an FL task.","sentences":["Federated Learning (FL) is a distributed machine learning paradigm that addresses privacy concerns in machine learning and still guarantees high test accuracy.","However, achieving the necessary accuracy by having all clients participate in FL is impractical, given the constraints of client local computing resource.","In this paper, we introduce a multi-user collaborative computing framework, categorizing users into two roles: model owners (MOs) and data owner (DOs).","Without resorting to monetary incentives, an MO can encourage more DOs to join in FL by allowing the DOs to offload extra local computing tasks to the MO for execution.","This exchange of \"data\" for \"computing resources\" streamlines the incentives for clients to engage more effectively in FL.","We formulate the interaction between MO and DOs as an optimization problem, and the objective is to effectively utilize the communication and computing resource of the MO and DOs to minimize the time to complete an FL task.","The proposed problem is a mixed integer nonlinear programming (MINLP) with high computational complexity.","We first decompose it into two distinct subproblems, namely the client selection problem and the resource allocation problem to segregate the integer variables from the continuous variables.","Then, an effective iterative algorithm is proposed to solve problem.","Simulation results demonstrate that the proposed collaborative computing framework can achieve an accuracy of more than 95\\% while minimizing the overall time to complete an FL task."],"url":"http://arxiv.org/abs/2312.08096v1"}
{"created":"2023-12-13 12:24:34","title":"3DGEN: A GAN-based approach for generating novel 3D models from image data","abstract":"The recent advances in text and image synthesis show a great promise for the future of generative models in creative fields. However, a less explored area is the one of 3D model generation, with a lot of potential applications to game design, video production, and physical product design. In our paper, we present 3DGEN, a model that leverages the recent work on both Neural Radiance Fields for object reconstruction and GAN-based image generation. We show that the proposed architecture can generate plausible meshes for objects of the same category as the training images and compare the resulting meshes with the state-of-the-art baselines, leading to visible uplifts in generation quality.","sentences":["The recent advances in text and image synthesis show a great promise for the future of generative models in creative fields.","However, a less explored area is the one of 3D model generation, with a lot of potential applications to game design, video production, and physical product design.","In our paper, we present 3DGEN, a model that leverages the recent work on both Neural Radiance Fields for object reconstruction and GAN-based image generation.","We show that the proposed architecture can generate plausible meshes for objects of the same category as the training images and compare the resulting meshes with the state-of-the-art baselines, leading to visible uplifts in generation quality."],"url":"http://arxiv.org/abs/2312.08094v1"}
{"created":"2023-12-13 12:17:16","title":"A hybrid analysis of LBSN data to early detect anomalies in crowd dynamics","abstract":"Undoubtedly, Location-based Social Networks (LBSNs) provide an interesting source of geo-located data that we have previously used to obtain patterns of the dynamics of crowds throughout urban areas. According to our previous results, activity in LBSNs reflects the real activity in the city. Therefore, unexpected behaviors in the social media activity are a trustful evidence of unexpected changes of the activity in the city. In this paper we introduce a hybrid solution to early detect these changes based on applying a combination of two approaches, the use of entropy analysis and clustering techniques, on the data gathered from LBSNs. In particular, we have performed our experiments over a data set collected from Instagram for seven months in New York City, obtaining promising results.","sentences":["Undoubtedly, Location-based Social Networks (LBSNs) provide an interesting source of geo-located data that we have previously used to obtain patterns of the dynamics of crowds throughout urban areas.","According to our previous results, activity in LBSNs reflects the real activity in the city.","Therefore, unexpected behaviors in the social media activity are a trustful evidence of unexpected changes of the activity in the city.","In this paper we introduce a hybrid solution to early detect these changes based on applying a combination of two approaches, the use of entropy analysis and clustering techniques, on the data gathered from LBSNs.","In particular, we have performed our experiments over a data set collected from Instagram for seven months in New York City, obtaining promising results."],"url":"http://arxiv.org/abs/2312.08092v1"}
{"created":"2023-12-13 12:01:32","title":"Solving Bayesian Inverse Problems With Expensive Likelihoods Using Constrained Gaussian Processes and Active Learning","abstract":"Solving inverse problems using Bayesian methods can become prohibitively expensive when likelihood evaluations involve complex and large scale numerical models. A common approach to circumvent this issue is to approximate the forward model or the likelihood function with a surrogate model. But also there, due to limited computational resources, only a few training points are available in many practically relevant cases. Thus, it can be advantageous to model the additional uncertainties of the surrogate in order to incorporate the epistemic uncertainty due to limited data. In this paper, we develop a novel approach to approximate the log likelihood by a constrained Gaussian process based on prior knowledge about its boundedness. This improves the accuracy of the surrogate approximation without increasing the number of training samples. Additionally, we introduce a formulation to integrate the epistemic uncertainty due to limited training points into the posterior density approximation. This is combined with a state of the art active learning strategy for selecting training points, which allows to approximate posterior densities in higher dimensions very efficiently. We demonstrate the fast convergence of our approach for a benchmark problem and infer a random field that is discretized by 30 parameters using only about 1000 model evaluations. In a practically relevant example, the parameters of a reduced lung model are calibrated based on flow observations over time and voltage measurements from a coupled electrical impedance tomography simulation.","sentences":["Solving inverse problems using Bayesian methods can become prohibitively expensive when likelihood evaluations involve complex and large scale numerical models.","A common approach to circumvent this issue is to approximate the forward model or the likelihood function with a surrogate model.","But also there, due to limited computational resources, only a few training points are available in many practically relevant cases.","Thus, it can be advantageous to model the additional uncertainties of the surrogate in order to incorporate the epistemic uncertainty due to limited data.","In this paper, we develop a novel approach to approximate the log likelihood by a constrained Gaussian process based on prior knowledge about its boundedness.","This improves the accuracy of the surrogate approximation without increasing the number of training samples.","Additionally, we introduce a formulation to integrate the epistemic uncertainty due to limited training points into the posterior density approximation.","This is combined with a state of the art active learning strategy for selecting training points, which allows to approximate posterior densities in higher dimensions very efficiently.","We demonstrate the fast convergence of our approach for a benchmark problem and infer a random field that is discretized by 30 parameters using only about 1000 model evaluations.","In a practically relevant example, the parameters of a reduced lung model are calibrated based on flow observations over time and voltage measurements from a coupled electrical impedance tomography simulation."],"url":"http://arxiv.org/abs/2312.08085v1"}
{"created":"2023-12-13 11:20:09","title":"A Novel Metric for Measuring Data Quality in Classification Applications (extended version)","abstract":"Data quality is a key element for building and optimizing good learning models. Despite many attempts to characterize data quality, there is still a need for rigorous formalization and an efficient measure of the quality from available observations. Indeed, without a clear understanding of the training and testing processes, it is hard to evaluate the intrinsic performance of a model. Besides, tools allowing to measure data quality specific to machine learning are still lacking. In this paper, we introduce and explain a novel metric to measure data quality. This metric is based on the correlated evolution between the classification performance and the deterioration of data. The proposed method has the major advantage of being model-independent. Furthermore, we provide an interpretation of each criterion and examples of assessment levels. We confirm the utility of the proposed metric with intensive numerical experiments and detail some illustrative cases with controlled and interpretable qualities.","sentences":["Data quality is a key element for building and optimizing good learning models.","Despite many attempts to characterize data quality, there is still a need for rigorous formalization and an efficient measure of the quality from available observations.","Indeed, without a clear understanding of the training and testing processes, it is hard to evaluate the intrinsic performance of a model.","Besides, tools allowing to measure data quality specific to machine learning are still lacking.","In this paper, we introduce and explain a novel metric to measure data quality.","This metric is based on the correlated evolution between the classification performance and the deterioration of data.","The proposed method has the major advantage of being model-independent.","Furthermore, we provide an interpretation of each criterion and examples of assessment levels.","We confirm the utility of the proposed metric with intensive numerical experiments and detail some illustrative cases with controlled and interpretable qualities."],"url":"http://arxiv.org/abs/2312.08066v1"}
{"created":"2023-12-13 11:03:07","title":"Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source Supervision","abstract":"Ancient artifacts are an important medium for cultural preservation and restoration. However, many physical copies of artifacts are either damaged or lost, leaving a blank space in archaeological and historical studies that calls for artifact image generation techniques. Despite the significant advancements in open-domain text-to-image synthesis, existing approaches fail to capture the important domain knowledge presented in the textual description, resulting in errors in recreated images such as incorrect shapes and patterns. In this paper, we propose a novel knowledge-aware artifact image synthesis approach that brings lost historical objects accurately into their visual forms. We use a pretrained diffusion model as backbone and introduce three key techniques to enhance the text-to-image generation framework: 1) we construct prompts with explicit archaeological knowledge elicited from large language models (LLMs); 2) we incorporate additional textual guidance to correlated historical expertise in a contrastive manner; 3) we introduce further visual-semantic constraints on edge and perceptual features that enable our model to learn more intricate visual details of the artifacts. Compared to existing approaches, our proposed model produces higher-quality artifact images that align better with the implicit details and historical knowledge contained within written documents, thus achieving significant improvements across automatic metrics and in human evaluation. Our code and data are available at https://github.com/danielwusg/artifact_diffusion.","sentences":["Ancient artifacts are an important medium for cultural preservation and restoration.","However, many physical copies of artifacts are either damaged or lost, leaving a blank space in archaeological and historical studies that calls for artifact image generation techniques.","Despite the significant advancements in open-domain text-to-image synthesis, existing approaches fail to capture the important domain knowledge presented in the textual description, resulting in errors in recreated images such as incorrect shapes and patterns.","In this paper, we propose a novel knowledge-aware artifact image synthesis approach that brings lost historical objects accurately into their visual forms.","We use a pretrained diffusion model as backbone and introduce three key techniques to enhance the text-to-image generation framework: 1) we construct prompts with explicit archaeological knowledge elicited from large language models (LLMs); 2) we incorporate additional textual guidance to correlated historical expertise in a contrastive manner; 3) we introduce further visual-semantic constraints on edge and perceptual features that enable our model to learn more intricate visual details of the artifacts.","Compared to existing approaches, our proposed model produces higher-quality artifact images that align better with the implicit details and historical knowledge contained within written documents, thus achieving significant improvements across automatic metrics and in human evaluation.","Our code and data are available at https://github.com/danielwusg/artifact_diffusion."],"url":"http://arxiv.org/abs/2312.08056v1"}
{"created":"2023-12-13 11:02:19","title":"Breaking the Silence: the Threats of Using LLMs in Software Engineering","abstract":"Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization. Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs. This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings. In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns. The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation.","sentences":["Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization.","Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs.","This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings.","In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns.","The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation."],"url":"http://arxiv.org/abs/2312.08055v1"}
{"created":"2023-12-13 10:59:54","title":"Explainable Trajectory Representation through Dictionary Learning","abstract":"Trajectory representation learning on a network enhances our understanding of vehicular traffic patterns and benefits numerous downstream applications. Existing approaches using classic machine learning or deep learning embed trajectories as dense vectors, which lack interpretability and are inefficient to store and analyze in downstream tasks. In this paper, an explainable trajectory representation learning framework through dictionary learning is proposed. Given a collection of trajectories on a network, it extracts a compact dictionary of commonly used subpaths called \"pathlets\", which optimally reconstruct each trajectory by simple concatenations. The resulting representation is naturally sparse and encodes strong spatial semantics. Theoretical analysis of our proposed algorithm is conducted to provide a probabilistic bound on the estimation error of the optimal dictionary. A hierarchical dictionary learning scheme is also proposed to ensure the algorithm's scalability on large networks, leading to a multi-scale trajectory representation. Our framework is evaluated on two large-scale real-world taxi datasets. Compared to previous work, the dictionary learned by our method is more compact and has better reconstruction rate for new trajectories. We also demonstrate the promising performance of this method in downstream tasks including trip time prediction task and data compression.","sentences":["Trajectory representation learning on a network enhances our understanding of vehicular traffic patterns and benefits numerous downstream applications.","Existing approaches using classic machine learning or deep learning embed trajectories as dense vectors, which lack interpretability and are inefficient to store and analyze in downstream tasks.","In this paper, an explainable trajectory representation learning framework through dictionary learning is proposed.","Given a collection of trajectories on a network, it extracts a compact dictionary of commonly used subpaths called \"pathlets\", which optimally reconstruct each trajectory by simple concatenations.","The resulting representation is naturally sparse and encodes strong spatial semantics.","Theoretical analysis of our proposed algorithm is conducted to provide a probabilistic bound on the estimation error of the optimal dictionary.","A hierarchical dictionary learning scheme is also proposed to ensure the algorithm's scalability on large networks, leading to a multi-scale trajectory representation.","Our framework is evaluated on two large-scale real-world taxi datasets.","Compared to previous work, the dictionary learned by our method is more compact and has better reconstruction rate for new trajectories.","We also demonstrate the promising performance of this method in downstream tasks including trip time prediction task and data compression."],"url":"http://arxiv.org/abs/2312.08052v1"}
{"created":"2023-12-13 10:40:15","title":"Leveraging User Simulation to Develop and Evaluate Conversational Information Access Agents","abstract":"We observe a change in the way users access information, that is, the rise of conversational information access (CIA) agents. However, the automatic evaluation of these agents remains an open challenge. Moreover, the training of CIA agents is cumbersome as it mostly relies on conversational corpora, expert knowledge, and reinforcement learning. User simulation has been identified as a promising solution to tackle automatic evaluation and has been previously used in reinforcement learning. In this research, we investigate how user simulation can be leveraged in the context of CIA. We organize the work in three parts. We begin with the identification of requirements for user simulators for training and evaluating CIA agents and compare existing types of simulator regarding these. Then, we plan to combine these different types of simulators into a new hybrid simulator. Finally, we aim to extend simulators to handle more complex information seeking scenarios.","sentences":["We observe a change in the way users access information, that is, the rise of conversational information access (CIA) agents.","However, the automatic evaluation of these agents remains an open challenge.","Moreover, the training of CIA agents is cumbersome as it mostly relies on conversational corpora, expert knowledge, and reinforcement learning.","User simulation has been identified as a promising solution to tackle automatic evaluation and has been previously used in reinforcement learning.","In this research, we investigate how user simulation can be leveraged in the context of CIA.","We organize the work in three parts.","We begin with the identification of requirements for user simulators for training and evaluating CIA agents and compare existing types of simulator regarding these.","Then, we plan to combine these different types of simulators into a new hybrid simulator.","Finally, we aim to extend simulators to handle more complex information seeking scenarios."],"url":"http://arxiv.org/abs/2312.08041v1"}
{"created":"2023-12-13 10:35:28","title":"Combined Approximations for Uniform Operational Consistent Query Answering","abstract":"Operational consistent query answering (CQA) is a recent framework for CQA based on revised definitions of repairs, which are built by applying a sequence of operations (e.g., fact deletions) starting from an inconsistent database until we reach a database that is consistent w.r.t. the given set of constraints. It has been recently shown that there are efficient approximations for computing the percentage of repairs, as well as of sequences of operations leading to repairs, that entail a given query when we focus on primary keys, conjunctive queries, and assuming the query is fixed (i.e., in data complexity). However, it has been left open whether such approximations exist when the query is part of the input (i.e., in combined complexity). We show that this is the case when we focus on self-join-free conjunctive queries of bounded generelized hypertreewidth. We also show that it is unlikely that efficient approximation schemes exist once we give up one of the adopted syntactic restrictions, i.e., self-join-freeness or bounding the generelized hypertreewidth. Towards the desired approximation schemes, we introduce a novel counting complexity class, called SpanTL, show that each problem in SpanTL admits an efficient approximation scheme by using a recent approximability result in the context of tree automata, and then place the problems of interest in SpanTL.","sentences":["Operational consistent query answering (CQA) is a recent framework for CQA based on revised definitions of repairs, which are built by applying a sequence of operations (e.g., fact deletions) starting from an inconsistent database until we reach a database that is consistent w.r.t.","the given set of constraints.","It has been recently shown that there are efficient approximations for computing the percentage of repairs, as well as of sequences of operations leading to repairs, that entail a given query when we focus on primary keys, conjunctive queries, and assuming the query is fixed (i.e., in data complexity).","However, it has been left open whether such approximations exist when the query is part of the input (i.e., in combined complexity).","We show that this is the case when we focus on self-join-free conjunctive queries of bounded generelized hypertreewidth.","We also show that it is unlikely that efficient approximation schemes exist once we give up one of the adopted syntactic restrictions, i.e., self-join-freeness or bounding the generelized hypertreewidth.","Towards the desired approximation schemes, we introduce a novel counting complexity class, called SpanTL, show that each problem in SpanTL admits an efficient approximation scheme by using a recent approximability result in the context of tree automata, and then place the problems of interest in SpanTL."],"url":"http://arxiv.org/abs/2312.08038v1"}
{"created":"2023-12-13 10:19:58","title":"Beyond Top-Class Agreement: Using Divergences to Forecast Performance under Distribution Shift","abstract":"Knowing if a model will generalize to data 'in the wild' is crucial for safe deployment. To this end, we study model disagreement notions that consider the full predictive distribution - specifically disagreement based on Hellinger distance, Jensen-Shannon and Kullback-Leibler divergence. We find that divergence-based scores provide better test error estimates and detection rates on out-of-distribution data compared to their top-1 counterparts. Experiments involve standard vision and foundation models.","sentences":["Knowing if a model will generalize to data 'in the wild' is crucial for safe deployment.","To this end, we study model disagreement notions that consider the full predictive distribution - specifically disagreement based on Hellinger distance, Jensen-Shannon and Kullback-Leibler divergence.","We find that divergence-based scores provide better test error estimates and detection rates on out-of-distribution data compared to their top-1 counterparts.","Experiments involve standard vision and foundation models."],"url":"http://arxiv.org/abs/2312.08033v1"}
{"created":"2023-12-13 10:06:15","title":"Incremental Learning of Full-Pose Via-Point Movement Primitives on Riemannian Manifolds","abstract":"Movement primitives (MPs) are compact representations of robot skills that can be learned from demonstrations and combined into complex behaviors. However, merely equipping robots with a fixed set of innate MPs is insufficient to deploy them in dynamic and unpredictable environments. Instead, the full potential of MPs remains to be attained via adaptable, large-scale MP libraries. In this paper, we propose a set of seven fundamental operations to incrementally learn, improve, and re-organize MP libraries. To showcase their applicability, we provide explicit formulations of the spatial operations for libraries composed of Via-Point Movement Primitives (VMPs). By building on Riemannian manifold theory, our approach enables the incremental learning of all parameters of position and orientation VMPs within a library. Moreover, our approach stores a fixed number of parameters, thus complying with the essential principles of incremental learning. We evaluate our approach to incrementally learn a VMP library from motion capture data provided sequentially.","sentences":["Movement primitives (MPs) are compact representations of robot skills that can be learned from demonstrations and combined into complex behaviors.","However, merely equipping robots with a fixed set of innate MPs is insufficient to deploy them in dynamic and unpredictable environments.","Instead, the full potential of MPs remains to be attained via adaptable, large-scale MP libraries.","In this paper, we propose a set of seven fundamental operations to incrementally learn, improve, and re-organize MP libraries.","To showcase their applicability, we provide explicit formulations of the spatial operations for libraries composed of Via-Point Movement Primitives (VMPs).","By building on Riemannian manifold theory, our approach enables the incremental learning of all parameters of position and orientation VMPs within a library.","Moreover, our approach stores a fixed number of parameters, thus complying with the essential principles of incremental learning.","We evaluate our approach to incrementally learn a VMP library from motion capture data provided sequentially."],"url":"http://arxiv.org/abs/2312.08030v1"}
{"created":"2023-12-13 10:04:06","title":"ClusterDDPM: An EM clustering framework with Denoising Diffusion Probabilistic Models","abstract":"Variational autoencoder (VAE) and generative adversarial networks (GAN) have found widespread applications in clustering and have achieved significant success. However, the potential of these approaches may be limited due to VAE's mediocre generation capability or GAN's well-known instability during adversarial training. In contrast, denoising diffusion probabilistic models (DDPMs) represent a new and promising class of generative models that may unlock fresh dimensions in clustering. In this study, we introduce an innovative expectation-maximization (EM) framework for clustering using DDPMs. In the E-step, we aim to derive a mixture of Gaussian priors for the subsequent M-step. In the M-step, our focus lies in learning clustering-friendly latent representations for the data by employing the conditional DDPM and matching the distribution of latent representations to the mixture of Gaussian priors. We present a rigorous theoretical analysis of the optimization process in the M-step, proving that the optimizations are equivalent to maximizing the lower bound of the Q function within the vanilla EM framework under certain constraints. Comprehensive experiments validate the advantages of the proposed framework, showcasing superior performance in clustering, unsupervised conditional generation and latent representation learning.","sentences":["Variational autoencoder (VAE) and generative adversarial networks (GAN) have found widespread applications in clustering and have achieved significant success.","However, the potential of these approaches may be limited due to VAE's mediocre generation capability or GAN's well-known instability during adversarial training.","In contrast, denoising diffusion probabilistic models (DDPMs) represent a new and promising class of generative models that may unlock fresh dimensions in clustering.","In this study, we introduce an innovative expectation-maximization (EM) framework for clustering using DDPMs.","In the E-step, we aim to derive a mixture of Gaussian priors for the subsequent M-step.","In the M-step, our focus lies in learning clustering-friendly latent representations for the data by employing the conditional DDPM and matching the distribution of latent representations to the mixture of Gaussian priors.","We present a rigorous theoretical analysis of the optimization process in the M-step, proving that the optimizations are equivalent to maximizing the lower bound of the Q function within the vanilla EM framework under certain constraints.","Comprehensive experiments validate the advantages of the proposed framework, showcasing superior performance in clustering, unsupervised conditional generation and latent representation learning."],"url":"http://arxiv.org/abs/2312.08029v1"}
{"created":"2023-12-13 09:49:15","title":"Generalized Deepfakes Detection with Reconstructed-Blended Images and Multi-scale Feature Reconstruction Network","abstract":"The growing diversity of digital face manipulation techniques has led to an urgent need for a universal and robust detection technology to mitigate the risks posed by malicious forgeries. We present a blended-based detection approach that has robust applicability to unseen datasets. It combines a method for generating synthetic training samples, i.e., reconstructed blended images, that incorporate potential deepfake generator artifacts and a detection model, a multi-scale feature reconstruction network, for capturing the generic boundary artifacts and noise distribution anomalies brought about by digital face manipulations. Experiments demonstrated that this approach results in better performance in both cross-manipulation detection and cross-dataset detection on unseen data.","sentences":["The growing diversity of digital face manipulation techniques has led to an urgent need for a universal and robust detection technology to mitigate the risks posed by malicious forgeries.","We present a blended-based detection approach that has robust applicability to unseen datasets.","It combines a method for generating synthetic training samples, i.e., reconstructed blended images, that incorporate potential deepfake generator artifacts and a detection model, a multi-scale feature reconstruction network, for capturing the generic boundary artifacts and noise distribution anomalies brought about by digital face manipulations.","Experiments demonstrated that this approach results in better performance in both cross-manipulation detection and cross-dataset detection on unseen data."],"url":"http://arxiv.org/abs/2312.08020v1"}
{"created":"2023-12-13 09:45:58","title":"AdapEdit: Spatio-Temporal Guided Adaptive Editing Algorithm for Text-Based Continuity-Sensitive Image Editing","abstract":"With the great success of text-conditioned diffusion models in creative text-to-image generation, various text-driven image editing approaches have attracted the attentions of many researchers. However, previous works mainly focus on discreteness-sensitive instructions such as adding, removing or replacing specific objects, background elements or global styles (i.e., hard editing), while generally ignoring subject-binding but semantically fine-changing continuity-sensitive instructions such as actions, poses or adjectives, and so on (i.e., soft editing), which hampers generative AI from generating user-customized visual contents. To mitigate this predicament, we propose a spatio-temporal guided adaptive editing algorithm AdapEdit, which realizes adaptive image editing by introducing a soft-attention strategy to dynamically vary the guiding degree from the editing conditions to visual pixels from both temporal and spatial perspectives. Note our approach has a significant advantage in preserving model priors and does not require model training, fine-tuning, extra data, or optimization. We present our results over a wide variety of raw images and editing instructions, demonstrating competitive performance and showing it significantly outperforms the previous approaches.","sentences":["With the great success of text-conditioned diffusion models in creative text-to-image generation, various text-driven image editing approaches have attracted the attentions of many researchers.","However, previous works mainly focus on discreteness-sensitive instructions such as adding, removing or replacing specific objects, background elements or global styles (i.e., hard editing), while generally ignoring subject-binding but semantically fine-changing continuity-sensitive instructions such as actions, poses or adjectives, and so on (i.e., soft editing), which hampers generative AI from generating user-customized visual contents.","To mitigate this predicament, we propose a spatio-temporal guided adaptive editing algorithm AdapEdit, which realizes adaptive image editing by introducing a soft-attention strategy to dynamically vary the guiding degree from the editing conditions to visual pixels from both temporal and spatial perspectives.","Note our approach has a significant advantage in preserving model priors and does not require model training, fine-tuning, extra data, or optimization.","We present our results over a wide variety of raw images and editing instructions, demonstrating competitive performance and showing it significantly outperforms the previous approaches."],"url":"http://arxiv.org/abs/2312.08019v1"}
{"created":"2023-12-13 09:39:32","title":"Secure Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless MEC Networks","abstract":"This paper proposes a blockchain-secured deep reinforcement learning (BC-DRL) optimization framework for {data management and} resource allocation in decentralized {wireless mobile edge computing (MEC)} networks. In our framework, {we design a low-latency reputation-based proof-of-stake (RPoS) consensus protocol to select highly reliable blockchain-enabled BSs to securely store MEC user requests and prevent data tampering attacks.} {We formulate the MEC resource allocation optimization as a constrained Markov decision process that balances minimum processing latency and denial-of-service (DoS) probability}. {We use the MEC aggregated features as the DRL input to significantly reduce the high-dimensionality input of the remaining service processing time for individual MEC requests. Our designed constrained DRL effectively attains the optimal resource allocations that are adapted to the dynamic DoS requirements. We provide extensive simulation results and analysis to} validate that our BC-DRL framework achieves higher security, reliability, and resource utilization efficiency than benchmark blockchain consensus protocols and {MEC} resource allocation algorithms.","sentences":["This paper proposes a blockchain-secured deep reinforcement learning (BC-DRL) optimization framework for {data management and} resource allocation in decentralized {wireless mobile edge computing (MEC)} networks.","In our framework, {we design a low-latency reputation-based proof-of-stake (RPoS) consensus protocol to select highly reliable blockchain-enabled BSs to securely store MEC user requests and prevent data tampering attacks.}","{We formulate the MEC resource allocation optimization as a constrained Markov decision process that balances minimum processing latency and denial-of-service (DoS) probability}.","{We use the MEC aggregated features as the DRL input to significantly reduce the high-dimensionality input of the remaining service processing time for individual MEC requests.","Our designed constrained DRL effectively attains the optimal resource allocations that are adapted to the dynamic DoS requirements.","We provide extensive simulation results and analysis to} validate that our BC-DRL framework achieves higher security, reliability, and resource utilization efficiency than benchmark blockchain consensus protocols and {MEC} resource allocation algorithms."],"url":"http://arxiv.org/abs/2312.08016v1"}
{"created":"2023-12-13 09:33:08","title":"EZ-CLIP: Efficient Zeroshot Video Action Recognition","abstract":"Recent advancements in large-scale pre-training of visual-language models on paired image-text data have demonstrated impressive generalization capabilities for zero-shot tasks. Building on this success, efforts have been made to adapt these image-based visual-language models, such as CLIP, for videos extending their zero-shot capabilities to the video domain. While these adaptations have shown promising results, they come at a significant computational cost and struggle with effectively modeling the crucial temporal aspects inherent to the video domain. In this study, we present EZ-CLIP, a simple and efficient adaptation of CLIP that addresses these challenges. EZ-CLIP leverages temporal visual prompting for seamless temporal adaptation, requiring no fundamental alterations to the core CLIP architecture while preserving its remarkable generalization abilities. Moreover, we introduce a novel learning objective that guides the temporal visual prompts to focus on capturing motion, thereby enhancing its learning capabilities from video data. We conducted extensive experiments on five different benchmark datasets, thoroughly evaluating EZ-CLIP for zero-shot learning and base-to-novel video action recognition, and also demonstrating its potential for few-shot generalization.Impressively, with a mere 5.2 million learnable parameters (as opposed to the 71.1 million in the prior best model), EZ-CLIP can be efficiently trained on a single GPU, outperforming existing approaches in several evaluations.","sentences":["Recent advancements in large-scale pre-training of visual-language models on paired image-text data have demonstrated impressive generalization capabilities for zero-shot tasks.","Building on this success, efforts have been made to adapt these image-based visual-language models, such as CLIP, for videos extending their zero-shot capabilities to the video domain.","While these adaptations have shown promising results, they come at a significant computational cost and struggle with effectively modeling the crucial temporal aspects inherent to the video domain.","In this study, we present EZ-CLIP, a simple and efficient adaptation of CLIP that addresses these challenges.","EZ-CLIP leverages temporal visual prompting for seamless temporal adaptation, requiring no fundamental alterations to the core CLIP architecture while preserving its remarkable generalization abilities.","Moreover, we introduce a novel learning objective that guides the temporal visual prompts to focus on capturing motion, thereby enhancing its learning capabilities from video data.","We conducted extensive experiments on five different benchmark datasets, thoroughly evaluating EZ-CLIP for zero-shot learning and base-to-novel video action recognition, and also demonstrating its potential for few-shot generalization.","Impressively, with a mere 5.2 million learnable parameters (as opposed to the 71.1 million in the prior best model), EZ-CLIP can be efficiently trained on a single GPU, outperforming existing approaches in several evaluations."],"url":"http://arxiv.org/abs/2312.08010v1"}
{"created":"2023-12-13 09:32:50","title":"Semi-Supervised Class-Agnostic Motion Prediction with Pseudo Label Regeneration and BEVMix","abstract":"Class-agnostic motion prediction methods aim to comprehend motion within open-world scenarios, holding significance for autonomous driving systems. However, training a high-performance model in a fully-supervised manner always requires substantial amounts of manually annotated data, which can be both expensive and time-consuming to obtain. To address this challenge, our study explores the potential of semi-supervised learning (SSL) for class-agnostic motion prediction. Our SSL framework adopts a consistency-based self-training paradigm, enabling the model to learn from unlabeled data by generating pseudo labels through test-time inference. To improve the quality of pseudo labels, we propose a novel motion selection and re-generation module. This module effectively selects reliable pseudo labels and re-generates unreliable ones. Furthermore, we propose two data augmentation strategies: temporal sampling and BEVMix. These strategies facilitate consistency regularization in SSL. Experiments conducted on nuScenes demonstrate that our SSL method can surpass the self-supervised approach by a large margin by utilizing only a tiny fraction of labeled data. Furthermore, our method exhibits comparable performance to weakly and some fully supervised methods. These results highlight the ability of our method to strike a favorable balance between annotation costs and performance. Code will be available at https://github.com/kwwcv/SSMP.","sentences":["Class-agnostic motion prediction methods aim to comprehend motion within open-world scenarios, holding significance for autonomous driving systems.","However, training a high-performance model in a fully-supervised manner always requires substantial amounts of manually annotated data, which can be both expensive and time-consuming to obtain.","To address this challenge, our study explores the potential of semi-supervised learning (SSL) for class-agnostic motion prediction.","Our SSL framework adopts a consistency-based self-training paradigm, enabling the model to learn from unlabeled data by generating pseudo labels through test-time inference.","To improve the quality of pseudo labels, we propose a novel motion selection and re-generation module.","This module effectively selects reliable pseudo labels and re-generates unreliable ones.","Furthermore, we propose two data augmentation strategies: temporal sampling and BEVMix.","These strategies facilitate consistency regularization in SSL.","Experiments conducted on nuScenes demonstrate that our SSL method can surpass the self-supervised approach by a large margin by utilizing only a tiny fraction of labeled data.","Furthermore, our method exhibits comparable performance to weakly and some fully supervised methods.","These results highlight the ability of our method to strike a favorable balance between annotation costs and performance.","Code will be available at https://github.com/kwwcv/SSMP."],"url":"http://arxiv.org/abs/2312.08009v2"}
{"created":"2023-12-13 09:29:45","title":"Unveiling Parts Beyond Objects:Towards Finer-Granularity Referring Expression Segmentation","abstract":"Referring expression segmentation (RES) aims at segmenting the foreground masks of the entities that match the descriptive natural language expression. Previous datasets and methods for classic RES task heavily rely on the prior assumption that one expression must refer to object-level targets. In this paper, we take a step further to finer-grained part-level RES task. To promote the object-level RES task towards finer-grained vision-language understanding, we put forward a new multi-granularity referring expression segmentation (MRES) task and construct an evaluation benchmark called RefCOCOm by manual annotations. By employing our automatic model-assisted data engine, we build the largest visual grounding dataset namely MRES-32M, which comprises over 32.2M high-quality masks and captions on the provided 1M images. Besides, a simple yet strong model named UniRES is designed to accomplish the unified object-level and part-level grounding task. Extensive experiments on our RefCOCOm for MRES and three datasets (i.e., RefCOCO(+/g) for classic RES task demonstrate the superiority of our method over previous state-of-the-art methods. To foster future research into fine-grained visual grounding, our benchmark RefCOCOm, the MRES-32M dataset and model UniRES will be publicly available at https://github.com/Rubics-Xuan/MRES","sentences":["Referring expression segmentation (RES) aims at segmenting the foreground masks of the entities that match the descriptive natural language expression.","Previous datasets and methods for classic RES task heavily rely on the prior assumption that one expression must refer to object-level targets.","In this paper, we take a step further to finer-grained part-level RES task.","To promote the object-level RES task towards finer-grained vision-language understanding, we put forward a new multi-granularity referring expression segmentation (MRES) task and construct an evaluation benchmark called RefCOCOm","by manual annotations.","By employing our automatic model-assisted data engine, we build the largest visual grounding dataset namely MRES-32M, which comprises over 32.2M high-quality masks and captions on the provided 1M images.","Besides, a simple yet strong model named UniRES is designed to accomplish the unified object-level and part-level grounding task.","Extensive experiments on our RefCOCOm for MRES and three datasets (i.e., RefCOCO(+/g) for classic RES task demonstrate the superiority of our method over previous state-of-the-art methods.","To foster future research into fine-grained visual grounding, our benchmark RefCOCOm, the MRES-32M dataset and model UniRES will be publicly available at https://github.com/Rubics-Xuan/MRES"],"url":"http://arxiv.org/abs/2312.08007v1"}
{"created":"2023-12-13 09:04:14","title":"On the privacy of federated Clustering: A Cryptographic View","abstract":"The privacy concern in federated clustering has attracted considerable attention in past decades. Many privacy-preserving clustering algorithms leverage cryptographic techniques like homomorphic encryption or secure multiparty computation, to guarantee full privacy, i.e., no additional information is leaked other than the final output. However, given the iterative nature of clustering algorithms, consistently encrypting intermediate outputs, such as centroids, hampers efficiency. This paper delves into this intricate trade-off, questioning the necessity of continuous encryption in iterative algorithms. Using the federated K-means clustering as an example, we mathematically formulate the problem of reconstructing input private data from the intermediate centroids as a classical cryptographic problem called hidden subset sum problem (HSSP)-extended from an NP-complete problem called subset sum problem (SSP). Through an in-depth analysis, we show that existing lattice-based HSSP attacks fail in reconstructing the private data given the knowledge of intermediate centroids, thus it is secure to reveal them for the sake of efficiency. To the best of our knowledge, our work is the first to cast federated clustering's privacy concerns as a cryptographic problem HSSP such that a concrete and rigorous analysis can be conducted.","sentences":["The privacy concern in federated clustering has attracted considerable attention in past decades.","Many privacy-preserving clustering algorithms leverage cryptographic techniques like homomorphic encryption or secure multiparty computation, to guarantee full privacy, i.e., no additional information is leaked other than the final output.","However, given the iterative nature of clustering algorithms, consistently encrypting intermediate outputs, such as centroids, hampers efficiency.","This paper delves into this intricate trade-off, questioning the necessity of continuous encryption in iterative algorithms.","Using the federated K-means clustering as an example, we mathematically formulate the problem of reconstructing input private data from the intermediate centroids as a classical cryptographic problem called hidden subset sum problem (HSSP)-extended from an NP-complete problem called subset sum problem (SSP).","Through an in-depth analysis, we show that existing lattice-based HSSP attacks fail in reconstructing the private data given the knowledge of intermediate centroids, thus it is secure to reveal them for the sake of efficiency.","To the best of our knowledge, our work is the first to cast federated clustering's privacy concerns as a cryptographic problem HSSP such that a concrete and rigorous analysis can be conducted."],"url":"http://arxiv.org/abs/2312.07992v1"}
{"created":"2023-12-13 08:53:37","title":"Time Series Diffusion Method: A Denoising Diffusion Probabilistic Model for Vibration Signal Generation","abstract":"Diffusion models have demonstrated robust data generation capabilities in various research fields. In this paper, a Time Series Diffusion Method (TSDM) is proposed for vibration signal generation, leveraging the foundational principles of diffusion models. The TSDM uses an improved U-net architecture with attention block to effectively segment and extract features from one-dimensional time series data. It operates based on forward diffusion and reverse denoising processes for time-series generation. Experimental validation is conducted using single-frequency, multi-frequency datasets, and bearing fault datasets. The results show that TSDM can accurately generate the single-frequency and multi-frequency features in the time series and retain the basic frequency features for the diffusion generation results of the bearing fault series. Finally, TSDM is applied to the small sample fault diagnosis of three public bearing fault datasets, and the results show that the accuracy of small sample fault diagnosis of the three datasets is improved by 32.380%, 18.355% and 9.298% at most, respectively","sentences":["Diffusion models have demonstrated robust data generation capabilities in various research fields.","In this paper, a Time Series Diffusion Method (TSDM) is proposed for vibration signal generation, leveraging the foundational principles of diffusion models.","The TSDM uses an improved U-net architecture with attention block to effectively segment and extract features from one-dimensional time series data.","It operates based on forward diffusion and reverse denoising processes for time-series generation.","Experimental validation is conducted using single-frequency, multi-frequency datasets, and bearing fault datasets.","The results show that TSDM can accurately generate the single-frequency and multi-frequency features in the time series and retain the basic frequency features for the diffusion generation results of the bearing fault series.","Finally, TSDM is applied to the small sample fault diagnosis of three public bearing fault datasets, and the results show that the accuracy of small sample fault diagnosis of the three datasets is improved by 32.380%, 18.355% and 9.298% at most, respectively"],"url":"http://arxiv.org/abs/2312.07981v1"}
{"created":"2023-12-13 08:45:57","title":"Challenges of YOLO Series for Object Detection in Extremely Heavy Rain: CALRA Simulator based Synthetic Evaluation Dataset","abstract":"Recently, as many studies of autonomous vehicles have been achieved for levels 4 and 5, there has been also increasing interest in the advancement of perception, decision, and control technologies, which are the three major aspects of autonomous vehicles. As for the perception technologies achieving reliable maneuvering of autonomous vehicles, object detection by using diverse sensors (e.g., LiDAR, radar, and camera) should be prioritized. These sensors require to detect objects accurately and quickly in diverse weather conditions, but they tend to have challenges to consistently detect objects in bad weather conditions with rain, snow, or fog. Thus, in this study, based on the experimentally obtained raindrop data from precipitation conditions, we constructed a novel dataset that could test diverse network model in various precipitation conditions through the CARLA simulator. Consequently, based on our novel dataset, YOLO series, a one-stage-detector, was used to quantitatively verify how much object detection performance could be decreased under various precipitation conditions from normal to extreme heavy rain situations.","sentences":["Recently, as many studies of autonomous vehicles have been achieved for levels 4 and 5, there has been also increasing interest in the advancement of perception, decision, and control technologies, which are the three major aspects of autonomous vehicles.","As for the perception technologies achieving reliable maneuvering of autonomous vehicles, object detection by using diverse sensors (e.g., LiDAR, radar, and camera) should be prioritized.","These sensors require to detect objects accurately and quickly in diverse weather conditions, but they tend to have challenges to consistently detect objects in bad weather conditions with rain, snow, or fog.","Thus, in this study, based on the experimentally obtained raindrop data from precipitation conditions, we constructed a novel dataset that could test diverse network model in various precipitation conditions through the CARLA simulator.","Consequently, based on our novel dataset, YOLO series, a one-stage-detector, was used to quantitatively verify how much object detection performance could be decreased under various precipitation conditions from normal to extreme heavy rain situations."],"url":"http://arxiv.org/abs/2312.07976v2"}
{"created":"2023-12-13 08:33:50","title":"Divide and Conquer: Hybrid Pre-training for Person Search","abstract":"Large-scale pre-training has proven to be an effective method for improving performance across different tasks. Current person search methods use ImageNet pre-trained models for feature extraction, yet it is not an optimal solution due to the gap between the pre-training task and person search task (as a downstream task). Therefore, in this paper, we focus on pre-training for person search, which involves detecting and re-identifying individuals simultaneously. Although labeled data for person search is scarce, datasets for two sub-tasks person detection and re-identification are relatively abundant. To this end, we propose a hybrid pre-training framework specifically designed for person search using sub-task data only. It consists of a hybrid learning paradigm that handles data with different kinds of supervisions, and an intra-task alignment module that alleviates domain discrepancy under limited resources. To the best of our knowledge, this is the first work that investigates how to support full-task pre-training using sub-task data. Extensive experiments demonstrate that our pre-trained model can achieve significant improvements across diverse protocols, such as person search method, fine-tuning data, pre-training data and model backbone. For example, our model improves ResNet50 based NAE by 10.3% relative improvement w.r.t. mAP. Our code and pre-trained models are released for plug-and-play usage to the person search community.","sentences":["Large-scale pre-training has proven to be an effective method for improving performance across different tasks.","Current person search methods use ImageNet pre-trained models for feature extraction, yet it is not an optimal solution due to the gap between the pre-training task and person search task (as a downstream task).","Therefore, in this paper, we focus on pre-training for person search, which involves detecting and re-identifying individuals simultaneously.","Although labeled data for person search is scarce, datasets for two sub-tasks person detection and re-identification are relatively abundant.","To this end, we propose a hybrid pre-training framework specifically designed for person search using sub-task data only.","It consists of a hybrid learning paradigm that handles data with different kinds of supervisions, and an intra-task alignment module that alleviates domain discrepancy under limited resources.","To the best of our knowledge, this is the first work that investigates how to support full-task pre-training using sub-task data.","Extensive experiments demonstrate that our pre-trained model can achieve significant improvements across diverse protocols, such as person search method, fine-tuning data, pre-training data and model backbone.","For example, our model improves ResNet50 based NAE by 10.3% relative improvement w.r.t.","mAP.","Our code and pre-trained models are released for plug-and-play usage to the person search community."],"url":"http://arxiv.org/abs/2312.07970v1"}
{"created":"2023-12-13 08:28:55","title":"A multi-sourced data and agent-based approach for complementing Time Use Surveys in the context of residential human activity and load curve simulation","abstract":"To address the major issues associated with using Time-Use Survey (TUS) for simulating residential load curves, we present the SMACH approach, which combines qualitative and quantitative data with agent-based simulation. Our model consists of autonomous agents assigned with daily tasks. The agents try to accomplish their assigned tasks to the best of their abilities. Quantitative data are used to generate tasks assignments. Qualitative studies allow us to define how agents select, based on plausible cognitive principles, the tasks to accomplish depending on the context. Our results show a better representation of weekdays and weekends, a more flexible association of tasks with appliances, and an improved simulation of load curves compared to real data. Highlights $\\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in activity and energy simulation $\\bullet$ Presentation of complementary data both qualitative and quantitative used to complement TUS data $\\bullet$ Proposition of an agent-based approach that balances these limitations","sentences":["To address the major issues associated with using Time-Use Survey (TUS) for simulating residential load curves, we present the SMACH approach, which combines qualitative and quantitative data with agent-based simulation.","Our model consists of autonomous agents assigned with daily tasks.","The agents try to accomplish their assigned tasks to the best of their abilities.","Quantitative data are used to generate tasks assignments.","Qualitative studies allow us to define how agents select, based on plausible cognitive principles, the tasks to accomplish depending on the context.","Our results show a better representation of weekdays and weekends, a more flexible association of tasks with appliances, and an improved simulation of load curves compared to real data.","Highlights $\\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in activity and energy simulation $\\bullet$ Presentation of complementary data both qualitative and quantitative used to complement TUS data $\\bullet$ Proposition of an agent-based approach that balances these limitations"],"url":"http://arxiv.org/abs/2312.07966v1"}
{"created":"2023-12-13 08:18:49","title":"Three-Filters-to-Normal+: Revisiting Discontinuity Discrimination in Depth-to-Normal Translation","abstract":"This article introduces three-filters-to-normal+ (3F2N+), an extension of our previous work three-filters-to-normal (3F2N), with a specific focus on incorporating discontinuity discrimination capability into surface normal estimators (SNEs). 3F2N+ achieves this capability by utilizing a novel discontinuity discrimination module (DDM), which combines depth curvature minimization and correlation coefficient maximization through conditional random fields (CRFs). To evaluate the robustness of SNEs on noisy data, we create a large-scale synthetic surface normal (SSN) dataset containing 20 scenarios (ten indoor scenarios and ten outdoor scenarios with and without random Gaussian noise added to depth images). Extensive experiments demonstrate that 3F2N+ achieves greater performance than all other geometry-based surface normal estimators, with average angular errors of 7.85$^\\circ$, 8.95$^\\circ$, 9.25$^\\circ$, and 11.98$^\\circ$ on the clean-indoor, clean-outdoor, noisy-indoor, and noisy-outdoor datasets, respectively. We conduct three additional experiments to demonstrate the effectiveness of incorporating our proposed 3F2N+ into downstream robot perception tasks, including freespace detection, 6D object pose estimation, and point cloud completion. Our source code and datasets are publicly available at https://mias.group/3F2Nplus.","sentences":["This article introduces three-filters-to-normal+ (3F2N+), an extension of our previous work three-filters-to-normal (3F2N), with a specific focus on incorporating discontinuity discrimination capability into surface normal estimators (SNEs).","3F2N+ achieves this capability by utilizing a novel discontinuity discrimination module (DDM), which combines depth curvature minimization and correlation coefficient maximization through conditional random fields (CRFs).","To evaluate the robustness of SNEs on noisy data, we create a large-scale synthetic surface normal (SSN) dataset containing 20 scenarios (ten indoor scenarios and ten outdoor scenarios with and without random Gaussian noise added to depth images).","Extensive experiments demonstrate that 3F2N+ achieves greater performance than all other geometry-based surface normal estimators, with average angular errors of 7.85$^\\circ$, 8.95$^\\circ$, 9.25$^\\circ$, and 11.98$^\\circ$ on the clean-indoor, clean-outdoor, noisy-indoor, and noisy-outdoor datasets, respectively.","We conduct three additional experiments to demonstrate the effectiveness of incorporating our proposed 3F2N+ into downstream robot perception tasks, including freespace detection, 6D object pose estimation, and point cloud completion.","Our source code and datasets are publicly available at https://mias.group/3F2Nplus."],"url":"http://arxiv.org/abs/2312.07964v1"}
{"created":"2023-12-13 08:17:00","title":"Robust Few-Shot Named Entity Recognition with Boundary Discrimination and Correlation Purification","abstract":"Few-shot named entity recognition (NER) aims to recognize novel named entities in low-resource domains utilizing existing knowledge. However, the present few-shot NER models assume that the labeled data are all clean without noise or outliers, and there are few works focusing on the robustness of the cross-domain transfer learning ability to textual adversarial attacks in Few-shot NER. In this work, we comprehensively explore and assess the robustness of few-shot NER models under textual adversarial attack scenario, and found the vulnerability of existing few-shot NER models. Furthermore, we propose a robust two-stage few-shot NER method with Boundary Discrimination and Correlation Purification (BDCP). Specifically, in the span detection stage, the entity boundary discriminative module is introduced to provide a highly distinguishing boundary representation space to detect entity spans. In the entity typing stage, the correlations between entities and contexts are purified by minimizing the interference information and facilitating correlation generalization to alleviate the perturbations caused by textual adversarial attacks. In addition, we construct adversarial examples for few-shot NER based on public datasets Few-NERD and Cross-Dataset. Comprehensive evaluations on those two groups of few-shot NER datasets containing adversarial examples demonstrate the robustness and superiority of the proposed method.","sentences":["Few-shot named entity recognition (NER) aims to recognize novel named entities in low-resource domains utilizing existing knowledge.","However, the present few-shot NER models assume that the labeled data are all clean without noise or outliers, and there are few works focusing on the robustness of the cross-domain transfer learning ability to textual adversarial attacks in Few-shot NER.","In this work, we comprehensively explore and assess the robustness of few-shot NER models under textual adversarial attack scenario, and found the vulnerability of existing few-shot NER models.","Furthermore, we propose a robust two-stage few-shot NER method with Boundary Discrimination and Correlation Purification (BDCP).","Specifically, in the span detection stage, the entity boundary discriminative module is introduced to provide a highly distinguishing boundary representation space to detect entity spans.","In the entity typing stage, the correlations between entities and contexts are purified by minimizing the interference information and facilitating correlation generalization to alleviate the perturbations caused by textual adversarial attacks.","In addition, we construct adversarial examples for few-shot NER based on public datasets Few-NERD and Cross-Dataset.","Comprehensive evaluations on those two groups of few-shot NER datasets containing adversarial examples demonstrate the robustness and superiority of the proposed method."],"url":"http://arxiv.org/abs/2312.07961v1"}
{"created":"2023-12-13 07:57:40","title":"Semantic-aware Data Augmentation for Text-to-image Synthesis","abstract":"Data augmentation has been recently leveraged as an effective regularizer in various vision-language deep neural networks. However, in text-to-image synthesis (T2Isyn), current augmentation wisdom still suffers from the semantic mismatch between augmented paired data. Even worse, semantic collapse may occur when generated images are less semantically constrained. In this paper, we develop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to T2Isyn. In particular, we propose to augment texts in the semantic space via an Implicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with a specifically designed Image Semantic Regularization Loss ($L_r$) as Generated Image Semantic Conservation, to cope well with semantic mismatch and collapse. As one major contribution, we theoretically show that $ITA$ can certify better text-image consistency while $L_r$ regularizing the semantics of generated images would avoid semantic collapse and enhance image quality. Extensive experiments validate that SADA enhances text-image consistency and improves image quality significantly in T2Isyn models across various backbones. Especially, incorporating SADA during the tuning process of Stable Diffusion models also yields performance improvements.","sentences":["Data augmentation has been recently leveraged as an effective regularizer in various vision-language deep neural networks.","However, in text-to-image synthesis (T2Isyn), current augmentation wisdom still suffers from the semantic mismatch between augmented paired data.","Even worse, semantic collapse may occur when generated images are less semantically constrained.","In this paper, we develop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to T2Isyn.","In particular, we propose to augment texts in the semantic space via an Implicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with a specifically designed Image Semantic Regularization Loss ($L_r$) as Generated Image Semantic Conservation, to cope well with semantic mismatch and collapse.","As one major contribution, we theoretically show that $ITA$ can certify better text-image consistency while $L_r$ regularizing the semantics of generated images would avoid semantic collapse and enhance image quality.","Extensive experiments validate that SADA enhances text-image consistency and improves image quality significantly in T2Isyn models across various backbones.","Especially, incorporating SADA during the tuning process of Stable Diffusion models also yields performance improvements."],"url":"http://arxiv.org/abs/2312.07951v1"}
{"created":"2023-12-13 07:53:06","title":"Zero-Knowledge Proof of Traffic: A Deterministic and Privacy-Preserving Cross Verification Mechanism for Cooperative Perception Data","abstract":"Cooperative perception is crucial for connected automated vehicles in intelligent transportation systems (ITSs); however, ensuring the authenticity of perception data remains a challenge as the vehicles cannot verify events that they do not witness independently. Various studies have been conducted on establishing the authenticity of data, such as trust-based statistical methods and plausibility-based methods. However, these methods are limited as they require prior knowledge such as previous sender behaviors or predefined rules to evaluate the authenticity. To overcome this limitation, this study proposes a novel approach called zero-knowledge Proof of Traffic (zk-PoT), which involves generating cryptographic proofs to the traffic observations. Multiple independent proofs regarding the same vehicle can be deterministically cross-verified by any receivers without relying on ground truth, probabilistic, or plausibility evaluations. Additionally, no private information is compromised during the entire procedure. A full on-board unit software stack that reflects the behavior of zk-PoT is implemented within a specifically designed simulator called Flowsim. A comprehensive experimental analysis is then conducted using synthesized city-scale simulations, which demonstrates that zk-PoT's cross-verification ratio ranges between 80 % to 96 %, and 80 % of the verification is achieved in 2 s, with a protocol overhead of approximately 25 %. Furthermore, the analyses of various attacks indicate that most of the attacks could be prevented, and some, such as collusion attacks, can be mitigated. The proposed approach can be incorporated into existing works, including the European Telecommunications Standards Institute (ETSI) and the International Organization for Standardization (ISO) ITS standards, without disrupting the backward compatibility.","sentences":["Cooperative perception is crucial for connected automated vehicles in intelligent transportation systems (ITSs); however, ensuring the authenticity of perception data remains a challenge as the vehicles cannot verify events that they do not witness independently.","Various studies have been conducted on establishing the authenticity of data, such as trust-based statistical methods and plausibility-based methods.","However, these methods are limited as they require prior knowledge such as previous sender behaviors or predefined rules to evaluate the authenticity.","To overcome this limitation, this study proposes a novel approach called zero-knowledge Proof of Traffic (zk-PoT), which involves generating cryptographic proofs to the traffic observations.","Multiple independent proofs regarding the same vehicle can be deterministically cross-verified by any receivers without relying on ground truth, probabilistic, or plausibility evaluations.","Additionally, no private information is compromised during the entire procedure.","A full on-board unit software stack that reflects the behavior of zk-PoT is implemented within a specifically designed simulator called Flowsim.","A comprehensive experimental analysis is then conducted using synthesized city-scale simulations, which demonstrates that zk-PoT's cross-verification ratio ranges between 80 % to 96 %, and 80 % of the verification is achieved in 2 s, with a protocol overhead of approximately 25 %.","Furthermore, the analyses of various attacks indicate that most of the attacks could be prevented, and some, such as collusion attacks, can be mitigated.","The proposed approach can be incorporated into existing works, including the European Telecommunications Standards Institute (ETSI) and the International Organization for Standardization (ISO) ITS standards, without disrupting the backward compatibility."],"url":"http://arxiv.org/abs/2312.07948v1"}
{"created":"2023-12-13 07:51:21","title":"Incremental Computation: What Is the Essence?","abstract":"Incremental computation aims to compute more efficiently on changed input by reusing previously computed results. We give a high-level overview of works on incremental computation, and highlight the essence underlying all of them, which we call incrementalization -- the discrete counterpart of differentiation in calculus. We review the gist of a systematic method for incrementalization, and a systematic method centered around it, called Iterate-Incrementalize-Implement, for program design and optimization, as well as algorithm design and optimization. At a meta-level, with historical contexts and for future directions, we stress the power of high-level data, control, and module abstractions in developing new and better algorithms and programs as well as their precise complexities.","sentences":["Incremental computation aims to compute more efficiently on changed input by reusing previously computed results.","We give a high-level overview of works on incremental computation, and highlight the essence underlying all of them, which we call incrementalization -- the discrete counterpart of differentiation in calculus.","We review the gist of a systematic method for incrementalization, and a systematic method centered around it, called Iterate-Incrementalize-Implement, for program design and optimization, as well as algorithm design and optimization.","At a meta-level, with historical contexts and for future directions, we stress the power of high-level data, control, and module abstractions in developing new and better algorithms and programs as well as their precise complexities."],"url":"http://arxiv.org/abs/2312.07946v1"}
{"created":"2023-12-13 07:38:34","title":"Learning Diffusions under Uncertainty","abstract":"To infer a diffusion network based on observations from historical diffusion processes, existing approaches assume that observation data contain exact occurrence time of each node infection, or at least the eventual infection statuses of nodes in each diffusion process. They determine potential influence relationships between nodes by identifying frequent sequences, or statistical correlations, among node infections. In some real-world settings, such as the spread of epidemics, tracing exact infection times is often infeasible due to a high cost; even obtaining precise infection statuses of nodes is a challenging task, since observable symptoms such as headache only partially reveal a node's true status. In this work, we investigate how to effectively infer a diffusion network from observation data with uncertainty. Provided with only probabilistic information about node infection statuses, we formulate the problem of diffusion network inference as a constrained nonlinear regression w.r.t. the probabilistic data. An alternating maximization method is designed to solve this regression problem iteratively, and the improvement of solution quality in each iteration can be theoretically guaranteed. Empirical studies are conducted on both synthetic and real-world networks, and the results verify the effectiveness and efficiency of our approach.","sentences":["To infer a diffusion network based on observations from historical diffusion processes, existing approaches assume that observation data contain exact occurrence time of each node infection, or at least the eventual infection statuses of nodes in each diffusion process.","They determine potential influence relationships between nodes by identifying frequent sequences, or statistical correlations, among node infections.","In some real-world settings, such as the spread of epidemics, tracing exact infection times is often infeasible due to a high cost; even obtaining precise infection statuses of nodes is a challenging task, since observable symptoms such as headache only partially reveal a node's true status.","In this work, we investigate how to effectively infer a diffusion network from observation data with uncertainty.","Provided with only probabilistic information about node infection statuses, we formulate the problem of diffusion network inference as a constrained nonlinear regression w.r.t.","the probabilistic data.","An alternating maximization method is designed to solve this regression problem iteratively, and the improvement of solution quality in each iteration can be theoretically guaranteed.","Empirical studies are conducted on both synthetic and real-world networks, and the results verify the effectiveness and efficiency of our approach."],"url":"http://arxiv.org/abs/2312.07942v1"}
{"created":"2023-12-13 07:30:19","title":"BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics","abstract":"The recently emerging text-to-motion advances have spired numerous attempts for convenient and interactive human motion generation. Yet, existing methods are largely limited to generating body motions only without considering the rich two-hand motions, let alone handling various conditions like body dynamics or texts. To break the data bottleneck, we propose BOTH57M, a novel multi-modal dataset for two-hand motion generation. Our dataset includes accurate motion tracking for the human body and hands and provides pair-wised finger-level hand annotations and body descriptions. We further provide a strong baseline method, BOTH2Hands, for the novel task: generating vivid two-hand motions from both implicit body dynamics and explicit text prompts. We first warm up two parallel body-to-hand and text-to-hand diffusion models and then utilize the cross-attention transformer for motion blending. Extensive experiments and cross-validations demonstrate the effectiveness of our approach and dataset for generating convincing two-hand motions from the hybrid body-and-textual conditions. Our dataset and code will be disseminated to the community for future research.","sentences":["The recently emerging text-to-motion advances have spired numerous attempts for convenient and interactive human motion generation.","Yet, existing methods are largely limited to generating body motions only without considering the rich two-hand motions, let alone handling various conditions like body dynamics or texts.","To break the data bottleneck, we propose BOTH57M, a novel multi-modal dataset for two-hand motion generation.","Our dataset includes accurate motion tracking for the human body and hands and provides pair-wised finger-level hand annotations and body descriptions.","We further provide a strong baseline method, BOTH2Hands, for the novel task: generating vivid two-hand motions from both implicit body dynamics and explicit text prompts.","We first warm up two parallel body-to-hand and text-to-hand diffusion models and then utilize the cross-attention transformer for motion blending.","Extensive experiments and cross-validations demonstrate the effectiveness of our approach and dataset for generating convincing two-hand motions from the hybrid body-and-textual conditions.","Our dataset and code will be disseminated to the community for future research."],"url":"http://arxiv.org/abs/2312.07937v1"}
{"created":"2023-12-13 07:20:27","title":"Levenshtein Distance Embedding with Poisson Regression for DNA Storage","abstract":"Efficient computation or approximation of Levenshtein distance, a widely-used metric for evaluating sequence similarity, has attracted significant attention with the emergence of DNA storage and other biological applications. Sequence embedding, which maps Levenshtein distance to a conventional distance between embedding vectors, has emerged as a promising solution. In this paper, a novel neural network-based sequence embedding technique using Poisson regression is proposed. We first provide a theoretical analysis of the impact of embedding dimension on model performance and present a criterion for selecting an appropriate embedding dimension. Under this embedding dimension, the Poisson regression is introduced by assuming the Levenshtein distance between sequences of fixed length following a Poisson distribution, which naturally aligns with the definition of Levenshtein distance. Moreover, from the perspective of the distribution of embedding distances, Poisson regression approximates the negative log likelihood of the chi-squared distribution and offers advancements in removing the skewness. Through comprehensive experiments on real DNA storage data, we demonstrate the superior performance of the proposed method compared to state-of-the-art approaches.","sentences":["Efficient computation or approximation of Levenshtein distance, a widely-used metric for evaluating sequence similarity, has attracted significant attention with the emergence of DNA storage and other biological applications.","Sequence embedding, which maps Levenshtein distance to a conventional distance between embedding vectors, has emerged as a promising solution.","In this paper, a novel neural network-based sequence embedding technique using Poisson regression is proposed.","We first provide a theoretical analysis of the impact of embedding dimension on model performance and present a criterion for selecting an appropriate embedding dimension.","Under this embedding dimension, the Poisson regression is introduced by assuming the Levenshtein distance between sequences of fixed length following a Poisson distribution, which naturally aligns with the definition of Levenshtein distance.","Moreover, from the perspective of the distribution of embedding distances, Poisson regression approximates the negative log likelihood of the chi-squared distribution and offers advancements in removing the skewness.","Through comprehensive experiments on real DNA storage data, we demonstrate the superior performance of the proposed method compared to state-of-the-art approaches."],"url":"http://arxiv.org/abs/2312.07931v1"}
{"created":"2023-12-13 06:35:39","title":"BinGo: Identifying Security Patches in Binary Code with Graph Representation Learning","abstract":"A timely software update is vital to combat the increasing security vulnerabilities. However, some software vendors may secretly patch their vulnerabilities without creating CVE entries or even describing the security issue in their change log. Thus, it is critical to identify these hidden security patches and defeat potential N-day attacks. Researchers have employed various machine learning techniques to identify security patches in open-source software, leveraging the syntax and semantic features of the software changes and commit messages. However, all these solutions cannot be directly applied to the binary code, whose instructions and program flow may dramatically vary due to different compilation configurations. In this paper, we propose BinGo, a new security patch detection system for binary code. The main idea is to present the binary code as code property graphs to enable a comprehensive understanding of program flow and perform a language model over each basic block of binary code to catch the instruction semantics. BinGo consists of four phases, namely, patch data pre-processing, graph extraction, embedding generation, and graph representation learning. Due to the lack of an existing binary security patch dataset, we construct such a dataset by compiling the pre-patch and post-patch source code of the Linux kernel. Our experimental results show BinGo can achieve up to 80.77% accuracy in identifying security patches between two neighboring versions of binary code. Moreover, BinGo can effectively reduce the false positives and false negatives caused by the different compilers and optimization levels.","sentences":["A timely software update is vital to combat the increasing security vulnerabilities.","However, some software vendors may secretly patch their vulnerabilities without creating CVE entries or even describing the security issue in their change log.","Thus, it is critical to identify these hidden security patches and defeat potential N-day attacks.","Researchers have employed various machine learning techniques to identify security patches in open-source software, leveraging the syntax and semantic features of the software changes and commit messages.","However, all these solutions cannot be directly applied to the binary code, whose instructions and program flow may dramatically vary due to different compilation configurations.","In this paper, we propose BinGo, a new security patch detection system for binary code.","The main idea is to present the binary code as code property graphs to enable a comprehensive understanding of program flow and perform a language model over each basic block of binary code to catch the instruction semantics.","BinGo consists of four phases, namely, patch data pre-processing, graph extraction, embedding generation, and graph representation learning.","Due to the lack of an existing binary security patch dataset, we construct such a dataset by compiling the pre-patch and post-patch source code of the Linux kernel.","Our experimental results show BinGo can achieve up to 80.77% accuracy in identifying security patches between two neighboring versions of binary code.","Moreover, BinGo can effectively reduce the false positives and false negatives caused by the different compilers and optimization levels."],"url":"http://arxiv.org/abs/2312.07921v1"}
{"created":"2023-12-13 06:22:02","title":"On Designing Multi-UAV aided Wireless Powered Dynamic Communication via Hierarchical Deep Reinforcement Learning","abstract":"This paper proposes a novel design on the wireless powered communication network (WPCN) in dynamic environments under the assistance of multiple unmanned aerial vehicles (UAVs). Unlike the existing studies, where the low-power wireless nodes (WNs) often conform to the coherent harvest-then-transmit protocol, under our newly proposed double-threshold based WN type updating rule, each WN can dynamically and repeatedly update its WN type as an E-node for non-linear energy harvesting over time slots or an I-node for transmitting data over sub-slots. To maximize the total transmission data size of all the WNs over T slots, each of the UAVs individually determines its trajectory and binary wireless energy transmission (WET) decisions over times slots and its binary wireless data collection (WDC) decisions over sub-slots, under the constraints of each UAV's limited on-board energy and each WN's node type updating rule. However, due to the UAVs' tightly-coupled trajectories with their WET and WDC decisions, as well as each WN's time-varying battery energy, this problem is difficult to solve optimally. We then propose a new multi-agent based hierarchical deep reinforcement learning (MAHDRL) framework with two tiers to solve the problem efficiently, where the soft actor critic (SAC) policy is designed in tier-1 to determine each UAV's continuous trajectory and binary WET decision over time slots, and the deep-Q learning (DQN) policy is designed in tier-2 to determine each UAV's binary WDC decisions over sub-slots under the given UAV trajectory from tier-1. Both of the SAC policy and the DQN policy are executed distributively at each UAV. Finally, extensive simulation results are provided to validate the outweighed performance of the proposed MAHDRL approach over various state-of-the-art benchmarks.","sentences":["This paper proposes a novel design on the wireless powered communication network (WPCN) in dynamic environments under the assistance of multiple unmanned aerial vehicles (UAVs).","Unlike the existing studies, where the low-power wireless nodes (WNs) often conform to the coherent harvest-then-transmit protocol, under our newly proposed double-threshold based WN type updating rule, each WN can dynamically and repeatedly update its WN type as an E-node for non-linear energy harvesting over time slots or an I-node for transmitting data over sub-slots.","To maximize the total transmission data size of all the WNs over T slots, each of the UAVs individually determines its trajectory and binary wireless energy transmission (WET) decisions over times slots and its binary wireless data collection (WDC) decisions over sub-slots, under the constraints of each UAV's limited on-board energy and each WN's node type updating rule.","However, due to the UAVs' tightly-coupled trajectories with their WET and WDC decisions, as well as each WN's time-varying battery energy, this problem is difficult to solve optimally.","We then propose a new multi-agent based hierarchical deep reinforcement learning (MAHDRL) framework with two tiers to solve the problem efficiently, where the soft actor critic (SAC) policy is designed in tier-1 to determine each UAV's continuous trajectory and binary WET decision over time slots, and the deep-Q learning (DQN) policy is designed in tier-2 to determine each UAV's binary WDC decisions over sub-slots under the given UAV trajectory from tier-1.","Both of the SAC policy and the DQN policy are executed distributively at each UAV.","Finally, extensive simulation results are provided to validate the outweighed performance of the proposed MAHDRL approach over various state-of-the-art benchmarks."],"url":"http://arxiv.org/abs/2312.07917v1"}
{"created":"2023-12-13 06:11:42","title":"A Survey of Text Watermarking in the Era of Large Language Models","abstract":"In recent years, significant advancements have been made in the text generation capabilities of Large Language Models (LLMs), demonstrating exceptional performance in downstream tasks such as abstract summarization, dialogue generation, and data-to-text conversion. However, their generative abilities also pose risks such as the rapid spread of fake news, infringement of datasets/LLM copyrights, and challenges to academic integrity. Text watermarking technology emerges as a potential solution. By embedding invisible yet detectable patterns in generated texts, it helps in tracking and verifying text origins, thus preventing misuse and piracy.   This survey aims to comprehensively summarize current text watermarking technologies, covering three main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their success rate, impact on text quality, robustness, and unforgeability; (3) potential applications of text watermarking technologys. This survey aims to help researchers thoroughly understanding the text watermarking technologies, thereby fostering further development.","sentences":["In recent years, significant advancements have been made in the text generation capabilities of Large Language Models (LLMs), demonstrating exceptional performance in downstream tasks such as abstract summarization, dialogue generation, and data-to-text conversion.","However, their generative abilities also pose risks such as the rapid spread of fake news, infringement of datasets/LLM copyrights, and challenges to academic integrity.","Text watermarking technology emerges as a potential solution.","By embedding invisible yet detectable patterns in generated texts, it helps in tracking and verifying text origins, thus preventing misuse and piracy.   ","This survey aims to comprehensively summarize current text watermarking technologies, covering three main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their success rate, impact on text quality, robustness, and unforgeability; (3) potential applications of text watermarking technologys.","This survey aims to help researchers thoroughly understanding the text watermarking technologies, thereby fostering further development."],"url":"http://arxiv.org/abs/2312.07913v1"}
{"created":"2023-12-13 05:15:57","title":"Artificial Intelligence Studies in Cartography: A Review and Synthesis of Methods, Applications, and Ethics","abstract":"The past decade has witnessed the rapid development of geospatial artificial intelligence (GeoAI) primarily due to the ground-breaking achievements in deep learning and machine learning. A growing number of scholars from cartography have demonstrated successfully that GeoAI can accelerate previously complex cartographic design tasks and even enable cartographic creativity in new ways. Despite the promise of GeoAI, researchers and practitioners have growing concerns about the ethical issues of GeoAI for cartography. In this paper, we conducted a systematic content analysis and narrative synthesis of research studies integrating GeoAI and cartography to summarize current research and development trends regarding the usage of GeoAI for cartographic design. Based on this review and synthesis, we first identify dimensions of GeoAI methods for cartography such as data sources, data formats, map evaluations, and six contemporary GeoAI models, each of which serves a variety of cartographic tasks. These models include decision trees, knowledge graph and semantic web technologies, deep convolutional neural networks, generative adversarial networks, graph neural networks, and reinforcement learning. Further, we summarize seven cartographic design applications where GeoAI have been effectively employed: generalization, symbolization, typography, map reading, map interpretation, map analysis, and map production. We also raise five potential ethical challenges that need to be addressed in the integration of GeoAI for cartography: commodification, responsibility, privacy, bias, and (together) transparency, explainability, and provenance. We conclude by identifying four potential research directions for future cartographic research with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI for cartography.","sentences":["The past decade has witnessed the rapid development of geospatial artificial intelligence (GeoAI) primarily due to the ground-breaking achievements in deep learning and machine learning.","A growing number of scholars from cartography have demonstrated successfully that GeoAI can accelerate previously complex cartographic design tasks and even enable cartographic creativity in new ways.","Despite the promise of GeoAI, researchers and practitioners have growing concerns about the ethical issues of GeoAI for cartography.","In this paper, we conducted a systematic content analysis and narrative synthesis of research studies integrating GeoAI and cartography to summarize current research and development trends regarding the usage of GeoAI for cartographic design.","Based on this review and synthesis, we first identify dimensions of GeoAI methods for cartography such as data sources, data formats, map evaluations, and six contemporary GeoAI models, each of which serves a variety of cartographic tasks.","These models include decision trees, knowledge graph and semantic web technologies, deep convolutional neural networks, generative adversarial networks, graph neural networks, and reinforcement learning.","Further, we summarize seven cartographic design applications where GeoAI have been effectively employed: generalization, symbolization, typography, map reading, map interpretation, map analysis, and map production.","We also raise five potential ethical challenges that need to be addressed in the integration of GeoAI for cartography: commodification, responsibility, privacy, bias, and (together) transparency, explainability, and provenance.","We conclude by identifying four potential research directions for future cartographic research with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI for cartography."],"url":"http://arxiv.org/abs/2312.07901v1"}
{"created":"2023-12-13 05:08:17","title":"Ensuring End-to-End Security with Fine-grained Access Control for Connected and Autonomous Vehicles","abstract":"As advanced V2X applications emerge in the connected and autonomous vehicle (CAV), the data communications between in-vehicle end-devices and outside nodes increase, which make the end-to-end (E2E) security to in-vehicle end-devices as the urgent issue to be handled. However, the E2E security with fine-grained access control still remains as a challenging issue for resource-constrained end-devices since the existing security solutions require complicated key management and high resource consumption. Therefore, we propose a practical and secure vehicular communication protocol for the E2E security based on a new attribute-based encryption (ABE) scheme. In our scheme, the outsourced computation is provided for encryption, and the computation cost for decryption constantly remains small, regardless of the number of attributes. The policy privacy can be ensured by the proposed ABE to support privacy-sensitive V2X applications, and the existing identity-based signature for outsourced signing is newly reconstructed. Our scheme achieves the confidentiality, message authentication, identity anonymity, unlinkability, traceability, and reconfigurable outsourced computation, and we also show the practical feasibility of our protocol via the performance evaluation.","sentences":["As advanced V2X applications emerge in the connected and autonomous vehicle (CAV), the data communications between in-vehicle end-devices and outside nodes increase, which make the end-to-end (E2E) security to in-vehicle end-devices as the urgent issue to be handled.","However, the E2E security with fine-grained access control still remains as a challenging issue for resource-constrained end-devices since the existing security solutions require complicated key management and high resource consumption.","Therefore, we propose a practical and secure vehicular communication protocol for the E2E security based on a new attribute-based encryption (ABE) scheme.","In our scheme, the outsourced computation is provided for encryption, and the computation cost for decryption constantly remains small, regardless of the number of attributes.","The policy privacy can be ensured by the proposed ABE to support privacy-sensitive V2X applications, and the existing identity-based signature for outsourced signing is newly reconstructed.","Our scheme achieves the confidentiality, message authentication, identity anonymity, unlinkability, traceability, and reconfigurable outsourced computation, and we also show the practical feasibility of our protocol via the performance evaluation."],"url":"http://arxiv.org/abs/2312.07898v2"}
