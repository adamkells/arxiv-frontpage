{"created":"2024-09-10 17:59:55","title":"GeoCalib: Learning Single-image Calibration with Geometric Optimization","abstract":"From a single image, visual cues can help deduce intrinsic and extrinsic camera parameters like the focal length and the gravity direction. This single-image calibration can benefit various downstream applications like image editing and 3D mapping. Current approaches to this problem are based on either classical geometry with lines and vanishing points or on deep neural networks trained end-to-end. The learned approaches are more robust but struggle to generalize to new environments and are less accurate than their classical counterparts. We hypothesize that they lack the constraints that 3D geometry provides. In this work, we introduce GeoCalib, a deep neural network that leverages universal rules of 3D geometry through an optimization process. GeoCalib is trained end-to-end to estimate camera parameters and learns to find useful visual cues from the data. Experiments on various benchmarks show that GeoCalib is more robust and more accurate than existing classical and learned approaches. Its internal optimization estimates uncertainties, which help flag failure cases and benefit downstream applications like visual localization. The code and trained models are publicly available at https://github.com/cvg/GeoCalib.","sentences":["From a single image, visual cues can help deduce intrinsic and extrinsic camera parameters like the focal length and the gravity direction.","This single-image calibration can benefit various downstream applications like image editing and 3D mapping.","Current approaches to this problem are based on either classical geometry with lines and vanishing points or on deep neural networks trained end-to-end.","The learned approaches are more robust but struggle to generalize to new environments and are less accurate than their classical counterparts.","We hypothesize that they lack the constraints that 3D geometry provides.","In this work, we introduce GeoCalib, a deep neural network that leverages universal rules of 3D geometry through an optimization process.","GeoCalib is trained end-to-end to estimate camera parameters and learns to find useful visual cues from the data.","Experiments on various benchmarks show that GeoCalib is more robust and more accurate than existing classical and learned approaches.","Its internal optimization estimates uncertainties, which help flag failure cases and benefit downstream applications like visual localization.","The code and trained models are publicly available at https://github.com/cvg/GeoCalib."],"url":"http://arxiv.org/abs/2409.06704v1"}
{"created":"2024-09-10 17:54:28","title":"Geometric-Averaged Preference Optimization for Soft Preference Labels","abstract":"Many algorithms for aligning LLMs with human preferences assume that human preferences are binary and deterministic. However, it is reasonable to think that they can vary with different individuals, and thus should be distributional to reflect the fine-grained relationship between the responses. In this work, we introduce the distributional soft preference labels and improve Direct Preference Optimization (DPO) with a weighted geometric average of the LLM output likelihood in the loss function. In doing so, the scale of learning loss is adjusted based on the soft labels, and the loss with equally preferred responses would be close to zero. This simple modification can be easily applied to any DPO family and helps the models escape from the over-optimization and objective mismatch prior works suffer from. In our experiments, we simulate the soft preference labels with AI feedback from LLMs and demonstrate that geometric averaging consistently improves performance on standard benchmarks for alignment research. In particular, we observe more preferable responses than binary labels and significant improvements with data where modestly-confident labels are in the majority.","sentences":["Many algorithms for aligning LLMs with human preferences assume that human preferences are binary and deterministic.","However, it is reasonable to think that they can vary with different individuals, and thus should be distributional to reflect the fine-grained relationship between the responses.","In this work, we introduce the distributional soft preference labels and improve Direct Preference Optimization (DPO) with a weighted geometric average of the LLM output likelihood in the loss function.","In doing so, the scale of learning loss is adjusted based on the soft labels, and the loss with equally preferred responses would be close to zero.","This simple modification can be easily applied to any DPO family and helps the models escape from the over-optimization and objective mismatch prior works suffer from.","In our experiments, we simulate the soft preference labels with AI feedback from LLMs and demonstrate that geometric averaging consistently improves performance on standard benchmarks for alignment research.","In particular, we observe more preferable responses than binary labels and significant improvements with data where modestly-confident labels are in the majority."],"url":"http://arxiv.org/abs/2409.06691v1"}
