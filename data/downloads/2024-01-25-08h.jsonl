{"created":"2024-01-24 18:58:35","title":"Predicting the Impact of Crashes Across Release Channels","abstract":"Software maintenance faces a persistent challenge with crash bugs, especially across diverse release channels catering to distinct user bases. Nightly builds, favoured by enthusiasts, often reveal crashes that are cheaper to fix but may differ significantly from those in stable releases. In this paper, we emphasize the need for a data-driven solution to predict the impact of crashes happening on nightly channels once they are released to stable channels. We also list the challenges that need to be considered when approaching this problem.","sentences":["Software maintenance faces a persistent challenge with crash bugs, especially across diverse release channels catering to distinct user bases.","Nightly builds, favoured by enthusiasts, often reveal crashes that are cheaper to fix but may differ significantly from those in stable releases.","In this paper, we emphasize the need for a data-driven solution to predict the impact of crashes happening on nightly channels once they are released to stable channels.","We also list the challenges that need to be considered when approaching this problem."],"url":"http://arxiv.org/abs/2401.13667v1"}
{"created":"2024-01-24 18:49:30","title":"Inadequacy of common stochastic neural networks for reliable clinical decision support","abstract":"Widespread adoption of AI for medical decision making is still hindered due to ethical and safety-related concerns. For AI-based decision support systems in healthcare settings it is paramount to be reliable and trustworthy. Common deep learning approaches, however, have the tendency towards overconfidence under data shift. Such inappropriate extrapolation beyond evidence-based scenarios may have dire consequences. This highlights the importance of reliable estimation of local uncertainty and its communication to the end user. While stochastic neural networks have been heralded as a potential solution to these issues, this study investigates their actual reliability in clinical applications. We centered our analysis on the exemplary use case of mortality prediction for ICU hospitalizations using EHR from MIMIC3 study. For predictions on the EHR time series, Encoder-Only Transformer models were employed. Stochasticity of model functions was achieved by incorporating common methods such as Bayesian neural network layers and model ensembles. Our models achieve state of the art performance in terms of discrimination performance (AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality prediction benchmark. However, epistemic uncertainty is critically underestimated by the selected stochastic deep learning methods. A heuristic proof for the responsible collapse of the posterior distribution is provided. Our findings reveal the inadequacy of commonly used stochastic deep learning approaches to reliably recognize OoD samples. In both methods, unsubstantiated model confidence is not prevented due to strongly biased functional posteriors, rendering them inappropriate for reliable clinical decision support. This highlights the need for approaches with more strictly enforced or inherent distance-awareness to known data points, e.g., using kernel-based techniques.","sentences":["Widespread adoption of AI for medical decision making is still hindered due to ethical and safety-related concerns.","For AI-based decision support systems in healthcare settings it is paramount to be reliable and trustworthy.","Common deep learning approaches, however, have the tendency towards overconfidence under data shift.","Such inappropriate extrapolation beyond evidence-based scenarios may have dire consequences.","This highlights the importance of reliable estimation of local uncertainty and its communication to the end user.","While stochastic neural networks have been heralded as a potential solution to these issues, this study investigates their actual reliability in clinical applications.","We centered our analysis on the exemplary use case of mortality prediction for ICU hospitalizations using EHR from MIMIC3 study.","For predictions on the EHR time series, Encoder-Only Transformer models were employed.","Stochasticity of model functions was achieved by incorporating common methods such as Bayesian neural network layers and model ensembles.","Our models achieve state of the art performance in terms of discrimination performance (AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality prediction benchmark.","However, epistemic uncertainty is critically underestimated by the selected stochastic deep learning methods.","A heuristic proof for the responsible collapse of the posterior distribution is provided.","Our findings reveal the inadequacy of commonly used stochastic deep learning approaches to reliably recognize OoD samples.","In both methods, unsubstantiated model confidence is not prevented due to strongly biased functional posteriors, rendering them inappropriate for reliable clinical decision support.","This highlights the need for approaches with more strictly enforced or inherent distance-awareness to known data points, e.g., using kernel-based techniques."],"url":"http://arxiv.org/abs/2401.13657v1"}
{"created":"2024-01-24 18:35:21","title":"VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks","abstract":"Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve. Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively. To bridge this gap, we introduce VisualWebArena, a benchmark designed to assess the performance of multimodal web agents on realistic \\textit{visually grounded tasks}. VisualWebArena comprises of a set of diverse and complex web-based tasks that evaluate various capabilities of autonomous multimodal agents. To perform on this benchmark, agents need to accurately process image-text inputs, interpret natural language instructions, and execute actions on websites to accomplish user-defined objectives. We conduct an extensive evaluation of state-of-the-art LLM-based autonomous agents, including several multimodal models. Through extensive quantitative and qualitative analysis, we identify several limitations of text-only LLM agents, and reveal gaps in the capabilities of state-of-the-art multimodal language agents. VisualWebArena provides a framework for evaluating multimodal autonomous language agents, and offers insights towards building stronger autonomous agents for the web. Our code, baseline models, and data is publicly available at https://jykoh.com/vwa.","sentences":["Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks.","However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve.","Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively.","To bridge this gap, we introduce VisualWebArena, a benchmark designed to assess the performance of multimodal web agents on realistic \\textit{visually grounded tasks}.","VisualWebArena comprises of a set of diverse and complex web-based tasks that evaluate various capabilities of autonomous multimodal agents.","To perform on this benchmark, agents need to accurately process image-text inputs, interpret natural language instructions, and execute actions on websites to accomplish user-defined objectives.","We conduct an extensive evaluation of state-of-the-art LLM-based autonomous agents, including several multimodal models.","Through extensive quantitative and qualitative analysis, we identify several limitations of text-only LLM agents, and reveal gaps in the capabilities of state-of-the-art multimodal language agents.","VisualWebArena provides a framework for evaluating multimodal autonomous language agents, and offers insights towards building stronger autonomous agents for the web.","Our code, baseline models, and data is publicly available at https://jykoh.com/vwa."],"url":"http://arxiv.org/abs/2401.13649v1"}
{"created":"2024-01-24 18:28:52","title":"Employing polyhedral methods to optimize stencils on FPGAs with stencil-specific caches, data reuse, and wide data bursts","abstract":"It is well known that to accelerate stencil codes on CPUs or GPUs and to exploit hardware caches and their lines optimizers must find spatial and temporal locality of array accesses to harvest data-reuse opportunities. On FPGAs there is the burden that there are no built-in caches (or only pre-built hardware descriptions for cache blocks that are inefficient for stencil codes). But this paper demonstrates that this lack is also a chance as polyhedral methods can be used to generate stencil-specific cache-structures of the right sizes on the FPGA and to fill and flush them efficiently with wide bursts during stencil execution. The paper shows how to derive the appropriate directives and code restructurings from stencil codes so that the FPGA compiler generates fast stencil hardware. Switching on our optimization improves the runtime of a set of 10 stencils by between 43x and 156x.","sentences":["It is well known that to accelerate stencil codes on CPUs or GPUs and to exploit hardware caches and their lines optimizers must find spatial and temporal locality of array accesses to harvest data-reuse opportunities.","On FPGAs there is the burden that there are no built-in caches (or only pre-built hardware descriptions for cache blocks that are inefficient for stencil codes).","But this paper demonstrates that this lack is also a chance as polyhedral methods can be used to generate stencil-specific cache-structures of the right sizes on the FPGA and to fill and flush them efficiently with wide bursts during stencil execution.","The paper shows how to derive the appropriate directives and code restructurings from stencil codes so that the FPGA compiler generates fast stencil hardware.","Switching on our optimization improves the runtime of a set of 10 stencils by between 43x and 156x."],"url":"http://arxiv.org/abs/2401.13645v1"}
{"created":"2024-01-24 17:59:00","title":"Enabling Seamless Data Security, Consensus, and Trading in Vehicular Networks","abstract":"Cooperative driving is an emerging paradigm to enhance the safety and efficiency of autonomous vehicles. To ensure successful cooperation, road users must reach a consensus for making collective decisions, while recording vehicular data to analyze and address failures related to such agreements. This data has the potential to provide valuable insights into various vehicular events, while also potentially improving accountability measures. Furthermore, vehicles may benefit from the ability to negotiate and trade services among themselves, adding value to the cooperative driving framework. However, the majority of proposed systems aiming to ensure data security, consensus, or service trading, lack efficient and thoroughly validated mechanisms that consider the distinctive characteristics of vehicular networks. These limitations are amplified by a dependency on the centralized support provided by the infrastructure. Furthermore, corresponding mechanisms must diligently address security concerns, especially regarding potential malicious or misbehaving nodes, while also considering inherent constraints of the wireless medium. We introduce the Verifiable Event Extension (VEE), an applicational extension designed for Intelligent Transportation System (ITS) messages. The VEE operates seamlessly with any existing standardized vehicular communications protocol, addressing crucial aspects of data security, consensus, and trading with minimal overhead. To achieve this, we employ blockchain techniques, Byzantine fault tolerance (BFT) consensus protocols, and cryptocurrency-based mechanics. To assess our proposal's feasibility and lightweight nature, we employed a hardware-in-the-loop setup for analysis. Experimental results demonstrate the viability and efficiency of the VEE extension in overcoming the challenges posed by the distributed and opportunistic nature of wireless vehicular communications.","sentences":["Cooperative driving is an emerging paradigm to enhance the safety and efficiency of autonomous vehicles.","To ensure successful cooperation, road users must reach a consensus for making collective decisions, while recording vehicular data to analyze and address failures related to such agreements.","This data has the potential to provide valuable insights into various vehicular events, while also potentially improving accountability measures.","Furthermore, vehicles may benefit from the ability to negotiate and trade services among themselves, adding value to the cooperative driving framework.","However, the majority of proposed systems aiming to ensure data security, consensus, or service trading, lack efficient and thoroughly validated mechanisms that consider the distinctive characteristics of vehicular networks.","These limitations are amplified by a dependency on the centralized support provided by the infrastructure.","Furthermore, corresponding mechanisms must diligently address security concerns, especially regarding potential malicious or misbehaving nodes, while also considering inherent constraints of the wireless medium.","We introduce the Verifiable Event Extension (VEE), an applicational extension designed for Intelligent Transportation System (ITS) messages.","The VEE operates seamlessly with any existing standardized vehicular communications protocol, addressing crucial aspects of data security, consensus, and trading with minimal overhead.","To achieve this, we employ blockchain techniques, Byzantine fault tolerance (BFT) consensus protocols, and cryptocurrency-based mechanics.","To assess our proposal's feasibility and lightweight nature, we employed a hardware-in-the-loop setup for analysis.","Experimental results demonstrate the viability and efficiency of the VEE extension in overcoming the challenges posed by the distributed and opportunistic nature of wireless vehicular communications."],"url":"http://arxiv.org/abs/2401.13630v1"}
{"created":"2024-01-24 17:52:24","title":"What Makes a Great Software Quality Assurance Engineer?","abstract":"Software Quality Assurance (SQA) Engineers are responsible for assessing a product during every phase of the software development process to ensure that the outcomes of each phase and the final product possess the desired qualities. In general, a great SQA engineer needs to have a different set of abilities from development engineers to effectively oversee the entire product development process from beginning to end. Recent empirical studies identified important attributes of software engineers and managers, but the quality assurance role is overlooked. As software quality aspects have become more of a priority in the life cycle of software development, employers seek professionals that best suit the company's objectives and new graduates desire to make a valuable contribution through their job as an SQA engineer, but what makes them great? We addressed this knowledge gap by conducting 25 semi-structured interviews and 363 survey respondents with software quality assurance engineers from different companies around the world. We use the data collected from these activities to derive a comprehensive set of attributes that are considered important. As a result of the interviews, twenty-five attributes were identified and grouped into five main categories: personal, social, technical, management, and decision-making attributes. Through a rating survey, we confirmed that the distinguishing characteristics of great SQA engineers are curiosity, the ability to communicate effectively, and critical thinking skills. This work will guide further studies with SQA practitioners, by considering contextual factors and providing some implications for research and practice.","sentences":["Software Quality Assurance (SQA) Engineers are responsible for assessing a product during every phase of the software development process to ensure that the outcomes of each phase and the final product possess the desired qualities.","In general, a great SQA engineer needs to have a different set of abilities from development engineers to effectively oversee the entire product development process from beginning to end.","Recent empirical studies identified important attributes of software engineers and managers, but the quality assurance role is overlooked.","As software quality aspects have become more of a priority in the life cycle of software development, employers seek professionals that best suit the company's objectives and new graduates desire to make a valuable contribution through their job as an SQA engineer, but what makes them great?","We addressed this knowledge gap by conducting 25 semi-structured interviews and 363 survey respondents with software quality assurance engineers from different companies around the world.","We use the data collected from these activities to derive a comprehensive set of attributes that are considered important.","As a result of the interviews, twenty-five attributes were identified and grouped into five main categories: personal, social, technical, management, and decision-making attributes.","Through a rating survey, we confirmed that the distinguishing characteristics of great SQA engineers are curiosity, the ability to communicate effectively, and critical thinking skills.","This work will guide further studies with SQA practitioners, by considering contextual factors and providing some implications for research and practice."],"url":"http://arxiv.org/abs/2401.13623v1"}
{"created":"2024-01-24 17:48:45","title":"DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning","abstract":"Contrastive-learning-based methods have dominated sentence representation learning. These methods regularize the representation space by pulling similar sentence representations closer and pushing away the dissimilar ones and have been proven effective in various NLP tasks, e.g., semantic textual similarity (STS) tasks. However, it is challenging for these methods to learn fine-grained semantics as they only learn from the inter-sentence perspective, i.e., their supervision signal comes from the relationship between data samples. In this work, we propose a novel denoising objective that inherits from another perspective, i.e., the intra-sentence perspective. By introducing both discrete and continuous noise, we generate noisy sentences and then train our model to restore them to their original form. Our empirical evaluations demonstrate that this approach delivers competitive results on both semantic textual similarity (STS) and a wide range of transfer tasks, standing up well in comparison to contrastive-learning-based methods. Notably, the proposed intra-sentence denoising objective complements existing inter-sentence contrastive methodologies and can be integrated with them to further enhance performance. Our code is available at https://github.com/xinghaow99/DenoSent.","sentences":["Contrastive-learning-based methods have dominated sentence representation learning.","These methods regularize the representation space by pulling similar sentence representations closer and pushing away the dissimilar ones and have been proven effective in various NLP tasks, e.g., semantic textual similarity (STS) tasks.","However, it is challenging for these methods to learn fine-grained semantics as they only learn from the inter-sentence perspective, i.e., their supervision signal comes from the relationship between data samples.","In this work, we propose a novel denoising objective that inherits from another perspective, i.e., the intra-sentence perspective.","By introducing both discrete and continuous noise, we generate noisy sentences and then train our model to restore them to their original form.","Our empirical evaluations demonstrate that this approach delivers competitive results on both semantic textual similarity (STS) and a wide range of transfer tasks, standing up well in comparison to contrastive-learning-based methods.","Notably, the proposed intra-sentence denoising objective complements existing inter-sentence contrastive methodologies and can be integrated with them to further enhance performance.","Our code is available at https://github.com/xinghaow99/DenoSent."],"url":"http://arxiv.org/abs/2401.13621v1"}
{"created":"2024-01-24 17:35:11","title":"Intermittent Connectivity Maintenance With Heterogeneous Robots","abstract":"We consider a scenario of cooperative task servicing, with a team of heterogeneous robots with different maximum speeds and communication radii, in charge of keeping the network intermittently connected. We abstract the task locations into a $1D$ cycle graph that is traversed by the communicating robots, and we discuss intermittent communication strategies so that each task location is periodically visited, with a worst--case revisiting time. Robots move forward and backward along the cycle graph, exchanging data with their previous and next neighbors when they meet, and updating their region boundaries. Asymptotically, each robot is in charge of a region of the cycle graph, depending on its capabilities. The method is distributed, and robots only exchange data when they meet.","sentences":["We consider a scenario of cooperative task servicing, with a team of heterogeneous robots with different maximum speeds and communication radii, in charge of keeping the network intermittently connected.","We abstract the task locations into a $1D$ cycle graph that is traversed by the communicating robots, and we discuss intermittent communication strategies so that each task location is periodically visited, with a worst--case revisiting time.","Robots move forward and backward along the cycle graph, exchanging data with their previous and next neighbors when they meet, and updating their region boundaries.","Asymptotically, each robot is in charge of a region of the cycle graph, depending on its capabilities.","The method is distributed, and robots only exchange data when they meet."],"url":"http://arxiv.org/abs/2401.13612v1"}
{"created":"2024-01-24 17:31:07","title":"Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users using Intermediate ASR Features and Human Memory Models","abstract":"Neural networks have been successfully used for non-intrusive speech intelligibility prediction. Recently, the use of feature representations sourced from intermediate layers of pre-trained self-supervised and weakly-supervised models has been found to be particularly useful for this task. This work combines the use of Whisper ASR decoder layer representations as neural network input features with an exemplar-based, psychologically motivated model of human memory to predict human intelligibility ratings for hearing-aid users. Substantial performance improvement over an established intrusive HASPI baseline system is found, including on enhancement systems and listeners unseen in the training data, with a root mean squared error of 25.3 compared with the baseline of 28.7.","sentences":["Neural networks have been successfully used for non-intrusive speech intelligibility prediction.","Recently, the use of feature representations sourced from intermediate layers of pre-trained self-supervised and weakly-supervised models has been found to be particularly useful for this task.","This work combines the use of Whisper ASR decoder layer representations as neural network input features with an exemplar-based, psychologically motivated model of human memory to predict human intelligibility ratings for hearing-aid users.","Substantial performance improvement over an established intrusive HASPI baseline system is found, including on enhancement systems and listeners unseen in the training data, with a root mean squared error of 25.3 compared with the baseline of 28.7."],"url":"http://arxiv.org/abs/2401.13611v1"}
{"created":"2024-01-24 17:27:08","title":"Building Contextual Knowledge Graphs for Personalized Learning Recommendations using Text Mining and Semantic Graph Completion","abstract":"Modelling learning objects (LO) within their context enables the learner to advance from a basic, remembering-level, learning objective to a higher-order one, i.e., a level with an application- and analysis objective. While hierarchical data models are commonly used in digital learning platforms, using graph-based models enables representing the context of LOs in those platforms. This leads to a foundation for personalized recommendations of learning paths. In this paper, the transformation of hierarchical data models into knowledge graph (KG) models of LOs using text mining is introduced and evaluated. We utilize custom text mining pipelines to mine semantic relations between elements of an expert-curated hierarchical model. We evaluate the KG structure and relation extraction using graph quality-control metrics and the comparison of algorithmic semantic-similarities to expert-defined ones. The results show that the relations in the KG are semantically comparable to those defined by domain experts, and that the proposed KG improves representing and linking the contexts of LOs through increasing graph communities and betweenness centrality.","sentences":["Modelling learning objects (LO) within their context enables the learner to advance from a basic, remembering-level, learning objective to a higher-order one, i.e., a level with an application- and analysis objective.","While hierarchical data models are commonly used in digital learning platforms, using graph-based models enables representing the context of LOs in those platforms.","This leads to a foundation for personalized recommendations of learning paths.","In this paper, the transformation of hierarchical data models into knowledge graph (KG) models of LOs using text mining is introduced and evaluated.","We utilize custom text mining pipelines to mine semantic relations between elements of an expert-curated hierarchical model.","We evaluate the KG structure and relation extraction using graph quality-control metrics and the comparison of algorithmic semantic-similarities to expert-defined ones.","The results show that the relations in the KG are semantically comparable to those defined by domain experts, and that the proposed KG improves representing and linking the contexts of LOs through increasing graph communities and betweenness centrality."],"url":"http://arxiv.org/abs/2401.13609v1"}
{"created":"2024-01-24 17:14:50","title":"Stream-based perception for cognitive agents in mobile ecosystems","abstract":"Cognitive agent abstractions can help to engineer intelligent systems across mobile devices. On smartphones, the data obtained from onboard sensors can give valuable insights into the user's current situation. Unfortunately, today's cognitive agent frameworks cannot cope well with the challenging characteristics of sensor data. Sensor data is located on a low abstraction level and the individual data elements are not meaningful when observed in isolation. In contrast, cognitive agents operate on high-level percepts and lack the means to effectively detect complex spatio-temporal patterns in sequences of multiple percepts. In this paper, we present a stream-based perception approach that enables the agents to perceive meaningful situations in low-level sensor data streams. We present a crowdshipping case study where autonomous, self-interested agents collaborate to deliver parcels to their destinations. We show how situations derived from smartphone sensor data can trigger and guide auctions, which the agents use to reach agreements. Experiments with real smartphone data demonstrate the benefits of stream-based agent perception.","sentences":["Cognitive agent abstractions can help to engineer intelligent systems across mobile devices.","On smartphones, the data obtained from onboard sensors can give valuable insights into the user's current situation.","Unfortunately, today's cognitive agent frameworks cannot cope well with the challenging characteristics of sensor data.","Sensor data is located on a low abstraction level and the individual data elements are not meaningful when observed in isolation.","In contrast, cognitive agents operate on high-level percepts and lack the means to effectively detect complex spatio-temporal patterns in sequences of multiple percepts.","In this paper, we present a stream-based perception approach that enables the agents to perceive meaningful situations in low-level sensor data streams.","We present a crowdshipping case study where autonomous, self-interested agents collaborate to deliver parcels to their destinations.","We show how situations derived from smartphone sensor data can trigger and guide auctions, which the agents use to reach agreements.","Experiments with real smartphone data demonstrate the benefits of stream-based agent perception."],"url":"http://arxiv.org/abs/2401.13604v1"}
{"created":"2024-01-24 17:04:28","title":"Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction","abstract":"Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document. Existing methods heavily rely on a substantial amount of fully labeled data. However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive. Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations. In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which generates labeled data by retrieval and denoising knowledge from LLMs, called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step. To improve the quality of synthetic data, we propose a denoising strategy based on the consistency of cross-document knowledge. Leveraging our denoised synthetic data, we proceed to fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets. We perform experiments for both zero-shot document-level relation and triplet extraction on two public datasets. The experimental results illustrate that our GenRDK framework outperforms strong baselines.","sentences":["Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document.","Existing methods heavily rely on a substantial amount of fully labeled data.","However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive.","Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations.","In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which generates labeled data by retrieval and denoising knowledge from LLMs, called GenRDK.","Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step.","To improve the quality of synthetic data, we propose a denoising strategy based on the consistency of cross-document knowledge.","Leveraging our denoised synthetic data, we proceed to fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets.","We perform experiments for both zero-shot document-level relation and triplet extraction on two public datasets.","The experimental results illustrate that our GenRDK framework outperforms strong baselines."],"url":"http://arxiv.org/abs/2401.13598v1"}
{"created":"2024-01-24 17:01:42","title":"Graph Guided Question Answer Generation for Procedural Question-Answering","abstract":"In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller. 2) semantic coverage is the key indicator for downstream QA performance. Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model. In contrast, the higher semantic coverage provided by our method is critical for QA performance.","sentences":["In this paper, we focus on task-specific question answering (QA).","To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants.","The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data.","While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model.","In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs.","We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner.","Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller.","2) semantic coverage is the key indicator for downstream QA performance.","Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model.","In contrast, the higher semantic coverage provided by our method is critical for QA performance."],"url":"http://arxiv.org/abs/2401.13594v1"}
{"created":"2024-01-24 16:52:37","title":"Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes","abstract":"The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance. However, their performance in actual clinical applications has been underexplored. Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts. This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings. Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes. Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an in-depth analysis. Results: GPT-4 showed overall superior performance compared to other LLMs. In contrast, both GPT-3.5 and text-davinci-003 exhibit enhanced performance when the appropriate prompting strategies are employed. The GPT family models have demonstrated considerable efficiency, evidenced by their cost-effectiveness and time-saving capabilities. Conclusion: A comprehensive qualitative performance evaluation framework for LLMs is developed and operationalized. This framework goes beyond singular performance aspects. With expert annotations, this methodology not only validates LLMs' capabilities in processing complex medical data but also establishes a benchmark for future LLM evaluations across specialized domains.","sentences":["The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance.","However, their performance in actual clinical applications has been underexplored.","Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts.","This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings.","Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication.","Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes.","Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians.","Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an in-depth analysis.","Results:","GPT-4 showed overall superior performance compared to other LLMs.","In contrast, both GPT-3.5 and text-davinci-003 exhibit enhanced performance when the appropriate prompting strategies are employed.","The GPT family models have demonstrated considerable efficiency, evidenced by their cost-effectiveness and time-saving capabilities.","Conclusion: A comprehensive qualitative performance evaluation framework for LLMs is developed and operationalized.","This framework goes beyond singular performance aspects.","With expert annotations, this methodology not only validates LLMs' capabilities in processing complex medical data but also establishes a benchmark for future LLM evaluations across specialized domains."],"url":"http://arxiv.org/abs/2401.13588v1"}
{"created":"2024-01-24 16:43:35","title":"WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition","abstract":"This work explores an emerging security threat against deep neural networks (DNNs) based image classification, i.e., backdoor attack. In this scenario, the attacker aims to inject a backdoor into the model by manipulating training data, such that the backdoor could be activated by a particular trigger and bootstraps the model to make a target prediction at inference. Currently, most existing data poisoning-based attacks struggle to achieve success at low poisoning ratios, increasing the risk of being defended by defense methods. In this paper, we propose a novel frequency-based backdoor attack via Wavelet Packet Decomposition (WPD), WPD decomposes the original image signal to a spectrogram that contains frequency information with different semantic meanings. We leverage WPD to statistically analyze the frequency distribution of the dataset to infer the key frequency regions the DNNs would focus on, and the trigger information is only injected into the key frequency regions. Our method mainly includes three parts: 1) the selection of the poisoning frequency regions in spectrogram; 2) trigger generation; 3) the generation of the poisoned dataset. Our method is stealthy and precise, evidenced by the 98.12% Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio 0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can bypass most existing defense methods. Besides, we also provide visualization analyses to explain why our method works.","sentences":["This work explores an emerging security threat against deep neural networks (DNNs) based image classification, i.e., backdoor attack.","In this scenario, the attacker aims to inject a backdoor into the model by manipulating training data, such that the backdoor could be activated by a particular trigger and bootstraps the model to make a target prediction at inference.","Currently, most existing data poisoning-based attacks struggle to achieve success at low poisoning ratios, increasing the risk of being defended by defense methods.","In this paper, we propose a novel frequency-based backdoor attack via Wavelet Packet Decomposition (WPD), WPD decomposes the original image signal to a spectrogram that contains frequency information with different semantic meanings.","We leverage WPD to statistically analyze the frequency distribution of the dataset to infer the key frequency regions the DNNs would focus on, and the trigger information is only injected into the key frequency regions.","Our method mainly includes three parts: 1) the selection of the poisoning frequency regions in spectrogram; 2) trigger generation; 3) the generation of the poisoned dataset.","Our method is stealthy and precise, evidenced by the 98.12% Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio 0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can bypass most existing defense methods.","Besides, we also provide visualization analyses to explain why our method works."],"url":"http://arxiv.org/abs/2401.13578v1"}
{"created":"2024-01-24 16:30:21","title":"SPARC-LoRa: A Scalable, Power-efficient, Affordable, Reliable, and Cloud Service-enabled LoRa Networking System for Agriculture Applications","abstract":"With the rapid development of cloud and edge computing, Internet of Things (IoT) applications have been deployed in various aspects of human life. In this paper, we design and implement a holistic LoRa-based IoT system with LoRa communication capabilities, named SPARC-LoRa, which consists of field sensor nodes and a gateway connected to the Internet. SPARC-LoRa has the following important features. First, the proposed wireless network of SPARC-LoRa is even-driven and using off-the-shelf microcontroller and LoRa communication modules with a customized PCB design to integrate all the hardware. This enables SPARC-LoRa to achieve low power consumption, long range communication, and low cost. With a new connection-based upper layer protocol design, the scalability and communication reliability of SPARC-loRa can be achieved. Second, an open source software including sensor nodes and servers is designed based on Docker container with cloud storage, computing, and LTE functionalities. In order to achieve reliable wireless communication under extreme conditions, a relay module is designed and applied to SPARC-LoRa to forward the data from sensor nodes to the gateway node. The system design and implementation is completely open source and hosted on the DigitalOcean Droplet Cloud. Hence, the proposed system enables further research and applications in both academia and industry. The proposed system has been tested in real fields under different and extreme environmental conditions in Salt Lake City, Utah and the University of Nebraska-Lincoln. The experimental results validate the features of SPARC-LoRa including low power, reliability, and cloud services provided by SPARC-LoRa.","sentences":["With the rapid development of cloud and edge computing, Internet of Things (IoT) applications have been deployed in various aspects of human life.","In this paper, we design and implement a holistic LoRa-based IoT system with LoRa communication capabilities, named SPARC-LoRa, which consists of field sensor nodes and a gateway connected to the Internet.","SPARC-LoRa has the following important features.","First, the proposed wireless network of SPARC-LoRa is even-driven and using off-the-shelf microcontroller and LoRa communication modules with a customized PCB design to integrate all the hardware.","This enables SPARC-LoRa to achieve low power consumption, long range communication, and low cost.","With a new connection-based upper layer protocol design, the scalability and communication reliability of SPARC-loRa can be achieved.","Second, an open source software including sensor nodes and servers is designed based on Docker container with cloud storage, computing, and LTE functionalities.","In order to achieve reliable wireless communication under extreme conditions, a relay module is designed and applied to SPARC-LoRa to forward the data from sensor nodes to the gateway node.","The system design and implementation is completely open source and hosted on the DigitalOcean Droplet Cloud.","Hence, the proposed system enables further research and applications in both academia and industry.","The proposed system has been tested in real fields under different and extreme environmental conditions in Salt Lake City, Utah and the University of Nebraska-Lincoln.","The experimental results validate the features of SPARC-LoRa including low power, reliability, and cloud services provided by SPARC-LoRa."],"url":"http://arxiv.org/abs/2401.13569v1"}
{"created":"2024-01-24 16:23:14","title":"A Cost-Sensitive Meta-Learning Strategy for Fair Provider Exposure in Recommendation","abstract":"When devising recommendation services, it is important to account for the interests of all content providers, encompassing not only newcomers but also minority demographic groups. In various instances, certain provider groups find themselves underrepresented in the item catalog, a situation that can influence recommendation results. Hence, platform owners often seek to regulate the exposure of these provider groups in the recommended lists. In this paper, we propose a novel cost-sensitive approach designed to guarantee these target exposure levels in pairwise recommendation models. This approach quantifies, and consequently mitigate, the discrepancies between the volume of recommendations allocated to groups and their contribution in the item catalog, under the principle of equity. Our results show that this approach, while aligning groups exposure with their assigned levels, does not compromise to the original recommendation utility. Source code and pre-processed data can be retrieved at https://github.com/alessandraperniciano/meta-learning-strategy-fair-provider-exposure.","sentences":["When devising recommendation services, it is important to account for the interests of all content providers, encompassing not only newcomers but also minority demographic groups.","In various instances, certain provider groups find themselves underrepresented in the item catalog, a situation that can influence recommendation results.","Hence, platform owners often seek to regulate the exposure of these provider groups in the recommended lists.","In this paper, we propose a novel cost-sensitive approach designed to guarantee these target exposure levels in pairwise recommendation models.","This approach quantifies, and consequently mitigate, the discrepancies between the volume of recommendations allocated to groups and their contribution in the item catalog, under the principle of equity.","Our results show that this approach, while aligning groups exposure with their assigned levels, does not compromise to the original recommendation utility.","Source code and pre-processed data can be retrieved at https://github.com/alessandraperniciano/meta-learning-strategy-fair-provider-exposure."],"url":"http://arxiv.org/abs/2401.13566v1"}
{"created":"2024-01-24 16:11:42","title":"Interleaving One-Class and Weakly-Supervised Models with Adaptive Thresholding for Unsupervised Video Anomaly Detection","abstract":"Without human annotations, a typical Unsupervised Video Anomaly Detection (UVAD) method needs to train two models that generate pseudo labels for each other. In previous work, the two models are closely entangled with each other, and it is not known how to upgrade their method without modifying their training framework significantly. Second, previous work usually adopts fixed thresholding to obtain pseudo labels, however the user-specified threshold is not reliable which inevitably introduces errors into the training process. To alleviate these two problems, we propose a novel interleaved framework that alternately trains a One-Class Classification (OCC) model and a Weakly-Supervised (WS) model for UVAD. The OCC or WS models in our method can be easily replaced with other OCC or WS models, which facilitates our method to upgrade with the most recent developments in both fields. For handling the fixed thresholding problem, we break through the conventional cognitive boundary and propose a weighted OCC model that can be trained on both normal and abnormal data. We also propose an adaptive mechanism for automatically finding the optimal threshold for the WS model in a loose to strict manner. Experiments demonstrate that the proposed UVAD method outperforms previous approaches.","sentences":["Without human annotations, a typical Unsupervised Video Anomaly Detection (UVAD) method needs to train two models that generate pseudo labels for each other.","In previous work, the two models are closely entangled with each other, and it is not known how to upgrade their method without modifying their training framework significantly.","Second, previous work usually adopts fixed thresholding to obtain pseudo labels, however the user-specified threshold is not reliable which inevitably introduces errors into the training process.","To alleviate these two problems, we propose a novel interleaved framework that alternately trains a One-Class Classification (OCC) model and a Weakly-Supervised (WS) model for UVAD.","The OCC or WS models in our method can be easily replaced with other OCC or WS models, which facilitates our method to upgrade with the most recent developments in both fields.","For handling the fixed thresholding problem, we break through the conventional cognitive boundary and propose a weighted OCC model that can be trained on both normal and abnormal data.","We also propose an adaptive mechanism for automatically finding the optimal threshold for the WS model in a loose to strict manner.","Experiments demonstrate that the proposed UVAD method outperforms previous approaches."],"url":"http://arxiv.org/abs/2401.13551v1"}
{"created":"2024-01-24 15:15:03","title":"Addressing Data Quality Challenges in Observational Ambulatory Studies: Analysis, Methodologies and Practical Solutions for Wrist-worn Wearable Monitoring","abstract":"Chronic disease management and follow-up are vital for realizing sustained patient well-being and optimal health outcomes. Recent advancements in wearable sensing technologies, particularly wrist-worn devices, offer promising solutions for longitudinal patient follow-up by shifting from subjective, intermittent self-reporting to objective, continuous monitoring. However, collecting and analyzing wearable data presents unique challenges, such as data entry errors, non-wear periods, missing wearable data, and wearable artifacts. We therefore present an in-depth exploration of data analysis challenges tied to wrist-worn wearables and ambulatory label acquisition, using two real-world datasets (i.e., mBrain21 and ETRI lifelog2020). We introduce novel practical countermeasures, including participant compliance visualizations, interaction-triggered questionnaires to assess personal bias, and an optimized wearable non-wear detection pipeline. Further, we propose a visual analytics approach to validate processing pipelines using scalable tools such as tsflex and Plotly-Resampler. Lastly, we investigate the impact of missing wearable data on \"window-of-interest\" analysis methodologies. Prioritizing transparency and reproducibility, we offer open access to our detailed code examples, facilitating adaptation in future wearable research. In conclusion, our contributions provide actionable approaches for wearable data collection and analysis in chronic disease management.","sentences":["Chronic disease management and follow-up are vital for realizing sustained patient well-being and optimal health outcomes.","Recent advancements in wearable sensing technologies, particularly wrist-worn devices, offer promising solutions for longitudinal patient follow-up by shifting from subjective, intermittent self-reporting to objective, continuous monitoring.","However, collecting and analyzing wearable data presents unique challenges, such as data entry errors, non-wear periods, missing wearable data, and wearable artifacts.","We therefore present an in-depth exploration of data analysis challenges tied to wrist-worn wearables and ambulatory label acquisition, using two real-world datasets (i.e., mBrain21 and ETRI lifelog2020).","We introduce novel practical countermeasures, including participant compliance visualizations, interaction-triggered questionnaires to assess personal bias, and an optimized wearable non-wear detection pipeline.","Further, we propose a visual analytics approach to validate processing pipelines using scalable tools such as tsflex and Plotly-Resampler.","Lastly, we investigate the impact of missing wearable data on \"window-of-interest\" analysis methodologies.","Prioritizing transparency and reproducibility, we offer open access to our detailed code examples, facilitating adaptation in future wearable research.","In conclusion, our contributions provide actionable approaches for wearable data collection and analysis in chronic disease management."],"url":"http://arxiv.org/abs/2401.13518v1"}
{"created":"2024-01-24 15:10:13","title":"Can GPT-3.5 Generate and Code Discharge Summaries?","abstract":"Objective: To investigate GPT-3.5 in generating and coding medical documents with ICD-10 codes for data augmentation on low-resources labels.   Materials and Methods: Employing GPT-3.5 we generated and coded 9,606 discharge summaries based on lists of ICD-10 code descriptions of patients with infrequent (generation) codes within the MIMIC-IV dataset. Combined with the baseline training set, this formed an augmented training set. Neural coding models were trained on baseline and augmented data and evaluated on a MIMIC-IV test set. We report micro- and macro-F1 scores on the full codeset, generation codes, and their families. Weak Hierarchical Confusion Matrices were employed to determine within-family and outside-of-family coding errors in the latter codesets. The coding performance of GPT-3.5 was evaluated both on prompt-guided self-generated data and real MIMIC-IV data. Clinical professionals evaluated the clinical acceptability of the generated documents.   Results: Augmentation slightly hinders the overall performance of the models but improves performance for the generation candidate codes and their families, including one unseen in the baseline training data. Augmented models display lower out-of-family error rates. GPT-3.5 can identify ICD-10 codes by the prompted descriptions, but performs poorly on real data. Evaluators note the correctness of generated concepts while suffering in variety, supporting information, and narrative.   Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding. Augmentation positively affects generation code families but mainly benefits codes with existing examples. Augmentation reduces out-of-family errors. Discharge summaries generated by GPT-3.5 state prompted concepts correctly but lack variety, and authenticity in narratives. They are unsuitable for clinical practice.","sentences":["Objective: To investigate GPT-3.5 in generating and coding medical documents with ICD-10 codes for data augmentation on low-resources labels.   ","Materials and Methods: Employing GPT-3.5 we generated and coded 9,606 discharge summaries based on lists of ICD-10 code descriptions of patients with infrequent (generation) codes within the MIMIC-IV dataset.","Combined with the baseline training set, this formed an augmented training set.","Neural coding models were trained on baseline and augmented data and evaluated on a MIMIC-IV test set.","We report micro- and macro-F1 scores on the full codeset, generation codes, and their families.","Weak Hierarchical Confusion Matrices were employed to determine within-family and outside-of-family coding errors in the latter codesets.","The coding performance of GPT-3.5 was evaluated both on prompt-guided self-generated data and real MIMIC-IV data.","Clinical professionals evaluated the clinical acceptability of the generated documents.   ","Results:","Augmentation slightly hinders the overall performance of the models but improves performance for the generation candidate codes and their families, including one unseen in the baseline training data.","Augmented models display lower out-of-family error rates.","GPT-3.5 can identify ICD-10 codes by the prompted descriptions, but performs poorly on real data.","Evaluators note the correctness of generated concepts while suffering in variety, supporting information, and narrative.   ","Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding.","Augmentation positively affects generation code families but mainly benefits codes with existing examples.","Augmentation reduces out-of-family errors.","Discharge summaries generated by GPT-3.5 state prompted concepts correctly but lack variety, and authenticity in narratives.","They are unsuitable for clinical practice."],"url":"http://arxiv.org/abs/2401.13512v1"}
{"created":"2024-01-24 14:51:17","title":"Faster Combinatorial k-Clique Algorithms","abstract":"Detecting if a graph contains a $k$-Clique is one of the most fundamental problems in computer science. The asymptotically fastest algorithm runs in time $O(n^{\\omega k/3})$, where $\\omega$ is the exponent of Boolean matrix multiplication. To date, this is the only technique capable of beating the trivial $O(n^k)$ bound by a polynomial factor. Due to this technique's various limitations, much effort has gone into designing \"combinatorial\" algorithms that improve over exhaustive search via other techniques.   The first contribution of this work is a faster combinatorial algorithm for $k$-Clique, improving Vassilevska's bound of $O(n^{k}/\\log^{k-1}{n})$ by two log factors. Technically, our main result is a new reduction from $k$-Clique to Triangle detection that exploits the same divide-and-conquer at the core of recent combinatorial algorithms by Chan (SODA'15) and Yu (ICALP'15).   Our second contribution is exploiting combinatorial techniques to improve the state-of-the-art (even of non-combinatorial algorithms) for generalizations of the $k$-Clique problem. In particular, we give the first $o(n^k)$ algorithm for $k$-clique in hypergraphs and an $O(n^3/\\log^{2.25}{n} + t)$ algorithm for listing $t$ triangles in a graph.","sentences":["Detecting if a graph contains a $k$-Clique is one of the most fundamental problems in computer science.","The asymptotically fastest algorithm runs in time $O(n^{\\omega k/3})$, where $\\omega$ is the exponent of Boolean matrix multiplication.","To date, this is the only technique capable of beating the trivial $O(n^k)$ bound by a polynomial factor.","Due to this technique's various limitations, much effort has gone into designing \"combinatorial\" algorithms that improve over exhaustive search via other techniques.   ","The first contribution of this work is a faster combinatorial algorithm for $k$-Clique, improving Vassilevska's bound of $O(n^{k}/\\log^{k-1}{n})$ by two log factors.","Technically, our main result is a new reduction from $k$-Clique to Triangle detection that exploits the same divide-and-conquer at the core of recent combinatorial algorithms by Chan (SODA'15) and Yu (ICALP'15).   ","Our second contribution is exploiting combinatorial techniques to improve the state-of-the-art (even of non-combinatorial algorithms) for generalizations of the $k$-Clique problem.","In particular, we give the first $o(n^k)$ algorithm for $k$-clique in hypergraphs and an $O(n^3/\\log^{2.25}{n} + t)$ algorithm for listing $t$ triangles in a graph."],"url":"http://arxiv.org/abs/2401.13502v1"}
{"created":"2024-01-24 14:44:48","title":"LDCA: Local Descriptors with Contextual Augmentation for Few-Shot Learning","abstract":"Few-shot image classification has emerged as a key challenge in the field of computer vision, highlighting the capability to rapidly adapt to new tasks with minimal labeled data. Existing methods predominantly rely on image-level features or local descriptors, often overlooking the holistic context surrounding these descriptors. In this work, we introduce a novel approach termed \"Local Descriptor with Contextual Augmentation (LDCA)\". Specifically, this method bridges the gap between local and global understanding uniquely by leveraging an adaptive global contextual enhancement module. This module incorporates a visual transformer, endowing local descriptors with contextual awareness capabilities, ranging from broad global perspectives to intricate surrounding nuances. By doing so, LDCA transcends traditional descriptor-based approaches, ensuring each local feature is interpreted within its larger visual narrative. Extensive experiments underscore the efficacy of our method, showing a maximal absolute improvement of 20\\% over the next-best on fine-grained classification datasets, thus demonstrating significant advancements in few-shot classification tasks.","sentences":["Few-shot image classification has emerged as a key challenge in the field of computer vision, highlighting the capability to rapidly adapt to new tasks with minimal labeled data.","Existing methods predominantly rely on image-level features or local descriptors, often overlooking the holistic context surrounding these descriptors.","In this work, we introduce a novel approach termed \"Local Descriptor with Contextual Augmentation (LDCA)\".","Specifically, this method bridges the gap between local and global understanding uniquely by leveraging an adaptive global contextual enhancement module.","This module incorporates a visual transformer, endowing local descriptors with contextual awareness capabilities, ranging from broad global perspectives to intricate surrounding nuances.","By doing so, LDCA transcends traditional descriptor-based approaches, ensuring each local feature is interpreted within its larger visual narrative.","Extensive experiments underscore the efficacy of our method, showing a maximal absolute improvement of 20\\% over the next-best on fine-grained classification datasets, thus demonstrating significant advancements in few-shot classification tasks."],"url":"http://arxiv.org/abs/2401.13499v1"}
{"created":"2024-01-24 14:44:01","title":"Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting","abstract":"Synthesizing performing guitar sound is a highly challenging task due to the polyphony and high variability in expression. Recently, deep generative models have shown promising results in synthesizing expressive polyphonic instrument sounds from music scores, often using a generic MIDI input. In this work, we propose an expressive acoustic guitar sound synthesis model with a customized input representation to the instrument, which we call guitarroll. We implement the proposed approach using diffusion-based outpainting which can generate audio with long-term consistency. To overcome the lack of MIDI/audio-paired datasets, we used not only an existing guitar dataset but also collected data from a high quality sample-based guitar synthesizer. Through quantitative and qualitative evaluations, we show that our proposed model has higher audio quality than the baseline model and generates more realistic timbre sounds than the previous leading work.","sentences":["Synthesizing performing guitar sound is a highly challenging task due to the polyphony and high variability in expression.","Recently, deep generative models have shown promising results in synthesizing expressive polyphonic instrument sounds from music scores, often using a generic MIDI input.","In this work, we propose an expressive acoustic guitar sound synthesis model with a customized input representation to the instrument, which we call guitarroll.","We implement the proposed approach using diffusion-based outpainting which can generate audio with long-term consistency.","To overcome the lack of MIDI/audio-paired datasets, we used not only an existing guitar dataset but also collected data from a high quality sample-based guitar synthesizer.","Through quantitative and qualitative evaluations, we show that our proposed model has higher audio quality than the baseline model and generates more realistic timbre sounds than the previous leading work."],"url":"http://arxiv.org/abs/2401.13498v1"}
{"created":"2024-01-24 14:42:05","title":"Towards an Autonomous Compost Turner: Current State of Research","abstract":"This preprint presents the current status of research into the development and application of an autonomous, self-driving compost turner. The aim is to overcome challenges in the composting industry, such as adverse working conditions, by automating the composting process. The preprint provides a comprehensive overview of the overall concept of the self-driving compost turner, including the hardware architecture with sensors, navigation module and control module. In addition, the methodical development of the architecture of concepts, models and their subsequent software integration in ROS using model-based systems engineering is described. The validation and verification of the overall system is carried out in an industrial environment using three scenarios. The capabilities of the compost turner are demonstrated by autonomously following predefined trajectories in the composting plant and performing the required composting tasks. The results show that the autonomous compost turner is capable of performing the required activities. In addition, the compost turner has intelligent processing capabilities for compost data as well as its transmission, visualization and storage in a cloud server. It is important to note that this work is a preprint that represents the current state of research. The authors aim to publish the full paper in a peer-reviewed journal in the near future.","sentences":["This preprint presents the current status of research into the development and application of an autonomous, self-driving compost turner.","The aim is to overcome challenges in the composting industry, such as adverse working conditions, by automating the composting process.","The preprint provides a comprehensive overview of the overall concept of the self-driving compost turner, including the hardware architecture with sensors, navigation module and control module.","In addition, the methodical development of the architecture of concepts, models and their subsequent software integration in ROS using model-based systems engineering is described.","The validation and verification of the overall system is carried out in an industrial environment using three scenarios.","The capabilities of the compost turner are demonstrated by autonomously following predefined trajectories in the composting plant and performing the required composting tasks.","The results show that the autonomous compost turner is capable of performing the required activities.","In addition, the compost turner has intelligent processing capabilities for compost data as well as its transmission, visualization and storage in a cloud server.","It is important to note that this work is a preprint that represents the current state of research.","The authors aim to publish the full paper in a peer-reviewed journal in the near future."],"url":"http://arxiv.org/abs/2401.13493v1"}
{"created":"2024-01-24 14:37:44","title":"Visualization of rank-citation curves for fast detection of h-index anomalies in university metrics","abstract":"University rankings, despite facing criticism, continue to maintain their popularity. In the 2023 Scopus Ranking of Ukrainian Universities, certain institutions stood out due to their high h-index, despite modest publication and citation numbers. This phenomenon can be attributed to influential research topics or involvement in international collaborative research. However, these results may also be due to the authors' own efforts to increase the number of citations of their publications in order to improve their h-index. To investigate this, the publications from the top 30 universities in the ranking were analysed, revealing humpback rank-citation curves for two universities. These humpbacks indicate unusual trends in the citation data, especially considering the high percentage of self-citations and FWCI of analysed papers. While quantitative analysis has limitations, the combination of humped rank-citation curves, self-citations, FWCI, and previous research findings raises concerns about the possible causes of these anomalies in the citation data of the analysed universities. The method presented in this paper can aid ranking compilers and citation databases managers in identifying potential instances of citation data anomalies, emphasizing the importance of expert assessment for accurate conclusions.","sentences":["University rankings, despite facing criticism, continue to maintain their popularity.","In the 2023 Scopus Ranking of Ukrainian Universities, certain institutions stood out due to their high h-index, despite modest publication and citation numbers.","This phenomenon can be attributed to influential research topics or involvement in international collaborative research.","However, these results may also be due to the authors' own efforts to increase the number of citations of their publications in order to improve their h-index.","To investigate this, the publications from the top 30 universities in the ranking were analysed, revealing humpback rank-citation curves for two universities.","These humpbacks indicate unusual trends in the citation data, especially considering the high percentage of self-citations and FWCI of analysed papers.","While quantitative analysis has limitations, the combination of humped rank-citation curves, self-citations, FWCI, and previous research findings raises concerns about the possible causes of these anomalies in the citation data of the analysed universities.","The method presented in this paper can aid ranking compilers and citation databases managers in identifying potential instances of citation data anomalies, emphasizing the importance of expert assessment for accurate conclusions."],"url":"http://arxiv.org/abs/2401.13490v1"}
{"created":"2024-01-24 14:36:08","title":"Fast Inverse Model Transformation: Algebraic Framework for Fast Data Plane Verification","abstract":"Data plane verification (DPV) analyzes routing tables and detects routing abnormalities and policy violations during network operation and planning. Thus, it has become an important tool to harden the networking infrastructure and the computing systems building on top. Substantial advancements have been made in the last decade and state-of-the-art DPV systems can achieve sub-us verification for an update of a single forwarding rule.   In this paper, we introduce fast inverse model transformation (FIMT), the first theoretical framework to systematically model and analyze centralized DPV systems. FIMT reveals the algebraic structure in the model update process, a key step in fast DPV systems. Thus, it can systematically analyze the correctness of several DPV systems, using algebraic properties. The theory also guides the design and implementation of NeoFlash, a refactored version of Flash with new optimization techniques. Evaluations show that NeoFlash outperforms existing state-of-the-art centralized DPV systems in various datasets and reveal insights to key techniques towards fast DPV.","sentences":["Data plane verification (DPV) analyzes routing tables and detects routing abnormalities and policy violations during network operation and planning.","Thus, it has become an important tool to harden the networking infrastructure and the computing systems building on top.","Substantial advancements have been made in the last decade and state-of-the-art DPV systems can achieve sub-us verification for an update of a single forwarding rule.   ","In this paper, we introduce fast inverse model transformation (FIMT), the first theoretical framework to systematically model and analyze centralized DPV systems.","FIMT reveals the algebraic structure in the model update process, a key step in fast DPV systems.","Thus, it can systematically analyze the correctness of several DPV systems, using algebraic properties.","The theory also guides the design and implementation of NeoFlash, a refactored version of Flash with new optimization techniques.","Evaluations show that NeoFlash outperforms existing state-of-the-art centralized DPV systems in various datasets and reveal insights to key techniques towards fast DPV."],"url":"http://arxiv.org/abs/2401.13488v1"}
{"created":"2024-01-24 14:23:12","title":"SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval","abstract":"Multi-modal information retrieval (MMIR) is a rapidly evolving field, where significant progress, particularly in image-text pairing, has been made through advanced representation learning and cross-modality alignment research. However, current benchmarks for evaluating MMIR performance in image-text pairing within the scientific domain show a notable gap, where chart and table images described in scholarly language usually do not play a significant role. To bridge this gap, we develop a specialised scientific MMIR (SciMMIR) benchmark by leveraging open-access paper collections to extract data relevant to the scientific domain. This benchmark comprises 530K meticulously curated image-text pairs, extracted from figures and tables with detailed captions in scientific documents. We further annotate the image-text pairs with two-level subset-subcategory hierarchy annotations to facilitate a more comprehensive evaluation of the baselines. We conducted zero-shot and fine-tuning evaluations on prominent multi-modal image-captioning and visual language models, such as CLIP and BLIP. Our analysis offers critical insights for MMIR in the scientific domain, including the impact of pre-training and fine-tuning settings and the influence of the visual and textual encoders. All our data and checkpoints are publicly available at https://github.com/Wusiwei0410/SciMMIR.","sentences":["Multi-modal information retrieval (MMIR) is a rapidly evolving field, where significant progress, particularly in image-text pairing, has been made through advanced representation learning and cross-modality alignment research.","However, current benchmarks for evaluating MMIR performance in image-text pairing within the scientific domain show a notable gap, where chart and table images described in scholarly language usually do not play a significant role.","To bridge this gap, we develop a specialised scientific MMIR (SciMMIR) benchmark by leveraging open-access paper collections to extract data relevant to the scientific domain.","This benchmark comprises 530K meticulously curated image-text pairs, extracted from figures and tables with detailed captions in scientific documents.","We further annotate the image-text pairs with two-level subset-subcategory hierarchy annotations to facilitate a more comprehensive evaluation of the baselines.","We conducted zero-shot and fine-tuning evaluations on prominent multi-modal image-captioning and visual language models, such as CLIP and BLIP.","Our analysis offers critical insights for MMIR in the scientific domain, including the impact of pre-training and fine-tuning settings and the influence of the visual and textual encoders.","All our data and checkpoints are publicly available at https://github.com/Wusiwei0410/SciMMIR."],"url":"http://arxiv.org/abs/2401.13478v1"}
{"created":"2024-01-24 14:08:38","title":"SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering","abstract":"Spoken Question Answering (SQA) is essential for machines to reply to user's question by finding the answer span within a given spoken passage. SQA has been previously achieved without ASR to avoid recognition errors and Out-of-Vocabulary (OOV) problems. However, the real-world problem of Open-domain SQA (openSQA), in which the machine needs to first retrieve passages that possibly contain the answer from a spoken archive in addition, was never considered. This paper proposes the first known end-to-end framework, Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of the openSQA problem. SpeechDPR learns a sentence-level semantic representation by distilling knowledge from the cascading model of unsupervised ASR (UASR) and text dense retriever (TDR). No manually transcribed speech data is needed. Initial experiments showed performance comparable to the cascading model of UASR and TDR, and significantly better when UASR was poor, verifying this approach is more robust to speech recognition errors.","sentences":["Spoken Question Answering (SQA) is essential for machines to reply to user's question by finding the answer span within a given spoken passage.","SQA has been previously achieved without ASR to avoid recognition errors and Out-of-Vocabulary (OOV) problems.","However, the real-world problem of Open-domain SQA (openSQA), in which the machine needs to first retrieve passages that possibly contain the answer from a spoken archive in addition, was never considered.","This paper proposes the first known end-to-end framework, Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of the openSQA problem.","SpeechDPR learns a sentence-level semantic representation by distilling knowledge from the cascading model of unsupervised ASR (UASR) and text dense retriever (TDR).","No manually transcribed speech data is needed.","Initial experiments showed performance comparable to the cascading model of UASR and TDR, and significantly better when UASR was poor, verifying this approach is more robust to speech recognition errors."],"url":"http://arxiv.org/abs/2401.13463v1"}
{"created":"2024-01-24 13:42:49","title":"Decentralized Collaborative Learning with Adaptive Reference Data for On-Device POI Recommendation","abstract":"In Location-based Social Networks, Point-of-Interest (POI) recommendation helps users discover interesting places. There is a trend to move from the cloud-based model to on-device recommendations for privacy protection and reduced server reliance. Due to the scarcity of local user-item interactions on individual devices, solely relying on local instances is not adequate. Collaborative Learning (CL) emerges to promote model sharing among users, where reference data is an intermediary that allows users to exchange their soft decisions without directly sharing their private data or parameters, ensuring privacy and benefiting from collaboration. However, existing CL-based recommendations typically use a single reference for all users. Reference data valuable for one user might be harmful to another, given diverse user preferences. Users may not offer meaningful soft decisions on items outside their interest scope. Consequently, using the same reference data for all collaborations can impede knowledge exchange and lead to sub-optimal performance. To address this gap, we introduce the Decentralized Collaborative Learning with Adaptive Reference Data (DARD) framework, which crafts adaptive reference data for effective user collaboration. It first generates a desensitized public reference data pool with transformation and probability data generation methods. For each user, the selection of adaptive reference data is executed in parallel by training loss tracking and influence function. Local models are trained with individual private data and collaboratively with the geographical and semantic neighbors. During the collaboration between two users, they exchange soft decisions based on a combined set of their adaptive reference data. Our evaluations across two real-world datasets highlight DARD's superiority in recommendation performance and addressing the scarcity of available reference data.","sentences":["In Location-based Social Networks, Point-of-Interest (POI) recommendation helps users discover interesting places.","There is a trend to move from the cloud-based model to on-device recommendations for privacy protection and reduced server reliance.","Due to the scarcity of local user-item interactions on individual devices, solely relying on local instances is not adequate.","Collaborative Learning (CL) emerges to promote model sharing among users, where reference data is an intermediary that allows users to exchange their soft decisions without directly sharing their private data or parameters, ensuring privacy and benefiting from collaboration.","However, existing CL-based recommendations typically use a single reference for all users.","Reference data valuable for one user might be harmful to another, given diverse user preferences.","Users may not offer meaningful soft decisions on items outside their interest scope.","Consequently, using the same reference data for all collaborations can impede knowledge exchange and lead to sub-optimal performance.","To address this gap, we introduce the Decentralized Collaborative Learning with Adaptive Reference Data (DARD) framework, which crafts adaptive reference data for effective user collaboration.","It first generates a desensitized public reference data pool with transformation and probability data generation methods.","For each user, the selection of adaptive reference data is executed in parallel by training loss tracking and influence function.","Local models are trained with individual private data and collaboratively with the geographical and semantic neighbors.","During the collaboration between two users, they exchange soft decisions based on a combined set of their adaptive reference data.","Our evaluations across two real-world datasets highlight DARD's superiority in recommendation performance and addressing the scarcity of available reference data."],"url":"http://arxiv.org/abs/2401.13448v1"}
{"created":"2024-01-24 13:03:28","title":"Semi-Supervised Coupled Thin-Plate Spline Model for Rotation Correction and Beyond","abstract":"Thin-plate spline (TPS) is a principal warp that allows for representing elastic, nonlinear transformation with control point motions. With the increase of control points, the warp becomes increasingly flexible but usually encounters a bottleneck caused by undesired issues, e.g., content distortion. In this paper, we explore generic applications of TPS in single-image-based warping tasks, such as rotation correction, rectangling, and portrait correction. To break this bottleneck, we propose the coupled thin-plate spline model (CoupledTPS), which iteratively couples multiple TPS with limited control points into a more flexible and powerful transformation. Concretely, we first design an iterative search to predict new control points according to the current latent condition. Then, we present the warping flow as a bridge for the coupling of different TPS transformations, effectively eliminating interpolation errors caused by multiple warps. Besides, in light of the laborious annotation cost, we develop a semi-supervised learning scheme to improve warping quality by exploiting unlabeled data. It is formulated through dual transformation between the searched control points of unlabeled data and its graphic augmentation, yielding an implicit correction consistency constraint. Finally, we collect massive unlabeled data to exhibit the benefit of our semi-supervised scheme in rotation correction. Extensive experiments demonstrate the superiority and universality of CoupledTPS over the existing state-of-the-art (SoTA) solutions for rotation correction and beyond. The code and data will be available at https://github.com/nie-lang/CoupledTPS.","sentences":["Thin-plate spline (TPS) is a principal warp that allows for representing elastic, nonlinear transformation with control point motions.","With the increase of control points, the warp becomes increasingly flexible but usually encounters a bottleneck caused by undesired issues, e.g., content distortion.","In this paper, we explore generic applications of TPS in single-image-based warping tasks, such as rotation correction, rectangling, and portrait correction.","To break this bottleneck, we propose the coupled thin-plate spline model (CoupledTPS), which iteratively couples multiple TPS with limited control points into a more flexible and powerful transformation.","Concretely, we first design an iterative search to predict new control points according to the current latent condition.","Then, we present the warping flow as a bridge for the coupling of different TPS transformations, effectively eliminating interpolation errors caused by multiple warps.","Besides, in light of the laborious annotation cost, we develop a semi-supervised learning scheme to improve warping quality by exploiting unlabeled data.","It is formulated through dual transformation between the searched control points of unlabeled data and its graphic augmentation, yielding an implicit correction consistency constraint.","Finally, we collect massive unlabeled data to exhibit the benefit of our semi-supervised scheme in rotation correction.","Extensive experiments demonstrate the superiority and universality of CoupledTPS over the existing state-of-the-art (SoTA) solutions for rotation correction and beyond.","The code and data will be available at https://github.com/nie-lang/CoupledTPS."],"url":"http://arxiv.org/abs/2401.13432v1"}
{"created":"2024-01-24 12:31:52","title":"Distributed network for measuring climatic parameters in heterogeneous environments: Application in a greenhouse","abstract":"In Mediterranean countries of Southern Europe, the climatic conditions are usually favourable to cultivate greenhouse vegetables but not always for workers. The aim of this study was to design a network of weather stations capable of gathering data of environmental parameters related to the wellbeing of workers in greenhouses in south-eastern Spain. The unevenness of the thermal environment was studied both vertically as well as horizontally following guideline ISO 7726. The results indicate that the greenhouse should be considered a heterogeneous environment, implying that, for an evaluation of the environmental conditions related to thermal stress of the workers inside the greenhouse, measurements should be taken at different points within the greenhouse at three heights (ankle, abdomen, and head).","sentences":["In Mediterranean countries of Southern Europe, the climatic conditions are usually favourable to cultivate greenhouse vegetables but not always for workers.","The aim of this study was to design a network of weather stations capable of gathering data of environmental parameters related to the wellbeing of workers in greenhouses in south-eastern Spain.","The unevenness of the thermal environment was studied both vertically as well as horizontally following guideline ISO 7726.","The results indicate that the greenhouse should be considered a heterogeneous environment, implying that, for an evaluation of the environmental conditions related to thermal stress of the workers inside the greenhouse, measurements should be taken at different points within the greenhouse at three heights (ankle, abdomen, and head)."],"url":"http://arxiv.org/abs/2401.13420v1"}
{"created":"2024-01-24 12:20:56","title":"Characterizing Perspective Error in Voxel-Based Lidar Scan Matching","abstract":"This paper quantifies an error source that limits the accuracy of lidar scan matching, particularly for voxel-based methods. Lidar scan matching, which is used in dead reckoning (also known as lidar odometry) and mapping, computes the rotation and translation that best align a pair of point clouds. Perspective errors occur when a scene is viewed from different angles, with different surfaces becoming visible or occluded from each viewpoint. To explain perspective anomalies observed in data, this paper models perspective errors for two objects representative of urban landscapes: a cylindrical column and a dual-wall corner. For each object, we provide an analytical model of the perspective error for voxel-based lidar scan matching. We then analyze how perspective errors accumulate as a lidar-equipped vehicle moves past these objects.","sentences":["This paper quantifies an error source that limits the accuracy of lidar scan matching, particularly for voxel-based methods.","Lidar scan matching, which is used in dead reckoning (also known as lidar odometry) and mapping, computes the rotation and translation that best align a pair of point clouds.","Perspective errors occur when a scene is viewed from different angles, with different surfaces becoming visible or occluded from each viewpoint.","To explain perspective anomalies observed in data, this paper models perspective errors for two objects representative of urban landscapes: a cylindrical column and a dual-wall corner.","For each object, we provide an analytical model of the perspective error for voxel-based lidar scan matching.","We then analyze how perspective errors accumulate as a lidar-equipped vehicle moves past these objects."],"url":"http://arxiv.org/abs/2401.13416v1"}
{"created":"2024-01-24 12:11:41","title":"How to Forget Clients in Federated Online Learning to Rank?","abstract":"Data protection legislation like the European Union's General Data Protection Regulation (GDPR) establishes the \\textit{right to be forgotten}: a user (client) can request contributions made using their data to be removed from learned models. In this paper, we study how to remove the contributions made by a client participating in a Federated Online Learning to Rank (FOLTR) system. In a FOLTR system, a ranker is learned by aggregating local updates to the global ranking model. Local updates are learned in an online manner at a client-level using queries and implicit interactions that have occurred within that specific client. By doing so, each client's local data is not shared with other clients or with a centralised search service, while at the same time clients can benefit from an effective global ranking model learned from contributions of each client in the federation.   In this paper, we study an effective and efficient unlearning method that can remove a client's contribution without compromising the overall ranker effectiveness and without needing to retrain the global ranker from scratch. A key challenge is how to measure whether the model has unlearned the contributions from the client $c^*$ that has requested removal. For this, we instruct $c^*$ to perform a poisoning attack (add noise to this client updates) and then we measure whether the impact of the attack is lessened when the unlearning process has taken place. Through experiments on four datasets, we demonstrate the effectiveness and efficiency of the unlearning strategy under different combinations of parameter settings.","sentences":["Data protection legislation like the European Union's General Data Protection Regulation (GDPR) establishes the \\textit{right to be forgotten}: a user (client) can request contributions made using their data to be removed from learned models.","In this paper, we study how to remove the contributions made by a client participating in a Federated Online Learning to Rank (FOLTR) system.","In a FOLTR system, a ranker is learned by aggregating local updates to the global ranking model.","Local updates are learned in an online manner at a client-level using queries and implicit interactions that have occurred within that specific client.","By doing so, each client's local data is not shared with other clients or with a centralised search service, while at the same time clients can benefit from an effective global ranking model learned from contributions of each client in the federation.   ","In this paper, we study an effective and efficient unlearning method that can remove a client's contribution without compromising the overall ranker effectiveness and without needing to retrain the global ranker from scratch.","A key challenge is how to measure whether the model has unlearned the contributions from the client $c^*$ that has requested removal.","For this, we instruct $c^*$ to perform a poisoning attack (add noise to this client updates) and then we measure whether the impact of the attack is lessened when the unlearning process has taken place.","Through experiments on four datasets, we demonstrate the effectiveness and efficiency of the unlearning strategy under different combinations of parameter settings."],"url":"http://arxiv.org/abs/2401.13410v1"}
{"created":"2024-01-24 11:58:30","title":"Synthetic data enables faster annotation and robust segmentation for multi-object grasping in clutter","abstract":"Object recognition and object pose estimation in robotic grasping continue to be significant challenges, since building a labelled dataset can be time consuming and financially costly in terms of data collection and annotation. In this work, we propose a synthetic data generation method that minimizes human intervention and makes downstream image segmentation algorithms more robust by combining a generated synthetic dataset with a smaller real-world dataset (hybrid dataset). Annotation experiments show that the proposed synthetic scene generation can diminish labelling time dramatically. RGB image segmentation is trained with hybrid dataset and combined with depth information to produce pixel-to-point correspondence of individual segmented objects. The object to grasp is then determined by the confidence score of the segmentation algorithm. Pick-and-place experiments demonstrate that segmentation trained on our hybrid dataset (98.9%, 70%) outperforms the real dataset and a publicly available dataset by (6.7%, 18.8%) and (2.8%, 10%) in terms of labelling and grasping success rate, respectively. Supplementary material is available at https://sites.google.com/view/synthetic-dataset-generation.","sentences":["Object recognition and object pose estimation in robotic grasping continue to be significant challenges, since building a labelled dataset can be time consuming and financially costly in terms of data collection and annotation.","In this work, we propose a synthetic data generation method that minimizes human intervention and makes downstream image segmentation algorithms more robust by combining a generated synthetic dataset with a smaller real-world dataset (hybrid dataset).","Annotation experiments show that the proposed synthetic scene generation can diminish labelling time dramatically.","RGB image segmentation is trained with hybrid dataset and combined with depth information to produce pixel-to-point correspondence of individual segmented objects.","The object to grasp is then determined by the confidence score of the segmentation algorithm.","Pick-and-place experiments demonstrate that segmentation trained on our hybrid dataset (98.9%, 70%) outperforms the real dataset and a publicly available dataset by (6.7%, 18.8%) and (2.8%, 10%) in terms of labelling and grasping success rate, respectively.","Supplementary material is available at https://sites.google.com/view/synthetic-dataset-generation."],"url":"http://arxiv.org/abs/2401.13405v1"}
{"created":"2024-01-24 11:36:44","title":"UNIMO-G: Unified Image Generation through Multimodal Conditional Diffusion","abstract":"Existing text-to-image diffusion models primarily generate images from text prompts. However, the inherent conciseness of textual descriptions poses challenges in faithfully synthesizing images with intricate details, such as specific entities or scenes. This paper presents \\textbf{UNIMO-G}, a simple multimodal conditional diffusion framework that operates on multimodal prompts with interleaved textual and visual inputs, which demonstrates a unified ability for both text-driven and subject-driven image generation. UNIMO-G comprises two core components: a Multimodal Large Language Model (MLLM) for encoding multimodal prompts, and a conditional denoising diffusion network for generating images based on the encoded multimodal input. We leverage a two-stage training strategy to effectively train the framework: firstly pre-training on large-scale text-image pairs to develop conditional image generation capabilities, and then instruction tuning with multimodal prompts to achieve unified image generation proficiency. A well-designed data processing pipeline involving language grounding and image segmentation is employed to construct multi-modal prompts. UNIMO-G excels in both text-to-image generation and zero-shot subject-driven synthesis, and is notably effective in generating high-fidelity images from complex multimodal prompts involving multiple image entities.","sentences":["Existing text-to-image diffusion models primarily generate images from text prompts.","However, the inherent conciseness of textual descriptions poses challenges in faithfully synthesizing images with intricate details, such as specific entities or scenes.","This paper presents \\textbf{UNIMO-G}, a simple multimodal conditional diffusion framework that operates on multimodal prompts with interleaved textual and visual inputs, which demonstrates a unified ability for both text-driven and subject-driven image generation.","UNIMO-G comprises two core components: a Multimodal Large Language Model (MLLM) for encoding multimodal prompts, and a conditional denoising diffusion network for generating images based on the encoded multimodal input.","We leverage a two-stage training strategy to effectively train the framework: firstly pre-training on large-scale text-image pairs to develop conditional image generation capabilities, and then instruction tuning with multimodal prompts to achieve unified image generation proficiency.","A well-designed data processing pipeline involving language grounding and image segmentation is employed to construct multi-modal prompts.","UNIMO-G excels in both text-to-image generation and zero-shot subject-driven synthesis, and is notably effective in generating high-fidelity images from complex multimodal prompts involving multiple image entities."],"url":"http://arxiv.org/abs/2401.13388v1"}
{"created":"2024-01-24 11:01:15","title":"SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification","abstract":"Addressing the limitations of individual attribution scores via the Shapley value (SV), the field of explainable AI (XAI) has recently explored intricate interactions of features or data points. In particular, \\mbox{extensions}~of~the SV, such as the Shapley Interaction Index (SII), have been proposed as a measure to still benefit from the axiomatic basis of the SV. However, similar to the SV, their exact computation remains computationally prohibitive. Hence, we propose with SVARM-IQ a sampling-based approach to efficiently approximate Shapley-based interaction indices of any order. SVARM-IQ can be applied to a broad class of interaction indices, including the SII, by leveraging a novel stratified representation. We provide non-asymptotic theoretical guarantees on its approximation quality and empirically demonstrate that SVARM-IQ achieves state-of-the-art estimation results in practical XAI scenarios on different model classes and application domains.","sentences":["Addressing the limitations of individual attribution scores via the Shapley value (SV), the field of explainable AI (XAI) has recently explored intricate interactions of features or data points.","In particular, \\mbox{extensions}~of~the SV, such as the Shapley Interaction Index (SII), have been proposed as a measure to still benefit from the axiomatic basis of the SV.","However, similar to the SV, their exact computation remains computationally prohibitive.","Hence, we propose with SVARM-IQ a sampling-based approach to efficiently approximate Shapley-based interaction indices of any order.","SVARM-IQ can be applied to a broad class of interaction indices, including the SII, by leveraging a novel stratified representation.","We provide non-asymptotic theoretical guarantees on its approximation quality and empirically demonstrate that SVARM-IQ achieves state-of-the-art estimation results in practical XAI scenarios on different model classes and application domains."],"url":"http://arxiv.org/abs/2401.13371v1"}
{"created":"2024-01-24 10:51:15","title":"Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems","abstract":"Federated learning (FL) systems face performance challenges in dealing with heterogeneous devices and non-identically distributed data across clients. We propose a dynamic global model aggregation method within Asynchronous Federated Learning (AFL) deployments to address these issues. Our aggregation method scores and adjusts the weighting of client model updates based on their upload frequency to accommodate differences in device capabilities. Additionally, we also immediately provide an updated global model to clients after they upload their local models to reduce idle time and improve training efficiency. We evaluate our approach within an AFL deployment consisting of 10 simulated clients with heterogeneous compute constraints and non-IID data. The simulation results, using the FashionMNIST dataset, demonstrate over 10% and 19% improvement in global model accuracy compared to state-of-the-art methods PAPAYA and FedAsync, respectively. Our dynamic aggregation method allows reliable global model training despite limiting client resources and statistical data heterogeneity. This improves robustness and scalability for real-world FL deployments.","sentences":["Federated learning (FL) systems face performance challenges in dealing with heterogeneous devices and non-identically distributed data across clients.","We propose a dynamic global model aggregation method within Asynchronous Federated Learning (AFL) deployments to address these issues.","Our aggregation method scores and adjusts the weighting of client model updates based on their upload frequency to accommodate differences in device capabilities.","Additionally, we also immediately provide an updated global model to clients after they upload their local models to reduce idle time and improve training efficiency.","We evaluate our approach within an AFL deployment consisting of 10 simulated clients with heterogeneous compute constraints and non-IID data.","The simulation results, using the FashionMNIST dataset, demonstrate over 10% and 19% improvement in global model accuracy compared to state-of-the-art methods PAPAYA and FedAsync, respectively.","Our dynamic aggregation method allows reliable global model training despite limiting client resources and statistical data heterogeneity.","This improves robustness and scalability for real-world FL deployments."],"url":"http://arxiv.org/abs/2401.13366v1"}
{"created":"2024-01-24 10:46:32","title":"Organizing Scientific Knowledge From Energy System Research Using the Open Research Knowledge Graph","abstract":"Engineering sciences, such as energy system research, play an important role in developing solutions to technical, environmental, economic, and social challenges of our modern society. In this context, the transformation of energy systems into climate-neutral systems is one of the key strategies for mitigating climate change. For the transformation of energy systems, engineers model, simulate and analyze scenarios and transformation pathways to initiate debates about possible transformation strategies. For these debates and research in general, all steps of the research process must be traceable to guarantee the trustworthiness of published results, avoid redundancies, and ensure their social acceptance. However, the analysis of energy systems is an interdisciplinary field as the investigations of large, complex energy systems often require the use of different software applications and large amounts of heterogeneous data. Engineers must therefore communicate, understand, and (re)use heterogeneous scientific knowledge and data. Although the importance of FAIR scientific knowledge and data in the engineering sciences and energy system research is increasing, little research has been conducted on this topic. When it comes to publishing scientific knowledge and data from publications, software, and datasets (such as models, scenarios, and simulations) openly available and transparent, energy system research lags behind other research domains. According to Schmitt et al. and Nie{\\ss}e et al., engineers need technical support in the form of infrastructures, services, and terminologies to improve communication, understanding, and (re)use of scientific knowledge and data.","sentences":["Engineering sciences, such as energy system research, play an important role in developing solutions to technical, environmental, economic, and social challenges of our modern society.","In this context, the transformation of energy systems into climate-neutral systems is one of the key strategies for mitigating climate change.","For the transformation of energy systems, engineers model, simulate and analyze scenarios and transformation pathways to initiate debates about possible transformation strategies.","For these debates and research in general, all steps of the research process must be traceable to guarantee the trustworthiness of published results, avoid redundancies, and ensure their social acceptance.","However, the analysis of energy systems is an interdisciplinary field as the investigations of large, complex energy systems often require the use of different software applications and large amounts of heterogeneous data.","Engineers must therefore communicate, understand, and (re)use heterogeneous scientific knowledge and data.","Although the importance of FAIR scientific knowledge and data in the engineering sciences and energy system research is increasing, little research has been conducted on this topic.","When it comes to publishing scientific knowledge and data from publications, software, and datasets (such as models, scenarios, and simulations) openly available and transparent, energy system research lags behind other research domains.","According to Schmitt et al. and Nie{\\ss}e et al., engineers need technical support in the form of infrastructures, services, and terminologies to improve communication, understanding, and (re)use of scientific knowledge and data."],"url":"http://arxiv.org/abs/2401.13365v1"}
{"created":"2024-01-24 10:37:28","title":"Debiased Sample Selection for Combating Noisy Labels","abstract":"Learning with noisy labels aims to ensure model generalization given a label-corrupted training set. The sample selection strategy achieves promising performance by selecting a label-reliable subset for model training. In this paper, we empirically reveal that existing sample selection methods suffer from both data and training bias that are represented as imbalanced selected sets and accumulation errors in practice, respectively. However, only the training bias was handled in previous studies. To address this limitation, we propose a noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection. Specifically, to mitigate the training bias, we design a robust network architecture that integrates with multiple experts. Compared with the prevailing double-branch network, our network exhibits better performance of selection and prediction by ensembling these experts while training with fewer parameters. Meanwhile, to mitigate the data bias, we propose a mixed sampling strategy based on two weight-based data samplers. By training on the mixture of two class-discriminative mini-batches, the model mitigates the effect of the imbalanced training set while avoiding sparse representations that are easily caused by sampling strategies. Extensive experiments and analyses demonstrate the effectiveness of ITEM. Our code is available at this url \\href{https://github.com/1998v7/ITEM}{ITEM}.","sentences":["Learning with noisy labels aims to ensure model generalization given a label-corrupted training set.","The sample selection strategy achieves promising performance by selecting a label-reliable subset for model training.","In this paper, we empirically reveal that existing sample selection methods suffer from both data and training bias that are represented as imbalanced selected sets and accumulation errors in practice, respectively.","However, only the training bias was handled in previous studies.","To address this limitation, we propose a noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection.","Specifically, to mitigate the training bias, we design a robust network architecture that integrates with multiple experts.","Compared with the prevailing double-branch network, our network exhibits better performance of selection and prediction by ensembling these experts while training with fewer parameters.","Meanwhile, to mitigate the data bias, we propose a mixed sampling strategy based on two weight-based data samplers.","By training on the mixture of two class-discriminative mini-batches, the model mitigates the effect of the imbalanced training set while avoiding sparse representations that are easily caused by sampling strategies.","Extensive experiments and analyses demonstrate the effectiveness of ITEM.","Our code is available at this url \\href{https://github.com/1998v7/ITEM}{ITEM}."],"url":"http://arxiv.org/abs/2401.13360v1"}
{"created":"2024-01-24 10:36:40","title":"Reconfigurable routing in data center networks","abstract":"The Reconfigurable Routing Problem (RRP) in hybrid networks is, in short, the problem of finding settings for optical switches augmenting a static network so as to achieve optimal delivery of some given workload. The problem has previously been studied in various scenarios with both tractable and NP-hardness results obtained. However, the data center and interconnection networks to which the problem is most relevant are almost always such that the static network is highly structured whereas all previous results assume that the static network can be arbitrary (which makes existing computational hardness results less technologically relevant and also easier to obtain). In this paper, and for the first time, we prove various intractability results for RRP where the underlying static network is highly structured, for example consisting of a hypercube, and also extend some existing tractability results.","sentences":["The Reconfigurable Routing Problem (RRP) in hybrid networks is, in short, the problem of finding settings for optical switches augmenting a static network so as to achieve optimal delivery of some given workload.","The problem has previously been studied in various scenarios with both tractable and NP-hardness results obtained.","However, the data center and interconnection networks to which the problem is most relevant are almost always such that the static network is highly structured whereas all previous results assume that the static network can be arbitrary (which makes existing computational hardness results less technologically relevant and also easier to obtain).","In this paper, and for the first time, we prove various intractability results for RRP where the underlying static network is highly structured, for example consisting of a hypercube, and also extend some existing tractability results."],"url":"http://arxiv.org/abs/2401.13359v1"}
{"created":"2024-01-24 10:09:30","title":"Evaluation of depth perception in crowded volumes","abstract":"Depth perception in volumetric visualization plays a crucial role in the understanding and interpretation of volumetric data. Numerous visualization techniques, many of which rely on physically based optical effects, promise to improve depth perception but often do so without considering camera movement or the content of the volume. As a result, the findings from previous studies may not be directly applicable to crowded volumes, where a large number of contained structures disrupts spatial perception. Crowded volumes therefore require special analysis and visualization tools with sparsification capabilities. Interactivity is an integral part of visualizing and exploring crowded spaces, but has received little attention in previous studies. To address this gap, we conducted a study to assess the impact of different rendering techniques on depth perception in crowded volumes, with a particular focus on the effects of camera movement. The results show that depth perception considering camera motion depends much more on the content of the volume than on the chosen visualization technique. Furthermore, we found that traditional rendering techniques, which have often performed poorly in previous studies, showed comparable performance to physically based methods in our study.","sentences":["Depth perception in volumetric visualization plays a crucial role in the understanding and interpretation of volumetric data.","Numerous visualization techniques, many of which rely on physically based optical effects, promise to improve depth perception but often do so without considering camera movement or the content of the volume.","As a result, the findings from previous studies may not be directly applicable to crowded volumes, where a large number of contained structures disrupts spatial perception.","Crowded volumes therefore require special analysis and visualization tools with sparsification capabilities.","Interactivity is an integral part of visualizing and exploring crowded spaces, but has received little attention in previous studies.","To address this gap, we conducted a study to assess the impact of different rendering techniques on depth perception in crowded volumes, with a particular focus on the effects of camera movement.","The results show that depth perception considering camera motion depends much more on the content of the volume than on the chosen visualization technique.","Furthermore, we found that traditional rendering techniques, which have often performed poorly in previous studies, showed comparable performance to physically based methods in our study."],"url":"http://arxiv.org/abs/2401.13341v1"}
{"created":"2024-01-24 09:44:57","title":"Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable Stress Detection","abstract":"Smartwatch health sensor data is increasingly utilized in smart health applications and patient monitoring, including stress detection. However, such medical data often comprises sensitive personal information and is resource-intensive to acquire for research purposes. In response to this challenge, we introduce the privacy-aware synthetization of multi-sensor smartwatch health readings related to moments of stress. Our method involves the generation of synthetic sequence data through Generative Adversarial Networks (GANs), coupled with the implementation of Differential Privacy (DP) safeguards for protecting patient information during model training. To ensure the integrity of our synthetic data, we employ a range of quality assessments and monitor the plausibility between synthetic and original data. To test the usefulness, we create private machine learning models on a commonly used, albeit small, stress detection dataset, exploring strategies for enhancing the existing data foundation with our synthetic data. Through our GAN-based augmentation methods, we observe improvements in model performance, both in non-private (0.45% F1) and private (11.90-15.48% F1) training scenarios. We underline the potential of differentially private synthetic data in optimizing utility-privacy trade-offs, especially with limited availability of real training samples.","sentences":["Smartwatch health sensor data is increasingly utilized in smart health applications and patient monitoring, including stress detection.","However, such medical data often comprises sensitive personal information and is resource-intensive to acquire for research purposes.","In response to this challenge, we introduce the privacy-aware synthetization of multi-sensor smartwatch health readings related to moments of stress.","Our method involves the generation of synthetic sequence data through Generative Adversarial Networks (GANs), coupled with the implementation of Differential Privacy (DP) safeguards for protecting patient information during model training.","To ensure the integrity of our synthetic data, we employ a range of quality assessments and monitor the plausibility between synthetic and original data.","To test the usefulness, we create private machine learning models on a commonly used, albeit small, stress detection dataset, exploring strategies for enhancing the existing data foundation with our synthetic data.","Through our GAN-based augmentation methods, we observe improvements in model performance, both in non-private (0.45% F1) and private (11.90-15.48% F1) training scenarios.","We underline the potential of differentially private synthetic data in optimizing utility-privacy trade-offs, especially with limited availability of real training samples."],"url":"http://arxiv.org/abs/2401.13327v1"}
{"created":"2024-01-24 09:39:45","title":"Memory Consistency Guided Divide-and-Conquer Learning for Generalized Category Discovery","abstract":"Generalized category discovery (GCD) aims at addressing a more realistic and challenging setting of semi-supervised learning, where only part of the category labels are assigned to certain training samples. Previous methods generally employ naive contrastive learning or unsupervised clustering scheme for all the samples. Nevertheless, they usually ignore the inherent critical information within the historical predictions of the model being trained. Specifically, we empirically reveal that a significant number of salient unlabeled samples yield consistent historical predictions corresponding to their ground truth category. From this observation, we propose a Memory Consistency guided Divide-and-conquer Learning framework (MCDL). In this framework, we introduce two memory banks to record historical prediction of unlabeled data, which are exploited to measure the credibility of each sample in terms of its prediction consistency. With the guidance of credibility, we can design a divide-and-conquer learning strategy to fully utilize the discriminative information of unlabeled data while alleviating the negative influence of noisy labels. Extensive experimental results on multiple benchmarks demonstrate the generality and superiority of our method, where our method outperforms state-of-the-art models by a large margin on both seen and unseen classes of the generic image recognition and challenging semantic shift settings (i.e.,with +8.4% gain on CUB and +8.1% on Standford Cars).","sentences":["Generalized category discovery (GCD) aims at addressing a more realistic and challenging setting of semi-supervised learning, where only part of the category labels are assigned to certain training samples.","Previous methods generally employ naive contrastive learning or unsupervised clustering scheme for all the samples.","Nevertheless, they usually ignore the inherent critical information within the historical predictions of the model being trained.","Specifically, we empirically reveal that a significant number of salient unlabeled samples yield consistent historical predictions corresponding to their ground truth category.","From this observation, we propose a Memory Consistency guided Divide-and-conquer Learning framework (MCDL).","In this framework, we introduce two memory banks to record historical prediction of unlabeled data, which are exploited to measure the credibility of each sample in terms of its prediction consistency.","With the guidance of credibility, we can design a divide-and-conquer learning strategy to fully utilize the discriminative information of unlabeled data while alleviating the negative influence of noisy labels.","Extensive experimental results on multiple benchmarks demonstrate the generality and superiority of our method, where our method outperforms state-of-the-art models by a large margin on both seen and unseen classes of the generic image recognition and challenging semantic shift settings (i.e.,with +8.4% gain on CUB and +8.1% on Standford Cars)."],"url":"http://arxiv.org/abs/2401.13325v1"}
{"created":"2024-01-24 09:39:39","title":"Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions","abstract":"Explanations of AI systems rarely address the information needs of people affected by algorithmic decision-making (ADM). This gap between conveyed information and information that matters to affected stakeholders can impede understanding and adherence to regulatory frameworks such as the AI Act. To address this gap, we present the \"XAI Novice Question Bank\": A catalog of affected stakeholders' information needs in two ADM use cases (employment prediction and health monitoring), covering the categories data, system context, system usage, and system specifications. Information needs were gathered in an interview study where participants received explanations in response to their inquiries. Participants further reported their understanding and decision confidence, showing that while confidence tended to increase after receiving explanations, participants also met understanding challenges, such as being unable to tell why their understanding felt incomplete. Explanations further influenced participants' perceptions of the systems' risks and benefits, which they confirmed or changed depending on the use case. When risks were perceived as high, participants expressed particular interest in explanations about intention, such as why and to what end a system was put in place. With this work, we aim to support the inclusion of affected stakeholders into explainability by contributing an overview of information and challenges relevant to them when deciding on the adoption of ADM systems. We close by summarizing our findings in a list of six key implications that inform the design of future explanations for affected stakeholder audiences.","sentences":["Explanations of AI systems rarely address the information needs of people affected by algorithmic decision-making (ADM).","This gap between conveyed information and information that matters to affected stakeholders can impede understanding and adherence to regulatory frameworks such as the AI Act.","To address this gap, we present the \"XAI Novice Question Bank\": A catalog of affected stakeholders' information needs in two ADM use cases (employment prediction and health monitoring), covering the categories data, system context, system usage, and system specifications.","Information needs were gathered in an interview study where participants received explanations in response to their inquiries.","Participants further reported their understanding and decision confidence, showing that while confidence tended to increase after receiving explanations, participants also met understanding challenges, such as being unable to tell why their understanding felt incomplete.","Explanations further influenced participants' perceptions of the systems' risks and benefits, which they confirmed or changed depending on the use case.","When risks were perceived as high, participants expressed particular interest in explanations about intention, such as why and to what end a system was put in place.","With this work, we aim to support the inclusion of affected stakeholders into explainability by contributing an overview of information and challenges relevant to them when deciding on the adoption of ADM systems.","We close by summarizing our findings in a list of six key implications that inform the design of future explanations for affected stakeholder audiences."],"url":"http://arxiv.org/abs/2401.13324v1"}
{"created":"2024-01-24 09:30:21","title":"A Big Data Architecture for Early Identification and Categorization of Dark Web Sites","abstract":"The dark web has become notorious for its association with illicit activities and there is a growing need for systems to automate the monitoring of this space. This paper proposes an end-to-end scalable architecture for the early identification of new Tor sites and the daily analysis of their content. The solution is built using an Open Source Big Data stack for data serving with Kubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onion addresses in different sources (threat intelligence, code repositories, web-Tor gateways, and Tor repositories), downloading the HTML from Tor and deduplicating the content using MinHash LSH, and categorizing with the BERTopic modeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN document clustering and c-TF-IDF topic keywords). In 93 days, the system identified 80,049 onion services and characterized 90% of them, addressing the challenge of Tor volatility. A disproportionate amount of repeated content is found, with only 6.1% unique sites. From the HTML files of the dark sites, 31 different low-topics are extracted, manually labeled, and grouped into 11 high-level topics. The five most popular included sexual and violent content, repositories, search engines, carding, cryptocurrencies, and marketplaces. During the experiments, we identified 14 sites with 13,946 clones that shared a suspiciously similar mirroring rate per day, suggesting an extensive common phishing network. Among the related works, this study is the most representative characterization of onion services based on topics to date.","sentences":["The dark web has become notorious for its association with illicit activities and there is a growing need for systems to automate the monitoring of this space.","This paper proposes an end-to-end scalable architecture for the early identification of new Tor sites and the daily analysis of their content.","The solution is built using an Open Source Big Data stack for data serving with Kubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onion addresses in different sources (threat intelligence, code repositories, web-Tor gateways, and Tor repositories), downloading the HTML from Tor and deduplicating the content using MinHash LSH, and categorizing with the BERTopic modeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN document clustering and c-TF-IDF topic keywords).","In 93 days, the system identified 80,049 onion services and characterized 90% of them, addressing the challenge of Tor volatility.","A disproportionate amount of repeated content is found, with only 6.1% unique sites.","From the HTML files of the dark sites, 31 different low-topics are extracted, manually labeled, and grouped into 11 high-level topics.","The five most popular included sexual and violent content, repositories, search engines, carding, cryptocurrencies, and marketplaces.","During the experiments, we identified 14 sites with 13,946 clones that shared a suspiciously similar mirroring rate per day, suggesting an extensive common phishing network.","Among the related works, this study is the most representative characterization of onion services based on topics to date."],"url":"http://arxiv.org/abs/2401.13320v1"}
{"created":"2024-01-24 09:07:01","title":"Lessons Learned Migrating CUDA to SYCL: A HEP Case Study with ROOT RDataFrame","abstract":"The world's largest particle accelerator, located at CERN, produces petabytes of data that need to be analysed efficiently, to study the fundamental structures of our universe. ROOT is an open-source C++ data analysis framework, developed for this purpose. Its high-level data analysis interface, RDataFrame, currently only supports CPU parallelism. Given the increasing heterogeneity in computing facilities, it becomes crucial to efficiently support GPGPUs to take advantage of the available resources. SYCL allows for a single-source implementation, which enables support for different architectures. In this paper, we describe a CUDA implementation and the migration process to SYCL, focusing on a core high energy physics operation in RDataFrame -- histogramming. We detail the challenges that we faced when integrating SYCL into a large and complex code base. Furthermore, we perform an extensive comparative performance analysis of two SYCL compilers, AdaptiveCpp and DPC++, and the reference CUDA implementation. We highlight the performance bottlenecks that we encountered, and the methodology used to detect these. Based on our findings, we provide actionable insights for developers of SYCL applications.","sentences":["The world's largest particle accelerator, located at CERN, produces petabytes of data that need to be analysed efficiently, to study the fundamental structures of our universe.","ROOT is an open-source C++ data analysis framework, developed for this purpose.","Its high-level data analysis interface, RDataFrame, currently only supports CPU parallelism.","Given the increasing heterogeneity in computing facilities, it becomes crucial to efficiently support GPGPUs to take advantage of the available resources.","SYCL allows for a single-source implementation, which enables support for different architectures.","In this paper, we describe a CUDA implementation and the migration process to SYCL, focusing on a core high energy physics operation in RDataFrame -- histogramming.","We detail the challenges that we faced when integrating SYCL into a large and complex code base.","Furthermore, we perform an extensive comparative performance analysis of two SYCL compilers, AdaptiveCpp and DPC++, and the reference CUDA implementation.","We highlight the performance bottlenecks that we encountered, and the methodology used to detect these.","Based on our findings, we provide actionable insights for developers of SYCL applications."],"url":"http://arxiv.org/abs/2401.13310v1"}
{"created":"2024-01-24 09:02:00","title":"ChatterBox: Multi-round Multimodal Referring and Grounding","abstract":"In this study, we establish a baseline for a new task named multimodal multi-round referring and grounding (MRG), opening up a promising direction for instance-level multimodal dialogues. We present a new benchmark and an efficient vision-language model for this purpose. The new benchmark, named CB-300K, spans challenges including multi-round dialogue, complex spatial relationships among multiple instances, and consistent reasoning, which are beyond those shown in existing benchmarks. The proposed model, named ChatterBox, utilizes a two-branch architecture to collaboratively handle vision and language tasks. By tokenizing instance regions, the language branch acquires the ability to perceive referential information. Meanwhile, ChatterBox feeds a query embedding in the vision branch to a token receiver for visual grounding. A two-stage optimization strategy is devised, making use of both CB-300K and auxiliary external data to improve the model's stability and capacity for instance-level understanding. Experiments show that ChatterBox outperforms existing models in MRG both quantitatively and qualitatively, paving a new path towards multimodal dialogue scenarios with complicated and precise interactions. Code, data, and model are available at: https://github.com/sunsmarterjie/ChatterBox.","sentences":["In this study, we establish a baseline for a new task named multimodal multi-round referring and grounding (MRG), opening up a promising direction for instance-level multimodal dialogues.","We present a new benchmark and an efficient vision-language model for this purpose.","The new benchmark, named CB-300K, spans challenges including multi-round dialogue, complex spatial relationships among multiple instances, and consistent reasoning, which are beyond those shown in existing benchmarks.","The proposed model, named ChatterBox, utilizes a two-branch architecture to collaboratively handle vision and language tasks.","By tokenizing instance regions, the language branch acquires the ability to perceive referential information.","Meanwhile, ChatterBox feeds a query embedding in the vision branch to a token receiver for visual grounding.","A two-stage optimization strategy is devised, making use of both CB-300K and auxiliary external data to improve the model's stability and capacity for instance-level understanding.","Experiments show that ChatterBox outperforms existing models in MRG both quantitatively and qualitatively, paving a new path towards multimodal dialogue scenarios with complicated and precise interactions.","Code, data, and model are available at: https://github.com/sunsmarterjie/ChatterBox."],"url":"http://arxiv.org/abs/2401.13307v1"}
{"created":"2024-01-24 08:49:50","title":"Classification of Radiologically Isolated Syndrome and Clinically Isolated Syndrome with Machine-Learning Techniques","abstract":"Background and purpose: The unanticipated detection by magnetic resonance imaging (MRI) in the brain of asymptomatic subjects of white matter lesions suggestive of multiple sclerosis (MS) has been named radiologically isolated syndrome (RIS). As the difference between early MS [i.e. clinically isolated syndrome (CIS)] and RIS is the occurrence of a clinical event, it is logical to improve detection of the subclinical form without interfering with MRI as there are radiological diagnostic criteria for that. Our objective was to use machine-learning classification methods to identify morphometric measures that help to discriminate patients with RIS from those with CIS.   Methods: We used a multimodal 3-T MRI approach by combining MRI biomarkers (cortical thickness, cortical and subcortical grey matter volume, and white matter integrity) of a cohort of 17 patients with RIS and 17 patients with CIS for single-subject level classification.   Results: The best proposed models to predict the diagnosis of CIS and RIS were based on the Naive Bayes, Bagging and Multilayer Perceptron classifiers using only three features: the left rostral middle frontal gyrus volume and the fractional anisotropy values in the right amygdala and right lingual gyrus. The Naive Bayes obtained the highest accuracy [overall classification, 0.765; area under the receiver operating characteristic (AUROC), 0.782].   Conclusions: A machine-learning approach applied to multimodal MRI data may differentiate between the earliest clinical expressions of MS (CIS and RIS) with an accuracy of 78%.   Keywords: Bagging; Multilayer Perceptron; Naive Bayes classifier; clinically isolated syndrome; diffusion tensor imaging; machine-learning; magnetic resonance imaging; multiple sclerosis; radiologically isolated syndrome.","sentences":["Background and purpose: The unanticipated detection by magnetic resonance imaging (MRI) in the brain of asymptomatic subjects of white matter lesions suggestive of multiple sclerosis (MS) has been named radiologically isolated syndrome (RIS).","As the difference between early MS [i.e. clinically isolated syndrome (CIS)] and RIS is the occurrence of a clinical event, it is logical to improve detection of the subclinical form without interfering with MRI as there are radiological diagnostic criteria for that.","Our objective was to use machine-learning classification methods to identify morphometric measures that help to discriminate patients with RIS from those with CIS.   ","Methods: We used a multimodal 3-T MRI approach by combining MRI biomarkers (cortical thickness, cortical and subcortical grey matter volume, and white matter integrity) of a cohort of 17 patients with RIS and 17 patients with CIS for single-subject level classification.   ","Results: The best proposed models to predict the diagnosis of CIS and RIS were based on the Naive Bayes, Bagging and Multilayer Perceptron classifiers using only three features: the left rostral middle frontal gyrus volume and the fractional anisotropy values in the right amygdala and right lingual gyrus.","The Naive Bayes obtained the highest accuracy","[overall classification, 0.765; area under the receiver operating characteristic (AUROC), 0.782].   ","Conclusions: A machine-learning approach applied to multimodal MRI data may differentiate between the earliest clinical expressions of MS (CIS and RIS) with an accuracy of 78%.   ","Keywords: Bagging; Multilayer Perceptron; Naive Bayes classifier; clinically isolated syndrome; diffusion tensor imaging; machine-learning; magnetic resonance imaging; multiple sclerosis; radiologically isolated syndrome."],"url":"http://arxiv.org/abs/2401.13301v1"}
{"created":"2024-01-24 07:11:05","title":"Enhancing cross-domain detection: adaptive class-aware contrastive transformer","abstract":"Recently,the detection transformer has gained substantial attention for its inherent minimal post-processing requirement.However,this paradigm relies on abundant training data,yet in the context of the cross-domain adaptation,insufficient labels in the target domain exacerbate issues of class imbalance and model performance degradation.To address these challenges, we propose a novel class-aware cross domain detection transformer based on the adversarial learning and mean-teacher framework.First,considering the inconsistencies between the classification and regression tasks,we introduce an IoU-aware prediction branch and exploit the consistency of classification and location scores to filter and reweight pseudo labels.Second, we devise a dynamic category threshold refinement to adaptively manage model confidence.Third,to alleviate the class imbalance,an instance-level class-aware contrastive learning module is presented to encourage the generation of discriminative features for each class,particularly benefiting minority classes.Experimental results across diverse domain-adaptive scenarios validate our method's effectiveness in improving performance and alleviating class imbalance issues,which outperforms the state-of-the-art transformer based methods.","sentences":["Recently,the detection transformer has gained substantial attention for its inherent minimal post-processing requirement.","However,this paradigm relies on abundant training data,yet in the context of the cross-domain adaptation,insufficient labels in the target domain exacerbate issues of class imbalance and model performance degradation.","To address these challenges, we propose a novel class-aware cross domain detection transformer based on the adversarial learning and mean-teacher framework.","First,considering the inconsistencies between the classification and regression tasks,we introduce an IoU-aware prediction branch and exploit the consistency of classification and location scores to filter and reweight pseudo labels.","Second, we devise a dynamic category threshold refinement to adaptively manage model confidence.","Third,to alleviate the class imbalance,an instance-level class-aware contrastive learning module is presented to encourage the generation of discriminative features for each class,particularly benefiting minority classes.","Experimental results across diverse domain-adaptive scenarios validate our method's effectiveness in improving performance and alleviating class imbalance issues,which outperforms the state-of-the-art transformer based methods."],"url":"http://arxiv.org/abs/2401.13264v1"}
{"created":"2024-01-24 06:34:06","title":"A modular architecture for IMU-based data gloves","abstract":"The flexibility and range of motion in human hands play a crucial role in human interaction with the environment and have been studied across different fields. Researchers explored various technological solutions for gathering information from the hands. These solutions include tracking hand motion through cameras or wearable sensors and using wearable sensors to measure the position and pressure of contact points. Data gloves can collect both types of information by utilizing inertial measurement units, flex sensors, magnetic trackers for motion tracking, and force resistors or touch sensors for contact measurement. Although there are commercially available data gloves, researchers often create custom data gloves to achieve the desired flexibility and control over the hardware. However, the existing literature lacks standardization and the reuse of previously designed data gloves. As a result, many gloves with unclear characteristics exist, which makes replication challenging and negatively impacts the reproducibility of studies. This work proposes a modular, open hardware and software architecture for creating customized data gloves based on IMU technology. We also provide an architecture implementation along with an experimental protocol to evaluate device performance.","sentences":["The flexibility and range of motion in human hands play a crucial role in human interaction with the environment and have been studied across different fields.","Researchers explored various technological solutions for gathering information from the hands.","These solutions include tracking hand motion through cameras or wearable sensors and using wearable sensors to measure the position and pressure of contact points.","Data gloves can collect both types of information by utilizing inertial measurement units, flex sensors, magnetic trackers for motion tracking, and force resistors or touch sensors for contact measurement.","Although there are commercially available data gloves, researchers often create custom data gloves to achieve the desired flexibility and control over the hardware.","However, the existing literature lacks standardization and the reuse of previously designed data gloves.","As a result, many gloves with unclear characteristics exist, which makes replication challenging and negatively impacts the reproducibility of studies.","This work proposes a modular, open hardware and software architecture for creating customized data gloves based on IMU technology.","We also provide an architecture implementation along with an experimental protocol to evaluate device performance."],"url":"http://arxiv.org/abs/2401.13254v1"}
{"created":"2024-01-24 06:11:09","title":"A Human-Centered Review of Algorithms in Homelessness Research","abstract":"Homelessness is a humanitarian challenge affecting an estimated 1.6 billion people worldwide. In the face of rising homeless populations in developed nations and a strain on social services, government agencies are increasingly adopting data-driven models to determine one's risk of experiencing homelessness and assigning scarce resources to those in need. We conducted a systematic literature review of 57 papers to understand the evolution of these decision-making algorithms. We investigated trends in computational methods, predictor variables, and target outcomes used to develop the models using a human-centered lens and found that only 9 papers (15.7%) investigated model fairness and bias. We uncovered tensions between explainability and ecological validity wherein predictive risk models (53.4%) focused on reductive explainability while resource allocation models (25.9%) were dependent on unrealistic assumptions and simulated data that are not useful in practice. Further, we discuss research challenges and opportunities for developing human-centered algorithms in this area.","sentences":["Homelessness is a humanitarian challenge affecting an estimated 1.6 billion people worldwide.","In the face of rising homeless populations in developed nations and a strain on social services, government agencies are increasingly adopting data-driven models to determine one's risk of experiencing homelessness and assigning scarce resources to those in need.","We conducted a systematic literature review of 57 papers to understand the evolution of these decision-making algorithms.","We investigated trends in computational methods, predictor variables, and target outcomes used to develop the models using a human-centered lens and found that only 9 papers (15.7%) investigated model fairness and bias.","We uncovered tensions between explainability and ecological validity wherein predictive risk models (53.4%) focused on reductive explainability while resource allocation models (25.9%) were dependent on unrealistic assumptions and simulated data that are not useful in practice.","Further, we discuss research challenges and opportunities for developing human-centered algorithms in this area."],"url":"http://arxiv.org/abs/2401.13247v1"}
{"created":"2024-01-24 05:41:34","title":"How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning","abstract":"Federated learning (FL) has attracted vivid attention as a privacy-preserving distributed learning framework. In this work, we focus on cross-silo FL, where clients become the model owners after training and are only concerned about the model's generalization performance on their local data. Due to the data heterogeneity issue, asking all the clients to join a single FL training process may result in model performance degradation. To investigate the effectiveness of collaboration, we first derive a generalization bound for each client when collaborating with others or when training independently. We show that the generalization performance of a client can be improved only by collaborating with other clients that have more training data and similar data distribution. Our analysis allows us to formulate a client utility maximization problem by partitioning clients into multiple collaborating groups. A hierarchical clustering-based collaborative training (HCCT) scheme is then proposed, which does not need to fix in advance the number of groups. We further analyze the convergence of HCCT for general non-convex loss functions which unveils the effect of data similarity among clients. Extensive simulations show that HCCT achieves better generalization performance than baseline schemes, whereas it degenerates to independent training and conventional FL in specific scenarios.","sentences":["Federated learning (FL) has attracted vivid attention as a privacy-preserving distributed learning framework.","In this work, we focus on cross-silo FL, where clients become the model owners after training and are only concerned about the model's generalization performance on their local data.","Due to the data heterogeneity issue, asking all the clients to join a single FL training process may result in model performance degradation.","To investigate the effectiveness of collaboration, we first derive a generalization bound for each client when collaborating with others or when training independently.","We show that the generalization performance of a client can be improved only by collaborating with other clients that have more training data and similar data distribution.","Our analysis allows us to formulate a client utility maximization problem by partitioning clients into multiple collaborating groups.","A hierarchical clustering-based collaborative training (HCCT) scheme is then proposed, which does not need to fix in advance the number of groups.","We further analyze the convergence of HCCT for general non-convex loss functions which unveils the effect of data similarity among clients.","Extensive simulations show that HCCT achieves better generalization performance than baseline schemes, whereas it degenerates to independent training and conventional FL in specific scenarios."],"url":"http://arxiv.org/abs/2401.13236v1"}
{"created":"2024-01-24 04:57:32","title":"From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning","abstract":"A major challenge in Natural Language Processing is obtaining annotated data for supervised learning. An option is the use of crowdsourcing platforms for data annotation. However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases. An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts. Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data. The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets. But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model. The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data. To address these issues, this paper contributes an automatic and informed data selection architecture to build a small dataset for few-shot learning. Our proposal minimizes the quantity and maximizes diversity of data selected for human annotation, while improving model performance.","sentences":["A major challenge in Natural Language Processing is obtaining annotated data for supervised learning.","An option is the use of crowdsourcing platforms for data annotation.","However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases.","An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts.","Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data.","The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets.","But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model.","The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data.","To address these issues, this paper contributes an automatic and informed data selection architecture to build a small dataset for few-shot learning.","Our proposal minimizes the quantity and maximizes diversity of data selected for human annotation, while improving model performance."],"url":"http://arxiv.org/abs/2401.13229v1"}
{"created":"2024-01-24 04:28:50","title":"TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data","abstract":"In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required. Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities. We then consider harnessing the amazing power of LLMs to solve our task. We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods. However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task. We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-wise Pipeline. The experimental results have verified that our TAT-LLM model can outperform all baseline models, including the previous best fine-tuned models and very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks. We hope our work can serve as a pioneering example of specializing smaller language models for specific tasks.","sentences":["In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required.","Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities.","We then consider harnessing the amazing power of LLMs to solve our task.","We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods.","However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task.","We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-wise Pipeline.","The experimental results have verified that our TAT-LLM model can outperform all baseline models, including the previous best fine-tuned models and very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks.","We hope our work can serve as a pioneering example of specializing smaller language models for specific tasks."],"url":"http://arxiv.org/abs/2401.13223v1"}
{"created":"2024-01-24 03:43:45","title":"Multitask Active Learning for Graph Anomaly Detection","abstract":"In the web era, graph machine learning has been widely used on ubiquitous graph-structured data. As a pivotal component for bolstering web security and enhancing the robustness of graph-based applications, the significance of graph anomaly detection is continually increasing. While Graph Neural Networks (GNNs) have demonstrated efficacy in supervised and semi-supervised graph anomaly detection, their performance is contingent upon the availability of sufficient ground truth labels. The labor-intensive nature of identifying anomalies from complex graph structures poses a significant challenge in real-world applications. Despite that, the indirect supervision signals from other tasks (e.g., node classification) are relatively abundant. In this paper, we propose a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE. Firstly, by coupling node classification tasks, MITIGATE obtains the capability to detect out-of-distribution nodes without known anomalies. Secondly, MITIGATE quantifies the informativeness of nodes by the confidence difference across tasks, allowing samples with conflicting predictions to provide informative yet not excessively challenging information for subsequent training. Finally, to enhance the likelihood of selecting representative nodes that are distant from known patterns, MITIGATE adopts a masked aggregation mechanism for distance measurement, considering both inherent features of nodes and current labeled status. Empirical studies on four datasets demonstrate that MITIGATE significantly outperforms the state-of-the-art methods for anomaly detection. Our code is publicly available at: https://github.com/AhaChang/MITIGATE.","sentences":["In the web era, graph machine learning has been widely used on ubiquitous graph-structured data.","As a pivotal component for bolstering web security and enhancing the robustness of graph-based applications, the significance of graph anomaly detection is continually increasing.","While Graph Neural Networks (GNNs) have demonstrated efficacy in supervised and semi-supervised graph anomaly detection, their performance is contingent upon the availability of sufficient ground truth labels.","The labor-intensive nature of identifying anomalies from complex graph structures poses a significant challenge in real-world applications.","Despite that, the indirect supervision signals from other tasks (e.g., node classification) are relatively abundant.","In this paper, we propose a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE.","Firstly, by coupling node classification tasks, MITIGATE obtains the capability to detect out-of-distribution nodes without known anomalies.","Secondly, MITIGATE quantifies the informativeness of nodes by the confidence difference across tasks, allowing samples with conflicting predictions to provide informative yet not excessively challenging information for subsequent training.","Finally, to enhance the likelihood of selecting representative nodes that are distant from known patterns, MITIGATE adopts a masked aggregation mechanism for distance measurement, considering both inherent features of nodes and current labeled status.","Empirical studies on four datasets demonstrate that MITIGATE significantly outperforms the state-of-the-art methods for anomaly detection.","Our code is publicly available at: https://github.com/AhaChang/MITIGATE."],"url":"http://arxiv.org/abs/2401.13210v1"}
{"created":"2024-01-24 03:28:48","title":"Self-Improving Interference Management Based on Deep Learning With Uncertainty Quantification","abstract":"This paper presents a groundbreaking self-improving interference management framework tailored for wireless communications, integrating deep learning with uncertainty quantification to enhance overall system performance. Our approach addresses the computational challenges inherent in traditional optimization-based algorithms by harnessing deep learning models to predict optimal interference management solutions. A significant breakthrough of our framework is its acknowledgment of the limitations inherent in data-driven models, particularly in scenarios not adequately represented by the training dataset. To overcome these challenges, we propose a method for uncertainty quantification, accompanied by a qualifying criterion, to assess the trustworthiness of model predictions. This framework strategically alternates between model-generated solutions and traditional algorithms, guided by a criterion that assesses the prediction credibility based on quantified uncertainties. Experimental results validate the framework's efficacy, demonstrating its superiority over traditional deep learning models, notably in scenarios underrepresented in the training dataset. This work marks a pioneering endeavor in harnessing self-improving deep learning for interference management, through the lens of uncertainty quantification.","sentences":["This paper presents a groundbreaking self-improving interference management framework tailored for wireless communications, integrating deep learning with uncertainty quantification to enhance overall system performance.","Our approach addresses the computational challenges inherent in traditional optimization-based algorithms by harnessing deep learning models to predict optimal interference management solutions.","A significant breakthrough of our framework is its acknowledgment of the limitations inherent in data-driven models, particularly in scenarios not adequately represented by the training dataset.","To overcome these challenges, we propose a method for uncertainty quantification, accompanied by a qualifying criterion, to assess the trustworthiness of model predictions.","This framework strategically alternates between model-generated solutions and traditional algorithms, guided by a criterion that assesses the prediction credibility based on quantified uncertainties.","Experimental results validate the framework's efficacy, demonstrating its superiority over traditional deep learning models, notably in scenarios underrepresented in the training dataset.","This work marks a pioneering endeavor in harnessing self-improving deep learning for interference management, through the lens of uncertainty quantification."],"url":"http://arxiv.org/abs/2401.13206v1"}
{"created":"2024-01-24 03:08:30","title":"PAC Learnability for Reliable Communication over Discrete Memoryless Channels","abstract":"In practical communication systems, knowledge of channel models is often absent, and consequently, transceivers need be designed based on empirical data. In this work, we study data-driven approaches to reliably choosing decoding metrics and code rates that facilitate reliable communication over unknown discrete memoryless channels (DMCs). Our analysis is inspired by the PAC learning theory and does not rely on any assumptions on the statistical characteristics of DMCs. We show that a naive plug-in algorithm for choosing decoding metrics is likely to fail for finite training sets. We propose an alternative algorithm called the virtual sample algorithm and establish a non-asymptotic lower bound on its performance. The virtual sample algorithm is then used as a building block for constructing a learning algorithm that chooses a decoding metric and a code rate using which a transmitter and a receiver can reliably communicate at a rate arbitrarily close to the channel mutual information. Therefore, we conclude that DMCs are PAC learnable.","sentences":["In practical communication systems, knowledge of channel models is often absent, and consequently, transceivers need be designed based on empirical data.","In this work, we study data-driven approaches to reliably choosing decoding metrics and code rates that facilitate reliable communication over unknown discrete memoryless channels (DMCs).","Our analysis is inspired by the PAC learning theory and does not rely on any assumptions on the statistical characteristics of DMCs.","We show that a naive plug-in algorithm for choosing decoding metrics is likely to fail for finite training sets.","We propose an alternative algorithm called the virtual sample algorithm and establish a non-asymptotic lower bound on its performance.","The virtual sample algorithm is then used as a building block for constructing a learning algorithm that chooses a decoding metric and a code rate using which a transmitter and a receiver can reliably communicate at a rate arbitrarily close to the channel mutual information.","Therefore, we conclude that DMCs are PAC learnable."],"url":"http://arxiv.org/abs/2401.13202v1"}
{"created":"2024-01-24 03:03:17","title":"Topology-aware Embedding Memory for Learning on Expanding Graphs","abstract":"Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data. Directly applying them to continually expanding graphs, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures. To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed framework not only reduces the memory space complexity from $\\mathcal{O}(nd^L)$ to $\\mathcal{O}(n)$~\\footnote{$n$: memory budget, $d$: average node degree, $L$: the radius of the GNN receptive field}, but also fully utilizes the topological information for memory replay. Specifically, PDGNNs decouple trainable parameters from the computation ego-subgraph via \\textit{Topology-aware Embeddings} (TEs), which compress ego-subgraphs into compact vectors (i.e., TEs) to reduce the memory consumption. Based on this framework, we discover a unique \\textit{pseudo-training effect} in continual learning on expanding graphs and this effect motivates us to develop a novel \\textit{coverage maximization sampling} strategy that can enhance the performance with a tight memory budget. Thorough empirical studies demonstrate that, by tackling the memory explosion problem and incorporating topological information into memory replay, PDGNNs with TEM significantly outperform state-of-the-art techniques, especially in the challenging class-incremental setting.","sentences":["Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data.","Directly applying them to continually expanding graphs, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures.","To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue.","The proposed framework not only reduces the memory space complexity from $\\mathcal{O}(nd^L)$ to $\\mathcal{O}(n)$~\\footnote{$n$: memory budget, $d$: average node degree, $L$: the radius of the GNN receptive field}, but also fully utilizes the topological information for memory replay.","Specifically, PDGNNs decouple trainable parameters from the computation ego-subgraph via \\textit{Topology-aware Embeddings} (TEs), which compress ego-subgraphs into compact vectors (i.e., TEs) to reduce the memory consumption.","Based on this framework, we discover a unique \\textit{pseudo-training effect} in continual learning on expanding graphs and this effect motivates us to develop a novel \\textit{coverage maximization sampling} strategy that can enhance the performance with a tight memory budget.","Thorough empirical studies demonstrate that, by tackling the memory explosion problem and incorporating topological information into memory replay, PDGNNs with TEM significantly outperform state-of-the-art techniques, especially in the challenging class-incremental setting."],"url":"http://arxiv.org/abs/2401.13200v1"}
{"created":"2024-01-24 03:00:49","title":"Why People Still Fall for Phishing Emails: An Empirical Investigation into How Users Make Email Response Decisions","abstract":"Despite technical and non-technical countermeasures, humans continue to be tricked by phishing emails. How users make email response decisions is a missing piece in the puzzle to identifying why people still fall for phishing emails. We conducted an empirical study using a think-aloud method to investigate how people make 'response decisions' while reading emails. The grounded theory analysis of the in-depth qualitative data has enabled us to identify different elements of email users' decision-making that influence their email response decisions. Furthermore, we developed a theoretical model that explains how people could be driven to respond to emails based on the identified elements of users' email decision-making processes and the relationships uncovered from the data. The findings provide deeper insights into phishing email susceptibility due to people's email response decision-making behavior. We also discuss the implications of our findings for designers and researchers working in anti-phishing training, education, and awareness interventions","sentences":["Despite technical and non-technical countermeasures, humans continue to be tricked by phishing emails.","How users make email response decisions is a missing piece in the puzzle to identifying why people still fall for phishing emails.","We conducted an empirical study using a think-aloud method to investigate how people make 'response decisions' while reading emails.","The grounded theory analysis of the in-depth qualitative data has enabled us to identify different elements of email users' decision-making that influence their email response decisions.","Furthermore, we developed a theoretical model that explains how people could be driven to respond to emails based on the identified elements of users' email decision-making processes and the relationships uncovered from the data.","The findings provide deeper insights into phishing email susceptibility due to people's email response decision-making behavior.","We also discuss the implications of our findings for designers and researchers working in anti-phishing training, education, and awareness interventions"],"url":"http://arxiv.org/abs/2401.13199v1"}
{"created":"2024-01-24 02:42:50","title":"Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN","abstract":"Deep learning has made significant advances in computer vision, particularly in image classification tasks. Despite their high accuracy on training data, deep learning models often face challenges related to complexity and overfitting. One notable concern is that the model often relies heavily on a limited subset of filters for making predictions. This dependency can result in compromised generalization and an increased vulnerability to minor variations. While regularization techniques like weight decay, dropout, and data augmentation are commonly used to address this issue, they may not directly tackle the reliance on specific filters. Our observations reveal that the heavy reliance problem gets severe when slow-learning filters are deprived of learning opportunities due to fast-learning filters. Drawing inspiration from image augmentation research that combats over-reliance on specific image regions by removing and replacing parts of images, our idea is to mitigate the problem of over-reliance on strong filters by substituting highly activated features. To this end, we present a novel method called Catch-up Mix, which provides learning opportunities to a wide range of filters during training, focusing on filters that may lag behind. By mixing activation maps with relatively lower norms, Catch-up Mix promotes the development of more diverse representations and reduces reliance on a small subset of filters. Experimental results demonstrate the superiority of our method in various vision classification datasets, providing enhanced robustness.","sentences":["Deep learning has made significant advances in computer vision, particularly in image classification tasks.","Despite their high accuracy on training data, deep learning models often face challenges related to complexity and overfitting.","One notable concern is that the model often relies heavily on a limited subset of filters for making predictions.","This dependency can result in compromised generalization and an increased vulnerability to minor variations.","While regularization techniques like weight decay, dropout, and data augmentation are commonly used to address this issue, they may not directly tackle the reliance on specific filters.","Our observations reveal that the heavy reliance problem gets severe when slow-learning filters are deprived of learning opportunities due to fast-learning filters.","Drawing inspiration from image augmentation research that combats over-reliance on specific image regions by removing and replacing parts of images, our idea is to mitigate the problem of over-reliance on strong filters by substituting highly activated features.","To this end, we present a novel method called Catch-up Mix, which provides learning opportunities to a wide range of filters during training, focusing on filters that may lag behind.","By mixing activation maps with relatively lower norms, Catch-up Mix promotes the development of more diverse representations and reduces reliance on a small subset of filters.","Experimental results demonstrate the superiority of our method in various vision classification datasets, providing enhanced robustness."],"url":"http://arxiv.org/abs/2401.13193v1"}
{"created":"2024-01-24 02:35:32","title":"Towards Multi-domain Face Landmark Detection with Synthetic Data from Diffusion model","abstract":"Recently, deep learning-based facial landmark detection for in-the-wild faces has achieved significant improvement. However, there are still challenges in face landmark detection in other domains (e.g. cartoon, caricature, etc). This is due to the scarcity of extensively annotated training data. To tackle this concern, we design a two-stage training approach that effectively leverages limited datasets and the pre-trained diffusion model to obtain aligned pairs of landmarks and face in multiple domains. In the first stage, we train a landmark-conditioned face generation model on a large dataset of real faces. In the second stage, we fine-tune the above model on a small dataset of image-landmark pairs with text prompts for controlling the domain. Our new designs enable our method to generate high-quality synthetic paired datasets from multiple domains while preserving the alignment between landmarks and facial features. Finally, we fine-tuned a pre-trained face landmark detection model on the synthetic dataset to achieve multi-domain face landmark detection. Our qualitative and quantitative results demonstrate that our method outperforms existing methods on multi-domain face landmark detection.","sentences":["Recently, deep learning-based facial landmark detection for in-the-wild faces has achieved significant improvement.","However, there are still challenges in face landmark detection in other domains (e.g. cartoon, caricature, etc).","This is due to the scarcity of extensively annotated training data.","To tackle this concern, we design a two-stage training approach that effectively leverages limited datasets and the pre-trained diffusion model to obtain aligned pairs of landmarks and face in multiple domains.","In the first stage, we train a landmark-conditioned face generation model on a large dataset of real faces.","In the second stage, we fine-tune the above model on a small dataset of image-landmark pairs with text prompts for controlling the domain.","Our new designs enable our method to generate high-quality synthetic paired datasets from multiple domains while preserving the alignment between landmarks and facial features.","Finally, we fine-tuned a pre-trained face landmark detection model on the synthetic dataset to achieve multi-domain face landmark detection.","Our qualitative and quantitative results demonstrate that our method outperforms existing methods on multi-domain face landmark detection."],"url":"http://arxiv.org/abs/2401.13191v1"}
{"created":"2024-01-24 02:16:03","title":"Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set $\\mathbf{X}^\\mathbf{T}\\mathbf{X}$ and $\\mathbf{X}^\\mathbf{T}\\mathbf{Y}$ Without Full Recomputation of Matrix Products or Statistical Moments","abstract":"Cross-validation is a widely used technique for assessing the performance of predictive models on unseen data. Many predictive models, such as Kernel-Based Partial Least-Squares (PLS) models, require the computation of $\\mathbf{X}^{\\mathbf{T}}\\mathbf{X}$ and $\\mathbf{X}^{\\mathbf{T}}\\mathbf{Y}$ using only training set samples from the input and output matrices, $\\mathbf{X}$ and $\\mathbf{Y}$, respectively. In this work, we present three algorithms that efficiently compute these matrices. The first one allows no column-wise preprocessing. The second one allows column-wise centering around the training set means. The third one allows column-wise centering and column-wise scaling around the training set means and standard deviations. Demonstrating correctness and superior computational complexity, they offer significant cross-validation speedup compared with straight-forward cross-validation and previous work on fast cross-validation - all without data leakage. Their suitability for parallelization is highlighted with an open-source Python implementation combining our algorithms with Improved Kernel PLS.","sentences":["Cross-validation is a widely used technique for assessing the performance of predictive models on unseen data.","Many predictive models, such as Kernel-Based Partial Least-Squares (PLS) models, require the computation of $\\mathbf{X}^{\\mathbf{T}}\\mathbf{X}$ and $\\mathbf{X}^{\\mathbf{T}}\\mathbf{Y}$ using only training set samples from the input and output matrices, $\\mathbf{X}$ and $\\mathbf{Y}$, respectively.","In this work, we present three algorithms that efficiently compute these matrices.","The first one allows no column-wise preprocessing.","The second one allows column-wise centering around the training set means.","The third one allows column-wise centering and column-wise scaling around the training set means and standard deviations.","Demonstrating correctness and superior computational complexity, they offer significant cross-validation speedup compared with straight-forward cross-validation and previous work on fast cross-validation - all without data leakage.","Their suitability for parallelization is highlighted with an open-source Python implementation combining our algorithms with Improved Kernel PLS."],"url":"http://arxiv.org/abs/2401.13185v1"}
{"created":"2024-01-24 01:33:39","title":"Compositional Generative Inverse Design","abstract":"Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learned diffusion model at test time, our method allows us to design initial states and boundary shapes that are more complex than those in the training data. Our method outperforms state-of-the-art neural inverse design method by an average of 41.5% in prediction MAE and 14.3% in design objective for the N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task. Project website and code can be found at https://github.com/AI4Science-WestlakeU/cindm.","sentences":["Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering.","Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models.","However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling.","We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance.","We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component.","In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learned diffusion model at test time, our method allows us to design initial states and boundary shapes that are more complex than those in the training data.","Our method outperforms state-of-the-art neural inverse design method by an average of 41.5% in prediction MAE and 14.3% in design objective for the N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task.","Project website and code can be found at https://github.com/AI4Science-WestlakeU/cindm."],"url":"http://arxiv.org/abs/2401.13171v1"}
{"created":"2024-01-24 01:30:25","title":"CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering","abstract":"Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive. We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests. We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evaluate answer correctness in accordance with adopted expert AE rules that are more aligned with human judgments.","sentences":["Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM).","There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive.","We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests.","We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evaluate answer correctness in accordance with adopted expert AE rules that are more aligned with human judgments."],"url":"http://arxiv.org/abs/2401.13170v1"}
{"created":"2024-01-24 01:27:48","title":"A Repository-Level Dataset For Detecting, Classifying and Repairing Software Vulnerabilities","abstract":"Open-Source Software (OSS) vulnerabilities bring great challenges to the software security and pose potential risks to our society. Enormous efforts have been devoted into automated vulnerability detection, among which deep learning (DL)-based approaches have proven to be the most effective. However, the current labeled data present the following limitations: (1) \\textbf{Tangled Patches}: Developers may submit code changes unrelated to vulnerability fixes within patches, leading to tangled patches. (2) \\textbf{Lacking Inter-procedural Vulnerabilities}: The existing vulnerability datasets typically contain function-level and file-level vulnerabilities, ignoring the relations between functions, thus rendering the approaches unable to detect the inter-procedural vulnerabilities. (3) \\textbf{Outdated Patches}: The existing datasets usually contain outdated patches, which may bias the model during training.   To address the above limitations, in this paper, we propose an automated data collection framework and construct the first repository-level high-quality vulnerability dataset named \\textbf{ReposVul}. The proposed framework mainly contains three modules: (1) A vulnerability untangling module, aiming at distinguishing vulnerability-fixing related code changes from tangled patches, in which the Large Language Models (LLMs) and static analysis tools are jointly employed. (2) A multi-granularity dependency extraction module, aiming at capturing the inter-procedural call relationships of vulnerabilities, in which we construct multiple-granularity information for each vulnerability patch, including repository-level, file-level, function-level, and line-level. (3) A trace-based filtering module, aiming at filtering the outdated patches, which leverages the file path trace-based filter and commit time trace-based filter to construct an up-to-date dataset.","sentences":["Open-Source Software (OSS) vulnerabilities bring great challenges to the software security and pose potential risks to our society.","Enormous efforts have been devoted into automated vulnerability detection, among which deep learning (DL)-based approaches have proven to be the most effective.","However, the current labeled data present the following limitations: (1) \\textbf{Tangled Patches}: Developers may submit code changes unrelated to vulnerability fixes within patches, leading to tangled patches.","(2) \\textbf{Lacking Inter-procedural Vulnerabilities}: The existing vulnerability datasets typically contain function-level and file-level vulnerabilities, ignoring the relations between functions, thus rendering the approaches unable to detect the inter-procedural vulnerabilities.","(3) \\textbf{Outdated Patches}: The existing datasets usually contain outdated patches, which may bias the model during training.   ","To address the above limitations, in this paper, we propose an automated data collection framework and construct the first repository-level high-quality vulnerability dataset named \\textbf{ReposVul}.","The proposed framework mainly contains three modules: (1) A vulnerability untangling module, aiming at distinguishing vulnerability-fixing related code changes from tangled patches, in which the Large Language Models (LLMs) and static analysis tools are jointly employed.","(2) A multi-granularity dependency extraction module, aiming at capturing the inter-procedural call relationships of vulnerabilities, in which we construct multiple-granularity information for each vulnerability patch, including repository-level, file-level, function-level, and line-level.","(3) A trace-based filtering module, aiming at filtering the outdated patches, which leverages the file path trace-based filter and commit time trace-based filter to construct an up-to-date dataset."],"url":"http://arxiv.org/abs/2401.13169v1"}
{"created":"2024-01-24 00:33:53","title":"Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence","abstract":"Learning time-evolving objects such as multivariate time series and dynamic networks requires the development of novel knowledge representation mechanisms and neural network architectures, which allow for capturing implicit time-dependent information contained in the data. Such information is typically not directly observed but plays a key role in the learning task performance. In turn, lack of time dimension in knowledge encoding mechanisms for time-dependent data leads to frequent model updates, poor learning performance, and, as a result, subpar decision-making. Here we propose a new approach to a time-aware knowledge representation mechanism that notably focuses on implicit time-dependent topological information along multiple geometric dimensions. In particular, we propose a new approach, named \\textit{Temporal MultiPersistence} (TMP), which produces multidimensional topological fingerprints of the data by using the existing single parameter topological summaries. The main idea behind TMP is to merge the two newest directions in topological representation learning, that is, multi-persistence which simultaneously describes data shape evolution along multiple key parameters, and zigzag persistence to enable us to extract the most salient data shape information over time. We derive theoretical guarantees of TMP vectorizations and show its utility, in application to forecasting on benchmark traffic flow, Ethereum blockchain, and electrocardiogram datasets, demonstrating the competitive performance, especially, in scenarios of limited data records. In addition, our TMP method improves the computational efficiency of the state-of-the-art multipersistence summaries up to 59.5 times.","sentences":["Learning time-evolving objects such as multivariate time series and dynamic networks requires the development of novel knowledge representation mechanisms and neural network architectures, which allow for capturing implicit time-dependent information contained in the data.","Such information is typically not directly observed but plays a key role in the learning task performance.","In turn, lack of time dimension in knowledge encoding mechanisms for time-dependent data leads to frequent model updates, poor learning performance, and, as a result, subpar decision-making.","Here we propose a new approach to a time-aware knowledge representation mechanism that notably focuses on implicit time-dependent topological information along multiple geometric dimensions.","In particular, we propose a new approach, named \\textit{Temporal MultiPersistence} (TMP), which produces multidimensional topological fingerprints of the data by using the existing single parameter topological summaries.","The main idea behind TMP is to merge the two newest directions in topological representation learning, that is, multi-persistence which simultaneously describes data shape evolution along multiple key parameters, and zigzag persistence to enable us to extract the most salient data shape information over time.","We derive theoretical guarantees of TMP vectorizations and show its utility, in application to forecasting on benchmark traffic flow, Ethereum blockchain, and electrocardiogram datasets, demonstrating the competitive performance, especially, in scenarios of limited data records.","In addition, our TMP method improves the computational efficiency of the state-of-the-art multipersistence summaries up to 59.5 times."],"url":"http://arxiv.org/abs/2401.13157v1"}
{"created":"2024-01-24 00:19:19","title":"MATRYOSHKA: Non-Exclusive Memory Tiering via Transactional Page Migration","abstract":"With the advent of byte-addressable memory devices, such as CXL memory, persistent memory, and storage-class memory, tiered memory systems have become a reality. Page migration is the de facto method within operating systems for managing tiered memory. It aims to bring hot data whenever possible into fast memory to optimize the performance of data accesses while using slow memory to accommodate data spilled from fast memory. While the existing research has demonstrated the effectiveness of various optimizations on page migration, it falls short of addressing a fundamental question: Is exclusive memory tiering, in which a page is either present in fast memory or slow memory, but not both simultaneously, the optimal strategy for tiered memory management?   We demonstrate that page migration-based exclusive memory tiering suffers significant performance degradation when fast memory is under pressure. In this paper, we propose non-exclusive memory tiering, a page management strategy that retains a copy of pages recently promoted from slow memory to fast memory to mitigate memory thrashing. To enable non-exclusive memory tiering, we develop MATRYOSHKA, a new mechanism that features transactional page migration and page shadowing. MATRYOSHKA removes page migration off the program's critical path and makes migration asynchronous. Evaluations with microbenchmarks and realworld applications show that MATRYOSHKA achieves 6x performance improvement over the state-of-the-art transparent page placement (TPP) approach under memory pressure. We also compare MATRYOSHKA with a recently proposed sampling-based migration approach and demonstrate MATRYOSHKA's strengths and potential weaknesses in various scenarios. Through the evaluations, we discover a serious issue facing all tested approaches, unfortunately including MATRYOSHKA, and call for further research on tiered memory-aware memory allocation.","sentences":["With the advent of byte-addressable memory devices, such as CXL memory, persistent memory, and storage-class memory, tiered memory systems have become a reality.","Page migration is the de facto method within operating systems for managing tiered memory.","It aims to bring hot data whenever possible into fast memory to optimize the performance of data accesses while using slow memory to accommodate data spilled from fast memory.","While the existing research has demonstrated the effectiveness of various optimizations on page migration, it falls short of addressing a fundamental question: Is exclusive memory tiering, in which a page is either present in fast memory or slow memory, but not both simultaneously, the optimal strategy for tiered memory management?   ","We demonstrate that page migration-based exclusive memory tiering suffers significant performance degradation when fast memory is under pressure.","In this paper, we propose non-exclusive memory tiering, a page management strategy that retains a copy of pages recently promoted from slow memory to fast memory to mitigate memory thrashing.","To enable non-exclusive memory tiering, we develop MATRYOSHKA, a new mechanism that features transactional page migration and page shadowing.","MATRYOSHKA removes page migration off the program's critical path and makes migration asynchronous.","Evaluations with microbenchmarks and realworld applications show that MATRYOSHKA achieves 6x performance improvement over the state-of-the-art transparent page placement (TPP) approach under memory pressure.","We also compare MATRYOSHKA with a recently proposed sampling-based migration approach and demonstrate MATRYOSHKA's strengths and potential weaknesses in various scenarios.","Through the evaluations, we discover a serious issue facing all tested approaches, unfortunately including MATRYOSHKA, and call for further research on tiered memory-aware memory allocation."],"url":"http://arxiv.org/abs/2401.13154v1"}
{"created":"2024-01-23 23:52:48","title":"Automated Programmatic Performance Analysis of Parallel Programs","abstract":"Developing efficient parallel applications is critical to advancing scientific development but requires significant performance analysis and optimization. Performance analysis tools help developers manage the increasing complexity and scale of performance data, but often rely on the user to manually explore low-level data and are rigid in how the data can be manipulated. We propose a Python-based API, Chopper, which provides high-level and flexible performance analysis for both single and multiple executions of parallel applications. Chopper facilitates performance analysis and reduces developer effort by providing configurable high-level methods for common performance analysis tasks such as calculating load imbalance, hot paths, scalability bottlenecks, correlation between metrics and CCT nodes, and causes of performance variability within a robust and mature Python environment that provides fluid access to lower-level data manipulations. We demonstrate how Chopper allows developers to quickly and succinctly explore performance and identify issues across applications such as AMG, Laghos, LULESH, Quicksilver and Tortuga.","sentences":["Developing efficient parallel applications is critical to advancing scientific development but requires significant performance analysis and optimization.","Performance analysis tools help developers manage the increasing complexity and scale of performance data, but often rely on the user to manually explore low-level data and are rigid in how the data can be manipulated.","We propose a Python-based API, Chopper, which provides high-level and flexible performance analysis for both single and multiple executions of parallel applications.","Chopper facilitates performance analysis and reduces developer effort by providing configurable high-level methods for common performance analysis tasks such as calculating load imbalance, hot paths, scalability bottlenecks, correlation between metrics and CCT nodes, and causes of performance variability within a robust and mature Python environment that provides fluid access to lower-level data manipulations.","We demonstrate how Chopper allows developers to quickly and succinctly explore performance and identify issues across applications such as AMG, Laghos, LULESH, Quicksilver and Tortuga."],"url":"http://arxiv.org/abs/2401.13150v1"}
{"created":"2024-01-23 22:36:03","title":"Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains","abstract":"Accurately typing entity mentions from text segments is a fundamental task for various natural language processing applications. Many previous approaches rely on massive human-annotated data to perform entity typing. Nevertheless, collecting such data in highly specialized science and engineering domains (e.g., software engineering and security) can be time-consuming and costly, without mentioning the domain gaps between training and inference data if the model needs to be applied to confidential datasets. In this paper, we study the task of seed-guided fine-grained entity typing in science and engineering domains, which takes the name and a few seed entities for each entity type as the only supervision and aims to classify new entity mentions into both seen and unseen types (i.e., those without seed entities). To solve this problem, we propose SEType which first enriches the weak supervision by finding more entities for each seen type from an unlabeled corpus using the contextualized representations of pre-trained language models. It then matches the enriched entities to unlabeled text to get pseudo-labeled samples and trains a textual entailment model that can make inferences for both seen and unseen types. Extensive experiments on two datasets covering four domains demonstrate the effectiveness of SEType in comparison with various baselines.","sentences":["Accurately typing entity mentions from text segments is a fundamental task for various natural language processing applications.","Many previous approaches rely on massive human-annotated data to perform entity typing.","Nevertheless, collecting such data in highly specialized science and engineering domains (e.g., software engineering and security) can be time-consuming and costly, without mentioning the domain gaps between training and inference data if the model needs to be applied to confidential datasets.","In this paper, we study the task of seed-guided fine-grained entity typing in science and engineering domains, which takes the name and a few seed entities for each entity type as the only supervision and aims to classify new entity mentions into both seen and unseen types (i.e., those without seed entities).","To solve this problem, we propose SEType which first enriches the weak supervision by finding more entities for each seen type from an unlabeled corpus using the contextualized representations of pre-trained language models.","It then matches the enriched entities to unlabeled text to get pseudo-labeled samples and trains a textual entailment model that can make inferences for both seen and unseen types.","Extensive experiments on two datasets covering four domains demonstrate the effectiveness of SEType in comparison with various baselines."],"url":"http://arxiv.org/abs/2401.13129v1"}
{"created":"2024-01-23 21:48:52","title":"DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport","abstract":"Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorithm is accompanied by an analysis of its convergence rate. The efficacy of our proposed method is substantiated through a series of illustrative case studies, highlighting its potential in providing deep insights into decision-making models.","sentences":["Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes.","This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE).","In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions.","We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence.","Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions.","This algorithm is accompanied by an analysis of its convergence rate.","The efficacy of our proposed method is substantiated through a series of illustrative case studies, highlighting its potential in providing deep insights into decision-making models."],"url":"http://arxiv.org/abs/2401.13112v1"}
{"created":"2024-01-23 21:42:41","title":"Development of a Causal Model for Improving Rural Seniors' Accessibility: Data Evidences","abstract":"Seniors residing in rural areas often encounter limited accessibility to opportunities, resources, and services. This paper introduces a model proposing that both aging and rural residency are factors contributing to the restricted accessibility faced by rural seniors. Leveraging data from the 2017 National Household Travel Survey, the study examines three hypotheses pertaining to this causal model. Multiple causal pathways emerge in the data analysis, with mobility identified as a mediator in one of them. The study further identifies specific challenges faced by rural seniors, such as the reduced accessibility in reaching medical services and assisting others. These challenges stem primarily from aging and geographic obstacles that not only diminish their willingness to travel but also restrict more in the group from choosing transportation modes with higher mobility. The insights gained from this study serve as a foundation for devising effective methods to enhance transportation accessibility for seniors in rural areas.","sentences":["Seniors residing in rural areas often encounter limited accessibility to opportunities, resources, and services.","This paper introduces a model proposing that both aging and rural residency are factors contributing to the restricted accessibility faced by rural seniors.","Leveraging data from the 2017 National Household Travel Survey, the study examines three hypotheses pertaining to this causal model.","Multiple causal pathways emerge in the data analysis, with mobility identified as a mediator in one of them.","The study further identifies specific challenges faced by rural seniors, such as the reduced accessibility in reaching medical services and assisting others.","These challenges stem primarily from aging and geographic obstacles that not only diminish their willingness to travel but also restrict more in the group from choosing transportation modes with higher mobility.","The insights gained from this study serve as a foundation for devising effective methods to enhance transportation accessibility for seniors in rural areas."],"url":"http://arxiv.org/abs/2401.13107v1"}
{"created":"2024-01-23 21:23:51","title":"Sparse identification of nonlinear dynamics in the presence of library and system uncertainty","abstract":"The SINDy algorithm has been successfully used to identify the governing equations of dynamical systems from time series data. However, SINDy assumes the user has prior knowledge of the variables in the system and of a function library that can act as a basis for the system. In this paper, we demonstrate on real world data how the Augmented SINDy algorithm outperforms SINDy in the presence of system variable uncertainty. We then show SINDy can be further augmented to perform robustly when both kinds of uncertainty are present.","sentences":["The SINDy algorithm has been successfully used to identify the governing equations of dynamical systems from time series data.","However, SINDy assumes the user has prior knowledge of the variables in the system and of a function library that can act as a basis for the system.","In this paper, we demonstrate on real world data how the Augmented SINDy algorithm outperforms SINDy in the presence of system variable uncertainty.","We then show SINDy can be further augmented to perform robustly when both kinds of uncertainty are present."],"url":"http://arxiv.org/abs/2401.13099v1"}
{"created":"2024-01-23 21:22:51","title":"Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge","abstract":"Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for assessing the invasion threat level given a pair of origin and destination. Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% segmentation accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of invasive species risk assessment. It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways. Besides, our model is versatile and can include new data sources, making it suitable for assessing species invasion risks in a changing global landscape.","sentences":["Invasive species in water bodies pose a major threat to the environment and biodiversity globally.","Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries.","Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions.","This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks.","Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs.","Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for assessing the invasion threat level given a pair of origin and destination.","Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible.","Thus, we introduce a physics-inspired framework that achieves an 89% segmentation accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model.","Along these lines, this research contributes to a better understanding of invasive species risk assessment.","It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways.","Besides, our model is versatile and can include new data sources, making it suitable for assessing species invasion risks in a changing global landscape."],"url":"http://arxiv.org/abs/2401.13098v1"}
{"created":"2024-01-23 21:22:06","title":"Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems","abstract":"Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences. We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings. We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance. Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in images from homes with lower socioeconomic status (SES). This trend is consistent across two datasets of international images and within the diverse economic and racial landscapes of the United States. This research contributes to understanding biases in computer vision, emphasizing the need for more inclusive and representative training datasets. By mitigating the bias in the computer vision pipelines, we can ensure fairer and more equitable outcomes for applied computer vision, including home valuation and smart home security systems. There is urgency in addressing these biases, which can significantly impact critical decisions in urban development and resource allocation. Our findings also motivate the development of AI systems that better understand and serve diverse communities, moving towards technology that equitably benefits all sectors of society.","sentences":["Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences.","We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings.","We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance.","Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in images from homes with lower socioeconomic status (SES).","This trend is consistent across two datasets of international images and within the diverse economic and racial landscapes of the United States.","This research contributes to understanding biases in computer vision, emphasizing the need for more inclusive and representative training datasets.","By mitigating the bias in the computer vision pipelines, we can ensure fairer and more equitable outcomes for applied computer vision, including home valuation and smart home security systems.","There is urgency in addressing these biases, which can significantly impact critical decisions in urban development and resource allocation.","Our findings also motivate the development of AI systems that better understand and serve diverse communities, moving towards technology that equitably benefits all sectors of society."],"url":"http://arxiv.org/abs/2401.13097v1"}
{"created":"2024-01-23 20:56:16","title":"Open-source data pipeline for street-view images: a case study on community mobility during COVID-19 pandemic","abstract":"Street View Images (SVI) are a common source of valuable data for researchers. Researchers have used SVI data for estimating pedestrian volumes, demographic surveillance, and to better understand built and natural environments in cityscapes. However, the most common source of publicly available SVI data is Google Street View. Google Street View images are collected infrequently, making temporal analysis challenging, especially in low population density areas. Our main contribution is the development of an open-source data pipeline for processing 360-degree video recorded from a car-mounted camera. The video data is used to generate SVIs, which then can be used as an input for temporal analysis. We demonstrate the use of the pipeline by collecting a SVI dataset over a 38-month longitudinal survey of Seattle, WA, USA during the COVID-19 pandemic. The output of our pipeline is validated through statistical analyses of pedestrian traffic in the images. We confirm known results in the literature and provide new insights into outdoor pedestrian traffic patterns. This study demonstrates the feasibility and value of collecting and using SVI for research purposes beyond what is possible with currently available SVI data. Limitations and future improvements on the data pipeline and case study are also discussed.","sentences":["Street View Images (SVI) are a common source of valuable data for researchers.","Researchers have used SVI data for estimating pedestrian volumes, demographic surveillance, and to better understand built and natural environments in cityscapes.","However, the most common source of publicly available SVI data is Google Street View.","Google Street View images are collected infrequently, making temporal analysis challenging, especially in low population density areas.","Our main contribution is the development of an open-source data pipeline for processing 360-degree video recorded from a car-mounted camera.","The video data is used to generate SVIs, which then can be used as an input for temporal analysis.","We demonstrate the use of the pipeline by collecting a SVI dataset over a 38-month longitudinal survey of Seattle, WA, USA during the COVID-19 pandemic.","The output of our pipeline is validated through statistical analyses of pedestrian traffic in the images.","We confirm known results in the literature and provide new insights into outdoor pedestrian traffic patterns.","This study demonstrates the feasibility and value of collecting and using SVI for research purposes beyond what is possible with currently available SVI data.","Limitations and future improvements on the data pipeline and case study are also discussed."],"url":"http://arxiv.org/abs/2401.13087v1"}
{"created":"2024-01-23 20:55:49","title":"Towards Trustable Language Models: Investigating Information Quality of Large Language Models","abstract":"Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.","sentences":["Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data.","Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality.","Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM.","Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information.","Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity.","In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models."],"url":"http://arxiv.org/abs/2401.13086v1"}
{"created":"2024-01-23 20:54:40","title":"IndiText Boost: Text Augmentation for Low Resource India Languages","abstract":"Text Augmentation is an important task for low-resource languages. It helps deal with the problem of data scarcity. A data augmentation strategy is used to deal with the problem of data scarcity. Through the years, much work has been done on data augmentation for the English language. In contrast, very less work has been done on Indian languages. This is contrary to the fact that data augmentation is used to deal with data scarcity. In this work, we focus on implementing techniques like Easy Data Augmentation, Back Translation, Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for text classification on different languages. We focus on 6 Indian languages namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to our knowledge, no such work exists for text augmentation on Indian languages. We carry out binary as well as multi-class text classification to make our results more comparable. We get surprising results as basic data augmentation techniques surpass LLMs.","sentences":["Text Augmentation is an important task for low-resource languages.","It helps deal with the problem of data scarcity.","A data augmentation strategy is used to deal with the problem of data scarcity.","Through the years, much work has been done on data augmentation for the English language.","In contrast, very less work has been done on Indian languages.","This is contrary to the fact that data augmentation is used to deal with data scarcity.","In this work, we focus on implementing techniques like Easy Data Augmentation, Back Translation, Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for text classification on different languages.","We focus on 6 Indian languages namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit.","According to our knowledge, no such work exists for text augmentation on Indian languages.","We carry out binary as well as multi-class text classification to make our results more comparable.","We get surprising results as basic data augmentation techniques surpass LLMs."],"url":"http://arxiv.org/abs/2401.13085v1"}
{"created":"2024-01-23 19:32:54","title":"TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur'anic QA","abstract":"In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks A and B. To address the challenge of low-resourced training data, we rely on transfer learning together with a voting ensemble to improve prediction stability across multiple runs. Additionally, we employ different architectures and learning mechanisms for a range of Arabic pre-trained transformer-based models for both tasks. To identify unanswerable questions, we propose using a thresholding mechanism. Our top-performing systems greatly surpass the baseline performance on the hidden split, achieving a MAP score of 25.05% for task A and a partial Average Precision (pAP) of 57.11% for task B.","sentences":["In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks A and B.","To address the challenge of low-resourced training data, we rely on transfer learning together with a voting ensemble to improve prediction stability across multiple runs.","Additionally, we employ different architectures and learning mechanisms for a range of Arabic pre-trained transformer-based models for both tasks.","To identify unanswerable questions, we propose using a thresholding mechanism.","Our top-performing systems greatly surpass the baseline performance on the hidden split, achieving a MAP score of 25.05% for task A and a partial Average Precision (pAP) of 57.11% for task B."],"url":"http://arxiv.org/abs/2401.13060v1"}
{"created":"2024-01-23 19:24:41","title":"Data Exchange Markets via Utility Balancing","abstract":"This paper explores the design of a balanced data-sharing marketplace for entities with heterogeneous datasets and machine learning models that they seek to refine using data from other agents. The goal of the marketplace is to encourage participation for data sharing in the presence of such heterogeneity. Our market design approach for data sharing focuses on interim utility balance, where participants contribute and receive equitable utility from refinement of their models. We present such a market model for which we study computational complexity, solution existence, and approximation algorithms for welfare maximization and core stability. We finally support our theoretical insights with simulations on a mean estimation task inspired by road traffic delay estimation.","sentences":["This paper explores the design of a balanced data-sharing marketplace for entities with heterogeneous datasets and machine learning models that they seek to refine using data from other agents.","The goal of the marketplace is to encourage participation for data sharing in the presence of such heterogeneity.","Our market design approach for data sharing focuses on interim utility balance, where participants contribute and receive equitable utility from refinement of their models.","We present such a market model for which we study computational complexity, solution existence, and approximation algorithms for welfare maximization and core stability.","We finally support our theoretical insights with simulations on a mean estimation task inspired by road traffic delay estimation."],"url":"http://arxiv.org/abs/2401.13053v1"}
{"created":"2024-01-23 19:00:02","title":"Locality Sensitive Sparse Encoding for Learning World Models Online","abstract":"Acquiring an accurate world model online for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs). From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round. Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents. In this paper, we revisit models that can achieve FTL with incremental updates. Specifically, our world model is a linear regression model supported by nonlinear random features. The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments. To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features. We validate the representation power of our encoding and verify that it allows efficient online learning under data covariate shift. We also show, in the Dyna MBRL setting, that our world models learned online using a single pass of trajectory data either surpass or match the performance of deep world models trained with replay and other continual learning methods.","sentences":["Acquiring an accurate world model online for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs).","From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round.","Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents.","In this paper, we revisit models that can achieve FTL with incremental updates.","Specifically, our world model is a linear regression model supported by nonlinear random features.","The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments.","To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features.","We validate the representation power of our encoding and verify that it allows efficient online learning under data covariate shift.","We also show, in the Dyna MBRL setting, that our world models learned online using a single pass of trajectory data either surpass or match the performance of deep world models trained with replay and other continual learning methods."],"url":"http://arxiv.org/abs/2401.13034v1"}
{"created":"2024-01-23 17:27:13","title":"White-box validation of quantitative product lines by statistical model checking and process mining","abstract":"We propose a novel methodology for validating software product line (PL) models by integrating Statistical Model Checking (SMC) with Process Mining (PM). Our approach focuses on the feature-oriented language QFLan in the PL engineering domain, allowing modeling of PLs with rich cross-tree and quantitative constraints, as well as aspects of dynamic PLs like staged configurations. This richness leads to models with infinite state-space, requiring simulation-based analysis techniques like SMC. For instance, we illustrate with a running example involving infinite state space. SMC involves generating samples of system dynamics to estimate properties such as event probabilities or expected values. On the other hand, PM uses data-driven techniques on execution logs to identify and reason about the underlying execution process. In this paper, we propose, for the first time, applying PM techniques to SMC simulations' byproducts to enhance the utility of SMC analyses. Typically, when SMC results are unexpected, modelers must determine whether they stem from actual system characteristics or model bugs in a black-box manner. We improve on this by using PM to provide a white-box perspective on the observed system dynamics. Samples from SMC are fed into PM tools, producing a compact graphical representation of observed dynamics. The mined PM model is then transformed into a QFLan model, accessible to PL engineers. Using two well-known PL models, we demonstrate the effectiveness and scalability of our methodology in pinpointing issues and suggesting fixes. Additionally, we show its generality by applying it to the security domain.","sentences":["We propose a novel methodology for validating software product line (PL) models by integrating Statistical Model Checking (SMC) with Process Mining (PM).","Our approach focuses on the feature-oriented language QFLan in the PL engineering domain, allowing modeling of PLs with rich cross-tree and quantitative constraints, as well as aspects of dynamic PLs like staged configurations.","This richness leads to models with infinite state-space, requiring simulation-based analysis techniques like SMC.","For instance, we illustrate with a running example involving infinite state space.","SMC involves generating samples of system dynamics to estimate properties such as event probabilities or expected values.","On the other hand, PM uses data-driven techniques on execution logs to identify and reason about the underlying execution process.","In this paper, we propose, for the first time, applying PM techniques to SMC simulations' byproducts to enhance the utility of SMC analyses.","Typically, when SMC results are unexpected, modelers must determine whether they stem from actual system characteristics or model bugs in a black-box manner.","We improve on this by using PM to provide a white-box perspective on the observed system dynamics.","Samples from SMC are fed into PM tools, producing a compact graphical representation of observed dynamics.","The mined PM model is then transformed into a QFLan model, accessible to PL engineers.","Using two well-known PL models, we demonstrate the effectiveness and scalability of our methodology in pinpointing issues and suggesting fixes.","Additionally, we show its generality by applying it to the security domain."],"url":"http://arxiv.org/abs/2401.13019v1"}
