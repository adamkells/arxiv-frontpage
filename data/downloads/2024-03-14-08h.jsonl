{"created":"2024-03-13 17:58:57","title":"Simple and Scalable Strategies to Continually Pre-train Large Language Models","abstract":"Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\\rightarrow$English) and a stronger distribution shift (English$\\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget.","sentences":["Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available.","A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training.","However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data.","In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks.","Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\\rightarrow$English) and a stronger distribution shift (English$\\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens).","Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM.","Our results demonstrate that LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute.","Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget."],"url":"http://arxiv.org/abs/2403.08763v1"}
{"created":"2024-03-13 17:58:00","title":"MIM4D: Masked Modeling with Multi-View Video for Autonomous Driving Representation Learning","abstract":"Learning robust and scalable visual representations from massive multi-view video data remains a challenge in computer vision and autonomous driving. Existing pre-training methods either rely on expensive supervised learning with 3D annotations, limiting the scalability, or focus on single-frame or monocular inputs, neglecting the temporal information. We propose MIM4D, a novel pre-training paradigm based on dual masked image modeling (MIM). MIM4D leverages both spatial and temporal relations by training on masked multi-view video inputs. It constructs pseudo-3D features using continuous scene flow and projects them onto 2D plane for supervision. To address the lack of dense 3D supervision, MIM4D reconstruct pixels by employing 3D volumetric differentiable rendering to learn geometric representations. We demonstrate that MIM4D achieves state-of-the-art performance on the nuScenes dataset for visual representation learning in autonomous driving. It significantly improves existing methods on multiple downstream tasks, including BEV segmentation (8.7% IoU), 3D object detection (3.5% mAP), and HD map construction (1.4% mAP). Our work offers a new choice for learning representation at scale in autonomous driving. Code and models are released at https://github.com/hustvl/MIM4D","sentences":["Learning robust and scalable visual representations from massive multi-view video data remains a challenge in computer vision and autonomous driving.","Existing pre-training methods either rely on expensive supervised learning with 3D annotations, limiting the scalability, or focus on single-frame or monocular inputs, neglecting the temporal information.","We propose MIM4D, a novel pre-training paradigm based on dual masked image modeling (MIM).","MIM4D leverages both spatial and temporal relations by training on masked multi-view video inputs.","It constructs pseudo-3D features using continuous scene flow and projects them onto 2D plane for supervision.","To address the lack of dense 3D supervision, MIM4D reconstruct pixels by employing 3D volumetric differentiable rendering to learn geometric representations.","We demonstrate that MIM4D achieves state-of-the-art performance on the nuScenes dataset for visual representation learning in autonomous driving.","It significantly improves existing methods on multiple downstream tasks, including BEV segmentation (8.7% IoU), 3D object detection (3.5% mAP), and HD map construction (1.4% mAP).","Our work offers a new choice for learning representation at scale in autonomous driving.","Code and models are released at https://github.com/hustvl/MIM4D"],"url":"http://arxiv.org/abs/2403.08760v1"}
{"created":"2024-03-13 17:46:28","title":"Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework","abstract":"Large language models (LLMs) can easily generate biased and discriminative responses. As LLMs tap into consequential decision-making (e.g., hiring and healthcare), it is of crucial importance to develop strategies to mitigate these biases. This paper focuses on social bias, tackling the association between demographic information and LLM outputs. We propose a causality-guided debiasing framework that utilizes causal understandings of (1) the data-generating process of the training corpus fed to LLMs, and (2) the internal reasoning process of LLM inference, to guide the design of prompts for debiasing LLM outputs through selection mechanisms. Our framework unifies existing de-biasing prompting approaches such as inhibitive instructions and in-context contrastive examples, and sheds light on new ways of debiasing by encouraging bias-free reasoning. Our strong empirical performance on real-world datasets demonstrates that our framework provides principled guidelines on debiasing LLM outputs even with only the black-box access.","sentences":["Large language models (LLMs) can easily generate biased and discriminative responses.","As LLMs tap into consequential decision-making (e.g., hiring and healthcare), it is of crucial importance to develop strategies to mitigate these biases.","This paper focuses on social bias, tackling the association between demographic information and LLM outputs.","We propose a causality-guided debiasing framework that utilizes causal understandings of (1) the data-generating process of the training corpus fed to LLMs, and (2) the internal reasoning process of LLM inference, to guide the design of prompts for debiasing LLM outputs through selection mechanisms.","Our framework unifies existing de-biasing prompting approaches such as inhibitive instructions and in-context contrastive examples, and sheds light on new ways of debiasing by encouraging bias-free reasoning.","Our strong empirical performance on real-world datasets demonstrates that our framework provides principled guidelines on debiasing LLM outputs even with only the black-box access."],"url":"http://arxiv.org/abs/2403.08743v1"}
{"created":"2024-03-13 17:38:05","title":"ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation","abstract":"Existing Machine Learning approaches for local citation recommendation directly map or translate a query, which is typically a claim or an entity mention, to citation-worthy research papers. Within such a formulation, it is challenging to pinpoint why one should cite a specific research paper for a particular query, leading to limited recommendation interpretability. To alleviate this, we introduce the evidence-grounded local citation recommendation task, where the target latent space comprises evidence spans for recommending specific papers. Using a distantly-supervised evidence retrieval and multi-step re-ranking framework, our proposed system, ILCiteR, recommends papers to cite for a query grounded on similar evidence spans extracted from the existing research literature. Unlike past formulations that simply output recommendations, ILCiteR retrieves ranked lists of evidence span and recommended paper pairs. Secondly, previously proposed neural models for citation recommendation require expensive training on massive labeled data, ideally after every significant update to the pool of candidate papers. In contrast, ILCiteR relies solely on distant supervision from a dynamic evidence database and pre-trained Transformer-based Language Models without any model training. We contribute a novel dataset for the evidence-grounded local citation recommendation task and demonstrate the efficacy of our proposed conditional neural rank-ensembling approach for re-ranking evidence spans.","sentences":["Existing Machine Learning approaches for local citation recommendation directly map or translate a query, which is typically a claim or an entity mention, to citation-worthy research papers.","Within such a formulation, it is challenging to pinpoint why one should cite a specific research paper for a particular query, leading to limited recommendation interpretability.","To alleviate this, we introduce the evidence-grounded local citation recommendation task, where the target latent space comprises evidence spans for recommending specific papers.","Using a distantly-supervised evidence retrieval and multi-step re-ranking framework, our proposed system, ILCiteR, recommends papers to cite for a query grounded on similar evidence spans extracted from the existing research literature.","Unlike past formulations that simply output recommendations, ILCiteR retrieves ranked lists of evidence span and recommended paper pairs.","Secondly, previously proposed neural models for citation recommendation require expensive training on massive labeled data, ideally after every significant update to the pool of candidate papers.","In contrast, ILCiteR relies solely on distant supervision from a dynamic evidence database and pre-trained Transformer-based Language Models without any model training.","We contribute a novel dataset for the evidence-grounded local citation recommendation task and demonstrate the efficacy of our proposed conditional neural rank-ensembling approach for re-ranking evidence spans."],"url":"http://arxiv.org/abs/2403.08737v1"}
{"created":"2024-03-13 17:28:20","title":"Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models trained on Corrupted Data","abstract":"We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data. Our method, Ambient Diffusion Posterior Sampling (A-DPS), leverages a generative model pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling conditioned on measurements from a potentially different forward process (e.g. image blurring). We test the efficacy of our approach on standard natural image datasets (CelebA, FFHQ, and AFHQ) and we show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance. We further extend the Ambient Diffusion framework to train MRI models with access only to Fourier subsampled multi-coil MRI measurements at various acceleration factors (R=2, 4, 6, 8). We again observe that models trained on highly subsampled data are better priors for solving inverse problems in the high acceleration regime than models trained on fully sampled data. We open-source our code and the trained Ambient Diffusion MRI models: https://github.com/utcsilab/ambient-diffusion-mri .","sentences":["We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data.","Our method, Ambient Diffusion Posterior Sampling (A-DPS), leverages a generative model pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling conditioned on measurements from a potentially different forward process (e.g. image blurring).","We test the efficacy of our approach on standard natural image datasets (CelebA, FFHQ, and AFHQ) and we show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance.","We further extend the Ambient Diffusion framework to train MRI models with access only to Fourier subsampled multi-coil MRI measurements at various acceleration factors (R=2, 4, 6, 8).","We again observe that models trained on highly subsampled data are better priors for solving inverse problems in the high acceleration regime than models trained on fully sampled data.","We open-source our code and the trained Ambient Diffusion MRI models: https://github.com/utcsilab/ambient-diffusion-mri ."],"url":"http://arxiv.org/abs/2403.08728v1"}
{"created":"2024-03-13 17:20:25","title":"Historical Astronomical Diagrams Decomposition in Geometric Primitives","abstract":"Automatically extracting the geometric content from the hundreds of thousands of diagrams drawn in historical manuscripts would enable historians to study the diffusion of astronomical knowledge on a global scale. However, state-of-the-art vectorization methods, often designed to tackle modern data, are not adapted to the complexity and diversity of historical astronomical diagrams. Our contribution is thus twofold. First, we introduce a unique dataset of 303 astronomical diagrams from diverse traditions, ranging from the XIIth to the XVIIIth century, annotated with more than 3000 line segments, circles and arcs. Second, we develop a model that builds on DINO-DETR to enable the prediction of multiple geometric primitives. We show that it can be trained solely on synthetic data and accurately predict primitives on our challenging dataset. Our approach widely improves over the LETR baseline, which is restricted to lines, by introducing a meaningful parametrization for multiple primitives, jointly training for detection and parameter refinement, using deformable attention and training on rich synthetic data. Our dataset and code are available on our webpage.","sentences":["Automatically extracting the geometric content from the hundreds of thousands of diagrams drawn in historical manuscripts would enable historians to study the diffusion of astronomical knowledge on a global scale.","However, state-of-the-art vectorization methods, often designed to tackle modern data, are not adapted to the complexity and diversity of historical astronomical diagrams.","Our contribution is thus twofold.","First, we introduce a unique dataset of 303 astronomical diagrams from diverse traditions, ranging from the XIIth to the XVIIIth century, annotated with more than 3000 line segments, circles and arcs.","Second, we develop a model that builds on DINO-DETR to enable the prediction of multiple geometric primitives.","We show that it can be trained solely on synthetic data and accurately predict primitives on our challenging dataset.","Our approach widely improves over the LETR baseline, which is restricted to lines, by introducing a meaningful parametrization for multiple primitives, jointly training for detection and parameter refinement, using deformable attention and training on rich synthetic data.","Our dataset and code are available on our webpage."],"url":"http://arxiv.org/abs/2403.08721v1"}
{"created":"2024-03-13 17:18:19","title":"DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation","abstract":"We introduce DIFFTACTILE, a physics-based differentiable tactile simulation system designed to enhance robotic manipulation with dense and physically accurate tactile feedback. In contrast to prior tactile simulators which primarily focus on manipulating rigid bodies and often rely on simplified approximations to model stress and deformations of materials in contact, DIFFTACTILE emphasizes physics-based contact modeling with high fidelity, supporting simulations of diverse contact modes and interactions with objects possessing a wide range of material properties. Our system incorporates several key components, including a Finite Element Method (FEM)-based soft body model for simulating the sensing elastomer, a multi-material simulator for modeling diverse object types (such as elastic, elastoplastic, cables) under manipulation, a penalty-based contact model for handling contact dynamics. The differentiable nature of our system facilitates gradient-based optimization for both 1) refining physical properties in simulation using real-world data, hence narrowing the sim-to-real gap and 2) efficient learning of tactile-assisted grasping and contact-rich manipulation skills. Additionally, we introduce a method to infer the optical response of our tactile sensor to contact using an efficient pixel-based neural module. We anticipate that DIFFTACTILE will serve as a useful platform for studying contact-rich manipulations, leveraging the benefits of dense tactile feedback and differentiable physics. Code and supplementary materials are available at the project website https://difftactile.github.io/.","sentences":["We introduce DIFFTACTILE, a physics-based differentiable tactile simulation system designed to enhance robotic manipulation with dense and physically accurate tactile feedback.","In contrast to prior tactile simulators which primarily focus on manipulating rigid bodies and often rely on simplified approximations to model stress and deformations of materials in contact, DIFFTACTILE emphasizes physics-based contact modeling with high fidelity, supporting simulations of diverse contact modes and interactions with objects possessing a wide range of material properties.","Our system incorporates several key components, including a Finite Element Method (FEM)-based soft body model for simulating the sensing elastomer, a multi-material simulator for modeling diverse object types (such as elastic, elastoplastic, cables) under manipulation, a penalty-based contact model for handling contact dynamics.","The differentiable nature of our system facilitates gradient-based optimization for both 1) refining physical properties in simulation using real-world data, hence narrowing the sim-to-real gap and 2) efficient learning of tactile-assisted grasping and contact-rich manipulation skills.","Additionally, we introduce a method to infer the optical response of our tactile sensor to contact using an efficient pixel-based neural module.","We anticipate that DIFFTACTILE will serve as a useful platform for studying contact-rich manipulations, leveraging the benefits of dense tactile feedback and differentiable physics.","Code and supplementary materials are available at the project website https://difftactile.github.io/."],"url":"http://arxiv.org/abs/2403.08716v1"}
{"created":"2024-03-13 17:17:48","title":"SOTOPIA-$\u03c0$: Interactive Learning of Socially Intelligent Language Agents","abstract":"Humans learn social skills through both imitation and social interaction. This social learning process is largely understudied by existing research on building language agents. Motivated by this gap, we propose an interactive learning method, SOTOPIA-$\\pi$, improving the social intelligence of language agents. This method leverages behavior cloning and self-reinforcement training on filtered social interaction data according to large language model (LLM) ratings. We show that our training method allows a 7B LLM to reach the social goal completion ability of an expert model (GPT-4-based agent), while improving the safety of language agents and maintaining general QA ability on the MMLU benchmark. We also find that this training paradigm uncovers some difficulties in LLM-based evaluation of social intelligence: LLM-based evaluators overestimate the abilities of the language agents trained specifically for social interaction.","sentences":["Humans learn social skills through both imitation and social interaction.","This social learning process is largely understudied by existing research on building language agents.","Motivated by this gap, we propose an interactive learning method, SOTOPIA-$\\pi$, improving the social intelligence of language agents.","This method leverages behavior cloning and self-reinforcement training on filtered social interaction data according to large language model (LLM) ratings.","We show that our training method allows a 7B LLM to reach the social goal completion ability of an expert model (GPT-4-based agent), while improving the safety of language agents and maintaining general QA ability on the MMLU benchmark.","We also find that this training paradigm uncovers some difficulties in LLM-based evaluation of social intelligence: LLM-based evaluators overestimate the abilities of the language agents trained specifically for social interaction."],"url":"http://arxiv.org/abs/2403.08715v1"}
{"created":"2024-03-13 17:12:36","title":"Improved Randomized Approximation of Hard Universality and Emptiness Problems","abstract":"We build on recent research on polynomial randomized approximation (PRAX) algorithms for the hard problems of NFA universality and NFA equivalence. Loosely speaking, PRAX algorithms use sampling of infinite domains within any desired accuracy $\\delta$. In the spirit of experimental mathematics, we extend the concept of PRAX algorithms to be applicable to the emptiness and universality problems in any domain whose instances admit a tractable distribution as defined in this paper. A technical result here is that a linear (w.r.t. $1/\\delta$) number of samples is sufficient, as opposed to the quadratic number of samples in previous papers. We show how the improved and generalized PRAX algorithms apply to universality and emptiness problems in various domains: ordinary automata, tautology testing of propositions, 2D automata, and to solution sets of certain Diophantine equations.","sentences":["We build on recent research on polynomial randomized approximation (PRAX) algorithms for the hard problems of NFA universality and NFA equivalence.","Loosely speaking, PRAX algorithms use sampling of infinite domains within any desired accuracy $\\delta$.","In the spirit of experimental mathematics, we extend the concept of PRAX algorithms to be applicable to the emptiness and universality problems in any domain whose instances admit a tractable distribution as defined in this paper.","A technical result here is that a linear (w.r.t. $1/\\delta$) number of samples is sufficient, as opposed to the quadratic number of samples in previous papers.","We show how the improved and generalized PRAX algorithms apply to universality and emptiness problems in various domains: ordinary automata, tautology testing of propositions, 2D automata, and to solution sets of certain Diophantine equations."],"url":"http://arxiv.org/abs/2403.08707v1"}
{"created":"2024-03-13 17:02:27","title":"Implicit Regularization of Gradient Flow on One-Layer Softmax Attention","abstract":"We study gradient flow on the exponential loss for a classification problem with a one-layer softmax attention model, where the key and query weight matrices are trained separately. Under a separability assumption on the data, we show that when gradient flow achieves the minimal loss value, it further implicitly minimizes the nuclear norm of the product of the key and query weight matrices. Such implicit regularization can be described by a Support Vector Machine (SVM) problem with respect to the attention weights. This finding contrasts with prior results showing that the gradient descent induces an implicit regularization on the Frobenius norm on the product weight matrix when the key and query matrices are combined into a single weight matrix for training. For diagonal key and query matrices, our analysis builds upon the reparameterization technique and exploits approximate KKT conditions of the SVM associated with the classification data. Moreover, the results are extended to general weights configurations given proper alignment of the weight matrices' singular spaces with the data features at initialization.","sentences":["We study gradient flow on the exponential loss for a classification problem with a one-layer softmax attention model, where the key and query weight matrices are trained separately.","Under a separability assumption on the data, we show that when gradient flow achieves the minimal loss value, it further implicitly minimizes the nuclear norm of the product of the key and query weight matrices.","Such implicit regularization can be described by a Support Vector Machine (SVM) problem with respect to the attention weights.","This finding contrasts with prior results showing that the gradient descent induces an implicit regularization on the Frobenius norm on the product weight matrix when the key and query matrices are combined into a single weight matrix for training.","For diagonal key and query matrices, our analysis builds upon the reparameterization technique and exploits approximate KKT conditions of the SVM associated with the classification data.","Moreover, the results are extended to general weights configurations given proper alignment of the weight matrices' singular spaces with the data features at initialization."],"url":"http://arxiv.org/abs/2403.08699v1"}
{"created":"2024-03-13 16:58:37","title":"Deep Learning for In-Orbit Cloud Segmentation and Classification in Hyperspectral Satellite Data","abstract":"This article explores the latest Convolutional Neural Networks (CNNs) for cloud detection aboard hyperspectral satellites. The performance of the latest 1D CNN (1D-Justo-LiuNet) and two recent 2D CNNs (nnU-net and 2D-Justo-UNet-Simple) for cloud segmentation and classification is assessed. Evaluation criteria include precision and computational efficiency for in-orbit deployment. Experiments utilize NASA's EO-1 Hyperion data, with varying spectral channel numbers after Principal Component Analysis. Results indicate that 1D-Justo-LiuNet achieves the highest accuracy, outperforming 2D CNNs, while maintaining compactness with larger spectral channel sets, albeit with increased inference times. However, the performance of 1D CNN degrades with significant channel reduction. In this context, the 2D-Justo-UNet-Simple offers the best balance for in-orbit deployment, considering precision, memory, and time costs. While nnU-net is suitable for on-ground processing, deployment of lightweight 1D-Justo-LiuNet is recommended for high-precision applications. Alternatively, lightweight 2D-Justo-UNet-Simple is recommended for balanced costs between timing and precision in orbit.","sentences":["This article explores the latest Convolutional Neural Networks (CNNs) for cloud detection aboard hyperspectral satellites.","The performance of the latest 1D CNN (1D-Justo-LiuNet) and two recent 2D CNNs (nnU-net and 2D-Justo-UNet-Simple) for cloud segmentation and classification is assessed.","Evaluation criteria include precision and computational efficiency for in-orbit deployment.","Experiments utilize NASA's EO-1 Hyperion data, with varying spectral channel numbers after Principal Component Analysis.","Results indicate that 1D-Justo-LiuNet achieves the highest accuracy, outperforming 2D CNNs, while maintaining compactness with larger spectral channel sets, albeit with increased inference times.","However, the performance of 1D CNN degrades with significant channel reduction.","In this context, the 2D-Justo-UNet-Simple offers the best balance for in-orbit deployment, considering precision, memory, and time costs.","While nnU-net is suitable for on-ground processing, deployment of lightweight 1D-Justo-LiuNet is recommended for high-precision applications.","Alternatively, lightweight 2D-Justo-UNet-Simple is recommended for balanced costs between timing and precision in orbit."],"url":"http://arxiv.org/abs/2403.08695v1"}
{"created":"2024-03-13 16:57:57","title":"TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning","abstract":"The development of Large Language Models (LLMs) often confronts challenges stemming from the heavy reliance on human annotators in the reinforcement learning with human feedback (RLHF) framework, or the frequent and costly external queries tied to the self-instruct paradigm. In this work, we pivot to Reinforcement Learning (RL) -- but with a twist. Diverging from the typical RLHF, which refines LLMs following instruction data training, we use RL to directly generate the foundational instruction dataset that alone suffices for fine-tuning. Our method, TeaMs-RL, uses a suite of textual operations and rules, prioritizing the diversification of training datasets. It facilitates the generation of high-quality data without excessive reliance on external advanced models, paving the way for a single fine-tuning step and negating the need for subsequent RLHF stages. Our findings highlight key advantages of our approach: reduced need for human involvement and fewer model queries (only $5.73\\%$ of WizardLM's total), along with enhanced capabilities of LLMs in crafting and comprehending complex instructions compared to strong baselines, and substantially improved model privacy protection.","sentences":["The development of Large Language Models (LLMs) often confronts challenges stemming from the heavy reliance on human annotators in the reinforcement learning with human feedback (RLHF) framework, or the frequent and costly external queries tied to the self-instruct paradigm.","In this work, we pivot to Reinforcement Learning (RL) -- but with a twist.","Diverging from the typical RLHF, which refines LLMs following instruction data training, we use RL to directly generate the foundational instruction dataset that alone suffices for fine-tuning.","Our method, TeaMs-RL, uses a suite of textual operations and rules, prioritizing the diversification of training datasets.","It facilitates the generation of high-quality data without excessive reliance on external advanced models, paving the way for a single fine-tuning step and negating the need for subsequent RLHF stages.","Our findings highlight key advantages of our approach: reduced need for human involvement and fewer model queries (only $5.73\\%$ of WizardLM's total), along with enhanced capabilities of LLMs in crafting and comprehending complex instructions compared to strong baselines, and substantially improved model privacy protection."],"url":"http://arxiv.org/abs/2403.08694v1"}
{"created":"2024-03-13 16:56:33","title":"Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages","abstract":"Large, curated, web-crawled corpora play a vital role in training language models (LMs). They form the lion's share of the training data in virtually all recent LMs, such as the well-known GPT, LLaMA and XLM-RoBERTa models. However, despite this importance, relatively little attention has been given to the quality of these corpora. In this paper, we compare four of the currently most relevant large, web-crawled corpora (CC100, MaCoCu, mC4 and OSCAR) across eleven lower-resourced European languages. Our approach is two-fold: first, we perform an intrinsic evaluation by performing a human evaluation of the quality of samples taken from different corpora; then, we assess the practical impact of the qualitative differences by training specific LMs on each of the corpora and evaluating their performance on downstream tasks. We find that there are clear differences in quality of the corpora, with MaCoCu and OSCAR obtaining the best results. However, during the extrinsic evaluation, we actually find that the CC100 corpus achieves the highest scores. We conclude that, in our experiments, the quality of the web-crawled corpora does not seem to play a significant role when training LMs.","sentences":["Large, curated, web-crawled corpora play a vital role in training language models (LMs).","They form the lion's share of the training data in virtually all recent LMs, such as the well-known GPT, LLaMA and XLM-RoBERTa models.","However, despite this importance, relatively little attention has been given to the quality of these corpora.","In this paper, we compare four of the currently most relevant large, web-crawled corpora (CC100, MaCoCu, mC4 and OSCAR) across eleven lower-resourced European languages.","Our approach is two-fold: first, we perform an intrinsic evaluation by performing a human evaluation of the quality of samples taken from different corpora; then, we assess the practical impact of the qualitative differences by training specific LMs on each of the corpora and evaluating their performance on downstream tasks.","We find that there are clear differences in quality of the corpora, with MaCoCu and OSCAR obtaining the best results.","However, during the extrinsic evaluation, we actually find that the CC100 corpus achieves the highest scores.","We conclude that, in our experiments, the quality of the web-crawled corpora does not seem to play a significant role when training LMs."],"url":"http://arxiv.org/abs/2403.08693v1"}
{"created":"2024-03-13 16:25:55","title":"When can we Approximate Wide Contrastive Models with Neural Tangent Kernels and Principal Component Analysis?","abstract":"Contrastive learning is a paradigm for learning representations from unlabelled data that has been highly successful for image and text data. Several recent works have examined contrastive losses to claim that contrastive models effectively learn spectral embeddings, while few works show relations between (wide) contrastive models and kernel principal component analysis (PCA). However, it is not known if trained contrastive models indeed correspond to kernel methods or PCA. In this work, we analyze the training dynamics of two-layer contrastive models, with non-linear activation, and answer when these models are close to PCA or kernel methods. It is well known in the supervised setting that neural networks are equivalent to neural tangent kernel (NTK) machines, and that the NTK of infinitely wide networks remains constant during training. We provide the first convergence results of NTK for contrastive losses, and present a nuanced picture: NTK of wide networks remains almost constant for cosine similarity based contrastive losses, but not for losses based on dot product similarity. We further study the training dynamics of contrastive models with orthogonality constraints on output layer, which is implicitly assumed in works relating contrastive learning to spectral embedding. Our deviation bounds suggest that representations learned by contrastive models are close to the principal components of a certain matrix computed from random features. We empirically show that our theoretical results possibly hold beyond two-layer networks.","sentences":["Contrastive learning is a paradigm for learning representations from unlabelled data that has been highly successful for image and text data.","Several recent works have examined contrastive losses to claim that contrastive models effectively learn spectral embeddings, while few works show relations between (wide) contrastive models and kernel principal component analysis (PCA).","However, it is not known if trained contrastive models indeed correspond to kernel methods or PCA.","In this work, we analyze the training dynamics of two-layer contrastive models, with non-linear activation, and answer when these models are close to PCA or kernel methods.","It is well known in the supervised setting that neural networks are equivalent to neural tangent kernel (NTK) machines, and that the NTK of infinitely wide networks remains constant during training.","We provide the first convergence results of NTK for contrastive losses, and present a nuanced picture: NTK of wide networks remains almost constant for cosine similarity based contrastive losses, but not for losses based on dot product similarity.","We further study the training dynamics of contrastive models with orthogonality constraints on output layer, which is implicitly assumed in works relating contrastive learning to spectral embedding.","Our deviation bounds suggest that representations learned by contrastive models are close to the principal components of a certain matrix computed from random features.","We empirically show that our theoretical results possibly hold beyond two-layer networks."],"url":"http://arxiv.org/abs/2403.08673v1"}
{"created":"2024-03-13 16:17:09","title":"Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records","abstract":"The challenge of accessing historical patient data for clinical research, while adhering to privacy regulations, is a significant obstacle in medical science. An innovative approach to circumvent this issue involves utilising synthetic medical records that mirror real patient data without compromising individual privacy. The creation of these synthetic datasets, particularly without using actual patient data to train Large Language Models (LLMs), presents a novel solution as gaining access to sensitive patient information to train models is also a challenge. This study assesses the capability of the Llama 2 LLM to create synthetic medical records that accurately reflect real patient information, employing zero-shot and few-shot prompting strategies for comparison against fine-tuned methodologies that do require sensitive patient data during training. We focus on generating synthetic narratives for the History of Present Illness section, utilising data from the MIMIC-IV dataset for comparison. In this work introduce a novel prompting technique that leverages a chain-of-thought approach, enhancing the model's ability to generate more accurate and contextually relevant medical narratives without prior fine-tuning. Our findings suggest that this chain-of-thought prompted approach allows the zero-shot model to achieve results on par with those of fine-tuned models, based on Rouge metrics evaluation.","sentences":["The challenge of accessing historical patient data for clinical research, while adhering to privacy regulations, is a significant obstacle in medical science.","An innovative approach to circumvent this issue involves utilising synthetic medical records that mirror real patient data without compromising individual privacy.","The creation of these synthetic datasets, particularly without using actual patient data to train Large Language Models (LLMs), presents a novel solution as gaining access to sensitive patient information to train models is also a challenge.","This study assesses the capability of the Llama 2 LLM to create synthetic medical records that accurately reflect real patient information, employing zero-shot and few-shot prompting strategies for comparison against fine-tuned methodologies that do require sensitive patient data during training.","We focus on generating synthetic narratives for the History of Present Illness section, utilising data from the MIMIC-IV dataset for comparison.","In this work introduce a novel prompting technique that leverages a chain-of-thought approach, enhancing the model's ability to generate more accurate and contextually relevant medical narratives without prior fine-tuning.","Our findings suggest that this chain-of-thought prompted approach allows the zero-shot model to achieve results on par with those of fine-tuned models, based on Rouge metrics evaluation."],"url":"http://arxiv.org/abs/2403.08664v1"}
{"created":"2024-03-13 16:05:18","title":"Data Augmentation in Human-Centric Vision","abstract":"This survey presents a comprehensive analysis of data augmentation techniques in human-centric vision tasks, a first of its kind in the field. It delves into a wide range of research areas including person ReID, human parsing, human pose estimation, and pedestrian detection, addressing the significant challenges posed by overfitting and limited training data in these domains. Our work categorizes data augmentation methods into two main types: data generation and data perturbation. Data generation covers techniques like graphic engine-based generation, generative model-based generation, and data recombination, while data perturbation is divided into image-level and human-level perturbations. Each method is tailored to the unique requirements of human-centric tasks, with some applicable across multiple areas. Our contributions include an extensive literature review, providing deep insights into the influence of these augmentation techniques in human-centric vision and highlighting the nuances of each method. We also discuss open issues and future directions, such as the integration of advanced generative models like Latent Diffusion Models, for creating more realistic and diverse training data. This survey not only encapsulates the current state of data augmentation in human-centric vision but also charts a course for future research, aiming to develop more robust, accurate, and efficient human-centric vision systems.","sentences":["This survey presents a comprehensive analysis of data augmentation techniques in human-centric vision tasks, a first of its kind in the field.","It delves into a wide range of research areas including person ReID, human parsing, human pose estimation, and pedestrian detection, addressing the significant challenges posed by overfitting and limited training data in these domains.","Our work categorizes data augmentation methods into two main types: data generation and data perturbation.","Data generation covers techniques like graphic engine-based generation, generative model-based generation, and data recombination, while data perturbation is divided into image-level and human-level perturbations.","Each method is tailored to the unique requirements of human-centric tasks, with some applicable across multiple areas.","Our contributions include an extensive literature review, providing deep insights into the influence of these augmentation techniques in human-centric vision and highlighting the nuances of each method.","We also discuss open issues and future directions, such as the integration of advanced generative models like Latent Diffusion Models, for creating more realistic and diverse training data.","This survey not only encapsulates the current state of data augmentation in human-centric vision but also charts a course for future research, aiming to develop more robust, accurate, and efficient human-centric vision systems."],"url":"http://arxiv.org/abs/2403.08650v1"}
{"created":"2024-03-13 16:02:18","title":"Meta Reinforcement Learning for Resource Allocation in Aerial Active-RIS-assisted Networks with Rate-Splitting Multiple Access","abstract":"Mounting a reconfigurable intelligent surface (RIS) on an unmanned aerial vehicle (UAV) holds promise for improving traditional terrestrial network performance. Unlike conventional methods deploying passive RIS on UAVs, this study delves into the efficacy of an aerial active RIS (AARIS). Specifically, the downlink transmission of an AARIS network is investigated, where the base station (BS) leverages rate-splitting multiple access (RSMA) for effective interference management and benefits from the support of an AARIS for jointly amplifying and reflecting the BS's transmit signals. Considering both the non-trivial energy consumption of the active RIS and the limited energy storage of the UAV, we propose an innovative element selection strategy for optimizing the on/off status of RIS elements, which adaptively and remarkably manages the system's power consumption. To this end, a resource management problem is formulated, aiming to maximize the system energy efficiency (EE) by jointly optimizing the transmit beamforming at the BS, the element activation, the phase shift and the amplification factor at the RIS, the RSMA common data rate at users, as well as the UAV's trajectory. Due to the dynamicity nature of UAV and user mobility, a deep reinforcement learning (DRL) algorithm is designed for resource allocation, utilizing meta-learning to adaptively handle fast time-varying system dynamics. Simulations indicate that incorporating an active RIS at the UAV leads to substantial EE gain, compared to passive RIS-aided UAV. We observe the superiority of the RSMA-based AARIS system in terms of EE, compared to existing approaches adopting non-orthogonal multiple access (NOMA).","sentences":["Mounting a reconfigurable intelligent surface (RIS) on an unmanned aerial vehicle (UAV) holds promise for improving traditional terrestrial network performance.","Unlike conventional methods deploying passive RIS on UAVs, this study delves into the efficacy of an aerial active RIS (AARIS).","Specifically, the downlink transmission of an AARIS network is investigated, where the base station (BS) leverages rate-splitting multiple access (RSMA) for effective interference management and benefits from the support of an AARIS for jointly amplifying and reflecting the BS's transmit signals.","Considering both the non-trivial energy consumption of the active RIS and the limited energy storage of the UAV, we propose an innovative element selection strategy for optimizing the on/off status of RIS elements, which adaptively and remarkably manages the system's power consumption.","To this end, a resource management problem is formulated, aiming to maximize the system energy efficiency (EE) by jointly optimizing the transmit beamforming at the BS, the element activation, the phase shift and the amplification factor at the RIS, the RSMA common data rate at users, as well as the UAV's trajectory.","Due to the dynamicity nature of UAV and user mobility, a deep reinforcement learning (DRL) algorithm is designed for resource allocation, utilizing meta-learning to adaptively handle fast time-varying system dynamics.","Simulations indicate that incorporating an active RIS at the UAV leads to substantial EE gain, compared to passive RIS-aided UAV.","We observe the superiority of the RSMA-based AARIS system in terms of EE, compared to existing approaches adopting non-orthogonal multiple access (NOMA)."],"url":"http://arxiv.org/abs/2403.08648v1"}
{"created":"2024-03-13 15:51:03","title":"Disparate Effect Of Missing Mediators On Transportability of Causal Effects","abstract":"Transported mediation effects provide an avenue to understand how upstream interventions (such as improved neighborhood conditions like green spaces) would work differently when applied to different populations as a result of factors that mediate the effects. However, when mediators are missing in the population where the effect is to be transported, these estimates could be biased. We study this issue of missing mediators, motivated by challenges in public health, wherein mediators can be missing, not at random. We propose a sensitivity analysis framework that quantifies the impact of missing mediator data on transported mediation effects. This framework enables us to identify the settings under which the conditional transported mediation effect is rendered insignificant for the subgroup with missing mediator data. Specifically, we provide the bounds on the transported mediation effect as a function of missingness. We then apply the framework to longitudinal data from the Moving to Opportunity Study, a large-scale housing voucher experiment, to quantify the effect of missing mediators on transport effect estimates of voucher receipt, an upstream intervention on living location, in childhood on subsequent risk of mental health or substance use disorder mediated through parental health across sites. Our findings provide a tangible understanding of how much missing data can be withstood for unbiased effect estimates.","sentences":["Transported mediation effects provide an avenue to understand how upstream interventions (such as improved neighborhood conditions like green spaces) would work differently when applied to different populations as a result of factors that mediate the effects.","However, when mediators are missing in the population where the effect is to be transported, these estimates could be biased.","We study this issue of missing mediators, motivated by challenges in public health, wherein mediators can be missing, not at random.","We propose a sensitivity analysis framework that quantifies the impact of missing mediator data on transported mediation effects.","This framework enables us to identify the settings under which the conditional transported mediation effect is rendered insignificant for the subgroup with missing mediator data.","Specifically, we provide the bounds on the transported mediation effect as a function of missingness.","We then apply the framework to longitudinal data from the Moving to Opportunity Study, a large-scale housing voucher experiment, to quantify the effect of missing mediators on transport effect estimates of voucher receipt, an upstream intervention on living location, in childhood on subsequent risk of mental health or substance use disorder mediated through parental health across sites.","Our findings provide a tangible understanding of how much missing data can be withstood for unbiased effect estimates."],"url":"http://arxiv.org/abs/2403.08638v1"}
{"created":"2024-03-13 15:47:26","title":"Human Alignment of Large Language Models through Online Preference Optimisation","abstract":"Ensuring alignment of language models' outputs with human preferences is critical to guarantee a useful, safe, and pleasant user experience. Thus, human alignment has been extensively studied recently and several methods such as Reinforcement Learning from Human Feedback (RLHF), Direct Policy Optimisation (DPO) and Sequence Likelihood Calibration (SLiC) have emerged. In this paper, our contribution is two-fold. First, we show the equivalence between two recent alignment methods, namely Identity Policy Optimisation (IPO) and Nash Mirror Descent (Nash-MD). Second, we introduce a generalisation of IPO, named IPO-MD, that leverages the regularised sampling approach proposed by Nash-MD.   This equivalence may seem surprising at first sight, since IPO is an offline method whereas Nash-MD is an online method using a preference model. However, this equivalence can be proven when we consider the online version of IPO, that is when both generations are sampled by the online policy and annotated by a trained preference model. Optimising the IPO loss with such a stream of data becomes then equivalent to finding the Nash equilibrium of the preference model through self-play. Building on this equivalence, we introduce the IPO-MD algorithm that generates data with a mixture policy (between the online and reference policy) similarly as the general Nash-MD algorithm. We compare online-IPO and IPO-MD to different online versions of existing losses on preference data such as DPO and SLiC on a summarisation task.","sentences":["Ensuring alignment of language models' outputs with human preferences is critical to guarantee a useful, safe, and pleasant user experience.","Thus, human alignment has been extensively studied recently and several methods such as Reinforcement Learning from Human Feedback (RLHF), Direct Policy Optimisation (DPO) and Sequence Likelihood Calibration (SLiC) have emerged.","In this paper, our contribution is two-fold.","First, we show the equivalence between two recent alignment methods, namely Identity Policy Optimisation (IPO) and Nash Mirror Descent (Nash-MD).","Second, we introduce a generalisation of IPO, named IPO-MD, that leverages the regularised sampling approach proposed by Nash-MD.   ","This equivalence may seem surprising at first sight, since IPO is an offline method whereas Nash-MD is an online method using a preference model.","However, this equivalence can be proven when we consider the online version of IPO, that is when both generations are sampled by the online policy and annotated by a trained preference model.","Optimising the IPO loss with such a stream of data becomes then equivalent to finding the Nash equilibrium of the preference model through self-play.","Building on this equivalence, we introduce the IPO-MD algorithm that generates data with a mixture policy (between the online and reference policy) similarly as the general Nash-MD algorithm.","We compare online-IPO and IPO-MD to different online versions of existing losses on preference data such as DPO and SLiC on a summarisation task."],"url":"http://arxiv.org/abs/2403.08635v1"}
{"created":"2024-03-13 15:46:37","title":"A Decade's Battle on Dataset Bias: Are We There Yet?","abstract":"We revisit the \"dataset classification\" experiment suggested by Torralba and Efros a decade ago, in the new era with large-scale, diverse, and hopefully less biased datasets as well as more capable neural network architectures. Surprisingly, we observe that modern neural networks can achieve excellent accuracy in classifying which dataset an image is from: e.g., we report 84.7% accuracy on held-out validation data for the three-way classification problem consisting of the YFCC, CC, and DataComp datasets. Our further experiments show that such a dataset classifier could learn semantic features that are generalizable and transferable, which cannot be simply explained by memorization. We hope our discovery will inspire the community to rethink the issue involving dataset bias and model capabilities.","sentences":["We revisit the \"dataset classification\" experiment suggested by Torralba and Efros a decade ago, in the new era with large-scale, diverse, and hopefully less biased datasets as well as more capable neural network architectures.","Surprisingly, we observe that modern neural networks can achieve excellent accuracy in classifying which dataset an image is from: e.g., we report 84.7% accuracy on held-out validation data for the three-way classification problem consisting of the YFCC, CC, and DataComp datasets.","Our further experiments show that such a dataset classifier could learn semantic features that are generalizable and transferable, which cannot be simply explained by memorization.","We hope our discovery will inspire the community to rethink the issue involving dataset bias and model capabilities."],"url":"http://arxiv.org/abs/2403.08632v1"}
{"created":"2024-03-13 15:45:04","title":"Scaling Up Dynamic Human-Scene Interaction Modeling","abstract":"Confronting the challenges of data scarcity and advanced motion synthesis in human-scene interaction modeling, we introduce the TRUMANS dataset alongside a novel HSI motion synthesis method. TRUMANS stands as the most comprehensive motion-captured HSI dataset currently available, encompassing over 15 hours of human interactions across 100 indoor scenes. It intricately captures whole-body human motions and part-level object dynamics, focusing on the realism of contact. This dataset is further scaled up by transforming physical environments into exact virtual models and applying extensive augmentations to appearance and motion for both humans and objects while maintaining interaction fidelity. Utilizing TRUMANS, we devise a diffusion-based autoregressive model that efficiently generates HSI sequences of any length, taking into account both scene context and intended actions. In experiments, our approach shows remarkable zero-shot generalizability on a range of 3D scene datasets (e.g., PROX, Replica, ScanNet, ScanNet++), producing motions that closely mimic original motion-captured sequences, as confirmed by quantitative experiments and human studies.","sentences":["Confronting the challenges of data scarcity and advanced motion synthesis in human-scene interaction modeling, we introduce the TRUMANS dataset alongside a novel HSI motion synthesis method.","TRUMANS stands as the most comprehensive motion-captured HSI dataset currently available, encompassing over 15 hours of human interactions across 100 indoor scenes.","It intricately captures whole-body human motions and part-level object dynamics, focusing on the realism of contact.","This dataset is further scaled up by transforming physical environments into exact virtual models and applying extensive augmentations to appearance and motion for both humans and objects while maintaining interaction fidelity.","Utilizing TRUMANS, we devise a diffusion-based autoregressive model that efficiently generates HSI sequences of any length, taking into account both scene context and intended actions.","In experiments, our approach shows remarkable zero-shot generalizability on a range of 3D scene datasets (e.g., PROX, Replica, ScanNet, ScanNet++), producing motions that closely mimic original motion-captured sequences, as confirmed by quantitative experiments and human studies."],"url":"http://arxiv.org/abs/2403.08629v1"}
{"created":"2024-03-13 15:32:08","title":"Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples","abstract":"Label corruption, where training samples have incorrect labels, can significantly degrade the performance of machine learning models. This corruption often arises from non-expert labeling or adversarial attacks. Acquiring large, perfectly labeled datasets is costly, and retraining large models from scratch when a clean dataset becomes available is computationally expensive. To address this challenge, we propose Post-Training Correction, a new paradigm that adjusts model parameters after initial training to mitigate label noise, eliminating the need for retraining. We introduce Verifix, a novel Singular Value Decomposition (SVD) based algorithm that leverages a small, verified dataset to correct the model weights using a single update. Verifix uses SVD to estimate a Clean Activation Space and then projects the model's weights onto this space to suppress activations corresponding to corrupted data. We demonstrate Verifix's effectiveness on both synthetic and real-world label noise. Experiments on the CIFAR dataset with 25% synthetic corruption show 7.36% generalization improvements on average. Additionally, we observe generalization improvements of up to 2.63% on naturally corrupted datasets like WebVision1.0 and Clothing1M.","sentences":["Label corruption, where training samples have incorrect labels, can significantly degrade the performance of machine learning models.","This corruption often arises from non-expert labeling or adversarial attacks.","Acquiring large, perfectly labeled datasets is costly, and retraining large models from scratch when a clean dataset becomes available is computationally expensive.","To address this challenge, we propose Post-Training Correction, a new paradigm that adjusts model parameters after initial training to mitigate label noise, eliminating the need for retraining.","We introduce Verifix, a novel Singular Value Decomposition (SVD) based algorithm that leverages a small, verified dataset to correct the model weights using a single update.","Verifix uses SVD to estimate a Clean Activation Space and then projects the model's weights onto this space to suppress activations corresponding to corrupted data.","We demonstrate Verifix's effectiveness on both synthetic and real-world label noise.","Experiments on the CIFAR dataset with 25% synthetic corruption show 7.36% generalization improvements on average.","Additionally, we observe generalization improvements of up to 2.63% on naturally corrupted datasets like WebVision1.0 and Clothing1M."],"url":"http://arxiv.org/abs/2403.08618v1"}
{"created":"2024-03-13 15:13:44","title":"DevBench: A Comprehensive Benchmark for Software Development","abstract":"Recent advancements in large language models (LLMs) have significantly enhanced their coding capabilities. However, existing benchmarks predominantly focused on simplified or isolated aspects of programming, such as single-file code generation or repository issue debugging, falling short of measuring the full spectrum of challenges raised by real-world programming activities. To this end, we propose DevBench, a comprehensive benchmark that evaluates LLMs across various stages of the software development lifecycle, including software design, environment setup, implementation, acceptance testing, and unit testing. DevBench features a wide range of programming languages and domains, high-quality data collection, and carefully designed and verified metrics for each task. Empirical studies show that current LLMs, including GPT-4-Turbo, fail to solve the challenges presented within DevBench. Analyses reveal that models struggle with understanding the complex structures in the repository, managing the compilation process, and grasping advanced programming concepts. Our findings offer actionable insights for the future development of LLMs toward real-world programming applications. Our benchmark is available at https://github.com/open-compass/DevBench","sentences":["Recent advancements in large language models (LLMs) have significantly enhanced their coding capabilities.","However, existing benchmarks predominantly focused on simplified or isolated aspects of programming, such as single-file code generation or repository issue debugging, falling short of measuring the full spectrum of challenges raised by real-world programming activities.","To this end, we propose DevBench, a comprehensive benchmark that evaluates LLMs across various stages of the software development lifecycle, including software design, environment setup, implementation, acceptance testing, and unit testing.","DevBench features a wide range of programming languages and domains, high-quality data collection, and carefully designed and verified metrics for each task.","Empirical studies show that current LLMs, including GPT-4-Turbo, fail to solve the challenges presented within DevBench.","Analyses reveal that models struggle with understanding the complex structures in the repository, managing the compilation process, and grasping advanced programming concepts.","Our findings offer actionable insights for the future development of LLMs toward real-world programming applications.","Our benchmark is available at https://github.com/open-compass/DevBench"],"url":"http://arxiv.org/abs/2403.08604v1"}
{"created":"2024-03-13 15:06:54","title":"Evaluation of Control/User-Plane Denial-of-Service (DoS) Attack on O-RAN Fronthaul Interface","abstract":"The open fronthaul interface defined by O-RAN ALLIANCE aims to support the interoperability between multi-vendor open radio access network (O-RAN) radio units (O-RU) and O-RAN distributed units (O-DU). This paper introduces a new tool that could be used to evaluate Denial-of-Service (DoS) attacks against the open fronthaul interface. We launched an array of control/user planes (C/U-Planes) attacks with the tool under different traffic types and data rates, and we evaluated their impacts on the throughput and block error rate (BLER) of real-world O-RAN systems with commercial hardware.","sentences":["The open fronthaul interface defined by O-RAN ALLIANCE aims to support the interoperability between multi-vendor open radio access network (O-RAN) radio units (O-RU) and O-RAN distributed units (O-DU).","This paper introduces a new tool that could be used to evaluate Denial-of-Service (DoS) attacks against the open fronthaul interface.","We launched an array of control/user planes (C/U-Planes) attacks with the tool under different traffic types and data rates, and we evaluated their impacts on the throughput and block error rate (BLER) of real-world O-RAN systems with commercial hardware."],"url":"http://arxiv.org/abs/2403.08600v1"}
{"created":"2024-03-13 14:57:10","title":"Data-Efficient Sleep Staging with Synthetic Time Series Pretraining","abstract":"Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we propose a pretraining task termed \"frequency pretraining\" to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects. Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond frequencies to enhance sleep staging performance, which is consistent with previous research. We anticipate that our approach will be advantageous across a broad spectrum of applications where EEG data is limited or derived from a small number of subjects, including the domain of brain-computer interfaces.","sentences":["Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets.","To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets.","Inspired by recent advances in computer vision, we propose a pretraining task termed \"frequency pretraining\" to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series.","Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects.","Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond frequencies to enhance sleep staging performance, which is consistent with previous research.","We anticipate that our approach will be advantageous across a broad spectrum of applications where EEG data is limited or derived from a small number of subjects, including the domain of brain-computer interfaces."],"url":"http://arxiv.org/abs/2403.08592v1"}
{"created":"2024-03-13 14:51:16","title":"Can physical information aid the generalization ability of Neural Networks for hydraulic modeling?","abstract":"Application of Neural Networks to river hydraulics is fledgling, despite the field suffering from data scarcity, a challenge for machine learning techniques. Consequently, many purely data-driven Neural Networks proved to lack predictive capabilities. In this work, we propose to mitigate such problem by introducing physical information into the training phase. The idea is borrowed from Physics-Informed Neural Networks which have been recently proposed in other contexts. Physics-Informed Neural Networks embed physical information in the form of the residual of the Partial Differential Equations (PDEs) governing the phenomenon and, as such, are conceived as neural solvers, i.e. an alternative to traditional numerical solvers. Such approach is seldom suitable for environmental hydraulics, where epistemic uncertainties are large, and computing residuals of PDEs exhibits difficulties similar to those faced by classical numerical methods. Instead, we envisaged the employment of Neural Networks as neural operators, featuring physical constraints formulated without resorting to PDEs. The proposed novel methodology shares similarities with data augmentation and regularization. We show that incorporating such soft physical information can improve predictive capabilities.","sentences":["Application of Neural Networks to river hydraulics is fledgling, despite the field suffering from data scarcity, a challenge for machine learning techniques.","Consequently, many purely data-driven Neural Networks proved to lack predictive capabilities.","In this work, we propose to mitigate such problem by introducing physical information into the training phase.","The idea is borrowed from Physics-Informed Neural Networks which have been recently proposed in other contexts.","Physics-Informed Neural Networks embed physical information in the form of the residual of the Partial Differential Equations (PDEs) governing the phenomenon and, as such, are conceived as neural solvers, i.e. an alternative to traditional numerical solvers.","Such approach is seldom suitable for environmental hydraulics, where epistemic uncertainties are large, and computing residuals of PDEs exhibits difficulties similar to those faced by classical numerical methods.","Instead, we envisaged the employment of Neural Networks as neural operators, featuring physical constraints formulated without resorting to PDEs.","The proposed novel methodology shares similarities with data augmentation and regularization.","We show that incorporating such soft physical information can improve predictive capabilities."],"url":"http://arxiv.org/abs/2403.08589v1"}
{"created":"2024-03-13 14:37:00","title":"Local Binary and Multiclass SVMs Trained on a Quantum Annealer","abstract":"Support vector machines (SVMs) are widely used machine learning models (e.g., in remote sensing), with formulations for both classification and regression tasks. In the last years, with the advent of working quantum annealers, hybrid SVM models characterised by quantum training and classical execution have been introduced. These models have demonstrated comparable performance to their classical counterparts. However, they are limited in the training set size due to the restricted connectivity of the current quantum annealers. Hence, to take advantage of large datasets (like those related to Earth observation), a strategy is required. In the classical domain, local SVMs, namely, SVMs trained on the data samples selected by a k-nearest neighbors model, have already proven successful. Here, the local application of quantum-trained SVM models is proposed and empirically assessed. In particular, this approach allows overcoming the constraints on the training set size of the quantum-trained models while enhancing their performance. In practice, the FaLK-SVM method, designed for efficient local SVMs, has been combined with quantum-trained SVM models for binary and multiclass classification. In addition, for comparison, FaLK-SVM has been interfaced for the first time with a classical single-step multiclass SVM model (CS SVM). Concerning the empirical evaluation, D-Wave's quantum annealers and real-world datasets taken from the remote sensing domain have been employed. The results have shown the effectiveness and scalability of the proposed approach, but also its practical applicability in a real-world large-scale scenario.","sentences":["Support vector machines (SVMs) are widely used machine learning models (e.g., in remote sensing), with formulations for both classification and regression tasks.","In the last years, with the advent of working quantum annealers, hybrid SVM models characterised by quantum training and classical execution have been introduced.","These models have demonstrated comparable performance to their classical counterparts.","However, they are limited in the training set size due to the restricted connectivity of the current quantum annealers.","Hence, to take advantage of large datasets (like those related to Earth observation), a strategy is required.","In the classical domain, local SVMs, namely, SVMs trained on the data samples selected by a k-nearest neighbors model, have already proven successful.","Here, the local application of quantum-trained SVM models is proposed and empirically assessed.","In particular, this approach allows overcoming the constraints on the training set size of the quantum-trained models while enhancing their performance.","In practice, the FaLK-SVM method, designed for efficient local SVMs, has been combined with quantum-trained SVM models for binary and multiclass classification.","In addition, for comparison, FaLK-SVM has been interfaced for the first time with a classical single-step multiclass SVM model (CS SVM).","Concerning the empirical evaluation, D-Wave's quantum annealers and real-world datasets taken from the remote sensing domain have been employed.","The results have shown the effectiveness and scalability of the proposed approach, but also its practical applicability in a real-world large-scale scenario."],"url":"http://arxiv.org/abs/2403.08584v1"}
{"created":"2024-03-13 14:35:13","title":"Leveraging Compressed Frame Sizes For Ultra-Fast Video Classification","abstract":"Classifying videos into distinct categories, such as Sport and Music Video, is crucial for multimedia understanding and retrieval, especially when an immense volume of video content is being constantly generated. Traditional methods require video decompression to extract pixel-level features like color, texture, and motion, thereby increasing computational and storage demands. Moreover, these methods often suffer from performance degradation in low-quality videos. We present a novel approach that examines only the post-compression bitstream of a video to perform classification, eliminating the need for bitstream decoding. To validate our approach, we built a comprehensive data set comprising over 29,000 YouTube video clips, totaling 6,000 hours and spanning 11 distinct categories. Our evaluations indicate precision, accuracy, and recall rates consistently above 80%, many exceeding 90%, and some reaching 99%. The algorithm operates approximately 15,000 times faster than real-time for 30fps videos, outperforming traditional Dynamic Time Warping (DTW) algorithm by seven orders of magnitude.","sentences":["Classifying videos into distinct categories, such as Sport and Music Video, is crucial for multimedia understanding and retrieval, especially when an immense volume of video content is being constantly generated.","Traditional methods require video decompression to extract pixel-level features like color, texture, and motion, thereby increasing computational and storage demands.","Moreover, these methods often suffer from performance degradation in low-quality videos.","We present a novel approach that examines only the post-compression bitstream of a video to perform classification, eliminating the need for bitstream decoding.","To validate our approach, we built a comprehensive data set comprising over 29,000 YouTube video clips, totaling 6,000 hours and spanning 11 distinct categories.","Our evaluations indicate precision, accuracy, and recall rates consistently above 80%, many exceeding 90%, and some reaching 99%.","The algorithm operates approximately 15,000 times faster than real-time for 30fps videos, outperforming traditional Dynamic Time Warping (DTW) algorithm by seven orders of magnitude."],"url":"http://arxiv.org/abs/2403.08580v1"}
{"created":"2024-03-13 14:24:09","title":"Consistent Prompting for Rehearsal-Free Continual Learning","abstract":"Continual learning empowers models to adapt autonomously to the ever-changing environment or data streams without forgetting old knowledge. Prompt-based approaches are built on frozen pre-trained models to learn the task-specific prompts and classifiers efficiently. Existing prompt-based methods are inconsistent between training and testing, limiting their effectiveness. Two types of inconsistency are revealed. Test predictions are made from all classifiers while training only focuses on the current task classifier without holistic alignment, leading to Classifier inconsistency. Prompt inconsistency indicates that the prompt selected during testing may not correspond to the one associated with this task during training. In this paper, we propose a novel prompt-based method, Consistent Prompting (CPrompt), for more aligned training and testing. Specifically, all existing classifiers are exposed to prompt training, resulting in classifier consistency learning. In addition, prompt consistency learning is proposed to enhance prediction robustness and boost prompt selection accuracy. Our Consistent Prompting surpasses its prompt-based counterparts and achieves state-of-the-art performance on multiple continual learning benchmarks. Detailed analysis shows that improvements come from more consistent training and testing.","sentences":["Continual learning empowers models to adapt autonomously to the ever-changing environment or data streams without forgetting old knowledge.","Prompt-based approaches are built on frozen pre-trained models to learn the task-specific prompts and classifiers efficiently.","Existing prompt-based methods are inconsistent between training and testing, limiting their effectiveness.","Two types of inconsistency are revealed.","Test predictions are made from all classifiers while training only focuses on the current task classifier without holistic alignment, leading to Classifier inconsistency.","Prompt inconsistency indicates that the prompt selected during testing may not correspond to the one associated with this task during training.","In this paper, we propose a novel prompt-based method, Consistent Prompting (CPrompt), for more aligned training and testing.","Specifically, all existing classifiers are exposed to prompt training, resulting in classifier consistency learning.","In addition, prompt consistency learning is proposed to enhance prediction robustness and boost prompt selection accuracy.","Our Consistent Prompting surpasses its prompt-based counterparts and achieves state-of-the-art performance on multiple continual learning benchmarks.","Detailed analysis shows that improvements come from more consistent training and testing."],"url":"http://arxiv.org/abs/2403.08568v1"}
{"created":"2024-03-13 14:14:47","title":"Structural perspective on constraint-based learning of Markov networks","abstract":"Markov networks are probabilistic graphical models that employ undirected graphs to depict conditional independence relationships among variables. Our focus lies in constraint-based structure learning, which entails learning the undirected graph from data through the execution of conditional independence tests. We establish theoretical limits concerning two critical aspects of constraint-based learning of Markov networks: the number of tests and the sizes of the conditioning sets. These bounds uncover an exciting interplay between the structural properties of the graph and the amount of tests required to learn a Markov network. The starting point of our work is that the graph parameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number of vertex-disjoint paths connecting a pair of vertices in the graph, is responsible for the sizes of independence tests required to learn the graph. On one hand, we show that at least one test with the size of the conditioning set at least $\\kappa$ is always necessary. On the other hand, we prove that any graph can be learned by performing tests of size at most $\\kappa$. This completely resolves the question of the minimum size of conditioning sets required to learn the graph. When it comes to the number of tests, our upper bound on the sizes of conditioning sets implies that every $n$-vertex graph can be learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at most $\\kappa$. We show that for any upper bound $q$ on the sizes of the conditioning sets, there exist graphs with $O(n q)$ vertices that require at least $n^{\\Omega(\\kappa)}$ tests to learn. This lower bound holds even when the treewidth and the maximum degree of the graph are at most $\\kappa+2$. On the positive side, we prove that every graph of bounded treewidth can be learned by a polynomial number of tests with conditioning sets of sizes at most $2\\kappa$.","sentences":["Markov networks are probabilistic graphical models that employ undirected graphs to depict conditional independence relationships among variables.","Our focus lies in constraint-based structure learning, which entails learning the undirected graph from data through the execution of conditional independence tests.","We establish theoretical limits concerning two critical aspects of constraint-based learning of Markov networks: the number of tests and the sizes of the conditioning sets.","These bounds uncover an exciting interplay between the structural properties of the graph and the amount of tests required to learn a Markov network.","The starting point of our work is that the graph parameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number of vertex-disjoint paths connecting a pair of vertices in the graph, is responsible for the sizes of independence tests required to learn the graph.","On one hand, we show that at least one test with the size of the conditioning set at least $\\kappa$ is always necessary.","On the other hand, we prove that any graph can be learned by performing tests of size at most $\\kappa$. This completely resolves the question of the minimum size of conditioning sets required to learn the graph.","When it comes to the number of tests, our upper bound on the sizes of conditioning sets implies that every $n$-vertex graph can be learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at most $\\kappa$. We show that for any upper bound $q$ on the sizes of the conditioning sets, there exist graphs with $O(n q)$ vertices that require at least $n^{\\Omega(\\kappa)}$ tests to learn.","This lower bound holds even when the treewidth and the maximum degree of the graph are at most $\\kappa+2$. On the positive side, we prove that every graph of bounded treewidth can be learned by a polynomial number of tests with conditioning sets of sizes at most $2\\kappa$."],"url":"http://arxiv.org/abs/2403.08562v1"}
{"created":"2024-03-13 14:10:10","title":"End-to-End Amp Modeling: From Data to Controllable Guitar Amplifier Models","abstract":"This paper describes a data-driven approach to creating real-time neural network models of guitar amplifiers, recreating the amplifiers' sonic response to arbitrary inputs at the full range of controls present on the physical device. While the focus on the paper is on the data collection pipeline, we demonstrate the effectiveness of this conditioned black-box approach by training an LSTM model to the task, and comparing its performance to an offline white-box SPICE circuit simulation. Our listening test results demonstrate that the neural amplifier modeling approach can match the subjective performance of a high-quality SPICE model, all while using an automated, non-intrusive data collection process, and an end-to-end trainable, real-time feasible neural network model.","sentences":["This paper describes a data-driven approach to creating real-time neural network models of guitar amplifiers, recreating the amplifiers' sonic response to arbitrary inputs at the full range of controls present on the physical device.","While the focus on the paper is on the data collection pipeline, we demonstrate the effectiveness of this conditioned black-box approach by training an LSTM model to the task, and comparing its performance to an offline white-box SPICE circuit simulation.","Our listening test results demonstrate that the neural amplifier modeling approach can match the subjective performance of a high-quality SPICE model, all while using an automated, non-intrusive data collection process, and an end-to-end trainable, real-time feasible neural network model."],"url":"http://arxiv.org/abs/2403.08559v1"}
{"created":"2024-03-13 14:08:25","title":"SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model","abstract":"The generalization of monocular metric depth estimation (MMDE) has been a longstanding challenge. Recent methods made progress by combining relative and metric depth or aligning input image focal length. However, they are still beset by challenges in camera, scene, and data levels: (1) Sensitivity to different cameras; (2) Inconsistent accuracy across scenes; (3) Reliance on massive training data. This paper proposes SM4Depth, a seamless MMDE method, to address all the issues above within a single network. First, we reveal that a consistent field of view (FOV) is the key to resolve ``metric ambiguity'' across cameras, which guides us to propose a more straightforward preprocessing unit. Second, to achieve consistently high accuracy across scenes, we explicitly model the metric scale determination as discretizing the depth interval into bins and propose variation-based unnormalized depth bins. This method bridges the depth gap of diverse scenes by reducing the ambiguity of the conventional metric bin. Third, to reduce the reliance on massive training data, we propose a ``divide and conquer\" solution. Instead of estimating directly from the vast solution space, the correct metric bins are estimated from multiple solution sub-spaces for complexity reduction. Finally, with just 150K RGB-D pairs and a consumer-grade GPU for training, SM4Depth achieves state-of-the-art performance on most previously unseen datasets, especially surpassing ZoeDepth and Metric3D on mRI$_\\theta$. The code can be found at https://github.com/1hao-Liu/SM4Depth.","sentences":["The generalization of monocular metric depth estimation (MMDE) has been a longstanding challenge.","Recent methods made progress by combining relative and metric depth or aligning input image focal length.","However, they are still beset by challenges in camera, scene, and data levels: (1) Sensitivity to different cameras; (2) Inconsistent accuracy across scenes; (3) Reliance on massive training data.","This paper proposes SM4Depth, a seamless MMDE method, to address all the issues above within a single network.","First, we reveal that a consistent field of view (FOV) is the key to resolve ``metric ambiguity'' across cameras, which guides us to propose a more straightforward preprocessing unit.","Second, to achieve consistently high accuracy across scenes, we explicitly model the metric scale determination as discretizing the depth interval into bins and propose variation-based unnormalized depth bins.","This method bridges the depth gap of diverse scenes by reducing the ambiguity of the conventional metric bin.","Third, to reduce the reliance on massive training data, we propose a ``divide and conquer\" solution.","Instead of estimating directly from the vast solution space, the correct metric bins are estimated from multiple solution sub-spaces for complexity reduction.","Finally, with just 150K RGB-D pairs and a consumer-grade GPU for training, SM4Depth achieves state-of-the-art performance on most previously unseen datasets, especially surpassing ZoeDepth and Metric3D on mRI$_\\theta$. The code can be found at https://github.com/1hao-Liu/SM4Depth."],"url":"http://arxiv.org/abs/2403.08556v1"}
{"created":"2024-03-13 14:06:51","title":"Federated Knowledge Graph Unlearning via Diffusion Model","abstract":"Federated learning (FL) promotes the development and application of artificial intelligence technologies by enabling model sharing and collaboration while safeguarding data privacy. Knowledge graph (KG) embedding representation provides a foundation for knowledge reasoning and applications by mapping entities and relations into vector space. Federated KG embedding enables the utilization of knowledge from diverse client sources while safeguarding the privacy of local data. However, due to demands such as privacy protection and the need to adapt to dynamic data changes, investigations into machine unlearning (MU) have been sparked. However, it is challenging to maintain the performance of KG embedding models while forgetting the influence of specific forgotten data on the model. In this paper, we propose FedDM, a novel framework tailored for machine unlearning in federated knowledge graphs. Leveraging diffusion models, we generate noisy data to sensibly mitigate the influence of specific knowledge on FL models while preserving the overall performance concerning the remaining data. We conduct experimental evaluations on benchmark datasets to assess the efficacy of the proposed model. Extensive experiments demonstrate that FedDM yields promising results in knowledge forgetting.","sentences":["Federated learning (FL) promotes the development and application of artificial intelligence technologies by enabling model sharing and collaboration while safeguarding data privacy.","Knowledge graph (KG) embedding representation provides a foundation for knowledge reasoning and applications by mapping entities and relations into vector space.","Federated KG embedding enables the utilization of knowledge from diverse client sources while safeguarding the privacy of local data.","However, due to demands such as privacy protection and the need to adapt to dynamic data changes, investigations into machine unlearning (MU) have been sparked.","However, it is challenging to maintain the performance of KG embedding models while forgetting the influence of specific forgotten data on the model.","In this paper, we propose FedDM, a novel framework tailored for machine unlearning in federated knowledge graphs.","Leveraging diffusion models, we generate noisy data to sensibly mitigate the influence of specific knowledge on FL models while preserving the overall performance concerning the remaining data.","We conduct experimental evaluations on benchmark datasets to assess the efficacy of the proposed model.","Extensive experiments demonstrate that FedDM yields promising results in knowledge forgetting."],"url":"http://arxiv.org/abs/2403.08554v1"}
{"created":"2024-03-13 13:56:34","title":"AIGCs Confuse AI Too: Investigating and Explaining Synthetic Image-induced Hallucinations in Large Vision-Language Models","abstract":"The evolution of Artificial Intelligence Generated Contents (AIGCs) is advancing towards higher quality. The growing interactions with AIGCs present a new challenge to the data-driven AI community: While AI-generated contents have played a crucial role in a wide range of AI models, the potential hidden risks they introduce have not been thoroughly examined. Beyond human-oriented forgery detection, AI-generated content poses potential issues for AI models originally designed to process natural data. In this study, we underscore the exacerbated hallucination phenomena in Large Vision-Language Models (LVLMs) caused by AI-synthetic images. Remarkably, our findings shed light on a consistent AIGC \\textbf{hallucination bias}: the object hallucinations induced by synthetic images are characterized by a greater quantity and a more uniform position distribution, even these synthetic images do not manifest unrealistic or additional relevant visual features compared to natural images. Moreover, our investigations on Q-former and Linear projector reveal that synthetic images may present token deviations after visual projection, thereby amplifying the hallucination bias.","sentences":["The evolution of Artificial Intelligence Generated Contents (AIGCs) is advancing towards higher quality.","The growing interactions with AIGCs present a new challenge to the data-driven AI community: While AI-generated contents have played a crucial role in a wide range of AI models, the potential hidden risks they introduce have not been thoroughly examined.","Beyond human-oriented forgery detection, AI-generated content poses potential issues for AI models originally designed to process natural data.","In this study, we underscore the exacerbated hallucination phenomena in Large Vision-Language Models (LVLMs) caused by AI-synthetic images.","Remarkably, our findings shed light on a consistent AIGC \\textbf{hallucination bias}: the object hallucinations induced by synthetic images are characterized by a greater quantity and a more uniform position distribution, even these synthetic images do not manifest unrealistic or additional relevant visual features compared to natural images.","Moreover, our investigations on Q-former and Linear projector reveal that synthetic images may present token deviations after visual projection, thereby amplifying the hallucination bias."],"url":"http://arxiv.org/abs/2403.08542v1"}
{"created":"2024-03-13 13:54:00","title":"Language models scale reliably with over-training and on downstream tasks","abstract":"Scaling laws are useful guides for developing language models, but there are still gaps between current scaling studies and how language models are ultimately trained and evaluated. For instance, scaling is usually studied in the compute-optimal training regime (i.e., \"Chinchilla optimal\" regime); however, in practice, models are often over-trained to reduce inference costs. Moreover, scaling laws mostly predict loss on next-token prediction, but ultimately models are compared based on downstream task performance. In this paper, we address both shortcomings. To do so, we create a testbed of 104 models with 0.011B to 6.9B parameters trained with various numbers of tokens on three data distributions. First, we investigate scaling in the over-trained regime. We fit scaling laws that extrapolate in both the number of model parameters and the ratio of training tokens to parameters. This enables us to predict the validation loss of a 1.4B parameter, 900B token run (i.e., 32$\\times$ over-trained) and a 6.9B parameter, 138B token run$\\unicode{x2014}$each from experiments that take 300$\\times$ less compute. Second, we relate the perplexity of a language model to its downstream task performance via a power law. We use this law to predict top-1 error averaged over downstream tasks for the two aforementioned models using experiments that take 20$\\times$ less compute. Our experiments are available at https://github.com/mlfoundations/scaling.","sentences":["Scaling laws are useful guides for developing language models, but there are still gaps between current scaling studies and how language models are ultimately trained and evaluated.","For instance, scaling is usually studied in the compute-optimal training regime (i.e., \"Chinchilla optimal\" regime); however, in practice, models are often over-trained to reduce inference costs.","Moreover, scaling laws mostly predict loss on next-token prediction, but ultimately models are compared based on downstream task performance.","In this paper, we address both shortcomings.","To do so, we create a testbed of 104 models with 0.011B to 6.9B parameters trained with various numbers of tokens on three data distributions.","First, we investigate scaling in the over-trained regime.","We fit scaling laws that extrapolate in both the number of model parameters and the ratio of training tokens to parameters.","This enables us to predict the validation loss of a 1.4B parameter, 900B token run (i.e., 32$\\times$ over-trained) and a 6.9B parameter, 138B token run$\\unicode{x2014}$each from experiments that take 300$\\times$ less compute.","Second, we relate the perplexity of a language model to its downstream task performance via a power law.","We use this law to predict top-1 error averaged over downstream tasks for the two aforementioned models using experiments that take 20$\\times$ less compute.","Our experiments are available at https://github.com/mlfoundations/scaling."],"url":"http://arxiv.org/abs/2403.08540v1"}
{"created":"2024-03-13 13:33:35","title":"From Weak to Strong Sound Event Labels using Adaptive Change-Point Detection and Active Learning","abstract":"In this work we propose an audio recording segmentation method based on an adaptive change point detection (A-CPD) for machine guided weak label annotation of audio recording segments. The goal is to maximize the amount of information gained about the temporal activation's of the target sounds. For each unlabeled audio recording, we use a prediction model to derive a probability curve used to guide annotation. The prediction model is initially pre-trained on available annotated sound event data with classes that are disjoint from the classes in the unlabeled dataset. The prediction model then gradually adapts to the annotations provided by the annotator in an active learning loop. The queries used to guide the weak label annotator towards strong labels are derived using change point detection on these probabilities. We show that it is possible to derive strong labels of high quality even with a limited annotation budget, and show favorable results for A-CPD when compared to two baseline query strategies.","sentences":["In this work we propose an audio recording segmentation method based on an adaptive change point detection (A-CPD) for machine guided weak label annotation of audio recording segments.","The goal is to maximize the amount of information gained about the temporal activation's of the target sounds.","For each unlabeled audio recording, we use a prediction model to derive a probability curve used to guide annotation.","The prediction model is initially pre-trained on available annotated sound event data with classes that are disjoint from the classes in the unlabeled dataset.","The prediction model then gradually adapts to the annotations provided by the annotator in an active learning loop.","The queries used to guide the weak label annotator towards strong labels are derived using change point detection on these probabilities.","We show that it is possible to derive strong labels of high quality even with a limited annotation budget, and show favorable results for A-CPD when compared to two baseline query strategies."],"url":"http://arxiv.org/abs/2403.08525v1"}
{"created":"2024-03-13 13:15:13","title":"MobileAtlas: Geographically Decoupled Measurements in Cellular Networks for Security and Privacy Research","abstract":"Cellular networks are not merely data access networks to the Internet. Their distinct services and ability to form large complex compounds for roaming purposes make them an attractive research target in their own right. Their promise of providing a consistent service with comparable privacy and security across roaming partners falls apart at close inspection.   Thus, there is a need for controlled testbeds and measurement tools for cellular access networks doing justice to the technology's unique structure and global scope. Particularly, such measurements suffer from a combinatorial explosion of operators, mobile plans, and services. To cope with these challenges, we built a framework that geographically decouples the SIM from the cellular modem by selectively connecting both remotely. This allows testing any subscriber with any operator at any modem location within minutes without moving parts. The resulting GSM/UMTS/LTE measurement and testbed platform offers a controlled experimentation environment, which is scalable and cost-effective. The platform is extensible and fully open-sourced, allowing other researchers to contribute locations, SIM cards, and measurement scripts.   Using the above framework, our international experiments in commercial networks revealed exploitable inconsistencies in traffic metering, leading to multiple phreaking opportunities, i.e., fare-dodging. We also expose problematic IPv6 firewall configurations, hidden SIM card communication to the home network, and fingerprint dial progress tones to track victims across different roaming networks and countries with voice calls.","sentences":["Cellular networks are not merely data access networks to the Internet.","Their distinct services and ability to form large complex compounds for roaming purposes make them an attractive research target in their own right.","Their promise of providing a consistent service with comparable privacy and security across roaming partners falls apart at close inspection.   ","Thus, there is a need for controlled testbeds and measurement tools for cellular access networks doing justice to the technology's unique structure and global scope.","Particularly, such measurements suffer from a combinatorial explosion of operators, mobile plans, and services.","To cope with these challenges, we built a framework that geographically decouples the SIM from the cellular modem by selectively connecting both remotely.","This allows testing any subscriber with any operator at any modem location within minutes without moving parts.","The resulting GSM/UMTS/LTE measurement and testbed platform offers a controlled experimentation environment, which is scalable and cost-effective.","The platform is extensible and fully open-sourced, allowing other researchers to contribute locations, SIM cards, and measurement scripts.   ","Using the above framework, our international experiments in commercial networks revealed exploitable inconsistencies in traffic metering, leading to multiple phreaking opportunities, i.e., fare-dodging.","We also expose problematic IPv6 firewall configurations, hidden SIM card communication to the home network, and fingerprint dial progress tones to track victims across different roaming networks and countries with voice calls."],"url":"http://arxiv.org/abs/2403.08507v1"}
{"created":"2024-03-13 13:06:31","title":"Gaussian Splatting in Style","abstract":"Scene stylization extends the work of neural style transfer to three spatial dimensions. A vital challenge in this problem is to maintain the uniformity of the stylized appearance across a multi-view setting. A vast majority of the previous works achieve this by optimizing the scene with a specific style image. In contrast, we propose a novel architecture trained on a collection of style images, that at test time produces high quality stylized novel views. Our work builds up on the framework of 3D Gaussian splatting. For a given scene, we take the pretrained Gaussians and process them using a multi resolution hash grid and a tiny MLP to obtain the conditional stylised views. The explicit nature of 3D Gaussians give us inherent advantages over NeRF-based methods including geometric consistency, along with having a fast training and rendering regime. This enables our method to be useful for vast practical use cases such as in augmented or virtual reality applications. Through our experiments, we show our methods achieve state-of-the-art performance with superior visual quality on various indoor and outdoor real-world data.","sentences":["Scene stylization extends the work of neural style transfer to three spatial dimensions.","A vital challenge in this problem is to maintain the uniformity of the stylized appearance across a multi-view setting.","A vast majority of the previous works achieve this by optimizing the scene with a specific style image.","In contrast, we propose a novel architecture trained on a collection of style images, that at test time produces high quality stylized novel views.","Our work builds up on the framework of 3D Gaussian splatting.","For a given scene, we take the pretrained Gaussians and process them using a multi resolution hash grid and a tiny MLP to obtain the conditional stylised views.","The explicit nature of 3D Gaussians give us inherent advantages over NeRF-based methods including geometric consistency, along with having a fast training and rendering regime.","This enables our method to be useful for vast practical use cases such as in augmented or virtual reality applications.","Through our experiments, we show our methods achieve state-of-the-art performance with superior visual quality on various indoor and outdoor real-world data."],"url":"http://arxiv.org/abs/2403.08498v1"}
{"created":"2024-03-13 12:52:57","title":"CAM: A Collection of Snapshots of GitHub Java Repositories Together with Metrics","abstract":"Even though numerous researchers require stable datasets along with source code and basic metrics calculated on them, neither GitHub nor any other code hosting platform provides such a resource. Consequently, each researcher must download their own data, compute the necessary metrics, and then publish the dataset somewhere to ensure it remains accessible indefinitely. Our CAM (stands for ``Classes and Metrics'') project addresses this need. It is an open-source software capable of cloning Java repositories from GitHub, filtering out unnecessary files, parsing Java classes, and computing metrics such as Cyclomatic Complexity, Halstead Effort and Volume, C\\&K metrics, Maintainability Metrics, LCOM5 and HND, as well as some Git-based Metrics. At least once a year, we execute the entire script, a process which requires a minimum of ten days on a very powerful server, to generate a new dataset. Subsequently, we publish it on Amazon S3, thereby ensuring its availability as a reference for researchers. The latest archive of 2.2Gb that we published on the 2nd of March, 2024 includes 532K Java classes with 48 metrics for each class.","sentences":["Even though numerous researchers require stable datasets along with source code and basic metrics calculated on them, neither GitHub nor any other code hosting platform provides such a resource.","Consequently, each researcher must download their own data, compute the necessary metrics, and then publish the dataset somewhere to ensure it remains accessible indefinitely.","Our CAM (stands for ``Classes and Metrics'') project addresses this need.","It is an open-source software capable of cloning Java repositories from GitHub, filtering out unnecessary files, parsing Java classes, and computing metrics such as Cyclomatic Complexity, Halstead Effort and Volume, C\\&K metrics, Maintainability Metrics, LCOM5 and HND, as well as some Git-based Metrics.","At least once a year, we execute the entire script, a process which requires a minimum of ten days on a very powerful server, to generate a new dataset.","Subsequently, we publish it on Amazon S3, thereby ensuring its availability as a reference for researchers.","The latest archive of 2.2Gb that we published on the 2nd of March, 2024 includes 532K Java classes with 48 metrics for each class."],"url":"http://arxiv.org/abs/2403.08488v1"}
{"created":"2024-03-13 12:52:37","title":"Model Will Tell: Training Membership Inference for Diffusion Models","abstract":"Diffusion models pose risks of privacy breaches and copyright disputes, primarily stemming from the potential utilization of unauthorized data during the training phase. The Training Membership Inference (TMI) task aims to determine whether a specific sample has been used in the training process of a target model, representing a critical tool for privacy violation verification. However, the increased stochasticity inherent in diffusion renders traditional shadow-model-based or metric-based methods ineffective when applied to diffusion models. Moreover, existing methods only yield binary classification labels which lack necessary comprehensibility in practical applications. In this paper, we explore a novel perspective for the TMI task by leveraging the intrinsic generative priors within the diffusion model. Compared with unseen samples, training samples exhibit stronger generative priors within the diffusion model, enabling the successful reconstruction of substantially degraded training images. Consequently, we propose the Degrade Restore Compare (DRC) framework. In this framework, an image undergoes sequential degradation and restoration, and its membership is determined by comparing it with the restored counterpart. Experimental results verify that our approach not only significantly outperforms existing methods in terms of accuracy but also provides comprehensible decision criteria, offering evidence for potential privacy violations.","sentences":["Diffusion models pose risks of privacy breaches and copyright disputes, primarily stemming from the potential utilization of unauthorized data during the training phase.","The Training Membership Inference (TMI) task aims to determine whether a specific sample has been used in the training process of a target model, representing a critical tool for privacy violation verification.","However, the increased stochasticity inherent in diffusion renders traditional shadow-model-based or metric-based methods ineffective when applied to diffusion models.","Moreover, existing methods only yield binary classification labels which lack necessary comprehensibility in practical applications.","In this paper, we explore a novel perspective for the TMI task by leveraging the intrinsic generative priors within the diffusion model.","Compared with unseen samples, training samples exhibit stronger generative priors within the diffusion model, enabling the successful reconstruction of substantially degraded training images.","Consequently, we propose the Degrade Restore Compare (DRC) framework.","In this framework, an image undergoes sequential degradation and restoration, and its membership is determined by comparing it with the restored counterpart.","Experimental results verify that our approach not only significantly outperforms existing methods in terms of accuracy but also provides comprehensible decision criteria, offering evidence for potential privacy violations."],"url":"http://arxiv.org/abs/2403.08487v1"}
{"created":"2024-03-13 12:50:23","title":"Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH Mask based Efficient Fine-tuning","abstract":"In view of the huge number of parameters of Large language models (LLMs) , tuning all parameters is very costly, and accordingly fine-tuning specific parameters is more sensible. Most of parameter efficient fine-tuning (PEFT) concentrate on parameter selection strategies, such as additive method, selective method and reparametrization-based method. However, there are few methods that consider the impact of data samples on parameter selecting, such as Fish Mask based method. Fish Mask randomly choose a part of data samples and treat them equally during parameter selection, which is unable to dynamically select optimal parameters for inconstant data distributions. In this work, we adopt a data-oriented perspective, then proposing an IRD ($\\mathrm{\\underline I}$terative sample-parameter $\\mathrm{\\underline R}$ange $\\mathrm{\\underline D}$ecreasing) algorithm to search the best setting of sample-parameter pair for FISH Mask. In each iteration, by searching the set of samples and parameters with larger Fish information, IRD can find better sample-parameter pair in most scale. We demonstrate the effectiveness and rationality of proposed strategy by conducting experiments on GLUE benchmark. Experimental results show our strategy optimizes the parameter selection and achieves preferable performance.","sentences":["In view of the huge number of parameters of Large language models (LLMs) , tuning all parameters is very costly, and accordingly fine-tuning specific parameters is more sensible.","Most of parameter efficient fine-tuning (PEFT) concentrate on parameter selection strategies, such as additive method, selective method and reparametrization-based method.","However, there are few methods that consider the impact of data samples on parameter selecting, such as Fish Mask based method.","Fish Mask randomly choose a part of data samples and treat them equally during parameter selection, which is unable to dynamically select optimal parameters for inconstant data distributions.","In this work, we adopt a data-oriented perspective, then proposing an IRD ($\\mathrm{\\underline I}$terative sample-parameter $\\mathrm{\\underline R}$ange $\\mathrm{\\underline D}$ecreasing) algorithm to search the best setting of sample-parameter pair for FISH Mask.","In each iteration, by searching the set of samples and parameters with larger Fish information, IRD can find better sample-parameter pair in most scale.","We demonstrate the effectiveness and rationality of proposed strategy by conducting experiments on GLUE benchmark.","Experimental results show our strategy optimizes the parameter selection and achieves preferable performance."],"url":"http://arxiv.org/abs/2403.08484v1"}
{"created":"2024-03-13 12:46:51","title":"SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks","abstract":"Natural language processing models have experienced a significant upsurge in recent years, with numerous applications being built upon them. Many of these applications require fine-tuning generic base models on customized, proprietary datasets. This fine-tuning data is especially likely to contain personal or sensitive information about individuals, resulting in increased privacy risk. Membership inference attacks are the most commonly employed attack to assess the privacy leakage of a machine learning model. However, limited research is available on the factors that affect the vulnerability of language models to this kind of attack, or on the applicability of different defense strategies in the language domain. We provide the first systematic review of the vulnerability of fine-tuned large language models to membership inference attacks, the various factors that come into play, and the effectiveness of different defense strategies. We find that some training methods provide significantly reduced privacy risk, with the combination of differential privacy and low-rank adaptors achieving the best privacy protection against these attacks.","sentences":["Natural language processing models have experienced a significant upsurge in recent years, with numerous applications being built upon them.","Many of these applications require fine-tuning generic base models on customized, proprietary datasets.","This fine-tuning data is especially likely to contain personal or sensitive information about individuals, resulting in increased privacy risk.","Membership inference attacks are the most commonly employed attack to assess the privacy leakage of a machine learning model.","However, limited research is available on the factors that affect the vulnerability of language models to this kind of attack, or on the applicability of different defense strategies in the language domain.","We provide the first systematic review of the vulnerability of fine-tuned large language models to membership inference attacks, the various factors that come into play, and the effectiveness of different defense strategies.","We find that some training methods provide significantly reduced privacy risk, with the combination of differential privacy and low-rank adaptors achieving the best privacy protection against these attacks."],"url":"http://arxiv.org/abs/2403.08481v1"}
{"created":"2024-03-13 12:31:08","title":"An Analysis of Human Alignment of Latent Diffusion Models","abstract":"Diffusion models, trained on large amounts of data, showed remarkable performance for image synthesis. They have high error consistency with humans and low texture bias when used for classification. Furthermore, prior work demonstrated the decomposability of their bottleneck layer representations into semantic directions. In this work, we analyze how well such representations are aligned to human responses on a triplet odd-one-out task. We find that despite the aforementioned observations: I) The representational alignment with humans is comparable to that of models trained only on ImageNet-1k. II) The most aligned layers of the denoiser U-Net are intermediate layers and not the bottleneck. III) Text conditioning greatly improves alignment at high noise levels, hinting at the importance of abstract textual information, especially in the early stage of generation.","sentences":["Diffusion models, trained on large amounts of data, showed remarkable performance for image synthesis.","They have high error consistency with humans and low texture bias when used for classification.","Furthermore, prior work demonstrated the decomposability of their bottleneck layer representations into semantic directions.","In this work, we analyze how well such representations are aligned to human responses on a triplet odd-one-out task.","We find that despite the aforementioned observations: I)","The representational alignment with humans is comparable to that of models trained only on ImageNet-1k. II)","The most aligned layers of the denoiser U-Net are intermediate layers and not the bottleneck.","III)","Text conditioning greatly improves alignment at high noise levels, hinting at the importance of abstract textual information, especially in the early stage of generation."],"url":"http://arxiv.org/abs/2403.08469v1"}
{"created":"2024-03-13 12:26:50","title":"A Comparison of SynDiffix Multi-table versus Single-table Synthetic Data","abstract":"SynDiffix is a new open-source tool for structured data synthesis. It has anonymization features that allow it to generate multiple synthetic tables while maintaining strong anonymity. Compared to the more common single-table approach, multi-table leads to more accurate data, since only the features of interest for a given analysis need be synthesized. This paper compares SynDiffix with 15 other commercial and academic synthetic data techniques using the SDNIST analysis framework, modified by us to accommodate multi-table synthetic data. The results show that SynDiffix is many times more accurate than other approaches for low-dimension tables, but somewhat worse than the best single-table techniques for high-dimension tables.","sentences":["SynDiffix is a new open-source tool for structured data synthesis.","It has anonymization features that allow it to generate multiple synthetic tables while maintaining strong anonymity.","Compared to the more common single-table approach, multi-table leads to more accurate data, since only the features of interest for a given analysis need be synthesized.","This paper compares SynDiffix with 15 other commercial and academic synthetic data techniques using the SDNIST analysis framework, modified by us to accommodate multi-table synthetic data.","The results show that SynDiffix is many times more accurate than other approaches for low-dimension tables, but somewhat worse than the best single-table techniques for high-dimension tables."],"url":"http://arxiv.org/abs/2403.08463v1"}
{"created":"2024-03-13 12:25:47","title":"Authorship Verification based on the Likelihood Ratio of Grammar Models","abstract":"Authorship Verification (AV) is the process of analyzing a set of documents to determine whether they were written by a specific author. This problem often arises in forensic scenarios, e.g., in cases where the documents in question constitute evidence for a crime. Existing state-of-the-art AV methods use computational solutions that are not supported by a plausible scientific explanation for their functioning and that are often difficult for analysts to interpret. To address this, we propose a method relying on calculating a quantity we call $\\lambda_G$ (LambdaG): the ratio between the likelihood of a document given a model of the Grammar for the candidate author and the likelihood of the same document given a model of the Grammar for a reference population. These Grammar Models are estimated using $n$-gram language models that are trained solely on grammatical features. Despite not needing large amounts of data for training, LambdaG still outperforms other established AV methods with higher computational complexity, including a fine-tuned Siamese Transformer network. Our empirical evaluation based on four baseline methods applied to twelve datasets shows that LambdaG leads to better results in terms of both accuracy and AUC in eleven cases and in all twelve cases if considering only topic-agnostic methods. The algorithm is also highly robust to important variations in the genre of the reference population in many cross-genre comparisons. In addition to these properties, we demonstrate how LambdaG is easier to interpret than the current state-of-the-art. We argue that the advantage of LambdaG over other methods is due to fact that it is compatible with Cognitive Linguistic theories of language processing.","sentences":["Authorship Verification (AV) is the process of analyzing a set of documents to determine whether they were written by a specific author.","This problem often arises in forensic scenarios, e.g., in cases where the documents in question constitute evidence for a crime.","Existing state-of-the-art AV methods use computational solutions that are not supported by a plausible scientific explanation for their functioning and that are often difficult for analysts to interpret.","To address this, we propose a method relying on calculating a quantity we call $\\lambda_G$ (LambdaG): the ratio between the likelihood of a document given a model of the Grammar for the candidate author and the likelihood of the same document given a model of the Grammar for a reference population.","These Grammar Models are estimated using $n$-gram language models that are trained solely on grammatical features.","Despite not needing large amounts of data for training, LambdaG still outperforms other established AV methods with higher computational complexity, including a fine-tuned Siamese Transformer network.","Our empirical evaluation based on four baseline methods applied to twelve datasets shows that LambdaG leads to better results in terms of both accuracy and AUC in eleven cases and in all twelve cases if considering only topic-agnostic methods.","The algorithm is also highly robust to important variations in the genre of the reference population in many cross-genre comparisons.","In addition to these properties, we demonstrate how LambdaG is easier to interpret than the current state-of-the-art.","We argue that the advantage of LambdaG over other methods is due to fact that it is compatible with Cognitive Linguistic theories of language processing."],"url":"http://arxiv.org/abs/2403.08462v1"}
{"created":"2024-03-13 12:20:20","title":"Towards Dense and Accurate Radar Perception Via Efficient Cross-Modal Diffusion Model","abstract":"Millimeter wave (mmWave) radars have attracted significant attention from both academia and industry due to their capability to operate in extreme weather conditions. However, they face challenges in terms of sparsity and noise interference, which hinder their application in the field of micro aerial vehicle (MAV) autonomous navigation. To this end, this paper proposes a novel approach to dense and accurate mmWave radar point cloud construction via cross-modal learning. Specifically, we introduce diffusion models, which possess state-of-the-art performance in generative modeling, to predict LiDAR-like point clouds from paired raw radar data. We also incorporate the most recent diffusion model inference accelerating techniques to ensure that the proposed method can be implemented on MAVs with limited computing resources.We validate the proposed method through extensive benchmark comparisons and real-world experiments, demonstrating its superior performance and generalization ability. Code and pretrained models will be available at https://github.com/ZJU-FAST-Lab/Radar-Diffusion.","sentences":["Millimeter wave (mmWave) radars have attracted significant attention from both academia and industry due to their capability to operate in extreme weather conditions.","However, they face challenges in terms of sparsity and noise interference, which hinder their application in the field of micro aerial vehicle (MAV) autonomous navigation.","To this end, this paper proposes a novel approach to dense and accurate mmWave radar point cloud construction via cross-modal learning.","Specifically, we introduce diffusion models, which possess state-of-the-art performance in generative modeling, to predict LiDAR-like point clouds from paired raw radar data.","We also incorporate the most recent diffusion model inference accelerating techniques to ensure that the proposed method can be implemented on MAVs with limited computing resources.","We validate the proposed method through extensive benchmark comparisons and real-world experiments, demonstrating its superior performance and generalization ability.","Code and pretrained models will be available at https://github.com/ZJU-FAST-Lab/Radar-Diffusion."],"url":"http://arxiv.org/abs/2403.08460v1"}
{"created":"2024-03-13 12:09:44","title":"IAMCV Multi-Scenario Vehicle Interaction Dataset","abstract":"The acquisition and analysis of high-quality sensor data constitute an essential requirement in shaping the development of fully autonomous driving systems. This process is indispensable for enhancing road safety and ensuring the effectiveness of the technological advancements in the automotive industry. This study introduces the Interaction of Autonomous and Manually-Controlled Vehicles (IAMCV) dataset, a novel and extensive dataset focused on inter-vehicle interactions. The dataset, enriched with a sophisticated array of sensors such as Light Detection and Ranging, cameras, Inertial Measurement Unit/Global Positioning System, and vehicle bus data acquisition, provides a comprehensive representation of real-world driving scenarios that include roundabouts, intersections, country roads, and highways, recorded across diverse locations in Germany. Furthermore, the study shows the versatility of the IAMCV dataset through several proof-of-concept use cases. Firstly, an unsupervised trajectory clustering algorithm illustrates the dataset's capability in categorizing vehicle movements without the need for labeled training data. Secondly, we compare an online camera calibration method with the Robot Operating System-based standard, using images captured in the dataset. Finally, a preliminary test employing the YOLOv8 object-detection model is conducted, augmented by reflections on the transferability of object detection across various LIDAR resolutions. These use cases underscore the practical utility of the collected dataset, emphasizing its potential to advance research and innovation in the area of intelligent vehicles.","sentences":["The acquisition and analysis of high-quality sensor data constitute an essential requirement in shaping the development of fully autonomous driving systems.","This process is indispensable for enhancing road safety and ensuring the effectiveness of the technological advancements in the automotive industry.","This study introduces the Interaction of Autonomous and Manually-Controlled Vehicles (IAMCV) dataset, a novel and extensive dataset focused on inter-vehicle interactions.","The dataset, enriched with a sophisticated array of sensors such as Light Detection and Ranging, cameras, Inertial Measurement Unit/Global Positioning System, and vehicle bus data acquisition, provides a comprehensive representation of real-world driving scenarios that include roundabouts, intersections, country roads, and highways, recorded across diverse locations in Germany.","Furthermore, the study shows the versatility of the IAMCV dataset through several proof-of-concept use cases.","Firstly, an unsupervised trajectory clustering algorithm illustrates the dataset's capability in categorizing vehicle movements without the need for labeled training data.","Secondly, we compare an online camera calibration method with the Robot Operating System-based standard, using images captured in the dataset.","Finally, a preliminary test employing the YOLOv8 object-detection model is conducted, augmented by reflections on the transferability of object detection across various LIDAR resolutions.","These use cases underscore the practical utility of the collected dataset, emphasizing its potential to advance research and innovation in the area of intelligent vehicles."],"url":"http://arxiv.org/abs/2403.08455v1"}
{"created":"2024-03-13 12:06:42","title":"An Integrated Usability Framework for Evaluating Open Government Data Portals: Comparative Analysis of EU and GCC Countries","abstract":"This study explores the critical role of open government data (OGD) portals in fostering transparency and collaboration between diverse stakeholders. Recognizing the challenges of usability, communication with diverse populations, and strategic value creation, this paper develops an integrated framework for evaluating OGD portal effectiveness that accommodates user diversity (regardless of their data literacy and language), evaluates collaboration and participation, and the ability of users to explore and understand the data provided through them. The framework is validated by applying it to 33 national portals across European Union and Gulf Cooperation Council (GCC) countries, as a result of which we rank OGD portals, identify some good practices that lower-performing portals can learn from, and common shortcomings. Notably, the study unveils the competitive and innovative nature of GCC OGD portals, pinpointing specific improvement areas such as multilingual support and data understandability. The findings underscore the growing trend of exposing data quality metrics and advocate for enhanced two-way communication channels between users and portal representatives. Overall, the study contributes to accelerating the development of user-friendly, collaborative, and sustainable OGD portals while addressing gaps identified in previous research.","sentences":["This study explores the critical role of open government data (OGD) portals in fostering transparency and collaboration between diverse stakeholders.","Recognizing the challenges of usability, communication with diverse populations, and strategic value creation, this paper develops an integrated framework for evaluating OGD portal effectiveness that accommodates user diversity (regardless of their data literacy and language), evaluates collaboration and participation, and the ability of users to explore and understand the data provided through them.","The framework is validated by applying it to 33 national portals across European Union and Gulf Cooperation Council (GCC) countries, as a result of which we rank OGD portals, identify some good practices that lower-performing portals can learn from, and common shortcomings.","Notably, the study unveils the competitive and innovative nature of GCC OGD portals, pinpointing specific improvement areas such as multilingual support and data understandability.","The findings underscore the growing trend of exposing data quality metrics and advocate for enhanced two-way communication channels between users and portal representatives.","Overall, the study contributes to accelerating the development of user-friendly, collaborative, and sustainable OGD portals while addressing gaps identified in previous research."],"url":"http://arxiv.org/abs/2403.08451v1"}
{"created":"2024-03-13 11:44:30","title":"Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research","abstract":"Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years. Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data. This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings. Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work. For this we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks. Building on these efforts we turn towards another critical challenge in machine learning, namely the curse of dimensionality, which poses challenges in data collection, representation, and analysis, making it harder to find representative data and impeding the training and inference processes. Using the closely linked concept of geometric intrinsic dimension we investigate to which extend the used machine learning models are influenced by the intrinsic dimension of the data sets they are trained on.","sentences":["Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years.","Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data.","This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings.","Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work.","For this we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks.","Building on these efforts we turn towards another critical challenge in machine learning, namely the curse of dimensionality, which poses challenges in data collection, representation, and analysis, making it harder to find representative data and impeding the training and inference processes.","Using the closely linked concept of geometric intrinsic dimension we investigate to which extend the used machine learning models are influenced by the intrinsic dimension of the data sets they are trained on."],"url":"http://arxiv.org/abs/2403.08438v1"}
{"created":"2024-03-13 11:33:38","title":"An Empirical Study of Parameter Efficient Fine-tuning on Vision-Language Pre-train Model","abstract":"Recent studies applied Parameter Efficient Fine-Tuning techniques (PEFTs) to efficiently narrow the performance gap between pre-training and downstream. There are two important factors for various PEFTs, namely, the accessible data size and fine-tunable parameter size. A natural expectation for PEFTs is that the performance of various PEFTs is positively related to the data size and fine-tunable parameter size. However, according to the evaluation of five PEFTs on two downstream vision-language (VL) tasks, we find that such an intuition holds only if the downstream data and task are not consistent with pre-training. For downstream fine-tuning consistent with pre-training, data size no longer affects the performance, while the influence of fine-tunable parameter size is not monotonous. We believe such an observation could guide the choice of training strategy for various PEFTs.","sentences":["Recent studies applied Parameter Efficient Fine-Tuning techniques (PEFTs) to efficiently narrow the performance gap between pre-training and downstream.","There are two important factors for various PEFTs, namely, the accessible data size and fine-tunable parameter size.","A natural expectation for PEFTs is that the performance of various PEFTs is positively related to the data size and fine-tunable parameter size.","However, according to the evaluation of five PEFTs on two downstream vision-language (VL) tasks, we find that such an intuition holds only if the downstream data and task are not consistent with pre-training.","For downstream fine-tuning consistent with pre-training, data size no longer affects the performance, while the influence of fine-tunable parameter size is not monotonous.","We believe such an observation could guide the choice of training strategy for various PEFTs."],"url":"http://arxiv.org/abs/2403.08433v1"}
{"created":"2024-03-13 11:29:13","title":"Software Vulnerability and Functionality Assessment using LLMs","abstract":"While code review is central to the software development process, it can be tedious and expensive to carry out. In this paper, we investigate whether and how Large Language Models (LLMs) can aid with code reviews. Our investigation focuses on two tasks that we argue are fundamental to good reviews: (i) flagging code with security vulnerabilities and (ii) performing software functionality validation, i.e., ensuring that code meets its intended functionality. To test performance on both tasks, we use zero-shot and chain-of-thought prompting to obtain final ``approve or reject'' recommendations. As data, we employ seminal code generation datasets (HumanEval and MBPP) along with expert-written code snippets with security vulnerabilities from the Common Weakness Enumeration (CWE). Our experiments consider a mixture of three proprietary models from OpenAI and smaller open-source LLMs. We find that the former outperforms the latter by a large margin. Motivated by promising results, we finally ask our models to provide detailed descriptions of security vulnerabilities. Results show that 36.7% of LLM-generated descriptions can be associated with true CWE vulnerabilities.","sentences":["While code review is central to the software development process, it can be tedious and expensive to carry out.","In this paper, we investigate whether and how Large Language Models (LLMs) can aid with code reviews.","Our investigation focuses on two tasks that we argue are fundamental to good reviews: (i) flagging code with security vulnerabilities and (ii) performing software functionality validation, i.e., ensuring that code meets its intended functionality.","To test performance on both tasks, we use zero-shot and chain-of-thought prompting to obtain final ``approve or reject'' recommendations.","As data, we employ seminal code generation datasets (HumanEval and MBPP) along with expert-written code snippets with security vulnerabilities from the Common Weakness Enumeration (CWE).","Our experiments consider a mixture of three proprietary models from OpenAI and smaller open-source LLMs.","We find that the former outperforms the latter by a large margin.","Motivated by promising results, we finally ask our models to provide detailed descriptions of security vulnerabilities.","Results show that 36.7% of LLM-generated descriptions can be associated with true CWE vulnerabilities."],"url":"http://arxiv.org/abs/2403.08429v1"}
{"created":"2024-03-13 11:26:43","title":"DeepCSHAP: Utilizing Shapley Values to Explain Deep Complex-Valued Neural Networks","abstract":"Deep Neural Networks are widely used in academy as well as corporate and public applications, including safety critical applications such as health care and autonomous driving. The ability to explain their output is critical for safety reasons as well as acceptance among applicants. A multitude of methods have been proposed to explain real-valued neural networks. Recently, complex-valued neural networks have emerged as a new class of neural networks dealing with complex-valued input data without the necessity of projecting them onto $\\mathbb{R}^2$. This brings up the need to develop explanation algorithms for this kind of neural networks. In this paper we provide these developments. While we focus on adapting the widely used DeepSHAP algorithm to the complex domain, we also present versions of four gradient based explanation methods suitable for use in complex-valued neural networks. We evaluate the explanation quality of all presented algorithms and provide all of them as an open source library adaptable to most recent complex-valued neural network architectures.","sentences":["Deep Neural Networks are widely used in academy as well as corporate and public applications, including safety critical applications such as health care and autonomous driving.","The ability to explain their output is critical for safety reasons as well as acceptance among applicants.","A multitude of methods have been proposed to explain real-valued neural networks.","Recently, complex-valued neural networks have emerged as a new class of neural networks dealing with complex-valued input data without the necessity of projecting them onto $\\mathbb{R}^2$. This brings up the need to develop explanation algorithms for this kind of neural networks.","In this paper we provide these developments.","While we focus on adapting the widely used DeepSHAP algorithm to the complex domain, we also present versions of four gradient based explanation methods suitable for use in complex-valued neural networks.","We evaluate the explanation quality of all presented algorithms and provide all of them as an open source library adaptable to most recent complex-valued neural network architectures."],"url":"http://arxiv.org/abs/2403.08428v1"}
{"created":"2024-03-13 10:58:55","title":"Causal Graph Neural Networks for Wildfire Danger Prediction","abstract":"Wildfire forecasting is notoriously hard due to the complex interplay of different factors such as weather conditions, vegetation types and human activities. Deep learning models show promise in dealing with this complexity by learning directly from data. However, to inform critical decision making, we argue that we need models that are right for the right reasons; that is, the implicit rules learned should be grounded by the underlying processes driving wildfires. In that direction, we propose integrating causality with Graph Neural Networks (GNNs) that explicitly model the causal mechanism among complex variables via graph learning. The causal adjacency matrix considers the synergistic effect among variables and removes the spurious links from highly correlated impacts. Our methodology's effectiveness is demonstrated through superior performance forecasting wildfire patterns in the European boreal and mediterranean biome. The gain is especially prominent in a highly imbalanced dataset, showcasing an enhanced robustness of the model to adapt to regime shifts in functional relationships. Furthermore, SHAP values from our trained model further enhance our understanding of the model's inner workings.","sentences":["Wildfire forecasting is notoriously hard due to the complex interplay of different factors such as weather conditions, vegetation types and human activities.","Deep learning models show promise in dealing with this complexity by learning directly from data.","However, to inform critical decision making, we argue that we need models that are right for the right reasons; that is, the implicit rules learned should be grounded by the underlying processes driving wildfires.","In that direction, we propose integrating causality with Graph Neural Networks (GNNs) that explicitly model the causal mechanism among complex variables via graph learning.","The causal adjacency matrix considers the synergistic effect among variables and removes the spurious links from highly correlated impacts.","Our methodology's effectiveness is demonstrated through superior performance forecasting wildfire patterns in the European boreal and mediterranean biome.","The gain is especially prominent in a highly imbalanced dataset, showcasing an enhanced robustness of the model to adapt to regime shifts in functional relationships.","Furthermore, SHAP values from our trained model further enhance our understanding of the model's inner workings."],"url":"http://arxiv.org/abs/2403.08414v1"}
{"created":"2024-03-13 10:51:38","title":"Reduced Jeffries-Matusita distance: A Novel Loss Function to Improve Generalization Performance of Deep Classification Models","abstract":"The generalization performance of deep neural networks in classification tasks is a major concern in machine learning research. Despite widespread techniques used to diminish the over-fitting issue such as data augmentation, pseudo-labeling, regularization, and ensemble learning, this performance still needs to be enhanced with other approaches. In recent years, it has been theoretically demonstrated that the loss function characteristics i.e. its Lipschitzness and maximum value affect the generalization performance of deep neural networks which can be utilized as a guidance to propose novel distance measures. In this paper, by analyzing the aforementioned characteristics, we introduce a distance called Reduced Jeffries-Matusita as a loss function for training deep classification models to reduce the over-fitting issue. In our experiments, we evaluate the new loss function in two different problems: image classification in computer vision and node classification in the context of graph learning. The results show that the new distance measure stabilizes the training process significantly, enhances the generalization ability, and improves the performance of the models in the Accuracy and F1-score metrics, even if the training set size is small.","sentences":["The generalization performance of deep neural networks in classification tasks is a major concern in machine learning research.","Despite widespread techniques used to diminish the over-fitting issue such as data augmentation, pseudo-labeling, regularization, and ensemble learning, this performance still needs to be enhanced with other approaches.","In recent years, it has been theoretically demonstrated that the loss function characteristics i.e. its Lipschitzness and maximum value affect the generalization performance of deep neural networks which can be utilized as a guidance to propose novel distance measures.","In this paper, by analyzing the aforementioned characteristics, we introduce a distance called Reduced Jeffries-Matusita as a loss function for training deep classification models to reduce the over-fitting issue.","In our experiments, we evaluate the new loss function in two different problems: image classification in computer vision and node classification in the context of graph learning.","The results show that the new distance measure stabilizes the training process significantly, enhances the generalization ability, and improves the performance of the models in the Accuracy and F1-score metrics, even if the training set size is small."],"url":"http://arxiv.org/abs/2403.08408v1"}
{"created":"2024-03-13 10:51:18","title":"Iterative Online Image Synthesis via Diffusion Model for Imbalanced Classification","abstract":"Accurate and robust classification of diseases is important for proper diagnosis and treatment. However, medical datasets often face challenges related to limited sample sizes and inherent imbalanced distributions, due to difficulties in data collection and variations in disease prevalence across different types. In this paper, we introduce an Iterative Online Image Synthesis (IOIS) framework to address the class imbalance problem in medical image classification. Our framework incorporates two key modules, namely Online Image Synthesis (OIS) and Accuracy Adaptive Sampling (AAS), which collectively target the imbalance classification issue at both the instance level and the class level. The OIS module alleviates the data insufficiency problem by generating representative samples tailored for online training of the classifier. On the other hand, the AAS module dynamically balances the synthesized samples among various classes, targeting those with low training accuracy. To evaluate the effectiveness of our proposed method in addressing imbalanced classification, we conduct experiments on the HAM10000 and APTOS datasets. The results obtained demonstrate the superiority of our approach over state-of-the-art methods as well as the effectiveness of each component. The source code will be released upon acceptance.","sentences":["Accurate and robust classification of diseases is important for proper diagnosis and treatment.","However, medical datasets often face challenges related to limited sample sizes and inherent imbalanced distributions, due to difficulties in data collection and variations in disease prevalence across different types.","In this paper, we introduce an Iterative Online Image Synthesis (IOIS) framework to address the class imbalance problem in medical image classification.","Our framework incorporates two key modules, namely Online Image Synthesis (OIS) and Accuracy Adaptive Sampling (AAS), which collectively target the imbalance classification issue at both the instance level and the class level.","The OIS module alleviates the data insufficiency problem by generating representative samples tailored for online training of the classifier.","On the other hand, the AAS module dynamically balances the synthesized samples among various classes, targeting those with low training accuracy.","To evaluate the effectiveness of our proposed method in addressing imbalanced classification, we conduct experiments on the HAM10000 and APTOS datasets.","The results obtained demonstrate the superiority of our approach over state-of-the-art methods as well as the effectiveness of each component.","The source code will be released upon acceptance."],"url":"http://arxiv.org/abs/2403.08407v1"}
{"created":"2024-03-13 10:37:52","title":"FSDR: A Novel Deep Learning-based Feature Selection Algorithm for Pseudo Time-Series Data using Discrete Relaxation","abstract":"Conventional feature selection algorithms applied to Pseudo Time-Series (PTS) data, which consists of observations arranged in sequential order without adhering to a conventional temporal dimension, often exhibit impractical computational complexities with high dimensional data. To address this challenge, we introduce a Deep Learning (DL)-based feature selection algorithm: Feature Selection through Discrete Relaxation (FSDR), tailored for PTS data. Unlike the existing feature selection algorithms, FSDR learns the important features as model parameters using discrete relaxation, which refers to the process of approximating a discrete optimisation problem with a continuous one. FSDR is capable of accommodating a high number of feature dimensions, a capability beyond the reach of existing DL-based or traditional methods. Through testing on a hyperspectral dataset (i.e., a type of PTS data), our experimental results demonstrate that FSDR outperforms three commonly used feature selection algorithms, taking into account a balance among execution time, $R^2$, and $RMSE$.","sentences":["Conventional feature selection algorithms applied to Pseudo Time-Series (PTS) data, which consists of observations arranged in sequential order without adhering to a conventional temporal dimension, often exhibit impractical computational complexities with high dimensional data.","To address this challenge, we introduce a Deep Learning (DL)-based feature selection algorithm: Feature Selection through Discrete Relaxation (FSDR), tailored for PTS data.","Unlike the existing feature selection algorithms, FSDR learns the important features as model parameters using discrete relaxation, which refers to the process of approximating a discrete optimisation problem with a continuous one.","FSDR is capable of accommodating a high number of feature dimensions, a capability beyond the reach of existing DL-based or traditional methods.","Through testing on a hyperspectral dataset (i.e., a type of PTS data), our experimental results demonstrate that FSDR outperforms three commonly used feature selection algorithms, taking into account a balance among execution time, $R^2$, and $RMSE$."],"url":"http://arxiv.org/abs/2403.08403v1"}
{"created":"2024-03-13 10:19:10","title":"Worst-Case to Expander-Case Reductions: Derandomized and Generalized","abstract":"A recent paper by Abboud and Wallheimer [ITCS 2023] presents self-reductions for various fundamental graph problems, that transform worst-case instances to expanders, thus proving that the complexity remains unchanged if the input is assumed to be an expander. An interesting corollary of their self-reductions is that, if some problem admit such reduction, then the popular algorithmic paradigm based on expander-decompositions is useless against it. In this paper, we improve their core gadget, which augments a graph to make it an expander while retaining its important structure. Our new core construction has the benefit of being simple to analyze and generalize, while obtaining the following results:   1. A derandomization of the self-reductions, showing that the equivalence between worst-case and expander-case holds even for deterministic algorithms, and ruling out the use of expander-decompositions as a derandomization tool.   2. An extension of the results to other models of computation, such as the Fully Dynamic model and the Congested Clique model. In the former, we either improve or provide an alternative approach to some recent hardness results for dynamic expander graphs, by Henzinger, Paz, and Sricharan [ESA 2022].   In addition, we continue this line of research by designing new self-reductions for more problems, such as Max-Cut and dynamic Densest Subgraph, and demonstrating that the core gadget can be utilized to lift lower bounds based on the OMv Conjecture to expanders.","sentences":["A recent paper by Abboud and Wallheimer [ITCS 2023] presents self-reductions for various fundamental graph problems, that transform worst-case instances to expanders, thus proving that the complexity remains unchanged if the input is assumed to be an expander.","An interesting corollary of their self-reductions is that, if some problem admit such reduction, then the popular algorithmic paradigm based on expander-decompositions is useless against it.","In this paper, we improve their core gadget, which augments a graph to make it an expander while retaining its important structure.","Our new core construction has the benefit of being simple to analyze and generalize, while obtaining the following results:   1.","A derandomization of the self-reductions, showing that the equivalence between worst-case and expander-case holds even for deterministic algorithms, and ruling out the use of expander-decompositions as a derandomization tool.   ","2.","An extension of the results to other models of computation, such as the Fully Dynamic model and the Congested Clique model.","In the former, we either improve or provide an alternative approach to some recent hardness results for dynamic expander graphs, by Henzinger, Paz, and Sricharan [ESA 2022].   ","In addition, we continue this line of research by designing new self-reductions for more problems, such as Max-Cut and dynamic Densest Subgraph, and demonstrating that the core gadget can be utilized to lift lower bounds based on the OMv Conjecture to expanders."],"url":"http://arxiv.org/abs/2403.08394v1"}
{"created":"2024-03-13 09:48:04","title":"RAF-GI: Towards Robust, Accurate and Fast-Convergent Gradient Inversion Attack in Federated Learning","abstract":"Federated learning (FL) empowers privacy-preservation in model training by only exposing users' model gradients. Yet, FL users are susceptible to the gradient inversion (GI) attack which can reconstruct ground-truth training data such as images based on model gradients. However, reconstructing high-resolution images by existing GI attack works faces two challenges: inferior accuracy and slow-convergence, especially when the context is complicated, e.g., the training batch size is much greater than 1 on each FL user. To address these challenges, we present a Robust, Accurate and Fast-convergent GI attack algorithm, called RAF-GI, with two components: 1) Additional Convolution Block (ACB) which can restore labels with up to 20% improvement compared with existing works; 2) Total variance, three-channel mEan and cAnny edge detection regularization term (TEA), which is a white-box attack strategy to reconstruct images based on labels inferred by ACB. Moreover, RAF-GI is robust that can still accurately reconstruct ground-truth data when the users' training batch size is no more than 48. Our experimental results manifest that RAF-GI can diminish 94% time costs while achieving superb inversion quality in ImageNet dataset. Notably, with a batch size of 1, RAF-GI exhibits a 7.89 higher Peak Signal-to-Noise Ratio (PSNR) compared to the state-of-the-art baselines.","sentences":["Federated learning (FL) empowers privacy-preservation in model training by only exposing users' model gradients.","Yet, FL users are susceptible to the gradient inversion (GI) attack which can reconstruct ground-truth training data such as images based on model gradients.","However, reconstructing high-resolution images by existing GI attack works faces two challenges: inferior accuracy and slow-convergence, especially when the context is complicated, e.g., the training batch size is much greater than 1 on each FL user.","To address these challenges, we present a Robust, Accurate and Fast-convergent GI attack algorithm, called RAF-GI, with two components: 1) Additional Convolution Block (ACB) which can restore labels with up to 20% improvement compared with existing works; 2) Total variance, three-channel mEan and cAnny edge detection regularization term (TEA), which is a white-box attack strategy to reconstruct images based on labels inferred by ACB.","Moreover, RAF-GI is robust that can still accurately reconstruct ground-truth data when the users' training batch size is no more than 48.","Our experimental results manifest that RAF-GI can diminish 94% time costs while achieving superb inversion quality in ImageNet dataset.","Notably, with a batch size of 1, RAF-GI exhibits a 7.89 higher Peak Signal-to-Noise Ratio (PSNR) compared to the state-of-the-art baselines."],"url":"http://arxiv.org/abs/2403.08383v1"}
{"created":"2024-03-13 09:43:14","title":"A Generalized Framework with Adaptive Weighted Soft-Margin for Imbalanced SVM Classification","abstract":"Category imbalance is one of the most popular and important issues in the domain of classification. In this paper, we present a new generalized framework with Adaptive Weight function for soft-margin Weighted SVM (AW-WSVM), which aims to enhance the issue of imbalance and outlier sensitivity in standard support vector machine (SVM) for classifying two-class data. The weight coefficient is introduced into the unconstrained soft-margin support vector machines, and the sample weights are updated before each training. The Adaptive Weight function (AW function) is constructed from the distance between the samples and the decision hyperplane, assigning different weights to each sample. A weight update method is proposed, taking into account the proximity of the support vectors to the decision hyperplane. Before training, the weights of the corresponding samples are initialized according to different categories. Subsequently, the samples close to the decision hyperplane are identified and assigned more weights. At the same time, lower weights are assigned to samples that are far from the decision hyperplane. Furthermore, we also put forward an effective way to eliminate noise. To evaluate the strength of the proposed generalized framework, we conducted experiments on standard datasets and emotion classification datasets with different imbalanced ratios (IR). The experimental results prove that the proposed generalized framework outperforms in terms of accuracy, recall metrics and G-mean, validating the effectiveness of the weighted strategy provided in this paper in enhancing support vector machines.","sentences":["Category imbalance is one of the most popular and important issues in the domain of classification.","In this paper, we present a new generalized framework with Adaptive Weight function for soft-margin Weighted SVM (AW-WSVM), which aims to enhance the issue of imbalance and outlier sensitivity in standard support vector machine (SVM) for classifying two-class data.","The weight coefficient is introduced into the unconstrained soft-margin support vector machines, and the sample weights are updated before each training.","The Adaptive Weight function (AW function) is constructed from the distance between the samples and the decision hyperplane, assigning different weights to each sample.","A weight update method is proposed, taking into account the proximity of the support vectors to the decision hyperplane.","Before training, the weights of the corresponding samples are initialized according to different categories.","Subsequently, the samples close to the decision hyperplane are identified and assigned more weights.","At the same time, lower weights are assigned to samples that are far from the decision hyperplane.","Furthermore, we also put forward an effective way to eliminate noise.","To evaluate the strength of the proposed generalized framework, we conducted experiments on standard datasets and emotion classification datasets with different imbalanced ratios (IR).","The experimental results prove that the proposed generalized framework outperforms in terms of accuracy, recall metrics and G-mean, validating the effectiveness of the weighted strategy provided in this paper in enhancing support vector machines."],"url":"http://arxiv.org/abs/2403.08378v1"}
{"created":"2024-03-13 09:42:46","title":"Learning to Describe for Predicting Zero-shot Drug-Drug Interactions","abstract":"Adverse drug-drug interactions~(DDIs) can compromise the effectiveness of concurrent drug administration, posing a significant challenge in healthcare. As the development of new drugs continues, the potential for unknown adverse effects resulting from DDIs becomes a growing concern. Traditional computational methods for DDI prediction may fail to capture interactions for new drugs due to the lack of knowledge. In this paper, we introduce a new problem setup as zero-shot DDI prediction that deals with the case of new drugs. Leveraging textual information from online databases like DrugBank and PubChem, we propose an innovative approach TextDDI with a language model-based DDI predictor and a reinforcement learning~(RL)-based information selector, enabling the selection of concise and pertinent text for accurate DDI prediction on new drugs. Empirical results show the benefits of the proposed approach on several settings including zero-shot and few-shot DDI prediction, and the selected texts are semantically relevant. Our code and data are available at \\url{https://github.com/zhufq00/DDIs-Prediction}.","sentences":["Adverse drug-drug interactions~(DDIs) can compromise the effectiveness of concurrent drug administration, posing a significant challenge in healthcare.","As the development of new drugs continues, the potential for unknown adverse effects resulting from DDIs becomes a growing concern.","Traditional computational methods for DDI prediction may fail to capture interactions for new drugs due to the lack of knowledge.","In this paper, we introduce a new problem setup as zero-shot DDI prediction that deals with the case of new drugs.","Leveraging textual information from online databases like DrugBank and PubChem, we propose an innovative approach TextDDI with a language model-based DDI predictor and a reinforcement learning~(RL)-based information selector, enabling the selection of concise and pertinent text for accurate DDI prediction on new drugs.","Empirical results show the benefits of the proposed approach on several settings including zero-shot and few-shot DDI prediction, and the selected texts are semantically relevant.","Our code and data are available at \\url{https://github.com/zhufq00/DDIs-Prediction}."],"url":"http://arxiv.org/abs/2403.08377v1"}
{"created":"2024-03-13 09:39:15","title":"Nonlinear Manifold Learning Determines Microgel Size from Raman Spectroscopy","abstract":"Polymer particle size constitutes a crucial characteristic of product quality in polymerization. Raman spectroscopy is an established and reliable process analytical technology for in-line concentration monitoring. Recent approaches and some theoretical considerations show a correlation between Raman signals and particle sizes but do not determine polymer size from Raman spectroscopic measurements accurately and reliably. With this in mind, we propose three alternative machine learning workflows to perform this task, all involving diffusion maps, a nonlinear manifold learning technique for dimensionality reduction: (i) directly from diffusion maps, (ii) alternating diffusion maps, and (iii) conformal autoencoder neural networks. We apply the workflows to a data set of Raman spectra with associated size measured via dynamic light scattering of 47 microgel (cross-linked polymer) samples in a diameter range of 208nm to 483 nm. The conformal autoencoders substantially outperform state-of-the-art methods and results for the first time in a promising prediction of polymer size from Raman spectra.","sentences":["Polymer particle size constitutes a crucial characteristic of product quality in polymerization.","Raman spectroscopy is an established and reliable process analytical technology for in-line concentration monitoring.","Recent approaches and some theoretical considerations show a correlation between Raman signals and particle sizes but do not determine polymer size from Raman spectroscopic measurements accurately and reliably.","With this in mind, we propose three alternative machine learning workflows to perform this task, all involving diffusion maps, a nonlinear manifold learning technique for dimensionality reduction: (i) directly from diffusion maps, (ii) alternating diffusion maps, and (iii) conformal autoencoder neural networks.","We apply the workflows to a data set of Raman spectra with associated size measured via dynamic light scattering of 47 microgel (cross-linked polymer) samples in a diameter range of 208nm to 483 nm.","The conformal autoencoders substantially outperform state-of-the-art methods and results for the first time in a promising prediction of polymer size from Raman spectra."],"url":"http://arxiv.org/abs/2403.08376v1"}
{"created":"2024-03-13 09:38:22","title":"Error-Free Near-Optimal Validated Agreement","abstract":"Byzantine agreement enables n processes to agree on a common L-bit value, despite t > 0 arbitrary failures. A long line of work has been dedicated to improving the worst-case bit complexity of Byzantine agreement in synchrony. This has culminated in COOL, an error-free (deterministically secure against a computationally unbounded adversary) algorithm that achieves a near-optimal bit complexity of O(nL + n^2 log n). COOL satisfies strong validity: if all correct processes propose the same value, only that value can be decided. Thus, whenever correct processes do not a priori agree, COOL might decide on \"bottom\", thus limiting its application in today's state machine replication (SMR) and blockchain protocols. In this work, we focus on the aforementioned limitation. Can we design an error-free near-optimal Byzantine agreement algorithm applicable in today's SMR and blockchain protocols? Can we design an error-free near-optimal agreement algorithm with external validity (a.k.a. validated agreement) stipulating that only values valid according to a predetermined predicate can be decided?   This paper answers the question affirmatively. Namely, we present EXT, an error-free synchronous Byzantine agreement algorithm that satisfies external (along with strong) validity while exchanging O(n log n L + n^2 log n) bits in the worst case. Importantly, EXT is optimally resilient (tolerates t < n / 3 failures) and terminates in optimal O(n) rounds. Perhaps surprisingly, we construct EXT by exploiting existing concepts: (1) the recursive framework proposed by Berman, Garay and Perry and Coan and Welch and recently restated by Momose and Ren, (2) the aforementioned COOL algorithm introduced by Chen, and (3) the data dissemination primitive introduced by Das, Xiang and Ren.","sentences":["Byzantine agreement enables n processes to agree on a common L-bit value, despite t > 0 arbitrary failures.","A long line of work has been dedicated to improving the worst-case bit complexity of Byzantine agreement in synchrony.","This has culminated in COOL, an error-free (deterministically secure against a computationally unbounded adversary) algorithm that achieves a near-optimal bit complexity of O(nL + n^2 log n).","COOL satisfies strong validity: if all correct processes propose the same value, only that value can be decided.","Thus, whenever correct processes do not a priori agree, COOL might decide on \"bottom\", thus limiting its application in today's state machine replication (SMR) and blockchain protocols.","In this work, we focus on the aforementioned limitation.","Can we design an error-free near-optimal Byzantine agreement algorithm applicable in today's SMR and blockchain protocols?","Can we design an error-free near-optimal agreement algorithm with external validity (a.k.a. validated agreement) stipulating that only values valid according to a predetermined predicate can be decided?   ","This paper answers the question affirmatively.","Namely, we present EXT, an error-free synchronous Byzantine agreement algorithm that satisfies external (along with strong) validity while exchanging O(n log n L + n^2 log n) bits in the worst case.","Importantly, EXT is optimally resilient (tolerates t < n / 3 failures) and terminates in optimal O(n) rounds.","Perhaps surprisingly, we construct EXT by exploiting existing concepts: (1) the recursive framework proposed by Berman, Garay and Perry and Coan and Welch and recently restated by Momose and Ren, (2) the aforementioned COOL algorithm introduced by Chen, and (3) the data dissemination primitive introduced by Das, Xiang and Ren."],"url":"http://arxiv.org/abs/2403.08374v1"}
{"created":"2024-03-13 09:31:50","title":"SMART: Submodular Data Mixture Strategy for Instruction Tuning","abstract":"Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks. Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance remains challenging. Unfortunately, there's currently no systematic method beyond manual tuning or relying on practitioners' intuition. In this paper, we introduce SMART (Submodular data Mixture strAtegy for instRuction Tuning) - a novel data mixture strategy which makes use of a submodular function to assign importance scores to tasks which are then used to determine the mixture weights. Given a fine-tuning budget, SMART redistributes the budget among tasks and selects non-redundant samples from each task. Experimental results demonstrate that SMART significantly outperforms traditional methods such as examples proportional mixing and equal mixing. Furthermore, SMART facilitates the creation of data mixtures based on a few representative subsets of tasks alone and through task pruning analysis, we reveal that in a limited budget setting, allocating budget among a subset of representative tasks yields superior performance compared to distributing the budget among all tasks. The code for reproducing our results is open-sourced at https://github.com/kowndinya-renduchintala/SMART.","sentences":["Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks.","Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance remains challenging.","Unfortunately, there's currently no systematic method beyond manual tuning or relying on practitioners' intuition.","In this paper, we introduce SMART (Submodular data Mixture strAtegy for instRuction Tuning) - a novel data mixture strategy which makes use of a submodular function to assign importance scores to tasks which are then used to determine the mixture weights.","Given a fine-tuning budget, SMART redistributes the budget among tasks and selects non-redundant samples from each task.","Experimental results demonstrate that SMART significantly outperforms traditional methods such as examples proportional mixing and equal mixing.","Furthermore, SMART facilitates the creation of data mixtures based on a few representative subsets of tasks alone and through task pruning analysis, we reveal that in a limited budget setting, allocating budget among a subset of representative tasks yields superior performance compared to distributing the budget among all tasks.","The code for reproducing our results is open-sourced at https://github.com/kowndinya-renduchintala/SMART."],"url":"http://arxiv.org/abs/2403.08370v1"}
{"created":"2024-03-13 09:30:08","title":"METER: a mobile vision transformer architecture for monocular depth estimation","abstract":"Depth estimation is a fundamental knowledge for autonomous systems that need to assess their own state and perceive the surrounding environment. Deep learning algorithms for depth estimation have gained significant interest in recent years, owing to the potential benefits of this methodology in overcoming the limitations of active depth sensing systems. Moreover, due to the low cost and size of monocular cameras, researchers have focused their attention on monocular depth estimation (MDE), which consists in estimating a dense depth map from a single RGB video frame. State of the art MDE models typically rely on vision transformers (ViT) architectures that are highly deep and complex, making them unsuitable for fast inference on devices with hardware constraints. Purposely, in this paper, we address the problem of exploiting ViT in MDE on embedded devices. Those systems are usually characterized by limited memory capabilities and low-power CPU/GPU. We propose METER, a novel lightweight vision transformer architecture capable of achieving state of the art estimations and low latency inference performances on the considered embedded hardwares: NVIDIA Jetson TX1 and NVIDIA Jetson Nano. We provide a solution consisting of three alternative configurations of METER, a novel loss function to balance pixel estimation and reconstruction of image details, and a new data augmentation strategy to improve the overall final predictions. The proposed method outperforms previous lightweight works over the two benchmark datasets: the indoor NYU Depth v2 and the outdoor KITTI.","sentences":["Depth estimation is a fundamental knowledge for autonomous systems that need to assess their own state and perceive the surrounding environment.","Deep learning algorithms for depth estimation have gained significant interest in recent years, owing to the potential benefits of this methodology in overcoming the limitations of active depth sensing systems.","Moreover, due to the low cost and size of monocular cameras, researchers have focused their attention on monocular depth estimation (MDE), which consists in estimating a dense depth map from a single RGB video frame.","State of the art MDE models typically rely on vision transformers (ViT) architectures that are highly deep and complex, making them unsuitable for fast inference on devices with hardware constraints.","Purposely, in this paper, we address the problem of exploiting ViT in MDE on embedded devices.","Those systems are usually characterized by limited memory capabilities and low-power CPU/GPU.","We propose METER, a novel lightweight vision transformer architecture capable of achieving state of the art estimations and low latency inference performances on the considered embedded hardwares: NVIDIA Jetson TX1 and NVIDIA Jetson Nano.","We provide a solution consisting of three alternative configurations of METER, a novel loss function to balance pixel estimation and reconstruction of image details, and a new data augmentation strategy to improve the overall final predictions.","The proposed method outperforms previous lightweight works over the two benchmark datasets: the indoor NYU Depth v2 and the outdoor KITTI."],"url":"http://arxiv.org/abs/2403.08368v1"}
{"created":"2024-03-13 09:24:59","title":"Decoupled Federated Learning on Long-Tailed and Non-IID data with Feature Statistics","abstract":"Federated learning is designed to enhance data security and privacy, but faces challenges when dealing with heterogeneous data in long-tailed and non-IID distributions. This paper explores an overlooked scenario where tail classes are sparsely distributed over a few clients, causing the models trained with these classes to have a lower probability of being selected during client aggregation, leading to slower convergence rates and poorer model performance. To address this issue, we propose a two-stage Decoupled Federated learning framework using Feature Statistics (DFL-FS). In the first stage, the server estimates the client's class coverage distributions through masked local feature statistics clustering to select models for aggregation to accelerate convergence and enhance feature learning without privacy leakage. In the second stage, DFL-FS employs federated feature regeneration based on global feature statistics and utilizes resampling and weighted covariance to calibrate the global classifier to enhance the model's adaptability to long-tailed data distributions. We conducted experiments on CIFAR10-LT and CIFAR100-LT datasets with various long-tailed rates. The results demonstrate that our method outperforms state-of-the-art methods in both accuracy and convergence rate.","sentences":["Federated learning is designed to enhance data security and privacy, but faces challenges when dealing with heterogeneous data in long-tailed and non-IID distributions.","This paper explores an overlooked scenario where tail classes are sparsely distributed over a few clients, causing the models trained with these classes to have a lower probability of being selected during client aggregation, leading to slower convergence rates and poorer model performance.","To address this issue, we propose a two-stage Decoupled Federated learning framework using Feature Statistics (DFL-FS).","In the first stage, the server estimates the client's class coverage distributions through masked local feature statistics clustering to select models for aggregation to accelerate convergence and enhance feature learning without privacy leakage.","In the second stage, DFL-FS employs federated feature regeneration based on global feature statistics and utilizes resampling and weighted covariance to calibrate the global classifier to enhance the model's adaptability to long-tailed data distributions.","We conducted experiments on CIFAR10-LT and CIFAR100-LT datasets with various long-tailed rates.","The results demonstrate that our method outperforms state-of-the-art methods in both accuracy and convergence rate."],"url":"http://arxiv.org/abs/2403.08364v1"}
{"created":"2024-03-13 09:20:43","title":"Improved Image-based Pose Regressor Models for Underwater Environments","abstract":"We investigate the performance of image-based pose regressor models in underwater environments for relocalization. Leveraging PoseNet and PoseLSTM, we regress a 6-degree-of-freedom pose from single RGB images with high accuracy. Additionally, we explore data augmentation with stereo camera images to improve model accuracy. Experimental results demonstrate that the models achieve high accuracy in both simulated and clear waters, promising effective real-world underwater navigation and inspection applications.","sentences":["We investigate the performance of image-based pose regressor models in underwater environments for relocalization.","Leveraging PoseNet and PoseLSTM, we regress a 6-degree-of-freedom pose from single RGB images with high accuracy.","Additionally, we explore data augmentation with stereo camera images to improve model accuracy.","Experimental results demonstrate that the models achieve high accuracy in both simulated and clear waters, promising effective real-world underwater navigation and inspection applications."],"url":"http://arxiv.org/abs/2403.08360v1"}
{"created":"2024-03-13 09:18:46","title":"Log Summarisation for Defect Evolution Analysis","abstract":"Log analysis and monitoring are essential aspects in software maintenance and identifying defects. In particular, the temporal nature and vast size of log data leads to an interesting and important research question: How can logs be summarised and monitored over time? While this has been a fundamental topic of research in the software engineering community, work has typically focused on heuristic-, syntax-, or static-based methods. In this work, we suggest an online semantic-based clustering approach to error logs that dynamically updates the log clusters to enable monitoring code error life-cycles. We also introduce a novel metric to evaluate the performance of temporal log clusters. We test our system and evaluation metric with an industrial dataset and find that our solution outperforms similar systems. We hope that our work encourages further temporal exploration in defect datasets.","sentences":["Log analysis and monitoring are essential aspects in software maintenance and identifying defects.","In particular, the temporal nature and vast size of log data leads to an interesting and important research question: How can logs be summarised and monitored over time?","While this has been a fundamental topic of research in the software engineering community, work has typically focused on heuristic-, syntax-, or static-based methods.","In this work, we suggest an online semantic-based clustering approach to error logs that dynamically updates the log clusters to enable monitoring code error life-cycles.","We also introduce a novel metric to evaluate the performance of temporal log clusters.","We test our system and evaluation metric with an industrial dataset and find that our solution outperforms similar systems.","We hope that our work encourages further temporal exploration in defect datasets."],"url":"http://arxiv.org/abs/2403.08358v1"}
{"created":"2024-03-13 09:00:38","title":"Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods","abstract":"Data augmentation is arguably the most important regularization technique commonly used to improve generalization performance of machine learning models. It primarily involves the application of appropriate data transformation operations to create new data samples with desired properties. Despite its effectiveness, the process is often challenging because of the time-consuming trial and error procedures for creating and testing different candidate augmentations and their hyperparameters manually. Automated data augmentation methods aim to automate the process. State-of-the-art approaches typically rely on automated machine learning (AutoML) principles. This work presents a comprehensive survey of AutoML-based data augmentation techniques. We discuss various approaches for accomplishing data augmentation with AutoML, including data manipulation, data integration and data synthesis techniques. We present extensive discussion of techniques for realizing each of the major subtasks of the data augmentation process: search space design, hyperparameter optimization and model evaluation. Finally, we carried out an extensive comparison and analysis of the performance of automated data augmentation techniques and state-of-the-art methods based on classical augmentation approaches. The results show that AutoML methods for data augmentation currently outperform state-of-the-art techniques based on conventional approaches.","sentences":["Data augmentation is arguably the most important regularization technique commonly used to improve generalization performance of machine learning models.","It primarily involves the application of appropriate data transformation operations to create new data samples with desired properties.","Despite its effectiveness, the process is often challenging because of the time-consuming trial and error procedures for creating and testing different candidate augmentations and their hyperparameters manually.","Automated data augmentation methods aim to automate the process.","State-of-the-art approaches typically rely on automated machine learning (AutoML) principles.","This work presents a comprehensive survey of AutoML-based data augmentation techniques.","We discuss various approaches for accomplishing data augmentation with AutoML, including data manipulation, data integration and data synthesis techniques.","We present extensive discussion of techniques for realizing each of the major subtasks of the data augmentation process: search space design, hyperparameter optimization and model evaluation.","Finally, we carried out an extensive comparison and analysis of the performance of automated data augmentation techniques and state-of-the-art methods based on classical augmentation approaches.","The results show that AutoML methods for data augmentation currently outperform state-of-the-art techniques based on conventional approaches."],"url":"http://arxiv.org/abs/2403.08352v1"}
{"created":"2024-03-13 08:50:15","title":"From human experts to machines: An LLM supported approach to ontology and knowledge graph construction","abstract":"The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (or populate with instances), and ensure data quality (including amongst others accuracy and completeness). On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process. This work explores the (semi-)automatic construction of KGs facilitated by open-source LLMs. Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts. We showcase the feasibility of our semi-automated pipeline by creating a KG on deep learning methodologies by exploiting scholarly publications. To evaluate the answers generated via Retrieval-Augmented-Generation (RAG) as well as the KG concepts automatically extracted using LLMs, we design a judge LLM, which rates the generated content based on ground truth. Our findings suggest that employing LLMs could potentially reduce the human effort involved in the construction of KGs, although a human-in-the-loop approach is recommended to evaluate automatically generated KGs.","sentences":["The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (or populate with instances), and ensure data quality (including amongst others accuracy and completeness).","On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process.","This work explores the (semi-)automatic construction of KGs facilitated by open-source LLMs.","Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts.","We showcase the feasibility of our semi-automated pipeline by creating a KG on deep learning methodologies by exploiting scholarly publications.","To evaluate the answers generated via Retrieval-Augmented-Generation (RAG) as well as the KG concepts automatically extracted using LLMs, we design a judge LLM, which rates the generated content based on ground truth.","Our findings suggest that employing LLMs could potentially reduce the human effort involved in the construction of KGs, although a human-in-the-loop approach is recommended to evaluate automatically generated KGs."],"url":"http://arxiv.org/abs/2403.08345v1"}
{"created":"2024-03-13 08:49:40","title":"STMPL: Human Soft-Tissue Simulation","abstract":"In various applications, such as virtual reality and gaming, simulating the deformation of soft tissues in the human body during interactions with external objects is essential. Traditionally, Finite Element Methods (FEM) have been employed for this purpose, but they tend to be slow and resource-intensive. In this paper, we propose a unified representation of human body shape and soft tissue with a data-driven simulator of non-rigid deformations. This approach enables rapid simulation of realistic interactions.   Our method builds upon the SMPL model, which generates human body shapes considering rigid transformations. We extend SMPL by incorporating a soft tissue layer and an intuitive representation of external forces applied to the body during object interactions. Specifically, we mapped the 3D body shape and soft tissue and applied external forces to 2D UV maps. Leveraging a UNET architecture designed for 2D data, our approach achieves high-accuracy inference in real time. Our experiment shows that our method achieves plausible deformation of the soft tissue layer, even for unseen scenarios.","sentences":["In various applications, such as virtual reality and gaming, simulating the deformation of soft tissues in the human body during interactions with external objects is essential.","Traditionally, Finite Element Methods (FEM) have been employed for this purpose, but they tend to be slow and resource-intensive.","In this paper, we propose a unified representation of human body shape and soft tissue with a data-driven simulator of non-rigid deformations.","This approach enables rapid simulation of realistic interactions.   ","Our method builds upon the SMPL model, which generates human body shapes considering rigid transformations.","We extend SMPL by incorporating a soft tissue layer and an intuitive representation of external forces applied to the body during object interactions.","Specifically, we mapped the 3D body shape and soft tissue and applied external forces to 2D UV maps.","Leveraging a UNET architecture designed for 2D data, our approach achieves high-accuracy inference in real time.","Our experiment shows that our method achieves plausible deformation of the soft tissue layer, even for unseen scenarios."],"url":"http://arxiv.org/abs/2403.08344v1"}
{"created":"2024-03-13 08:40:49","title":"A Sparsity Principle for Partially Observable Causal Representation Learning","abstract":"Causal representation learning aims at identifying high-level causal variables from perceptual data. Most methods assume that all latent causal variables are captured in the high-dimensional observations. We instead consider a partially observed setting, in which each measurement only provides information about a subset of the underlying causal state. Prior work has studied this setting with multiple domains or views, each depending on a fixed subset of latents. Here, we focus on learning from unpaired observations from a dataset with an instance-dependent partial observability pattern. Our main contribution is to establish two identifiability results for this setting: one for linear mixing functions without parametric assumptions on the underlying causal model, and one for piecewise linear mixing functions with Gaussian latent causal variables. Based on these insights, we propose two methods for estimating the underlying causal variables by enforcing sparsity in the inferred representation. Experiments on different simulated datasets and established benchmarks highlight the effectiveness of our approach in recovering the ground-truth latents.","sentences":["Causal representation learning aims at identifying high-level causal variables from perceptual data.","Most methods assume that all latent causal variables are captured in the high-dimensional observations.","We instead consider a partially observed setting, in which each measurement only provides information about a subset of the underlying causal state.","Prior work has studied this setting with multiple domains or views, each depending on a fixed subset of latents.","Here, we focus on learning from unpaired observations from a dataset with an instance-dependent partial observability pattern.","Our main contribution is to establish two identifiability results for this setting: one for linear mixing functions without parametric assumptions on the underlying causal model, and one for piecewise linear mixing functions with Gaussian latent causal variables.","Based on these insights, we propose two methods for estimating the underlying causal variables by enforcing sparsity in the inferred representation.","Experiments on different simulated datasets and established benchmarks highlight the effectiveness of our approach in recovering the ground-truth latents."],"url":"http://arxiv.org/abs/2403.08335v1"}
{"created":"2024-03-13 08:34:40","title":"Bayesian Optimization that Limits Search Region to Lower Dimensions Utilizing Local GPR","abstract":"Optimization of product and system characteristics is required in many fields, including design and control. Bayesian optimization (BO) is often used when there are high observing costs, because BO theoretically guarantees an upper bound on regret. However, computational costs increase exponentially with the number of parameters to be optimized, decreasing search efficiency. We propose a BO that limits the search region to lower dimensions and utilizes local Gaussian process regression (LGPR) to scale the BO to higher dimensions. LGPR treats the low-dimensional search region as \"local,\" improving prediction accuracies there. The LGPR model is trained on a local subset of data specific to that region. This improves prediction accuracy and search efficiency and reduces the time complexity of matrix inversion in the Gaussian process regression. In evaluations with 20D Ackley and Rosenbrock functions, search efficiencies are equal to or higher than those of the compared methods, improved by about 69% and 40% from the case without LGPR. We apply our method to an automatic design task for a power semiconductor device. We successfully reduce the specific on-resistance to 25% better than a conventional method and 3.4% better than without LGPR.","sentences":["Optimization of product and system characteristics is required in many fields, including design and control.","Bayesian optimization (BO) is often used when there are high observing costs, because BO theoretically guarantees an upper bound on regret.","However, computational costs increase exponentially with the number of parameters to be optimized, decreasing search efficiency.","We propose a BO that limits the search region to lower dimensions and utilizes local Gaussian process regression (LGPR) to scale the BO to higher dimensions.","LGPR treats the low-dimensional search region as \"local,\" improving prediction accuracies there.","The LGPR model is trained on a local subset of data specific to that region.","This improves prediction accuracy and search efficiency and reduces the time complexity of matrix inversion in the Gaussian process regression.","In evaluations with 20D Ackley and Rosenbrock functions, search efficiencies are equal to or higher than those of the compared methods, improved by about 69% and 40% from the case without LGPR.","We apply our method to an automatic design task for a power semiconductor device.","We successfully reduce the specific on-resistance to 25% better than a conventional method and 3.4% better than without LGPR."],"url":"http://arxiv.org/abs/2403.08331v1"}
{"created":"2024-03-13 08:00:07","title":"DrFER: Learning Disentangled Representations for 3D Facial Expression Recognition","abstract":"Facial Expression Recognition (FER) has consistently been a focal point in the field of facial analysis. In the context of existing methodologies for 3D FER or 2D+3D FER, the extraction of expression features often gets entangled with identity information, compromising the distinctiveness of these features. To tackle this challenge, we introduce the innovative DrFER method, which brings the concept of disentangled representation learning to the field of 3D FER. DrFER employs a dual-branch framework to effectively disentangle expression information from identity information. Diverging from prior disentanglement endeavors in the 3D facial domain, we have carefully reconfigured both the loss functions and network structure to make the overall framework adaptable to point cloud data. This adaptation enhances the capability of the framework in recognizing facial expressions, even in cases involving varying head poses. Extensive evaluations conducted on the BU-3DFE and Bosphorus datasets substantiate that DrFER surpasses the performance of other 3D FER methods.","sentences":["Facial Expression Recognition (FER) has consistently been a focal point in the field of facial analysis.","In the context of existing methodologies for 3D FER or 2D+3D FER, the extraction of expression features often gets entangled with identity information, compromising the distinctiveness of these features.","To tackle this challenge, we introduce the innovative DrFER method, which brings the concept of disentangled representation learning to the field of 3D FER.","DrFER employs a dual-branch framework to effectively disentangle expression information from identity information.","Diverging from prior disentanglement endeavors in the 3D facial domain, we have carefully reconfigured both the loss functions and network structure to make the overall framework adaptable to point cloud data.","This adaptation enhances the capability of the framework in recognizing facial expressions, even in cases involving varying head poses.","Extensive evaluations conducted on the BU-3DFE and Bosphorus datasets substantiate that DrFER surpasses the performance of other 3D FER methods."],"url":"http://arxiv.org/abs/2403.08318v1"}
{"created":"2024-03-13 07:54:01","title":"From Channel Measurement to Training Data for PHY Layer AI Applications","abstract":"Learning-based techniques such as artificial intelligence (AI) and machine learning (ML) play an increasingly important role in the development of future communication networks. The success of a learning algorithm depends on the quality and quantity of the available training data. In the physical layer (PHY), channel information data can be obtained either through measurement campaigns or through simulations based on predefined channel models. Performing measurements can be time consuming while only gaining information about one specific position or scenario. Simulated data, on the other hand, are more generalized and reflect in most cases not a real environment but instead, a statistical approximation based on a mathematical model. This paper presents a procedure for acquiring channel data by means of fast and flexible software defined radio (SDR) based channel measurements along with a method for a parameter extraction that provides configuration input to the simulator. The procedure from the measurement to the simulated channel data is demonstrated in two exemplary propagation scenarios. It is shown, that in both cases the simulated data is in good accordance to the measurements","sentences":["Learning-based techniques such as artificial intelligence (AI) and machine learning (ML) play an increasingly important role in the development of future communication networks.","The success of a learning algorithm depends on the quality and quantity of the available training data.","In the physical layer (PHY), channel information data can be obtained either through measurement campaigns or through simulations based on predefined channel models.","Performing measurements can be time consuming while only gaining information about one specific position or scenario.","Simulated data, on the other hand, are more generalized and reflect in most cases not a real environment but instead, a statistical approximation based on a mathematical model.","This paper presents a procedure for acquiring channel data by means of fast and flexible software defined radio (SDR) based channel measurements along with a method for a parameter extraction that provides configuration input to the simulator.","The procedure from the measurement to the simulated channel data is demonstrated in two exemplary propagation scenarios.","It is shown, that in both cases the simulated data is in good accordance to the measurements"],"url":"http://arxiv.org/abs/2403.08317v1"}
{"created":"2024-03-13 07:45:46","title":"An improvement on the Louvain algorithm using random walks","abstract":"We will present improvements to famous algorithms for community detection, namely Newman's spectral method algorithm and the Louvain algorithm. The Newman algorithm begins by treating the original graph as a single cluster, then repeats the process to split each cluster into two, based on the signs of the eigenvector corresponding to the secondlargest eigenvalue. Our improvement involves replacing the time-consuming computation of eigenvalues with a random walk during the splitting process. The Louvain algorithm iteratively performs the following steps until no increase in modularity can be achieved anymore: each step consists of two phases, phase 1 for partitioning the graph into clusters, and phase 2 for constructing a new graph where each vertex represents one cluster obtained from phase 1. We propose an improvement to this algorithm by adding our random walk algorithm as an additional phase for refining clusters obtained from phase 1. It maintains a complexity comparable to the Louvain algorithm while exhibiting superior efficiency. To validate the robustness and effectiveness of our proposed algorithms, we conducted experiments using randomly generated graphs and real-world data.","sentences":["We will present improvements to famous algorithms for community detection, namely Newman's spectral method algorithm and the Louvain algorithm.","The Newman algorithm begins by treating the original graph as a single cluster, then repeats the process to split each cluster into two, based on the signs of the eigenvector corresponding to the secondlargest eigenvalue.","Our improvement involves replacing the time-consuming computation of eigenvalues with a random walk during the splitting process.","The Louvain algorithm iteratively performs the following steps until no increase in modularity can be achieved anymore: each step consists of two phases, phase 1 for partitioning the graph into clusters, and phase 2 for constructing a new graph where each vertex represents one cluster obtained from phase 1.","We propose an improvement to this algorithm by adding our random walk algorithm as an additional phase for refining clusters obtained from phase 1.","It maintains a complexity comparable to the Louvain algorithm while exhibiting superior efficiency.","To validate the robustness and effectiveness of our proposed algorithms, we conducted experiments using randomly generated graphs and real-world data."],"url":"http://arxiv.org/abs/2403.08313v1"}
{"created":"2024-03-13 07:42:21","title":"StyleDyRF: Zero-shot 4D Style Transfer for Dynamic Neural Radiance Fields","abstract":"4D style transfer aims at transferring arbitrary visual style to the synthesized novel views of a dynamic 4D scene with varying viewpoints and times. Existing efforts on 3D style transfer can effectively combine the visual features of style images and neural radiance fields (NeRF) but fail to handle the 4D dynamic scenes limited by the static scene assumption. Consequently, we aim to handle the novel challenging problem of 4D style transfer for the first time, which further requires the consistency of stylized results on dynamic objects. In this paper, we introduce StyleDyRF, a method that represents the 4D feature space by deforming a canonical feature volume and learns a linear style transformation matrix on the feature volume in a data-driven fashion. To obtain the canonical feature volume, the rays at each time step are deformed with the geometric prior of a pre-trained dynamic NeRF to render the feature map under the supervision of pre-trained visual encoders. With the content and style cues in the canonical feature volume and the style image, we can learn the style transformation matrix from their covariance matrices with lightweight neural networks. The learned style transformation matrix can reflect a direct matching of feature covariance from the content volume to the given style pattern, in analogy with the optimization of the Gram matrix in traditional 2D neural style transfer. The experimental results show that our method not only renders 4D photorealistic style transfer results in a zero-shot manner but also outperforms existing methods in terms of visual quality and consistency.","sentences":["4D style transfer aims at transferring arbitrary visual style to the synthesized novel views of a dynamic 4D scene with varying viewpoints and times.","Existing efforts on 3D style transfer can effectively combine the visual features of style images and neural radiance fields (NeRF) but fail to handle the 4D dynamic scenes limited by the static scene assumption.","Consequently, we aim to handle the novel challenging problem of 4D style transfer for the first time, which further requires the consistency of stylized results on dynamic objects.","In this paper, we introduce StyleDyRF, a method that represents the 4D feature space by deforming a canonical feature volume and learns a linear style transformation matrix on the feature volume in a data-driven fashion.","To obtain the canonical feature volume, the rays at each time step are deformed with the geometric prior of a pre-trained dynamic NeRF to render the feature map under the supervision of pre-trained visual encoders.","With the content and style cues in the canonical feature volume and the style image, we can learn the style transformation matrix from their covariance matrices with lightweight neural networks.","The learned style transformation matrix can reflect a direct matching of feature covariance from the content volume to the given style pattern, in analogy with the optimization of the Gram matrix in traditional 2D neural style transfer.","The experimental results show that our method not only renders 4D photorealistic style transfer results in a zero-shot manner but also outperforms existing methods in terms of visual quality and consistency."],"url":"http://arxiv.org/abs/2403.08310v1"}
{"created":"2024-03-13 06:54:15","title":"CleanAgent: Automating Data Standardization with LLM-based Agents","abstract":"Data standardization is a crucial part in data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing column types, simplifying the code generation of LLM with concise API calls. We first propose Dataprep.Clean which is written as a component of the Dataprep Library, offers a significant reduction in complexity by enabling the standardization of specific column types with a single line of code. Then we introduce the CleanAgent framework integrating Dataprep.Clean and LLM-based agents to automate the data standardization process. With CleanAgent, data scientists need only provide their requirements once, allowing for a hands-free, automatic standardization process.","sentences":["Data standardization is a crucial part in data science life cycle.","While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges.","Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement.","To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing column types, simplifying the code generation of LLM with concise API calls.","We first propose Dataprep.","Clean which is written as a component of the Dataprep Library, offers a significant reduction in complexity by enabling the standardization of specific column types with a single line of code.","Then we introduce the CleanAgent framework integrating Dataprep.","Clean and LLM-based agents to automate the data standardization process.","With CleanAgent, data scientists need only provide their requirements once, allowing for a hands-free, automatic standardization process."],"url":"http://arxiv.org/abs/2403.08291v1"}
{"created":"2024-03-13 06:34:49","title":"MGIC: A Multi-Label Gradient Inversion Attack based on Canny Edge Detection on Federated Learning","abstract":"As a new distributed computing framework that can protect data privacy, federated learning (FL) has attracted more and more attention in recent years. It receives gradients from users to train the global model and releases the trained global model to working users. Nonetheless, the gradient inversion (GI) attack reflects the risk of privacy leakage in federated learning. Attackers only need to use gradients through hundreds of thousands of simple iterations to obtain relatively accurate private data stored on users' local devices. For this, some works propose simple but effective strategies to obtain user data under a single-label dataset. However, these strategies induce a satisfactory visual effect of the inversion image at the expense of higher time costs. Due to the semantic limitation of a single label, the image obtained by gradient inversion may have semantic errors. We present a novel gradient inversion strategy based on canny edge detection (MGIC) in both the multi-label and single-label datasets. To reduce semantic errors caused by a single label, we add new convolution layers' blocks in the trained model to obtain the image's multi-label. Through multi-label representation, serious semantic errors in inversion images are reduced. Then, we analyze the impact of parameters on the difficulty of input image reconstruction and discuss how image multi-subjects affect the inversion performance. Our proposed strategy has better visual inversion image results than the most widely used ones, saving more than 78% of time costs in the ImageNet dataset.","sentences":["As a new distributed computing framework that can protect data privacy, federated learning (FL) has attracted more and more attention in recent years.","It receives gradients from users to train the global model and releases the trained global model to working users.","Nonetheless, the gradient inversion (GI) attack reflects the risk of privacy leakage in federated learning.","Attackers only need to use gradients through hundreds of thousands of simple iterations to obtain relatively accurate private data stored on users' local devices.","For this, some works propose simple but effective strategies to obtain user data under a single-label dataset.","However, these strategies induce a satisfactory visual effect of the inversion image at the expense of higher time costs.","Due to the semantic limitation of a single label, the image obtained by gradient inversion may have semantic errors.","We present a novel gradient inversion strategy based on canny edge detection (MGIC) in both the multi-label and single-label datasets.","To reduce semantic errors caused by a single label, we add new convolution layers' blocks in the trained model to obtain the image's multi-label.","Through multi-label representation, serious semantic errors in inversion images are reduced.","Then, we analyze the impact of parameters on the difficulty of input image reconstruction and discuss how image multi-subjects affect the inversion performance.","Our proposed strategy has better visual inversion image results than the most widely used ones, saving more than 78% of time costs in the ImageNet dataset."],"url":"http://arxiv.org/abs/2403.08284v1"}
{"created":"2024-03-13 06:22:17","title":"Hierarchical Auto-Organizing System for Open-Ended Multi-Agent Navigation","abstract":"Navigating complex environments in Minecraft poses significant challenges for multi-agent systems due to the game's dynamic and unpredictable open-world setting. Agents need to interact with the environment and coordinate their actions with other agents to achieve common objectives. However, traditional approaches often struggle to efficiently manage inter-agent communication and task distribution, which are crucial for effective multi-agent navigation. Furthermore, processing and integrating multi-modal information (such as visual, textual, and auditory data) is essential for agents to fully comprehend their goals and navigate the environment successfully. To address this issue, we design the HAS framework to auto-organize groups of LLM-based agents to complete Navigation tasks. In our approach, we devise a hierarchical auto-organizing navigation system, which is characterized by 1) a hierarchical system for multi-agent organization, ensuring centralized planning and decentralized execution; 2) an auto-organizing and intra-communication mechanism, enabling dynamic group adjustment under subtasks; 3) a multi-modal information platform, facilitating multi-modal perception to perform the three navigation tasks with one system. To assess organizational behavior, we design a series of navigation tasks in the Minecraft environment, which includes searching and exploring. We aim to develop embodied organizations that push the boundaries of embodied AI, moving it towards a more human-like organizational structure.","sentences":["Navigating complex environments in Minecraft poses significant challenges for multi-agent systems due to the game's dynamic and unpredictable open-world setting.","Agents need to interact with the environment and coordinate their actions with other agents to achieve common objectives.","However, traditional approaches often struggle to efficiently manage inter-agent communication and task distribution, which are crucial for effective multi-agent navigation.","Furthermore, processing and integrating multi-modal information (such as visual, textual, and auditory data) is essential for agents to fully comprehend their goals and navigate the environment successfully.","To address this issue, we design the HAS framework to auto-organize groups of LLM-based agents to complete Navigation tasks.","In our approach, we devise a hierarchical auto-organizing navigation system, which is characterized by 1) a hierarchical system for multi-agent organization, ensuring centralized planning and decentralized execution; 2)","an auto-organizing and intra-communication mechanism, enabling dynamic group adjustment under subtasks; 3) a multi-modal information platform, facilitating multi-modal perception to perform the three navigation tasks with one system.","To assess organizational behavior, we design a series of navigation tasks in the Minecraft environment, which includes searching and exploring.","We aim to develop embodied organizations that push the boundaries of embodied AI, moving it towards a more human-like organizational structure."],"url":"http://arxiv.org/abs/2403.08282v1"}
{"created":"2024-03-13 06:18:48","title":"Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models","abstract":"Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we propose to fuse models that are already highly-specialized directly. The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics. A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a high-quality supervised instruction tuning dataset, UltraChat 2, which includes text, code, and mathematical content. This dataset comprises approximately 300,000 instructions and covers a wide range of topics in each domain. Experiments show that our model could simultaneously achieve mastery of the three crucial domains.","sentences":["Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously.","Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains.","In this paper, we propose to fuse models that are already highly-specialized directly.","The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics.","A token-level gating mechanism is introduced to blend the specialists' outputs.","A two-stage training strategy accompanied by balanced sampling is designed to ensure stability.","To effectively train the fused model, we further construct a high-quality supervised instruction tuning dataset, UltraChat 2, which includes text, code, and mathematical content.","This dataset comprises approximately 300,000 instructions and covers a wide range of topics in each domain.","Experiments show that our model could simultaneously achieve mastery of the three crucial domains."],"url":"http://arxiv.org/abs/2403.08281v1"}
{"created":"2024-03-13 06:11:41","title":"VIGFace: Virtual Identity Generation Model for Face Image Synthesis","abstract":"Deep learning-based face recognition continues to face challenges due to its reliance on huge datasets obtained from web crawling, which can be costly to gather and raise significant real-world privacy concerns. To address this issue, we propose VIGFace, a novel framework capable of generating synthetic facial images. Initially, we train the face recognition model using a real face dataset and create a feature space for both real and virtual IDs where virtual prototypes are orthogonal to other prototypes. Subsequently, we generate synthetic images by using the diffusion model based on the feature space. Our proposed framework provides two significant benefits. Firstly, it allows for creating virtual facial images without concerns about portrait rights, guaranteeing that the generated virtual face images are clearly differentiated from existing individuals. Secondly, it serves as an effective augmentation method by incorporating real existing images. Further experiments demonstrate the efficacy of our framework, achieving state-of-the-art results from both perspectives without any external data.","sentences":["Deep learning-based face recognition continues to face challenges due to its reliance on huge datasets obtained from web crawling, which can be costly to gather and raise significant real-world privacy concerns.","To address this issue, we propose VIGFace, a novel framework capable of generating synthetic facial images.","Initially, we train the face recognition model using a real face dataset and create a feature space for both real and virtual IDs where virtual prototypes are orthogonal to other prototypes.","Subsequently, we generate synthetic images by using the diffusion model based on the feature space.","Our proposed framework provides two significant benefits.","Firstly, it allows for creating virtual facial images without concerns about portrait rights, guaranteeing that the generated virtual face images are clearly differentiated from existing individuals.","Secondly, it serves as an effective augmentation method by incorporating real existing images.","Further experiments demonstrate the efficacy of our framework, achieving state-of-the-art results from both perspectives without any external data."],"url":"http://arxiv.org/abs/2403.08277v1"}
{"created":"2024-03-13 05:53:25","title":"LiqD: A Dynamic Liquid Level Detection Model under Tricky Small Containers","abstract":"In daily life and industrial production, it is crucial to accurately detect changes in liquid level in containers. Traditional contact measurement methods have some limitations, while emerging non-contact image processing technology shows good application prospects. This paper proposes a container dynamic liquid level detection model based on U^2-Net. This model uses the SAM model to generate an initial data set, and then evaluates and filters out high-quality pseudo-label images through the SemiReward framework to build an exclusive data set. The model uses U^2-Net to extract mask images of containers from the data set, and uses morphological processing to compensate for mask defects. Subsequently, the model calculates the grayscale difference between adjacent video frame images at the same position, segments the liquid level change area by setting a difference threshold, and finally uses a lightweight neural network to classify the liquid level state. This approach not only mitigates the impact of intricate surroundings, but also reduces the demand for training data, showing strong robustness and versatility. A large number of experimental results show that the proposed model can effectively detect the dynamic liquid level changes of the liquid in the container, providing a novel and efficient solution for related fields.","sentences":["In daily life and industrial production, it is crucial to accurately detect changes in liquid level in containers.","Traditional contact measurement methods have some limitations, while emerging non-contact image processing technology shows good application prospects.","This paper proposes a container dynamic liquid level detection model based on U^2-Net.","This model uses the SAM model to generate an initial data set, and then evaluates and filters out high-quality pseudo-label images through the SemiReward framework to build an exclusive data set.","The model uses U^2-Net to extract mask images of containers from the data set, and uses morphological processing to compensate for mask defects.","Subsequently, the model calculates the grayscale difference between adjacent video frame images at the same position, segments the liquid level change area by setting a difference threshold, and finally uses a lightweight neural network to classify the liquid level state.","This approach not only mitigates the impact of intricate surroundings, but also reduces the demand for training data, showing strong robustness and versatility.","A large number of experimental results show that the proposed model can effectively detect the dynamic liquid level changes of the liquid in the container, providing a novel and efficient solution for related fields."],"url":"http://arxiv.org/abs/2403.08273v1"}
{"created":"2024-03-13 05:51:57","title":"RECIPE4U: Student-ChatGPT Interaction Dataset in EFL Writing Education","abstract":"The integration of generative AI in education is expanding, yet empirical analyses of large-scale and real-world interactions between students and AI systems still remain limited. Addressing this gap, we present RECIPE4U (RECIPE for University), a dataset sourced from a semester-long experiment with 212 college students in English as Foreign Language (EFL) writing courses. During the study, students engaged in dialogues with ChatGPT to revise their essays. RECIPE4U includes comprehensive records of these interactions, including conversation logs, students' intent, students' self-rated satisfaction, and students' essay edit histories. In particular, we annotate the students' utterances in RECIPE4U with 13 intention labels based on our coding schemes. We establish baseline results for two subtasks in task-oriented dialogue systems within educational contexts: intent detection and satisfaction estimation. As a foundational step, we explore student-ChatGPT interaction patterns through RECIPE4U and analyze them by focusing on students' dialogue, essay data statistics, and students' essay edits. We further illustrate potential applications of RECIPE4U dataset for enhancing the incorporation of LLMs in educational frameworks. RECIPE4U is publicly available at https://zeunie.github.io/RECIPE4U/.","sentences":["The integration of generative AI in education is expanding, yet empirical analyses of large-scale and real-world interactions between students and AI systems still remain limited.","Addressing this gap, we present RECIPE4U (RECIPE for University), a dataset sourced from a semester-long experiment with 212 college students in English as Foreign Language (EFL) writing courses.","During the study, students engaged in dialogues with ChatGPT to revise their essays.","RECIPE4U includes comprehensive records of these interactions, including conversation logs, students' intent, students' self-rated satisfaction, and students' essay edit histories.","In particular, we annotate the students' utterances in RECIPE4U with 13 intention labels based on our coding schemes.","We establish baseline results for two subtasks in task-oriented dialogue systems within educational contexts: intent detection and satisfaction estimation.","As a foundational step, we explore student-ChatGPT interaction patterns through RECIPE4U and analyze them by focusing on students' dialogue, essay data statistics, and students' essay edits.","We further illustrate potential applications of RECIPE4U dataset for enhancing the incorporation of LLMs in educational frameworks.","RECIPE4U is publicly available at https://zeunie.github.io/RECIPE4U/."],"url":"http://arxiv.org/abs/2403.08272v1"}
{"created":"2024-03-13 05:48:58","title":"Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification","abstract":"Fine-grained ship classification in remote sensing (RS-FGSC) poses a significant challenge due to the high similarity between classes and the limited availability of labeled data, limiting the effectiveness of traditional supervised classification methods. Recent advancements in large pre-trained Vision-Language Models (VLMs) have demonstrated impressive capabilities in few-shot or zero-shot learning, particularly in understanding image content. This study delves into harnessing the potential of VLMs to enhance classification accuracy for unseen ship categories, which holds considerable significance in scenarios with restricted data due to cost or privacy constraints. Directly fine-tuning VLMs for RS-FGSC often encounters the challenge of overfitting the seen classes, resulting in suboptimal generalization to unseen classes, which highlights the difficulty in differentiating complex backgrounds and capturing distinct ship features. To address these issues, we introduce a novel prompt tuning technique that employs a hierarchical, multi-granularity prompt design. Our approach integrates remote sensing ship priors through bias terms, learned from a small trainable network. This strategy enhances the model's generalization capabilities while improving its ability to discern intricate backgrounds and learn discriminative ship features. Furthermore, we contribute to the field by introducing a comprehensive dataset, FGSCM-52, significantly expanding existing datasets with more extensive data and detailed annotations for less common ship classes. Extensive experimental evaluations demonstrate the superiority of our proposed method over current state-of-the-art techniques. The source code will be made publicly available.","sentences":["Fine-grained ship classification in remote sensing (RS-FGSC) poses a significant challenge due to the high similarity between classes and the limited availability of labeled data, limiting the effectiveness of traditional supervised classification methods.","Recent advancements in large pre-trained Vision-Language Models (VLMs) have demonstrated impressive capabilities in few-shot or zero-shot learning, particularly in understanding image content.","This study delves into harnessing the potential of VLMs to enhance classification accuracy for unseen ship categories, which holds considerable significance in scenarios with restricted data due to cost or privacy constraints.","Directly fine-tuning VLMs for RS-FGSC often encounters the challenge of overfitting the seen classes, resulting in suboptimal generalization to unseen classes, which highlights the difficulty in differentiating complex backgrounds and capturing distinct ship features.","To address these issues, we introduce a novel prompt tuning technique that employs a hierarchical, multi-granularity prompt design.","Our approach integrates remote sensing ship priors through bias terms, learned from a small trainable network.","This strategy enhances the model's generalization capabilities while improving its ability to discern intricate backgrounds and learn discriminative ship features.","Furthermore, we contribute to the field by introducing a comprehensive dataset, FGSCM-52, significantly expanding existing datasets with more extensive data and detailed annotations for less common ship classes.","Extensive experimental evaluations demonstrate the superiority of our proposed method over current state-of-the-art techniques.","The source code will be made publicly available."],"url":"http://arxiv.org/abs/2403.08271v1"}
{"created":"2024-03-13 05:33:52","title":"Sketch2Manga: Shaded Manga Screening from Sketch with Diffusion Models","abstract":"While manga is a popular entertainment form, creating manga is tedious, especially adding screentones to the created sketch, namely manga screening. Unfortunately, there is no existing method that tailors for automatic manga screening, probably due to the difficulty of generating high-quality shaded high-frequency screentones. The classic manga screening approaches generally require user input to provide screentone exemplars or a reference manga image. The recent deep learning models enables the automatic generation by learning from a large-scale dataset. However, the state-of-the-art models still fail to generate high-quality shaded screentones due to the lack of a tailored model and high-quality manga training data. In this paper, we propose a novel sketch-to-manga framework that first generates a color illustration from the sketch and then generates a screentoned manga based on the intensity guidance. Our method significantly outperforms existing methods in generating high-quality manga with shaded high-frequency screentones.","sentences":["While manga is a popular entertainment form, creating manga is tedious, especially adding screentones to the created sketch, namely manga screening.","Unfortunately, there is no existing method that tailors for automatic manga screening, probably due to the difficulty of generating high-quality shaded high-frequency screentones.","The classic manga screening approaches generally require user input to provide screentone exemplars or a reference manga image.","The recent deep learning models enables the automatic generation by learning from a large-scale dataset.","However, the state-of-the-art models still fail to generate high-quality shaded screentones due to the lack of a tailored model and high-quality manga training data.","In this paper, we propose a novel sketch-to-manga framework that first generates a color illustration from the sketch and then generates a screentoned manga based on the intensity guidance.","Our method significantly outperforms existing methods in generating high-quality manga with shaded high-frequency screentones."],"url":"http://arxiv.org/abs/2403.08266v1"}
{"created":"2024-03-13 05:24:28","title":"CoroNetGAN: Controlled Pruning of GANs via Hypernetworks","abstract":"Generative Adversarial Networks (GANs) have proven to exhibit remarkable performance and are widely used across many generative computer vision applications. However, the unprecedented demand for the deployment of GANs on resource-constrained edge devices still poses a challenge due to huge number of parameters involved in the generation process. This has led to focused attention on the area of compressing GANs. Most of the existing works use knowledge distillation with the overhead of teacher dependency. Moreover, there is no ability to control the degree of compression in these methods. Hence, we propose CoroNet-GAN for compressing GAN using the combined strength of differentiable pruning method via hypernetworks. The proposed method provides the advantage of performing controllable compression while training along with reducing training time by a substantial factor. Experiments have been done on various conditional GAN architectures (Pix2Pix and CycleGAN) to signify the effectiveness of our approach on multiple benchmark datasets such as Edges-to-Shoes, Horse-to-Zebra and Summer-to-Winter. The results obtained illustrate that our approach succeeds to outperform the baselines on Zebra-to-Horse and Summer-to-Winter achieving the best FID score of 32.3 and 72.3 respectively, yielding high-fidelity images across all the datasets. Additionally, our approach also outperforms the state-of-the-art methods in achieving better inference time on various smart-phone chipsets and data-types making it a feasible solution for deployment on edge devices.","sentences":["Generative Adversarial Networks (GANs) have proven to exhibit remarkable performance and are widely used across many generative computer vision applications.","However, the unprecedented demand for the deployment of GANs on resource-constrained edge devices still poses a challenge due to huge number of parameters involved in the generation process.","This has led to focused attention on the area of compressing GANs.","Most of the existing works use knowledge distillation with the overhead of teacher dependency.","Moreover, there is no ability to control the degree of compression in these methods.","Hence, we propose CoroNet-GAN for compressing GAN using the combined strength of differentiable pruning method via hypernetworks.","The proposed method provides the advantage of performing controllable compression while training along with reducing training time by a substantial factor.","Experiments have been done on various conditional GAN architectures (Pix2Pix and CycleGAN) to signify the effectiveness of our approach on multiple benchmark datasets such as Edges-to-Shoes, Horse-to-Zebra and Summer-to-Winter.","The results obtained illustrate that our approach succeeds to outperform the baselines on Zebra-to-Horse and Summer-to-Winter achieving the best FID score of 32.3 and 72.3 respectively, yielding high-fidelity images across all the datasets.","Additionally, our approach also outperforms the state-of-the-art methods in achieving better inference time on various smart-phone chipsets and data-types making it a feasible solution for deployment on edge devices."],"url":"http://arxiv.org/abs/2403.08261v1"}
{"created":"2024-03-13 05:23:20","title":"Understanding Reader Takeaways in Thematic Maps Under Varying Text, Detail, and Spatial Autocorrelation","abstract":"Maps are crucial in conveying geospatial data in diverse contexts such as news and scientific reports. This research, utilizing thematic maps, probes deeper into the underexplored intersection of text framing and map types in influencing map interpretation. In this work, we conducted experiments to evaluate how textual detail and semantic content variations affect the quality of insights derived from map examination. We also explored the influence of explanatory annotations across different map types (e.g., choropleth, hexbin, isarithmic), base map details, and changing levels of spatial autocorrelation in the data. From two online experiments with $N=103$ participants, we found that annotations, their specific attributes, and map type used to present the data significantly shape the quality of takeaways. Notably, we found that the effectiveness of annotations hinges on their contextual integration. These findings offer valuable guidance to the visualization community for crafting impactful thematic geospatial representations.","sentences":["Maps are crucial in conveying geospatial data in diverse contexts such as news and scientific reports.","This research, utilizing thematic maps, probes deeper into the underexplored intersection of text framing and map types in influencing map interpretation.","In this work, we conducted experiments to evaluate how textual detail and semantic content variations affect the quality of insights derived from map examination.","We also explored the influence of explanatory annotations across different map types (e.g., choropleth, hexbin, isarithmic), base map details, and changing levels of spatial autocorrelation in the data.","From two online experiments with $N=103$ participants, we found that annotations, their specific attributes, and map type used to present the data significantly shape the quality of takeaways.","Notably, we found that the effectiveness of annotations hinges on their contextual integration.","These findings offer valuable guidance to the visualization community for crafting impactful thematic geospatial representations."],"url":"http://arxiv.org/abs/2403.08260v1"}
{"created":"2024-03-13 05:20:35","title":"Reconciling Conflicting Data Curation Actions: Transparency Through Argumentation","abstract":"We propose a new approach for modeling and reconciling conflicting data cleaning actions. Such conflicts arise naturally in collaborative data curation settings where multiple experts work independently and then aim to put their efforts together to improve and accelerate data cleaning. The key idea of our approach is to model conflicting updates as a formal \\emph{argumentation framework}(AF). Such argumentation frameworks can be automatically analyzed and solved by translating them to a logic program $P_{AF}$ whose declarative semantics yield a transparent solution with many desirable properties, e.g., uncontroversial updates are accepted, unjustified ones are rejected, and the remaining ambiguities are exposed and presented to users for further analysis. After motivating the problem, we introduce our approach and illustrate it with a detailed running example introducing both well-founded and stable semantics to help understand the AF solutions. We have begun to develop open source tools and Jupyter notebooks that demonstrate the practicality of our approach. In future work we plan to develop a toolkit for conflict resolution that can be used in conjunction with OpenRefine, a popular interactive data cleaning tool.","sentences":["We propose a new approach for modeling and reconciling conflicting data cleaning actions.","Such conflicts arise naturally in collaborative data curation settings where multiple experts work independently and then aim to put their efforts together to improve and accelerate data cleaning.","The key idea of our approach is to model conflicting updates as a formal \\emph{argumentation framework}(AF).","Such argumentation frameworks can be automatically analyzed and solved by translating them to a logic program $P_{AF}$ whose declarative semantics yield a transparent solution with many desirable properties, e.g., uncontroversial updates are accepted, unjustified ones are rejected, and the remaining ambiguities are exposed and presented to users for further analysis.","After motivating the problem, we introduce our approach and illustrate it with a detailed running example introducing both well-founded and stable semantics to help understand the AF solutions.","We have begun to develop open source tools and Jupyter notebooks that demonstrate the practicality of our approach.","In future work we plan to develop a toolkit for conflict resolution that can be used in conjunction with OpenRefine, a popular interactive data cleaning tool."],"url":"http://arxiv.org/abs/2403.08257v1"}
{"created":"2024-03-13 05:15:43","title":"IG-FIQA: Improving Face Image Quality Assessment through Intra-class Variance Guidance robust to Inaccurate Pseudo-Labels","abstract":"In the realm of face image quality assesment (FIQA), method based on sample relative classification have shown impressive performance. However, the quality scores used as pseudo-labels assigned from images of classes with low intra-class variance could be unrelated to the actual quality in this method. To address this issue, we present IG-FIQA, a novel approach to guide FIQA training, introducing a weight parameter to alleviate the adverse impact of these classes. This method involves estimating sample intra-class variance at each iteration during training, ensuring minimal computational overhead and straightforward implementation. Furthermore, this paper proposes an on-the-fly data augmentation methodology for improved generalization performance in FIQA. On various benchmark datasets, our proposed method, IG-FIQA, achieved novel state-of-the-art (SOTA) performance.","sentences":["In the realm of face image quality assesment (FIQA), method based on sample relative classification have shown impressive performance.","However, the quality scores used as pseudo-labels assigned from images of classes with low intra-class variance could be unrelated to the actual quality in this method.","To address this issue, we present IG-FIQA, a novel approach to guide FIQA training, introducing a weight parameter to alleviate the adverse impact of these classes.","This method involves estimating sample intra-class variance at each iteration during training, ensuring minimal computational overhead and straightforward implementation.","Furthermore, this paper proposes an on-the-fly data augmentation methodology for improved generalization performance in FIQA.","On various benchmark datasets, our proposed method, IG-FIQA, achieved novel state-of-the-art (SOTA) performance."],"url":"http://arxiv.org/abs/2403.08256v1"}
{"created":"2024-03-13 05:13:17","title":"Make Me Happier: Evoking Emotions Through Image Diffusion Models","abstract":"Despite the rapid progress in image generation, emotional image editing remains under-explored. The semantics, context, and structure of an image can evoke emotional responses, making emotional image editing techniques valuable for various real-world applications, including treatment of psychological disorders, commercialization of products, and artistic design. For the first time, we present a novel challenge of emotion-evoked image generation, aiming to synthesize images that evoke target emotions while retaining the semantics and structures of the original scenes. To address this challenge, we propose a diffusion model capable of effectively understanding and editing source images to convey desired emotions and sentiments. Moreover, due to the lack of emotion editing datasets, we provide a unique dataset consisting of 340,000 pairs of images and their emotion annotations. Furthermore, we conduct human psychophysics experiments and introduce four new evaluation metrics to systematically benchmark all the methods. Experimental results demonstrate that our method surpasses all competitive baselines. Our diffusion model is capable of identifying emotional cues from original images, editing images that elicit desired emotions, and meanwhile, preserving the semantic structure of the original images. All code, model, and data will be made public.","sentences":["Despite the rapid progress in image generation, emotional image editing remains under-explored.","The semantics, context, and structure of an image can evoke emotional responses, making emotional image editing techniques valuable for various real-world applications, including treatment of psychological disorders, commercialization of products, and artistic design.","For the first time, we present a novel challenge of emotion-evoked image generation, aiming to synthesize images that evoke target emotions while retaining the semantics and structures of the original scenes.","To address this challenge, we propose a diffusion model capable of effectively understanding and editing source images to convey desired emotions and sentiments.","Moreover, due to the lack of emotion editing datasets, we provide a unique dataset consisting of 340,000 pairs of images and their emotion annotations.","Furthermore, we conduct human psychophysics experiments and introduce four new evaluation metrics to systematically benchmark all the methods.","Experimental results demonstrate that our method surpasses all competitive baselines.","Our diffusion model is capable of identifying emotional cues from original images, editing images that elicit desired emotions, and meanwhile, preserving the semantic structure of the original images.","All code, model, and data will be made public."],"url":"http://arxiv.org/abs/2403.08255v1"}
{"created":"2024-03-13 05:11:24","title":"Machine Unlearning: Taxonomy, Metrics, Applications, Challenges, and Prospects","abstract":"Personal digital data is a critical asset, and governments worldwide have enforced laws and regulations to protect data privacy. Data users have been endowed with the right to be forgotten of their data. In the course of machine learning (ML), the forgotten right requires a model provider to delete user data and its subsequent impact on ML models upon user requests. Machine unlearning emerges to address this, which has garnered ever-increasing attention from both industry and academia. While the area has developed rapidly, there is a lack of comprehensive surveys to capture the latest advancements. Recognizing this shortage, we conduct an extensive exploration to map the landscape of machine unlearning including the (fine-grained) taxonomy of unlearning algorithms under centralized and distributed settings, debate on approximate unlearning, verification and evaluation metrics, challenges and solutions for unlearning under different applications, as well as attacks targeting machine unlearning. The survey concludes by outlining potential directions for future research, hoping to serve as a guide for interested scholars.","sentences":["Personal digital data is a critical asset, and governments worldwide have enforced laws and regulations to protect data privacy.","Data users have been endowed with the right to be forgotten of their data.","In the course of machine learning (ML), the forgotten right requires a model provider to delete user data and its subsequent impact on ML models upon user requests.","Machine unlearning emerges to address this, which has garnered ever-increasing attention from both industry and academia.","While the area has developed rapidly, there is a lack of comprehensive surveys to capture the latest advancements.","Recognizing this shortage, we conduct an extensive exploration to map the landscape of machine unlearning including the (fine-grained) taxonomy of unlearning algorithms under centralized and distributed settings, debate on approximate unlearning, verification and evaluation metrics, challenges and solutions for unlearning under different applications, as well as attacks targeting machine unlearning.","The survey concludes by outlining potential directions for future research, hoping to serve as a guide for interested scholars."],"url":"http://arxiv.org/abs/2403.08254v1"}
{"created":"2024-03-13 05:03:58","title":"CoPa: General Robotic Manipulation through Spatial Constraints of Parts with Foundation Models","abstract":"Foundation models pre-trained on web-scale data are shown to encapsulate extensive world knowledge beneficial for robotic manipulation in the form of task planning. However, the actual physical implementation of these plans often relies on task-specific learning methods, which require significant data collection and struggle with generalizability. In this work, we introduce Robotic Manipulation through Spatial Constraints of Parts (CoPa), a novel framework that leverages the common sense knowledge embedded within foundation models to generate a sequence of 6-DoF end-effector poses for open-world robotic manipulation. Specifically, we decompose the manipulation process into two phases: task-oriented grasping and task-aware motion planning. In the task-oriented grasping phase, we employ foundation vision-language models (VLMs) to select the object's grasping part through a novel coarse-to-fine grounding mechanism. During the task-aware motion planning phase, VLMs are utilized again to identify the spatial geometry constraints of task-relevant object parts, which are then used to derive post-grasp poses. We also demonstrate how CoPa can be seamlessly integrated with existing robotic planning algorithms to accomplish complex, long-horizon tasks. Our comprehensive real-world experiments show that CoPa possesses a fine-grained physical understanding of scenes, capable of handling open-set instructions and objects with minimal prompt engineering and without additional training. Project page: https://copa-2024.github.io/","sentences":["Foundation models pre-trained on web-scale data are shown to encapsulate extensive world knowledge beneficial for robotic manipulation in the form of task planning.","However, the actual physical implementation of these plans often relies on task-specific learning methods, which require significant data collection and struggle with generalizability.","In this work, we introduce Robotic Manipulation through Spatial Constraints of Parts (CoPa), a novel framework that leverages the common sense knowledge embedded within foundation models to generate a sequence of 6-DoF end-effector poses for open-world robotic manipulation.","Specifically, we decompose the manipulation process into two phases: task-oriented grasping and task-aware motion planning.","In the task-oriented grasping phase, we employ foundation vision-language models (VLMs) to select the object's grasping part through a novel coarse-to-fine grounding mechanism.","During the task-aware motion planning phase, VLMs are utilized again to identify the spatial geometry constraints of task-relevant object parts, which are then used to derive post-grasp poses.","We also demonstrate how CoPa can be seamlessly integrated with existing robotic planning algorithms to accomplish complex, long-horizon tasks.","Our comprehensive real-world experiments show that CoPa possesses a fine-grained physical understanding of scenes, capable of handling open-set instructions and objects with minimal prompt engineering and without additional training.","Project page: https://copa-2024.github.io/"],"url":"http://arxiv.org/abs/2403.08248v1"}
{"created":"2024-03-13 04:14:33","title":"Boosting Disfluency Detection with Large Language Model as Disfluency Generator","abstract":"Current disfluency detection methods heavily rely on costly and scarce human-annotated data. To tackle this issue, some approaches employ heuristic or statistical features to generate disfluent sentences, partially improving detection performance. However, these sentences often deviate from real-life scenarios, constraining overall model enhancement. In this study, we propose a lightweight data augmentation approach for disfluency detection, utilizing the superior generative and semantic understanding capabilities of large language model (LLM) to generate disfluent sentences as augmentation data. We leverage LLM to generate diverse and more realistic sentences guided by specific prompts, without the need for fine-tuning the LLM. Subsequently, we apply an uncertainty-aware data filtering approach to improve the quality of the generated sentences, utilized in training a small detection model for improved performance. Experiments using enhanced data yielded state-of-the-art results. The results showed that using a small amount of LLM-generated enhanced data can significantly improve performance, thereby further enhancing cost-effectiveness.","sentences":["Current disfluency detection methods heavily rely on costly and scarce human-annotated data.","To tackle this issue, some approaches employ heuristic or statistical features to generate disfluent sentences, partially improving detection performance.","However, these sentences often deviate from real-life scenarios, constraining overall model enhancement.","In this study, we propose a lightweight data augmentation approach for disfluency detection, utilizing the superior generative and semantic understanding capabilities of large language model (LLM) to generate disfluent sentences as augmentation data.","We leverage LLM to generate diverse and more realistic sentences guided by specific prompts, without the need for fine-tuning the LLM.","Subsequently, we apply an uncertainty-aware data filtering approach to improve the quality of the generated sentences, utilized in training a small detection model for improved performance.","Experiments using enhanced data yielded state-of-the-art results.","The results showed that using a small amount of LLM-generated enhanced data can significantly improve performance, thereby further enhancing cost-effectiveness."],"url":"http://arxiv.org/abs/2403.08229v1"}
{"created":"2024-03-13 04:01:20","title":"REPAIR: Rank Correlation and Noisy Pair Half-replacing with Memory for Noisy Correspondence","abstract":"The presence of noise in acquired data invariably leads to performance degradation in cross-modal matching. Unfortunately, obtaining precise annotations in the multimodal field is expensive, which has prompted some methods to tackle the mismatched data pair issue in cross-modal matching contexts, termed as noisy correspondence. However, most of these existing noisy correspondence methods exhibit the following limitations: a) the problem of self-reinforcing error accumulation, and b) improper handling of noisy data pair. To tackle the two problems, we propose a generalized framework termed as Rank corrElation and noisy Pair hAlf-replacing wIth memoRy (REPAIR), which benefits from maintaining a memory bank for features of matched pairs. Specifically, we calculate the distances between the features in the memory bank and those of the target pair for each respective modality, and use the rank correlation of these two sets of distances to estimate the soft correspondence label of the target pair. Estimating soft correspondence based on memory bank features rather than using a similarity network can avoid the accumulation of errors due to incorrect network identifications. For pairs that are completely mismatched, REPAIR searches the memory bank for the most matching feature to replace one feature of one modality, instead of using the original pair directly or merely discarding the mismatched pair. We conduct experiments on three cross-modal datasets, i.e., Flickr30K, MSCOCO, and CC152K, proving the effectiveness and robustness of our REPAIR on synthetic and real-world noise.","sentences":["The presence of noise in acquired data invariably leads to performance degradation in cross-modal matching.","Unfortunately, obtaining precise annotations in the multimodal field is expensive, which has prompted some methods to tackle the mismatched data pair issue in cross-modal matching contexts, termed as noisy correspondence.","However, most of these existing noisy correspondence methods exhibit the following limitations: a) the problem of self-reinforcing error accumulation, and b) improper handling of noisy data pair.","To tackle the two problems, we propose a generalized framework termed as Rank corrElation and noisy Pair hAlf-replacing wIth memoRy (REPAIR), which benefits from maintaining a memory bank for features of matched pairs.","Specifically, we calculate the distances between the features in the memory bank and those of the target pair for each respective modality, and use the rank correlation of these two sets of distances to estimate the soft correspondence label of the target pair.","Estimating soft correspondence based on memory bank features rather than using a similarity network can avoid the accumulation of errors due to incorrect network identifications.","For pairs that are completely mismatched, REPAIR searches the memory bank for the most matching feature to replace one feature of one modality, instead of using the original pair directly or merely discarding the mismatched pair.","We conduct experiments on three cross-modal datasets, i.e., Flickr30K, MSCOCO, and CC152K, proving the effectiveness and robustness of our REPAIR on synthetic and real-world noise."],"url":"http://arxiv.org/abs/2403.08224v1"}
{"created":"2024-03-13 03:28:39","title":"PaddingFlow: Improving Normalizing Flows with Padding-Dimensional Noise","abstract":"Normalizing flow is a generative modeling approach with efficient sampling. However, Flow-based models suffer two issues, which are manifold and discrete data. If the target distribution is a manifold, which means the dimension of the latent target distribution and the dimension of the data distribution are unmatched, flow-based models might perform badly. Discrete data makes flow-based models collapse into a degenerate mixture of point masses. In this paper, to sidestep such two issues we propose PaddingFlow, a novel dequantization method, which improves normalizing flows with padding-dimensional noise. PaddingFlow is easy to implement, computationally cheap, widely suitable for various tasks, and generates samples that are unbiased estimations of the data. Especially, our method can overcome the limitation of existing dequantization methods that have to change the data distribution, which might degrade performance. We validate our method on the main benchmarks of unconditional density estimation, including five tabular datasets and four image datasets for VAE models, and the IK experiments which are conditional density estimation. The results show that PaddingFlow can provide improvement on all tasks in this paper.","sentences":["Normalizing flow is a generative modeling approach with efficient sampling.","However, Flow-based models suffer two issues, which are manifold and discrete data.","If the target distribution is a manifold, which means the dimension of the latent target distribution and the dimension of the data distribution are unmatched, flow-based models might perform badly.","Discrete data makes flow-based models collapse into a degenerate mixture of point masses.","In this paper, to sidestep such two issues we propose PaddingFlow, a novel dequantization method, which improves normalizing flows with padding-dimensional noise.","PaddingFlow is easy to implement, computationally cheap, widely suitable for various tasks, and generates samples that are unbiased estimations of the data.","Especially, our method can overcome the limitation of existing dequantization methods that have to change the data distribution, which might degrade performance.","We validate our method on the main benchmarks of unconditional density estimation, including five tabular datasets and four image datasets for VAE models, and the IK experiments which are conditional density estimation.","The results show that PaddingFlow can provide improvement on all tasks in this paper."],"url":"http://arxiv.org/abs/2403.08216v1"}
{"created":"2024-03-13 03:24:36","title":"LIX: Implicitly Infusing Spatial Geometric Prior Knowledge into Visual Semantic Segmentation for Autonomous Driving","abstract":"Despite the impressive performance achieved by data-fusion networks with duplex encoders for visual semantic segmentation, they become ineffective when spatial geometric data are not available. Implicitly infusing the spatial geometric prior knowledge acquired by a duplex-encoder teacher model into a single-encoder student model is a practical, albeit less explored research avenue. This paper delves into this topic and resorts to knowledge distillation approaches to address this problem. We introduce the Learning to Infuse \"X\" (LIX) framework, with novel contributions in both logit distillation and feature distillation aspects. We present a mathematical proof that underscores the limitation of using a single fixed weight in decoupled knowledge distillation and introduce a logit-wise dynamic weight controller as a solution to this issue. Furthermore, we develop an adaptively-recalibrated feature distillation algorithm, including two technical novelties: feature recalibration via kernel regression and in-depth feature consistency quantification via centered kernel alignment. Extensive experiments conducted with intermediate-fusion and late-fusion networks across various public datasets provide both quantitative and qualitative evaluations, demonstrating the superior performance of our LIX framework when compared to other state-of-the-art approaches.","sentences":["Despite the impressive performance achieved by data-fusion networks with duplex encoders for visual semantic segmentation, they become ineffective when spatial geometric data are not available.","Implicitly infusing the spatial geometric prior knowledge acquired by a duplex-encoder teacher model into a single-encoder student model is a practical, albeit less explored research avenue.","This paper delves into this topic and resorts to knowledge distillation approaches to address this problem.","We introduce the Learning to Infuse \"X\" (LIX) framework, with novel contributions in both logit distillation and feature distillation aspects.","We present a mathematical proof that underscores the limitation of using a single fixed weight in decoupled knowledge distillation and introduce a logit-wise dynamic weight controller as a solution to this issue.","Furthermore, we develop an adaptively-recalibrated feature distillation algorithm, including two technical novelties: feature recalibration via kernel regression and in-depth feature consistency quantification via centered kernel alignment.","Extensive experiments conducted with intermediate-fusion and late-fusion networks across various public datasets provide both quantitative and qualitative evaluations, demonstrating the superior performance of our LIX framework when compared to other state-of-the-art approaches."],"url":"http://arxiv.org/abs/2403.08215v1"}
{"created":"2024-03-13 03:23:50","title":"P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer","abstract":"Traditional deep learning methods struggle to simultaneously segment, recognize, and forecast human activities from sensor data. This limits their usefulness in many fields such as healthcare and assisted living, where real-time understanding of ongoing and upcoming activities is crucial. This paper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles all three tasks in a efficient single-task model. P2LHAP divides sensor data streams into a sequence of \"patches\", served as input tokens, and outputs a sequence of patch-level activity labels including the predicted future activities. A unique smoothing technique based on surrounding patch labels, is proposed to identify activity boundaries accurately. Additionally, P2LHAP learns patch-level representation by sensor signal channel-independent Transformer encoders and decoders. All channels share embedding and Transformer weights across all sequences. Evaluated on three public datasets, P2LHAP significantly outperforms the state-of-the-art in all three tasks, demonstrating its effectiveness and potential for real-world applications.","sentences":["Traditional deep learning methods struggle to simultaneously segment, recognize, and forecast human activities from sensor data.","This limits their usefulness in many fields such as healthcare and assisted living, where real-time understanding of ongoing and upcoming activities is crucial.","This paper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles all three tasks in a efficient single-task model.","P2LHAP divides sensor data streams into a sequence of \"patches\", served as input tokens, and outputs a sequence of patch-level activity labels including the predicted future activities.","A unique smoothing technique based on surrounding patch labels, is proposed to identify activity boundaries accurately.","Additionally, P2LHAP learns patch-level representation by sensor signal channel-independent Transformer encoders and decoders.","All channels share embedding and Transformer weights across all sequences.","Evaluated on three public datasets, P2LHAP significantly outperforms the state-of-the-art in all three tasks, demonstrating its effectiveness and potential for real-world applications."],"url":"http://arxiv.org/abs/2403.08214v1"}
{"created":"2024-03-13 03:22:02","title":"Can Large Language Models Identify Authorship?","abstract":"The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis, encompassing authorship verification and attribution, remains underexplored. This paper conducts a comprehensive evaluation of LLMs in these critical tasks. Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models. These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability. This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively? (2) Are LLMs capable of accurately attributing authorship among multiple candidates authors (e.g., 10 and 20)? (3) How can LLMs provide explainability in authorship analysis, particularly through the role of linguistic features? Moreover, we investigate the integration of explicit linguistic features to guide LLMs in their reasoning processes. Our extensive assessment demonstrates LLMs' proficiency in both tasks without the need for domain-specific fine-tuning, providing insights into their decision-making via a detailed analysis of linguistic features. This establishes a new benchmark for future research on LLM-based authorship analysis. The code and data are available at https://github.com/baixianghuang/authorship-llm.","sentences":["The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation.","Large Language Models (LLMs) have demonstrated exceptional capacity for reasoning and problem-solving.","However, their potential in authorship analysis, encompassing authorship verification and attribution, remains underexplored.","This paper conducts a comprehensive evaluation of LLMs in these critical tasks.","Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models.","These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability.","This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively?","(2) Are LLMs capable of accurately attributing authorship among multiple candidates authors (e.g., 10 and 20)?","(3) How can LLMs provide explainability in authorship analysis, particularly through the role of linguistic features?","Moreover, we investigate the integration of explicit linguistic features to guide LLMs in their reasoning processes.","Our extensive assessment demonstrates LLMs' proficiency in both tasks without the need for domain-specific fine-tuning, providing insights into their decision-making via a detailed analysis of linguistic features.","This establishes a new benchmark for future research on LLM-based authorship analysis.","The code and data are available at https://github.com/baixianghuang/authorship-llm."],"url":"http://arxiv.org/abs/2403.08213v1"}
{"created":"2024-03-13 03:11:50","title":"Height-bounded Lempel-Ziv encodings","abstract":"We introduce height-bounded LZ encodings (LZHB), a new family of compressed representations that is a variant of Lempel-Ziv parsings with a focus on allowing fast access to arbitrary positions of the text directly via the compressed representation. Any LZHB encoding whose referencing height is bounded by $h$ allows access to an arbitrary position of the underlying text using $O(h)$ predecessor queries. We show that there exists a constant $c$ such that the size $\\hat{z}_{\\mathit{HB}(c\\log n)}$ of the optimal (smallest) LZHB encoding whose height is bounded by $c\\log n$ for any string of length $n$ is $O(\\hat{g}_{\\mathrm{rl}})$, where $\\hat{g}_{\\mathrm{rl}}$ is the size of the smallest run-length grammar. Furthermore, we show that there exists a family of strings such that $\\hat{z}_{\\mathit{HB}(c\\log n)} = o(\\hat{g}_{\\mathrm{rl}})$, thus making $\\hat{z}_{\\mathit{HB}(c\\log n)}$ one of the smallest known repetitiveness measures for which $O(\\mathit{polylog} n)$ time access is possible using $O(\\hat{z}_{\\mathit{HB}(c\\log n)})$ space. While computing the optimal LZHB representation for any given height seems difficult, we propose linear and near linear time greedy algorithms which we show experimentally can efficiently find small LZHB representations in practice.","sentences":["We introduce height-bounded LZ encodings (LZHB), a new family of compressed representations that is a variant of Lempel-Ziv parsings with a focus on allowing fast access to arbitrary positions of the text directly via the compressed representation.","Any LZHB encoding whose referencing height is bounded by $h$ allows access to an arbitrary position of the underlying text using $O(h)$ predecessor queries.","We show that there exists a constant $c$ such that the size $\\hat{z}_{\\mathit{HB}(c\\log n)}$ of the optimal (smallest) LZHB encoding whose height is bounded by $c\\log n$ for any string of length $n$ is $O(\\hat{g}_{\\mathrm{rl}})$, where $\\hat{g}_{\\mathrm{rl}}$ is the size of the smallest run-length grammar.","Furthermore, we show that there exists a family of strings such that $\\hat{z}_{\\mathit{HB}(c\\log n)} = o(\\hat{g}_{\\mathrm{rl}})$, thus making $\\hat{z}_{\\mathit{HB}(c\\log n)}$ one of the smallest known repetitiveness measures for which $O(\\mathit{polylog} n)$ time access is possible using $O(\\hat{z}_{\\mathit{HB}(c\\log n)})$ space.","While computing the optimal LZHB representation for any given height seems difficult, we propose linear and near linear time greedy algorithms which we show experimentally can efficiently find small LZHB representations in practice."],"url":"http://arxiv.org/abs/2403.08209v1"}
{"created":"2024-03-13 03:10:11","title":"Advancing Security in AI Systems: A Novel Approach to Detecting Backdoors in Deep Neural Networks","abstract":"In the rapidly evolving landscape of communication and network security, the increasing reliance on deep neural networks (DNNs) and cloud services for data processing presents a significant vulnerability: the potential for backdoors that can be exploited by malicious actors. Our approach leverages advanced tensor decomposition algorithms Independent Vector Analysis (IVA), Multiset Canonical Correlation Analysis (MCCA), and Parallel Factor Analysis (PARAFAC2) to meticulously analyze the weights of pre-trained DNNs and distinguish between backdoored and clean models effectively. The key strengths of our method lie in its domain independence, adaptability to various network architectures, and ability to operate without access to the training data of the scrutinized models. This not only ensures versatility across different application scenarios but also addresses the challenge of identifying backdoors without prior knowledge of the specific triggers employed to alter network behavior. We have applied our detection pipeline to three distinct computer vision datasets, encompassing both image classification and object detection tasks. The results demonstrate a marked improvement in both accuracy and efficiency over existing backdoor detection methods. This advancement enhances the security of deep learning and AI in networked systems, providing essential cybersecurity against evolving threats in emerging technologies.","sentences":["In the rapidly evolving landscape of communication and network security, the increasing reliance on deep neural networks (DNNs) and cloud services for data processing presents a significant vulnerability: the potential for backdoors that can be exploited by malicious actors.","Our approach leverages advanced tensor decomposition algorithms Independent Vector Analysis (IVA), Multiset Canonical Correlation Analysis (MCCA), and Parallel Factor Analysis (PARAFAC2) to meticulously analyze the weights of pre-trained DNNs and distinguish between backdoored and clean models effectively.","The key strengths of our method lie in its domain independence, adaptability to various network architectures, and ability to operate without access to the training data of the scrutinized models.","This not only ensures versatility across different application scenarios but also addresses the challenge of identifying backdoors without prior knowledge of the specific triggers employed to alter network behavior.","We have applied our detection pipeline to three distinct computer vision datasets, encompassing both image classification and object detection tasks.","The results demonstrate a marked improvement in both accuracy and efficiency over existing backdoor detection methods.","This advancement enhances the security of deep learning and AI in networked systems, providing essential cybersecurity against evolving threats in emerging technologies."],"url":"http://arxiv.org/abs/2403.08208v1"}
{"created":"2024-03-13 02:56:31","title":"AutoDFP: Automatic Data-Free Pruning via Channel Similarity Reconstruction","abstract":"Structured pruning methods are developed to bridge the gap between the massive scale of neural networks and the limited hardware resources. Most current structured pruning methods rely on training datasets to fine-tune the compressed model, resulting in high computational burdens and being inapplicable for scenarios with stringent requirements on privacy and security. As an alternative, some data-free methods have been proposed, however, these methods often require handcraft parameter tuning and can only achieve inflexible reconstruction. In this paper, we propose the Automatic Data-Free Pruning (AutoDFP) method that achieves automatic pruning and reconstruction without fine-tuning. Our approach is based on the assumption that the loss of information can be partially compensated by retaining focused information from similar channels. Specifically, We formulate data-free pruning as an optimization problem, which can be effectively addressed through reinforcement learning. AutoDFP assesses the similarity of channels for each layer and provides this information to the reinforcement learning agent, guiding the pruning and reconstruction process of the network. We evaluate AutoDFP with multiple networks on multiple datasets, achieving impressive compression results. For instance, on the CIFAR-10 dataset, AutoDFP demonstrates a 2.87\\% reduction in accuracy loss compared to the recently proposed data-free pruning method DFPC with fewer FLOPs on VGG-16. Furthermore, on the ImageNet dataset, AutoDFP achieves 43.17\\% higher accuracy than the SOTA method with the same 80\\% preserved ratio on MobileNet-V1.","sentences":["Structured pruning methods are developed to bridge the gap between the massive scale of neural networks and the limited hardware resources.","Most current structured pruning methods rely on training datasets to fine-tune the compressed model, resulting in high computational burdens and being inapplicable for scenarios with stringent requirements on privacy and security.","As an alternative, some data-free methods have been proposed, however, these methods often require handcraft parameter tuning and can only achieve inflexible reconstruction.","In this paper, we propose the Automatic Data-Free Pruning (AutoDFP) method that achieves automatic pruning and reconstruction without fine-tuning.","Our approach is based on the assumption that the loss of information can be partially compensated by retaining focused information from similar channels.","Specifically, We formulate data-free pruning as an optimization problem, which can be effectively addressed through reinforcement learning.","AutoDFP assesses the similarity of channels for each layer and provides this information to the reinforcement learning agent, guiding the pruning and reconstruction process of the network.","We evaluate AutoDFP with multiple networks on multiple datasets, achieving impressive compression results.","For instance, on the CIFAR-10 dataset, AutoDFP demonstrates a 2.87\\% reduction in accuracy loss compared to the recently proposed data-free pruning method DFPC with fewer FLOPs on VGG-16.","Furthermore, on the ImageNet dataset, AutoDFP achieves 43.17\\% higher accuracy than the SOTA method with the same 80\\% preserved ratio on MobileNet-V1."],"url":"http://arxiv.org/abs/2403.08204v1"}
{"created":"2024-03-13 02:46:17","title":"Validating and Exploring Large Geographic Corpora","abstract":"This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora. Beginning with a 427 billion word corpus derived from the Common Crawl, three methods are used to improve the quality of sub-corpora representing specific language-country pairs like New Zealand English: (i) the agreement of independent language identification systems, (ii) hash-based deduplication, and (iii) location-specific outlier detection. The impact of each of these steps is then evaluated at the language level and the country level by using corpus similarity measures to compare each resulting corpus with baseline data sets. The goal is to understand the impact of upstream data cleaning decisions on downstream corpora with a specific focus on under-represented languages and populations. The evaluation shows that the validity of sub-corpora is improved with each stage of cleaning but that this improvement is unevenly distributed across languages and populations. This result shows how standard corpus creation techniques can accidentally exclude under-represented populations.","sentences":["This paper investigates the impact of corpus creation decisions on large multi-lingual geographic web corpora.","Beginning with a 427 billion word corpus derived from the Common Crawl, three methods are used to improve the quality of sub-corpora representing specific language-country pairs like New Zealand English: (i) the agreement of independent language identification systems, (ii) hash-based deduplication, and (iii) location-specific outlier detection.","The impact of each of these steps is then evaluated at the language level and the country level by using corpus similarity measures to compare each resulting corpus with baseline data sets.","The goal is to understand the impact of upstream data cleaning decisions on downstream corpora with a specific focus on under-represented languages and populations.","The evaluation shows that the validity of sub-corpora is improved with each stage of cleaning but that this improvement is unevenly distributed across languages and populations.","This result shows how standard corpus creation techniques can accidentally exclude under-represented populations."],"url":"http://arxiv.org/abs/2403.08198v1"}
{"created":"2024-03-13 02:44:33","title":"PAGE: Domain-Incremental Adaptation with Past-Agnostic Generative Replay for Smart Healthcare","abstract":"We propose PAGE, a domain-incremental adaptation strategy with past-agnostic generative replay for smart healthcare. PAGE enables generative replay without the aid of any preserved data or information from prior domains. When adapting to a new domain, it exploits real data from the new distribution and the current model to generate synthetic data that retain the learned knowledge of previous domains. By replaying the synthetic data with the new real data during training, PAGE achieves a good balance between domain adaptation and knowledge retention. In addition, we incorporate an extended inductive conformal prediction (EICP) method into PAGE to produce a confidence score and a credibility value for each detection result. This makes the predictions interpretable and provides statistical guarantees for disease detection in smart healthcare applications. We demonstrate PAGE's effectiveness in domain-incremental disease detection with three distinct disease datasets collected from commercially available WMSs. PAGE achieves highly competitive performance against state-of-the-art with superior scalability, data privacy, and feasibility. Furthermore, PAGE can enable up to 75% reduction in clinical workload with the help of EICP.","sentences":["We propose PAGE, a domain-incremental adaptation strategy with past-agnostic generative replay for smart healthcare.","PAGE enables generative replay without the aid of any preserved data or information from prior domains.","When adapting to a new domain, it exploits real data from the new distribution and the current model to generate synthetic data that retain the learned knowledge of previous domains.","By replaying the synthetic data with the new real data during training, PAGE achieves a good balance between domain adaptation and knowledge retention.","In addition, we incorporate an extended inductive conformal prediction (EICP) method into PAGE to produce a confidence score and a credibility value for each detection result.","This makes the predictions interpretable and provides statistical guarantees for disease detection in smart healthcare applications.","We demonstrate PAGE's effectiveness in domain-incremental disease detection with three distinct disease datasets collected from commercially available WMSs.","PAGE achieves highly competitive performance against state-of-the-art with superior scalability, data privacy, and feasibility.","Furthermore, PAGE can enable up to 75% reduction in clinical workload with the help of EICP."],"url":"http://arxiv.org/abs/2403.08197v1"}
{"created":"2024-03-13 02:33:57","title":"Unsupervised Learning of Hybrid Latent Dynamics: A Learn-to-Identify Framework","abstract":"Modern applications increasingly require unsupervised learning of latent dynamics from high-dimensional time-series. This presents a significant challenge of identifiability: many abstract latent representations may reconstruct observations, yet do they guarantee an adequate identification of the governing dynamics? This paper investigates this challenge from two angles: the use of physics inductive bias specific to the data being modeled, and a learn-to-identify strategy that separates forecasting objectives from the data used for the identification. We combine these two strategies in a novel framework for unsupervised meta-learning of hybrid latent dynamics (Meta-HyLaD) with: 1) a latent dynamic function that hybridize known mathematical expressions of prior physics with neural functions describing its unknown errors, and 2) a meta-learning formulation to learn to separately identify both components of the hybrid dynamics. Through extensive experiments on five physics and one biomedical systems, we provide strong evidence for the benefits of Meta-HyLaD to integrate rich prior knowledge while identifying their gap to observed data.","sentences":["Modern applications increasingly require unsupervised learning of latent dynamics from high-dimensional time-series.","This presents a significant challenge of identifiability: many abstract latent representations may reconstruct observations, yet do they guarantee an adequate identification of the governing dynamics?","This paper investigates this challenge from two angles: the use of physics inductive bias specific to the data being modeled, and a learn-to-identify strategy that separates forecasting objectives from the data used for the identification.","We combine these two strategies in a novel framework for unsupervised meta-learning of hybrid latent dynamics (Meta-HyLaD) with: 1) a latent dynamic function that hybridize known mathematical expressions of prior physics with neural functions describing its unknown errors, and 2) a meta-learning formulation to learn to separately identify both components of the hybrid dynamics.","Through extensive experiments on five physics and one biomedical systems, we provide strong evidence for the benefits of Meta-HyLaD to integrate rich prior knowledge while identifying their gap to observed data."],"url":"http://arxiv.org/abs/2403.08194v1"}
{"created":"2024-03-13 02:23:13","title":"Embedded Translations for Low-resource Automated Glossing","abstract":"We investigate automatic interlinear glossing in low-resource settings. We augment a hard-attentional neural model with embedded translation information extracted from interlinear glossed text. After encoding these translations using large language models, specifically BERT and T5, we introduce a character-level decoder for generating glossed output. Aided by these enhancements, our model demonstrates an average improvement of 3.97\\%-points over the previous state of the art on datasets from the SIGMORPHON 2023 Shared Task on Interlinear Glossing. In a simulated ultra low-resource setting, trained on as few as 100 sentences, our system achieves an average 9.78\\%-point improvement over the plain hard-attentional baseline. These results highlight the critical role of translation information in boosting the system's performance, especially in processing and interpreting modest data sources. Our findings suggest a promising avenue for the documentation and preservation of languages, with our experiments on shared task datasets indicating significant advancements over the existing state of the art.","sentences":["We investigate automatic interlinear glossing in low-resource settings.","We augment a hard-attentional neural model with embedded translation information extracted from interlinear glossed text.","After encoding these translations using large language models, specifically BERT and T5, we introduce a character-level decoder for generating glossed output.","Aided by these enhancements, our model demonstrates an average improvement of 3.97\\%-points over the previous state of the art on datasets from the SIGMORPHON 2023 Shared Task on Interlinear Glossing.","In a simulated ultra low-resource setting, trained on as few as 100 sentences, our system achieves an average 9.78\\%-point improvement over the plain hard-attentional baseline.","These results highlight the critical role of translation information in boosting the system's performance, especially in processing and interpreting modest data sources.","Our findings suggest a promising avenue for the documentation and preservation of languages, with our experiments on shared task datasets indicating significant advancements over the existing state of the art."],"url":"http://arxiv.org/abs/2403.08189v1"}
{"created":"2024-03-13 01:56:32","title":"Rethinking Loss Functions for Fact Verification","abstract":"We explore loss functions for fact verification in the FEVER shared task. While the cross-entropy loss is a standard objective for training verdict predictors, it fails to capture the heterogeneity among the FEVER verdict classes. In this paper, we develop two task-specific objectives tailored to FEVER. Experimental results confirm that the proposed objective functions outperform the standard cross-entropy. Performance is further improved when these objectives are combined with simple class weighting, which effectively overcomes the imbalance in the training data. The souce code is available at https://github.com/yuta-mukobara/RLF-KGAT","sentences":["We explore loss functions for fact verification in the FEVER shared task.","While the cross-entropy loss is a standard objective for training verdict predictors, it fails to capture the heterogeneity among the FEVER verdict classes.","In this paper, we develop two task-specific objectives tailored to FEVER.","Experimental results confirm that the proposed objective functions outperform the standard cross-entropy.","Performance is further improved when these objectives are combined with simple class weighting, which effectively overcomes the imbalance in the training data.","The souce code is available at https://github.com/yuta-mukobara/RLF-KGAT"],"url":"http://arxiv.org/abs/2403.08174v1"}
{"created":"2024-03-13 01:54:33","title":"A bargain for mergesorts (functional pearl) -- How to prove your mergesort correct and stable, almost for free","abstract":"We present a novel characterization of stable mergesort functions using relational parametricity, and show that it implies the correctness of mergesort. As a result, one can prove the correctness of several variations of mergesort (e.g., top-down, bottom-up, tail-recursive, non-tail-recursive, smooth, and non-smooth mergesorts) by proving the characterization property for each variation. To further motivate this work, we show a performance trade-off between tail-recursive and non-tail-recursive mergesorts that (1) the former in call-by-value evaluation avoids using up stack space and is efficient and (2) the latter in call-by-need evaluation is an optimal incremental sort, meaning that it performs only $\\mathcal{O}(n + k \\log k)$ comparisons to compute the least (or greatest) $k$ items of a list of length $n$. Thanks to our characterization and the parametricity translation, we deduced the correctness results, including stability, of various implementations of mergesort for lists, including highly optimized ones, in the Coq proof assistant.","sentences":["We present a novel characterization of stable mergesort functions using relational parametricity, and show that it implies the correctness of mergesort.","As a result, one can prove the correctness of several variations of mergesort (e.g., top-down, bottom-up, tail-recursive, non-tail-recursive, smooth, and non-smooth mergesorts) by proving the characterization property for each variation.","To further motivate this work, we show a performance trade-off between tail-recursive and non-tail-recursive mergesorts that (1) the former in call-by-value evaluation avoids using up stack space and is efficient and (2) the latter in call-by-need evaluation is an optimal incremental sort, meaning that it performs only $\\mathcal{O}(n + k \\log k)$ comparisons to compute the least (or greatest)","$k$ items of a list of length $n$. Thanks to our characterization and the parametricity translation, we deduced the correctness results, including stability, of various implementations of mergesort for lists, including highly optimized ones, in the Coq proof assistant."],"url":"http://arxiv.org/abs/2403.08173v1"}
{"created":"2024-03-13 01:38:42","title":"MolBind: Multimodal Alignment of Language, Molecules, and Proteins","abstract":"Recent advancements in biology and chemistry have leveraged multi-modal learning, integrating molecules and their natural language descriptions to enhance drug discovery. However, current pre-training frameworks are limited to two modalities, and designing a unified network to process different modalities (e.g., natural language, 2D molecular graphs, 3D molecular conformations, and 3D proteins) remains challenging due to inherent gaps among them. In this work, we propose MolBind, a framework that trains encoders for multiple modalities through contrastive learning, mapping all modalities to a shared feature space for multi-modal semantic alignment. To facilitate effective pre-training of MolBind on multiple modalities, we also build and collect a high-quality dataset with four modalities, MolBind-M4, including graph-language, conformation-language, graph-conformation, and conformation-protein paired data. MolBind shows superior zero-shot learning performance across a wide range of tasks, demonstrating its strong capability of capturing the underlying semantics of multiple modalities.","sentences":["Recent advancements in biology and chemistry have leveraged multi-modal learning, integrating molecules and their natural language descriptions to enhance drug discovery.","However, current pre-training frameworks are limited to two modalities, and designing a unified network to process different modalities (e.g., natural language, 2D molecular graphs, 3D molecular conformations, and 3D proteins) remains challenging due to inherent gaps among them.","In this work, we propose MolBind, a framework that trains encoders for multiple modalities through contrastive learning, mapping all modalities to a shared feature space for multi-modal semantic alignment.","To facilitate effective pre-training of MolBind on multiple modalities, we also build and collect a high-quality dataset with four modalities, MolBind-M4, including graph-language, conformation-language, graph-conformation, and conformation-protein paired data.","MolBind shows superior zero-shot learning performance across a wide range of tasks, demonstrating its strong capability of capturing the underlying semantics of multiple modalities."],"url":"http://arxiv.org/abs/2403.08167v1"}
{"created":"2024-03-13 01:27:57","title":"EM-TTS: Efficiently Trained Low-Resource Mongolian Lightweight Text-to-Speech","abstract":"Recently, deep learning-based Text-to-Speech (TTS) systems have achieved high-quality speech synthesis results. Recurrent neural networks have become a standard modeling technique for sequential data in TTS systems and are widely used. However, training a TTS model which includes RNN components requires powerful GPU performance and takes a long time. In contrast, CNN-based sequence synthesis techniques can significantly reduce the parameters and training time of a TTS model while guaranteeing a certain performance due to their high parallelism, which alleviate these economic costs of training. In this paper, we propose a lightweight TTS system based on deep convolutional neural networks, which is a two-stage training end-to-end TTS model and does not employ any recurrent units. Our model consists of two stages: Text2Spectrum and SSRN. The former is used to encode phonemes into a coarse mel spectrogram and the latter is used to synthesize the complete spectrum from the coarse mel spectrogram. Meanwhile, we improve the robustness of our model by a series of data augmentations, such as noise suppression, time warping, frequency masking and time masking, for solving the low resource mongolian problem. Experiments show that our model can reduce the training time and parameters while ensuring the quality and naturalness of the synthesized speech compared to using mainstream TTS models. Our method uses NCMMSC2022-MTTSC Challenge dataset for validation, which significantly reduces training time while maintaining a certain accuracy.","sentences":["Recently, deep learning-based Text-to-Speech (TTS) systems have achieved high-quality speech synthesis results.","Recurrent neural networks have become a standard modeling technique for sequential data in TTS systems and are widely used.","However, training a TTS model which includes RNN components requires powerful GPU performance and takes a long time.","In contrast, CNN-based sequence synthesis techniques can significantly reduce the parameters and training time of a TTS model while guaranteeing a certain performance due to their high parallelism, which alleviate these economic costs of training.","In this paper, we propose a lightweight TTS system based on deep convolutional neural networks, which is a two-stage training end-to-end TTS model and does not employ any recurrent units.","Our model consists of two stages: Text2Spectrum and SSRN.","The former is used to encode phonemes into a coarse mel spectrogram and the latter is used to synthesize the complete spectrum from the coarse mel spectrogram.","Meanwhile, we improve the robustness of our model by a series of data augmentations, such as noise suppression, time warping, frequency masking and time masking, for solving the low resource mongolian problem.","Experiments show that our model can reduce the training time and parameters while ensuring the quality and naturalness of the synthesized speech compared to using mainstream TTS models.","Our method uses NCMMSC2022-MTTSC Challenge dataset for validation, which significantly reduces training time while maintaining a certain accuracy."],"url":"http://arxiv.org/abs/2403.08164v1"}
{"created":"2024-03-13 00:48:41","title":"Multiscale Low-Frequency Memory Network for Improved Feature Extraction in Convolutional Neural Networks","abstract":"Deep learning and Convolutional Neural Networks (CNNs) have driven major transformations in diverse research areas. However, their limitations in handling low-frequency information present obstacles in certain tasks like interpreting global structures or managing smooth transition images. Despite the promising performance of transformer structures in numerous tasks, their intricate optimization complexities highlight the persistent need for refined CNN enhancements using limited resources. Responding to these complexities, we introduce a novel framework, the Multiscale Low-Frequency Memory (MLFM) Network, with the goal to harness the full potential of CNNs while keeping their complexity unchanged. The MLFM efficiently preserves low-frequency information, enhancing performance in targeted computer vision tasks. Central to our MLFM is the Low-Frequency Memory Unit (LFMU), which stores various low-frequency data and forms a parallel channel to the core network. A key advantage of MLFM is its seamless compatibility with various prevalent networks, requiring no alterations to their original core structure. Testing on ImageNet demonstrated substantial accuracy improvements in multiple 2D CNNs, including ResNet, MobileNet, EfficientNet, and ConvNeXt. Furthermore, we showcase MLFM's versatility beyond traditional image classification by successfully integrating it into image-to-image translation tasks, specifically in semantic segmentation networks like FCN and U-Net. In conclusion, our work signifies a pivotal stride in the journey of optimizing the efficacy and efficiency of CNNs with limited resources. This research builds upon the existing CNN foundations and paves the way for future advancements in computer vision. Our codes are available at https://github.com/AlphaWuSeu/ MLFM.","sentences":["Deep learning and Convolutional Neural Networks (CNNs) have driven major transformations in diverse research areas.","However, their limitations in handling low-frequency information present obstacles in certain tasks like interpreting global structures or managing smooth transition images.","Despite the promising performance of transformer structures in numerous tasks, their intricate optimization complexities highlight the persistent need for refined CNN enhancements using limited resources.","Responding to these complexities, we introduce a novel framework, the Multiscale Low-Frequency Memory (MLFM) Network, with the goal to harness the full potential of CNNs while keeping their complexity unchanged.","The MLFM efficiently preserves low-frequency information, enhancing performance in targeted computer vision tasks.","Central to our MLFM is the Low-Frequency Memory Unit (LFMU), which stores various low-frequency data and forms a parallel channel to the core network.","A key advantage of MLFM is its seamless compatibility with various prevalent networks, requiring no alterations to their original core structure.","Testing on ImageNet demonstrated substantial accuracy improvements in multiple 2D CNNs, including ResNet, MobileNet, EfficientNet, and ConvNeXt.","Furthermore, we showcase MLFM's versatility beyond traditional image classification by successfully integrating it into image-to-image translation tasks, specifically in semantic segmentation networks like FCN and U-Net.","In conclusion, our work signifies a pivotal stride in the journey of optimizing the efficacy and efficiency of CNNs with limited resources.","This research builds upon the existing CNN foundations and paves the way for future advancements in computer vision.","Our codes are available at https://github.com/AlphaWuSeu/ MLFM."],"url":"http://arxiv.org/abs/2403.08157v1"}
{"created":"2024-03-13 00:43:10","title":"NeRF-Supervised Feature Point Detection and Description","abstract":"Feature point detection and description is the backbone for various computer vision applications, such as Structure-from-Motion, visual SLAM, and visual place recognition. While learning-based methods have surpassed traditional handcrafted techniques, their training often relies on simplistic homography-based simulations of multi-view perspectives, limiting model generalisability. This paper introduces a novel approach leveraging neural radiance fields (NeRFs) for realistic multi-view training data generation. We create a diverse multi-view dataset using NeRFs, consisting of indoor and outdoor scenes. Our proposed methodology adapts state-of-the-art feature detectors and descriptors to train on NeRF-synthesised views supervised by perspective projective geometry. Our experiments demonstrate that the proposed methods achieve competitive or superior performance on standard benchmarks for relative pose estimation, point cloud registration, and homography estimation while requiring significantly less training data compared to existing approaches.","sentences":["Feature point detection and description is the backbone for various computer vision applications, such as Structure-from-Motion, visual SLAM, and visual place recognition.","While learning-based methods have surpassed traditional handcrafted techniques, their training often relies on simplistic homography-based simulations of multi-view perspectives, limiting model generalisability.","This paper introduces a novel approach leveraging neural radiance fields (NeRFs) for realistic multi-view training data generation.","We create a diverse multi-view dataset using NeRFs, consisting of indoor and outdoor scenes.","Our proposed methodology adapts state-of-the-art feature detectors and descriptors to train on NeRF-synthesised views supervised by perspective projective geometry.","Our experiments demonstrate that the proposed methods achieve competitive or superior performance on standard benchmarks for relative pose estimation, point cloud registration, and homography estimation while requiring significantly less training data compared to existing approaches."],"url":"http://arxiv.org/abs/2403.08156v1"}
{"created":"2024-03-13 00:32:30","title":"The Effect of Different Optimization Strategies to Physics-Constrained Deep Learning for Soil Moisture Estimation","abstract":"Soil moisture is a key hydrological parameter that has significant importance to human society and the environment. Accurate modeling and monitoring of soil moisture in crop fields, especially in the root zone (top 100 cm of soil), is essential for improving agricultural production and crop yield with the help of precision irrigation and farming tools. Realizing the full sensor data potential depends greatly on advanced analytical and predictive domain-aware models. In this work, we propose a physics-constrained deep learning (P-DL) framework to integrate physics-based principles on water transport and water sensing signals for effective reconstruction of the soil moisture dynamics. We adopt three different optimizers, namely Adam, RMSprop, and GD, to minimize the loss function of P-DL during the training process. In the illustrative case study, we demonstrate the empirical convergence of Adam optimizers outperforms the other optimization methods in both mini-batch and full-batch training.","sentences":["Soil moisture is a key hydrological parameter that has significant importance to human society and the environment.","Accurate modeling and monitoring of soil moisture in crop fields, especially in the root zone (top 100 cm of soil), is essential for improving agricultural production and crop yield with the help of precision irrigation and farming tools.","Realizing the full sensor data potential depends greatly on advanced analytical and predictive domain-aware models.","In this work, we propose a physics-constrained deep learning (P-DL) framework to integrate physics-based principles on water transport and water sensing signals for effective reconstruction of the soil moisture dynamics.","We adopt three different optimizers, namely Adam, RMSprop, and GD, to minimize the loss function of P-DL during the training process.","In the illustrative case study, we demonstrate the empirical convergence of Adam optimizers outperforms the other optimization methods in both mini-batch and full-batch training."],"url":"http://arxiv.org/abs/2403.08154v1"}
{"created":"2024-03-13 00:30:47","title":"The Runtime of Random Local Search on the Generalized Needle Problem","abstract":"In their recent work, C. Doerr and Krejca (Transactions on Evolutionary Computation, 2023) proved upper bounds on the expected runtime of the randomized local search heuristic on generalized Needle functions. Based on these upper bounds, they deduce in a not fully rigorous manner a drastic influence of the needle radius $k$ on the runtime.   In this short article, we add the missing lower bound necessary to determine the influence of parameter $k$ on the runtime. To this aim, we derive an exact description of the expected runtime, which also significantly improves the upper bound given by C. Doerr and Krejca. We also describe asymptotic estimates of the expected runtime.","sentences":["In their recent work, C. Doerr and Krejca (Transactions on Evolutionary Computation, 2023) proved upper bounds on the expected runtime of the randomized local search heuristic on generalized Needle functions.","Based on these upper bounds, they deduce in a not fully rigorous manner a drastic influence of the needle radius $k$ on the runtime.   ","In this short article, we add the missing lower bound necessary to determine the influence of parameter $k$ on the runtime.","To this aim, we derive an exact description of the expected runtime, which also significantly improves the upper bound given by C. Doerr and Krejca.","We also describe asymptotic estimates of the expected runtime."],"url":"http://arxiv.org/abs/2403.08153v1"}
{"created":"2024-03-13 00:27:19","title":"Measuring the Energy Consumption and Efficiency of Deep Neural Networks: An Empirical Analysis and Design Recommendations","abstract":"Addressing the so-called ``Red-AI'' trend of rising energy consumption by large-scale neural networks, this study investigates the actual energy consumption, as measured by node-level watt-meters, of training various fully connected neural network architectures. We introduce the BUTTER-E dataset, an augmentation to the BUTTER Empirical Deep Learning dataset, containing energy consumption and performance data from 63,527 individual experimental runs spanning 30,582 distinct configurations: 13 datasets, 20 sizes (number of trainable parameters), 8 network ``shapes'', and 14 depths on both CPU and GPU hardware collected using node-level watt-meters. This dataset reveals the complex relationship between dataset size, network structure, and energy use, and highlights the impact of cache effects. We propose a straightforward and effective energy model that accounts for network size, computing, and memory hierarchy. Our analysis also uncovers a surprising, hardware-mediated non-linear relationship between energy efficiency and network design, challenging the assumption that reducing the number of parameters or FLOPs is the best way to achieve greater energy efficiency. Highlighting the need for cache-considerate algorithm development, we suggest a combined approach to energy efficient network, algorithm, and hardware design. This work contributes to the fields of sustainable computing and Green AI, offering practical guidance for creating more energy-efficient neural networks and promoting sustainable AI.","sentences":["Addressing the so-called ``Red-AI'' trend of rising energy consumption by large-scale neural networks, this study investigates the actual energy consumption, as measured by node-level watt-meters, of training various fully connected neural network architectures.","We introduce the BUTTER-E dataset, an augmentation to the BUTTER Empirical Deep Learning dataset, containing energy consumption and performance data from 63,527 individual experimental runs spanning 30,582 distinct configurations: 13 datasets, 20 sizes (number of trainable parameters), 8 network ``shapes'', and 14 depths on both CPU and GPU hardware collected using node-level watt-meters.","This dataset reveals the complex relationship between dataset size, network structure, and energy use, and highlights the impact of cache effects.","We propose a straightforward and effective energy model that accounts for network size, computing, and memory hierarchy.","Our analysis also uncovers a surprising, hardware-mediated non-linear relationship between energy efficiency and network design, challenging the assumption that reducing the number of parameters or FLOPs is the best way to achieve greater energy efficiency.","Highlighting the need for cache-considerate algorithm development, we suggest a combined approach to energy efficient network, algorithm, and hardware design.","This work contributes to the fields of sustainable computing and Green AI, offering practical guidance for creating more energy-efficient neural networks and promoting sustainable AI."],"url":"http://arxiv.org/abs/2403.08151v1"}
{"created":"2024-03-13 00:19:44","title":"On the Feasibility of EEG-based Motor Intention Detection for Real-Time Robot Assistive Control","abstract":"This paper explores the feasibility of employing EEG-based intention detection for real-time robot assistive control. We focus on predicting and distinguishing motor intentions of left/right arm movements by presenting: i) an offline data collection and training pipeline, used to train a classifier for left/right motion intention prediction, and ii) an online real-time prediction pipeline leveraging the trained classifier and integrated with an assistive robot. Central to our approach is a rich feature representation composed of the tangent space projection of time-windowed sample covariance matrices from EEG filtered signals and derivatives; allowing for a simple SVM classifier to achieve unprecedented accuracy and real-time performance. In pre-recorded real-time settings (160 Hz), a peak accuracy of 86.88% is achieved, surpassing prior works. In robot-in-the-loop settings, our system successfully detects intended motion solely from EEG data with 70% accuracy, triggering a robot to execute an assistive task. We provide a comprehensive evaluation of the proposed classifier.","sentences":["This paper explores the feasibility of employing EEG-based intention detection for real-time robot assistive control.","We focus on predicting and distinguishing motor intentions of left/right arm movements by presenting: i) an offline data collection and training pipeline, used to train a classifier for left/right motion intention prediction, and ii) an online real-time prediction pipeline leveraging the trained classifier and integrated with an assistive robot.","Central to our approach is a rich feature representation composed of the tangent space projection of time-windowed sample covariance matrices from EEG filtered signals and derivatives; allowing for a simple SVM classifier to achieve unprecedented accuracy and real-time performance.","In pre-recorded real-time settings (160 Hz), a peak accuracy of 86.88% is achieved, surpassing prior works.","In robot-in-the-loop settings, our system successfully detects intended motion solely from EEG data with 70% accuracy, triggering a robot to execute an assistive task.","We provide a comprehensive evaluation of the proposed classifier."],"url":"http://arxiv.org/abs/2403.08149v1"}
{"created":"2024-03-13 00:19:06","title":"Representing Molecules as Random Walks Over Interpretable Grammars","abstract":"Recent research in molecular discovery has primarily been devoted to small, drug-like molecules, leaving many similarly important applications in material design without adequate technology. These applications often rely on more complex molecular structures with fewer examples that are carefully designed using known substructures. We propose a data-efficient and interpretable model for representing and reasoning over such molecules in terms of graph grammars that explicitly describe the hierarchical design space featuring motifs to be the design basis. We present a novel representation in the form of random walks over the design space, which facilitates both molecule generation and property prediction. We demonstrate clear advantages over existing methods in terms of performance, efficiency, and synthesizability of predicted molecules, and we provide detailed insights into the method's chemical interpretability.","sentences":["Recent research in molecular discovery has primarily been devoted to small, drug-like molecules, leaving many similarly important applications in material design without adequate technology.","These applications often rely on more complex molecular structures with fewer examples that are carefully designed using known substructures.","We propose a data-efficient and interpretable model for representing and reasoning over such molecules in terms of graph grammars that explicitly describe the hierarchical design space featuring motifs to be the design basis.","We present a novel representation in the form of random walks over the design space, which facilitates both molecule generation and property prediction.","We demonstrate clear advantages over existing methods in terms of performance, efficiency, and synthesizability of predicted molecules, and we provide detailed insights into the method's chemical interpretability."],"url":"http://arxiv.org/abs/2403.08147v1"}
{"created":"2024-03-12 23:39:54","title":"Information Leakage through Physical Layer Supply Voltage Coupling Vulnerability","abstract":"Side-channel attacks exploit variations in non-functional behaviors to expose sensitive information across security boundaries. Existing methods leverage side-channels based on power consumption, electromagnetic radiation, silicon substrate coupling, and channels created by malicious implants. Power-based side-channel attacks are widely known for extracting information from data processed within a device while assuming that an attacker has physical access or the ability to modify the device. In this paper, we introduce a novel side-channel vulnerability that leaks data-dependent power variations through physical layer supply voltage coupling (PSVC). Unlike traditional power side-channel attacks, the proposed vulnerability allows an adversary to mount an attack and extract information without modifying the device. We assess the effectiveness of PSVC vulnerability through three case studies, demonstrating several end-to-end attacks on general-purpose microcontrollers with varying adversary capabilities. These case studies provide evidence for the existence of PSVC vulnerability, its applicability for on-chip as well as on-board side-channel attacks, and how it can eliminate the need for physical access to the target device, making it applicable to any off-the-shelf hardware. Our experiments also reveal that designing devices to operate at the lowest operational voltage significantly reduces the risk of PSVC side-channel vulnerability.","sentences":["Side-channel attacks exploit variations in non-functional behaviors to expose sensitive information across security boundaries.","Existing methods leverage side-channels based on power consumption, electromagnetic radiation, silicon substrate coupling, and channels created by malicious implants.","Power-based side-channel attacks are widely known for extracting information from data processed within a device while assuming that an attacker has physical access or the ability to modify the device.","In this paper, we introduce a novel side-channel vulnerability that leaks data-dependent power variations through physical layer supply voltage coupling (PSVC).","Unlike traditional power side-channel attacks, the proposed vulnerability allows an adversary to mount an attack and extract information without modifying the device.","We assess the effectiveness of PSVC vulnerability through three case studies, demonstrating several end-to-end attacks on general-purpose microcontrollers with varying adversary capabilities.","These case studies provide evidence for the existence of PSVC vulnerability, its applicability for on-chip as well as on-board side-channel attacks, and how it can eliminate the need for physical access to the target device, making it applicable to any off-the-shelf hardware.","Our experiments also reveal that designing devices to operate at the lowest operational voltage significantly reduces the risk of PSVC side-channel vulnerability."],"url":"http://arxiv.org/abs/2403.08132v1"}
{"created":"2024-03-12 23:33:49","title":"Guidelines for the Creation of Analysis Ready Data","abstract":"Globally, there is an increased need for guidelines to produce high-quality data outputs for analysis. There is no framework currently exists providing guidelines for a comprehensive approach in producing analysis ready data (ARD). Through critically reviewing and summarising current literature, this paper proposes such guidelines for the creation of ARD. The guidelines proposed in this paper inform ten steps in the generation of ARD: ethics, project documentation, data governance, data management, data storage, data discovery and collection, data cleaning, quality assurance, metadata, and data dictionary. These steps are illustrated through a substantive case study which aimed to create ARD for a digital spatial platform: the Australian Child and Youth Wellbeing Atlas (ACYWA).","sentences":["Globally, there is an increased need for guidelines to produce high-quality data outputs for analysis.","There is no framework currently exists providing guidelines for a comprehensive approach in producing analysis ready data (ARD).","Through critically reviewing and summarising current literature, this paper proposes such guidelines for the creation of ARD.","The guidelines proposed in this paper inform ten steps in the generation of ARD: ethics, project documentation, data governance, data management, data storage, data discovery and collection, data cleaning, quality assurance, metadata, and data dictionary.","These steps are illustrated through a substantive case study which aimed to create ARD for a digital spatial platform: the Australian Child and Youth Wellbeing Atlas (ACYWA)."],"url":"http://arxiv.org/abs/2403.08127v1"}
{"created":"2024-03-12 23:21:09","title":"Towards Independence Criterion in Machine Unlearning of Features and Labels","abstract":"This work delves into the complexities of machine unlearning in the face of distributional shifts, particularly focusing on the challenges posed by non-uniform feature and label removal. With the advent of regulations like the GDPR emphasizing data privacy and the right to be forgotten, machine learning models face the daunting task of unlearning sensitive information without compromising their integrity or performance. Our research introduces a novel approach that leverages influence functions and principles of distributional independence to address these challenges. By proposing a comprehensive framework for machine unlearning, we aim to ensure privacy protection while maintaining model performance and adaptability across varying distributions. Our method not only facilitates efficient data removal but also dynamically adjusts the model to preserve its generalization capabilities. Through extensive experimentation, we demonstrate the efficacy of our approach in scenarios characterized by significant distributional shifts, making substantial contributions to the field of machine unlearning. This research paves the way for developing more resilient and adaptable unlearning techniques, ensuring models remain robust and accurate in the dynamic landscape of data privacy and machine learning.","sentences":["This work delves into the complexities of machine unlearning in the face of distributional shifts, particularly focusing on the challenges posed by non-uniform feature and label removal.","With the advent of regulations like the GDPR emphasizing data privacy and the right to be forgotten, machine learning models face the daunting task of unlearning sensitive information without compromising their integrity or performance.","Our research introduces a novel approach that leverages influence functions and principles of distributional independence to address these challenges.","By proposing a comprehensive framework for machine unlearning, we aim to ensure privacy protection while maintaining model performance and adaptability across varying distributions.","Our method not only facilitates efficient data removal but also dynamically adjusts the model to preserve its generalization capabilities.","Through extensive experimentation, we demonstrate the efficacy of our approach in scenarios characterized by significant distributional shifts, making substantial contributions to the field of machine unlearning.","This research paves the way for developing more resilient and adaptable unlearning techniques, ensuring models remain robust and accurate in the dynamic landscape of data privacy and machine learning."],"url":"http://arxiv.org/abs/2403.08124v1"}
{"created":"2024-03-12 23:05:10","title":"CMax-SLAM: Event-based Rotational-Motion Bundle Adjustment and SLAM System using Contrast Maximization","abstract":"Event cameras are bio-inspired visual sensors that capture pixel-wise intensity changes and output asynchronous event streams. They show great potential over conventional cameras to handle challenging scenarios in robotics and computer vision, such as high-speed and high dynamic range. This paper considers the problem of rotational motion estimation using event cameras. Several event-based rotation estimation methods have been developed in the past decade, but their performance has not been evaluated and compared under unified criteria yet. In addition, these prior works do not consider a global refinement step. To this end, we conduct a systematic study of this problem with two objectives in mind: summarizing previous works and presenting our own solution. First, we compare prior works both theoretically and experimentally. Second, we propose the first event-based rotation-only bundle adjustment (BA) approach. We formulate it leveraging the state-of-the-art Contrast Maximization (CMax) framework, which is principled and avoids the need to convert events into frames. Third, we use the proposed BA to build CMax-SLAM, the first event-based rotation-only SLAM system comprising a front-end and a back-end. Our BA is able to run both offline (trajectory smoothing) and online (CMax-SLAM back-end). To demonstrate the performance and versatility of our method, we present comprehensive experiments on synthetic and real-world datasets, including indoor, outdoor and space scenarios. We discuss the pitfalls of real-world evaluation and propose a proxy for the reprojection error as the figure of merit to evaluate event-based rotation BA methods. We release the source code and novel data sequences to benefit the community. We hope this work leads to a better understanding and fosters further research on event-based ego-motion estimation. Project page: https://github.com/tub-rip/cmax_slam","sentences":["Event cameras are bio-inspired visual sensors that capture pixel-wise intensity changes and output asynchronous event streams.","They show great potential over conventional cameras to handle challenging scenarios in robotics and computer vision, such as high-speed and high dynamic range.","This paper considers the problem of rotational motion estimation using event cameras.","Several event-based rotation estimation methods have been developed in the past decade, but their performance has not been evaluated and compared under unified criteria yet.","In addition, these prior works do not consider a global refinement step.","To this end, we conduct a systematic study of this problem with two objectives in mind: summarizing previous works and presenting our own solution.","First, we compare prior works both theoretically and experimentally.","Second, we propose the first event-based rotation-only bundle adjustment (BA) approach.","We formulate it leveraging the state-of-the-art Contrast Maximization (CMax) framework, which is principled and avoids the need to convert events into frames.","Third, we use the proposed BA to build CMax-SLAM, the first event-based rotation-only SLAM system comprising a front-end and a back-end.","Our BA is able to run both offline (trajectory smoothing) and online (CMax-SLAM back-end).","To demonstrate the performance and versatility of our method, we present comprehensive experiments on synthetic and real-world datasets, including indoor, outdoor and space scenarios.","We discuss the pitfalls of real-world evaluation and propose a proxy for the reprojection error as the figure of merit to evaluate event-based rotation BA methods.","We release the source code and novel data sequences to benefit the community.","We hope this work leads to a better understanding and fosters further research on event-based ego-motion estimation.","Project page: https://github.com/tub-rip/cmax_slam"],"url":"http://arxiv.org/abs/2403.08119v1"}
{"created":"2024-03-12 22:53:32","title":"Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies","abstract":"Privacy policies are expected to inform data subjects about their data protection rights. They should explain the data controller's data management practices, and make facts such as retention periods or data transfers to third parties transparent. Privacy policies only fulfill their purpose, if they are correctly perceived, interpreted, understood, and trusted by the data subject. Amongst others, this requires that a privacy policy is written in a fair way, e.g., it does not use polarizing terms, does not require a certain education, or does not assume a particular social background. In this work-in-progress paper, we outline our approach to assessing fairness in privacy policies. To this end, we identify from fundamental legal sources and fairness research, how the dimensions informational fairness, representational fairness and ethics/morality are related to privacy policies. We propose options to automatically assess policies in these fairness dimensions, based on text statistics, linguistic methods and artificial intelligence. Finally, we conduct initial experiments with German privacy policies to provide evidence that our approach is applicable. Our experiments indicate that there are indeed issues in all three dimensions of fairness. For example, our approach finds out if a policy discriminates against individuals with impaired reading skills or certain demographics, and identifies questionable ethics. This is important, as future privacy policies may be used in a corpus for legal artificial intelligence models.","sentences":["Privacy policies are expected to inform data subjects about their data protection rights.","They should explain the data controller's data management practices, and make facts such as retention periods or data transfers to third parties transparent.","Privacy policies only fulfill their purpose, if they are correctly perceived, interpreted, understood, and trusted by the data subject.","Amongst others, this requires that a privacy policy is written in a fair way, e.g., it does not use polarizing terms, does not require a certain education, or does not assume a particular social background.","In this work-in-progress paper, we outline our approach to assessing fairness in privacy policies.","To this end, we identify from fundamental legal sources and fairness research, how the dimensions informational fairness, representational fairness and ethics/morality are related to privacy policies.","We propose options to automatically assess policies in these fairness dimensions, based on text statistics, linguistic methods and artificial intelligence.","Finally, we conduct initial experiments with German privacy policies to provide evidence that our approach is applicable.","Our experiments indicate that there are indeed issues in all three dimensions of fairness.","For example, our approach finds out if a policy discriminates against individuals with impaired reading skills or certain demographics, and identifies questionable ethics.","This is important, as future privacy policies may be used in a corpus for legal artificial intelligence models."],"url":"http://arxiv.org/abs/2403.08115v1"}
{"created":"2024-03-12 22:48:21","title":"Assessing the Influence of Toxic and Gender Discriminatory Communication on Perceptible Diversity in OSS Projects","abstract":"The presence of toxic and gender-identity derogatory language in open-source software (OSS) communities has recently become a focal point for researchers. Such comments not only lead to frustration and disengagement among developers but may also influence their leave from the OSS projects. Despite ample evidence suggesting that diverse teams enhance productivity, the existence of toxic or gender identity discriminatory communications poses a significant threat to the participation of individuals from marginalized groups and, as such, may act as a barrier to fostering diversity and inclusion in OSS projects. However, there is a notable lack of research dedicated to exploring the association between gender-based toxic and derogatory language with a perceptible diversity of open-source software teams. Consequently, this study aims to investigate how such content influences the gender, ethnicity, and tenure diversity of open-source software development teams. To achieve this, we extract data from active GitHub projects, assess various project characteristics, and identify instances of toxic and gender-discriminatory language within issue/pull request comments. Using these attributes, we construct a regression model to explore how they associate with the perceptible diversity of those projects.","sentences":["The presence of toxic and gender-identity derogatory language in open-source software (OSS) communities has recently become a focal point for researchers.","Such comments not only lead to frustration and disengagement among developers but may also influence their leave from the OSS projects.","Despite ample evidence suggesting that diverse teams enhance productivity, the existence of toxic or gender identity discriminatory communications poses a significant threat to the participation of individuals from marginalized groups and, as such, may act as a barrier to fostering diversity and inclusion in OSS projects.","However, there is a notable lack of research dedicated to exploring the association between gender-based toxic and derogatory language with a perceptible diversity of open-source software teams.","Consequently, this study aims to investigate how such content influences the gender, ethnicity, and tenure diversity of open-source software development teams.","To achieve this, we extract data from active GitHub projects, assess various project characteristics, and identify instances of toxic and gender-discriminatory language within issue/pull request comments.","Using these attributes, we construct a regression model to explore how they associate with the perceptible diversity of those projects."],"url":"http://arxiv.org/abs/2403.08113v1"}
{"created":"2024-03-12 22:33:08","title":"VANP: Learning Where to See for Navigation with Self-Supervised Vision-Action Pre-Training","abstract":"Humans excel at efficiently navigating through crowds without collision by focusing on specific visual regions relevant to navigation. However, most robotic visual navigation methods rely on deep learning models pre-trained on vision tasks, which prioritize salient objects -- not necessarily relevant to navigation and potentially misleading. Alternative approaches train specialized navigation models from scratch, requiring significant computation. On the other hand, self-supervised learning has revolutionized computer vision and natural language processing, but its application to robotic navigation remains underexplored due to the difficulty of defining effective self-supervision signals. Motivated by these observations, in this work, we propose a Self-Supervised Vision-Action Model for Visual Navigation Pre-Training (VANP). Instead of detecting salient objects that are beneficial for tasks such as classification or detection, VANP learns to focus only on specific visual regions that are relevant to the navigation task. To achieve this, VANP uses a history of visual observations, future actions, and a goal image for self-supervision, and embeds them using two small Transformer Encoders. Then, VANP maximizes the information between the embeddings by using a mutual information maximization objective function. We demonstrate that most VANP-extracted features match with human navigation intuition. VANP achieves comparable performance as models learned end-to-end with half the training time and models trained on a large-scale, fully supervised dataset, i.e., ImageNet, with only 0.08% data.","sentences":["Humans excel at efficiently navigating through crowds without collision by focusing on specific visual regions relevant to navigation.","However, most robotic visual navigation methods rely on deep learning models pre-trained on vision tasks, which prioritize salient objects -- not necessarily relevant to navigation and potentially misleading.","Alternative approaches train specialized navigation models from scratch, requiring significant computation.","On the other hand, self-supervised learning has revolutionized computer vision and natural language processing, but its application to robotic navigation remains underexplored due to the difficulty of defining effective self-supervision signals.","Motivated by these observations, in this work, we propose a Self-Supervised Vision-Action Model for Visual Navigation Pre-Training (VANP).","Instead of detecting salient objects that are beneficial for tasks such as classification or detection, VANP learns to focus only on specific visual regions that are relevant to the navigation task.","To achieve this, VANP uses a history of visual observations, future actions, and a goal image for self-supervision, and embeds them using two small Transformer Encoders.","Then, VANP maximizes the information between the embeddings by using a mutual information maximization objective function.","We demonstrate that most VANP-extracted features match with human navigation intuition.","VANP achieves comparable performance as models learned end-to-end with half the training time and models trained on a large-scale, fully supervised dataset, i.e., ImageNet, with only 0.08% data."],"url":"http://arxiv.org/abs/2403.08109v1"}
{"created":"2024-03-12 22:33:02","title":"TaskCLIP: Extend Large Vision-Language Model for Task Oriented Object Detection","abstract":"Task-oriented object detection aims to find objects suitable for accomplishing specific tasks. As a challenging task, it requires simultaneous visual data processing and reasoning under ambiguous semantics. Recent solutions are mainly all-in-one models. However, the object detection backbones are pre-trained without text supervision. Thus, to incorporate task requirements, their intricate models undergo extensive learning on a highly imbalanced and scarce dataset, resulting in capped performance, laborious training, and poor generalizability. In contrast, we propose TaskCLIP, a more natural two-stage design composed of general object detection and task-guided object selection. Particularly for the latter, we resort to the recently successful large Vision-Language Models (VLMs) as our backbone, which provides rich semantic knowledge and a uniform embedding space for images and texts. Nevertheless, the naive application of VLMs leads to sub-optimal quality, due to the misalignment between embeddings of object images and their visual attributes, which are mainly adjective phrases. To this end, we design a transformer-based aligner after the pre-trained VLMs to re-calibrate both embeddings. Finally, we employ a trainable score function to post-process the VLM matching results for object selection. Experimental results demonstrate that our TaskCLIP outperforms the state-of-the-art DETR-based model TOIST by 3.5% and only requires a single NVIDIA RTX 4090 for both training and inference.","sentences":["Task-oriented object detection aims to find objects suitable for accomplishing specific tasks.","As a challenging task, it requires simultaneous visual data processing and reasoning under ambiguous semantics.","Recent solutions are mainly all-in-one models.","However, the object detection backbones are pre-trained without text supervision.","Thus, to incorporate task requirements, their intricate models undergo extensive learning on a highly imbalanced and scarce dataset, resulting in capped performance, laborious training, and poor generalizability.","In contrast, we propose TaskCLIP, a more natural two-stage design composed of general object detection and task-guided object selection.","Particularly for the latter, we resort to the recently successful large Vision-Language Models (VLMs) as our backbone, which provides rich semantic knowledge and a uniform embedding space for images and texts.","Nevertheless, the naive application of VLMs leads to sub-optimal quality, due to the misalignment between embeddings of object images and their visual attributes, which are mainly adjective phrases.","To this end, we design a transformer-based aligner after the pre-trained VLMs to re-calibrate both embeddings.","Finally, we employ a trainable score function to post-process the VLM matching results for object selection.","Experimental results demonstrate that our TaskCLIP outperforms the state-of-the-art DETR-based model TOIST by 3.5% and only requires a single NVIDIA RTX 4090 for both training and inference."],"url":"http://arxiv.org/abs/2403.08108v1"}
{"created":"2024-03-12 22:26:45","title":"V-PRISM: Probabilistic Mapping of Unknown Tabletop Scenes","abstract":"The ability to construct concise scene representations from sensor input is central to the field of robotics. This paper addresses the problem of robustly creating a 3D representation of a tabletop scene from a segmented RGB-D image. These representations are then critical for a range of downstream manipulation tasks. Many previous attempts to tackle this problem do not capture accurate uncertainty, which is required to subsequently produce safe motion plans. In this paper, we cast the representation of 3D tabletop scenes as a multi-class classification problem. To tackle this, we introduce \\ourmethod{}, a framework and method for robustly creating probabilistic 3D segmentation maps of tabletop scenes. Our maps contain both occupancy estimates, segmentation information, and principled uncertainty measures. We evaluate the robustness of our method in (1) procedurally generated scenes using open-source object datasets, and (2) real-world tabletop data collected from a depth camera. Our experiments show that our approach outperforms alternative continuous reconstruction approaches that do not explicitly reason about objects in a multi-class formulation.","sentences":["The ability to construct concise scene representations from sensor input is central to the field of robotics.","This paper addresses the problem of robustly creating a 3D representation of a tabletop scene from a segmented RGB-D image.","These representations are then critical for a range of downstream manipulation tasks.","Many previous attempts to tackle this problem do not capture accurate uncertainty, which is required to subsequently produce safe motion plans.","In this paper, we cast the representation of 3D tabletop scenes as a multi-class classification problem.","To tackle this, we introduce \\ourmethod{}, a framework and method for robustly creating probabilistic 3D segmentation maps of tabletop scenes.","Our maps contain both occupancy estimates, segmentation information, and principled uncertainty measures.","We evaluate the robustness of our method in (1) procedurally generated scenes using open-source object datasets, and (2) real-world tabletop data collected from a depth camera.","Our experiments show that our approach outperforms alternative continuous reconstruction approaches that do not explicitly reason about objects in a multi-class formulation."],"url":"http://arxiv.org/abs/2403.08106v1"}
{"created":"2024-03-12 22:24:05","title":"Highway Preferential Attachment Models for Geographic Routing","abstract":"In the 1960s, the world-renowned social psychologist Stanley Milgram conducted experiments that showed that not only do there exist ``short chains'' of acquaintances between any two arbitrary people, but that these arbitrary strangers are able to find these short chains. This phenomenon, known as the \\emph{small-world phenomenon}, is explained in part by any model that has a low diameter, such as the Barab\\'asi and Albert's \\emph{preferential attachment} model, but these models do not display the same efficient routing that Milgram's experiments showed. In the year 2000, Kleinberg proposed a model with an efficient $\\mathcal{O}(\\log^2{n})$ greedy routing algorithm. In 2004, Martel and Nguyen showed that Kleinberg's analysis was tight, while also showing that Kleinberg's model had an expected diameter of only $\\Theta(\\log{n})$ -- a much smaller value than the greedy routing algorithm's path lengths. In 2022, Goodrich and Ozel proposed the \\emph{neighborhood preferential attachment} model (NPA), combining elements from Barab\\'asi and Albert's model with Kleinberg's model, and experimentally showed that the resulting model outperformed Kleinberg's greedy routing performance on U.S. road networks. While they displayed impressive empirical results, they did not provide any theoretical analysis of their model. In this paper, we first provide a theoretical analysis of a generalization of Kleinberg's original model and show that it can achieve expected $\\mathcal{O}(\\log{n})$ routing, a much better result than Kleinberg's model. We then propose a new model, \\emph{windowed NPA}, that is similar to the neighborhood preferential attachment model but has provable theoretical guarantees w.h.p. We show that this model is able to achieve $\\mathcal{O}(\\log^{1 + \\epsilon}{n})$ greedy routing for any $\\epsilon > 0$.","sentences":["In the 1960s, the world-renowned social psychologist Stanley Milgram conducted experiments that showed that not only do there exist ``short chains'' of acquaintances between any two arbitrary people, but that these arbitrary strangers are able to find these short chains.","This phenomenon, known as the \\emph{small-world phenomenon}, is explained in part by any model that has a low diameter, such as the Barab\\'asi and Albert's \\emph{preferential attachment} model, but these models do not display the same efficient routing that Milgram's experiments showed.","In the year 2000, Kleinberg proposed a model with an efficient $\\mathcal{O}(\\log^2{n})$ greedy routing algorithm.","In 2004, Martel and Nguyen showed that Kleinberg's analysis was tight, while also showing that Kleinberg's model had an expected diameter of only $\\Theta(\\log{n})$ -- a much smaller value than the greedy routing algorithm's path lengths.","In 2022, Goodrich and Ozel proposed the \\emph{neighborhood preferential attachment} model (NPA), combining elements from Barab\\'asi and Albert's model with Kleinberg's model, and experimentally showed that the resulting model outperformed Kleinberg's greedy routing performance on U.S. road networks.","While they displayed impressive empirical results, they did not provide any theoretical analysis of their model.","In this paper, we first provide a theoretical analysis of a generalization of Kleinberg's original model and show that it can achieve expected $\\mathcal{O}(\\log{n})$ routing, a much better result than Kleinberg's model.","We then propose a new model, \\emph{windowed NPA}, that is similar to the neighborhood preferential attachment model but has provable theoretical guarantees w.h.p.","We show that this model is able to achieve $\\mathcal{O}(\\log^{1 + \\epsilon}{n})$ greedy routing for any $\\epsilon > 0$."],"url":"http://arxiv.org/abs/2403.08105v1"}
{"created":"2024-03-12 22:23:08","title":"Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data","abstract":"In the age of information abundance, the ability to provide users with contextually relevant and concise information is crucial. Keyword in Context (KIC) generation is a task that plays a vital role in and generation applications, such as search engines, personal assistants, and content summarization. In this paper, we present a novel approach to generating unambiguous and brief sentence-contexts for given keywords using the T5 transformer model, leveraging data obtained from the Context-Reverso API. The code is available at https://github.com/Rusamus/word2context/tree/main .","sentences":["In the age of information abundance, the ability to provide users with contextually relevant and concise information is crucial.","Keyword in Context (KIC) generation is a task that plays a vital role in and generation applications, such as search engines, personal assistants, and content summarization.","In this paper, we present a novel approach to generating unambiguous and brief sentence-contexts for given keywords using the T5 transformer model, leveraging data obtained from the Context-Reverso API.","The code is available at https://github.com/Rusamus/word2context/tree/main ."],"url":"http://arxiv.org/abs/2403.08103v1"}
{"created":"2024-03-12 22:21:48","title":"Efficient Language Model Architectures for Differentially Private Federated Learning","abstract":"Cross-device federated learning (FL) is a technique that trains a model on data distributed across typically millions of edge devices without data leaving the devices. SGD is the standard client optimizer for on device training in cross-device FL, favored for its memory and computational efficiency. However, in centralized training of neural language models, adaptive optimizers are preferred as they offer improved stability and performance. In light of this, we ask if language models can be modified such that they can be efficiently trained with SGD client optimizers and answer this affirmatively.   We propose a scale-invariant Coupled Input Forget Gate (SI CIFG) recurrent network by modifying the sigmoid and tanh activations in the recurrent cell and show that this new model converges faster and achieves better utility than the standard CIFG recurrent model in cross-device FL in large scale experiments. We further show that the proposed scale invariant modification also helps in federated learning of larger transformer models. Finally, we demonstrate the scale invariant modification is also compatible with other non-adaptive algorithms. Particularly, our results suggest an improved privacy utility trade-off in federated learning with differential privacy.","sentences":["Cross-device federated learning (FL) is a technique that trains a model on data distributed across typically millions of edge devices without data leaving the devices.","SGD is the standard client optimizer for on device training in cross-device FL, favored for its memory and computational efficiency.","However, in centralized training of neural language models, adaptive optimizers are preferred as they offer improved stability and performance.","In light of this, we ask if language models can be modified such that they can be efficiently trained with SGD client optimizers and answer this affirmatively.   ","We propose a scale-invariant Coupled Input Forget Gate (SI CIFG) recurrent network by modifying the sigmoid and tanh activations in the recurrent cell and show that this new model converges faster and achieves better utility than the standard CIFG recurrent model in cross-device FL in large scale experiments.","We further show that the proposed scale invariant modification also helps in federated learning of larger transformer models.","Finally, we demonstrate the scale invariant modification is also compatible with other non-adaptive algorithms.","Particularly, our results suggest an improved privacy utility trade-off in federated learning with differential privacy."],"url":"http://arxiv.org/abs/2403.08100v1"}
{"created":"2024-03-12 22:06:57","title":"Preserving Automotive Heritage: A Blockchain-Based Solution for Secure Documentation of Classic Cars Restoration","abstract":"Classic automobiles are an important part of the automotive industry and represent the historical and technological achievements of certain eras. However, to be considered masterpieces, they must be maintained in pristine condition or restored according to strict guidelines applied by expert services. Therefore, all data about restoration processes and other relevant information about these vehicles must be rigorously documented to ensure their verifiability and immutability. Here, we report on our ongoing research to adequately provide such capabilities to the classic car ecosystem.   Using a design science research approach, we have developed a blockchain-based solution using Hyperledger Fabric that facilitates the proper recording of classic car information, restoration procedures applied, and all related documentation by ensuring that this data is immutable and trustworthy while promoting collaboration between interested parties. This solution was validated and received positive feedback from various entities in the classic car sector. The enhanced and secured documentation is expected to contribute to the digital transformation of the classic car sector, promote authenticity and trustworthiness, and ultimately increase the market value of classic cars.","sentences":["Classic automobiles are an important part of the automotive industry and represent the historical and technological achievements of certain eras.","However, to be considered masterpieces, they must be maintained in pristine condition or restored according to strict guidelines applied by expert services.","Therefore, all data about restoration processes and other relevant information about these vehicles must be rigorously documented to ensure their verifiability and immutability.","Here, we report on our ongoing research to adequately provide such capabilities to the classic car ecosystem.   ","Using a design science research approach, we have developed a blockchain-based solution using Hyperledger Fabric that facilitates the proper recording of classic car information, restoration procedures applied, and all related documentation by ensuring that this data is immutable and trustworthy while promoting collaboration between interested parties.","This solution was validated and received positive feedback from various entities in the classic car sector.","The enhanced and secured documentation is expected to contribute to the digital transformation of the classic car sector, promote authenticity and trustworthiness, and ultimately increase the market value of classic cars."],"url":"http://arxiv.org/abs/2403.08093v1"}
{"created":"2024-03-12 21:36:41","title":"Flow-Based Visual Stream Compression for Event Cameras","abstract":"As the use of neuromorphic, event-based vision sensors expands, the need for compression of their output streams has increased. While their operational principle ensures event streams are spatially sparse, the high temporal resolution of the sensors can result in high data rates from the sensor depending on scene dynamics. For systems operating in communication-bandwidth-constrained and power-constrained environments, it is essential to compress these streams before transmitting them to a remote receiver. Therefore, we introduce a flow-based method for the real-time asynchronous compression of event streams as they are generated. This method leverages real-time optical flow estimates to predict future events without needing to transmit them, therefore, drastically reducing the amount of data transmitted. The flow-based compression introduced is evaluated using a variety of methods including spatiotemporal distance between event streams. The introduced method itself is shown to achieve an average compression ratio of 2.81 on a variety of event-camera datasets with the evaluation configuration used. That compression is achieved with a median temporal error of 0.48 ms and an average spatiotemporal event-stream distance of 3.07. When combined with LZMA compression for non-real-time applications, our method can achieve state-of-the-art average compression ratios ranging from 10.45 to 17.24. Additionally, we demonstrate that the proposed prediction algorithm is capable of performing real-time, low-latency event prediction.","sentences":["As the use of neuromorphic, event-based vision sensors expands, the need for compression of their output streams has increased.","While their operational principle ensures event streams are spatially sparse, the high temporal resolution of the sensors can result in high data rates from the sensor depending on scene dynamics.","For systems operating in communication-bandwidth-constrained and power-constrained environments, it is essential to compress these streams before transmitting them to a remote receiver.","Therefore, we introduce a flow-based method for the real-time asynchronous compression of event streams as they are generated.","This method leverages real-time optical flow estimates to predict future events without needing to transmit them, therefore, drastically reducing the amount of data transmitted.","The flow-based compression introduced is evaluated using a variety of methods including spatiotemporal distance between event streams.","The introduced method itself is shown to achieve an average compression ratio of 2.81 on a variety of event-camera datasets with the evaluation configuration used.","That compression is achieved with a median temporal error of 0.48 ms and an average spatiotemporal event-stream distance of 3.07.","When combined with LZMA compression for non-real-time applications, our method can achieve state-of-the-art average compression ratios ranging from 10.45 to 17.24.","Additionally, we demonstrate that the proposed prediction algorithm is capable of performing real-time, low-latency event prediction."],"url":"http://arxiv.org/abs/2403.08086v1"}
{"created":"2024-03-12 21:16:25","title":"Data Monetization Pathways and Complex Dynamic Game Equilibrium Analysis in the Energy Industry","abstract":"As the most critical production factor in the era of the digital economy, data will have a significant impact on social production and development. Energy enterprises possess data that is interconnected with multiple industries, characterized by diverse needs, sensitivity, and long-term nature. The path to monetizing energy enterprises' data is challenging yet crucial. This paper explores the game-theoretic aspects of the data monetization process in energy enterprises by considering the relationships between enterprises and trading platforms. We construct a class of game decision models and study their equilibrium strategies. Our analysis shows that enterprises and platforms can adjust respective benefits by regulating the wholesale price of data and the intensity of data value mining to form a benign equilibrium state. Furthermore, by integrating nonlinear dynamical theory, we discuss the dynamic characteristics present in multi-period repeated game processes. We find that decision-makers should keep the adjustment parameters and initial states within reasonable ranges in multi-period dynamic decision-making to avoid market failure. Finally, based on the theoretical and numerical analysis, we provide decision insights and recommendations for enterprise decision-making to facilitate data monetization through strategic interactions with trading platforms.","sentences":["As the most critical production factor in the era of the digital economy, data will have a significant impact on social production and development.","Energy enterprises possess data that is interconnected with multiple industries, characterized by diverse needs, sensitivity, and long-term nature.","The path to monetizing energy enterprises' data is challenging yet crucial.","This paper explores the game-theoretic aspects of the data monetization process in energy enterprises by considering the relationships between enterprises and trading platforms.","We construct a class of game decision models and study their equilibrium strategies.","Our analysis shows that enterprises and platforms can adjust respective benefits by regulating the wholesale price of data and the intensity of data value mining to form a benign equilibrium state.","Furthermore, by integrating nonlinear dynamical theory, we discuss the dynamic characteristics present in multi-period repeated game processes.","We find that decision-makers should keep the adjustment parameters and initial states within reasonable ranges in multi-period dynamic decision-making to avoid market failure.","Finally, based on the theoretical and numerical analysis, we provide decision insights and recommendations for enterprise decision-making to facilitate data monetization through strategic interactions with trading platforms."],"url":"http://arxiv.org/abs/2403.08082v1"}
{"created":"2024-03-12 21:15:38","title":"Mechanics of Next Token Prediction with Self-Attention","abstract":"Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: $\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$ $\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$ $\\textit{next-token}$ $\\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$ $\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with the last input token. $\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures.","sentences":["Transformer-based language models are trained on large datasets to predict the next token given an input sequence.","Despite this simple training objective, they have led to revolutionary advances in natural language processing.","Underlying this success is the self-attention mechanism.","In this work, we ask: $\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$ $\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$ $\\textit{next-token}$ $\\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$ $\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with the last input token.","$\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It then creates a convex combination of the high-priority tokens from which the next token can be sampled.","Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data.","We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window.","Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively.","This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023].","We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures."],"url":"http://arxiv.org/abs/2403.08081v1"}
{"created":"2024-03-12 21:12:53","title":"BayesFLo: Bayesian fault localization of complex software systems","abstract":"Software testing is essential for the reliable development of complex software systems. A key step in software testing is fault localization, which uses test data to pinpoint failure-inducing combinations for further diagnosis. Existing fault localization methods, however, are largely deterministic, and thus do not provide a principled approach for assessing probabilistic risk of potential root causes, or for integrating domain and/or structural knowledge from test engineers. To address this, we propose a novel Bayesian fault localization framework called BayesFLo, which leverages a flexible Bayesian model on potential root cause combinations. A key feature of BayesFLo is its integration of the principles of combination hierarchy and heredity, which capture the structured nature of failure-inducing combinations. A critical challenge, however, is the sheer number of potential root cause scenarios to consider, which renders the computation of posterior root cause probabilities infeasible even for small software systems. We thus develop new algorithms for efficient computation of such probabilities, leveraging recent tools from integer programming and graph representations. We then demonstrate the effectiveness of BayesFLo over state-of-the-art fault localization methods, in a suite of numerical experiments and in two motivating case studies on the JMP XGBoost interface.","sentences":["Software testing is essential for the reliable development of complex software systems.","A key step in software testing is fault localization, which uses test data to pinpoint failure-inducing combinations for further diagnosis.","Existing fault localization methods, however, are largely deterministic, and thus do not provide a principled approach for assessing probabilistic risk of potential root causes, or for integrating domain and/or structural knowledge from test engineers.","To address this, we propose a novel Bayesian fault localization framework called BayesFLo, which leverages a flexible Bayesian model on potential root cause combinations.","A key feature of BayesFLo is its integration of the principles of combination hierarchy and heredity, which capture the structured nature of failure-inducing combinations.","A critical challenge, however, is the sheer number of potential root cause scenarios to consider, which renders the computation of posterior root cause probabilities infeasible even for small software systems.","We thus develop new algorithms for efficient computation of such probabilities, leveraging recent tools from integer programming and graph representations.","We then demonstrate the effectiveness of BayesFLo over state-of-the-art fault localization methods, in a suite of numerical experiments and in two motivating case studies on the JMP XGBoost interface."],"url":"http://arxiv.org/abs/2403.08079v1"}
