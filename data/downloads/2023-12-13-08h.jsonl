{"created":"2023-12-12 18:59:21","title":"Anatomically Constrained Implicit Face Models","abstract":"Coordinate based implicit neural representations have gained rapid popularity in recent years as they have been successfully used in image, geometry and scene modeling tasks. In this work, we present a novel use case for such implicit representations in the context of learning anatomically constrained face models. Actor specific anatomically constrained face models are the state of the art in both facial performance capture and performance retargeting. Despite their practical success, these anatomical models are slow to evaluate and often require extensive data capture to be built. We propose the anatomical implicit face model; an ensemble of implicit neural networks that jointly learn to model the facial anatomy and the skin surface with high-fidelity, and can readily be used as a drop in replacement to conventional blendshape models. Given an arbitrary set of skin surface meshes of an actor and only a neutral shape with estimated skull and jaw bones, our method can recover a dense anatomical substructure which constrains every point on the facial surface. We demonstrate the usefulness of our approach in several tasks ranging from shape fitting, shape editing, and performance retargeting.","sentences":["Coordinate based implicit neural representations have gained rapid popularity in recent years as they have been successfully used in image, geometry and scene modeling tasks.","In this work, we present a novel use case for such implicit representations in the context of learning anatomically constrained face models.","Actor specific anatomically constrained face models are the state of the art in both facial performance capture and performance retargeting.","Despite their practical success, these anatomical models are slow to evaluate and often require extensive data capture to be built.","We propose the anatomical implicit face model; an ensemble of implicit neural networks that jointly learn to model the facial anatomy and the skin surface with high-fidelity, and can readily be used as a drop in replacement to conventional blendshape models.","Given an arbitrary set of skin surface meshes of an actor and only a neutral shape with estimated skull and jaw bones, our method can recover a dense anatomical substructure which constrains every point on the facial surface.","We demonstrate the usefulness of our approach in several tasks ranging from shape fitting, shape editing, and performance retargeting."],"url":"http://arxiv.org/abs/2312.07538v1"}
{"created":"2023-12-12 18:59:06","title":"Improved Frequency Estimation Algorithms with and without Predictions","abstract":"Estimating frequencies of elements appearing in a data stream is a key task in large-scale data analysis. Popular sketching approaches to this problem (e.g., CountMin and CountSketch) come with worst-case guarantees that probabilistically bound the error of the estimated frequencies for any possible input. The work of Hsu et al. (2019) introduced the idea of using machine learning to tailor sketching algorithms to the specific data distribution they are being run on. In particular, their learning-augmented frequency estimation algorithm uses a learned heavy-hitter oracle which predicts which elements will appear many times in the stream. We give a novel algorithm, which in some parameter regimes, already theoretically outperforms the learning based algorithm of Hsu et al. without the use of any predictions. Augmenting our algorithm with heavy-hitter predictions further reduces the error and improves upon the state of the art. Empirically, our algorithms achieve superior performance in all experiments compared to prior approaches.","sentences":["Estimating frequencies of elements appearing in a data stream is a key task in large-scale data analysis.","Popular sketching approaches to this problem (e.g., CountMin and CountSketch) come with worst-case guarantees that probabilistically bound the error of the estimated frequencies for any possible input.","The work of Hsu et al. (2019) introduced the idea of using machine learning to tailor sketching algorithms to the specific data distribution they are being run on.","In particular, their learning-augmented frequency estimation algorithm uses a learned heavy-hitter oracle which predicts which elements will appear many times in the stream.","We give a novel algorithm, which in some parameter regimes, already theoretically outperforms the learning based algorithm of Hsu et al.","without the use of any predictions.","Augmenting our algorithm with heavy-hitter predictions further reduces the error and improves upon the state of the art.","Empirically, our algorithms achieve superior performance in all experiments compared to prior approaches."],"url":"http://arxiv.org/abs/2312.07535v1"}
{"created":"2023-12-12 18:58:18","title":"VILA: On Pre-training for Visual Language Models","abstract":"Visual language models (VLMs) rapidly progressed with the recent success of large language models. There have been growing efforts on visual instruction tuning to extend the LLM with visual inputs, but lacks an in-depth study of the visual language pre-training process, where the model learns to perform joint modeling on both modalities. In this work, we examine the design options for VLM pre-training by augmenting LLM towards VLM through step-by-step controllable comparisons. We introduce three main findings: (1) freezing LLMs during pre-training can achieve decent zero-shot performance, but lack in-context learning capability, which requires unfreezing the LLM; (2) interleaved pre-training data is beneficial whereas image-text pairs alone are not optimal; (3) re-blending text-only instruction data to image-text data during instruction fine-tuning not only remedies the degradation of text-only tasks, but also boosts VLM task accuracy. With an enhanced pre-training recipe we build VILA, a Visual Language model family that consistently outperforms the state-of-the-art models, e.g., LLaVA-1.5, across main benchmarks without bells and whistles. Multi-modal pre-training also helps unveil appealing properties of VILA, including multi-image reasoning, enhanced in-context learning, and better world knowledge.","sentences":["Visual language models (VLMs) rapidly progressed with the recent success of large language models.","There have been growing efforts on visual instruction tuning to extend the LLM with visual inputs, but lacks an in-depth study of the visual language pre-training process, where the model learns to perform joint modeling on both modalities.","In this work, we examine the design options for VLM pre-training by augmenting LLM towards VLM through step-by-step controllable comparisons.","We introduce three main findings: (1) freezing LLMs during pre-training can achieve decent zero-shot performance, but lack in-context learning capability, which requires unfreezing the LLM; (2) interleaved pre-training data is beneficial whereas image-text pairs alone are not optimal; (3) re-blending text-only instruction data to image-text data during instruction fine-tuning not only remedies the degradation of text-only tasks, but also boosts VLM task accuracy.","With an enhanced pre-training recipe we build VILA, a Visual Language model family that consistently outperforms the state-of-the-art models, e.g., LLaVA-1.5, across main benchmarks without bells and whistles.","Multi-modal pre-training also helps unveil appealing properties of VILA, including multi-image reasoning, enhanced in-context learning, and better world knowledge."],"url":"http://arxiv.org/abs/2312.07533v1"}
{"created":"2023-12-12 18:57:46","title":"WHAM: Reconstructing World-grounded Humans with Accurate 3D Motion","abstract":"The estimation of 3D human motion from video has progressed rapidly but current methods still have several key limitations. First, most methods estimate the human in camera coordinates. Second, prior work on estimating humans in global coordinates often assumes a flat ground plane and produces foot sliding. Third, the most accurate methods rely on computationally expensive optimization pipelines, limiting their use to offline applications. Finally, existing video-based methods are surprisingly less accurate than single-frame methods. We address these limitations with WHAM (World-grounded Humans with Accurate Motion), which accurately and efficiently reconstructs 3D human motion in a global coordinate system from video. WHAM learns to lift 2D keypoint sequences to 3D using motion capture data and fuses this with video features, integrating motion context and visual information. WHAM exploits camera angular velocity estimated from a SLAM method together with human motion to estimate the body's global trajectory. We combine this with a contact-aware trajectory refinement method that lets WHAM capture human motion in diverse conditions, such as climbing stairs. WHAM outperforms all existing 3D human motion recovery methods across multiple in-the-wild benchmarks. Code will be available for research purposes at http://wham.is.tue.mpg.de/","sentences":["The estimation of 3D human motion from video has progressed rapidly but current methods still have several key limitations.","First, most methods estimate the human in camera coordinates.","Second, prior work on estimating humans in global coordinates often assumes a flat ground plane and produces foot sliding.","Third, the most accurate methods rely on computationally expensive optimization pipelines, limiting their use to offline applications.","Finally, existing video-based methods are surprisingly less accurate than single-frame methods.","We address these limitations with WHAM (World-grounded Humans with Accurate Motion), which accurately and efficiently reconstructs 3D human motion in a global coordinate system from video.","WHAM learns to lift 2D keypoint sequences to 3D using motion capture data and fuses this with video features, integrating motion context and visual information.","WHAM exploits camera angular velocity estimated from a SLAM method together with human motion to estimate the body's global trajectory.","We combine this with a contact-aware trajectory refinement method that lets WHAM capture human motion in diverse conditions, such as climbing stairs.","WHAM outperforms all existing 3D human motion recovery methods across multiple in-the-wild benchmarks.","Code will be available for research purposes at http://wham.is.tue.mpg.de/"],"url":"http://arxiv.org/abs/2312.07531v1"}
{"created":"2023-12-12 18:57:25","title":"Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance","abstract":"Weakly supervised 3D object detection aims to learn a 3D detector with lower annotation cost, e.g., 2D labels. Unlike prior work which still relies on few accurate 3D annotations, we propose a framework to study how to leverage constraints between 2D and 3D domains without requiring any 3D labels. Specifically, we employ visual data from three perspectives to establish connections between 2D and 3D domains. First, we design a feature-level constraint to align LiDAR and image features based on object-aware regions. Second, the output-level constraint is developed to enforce the overlap between 2D and projected 3D box estimations. Finally, the training-level constraint is utilized by producing accurate and consistent 3D pseudo-labels that align with the visual data. We conduct extensive experiments on the KITTI dataset to validate the effectiveness of the proposed three constraints. Without using any 3D labels, our method achieves favorable performance against state-of-the-art approaches and is competitive with the method that uses 500-frame 3D annotations. Code and models will be made publicly available at https://github.com/kuanchihhuang/VG-W3D.","sentences":["Weakly supervised 3D object detection aims to learn a 3D detector with lower annotation cost, e.g., 2D labels.","Unlike prior work which still relies on few accurate 3D annotations, we propose a framework to study how to leverage constraints between 2D and 3D domains without requiring any 3D labels.","Specifically, we employ visual data from three perspectives to establish connections between 2D and 3D domains.","First, we design a feature-level constraint to align LiDAR and image features based on object-aware regions.","Second, the output-level constraint is developed to enforce the overlap between 2D and projected 3D box estimations.","Finally, the training-level constraint is utilized by producing accurate and consistent 3D pseudo-labels that align with the visual data.","We conduct extensive experiments on the KITTI dataset to validate the effectiveness of the proposed three constraints.","Without using any 3D labels, our method achieves favorable performance against state-of-the-art approaches and is competitive with the method that uses 500-frame 3D annotations.","Code and models will be made publicly available at https://github.com/kuanchihhuang/VG-W3D."],"url":"http://arxiv.org/abs/2312.07530v1"}
{"created":"2023-12-12 18:56:14","title":"Topological Obstructions and How to Avoid Them","abstract":"Incorporating geometric inductive biases into models can aid interpretability and generalization, but encoding to a specific geometric structure can be challenging due to the imposed topological constraints. In this paper, we theoretically and empirically characterize obstructions to training encoders with geometric latent spaces. We show that local optima can arise due to singularities (e.g. self-intersection) or due to an incorrect degree or winding number. We then discuss how normalizing flows can potentially circumvent these obstructions by defining multimodal variational distributions. Inspired by this observation, we propose a new flow-based model that maps data points to multimodal distributions over geometric spaces and empirically evaluate our model on 2 domains. We observe improved stability during training and a higher chance of converging to a homeomorphic encoder.","sentences":["Incorporating geometric inductive biases into models can aid interpretability and generalization, but encoding to a specific geometric structure can be challenging due to the imposed topological constraints.","In this paper, we theoretically and empirically characterize obstructions to training encoders with geometric latent spaces.","We show that local optima can arise due to singularities (e.g. self-intersection) or due to an incorrect degree or winding number.","We then discuss how normalizing flows can potentially circumvent these obstructions by defining multimodal variational distributions.","Inspired by this observation, we propose a new flow-based model that maps data points to multimodal distributions over geometric spaces and empirically evaluate our model on 2 domains.","We observe improved stability during training and a higher chance of converging to a homeomorphic encoder."],"url":"http://arxiv.org/abs/2312.07529v1"}
{"created":"2023-12-12 18:48:25","title":"Search Optimization with Query Likelihood Boosting and Two-Level Approximate Search for Edge Devices","abstract":"We present a novel search optimization solution for approximate nearest neighbor (ANN) search on resource-constrained edge devices. Traditional ANN approaches fall short in meeting the specific demands of real-world scenarios, e.g., skewed query likelihood distribution and search on large-scale indices with a low latency and small footprint. To address these limitations, we introduce two key components: a Query Likelihood Boosted Tree (QLBT) to optimize average search latency for frequently used small datasets, and a two-level approximate search algorithm to enable efficient retrieval with large datasets on edge devices. We perform thorough evaluation on simulated and real data and demonstrate QLBT can significantly reduce latency by 15% on real data and our two-level search algorithm successfully achieve deployable accuracy and latency on a 10 million dataset for edge devices. In addition, we provide a comprehensive protocol for configuring and optimizing on-device search algorithm through extensive empirical studies.","sentences":["We present a novel search optimization solution for approximate nearest neighbor (ANN) search on resource-constrained edge devices.","Traditional ANN approaches fall short in meeting the specific demands of real-world scenarios, e.g., skewed query likelihood distribution and search on large-scale indices with a low latency and small footprint.","To address these limitations, we introduce two key components: a Query Likelihood Boosted Tree (QLBT) to optimize average search latency for frequently used small datasets, and a two-level approximate search algorithm to enable efficient retrieval with large datasets on edge devices.","We perform thorough evaluation on simulated and real data and demonstrate QLBT can significantly reduce latency by 15% on real data and our two-level search algorithm successfully achieve deployable accuracy and latency on a 10 million dataset for edge devices.","In addition, we provide a comprehensive protocol for configuring and optimizing on-device search algorithm through extensive empirical studies."],"url":"http://arxiv.org/abs/2312.07517v1"}
{"created":"2023-12-12 18:24:44","title":"NearbyPatchCL: Leveraging Nearby Patches for Self-Supervised Patch-Level Multi-Class Classification in Whole-Slide Images","abstract":"Whole-slide image (WSI) analysis plays a crucial role in cancer diagnosis and treatment. In addressing the demands of this critical task, self-supervised learning (SSL) methods have emerged as a valuable resource, leveraging their efficiency in circumventing the need for a large number of annotations, which can be both costly and time-consuming to deploy supervised methods. Nevertheless, patch-wise representation may exhibit instability in performance, primarily due to class imbalances stemming from patch selection within WSIs. In this paper, we introduce Nearby Patch Contrastive Learning (NearbyPatchCL), a novel self-supervised learning method that leverages nearby patches as positive samples and a decoupled contrastive loss for robust representation learning. Our method demonstrates a tangible enhancement in performance for downstream tasks involving patch-level multi-class classification. Additionally, we curate a new dataset derived from WSIs sourced from the Canine Cutaneous Cancer Histology, thus establishing a benchmark for the rigorous evaluation of patch-level multi-class classification methodologies. Intensive experiments show that our method significantly outperforms the supervised baseline and state-of-the-art SSL methods with top-1 classification accuracy of 87.56%. Our method also achieves comparable results while utilizing a mere 1% of labeled data, a stark contrast to the 100% labeled data requirement of other approaches. Source code: https://github.com/nvtien457/NearbyPatchCL","sentences":["Whole-slide image (WSI) analysis plays a crucial role in cancer diagnosis and treatment.","In addressing the demands of this critical task, self-supervised learning (SSL) methods have emerged as a valuable resource, leveraging their efficiency in circumventing the need for a large number of annotations, which can be both costly and time-consuming to deploy supervised methods.","Nevertheless, patch-wise representation may exhibit instability in performance, primarily due to class imbalances stemming from patch selection within WSIs.","In this paper, we introduce Nearby Patch Contrastive Learning (NearbyPatchCL), a novel self-supervised learning method that leverages nearby patches as positive samples and a decoupled contrastive loss for robust representation learning.","Our method demonstrates a tangible enhancement in performance for downstream tasks involving patch-level multi-class classification.","Additionally, we curate a new dataset derived from WSIs sourced from the Canine Cutaneous Cancer Histology, thus establishing a benchmark for the rigorous evaluation of patch-level multi-class classification methodologies.","Intensive experiments show that our method significantly outperforms the supervised baseline and state-of-the-art SSL methods with top-1 classification accuracy of 87.56%.","Our method also achieves comparable results while utilizing a mere 1% of labeled data, a stark contrast to the 100% labeled data requirement of other approaches.","Source code: https://github.com/nvtien457/NearbyPatchCL"],"url":"http://arxiv.org/abs/2312.07489v1"}
{"created":"2023-12-12 18:24:15","title":"LMDrive: Closed-Loop End-to-End Driving with Large Language Models","abstract":"Despite significant recent progress in the field of autonomous driving, modern methods still struggle and can incur serious accidents when encountering long-tail unforeseen events and challenging urban scenarios. On the one hand, large language models (LLM) have shown impressive reasoning capabilities that approach \"Artificial General Intelligence\". On the other hand, previous autonomous driving methods tend to rely on limited-format inputs (e.g. sensor data and navigation waypoints), restricting the vehicle's ability to understand language information and interact with humans. To this end, this paper introduces LMDrive, a novel language-guided, end-to-end, closed-loop autonomous driving framework. LMDrive uniquely processes and integrates multi-modal sensor data with natural language instructions, enabling interaction with humans and navigation software in realistic instructional settings. To facilitate further research in language-based closed-loop autonomous driving, we also publicly release the corresponding dataset which includes approximately 64K instruction-following data clips, and the LangAuto benchmark that tests the system's ability to handle complex instructions and challenging driving scenarios. Extensive closed-loop experiments are conducted to demonstrate LMDrive's effectiveness. To the best of our knowledge, we're the very first work to leverage LLMs for closed-loop end-to-end autonomous driving. Codes can be found at https://github.com/opendilab/LMDrive","sentences":["Despite significant recent progress in the field of autonomous driving, modern methods still struggle and can incur serious accidents when encountering long-tail unforeseen events and challenging urban scenarios.","On the one hand, large language models (LLM) have shown impressive reasoning capabilities that approach \"Artificial General Intelligence\".","On the other hand, previous autonomous driving methods tend to rely on limited-format inputs (e.g. sensor data and navigation waypoints), restricting the vehicle's ability to understand language information and interact with humans.","To this end, this paper introduces LMDrive, a novel language-guided, end-to-end, closed-loop autonomous driving framework.","LMDrive uniquely processes and integrates multi-modal sensor data with natural language instructions, enabling interaction with humans and navigation software in realistic instructional settings.","To facilitate further research in language-based closed-loop autonomous driving, we also publicly release the corresponding dataset which includes approximately 64K instruction-following data clips, and the LangAuto benchmark that tests the system's ability to handle complex instructions and challenging driving scenarios.","Extensive closed-loop experiments are conducted to demonstrate LMDrive's effectiveness.","To the best of our knowledge, we're the very first work to leverage LLMs for closed-loop end-to-end autonomous driving.","Codes can be found at https://github.com/opendilab/LMDrive"],"url":"http://arxiv.org/abs/2312.07488v1"}
{"created":"2023-12-12 18:11:15","title":"Classification of retail products: From probabilistic ranking to neural networks","abstract":"Food retailing is now on an accelerated path to a success penetration into the digital market by new ways of value creation at all stages of the consumer decision process. One of the most important imperatives in this path is the availability of quality data to feed all the process in digital transformation. But the quality of data is not so obvious if we consider the variety of products and suppliers in the grocery market. Within this context of digital transformation of grocery industry, \\textit{Midiadia} is Spanish data provider company that works on converting data from the retailers' products into knowledge with attributes and insights from the product labels, that is, maintaining quality data in a dynamic market with a high dispersion of products. Currently, they manually categorize products (groceries) according to the information extracted directly (text processing) from the product labelling and packaging. This paper introduces a solution to automatically categorize the constantly changing product catalogue into a 3-level food taxonomy. Our proposal studies three different approaches: a score-based ranking method, traditional machine learning algorithms, and deep neural networks. Thus, we provide four different classifiers that support a more efficient and less error-prone maintenance of groceries catalogues, the main asset of the company. Finally, we have compared the performance of these three alternatives, concluding that traditional machine learning algorithms perform better, but closely followed by the score-based approach.","sentences":["Food retailing is now on an accelerated path to a success penetration into the digital market by new ways of value creation at all stages of the consumer decision process.","One of the most important imperatives in this path is the availability of quality data to feed all the process in digital transformation.","But the quality of data is not so obvious if we consider the variety of products and suppliers in the grocery market.","Within this context of digital transformation of grocery industry, \\textit{Midiadia} is Spanish data provider company that works on converting data from the retailers' products into knowledge with attributes and insights from the product labels, that is, maintaining quality data in a dynamic market with a high dispersion of products.","Currently, they manually categorize products (groceries) according to the information extracted directly (text processing) from the product labelling and packaging.","This paper introduces a solution to automatically categorize the constantly changing product catalogue into a 3-level food taxonomy.","Our proposal studies three different approaches: a score-based ranking method, traditional machine learning algorithms, and deep neural networks.","Thus, we provide four different classifiers that support a more efficient and less error-prone maintenance of groceries catalogues, the main asset of the company.","Finally, we have compared the performance of these three alternatives, concluding that traditional machine learning algorithms perform better, but closely followed by the score-based approach."],"url":"http://arxiv.org/abs/2312.07482v1"}
{"created":"2023-12-12 17:47:13","title":"Efficient Object Detection in Autonomous Driving using Spiking Neural Networks: Performance, Energy Consumption Analysis, and Insights into Open-set Object Discovery","abstract":"Besides performance, efficiency is a key design driver of technologies supporting vehicular perception. Indeed, a well-balanced trade-off between performance and energy consumption is crucial for the sustainability of autonomous vehicles. In this context, the diversity of real-world contexts in which autonomous vehicles can operate motivates the need for empowering perception models with the capability to detect, characterize and identify newly appearing objects by themselves. In this manuscript we elaborate on this threefold conundrum (performance, efficiency and open-world learning) for object detection modeling tasks over image data collected from vehicular scenarios. Specifically, we show that well-performing and efficient models can be realized by virtue of Spiking Neural Networks (SNNs), reaching competitive levels of detection performance when compared to their non-spiking counterparts at dramatic energy consumption savings (up to 85%) and a slightly improved robustness against image noise. Our experiments herein offered also expose qualitatively the complexity of detecting new objects based on the preliminary results of a simple approach to discriminate potential object proposals in the captured image.","sentences":["Besides performance, efficiency is a key design driver of technologies supporting vehicular perception.","Indeed, a well-balanced trade-off between performance and energy consumption is crucial for the sustainability of autonomous vehicles.","In this context, the diversity of real-world contexts in which autonomous vehicles can operate motivates the need for empowering perception models with the capability to detect, characterize and identify newly appearing objects by themselves.","In this manuscript we elaborate on this threefold conundrum (performance, efficiency and open-world learning) for object detection modeling tasks over image data collected from vehicular scenarios.","Specifically, we show that well-performing and efficient models can be realized by virtue of Spiking Neural Networks (SNNs), reaching competitive levels of detection performance when compared to their non-spiking counterparts at dramatic energy consumption savings (up to 85%) and a slightly improved robustness against image noise.","Our experiments herein offered also expose qualitatively the complexity of detecting new objects based on the preliminary results of a simple approach to discriminate potential object proposals in the captured image."],"url":"http://arxiv.org/abs/2312.07466v1"}
{"created":"2023-12-12 17:34:42","title":"Dynamics Harmonic Analysis of Robotic Systems: Application in Data-Driven Koopman Modelling","abstract":"We introduce the use of harmonic analysis to decompose the state space of symmetric robotic systems into orthogonal isotypic subspaces. These are lower-dimensional spaces that capture distinct, symmetric, and synergistic motions. For linear dynamics, we characterize how this decomposition leads to a subdivision of the dynamics into independent linear systems on each subspace, a property we term dynamics harmonic analysis (DHA). To exploit this property, we use Koopman operator theory to propose an equivariant deep-learning architecture that leverages the properties of DHA to learn a global linear model of system dynamics. Our architecture, validated on synthetic systems and the dynamics of locomotion of a quadrupedal robot, demonstrates enhanced generalization, sample efficiency, and interpretability, with less trainable parameters and computational costs.","sentences":["We introduce the use of harmonic analysis to decompose the state space of symmetric robotic systems into orthogonal isotypic subspaces.","These are lower-dimensional spaces that capture distinct, symmetric, and synergistic motions.","For linear dynamics, we characterize how this decomposition leads to a subdivision of the dynamics into independent linear systems on each subspace, a property we term dynamics harmonic analysis (DHA).","To exploit this property, we use Koopman operator theory to propose an equivariant deep-learning architecture that leverages the properties of DHA to learn a global linear model of system dynamics.","Our architecture, validated on synthetic systems and the dynamics of locomotion of a quadrupedal robot, demonstrates enhanced generalization, sample efficiency, and interpretability, with less trainable parameters and computational costs."],"url":"http://arxiv.org/abs/2312.07457v1"}
{"created":"2023-12-12 17:00:13","title":"Multi-Modal Conformal Prediction Regions by Optimizing Convex Shape Templates","abstract":"Conformal prediction is a statistical tool for producing prediction regions for machine learning models that are valid with high probability. A key component of conformal prediction algorithms is a non-conformity score function that quantifies how different a model's prediction is from the unknown ground truth value. Essentially, these functions determine the shape and the size of the conformal prediction regions. However, little work has gone into finding non-conformity score functions that produce prediction regions that are multi-modal and practical, i.e., that can efficiently be used in engineering applications. We propose a method that optimizes parameterized shape template functions over calibration data, which results in non-conformity score functions that produce prediction regions with minimum volume. Our approach results in prediction regions that are multi-modal, so they can properly capture residuals of distributions that have multiple modes, and practical, so each region is convex and can be easily incorporated into downstream tasks, such as a motion planner using conformal prediction regions. Our method applies to general supervised learning tasks, while we illustrate its use in time-series prediction. We provide a toolbox and present illustrative case studies of F16 fighter jets and autonomous vehicles, showing an up to $68\\%$ reduction in prediction region area.","sentences":["Conformal prediction is a statistical tool for producing prediction regions for machine learning models that are valid with high probability.","A key component of conformal prediction algorithms is a non-conformity score function that quantifies how different a model's prediction is from the unknown ground truth value.","Essentially, these functions determine the shape and the size of the conformal prediction regions.","However, little work has gone into finding non-conformity score functions that produce prediction regions that are multi-modal and practical, i.e., that can efficiently be used in engineering applications.","We propose a method that optimizes parameterized shape template functions over calibration data, which results in non-conformity score functions that produce prediction regions with minimum volume.","Our approach results in prediction regions that are multi-modal, so they can properly capture residuals of distributions that have multiple modes, and practical, so each region is convex and can be easily incorporated into downstream tasks, such as a motion planner using conformal prediction regions.","Our method applies to general supervised learning tasks, while we illustrate its use in time-series prediction.","We provide a toolbox and present illustrative case studies of F16 fighter jets and autonomous vehicles, showing an up to $68\\%$ reduction in prediction region area."],"url":"http://arxiv.org/abs/2312.07434v1"}
{"created":"2023-12-12 16:57:01","title":"Algorithms and Complexity for Congested Assignments","abstract":"We study the congested assignment problem as introduced by Bogomolnaia and Moulin (2023). We show that deciding whether a competitive assignment exists can be done in polynomial time, while deciding whether an envy-free assignment exists is NP-complete.","sentences":["We study the congested assignment problem as introduced by Bogomolnaia and Moulin (2023).","We show that deciding whether a competitive assignment exists can be done in polynomial time, while deciding whether an envy-free assignment exists is NP-complete."],"url":"http://arxiv.org/abs/2312.07431v1"}
{"created":"2023-12-12 16:53:18","title":"Ensemble Federated Learning: an approach for collaborative pneumonia diagnosis","abstract":"Federated learning is a very convenient approach for scenarios where (i) the exchange of data implies privacy concerns and/or (ii) a quick reaction is needed. In smart healthcare systems, both aspects are usually required. In this paper, we work on the first scenario, where preserving privacy is key and, consequently, building a unique and massive medical image data set by fusing different data sets from different medical institutions or research centers (computation nodes) is not an option. We propose an ensemble federated learning (EFL) approach that is based on the following characteristics: First, each computation node works with a different data set (but of the same type). They work locally and apply an ensemble approach combining eight well-known CNN models (densenet169, mobilenetv2, xception, inceptionv3, vgg16, resnet50, densenet121, and resnet152v2) on Chest X-ray images. Second, the best two local models are used to create a local ensemble model that is shared with a central node. Third, the ensemble models are aggregated to obtain a global model, which is shared with the computation nodes to continue with a new iteration. This procedure continues until there are no changes in the best local models. We have performed different experiments to compare our approach with centralized ones (with or without an ensemble approach)\\color{black}. The results conclude that our proposal outperforms these ones in Chest X-ray images (achieving an accuracy of 96.63\\%) and offers very competitive results compared to other proposals in the literature.","sentences":["Federated learning is a very convenient approach for scenarios where (i) the exchange of data implies privacy concerns and/or (ii) a quick reaction is needed.","In smart healthcare systems, both aspects are usually required.","In this paper, we work on the first scenario, where preserving privacy is key and, consequently, building a unique and massive medical image data set by fusing different data sets from different medical institutions or research centers (computation nodes) is not an option.","We propose an ensemble federated learning (EFL) approach that is based on the following characteristics:","First, each computation node works with a different data set (but of the same type).","They work locally and apply an ensemble approach combining eight well-known CNN models (densenet169, mobilenetv2, xception, inceptionv3, vgg16, resnet50, densenet121, and resnet152v2) on Chest X-ray images.","Second, the best two local models are used to create a local ensemble model that is shared with a central node.","Third, the ensemble models are aggregated to obtain a global model, which is shared with the computation nodes to continue with a new iteration.","This procedure continues until there are no changes in the best local models.","We have performed different experiments to compare our approach with centralized ones (with or without an ensemble approach)\\color{black}.","The results conclude that our proposal outperforms these ones in Chest X-ray images (achieving an accuracy of 96.63\\%) and offers very competitive results compared to other proposals in the literature."],"url":"http://arxiv.org/abs/2312.07428v1"}
{"created":"2023-12-12 16:48:53","title":"Deep Internal Learning: Deep Learning from a Single Input","abstract":"Deep learning in general focuses on training a neural network from large labeled datasets. Yet, in many cases there is value in training a network just from the input at hand. This may involve training a network from scratch using a single input or adapting an already trained network to a provided input example at inference time. This survey paper aims at covering deep internal-learning techniques that have been proposed in the past few years for these two important directions. While our main focus will be on image processing problems, most of the approaches that we survey are derived for general signals (vectors with recurring patterns that can be distinguished from noise) and are therefore applicable to other modalities. We believe that the topic of internal-learning is very important in many signal and image processing problems where training data is scarce and diversity is large on the one hand, and on the other, there is a lot of structure in the data that can be exploited.","sentences":["Deep learning in general focuses on training a neural network from large labeled datasets.","Yet, in many cases there is value in training a network just from the input at hand.","This may involve training a network from scratch using a single input or adapting an already trained network to a provided input example at inference time.","This survey paper aims at covering deep internal-learning techniques that have been proposed in the past few years for these two important directions.","While our main focus will be on image processing problems, most of the approaches that we survey are derived for general signals (vectors with recurring patterns that can be distinguished from noise) and are therefore applicable to other modalities.","We believe that the topic of internal-learning is very important in many signal and image processing problems where training data is scarce and diversity is large on the one hand, and on the other, there is a lot of structure in the data that can be exploited."],"url":"http://arxiv.org/abs/2312.07425v1"}
{"created":"2023-12-12 16:48:07","title":"How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation","abstract":"In machine learning, generalization against distribution shifts -- where deployment conditions diverge from the training scenarios -- is crucial, particularly in fields like climate modeling, biomedicine, and autonomous driving. The emergence of foundation models, distinguished by their extensive pretraining and task versatility, has led to an increased interest in their adaptability to distribution shifts. GPT-4V(ision) acts as the most advanced publicly accessible multimodal foundation model, with extensive applications across various domains, including anomaly detection, video understanding, image generation, and medical diagnosis. However, its robustness against data distributions remains largely underexplored. Addressing this gap, this study rigorously evaluates GPT-4V's adaptability and generalization capabilities in dynamic environments, benchmarking against prominent models like CLIP and LLaVA. We delve into GPT-4V's zero-shot generalization across 13 diverse datasets spanning natural, medical, and molecular domains. We further investigate its adaptability to controlled data perturbations and examine the efficacy of in-context learning as a tool to enhance its adaptation. Our findings delineate GPT-4V's capability boundaries in distribution shifts, shedding light on its strengths and limitations across various scenarios. Importantly, this investigation contributes to our understanding of how AI foundation models generalize to distribution shifts, offering pivotal insights into their adaptability and robustness. Code is publicly available at https://github.com/jameszhou-gl/gpt-4v-distribution-shift.","sentences":["In machine learning, generalization against distribution shifts -- where deployment conditions diverge from the training scenarios -- is crucial, particularly in fields like climate modeling, biomedicine, and autonomous driving.","The emergence of foundation models, distinguished by their extensive pretraining and task versatility, has led to an increased interest in their adaptability to distribution shifts.","GPT-4V(ision) acts as the most advanced publicly accessible multimodal foundation model, with extensive applications across various domains, including anomaly detection, video understanding, image generation, and medical diagnosis.","However, its robustness against data distributions remains largely underexplored.","Addressing this gap, this study rigorously evaluates GPT-4V's adaptability and generalization capabilities in dynamic environments, benchmarking against prominent models like CLIP and LLaVA.","We delve into GPT-4V's zero-shot generalization across 13 diverse datasets spanning natural, medical, and molecular domains.","We further investigate its adaptability to controlled data perturbations and examine the efficacy of in-context learning as a tool to enhance its adaptation.","Our findings delineate GPT-4V's capability boundaries in distribution shifts, shedding light on its strengths and limitations across various scenarios.","Importantly, this investigation contributes to our understanding of how AI foundation models generalize to distribution shifts, offering pivotal insights into their adaptability and robustness.","Code is publicly available at https://github.com/jameszhou-gl/gpt-4v-distribution-shift."],"url":"http://arxiv.org/abs/2312.07424v1"}
{"created":"2023-12-12 16:44:47","title":"FairSISA: Ensemble Post-Processing to Improve Fairness of Unlearning in LLMs","abstract":"Training large language models (LLMs) is a costly endeavour in terms of time and computational resources. The large amount of training data used during the unsupervised pre-training phase makes it difficult to verify all data and, unfortunately, undesirable data may be ingested during training. Re-training from scratch is impractical and has led to the creation of the 'unlearning' discipline where models are modified to \"unlearn\" undesirable information without retraining. However, any modification can alter the behaviour of LLMs, especially on key dimensions such as fairness. This is the first work that examines this interplay between unlearning and fairness for LLMs. In particular, we focus on a popular unlearning framework known as SISA [Bourtoule et al., 2021], which creates an ensemble of models trained on disjoint shards. We evaluate the performance-fairness trade-off for SISA, and empirically demsontrate that SISA can indeed reduce fairness in LLMs. To remedy this, we propose post-processing bias mitigation techniques for ensemble models produced by SISA. We adapt the post-processing fairness improvement technique from [Hardt et al., 2016] to design three methods that can handle model ensembles, and prove that one of the methods is an optimal fair predictor for ensemble of models. Through experimental results, we demonstrate the efficacy of our post-processing framework called 'FairSISA'.","sentences":["Training large language models (LLMs) is a costly endeavour in terms of time and computational resources.","The large amount of training data used during the unsupervised pre-training phase makes it difficult to verify all data and, unfortunately, undesirable data may be ingested during training.","Re-training from scratch is impractical and has led to the creation of the 'unlearning' discipline where models are modified to \"unlearn\" undesirable information without retraining.","However, any modification can alter the behaviour of LLMs, especially on key dimensions such as fairness.","This is the first work that examines this interplay between unlearning and fairness for LLMs.","In particular, we focus on a popular unlearning framework known as SISA [Bourtoule et al., 2021], which creates an ensemble of models trained on disjoint shards.","We evaluate the performance-fairness trade-off for SISA, and empirically demsontrate that SISA can indeed reduce fairness in LLMs.","To remedy this, we propose post-processing bias mitigation techniques for ensemble models produced by SISA.","We adapt the post-processing fairness improvement technique from [Hardt et al., 2016] to design three methods that can handle model ensembles, and prove that one of the methods is an optimal fair predictor for ensemble of models.","Through experimental results, we demonstrate the efficacy of our post-processing framework called 'FairSISA'."],"url":"http://arxiv.org/abs/2312.07420v1"}
{"created":"2023-12-12 16:34:19","title":"AI capabilities can be significantly improved without expensive retraining","abstract":"State-of-the-art AI systems can be significantly improved without expensive retraining via \"post-training enhancements\"-techniques applied after initial training like fine-tuning the system to use a web browser. We review recent post-training enhancements, categorizing them into five types: tool-use, prompting methods, scaffolding, solution selection, and data generation. Different enhancements improve performance on different tasks, making it hard to compare their significance. So we translate improvements from different enhancements into a common currency, the compute-equivalent gain: how much additional training compute would be needed to improve performance by the same amount as the enhancement. Our non-experimental work shows that post-training enhancements have significant benefits: most surveyed enhancements improve benchmark performance by more than a 5x increase in training compute, some by more than 20x. Post-training enhancements are relatively cheap to develop: fine-tuning costs are typically <1% of the original training cost. Governing the development of capable post-training enhancements may be challenging because frontier models could be enhanced by a wide range of actors.","sentences":["State-of-the-art AI systems can be significantly improved without expensive retraining via \"post-training enhancements\"-techniques applied after initial training like fine-tuning the system to use a web browser.","We review recent post-training enhancements, categorizing them into five types: tool-use, prompting methods, scaffolding, solution selection, and data generation.","Different enhancements improve performance on different tasks, making it hard to compare their significance.","So we translate improvements from different enhancements into a common currency, the compute-equivalent gain: how much additional training compute would be needed to improve performance by the same amount as the enhancement.","Our non-experimental work shows that post-training enhancements have significant benefits: most surveyed enhancements improve benchmark performance by more than a 5x increase in training compute, some by more than 20x.","Post-training enhancements are relatively cheap to develop: fine-tuning costs are typically <1% of the original training cost.","Governing the development of capable post-training enhancements may be challenging because frontier models could be enhanced by a wide range of actors."],"url":"http://arxiv.org/abs/2312.07413v1"}
{"created":"2023-12-12 16:27:35","title":"Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Models","abstract":"Vision-Language Large Models (VLMs) have become primary backbone of AI, due to the impressive performance. However, their expensive computation costs, i.e., throughput and delay, impede potentials in real-world scenarios. To achieve acceleration for VLMs, most existing methods focus on the model perspective: pruning, distillation, quantification, but completely overlook the data-perspective redundancy. To fill the overlook, this paper pioneers the severity of data redundancy, and designs one plug-and-play Turbo module guided by information degree to prune inefficient tokens from visual or textual data. In pursuit of efficiency-performance trade-offs, information degree takes two key factors into consideration: mutual redundancy and semantic value. Concretely, the former evaluates the data duplication between sequential tokens; while the latter evaluates each token by its contribution to the overall semantics. As a result, tokens with high information degree carry less redundancy and stronger semantics. For VLMs' calculation, Turbo works as a user-friendly plug-in that sorts data referring to information degree, utilizing only top-level ones to save costs. Its advantages are multifaceted, e.g., being generally compatible to various VLMs across understanding and generation, simple use without retraining and trivial engineering efforts. On multiple public VLMs benchmarks, we conduct extensive experiments to reveal the gratifying acceleration of Turbo, under negligible performance drop.","sentences":["Vision-Language Large Models (VLMs) have become primary backbone of AI, due to the impressive performance.","However, their expensive computation costs, i.e., throughput and delay, impede potentials in real-world scenarios.","To achieve acceleration for VLMs, most existing methods focus on the model perspective: pruning, distillation, quantification, but completely overlook the data-perspective redundancy.","To fill the overlook, this paper pioneers the severity of data redundancy, and designs one plug-and-play Turbo module guided by information degree to prune inefficient tokens from visual or textual data.","In pursuit of efficiency-performance trade-offs, information degree takes two key factors into consideration: mutual redundancy and semantic value.","Concretely, the former evaluates the data duplication between sequential tokens; while the latter evaluates each token by its contribution to the overall semantics.","As a result, tokens with high information degree carry less redundancy and stronger semantics.","For VLMs' calculation, Turbo works as a user-friendly plug-in that sorts data referring to information degree, utilizing only top-level ones to save costs.","Its advantages are multifaceted, e.g., being generally compatible to various VLMs across understanding and generation, simple use without retraining and trivial engineering efforts.","On multiple public VLMs benchmarks, we conduct extensive experiments to reveal the gratifying acceleration of Turbo, under negligible performance drop."],"url":"http://arxiv.org/abs/2312.07408v1"}
{"created":"2023-12-12 16:17:15","title":"On Diverse Preferences for Large Language Model Alignment","abstract":"The alignment of large language models (LLMs) with human values is crucial for the development of artificial general intelligence (AGI). One promising approach to achieve this alignment is reinforcement learning from human feedback, which employs a reward model (RM) learned from human preference datasets to guide LLMs in generating text that aligns with human preferences. Through intensive experiments and analysis of reward distribution, this paper finds that preference datasets are diverse from each other, even though they are all proposed to align human preference. Hence, mixing diverse human preference datasets to increase data size for enhancing reward modeling could fail. To address the issue and capture the shared human values from diverse preferences, a new training policy called MORE is introduced, which minimizes preference bias by adaptively adjusting the preference objective across diverse preferences. Experiments with the Pythia-1.4B model and five mixed preference datasets show that MORE achieves superior reward accuracy and lower calibration error, highlighting its ability to leverage diverse human preference data.","sentences":["The alignment of large language models (LLMs) with human values is crucial for the development of artificial general intelligence (AGI).","One promising approach to achieve this alignment is reinforcement learning from human feedback, which employs a reward model (RM) learned from human preference datasets to guide LLMs in generating text that aligns with human preferences.","Through intensive experiments and analysis of reward distribution, this paper finds that preference datasets are diverse from each other, even though they are all proposed to align human preference.","Hence, mixing diverse human preference datasets to increase data size for enhancing reward modeling could fail.","To address the issue and capture the shared human values from diverse preferences, a new training policy called MORE is introduced, which minimizes preference bias by adaptively adjusting the preference objective across diverse preferences.","Experiments with the Pythia-1.4B model and five mixed preference datasets show that MORE achieves superior reward accuracy and lower calibration error, highlighting its ability to leverage diverse human preference data."],"url":"http://arxiv.org/abs/2312.07401v1"}
{"created":"2023-12-12 16:14:45","title":"Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales","abstract":"Machine reasoning has made great progress in recent years owing to large language models (LLMs). In the clinical domain, however, most NLP-driven projects mainly focus on clinical classification or reading comprehension, and under-explore clinical reasoning for disease diagnosis due to the expensive rationale annotation with clinicians. In this work, we present a ``reasoning-aware'' diagnosis framework that rationalizes the diagnostic process via prompt-based learning in a time- and labor-efficient manner, and learns to reason over the prompt-generated rationales. Specifically, we address the clinical reasoning for disease diagnosis, where the LLM generates diagnostic rationales providing its insight on presented patient data and the reasoning path towards the diagnosis, namely Clinical Chain-of-Thought (Clinical CoT). We empirically demonstrate LLMs/LMs' ability of clinical reasoning via extensive experiments and analyses on both rationale generation and disease diagnosis in various settings. We further propose a novel set of criteria for evaluating machine-generated rationales' potential for real-world clinical settings, facilitating and benefiting future research in this area.","sentences":["Machine reasoning has made great progress in recent years owing to large language models (LLMs).","In the clinical domain, however, most NLP-driven projects mainly focus on clinical classification or reading comprehension, and under-explore clinical reasoning for disease diagnosis due to the expensive rationale annotation with clinicians.","In this work, we present a ``reasoning-aware'' diagnosis framework that rationalizes the diagnostic process via prompt-based learning in a time- and labor-efficient manner, and learns to reason over the prompt-generated rationales.","Specifically, we address the clinical reasoning for disease diagnosis, where the LLM generates diagnostic rationales providing its insight on presented patient data and the reasoning path towards the diagnosis, namely Clinical Chain-of-Thought (Clinical CoT).","We empirically demonstrate LLMs/LMs' ability of clinical reasoning via extensive experiments and analyses on both rationale generation and disease diagnosis in various settings.","We further propose a novel set of criteria for evaluating machine-generated rationales' potential for real-world clinical settings, facilitating and benefiting future research in this area."],"url":"http://arxiv.org/abs/2312.07399v1"}
{"created":"2023-12-12 16:05:12","title":"Eroding Trust In Aerial Imagery: Comprehensive Analysis and Evaluation Of Adversarial Attacks In Geospatial Systems","abstract":"In critical operations where aerial imagery plays an essential role, the integrity and trustworthiness of data are paramount. The emergence of adversarial attacks, particularly those that exploit control over labels or employ physically feasible trojans, threatens to erode that trust, making the analysis and mitigation of these attacks a matter of urgency. We demonstrate how adversarial attacks can degrade confidence in geospatial systems, specifically focusing on scenarios where the attacker's control over labels is restricted and the use of realistic threat vectors. Proposing and evaluating several innovative attack methodologies, including those tailored to overhead images, we empirically show their threat to remote sensing systems using high-quality SpaceNet datasets. Our experimentation reflects the unique challenges posed by aerial imagery, and these preliminary results not only reveal the potential risks but also highlight the non-trivial nature of the problem compared to recent works.","sentences":["In critical operations where aerial imagery plays an essential role, the integrity and trustworthiness of data are paramount.","The emergence of adversarial attacks, particularly those that exploit control over labels or employ physically feasible trojans, threatens to erode that trust, making the analysis and mitigation of these attacks a matter of urgency.","We demonstrate how adversarial attacks can degrade confidence in geospatial systems, specifically focusing on scenarios where the attacker's control over labels is restricted and the use of realistic threat vectors.","Proposing and evaluating several innovative attack methodologies, including those tailored to overhead images, we empirically show their threat to remote sensing systems using high-quality SpaceNet datasets.","Our experimentation reflects the unique challenges posed by aerial imagery, and these preliminary results not only reveal the potential risks but also highlight the non-trivial nature of the problem compared to recent works."],"url":"http://arxiv.org/abs/2312.07389v1"}
{"created":"2023-12-12 16:03:38","title":"Transformation rules for the decentralization of a blockchain-extended global process model","abstract":"Blockchains and distributed ledger technology offer promising capabilities for supporting collaborative business processes across organizations. Typically, approaches in this field fall into two categories: either executing the entire process model on the blockchain or using the blockchain primarily to enforce or monitor the exchange of messages between participants. Our work proposes a novel approach that sits between these two methods.   We introduce a centralized process model extended with blockchain annotations, detailing the tasks of each participating organization and the extent to which blockchain technology is needed to secure task execution. This model also includes all critical data objects and specifies how their handling should be protected by the blockchain.   This technical report outlines a systematic three-step method for automatically decentralizing this comprehensive model into individual local process models for each organization, coupled with a separate process model for the blockchain. This decentralized structure effectively replicates the original global process model.   Our transformation approach is rule-based, focusing on creating a platform-inde-pendent model first, then a platform-specific model. Subsequently, we project the platform-specific model to obtain one model for the blockchain and one model for each participating organization.","sentences":["Blockchains and distributed ledger technology offer promising capabilities for supporting collaborative business processes across organizations.","Typically, approaches in this field fall into two categories: either executing the entire process model on the blockchain or using the blockchain primarily to enforce or monitor the exchange of messages between participants.","Our work proposes a novel approach that sits between these two methods.   ","We introduce a centralized process model extended with blockchain annotations, detailing the tasks of each participating organization and the extent to which blockchain technology is needed to secure task execution.","This model also includes all critical data objects and specifies how their handling should be protected by the blockchain.   ","This technical report outlines a systematic three-step method for automatically decentralizing this comprehensive model into individual local process models for each organization, coupled with a separate process model for the blockchain.","This decentralized structure effectively replicates the original global process model.   ","Our transformation approach is rule-based, focusing on creating a platform-inde-pendent model first, then a platform-specific model.","Subsequently, we project the platform-specific model to obtain one model for the blockchain and one model for each participating organization."],"url":"http://arxiv.org/abs/2312.07388v1"}
{"created":"2023-12-12 16:00:55","title":"GSmoothFace: Generalized Smooth Talking Face Generation via Fine Grained 3D Face Guidance","abstract":"Although existing speech-driven talking face generation methods achieve significant progress, they are far from real-world application due to the avatar-specific training demand and unstable lip movements. To address the above issues, we propose the GSmoothFace, a novel two-stage generalized talking face generation model guided by a fine-grained 3d face model, which can synthesize smooth lip dynamics while preserving the speaker's identity. Our proposed GSmoothFace model mainly consists of the Audio to Expression Prediction (A2EP) module and the Target Adaptive Face Translation (TAFT) module. Specifically, we first develop the A2EP module to predict expression parameters synchronized with the driven speech. It uses a transformer to capture the long-term audio context and learns the parameters from the fine-grained 3D facial vertices, resulting in accurate and smooth lip-synchronization performance. Afterward, the well-designed TAFT module, empowered by Morphology Augmented Face Blending (MAFB), takes the predicted expression parameters and target video as inputs to modify the facial region of the target video without distorting the background content. The TAFT effectively exploits the identity appearance and background context in the target video, which makes it possible to generalize to different speakers without retraining. Both quantitative and qualitative experiments confirm the superiority of our method in terms of realism, lip synchronization, and visual quality. See the project page for code, data, and request pre-trained models: https://zhanghm1995.github.io/GSmoothFace.","sentences":["Although existing speech-driven talking face generation methods achieve significant progress, they are far from real-world application due to the avatar-specific training demand and unstable lip movements.","To address the above issues, we propose the GSmoothFace, a novel two-stage generalized talking face generation model guided by a fine-grained 3d face model, which can synthesize smooth lip dynamics while preserving the speaker's identity.","Our proposed GSmoothFace model mainly consists of the Audio to Expression Prediction (A2EP) module and the Target Adaptive Face Translation (TAFT) module.","Specifically, we first develop the A2EP module to predict expression parameters synchronized with the driven speech.","It uses a transformer to capture the long-term audio context and learns the parameters from the fine-grained 3D facial vertices, resulting in accurate and smooth lip-synchronization performance.","Afterward, the well-designed TAFT module, empowered by Morphology Augmented Face Blending (MAFB), takes the predicted expression parameters and target video as inputs to modify the facial region of the target video without distorting the background content.","The TAFT effectively exploits the identity appearance and background context in the target video, which makes it possible to generalize to different speakers without retraining.","Both quantitative and qualitative experiments confirm the superiority of our method in terms of realism, lip synchronization, and visual quality.","See the project page for code, data, and request pre-trained models: https://zhanghm1995.github.io/GSmoothFace."],"url":"http://arxiv.org/abs/2312.07385v1"}
{"created":"2023-12-12 15:57:03","title":"ScribblePrompt: Fast and Flexible Interactive Segmentation for Any Medical Image","abstract":"Semantic medical image segmentation is a crucial part of both scientific research and clinical care. With enough labelled data, deep learning models can be trained to accurately automate specific medical image segmentation tasks. However, manually segmenting images to create training data is highly labor intensive. In this paper, we present ScribblePrompt, an interactive segmentation framework for medical imaging that enables human annotators to segment unseen structures using scribbles, clicks, and bounding boxes. Scribbles are an intuitive and effective form of user interaction for complex tasks, however most existing methods focus on click-based interactions. We introduce algorithms for simulating realistic scribbles that enable training models that are amenable to multiple types of interaction. To achieve generalization to new tasks, we train on a diverse collection of 65 open-access biomedical datasets -- using both real and synthetic labels. We test ScribblePrompt on multiple network architectures and unseen datasets, and demonstrate that it can be used in real-time on a single CPU. We evaluate ScribblePrompt using manually-collected scribbles, simulated interactions, and a user study. ScribblePrompt outperforms existing methods in all our evaluations. In the user study, ScribblePrompt reduced annotation time by 28% while improving Dice by 15% compared to existing methods. We showcase ScribblePrompt in an online demo and provide code at https://scribbleprompt.csail.mit.edu","sentences":["Semantic medical image segmentation is a crucial part of both scientific research and clinical care.","With enough labelled data, deep learning models can be trained to accurately automate specific medical image segmentation tasks.","However, manually segmenting images to create training data is highly labor intensive.","In this paper, we present ScribblePrompt, an interactive segmentation framework for medical imaging that enables human annotators to segment unseen structures using scribbles, clicks, and bounding boxes.","Scribbles are an intuitive and effective form of user interaction for complex tasks, however most existing methods focus on click-based interactions.","We introduce algorithms for simulating realistic scribbles that enable training models that are amenable to multiple types of interaction.","To achieve generalization to new tasks, we train on a diverse collection of 65 open-access biomedical datasets -- using both real and synthetic labels.","We test ScribblePrompt on multiple network architectures and unseen datasets, and demonstrate that it can be used in real-time on a single CPU.","We evaluate ScribblePrompt using manually-collected scribbles, simulated interactions, and a user study.","ScribblePrompt outperforms existing methods in all our evaluations.","In the user study, ScribblePrompt reduced annotation time by 28% while improving Dice by 15% compared to existing methods.","We showcase ScribblePrompt in an online demo and provide code at https://scribbleprompt.csail.mit.edu"],"url":"http://arxiv.org/abs/2312.07381v1"}
{"created":"2023-12-12 15:40:38","title":"Privacy-Aware Energy Consumption Modeling of Connected Battery Electric Vehicles using Federated Learning","abstract":"Battery Electric Vehicles (BEVs) are increasingly significant in modern cities due to their potential to reduce air pollution. Precise and real-time estimation of energy consumption for them is imperative for effective itinerary planning and optimizing vehicle systems, which can reduce driving range anxiety and decrease energy costs. As public awareness of data privacy increases, adopting approaches that safeguard data privacy in the context of BEV energy consumption modeling is crucial. Federated Learning (FL) is a promising solution mitigating the risk of exposing sensitive information to third parties by allowing local data to remain on devices and only sharing model updates with a central server. Our work investigates the potential of using FL methods, such as FedAvg, and FedPer, to improve BEV energy consumption prediction while maintaining user privacy. We conducted experiments using data from 10 BEVs under simulated real-world driving conditions. Our results demonstrate that the FedAvg-LSTM model achieved a reduction of up to 67.84\\% in the MAE value of the prediction results. Furthermore, we explored various real-world scenarios and discussed how FL methods can be employed in those cases. Our findings show that FL methods can effectively improve the performance of BEV energy consumption prediction while maintaining user privacy.","sentences":["Battery Electric Vehicles (BEVs) are increasingly significant in modern cities due to their potential to reduce air pollution.","Precise and real-time estimation of energy consumption for them is imperative for effective itinerary planning and optimizing vehicle systems, which can reduce driving range anxiety and decrease energy costs.","As public awareness of data privacy increases, adopting approaches that safeguard data privacy in the context of BEV energy consumption modeling is crucial.","Federated Learning (FL) is a promising solution mitigating the risk of exposing sensitive information to third parties by allowing local data to remain on devices and only sharing model updates with a central server.","Our work investigates the potential of using FL methods, such as FedAvg, and FedPer, to improve BEV energy consumption prediction while maintaining user privacy.","We conducted experiments using data from 10 BEVs under simulated real-world driving conditions.","Our results demonstrate that the FedAvg-LSTM model achieved a reduction of up to 67.84\\% in the MAE value of the prediction results.","Furthermore, we explored various real-world scenarios and discussed how FL methods can be employed in those cases.","Our findings show that FL methods can effectively improve the performance of BEV energy consumption prediction while maintaining user privacy."],"url":"http://arxiv.org/abs/2312.07371v1"}
{"created":"2023-12-12 15:40:22","title":"Adversarial Semi-Supervised Domain Adaptation for Semantic Segmentation: A New Role for Labeled Target Samples","abstract":"Adversarial learning baselines for domain adaptation (DA) approaches in the context of semantic segmentation are under explored in semi-supervised framework. These baselines involve solely the available labeled target samples in the supervision loss. In this work, we propose to enhance their usefulness on both semantic segmentation and the single domain classifier neural networks. We design new training objective losses for cases when labeled target data behave as source samples or as real target samples. The underlying rationale is that considering the set of labeled target samples as part of source domain helps reducing the domain discrepancy and, hence, improves the contribution of the adversarial loss. To support our approach, we consider a complementary method that mixes source and labeled target data, then applies the same adaptation process. We further propose an unsupervised selection procedure using entropy to optimize the choice of labeled target samples for adaptation. We illustrate our findings through extensive experiments on the benchmarks GTA5, SYNTHIA, and Cityscapes. The empirical evaluation highlights competitive performance of our proposed approach.","sentences":["Adversarial learning baselines for domain adaptation (DA) approaches in the context of semantic segmentation are under explored in semi-supervised framework.","These baselines involve solely the available labeled target samples in the supervision loss.","In this work, we propose to enhance their usefulness on both semantic segmentation and the single domain classifier neural networks.","We design new training objective losses for cases when labeled target data behave as source samples or as real target samples.","The underlying rationale is that considering the set of labeled target samples as part of source domain helps reducing the domain discrepancy and, hence, improves the contribution of the adversarial loss.","To support our approach, we consider a complementary method that mixes source and labeled target data, then applies the same adaptation process.","We further propose an unsupervised selection procedure using entropy to optimize the choice of labeled target samples for adaptation.","We illustrate our findings through extensive experiments on the benchmarks GTA5, SYNTHIA, and Cityscapes.","The empirical evaluation highlights competitive performance of our proposed approach."],"url":"http://arxiv.org/abs/2312.07370v1"}
{"created":"2023-12-12 15:36:59","title":"Sequential Planning in Large Partially Observable Environments guided by LLMs","abstract":"Sequential planning in large state space and action space quickly becomes intractable due to combinatorial explosion of the search space. Heuristic methods, like monte-carlo tree search, though effective for large state space, but struggle if action space is large. Pure reinforcement learning methods, relying only on reward signals, needs prohibitively large interactions with the environment to device a viable plan. If the state space, observations and actions can be represented in natural language then Large Language models (LLM) can be used to generate action plans. Recently several such goal-directed agents like Reflexion, CLIN, SayCan were able to surpass the performance of other state-of-the-art methods with minimum or no task specific training. But they still struggle with exploration and get stuck in local optima. Their planning capabilities are limited by the limited reasoning capability of the foundational LLMs on text data. We propose a hybrid agent \"neoplanner\", that synergizes both state space search with queries to foundational LLM to get the best action plan. The reward signals are quantitatively used to drive the search. A balance of exploration and exploitation is maintained by maximizing upper confidence bounds of values of states. In places where random exploration is needed, the LLM is queried to generate an action plan. Learnings from each trial are stored as entity relationships in text format. Those are used in future queries to the LLM for continual improvement. Experiments in the Scienceworld environment reveals a 124% improvement from the current best method in terms of average reward gained across multiple tasks.","sentences":["Sequential planning in large state space and action space quickly becomes intractable due to combinatorial explosion of the search space.","Heuristic methods, like monte-carlo tree search, though effective for large state space, but struggle if action space is large.","Pure reinforcement learning methods, relying only on reward signals, needs prohibitively large interactions with the environment to device a viable plan.","If the state space, observations and actions can be represented in natural language then Large Language models (LLM) can be used to generate action plans.","Recently several such goal-directed agents like Reflexion, CLIN, SayCan were able to surpass the performance of other state-of-the-art methods with minimum or no task specific training.","But they still struggle with exploration and get stuck in local optima.","Their planning capabilities are limited by the limited reasoning capability of the foundational LLMs on text data.","We propose a hybrid agent \"neoplanner\", that synergizes both state space search with queries to foundational LLM to get the best action plan.","The reward signals are quantitatively used to drive the search.","A balance of exploration and exploitation is maintained by maximizing upper confidence bounds of values of states.","In places where random exploration is needed, the LLM is queried to generate an action plan.","Learnings from each trial are stored as entity relationships in text format.","Those are used in future queries to the LLM for continual improvement.","Experiments in the Scienceworld environment reveals a 124% improvement from the current best method in terms of average reward gained across multiple tasks."],"url":"http://arxiv.org/abs/2312.07368v1"}
{"created":"2023-12-12 15:23:38","title":"MRCN: Enhanced Coherence Mechanism for Near Memory Processing Architectures","abstract":"In Near Memory Processing (NMP), processing elements(PEs) are placed near the 3D memory, reducing unnecessary data transfers between the CPU and the memory. However, as the CPUs and the PEs of the NMP use a shared memory space, maintaining coherency between them is a challenge. Most current literature relies on maintaining coherence for fine-grained or coarse-grained instruction granularities for the offloaded code blocks. We understand that for most NMP-offloaded instructions, the coherence conflict is low, and waiting for the coherence transaction hinders the performance. We construct an analytical model for an existing coherence strategy called CONDA, which is within 4% accuracy. This model indicates the key parameters responsible - the granularity of offloaded code, probability of conflicts, transaction times, and commit time. This paper identifies the prospective optimizations using the analytical model for CONDA. It proposes a new coherence scheme called MRCN: Monitored Rollback Coherence for NMP. MRCN addresses the coherence issue while eliminating unnecessary re-executions with limited hardware overhead. The MRCN is evaluated on synthetic as well as Rodinia benchmarks. The analytical results are within 4% accuracy of the simulation results. The MRCN shows improvement of upto 25% over CONDA strategy for the same benchmark under different execution conditions.","sentences":["In Near Memory Processing (NMP), processing elements(PEs) are placed near the 3D memory, reducing unnecessary data transfers between the CPU and the memory.","However, as the CPUs and the PEs of the NMP use a shared memory space, maintaining coherency between them is a challenge.","Most current literature relies on maintaining coherence for fine-grained or coarse-grained instruction granularities for the offloaded code blocks.","We understand that for most NMP-offloaded instructions, the coherence conflict is low, and waiting for the coherence transaction hinders the performance.","We construct an analytical model for an existing coherence strategy called CONDA, which is within 4% accuracy.","This model indicates the key parameters responsible - the granularity of offloaded code, probability of conflicts, transaction times, and commit time.","This paper identifies the prospective optimizations using the analytical model for CONDA.","It proposes a new coherence scheme called MRCN:","Monitored Rollback Coherence for NMP.","MRCN addresses the coherence issue while eliminating unnecessary re-executions with limited hardware overhead.","The MRCN is evaluated on synthetic as well as Rodinia benchmarks.","The analytical results are within 4% accuracy of the simulation results.","The MRCN shows improvement of upto 25% over CONDA strategy for the same benchmark under different execution conditions."],"url":"http://arxiv.org/abs/2312.07355v1"}
{"created":"2023-12-12 15:10:03","title":"\"It doesn't tell me anything about how my data is used'': User Perceptions of Data Collection Purposes","abstract":"Data collection purposes and their descriptions are presented on almost all privacy notices under the GDPR, yet there is a lack of research focusing on how effective they are at informing users about data practices. We fill this gap by investigating users' perceptions of data collection purposes and their descriptions, a crucial aspect of informed consent. We conducted 23 semi-structured interviews with European users to investigate user perceptions of six common purposes (Strictly Necessary, Statistics and Analytics, Performance and Functionality, Marketing and Advertising, Personalized Advertising, and Personalized Content) and identified elements of an effective purpose name and description.   We found that most purpose descriptions do not contain the information users wish to know, and that participants preferred some purpose names over others due to their perceived transparency or ease of understanding. Based on these findings, we suggest how the framing of purposes can be improved toward meaningful informed consent.","sentences":["Data collection purposes and their descriptions are presented on almost all privacy notices under the GDPR, yet there is a lack of research focusing on how effective they are at informing users about data practices.","We fill this gap by investigating users' perceptions of data collection purposes and their descriptions, a crucial aspect of informed consent.","We conducted 23 semi-structured interviews with European users to investigate user perceptions of six common purposes (Strictly Necessary, Statistics and Analytics, Performance and Functionality, Marketing and Advertising, Personalized Advertising, and Personalized Content) and identified elements of an effective purpose name and description.   ","We found that most purpose descriptions do not contain the information users wish to know, and that participants preferred some purpose names over others due to their perceived transparency or ease of understanding.","Based on these findings, we suggest how the framing of purposes can be improved toward meaningful informed consent."],"url":"http://arxiv.org/abs/2312.07348v1"}
{"created":"2023-12-12 14:58:08","title":"Self-supervised Adaptive Pre-training of Multilingual Speech Models for Language and Dialect Identification","abstract":"Pre-trained Transformer-based speech models have shown striking performance when fine-tuned on various downstream tasks such as automatic speech recognition and spoken language identification (SLID). However, the problem of domain mismatch remains a challenge in this area, where the domain of the pre-training data might differ from that of the downstream labeled data used for fine-tuning. In multilingual tasks such as SLID, the pre-trained speech model may not support all the languages in the downstream task. To address this challenge, we propose self-supervised adaptive pre-training (SAPT) to adapt the pre-trained model to the target domain and languages of the downstream task. We apply SAPT to the XLSR-128 model and investigate the effectiveness of this approach for the SLID task. First, we demonstrate that SAPT improves XLSR performance on the FLEURS benchmark with substantial gains up to 40.1% for under-represented languages. Second, we apply SAPT on four different datasets in a few-shot learning setting, showing that our approach improves the sample efficiency of XLSR during fine-tuning. Our experiments provide strong empirical evidence that continual adaptation via self-supervision improves downstream performance for multilingual speech models.","sentences":["Pre-trained Transformer-based speech models have shown striking performance when fine-tuned on various downstream tasks such as automatic speech recognition and spoken language identification (SLID).","However, the problem of domain mismatch remains a challenge in this area, where the domain of the pre-training data might differ from that of the downstream labeled data used for fine-tuning.","In multilingual tasks such as SLID, the pre-trained speech model may not support all the languages in the downstream task.","To address this challenge, we propose self-supervised adaptive pre-training (SAPT) to adapt the pre-trained model to the target domain and languages of the downstream task.","We apply SAPT to the XLSR-128 model and investigate the effectiveness of this approach for the SLID task.","First, we demonstrate that SAPT improves XLSR performance on the FLEURS benchmark with substantial gains up to 40.1% for under-represented languages.","Second, we apply SAPT on four different datasets in a few-shot learning setting, showing that our approach improves the sample efficiency of XLSR during fine-tuning.","Our experiments provide strong empirical evidence that continual adaptation via self-supervision improves downstream performance for multilingual speech models."],"url":"http://arxiv.org/abs/2312.07338v1"}
{"created":"2023-12-12 14:47:26","title":"Coupled Confusion Correction: Learning from Crowds with Sparse Annotations","abstract":"As the size of the datasets getting larger, accurately annotating such datasets is becoming more impractical due to the expensiveness on both time and economy. Therefore, crowd-sourcing has been widely adopted to alleviate the cost of collecting labels, which also inevitably introduces label noise and eventually degrades the performance of the model. To learn from crowd-sourcing annotations, modeling the expertise of each annotator is a common but challenging paradigm, because the annotations collected by crowd-sourcing are usually highly-sparse. To alleviate this problem, we propose Coupled Confusion Correction (CCC), where two models are simultaneously trained to correct the confusion matrices learned by each other. Via bi-level optimization, the confusion matrices learned by one model can be corrected by the distilled data from the other. Moreover, we cluster the ``annotator groups'' who share similar expertise so that their confusion matrices could be corrected together. In this way, the expertise of the annotators, especially of those who provide seldom labels, could be better captured. Remarkably, we point out that the annotation sparsity not only means the average number of labels is low, but also there are always some annotators who provide very few labels, which is neglected by previous works when constructing synthetic crowd-sourcing annotations. Based on that, we propose to use Beta distribution to control the generation of the crowd-sourcing labels so that the synthetic annotations could be more consistent with the real-world ones. Extensive experiments are conducted on two types of synthetic datasets and three real-world datasets, the results of which demonstrate that CCC significantly outperforms state-of-the-art approaches.","sentences":["As the size of the datasets getting larger, accurately annotating such datasets is becoming more impractical due to the expensiveness on both time and economy.","Therefore, crowd-sourcing has been widely adopted to alleviate the cost of collecting labels, which also inevitably introduces label noise and eventually degrades the performance of the model.","To learn from crowd-sourcing annotations, modeling the expertise of each annotator is a common but challenging paradigm, because the annotations collected by crowd-sourcing are usually highly-sparse.","To alleviate this problem, we propose Coupled Confusion Correction (CCC), where two models are simultaneously trained to correct the confusion matrices learned by each other.","Via bi-level optimization, the confusion matrices learned by one model can be corrected by the distilled data from the other.","Moreover, we cluster the ``annotator groups'' who share similar expertise so that their confusion matrices could be corrected together.","In this way, the expertise of the annotators, especially of those who provide seldom labels, could be better captured.","Remarkably, we point out that the annotation sparsity not only means the average number of labels is low, but also there are always some annotators who provide very few labels, which is neglected by previous works when constructing synthetic crowd-sourcing annotations.","Based on that, we propose to use Beta distribution to control the generation of the crowd-sourcing labels so that the synthetic annotations could be more consistent with the real-world ones.","Extensive experiments are conducted on two types of synthetic datasets and three real-world datasets, the results of which demonstrate that CCC significantly outperforms state-of-the-art approaches."],"url":"http://arxiv.org/abs/2312.07331v1"}
{"created":"2023-12-12 14:45:45","title":"Learned representation-guided diffusion models for large-image generation","abstract":"To synthesize high-fidelity samples, diffusion models typically require auxiliary data to guide the generation process. However, it is impractical to procure the painstaking patch-level annotation effort required in specialized domains like histopathology and satellite imagery; it is often performed by domain experts and involves hundreds of millions of patches. Modern-day self-supervised learning (SSL) representations encode rich semantic and visual information. In this paper, we posit that such representations are expressive enough to act as proxies to fine-grained human labels. We introduce a novel approach that trains diffusion models conditioned on embeddings from SSL. Our diffusion models successfully project these features back to high-quality histopathology and remote sensing images. In addition, we construct larger images by assembling spatially consistent patches inferred from SSL embeddings, preserving long-range dependencies. Augmenting real data by generating variations of real images improves downstream classifier accuracy for patch-level and larger, image-scale classification tasks. Our models are effective even on datasets not encountered during training, demonstrating their robustness and generalizability. Generating images from learned embeddings is agnostic to the source of the embeddings. The SSL embeddings used to generate a large image can either be extracted from a reference image, or sampled from an auxiliary model conditioned on any related modality (e.g. class labels, text, genomic data). As proof of concept, we introduce the text-to-large image synthesis paradigm where we successfully synthesize large pathology and satellite images out of text descriptions.","sentences":["To synthesize high-fidelity samples, diffusion models typically require auxiliary data to guide the generation process.","However, it is impractical to procure the painstaking patch-level annotation effort required in specialized domains like histopathology and satellite imagery; it is often performed by domain experts and involves hundreds of millions of patches.","Modern-day self-supervised learning (SSL) representations encode rich semantic and visual information.","In this paper, we posit that such representations are expressive enough to act as proxies to fine-grained human labels.","We introduce a novel approach that trains diffusion models conditioned on embeddings from SSL.","Our diffusion models successfully project these features back to high-quality histopathology and remote sensing images.","In addition, we construct larger images by assembling spatially consistent patches inferred from SSL embeddings, preserving long-range dependencies.","Augmenting real data by generating variations of real images improves downstream classifier accuracy for patch-level and larger, image-scale classification tasks.","Our models are effective even on datasets not encountered during training, demonstrating their robustness and generalizability.","Generating images from learned embeddings is agnostic to the source of the embeddings.","The SSL embeddings used to generate a large image can either be extracted from a reference image, or sampled from an auxiliary model conditioned on any related modality (e.g. class labels, text, genomic data).","As proof of concept, we introduce the text-to-large image synthesis paradigm where we successfully synthesize large pathology and satellite images out of text descriptions."],"url":"http://arxiv.org/abs/2312.07330v1"}
{"created":"2023-12-12 14:43:09","title":"Adaptive Confidence Multi-View Hashing for Multimedia Retrieval","abstract":"The multi-view hash method converts heterogeneous data from multiple views into binary hash codes, which is one of the critical technologies in multimedia retrieval. However, the current methods mainly explore the complementarity among multiple views while lacking confidence learning and fusion. Moreover, in practical application scenarios, the single-view data contain redundant noise. To conduct the confidence learning and eliminate unnecessary noise, we propose a novel Adaptive Confidence Multi-View Hashing (ACMVH) method. First, a confidence network is developed to extract useful information from various single-view features and remove noise information. Furthermore, an adaptive confidence multi-view network is employed to measure the confidence of each view and then fuse multi-view features through a weighted summation. Lastly, a dilation network is designed to further enhance the feature representation of the fused features. To the best of our knowledge, we pioneer the application of confidence learning into the field of multimedia retrieval. Extensive experiments on two public datasets show that the proposed ACMVH performs better than state-of-the-art methods (maximum increase of 3.24%). The source code is available at https://github.com/HackerHyper/ACMVH.","sentences":["The multi-view hash method converts heterogeneous data from multiple views into binary hash codes, which is one of the critical technologies in multimedia retrieval.","However, the current methods mainly explore the complementarity among multiple views while lacking confidence learning and fusion.","Moreover, in practical application scenarios, the single-view data contain redundant noise.","To conduct the confidence learning and eliminate unnecessary noise, we propose a novel Adaptive Confidence Multi-View Hashing (ACMVH) method.","First, a confidence network is developed to extract useful information from various single-view features and remove noise information.","Furthermore, an adaptive confidence multi-view network is employed to measure the confidence of each view and then fuse multi-view features through a weighted summation.","Lastly, a dilation network is designed to further enhance the feature representation of the fused features.","To the best of our knowledge, we pioneer the application of confidence learning into the field of multimedia retrieval.","Extensive experiments on two public datasets show that the proposed ACMVH performs better than state-of-the-art methods (maximum increase of 3.24%).","The source code is available at https://github.com/HackerHyper/ACMVH."],"url":"http://arxiv.org/abs/2312.07327v1"}
{"created":"2023-12-12 14:37:36","title":"GenHowTo: Learning to Generate Actions and State Transformations from Instructional Videos","abstract":"We address the task of generating temporally consistent and physically plausible images of actions and object state transformations. Given an input image and a text prompt describing the targeted transformation, our generated images preserve the environment and transform objects in the initial image. Our contributions are threefold. First, we leverage a large body of instructional videos and automatically mine a dataset of triplets of consecutive frames corresponding to initial object states, actions, and resulting object transformations. Second, equipped with this data, we develop and train a conditioned diffusion model dubbed GenHowTo. Third, we evaluate GenHowTo on a variety of objects and actions and show superior performance compared to existing methods. In particular, we introduce a quantitative evaluation where GenHowTo achieves 88% and 74% on seen and unseen interaction categories, respectively, outperforming prior work by a large margin.","sentences":["We address the task of generating temporally consistent and physically plausible images of actions and object state transformations.","Given an input image and a text prompt describing the targeted transformation, our generated images preserve the environment and transform objects in the initial image.","Our contributions are threefold.","First, we leverage a large body of instructional videos and automatically mine a dataset of triplets of consecutive frames corresponding to initial object states, actions, and resulting object transformations.","Second, equipped with this data, we develop and train a conditioned diffusion model dubbed GenHowTo.","Third, we evaluate GenHowTo on a variety of objects and actions and show superior performance compared to existing methods.","In particular, we introduce a quantitative evaluation where GenHowTo achieves 88% and 74% on seen and unseen interaction categories, respectively, outperforming prior work by a large margin."],"url":"http://arxiv.org/abs/2312.07322v1"}
{"created":"2023-12-12 14:34:36","title":"Top-Down Drawings of Compound Graphs","abstract":"Bottom-up layout algorithms for compound graphs are suitable for presenting the microscale view of models and are often used in model-driven engineering. However, they have difficulties at the macroscale where maintaining the overview of large models becomes challenging. We propose top-down layout, which utilizes scale to hide low-level details at high zoom levels. The entire high-level view can fit into the viewport and remain readable, while the ability to zoom in to see the details is still maintained. Top-down layout is an abstract high-level layout process that can be used in conjunction with classic layout algorithms to produce visually compelling and readable diagrams of large compound graphs.","sentences":["Bottom-up layout algorithms for compound graphs are suitable for presenting the microscale view of models and are often used in model-driven engineering.","However, they have difficulties at the macroscale where maintaining the overview of large models becomes challenging.","We propose top-down layout, which utilizes scale to hide low-level details at high zoom levels.","The entire high-level view can fit into the viewport and remain readable, while the ability to zoom in to see the details is still maintained.","Top-down layout is an abstract high-level layout process that can be used in conjunction with classic layout algorithms to produce visually compelling and readable diagrams of large compound graphs."],"url":"http://arxiv.org/abs/2312.07319v1"}
{"created":"2023-12-12 14:29:57","title":"NVS-Adapter: Plug-and-Play Novel View Synthesis from a Single Image","abstract":"Transfer learning of large-scale Text-to-Image (T2I) models has recently shown impressive potential for Novel View Synthesis (NVS) of diverse objects from a single image. While previous methods typically train large models on multi-view datasets for NVS, fine-tuning the whole parameters of T2I models not only demands a high cost but also reduces the generalization capacity of T2I models in generating diverse images in a new domain. In this study, we propose an effective method, dubbed NVS-Adapter, which is a plug-and-play module for a T2I model, to synthesize novel multi-views of visual objects while fully exploiting the generalization capacity of T2I models. NVS-Adapter consists of two main components; view-consistency cross-attention learns the visual correspondences to align the local details of view features, and global semantic conditioning aligns the semantic structure of generated views with the reference view. Experimental results demonstrate that the NVS-Adapter can effectively synthesize geometrically consistent multi-views and also achieve high performance on benchmarks without full fine-tuning of T2I models. The code and data are publicly available in ~\\href{https://postech-cvlab.github.io/nvsadapter/}{https://postech-cvlab.github.io/nvsadapter/}.","sentences":["Transfer learning of large-scale Text-to-Image (T2I) models has recently shown impressive potential for Novel View Synthesis (NVS) of diverse objects from a single image.","While previous methods typically train large models on multi-view datasets for NVS, fine-tuning the whole parameters of T2I models not only demands a high cost but also reduces the generalization capacity of T2I models in generating diverse images in a new domain.","In this study, we propose an effective method, dubbed NVS-Adapter, which is a plug-and-play module for a T2I model, to synthesize novel multi-views of visual objects while fully exploiting the generalization capacity of T2I models.","NVS-Adapter consists of two main components; view-consistency cross-attention learns the visual correspondences to align the local details of view features, and global semantic conditioning aligns the semantic structure of generated views with the reference view.","Experimental results demonstrate that the NVS-Adapter can effectively synthesize geometrically consistent multi-views and also achieve high performance on benchmarks without full fine-tuning of T2I models.","The code and data are publicly available in ~\\href{https://postech-cvlab.github.io/nvsadapter/}{https://postech-cvlab.github.io/nvsadapter/}."],"url":"http://arxiv.org/abs/2312.07315v1"}
{"created":"2023-12-12 14:28:31","title":"Scalable Motion Style Transfer with Constrained Diffusion Generation","abstract":"Current training of motion style transfer systems relies on consistency losses across style domains to preserve contents, hindering its scalable application to a large number of domains and private data. Recent image transfer works show the potential of independent training on each domain by leveraging implicit bridging between diffusion models, with the content preservation, however, limited to simple data patterns. We address this by imposing biased sampling in backward diffusion while maintaining the domain independence in the training stage. We construct the bias from the source domain keyframes and apply them as the gradient of content constraints, yielding a framework with keyframe manifold constraint gradients (KMCGs). Our validation demonstrates the success of training separate models to transfer between as many as ten dance motion styles. Comprehensive experiments find a significant improvement in preserving motion contents in comparison to baseline and ablative diffusion-based style transfer models. In addition, we perform a human study for a subjective assessment of the quality of generated dance motions. The results validate the competitiveness of KMCGs.","sentences":["Current training of motion style transfer systems relies on consistency losses across style domains to preserve contents, hindering its scalable application to a large number of domains and private data.","Recent image transfer works show the potential of independent training on each domain by leveraging implicit bridging between diffusion models, with the content preservation, however, limited to simple data patterns.","We address this by imposing biased sampling in backward diffusion while maintaining the domain independence in the training stage.","We construct the bias from the source domain keyframes and apply them as the gradient of content constraints, yielding a framework with keyframe manifold constraint gradients (KMCGs).","Our validation demonstrates the success of training separate models to transfer between as many as ten dance motion styles.","Comprehensive experiments find a significant improvement in preserving motion contents in comparison to baseline and ablative diffusion-based style transfer models.","In addition, we perform a human study for a subjective assessment of the quality of generated dance motions.","The results validate the competitiveness of KMCGs."],"url":"http://arxiv.org/abs/2312.07311v1"}
{"created":"2023-12-12 14:23:18","title":"From Knowledge Representation to Knowledge Organization and Back","abstract":"Knowledge Representation (KR) and facet-analytical Knowledge Organization (KO) have been the two most prominent methodologies of data and knowledge modelling in the Artificial Intelligence community and the Information Science community, respectively. KR boasts of a robust and scalable ecosystem of technologies to support knowledge modelling while, often, underemphasizing the quality of its models (and model-based data). KO, on the other hand, is less technology-driven but has developed a robust framework of guiding principles (canons) for ensuring modelling (and model-based data) quality. This paper elucidates both the KR and facet-analytical KO methodologies in detail and provides a functional mapping between them. Out of the mapping, the paper proposes an integrated KO-enriched KR methodology with all the standard components of a KR methodology plus the guiding canons of modelling quality provided by KO. The practical benefits of the methodological integration has been exemplified through a prominent case study of KR-based image annotation exercise.","sentences":["Knowledge Representation (KR) and facet-analytical Knowledge Organization (KO) have been the two most prominent methodologies of data and knowledge modelling in the Artificial Intelligence community and the Information Science community, respectively.","KR boasts of a robust and scalable ecosystem of technologies to support knowledge modelling while, often, underemphasizing the quality of its models (and model-based data).","KO, on the other hand, is less technology-driven but has developed a robust framework of guiding principles (canons) for ensuring modelling (and model-based data) quality.","This paper elucidates both the KR and facet-analytical KO methodologies in detail and provides a functional mapping between them.","Out of the mapping, the paper proposes an integrated KO-enriched KR methodology with all the standard components of a KR methodology plus the guiding canons of modelling quality provided by KO.","The practical benefits of the methodological integration has been exemplified through a prominent case study of KR-based image annotation exercise."],"url":"http://arxiv.org/abs/2312.07302v1"}
{"created":"2023-12-12 14:14:40","title":"Complex Recurrent Spectral Network","abstract":"This paper presents a novel approach to advancing artificial intelligence (AI) through the development of the Complex Recurrent Spectral Network ($\\mathbb{C}$-RSN), an innovative variant of the Recurrent Spectral Network (RSN) model. The $\\mathbb{C}$-RSN is designed to address a critical limitation in existing neural network models: their inability to emulate the complex processes of biological neural networks dynamically and accurately. By integrating key concepts from dynamical systems theory and leveraging principles from statistical mechanics, the $\\mathbb{C}$-RSN model introduces localized non-linearity, complex fixed eigenvalues, and a distinct separation of memory and input processing functionalities. These features collectively enable the $\\mathbb{C}$-RSN evolving towards a dynamic, oscillating final state that more closely mirrors biological cognition. Central to this work is the exploration of how the $\\mathbb{C}$-RSN manages to capture the rhythmic, oscillatory dynamics intrinsic to biological systems, thanks to its complex eigenvalue structure and the innovative segregation of its linear and non-linear components. The model's ability to classify data through a time-dependent function, and the localization of information processing, is demonstrated with an empirical evaluation using the MNIST dataset. Remarkably, distinct items supplied as a sequential input yield patterns in time which bear the indirect imprint of the insertion order (and of the time of separation between contiguous insertions).","sentences":["This paper presents a novel approach to advancing artificial intelligence (AI) through the development of the Complex Recurrent Spectral Network ($\\mathbb{C}$-RSN), an innovative variant of the Recurrent Spectral Network (RSN) model.","The $\\mathbb{C}$-RSN is designed to address a critical limitation in existing neural network models: their inability to emulate the complex processes of biological neural networks dynamically and accurately.","By integrating key concepts from dynamical systems theory and leveraging principles from statistical mechanics, the $\\mathbb{C}$-RSN model introduces localized non-linearity, complex fixed eigenvalues, and a distinct separation of memory and input processing functionalities.","These features collectively enable the $\\mathbb{C}$-RSN evolving towards a dynamic, oscillating final state that more closely mirrors biological cognition.","Central to this work is the exploration of how the $\\mathbb{C}$-RSN manages to capture the rhythmic, oscillatory dynamics intrinsic to biological systems, thanks to its complex eigenvalue structure and the innovative segregation of its linear and non-linear components.","The model's ability to classify data through a time-dependent function, and the localization of information processing, is demonstrated with an empirical evaluation using the MNIST dataset.","Remarkably, distinct items supplied as a sequential input yield patterns in time which bear the indirect imprint of the insertion order (and of the time of separation between contiguous insertions)."],"url":"http://arxiv.org/abs/2312.07296v1"}
{"created":"2023-12-12 13:52:55","title":"Benchmarking Pretrained Vision Embeddings for Near- and Duplicate Detection in Medical Images","abstract":"Near- and duplicate image detection is a critical concern in the field of medical imaging. Medical datasets often contain similar or duplicate images from various sources, which can lead to significant performance issues and evaluation biases, especially in machine learning tasks due to data leakage between training and testing subsets. In this paper, we present an approach for identifying near- and duplicate 3D medical images leveraging publicly available 2D computer vision embeddings. We assessed our approach by comparing embeddings extracted from two state-of-the-art self-supervised pretrained models and two different vector index structures for similarity retrieval. We generate an experimental benchmark based on the publicly available Medical Segmentation Decathlon dataset. The proposed method yields promising results for near- and duplicate image detection achieving a mean sensitivity and specificity of 0.9645 and 0.8559, respectively.","sentences":["Near- and duplicate image detection is a critical concern in the field of medical imaging.","Medical datasets often contain similar or duplicate images from various sources, which can lead to significant performance issues and evaluation biases, especially in machine learning tasks due to data leakage between training and testing subsets.","In this paper, we present an approach for identifying near- and duplicate 3D medical images leveraging publicly available 2D computer vision embeddings.","We assessed our approach by comparing embeddings extracted from two state-of-the-art self-supervised pretrained models and two different vector index structures for similarity retrieval.","We generate an experimental benchmark based on the publicly available Medical Segmentation Decathlon dataset.","The proposed method yields promising results for near- and duplicate image detection achieving a mean sensitivity and specificity of 0.9645 and 0.8559, respectively."],"url":"http://arxiv.org/abs/2312.07273v1"}
{"created":"2023-12-12 13:51:25","title":"Analyze the Robustness of Classifiers under Label Noise","abstract":"This study explores the robustness of label noise classifiers, aiming to enhance model resilience against noisy data in complex real-world scenarios. Label noise in supervised learning, characterized by erroneous or imprecise labels, significantly impairs model performance. This research focuses on the increasingly pertinent issue of label noise's impact on practical applications. Addressing the prevalent challenge of inaccurate training data labels, we integrate adversarial machine learning (AML) and importance reweighting techniques. Our approach involves employing convolutional neural networks (CNN) as the foundational model, with an emphasis on parameter adjustment for individual training samples. This strategy is designed to heighten the model's focus on samples critically influencing performance.","sentences":["This study explores the robustness of label noise classifiers, aiming to enhance model resilience against noisy data in complex real-world scenarios.","Label noise in supervised learning, characterized by erroneous or imprecise labels, significantly impairs model performance.","This research focuses on the increasingly pertinent issue of label noise's impact on practical applications.","Addressing the prevalent challenge of inaccurate training data labels, we integrate adversarial machine learning (AML) and importance reweighting techniques.","Our approach involves employing convolutional neural networks (CNN) as the foundational model, with an emphasis on parameter adjustment for individual training samples.","This strategy is designed to heighten the model's focus on samples critically influencing performance."],"url":"http://arxiv.org/abs/2312.07271v1"}
{"created":"2023-12-12 13:48:36","title":"Calibrating \"Cheap Signals\" in Peer Review without a Prior","abstract":"Peer review lies at the core of the academic process, but even well-intentioned reviewers can still provide noisy ratings. While ranking papers by average ratings may reduce noise, varying noise levels and systematic biases stemming from ``cheap'' signals (e.g. author identity, proof length) can lead to unfairness. Detecting and correcting bias is challenging, as ratings are subjective and unverifiable. Unlike previous works relying on prior knowledge or historical data, we propose a one-shot noise calibration process without any prior information. We ask reviewers to predict others' scores and use these predictions for calibration. Assuming reviewers adjust their predictions according to the noise, we demonstrate that the calibrated score results in a more robust ranking compared to average ratings, even with varying noise levels and biases. In detail, we show that the error probability of the calibrated score approaches zero as the number of reviewers increases and is significantly lower compared to average ratings when the number of reviewers is small.","sentences":["Peer review lies at the core of the academic process, but even well-intentioned reviewers can still provide noisy ratings.","While ranking papers by average ratings may reduce noise, varying noise levels and systematic biases stemming from ``cheap'' signals (e.g. author identity, proof length) can lead to unfairness.","Detecting and correcting bias is challenging, as ratings are subjective and unverifiable.","Unlike previous works relying on prior knowledge or historical data, we propose a one-shot noise calibration process without any prior information.","We ask reviewers to predict others' scores and use these predictions for calibration.","Assuming reviewers adjust their predictions according to the noise, we demonstrate that the calibrated score results in a more robust ranking compared to average ratings, even with varying noise levels and biases.","In detail, we show that the error probability of the calibrated score approaches zero as the number of reviewers increases and is significantly lower compared to average ratings when the number of reviewers is small."],"url":"http://arxiv.org/abs/2312.07269v1"}
{"created":"2023-12-12 13:45:56","title":"ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open Vocabulary Object Detection","abstract":"Open-vocabulary object detection (OVOD) aims to recognize novel objects whose categories are not included in training set. In order to classify these unseen classes during training, many OVOD frameworks leverage the zero-shot capability of largely pretrained vision and language models, such as CLIP. To further improve generalization on the unseen novel classes, several approaches proposed to additionally train with pseudo region labeling on the external data sources that contain a substantial number of novel category labels beyond the existing training data. Albeit its simplicity, these pseudo-labeling methods still exhibit limited improvement with regard to the genuine novel classes that were not pseudo-labeled. In this paper, we present a novel, yet simple technique that helps generalization on the overall distribution of novel classes. Inspired by our observation that numerous novel classes reside within the convex hull constructed by the base (seen) classes in the CLIP embedding space, we propose to synthesize proxy-novel classes approximating novel classes via linear mixup between a pair of base classes. By training our detector with these synthetic proxy-novel classes, we effectively explore the embedding space of novel classes. The experimental results on various OVOD benchmarks such as LVIS and COCO demonstrate superior performance on novel classes compared to the other state-of-the-art methods.","sentences":["Open-vocabulary object detection (OVOD) aims to recognize novel objects whose categories are not included in training set.","In order to classify these unseen classes during training, many OVOD frameworks leverage the zero-shot capability of largely pretrained vision and language models, such as CLIP.","To further improve generalization on the unseen novel classes, several approaches proposed to additionally train with pseudo region labeling on the external data sources that contain a substantial number of novel category labels beyond the existing training data.","Albeit its simplicity, these pseudo-labeling methods still exhibit limited improvement with regard to the genuine novel classes that were not pseudo-labeled.","In this paper, we present a novel, yet simple technique that helps generalization on the overall distribution of novel classes.","Inspired by our observation that numerous novel classes reside within the convex hull constructed by the base (seen) classes in the CLIP embedding space, we propose to synthesize proxy-novel classes approximating novel classes via linear mixup between a pair of base classes.","By training our detector with these synthetic proxy-novel classes, we effectively explore the embedding space of novel classes.","The experimental results on various OVOD benchmarks such as LVIS and COCO demonstrate superior performance on novel classes compared to the other state-of-the-art methods."],"url":"http://arxiv.org/abs/2312.07266v1"}
{"created":"2023-12-12 13:28:53","title":"Identifying Drivers of Predictive Uncertainty using Variance Feature Attribution","abstract":"Explainability and uncertainty quantification are two pillars of trustable artificial intelligence. However, the reasoning behind uncertainty estimates is generally left unexplained. Identifying the drivers of uncertainty complements explanations of point predictions in recognizing potential model limitations. It facilitates the detection of oversimplification in the uncertainty estimation process. Explanations of uncertainty enhance communication and trust in decisions. They allow for verifying whether the main drivers of model uncertainty are relevant and may impact model usage. So far, the subject of explaining uncertainties has been rarely studied. The few exceptions in existing literature are tailored to Bayesian neural networks or rely heavily on technically intricate approaches, hindering their broad adoption. We propose variance feature attribution, a simple and scalable solution to explain predictive aleatoric uncertainties. First, we estimate uncertainty as predictive variance by equipping a neural network with a Gaussian output distribution by adding a variance output neuron. Thereby, we can rely on pre-trained point prediction models and fine-tune them for meaningful variance estimation. Second, we apply out-of-the-box explainers on the variance output of these models to explain the uncertainty estimation. We evaluate our approach in a synthetic setting where the data-generating process is known. We show that our method can explain uncertainty influences more reliably and faster than the established baseline CLUE. We fine-tune a state-of-the-art age regression model to estimate uncertainty and obtain attributions. Our explanations highlight potential sources of uncertainty, such as laugh lines. Variance feature attribution provides accurate explanations for uncertainty estimates with little modifications to the model architecture and low computational overhead.","sentences":["Explainability and uncertainty quantification are two pillars of trustable artificial intelligence.","However, the reasoning behind uncertainty estimates is generally left unexplained.","Identifying the drivers of uncertainty complements explanations of point predictions in recognizing potential model limitations.","It facilitates the detection of oversimplification in the uncertainty estimation process.","Explanations of uncertainty enhance communication and trust in decisions.","They allow for verifying whether the main drivers of model uncertainty are relevant and may impact model usage.","So far, the subject of explaining uncertainties has been rarely studied.","The few exceptions in existing literature are tailored to Bayesian neural networks or rely heavily on technically intricate approaches, hindering their broad adoption.","We propose variance feature attribution, a simple and scalable solution to explain predictive aleatoric uncertainties.","First, we estimate uncertainty as predictive variance by equipping a neural network with a Gaussian output distribution by adding a variance output neuron.","Thereby, we can rely on pre-trained point prediction models and fine-tune them for meaningful variance estimation.","Second, we apply out-of-the-box explainers on the variance output of these models to explain the uncertainty estimation.","We evaluate our approach in a synthetic setting where the data-generating process is known.","We show that our method can explain uncertainty influences more reliably and faster than the established baseline CLUE.","We fine-tune a state-of-the-art age regression model to estimate uncertainty and obtain attributions.","Our explanations highlight potential sources of uncertainty, such as laugh lines.","Variance feature attribution provides accurate explanations for uncertainty estimates with little modifications to the model architecture and low computational overhead."],"url":"http://arxiv.org/abs/2312.07252v1"}
{"created":"2023-12-12 13:26:42","title":"Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning","abstract":"We conduct investigations on clinical text machine translation by examining multilingual neural network models using deep learning such as Transformer based structures. Furthermore, to address the language resource imbalance issue, we also carry out experiments using a transfer learning methodology based on massive multilingual pre-trained language models (MMPLMs). The experimental results on three subtasks including 1) clinical case (CC), 2) clinical terminology (CT), and 3) ontological concept (OC) show that our models achieved top-level performances in the ClinSpEn-2022 shared task on English-Spanish clinical domain data. Furthermore, our expert-based human evaluations demonstrate that the small-sized pre-trained language model (PLM) won over the other two extra-large language models by a large margin, in the clinical domain fine-tuning, which finding was never reported in the field. Finally, the transfer learning method works well in our experimental setting using the WMT21fb model to accommodate a new language space Spanish that was not seen at the pre-training stage within WMT21fb itself, which deserves more exploitation for clinical knowledge transformation, e.g. to investigate into more languages. These research findings can shed some light on domain-specific machine translation development, especially in clinical and healthcare fields. Further research projects can be carried out based on our work to improve healthcare text analytics and knowledge transformation.","sentences":["We conduct investigations on clinical text machine translation by examining multilingual neural network models using deep learning such as Transformer based structures.","Furthermore, to address the language resource imbalance issue, we also carry out experiments using a transfer learning methodology based on massive multilingual pre-trained language models (MMPLMs).","The experimental results on three subtasks including 1) clinical case (CC), 2) clinical terminology (CT), and 3) ontological concept (OC) show that our models achieved top-level performances in the ClinSpEn-2022 shared task on English-Spanish clinical domain data.","Furthermore, our expert-based human evaluations demonstrate that the small-sized pre-trained language model (PLM) won over the other two extra-large language models by a large margin, in the clinical domain fine-tuning, which finding was never reported in the field.","Finally, the transfer learning method works well in our experimental setting using the WMT21fb model to accommodate a new language space Spanish that was not seen at the pre-training stage within WMT21fb itself, which deserves more exploitation for clinical knowledge transformation, e.g. to investigate into more languages.","These research findings can shed some light on domain-specific machine translation development, especially in clinical and healthcare fields.","Further research projects can be carried out based on our work to improve healthcare text analytics and knowledge transformation."],"url":"http://arxiv.org/abs/2312.07250v1"}
{"created":"2023-12-12 13:25:32","title":"Multi-Granularity Framework for Unsupervised Representation Learning of Time Series","abstract":"Representation learning plays a critical role in the analysis of time series data and has high practical value across a wide range of applications. including trend analysis, time series data retrieval and forecasting. In practice, data confusion is a significant issue as it can considerably impact the effectiveness and accuracy of data analysis, machine learning models and decision-making processes. In general, previous studies did not consider the variability at various levels of granularity, thus resulting in inadequate information utilization, which further exacerbated the issue of data confusion. This paper proposes an unsupervised framework to realize multi-granularity representation learning for time series. Specifically, we employed a cross-granularity transformer to develop an association between fine- and coarse-grained representations. In addition, we introduced a retrieval task as an unsupervised training task to learn the multi-granularity representation of time series. Moreover, a novel loss function was designed to obtain the comprehensive multi-granularity representation of the time series via unsupervised learning. The experimental results revealed that the proposed framework demonstrates significant advantages over alternative representation learning models.","sentences":["Representation learning plays a critical role in the analysis of time series data and has high practical value across a wide range of applications.","including trend analysis, time series data retrieval and forecasting.","In practice, data confusion is a significant issue as it can considerably impact the effectiveness and accuracy of data analysis, machine learning models and decision-making processes.","In general, previous studies did not consider the variability at various levels of granularity, thus resulting in inadequate information utilization, which further exacerbated the issue of data confusion.","This paper proposes an unsupervised framework to realize multi-granularity representation learning for time series.","Specifically, we employed a cross-granularity transformer to develop an association between fine- and coarse-grained representations.","In addition, we introduced a retrieval task as an unsupervised training task to learn the multi-granularity representation of time series.","Moreover, a novel loss function was designed to obtain the comprehensive multi-granularity representation of the time series via unsupervised learning.","The experimental results revealed that the proposed framework demonstrates significant advantages over alternative representation learning models."],"url":"http://arxiv.org/abs/2312.07248v1"}
{"created":"2023-12-12 12:29:18","title":"Learning from Interaction: User Interface Adaptation using Reinforcement Learning","abstract":"The continuous adaptation of software systems to meet the evolving needs of users is very important for enhancing user experience (UX). User interface (UI) adaptation, which involves adjusting the layout, navigation, and content presentation based on user preferences and contextual conditions, plays an important role in achieving this goal. However, suggesting the right adaptation at the right time and in the right place remains a challenge in order to make it valuable for the end-user. To tackle this challenge, machine learning approaches could be used. In particular, we are using Reinforcement Learning (RL) due to its ability to learn from interaction with the users. In this approach, the feedback is very important and the use of physiological data could be benefitial to obtain objective insights into how users are reacting to the different adaptations. Thus, in this PhD thesis, we propose an RL-based UI adaptation framework that uses physiological data. The framework aims to learn from user interactions and make informed adaptations to improve UX. To this end, our research aims to answer the following questions: Does the use of an RL-based approach improve UX? How effective is RL in guiding UI adaptation? and Can physiological data support UI adaptation for enhancing UX? The evaluation plan involves conducting user studies to evaluate answer these questions. The empirical evaluation will provide a strong empirical foundation for building, evaluating, and improving the proposed adaptation framework. The expected contributions of this research include the development of a novel framework for intelligent Adaptive UIs, insights into the effectiveness of RL algorithms in guiding UI adaptation, the integration of physiological data as objective measures of UX, and empirical validation of the proposed framework's impact on UX.","sentences":["The continuous adaptation of software systems to meet the evolving needs of users is very important for enhancing user experience (UX).","User interface (UI) adaptation, which involves adjusting the layout, navigation, and content presentation based on user preferences and contextual conditions, plays an important role in achieving this goal.","However, suggesting the right adaptation at the right time and in the right place remains a challenge in order to make it valuable for the end-user.","To tackle this challenge, machine learning approaches could be used.","In particular, we are using Reinforcement Learning (RL) due to its ability to learn from interaction with the users.","In this approach, the feedback is very important and the use of physiological data could be benefitial to obtain objective insights into how users are reacting to the different adaptations.","Thus, in this PhD thesis, we propose an RL-based UI adaptation framework that uses physiological data.","The framework aims to learn from user interactions and make informed adaptations to improve UX.","To this end, our research aims to answer the following questions: Does the use of an RL-based approach improve UX?","How effective is RL in guiding UI adaptation?","and Can physiological data support UI adaptation for enhancing UX?","The evaluation plan involves conducting user studies to evaluate answer these questions.","The empirical evaluation will provide a strong empirical foundation for building, evaluating, and improving the proposed adaptation framework.","The expected contributions of this research include the development of a novel framework for intelligent Adaptive UIs, insights into the effectiveness of RL algorithms in guiding UI adaptation, the integration of physiological data as objective measures of UX, and empirical validation of the proposed framework's impact on UX."],"url":"http://arxiv.org/abs/2312.07216v1"}
{"created":"2023-12-12 12:21:08","title":"Experimental Investigation of Machine Learning based Soft-Failure Management using the Optical Spectrum","abstract":"The demand for high-speed data is exponentially growing. To conquer this, optical networks underwent significant changes getting more complex and versatile. The increasing complexity necessitates the fault management to be more adaptive to enhance network assurance. In this paper, we experimentally compare the performance of soft-failure management of different machine learning algorithms. We further introduce a machine-learning based soft-failure management framework. It utilizes a variational autoencoder based generative adversarial network (VAE-GAN) running on optical spectral data obtained by optical spectrum analyzers. The framework is able to reliably run on a fraction of available training data as well as identifying unknown failure types. The investigations show, that the VAE-GAN outperforms the other machine learning algorithms when up to 10\\% of the total training data is available in identification tasks. Furthermore, the advanced training mechanism for the GAN shows a high F1-score for unknown spectrum identification. The failure localization comparison shows the advantage of a low complexity neural network in combination with a VAE over established machine learning algorithms.","sentences":["The demand for high-speed data is exponentially growing.","To conquer this, optical networks underwent significant changes getting more complex and versatile.","The increasing complexity necessitates the fault management to be more adaptive to enhance network assurance.","In this paper, we experimentally compare the performance of soft-failure management of different machine learning algorithms.","We further introduce a machine-learning based soft-failure management framework.","It utilizes a variational autoencoder based generative adversarial network (VAE-GAN) running on optical spectral data obtained by optical spectrum analyzers.","The framework is able to reliably run on a fraction of available training data as well as identifying unknown failure types.","The investigations show, that the VAE-GAN outperforms the other machine learning algorithms when up to 10\\% of the total training data is available in identification tasks.","Furthermore, the advanced training mechanism for the GAN shows a high F1-score for unknown spectrum identification.","The failure localization comparison shows the advantage of a low complexity neural network in combination with a VAE over established machine learning algorithms."],"url":"http://arxiv.org/abs/2312.07208v1"}
{"created":"2023-12-12 12:19:13","title":"A churn prediction dataset from the telecom sector: a new benchmark for uplift modeling","abstract":"Uplift modeling, also known as individual treatment effect (ITE) estimation, is an important approach for data-driven decision making that aims to identify the causal impact of an intervention on individuals. This paper introduces a new benchmark dataset for uplift modeling focused on churn prediction, coming from a telecom company in Belgium, Orange Belgium. Churn, in this context, refers to customers terminating their subscription to the telecom service. This is the first publicly available dataset offering the possibility to evaluate the efficiency of uplift modeling on the churn prediction problem. Moreover, its unique characteristics make it more challenging than the few other public uplift datasets.","sentences":["Uplift modeling, also known as individual treatment effect (ITE) estimation, is an important approach for data-driven decision making that aims to identify the causal impact of an intervention on individuals.","This paper introduces a new benchmark dataset for uplift modeling focused on churn prediction, coming from a telecom company in Belgium, Orange Belgium.","Churn, in this context, refers to customers terminating their subscription to the telecom service.","This is the first publicly available dataset offering the possibility to evaluate the efficiency of uplift modeling on the churn prediction problem.","Moreover, its unique characteristics make it more challenging than the few other public uplift datasets."],"url":"http://arxiv.org/abs/2312.07206v1"}
{"created":"2023-12-12 12:07:54","title":"Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models","abstract":"Code pre-trained language models (CPLMs) have received great attention since they can benefit various tasks that facilitate software development and maintenance. However, CPLMs are trained on massive open-source code, raising concerns about potential data infringement. This paper launches the first study of detecting unauthorized code use in CPLMs, i.e., Code Membership Inference (CMI) task. We design a framework Buzzer for different settings of CMI. Buzzer deploys several inference techniques, including distilling the target CPLM, ensemble inference, and unimodal and bimodal calibration. Extensive experiments show that CMI can be achieved with high accuracy using Buzzer. Hence, Buzzer can serve as a CMI tool and help protect intellectual property rights.","sentences":["Code pre-trained language models (CPLMs) have received great attention since they can benefit various tasks that facilitate software development and maintenance.","However, CPLMs are trained on massive open-source code, raising concerns about potential data infringement.","This paper launches the first study of detecting unauthorized code use in CPLMs, i.e., Code Membership Inference (CMI) task.","We design a framework Buzzer for different settings of CMI.","Buzzer deploys several inference techniques, including distilling the target CPLM, ensemble inference, and unimodal and bimodal calibration.","Extensive experiments show that CMI can be achieved with high accuracy using Buzzer.","Hence, Buzzer can serve as a CMI tool and help protect intellectual property rights."],"url":"http://arxiv.org/abs/2312.07200v1"}
{"created":"2023-12-12 11:18:56","title":"Instrumental Variable Estimation for Causal Inference in Longitudinal Data with Time-Dependent Latent Confounders","abstract":"Causal inference from longitudinal observational data is a challenging problem due to the difficulty in correctly identifying the time-dependent confounders, especially in the presence of latent time-dependent confounders. Instrumental variable (IV) is a powerful tool for addressing the latent confounders issue, but the traditional IV technique cannot deal with latent time-dependent confounders in longitudinal studies. In this work, we propose a novel Time-dependent Instrumental Factor Model (TIFM) for time-varying causal effect estimation from data with latent time-dependent confounders. At each time-step, the proposed TIFM method employs the Recurrent Neural Network (RNN) architecture to infer latent IV, and then uses the inferred latent IV factor for addressing the confounding bias caused by the latent time-dependent confounders. We provide a theoretical analysis for the proposed TIFM method regarding causal effect estimation in longitudinal data. Extensive evaluation with synthetic datasets demonstrates the effectiveness of TIFM in addressing causal effect estimation over time. We further apply TIFM to a climate dataset to showcase the potential of the proposed method in tackling real-world problems.","sentences":["Causal inference from longitudinal observational data is a challenging problem due to the difficulty in correctly identifying the time-dependent confounders, especially in the presence of latent time-dependent confounders.","Instrumental variable (IV) is a powerful tool for addressing the latent confounders issue, but the traditional IV technique cannot deal with latent time-dependent confounders in longitudinal studies.","In this work, we propose a novel Time-dependent Instrumental Factor Model (TIFM) for time-varying causal effect estimation from data with latent time-dependent confounders.","At each time-step, the proposed TIFM method employs the Recurrent Neural Network (RNN) architecture to infer latent IV, and then uses the inferred latent IV factor for addressing the confounding bias caused by the latent time-dependent confounders.","We provide a theoretical analysis for the proposed TIFM method regarding causal effect estimation in longitudinal data.","Extensive evaluation with synthetic datasets demonstrates the effectiveness of TIFM in addressing causal effect estimation over time.","We further apply TIFM to a climate dataset to showcase the potential of the proposed method in tackling real-world problems."],"url":"http://arxiv.org/abs/2312.07175v1"}
{"created":"2023-12-12 11:13:17","title":"Semi-supervised Active Learning for Video Action Detection","abstract":"In this work, we focus on label efficient learning for video action detection. We develop a novel semi-supervised active learning approach which utilizes both labeled as well as unlabeled data along with informative sample selection for action detection. Video action detection requires spatio-temporal localization along with classification, which poses several challenges for both active learning informative sample selection as well as semi-supervised learning pseudo label generation. First, we propose NoiseAug, a simple augmentation strategy which effectively selects informative samples for video action detection. Next, we propose fft-attention, a novel technique based on high-pass filtering which enables effective utilization of pseudo label for SSL in video action detection by emphasizing on relevant activity region within a video. We evaluate the proposed approach on three different benchmark datasets, UCF-101-24, JHMDB-21, and Youtube-VOS. First, we demonstrate its effectiveness on video action detection where the proposed approach outperforms prior works in semi-supervised and weakly-supervised learning along with several baseline approaches in both UCF101-24 and JHMDB-21. Next, we also show its effectiveness on Youtube-VOS for video object segmentation demonstrating its generalization capability for other dense prediction tasks in videos.","sentences":["In this work, we focus on label efficient learning for video action detection.","We develop a novel semi-supervised active learning approach which utilizes both labeled as well as unlabeled data along with informative sample selection for action detection.","Video action detection requires spatio-temporal localization along with classification, which poses several challenges for both active learning informative sample selection as well as semi-supervised learning pseudo label generation.","First, we propose NoiseAug, a simple augmentation strategy which effectively selects informative samples for video action detection.","Next, we propose fft-attention, a novel technique based on high-pass filtering which enables effective utilization of pseudo label for SSL in video action detection by emphasizing on relevant activity region within a video.","We evaluate the proposed approach on three different benchmark datasets, UCF-101-24, JHMDB-21, and Youtube-VOS.","First, we demonstrate its effectiveness on video action detection where the proposed approach outperforms prior works in semi-supervised and weakly-supervised learning along with several baseline approaches in both UCF101-24 and JHMDB-21.","Next, we also show its effectiveness on Youtube-VOS for video object segmentation demonstrating its generalization capability for other dense prediction tasks in videos."],"url":"http://arxiv.org/abs/2312.07169v1"}
{"created":"2023-12-12 11:03:51","title":"Language-Guided Transformer for Federated Multi-Label Classification","abstract":"Federated Learning (FL) is an emerging paradigm that enables multiple users to collaboratively train a robust model in a privacy-preserving manner without sharing their private data. Most existing approaches of FL only consider traditional single-label image classification, ignoring the impact when transferring the task to multi-label image classification. Nevertheless, it is still challenging for FL to deal with user heterogeneity in their local data distribution in the real-world FL scenario, and this issue becomes even more severe in multi-label image classification. Inspired by the recent success of Transformers in centralized settings, we propose a novel FL framework for multi-label classification. Since partial label correlation may be observed by local clients during training, direct aggregation of locally updated models would not produce satisfactory performances. Thus, we propose a novel FL framework of Language-Guided Transformer (FedLGT) to tackle this challenging task, which aims to exploit and transfer knowledge across different clients for learning a robust global model. Through extensive experiments on various multi-label datasets (e.g., FLAIR, MS-COCO, etc.), we show that our FedLGT is able to achieve satisfactory performance and outperforms standard FL techniques under multi-label FL scenarios. Code is available at https://github.com/Jack24658735/FedLGT.","sentences":["Federated Learning (FL) is an emerging paradigm that enables multiple users to collaboratively train a robust model in a privacy-preserving manner without sharing their private data.","Most existing approaches of FL only consider traditional single-label image classification, ignoring the impact when transferring the task to multi-label image classification.","Nevertheless, it is still challenging for FL to deal with user heterogeneity in their local data distribution in the real-world FL scenario, and this issue becomes even more severe in multi-label image classification.","Inspired by the recent success of Transformers in centralized settings, we propose a novel FL framework for multi-label classification.","Since partial label correlation may be observed by local clients during training, direct aggregation of locally updated models would not produce satisfactory performances.","Thus, we propose a novel FL framework of Language-Guided Transformer (FedLGT) to tackle this challenging task, which aims to exploit and transfer knowledge across different clients for learning a robust global model.","Through extensive experiments on various multi-label datasets (e.g., FLAIR, MS-COCO, etc.), we show that our FedLGT is able to achieve satisfactory performance and outperforms standard FL techniques under multi-label FL scenarios.","Code is available at https://github.com/Jack24658735/FedLGT."],"url":"http://arxiv.org/abs/2312.07165v1"}
{"created":"2023-12-12 10:55:34","title":"Audience Prospecting for Dynamic-Product-Ads in Native Advertising","abstract":"With yearly revenue exceeding one billion USD, Yahoo Gemini native advertising marketplace serves more than two billion impressions daily to hundreds of millions of unique users. One of the fastest growing segments of Gemini native is dynamic-product-ads (DPA), where major advertisers, such as Amazon and Walmart, provide catalogs with millions of products for the system to choose from and present to users. The subject of this work is finding and expanding the right audience for each DPA ad, which is one of the many challenges DPA presents. Approaches such as targeting various user groups, e.g., users who already visited the advertisers' websites (Retargeting), users that searched for certain products (Search-Prospecting), or users that reside in preferred locations (Location-Prospecting), have limited audience expansion capabilities. In this work we present two new approaches for audience expansion that also maintain predefined performance goals. The Conversion-Prospecting approach predicts DPA conversion rates based on Gemini native logged data, and calculates the expected cost-per-action (CPA) for determining users' eligibility to products and optimizing DPA bids in Gemini native auctions. To support new advertisers and products, the Trending-Prospecting approach matches trending products to users by learning their tendency towards products from advertisers' sites logged events. The tendency scores indicate the popularity of the product and the similarity of the user to those who have previously engaged with this product. The two new prospecting approaches were tested online, serving real Gemini native traffic, demonstrating impressive DPA delivery and DPA revenue lifts while maintaining most traffic within the acceptable CPA range (i.e., performance goal). After a successful testing phase, the proposed approaches are currently in production and serve all Gemini native traffic.","sentences":["With yearly revenue exceeding one billion USD, Yahoo Gemini native advertising marketplace serves more than two billion impressions daily to hundreds of millions of unique users.","One of the fastest growing segments of Gemini native is dynamic-product-ads (DPA), where major advertisers, such as Amazon and Walmart, provide catalogs with millions of products for the system to choose from and present to users.","The subject of this work is finding and expanding the right audience for each DPA ad, which is one of the many challenges DPA presents.","Approaches such as targeting various user groups, e.g., users who already visited the advertisers' websites (Retargeting), users that searched for certain products (Search-Prospecting), or users that reside in preferred locations (Location-Prospecting), have limited audience expansion capabilities.","In this work we present two new approaches for audience expansion that also maintain predefined performance goals.","The Conversion-Prospecting approach predicts DPA conversion rates based on Gemini native logged data, and calculates the expected cost-per-action (CPA) for determining users' eligibility to products and optimizing DPA bids in Gemini native auctions.","To support new advertisers and products, the Trending-Prospecting approach matches trending products to users by learning their tendency towards products from advertisers' sites logged events.","The tendency scores indicate the popularity of the product and the similarity of the user to those who have previously engaged with this product.","The two new prospecting approaches were tested online, serving real Gemini native traffic, demonstrating impressive DPA delivery and DPA revenue lifts while maintaining most traffic within the acceptable CPA range (i.e., performance goal).","After a successful testing phase, the proposed approaches are currently in production and serve all Gemini native traffic."],"url":"http://arxiv.org/abs/2312.07160v1"}
{"created":"2023-12-12 10:26:01","title":"The Parameterized Complexity of Coordinated Motion Planning","abstract":"In Coordinated Motion Planning (CMP), we are given a rectangular-grid on which $k$ robots occupy $k$ distinct starting gridpoints and need to reach $k$ distinct destination gridpoints. In each time step, any robot may move to a neighboring gridpoint or stay in its current gridpoint, provided that it does not collide with other robots. The goal is to compute a schedule for moving the $k$ robots to their destinations which minimizes a certain objective target - prominently the number of time steps in the schedule, i.e., the makespan, or the total length traveled by the robots. We refer to the problem arising from minimizing the former objective target as CMP-M and the latter as CMP-L. Both CMP-M and CMP-L are fundamental problems that were posed as the computational geometry challenge of SoCG 2021, and CMP also embodies the famous $(n^2-1)$-puzzle as a special case.   In this paper, we settle the parameterized complexity of CMP-M and CMP-L with respect to their two most fundamental parameters: the number of robots, and the objective target. We develop a new approach to establish the fixed-parameter tractability of both problems under the former parameterization that relies on novel structural insights into optimal solutions to the problem. When parameterized by the objective target, we show that CMP-L remains fixed-parameter tractable while CMP-M becomes para-NP-hard. The latter result is noteworthy, not only because it improves the previously-known boundaries of intractability for the problem, but also because the underlying reduction allows us to establish - as a simpler case - the NP-hardness of the classical Vertex Disjoint and Edge Disjoint Paths problems with constant path-lengths on grids.","sentences":["In Coordinated Motion Planning (CMP), we are given a rectangular-grid on which $k$ robots occupy $k$ distinct starting gridpoints and need to reach $k$ distinct destination gridpoints.","In each time step, any robot may move to a neighboring gridpoint or stay in its current gridpoint, provided that it does not collide with other robots.","The goal is to compute a schedule for moving the $k$ robots to their destinations which minimizes a certain objective target - prominently the number of time steps in the schedule, i.e., the makespan, or the total length traveled by the robots.","We refer to the problem arising from minimizing the former objective target as CMP-M and the latter as CMP-L. Both CMP-M and CMP-L are fundamental problems that were posed as the computational geometry challenge of SoCG 2021, and CMP also embodies the famous $(n^2-1)$-puzzle as a special case.   ","In this paper, we settle the parameterized complexity of CMP-M and CMP-L with respect to their two most fundamental parameters: the number of robots, and the objective target.","We develop a new approach to establish the fixed-parameter tractability of both problems under the former parameterization that relies on novel structural insights into optimal solutions to the problem.","When parameterized by the objective target, we show that CMP-L remains fixed-parameter tractable while CMP-M becomes para-NP-hard.","The latter result is noteworthy, not only because it improves the previously-known boundaries of intractability for the problem, but also because the underlying reduction allows us to establish - as a simpler case - the NP-hardness of the classical Vertex Disjoint and Edge Disjoint Paths problems with constant path-lengths on grids."],"url":"http://arxiv.org/abs/2312.07144v1"}
{"created":"2023-12-12 10:24:17","title":"Multilingual large language models leak human stereotypes across language boundaries","abstract":"Multilingual large language models have been increasingly popular for their proficiency in comprehending and generating text across various languages. Previous research has shown that the presence of stereotypes and biases in monolingual large language models can be attributed to the nature of their training data, which is collected from humans and reflects societal biases. Multilingual language models undergo the same training procedure as monolingual ones, albeit with training data sourced from various languages. This raises the question: do stereotypes present in one social context leak across languages within the model? In our work, we first define the term ``stereotype leakage'' and propose a framework for its measurement. With this framework, we investigate how stereotypical associations leak across four languages: English, Russian, Chinese, and Hindi. To quantify the stereotype leakage, we employ an approach from social psychology, measuring stereotypes via group-trait associations. We evaluate human stereotypes and stereotypical associations manifested in multilingual large language models such as mBERT, mT5, and ChatGPT. Our findings show a noticeable leakage of positive, negative, and non-polar associations across all languages. Notably, Hindi within multilingual models appears to be the most susceptible to influence from other languages, while Chinese is the least. Additionally, ChatGPT exhibits a better alignment with human scores than other models.","sentences":["Multilingual large language models have been increasingly popular for their proficiency in comprehending and generating text across various languages.","Previous research has shown that the presence of stereotypes and biases in monolingual large language models can be attributed to the nature of their training data, which is collected from humans and reflects societal biases.","Multilingual language models undergo the same training procedure as monolingual ones, albeit with training data sourced from various languages.","This raises the question: do stereotypes present in one social context leak across languages within the model?","In our work, we first define the term ``stereotype leakage'' and propose a framework for its measurement.","With this framework, we investigate how stereotypical associations leak across four languages: English, Russian, Chinese, and Hindi.","To quantify the stereotype leakage, we employ an approach from social psychology, measuring stereotypes via group-trait associations.","We evaluate human stereotypes and stereotypical associations manifested in multilingual large language models such as mBERT, mT5, and ChatGPT.","Our findings show a noticeable leakage of positive, negative, and non-polar associations across all languages.","Notably, Hindi within multilingual models appears to be the most susceptible to influence from other languages, while Chinese is the least.","Additionally, ChatGPT exhibits a better alignment with human scores than other models."],"url":"http://arxiv.org/abs/2312.07141v1"}
{"created":"2023-12-12 10:23:03","title":"Exploiting Automorphisms of Temporal Graphs for Fast Exploration and Rendezvous","abstract":"Temporal graphs are dynamic graphs where the edge set can change in each time step, while the vertex set stays the same. Exploration of temporal graphs whose snapshot in each time step is a connected graph, called connected temporal graphs, has been widely studied. In this paper, we extend the concept of graph automorphisms from static graphs to temporal graphs for the first time and show that symmetries enable faster exploration: We prove that a connected temporal graph with $n$ vertices and orbit number $r$ (i.e., $r$~is the number of automorphism orbits) can be explored in $O(r n^{1+\\epsilon})$ time steps, for any fixed $\\epsilon>0$. For $r=O(n^c)$ for constant $c<1$, this is a significant improvement over the known tight worst-case bound of $\\Theta(n^2)$ time steps for arbitrary connected temporal graphs. We also give two lower bounds for temporal exploration, showing that $\\Omega(n \\log n)$ time steps are required for some inputs with $r=O(1)$ and that $\\Omega(rn)$ time steps are required for some inputs for any $r$ with $1\\le r\\le n$.   Moreover, we show that the techniques we develop for fast exploration can be used to derive the following result for rendezvous: Two agents with different programs and without communication ability are placed by an adversary at arbitrary vertices and given full information about the connected temporal graph, except that they do not have consistent vertex labels. Then the two agents can meet at a common vertex after $O(n^{1+\\epsilon})$ time steps, for any constant $\\epsilon>0$. For some connected temporal graphs with the orbit number being a constant, we also present a complementary lower bound of $\\Omega(n\\log n)$ time steps.","sentences":["Temporal graphs are dynamic graphs where the edge set can change in each time step, while the vertex set stays the same.","Exploration of temporal graphs whose snapshot in each time step is a connected graph, called connected temporal graphs, has been widely studied.","In this paper, we extend the concept of graph automorphisms from static graphs to temporal graphs for the first time and show that symmetries enable faster exploration: We prove that a connected temporal graph with $n$ vertices and orbit number $r$ (i.e., $r$~is the number of automorphism orbits) can be explored in $O(r n^{1+\\epsilon})$ time steps, for any fixed $\\epsilon>0$. For $r=O(n^c)$ for constant $c<1$, this is a significant improvement over the known tight worst-case bound of $\\Theta(n^2)$ time steps for arbitrary connected temporal graphs.","We also give two lower bounds for temporal exploration, showing that $\\Omega(n \\log n)$ time steps are required for some inputs with $r=O(1)$ and that $\\Omega(rn)$ time steps are required for some inputs for any $r$ with $1\\le r\\le n$.   Moreover, we show that the techniques we develop for fast exploration can be used to derive the following result for rendezvous: Two agents with different programs and without communication ability are placed by an adversary at arbitrary vertices and given full information about the connected temporal graph, except that they do not have consistent vertex labels.","Then the two agents can meet at a common vertex after $O(n^{1+\\epsilon})$ time steps, for any constant $\\epsilon>0$. For some connected temporal graphs with the orbit number being a constant, we also present a complementary lower bound of $\\Omega(n\\log n)$ time steps."],"url":"http://arxiv.org/abs/2312.07140v1"}
{"created":"2023-12-12 10:20:04","title":"Practical considerations on using private sampling for synthetic data","abstract":"Artificial intelligence and data access are already mainstream. One of the main challenges when designing an artificial intelligence or disclosing content from a database is preserving the privacy of individuals who participate in the process. Differential privacy for synthetic data generation has received much attention due to the ability of preserving privacy while freely using the synthetic data. Private sampling is the first noise-free method to construct differentially private synthetic data with rigorous bounds for privacy and accuracy. However, this synthetic data generation method comes with constraints which seem unrealistic and not applicable for real-world datasets. In this paper, we provide an implementation of the private sampling algorithm and discuss the realism of its constraints in practical cases.","sentences":["Artificial intelligence and data access are already mainstream.","One of the main challenges when designing an artificial intelligence or disclosing content from a database is preserving the privacy of individuals who participate in the process.","Differential privacy for synthetic data generation has received much attention due to the ability of preserving privacy while freely using the synthetic data.","Private sampling is the first noise-free method to construct differentially private synthetic data with rigorous bounds for privacy and accuracy.","However, this synthetic data generation method comes with constraints which seem unrealistic and not applicable for real-world datasets.","In this paper, we provide an implementation of the private sampling algorithm and discuss the realism of its constraints in practical cases."],"url":"http://arxiv.org/abs/2312.07139v1"}
{"created":"2023-12-12 10:15:12","title":"Robust End-to-End Diarization with Domain Adaptive Training and Multi-Task Learning","abstract":"Due to the scarcity of publicly available diarization data, the model performance can be improved by training a single model with data from different domains. In this work, we propose to incorporate domain information to train a single end-to-end diarization model for multiple domains. First, we employ domain adaptive training with parameter-efficient adapters for on-the-fly model reconfiguration. Second, we introduce an auxiliary domain classification task to make the diarization model more domain-aware. For seen domains, the combination of our proposed methods reduces the absolute DER from 17.66% to 16.59% when compared with the baseline. During inference, adapters from ground-truth domains are not available for unseen domains. We demonstrate our model exhibits a stronger generalizability to unseen domains when adapters are removed. For two unseen domains, this improves the DER performance from 39.91% to 23.09% and 25.32% to 18.76% over the baseline, respectively.","sentences":["Due to the scarcity of publicly available diarization data, the model performance can be improved by training a single model with data from different domains.","In this work, we propose to incorporate domain information to train a single end-to-end diarization model for multiple domains.","First, we employ domain adaptive training with parameter-efficient adapters for on-the-fly model reconfiguration.","Second, we introduce an auxiliary domain classification task to make the diarization model more domain-aware.","For seen domains, the combination of our proposed methods reduces the absolute DER from 17.66% to 16.59% when compared with the baseline.","During inference, adapters from ground-truth domains are not available for unseen domains.","We demonstrate our model exhibits a stronger generalizability to unseen domains when adapters are removed.","For two unseen domains, this improves the DER performance from 39.91% to 23.09% and 25.32% to 18.76% over the baseline, respectively."],"url":"http://arxiv.org/abs/2312.07136v1"}
{"created":"2023-12-12 10:07:16","title":"Image Content Generation with Causal Reasoning","abstract":"The emergence of ChatGPT has once again sparked research in generative artificial intelligence (GAI). While people have been amazed by the generated results, they have also noticed the reasoning potential reflected in the generated textual content. However, this current ability for causal reasoning is primarily limited to the domain of language generation, such as in models like GPT-3. In visual modality, there is currently no equivalent research. Considering causal reasoning in visual content generation is significant. This is because visual information contains infinite granularity. Particularly, images can provide more intuitive and specific demonstrations for certain reasoning tasks, especially when compared to coarse-grained text. Hence, we propose a new image generation task called visual question answering with image (VQAI) and establish a dataset of the same name based on the classic \\textit{Tom and Jerry} animated series. Additionally, we develop a new paradigm for image generation to tackle the challenges of this task. Finally, we perform extensive experiments and analyses, including visualizations of the generated content and discussions on the potentials and limitations. The code and data are publicly available under the license of CC BY-NC-SA 4.0 for academic and non-commercial usage. The code and dataset are publicly available at: https://github.com/IEIT-AGI/MIX-Shannon/blob/main/projects/VQAI/lgd_vqai.md.","sentences":["The emergence of ChatGPT has once again sparked research in generative artificial intelligence (GAI).","While people have been amazed by the generated results, they have also noticed the reasoning potential reflected in the generated textual content.","However, this current ability for causal reasoning is primarily limited to the domain of language generation, such as in models like GPT-3.","In visual modality, there is currently no equivalent research.","Considering causal reasoning in visual content generation is significant.","This is because visual information contains infinite granularity.","Particularly, images can provide more intuitive and specific demonstrations for certain reasoning tasks, especially when compared to coarse-grained text.","Hence, we propose a new image generation task called visual question answering with image (VQAI) and establish a dataset of the same name based on the classic \\textit{Tom and Jerry} animated series.","Additionally, we develop a new paradigm for image generation to tackle the challenges of this task.","Finally, we perform extensive experiments and analyses, including visualizations of the generated content and discussions on the potentials and limitations.","The code and data are publicly available under the license of CC BY-NC-SA 4.0 for academic and non-commercial usage.","The code and dataset are publicly available at: https://github.com/IEIT-AGI/MIX-Shannon/blob/main/projects/VQAI/lgd_vqai.md."],"url":"http://arxiv.org/abs/2312.07132v1"}
{"created":"2023-12-12 10:04:43","title":"Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass the Censorship of Text-to-Image Generation Model","abstract":"Text-to-image generative models offer many innovative services but also raise ethical concerns due to their potential to generate unethical images. Most publicly available text-to-image models employ safety filters to prevent unintended generation intents. In this work, we introduce the Divide-and-Conquer Attack to circumvent the safety filters of state-of-the-art text-to-image models. Our attack leverages LLMs as agents for text transformation, creating adversarial prompts from sensitive ones. We have developed effective helper prompts that enable LLMs to break down sensitive drawing prompts into multiple harmless descriptions, allowing them to bypass safety filters while still generating sensitive images. This means that the latent harmful meaning only becomes apparent when all individual elements are drawn together. Our evaluation demonstrates that our attack successfully circumvents the closed-box safety filter of SOTA DALLE-3 integrated natively into ChatGPT to generate unethical images. This approach, which essentially uses LLM-generated adversarial prompts against GPT-4-assisted DALLE-3, is akin to using one's own spear to breach their shield. It could have more severe security implications than previous manual crafting or iterative model querying methods, and we hope it stimulates more attention towards similar efforts. Our code and data are available at: https://github.com/researchcode001/Divide-and-Conquer-Attack","sentences":["Text-to-image generative models offer many innovative services but also raise ethical concerns due to their potential to generate unethical images.","Most publicly available text-to-image models employ safety filters to prevent unintended generation intents.","In this work, we introduce the Divide-and-Conquer Attack to circumvent the safety filters of state-of-the-art text-to-image models.","Our attack leverages LLMs as agents for text transformation, creating adversarial prompts from sensitive ones.","We have developed effective helper prompts that enable LLMs to break down sensitive drawing prompts into multiple harmless descriptions, allowing them to bypass safety filters while still generating sensitive images.","This means that the latent harmful meaning only becomes apparent when all individual elements are drawn together.","Our evaluation demonstrates that our attack successfully circumvents the closed-box safety filter of SOTA DALLE-3 integrated natively into ChatGPT to generate unethical images.","This approach, which essentially uses LLM-generated adversarial prompts against GPT-4-assisted DALLE-3, is akin to using one's own spear to breach their shield.","It could have more severe security implications than previous manual crafting or iterative model querying methods, and we hope it stimulates more attention towards similar efforts.","Our code and data are available at: https://github.com/researchcode001/Divide-and-Conquer-Attack"],"url":"http://arxiv.org/abs/2312.07130v1"}
{"created":"2023-12-12 09:39:52","title":"Generating High-Resolution Regional Precipitation Using Conditional Diffusion Model","abstract":"Climate downscaling is a crucial technique within climate research, serving to project low-resolution (LR) climate data to higher resolutions (HR). Previous research has demonstrated the effectiveness of deep learning for downscaling tasks. However, most deep learning models for climate downscaling may not perform optimally for high scaling factors (i.e., 4x, 8x) due to their limited ability to capture the intricate details required for generating HR climate data. Furthermore, climate data behaves differently from image data, necessitating a nuanced approach when employing deep generative models. In response to these challenges, this paper presents a deep generative model for downscaling climate data, specifically precipitation on a regional scale. We employ a denoising diffusion probabilistic model (DDPM) conditioned on multiple LR climate variables. The proposed model is evaluated using precipitation data from the Community Earth System Model (CESM) v1.2.2 simulation. Our results demonstrate significant improvements over existing baselines, underscoring the effectiveness of the conditional diffusion model in downscaling climate data.","sentences":["Climate downscaling is a crucial technique within climate research, serving to project low-resolution (LR) climate data to higher resolutions (HR).","Previous research has demonstrated the effectiveness of deep learning for downscaling tasks.","However, most deep learning models for climate downscaling may not perform optimally for high scaling factors (i.e., 4x, 8x) due to their limited ability to capture the intricate details required for generating HR climate data.","Furthermore, climate data behaves differently from image data, necessitating a nuanced approach when employing deep generative models.","In response to these challenges, this paper presents a deep generative model for downscaling climate data, specifically precipitation on a regional scale.","We employ a denoising diffusion probabilistic model (DDPM) conditioned on multiple LR climate variables.","The proposed model is evaluated using precipitation data from the Community Earth System Model (CESM) v1.2.2 simulation.","Our results demonstrate significant improvements over existing baselines, underscoring the effectiveness of the conditional diffusion model in downscaling climate data."],"url":"http://arxiv.org/abs/2312.07112v1"}
{"created":"2023-12-12 09:39:03","title":"LLMs Perform Poorly at Concept Extraction in Cyber-security Research Literature","abstract":"The cybersecurity landscape evolves rapidly and poses threats to organizations. To enhance resilience, one needs to track the latest developments and trends in the domain. It has been demonstrated that standard bibliometrics approaches show their limits in such a fast-evolving domain. For this purpose, we use large language models (LLMs) to extract relevant knowledge entities from cybersecurity-related texts. We use a subset of arXiv preprints on cybersecurity as our data and compare different LLMs in terms of entity recognition (ER) and relevance. The results suggest that LLMs do not produce good knowledge entities that reflect the cybersecurity context, but our results show some potential for noun extractors. For this reason, we developed a noun extractor boosted with some statistical analysis to extract specific and relevant compound nouns from the domain. Later, we tested our model to identify trends in the LLM domain. We observe some limitations, but it offers promising results to monitor the evolution of emergent trends.","sentences":["The cybersecurity landscape evolves rapidly and poses threats to organizations.","To enhance resilience, one needs to track the latest developments and trends in the domain.","It has been demonstrated that standard bibliometrics approaches show their limits in such a fast-evolving domain.","For this purpose, we use large language models (LLMs) to extract relevant knowledge entities from cybersecurity-related texts.","We use a subset of arXiv preprints on cybersecurity as our data and compare different LLMs in terms of entity recognition (ER) and relevance.","The results suggest that LLMs do not produce good knowledge entities that reflect the cybersecurity context, but our results show some potential for noun extractors.","For this reason, we developed a noun extractor boosted with some statistical analysis to extract specific and relevant compound nouns from the domain.","Later, we tested our model to identify trends in the LLM domain.","We observe some limitations, but it offers promising results to monitor the evolution of emergent trends."],"url":"http://arxiv.org/abs/2312.07110v1"}
{"created":"2023-12-12 09:36:43","title":"A Progression Model of Software Engineering Goals, Challenges, and Practices in Start-Ups","abstract":"Context: Software start-ups are emerging as suppliers of innovation and software-intensive products. However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups. As a result, there is insufficient support for software engineering in the start-up context. Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups. Such data allows researchers to understand better how goals and challenges are related to practices. This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges. Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice. Method: We use a case survey method to gather first-hand, in-depth experiences from a large sample of software start-ups. We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis. Results: We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups. We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity). Thus, creating the progression model guiding software engineering efforts in start-ups. Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies. However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors.","sentences":["Context: Software start-ups are emerging as suppliers of innovation and software-intensive products.","However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups.","As a result, there is insufficient support for software engineering in the start-up context.","Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups.","Such data allows researchers to understand better how goals and challenges are related to practices.","This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges.","Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice.","Method: We use a case survey method to gather first-hand, in-depth experiences from a large sample of software start-ups.","We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis.","Results:","We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups.","We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity).","Thus, creating the progression model guiding software engineering efforts in start-ups.","Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies.","However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors."],"url":"http://arxiv.org/abs/2312.07106v1"}
{"created":"2023-12-12 09:33:03","title":"The Computational Complexity of Concise Hypersphere Classification","abstract":"Hypersphere classification is a classical and foundational method that can provide easy-to-process explanations for the classification of real-valued and binary data. However, obtaining an (ideally concise) explanation via hypersphere classification is much more difficult when dealing with binary data than real-valued data. In this paper, we perform the first complexity-theoretic study of the hypersphere classification problem for binary data. We use the fine-grained parameterized complexity paradigm to analyze the impact of structural properties that may be present in the input data as well as potential conciseness constraints. Our results include stronger lower bounds and new fixed-parameter algorithms for hypersphere classification of binary data, which can find an exact and concise explanation when one exists.","sentences":["Hypersphere classification is a classical and foundational method that can provide easy-to-process explanations for the classification of real-valued and binary data.","However, obtaining an (ideally concise) explanation via hypersphere classification is much more difficult when dealing with binary data than real-valued data.","In this paper, we perform the first complexity-theoretic study of the hypersphere classification problem for binary data.","We use the fine-grained parameterized complexity paradigm to analyze the impact of structural properties that may be present in the input data as well as potential conciseness constraints.","Our results include stronger lower bounds and new fixed-parameter algorithms for hypersphere classification of binary data, which can find an exact and concise explanation when one exists."],"url":"http://arxiv.org/abs/2312.07103v1"}
{"created":"2023-12-12 09:29:22","title":"Meta-survey on outlier and anomaly detection","abstract":"The impact of outliers and anomalies on model estimation and data processing is of paramount importance, as evidenced by the extensive body of research spanning various fields over several decades: thousands of research papers have been published on the subject. As a consequence, numerous reviews, surveys, and textbooks have sought to summarize the existing literature, encompassing a wide range of methods from both the statistical and data mining communities. While these endeavors to organize and summarize the research are invaluable, they face inherent challenges due to the pervasive nature of outliers and anomalies in all data-intensive applications, irrespective of the specific application field or scientific discipline. As a result, the resulting collection of papers remains voluminous and somewhat heterogeneous. To address the need for knowledge organization in this domain, this paper implements the first systematic meta-survey of general surveys and reviews on outlier and anomaly detection. Employing a classical systematic survey approach, the study collects nearly 500 papers using two specialized scientific search engines. From this comprehensive collection, a subset of 56 papers that claim to be general surveys on outlier detection is selected using a snowball search technique to enhance field coverage. A meticulous quality assessment phase further refines the selection to a subset of 25 high-quality general surveys. Using this curated collection, the paper investigates the evolution of the outlier detection field over a 20-year period, revealing emerging themes and methods. Furthermore, an analysis of the surveys sheds light on the survey writing practices adopted by scholars from different communities who have contributed to this field. Finally, the paper delves into several topics where consensus has emerged from the literature. These include taxonomies of outlier types, challenges posed by high-dimensional data, the importance of anomaly scores, the impact of learning conditions, difficulties in benchmarking, and the significance of neural networks. Non-consensual aspects are also discussed, particularly the distinction between local and global outliers and the challenges in organizing detection methods into meaningful taxonomies.","sentences":["The impact of outliers and anomalies on model estimation and data processing is of paramount importance, as evidenced by the extensive body of research spanning various fields over several decades: thousands of research papers have been published on the subject.","As a consequence, numerous reviews, surveys, and textbooks have sought to summarize the existing literature, encompassing a wide range of methods from both the statistical and data mining communities.","While these endeavors to organize and summarize the research are invaluable, they face inherent challenges due to the pervasive nature of outliers and anomalies in all data-intensive applications, irrespective of the specific application field or scientific discipline.","As a result, the resulting collection of papers remains voluminous and somewhat heterogeneous.","To address the need for knowledge organization in this domain, this paper implements the first systematic meta-survey of general surveys and reviews on outlier and anomaly detection.","Employing a classical systematic survey approach, the study collects nearly 500 papers using two specialized scientific search engines.","From this comprehensive collection, a subset of 56 papers that claim to be general surveys on outlier detection is selected using a snowball search technique to enhance field coverage.","A meticulous quality assessment phase further refines the selection to a subset of 25 high-quality general surveys.","Using this curated collection, the paper investigates the evolution of the outlier detection field over a 20-year period, revealing emerging themes and methods.","Furthermore, an analysis of the surveys sheds light on the survey writing practices adopted by scholars from different communities who have contributed to this field.","Finally, the paper delves into several topics where consensus has emerged from the literature.","These include taxonomies of outlier types, challenges posed by high-dimensional data, the importance of anomaly scores, the impact of learning conditions, difficulties in benchmarking, and the significance of neural networks.","Non-consensual aspects are also discussed, particularly the distinction between local and global outliers and the challenges in organizing detection methods into meaningful taxonomies."],"url":"http://arxiv.org/abs/2312.07101v1"}
{"created":"2023-12-12 09:18:53","title":"Scaling a Variant Calling Genomics Pipeline with FaaS","abstract":"With the escalating complexity and volume of genomic data, the capacity of biology institutions' HPC faces limitations. While the Cloud presents a viable solution for short-term elasticity, its intricacies pose challenges for bioinformatics users. Alternatively, serverless computing allows for workload scalability with minimal developer burden. However, porting a scientific application to serverless is not a straightforward process. In this article, we present a Variant Calling genomics pipeline migrated from single-node HPC to a serverless architecture. We describe the inherent challenges of this approach and the engineering efforts required to achieve scalability. We contribute by open-sourcing the pipeline for future systems research and as a scalable user-friendly tool for the bioinformatics community.","sentences":["With the escalating complexity and volume of genomic data, the capacity of biology institutions' HPC faces limitations.","While the Cloud presents a viable solution for short-term elasticity, its intricacies pose challenges for bioinformatics users.","Alternatively, serverless computing allows for workload scalability with minimal developer burden.","However, porting a scientific application to serverless is not a straightforward process.","In this article, we present a Variant Calling genomics pipeline migrated from single-node HPC to a serverless architecture.","We describe the inherent challenges of this approach and the engineering efforts required to achieve scalability.","We contribute by open-sourcing the pipeline for future systems research and as a scalable user-friendly tool for the bioinformatics community."],"url":"http://arxiv.org/abs/2312.07090v1"}
{"created":"2023-12-12 09:14:55","title":"BED: Bi-Encoder-Decoder Model for Canonical Relation Extraction","abstract":"Canonical relation extraction aims to extract relational triples from sentences, where the triple elements (entity pairs and their relationship) are mapped to the knowledge base. Recently, methods based on the encoder-decoder architecture are proposed and achieve promising results. However, these methods cannot well utilize the entity information, which is merely used as augmented training data. Moreover, they are incapable of representing novel entities, since no embeddings have been learned for them. In this paper, we propose a novel framework, Bi-Encoder-Decoder (BED), to solve the above issues. Specifically, to fully utilize entity information, we employ an encoder to encode semantics of this information, leading to high-quality entity representations. For novel entities, given a trained entity encoder, their representations can be easily generated. Experimental results on two datasets show that, our method achieves a significant performance improvement over the previous state-of-the-art and handle novel entities well without retraining.","sentences":["Canonical relation extraction aims to extract relational triples from sentences, where the triple elements (entity pairs and their relationship) are mapped to the knowledge base.","Recently, methods based on the encoder-decoder architecture are proposed and achieve promising results.","However, these methods cannot well utilize the entity information, which is merely used as augmented training data.","Moreover, they are incapable of representing novel entities, since no embeddings have been learned for them.","In this paper, we propose a novel framework, Bi-Encoder-Decoder (BED), to solve the above issues.","Specifically, to fully utilize entity information, we employ an encoder to encode semantics of this information, leading to high-quality entity representations.","For novel entities, given a trained entity encoder, their representations can be easily generated.","Experimental results on two datasets show that, our method achieves a significant performance improvement over the previous state-of-the-art and handle novel entities well without retraining."],"url":"http://arxiv.org/abs/2312.07088v1"}
{"created":"2023-12-12 09:09:45","title":"Toward Robustness in Multi-label Classification: A Data Augmentation Strategy against Imbalance and Noise","abstract":"Multi-label classification poses challenges due to imbalanced and noisy labels in training data. We propose a unified data augmentation method, named BalanceMix, to address these challenges. Our approach includes two samplers for imbalanced labels, generating minority-augmented instances with high diversity. It also refines multi-labels at the label-wise granularity, categorizing noisy labels as clean, re-labeled, or ambiguous for robust optimization. Extensive experiments on three benchmark datasets demonstrate that BalanceMix outperforms existing state-of-the-art methods. We release the code at https://github.com/DISL-Lab/BalanceMix.","sentences":["Multi-label classification poses challenges due to imbalanced and noisy labels in training data.","We propose a unified data augmentation method, named BalanceMix, to address these challenges.","Our approach includes two samplers for imbalanced labels, generating minority-augmented instances with high diversity.","It also refines multi-labels at the label-wise granularity, categorizing noisy labels as clean, re-labeled, or ambiguous for robust optimization.","Extensive experiments on three benchmark datasets demonstrate that BalanceMix outperforms existing state-of-the-art methods.","We release the code at https://github.com/DISL-Lab/BalanceMix."],"url":"http://arxiv.org/abs/2312.07087v1"}
{"created":"2023-12-12 08:43:20","title":"Context Matter: Data-Efficient Augmentation of Large Language Models for Scientific Applications","abstract":"In this paper, we explore the challenges inherent to Large Language Models (LLMs) like GPT-4, particularly their propensity for hallucinations, logic mistakes, and incorrect conclusions when tasked with answering complex questions. The capacity of LLMs to present erroneous answers in a coherent and semantically rigorous manner further complicates the detection of factual inaccuracies. This issue is especially pronounced in fields that require specialized expertise. Our work delves into these challenges, aiming to enhance the understanding and mitigation of such errors, thereby contributing to the improvement of LLM accuracy and reliability in scientific and other specialized domains. Our findings reveal a non-linear relationship between the context's relevancy and the answers' measured quality. In addition, we demonstrate that with the correct calibration, it is possible to automate the grading procedure -- a finding suggesting that, at least to some degree, the LLMs can be used to self-examine the quality of their own performance. Finally, we describe an experimental platform that can be seen as a proof-of-concept of the techniques described in this work.","sentences":["In this paper, we explore the challenges inherent to Large Language Models (LLMs) like GPT-4, particularly their propensity for hallucinations, logic mistakes, and incorrect conclusions when tasked with answering complex questions.","The capacity of LLMs to present erroneous answers in a coherent and semantically rigorous manner further complicates the detection of factual inaccuracies.","This issue is especially pronounced in fields that require specialized expertise.","Our work delves into these challenges, aiming to enhance the understanding and mitigation of such errors, thereby contributing to the improvement of LLM accuracy and reliability in scientific and other specialized domains.","Our findings reveal a non-linear relationship between the context's relevancy and the answers' measured quality.","In addition, we demonstrate that with the correct calibration, it is possible to automate the grading procedure -- a finding suggesting that, at least to some degree, the LLMs can be used to self-examine the quality of their own performance.","Finally, we describe an experimental platform that can be seen as a proof-of-concept of the techniques described in this work."],"url":"http://arxiv.org/abs/2312.07069v1"}
{"created":"2023-12-12 08:33:34","title":"Efficient Cross-Domain Federated Learning by MixStyle Approximation","abstract":"With the advent of interconnected and sensor-equipped edge devices, Federated Learning (FL) has gained significant attention, enabling decentralized learning while maintaining data privacy. However, FL faces two challenges in real-world tasks: expensive data labeling and domain shift between source and target samples. In this paper, we introduce a privacy-preserving, resource-efficient FL concept for client adaptation in hardware-constrained environments. Our approach includes server model pre-training on source data and subsequent fine-tuning on target data via low-end clients. The local client adaptation process is streamlined by probabilistic mixing of instance-level feature statistics approximated from source and target domain data. The adapted parameters are transferred back to the central server and globally aggregated. Preliminary results indicate that our method reduces computational and transmission costs while maintaining competitive performance on downstream tasks.","sentences":["With the advent of interconnected and sensor-equipped edge devices, Federated Learning (FL) has gained significant attention, enabling decentralized learning while maintaining data privacy.","However, FL faces two challenges in real-world tasks: expensive data labeling and domain shift between source and target samples.","In this paper, we introduce a privacy-preserving, resource-efficient FL concept for client adaptation in hardware-constrained environments.","Our approach includes server model pre-training on source data and subsequent fine-tuning on target data via low-end clients.","The local client adaptation process is streamlined by probabilistic mixing of instance-level feature statistics approximated from source and target domain data.","The adapted parameters are transferred back to the central server and globally aggregated.","Preliminary results indicate that our method reduces computational and transmission costs while maintaining competitive performance on downstream tasks."],"url":"http://arxiv.org/abs/2312.07064v1"}
{"created":"2023-12-12 08:32:55","title":"Template Free Reconstruction of Human-object Interaction with Procedural Interaction Generation","abstract":"Reconstructing human-object interaction in 3D from a single RGB image is a challenging task and existing data driven methods do not generalize beyond the objects present in the carefully curated 3D interaction datasets. Capturing large-scale real data to learn strong interaction and 3D shape priors is very expensive due to the combinatorial nature of human-object interactions. In this paper, we propose ProciGen (Procedural interaction Generation), a method to procedurally generate datasets with both, plausible interaction and diverse object variation. We generate 1M+ human-object interaction pairs in 3D and leverage this large-scale data to train our HDM (Hierarchical Diffusion Model), a novel method to reconstruct interacting human and unseen objects, without any templates. Our HDM is an image-conditioned diffusion model that learns both realistic interaction and highly accurate human and object shapes. Experiments show that our HDM trained with ProciGen significantly outperforms prior methods that requires template meshes and that our dataset allows training methods with strong generalization ability to unseen object instances. Our code and data will be publicly released at: https://virtualhumans.mpi-inf.mpg.de/procigen-hdm.","sentences":["Reconstructing human-object interaction in 3D from a single RGB image is a challenging task and existing data driven methods do not generalize beyond the objects present in the carefully curated 3D interaction datasets.","Capturing large-scale real data to learn strong interaction and 3D shape priors is very expensive due to the combinatorial nature of human-object interactions.","In this paper, we propose ProciGen (Procedural interaction Generation), a method to procedurally generate datasets with both, plausible interaction and diverse object variation.","We generate 1M+ human-object interaction pairs in 3D and leverage this large-scale data to train our HDM (Hierarchical Diffusion Model), a novel method to reconstruct interacting human and unseen objects, without any templates.","Our HDM is an image-conditioned diffusion model that learns both realistic interaction and highly accurate human and object shapes.","Experiments show that our HDM trained with ProciGen significantly outperforms prior methods that requires template meshes and that our dataset allows training methods with strong generalization ability to unseen object instances.","Our code and data will be publicly released at: https://virtualhumans.mpi-inf.mpg.de/procigen-hdm."],"url":"http://arxiv.org/abs/2312.07063v1"}
{"created":"2023-12-12 08:26:20","title":"LSTM-CNN Network for Audio Signature Analysis in Noisy Environments","abstract":"There are multiple applications to automatically count people and specify their gender at work, exhibitions, malls, sales, and industrial usage. Although current speech detection methods are supposed to operate well, in most situations, in addition to genders, the number of current speakers is unknown and the classification methods are not suitable due to many possible classes. In this study, we focus on a long-short-term memory convolutional neural network (LSTM-CNN) to extract time and / or frequency-dependent features of the sound data to estimate the number / gender of simultaneous active speakers at each frame in noisy environments. Considering the maximum number of speakers as 10, we have utilized 19000 audio samples with diverse combinations of males, females, and background noise in public cities, industrial situations, malls, exhibitions, workplaces, and nature for learning purposes. This proof of concept shows promising performance with training/validation MSE values of about 0.019/0.017 in detecting count and gender.","sentences":["There are multiple applications to automatically count people and specify their gender at work, exhibitions, malls, sales, and industrial usage.","Although current speech detection methods are supposed to operate well, in most situations, in addition to genders, the number of current speakers is unknown and the classification methods are not suitable due to many possible classes.","In this study, we focus on a long-short-term memory convolutional neural network (LSTM-CNN) to extract time and / or frequency-dependent features of the sound data to estimate the number / gender of simultaneous active speakers at each frame in noisy environments.","Considering the maximum number of speakers as 10, we have utilized 19000 audio samples with diverse combinations of males, females, and background noise in public cities, industrial situations, malls, exhibitions, workplaces, and nature for learning purposes.","This proof of concept shows promising performance with training/validation MSE values of about 0.019/0.017 in detecting count and gender."],"url":"http://arxiv.org/abs/2312.07059v1"}
{"created":"2023-12-12 08:12:18","title":"Communication Cost Reduction for Subgraph Counting under Local Differential Privacy via Hash Functions","abstract":"We suggest the use of hash functions to cut down the communication costs when counting subgraphs under edge local differential privacy. While various algorithms exist for computing graph statistics, including the count of subgraphs, under the edge local differential privacy, many suffer with high communication costs, making them less efficient for large graphs. Though data compression is a typical approach in differential privacy, its application in local differential privacy requires a form of compression that every node can reproduce. In our study, we introduce linear congruence hashing. With a sampling rate of $s$, our method can cut communication costs by a factor of $s^2$, albeit at the cost of increasing variance in the published graph statistic by a factor of $s$. The experimental results indicate that, when matched for communication costs, our method achieves a reduction in the $\\ell_2$-error for triangle counts by up to 1000 times compared to the performance of leading algorithms.","sentences":["We suggest the use of hash functions to cut down the communication costs when counting subgraphs under edge local differential privacy.","While various algorithms exist for computing graph statistics, including the count of subgraphs, under the edge local differential privacy, many suffer with high communication costs, making them less efficient for large graphs.","Though data compression is a typical approach in differential privacy, its application in local differential privacy requires a form of compression that every node can reproduce.","In our study, we introduce linear congruence hashing.","With a sampling rate of $s$, our method can cut communication costs by a factor of $s^2$, albeit at the cost of increasing variance in the published graph statistic by a factor of $s$. The experimental results indicate that, when matched for communication costs, our method achieves a reduction in the $\\ell_2$-error for triangle counts by up to 1000 times compared to the performance of leading algorithms."],"url":"http://arxiv.org/abs/2312.07055v1"}
{"created":"2023-12-12 08:08:39","title":"Adjustable Robust Transformer for High Myopia Screening in Optical Coherence Tomography","abstract":"Myopia is a manifestation of visual impairment caused by an excessively elongated eyeball. Image data is critical material for studying high myopia and pathological myopia. Measurements of spherical equivalent and axial length are the gold standards for identifying high myopia, but the available image data for matching them is scarce. In addition, the criteria for defining high myopia vary from study to study, and therefore the inclusion of samples in automated screening efforts requires an appropriate assessment of interpretability. In this work, we propose a model called adjustable robust transformer (ARTran) for high myopia screening of optical coherence tomography (OCT) data. Based on vision transformer, we propose anisotropic patch embedding (APE) to capture more discriminative features of high myopia. To make the model effective under variable screening conditions, we propose an adjustable class embedding (ACE) to replace the fixed class token, which changes the output to adapt to different conditions. Considering the confusion of the data at high myopia and low myopia threshold, we introduce the label noise learning strategy and propose a shifted subspace transition matrix (SST) to enhance the robustness of the model. Besides, combining the two structures proposed above, the model can provide evidence for uncertainty evaluation. The experimental results demonstrate the effectiveness and reliability of the proposed method. Code is available at: https://github.com/maxiao0234/ARTran.","sentences":["Myopia is a manifestation of visual impairment caused by an excessively elongated eyeball.","Image data is critical material for studying high myopia and pathological myopia.","Measurements of spherical equivalent and axial length are the gold standards for identifying high myopia, but the available image data for matching them is scarce.","In addition, the criteria for defining high myopia vary from study to study, and therefore the inclusion of samples in automated screening efforts requires an appropriate assessment of interpretability.","In this work, we propose a model called adjustable robust transformer (ARTran) for high myopia screening of optical coherence tomography (OCT) data.","Based on vision transformer, we propose anisotropic patch embedding (APE) to capture more discriminative features of high myopia.","To make the model effective under variable screening conditions, we propose an adjustable class embedding (ACE) to replace the fixed class token, which changes the output to adapt to different conditions.","Considering the confusion of the data at high myopia and low myopia threshold, we introduce the label noise learning strategy and propose a shifted subspace transition matrix (SST) to enhance the robustness of the model.","Besides, combining the two structures proposed above, the model can provide evidence for uncertainty evaluation.","The experimental results demonstrate the effectiveness and reliability of the proposed method.","Code is available at: https://github.com/maxiao0234/ARTran."],"url":"http://arxiv.org/abs/2312.07052v1"}
{"created":"2023-12-12 08:08:34","title":"Mask as Supervision: Leveraging Unified Mask Information for Unsupervised 3D Pose Estimation","abstract":"Automatic estimation of 3D human pose from monocular RGB images is a challenging and unsolved problem in computer vision. In a supervised manner, approaches heavily rely on laborious annotations and present hampered generalization ability due to the limited diversity of 3D pose datasets. To address these challenges, we propose a unified framework that leverages mask as supervision for unsupervised 3D pose estimation. With general unsupervised segmentation algorithms, the proposed model employs skeleton and physique representations that exploit accurate pose information from coarse to fine. Compared with previous unsupervised approaches, we organize the human skeleton in a fully unsupervised way which enables the processing of annotation-free data and provides ready-to-use estimation results. Comprehensive experiments demonstrate our state-of-the-art pose estimation performance on Human3.6M and MPI-INF-3DHP datasets. Further experiments on in-the-wild datasets also illustrate the capability to access more data to boost our model. Code will be available at https://github.com/Charrrrrlie/Mask-as-Supervision.","sentences":["Automatic estimation of 3D human pose from monocular RGB images is a challenging and unsolved problem in computer vision.","In a supervised manner, approaches heavily rely on laborious annotations and present hampered generalization ability due to the limited diversity of 3D pose datasets.","To address these challenges, we propose a unified framework that leverages mask as supervision for unsupervised 3D pose estimation.","With general unsupervised segmentation algorithms, the proposed model employs skeleton and physique representations that exploit accurate pose information from coarse to fine.","Compared with previous unsupervised approaches, we organize the human skeleton in a fully unsupervised way which enables the processing of annotation-free data and provides ready-to-use estimation results.","Comprehensive experiments demonstrate our state-of-the-art pose estimation performance on Human3.6M and MPI-INF-3DHP datasets.","Further experiments on in-the-wild datasets also illustrate the capability to access more data to boost our model.","Code will be available at https://github.com/Charrrrrlie/Mask-as-Supervision."],"url":"http://arxiv.org/abs/2312.07051v1"}
{"created":"2023-12-12 08:02:06","title":"Improving Factual Error Correction by Learning to Inject Factual Errors","abstract":"Factual error correction (FEC) aims to revise factual errors in false claims with minimal editing, making them faithful to the provided evidence. This task is crucial for alleviating the hallucination problem encountered by large language models. Given the lack of paired data (i.e., false claims and their corresponding correct claims), existing methods typically adopt the mask-then-correct paradigm. This paradigm relies solely on unpaired false claims and correct claims, thus being referred to as distantly supervised methods. These methods require a masker to explicitly identify factual errors within false claims before revising with a corrector. However, the absence of paired data to train the masker makes accurately pinpointing factual errors within claims challenging. To mitigate this, we propose to improve FEC by Learning to Inject Factual Errors (LIFE), a three-step distantly supervised method: mask-corrupt-correct. Specifically, we first train a corruptor using the mask-then-corrupt procedure, allowing it to deliberately introduce factual errors into correct text. The corruptor is then applied to correct claims, generating a substantial amount of paired data. After that, we filter out low-quality data, and use the remaining data to train a corrector. Notably, our corrector does not require a masker, thus circumventing the bottleneck associated with explicit factual error identification. Our experiments on a public dataset verify the effectiveness of LIFE in two key aspects: Firstly, it outperforms the previous best-performing distantly supervised method by a notable margin of 10.59 points in SARI Final (19.3% improvement). Secondly, even compared to ChatGPT prompted with in-context examples, LIFE achieves a superiority of 7.16 points in SARI Final.","sentences":["Factual error correction (FEC) aims to revise factual errors in false claims with minimal editing, making them faithful to the provided evidence.","This task is crucial for alleviating the hallucination problem encountered by large language models.","Given the lack of paired data (i.e., false claims and their corresponding correct claims), existing methods typically adopt the mask-then-correct paradigm.","This paradigm relies solely on unpaired false claims and correct claims, thus being referred to as distantly supervised methods.","These methods require a masker to explicitly identify factual errors within false claims before revising with a corrector.","However, the absence of paired data to train the masker makes accurately pinpointing factual errors within claims challenging.","To mitigate this, we propose to improve FEC by Learning to Inject Factual Errors (LIFE), a three-step distantly supervised method: mask-corrupt-correct.","Specifically, we first train a corruptor using the mask-then-corrupt procedure, allowing it to deliberately introduce factual errors into correct text.","The corruptor is then applied to correct claims, generating a substantial amount of paired data.","After that, we filter out low-quality data, and use the remaining data to train a corrector.","Notably, our corrector does not require a masker, thus circumventing the bottleneck associated with explicit factual error identification.","Our experiments on a public dataset verify the effectiveness of LIFE in two key aspects: Firstly, it outperforms the previous best-performing distantly supervised method by a notable margin of 10.59 points in SARI Final (19.3% improvement).","Secondly, even compared to ChatGPT prompted with in-context examples, LIFE achieves a superiority of 7.16 points in SARI Final."],"url":"http://arxiv.org/abs/2312.07049v1"}
{"created":"2023-12-12 07:54:30","title":"The Complexity of Envy-Free Graph Cutting","abstract":"We consider the problem of fairly dividing a set of heterogeneous divisible resources among agents with different preferences. We focus on the setting where the resources correspond to the edges of a connected graph, every agent must be assigned a connected piece of this graph, and the fairness notion considered is the classical envy freeness. The problem is NP-complete, and we analyze its complexity with respect to two natural complexity measures: the number of agents and the number of edges in the graph. While the problem remains NP-hard even for instances with 2 agents, we provide a dichotomy characterizing the complexity of the problem when the number of agents is constant based on structural properties of the graph. For the latter case, we design a polynomial-time algorithm when the graph has a constant number of edges.","sentences":["We consider the problem of fairly dividing a set of heterogeneous divisible resources among agents with different preferences.","We focus on the setting where the resources correspond to the edges of a connected graph, every agent must be assigned a connected piece of this graph, and the fairness notion considered is the classical envy freeness.","The problem is NP-complete, and we analyze its complexity with respect to two natural complexity measures: the number of agents and the number of edges in the graph.","While the problem remains NP-hard even for instances with 2 agents, we provide a dichotomy characterizing the complexity of the problem when the number of agents is constant based on structural properties of the graph.","For the latter case, we design a polynomial-time algorithm when the graph has a constant number of edges."],"url":"http://arxiv.org/abs/2312.07043v1"}
{"created":"2023-12-12 07:52:35","title":"Patch-MI: Enhancing Model Inversion Attacks via Patch-Based Reconstruction","abstract":"Model inversion (MI) attacks aim to reveal sensitive information in training datasets by solely accessing model weights. Generative MI attacks, a prominent strand in this field, utilize auxiliary datasets to recreate target data attributes, restricting the images to remain photo-realistic, but their success often depends on the similarity between auxiliary and target datasets. If the distributions are dissimilar, existing MI attack attempts frequently fail, yielding unrealistic or target-unrelated results. In response to these challenges, we introduce a groundbreaking approach named Patch-MI, inspired by jigsaw puzzle assembly. To this end, we build upon a new probabilistic interpretation of MI attacks, employing a generative adversarial network (GAN)-like framework with a patch-based discriminator. This approach allows the synthesis of images that are similar to the target dataset distribution, even in cases of dissimilar auxiliary dataset distribution. Moreover, we artfully employ a random transformation block, a sophisticated maneuver that crafts generalized images, thus enhancing the efficacy of the target classifier. Our numerical and graphical findings demonstrate that Patch-MI surpasses existing generative MI methods in terms of accuracy, marking significant advancements while preserving comparable statistical dataset quality. For reproducibility of our results, we make our source code publicly available in https://github.com/jonggyujang0123/Patch-Attack.","sentences":["Model inversion (MI) attacks aim to reveal sensitive information in training datasets by solely accessing model weights.","Generative MI attacks, a prominent strand in this field, utilize auxiliary datasets to recreate target data attributes, restricting the images to remain photo-realistic, but their success often depends on the similarity between auxiliary and target datasets.","If the distributions are dissimilar, existing MI attack attempts frequently fail, yielding unrealistic or target-unrelated results.","In response to these challenges, we introduce a groundbreaking approach named Patch-MI, inspired by jigsaw puzzle assembly.","To this end, we build upon a new probabilistic interpretation of MI attacks, employing a generative adversarial network (GAN)-like framework with a patch-based discriminator.","This approach allows the synthesis of images that are similar to the target dataset distribution, even in cases of dissimilar auxiliary dataset distribution.","Moreover, we artfully employ a random transformation block, a sophisticated maneuver that crafts generalized images, thus enhancing the efficacy of the target classifier.","Our numerical and graphical findings demonstrate that Patch-MI surpasses existing generative MI methods in terms of accuracy, marking significant advancements while preserving comparable statistical dataset quality.","For reproducibility of our results, we make our source code publicly available in https://github.com/jonggyujang0123/Patch-Attack."],"url":"http://arxiv.org/abs/2312.07040v1"}
{"created":"2023-12-12 07:52:33","title":"Diff-OP3D: Bridging 2D Diffusion for Open Pose 3D Zero-Shot Classification","abstract":"With the explosive 3D data growth, the urgency of utilizing zero-shot learning to facilitate data labeling becomes evident. Recently, the methods via transferring Contrastive Language-Image Pre-training (CLIP) to 3D vision have made great progress in the 3D zero-shot classification task. However, these methods primarily focus on aligned pose 3D objects (ap-3os), overlooking the recognition of 3D objects with open poses (op-3os) typically encountered in real-world scenarios, such as an overturned chair or a lying teddy bear. To this end, we propose a more challenging benchmark for 3D open-pose zero-shot classification. Echoing our benchmark, we design a concise angle-refinement mechanism that automatically optimizes one ideal pose as well as classifies these op-3os. Furthermore, we make a first attempt to bridge 2D pre-trained diffusion model as a classifer to 3D zero-shot classification without any additional training. Such 2D diffusion to 3D objects proves vital in improving zero-shot classification for both ap-3os and op-3os. Our model notably improves by 3.5% and 15.8% on ModelNet10$^{\\ddag}$ and McGill$^{\\ddag}$ open pose benchmarks, respectively, and surpasses the current state-of-the-art by 6.8% on the aligned pose ModelNet10, affirming diffusion's efficacy in 3D zero-shot tasks.","sentences":["With the explosive 3D data growth, the urgency of utilizing zero-shot learning to facilitate data labeling becomes evident.","Recently, the methods via transferring Contrastive Language-Image Pre-training (CLIP) to 3D vision have made great progress in the 3D zero-shot classification task.","However, these methods primarily focus on aligned pose 3D objects (ap-3os), overlooking the recognition of 3D objects with open poses (op-3os) typically encountered in real-world scenarios, such as an overturned chair or a lying teddy bear.","To this end, we propose a more challenging benchmark for 3D open-pose zero-shot classification.","Echoing our benchmark, we design a concise angle-refinement mechanism that automatically optimizes one ideal pose as well as classifies these op-3os.","Furthermore, we make a first attempt to bridge 2D pre-trained diffusion model as a classifer to 3D zero-shot classification without any additional training.","Such 2D diffusion to 3D objects proves vital in improving zero-shot classification for both ap-3os and op-3os.","Our model notably improves by 3.5% and 15.8% on ModelNet10$^{\\ddag}$ and McGill$^{\\ddag}$ open pose benchmarks, respectively, and surpasses the current state-of-the-art by 6.8% on the aligned pose ModelNet10, affirming diffusion's efficacy in 3D zero-shot tasks."],"url":"http://arxiv.org/abs/2312.07039v1"}
{"created":"2023-12-12 07:41:05","title":"Debiasing Sequential Recommenders through Distributionally Robust Optimization over System Exposure","abstract":"Sequential recommendation (SR) models are typically trained on user-item interactions which are affected by the system exposure bias, leading to the user preference learned from the biased SR model not being fully consistent with the true user preference. Exposure bias refers to the fact that user interactions are dependent upon the partial items exposed to the user. Existing debiasing methods do not make full use of the system exposure data and suffer from sub-optimal recommendation performance and high variance. In this paper, we propose to debias sequential recommenders through Distributionally Robust Optimization (DRO) over system exposure data. The key idea is to utilize DRO to optimize the worst-case error over an uncertainty set to safeguard the model against distributional discrepancy caused by the exposure bias. The main challenge to apply DRO for exposure debiasing in SR lies in how to construct the uncertainty set and avoid the overestimation of user preference on biased samples. Moreover, how to evaluate the debiasing effect on biased test set is also an open question. To this end, we first introduce an exposure simulator trained upon the system exposure data to calculate the exposure distribution, which is then regarded as the nominal distribution to construct the uncertainty set of DRO. Then, we introduce a penalty to items with high exposure probability to avoid the overestimation of user preference for biased samples. Finally, we design a debiased self-normalized inverse propensity score (SNIPS) evaluator for evaluating the debiasing effect on the biased offline test set. We conduct extensive experiments on two real-world datasets to verify the effectiveness of the proposed methods. Experimental results demonstrate the superior exposure debiasing performance of proposed methods. Codes and data are available at \\url{https://github.com/nancheng58/DebiasedSR_DRO}.","sentences":["Sequential recommendation (SR) models are typically trained on user-item interactions which are affected by the system exposure bias, leading to the user preference learned from the biased SR model not being fully consistent with the true user preference.","Exposure bias refers to the fact that user interactions are dependent upon the partial items exposed to the user.","Existing debiasing methods do not make full use of the system exposure data and suffer from sub-optimal recommendation performance and high variance.","In this paper, we propose to debias sequential recommenders through Distributionally Robust Optimization (DRO) over system exposure data.","The key idea is to utilize DRO to optimize the worst-case error over an uncertainty set to safeguard the model against distributional discrepancy caused by the exposure bias.","The main challenge to apply DRO for exposure debiasing in SR lies in how to construct the uncertainty set and avoid the overestimation of user preference on biased samples.","Moreover, how to evaluate the debiasing effect on biased test set is also an open question.","To this end, we first introduce an exposure simulator trained upon the system exposure data to calculate the exposure distribution, which is then regarded as the nominal distribution to construct the uncertainty set of DRO.","Then, we introduce a penalty to items with high exposure probability to avoid the overestimation of user preference for biased samples.","Finally, we design a debiased self-normalized inverse propensity score (SNIPS) evaluator for evaluating the debiasing effect on the biased offline test set.","We conduct extensive experiments on two real-world datasets to verify the effectiveness of the proposed methods.","Experimental results demonstrate the superior exposure debiasing performance of proposed methods.","Codes and data are available at \\url{https://github.com/nancheng58/DebiasedSR_DRO}."],"url":"http://arxiv.org/abs/2312.07036v1"}
{"created":"2023-12-12 07:26:36","title":"Dynamic Corrective Self-Distillation for Better Fine-Tuning of Pretrained Models","abstract":"We tackle the challenging issue of aggressive fine-tuning encountered during the process of transfer learning of pre-trained language models (PLMs) with limited labeled downstream data. This problem primarily results in a decline in performance on the subsequent task. Inspired by the adaptive boosting method in traditional machine learning, we present an effective dynamic corrective self-distillation (DCS) approach to improve the fine-tuning of the PLMs. Our technique involves performing a self-distillation mechanism where, at each iteration, the student model actively adapts and corrects itself by dynamically adjusting the weights assigned to individual data points. This iterative self-correcting process significantly enhances the overall fine-tuning capability of PLMs, leading to improved performance and robustness. We conducted comprehensive evaluations using the GLUE benchmark demonstrating the efficacy of our method in enhancing the fine-tuning process for various PLMs across diverse downstream tasks.","sentences":["We tackle the challenging issue of aggressive fine-tuning encountered during the process of transfer learning of pre-trained language models (PLMs) with limited labeled downstream data.","This problem primarily results in a decline in performance on the subsequent task.","Inspired by the adaptive boosting method in traditional machine learning, we present an effective dynamic corrective self-distillation (DCS) approach to improve the fine-tuning of the PLMs.","Our technique involves performing a self-distillation mechanism where, at each iteration, the student model actively adapts and corrects itself by dynamically adjusting the weights assigned to individual data points.","This iterative self-correcting process significantly enhances the overall fine-tuning capability of PLMs, leading to improved performance and robustness.","We conducted comprehensive evaluations using the GLUE benchmark demonstrating the efficacy of our method in enhancing the fine-tuning process for various PLMs across diverse downstream tasks."],"url":"http://arxiv.org/abs/2312.07028v1"}
{"created":"2023-12-12 07:15:17","title":"Transferring Modality-Aware Pedestrian Attentive Learning Visible-Infrared Person Re-identification","abstract":"Visible-infrared person re-identification (VI-ReID) aims to search the same pedestrian of interest across visible and infrared modalities. Existing models mainly focus on compensating for modality-specific information to reduce modality variation. However, these methods often lead to a higher computational overhead and may introduce interfering information when generating the corresponding images or features. To address this issue, it is critical to leverage pedestrian-attentive features and learn modality-complete and -consistent representation. In this paper, a novel Transferring Modality-Aware Pedestrian Attentive Learning (TMPA) model is proposed, focusing on the pedestrian regions to efficiently compensate for missing modality-specific features. Specifically, we propose a region-based data augmentation module PedMix to enhance pedestrian region coherence by mixing the corresponding regions from different modalities. A lightweight hybrid compensation module, i.e., the Modality Feature Transfer (MFT), is devised to integrate cross attention and convolution networks to fully explore the discriminative modality-complete features with minimal computational overhead. Extensive experiments conducted on the benchmark SYSU-MM01 and RegDB datasets demonstrated the effectiveness of our proposed TMPA model.","sentences":["Visible-infrared person re-identification (VI-ReID) aims to search the same pedestrian of interest across visible and infrared modalities.","Existing models mainly focus on compensating for modality-specific information to reduce modality variation.","However, these methods often lead to a higher computational overhead and may introduce interfering information when generating the corresponding images or features.","To address this issue, it is critical to leverage pedestrian-attentive features and learn modality-complete and -consistent representation.","In this paper, a novel Transferring Modality-Aware Pedestrian Attentive Learning (TMPA) model is proposed, focusing on the pedestrian regions to efficiently compensate for missing modality-specific features.","Specifically, we propose a region-based data augmentation module PedMix to enhance pedestrian region coherence by mixing the corresponding regions from different modalities.","A lightweight hybrid compensation module, i.e., the Modality Feature Transfer (MFT), is devised to integrate cross attention and convolution networks to fully explore the discriminative modality-complete features with minimal computational overhead.","Extensive experiments conducted on the benchmark SYSU-MM01 and RegDB datasets demonstrated the effectiveness of our proposed TMPA model."],"url":"http://arxiv.org/abs/2312.07021v1"}
{"created":"2023-12-12 06:35:27","title":"Mixed Pseudo Labels for Semi-Supervised Object Detection","abstract":"While the pseudo-label method has demonstrated considerable success in semi-supervised object detection tasks, this paper uncovers notable limitations within this approach. Specifically, the pseudo-label method tends to amplify the inherent strengths of the detector while accentuating its weaknesses, which is manifested in the missed detection of pseudo-labels, particularly for small and tail category objects. To overcome these challenges, this paper proposes Mixed Pseudo Labels (MixPL), consisting of Mixup and Mosaic for pseudo-labeled data, to mitigate the negative impact of missed detections and balance the model's learning across different object scales. Additionally, the model's detection performance on tail categories is improved by resampling labeled data with relevant instances. Notably, MixPL consistently improves the performance of various detectors and obtains new state-of-the-art results with Faster R-CNN, FCOS, and DINO on COCO-Standard and COCO-Full benchmarks. Furthermore, MixPL also exhibits good scalability on large models, improving DINO Swin-L by 2.5% mAP and achieving nontrivial new records (60.2% mAP) on the COCO val2017 benchmark without extra annotations.","sentences":["While the pseudo-label method has demonstrated considerable success in semi-supervised object detection tasks, this paper uncovers notable limitations within this approach.","Specifically, the pseudo-label method tends to amplify the inherent strengths of the detector while accentuating its weaknesses, which is manifested in the missed detection of pseudo-labels, particularly for small and tail category objects.","To overcome these challenges, this paper proposes Mixed Pseudo Labels (MixPL), consisting of Mixup and Mosaic for pseudo-labeled data, to mitigate the negative impact of missed detections and balance the model's learning across different object scales.","Additionally, the model's detection performance on tail categories is improved by resampling labeled data with relevant instances.","Notably, MixPL consistently improves the performance of various detectors and obtains new state-of-the-art results with Faster R-CNN, FCOS, and DINO on COCO-Standard and COCO-Full benchmarks.","Furthermore, MixPL also exhibits good scalability on large models, improving DINO Swin-L by 2.5% mAP and achieving nontrivial new records (60.2% mAP) on the COCO val2017 benchmark without extra annotations."],"url":"http://arxiv.org/abs/2312.07006v1"}
{"created":"2023-12-12 06:21:30","title":"RACER: Rational Artificial Intelligence Car-following-model Enhanced by Reality","abstract":"This paper introduces RACER, the Rational Artificial Intelligence Car-following model Enhanced by Reality, a cutting-edge deep learning car-following model, that satisfies partial derivative constraints, designed to predict Adaptive Cruise Control (ACC) driving behavior while staying theoretically feasible. Unlike conventional models, RACER effectively integrates Rational Driving Constraints (RDCs), crucial tenets of actual driving, resulting in strikingly accurate and realistic predictions. Against established models like the Optimal Velocity Relative Velocity (OVRV), a car-following Neural Network (NN), and a car-following Physics-Informed Neural Network (PINN), RACER excels across key metrics, such as acceleration, velocity, and spacing. Notably, it displays a perfect adherence to the RDCs, registering zero violations, in stark contrast to other models. This study highlights the immense value of incorporating physical constraints within AI models, especially for augmenting safety measures in transportation. It also paves the way for future research to test these models against human driving data, with the potential to guide safer and more rational driving behavior. The versatility of the proposed model, including its potential to incorporate additional derivative constraints and broader architectural applications, enhances its appeal and broadens its impact within the scientific community.","sentences":["This paper introduces RACER, the Rational Artificial Intelligence Car-following model Enhanced by Reality, a cutting-edge deep learning car-following model, that satisfies partial derivative constraints, designed to predict Adaptive Cruise Control (ACC) driving behavior while staying theoretically feasible.","Unlike conventional models, RACER effectively integrates Rational Driving Constraints (RDCs), crucial tenets of actual driving, resulting in strikingly accurate and realistic predictions.","Against established models like the Optimal Velocity Relative Velocity (OVRV), a car-following Neural Network (NN), and a car-following Physics-Informed Neural Network (PINN), RACER excels across key metrics, such as acceleration, velocity, and spacing.","Notably, it displays a perfect adherence to the RDCs, registering zero violations, in stark contrast to other models.","This study highlights the immense value of incorporating physical constraints within AI models, especially for augmenting safety measures in transportation.","It also paves the way for future research to test these models against human driving data, with the potential to guide safer and more rational driving behavior.","The versatility of the proposed model, including its potential to incorporate additional derivative constraints and broader architectural applications, enhances its appeal and broadens its impact within the scientific community."],"url":"http://arxiv.org/abs/2312.07003v1"}
{"created":"2023-12-12 06:07:21","title":"DGNet: Dynamic Gradient-guided Network with Noise Suppression for Underwater Image Enhancement","abstract":"Underwater image enhancement (UIE) is a challenging task due to the complex degradation caused by underwater environments. To solve this issue, previous methods often idealize the degradation process, and neglect the impact of medium noise and object motion on the distribution of image features, limiting the generalization and adaptability of the model. Previous methods use the reference gradient that is constructed from original images and synthetic ground-truth images. This may cause the network performance to be influenced by some low-quality training data. Our approach utilizes predicted images to dynamically update pseudo-labels, adding a dynamic gradient to optimize the network's gradient space. This process improves image quality and avoids local optima. Moreover, we propose a Feature Restoration and Reconstruction module (FRR) based on a Channel Combination Inference (CCI) strategy and a Frequency Domain Smoothing module (FRS). These modules decouple other degradation features while reducing the impact of various types of noise on network performance. Experiments on multiple public datasets demonstrate the superiority of our method over existing state-of-the-art approaches, especially in achieving performance milestones: PSNR of 25.6dB and SSIM of 0.93 on the UIEB dataset. Its efficiency in terms of parameter size and inference time further attests to its broad practicality. The code will be made publicly available.","sentences":["Underwater image enhancement (UIE) is a challenging task due to the complex degradation caused by underwater environments.","To solve this issue, previous methods often idealize the degradation process, and neglect the impact of medium noise and object motion on the distribution of image features, limiting the generalization and adaptability of the model.","Previous methods use the reference gradient that is constructed from original images and synthetic ground-truth images.","This may cause the network performance to be influenced by some low-quality training data.","Our approach utilizes predicted images to dynamically update pseudo-labels, adding a dynamic gradient to optimize the network's gradient space.","This process improves image quality and avoids local optima.","Moreover, we propose a Feature Restoration and Reconstruction module (FRR) based on a Channel Combination Inference (CCI) strategy and a Frequency Domain Smoothing module (FRS).","These modules decouple other degradation features while reducing the impact of various types of noise on network performance.","Experiments on multiple public datasets demonstrate the superiority of our method over existing state-of-the-art approaches, especially in achieving performance milestones: PSNR of 25.6dB and SSIM of 0.93 on the UIEB dataset.","Its efficiency in terms of parameter size and inference time further attests to its broad practicality.","The code will be made publicly available."],"url":"http://arxiv.org/abs/2312.06999v1"}
{"created":"2023-12-12 05:35:30","title":"Dynamically configured physics-informed neural network in topology optimization applications","abstract":"Integration of machine learning (ML) into the topology optimization (TO) framework is attracting increasing attention, but data acquisition in data-driven models is prohibitive. Compared with popular ML methods, the physics-informed neural network (PINN) can avoid generating enormous amounts of data when solving forward problems and additionally provide better inference. To this end, a dynamically configured PINN-based topology optimization (DCPINN-TO) method is proposed. The DCPINN is composed of two subnetworks, namely the backbone neural network (NN) and the coefficient NN, where the coefficient NN has fewer trainable parameters. The designed architecture aims to dynamically configure trainable parameters; that is, an inexpensive NN is used to replace an expensive one at certain optimization cycles. Furthermore, an active sampling strategy is proposed to selectively sample collocations depending on the pseudo-densities at each optimization cycle. In this manner, the number of collocations will decrease with the optimization process but will hardly affect it. The Gaussian integral is used to calculate the strain energy of elements, which yields a byproduct of decoupling the mapping of the material at the collocations. Several examples with different resolutions validate the feasibility of the DCPINN-TO method, and multiload and multiconstraint problems are employed to illustrate its generalization. In addition, compared to finite element analysis-based TO (FEA-TO), the accuracy of the displacement prediction and optimization results indicate that the DCPINN-TO method is effective and efficient.","sentences":["Integration of machine learning (ML) into the topology optimization (TO) framework is attracting increasing attention, but data acquisition in data-driven models is prohibitive.","Compared with popular ML methods, the physics-informed neural network (PINN) can avoid generating enormous amounts of data when solving forward problems and additionally provide better inference.","To this end, a dynamically configured PINN-based topology optimization (DCPINN-TO) method is proposed.","The DCPINN is composed of two subnetworks, namely the backbone neural network (NN) and the coefficient NN, where the coefficient NN has fewer trainable parameters.","The designed architecture aims to dynamically configure trainable parameters; that is, an inexpensive NN is used to replace an expensive one at certain optimization cycles.","Furthermore, an active sampling strategy is proposed to selectively sample collocations depending on the pseudo-densities at each optimization cycle.","In this manner, the number of collocations will decrease with the optimization process but will hardly affect it.","The Gaussian integral is used to calculate the strain energy of elements, which yields a byproduct of decoupling the mapping of the material at the collocations.","Several examples with different resolutions validate the feasibility of the DCPINN-TO method, and multiload and multiconstraint problems are employed to illustrate its generalization.","In addition, compared to finite element analysis-based TO (FEA-TO), the accuracy of the displacement prediction and optimization results indicate that the DCPINN-TO method is effective and efficient."],"url":"http://arxiv.org/abs/2312.06993v1"}
{"created":"2023-12-12 05:18:23","title":"AI-based Wildfire Prevention, Detection and Suppression System","abstract":"Wildfires pose a serious threat to the environment of the world. The global wildfire season length has increased by 19% and severe wildfires have besieged nations around the world. Every year, forests are burned by wildfires, causing vast amounts of carbon dioxide to be released into the atmosphere, contributing to climate change. There is a need for a system which prevents, detects, and suppresses wildfires. The AI based Wildfire Prevention, Detection and Suppression System (WPDSS) is a novel, fully automated, end to end, AI based solution to effectively predict hotspots and detect wildfires, deploy drones to spray fire retardant, preventing and suppressing wildfires. WPDSS consists of four steps. 1. Preprocessing: WPDSS loads real time satellite data from NASA and meteorological data from NOAA of vegetation, temperature, precipitation, wind, soil moisture, and land cover for prevention. For detection, it loads the real time data of Land Cover, Humidity, Temperature, Vegetation, Burned Area Index, Ozone, and CO2. It uses the process of masking to eliminate not hotspots and not wildfires such as water bodies, and rainfall. 2. Learning: The AI model consists of a random forest classifier, which is trained using a labeled dataset of hotspots and wildfires and not hotspots and not wildfires. 3. Identification of hotspots and wildfires: WPDSS runs the real time data through the model to automatically identify hotspots and wildfires. 4. Drone deployment: The drone flies to the identified hotspot or wildfire location. WPDSS attained a 98.6% accuracy in identifying hotspots and a 98.7% accuracy in detecting wildfires. WPDSS will reduce the impacts of climate change, protect ecosystems and biodiversity, avert huge economic losses, and save human lives. The power of WPDSS developed can be applied to any location globally to prevent and suppress wildfires, reducing climate change.","sentences":["Wildfires pose a serious threat to the environment of the world.","The global wildfire season length has increased by 19% and severe wildfires have besieged nations around the world.","Every year, forests are burned by wildfires, causing vast amounts of carbon dioxide to be released into the atmosphere, contributing to climate change.","There is a need for a system which prevents, detects, and suppresses wildfires.","The AI based Wildfire Prevention, Detection and Suppression System (WPDSS) is a novel, fully automated, end to end, AI based solution to effectively predict hotspots and detect wildfires, deploy drones to spray fire retardant, preventing and suppressing wildfires.","WPDSS consists of four steps.","1. Preprocessing: WPDSS loads real time satellite data from NASA and meteorological data from NOAA of vegetation, temperature, precipitation, wind, soil moisture, and land cover for prevention.","For detection, it loads the real time data of Land Cover, Humidity, Temperature, Vegetation, Burned Area Index, Ozone, and CO2.","It uses the process of masking to eliminate not hotspots and not wildfires such as water bodies, and rainfall.","2. Learning:","The AI model consists of a random forest classifier, which is trained using a labeled dataset of hotspots and wildfires and not hotspots and not wildfires.","3. Identification of hotspots and wildfires: WPDSS runs the real time data through the model to automatically identify hotspots and wildfires.","4.","Drone deployment: The drone flies to the identified hotspot or wildfire location.","WPDSS attained a 98.6% accuracy in identifying hotspots and a 98.7% accuracy in detecting wildfires.","WPDSS will reduce the impacts of climate change, protect ecosystems and biodiversity, avert huge economic losses, and save human lives.","The power of WPDSS developed can be applied to any location globally to prevent and suppress wildfires, reducing climate change."],"url":"http://arxiv.org/abs/2312.06990v1"}
{"created":"2023-12-12 05:17:34","title":"Task-Agnostic Privacy-Preserving Representation Learning for Federated Learning Against Attribute Inference Attacks","abstract":"Federated learning (FL) has been widely studied recently due to its property to collaboratively train data from different devices without sharing the raw data. Nevertheless, recent studies show that an adversary can still be possible to infer private information about devices' data, e.g., sensitive attributes such as income, race, and sexual orientation. To mitigate the attribute inference attacks, various existing privacy-preserving FL methods can be adopted/adapted. However, all these existing methods have key limitations: they need to know the FL task in advance, or have intolerable computational overheads or utility losses, or do not have provable privacy guarantees.   We address these issues and design a task-agnostic privacy-preserving presentation learning method for FL ({\\bf TAPPFL}) against attribute inference attacks. TAPPFL is formulated via information theory. Specifically, TAPPFL has two mutual information goals, where one goal learns task-agnostic data representations that contain the least information about the private attribute in each device's data, and the other goal ensures the learnt data representations include as much information as possible about the device data to maintain FL utility. We also derive privacy guarantees of TAPPFL against worst-case attribute inference attacks, as well as the inherent tradeoff between utility preservation and privacy protection. Extensive results on multiple datasets and applications validate the effectiveness of TAPPFL to protect data privacy, maintain the FL utility, and be efficient as well. Experimental results also show that TAPPFL outperforms the existing defenses\\footnote{Source code and full version: \\url{https://github.com/TAPPFL}}.","sentences":["Federated learning (FL) has been widely studied recently due to its property to collaboratively train data from different devices without sharing the raw data.","Nevertheless, recent studies show that an adversary can still be possible to infer private information about devices' data, e.g., sensitive attributes such as income, race, and sexual orientation.","To mitigate the attribute inference attacks, various existing privacy-preserving FL methods can be adopted/adapted.","However, all these existing methods have key limitations: they need to know the FL task in advance, or have intolerable computational overheads or utility losses, or do not have provable privacy guarantees.   ","We address these issues and design a task-agnostic privacy-preserving presentation learning method for FL ({\\bf TAPPFL}) against attribute inference attacks.","TAPPFL is formulated via information theory.","Specifically, TAPPFL has two mutual information goals, where one goal learns task-agnostic data representations that contain the least information about the private attribute in each device's data, and the other goal ensures the learnt data representations include as much information as possible about the device data to maintain FL utility.","We also derive privacy guarantees of TAPPFL against worst-case attribute inference attacks, as well as the inherent tradeoff between utility preservation and privacy protection.","Extensive results on multiple datasets and applications validate the effectiveness of TAPPFL to protect data privacy, maintain the FL utility, and be efficient as well.","Experimental results also show that TAPPFL outperforms the existing defenses\\footnote{Source code and full version: \\url{https://github.com/TAPPFL}}."],"url":"http://arxiv.org/abs/2312.06989v1"}
{"created":"2023-12-12 04:38:30","title":"CLASSMix: Adaptive stain separation-based contrastive learning with pseudo labeling for histopathological image classification","abstract":"Histopathological image classification is one of the critical aspects in medical image analysis. Due to the high expense associated with the labeled data in model training, semi-supervised learning methods have been proposed to alleviate the need of extensively labeled datasets. In this work, we propose a model for semi-supervised classification tasks on digital histopathological Hematoxylin and Eosin (H&E) images. We call the new model Contrastive Learning with Adaptive Stain Separation and MixUp (CLASSMix). Our model is formed by two main parts: contrastive learning between adaptively stain separated Hematoxylin images and Eosin images, and pseudo labeling using MixUp. We compare our model with other state-of-the-art models on clear cell renal cell carcinoma (ccRCC) datasets from our institution and The Cancer Genome Atlas Program (TCGA). We demonstrate that our CLASSMix model has the best performance on both datasets. The contributions of different parts in our model are also analyzed.","sentences":["Histopathological image classification is one of the critical aspects in medical image analysis.","Due to the high expense associated with the labeled data in model training, semi-supervised learning methods have been proposed to alleviate the need of extensively labeled datasets.","In this work, we propose a model for semi-supervised classification tasks on digital histopathological Hematoxylin and Eosin (H&E) images.","We call the new model Contrastive Learning with Adaptive Stain Separation and MixUp (CLASSMix).","Our model is formed by two main parts: contrastive learning between adaptively stain separated Hematoxylin images and Eosin images, and pseudo labeling using MixUp.","We compare our model with other state-of-the-art models on clear cell renal cell carcinoma (ccRCC) datasets from our institution and The Cancer Genome Atlas Program (TCGA).","We demonstrate that our CLASSMix model has the best performance on both datasets.","The contributions of different parts in our model are also analyzed."],"url":"http://arxiv.org/abs/2312.06978v1"}
{"created":"2023-12-12 04:25:26","title":"SM70: A Large Language Model for Medical Devices","abstract":"We are introducing SM70, a 70 billion-parameter Large Language Model that is specifically designed for SpassMed's medical devices under the brand name 'JEE1' (pronounced as G1 and means 'Life'). This large language model provides more accurate and safe responses to medical-domain questions. To fine-tune SM70, we used around 800K data entries from the publicly available dataset MedAlpaca. The Llama2 70B open-sourced model served as the foundation for SM70, and we employed the QLoRA technique for fine-tuning. The evaluation is conducted across three benchmark datasets - MEDQA - USMLE, PUBMEDQA, and USMLE - each representing a unique aspect of medical knowledge and reasoning. The performance of SM70 is contrasted with other notable LLMs, including Llama2 70B, Clinical Camel 70 (CC70), GPT 3.5, GPT 4, and Med-Palm, to provide a comparative understanding of its capabilities within the medical domain. Our results indicate that SM70 outperforms several established models in these datasets, showcasing its proficiency in handling a range of medical queries, from fact-based questions derived from PubMed abstracts to complex clinical decision-making scenarios. The robust performance of SM70, particularly in the USMLE and PUBMEDQA datasets, suggests its potential as an effective tool in clinical decision support and medical information retrieval. Despite its promising results, the paper also acknowledges the areas where SM70 lags behind the most advanced model, GPT 4, thereby highlighting the need for further development, especially in tasks demanding extensive medical knowledge and intricate reasoning.","sentences":["We are introducing SM70, a 70 billion-parameter Large Language Model that is specifically designed for SpassMed's medical devices under the brand name 'JEE1' (pronounced as G1 and means 'Life').","This large language model provides more accurate and safe responses to medical-domain questions.","To fine-tune SM70, we used around 800K data entries from the publicly available dataset MedAlpaca.","The Llama2 70B open-sourced model served as the foundation for SM70, and we employed the QLoRA technique for fine-tuning.","The evaluation is conducted across three benchmark datasets - MEDQA - USMLE, PUBMEDQA, and USMLE - each representing a unique aspect of medical knowledge and reasoning.","The performance of SM70 is contrasted with other notable LLMs, including Llama2 70B, Clinical Camel 70 (CC70), GPT 3.5, GPT 4, and Med-Palm, to provide a comparative understanding of its capabilities within the medical domain.","Our results indicate that SM70 outperforms several established models in these datasets, showcasing its proficiency in handling a range of medical queries, from fact-based questions derived from PubMed abstracts to complex clinical decision-making scenarios.","The robust performance of SM70, particularly in the USMLE and PUBMEDQA datasets, suggests its potential as an effective tool in clinical decision support and medical information retrieval.","Despite its promising results, the paper also acknowledges the areas where SM70 lags behind the most advanced model, GPT 4, thereby highlighting the need for further development, especially in tasks demanding extensive medical knowledge and intricate reasoning."],"url":"http://arxiv.org/abs/2312.06974v1"}
{"created":"2023-12-12 03:59:32","title":"How Much Data is Needed for Channel Knowledge Map Construction?","abstract":"Channel knowledge map (CKM) has been recently proposed to enable environment-aware communications by utilizing historical or simulation generated wireless channel data. This paper studies the construction of one particular type of CKM, namely channel gain map (CGM), by using a finite number of measurements or simulation-generated data, with model-based spatial channel prediction. We try to answer the following question: How much data is sufficient for CKM construction? To this end, we first derive the average mean square error (AMSE) of the channel gain prediction as a function of the sample density of data collection for offline CGM construction, as well as the number of data points used for online spatial channel gain prediction. To model the spatial variation of the wireless environment even within each cell, we divide the CGM into subregions and estimate the channel parameters from the local data within each subregion. The parameter estimation error and the channel prediction error based on estimated channel parameters are derived as functions of the number of data points within the subregion. The analytical results provide useful guide for CGM construction and utilization by determining the required spatial sample density for offline data collection and number of data points to be used for online channel prediction, so that the desired level of channel prediction accuracy is guaranteed.","sentences":["Channel knowledge map (CKM) has been recently proposed to enable environment-aware communications by utilizing historical or simulation generated wireless channel data.","This paper studies the construction of one particular type of CKM, namely channel gain map (CGM), by using a finite number of measurements or simulation-generated data, with model-based spatial channel prediction.","We try to answer the following question: How much data is sufficient for CKM construction?","To this end, we first derive the average mean square error (AMSE) of the channel gain prediction as a function of the sample density of data collection for offline CGM construction, as well as the number of data points used for online spatial channel gain prediction.","To model the spatial variation of the wireless environment even within each cell, we divide the CGM into subregions and estimate the channel parameters from the local data within each subregion.","The parameter estimation error and the channel prediction error based on estimated channel parameters are derived as functions of the number of data points within the subregion.","The analytical results provide useful guide for CGM construction and utilization by determining the required spatial sample density for offline data collection and number of data points to be used for online channel prediction, so that the desired level of channel prediction accuracy is guaranteed."],"url":"http://arxiv.org/abs/2312.06966v1"}
{"created":"2023-12-12 03:47:41","title":"Strictly Monotone Brouwer Trees for Well-founded Recursion Over Multiple Arguments","abstract":"Ordinals can help prove termination for dependently typed programs. Brouwer trees are a particular ordinal notation that make it very easy to assign sizes to higher order data structures. They extend natural numbers with a limit constructor, so a function's size can be the supremum of the sizes of values from its image. These can then be used to define well-founded recursion: any recursive calls are allowed so long as they are on values whose sizes are strictly smaller than the current size. Unfortunately, Brouwer trees are not algebraically well-behaved. They can be characterized equationally as a join-semilattice, where the join takes the maximum of two trees. However, it does not interact well with the successor constructor, so it does not interact properly with the strict ordering used in well-founded recursion. We present Strictly Monotone Brouwer trees (SMB-trees), a refinement of Brouwer trees that are algebraically well-behaved. SMB-trees are built using functions with the same signatures as Brouwer tree constructors, and they satisfy all Brouwer tree inequalities. However, their join operator distributes over the successor, making them suited for well-founded recursion or equational reasoning. We show how, using dependent pairs and careful definitions, an ill-behaved definition can be turned into a well-behaved one, with light axiomatic requirements. We implement a recursively-defined maximum operator for Brouwer trees that matches on successors and handles them specifically. Then, we define SMB-trees as the subset of Brouwer trees for which the recursive maximum computes a least upper bound. Finally, we show that every Brouwer tree can be transformed into a corresponding SMB-tree by joining it with itself an infinite number of times. All definitions and theorems are implemented in Agda.","sentences":["Ordinals can help prove termination for dependently typed programs.","Brouwer trees are a particular ordinal notation that make it very easy to assign sizes to higher order data structures.","They extend natural numbers with a limit constructor, so a function's size can be the supremum of the sizes of values from its image.","These can then be used to define well-founded recursion: any recursive calls are allowed so long as they are on values whose sizes are strictly smaller than the current size.","Unfortunately, Brouwer trees are not algebraically well-behaved.","They can be characterized equationally as a join-semilattice, where the join takes the maximum of two trees.","However, it does not interact well with the successor constructor, so it does not interact properly with the strict ordering used in well-founded recursion.","We present Strictly Monotone Brouwer trees (SMB-trees), a refinement of Brouwer trees that are algebraically well-behaved.","SMB-trees are built using functions with the same signatures as Brouwer tree constructors, and they satisfy all Brouwer tree inequalities.","However, their join operator distributes over the successor, making them suited for well-founded recursion or equational reasoning.","We show how, using dependent pairs and careful definitions, an ill-behaved definition can be turned into a well-behaved one, with light axiomatic requirements.","We implement a recursively-defined maximum operator for Brouwer trees that matches on successors and handles them specifically.","Then, we define SMB-trees as the subset of Brouwer trees for which the recursive maximum computes a least upper bound.","Finally, we show that every Brouwer tree can be transformed into a corresponding SMB-tree by joining it with itself an infinite number of times.","All definitions and theorems are implemented in Agda."],"url":"http://arxiv.org/abs/2312.06962v1"}
{"created":"2023-12-12 03:09:37","title":"Feature Norm Regularized Federated Learning: Transforming Skewed Distributions into Global Insights","abstract":"In the field of federated learning, addressing non-independent and identically distributed (non-i.i.d.) data remains a quintessential challenge for improving global model performance. This work introduces the Feature Norm Regularized Federated Learning (FNR-FL) algorithm, which uniquely incorporates class average feature norms to enhance model accuracy and convergence in non-i.i.d. scenarios. Our comprehensive analysis reveals that FNR-FL not only accelerates convergence but also significantly surpasses other contemporary federated learning algorithms in test accuracy, particularly under feature distribution skew scenarios. The novel modular design of FNR-FL facilitates seamless integration with existing federated learning frameworks, reinforcing its adaptability and potential for widespread application. We substantiate our claims through rigorous empirical evaluations, demonstrating FNR-FL's exceptional performance across various skewed data distributions. Relative to FedAvg, FNR-FL exhibits a substantial 66.24\\% improvement in accuracy and a significant 11.40\\% reduction in training time, underscoring its enhanced effectiveness and efficiency.","sentences":["In the field of federated learning, addressing non-independent and identically distributed (non-i.i.d.)","data remains a quintessential challenge for improving global model performance.","This work introduces the Feature Norm Regularized Federated Learning (FNR-FL) algorithm, which uniquely incorporates class average feature norms to enhance model accuracy and convergence in non-i.i.d. scenarios.","Our comprehensive analysis reveals that FNR-FL not only accelerates convergence but also significantly surpasses other contemporary federated learning algorithms in test accuracy, particularly under feature distribution skew scenarios.","The novel modular design of FNR-FL facilitates seamless integration with existing federated learning frameworks, reinforcing its adaptability and potential for widespread application.","We substantiate our claims through rigorous empirical evaluations, demonstrating FNR-FL's exceptional performance across various skewed data distributions.","Relative to FedAvg, FNR-FL exhibits a substantial 66.24\\% improvement in accuracy and a significant 11.40\\% reduction in training time, underscoring its enhanced effectiveness and efficiency."],"url":"http://arxiv.org/abs/2312.06951v1"}
{"created":"2023-12-12 03:09:30","title":"READ-PVLA: Recurrent Adapter with Partial Video-Language Alignment for Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling","abstract":"Fully fine-tuning pretrained large-scale transformer models has become a popular paradigm for video-language modeling tasks, such as temporal language grounding and video-language summarization. With a growing number of tasks and limited training data, such full fine-tuning approach leads to costly model storage and unstable training. To overcome these shortcomings, we introduce lightweight adapters to the pre-trained model and only update them at fine-tuning time. However, existing adapters fail to capture intrinsic temporal relations among video frames or textual words. Moreover, they neglect the preservation of critical task-related information that flows from the raw video-language input into the adapter's low-dimensional space. To address these issues, we first propose a novel REcurrent ADapter (READ) that employs recurrent computation to enable temporal modeling capability. Second, we propose Partial Video-Language Alignment (PVLA) objective via the use of partial optimal transport to maintain task-related information flowing into our READ modules. We validate our READ-PVLA framework through extensive experiments where READ-PVLA significantly outperforms all existing fine-tuning strategies on multiple low-resource temporal language grounding and video-language summarization benchmarks.","sentences":["Fully fine-tuning pretrained large-scale transformer models has become a popular paradigm for video-language modeling tasks, such as temporal language grounding and video-language summarization.","With a growing number of tasks and limited training data, such full fine-tuning approach leads to costly model storage and unstable training.","To overcome these shortcomings, we introduce lightweight adapters to the pre-trained model and only update them at fine-tuning time.","However, existing adapters fail to capture intrinsic temporal relations among video frames or textual words.","Moreover, they neglect the preservation of critical task-related information that flows from the raw video-language input into the adapter's low-dimensional space.","To address these issues, we first propose a novel REcurrent ADapter (READ) that employs recurrent computation to enable temporal modeling capability.","Second, we propose Partial Video-Language Alignment (PVLA) objective via the use of partial optimal transport to maintain task-related information flowing into our READ modules.","We validate our READ-PVLA framework through extensive experiments where READ-PVLA significantly outperforms all existing fine-tuning strategies on multiple low-resource temporal language grounding and video-language summarization benchmarks."],"url":"http://arxiv.org/abs/2312.06950v1"}
{"created":"2023-12-12 02:06:50","title":"Predictive variational autoencoder for learning robust representations of time-series data","abstract":"Variational autoencoders (VAEs) have been used extensively to discover low-dimensional latent factors governing neural activity and animal behavior. However, without careful model selection, the uncovered latent factors may reflect noise in the data rather than true underlying features, rendering such representations unsuitable for scientific interpretation. Existing solutions to this problem involve introducing additional measured variables or data augmentations specific to a particular data type. We propose a VAE architecture that predicts the next point in time and show that it mitigates the learning of spurious features. In addition, we introduce a model selection metric based on smoothness over time in the latent space. We show that together these two constraints on VAEs to be smooth over time produce robust latent representations and faithfully recover latent factors on synthetic datasets.","sentences":["Variational autoencoders (VAEs) have been used extensively to discover low-dimensional latent factors governing neural activity and animal behavior.","However, without careful model selection, the uncovered latent factors may reflect noise in the data rather than true underlying features, rendering such representations unsuitable for scientific interpretation.","Existing solutions to this problem involve introducing additional measured variables or data augmentations specific to a particular data type.","We propose a VAE architecture that predicts the next point in time and show that it mitigates the learning of spurious features.","In addition, we introduce a model selection metric based on smoothness over time in the latent space.","We show that together these two constraints on VAEs to be smooth over time produce robust latent representations and faithfully recover latent factors on synthetic datasets."],"url":"http://arxiv.org/abs/2312.06932v1"}
{"created":"2023-12-12 01:42:41","title":"Content-Localization based Neural Machine Translation for Informal Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic","abstract":"Resources in high-resource languages have not been efficiently exploited in low-resource languages to solve language-dependent research problems. Spanish and French are considered high resource languages in which an adequate level of data resources for informal online social behavior modeling, is observed. However, a machine translation system to access those data resources and transfer their context and tone to a low-resource language like dialectal Arabic, does not exist. In response, we propose a framework that localizes contents of high-resource languages to a low-resource language/dialects by utilizing AI power. To the best of our knowledge, we are the first work to provide a parallel translation dataset from/to informal Spanish and French to/from informal Arabic dialects. Using this, we aim to enrich the under-resource-status dialectal Arabic and fast-track the research of diverse online social behaviors within and across smart cities in different geo-regions. The experimental results have illustrated the capability of our proposed solution in exploiting the resources between high and low resource languages and dialects. Not only this, but it has also been proven that ignoring dialects within the same language could lead to misleading analysis of online social behavior.","sentences":["Resources in high-resource languages have not been efficiently exploited in low-resource languages to solve language-dependent research problems.","Spanish and French are considered high resource languages in which an adequate level of data resources for informal online social behavior modeling, is observed.","However, a machine translation system to access those data resources and transfer their context and tone to a low-resource language like dialectal Arabic, does not exist.","In response, we propose a framework that localizes contents of high-resource languages to a low-resource language/dialects by utilizing AI power.","To the best of our knowledge, we are the first work to provide a parallel translation dataset from/to informal Spanish and French to/from informal Arabic dialects.","Using this, we aim to enrich the under-resource-status dialectal Arabic and fast-track the research of diverse online social behaviors within and across smart cities in different geo-regions.","The experimental results have illustrated the capability of our proposed solution in exploiting the resources between high and low resource languages and dialects.","Not only this, but it has also been proven that ignoring dialects within the same language could lead to misleading analysis of online social behavior."],"url":"http://arxiv.org/abs/2312.06926v1"}
{"created":"2023-12-12 01:40:14","title":"Facial Emotion Recognition in VR Games","abstract":"Emotion detection is a crucial component of Games User Research (GUR), as it allows game developers to gain insights into players' emotional experiences and tailor their games accordingly. However, detecting emotions in Virtual Reality (VR) games is challenging due to the Head-Mounted Display (HMD) that covers the top part of the player's face, namely, their eyes and eyebrows, which provide crucial information for recognizing the impression. To tackle this we used a Convolutional Neural Network (CNN) to train a model to predict emotions in full-face images where the eyes and eyebrows are covered. We used the FER2013 dataset, which we modified to cover eyes and eyebrows in images. The model in these images can accurately recognize seven different emotions which are anger, happiness, disgust, fear, impartiality, sadness and surprise.   We assessed the model's performance by testing it on two VR games and using it to detect players' emotions. We collected self-reported emotion data from the players after the gameplay sessions. We analyzed the data collected from our experiment to understand which emotions players experience during the gameplay. We found that our approach has the potential to enhance gameplay analysis by enabling the detection of players' emotions in VR games, which can help game developers create more engaging and immersive game experiences.","sentences":["Emotion detection is a crucial component of Games User Research (GUR), as it allows game developers to gain insights into players' emotional experiences and tailor their games accordingly.","However, detecting emotions in Virtual Reality (VR) games is challenging due to the Head-Mounted Display (HMD) that covers the top part of the player's face, namely, their eyes and eyebrows, which provide crucial information for recognizing the impression.","To tackle this we used a Convolutional Neural Network (CNN) to train a model to predict emotions in full-face images where the eyes and eyebrows are covered.","We used the FER2013 dataset, which we modified to cover eyes and eyebrows in images.","The model in these images can accurately recognize seven different emotions which are anger, happiness, disgust, fear, impartiality, sadness and surprise.   ","We assessed the model's performance by testing it on two VR games and using it to detect players' emotions.","We collected self-reported emotion data from the players after the gameplay sessions.","We analyzed the data collected from our experiment to understand which emotions players experience during the gameplay.","We found that our approach has the potential to enhance gameplay analysis by enabling the detection of players' emotions in VR games, which can help game developers create more engaging and immersive game experiences."],"url":"http://arxiv.org/abs/2312.06925v1"}
{"created":"2023-12-12 01:23:05","title":"Pain Analysis using Adaptive Hierarchical Spatiotemporal Dynamic Imaging","abstract":"Automatic pain intensity estimation plays a pivotal role in healthcare and medical fields. While many methods have been developed to gauge human pain using behavioral or physiological indicators, facial expressions have emerged as a prominent tool for this purpose. Nevertheless, the dependence on labeled data for these techniques often renders them expensive and time-consuming. To tackle this, we introduce the Adaptive Hierarchical Spatio-temporal Dynamic Image (AHDI) technique. AHDI encodes spatiotemporal changes in facial videos into a singular RGB image, permitting the application of simpler 2D deep models for video representation. Within this framework, we employ a residual network to derive generalized facial representations. These representations are optimized for two tasks: estimating pain intensity and differentiating between genuine and simulated pain expressions. For the former, a regression model is trained using the extracted representations, while for the latter, a binary classifier identifies genuine versus feigned pain displays. Testing our method on two widely-used pain datasets, we observed encouraging results for both tasks. On the UNBC database, we achieved an MSE of 0.27 outperforming the SOTA which had an MSE of 0.40. On the BioVid dataset, our model achieved an accuracy of 89.76%, which is an improvement of 5.37% over the SOTA accuracy. Most notably, for distinguishing genuine from simulated pain, our accuracy stands at 94.03%, marking a substantial improvement of 8.98%. Our methodology not only minimizes the need for extensive labeled data but also augments the precision of pain evaluations, facilitating superior pain management.","sentences":["Automatic pain intensity estimation plays a pivotal role in healthcare and medical fields.","While many methods have been developed to gauge human pain using behavioral or physiological indicators, facial expressions have emerged as a prominent tool for this purpose.","Nevertheless, the dependence on labeled data for these techniques often renders them expensive and time-consuming.","To tackle this, we introduce the Adaptive Hierarchical Spatio-temporal Dynamic Image (AHDI) technique.","AHDI encodes spatiotemporal changes in facial videos into a singular RGB image, permitting the application of simpler 2D deep models for video representation.","Within this framework, we employ a residual network to derive generalized facial representations.","These representations are optimized for two tasks: estimating pain intensity and differentiating between genuine and simulated pain expressions.","For the former, a regression model is trained using the extracted representations, while for the latter, a binary classifier identifies genuine versus feigned pain displays.","Testing our method on two widely-used pain datasets, we observed encouraging results for both tasks.","On the UNBC database, we achieved an MSE of 0.27 outperforming the SOTA which had an MSE of 0.40.","On the BioVid dataset, our model achieved an accuracy of 89.76%, which is an improvement of 5.37% over the SOTA accuracy.","Most notably, for distinguishing genuine from simulated pain, our accuracy stands at 94.03%, marking a substantial improvement of 8.98%.","Our methodology not only minimizes the need for extensive labeled data but also augments the precision of pain evaluations, facilitating superior pain management."],"url":"http://arxiv.org/abs/2312.06920v1"}
{"created":"2023-12-12 00:54:39","title":"Exploring Novel Object Recognition and Spontaneous Location Recognition Machine Learning Analysis Techniques in Alzheimer's Mice","abstract":"Understanding object recognition patterns in mice is crucial for advancing behavioral neuroscience and has significant implications for human health, particularly in the realm of Alzheimer's research. This study is centered on the development, application, and evaluation of a state-of-the-art computational pipeline designed to analyze such behaviors, specifically focusing on Novel Object Recognition (NOR) and Spontaneous Location Recognition (SLR) tasks. The pipeline integrates three advanced computational models: Any-Maze for initial data collection, DeepLabCut for detailed pose estimation, and Convolutional Neural Networks (CNNs) for nuanced behavioral classification. Employed across four distinct mouse groups, this pipeline demonstrated high levels of accuracy and robustness. Despite certain challenges like video quality limitations and the need for manual calculations, the results affirm the pipeline's efficacy and potential for scalability. The study serves as a proof of concept for a multidimensional computational approach to behavioral neuroscience, emphasizing the pipeline's versatility and readiness for future, more complex analyses.","sentences":["Understanding object recognition patterns in mice is crucial for advancing behavioral neuroscience and has significant implications for human health, particularly in the realm of Alzheimer's research.","This study is centered on the development, application, and evaluation of a state-of-the-art computational pipeline designed to analyze such behaviors, specifically focusing on Novel Object Recognition (NOR) and Spontaneous Location Recognition (SLR) tasks.","The pipeline integrates three advanced computational models: Any-Maze for initial data collection, DeepLabCut for detailed pose estimation, and Convolutional Neural Networks (CNNs) for nuanced behavioral classification.","Employed across four distinct mouse groups, this pipeline demonstrated high levels of accuracy and robustness.","Despite certain challenges like video quality limitations and the need for manual calculations, the results affirm the pipeline's efficacy and potential for scalability.","The study serves as a proof of concept for a multidimensional computational approach to behavioral neuroscience, emphasizing the pipeline's versatility and readiness for future, more complex analyses."],"url":"http://arxiv.org/abs/2312.06914v1"}
{"created":"2023-12-11 23:30:37","title":"VitalLens: Take A Vital Selfie","abstract":"This report introduces VitalLens, an app that estimates vital signs such as heart rate and respiration rate from selfie video in real time. VitalLens uses a computer vision model trained on a diverse dataset of video and physiological sensor data. We benchmark performance on several diverse datasets, including VV-Medium, which consists of 289 unique participants. VitalLens outperforms several existing methods including POS and MTTS-CAN on all datasets while maintaining a fast inference speed. On VV-Medium, VitalLens achieves absolute errors of 0.71 bpm for heart rate estimation, and 0.76 rpm for respiratory rate estimation.","sentences":["This report introduces VitalLens, an app that estimates vital signs such as heart rate and respiration rate from selfie video in real time.","VitalLens uses a computer vision model trained on a diverse dataset of video and physiological sensor data.","We benchmark performance on several diverse datasets, including VV-Medium, which consists of 289 unique participants.","VitalLens outperforms several existing methods including POS and MTTS-CAN on all datasets while maintaining a fast inference speed.","On VV-Medium, VitalLens achieves absolute errors of 0.71 bpm for heart rate estimation, and 0.76 rpm for respiratory rate estimation."],"url":"http://arxiv.org/abs/2312.06892v1"}
{"created":"2023-12-11 23:20:58","title":"Understanding and Leveraging the Learning Phases of Neural Networks","abstract":"The learning dynamics of deep neural networks are not well understood. The information bottleneck (IB) theory proclaimed separate fitting and compression phases. But they have since been heavily debated. We comprehensively analyze the learning dynamics by investigating a layer's reconstruction ability of the input and prediction performance based on the evolution of parameters during training. We empirically show the existence of three phases using common datasets and architectures such as ResNet and VGG: (i) near constant reconstruction loss, (ii) decrease, and (iii) increase. We also derive an empirically grounded data model and prove the existence of phases for single-layer networks. Technically, our approach leverages classical complexity analysis. It differs from IB by relying on measuring reconstruction loss rather than information theoretic measures to relate information of intermediate layers and inputs. Our work implies a new best practice for transfer learning: We show empirically that the pre-training of a classifier should stop well before its performance is optimal.","sentences":["The learning dynamics of deep neural networks are not well understood.","The information bottleneck (IB) theory proclaimed separate fitting and compression phases.","But they have since been heavily debated.","We comprehensively analyze the learning dynamics by investigating a layer's reconstruction ability of the input and prediction performance based on the evolution of parameters during training.","We empirically show the existence of three phases using common datasets and architectures such as ResNet and VGG: (i) near constant reconstruction loss, (ii) decrease, and (iii) increase.","We also derive an empirically grounded data model and prove the existence of phases for single-layer networks.","Technically, our approach leverages classical complexity analysis.","It differs from IB by relying on measuring reconstruction loss rather than information theoretic measures to relate information of intermediate layers and inputs.","Our work implies a new best practice for transfer learning: We show empirically that the pre-training of a classifier should stop well before its performance is optimal."],"url":"http://arxiv.org/abs/2312.06887v1"}
{"created":"2023-12-11 23:20:31","title":"Relightful Harmonization: Lighting-aware Portrait Background Replacement","abstract":"Portrait harmonization aims to composite a subject into a new background, adjusting its lighting and color to ensure harmony with the background scene. Existing harmonization techniques often only focus on adjusting the global color and brightness of the foreground and ignore crucial illumination cues from the background such as apparent lighting direction, leading to unrealistic compositions. We introduce Relightful Harmonization, a lighting-aware diffusion model designed to seamlessly harmonize sophisticated lighting effect for the foreground portrait using any background image. Our approach unfolds in three stages. First, we introduce a lighting representation module that allows our diffusion model to encode lighting information from target image background. Second, we introduce an alignment network that aligns lighting features learned from image background with lighting features learned from panorama environment maps, which is a complete representation for scene illumination. Last, to further boost the photorealism of the proposed method, we introduce a novel data simulation pipeline that generates synthetic training pairs from a diverse range of natural images, which are used to refine the model. Our method outperforms existing benchmarks in visual fidelity and lighting coherence, showing superior generalization in real-world testing scenarios, highlighting its versatility and practicality.","sentences":["Portrait harmonization aims to composite a subject into a new background, adjusting its lighting and color to ensure harmony with the background scene.","Existing harmonization techniques often only focus on adjusting the global color and brightness of the foreground and ignore crucial illumination cues from the background such as apparent lighting direction, leading to unrealistic compositions.","We introduce Relightful Harmonization, a lighting-aware diffusion model designed to seamlessly harmonize sophisticated lighting effect for the foreground portrait using any background image.","Our approach unfolds in three stages.","First, we introduce a lighting representation module that allows our diffusion model to encode lighting information from target image background.","Second, we introduce an alignment network that aligns lighting features learned from image background with lighting features learned from panorama environment maps, which is a complete representation for scene illumination.","Last, to further boost the photorealism of the proposed method, we introduce a novel data simulation pipeline that generates synthetic training pairs from a diverse range of natural images, which are used to refine the model.","Our method outperforms existing benchmarks in visual fidelity and lighting coherence, showing superior generalization in real-world testing scenarios, highlighting its versatility and practicality."],"url":"http://arxiv.org/abs/2312.06886v1"}
{"created":"2023-12-11 22:49:02","title":"Dozerformer: Sequence Adaptive Sparse Transformer for Multivariate Time Series Forecasting","abstract":"Transformers have achieved remarkable performance in multivariate time series(MTS) forecasting due to their capability to capture long-term dependencies. However, the canonical attention mechanism has two key limitations: (1) its quadratic time complexity limits the sequence length, and (2) it generates future values from the entire historical sequence. To address this, we propose a Dozer Attention mechanism consisting of three sparse components: (1) Local, each query exclusively attends to keys within a localized window of neighboring time steps. (2) Stride, enables each query to attend to keys at predefined intervals. (3) Vary, allows queries to selectively attend to keys from a subset of the historical sequence. Notably, the size of this subset dynamically expands as forecasting horizons extend. Those three components are designed to capture essential attributes of MTS data, including locality, seasonality, and global temporal dependencies. Additionally, we present the Dozerformer Framework, incorporating the Dozer Attention mechanism for the MTS forecasting task. We evaluated the proposed Dozerformer framework with recent state-of-the-art methods on nine benchmark datasets and confirmed its superior performance. The code will be released after the manuscript is accepted.","sentences":["Transformers have achieved remarkable performance in multivariate time series(MTS) forecasting due to their capability to capture long-term dependencies.","However, the canonical attention mechanism has two key limitations: (1) its quadratic time complexity limits the sequence length, and (2) it generates future values from the entire historical sequence.","To address this, we propose a Dozer Attention mechanism consisting of three sparse components: (1) Local, each query exclusively attends to keys within a localized window of neighboring time steps.","(2) Stride, enables each query to attend to keys at predefined intervals.","(3) Vary, allows queries to selectively attend to keys from a subset of the historical sequence.","Notably, the size of this subset dynamically expands as forecasting horizons extend.","Those three components are designed to capture essential attributes of MTS data, including locality, seasonality, and global temporal dependencies.","Additionally, we present the Dozerformer Framework, incorporating the Dozer Attention mechanism for the MTS forecasting task.","We evaluated the proposed Dozerformer framework with recent state-of-the-art methods on nine benchmark datasets and confirmed its superior performance.","The code will be released after the manuscript is accepted."],"url":"http://arxiv.org/abs/2312.06874v1"}
{"created":"2023-12-11 22:39:12","title":"Using Analytics on Student Created Data to Content Validate Pedagogical Tools","abstract":"Conceptual and simulation models can function as useful pedagogical tools, however it is important to categorize different outcomes when evaluating them in order to more meaningfully interpret results. VERA is a ecology-based conceptual modeling software that enables users to simulate interactions between biotics and abiotics in an ecosystem, allowing users to form and then verify hypothesis through observing a time series of the species populations. In this paper, we classify this time series into common patterns found in the domain of ecological modeling through two methods, hierarchical clustering and curve fitting, illustrating a general methodology for showing content validity when combining different pedagogical tools. When applied to a diverse sample of 263 models containing 971 time series collected from three different VERA user categories: a Georgia Tech (GATECH), North Georgia Technical College (NGTC), and ``Self Directed Learners'', results showed agreement between both classification methods on 89.38\\% of the sample curves in the test set. This serves as a good indication that our methodology for determining content validity was successful.","sentences":["Conceptual and simulation models can function as useful pedagogical tools, however it is important to categorize different outcomes when evaluating them in order to more meaningfully interpret results.","VERA is a ecology-based conceptual modeling software that enables users to simulate interactions between biotics and abiotics in an ecosystem, allowing users to form and then verify hypothesis through observing a time series of the species populations.","In this paper, we classify this time series into common patterns found in the domain of ecological modeling through two methods, hierarchical clustering and curve fitting, illustrating a general methodology for showing content validity when combining different pedagogical tools.","When applied to a diverse sample of 263 models containing 971 time series collected from three different VERA user categories: a Georgia Tech (GATECH), North Georgia Technical College (NGTC), and ``Self Directed Learners'', results showed agreement between both classification methods on 89.38\\% of the sample curves in the test set.","This serves as a good indication that our methodology for determining content validity was successful."],"url":"http://arxiv.org/abs/2312.06871v1"}
{"created":"2023-12-11 22:29:54","title":"Adversarial Estimation of Topological Dimension with Harmonic Score Maps","abstract":"Quantification of the number of variables needed to locally explain complex data is often the first step to better understanding it. Existing techniques from intrinsic dimension estimation leverage statistical models to glean this information from samples within a neighborhood. However, existing methods often rely on well-picked hyperparameters and ample data as manifold dimension and curvature increases. Leveraging insight into the fixed point of the score matching objective as the score map is regularized by its Dirichlet energy, we show that it is possible to retrieve the topological dimension of the manifold learned by the score map. We then introduce a novel method to measure the learned manifold's topological dimension (i.e., local intrinsic dimension) using adversarial attacks, thereby generating useful interpretations of the learned manifold.","sentences":["Quantification of the number of variables needed to locally explain complex data is often the first step to better understanding it.","Existing techniques from intrinsic dimension estimation leverage statistical models to glean this information from samples within a neighborhood.","However, existing methods often rely on well-picked hyperparameters and ample data as manifold dimension and curvature increases.","Leveraging insight into the fixed point of the score matching objective as the score map is regularized by its Dirichlet energy, we show that it is possible to retrieve the topological dimension of the manifold learned by the score map.","We then introduce a novel method to measure the learned manifold's topological dimension (i.e., local intrinsic dimension) using adversarial attacks, thereby generating useful interpretations of the learned manifold."],"url":"http://arxiv.org/abs/2312.06869v1"}
{"created":"2023-12-11 22:28:51","title":"RAFIC: Retrieval-Augmented Few-shot Image Classification","abstract":"Few-shot image classification is the task of classifying unseen images to one of N mutually exclusive classes, using only a small number of training examples for each class. The limited availability of these examples (denoted as K) presents a significant challenge to classification accuracy in some cases. To address this, we have developed a method for augmenting the set of K with an addition set of A retrieved images. We call this system Retrieval-Augmented Few-shot Image Classification (RAFIC). Through a series of experiments, we demonstrate that RAFIC markedly improves performance of few-shot image classification across two challenging datasets. RAFIC consists of two main components: (a) a retrieval component which uses CLIP, LAION-5B, and faiss, in order to efficiently retrieve images similar to the supplied images, and (b) retrieval meta-learning, which learns to judiciously utilize the retrieved images. Code and data is available at github.com/amirziai/rafic.","sentences":["Few-shot image classification is the task of classifying unseen images to one of N mutually exclusive classes, using only a small number of training examples for each class.","The limited availability of these examples (denoted as K) presents a significant challenge to classification accuracy in some cases.","To address this, we have developed a method for augmenting the set of K with an addition set of A retrieved images.","We call this system Retrieval-Augmented Few-shot Image Classification (RAFIC).","Through a series of experiments, we demonstrate that RAFIC markedly improves performance of few-shot image classification across two challenging datasets.","RAFIC consists of two main components: (a) a retrieval component which uses CLIP, LAION-5B, and faiss, in order to efficiently retrieve images similar to the supplied images, and (b) retrieval meta-learning, which learns to judiciously utilize the retrieved images.","Code and data is available at github.com/amirziai/rafic."],"url":"http://arxiv.org/abs/2312.06868v1"}
{"created":"2023-12-11 22:12:20","title":"Disentangling Perceptions of Offensiveness: Cultural and Moral Correlates","abstract":"Perception of offensiveness is inherently subjective, shaped by the lived experiences and socio-cultural values of the perceivers. Recent years have seen substantial efforts to build AI-based tools that can detect offensive language at scale, as a means to moderate social media platforms, and to ensure safety of conversational AI technologies such as ChatGPT and Bard. However, existing approaches treat this task as a technical endeavor, built on top of data annotated for offensiveness by a global crowd workforce without any attention to the crowd workers' provenance or the values their perceptions reflect. We argue that cultural and psychological factors play a vital role in the cognitive processing of offensiveness, which is critical to consider in this context. We re-frame the task of determining offensiveness as essentially a matter of moral judgment -- deciding the boundaries of ethically wrong vs. right language within an implied set of socio-cultural norms. Through a large-scale cross-cultural study based on 4309 participants from 21 countries across 8 cultural regions, we demonstrate substantial cross-cultural differences in perceptions of offensiveness. More importantly, we find that individual moral values play a crucial role in shaping these variations: moral concerns about Care and Purity are significant mediating factors driving cross-cultural differences. These insights are of crucial importance as we build AI models for the pluralistic world, where the values they espouse should aim to respect and account for moral values in diverse geo-cultural contexts.","sentences":["Perception of offensiveness is inherently subjective, shaped by the lived experiences and socio-cultural values of the perceivers.","Recent years have seen substantial efforts to build AI-based tools that can detect offensive language at scale, as a means to moderate social media platforms, and to ensure safety of conversational AI technologies such as ChatGPT and Bard.","However, existing approaches treat this task as a technical endeavor, built on top of data annotated for offensiveness by a global crowd workforce without any attention to the crowd workers' provenance or the values their perceptions reflect.","We argue that cultural and psychological factors play a vital role in the cognitive processing of offensiveness, which is critical to consider in this context.","We re-frame the task of determining offensiveness as essentially a matter of moral judgment -- deciding the boundaries of ethically wrong vs. right language within an implied set of socio-cultural norms.","Through a large-scale cross-cultural study based on 4309 participants from 21 countries across 8 cultural regions, we demonstrate substantial cross-cultural differences in perceptions of offensiveness.","More importantly, we find that individual moral values play a crucial role in shaping these variations: moral concerns about Care and Purity are significant mediating factors driving cross-cultural differences.","These insights are of crucial importance as we build AI models for the pluralistic world, where the values they espouse should aim to respect and account for moral values in diverse geo-cultural contexts."],"url":"http://arxiv.org/abs/2312.06861v1"}
{"created":"2023-12-11 21:53:40","title":"Multimodal Pretraining of Medical Time Series and Notes","abstract":"Within the intensive care unit (ICU), a wealth of patient data, including clinical measurements and clinical notes, is readily available. This data is a valuable resource for comprehending patient health and informing medical decisions, but it also contains many challenges in analysis. Deep learning models show promise in extracting meaningful patterns, but they require extensive labeled data, a challenge in critical care. To address this, we propose a novel approach employing self-supervised pretraining, focusing on the alignment of clinical measurements and notes. Our approach combines contrastive and masked token prediction tasks during pretraining. Semi-supervised experiments on the MIMIC-III dataset demonstrate the effectiveness of our self-supervised pretraining. In downstream tasks, including in-hospital mortality prediction and phenotyping, our pretrained model outperforms baselines in settings where only a fraction of the data is labeled, emphasizing its ability to enhance ICU data analysis. Notably, our method excels in situations where very few labels are available, as evidenced by an increase in the AUC-ROC for in-hospital mortality by 0.17 and in AUC-PR for phenotyping by 0.1 when only 1% of labels are accessible. This work advances self-supervised learning in the healthcare domain, optimizing clinical insights from abundant yet challenging ICU data.","sentences":["Within the intensive care unit (ICU), a wealth of patient data, including clinical measurements and clinical notes, is readily available.","This data is a valuable resource for comprehending patient health and informing medical decisions, but it also contains many challenges in analysis.","Deep learning models show promise in extracting meaningful patterns, but they require extensive labeled data, a challenge in critical care.","To address this, we propose a novel approach employing self-supervised pretraining, focusing on the alignment of clinical measurements and notes.","Our approach combines contrastive and masked token prediction tasks during pretraining.","Semi-supervised experiments on the MIMIC-III dataset demonstrate the effectiveness of our self-supervised pretraining.","In downstream tasks, including in-hospital mortality prediction and phenotyping, our pretrained model outperforms baselines in settings where only a fraction of the data is labeled, emphasizing its ability to enhance ICU data analysis.","Notably, our method excels in situations where very few labels are available, as evidenced by an increase in the AUC-ROC for in-hospital mortality by 0.17 and in AUC-PR for phenotyping by 0.1 when only 1% of labels are accessible.","This work advances self-supervised learning in the healthcare domain, optimizing clinical insights from abundant yet challenging ICU data."],"url":"http://arxiv.org/abs/2312.06855v1"}
{"created":"2023-12-11 21:23:55","title":"Deep Learning based Modeling of Wireless Communication Channel with Fading","abstract":"In the realm of wireless communication, stochastic modeling of channels is instrumental for the assessment and design of operational systems. Deep learning neural networks (DLNN), including generative adversarial networks (GANs), are being used to approximate wireless Orthogonal frequency-division multiplexing (OFDM) channels with fading and noise, using real measurement data. These models primarily focus on channel output (y) distribution given input x: p(y|x), limiting their application scope. DLNN channel models have been tested predominantly on simple simulated channels. In this paper, we build both GANs and feedforward neural networks (FNN) to approximate a more general channel model, which is represented by a conditional probability density function (PDF) of receiving signal or power of node receiving power Prx: f_p_rx|d(()), where is communication distance. The stochastic models are trained and tested for the impact of fading channels on transmissions of OFDM QAM modulated signal and transmissions of general signal regardless of modulations. New metrics are proposed for evaluation of modeling accuracy and comparisons of the GAN-based model with the FNN-based model. Extensive experiments on Nakagami fading channel show accuracy and the effectiveness of the approaches.","sentences":["In the realm of wireless communication, stochastic modeling of channels is instrumental for the assessment and design of operational systems.","Deep learning neural networks (DLNN), including generative adversarial networks (GANs), are being used to approximate wireless Orthogonal frequency-division multiplexing (OFDM) channels with fading and noise, using real measurement data.","These models primarily focus on channel output (y) distribution given input x: p(y|x), limiting their application scope.","DLNN channel models have been tested predominantly on simple simulated channels.","In this paper, we build both GANs and feedforward neural networks (FNN) to approximate a more general channel model, which is represented by a conditional probability density function (PDF) of receiving signal or power of node receiving power Prx: f_p_rx|d(()), where is communication distance.","The stochastic models are trained and tested for the impact of fading channels on transmissions of OFDM QAM modulated signal and transmissions of general signal regardless of modulations.","New metrics are proposed for evaluation of modeling accuracy and comparisons of the GAN-based model with the FNN-based model.","Extensive experiments on Nakagami fading channel show accuracy and the effectiveness of the approaches."],"url":"http://arxiv.org/abs/2312.06849v1"}
{"created":"2023-12-11 20:54:59","title":"The unreasonable effectiveness of AI CADe polyp detectors to generalize to new countries","abstract":"$\\textbf{Background and aims}$: Artificial Intelligence (AI) Computer-Aided Detection (CADe) is commonly used for polyp detection, but data seen in clinical settings can differ from model training. Few studies evaluate how well CADe detectors perform on colonoscopies from countries not seen during training, and none are able to evaluate performance without collecting expensive and time-intensive labels.   $\\textbf{Methods}$: We trained a CADe polyp detector on Israeli colonoscopy videos (5004 videos, 1106 hours) and evaluated on Japanese videos (354 videos, 128 hours) by measuring the True Positive Rate (TPR) versus false alarms per minute (FAPM). We introduce a colonoscopy dissimilarity measure called \"MAsked mediCal Embedding Distance\" (MACE) to quantify differences between colonoscopies, without labels. We evaluated CADe on all Japan videos and on those with the highest MACE.   $\\textbf{Results}$: MACE correctly quantifies that narrow-band imaging (NBI) and chromoendoscopy (CE) frames are less similar to Israel data than Japan whitelight (bootstrapped z-test, |z| > 690, p < $10^{-8}$ for both). Despite differences in the data, CADe performance on Japan colonoscopies was non-inferior to Israel ones without additional training (TPR at 0.5 FAPM: 0.957 and 0.972 for Israel and Japan; TPR at 1.0 FAPM: 0.972 and 0.989 for Israel and Japan; superiority test t > 45.2, p < $10^{-8}$). Despite not being trained on NBI or CE, TPR on those subsets were non-inferior to Japan overall (non-inferiority test t > 47.3, p < $10^{-8}$, $\\delta$ = 1.5% for both).   $\\textbf{Conclusion}$: Differences that prevent CADe detectors from performing well in non-medical settings do not degrade the performance of our AI CADe polyp detector when applied to data from a new country. MACE can help medical AI models internationalize by identifying the most \"dissimilar\" data on which to evaluate models.","sentences":["$\\textbf{Background and aims}$:","Artificial Intelligence (AI) Computer-Aided Detection (CADe) is commonly used for polyp detection, but data seen in clinical settings can differ from model training.","Few studies evaluate how well CADe detectors perform on colonoscopies from countries not seen during training, and none are able to evaluate performance without collecting expensive and time-intensive labels.   ","$\\textbf{Methods}$: We trained a CADe polyp detector on Israeli colonoscopy videos (5004 videos, 1106 hours) and evaluated on Japanese videos (354 videos, 128 hours) by measuring the True Positive Rate (TPR) versus false alarms per minute (FAPM).","We introduce a colonoscopy dissimilarity measure called \"MAsked mediCal Embedding Distance\" (MACE) to quantify differences between colonoscopies, without labels.","We evaluated CADe on all Japan videos and on those with the highest MACE.   ","$\\textbf{Results}$:","MACE correctly quantifies that narrow-band imaging (NBI) and chromoendoscopy (CE) frames are less similar to Israel data than Japan whitelight (bootstrapped z-test, |z| > 690, p < $10^{-8}$ for both).","Despite differences in the data, CADe performance on Japan colonoscopies was non-inferior to Israel ones without additional training (TPR at 0.5 FAPM: 0.957 and 0.972 for Israel and Japan; TPR at 1.0 FAPM: 0.972 and 0.989 for Israel and Japan; superiority test t > 45.2, p < $10^{-8}$).","Despite not being trained on NBI or CE, TPR on those subsets were non-inferior to Japan overall (non-inferiority test t > 47.3, p < $10^{-8}$, $\\delta$ = 1.5% for both).   ","$\\textbf{Conclusion}$: Differences that prevent CADe detectors from performing well in non-medical settings do not degrade the performance of our AI CADe polyp detector when applied to data from a new country.","MACE can help medical AI models internationalize by identifying the most \"dissimilar\" data on which to evaluate models."],"url":"http://arxiv.org/abs/2312.06833v1"}
{"created":"2023-12-11 19:13:38","title":"Improving the Robustness of 3D Human Pose Estimation: A Benchmark and Learning from Noisy Input","abstract":"Despite the promising performance of current 3D human pose estimation techniques, understanding and enhancing their generalization on challenging in-the-wild videos remain an open problem. In this work, we focus on the robustness of 2D-to-3D pose lifters. To this end, we develop two benchmark datasets, namely Human3.6M-C and HumanEva-I-C, to examine the robustness of video-based 3D pose lifters to a wide range of common video corruptions including temporary occlusion, motion blur, and pixel-level noise. We observe the poor generalization of state-of-the-art 3D pose lifters in the presence of corruption and establish two techniques to tackle this issue. First, we introduce Temporal Additive Gaussian Noise (TAGN) as a simple yet effective 2D input pose data augmentation. Additionally, to incorporate the confidence scores output by the 2D pose detectors, we design a confidence-aware convolution (CA-Conv) block. Extensively tested on corrupted videos, the proposed strategies consistently boost the robustness of 3D pose lifters and serve as new baselines for future research.","sentences":["Despite the promising performance of current 3D human pose estimation techniques, understanding and enhancing their generalization on challenging in-the-wild videos remain an open problem.","In this work, we focus on the robustness of 2D-to-3D pose lifters.","To this end, we develop two benchmark datasets, namely Human3.6M-C and HumanEva-I-C, to examine the robustness of video-based 3D pose lifters to a wide range of common video corruptions including temporary occlusion, motion blur, and pixel-level noise.","We observe the poor generalization of state-of-the-art 3D pose lifters in the presence of corruption and establish two techniques to tackle this issue.","First, we introduce Temporal Additive Gaussian Noise (TAGN) as a simple yet effective 2D input pose data augmentation.","Additionally, to incorporate the confidence scores output by the 2D pose detectors, we design a confidence-aware convolution (CA-Conv) block.","Extensively tested on corrupted videos, the proposed strategies consistently boost the robustness of 3D pose lifters and serve as new baselines for future research."],"url":"http://arxiv.org/abs/2312.06797v1"}
{"created":"2023-12-11 19:06:58","title":"A Critique of Human-Autonomous Team Dynamics: Contrasting Qualitative and Quantitative Perspectives","abstract":"The critique paper provides an in-depth analysis of two influential studies in the field of Human-Autonomous Teams (HATs). Musick et al. explored qualitative dimensions of HAT dynamics, examining the influence of team composition on emotions, cognitive processes, and the development of team cognition. Their research revealed that teams with a majority of human members, known as Multi-Human HATs, generally surpass Multi-Agent HATs in performance, highlighting the critical influence of human perception on team dynamics. Employing qualitative interview analysis anchored in theoretical frameworks, Musick et al. captured the detailed subtleties of participants' experiences. In contrast, Schelble et al. utilized a quantitative methodology to provide data-driven insights into how the perception of AI teammates affects team performance. Despite the rich insights from Musick et al.'s qualitative research, their findings face limitations in terms of broader applicability. Both Musick et al. and Schelble et al. agree in their conclusions that Multi-Human HATs typically outperform their Multi-Agent counterparts, again emphasizing the crucial role of human perception in team dynamics. The critique paper suggests that future research should focus on understanding perceptions of teams heavily reliant on AI. Such investigations could illuminate how trust and skepticism are shaped in teams where AI plays a dominant role.","sentences":["The critique paper provides an in-depth analysis of two influential studies in the field of Human-Autonomous Teams (HATs).","Musick et al. explored qualitative dimensions of HAT dynamics, examining the influence of team composition on emotions, cognitive processes, and the development of team cognition.","Their research revealed that teams with a majority of human members, known as Multi-Human HATs, generally surpass Multi-Agent HATs in performance, highlighting the critical influence of human perception on team dynamics.","Employing qualitative interview analysis anchored in theoretical frameworks, Musick et al. captured the detailed subtleties of participants' experiences.","In contrast, Schelble et al. utilized a quantitative methodology to provide data-driven insights into how the perception of AI teammates affects team performance.","Despite the rich insights from Musick et al.'s qualitative research, their findings face limitations in terms of broader applicability.","Both Musick et al. and Schelble et al. agree in their conclusions that Multi-Human HATs typically outperform their Multi-Agent counterparts, again emphasizing the crucial role of human perception in team dynamics.","The critique paper suggests that future research should focus on understanding perceptions of teams heavily reliant on AI.","Such investigations could illuminate how trust and skepticism are shaped in teams where AI plays a dominant role."],"url":"http://arxiv.org/abs/2312.06789v1"}
