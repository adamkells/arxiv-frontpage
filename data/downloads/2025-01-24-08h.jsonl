{"created":"2025-01-23 18:59:47","title":"CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation","abstract":"Large language models (LLMs) have shown great potential in natural language processing tasks, but their application to machine translation (MT) remains challenging due to pretraining on English-centric data and the complexity of reinforcement learning from human feedback (RLHF). Direct Preference Optimization (DPO) has emerged as a simpler and more efficient alternative, but its performance depends heavily on the quality of preference data. To address this, we propose Confidence-Reward driven Preference Optimization (CRPO), a novel method that combines reward scores with model confidence to improve data selection for fine-tuning. CRPO selects challenging sentence pairs where the model is uncertain or underperforms, leading to more effective learning. While primarily designed for LLMs, CRPO also generalizes to encoder-decoder models like NLLB, demonstrating its versatility. Empirical results show that CRPO outperforms existing methods such as RS-DPO, RSO and MBR score in both translation accuracy and data efficiency.","sentences":["Large language models (LLMs) have shown great potential in natural language processing tasks, but their application to machine translation (MT) remains challenging due to pretraining on English-centric data and the complexity of reinforcement learning from human feedback (RLHF).","Direct Preference Optimization (DPO) has emerged as a simpler and more efficient alternative, but its performance depends heavily on the quality of preference data.","To address this, we propose Confidence-Reward driven Preference Optimization (CRPO), a novel method that combines reward scores with model confidence to improve data selection for fine-tuning.","CRPO selects challenging sentence pairs where the model is uncertain or underperforms, leading to more effective learning.","While primarily designed for LLMs, CRPO also generalizes to encoder-decoder models like NLLB, demonstrating its versatility.","Empirical results show that CRPO outperforms existing methods such as RS-DPO, RSO and MBR score in both translation accuracy and data efficiency."],"url":"http://arxiv.org/abs/2501.13927v1"}
{"created":"2025-01-23 18:59:30","title":"Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization","abstract":"Test-time adaptation (TTA) has demonstrated significant potential in addressing distribution shifts between training and testing data. Open-set test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to an unlabeled target domain that contains unknown classes. This task becomes more challenging when multiple modalities are involved. Existing methods have primarily focused on unimodal OSTTA, often filtering out low-confidence samples without addressing the complexities of multimodal data. In this work, we present Adaptive Entropy-aware Optimization (AEO), a novel framework specifically designed to tackle Multimodal Open-set Test-time Adaptation (MM-OSTTA) for the first time. Our analysis shows that the entropy difference between known and unknown samples in the target domain strongly correlates with MM-OSTTA performance. To leverage this, we propose two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP). These components enhance the ability of model to distinguish unknown class samples during online adaptation by amplifying the entropy difference between known and unknown samples. To thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish a new benchmark derived from existing datasets. This benchmark includes two downstream tasks and incorporates five modalities. Extensive experiments across various domain shift situations demonstrate the efficacy and versatility of the AEO framework. Additionally, we highlight the strong performance of AEO in long-term and continual MM-OSTTA settings, both of which are challenging and highly relevant to real-world applications. Our source code is available at https://github.com/donghao51/AEO.","sentences":["Test-time adaptation (TTA) has demonstrated significant potential in addressing distribution shifts between training and testing data.","Open-set test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to an unlabeled target domain that contains unknown classes.","This task becomes more challenging when multiple modalities are involved.","Existing methods have primarily focused on unimodal OSTTA, often filtering out low-confidence samples without addressing the complexities of multimodal data.","In this work, we present Adaptive Entropy-aware Optimization (AEO), a novel framework specifically designed to tackle Multimodal Open-set Test-time Adaptation (MM-OSTTA) for the first time.","Our analysis shows that the entropy difference between known and unknown samples in the target domain strongly correlates with MM-OSTTA performance.","To leverage this, we propose two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP).","These components enhance the ability of model to distinguish unknown class samples during online adaptation by amplifying the entropy difference between known and unknown samples.","To thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish a new benchmark derived from existing datasets.","This benchmark includes two downstream tasks and incorporates five modalities.","Extensive experiments across various domain shift situations demonstrate the efficacy and versatility of the AEO framework.","Additionally, we highlight the strong performance of AEO in long-term and continual MM-OSTTA settings, both of which are challenging and highly relevant to real-world applications.","Our source code is available at https://github.com/donghao51/AEO."],"url":"http://arxiv.org/abs/2501.13924v1"}
{"created":"2025-01-23 18:59:30","title":"GeoPixel: Pixel Grounding Large Multimodal Model in Remote Sensing","abstract":"Recent advances in large multimodal models (LMMs) have recognized fine-grained grounding as an imperative factor of visual understanding and dialogue. However, the benefits of such representation in LMMs are limited to the natural image domain, and these models perform poorly for remote sensing (RS). The distinct overhead viewpoint, scale variation, and presence of small objects in high-resolution RS imagery present a unique challenge in region-level comprehension. Moreover, the development of the grounding conversation capability of LMMs within RS is hindered by the lack of granular, RS domain-specific grounded data. Addressing these limitations, we propose GeoPixel - the first end-to-end high resolution RS-LMM that supports pixel-level grounding. This capability allows fine-grained visual perception by generating interleaved masks in conversation. GeoPixel supports up to 4K HD resolution in any aspect ratio, ideal for high-precision RS image analysis. To support the grounded conversation generation (GCG) in RS imagery, we curate a visually grounded dataset GeoPixelD through a semi-automated pipeline that utilizes set-of-marks prompting and spatial priors tailored for RS data to methodically control the data generation process. GeoPixel demonstrates superior performance in pixel-level comprehension, surpassing existing LMMs in both single-target and multi-target segmentation tasks. Our methodological ablation studies validate the effectiveness of each component in the overall architecture. Our code and data will be publicly released.","sentences":["Recent advances in large multimodal models (LMMs) have recognized fine-grained grounding as an imperative factor of visual understanding and dialogue.","However, the benefits of such representation in LMMs are limited to the natural image domain, and these models perform poorly for remote sensing (RS).","The distinct overhead viewpoint, scale variation, and presence of small objects in high-resolution RS imagery present a unique challenge in region-level comprehension.","Moreover, the development of the grounding conversation capability of LMMs within RS is hindered by the lack of granular, RS domain-specific grounded data.","Addressing these limitations, we propose GeoPixel - the first end-to-end high resolution RS-LMM that supports pixel-level grounding.","This capability allows fine-grained visual perception by generating interleaved masks in conversation.","GeoPixel supports up to 4K HD resolution in any aspect ratio, ideal for high-precision RS image analysis.","To support the grounded conversation generation (GCG) in RS imagery, we curate a visually grounded dataset GeoPixelD through a semi-automated pipeline that utilizes set-of-marks prompting and spatial priors tailored for RS data to methodically control the data generation process.","GeoPixel demonstrates superior performance in pixel-level comprehension, surpassing existing LMMs in both single-target and multi-target segmentation tasks.","Our methodological ablation studies validate the effectiveness of each component in the overall architecture.","Our code and data will be publicly released."],"url":"http://arxiv.org/abs/2501.13925v1"}
{"created":"2025-01-23 18:59:02","title":"The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities","abstract":"Breeze 2 is a suite of advanced multi-modal language models, available in 3B and 8B parameter configurations, specifically designed to enhance Traditional Chinese language representation. Building upon the Llama 3, Breeze 2 continues pretraining on an extensive corpus to enhance the linguistic and cultural heritage of Traditional Chinese. It incorporates vision-aware capabilities through a visual encoder and a bridge module, and supports function-calling via prompt templates and post-training on function-calling data. The effectiveness of Breeze 2 is benchmarked across various tasks, including Taiwan general knowledge, instruction-following, long context, function calling, and vision understanding. Furthermore, we showcase the capabilities of the its 3B model in a mobile application. We are publicly releasing all Breeze 2 models under the Llama 3 Community License.","sentences":["Breeze 2 is a suite of advanced multi-modal language models, available in 3B and 8B parameter configurations, specifically designed to enhance Traditional Chinese language representation.","Building upon the Llama 3, Breeze 2 continues pretraining on an extensive corpus to enhance the linguistic and cultural heritage of Traditional Chinese.","It incorporates vision-aware capabilities through a visual encoder and a bridge module, and supports function-calling via prompt templates and post-training on function-calling data.","The effectiveness of Breeze 2 is benchmarked across various tasks, including Taiwan general knowledge, instruction-following, long context, function calling, and vision understanding.","Furthermore, we showcase the capabilities of the its 3B model in a mobile application.","We are publicly releasing all Breeze 2 models under the Llama 3 Community License."],"url":"http://arxiv.org/abs/2501.13921v1"}
{"created":"2025-01-23 18:58:03","title":"Temporal Preference Optimization for Long-Form Video Understanding","abstract":"Despite significant advancements in video large multimodal models (video-LMMs), achieving effective temporal grounding in long-form videos remains a challenge for existing models. To address this limitation, we propose Temporal Preference Optimization (TPO), a novel post-training framework designed to enhance the temporal grounding capabilities of video-LMMs through preference learning. TPO adopts a self-training approach that enables models to differentiate between well-grounded and less accurate temporal responses by leveraging curated preference datasets at two granularities: localized temporal grounding, which focuses on specific video segments, and comprehensive temporal grounding, which captures extended temporal dependencies across entire video sequences. By optimizing on these preference datasets, TPO significantly enhances temporal understanding while reducing reliance on manually annotated data. Extensive experiments on three long-form video understanding benchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness of TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO establishes itself as the leading 7B model on the Video-MME benchmark, underscoring the potential of TPO as a scalable and efficient solution for advancing temporal reasoning in long-form video understanding. Project page: https://ruili33.github.io/tpo_website.","sentences":["Despite significant advancements in video large multimodal models (video-LMMs), achieving effective temporal grounding in long-form videos remains a challenge for existing models.","To address this limitation, we propose Temporal Preference Optimization (TPO), a novel post-training framework designed to enhance the temporal grounding capabilities of video-LMMs through preference learning.","TPO adopts a self-training approach that enables models to differentiate between well-grounded and less accurate temporal responses by leveraging curated preference datasets at two granularities: localized temporal grounding, which focuses on specific video segments, and comprehensive temporal grounding, which captures extended temporal dependencies across entire video sequences.","By optimizing on these preference datasets, TPO significantly enhances temporal understanding while reducing reliance on manually annotated data.","Extensive experiments on three long-form video understanding benchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness of TPO across two state-of-the-art video-LMMs.","Notably, LLaVA-Video-TPO establishes itself as the leading 7B model on the Video-MME benchmark, underscoring the potential of TPO as a scalable and efficient solution for advancing temporal reasoning in long-form video understanding.","Project page: https://ruili33.github.io/tpo_website."],"url":"http://arxiv.org/abs/2501.13919v1"}
{"created":"2025-01-23 18:52:47","title":"Binary Diffusion Probabilistic Model","abstract":"We introduce the Binary Diffusion Probabilistic Model (BDPM), a novel generative model optimized for binary data representations. While denoising diffusion probabilistic models (DDPMs) have demonstrated notable success in tasks like image synthesis and restoration, traditional DDPMs rely on continuous data representations and mean squared error (MSE) loss for training, applying Gaussian noise models that may not be optimal for discrete or binary data structures. BDPM addresses this by decomposing images into bitplanes and employing XOR-based noise transformations, with a denoising model trained using binary cross-entropy loss. This approach enables precise noise control and computationally efficient inference, significantly lowering computational costs and improving model convergence. When evaluated on image restoration tasks such as image super-resolution, inpainting, and blind image restoration, BDPM outperforms state-of-the-art methods on the FFHQ, CelebA, and CelebA-HQ datasets. Notably, BDPM requires fewer inference steps than traditional DDPM models to reach optimal results, showcasing enhanced inference efficiency.","sentences":["We introduce the Binary Diffusion Probabilistic Model (BDPM), a novel generative model optimized for binary data representations.","While denoising diffusion probabilistic models (DDPMs) have demonstrated notable success in tasks like image synthesis and restoration, traditional DDPMs rely on continuous data representations and mean squared error (MSE) loss for training, applying Gaussian noise models that may not be optimal for discrete or binary data structures.","BDPM addresses this by decomposing images into bitplanes and employing XOR-based noise transformations, with a denoising model trained using binary cross-entropy loss.","This approach enables precise noise control and computationally efficient inference, significantly lowering computational costs and improving model convergence.","When evaluated on image restoration tasks such as image super-resolution, inpainting, and blind image restoration, BDPM outperforms state-of-the-art methods on the FFHQ, CelebA, and CelebA-HQ datasets.","Notably, BDPM requires fewer inference steps than traditional DDPM models to reach optimal results, showcasing enhanced inference efficiency."],"url":"http://arxiv.org/abs/2501.13915v1"}
{"created":"2025-01-23 18:49:33","title":"Analysis of Indic Language Capabilities in LLMs","abstract":"This report evaluates the performance of text-in text-out Large Language Models (LLMs) to understand and generate Indic languages. This evaluation is used to identify and prioritize Indic languages suited for inclusion in safety benchmarks. We conduct this study by reviewing existing evaluation studies and datasets; and a set of twenty-eight LLMs that support Indic languages. We analyze the LLMs on the basis of the training data, license for model and data, type of access and model developers. We also compare Indic language performance across evaluation datasets and find that significant performance disparities in performance across Indic languages. Hindi is the most widely represented language in models. While model performance roughly correlates with number of speakers for the top five languages, the assessment after that varies.","sentences":["This report evaluates the performance of text-in text-out Large Language Models (LLMs) to understand and generate Indic languages.","This evaluation is used to identify and prioritize Indic languages suited for inclusion in safety benchmarks.","We conduct this study by reviewing existing evaluation studies and datasets; and a set of twenty-eight LLMs that support Indic languages.","We analyze the LLMs on the basis of the training data, license for model and data, type of access and model developers.","We also compare Indic language performance across evaluation datasets and find that significant performance disparities in performance across Indic languages.","Hindi is the most widely represented language in models.","While model performance roughly correlates with number of speakers for the top five languages, the assessment after that varies."],"url":"http://arxiv.org/abs/2501.13912v1"}
{"created":"2025-01-23 18:35:15","title":"On Learning Representations for Tabular Data Distillation","abstract":"Dataset distillation generates a small set of information-rich instances from a large dataset, resulting in reduced storage requirements, privacy or copyright risks, and computational costs for downstream modeling, though much of the research has focused on the image data modality. We study tabular data distillation, which brings in novel challenges such as the inherent feature heterogeneity and the common use of non-differentiable learning models (such as decision tree ensembles and nearest-neighbor predictors). To mitigate these challenges, we present $\\texttt{TDColER}$, a tabular data distillation framework via column embeddings-based representation learning. To evaluate this framework, we also present a tabular data distillation benchmark, ${{\\sf \\small TDBench}}$. Based on an elaborate evaluation on ${{\\sf \\small TDBench}}$, resulting in 226,890 distilled datasets and 548,880 models trained on them, we demonstrate that $\\texttt{TDColER}$ is able to boost the distilled data quality of off-the-shelf distillation schemes by 0.5-143% across 7 different tabular learning models.","sentences":["Dataset distillation generates a small set of information-rich instances from a large dataset, resulting in reduced storage requirements, privacy or copyright risks, and computational costs for downstream modeling, though much of the research has focused on the image data modality.","We study tabular data distillation, which brings in novel challenges such as the inherent feature heterogeneity and the common use of non-differentiable learning models (such as decision tree ensembles and nearest-neighbor predictors).","To mitigate these challenges, we present $\\texttt{TDColER}$, a tabular data distillation framework via column embeddings-based representation learning.","To evaluate this framework, we also present a tabular data distillation benchmark, ${{\\sf \\small TDBench}}$. Based on an elaborate evaluation on ${{\\sf \\small TDBench}}$, resulting in 226,890 distilled datasets and 548,880 models trained on them, we demonstrate that $\\texttt{TDColER}$ is able to boost the distilled data quality of off-the-shelf distillation schemes by 0.5-143% across 7 different tabular learning models."],"url":"http://arxiv.org/abs/2501.13905v1"}
{"created":"2025-01-23 18:16:21","title":"GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration","abstract":"Graphical User Interface (GUI) action grounding is a critical step in GUI automation that maps language instructions to actionable elements on GUI screens. Most recent works of GUI action grounding leverage large GUI datasets to fine-tune MLLMs. However, the fine-tuning data always covers limited GUI environments, and we find the performance of the resulting model deteriorates in novel environments. We argue that the GUI grounding models should be further aligned to the novel environments to reveal their full potential, when the inference is known to involve novel environments, i.e., environments not used during the previous fine-tuning. To realize this, we first propose GUI-Bee, an MLLM-based autonomous agent, to collect high-quality, environment-specific data through exploration and then continuously fine-tune GUI grounding models with the collected data. Our agent leverages a novel Q-value-Incentive In-Context Reinforcement Learning (Q-ICRL) method to optimize exploration efficiency and data quality. Additionally, we introduce NovelScreenSpot, a benchmark for testing how well the data can help align GUI action grounding models to novel environments and demonstrate the effectiveness of data collected by GUI-Bee in the experiments. Furthermore, we conduct an ablation study to validate the Q-ICRL method in enhancing the efficiency of GUI-Bee. Project page: https://gui-bee.github.io","sentences":["Graphical User Interface (GUI) action grounding is a critical step in GUI automation that maps language instructions to actionable elements on GUI screens.","Most recent works of GUI action grounding leverage large GUI datasets to fine-tune MLLMs.","However, the fine-tuning data always covers limited GUI environments, and we find the performance of the resulting model deteriorates in novel environments.","We argue that the GUI grounding models should be further aligned to the novel environments to reveal their full potential, when the inference is known to involve novel environments, i.e., environments not used during the previous fine-tuning.","To realize this, we first propose GUI-Bee, an MLLM-based autonomous agent, to collect high-quality, environment-specific data through exploration and then continuously fine-tune GUI grounding models with the collected data.","Our agent leverages a novel Q-value-Incentive In-Context Reinforcement Learning (Q-ICRL) method to optimize exploration efficiency and data quality.","Additionally, we introduce NovelScreenSpot, a benchmark for testing how well the data can help align GUI action grounding models to novel environments and demonstrate the effectiveness of data collected by GUI-Bee in the experiments.","Furthermore, we conduct an ablation study to validate the Q-ICRL method in enhancing the efficiency of GUI-Bee.","Project page: https://gui-bee.github.io"],"url":"http://arxiv.org/abs/2501.13896v1"}
{"created":"2025-01-23 18:04:21","title":"Federated Granger Causality Learning for Interdependent Clients with State Space Representation","abstract":"Advanced sensors and IoT devices have improved the monitoring and control of complex industrial enterprises. They have also created an interdependent fabric of geographically distributed process operations (clients) across these enterprises. Granger causality is an effective approach to detect and quantify interdependencies by examining how one client's state affects others over time. Understanding these interdependencies captures how localized events, such as faults and disruptions, can propagate throughout the system, possibly causing widespread operational impacts. However, the large volume and complexity of industrial data pose challenges in modeling these interdependencies. This paper develops a federated approach to learning Granger causality. We utilize a linear state space system framework that leverages low-dimensional state estimates to analyze interdependencies. This addresses bandwidth limitations and the computational burden commonly associated with centralized data processing. We propose augmenting the client models with the Granger causality information learned by the server through a Machine Learning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover, we include a differential privacy analysis to ensure data security while preserving causal insights. Using synthetic data, we conduct comprehensive experiments to demonstrate the robustness of our approach to perturbations in causality, the scalability to the size of communication, number of clients, and the dimensions of raw data. We also evaluate the performance on two real-world industrial control system datasets by reporting the volume of data saved by decentralization.","sentences":["Advanced sensors and IoT devices have improved the monitoring and control of complex industrial enterprises.","They have also created an interdependent fabric of geographically distributed process operations (clients) across these enterprises.","Granger causality is an effective approach to detect and quantify interdependencies by examining how one client's state affects others over time.","Understanding these interdependencies captures how localized events, such as faults and disruptions, can propagate throughout the system, possibly causing widespread operational impacts.","However, the large volume and complexity of industrial data pose challenges in modeling these interdependencies.","This paper develops a federated approach to learning Granger causality.","We utilize a linear state space system framework that leverages low-dimensional state estimates to analyze interdependencies.","This addresses bandwidth limitations and the computational burden commonly associated with centralized data processing.","We propose augmenting the client models with the Granger causality information learned by the server through a Machine Learning (ML) function.","We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates.","We also study the convergence of the framework to a centralized oracle model.","Moreover, we include a differential privacy analysis to ensure data security while preserving causal insights.","Using synthetic data, we conduct comprehensive experiments to demonstrate the robustness of our approach to perturbations in causality, the scalability to the size of communication, number of clients, and the dimensions of raw data.","We also evaluate the performance on two real-world industrial control system datasets by reporting the volume of data saved by decentralization."],"url":"http://arxiv.org/abs/2501.13890v1"}
{"created":"2025-01-23 18:01:19","title":"Generating Realistic Forehead-Creases for User Verification via Conditioned Piecewise Polynomial Curves","abstract":"We propose a trait-specific image generation method that models forehead creases geometrically using B-spline and B\\'ezier curves. This approach ensures the realistic generation of both principal creases and non-prominent crease patterns, effectively constructing detailed and authentic forehead-crease images. These geometrically rendered images serve as visual prompts for a diffusion-based Edge-to-Image translation model, which generates corresponding mated samples. The resulting novel synthetic identities are then used to train a forehead-crease verification network. To enhance intra-subject diversity in the generated samples, we employ two strategies: (a) perturbing the control points of B-splines under defined constraints to maintain label consistency, and (b) applying image-level augmentations to the geometric visual prompts, such as dropout and elastic transformations, specifically tailored to crease patterns. By integrating the proposed synthetic dataset with real-world data, our method significantly improves the performance of forehead-crease verification systems under a cross-database verification protocol.","sentences":["We propose a trait-specific image generation method that models forehead creases geometrically using B-spline and B\\'ezier curves.","This approach ensures the realistic generation of both principal creases and non-prominent crease patterns, effectively constructing detailed and authentic forehead-crease images.","These geometrically rendered images serve as visual prompts for a diffusion-based Edge-to-Image translation model, which generates corresponding mated samples.","The resulting novel synthetic identities are then used to train a forehead-crease verification network.","To enhance intra-subject diversity in the generated samples, we employ two strategies: (a) perturbing the control points of B-splines under defined constraints to maintain label consistency, and (b) applying image-level augmentations to the geometric visual prompts, such as dropout and elastic transformations, specifically tailored to crease patterns.","By integrating the proposed synthetic dataset with real-world data, our method significantly improves the performance of forehead-crease verification systems under a cross-database verification protocol."],"url":"http://arxiv.org/abs/2501.13889v1"}
{"created":"2025-01-23 18:01:01","title":"Multimodal Sensor Dataset for Monitoring Older Adults Post Lower-Limb Fractures in Community Settings","abstract":"Lower-Limb Fractures (LLF) are a major health concern for older adults, often leading to reduced mobility and prolonged recovery, potentially impairing daily activities and independence. During recovery, older adults frequently face social isolation and functional decline, complicating rehabilitation and adversely affecting physical and mental health. Multi-modal sensor platforms that continuously collect data and analyze it using machine-learning algorithms can remotely monitor this population and infer health outcomes. They can also alert clinicians to individuals at risk of isolation and decline. This paper presents a new publicly available multi-modal sensor dataset, MAISON-LLF, collected from older adults recovering from LLF in community settings. The dataset includes data from smartphone and smartwatch sensors, motion detectors, sleep-tracking mattresses, and clinical questionnaires on isolation and decline. The dataset was collected from ten older adults living alone at home for eight weeks each, totaling 560 days of 24-hour sensor data. For technical validation, supervised machine-learning and deep-learning models were developed using the sensor and clinical questionnaire data, providing a foundational comparison for the research community.","sentences":["Lower-Limb Fractures (LLF) are a major health concern for older adults, often leading to reduced mobility and prolonged recovery, potentially impairing daily activities and independence.","During recovery, older adults frequently face social isolation and functional decline, complicating rehabilitation and adversely affecting physical and mental health.","Multi-modal sensor platforms that continuously collect data and analyze it using machine-learning algorithms can remotely monitor this population and infer health outcomes.","They can also alert clinicians to individuals at risk of isolation and decline.","This paper presents a new publicly available multi-modal sensor dataset, MAISON-LLF, collected from older adults recovering from LLF in community settings.","The dataset includes data from smartphone and smartwatch sensors, motion detectors, sleep-tracking mattresses, and clinical questionnaires on isolation and decline.","The dataset was collected from ten older adults living alone at home for eight weeks each, totaling 560 days of 24-hour sensor data.","For technical validation, supervised machine-learning and deep-learning models were developed using the sensor and clinical questionnaire data, providing a foundational comparison for the research community."],"url":"http://arxiv.org/abs/2501.13888v1"}
{"created":"2025-01-23 17:41:40","title":"Everyone-Can-Sing: Zero-Shot Singing Voice Synthesis and Conversion with Speech Reference","abstract":"We propose a unified framework for Singing Voice Synthesis (SVS) and Conversion (SVC), addressing the limitations of existing approaches in cross-domain SVS/SVC, poor output musicality, and scarcity of singing data. Our framework enables control over multiple aspects, including language content based on lyrics, performance attributes based on a musical score, singing style and vocal techniques based on a selector, and voice identity based on a speech sample. The proposed zero-shot learning paradigm consists of one SVS model and two SVC models, utilizing pre-trained content embeddings and a diffusion-based generator. The proposed framework is also trained on mixed datasets comprising both singing and speech audio, allowing singing voice cloning based on speech reference. Experiments show substantial improvements in timbre similarity and musicality over state-of-the-art baselines, providing insights into other low-data music tasks such as instrumental style transfer. Examples can be found at: everyone-can-sing.github.io.","sentences":["We propose a unified framework for Singing Voice Synthesis (SVS) and Conversion (SVC), addressing the limitations of existing approaches in cross-domain SVS/SVC, poor output musicality, and scarcity of singing data.","Our framework enables control over multiple aspects, including language content based on lyrics, performance attributes based on a musical score, singing style and vocal techniques based on a selector, and voice identity based on a speech sample.","The proposed zero-shot learning paradigm consists of one SVS model and two SVC models, utilizing pre-trained content embeddings and a diffusion-based generator.","The proposed framework is also trained on mixed datasets comprising both singing and speech audio, allowing singing voice cloning based on speech reference.","Experiments show substantial improvements in timbre similarity and musicality over state-of-the-art baselines, providing insights into other low-data music tasks such as instrumental style transfer.","Examples can be found at: everyone-can-sing.github.io."],"url":"http://arxiv.org/abs/2501.13870v1"}
{"created":"2025-01-23 17:40:28","title":"Lost in Siting: The Hidden Carbon Cost of Inequitable Residential Solar Installations","abstract":"The declining cost of solar photovoltaics (PV) combined with strong federal and state-level incentives have resulted in a high number of residential solar PV installations in the US. However, these installations are concentrated in particular regions, such as California, and demographics, such as high-income Asian neighborhoods. This inequitable distribution creates an illusion that further increasing residential solar installations will become increasingly challenging. Furthermore, while the inequity in solar installations has received attention, no prior comprehensive work has been done on understanding whether our current trajectory of residential solar adoption is energy- and carbon-efficient. In this paper, we reveal the hidden energy and carbon cost of the inequitable distribution of existing installations. Using US-based data on carbon offset potential, the amount of avoided carbon emissions from using rooftop PV instead of electric grid energy, and the number of existing solar installations, we surprisingly observe that locations and demographics with a higher carbon offset potential have fewer existing installations. For instance, neighborhoods with relatively higher black population have 7.4% higher carbon offset potential than average but 36.7% fewer installations; lower-income neighborhoods have 14.7% higher potential and 47% fewer installations. We propose several equity- and carbon-aware solar siting strategies. In evaluating these strategies, we develop Sunsight, a toolkit that combines simulation/visualization tools and our relevant datasets, which we are releasing publicly. Our projections show that a multi-objective siting strategy can address two problems at once; namely, it can improve societal outcomes in terms of distributional equity and simultaneously improve the carbon-efficiency (i.e., climate impact) of current installation trends by up to 39.8%.","sentences":["The declining cost of solar photovoltaics (PV) combined with strong federal and state-level incentives have resulted in a high number of residential solar PV installations in the US.","However, these installations are concentrated in particular regions, such as California, and demographics, such as high-income Asian neighborhoods.","This inequitable distribution creates an illusion that further increasing residential solar installations will become increasingly challenging.","Furthermore, while the inequity in solar installations has received attention, no prior comprehensive work has been done on understanding whether our current trajectory of residential solar adoption is energy- and carbon-efficient.","In this paper, we reveal the hidden energy and carbon cost of the inequitable distribution of existing installations.","Using US-based data on carbon offset potential, the amount of avoided carbon emissions from using rooftop PV instead of electric grid energy, and the number of existing solar installations, we surprisingly observe that locations and demographics with a higher carbon offset potential have fewer existing installations.","For instance, neighborhoods with relatively higher black population have 7.4% higher carbon offset potential than average but 36.7% fewer installations; lower-income neighborhoods have 14.7% higher potential and 47% fewer installations.","We propose several equity- and carbon-aware solar siting strategies.","In evaluating these strategies, we develop Sunsight, a toolkit that combines simulation/visualization tools and our relevant datasets, which we are releasing publicly.","Our projections show that a multi-objective siting strategy can address two problems at once; namely, it can improve societal outcomes in terms of distributional equity and simultaneously improve the carbon-efficiency (i.e., climate impact) of current installation trends by up to 39.8%."],"url":"http://arxiv.org/abs/2501.13868v1"}
{"created":"2025-01-23 17:38:22","title":"Threshold Selection for Iterative Decoding of $(v,w)$-regular Binary Codes","abstract":"Iterative bit flipping decoders are an efficient and effective decoder choice for decoding codes which admit a sparse parity-check matrix. Among these, sparse $(v,w)$-regular codes, which include LDPC and MDPC codes are of particular interest both for efficient data correction and the design of cryptographic primitives. In attaining the decoding the choice of the bit flipping thresholds, which can be determined either statically, or during the decoder execution by using information coming from the initial syndrome value and its updates. In this work, we analyze a two-iterations parallel hard decision bit flipping decoders and propose concrete criteria for threshold determination, backed by a closed form model. In doing so, we introduce a new tightly fitting model for the distribution of the Hamming weight of the syndrome after the first decoder iteration and substantial improvements on the DFR estimation with respect to existing approaches.","sentences":["Iterative bit flipping decoders are an efficient and effective decoder choice for decoding codes which admit a sparse parity-check matrix.","Among these, sparse $(v,w)$-regular codes, which include LDPC and MDPC codes are of particular interest both for efficient data correction and the design of cryptographic primitives.","In attaining the decoding the choice of the bit flipping thresholds, which can be determined either statically, or during the decoder execution by using information coming from the initial syndrome value and its updates.","In this work, we analyze a two-iterations parallel hard decision bit flipping decoders and propose concrete criteria for threshold determination, backed by a closed form model.","In doing so, we introduce a new tightly fitting model for the distribution of the Hamming weight of the syndrome after the first decoder iteration and substantial improvements on the DFR estimation with respect to existing approaches."],"url":"http://arxiv.org/abs/2501.13865v1"}
{"created":"2025-01-23 17:36:48","title":"Autoencoders for Anomaly Detection are Unreliable","abstract":"Autoencoders are frequently used for anomaly detection, both in the unsupervised and semi-supervised settings. They rely on the assumption that when trained using the reconstruction loss, they will be able to reconstruct normal data more accurately than anomalous data. Some recent works have posited that this assumption may not always hold, but little has been done to study the validity of the assumption in theory. In this work we show that this assumption indeed does not hold, and illustrate that anomalies, lying far away from normal data, can be perfectly reconstructed in practice. We revisit the theory of failure of linear autoencoders for anomaly detection by showing how they can perfectly reconstruct out of bounds, or extrapolate undesirably, and note how this can be dangerous in safety critical applications. We connect this to non-linear autoencoders through experiments on both tabular data and real-world image data, the two primary application areas of autoencoders for anomaly detection.","sentences":["Autoencoders are frequently used for anomaly detection, both in the unsupervised and semi-supervised settings.","They rely on the assumption that when trained using the reconstruction loss, they will be able to reconstruct normal data more accurately than anomalous data.","Some recent works have posited that this assumption may not always hold, but little has been done to study the validity of the assumption in theory.","In this work we show that this assumption indeed does not hold, and illustrate that anomalies, lying far away from normal data, can be perfectly reconstructed in practice.","We revisit the theory of failure of linear autoencoders for anomaly detection by showing how they can perfectly reconstruct out of bounds, or extrapolate undesirably, and note how this can be dangerous in safety critical applications.","We connect this to non-linear autoencoders through experiments on both tabular data and real-world image data, the two primary application areas of autoencoders for anomaly detection."],"url":"http://arxiv.org/abs/2501.13864v1"}
{"created":"2025-01-23 17:29:50","title":"The Lock Generative Adversarial Network for Medical Waveform Anomaly Detection","abstract":"Waveform signal analysis is a complex and important task in medical care. For example, mechanical ventilators are critical life-support machines, but they can cause serious injury to patients if they are out of synchronization with the patients' own breathing reflex. This asynchrony is revealed by the waveforms showing flow and pressure histories. Likewise, electrocardiograms record the electrical activity of a patients' heart as a set of waveforms, and anomalous waveforms can reveal important disease states. In both cases, subtle variations in a complex waveform are important information for patient care; signals which may be missed or mis-interpreted by human caregivers.   We report on the design of a novel Lock Generative Adversarial Network architecture for anomaly detection in raw or summarized medical waveform data. The proposed architecture uses alternating optimization of the generator and discriminator networks to solve the convergence dilemma. Furthermore, the fidelity of the generator networks' outputs to the actual distribution of anomalous data is improved via synthetic minority oversampling. We evaluate this new architecture on one ventilator asynchrony dataset, and two electrocardiogram datasets, finding that the performance was either equal or superior to the state-of-the art on all three.","sentences":["Waveform signal analysis is a complex and important task in medical care.","For example, mechanical ventilators are critical life-support machines, but they can cause serious injury to patients if they are out of synchronization with the patients' own breathing reflex.","This asynchrony is revealed by the waveforms showing flow and pressure histories.","Likewise, electrocardiograms record the electrical activity of a patients' heart as a set of waveforms, and anomalous waveforms can reveal important disease states.","In both cases, subtle variations in a complex waveform are important information for patient care; signals which may be missed or mis-interpreted by human caregivers.   ","We report on the design of a novel Lock Generative Adversarial Network architecture for anomaly detection in raw or summarized medical waveform data.","The proposed architecture uses alternating optimization of the generator and discriminator networks to solve the convergence dilemma.","Furthermore, the fidelity of the generator networks' outputs to the actual distribution of anomalous data is improved via synthetic minority oversampling.","We evaluate this new architecture on one ventilator asynchrony dataset, and two electrocardiogram datasets, finding that the performance was either equal or superior to the state-of-the art on all three."],"url":"http://arxiv.org/abs/2501.13858v1"}
{"created":"2025-01-23 17:18:30","title":"Large Vision-Language Models for Knowledge-Grounded Data Annotation of Memes","abstract":"Memes have emerged as a powerful form of communication, integrating visual and textual elements to convey humor, satire, and cultural messages. Existing research has focused primarily on aspects such as emotion classification, meme generation, propagation, interpretation, figurative language, and sociolinguistics, but has often overlooked deeper meme comprehension and meme-text retrieval. To address these gaps, this study introduces ClassicMemes-50-templates (CM50), a large-scale dataset consisting of over 33,000 memes, centered around 50 popular meme templates. We also present an automated knowledge-grounded annotation pipeline leveraging large vision-language models to produce high-quality image captions, meme captions, and literary device labels overcoming the labor intensive demands of manual annotation. Additionally, we propose a meme-text retrieval CLIP model (mtrCLIP) that utilizes cross-modal embedding to enhance meme analysis, significantly improving retrieval performance. Our contributions include:(1) a novel dataset for large-scale meme study, (2) a scalable meme annotation framework, and (3) a fine-tuned CLIP for meme-text retrieval, all aimed at advancing the understanding and analysis of memes at scale.","sentences":["Memes have emerged as a powerful form of communication, integrating visual and textual elements to convey humor, satire, and cultural messages.","Existing research has focused primarily on aspects such as emotion classification, meme generation, propagation, interpretation, figurative language, and sociolinguistics, but has often overlooked deeper meme comprehension and meme-text retrieval.","To address these gaps, this study introduces ClassicMemes-50-templates (CM50), a large-scale dataset consisting of over 33,000 memes, centered around 50 popular meme templates.","We also present an automated knowledge-grounded annotation pipeline leveraging large vision-language models to produce high-quality image captions, meme captions, and literary device labels overcoming the labor intensive demands of manual annotation.","Additionally, we propose a meme-text retrieval CLIP model (mtrCLIP) that utilizes cross-modal embedding to enhance meme analysis, significantly improving retrieval performance.","Our contributions include:(1) a novel dataset for large-scale meme study, (2) a scalable meme annotation framework, and (3) a fine-tuned CLIP for meme-text retrieval, all aimed at advancing the understanding and analysis of memes at scale."],"url":"http://arxiv.org/abs/2501.13851v1"}
{"created":"2025-01-23 17:10:33","title":"A Multi-stage Optimisation Approach to Design Relocation Strategies in One-way Car-sharing Systems with Stackable Cars","abstract":"One of the main operational challenges faced by the operators of one-way car-sharing systems is to ensure vehicle availability across the regions of the service areas with uneven patterns of rental requests. Fleet balancing strategies are required to maximise the demand served while minimising the relocation costs. However, the design of optimal relocation policies is a complex problem, and global optimisation solutions are often limited to very small network sizes for computational reasons. In this work, we propose a multi-stage decision support system for vehicle relocation that decomposes the general relocation problem into three independent decision stages to allow scalable solutions. Furthermore, we adopt a rolling horizon control strategy to cope with demand uncertainty. Our approach is highly modular and flexible, and we leverage it to design user-based, operator-based and robotic relocation schemes. Besides, we formulate the relocation problem considering both conventional cars and a new class of compact stackable vehicles that can be driven in a road train. We compare the proposed relocation schemes with two recognised benchmarks using a large data set of taxi trips in New York. Our results show that our approach is scalable and outperforms the benchmark schemes in terms of quality of service, vehicle utilisation and relocation efficiency. Furthermore, we find that stackable vehicles can achieve a relocation performance close to that of autonomous cars, even with a small workforce of relocators.","sentences":["One of the main operational challenges faced by the operators of one-way car-sharing systems is to ensure vehicle availability across the regions of the service areas with uneven patterns of rental requests.","Fleet balancing strategies are required to maximise the demand served while minimising the relocation costs.","However, the design of optimal relocation policies is a complex problem, and global optimisation solutions are often limited to very small network sizes for computational reasons.","In this work, we propose a multi-stage decision support system for vehicle relocation that decomposes the general relocation problem into three independent decision stages to allow scalable solutions.","Furthermore, we adopt a rolling horizon control strategy to cope with demand uncertainty.","Our approach is highly modular and flexible, and we leverage it to design user-based, operator-based and robotic relocation schemes.","Besides, we formulate the relocation problem considering both conventional cars and a new class of compact stackable vehicles that can be driven in a road train.","We compare the proposed relocation schemes with two recognised benchmarks using a large data set of taxi trips in New York.","Our results show that our approach is scalable and outperforms the benchmark schemes in terms of quality of service, vehicle utilisation and relocation efficiency.","Furthermore, we find that stackable vehicles can achieve a relocation performance close to that of autonomous cars, even with a small workforce of relocators."],"url":"http://arxiv.org/abs/2501.13843v1"}
{"created":"2025-01-23 17:01:53","title":"Think Outside the Data: Colonial Biases and Systemic Issues in Automated Moderation Pipelines for Low-Resource Languages","abstract":"Most social media users come from non-English speaking countries in the Global South. Despite the widespread prevalence of harmful content in these regions, current moderation systems repeatedly struggle in low-resource languages spoken there. In this work, we examine the challenges AI researchers and practitioners face when building moderation tools for low-resource languages. We conducted semi-structured interviews with 22 AI researchers and practitioners specializing in automatic detection of harmful content in four diverse low-resource languages from the Global South. These are: Tamil from South Asia, Swahili from East Africa, Maghrebi Arabic from North Africa, and Quechua from South America. Our findings reveal that social media companies' restrictions on researchers' access to data exacerbate the historical marginalization of these languages, which have long lacked datasets for studying online harms. Moreover, common preprocessing techniques and language models, predominantly designed for data-rich English, fail to account for the linguistic complexity of low-resource languages. This leads to critical errors when moderating content in Tamil, Swahili, Arabic, and Quechua, which are morphologically richer than English. Based on our findings, we establish that the precarities in current moderation pipelines are rooted in deep systemic inequities and continue to reinforce historical power imbalances. We conclude by discussing multi-stakeholder approaches to improve moderation for low-resource languages.","sentences":["Most social media users come from non-English speaking countries in the Global South.","Despite the widespread prevalence of harmful content in these regions, current moderation systems repeatedly struggle in low-resource languages spoken there.","In this work, we examine the challenges AI researchers and practitioners face when building moderation tools for low-resource languages.","We conducted semi-structured interviews with 22 AI researchers and practitioners specializing in automatic detection of harmful content in four diverse low-resource languages from the Global South.","These are: Tamil from South Asia, Swahili from East Africa, Maghrebi Arabic from North Africa, and Quechua from South America.","Our findings reveal that social media companies' restrictions on researchers' access to data exacerbate the historical marginalization of these languages, which have long lacked datasets for studying online harms.","Moreover, common preprocessing techniques and language models, predominantly designed for data-rich English, fail to account for the linguistic complexity of low-resource languages.","This leads to critical errors when moderating content in Tamil, Swahili, Arabic, and Quechua, which are morphologically richer than English.","Based on our findings, we establish that the precarities in current moderation pipelines are rooted in deep systemic inequities and continue to reinforce historical power imbalances.","We conclude by discussing multi-stakeholder approaches to improve moderation for low-resource languages."],"url":"http://arxiv.org/abs/2501.13836v1"}
{"created":"2025-01-23 16:56:40","title":"Software Bills of Materials in Maven Central","abstract":"Software Bills of Materials (SBOMs) are essential to ensure the transparency and integrity of the software supply chain. There is a growing body of work that investigates the accuracy of SBOM generation tools and the challenges for producing complete SBOMs. Yet, there is little knowledge about how developers distribute SBOMs. In this work, we mine SBOMs from Maven Central to assess the extent to which developers publish SBOMs along with the artifacts. We develop our work on top of the Goblin framework, which consists of a Maven Central dependency graph and a Weaver that allows augmenting the dependency graph with additional data. For this study, we select a sample of 10% of release nodes from the Maven Central dependency graph and collected 14,071 SBOMs from 7,290 package releases. We then augment the Maven Central dependency graph with the collected SBOMs. We present our methodology to mine SBOMs, as well as novel insights about SBOM publication. Our dataset is the first set of SBOMs collected from a package registry. We make it available as a standalone dataset, which can be used for future research about SBOMs and package distribution.","sentences":["Software Bills of Materials (SBOMs) are essential to ensure the transparency and integrity of the software supply chain.","There is a growing body of work that investigates the accuracy of SBOM generation tools and the challenges for producing complete SBOMs.","Yet, there is little knowledge about how developers distribute SBOMs.","In this work, we mine SBOMs from Maven Central to assess the extent to which developers publish SBOMs along with the artifacts.","We develop our work on top of the Goblin framework, which consists of a Maven Central dependency graph and a Weaver that allows augmenting the dependency graph with additional data.","For this study, we select a sample of 10% of release nodes from the Maven Central dependency graph and collected 14,071 SBOMs from 7,290 package releases.","We then augment the Maven Central dependency graph with the collected SBOMs.","We present our methodology to mine SBOMs, as well as novel insights about SBOM publication.","Our dataset is the first set of SBOMs collected from a package registry.","We make it available as a standalone dataset, which can be used for future research about SBOMs and package distribution."],"url":"http://arxiv.org/abs/2501.13832v1"}
{"created":"2025-01-23 16:53:46","title":"MV-GMN: State Space Model for Multi-View Action Recognition","abstract":"Recent advancements in multi-view action recognition have largely relied on Transformer-based models. While effective and adaptable, these models often require substantial computational resources, especially in scenarios with multiple views and multiple temporal sequences. Addressing this limitation, this paper introduces the MV-GMN model, a state-space model specifically designed to efficiently aggregate multi-modal data (RGB and skeleton), multi-view perspectives, and multi-temporal information for action recognition with reduced computational complexity. The MV-GMN model employs an innovative Multi-View Graph Mamba network comprising a series of MV-GMN blocks. Each block includes a proposed Bidirectional State Space Block and a GCN module. The Bidirectional State Space Block introduces four scanning strategies, including view-prioritized and time-prioritized approaches. The GCN module leverages rule-based and KNN-based methods to construct the graph network, effectively integrating features from different viewpoints and temporal instances. Demonstrating its efficacy, MV-GMN outperforms the state-of-the-arts on several datasets, achieving notable accuracies of 97.3\\% and 96.7\\% on the NTU RGB+D 120 dataset in cross-subject and cross-view scenarios, respectively. MV-GMN also surpasses Transformer-based baselines while requiring only linear inference complexity, underscoring the model's ability to reduce computational load and enhance the scalability and applicability of multi-view action recognition technologies.","sentences":["Recent advancements in multi-view action recognition have largely relied on Transformer-based models.","While effective and adaptable, these models often require substantial computational resources, especially in scenarios with multiple views and multiple temporal sequences.","Addressing this limitation, this paper introduces the MV-GMN model, a state-space model specifically designed to efficiently aggregate multi-modal data (RGB and skeleton), multi-view perspectives, and multi-temporal information for action recognition with reduced computational complexity.","The MV-GMN model employs an innovative Multi-View Graph Mamba network comprising a series of MV-GMN blocks.","Each block includes a proposed Bidirectional State Space Block and a GCN module.","The Bidirectional State Space Block introduces four scanning strategies, including view-prioritized and time-prioritized approaches.","The GCN module leverages rule-based and KNN-based methods to construct the graph network, effectively integrating features from different viewpoints and temporal instances.","Demonstrating its efficacy, MV-GMN outperforms the state-of-the-arts on several datasets, achieving notable accuracies of 97.3\\% and 96.7\\% on the NTU RGB+D 120 dataset in cross-subject and cross-view scenarios, respectively.","MV-GMN also surpasses Transformer-based baselines while requiring only linear inference complexity, underscoring the model's ability to reduce computational load and enhance the scalability and applicability of multi-view action recognition technologies."],"url":"http://arxiv.org/abs/2501.13829v1"}
{"created":"2025-01-23 16:53:31","title":"PhotoGAN: Generative Adversarial Neural Network Acceleration with Silicon Photonics","abstract":"Generative Adversarial Networks (GANs) are at the forefront of AI innovation, driving advancements in areas such as image synthesis, medical imaging, and data augmentation. However, the unique computational operations within GANs, such as transposed convolutions and instance normalization, introduce significant inefficiencies when executed on traditional electronic accelerators, resulting in high energy consumption and suboptimal performance. To address these challenges, we introduce PhotoGAN, the first silicon-photonic accelerator designed to handle the specialized operations of GAN models. By leveraging the inherent high throughput and energy efficiency of silicon photonics, PhotoGAN offers an innovative, reconfigurable architecture capable of accelerating transposed convolutions and other GAN-specific layers. The accelerator also incorporates a sparse computation optimization technique to reduce redundant operations, improving computational efficiency. Our experimental results demonstrate that PhotoGAN achieves at least 4.4x higher GOPS and 2.18x lower energy-per-bit (EPB) compared to state-of-the-art accelerators, including GPUs and TPUs. These findings showcase PhotoGAN as a promising solution for the next generation of GAN acceleration, providing substantial gains in both performance and energy efficiency.","sentences":["Generative Adversarial Networks (GANs) are at the forefront of AI innovation, driving advancements in areas such as image synthesis, medical imaging, and data augmentation.","However, the unique computational operations within GANs, such as transposed convolutions and instance normalization, introduce significant inefficiencies when executed on traditional electronic accelerators, resulting in high energy consumption and suboptimal performance.","To address these challenges, we introduce PhotoGAN, the first silicon-photonic accelerator designed to handle the specialized operations of GAN models.","By leveraging the inherent high throughput and energy efficiency of silicon photonics, PhotoGAN offers an innovative, reconfigurable architecture capable of accelerating transposed convolutions and other GAN-specific layers.","The accelerator also incorporates a sparse computation optimization technique to reduce redundant operations, improving computational efficiency.","Our experimental results demonstrate that PhotoGAN achieves at least 4.4x higher GOPS and 2.18x lower energy-per-bit (EPB) compared to state-of-the-art accelerators, including GPUs and TPUs.","These findings showcase PhotoGAN as a promising solution for the next generation of GAN acceleration, providing substantial gains in both performance and energy efficiency."],"url":"http://arxiv.org/abs/2501.13828v1"}
{"created":"2025-01-23 16:39:09","title":"Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data","abstract":"Deep neural networks are increasingly employed in high-stakes medical applications, despite their tendency for shortcut learning in the presence of spurious correlations, which can have potentially fatal consequences in practice. Detecting and mitigating shortcut behavior is a challenging task that often requires significant labeling efforts from domain experts. To alleviate this problem, we introduce a semi-automated framework for the identification of spurious behavior from both data and model perspective by leveraging insights from eXplainable Artificial Intelligence (XAI). This allows the retrieval of spurious data points and the detection of model circuits that encode the associated prediction rules. Moreover, we demonstrate how these shortcut encodings can be used for XAI-based sample- and pixel-level data annotation, providing valuable information for bias mitigation methods to unlearn the undesired shortcut behavior. We show the applicability of our framework using four medical datasets across two modalities, featuring controlled and real-world spurious correlations caused by data artifacts. We successfully identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision Transformer models, ultimately increasing their robustness and applicability for real-world medical tasks.","sentences":["Deep neural networks are increasingly employed in high-stakes medical applications, despite their tendency for shortcut learning in the presence of spurious correlations, which can have potentially fatal consequences in practice.","Detecting and mitigating shortcut behavior is a challenging task that often requires significant labeling efforts from domain experts.","To alleviate this problem, we introduce a semi-automated framework for the identification of spurious behavior from both data and model perspective by leveraging insights from eXplainable Artificial Intelligence (XAI).","This allows the retrieval of spurious data points and the detection of model circuits that encode the associated prediction rules.","Moreover, we demonstrate how these shortcut encodings can be used for XAI-based sample- and pixel-level data annotation, providing valuable information for bias mitigation methods to unlearn the undesired shortcut behavior.","We show the applicability of our framework using four medical datasets across two modalities, featuring controlled and real-world spurious correlations caused by data artifacts.","We successfully identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision Transformer models, ultimately increasing their robustness and applicability for real-world medical tasks."],"url":"http://arxiv.org/abs/2501.13818v1"}
{"created":"2025-01-23 16:37:44","title":"Large Language Model driven Policy Exploration for Recommender Systems","abstract":"Recent advancements in Recommender Systems (RS) have incorporated Reinforcement Learning (RL), framing the recommendation as a Markov Decision Process (MDP). However, offline RL policies trained on static user data are vulnerable to distribution shift when deployed in dynamic online environments. Additionally, excessive focus on exploiting short-term relevant items can hinder exploration, leading to suboptimal recommendations and negatively impacting long-term user gains. Online RL-based RS also face challenges in production deployment, due to the risks of exposing users to untrained or unstable policies. Large Language Models (LLMs) offer a promising solution to mimic user objectives and preferences for pre-training policies offline to enhance the initial recommendations in online settings. Effectively managing distribution shift and balancing exploration are crucial for improving RL-based RS, especially when leveraging LLM-based pre-training. To address these challenges, we propose an Interaction-Augmented Learned Policy (iALP) that utilizes user preferences distilled from an LLM. Our approach involves prompting the LLM with user states to extract item preferences, learning rewards based on feedback, and updating the RL policy using an actor-critic framework. Furthermore, to deploy iALP in an online scenario, we introduce an adaptive variant, A-iALP, that implements a simple fine-tuning strategy (A-iALP$_{ft}$), and an adaptive approach (A-iALP$_{ap}$) designed to mitigate issues with compromised policies and limited exploration. Experiments across three simulated environments demonstrate that A-iALP introduces substantial performance improvements","sentences":["Recent advancements in Recommender Systems (RS) have incorporated Reinforcement Learning (RL), framing the recommendation as a Markov Decision Process (MDP).","However, offline RL policies trained on static user data are vulnerable to distribution shift when deployed in dynamic online environments.","Additionally, excessive focus on exploiting short-term relevant items can hinder exploration, leading to suboptimal recommendations and negatively impacting long-term user gains.","Online RL-based RS also face challenges in production deployment, due to the risks of exposing users to untrained or unstable policies.","Large Language Models (LLMs) offer a promising solution to mimic user objectives and preferences for pre-training policies offline to enhance the initial recommendations in online settings.","Effectively managing distribution shift and balancing exploration are crucial for improving RL-based RS, especially when leveraging LLM-based pre-training.","To address these challenges, we propose an Interaction-Augmented Learned Policy (iALP) that utilizes user preferences distilled from an LLM.","Our approach involves prompting the LLM with user states to extract item preferences, learning rewards based on feedback, and updating the RL policy using an actor-critic framework.","Furthermore, to deploy iALP in an online scenario, we introduce an adaptive variant, A-iALP, that implements a simple fine-tuning strategy (A-iALP$_{ft}$), and an adaptive approach (A-iALP$_{ap}$) designed to mitigate issues with compromised policies and limited exploration.","Experiments across three simulated environments demonstrate that A-iALP introduces substantial performance improvements"],"url":"http://arxiv.org/abs/2501.13816v1"}
{"created":"2025-01-23 16:35:21","title":"By-Example Synthesis of Vector Textures","abstract":"We propose a new method for synthesizing an arbitrarily sized novel vector texture given a single raster exemplar. Our method first segments the exemplar to extract the primary textons, and then clusters them based on visual similarity. We then compute a descriptor to capture each texton's neighborhood which contains the inter-category relationships that are used at synthesis time. Next, we use a simple procedure to both extract and place the secondary textons behind the primary polygons. Finally, our method constructs a gradient field for the background which is defined by a set of data points and colors. The color of the secondary polygons are also adjusted to better match the gradient field. To compare our work with other methods, we use a wide range of perceptual-based metrics.","sentences":["We propose a new method for synthesizing an arbitrarily sized novel vector texture given a single raster exemplar.","Our method first segments the exemplar to extract the primary textons, and then clusters them based on visual similarity.","We then compute a descriptor to capture each texton's neighborhood which contains the inter-category relationships that are used at synthesis time.","Next, we use a simple procedure to both extract and place the secondary textons behind the primary polygons.","Finally, our method constructs a gradient field for the background which is defined by a set of data points and colors.","The color of the secondary polygons are also adjusted to better match the gradient field.","To compare our work with other methods, we use a wide range of perceptual-based metrics."],"url":"http://arxiv.org/abs/2501.13812v1"}
{"created":"2025-01-23 16:27:15","title":"Generation of reusable learning objects from digital medical collections: An analysis based on the MASMDOA framework","abstract":"Learning Objects represent a widespread approach to structuring instructional materials in a large variety of educational contexts. The main aim of this work consists of analyzing from a qualitative point of view the process of generating reusable learning objects (RLOs) followed by Clavy, a tool that can be used to retrieve data from multiple medical knowledge sources and reconfigure such sources in diverse multimedia-based structures and organizations. From these organizations, Clavy is able to generate learning objects which can be adapted to various instructional healthcare scenarios with several types of user profiles and distinct learning requirements. Moreover, Clavy provides the capability of exporting these learning objects through educational standard specifications, which improves their reusability features. The analysis insights highlight the importance of having a tool able to transfer knowledge from the available digital medical collections to learning objects that can be easily accessed by medical students and healthcare practitioners through the most popular e-learning platforms.","sentences":["Learning Objects represent a widespread approach to structuring instructional materials in a large variety of educational contexts.","The main aim of this work consists of analyzing from a qualitative point of view the process of generating reusable learning objects (RLOs) followed by Clavy, a tool that can be used to retrieve data from multiple medical knowledge sources and reconfigure such sources in diverse multimedia-based structures and organizations.","From these organizations, Clavy is able to generate learning objects which can be adapted to various instructional healthcare scenarios with several types of user profiles and distinct learning requirements.","Moreover, Clavy provides the capability of exporting these learning objects through educational standard specifications, which improves their reusability features.","The analysis insights highlight the importance of having a tool able to transfer knowledge from the available digital medical collections to learning objects that can be easily accessed by medical students and healthcare practitioners through the most popular e-learning platforms."],"url":"http://arxiv.org/abs/2501.13806v1"}
{"created":"2025-01-23 16:16:23","title":"Rudraksh: A compact and lightweight post-quantum key-encapsulation mechanism","abstract":"Resource-constrained devices such as wireless sensors and Internet of Things (IoT) devices have become ubiquitous in our digital ecosystem. These devices generate and handle a major part of our digital data. However, due to the impending threat of quantum computers on our existing public-key cryptographic schemes and the limited resources available on IoT devices, it is important to design lightweight post-quantum cryptographic (PQC) schemes suitable for these devices. In this work, we explored the design space of learning with error-based PQC schemes to design a lightweight key-encapsulation mechanism (KEM) suitable for resource-constrained devices. We have done a scrupulous and extensive analysis and evaluation of different design elements, such as polynomial size, field modulus structure, reduction algorithm, and secret and error distribution of an LWE-based KEM. Our explorations led to the proposal of a lightweight PQC-KEM, Rudraksh, without compromising security. Our scheme provides security against chosen ciphertext attacks (CCA) with more than 100 bits of Core-SVP post-quantum security and belongs to the NIST-level-I security category (provide security at least as much as AES-128). We have also shown how ASCON can be used for lightweight pseudo-random number generation and hash function in the lattice-based KEMs instead of the widely used Keccak for lightweight design. Our FPGA results show that Rudraksh currently requires the least area among the PQC KEMs of similar security. Our implementation of Rudraksh provides a $\\sim3\\times$ improvement in terms of the area requirement compared to the state-of-the-art area-optimized implementation of Kyber, can operate at $63\\%$-$76\\%$ higher frequency with respect to high-throughput Kyber, and improves time-area-product $\\sim2\\times$ compared to the state-of-the-art compact implementation of Kyber published in HPEC 2022.","sentences":["Resource-constrained devices such as wireless sensors and Internet of Things (IoT) devices have become ubiquitous in our digital ecosystem.","These devices generate and handle a major part of our digital data.","However, due to the impending threat of quantum computers on our existing public-key cryptographic schemes and the limited resources available on IoT devices, it is important to design lightweight post-quantum cryptographic (PQC) schemes suitable for these devices.","In this work, we explored the design space of learning with error-based PQC schemes to design a lightweight key-encapsulation mechanism (KEM) suitable for resource-constrained devices.","We have done a scrupulous and extensive analysis and evaluation of different design elements, such as polynomial size, field modulus structure, reduction algorithm, and secret and error distribution of an LWE-based KEM.","Our explorations led to the proposal of a lightweight PQC-KEM, Rudraksh, without compromising security.","Our scheme provides security against chosen ciphertext attacks (CCA) with more than 100 bits of Core-SVP post-quantum security and belongs to the NIST-level-I security category (provide security at least as much as AES-128).","We have also shown how ASCON can be used for lightweight pseudo-random number generation and hash function in the lattice-based KEMs instead of the widely used Keccak for lightweight design.","Our FPGA results show that Rudraksh currently requires the least area among the PQC KEMs of similar security.","Our implementation of Rudraksh provides a $\\sim3\\times$ improvement in terms of the area requirement compared to the state-of-the-art area-optimized implementation of Kyber, can operate at $63\\%$-$76\\%$ higher frequency with respect to high-throughput Kyber, and improves time-area-product $\\sim2\\times$ compared to the state-of-the-art compact implementation of Kyber published in HPEC 2022."],"url":"http://arxiv.org/abs/2501.13799v1"}
{"created":"2025-01-23 16:13:08","title":"Unveiling the Power of Noise Priors: Enhancing Diffusion Models for Mobile Traffic Prediction","abstract":"Accurate prediction of mobile traffic, \\textit{i.e.,} network traffic from cellular base stations, is crucial for optimizing network performance and supporting urban development. However, the non-stationary nature of mobile traffic, driven by human activity and environmental changes, leads to both regular patterns and abrupt variations. Diffusion models excel in capturing such complex temporal dynamics due to their ability to capture the inherent uncertainties. Most existing approaches prioritize designing novel denoising networks but often neglect the critical role of noise itself, potentially leading to sub-optimal performance. In this paper, we introduce a novel perspective by emphasizing the role of noise in the denoising process. Our analysis reveals that noise fundamentally shapes mobile traffic predictions, exhibiting distinct and consistent patterns. We propose NPDiff, a framework that decomposes noise into \\textit{prior} and \\textit{residual} components, with the \\textit{prior} derived from data dynamics, enhancing the model's ability to capture both regular and abrupt variations. NPDiff can seamlessly integrate with various diffusion-based prediction models, delivering predictions that are effective, efficient, and robust. Extensive experiments demonstrate that it achieves superior performance with an improvement over 30\\%, offering a new perspective on leveraging diffusion models in this domain.","sentences":["Accurate prediction of mobile traffic, \\textit{i.e.,} network traffic from cellular base stations, is crucial for optimizing network performance and supporting urban development.","However, the non-stationary nature of mobile traffic, driven by human activity and environmental changes, leads to both regular patterns and abrupt variations.","Diffusion models excel in capturing such complex temporal dynamics due to their ability to capture the inherent uncertainties.","Most existing approaches prioritize designing novel denoising networks but often neglect the critical role of noise itself, potentially leading to sub-optimal performance.","In this paper, we introduce a novel perspective by emphasizing the role of noise in the denoising process.","Our analysis reveals that noise fundamentally shapes mobile traffic predictions, exhibiting distinct and consistent patterns.","We propose NPDiff, a framework that decomposes noise into \\textit{prior} and \\textit{residual} components, with the \\textit{prior} derived from data dynamics, enhancing the model's ability to capture both regular and abrupt variations.","NPDiff can seamlessly integrate with various diffusion-based prediction models, delivering predictions that are effective, efficient, and robust.","Extensive experiments demonstrate that it achieves superior performance with an improvement over 30\\%, offering a new perspective on leveraging diffusion models in this domain."],"url":"http://arxiv.org/abs/2501.13794v1"}
{"created":"2025-01-23 16:09:26","title":"Local Steps Speed Up Local GD for Heterogeneous Distributed Logistic Regression","abstract":"We analyze two variants of Local Gradient Descent applied to distributed logistic regression with heterogeneous, separable data and show convergence at the rate $O(1/KR)$ for $K$ local steps and sufficiently large $R$ communication rounds. In contrast, all existing convergence guarantees for Local GD applied to any problem are at least $\\Omega(1/R)$, meaning they fail to show the benefit of local updates. The key to our improved guarantee is showing progress on the logistic regression objective when using a large stepsize $\\eta \\gg 1/K$, whereas prior analysis depends on $\\eta \\leq 1/K$.","sentences":["We analyze two variants of Local Gradient Descent applied to distributed logistic regression with heterogeneous, separable data and show convergence at the rate $O(1/KR)$ for $K$ local steps and sufficiently large $R$ communication rounds.","In contrast, all existing convergence guarantees for Local GD applied to any problem are at least $\\Omega(1/R)$, meaning they fail to show the benefit of local updates.","The key to our improved guarantee is showing progress on the logistic regression objective when using a large stepsize $\\eta \\gg 1/K$, whereas prior analysis depends on $\\eta \\leq 1/K$."],"url":"http://arxiv.org/abs/2501.13790v1"}
{"created":"2025-01-23 16:04:18","title":"Fast Iterative and Task-Specific Imputation with Online Learning","abstract":"Missing feature values are a significant hurdle for downstream machine-learning tasks such as classification and regression. However, they are pervasive in multiple real-life use cases, for instance, in drug discovery research. Moreover, imputation methods might be time-consuming and offer few guarantees on the imputation quality, especially for not-missing-at-random mechanisms. We propose an imputation approach named F3I based on the iterative improvement of a K-nearest neighbor imputation that learns the weights for each neighbor of a data point, optimizing for the most likely distribution of points over data points. This algorithm can also be jointly trained with a downstream task on the imputed values. We provide a theoretical analysis of the imputation quality by F3I for several types of missing mechanisms. We also demonstrate the performance of F3I on both synthetic data sets and real-life drug repurposing and handwritten-digit recognition data.","sentences":["Missing feature values are a significant hurdle for downstream machine-learning tasks such as classification and regression.","However, they are pervasive in multiple real-life use cases, for instance, in drug discovery research.","Moreover, imputation methods might be time-consuming and offer few guarantees on the imputation quality, especially for not-missing-at-random mechanisms.","We propose an imputation approach named F3I based on the iterative improvement of a K-nearest neighbor imputation that learns the weights for each neighbor of a data point, optimizing for the most likely distribution of points over data points.","This algorithm can also be jointly trained with a downstream task on the imputed values.","We provide a theoretical analysis of the imputation quality by F3I for several types of missing mechanisms.","We also demonstrate the performance of F3I on both synthetic data sets and real-life drug repurposing and handwritten-digit recognition data."],"url":"http://arxiv.org/abs/2501.13786v1"}
{"created":"2025-01-23 15:59:01","title":"Defending against Adversarial Malware Attacks on ML-based Android Malware Detection Systems","abstract":"Android malware presents a persistent threat to users' privacy and data integrity. To combat this, researchers have proposed machine learning-based (ML-based) Android malware detection (AMD) systems. However, adversarial Android malware attacks compromise the detection integrity of the ML-based AMD systems, raising significant concerns. Existing defenses against adversarial Android malware provide protections against feature space attacks which generate adversarial feature vectors only, leaving protection against realistic threats from problem space attacks which generate real adversarial malware an open problem. In this paper, we address this gap by proposing ADD, a practical adversarial Android malware defense framework designed as a plug-in to enhance the adversarial robustness of the ML-based AMD systems against problem space attacks. Our extensive evaluation across various ML-based AMD systems demonstrates that ADD is effective against state-of-the-art problem space adversarial Android malware attacks. Additionally, ADD shows the defense effectiveness in enhancing the adversarial robustness of real-world antivirus solutions.","sentences":["Android malware presents a persistent threat to users' privacy and data integrity.","To combat this, researchers have proposed machine learning-based (ML-based) Android malware detection (AMD) systems.","However, adversarial Android malware attacks compromise the detection integrity of the ML-based AMD systems, raising significant concerns.","Existing defenses against adversarial Android malware provide protections against feature space attacks which generate adversarial feature vectors only, leaving protection against realistic threats from problem space attacks which generate real adversarial malware an open problem.","In this paper, we address this gap by proposing ADD, a practical adversarial Android malware defense framework designed as a plug-in to enhance the adversarial robustness of the ML-based AMD systems against problem space attacks.","Our extensive evaluation across various ML-based AMD systems demonstrates that ADD is effective against state-of-the-art problem space adversarial Android malware attacks.","Additionally, ADD shows the defense effectiveness in enhancing the adversarial robustness of real-world antivirus solutions."],"url":"http://arxiv.org/abs/2501.13782v1"}
{"created":"2025-01-23 15:58:14","title":"Not Every AI Problem is a Data Problem: We Should Be Intentional About Data Scaling","abstract":"While Large Language Models require more and more data to train and scale, rather than looking for any data to acquire, we should consider what types of tasks are more likely to benefit from data scaling. We should be intentional in our data acquisition. We argue that the topology of data itself informs which tasks to prioritize in data scaling, and shapes the development of the next generation of compute paradigms for tasks where data scaling is inefficient, or even insufficient.","sentences":["While Large Language Models require more and more data to train and scale, rather than looking for any data to acquire, we should consider what types of tasks are more likely to benefit from data scaling.","We should be intentional in our data acquisition.","We argue that the topology of data itself informs which tasks to prioritize in data scaling, and shapes the development of the next generation of compute paradigms for tasks where data scaling is inefficient, or even insufficient."],"url":"http://arxiv.org/abs/2501.13779v1"}
{"created":"2025-01-23 15:55:07","title":"Explainable XR: Understanding User Behaviors of XR Environments using LLM-assisted Analytics Framework","abstract":"We present Explainable XR, an end-to-end framework for analyzing user behavior in diverse eXtended Reality (XR) environments by leveraging Large Language Models (LLMs) for data interpretation assistance. Existing XR user analytics frameworks face challenges in handling cross-virtuality - AR, VR, MR - transitions, multi-user collaborative application scenarios, and the complexity of multimodal data. Explainable XR addresses these challenges by providing a virtuality-agnostic solution for the collection, analysis, and visualization of immersive sessions. We propose three main components in our framework: (1) A novel user data recording schema, called User Action Descriptor (UAD), that can capture the users' multimodal actions, along with their intents and the contexts; (2) a platform-agnostic XR session recorder, and (3) a visual analytics interface that offers LLM-assisted insights tailored to the analysts' perspectives, facilitating the exploration and analysis of the recorded XR session data. We demonstrate the versatility of Explainable XR by demonstrating five use-case scenarios, in both individual and collaborative XR applications across virtualities. Our technical evaluation and user studies show that Explainable XR provides a highly usable analytics solution for understanding user actions and delivering multifaceted, actionable insights into user behaviors in immersive environments.","sentences":["We present Explainable XR, an end-to-end framework for analyzing user behavior in diverse eXtended Reality (XR) environments by leveraging Large Language Models (LLMs) for data interpretation assistance.","Existing XR user analytics frameworks face challenges in handling cross-virtuality - AR, VR, MR - transitions, multi-user collaborative application scenarios, and the complexity of multimodal data.","Explainable XR addresses these challenges by providing a virtuality-agnostic solution for the collection, analysis, and visualization of immersive sessions.","We propose three main components in our framework: (1) A novel user data recording schema, called User Action Descriptor (UAD), that can capture the users' multimodal actions, along with their intents and the contexts; (2) a platform-agnostic XR session recorder, and (3) a visual analytics interface that offers LLM-assisted insights tailored to the analysts' perspectives, facilitating the exploration and analysis of the recorded XR session data.","We demonstrate the versatility of Explainable XR by demonstrating five use-case scenarios, in both individual and collaborative XR applications across virtualities.","Our technical evaluation and user studies show that Explainable XR provides a highly usable analytics solution for understanding user actions and delivering multifaceted, actionable insights into user behaviors in immersive environments."],"url":"http://arxiv.org/abs/2501.13778v1"}
{"created":"2025-01-23 15:53:35","title":"Crossfire: An Elastic Defense Framework for Graph Neural Networks Under Bit Flip Attacks","abstract":"Bit Flip Attacks (BFAs) are a well-established class of adversarial attacks, originally developed for Convolutional Neural Networks within the computer vision domain. Most recently, these attacks have been extended to target Graph Neural Networks (GNNs), revealing significant vulnerabilities. This new development naturally raises questions about the best strategies to defend GNNs against BFAs, a challenge for which no solutions currently exist. Given the applications of GNNs in critical fields, any defense mechanism must not only maintain network performance, but also verifiably restore the network to its pre-attack state. Verifiably restoring the network to its pre-attack state also eliminates the need for costly evaluations on test data to ensure network quality. We offer first insights into the effectiveness of existing honeypot- and hashing-based defenses against BFAs adapted from the computer vision domain to GNNs, and characterize the shortcomings of these approaches. To overcome their limitations, we propose Crossfire, a hybrid approach that exploits weight sparsity and combines hashing and honeypots with bit-level correction of out-of-distribution weight elements to restore network integrity. Crossfire is retraining-free and does not require labeled data. Averaged over 2,160 experiments on six benchmark datasets, Crossfire offers a 21.8% higher probability than its competitors of reconstructing a GNN attacked by a BFA to its pre-attack state. These experiments cover up to 55 bit flips from various attacks. Moreover, it improves post-repair prediction quality by 10.85%. Computational and storage overheads are negligible compared to the inherent complexity of even the simplest GNNs.","sentences":["Bit Flip Attacks (BFAs) are a well-established class of adversarial attacks, originally developed for Convolutional Neural Networks within the computer vision domain.","Most recently, these attacks have been extended to target Graph Neural Networks (GNNs), revealing significant vulnerabilities.","This new development naturally raises questions about the best strategies to defend GNNs against BFAs, a challenge for which no solutions currently exist.","Given the applications of GNNs in critical fields, any defense mechanism must not only maintain network performance, but also verifiably restore the network to its pre-attack state.","Verifiably restoring the network to its pre-attack state also eliminates the need for costly evaluations on test data to ensure network quality.","We offer first insights into the effectiveness of existing honeypot- and hashing-based defenses against BFAs adapted from the computer vision domain to GNNs, and characterize the shortcomings of these approaches.","To overcome their limitations, we propose Crossfire, a hybrid approach that exploits weight sparsity and combines hashing and honeypots with bit-level correction of out-of-distribution weight elements to restore network integrity.","Crossfire is retraining-free and does not require labeled data.","Averaged over 2,160 experiments on six benchmark datasets, Crossfire offers a 21.8% higher probability than its competitors of reconstructing a GNN attacked by a BFA to its pre-attack state.","These experiments cover up to 55 bit flips from various attacks.","Moreover, it improves post-repair prediction quality by 10.85%.","Computational and storage overheads are negligible compared to the inherent complexity of even the simplest GNNs."],"url":"http://arxiv.org/abs/2501.13776v1"}
{"created":"2025-01-23 15:48:49","title":"Aggregating Digital Identities through Bridging. An Integration of Open Authentication Protocols for Web3 Identifiers","abstract":"Web3's decentralised infrastructure has upended the standardised approach to digital identity established by protocols like OpenID Connect. Web2 and Web3 currently operate in silos, with Web2 leveraging selective disclosure JSON web tokens (SD-JWTs) and Web3 dApps being reliant on on-chain data and sometimes clinging to centralised system data. This fragmentation hinders user experience and the interconnectedness of the digital world. This paper explores the integration of Web3 within the OpenID Connect framework, scrutinising established authentication protocols for their adaptability to decentralised identities. The research examines the interplay between OpenID Connect and decentralised identity concepts, the limitations of existing protocols like OpenID Connect for verifiable credential issuance, OpenID Connect framework for verifiable presentations, and self-issued OpenID provider. As a result, a novel privacy-preserving digital identity bridge is proposed, which aims to answer the research question of whether authentication protocols should inherently support Web3 functionalities and the mechanisms for their integration. Through a Decentralised Autonomous Organisation (DAO) use case, the findings indicate that a privacy-centric bridge can mitigate existing fragmentation by aggregating different identities to provide a better user experience. While the digital identity bridge demonstrates a possible approach to harmonise digital identity across platforms for their use in Web3, the bridging is unidirectional and limits root trust of credentials. The bridge's dependence on centralised systems may further fuel the debate on (de-)centralised identities.","sentences":["Web3's decentralised infrastructure has upended the standardised approach to digital identity established by protocols like OpenID Connect.","Web2 and Web3 currently operate in silos, with Web2 leveraging selective disclosure JSON web tokens (SD-JWTs) and Web3 dApps being reliant on on-chain data and sometimes clinging to centralised system data.","This fragmentation hinders user experience and the interconnectedness of the digital world.","This paper explores the integration of Web3 within the OpenID Connect framework, scrutinising established authentication protocols for their adaptability to decentralised identities.","The research examines the interplay between OpenID Connect and decentralised identity concepts, the limitations of existing protocols like OpenID Connect for verifiable credential issuance, OpenID Connect framework for verifiable presentations, and self-issued OpenID provider.","As a result, a novel privacy-preserving digital identity bridge is proposed, which aims to answer the research question of whether authentication protocols should inherently support Web3 functionalities and the mechanisms for their integration.","Through a Decentralised Autonomous Organisation (DAO) use case, the findings indicate that a privacy-centric bridge can mitigate existing fragmentation by aggregating different identities to provide a better user experience.","While the digital identity bridge demonstrates a possible approach to harmonise digital identity across platforms for their use in Web3, the bridging is unidirectional and limits root trust of credentials.","The bridge's dependence on centralised systems may further fuel the debate on (de-)centralised identities."],"url":"http://arxiv.org/abs/2501.13770v1"}
{"created":"2025-01-23 15:45:29","title":"Integrating Causality with Neurochaos Learning: Proposed Approach and Research Agenda","abstract":"Deep learning implemented via neural networks, has revolutionized machine learning by providing methods for complex tasks such as object detection/classification and prediction. However, architectures based on deep neural networks have started to yield diminishing returns, primarily due to their statistical nature and inability to capture causal structure in the training data. Another issue with deep learning is its high energy consumption, which is not that desirable from a sustainability perspective.   Therefore, alternative approaches are being considered to address these issues, both of which are inspired by the functioning of the human brain. One approach is causal learning, which takes into account causality among the items in the dataset on which the neural network is trained. It is expected that this will help minimize the spurious correlations that are prevalent in the learned representations of deep neural networks. The other approach is Neurochaos Learning, a recent development, which draws its inspiration from the nonlinear chaotic firing intrinsic to neurons in biological neural networks (brain/central nervous system). Both approaches have shown improved results over just deep learning alone.   To that end, in this position paper, we investigate how causal and neurochaos learning approaches can be integrated together to produce better results, especially in domains that contain linked data. We propose an approach for this integration to enhance classification, prediction and reinforcement learning. We also propose a set of research questions that need to be investigated in order to make this integration a reality.","sentences":["Deep learning implemented via neural networks, has revolutionized machine learning by providing methods for complex tasks such as object detection/classification and prediction.","However, architectures based on deep neural networks have started to yield diminishing returns, primarily due to their statistical nature and inability to capture causal structure in the training data.","Another issue with deep learning is its high energy consumption, which is not that desirable from a sustainability perspective.   ","Therefore, alternative approaches are being considered to address these issues, both of which are inspired by the functioning of the human brain.","One approach is causal learning, which takes into account causality among the items in the dataset on which the neural network is trained.","It is expected that this will help minimize the spurious correlations that are prevalent in the learned representations of deep neural networks.","The other approach is Neurochaos Learning, a recent development, which draws its inspiration from the nonlinear chaotic firing intrinsic to neurons in biological neural networks (brain/central nervous system).","Both approaches have shown improved results over just deep learning alone.   ","To that end, in this position paper, we investigate how causal and neurochaos learning approaches can be integrated together to produce better results, especially in domains that contain linked data.","We propose an approach for this integration to enhance classification, prediction and reinforcement learning.","We also propose a set of research questions that need to be investigated in order to make this integration a reality."],"url":"http://arxiv.org/abs/2501.13763v1"}
{"created":"2025-01-23 15:41:48","title":"On Deciding the Data Complexity of Answering Linear Monadic Datalog Queries with LTL Operators(Extended Version)","abstract":"Our concern is the data complexity of answering linear monadic datalog queries whose atoms in the rule bodies can be prefixed by operators of linear temporal logic LTL. We first observe that, for data complexity, answering any connected query with operators $\\bigcirc/\\bigcirc^-$ (at the next/previous moment) is either in AC0, or in $ACC0\\!\\setminus\\!AC0$, or $NC^1$-complete, or LogSpace-hard and in NLogSpace. Then we show that the problem of deciding LogSpace-hardness of answering such queries is PSpace-complete, while checking membership in the classes AC0 and ACC0 as well as $NC^1$-completeness can be done in ExpSpace. Finally, we prove that membership in AC0 or in ACC0, $NC^1$-completeness, and LogSpace-hardness are undecidable for queries with operators $\\Diamond_f/\\Diamond_p$ (sometime in the future/past) provided that $NC^1 \\ne NLogSpace$, and $LogSpace \\ne NLogSpace$.","sentences":["Our concern is the data complexity of answering linear monadic datalog queries whose atoms in the rule bodies can be prefixed by operators of linear temporal logic LTL.","We first observe that, for data complexity, answering any connected query with operators $\\bigcirc/\\bigcirc^-$ (at the next/previous moment) is either in AC0, or in $ACC0\\!\\setminus\\!AC0$, or $NC^1$-complete, or LogSpace-hard and in NLogSpace.","Then we show that the problem of deciding LogSpace-hardness of answering such queries is PSpace-complete, while checking membership in the classes AC0 and ACC0 as well as $NC^1$-completeness can be done in ExpSpace.","Finally, we prove that membership in AC0 or in ACC0, $NC^1$-completeness, and LogSpace-hardness are undecidable for queries with operators $\\Diamond_f/\\Diamond_p$ (sometime in the future/past) provided that $NC^1 \\ne NLogSpace$, and $LogSpace \\ne NLogSpace$."],"url":"http://arxiv.org/abs/2501.13762v1"}
{"created":"2025-01-23 15:35:15","title":"Solving the long-tailed distribution problem by exploiting the synergies and balance of different techniques","abstract":"In real-world data, long-tailed data distribution is common, making it challenging for models trained on empirical risk minimisation to learn and classify tail classes effectively. While many studies have sought to improve long tail recognition by altering the data distribution in the feature space and adjusting model decision boundaries, research on the synergy and corrective approach among various methods is limited. Our study delves into three long-tail recognition techniques: Supervised Contrastive Learning (SCL), Rare-Class Sample Generator (RSG), and Label-Distribution-Aware Margin Loss (LDAM). SCL enhances intra-class clusters based on feature similarity and promotes clear inter-class separability but tends to favour dominant classes only. When RSG is integrated into the model, we observed that the intra-class features further cluster towards the class centre, which demonstrates a synergistic effect together with SCL's principle of enhancing intra-class clustering. RSG generates new tail features and compensates for the tail feature space squeezed by SCL. Similarly, LDAM is known to introduce a larger margin specifically for tail classes; we demonstrate that LDAM further bolsters the model's performance on tail classes when combined with the more explicit decision boundaries achieved by SCL and RSG. Furthermore, SCL can compensate for the dominant class accuracy sacrificed by RSG and LDAM. Our research emphasises the synergy and balance among the three techniques, with each amplifying the strengths of the others and mitigating their shortcomings. Our experiment on long-tailed distribution datasets, using an end-to-end architecture, yields competitive results by enhancing tail class accuracy without compromising dominant class performance, achieving a balanced improvement across all classes.","sentences":["In real-world data, long-tailed data distribution is common, making it challenging for models trained on empirical risk minimisation to learn and classify tail classes effectively.","While many studies have sought to improve long tail recognition by altering the data distribution in the feature space and adjusting model decision boundaries, research on the synergy and corrective approach among various methods is limited.","Our study delves into three long-tail recognition techniques: Supervised Contrastive Learning (SCL), Rare-Class Sample Generator (RSG), and Label-Distribution-Aware Margin Loss (LDAM).","SCL enhances intra-class clusters based on feature similarity and promotes clear inter-class separability but tends to favour dominant classes only.","When RSG is integrated into the model, we observed that the intra-class features further cluster towards the class centre, which demonstrates a synergistic effect together with SCL's principle of enhancing intra-class clustering.","RSG generates new tail features and compensates for the tail feature space squeezed by SCL.","Similarly, LDAM is known to introduce a larger margin specifically for tail classes; we demonstrate that LDAM further bolsters the model's performance on tail classes when combined with the more explicit decision boundaries achieved by SCL and RSG.","Furthermore, SCL can compensate for the dominant class accuracy sacrificed by RSG and LDAM.","Our research emphasises the synergy and balance among the three techniques, with each amplifying the strengths of the others and mitigating their shortcomings.","Our experiment on long-tailed distribution datasets, using an end-to-end architecture, yields competitive results by enhancing tail class accuracy without compromising dominant class performance, achieving a balanced improvement across all classes."],"url":"http://arxiv.org/abs/2501.13756v1"}
{"created":"2025-01-23 15:22:25","title":"EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents","abstract":"The paper introduces EICopilot, an novel agent-based solution enhancing search and exploration of enterprise registration data within extensive online knowledge graphs like those detailing legal entities, registered capital, and major shareholders. Traditional methods necessitate text-based queries and manual subgraph explorations, often resulting in time-consuming processes. EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this landscape by utilizing Large Language Models (LLMs) to interpret natural language queries. This solution automatically generates and executes Gremlin scripts, providing efficient summaries of complex enterprise relationships. Distinct feature a data pre-processing pipeline that compiles and annotates representative queries into a vector database of examples for In-context learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought with ICL to enhance Gremlin script generation for knowledge graph search and exploration, and a novel query masking strategy that improves intent recognition for heightened script accuracy. Empirical evaluations demonstrate the superior performance of EICopilot, including speed and accuracy, over baseline methods, with the \\emph{Full Mask} variant achieving a syntax error rate reduction to as low as 10.00% and an execution correctness of up to 82.14%. These components collectively contribute to superior querying capabilities and summarization of intricate datasets, positioning EICopilot as a groundbreaking tool in the exploration and exploitation of large-scale knowledge graphs for enterprise information search.","sentences":["The paper introduces EICopilot, an novel agent-based solution enhancing search and exploration of enterprise registration data within extensive online knowledge graphs like those detailing legal entities, registered capital, and major shareholders.","Traditional methods necessitate text-based queries and manual subgraph explorations, often resulting in time-consuming processes.","EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this landscape by utilizing Large Language Models (LLMs) to interpret natural language queries.","This solution automatically generates and executes Gremlin scripts, providing efficient summaries of complex enterprise relationships.","Distinct feature a data pre-processing pipeline that compiles and annotates representative queries into a vector database of examples for In-context learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought with ICL to enhance Gremlin script generation for knowledge graph search and exploration, and a novel query masking strategy that improves intent recognition for heightened script accuracy.","Empirical evaluations demonstrate the superior performance of EICopilot, including speed and accuracy, over baseline methods, with the \\emph{Full Mask} variant achieving a syntax error rate reduction to as low as 10.00% and an execution correctness of up to 82.14%.","These components collectively contribute to superior querying capabilities and summarization of intricate datasets, positioning EICopilot as a groundbreaking tool in the exploration and exploitation of large-scale knowledge graphs for enterprise information search."],"url":"http://arxiv.org/abs/2501.13746v1"}
{"created":"2025-01-23 15:10:51","title":"Sample complexity of data-driven tuning of model hyperparameters in neural networks with structured parameter-dependent dual function","abstract":"Modern machine learning algorithms, especially deep learning based techniques, typically involve careful hyperparameter tuning to achieve the best performance. Despite the surge of intense interest in practical techniques like Bayesian optimization and random search based approaches to automating this laborious and compute-intensive task, the fundamental learning theoretic complexity of tuning hyperparameters for deep neural networks is poorly understood. Inspired by this glaring gap, we initiate the formal study of hyperparameter tuning complexity in deep learning through a recently introduced data driven setting. We assume that we have a series of deep learning tasks, and we have to tune hyperparameters to do well on average over the distribution of tasks. A major difficulty is that the utility function as a function of the hyperparameter is very volatile and furthermore, it is given implicitly by an optimization problem over the model parameters. This is unlike previous work in data driven design, where one can typically explicitly model the algorithmic behavior as a function of the hyperparameters. To tackle this challenge, we introduce a new technique to characterize the discontinuities and oscillations of the utility function on any fixed problem instance as we vary the hyperparameter, our analysis relies on subtle concepts including tools from differential/algebraic geometry and constrained optimization. This can be used to show that the learning theoretic complexity of the corresponding family of utility functions is bounded. We instantiate our results and provide sample complexity bounds for concrete applications tuning a hyperparameter that interpolates neural activation functions and setting the kernel parameter in graph neural networks.","sentences":["Modern machine learning algorithms, especially deep learning based techniques, typically involve careful hyperparameter tuning to achieve the best performance.","Despite the surge of intense interest in practical techniques like Bayesian optimization and random search based approaches to automating this laborious and compute-intensive task, the fundamental learning theoretic complexity of tuning hyperparameters for deep neural networks is poorly understood.","Inspired by this glaring gap, we initiate the formal study of hyperparameter tuning complexity in deep learning through a recently introduced data driven setting.","We assume that we have a series of deep learning tasks, and we have to tune hyperparameters to do well on average over the distribution of tasks.","A major difficulty is that the utility function as a function of the hyperparameter is very volatile and furthermore, it is given implicitly by an optimization problem over the model parameters.","This is unlike previous work in data driven design, where one can typically explicitly model the algorithmic behavior as a function of the hyperparameters.","To tackle this challenge, we introduce a new technique to characterize the discontinuities and oscillations of the utility function on any fixed problem instance as we vary the hyperparameter, our analysis relies on subtle concepts including tools from differential/algebraic geometry and constrained optimization.","This can be used to show that the learning theoretic complexity of the corresponding family of utility functions is bounded.","We instantiate our results and provide sample complexity bounds for concrete applications tuning a hyperparameter that interpolates neural activation functions and setting the kernel parameter in graph neural networks."],"url":"http://arxiv.org/abs/2501.13734v1"}
{"created":"2025-01-23 14:58:49","title":"You Only Crash Once v2: Perceptually Consistent Strong Features for One-Stage Domain Adaptive Detection of Space Terrain","abstract":"The in-situ detection of planetary, lunar, and small-body surface terrain is crucial for autonomous spacecraft applications, where learning-based computer vision methods are increasingly employed to enable intelligence without prior information or human intervention. However, many of these methods remain computationally expensive for spacecraft processors and prevent real-time operation. Training of such algorithms is additionally complex due to the scarcity of labeled data and reliance on supervised learning approaches. Unsupervised Domain Adaptation (UDA) offers a promising solution by facilitating model training with disparate data sources such as simulations or synthetic scenes, although UDA is difficult to apply to celestial environments where challenging feature spaces are paramount. To alleviate such issues, You Only Crash Once (YOCOv1) has studied the integration of Visual Similarity-based Alignment (VSA) into lightweight one-stage object detection architectures to improve space terrain UDA. Although proven effective, the approach faces notable limitations, including performance degradations in multi-class and high-altitude scenarios. Building upon the foundation of YOCOv1, we propose novel additions to the VSA scheme that enhance terrain detection capabilities under UDA, and our approach is evaluated across both simulated and real-world data. Our second YOCO rendition, YOCOv2, is capable of achieving state-of-the-art UDA performance on surface terrain detection, where we showcase improvements upwards of 31% compared with YOCOv1 and terrestrial state-of-the-art. We demonstrate the practical utility of YOCOv2 with spacecraft flight hardware performance benchmarking and qualitative evaluation of NASA mission data.","sentences":["The in-situ detection of planetary, lunar, and small-body surface terrain is crucial for autonomous spacecraft applications, where learning-based computer vision methods are increasingly employed to enable intelligence without prior information or human intervention.","However, many of these methods remain computationally expensive for spacecraft processors and prevent real-time operation.","Training of such algorithms is additionally complex due to the scarcity of labeled data and reliance on supervised learning approaches.","Unsupervised Domain Adaptation (UDA) offers a promising solution by facilitating model training with disparate data sources such as simulations or synthetic scenes, although UDA is difficult to apply to celestial environments where challenging feature spaces are paramount.","To alleviate such issues, You Only Crash Once (YOCOv1) has studied the integration of Visual Similarity-based Alignment (VSA) into lightweight one-stage object detection architectures to improve space terrain UDA.","Although proven effective, the approach faces notable limitations, including performance degradations in multi-class and high-altitude scenarios.","Building upon the foundation of YOCOv1, we propose novel additions to the VSA scheme that enhance terrain detection capabilities under UDA, and our approach is evaluated across both simulated and real-world data.","Our second YOCO rendition, YOCOv2, is capable of achieving state-of-the-art UDA performance on surface terrain detection, where we showcase improvements upwards of 31% compared with YOCOv1 and terrestrial state-of-the-art.","We demonstrate the practical utility of YOCOv2 with spacecraft flight hardware performance benchmarking and qualitative evaluation of NASA mission data."],"url":"http://arxiv.org/abs/2501.13725v1"}
{"created":"2025-01-23 14:50:37","title":"Musical ethnocentrism in Large Language Models","abstract":"Large Language Models (LLMs) reflect the biases in their training data and, by extension, those of the people who created this training data. Detecting, analyzing, and mitigating such biases is becoming a focus of research. One type of bias that has been understudied so far are geocultural biases. Those can be caused by an imbalance in the representation of different geographic regions and cultures in the training data, but also by value judgments contained therein. In this paper, we make a first step towards analyzing musical biases in LLMs, particularly ChatGPT and Mixtral. We conduct two experiments. In the first, we prompt LLMs to provide lists of the \"Top 100\" musical contributors of various categories and analyze their countries of origin. In the second experiment, we ask the LLMs to numerically rate various aspects of the musical cultures of different countries. Our results indicate a strong preference of the LLMs for Western music cultures in both experiments.","sentences":["Large Language Models (LLMs) reflect the biases in their training data and, by extension, those of the people who created this training data.","Detecting, analyzing, and mitigating such biases is becoming a focus of research.","One type of bias that has been understudied so far are geocultural biases.","Those can be caused by an imbalance in the representation of different geographic regions and cultures in the training data, but also by value judgments contained therein.","In this paper, we make a first step towards analyzing musical biases in LLMs, particularly ChatGPT and Mixtral.","We conduct two experiments.","In the first, we prompt LLMs to provide lists of the \"Top 100\" musical contributors of various categories and analyze their countries of origin.","In the second experiment, we ask the LLMs to numerically rate various aspects of the musical cultures of different countries.","Our results indicate a strong preference of the LLMs for Western music cultures in both experiments."],"url":"http://arxiv.org/abs/2501.13720v1"}
{"created":"2025-01-23 14:46:38","title":"A Mutual Information Perspective on Multiple Latent Variable Generative Models for Positive View Generation","abstract":"In image generation, Multiple Latent Variable Generative Models (MLVGMs) employ multiple latent variables to gradually shape the final images, from global characteristics to finer and local details (e.g., StyleGAN, NVAE), emerging as powerful tools for diverse applications. Yet their generative dynamics and latent variable utilization remain only empirically observed. In this work, we propose a novel framework to systematically quantify the impact of each latent variable in MLVGMs, using Mutual Information (MI) as a guiding metric. Our analysis reveals underutilized variables and can guide the use of MLVGMs in downstream applications.   With this foundation, we introduce a method for generating synthetic data for Self-Supervised Contrastive Representation Learning (SSCRL). By leveraging the hierarchical and disentangled variables of MLVGMs, and guided by the previous analysis, we apply tailored latent perturbations to produce diverse views for SSCRL, without relying on real data altogether.   Additionally, we introduce a Continuous Sampling (CS) strategy, where the generator dynamically creates new samples during SSCRL training, greatly increasing data variability. Our comprehensive experiments demonstrate the effectiveness of these contributions, showing that MLVGMs' generated views compete on par with or even surpass views generated from real data.   This work establishes a principled approach to understanding and exploiting MLVGMs, advancing both generative modeling and self-supervised learning.","sentences":["In image generation, Multiple Latent Variable Generative Models (MLVGMs) employ multiple latent variables to gradually shape the final images, from global characteristics to finer and local details (e.g., StyleGAN, NVAE), emerging as powerful tools for diverse applications.","Yet their generative dynamics and latent variable utilization remain only empirically observed.","In this work, we propose a novel framework to systematically quantify the impact of each latent variable in MLVGMs, using Mutual Information (MI) as a guiding metric.","Our analysis reveals underutilized variables and can guide the use of MLVGMs in downstream applications.   ","With this foundation, we introduce a method for generating synthetic data for Self-Supervised Contrastive Representation Learning (SSCRL).","By leveraging the hierarchical and disentangled variables of MLVGMs, and guided by the previous analysis, we apply tailored latent perturbations to produce diverse views for SSCRL, without relying on real data altogether.   ","Additionally, we introduce a Continuous Sampling (CS) strategy, where the generator dynamically creates new samples during SSCRL training, greatly increasing data variability.","Our comprehensive experiments demonstrate the effectiveness of these contributions, showing that MLVGMs' generated views compete on par with or even surpass views generated from real data.   ","This work establishes a principled approach to understanding and exploiting MLVGMs, advancing both generative modeling and self-supervised learning."],"url":"http://arxiv.org/abs/2501.13718v1"}
{"created":"2025-01-23 14:43:53","title":"Skin Disease Detection and Classification of Actinic Keratosis and Psoriasis Utilizing Deep Transfer Learning","abstract":"Skin diseases can arise from infections, allergies, genetic factors, autoimmune disorders, hormonal imbalances, or environmental triggers such as sun damage and pollution. Some skin diseases, such as Actinic Keratosis and Psoriasis, can be fatal if not treated in time. Early identification is crucial, but the diagnostic methods for these conditions are often expensive and not widely accessible. In this study, we propose a novel and efficient method for diagnosing skin diseases using deep learning techniques. This approach employs a modified VGG16 Convolutional Neural Network (CNN) model. The model includes several convolutional layers and utilizes ImageNet weights with modified top layers. The top layer is updated with fully connected layers and a final softmax activation layer to classify skin diseases. The dataset used, titled \"Skin Disease Dataset,\" is publicly available. While the VGG16 architecture does not include data augmentation by default, preprocessing techniques such as rotation, shifting, and zooming were applied to augment the data prior to model training. The proposed methodology achieved 90.67% accuracy using the modified VGG16 model, demonstrating its reliability in classifying skin diseases. The promising results highlight the potential of this approach for real-world applications.","sentences":["Skin diseases can arise from infections, allergies, genetic factors, autoimmune disorders, hormonal imbalances, or environmental triggers such as sun damage and pollution.","Some skin diseases, such as Actinic Keratosis and Psoriasis, can be fatal if not treated in time.","Early identification is crucial, but the diagnostic methods for these conditions are often expensive and not widely accessible.","In this study, we propose a novel and efficient method for diagnosing skin diseases using deep learning techniques.","This approach employs a modified VGG16 Convolutional Neural Network (CNN) model.","The model includes several convolutional layers and utilizes ImageNet weights with modified top layers.","The top layer is updated with fully connected layers and a final softmax activation layer to classify skin diseases.","The dataset used, titled \"Skin Disease Dataset,\" is publicly available.","While the VGG16 architecture does not include data augmentation by default, preprocessing techniques such as rotation, shifting, and zooming were applied to augment the data prior to model training.","The proposed methodology achieved 90.67% accuracy using the modified VGG16 model, demonstrating its reliability in classifying skin diseases.","The promising results highlight the potential of this approach for real-world applications."],"url":"http://arxiv.org/abs/2501.13713v1"}
{"created":"2025-01-23 14:38:40","title":"YOLO11-JDE: Fast and Accurate Multi-Object Tracking with Self-Supervised Re-ID","abstract":"We introduce YOLO11-JDE, a fast and accurate multi-object tracking (MOT) solution that combines real-time object detection with self-supervised Re-Identification (Re-ID). By incorporating a dedicated Re-ID branch into YOLO11s, our model performs Joint Detection and Embedding (JDE), generating appearance features for each detection. The Re-ID branch is trained in a fully self-supervised setting while simultaneously training for detection, eliminating the need for costly identity-labeled datasets. The triplet loss, with hard positive and semi-hard negative mining strategies, is used for learning discriminative embeddings. Data association is enhanced with a custom tracking implementation that successfully integrates motion, appearance, and location cues. YOLO11-JDE achieves competitive results on MOT17 and MOT20 benchmarks, surpassing existing JDE methods in terms of FPS and using up to ten times fewer parameters. Thus, making our method a highly attractive solution for real-world applications.","sentences":["We introduce YOLO11-JDE, a fast and accurate multi-object tracking (MOT) solution that combines real-time object detection with self-supervised Re-Identification (Re-ID).","By incorporating a dedicated Re-ID branch into YOLO11s, our model performs Joint Detection and Embedding (JDE), generating appearance features for each detection.","The Re-ID branch is trained in a fully self-supervised setting while simultaneously training for detection, eliminating the need for costly identity-labeled datasets.","The triplet loss, with hard positive and semi-hard negative mining strategies, is used for learning discriminative embeddings.","Data association is enhanced with a custom tracking implementation that successfully integrates motion, appearance, and location cues.","YOLO11-JDE achieves competitive results on MOT17 and MOT20 benchmarks, surpassing existing JDE methods in terms of FPS and using up to ten times fewer parameters.","Thus, making our method a highly attractive solution for real-world applications."],"url":"http://arxiv.org/abs/2501.13710v1"}
{"created":"2025-01-23 14:37:21","title":"EventVL: Understand Event Streams via Multimodal Large Language Model","abstract":"The event-based Vision-Language Model (VLM) recently has made good progress for practical vision tasks. However, most of these works just utilize CLIP for focusing on traditional perception tasks, which obstruct model understanding explicitly the sufficient semantics and context from event streams. To address the deficiency, we propose EventVL, the first generative event-based MLLM (Multimodal Large Language Model) framework for explicit semantic understanding. Specifically, to bridge the data gap for connecting different modalities semantics, we first annotate a large event-image/video-text dataset, containing almost 1.4 million high-quality pairs of data, which enables effective learning across various scenes, e.g., drive scene or human motion. After that, we design Event Spatiotemporal Representation to fully explore the comprehensive information by diversely aggregating and segmenting the event stream. To further promote a compact semantic space, Dynamic Semantic Alignment is introduced to improve and complete sparse semantic spaces of events. Extensive experiments show that our EventVL can significantly surpass existing MLLM baselines in event captioning and scene description generation tasks. We hope our research could contribute to the development of the event vision community.","sentences":["The event-based Vision-Language Model (VLM) recently has made good progress for practical vision tasks.","However, most of these works just utilize CLIP for focusing on traditional perception tasks, which obstruct model understanding explicitly the sufficient semantics and context from event streams.","To address the deficiency, we propose EventVL, the first generative event-based MLLM (Multimodal Large Language Model) framework for explicit semantic understanding.","Specifically, to bridge the data gap for connecting different modalities semantics, we first annotate a large event-image/video-text dataset, containing almost 1.4 million high-quality pairs of data, which enables effective learning across various scenes, e.g., drive scene or human motion.","After that, we design Event Spatiotemporal Representation to fully explore the comprehensive information by diversely aggregating and segmenting the event stream.","To further promote a compact semantic space, Dynamic Semantic Alignment is introduced to improve and complete sparse semantic spaces of events.","Extensive experiments show that our EventVL can significantly surpass existing MLLM baselines in event captioning and scene description generation tasks.","We hope our research could contribute to the development of the event vision community."],"url":"http://arxiv.org/abs/2501.13707v1"}
{"created":"2025-01-23 14:35:19","title":"A real-time battle situation intelligent awareness system based on Meta-learning & RNN","abstract":"In modern warfare, real-time and accurate battle situation analysis is crucial for making strategic and tactical decisions. The proposed real-time battle situation intelligent awareness system (BSIAS) aims at meta-learning analysis and stepwise RNN (recurrent neural network) modeling, where the former carries out the basic processing and analysis of battlefield data, which includes multi-steps such as data cleansing, data fusion, data mining and continuously updates, and the latter optimizes the battlefield modeling by stepwise capturing the temporal dependencies of data set. BSIAS can predict the possible movement from any side of the fence and attack routes by taking a simulated battle as an example, which can be an intelligent support platform for commanders to make scientific decisions during wartime. This work delivers the potential application of integrated BSIAS in the field of battlefield command & analysis engineering.","sentences":["In modern warfare, real-time and accurate battle situation analysis is crucial for making strategic and tactical decisions.","The proposed real-time battle situation intelligent awareness system (BSIAS) aims at meta-learning analysis and stepwise RNN (recurrent neural network) modeling, where the former carries out the basic processing and analysis of battlefield data, which includes multi-steps such as data cleansing, data fusion, data mining and continuously updates, and the latter optimizes the battlefield modeling by stepwise capturing the temporal dependencies of data set.","BSIAS can predict the possible movement from any side of the fence and attack routes by taking a simulated battle as an example, which can be an intelligent support platform for commanders to make scientific decisions during wartime.","This work delivers the potential application of integrated BSIAS in the field of battlefield command & analysis engineering."],"url":"http://arxiv.org/abs/2501.13704v1"}
{"created":"2025-01-23 14:17:01","title":"Training-Free Consistency Pipeline for Fashion Repose","abstract":"Recent advancements in diffusion models have significantly broadened the possibilities for editing images of real-world objects. However, performing non-rigid transformations, such as changing the pose of objects or image-based conditioning, remains challenging. Maintaining object identity during these edits is difficult, and current methods often fall short of the precision needed for industrial applications, where consistency is critical. Additionally, fine-tuning diffusion models requires custom training data, which is not always accessible in real-world scenarios. This work introduces FashionRepose, a training-free pipeline for non-rigid pose editing specifically designed for the fashion industry. The approach integrates off-the-shelf models to adjust poses of long-sleeve garments, maintaining identity and branding attributes. FashionRepose uses a zero-shot approach to perform these edits in near real-time, eliminating the need for specialized training. consistent image editing. The solution holds potential for applications in the fashion industry and other fields demanding identity preservation in image editing.","sentences":["Recent advancements in diffusion models have significantly broadened the possibilities for editing images of real-world objects.","However, performing non-rigid transformations, such as changing the pose of objects or image-based conditioning, remains challenging.","Maintaining object identity during these edits is difficult, and current methods often fall short of the precision needed for industrial applications, where consistency is critical.","Additionally, fine-tuning diffusion models requires custom training data, which is not always accessible in real-world scenarios.","This work introduces FashionRepose, a training-free pipeline for non-rigid pose editing specifically designed for the fashion industry.","The approach integrates off-the-shelf models to adjust poses of long-sleeve garments, maintaining identity and branding attributes.","FashionRepose uses a zero-shot approach to perform these edits in near real-time, eliminating the need for specialized training.","consistent image editing.","The solution holds potential for applications in the fashion industry and other fields demanding identity preservation in image editing."],"url":"http://arxiv.org/abs/2501.13692v1"}
{"created":"2025-01-23 14:13:56","title":"Question Answering on Patient Medical Records with Private Fine-Tuned LLMs","abstract":"Healthcare systems continuously generate vast amounts of electronic health records (EHRs), commonly stored in the Fast Healthcare Interoperability Resources (FHIR) standard. Despite the wealth of information in these records, their complexity and volume make it difficult for users to retrieve and interpret crucial health insights. Recent advances in Large Language Models (LLMs) offer a solution, enabling semantic question answering (QA) over medical data, allowing users to interact with their health records more effectively. However, ensuring privacy and compliance requires edge and private deployments of LLMs.   This paper proposes a novel approach to semantic QA over EHRs by first identifying the most relevant FHIR resources for a user query (Task1) and subsequently answering the query based on these resources (Task2). We explore the performance of privately hosted, fine-tuned LLMs, evaluating them against benchmark models such as GPT-4 and GPT-4o. Our results demonstrate that fine-tuned LLMs, while 250x smaller in size, outperform GPT-4 family models by 0.55% in F1 score on Task1 and 42% on Meteor Task in Task2. Additionally, we examine advanced aspects of LLM usage, including sequential fine-tuning, model self-evaluation (narcissistic evaluation), and the impact of training data size on performance. The models and datasets are available here: https://huggingface.co/genloop","sentences":["Healthcare systems continuously generate vast amounts of electronic health records (EHRs), commonly stored in the Fast Healthcare Interoperability Resources (FHIR) standard.","Despite the wealth of information in these records, their complexity and volume make it difficult for users to retrieve and interpret crucial health insights.","Recent advances in Large Language Models (LLMs) offer a solution, enabling semantic question answering (QA) over medical data, allowing users to interact with their health records more effectively.","However, ensuring privacy and compliance requires edge and private deployments of LLMs.   ","This paper proposes a novel approach to semantic QA over EHRs by first identifying the most relevant FHIR resources for a user query (Task1) and subsequently answering the query based on these resources (Task2).","We explore the performance of privately hosted, fine-tuned LLMs, evaluating them against benchmark models such as GPT-4 and GPT-4o.","Our results demonstrate that fine-tuned LLMs, while 250x smaller in size, outperform GPT-4 family models by 0.55% in F1 score on Task1 and 42% on Meteor Task in Task2.","Additionally, we examine advanced aspects of LLM usage, including sequential fine-tuning, model self-evaluation (narcissistic evaluation), and the impact of training data size on performance.","The models and datasets are available here: https://huggingface.co/genloop"],"url":"http://arxiv.org/abs/2501.13687v1"}
{"created":"2025-01-23 14:13:26","title":"Learning in Conjectural Stackelberg Games","abstract":"We extend the formalism of Conjectural Variations games to Stackelberg games involving multiple leaders and a single follower. To solve these nonconvex games, a common assumption is that the leaders compute their strategies having perfect knowledge of the follower's best response. However, in practice, the leaders may have little to no knowledge about the other players' reactions. To deal with this lack of knowledge, we assume that each leader can form conjectures about the other players' best responses, and update its strategy relying on these conjectures. Our contributions are twofold: (i) On the theoretical side, we introduce the concept of Conjectural Stackelberg Equilibrium -- keeping our formalism conjecture agnostic -- with Stackelberg Equilibrium being a refinement of it. (ii) On the algorithmic side, we introduce a two-stage algorithm with guarantees of convergence, which allows the leaders to first learn conjectures on a training data set, and then update their strategies. Theoretical results are illustrated numerically.","sentences":["We extend the formalism of Conjectural Variations games to Stackelberg games involving multiple leaders and a single follower.","To solve these nonconvex games, a common assumption is that the leaders compute their strategies having perfect knowledge of the follower's best response.","However, in practice, the leaders may have little to no knowledge about the other players' reactions.","To deal with this lack of knowledge, we assume that each leader can form conjectures about the other players' best responses, and update its strategy relying on these conjectures.","Our contributions are twofold: (i) On the theoretical side, we introduce the concept of Conjectural Stackelberg Equilibrium -- keeping our formalism conjecture agnostic -- with Stackelberg Equilibrium being a refinement of it.","(ii) On the algorithmic side, we introduce a two-stage algorithm with guarantees of convergence, which allows the leaders to first learn conjectures on a training data set, and then update their strategies.","Theoretical results are illustrated numerically."],"url":"http://arxiv.org/abs/2501.13686v1"}
{"created":"2025-01-23 14:02:51","title":"HumorReject: Decoupling LLM Safety from Refusal Prefix via A Little Humor","abstract":"Large Language Models (LLMs) commonly rely on explicit refusal prefixes for safety, making them vulnerable to prefix injection attacks. We introduce HumorReject, a novel data-driven approach that fundamentally reimagines LLM safety by decoupling it from refusal prefixes through the use of humor as an indirect refusal strategy. Rather than explicitly rejecting harmful instructions, HumorReject responds with contextually appropriate humor that naturally defuses potentially dangerous requests while maintaining engaging interactions. Our approach effectively addresses the common \"over-defense\" issues in existing safety mechanisms, demonstrating superior robustness against various attack vectors while preserving natural and high-quality interactions on legitimate tasks. Our findings suggest that innovations at the data level are even more fundamental than the alignment algorithm itself in achieving effective LLM safety, opening new directions for developing more resilient and user-friendly AI systems.","sentences":["Large Language Models (LLMs) commonly rely on explicit refusal prefixes for safety, making them vulnerable to prefix injection attacks.","We introduce HumorReject, a novel data-driven approach that fundamentally reimagines LLM safety by decoupling it from refusal prefixes through the use of humor as an indirect refusal strategy.","Rather than explicitly rejecting harmful instructions, HumorReject responds with contextually appropriate humor that naturally defuses potentially dangerous requests while maintaining engaging interactions.","Our approach effectively addresses the common \"over-defense\" issues in existing safety mechanisms, demonstrating superior robustness against various attack vectors while preserving natural and high-quality interactions on legitimate tasks.","Our findings suggest that innovations at the data level are even more fundamental than the alignment algorithm itself in achieving effective LLM safety, opening new directions for developing more resilient and user-friendly AI systems."],"url":"http://arxiv.org/abs/2501.13677v1"}
{"created":"2025-01-23 13:06:35","title":"SMILES has to go : Representation of Molecules via Algebraic Data Types","abstract":"This paper proposes a novel representation of molecules through Algebraic Data Types (ADTs). The representation has useful properties primarily by including type information. The representation uses the Dietz representation enabling representation of organometallics with multi-centre, multi-atom bonding and delocalised electrons, resonant structures and co-ordinate data of atoms. Furthermore, this representation goes further than any other in the literature, providing a natural data structure to represent shells, subshells and orbitals. Perks of the representation include it's natural inclusion in reaction descriptions and the ability to make molecules instances of algebraic groups. The representation is further motivated as providing guarantees for those wishing to do Bayesian machine learning (probabilistic programming) over molecular structures. A criticism of competing and commonly used representations such as SMILES and SELFIES is provided and solutions are proposed to the weaknesses of these along with an open source library, written in Haskell. An example of integrating the library with LazyPPL -- a lazy probabilistic programming library written in Haskell -- is provided, conceptually justifying the efficiency of the representation over string based representations and recent work such as SELFIES. This library distinguishes between the data and the type of data -- enabling a separation of concerns between interface and object. I solve three problems associated with the future of SELFIES, molecular programming language, 3D information, syntactic invalidity and Dietz representation.","sentences":["This paper proposes a novel representation of molecules through Algebraic Data Types (ADTs).","The representation has useful properties primarily by including type information.","The representation uses the Dietz representation enabling representation of organometallics with multi-centre, multi-atom bonding and delocalised electrons, resonant structures and co-ordinate data of atoms.","Furthermore, this representation goes further than any other in the literature, providing a natural data structure to represent shells, subshells and orbitals.","Perks of the representation include it's natural inclusion in reaction descriptions and the ability to make molecules instances of algebraic groups.","The representation is further motivated as providing guarantees for those wishing to do Bayesian machine learning (probabilistic programming) over molecular structures.","A criticism of competing and commonly used representations such as SMILES and SELFIES is provided and solutions are proposed to the weaknesses of these along with an open source library, written in Haskell.","An example of integrating the library with LazyPPL -- a lazy probabilistic programming library written in Haskell -- is provided, conceptually justifying the efficiency of the representation over string based representations and recent work such as SELFIES.","This library distinguishes between the data and the type of data -- enabling a separation of concerns between interface and object.","I solve three problems associated with the future of SELFIES, molecular programming language, 3D information, syntactic invalidity and Dietz representation."],"url":"http://arxiv.org/abs/2501.13633v1"}
{"created":"2025-01-23 12:58:14","title":"Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models","abstract":"We introduce Sigma, an efficient large language model specialized for the system domain, empowered by a novel architecture including DiffQKV attention, and pre-trained on our meticulously collected system domain data. DiffQKV attention significantly enhances the inference efficiency of Sigma by optimizing the Query (Q), Key (K), and Value (V) components in the attention mechanism differentially, based on their varying impacts on the model performance and efficiency indicators. Specifically, we (1) conduct extensive experiments that demonstrate the model's varying sensitivity to the compression of K and V components, leading to the development of differentially compressed KV, and (2) propose augmented Q to expand the Q head dimension, which enhances the model's representation capacity with minimal impacts on the inference speed. Rigorous theoretical and empirical analyses reveal that DiffQKV attention significantly enhances efficiency, achieving up to a 33.36% improvement in inference speed over the conventional grouped-query attention (GQA) in long-context scenarios. We pre-train Sigma on 6T tokens from various sources, including 19.5B system domain data that we carefully collect and 1T tokens of synthesized and rewritten data. In general domains, Sigma achieves comparable performance to other state-of-arts models. In the system domain, we introduce the first comprehensive benchmark AIMicius, where Sigma demonstrates remarkable performance across all tasks, significantly outperforming GPT-4 with an absolute improvement up to 52.5%.","sentences":["We introduce Sigma, an efficient large language model specialized for the system domain, empowered by a novel architecture including DiffQKV attention, and pre-trained on our meticulously collected system domain data.","DiffQKV attention significantly enhances the inference efficiency of Sigma by optimizing the Query (Q), Key (K), and Value (V) components in the attention mechanism differentially, based on their varying impacts on the model performance and efficiency indicators.","Specifically, we (1) conduct extensive experiments that demonstrate the model's varying sensitivity to the compression of K and V components, leading to the development of differentially compressed KV, and (2) propose augmented Q to expand the Q head dimension, which enhances the model's representation capacity with minimal impacts on the inference speed.","Rigorous theoretical and empirical analyses reveal that DiffQKV attention significantly enhances efficiency, achieving up to a 33.36% improvement in inference speed over the conventional grouped-query attention (GQA) in long-context scenarios.","We pre-train Sigma on 6T tokens from various sources, including 19.5B system domain data that we carefully collect and 1T tokens of synthesized and rewritten data.","In general domains, Sigma achieves comparable performance to other state-of-arts models.","In the system domain, we introduce the first comprehensive benchmark AIMicius, where Sigma demonstrates remarkable performance across all tasks, significantly outperforming GPT-4 with an absolute improvement up to 52.5%."],"url":"http://arxiv.org/abs/2501.13629v1"}
{"created":"2025-01-23 12:44:45","title":"Coarse-to-Fine Process Reward Modeling for Enhanced Mathematical Reasoning","abstract":"Process reward model (PRM) is critical for mathematical reasoning tasks to assign rewards for each intermediate steps. The PRM requires constructing process-wise supervision data for training, which rely on chain-of-thought (CoT) or tree-based methods to construct the reasoning steps, however, the individual reasoning steps may be redundant or containing nuanced errors that difficult to detect. We attribute these to the issue of the overlook of granularity division during process data collection. In this paper, we propose a coarse-to-fine framework to tackle this issue. Specifically, while gathering the process supervision data, we collect the coarse reasoning steps by merging adjacent steps according to preset merging granularity, then we sequentially reduce the merging granularity to collect fine-grained reasoning steps. For each synthesized new step, we relabel according to the label of last step. During training, we also traverse the collected training corpus in a coarse-to-fine manner. We conduct extensive experiments on popular mathematical reasoning datasets across diverse loss criterions, the proposed framework can consistently boost the reasoning performance.","sentences":["Process reward model (PRM) is critical for mathematical reasoning tasks to assign rewards for each intermediate steps.","The PRM requires constructing process-wise supervision data for training, which rely on chain-of-thought (CoT) or tree-based methods to construct the reasoning steps, however, the individual reasoning steps may be redundant or containing nuanced errors that difficult to detect.","We attribute these to the issue of the overlook of granularity division during process data collection.","In this paper, we propose a coarse-to-fine framework to tackle this issue.","Specifically, while gathering the process supervision data, we collect the coarse reasoning steps by merging adjacent steps according to preset merging granularity, then we sequentially reduce the merging granularity to collect fine-grained reasoning steps.","For each synthesized new step, we relabel according to the label of last step.","During training, we also traverse the collected training corpus in a coarse-to-fine manner.","We conduct extensive experiments on popular mathematical reasoning datasets across diverse loss criterions, the proposed framework can consistently boost the reasoning performance."],"url":"http://arxiv.org/abs/2501.13622v1"}
{"created":"2025-01-23 12:28:22","title":"AirTOWN: A Privacy-Preserving Mobile App for Real-time Pollution-Aware POI Suggestion","abstract":"This demo paper presents \\airtown, a privacy-preserving mobile application that provides real-time, pollution-aware recommendations for points of interest (POIs) in urban environments. By combining real-time Air Quality Index (AQI) data with user preferences, the proposed system aims to help users make health-conscious decisions about the locations they visit. The application utilizes collaborative filtering for personalized suggestions, and federated learning for privacy protection, and integrates AQI data from sensor networks in cities such as Bari, Italy, and Cork, UK. In areas with sparse sensor coverage, interpolation techniques approximate AQI values, ensuring broad applicability. This system offers a poromsing, health-oriented POI recommendation solution that adapts dynamically to current urban air quality conditions while safeguarding user privacy.","sentences":["This demo paper presents \\airtown, a privacy-preserving mobile application that provides real-time, pollution-aware recommendations for points of interest (POIs) in urban environments.","By combining real-time Air Quality Index (AQI) data with user preferences, the proposed system aims to help users make health-conscious decisions about the locations they visit.","The application utilizes collaborative filtering for personalized suggestions, and federated learning for privacy protection, and integrates AQI data from sensor networks in cities such as Bari, Italy, and Cork, UK.","In areas with sparse sensor coverage, interpolation techniques approximate AQI values, ensuring broad applicability.","This system offers a poromsing, health-oriented POI recommendation solution that adapts dynamically to current urban air quality conditions while safeguarding user privacy."],"url":"http://arxiv.org/abs/2501.13608v1"}
{"created":"2025-01-23 12:19:33","title":"Two Step SOVA-Based Decoding Algorithm for Tailbiting Codes","abstract":"In this work we propose a novel decoding algorithm for tailbiting convolutional codes and evaluate its performance over different channels. The proposed method consists on a fixed two-step Viterbi decoding of the received data. In the first step, an estimation of the most likely state is performed based on a SOVA decoding. The second step consists of a conventional Viterbi decoding that employs the state estimated in the previous step as the initial and final states of the trellis. Simulations results show a performance close to that of maximum-likelihood decoding.","sentences":["In this work we propose a novel decoding algorithm for tailbiting convolutional codes and evaluate its performance over different channels.","The proposed method consists on a fixed two-step Viterbi decoding of the received data.","In the first step, an estimation of the most likely state is performed based on a SOVA decoding.","The second step consists of a conventional Viterbi decoding that employs the state estimated in the previous step as the initial and final states of the trellis.","Simulations results show a performance close to that of maximum-likelihood decoding."],"url":"http://arxiv.org/abs/2501.13606v1"}
{"created":"2025-01-23 12:12:59","title":"FedPref: Federated Learning Across Heterogeneous Multi-objective Preferences","abstract":"Federated Learning (FL) is a distributed machine learning strategy, developed for settings where training data is owned by distributed devices and cannot be shared. FL circumvents this constraint by carrying out model training in distribution. The parameters of these local models are shared intermittently among participants and aggregated to enhance model accuracy. This strategy has been rapidly adopted by the industry in efforts to overcome privacy and resource constraints in model training. However, the application of FL to real-world settings brings additional challenges associated with heterogeneity between participants. Research into mitigating these difficulties in FL has largely focused on only two types of heterogeneity: the unbalanced distribution of training data, and differences in client resources. Yet more types of heterogeneity are becoming relevant as the capability of FL expands to cover more complex problems, from the tuning of LLMs to enabling machine learning on edge devices. In this work, we discuss a novel type of heterogeneity that is likely to become increasingly relevant in future applications: this is preference heterogeneity, emerging when clients learn under multiple objectives, with different importance assigned to each objective on different clients. In this work, we discuss the implications of this type of heterogeneity and propose FedPref, a first algorithm designed to facilitate personalised FL in this setting. We demonstrate the effectiveness of the algorithm across different problems, preference distributions and model architectures. In addition, we introduce a new analytical point of view, based on multi-objective metrics, for evaluating the performance of FL algorithms in this setting beyond the traditional client-focused metrics. We perform a second experimental analysis based in this view, and show that FedPref outperforms compared algorithms.","sentences":["Federated Learning (FL) is a distributed machine learning strategy, developed for settings where training data is owned by distributed devices and cannot be shared.","FL circumvents this constraint by carrying out model training in distribution.","The parameters of these local models are shared intermittently among participants and aggregated to enhance model accuracy.","This strategy has been rapidly adopted by the industry in efforts to overcome privacy and resource constraints in model training.","However, the application of FL to real-world settings brings additional challenges associated with heterogeneity between participants.","Research into mitigating these difficulties in FL has largely focused on only two types of heterogeneity: the unbalanced distribution of training data, and differences in client resources.","Yet more types of heterogeneity are becoming relevant as the capability of FL expands to cover more complex problems, from the tuning of LLMs to enabling machine learning on edge devices.","In this work, we discuss a novel type of heterogeneity that is likely to become increasingly relevant in future applications: this is preference heterogeneity, emerging when clients learn under multiple objectives, with different importance assigned to each objective on different clients.","In this work, we discuss the implications of this type of heterogeneity and propose FedPref, a first algorithm designed to facilitate personalised FL in this setting.","We demonstrate the effectiveness of the algorithm across different problems, preference distributions and model architectures.","In addition, we introduce a new analytical point of view, based on multi-objective metrics, for evaluating the performance of FL algorithms in this setting beyond the traditional client-focused metrics.","We perform a second experimental analysis based in this view, and show that FedPref outperforms compared algorithms."],"url":"http://arxiv.org/abs/2501.13604v1"}
{"created":"2025-01-23 12:06:32","title":"A Comprehensive Survey on Spectral Clustering with Graph Structure Learnin","abstract":"Spectral clustering is a powerful technique for clustering high-dimensional data, utilizing graph-based representations to detect complex, non-linear structures and non-convex clusters. The construction of a similarity graph is essential for ensuring accurate and effective clustering, making graph structure learning (GSL) central for enhancing spectral clustering performance in response to the growing demand for scalable solutions. Despite advancements in GSL, there is a lack of comprehensive surveys specifically addressing its role within spectral clustering. To bridge this gap, this survey presents a comprehensive review of spectral clustering methods, emphasizing on the critical role of GSL. We explore various graph construction techniques, including pairwise, anchor, and hypergraph-based methods, in both fixed and adaptive settings. Additionally, we categorize spectral clustering approaches into single-view and multi-view frameworks, examining their applications within one-step and two-step clustering processes. We also discuss multi-view information fusion techniques and their impact on clustering data. By addressing current challenges and proposing future research directions, this survey provides valuable insights for advancing spectral clustering methodologies and highlights the pivotal role of GSL in tackling large-scale and high-dimensional data clustering tasks.","sentences":["Spectral clustering is a powerful technique for clustering high-dimensional data, utilizing graph-based representations to detect complex, non-linear structures and non-convex clusters.","The construction of a similarity graph is essential for ensuring accurate and effective clustering, making graph structure learning (GSL) central for enhancing spectral clustering performance in response to the growing demand for scalable solutions.","Despite advancements in GSL, there is a lack of comprehensive surveys specifically addressing its role within spectral clustering.","To bridge this gap, this survey presents a comprehensive review of spectral clustering methods, emphasizing on the critical role of GSL.","We explore various graph construction techniques, including pairwise, anchor, and hypergraph-based methods, in both fixed and adaptive settings.","Additionally, we categorize spectral clustering approaches into single-view and multi-view frameworks, examining their applications within one-step and two-step clustering processes.","We also discuss multi-view information fusion techniques and their impact on clustering data.","By addressing current challenges and proposing future research directions, this survey provides valuable insights for advancing spectral clustering methodologies and highlights the pivotal role of GSL in tackling large-scale and high-dimensional data clustering tasks."],"url":"http://arxiv.org/abs/2501.13597v1"}
{"created":"2025-01-23 12:06:02","title":"New Oracles and Labeling Schemes for Vertex Cut Queries","abstract":"We study succinct representations of vertex cuts by centralized oracles and labeling schemes. For an undirected $n$-vertex graph $G = (V,E)$ and integer parameter $f \\geq 1$, the goal is supporting vertex cut queries: Given $F \\subseteq V$ with $|F| \\leq f$, determine if $F$ is a vertex cut in $G$. In the centralized data structure setting, it is required to preprocess $G$ into an $f$-vertex cut oracle that can answer such queries quickly, while occupying only small space. In the labeling setting, one should assign a short label to each vertex in $G$, so that a cut query $F$ can be answered by merely inspecting the labels assigned to the vertices in $F$. While the ``$st$ cut variants'' of the above problems have been extensively researched and are known to admit very efficient solutions, the basic ``cut query'' setting is essentially open (particularly for $f > 3$). This work achieves the first significant progress on these problems:   [$f$-Vertex Cut Oracles:] Every $n$-vertex graph $G$ admits $f$-vertex cut oracle with $\\tilde{O}(2^{2f} n)$ space and $\\tilde{O}(2^{2f})$ query time, hence almost optimal for $f=o(\\log n)$. In case $G$ is $f$-connected (namely, when interested in minimum vertex cut queries), the space and query time improve to $\\tilde{O}(f n)$ and $\\tilde{O}(f^2)$, respectively.   [$f$-Vertex Cut Labels:] Every $n$-vertex graph admits an $f$-vertex cut labeling scheme, where the labels have length of $\\tilde{O}(n^{1-1/f})$ bits (when $f$ is polylogarithmic in $n$). This nearly matches the recent lower bound given by Long, Pettie and Saranurak (SODA 2025).","sentences":["We study succinct representations of vertex cuts by centralized oracles and labeling schemes.","For an undirected $n$-vertex graph $G = (V,E)$ and integer parameter $f \\geq 1$, the goal is supporting vertex cut queries: Given $F \\subseteq V$ with $|F| \\leq f$, determine if $F$ is a vertex cut in $G$. In the centralized data structure setting, it is required to preprocess $G$ into an $f$-vertex cut oracle that can answer such queries quickly, while occupying only small space.","In the labeling setting, one should assign a short label to each vertex in $G$, so that a cut query $F$ can be answered by merely inspecting the labels assigned to the vertices in $F$. While the ``$st$ cut variants'' of the above problems have been extensively researched and are known to admit very efficient solutions, the basic ``cut query'' setting is essentially open (particularly for $f > 3$).","This work achieves the first significant progress on these problems:   [$f$-Vertex Cut Oracles:] Every $n$-vertex graph $G$ admits $f$-vertex cut oracle with $\\tilde{O}(2^{2f} n)$ space and $\\tilde{O}(2^{2f})$ query time, hence almost optimal for $f=o(\\log n)$.","In case $G$ is $f$-connected (namely, when interested in minimum vertex cut queries), the space and query time improve to $\\tilde{O}(f n)$ and $\\tilde{O}(f^2)$, respectively.   ","[$f$-Vertex Cut Labels:]","Every $n$-vertex graph admits an $f$-vertex cut labeling scheme, where the labels have length of $\\tilde{O}(n^{1-1/f})$ bits (when $f$ is polylogarithmic in $n$).","This nearly matches the recent lower bound given by Long, Pettie and Saranurak (SODA 2025)."],"url":"http://arxiv.org/abs/2501.13596v1"}
{"created":"2025-01-23 11:55:13","title":"Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management","abstract":"Clinical machine learning deployment across institutions faces significant challenges when patient populations and clinical practices differ substantially. We present a systematic framework for cross-institutional knowledge transfer in clinical time series, demonstrated through pediatric ventilation management between a general pediatric intensive care unit (PICU) and a cardiac-focused unit. Using contrastive predictive coding (CPC) for representation learning, we investigate how different data regimes and fine-tuning strategies affect knowledge transfer across institutional boundaries. Our results show that while direct model transfer performs poorly, CPC with appropriate fine-tuning enables effective knowledge sharing between institutions, with benefits particularly evident in limited data scenarios. Analysis of transfer patterns reveals an important asymmetry: temporal progression patterns transfer more readily than point-of-care decisions, suggesting practical pathways for cross-institutional deployment. Through a systematic evaluation of fine-tuning approaches and transfer patterns, our work provides insights for developing more generalizable clinical decision support systems while enabling smaller specialized units to leverage knowledge from larger centers.","sentences":["Clinical machine learning deployment across institutions faces significant challenges when patient populations and clinical practices differ substantially.","We present a systematic framework for cross-institutional knowledge transfer in clinical time series, demonstrated through pediatric ventilation management between a general pediatric intensive care unit (PICU) and a cardiac-focused unit.","Using contrastive predictive coding (CPC) for representation learning, we investigate how different data regimes and fine-tuning strategies affect knowledge transfer across institutional boundaries.","Our results show that while direct model transfer performs poorly, CPC with appropriate fine-tuning enables effective knowledge sharing between institutions, with benefits particularly evident in limited data scenarios.","Analysis of transfer patterns reveals an important asymmetry: temporal progression patterns transfer more readily than point-of-care decisions, suggesting practical pathways for cross-institutional deployment.","Through a systematic evaluation of fine-tuning approaches and transfer patterns, our work provides insights for developing more generalizable clinical decision support systems while enabling smaller specialized units to leverage knowledge from larger centers."],"url":"http://arxiv.org/abs/2501.13587v1"}
{"created":"2025-01-23 11:52:53","title":"Towards Robust Incremental Learning under Ambiguous Supervision","abstract":"Traditional Incremental Learning (IL) targets to handle sequential fully-supervised learning problems where novel classes emerge from time to time. However, due to inherent annotation uncertainty and ambiguity, collecting high-quality annotated data in a dynamic learning system can be extremely expensive. To mitigate this problem, we propose a novel weakly-supervised learning paradigm called Incremental Partial Label Learning (IPLL), where the sequentially arrived data relate to a set of candidate labels rather than the ground truth. Technically, we develop the Prototype-Guided Disambiguation and Replay Algorithm (PGDR) which leverages the class prototypes as a proxy to mitigate two intertwined challenges in IPLL, i.e., label ambiguity and catastrophic forgetting. To handle the former, PGDR encapsulates a momentum-based pseudo-labeling algorithm along with prototype-guided initialization, resulting in a balanced perception of classes. To alleviate forgetting, we develop a memory replay technique that collects well-disambiguated samples while maintaining representativeness and diversity. By jointly distilling knowledge from curated memory data, our framework exhibits a great disambiguation ability for samples of new tasks and achieves less forgetting of knowledge. Extensive experiments demonstrate that PGDR achieves superior","sentences":["Traditional Incremental Learning (IL) targets to handle sequential fully-supervised learning problems where novel classes emerge from time to time.","However, due to inherent annotation uncertainty and ambiguity, collecting high-quality annotated data in a dynamic learning system can be extremely expensive.","To mitigate this problem, we propose a novel weakly-supervised learning paradigm called Incremental Partial Label Learning (IPLL), where the sequentially arrived data relate to a set of candidate labels rather than the ground truth.","Technically, we develop the Prototype-Guided Disambiguation and Replay Algorithm (PGDR) which leverages the class prototypes as a proxy to mitigate two intertwined challenges in IPLL, i.e., label ambiguity and catastrophic forgetting.","To handle the former, PGDR encapsulates a momentum-based pseudo-labeling algorithm along with prototype-guided initialization, resulting in a balanced perception of classes.","To alleviate forgetting, we develop a memory replay technique that collects well-disambiguated samples while maintaining representativeness and diversity.","By jointly distilling knowledge from curated memory data, our framework exhibits a great disambiguation ability for samples of new tasks and achieves less forgetting of knowledge.","Extensive experiments demonstrate that PGDR achieves superior"],"url":"http://arxiv.org/abs/2501.13584v1"}
{"created":"2025-01-23 11:38:00","title":"MixRec: Individual and Collective Mixing Empowers Data Augmentation for Recommender Systems","abstract":"The core of the general recommender systems lies in learning high-quality embedding representations of users and items to investigate their positional relations in the feature space. Unfortunately, data sparsity caused by difficult-to-access interaction data severely limits the effectiveness of recommender systems. Faced with such a dilemma, various types of self-supervised learning methods have been introduced into recommender systems in an attempt to alleviate the data sparsity through distribution modeling or data augmentation. However, most data augmentation relies on elaborate manual design, which is not only not universal, but the bloated and redundant augmentation process may significantly slow down model training progress. To tackle these limitations, we propose a novel Dual Mixing-based Recommendation Framework (MixRec) to empower data augmentation as we wish. Specifically, we propose individual mixing and collective mixing, respectively. The former aims to provide a new positive sample that is unique to the target (user or item) and to make the pair-wise recommendation loss benefit from it, while the latter aims to portray a new sample that contains group properties in a batch. The two mentioned mixing mechanisms allow for data augmentation with only one parameter that does not need to be set multiple times and can be done in linear time complexity. Besides, we propose the dual-mixing contrastive learning to maximize the utilization of these new-constructed samples to enhance the consistency between pairs of positive samples. Experimental results on four real-world datasets demonstrate the effectiveness of MixRec in terms of recommendation performance, training efficiency, sparsity resistance, and usability.","sentences":["The core of the general recommender systems lies in learning high-quality embedding representations of users and items to investigate their positional relations in the feature space.","Unfortunately, data sparsity caused by difficult-to-access interaction data severely limits the effectiveness of recommender systems.","Faced with such a dilemma, various types of self-supervised learning methods have been introduced into recommender systems in an attempt to alleviate the data sparsity through distribution modeling or data augmentation.","However, most data augmentation relies on elaborate manual design, which is not only not universal, but the bloated and redundant augmentation process may significantly slow down model training progress.","To tackle these limitations, we propose a novel Dual Mixing-based Recommendation Framework (MixRec) to empower data augmentation as we wish.","Specifically, we propose individual mixing and collective mixing, respectively.","The former aims to provide a new positive sample that is unique to the target (user or item) and to make the pair-wise recommendation loss benefit from it, while the latter aims to portray a new sample that contains group properties in a batch.","The two mentioned mixing mechanisms allow for data augmentation with only one parameter that does not need to be set multiple times and can be done in linear time complexity.","Besides, we propose the dual-mixing contrastive learning to maximize the utilization of these new-constructed samples to enhance the consistency between pairs of positive samples.","Experimental results on four real-world datasets demonstrate the effectiveness of MixRec in terms of recommendation performance, training efficiency, sparsity resistance, and usability."],"url":"http://arxiv.org/abs/2501.13579v1"}
{"created":"2025-01-23 10:56:47","title":"Compiler Support for Speculation in Decoupled Access/Execute Architectures","abstract":"Irregular codes are bottlenecked by memory and communication latency. Decoupled access/execute (DAE) is a common technique to tackle this problem. It relies on the compiler to separate memory address generation from the rest of the program, however, such a separation is not always possible due to control and data dependencies between the access and execute slices, resulting in a loss of decoupling.   In this paper, we present compiler support for speculation in DAE architectures that preserves decoupling in the face of control dependencies. We speculate memory requests in the access slice and poison mis-speculations in the execute slice without the need for replays or synchronization. Our transformation works on arbitrary, reducible control flow and is proven to preserve sequential consistency. We show that our approach applies to a wide range of architectural work on CPU/GPU prefetchers, CGRAs, and accelerators, enabling DAE on a wider range of codes than before.","sentences":["Irregular codes are bottlenecked by memory and communication latency.","Decoupled access/execute (DAE) is a common technique to tackle this problem.","It relies on the compiler to separate memory address generation from the rest of the program, however, such a separation is not always possible due to control and data dependencies between the access and execute slices, resulting in a loss of decoupling.   ","In this paper, we present compiler support for speculation in DAE architectures that preserves decoupling in the face of control dependencies.","We speculate memory requests in the access slice and poison mis-speculations in the execute slice without the need for replays or synchronization.","Our transformation works on arbitrary, reducible control flow and is proven to preserve sequential consistency.","We show that our approach applies to a wide range of architectural work on CPU/GPU prefetchers, CGRAs, and accelerators, enabling DAE on a wider range of codes than before."],"url":"http://arxiv.org/abs/2501.13553v1"}
{"created":"2025-01-23 10:54:22","title":"Minimizing Queue Length Regret for Arbitrarily Varying Channels","abstract":"We consider an online channel scheduling problem for a single transmitter-receiver pair equipped with $N$ arbitrarily varying wireless channels. The transmission rates of the channels might be non-stationary and could be controlled by an oblivious adversary. At every slot, incoming data arrives at an infinite-capacity data queue located at the transmitter. A scheduler, which is oblivious to the current channel rates, selects one of the $N$ channels for transmission. At the end of the slot, the scheduler only gets to know the transmission rate of the selected channel. The objective is to minimize the queue length regret, defined as the difference between the queue length at some time $T$ achieved by an online policy and the queue length obtained by always transmitting over the single best channel in hindsight. We propose a weakly adaptive Multi-Armed Bandit (MAB) algorithm for minimizing the queue length regret in this setup. Unlike previous works, we do not make any stability assumptions about the queue or the arrival process. Hence, our result holds even when the queueing process is unstable. Our main observation is that the queue length regret can be upper bounded by the regret of a MAB policy that competes against the best channel in hindsight uniformly over all sub-intervals of $[T]$. As a technical contribution of independent interest, we then propose a weakly adaptive adversarial MAB policy which achieves $\\tilde{O}(\\sqrt{N}T^{\\frac{3}{4}})$ regret with high probability, implying the same bound for queue length regret.","sentences":["We consider an online channel scheduling problem for a single transmitter-receiver pair equipped with $N$ arbitrarily varying wireless channels.","The transmission rates of the channels might be non-stationary and could be controlled by an oblivious adversary.","At every slot, incoming data arrives at an infinite-capacity data queue located at the transmitter.","A scheduler, which is oblivious to the current channel rates, selects one of the $N$ channels for transmission.","At the end of the slot, the scheduler only gets to know the transmission rate of the selected channel.","The objective is to minimize the queue length regret, defined as the difference between the queue length at some time $T$ achieved by an online policy and the queue length obtained by always transmitting over the single best channel in hindsight.","We propose a weakly adaptive Multi-Armed Bandit (MAB) algorithm for minimizing the queue length regret in this setup.","Unlike previous works, we do not make any stability assumptions about the queue or the arrival process.","Hence, our result holds even when the queueing process is unstable.","Our main observation is that the queue length regret can be upper bounded by the regret of a MAB policy that competes against the best channel in hindsight uniformly over all sub-intervals of $[T]$. As a technical contribution of independent interest, we then propose a weakly adaptive adversarial MAB policy which achieves $\\tilde{O}(\\sqrt{N}T^{\\frac{3}{4}})$ regret with high probability, implying the same bound for queue length regret."],"url":"http://arxiv.org/abs/2501.13551v1"}
{"created":"2025-01-23 10:44:35","title":"Advancing ATLAS DCS Data Analysis with a Modern Data Platform","abstract":"This paper presents a modern and scalable framework for analyzing Detector Control System (DCS) data from the ATLAS experiment at CERN. The DCS data, stored in an Oracle database via the WinCC OA system, is optimized for transactional operations, posing challenges for large-scale analysis across extensive time periods and devices. To address these limitations, we developed a data pipeline using Apache Spark, CERN's Hadoop service, and the CERN SWAN platform. This framework integrates seamlessly with Python notebooks, providing an accessible and efficient environment for data analysis using industry-standard tools. The approach has proven effective in troubleshooting Data Acquisition (DAQ) links for the ATLAS New Small Wheel (NSW) detector, demonstrating the value of modern data platforms in enabling detector experts to quickly identify and resolve critical issues.","sentences":["This paper presents a modern and scalable framework for analyzing Detector Control System (DCS) data from the ATLAS experiment at CERN.","The DCS data, stored in an Oracle database via the WinCC OA system, is optimized for transactional operations, posing challenges for large-scale analysis across extensive time periods and devices.","To address these limitations, we developed a data pipeline using Apache Spark, CERN's Hadoop service, and the CERN SWAN platform.","This framework integrates seamlessly with Python notebooks, providing an accessible and efficient environment for data analysis using industry-standard tools.","The approach has proven effective in troubleshooting Data Acquisition (DAQ) links for the ATLAS New Small Wheel (NSW) detector, demonstrating the value of modern data platforms in enabling detector experts to quickly identify and resolve critical issues."],"url":"http://arxiv.org/abs/2501.13543v1"}
{"created":"2025-01-23 10:35:22","title":"ReasVQA: Advancing VideoQA with Imperfect Reasoning Process","abstract":"Video Question Answering (VideoQA) is a challenging task that requires understanding complex visual and temporal relationships within videos to answer questions accurately. In this work, we introduce \\textbf{ReasVQA} (Reasoning-enhanced Video Question Answering), a novel approach that leverages reasoning processes generated by Multimodal Large Language Models (MLLMs) to improve the performance of VideoQA models. Our approach consists of three phases: reasoning generation, reasoning refinement, and learning from reasoning. First, we generate detailed reasoning processes using additional MLLMs, and second refine them via a filtering step to ensure data quality. Finally, we use the reasoning data, which might be in an imperfect form, to guide the VideoQA model via multi-task learning, on how to interpret and answer questions based on a given video. We evaluate ReasVQA on three popular benchmarks, and our results establish new state-of-the-art performance with significant improvements of +2.9 on NExT-QA, +7.3 on STAR, and +5.9 on IntentQA. Our findings demonstrate the supervising benefits of integrating reasoning processes into VideoQA. Further studies validate each component of our method, also with different backbones and MLLMs, and again highlight the advantages of this simple but effective method. We offer a new perspective on enhancing VideoQA performance by utilizing advanced reasoning techniques, setting a new benchmark in this research field.","sentences":["Video Question Answering (VideoQA) is a challenging task that requires understanding complex visual and temporal relationships within videos to answer questions accurately.","In this work, we introduce \\textbf{ReasVQA} (Reasoning-enhanced Video Question Answering), a novel approach that leverages reasoning processes generated by Multimodal Large Language Models (MLLMs) to improve the performance of VideoQA models.","Our approach consists of three phases: reasoning generation, reasoning refinement, and learning from reasoning.","First, we generate detailed reasoning processes using additional MLLMs, and second refine them via a filtering step to ensure data quality.","Finally, we use the reasoning data, which might be in an imperfect form, to guide the VideoQA model via multi-task learning, on how to interpret and answer questions based on a given video.","We evaluate ReasVQA on three popular benchmarks, and our results establish new state-of-the-art performance with significant improvements of +2.9 on NExT-QA, +7.3 on STAR, and +5.9 on IntentQA.","Our findings demonstrate the supervising benefits of integrating reasoning processes into VideoQA.","Further studies validate each component of our method, also with different backbones and MLLMs, and again highlight the advantages of this simple but effective method.","We offer a new perspective on enhancing VideoQA performance by utilizing advanced reasoning techniques, setting a new benchmark in this research field."],"url":"http://arxiv.org/abs/2501.13536v1"}
{"created":"2025-01-23 10:05:25","title":"Propensity-driven Uncertainty Learning for Sample Exploration in Source-Free Active Domain Adaptation","abstract":"Source-free active domain adaptation (SFADA) addresses the challenge of adapting a pre-trained model to new domains without access to source data while minimizing the need for target domain annotations. This scenario is particularly relevant in real-world applications where data privacy, storage limitations, or labeling costs are significant concerns. Key challenges in SFADA include selecting the most informative samples from the target domain for labeling, effectively leveraging both labeled and unlabeled target data, and adapting the model without relying on source domain information. Additionally, existing methods often struggle with noisy or outlier samples and may require impractical progressive labeling during training. To effectively select more informative samples without frequently requesting human annotations, we propose the Propensity-driven Uncertainty Learning (ProULearn) framework. ProULearn utilizes a novel homogeneity propensity estimation mechanism combined with correlation index calculation to evaluate feature-level relationships. This approach enables the identification of representative and challenging samples while avoiding noisy outliers. Additionally, we develop a central correlation loss to refine pseudo-labels and create compact class distributions during adaptation. In this way, ProULearn effectively bridges the domain gap and maximizes adaptation performance. The principles of informative sample selection underlying ProULearn have broad implications beyond SFADA, offering benefits across various deep learning tasks where identifying key data points or features is crucial. Extensive experiments on four benchmark datasets demonstrate that ProULearn outperforms state-of-the-art methods in domain adaptation scenarios.","sentences":["Source-free active domain adaptation (SFADA) addresses the challenge of adapting a pre-trained model to new domains without access to source data while minimizing the need for target domain annotations.","This scenario is particularly relevant in real-world applications where data privacy, storage limitations, or labeling costs are significant concerns.","Key challenges in SFADA include selecting the most informative samples from the target domain for labeling, effectively leveraging both labeled and unlabeled target data, and adapting the model without relying on source domain information.","Additionally, existing methods often struggle with noisy or outlier samples and may require impractical progressive labeling during training.","To effectively select more informative samples without frequently requesting human annotations, we propose the Propensity-driven Uncertainty Learning (ProULearn) framework.","ProULearn utilizes a novel homogeneity propensity estimation mechanism combined with correlation index calculation to evaluate feature-level relationships.","This approach enables the identification of representative and challenging samples while avoiding noisy outliers.","Additionally, we develop a central correlation loss to refine pseudo-labels and create compact class distributions during adaptation.","In this way, ProULearn effectively bridges the domain gap and maximizes adaptation performance.","The principles of informative sample selection underlying ProULearn have broad implications beyond SFADA, offering benefits across various deep learning tasks where identifying key data points or features is crucial.","Extensive experiments on four benchmark datasets demonstrate that ProULearn outperforms state-of-the-art methods in domain adaptation scenarios."],"url":"http://arxiv.org/abs/2501.13517v1"}
{"created":"2025-01-23 09:29:40","title":"Continuous signal sparse encoding using analog neuromorphic variability","abstract":"Achieving fast and reliable temporal signal encoding is crucial for low-power, always-on systems. While current spike-based encoding algorithms rely on complex networks or precise timing references, simple and robust encoding models can be obtained by leveraging the intrinsic properties of analog hardware substrates. We propose an encoding framework inspired by biological principles that leverages intrinsic neuronal variability to robustly encode continuous stimuli into spatio-temporal patterns, using at most one spike per neuron. The encoder has low model complexity, relying on a shallow network of heterogeneous neurons. It relies on an internal time reference, allowing for continuous processing. Moreover, stimulus parameters can be linearly decoded from the spiking patterns, granting fast information retrieval. Our approach, validated on both analog neuromorphic hardware and simulation, demonstrates high robustness to noise, spike jitter, and reduced heterogeneity. Consistently with biological observations, we observed the spontaneous emergence of patterns with stereotyped spiking order. The proposed encoding scheme facilitates fast, robust and continuous information processing, making it well-suited for low-power, low-latency processing of temporal data on analog neuromorphic substrates.","sentences":["Achieving fast and reliable temporal signal encoding is crucial for low-power, always-on systems.","While current spike-based encoding algorithms rely on complex networks or precise timing references, simple and robust encoding models can be obtained by leveraging the intrinsic properties of analog hardware substrates.","We propose an encoding framework inspired by biological principles that leverages intrinsic neuronal variability to robustly encode continuous stimuli into spatio-temporal patterns, using at most one spike per neuron.","The encoder has low model complexity, relying on a shallow network of heterogeneous neurons.","It relies on an internal time reference, allowing for continuous processing.","Moreover, stimulus parameters can be linearly decoded from the spiking patterns, granting fast information retrieval.","Our approach, validated on both analog neuromorphic hardware and simulation, demonstrates high robustness to noise, spike jitter, and reduced heterogeneity.","Consistently with biological observations, we observed the spontaneous emergence of patterns with stereotyped spiking order.","The proposed encoding scheme facilitates fast, robust and continuous information processing, making it well-suited for low-power, low-latency processing of temporal data on analog neuromorphic substrates."],"url":"http://arxiv.org/abs/2501.13504v1"}
{"created":"2025-01-23 09:14:07","title":"RECALL: Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles","abstract":"We introduce the concept of the self-referencing causal cycle (abbreviated RECALL) - a mechanism that enables large language models (LLMs) to bypass the limitations of unidirectional causality, which underlies a phenomenon known as the reversal curse. When an LLM is prompted with sequential data, it often fails to recall preceding context. For example, when we ask an LLM to recall the line preceding \"O say does that star-spangled banner yet wave\" in the U.S. National Anthem, it often fails to correctly return \"Gave proof through the night that our flag was still there\" - this is due to the reversal curse. It occurs because language models such as ChatGPT and Llama generate text based on preceding tokens, requiring facts to be learned and reproduced in a consistent token order. While the reversal curse is often viewed as a limitation, we offer evidence of an alternative view: it is not always an obstacle in practice. We find that RECALL is driven by what we designate as cycle tokens - sequences that connect different parts of the training data, enabling recall of preceding tokens from succeeding ones. Through rigorous probabilistic formalization and controlled experiments, we demonstrate how the cycles they induce influence a model's ability to reproduce information. To facilitate reproducibility, we provide our code and experimental details at https://anonymous.4open.science/r/remember-B0B8/.","sentences":["We introduce the concept of the self-referencing causal cycle (abbreviated RECALL) - a mechanism that enables large language models (LLMs) to bypass the limitations of unidirectional causality, which underlies a phenomenon known as the reversal curse.","When an LLM is prompted with sequential data, it often fails to recall preceding context.","For example, when we ask an LLM to recall the line preceding \"O say does that star-spangled banner yet wave\" in the U.S. National Anthem, it often fails to correctly return \"Gave proof through the night that our flag was still there\" - this is due to the reversal curse.","It occurs because language models such as ChatGPT and Llama generate text based on preceding tokens, requiring facts to be learned and reproduced in a consistent token order.","While the reversal curse is often viewed as a limitation, we offer evidence of an alternative view: it is not always an obstacle in practice.","We find that RECALL is driven by what we designate as cycle tokens - sequences that connect different parts of the training data, enabling recall of preceding tokens from succeeding ones.","Through rigorous probabilistic formalization and controlled experiments, we demonstrate how the cycles they induce influence a model's ability to reproduce information.","To facilitate reproducibility, we provide our code and experimental details at https://anonymous.4open.science/r/remember-B0B8/."],"url":"http://arxiv.org/abs/2501.13491v1"}
{"created":"2025-01-23 08:57:33","title":"MambaQuant: Quantizing the Mamba Family with Variance Aligned Rotation Methods","abstract":"Mamba is an efficient sequence model that rivals Transformers and demonstrates significant potential as a foundational architecture for various tasks. Quantization is commonly used in neural networks to reduce model size and computational latency. However, applying quantization to Mamba remains underexplored, and existing quantization methods, which have been effective for CNN and Transformer models, appear inadequate for Mamba models (e.g., Quarot suffers a 21% accuracy drop on Vim-T$^\\dagger$ even under W8A8). We have pioneered the exploration of this issue and identified several key challenges. First, significant outliers are present in gate projections, output projections, and matrix multiplications. Second, Mamba's unique parallel scan further amplifies these outliers, leading to uneven and heavy-tailed data distributions. Third, even with the application of the Hadamard transform, the variance across channels in weights and activations still remains inconsistent. To these ends, we propose MambaQuant, a post-training quantization (PTQ) framework consisting of: 1) Karhunen-Loeve Transformation (KLT) enhanced rotation, rendering the rotation matrix adaptable to diverse channel distributions. 2) Smooth-Fused rotation, which equalizes channel variances and can merge additional parameters into model weights. Experiments show that MambaQuant can quantize both weights and activations into 8-bit with less than 1% accuracy loss for Mamba-based vision and language tasks. To the best of our knowledge, MambaQuant is the first comprehensive PTQ design for the Mamba family, paving the way for further advancements in its application.","sentences":["Mamba is an efficient sequence model that rivals Transformers and demonstrates significant potential as a foundational architecture for various tasks.","Quantization is commonly used in neural networks to reduce model size and computational latency.","However, applying quantization to Mamba remains underexplored, and existing quantization methods, which have been effective for CNN and Transformer models, appear inadequate for Mamba models (e.g., Quarot suffers a 21% accuracy drop on Vim-T$^\\dagger$ even under W8A8).","We have pioneered the exploration of this issue and identified several key challenges.","First, significant outliers are present in gate projections, output projections, and matrix multiplications.","Second, Mamba's unique parallel scan further amplifies these outliers, leading to uneven and heavy-tailed data distributions.","Third, even with the application of the Hadamard transform, the variance across channels in weights and activations still remains inconsistent.","To these ends, we propose MambaQuant, a post-training quantization (PTQ) framework consisting of: 1) Karhunen-Loeve Transformation (KLT) enhanced rotation, rendering the rotation matrix adaptable to diverse channel distributions.","2) Smooth-Fused rotation, which equalizes channel variances and can merge additional parameters into model weights.","Experiments show that MambaQuant can quantize both weights and activations into 8-bit with less than 1% accuracy loss for Mamba-based vision and language tasks.","To the best of our knowledge, MambaQuant is the first comprehensive PTQ design for the Mamba family, paving the way for further advancements in its application."],"url":"http://arxiv.org/abs/2501.13484v1"}
{"created":"2025-01-23 08:51:49","title":"Adaptive Few-Shot Learning (AFSL): Tackling Data Scarcity with Stability, Robustness, and Versatility","abstract":"Few-shot learning (FSL) enables machine learning models to generalize effectively with minimal labeled data, making it crucial for data-scarce domains such as healthcare, robotics, and natural language processing. Despite its potential, FSL faces challenges including sensitivity to initialization, difficulty in adapting to diverse domains, and vulnerability to noisy datasets. To address these issues, this paper introduces Adaptive Few-Shot Learning (AFSL), a framework that integrates advancements in meta-learning, domain alignment, noise resilience, and multi-modal integration. AFSL consists of four key modules: a Dynamic Stability Module for performance consistency, a Contextual Domain Alignment Module for domain adaptation, a Noise-Adaptive Resilience Module for handling noisy data, and a Multi-Modal Fusion Module for integrating diverse modalities. This work also explores strategies such as task-aware data augmentation, semi-supervised learning, and explainable AI techniques to enhance the applicability and robustness of FSL. AFSL provides scalable, reliable, and impactful solutions for real-world, high-stakes domains.","sentences":["Few-shot learning (FSL) enables machine learning models to generalize effectively with minimal labeled data, making it crucial for data-scarce domains such as healthcare, robotics, and natural language processing.","Despite its potential, FSL faces challenges including sensitivity to initialization, difficulty in adapting to diverse domains, and vulnerability to noisy datasets.","To address these issues, this paper introduces Adaptive Few-Shot Learning (AFSL), a framework that integrates advancements in meta-learning, domain alignment, noise resilience, and multi-modal integration.","AFSL consists of four key modules: a Dynamic Stability Module for performance consistency, a Contextual Domain Alignment Module for domain adaptation, a Noise-Adaptive Resilience Module for handling noisy data, and a Multi-Modal Fusion Module for integrating diverse modalities.","This work also explores strategies such as task-aware data augmentation, semi-supervised learning, and explainable AI techniques to enhance the applicability and robustness of FSL.","AFSL provides scalable, reliable, and impactful solutions for real-world, high-stakes domains."],"url":"http://arxiv.org/abs/2501.13479v1"}
{"created":"2025-01-23 08:33:10","title":"Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge","abstract":"Recent advances in Large Language Models (LLMs) have enabled the development of Video-LLMs, advancing multimodal learning by bridging video data with language tasks. However, current video understanding models struggle with processing long video sequences, supporting multi-turn dialogues, and adapting to real-world dynamic scenarios. To address these issues, we propose StreamChat, a training-free framework for streaming video reasoning and conversational interaction. $\\StreamChat$ leverages a novel hierarchical memory system to efficiently process and compress video features over extended sequences, enabling real-time, multi-turn dialogue. Our framework incorporates a parallel system scheduling strategy that enhances processing speed and reduces latency, ensuring robust performance in real-world applications. Furthermore, we introduce StreamBench, a versatile benchmark that evaluates streaming video understanding across diverse media types and interactive scenarios, including multi-turn interactions and complex reasoning tasks. Extensive evaluations on StreamBench and other public benchmarks demonstrate that StreamChat significantly outperforms existing state-of-the-art models in terms of accuracy and response times, confirming its effectiveness for streaming video understanding. Code is available at StreamChat: https://github.com/hmxiong/StreamChat.","sentences":["Recent advances in Large Language Models (LLMs) have enabled the development of Video-LLMs, advancing multimodal learning by bridging video data with language tasks.","However, current video understanding models struggle with processing long video sequences, supporting multi-turn dialogues, and adapting to real-world dynamic scenarios.","To address these issues, we propose StreamChat, a training-free framework for streaming video reasoning and conversational interaction.","$\\StreamChat$ leverages a novel hierarchical memory system to efficiently process and compress video features over extended sequences, enabling real-time, multi-turn dialogue.","Our framework incorporates a parallel system scheduling strategy that enhances processing speed and reduces latency, ensuring robust performance in real-world applications.","Furthermore, we introduce StreamBench, a versatile benchmark that evaluates streaming video understanding across diverse media types and interactive scenarios, including multi-turn interactions and complex reasoning tasks.","Extensive evaluations on StreamBench and other public benchmarks demonstrate that StreamChat significantly outperforms existing state-of-the-art models in terms of accuracy and response times, confirming its effectiveness for streaming video understanding.","Code is available at StreamChat: https://github.com/hmxiong/StreamChat."],"url":"http://arxiv.org/abs/2501.13468v1"}
{"created":"2025-01-23 08:32:27","title":"Multi-Level Attention and Contrastive Learning for Enhanced Text Classification with an Optimized Transformer","abstract":"This paper studies a text classification algorithm based on an improved Transformer to improve the performance and efficiency of the model in text classification tasks. Aiming at the shortcomings of the traditional Transformer model in capturing deep semantic relationships and optimizing computational complexity, this paper introduces a multi-level attention mechanism and a contrastive learning strategy. The multi-level attention mechanism effectively models the global semantics and local features in the text by combining global attention with local attention; the contrastive learning strategy enhances the model's ability to distinguish between different categories by constructing positive and negative sample pairs while improving the classification effect. In addition, in order to improve the training and inference efficiency of the model on large-scale text data, this paper designs a lightweight module to optimize the feature transformation process and reduce the computational cost. Experimental results on the dataset show that the improved Transformer model outperforms the comparative models such as BiLSTM, CNN, standard Transformer, and BERT in terms of classification accuracy, F1 score, and recall rate, showing stronger semantic representation ability and generalization performance. The method proposed in this paper provides a new idea for algorithm optimization in the field of text classification and has good application potential and practical value. Future work will focus on studying the performance of this model in multi-category imbalanced datasets and cross-domain tasks and explore the integration wi","sentences":["This paper studies a text classification algorithm based on an improved Transformer to improve the performance and efficiency of the model in text classification tasks.","Aiming at the shortcomings of the traditional Transformer model in capturing deep semantic relationships and optimizing computational complexity, this paper introduces a multi-level attention mechanism and a contrastive learning strategy.","The multi-level attention mechanism effectively models the global semantics and local features in the text by combining global attention with local attention; the contrastive learning strategy enhances the model's ability to distinguish between different categories by constructing positive and negative sample pairs while improving the classification effect.","In addition, in order to improve the training and inference efficiency of the model on large-scale text data, this paper designs a lightweight module to optimize the feature transformation process and reduce the computational cost.","Experimental results on the dataset show that the improved Transformer model outperforms the comparative models such as BiLSTM, CNN, standard Transformer, and BERT in terms of classification accuracy, F1 score, and recall rate, showing stronger semantic representation ability and generalization performance.","The method proposed in this paper provides a new idea for algorithm optimization in the field of text classification and has good application potential and practical value.","Future work will focus on studying the performance of this model in multi-category imbalanced datasets and cross-domain tasks and explore the integration wi"],"url":"http://arxiv.org/abs/2501.13467v1"}
{"created":"2025-01-23 08:15:52","title":"Zero-Shot Trajectory Planning for Signal Temporal Logic Tasks","abstract":"Signal Temporal Logic (STL) is a powerful specification language for describing complex temporal behaviors of continuous signals, making it well-suited for high-level robotic task descriptions. However, generating executable plans for STL tasks is challenging, as it requires consideration of the coupling between the task specification and the system dynamics. Existing approaches either follow a model-based setting that explicitly requires knowledge of the system dynamics or adopt a task-oriented data-driven approach to learn plans for specific tasks. In this work, we investigate the problem of generating executable STL plans for systems whose dynamics are unknown a priori. We propose a new planning framework that uses only task-agnostic data during the offline training stage, enabling zero-shot generalization to new STL tasks. Our framework is hierarchical, involving: (i) decomposing the STL task into a set of progress and time constraints, (ii) searching for time-aware waypoints guided by task-agnostic data, and (iii) generating trajectories using a pre-trained safe diffusion model. Simulation results demonstrate the effectiveness of our method indeed in achieving zero-shot generalization to various STL tasks.","sentences":["Signal Temporal Logic (STL) is a powerful specification language for describing complex temporal behaviors of continuous signals, making it well-suited for high-level robotic task descriptions.","However, generating executable plans for STL tasks is challenging, as it requires consideration of the coupling between the task specification and the system dynamics.","Existing approaches either follow a model-based setting that explicitly requires knowledge of the system dynamics or adopt a task-oriented data-driven approach to learn plans for specific tasks.","In this work, we investigate the problem of generating executable STL plans for systems whose dynamics are unknown a priori.","We propose a new planning framework that uses only task-agnostic data during the offline training stage, enabling zero-shot generalization to new STL tasks.","Our framework is hierarchical, involving: (i) decomposing the STL task into a set of progress and time constraints, (ii) searching for time-aware waypoints guided by task-agnostic data, and (iii) generating trajectories using a pre-trained safe diffusion model.","Simulation results demonstrate the effectiveness of our method indeed in achieving zero-shot generalization to various STL tasks."],"url":"http://arxiv.org/abs/2501.13457v1"}
{"created":"2025-01-23 07:49:36","title":"Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design","abstract":"The recent surge in artificial intelligence, particularly in multimodal processing technology, has advanced human-computer interaction, by altering how intelligent systems perceive, understand, and respond to contextual information (i.e., context awareness). Despite such advancements, there is a significant gap in comprehensive reviews examining these advances, especially from a multimodal data perspective, which is crucial for refining system design. This paper addresses a key aspect of this gap by conducting a systematic survey of data modality-driven Vision-based Multimodal Interfaces (VMIs). VMIs are essential for integrating multimodal data, enabling more precise interpretation of user intentions and complex interactions across physical and digital environments. Unlike previous task- or scenario-driven surveys, this study highlights the critical role of the visual modality in processing contextual information and facilitating multimodal interaction. Adopting a design framework moving from the whole to the details and back, it classifies VMIs across dimensions, providing insights for developing effective, context-aware systems.","sentences":["The recent surge in artificial intelligence, particularly in multimodal processing technology, has advanced human-computer interaction, by altering how intelligent systems perceive, understand, and respond to contextual information (i.e., context awareness).","Despite such advancements, there is a significant gap in comprehensive reviews examining these advances, especially from a multimodal data perspective, which is crucial for refining system design.","This paper addresses a key aspect of this gap by conducting a systematic survey of data modality-driven Vision-based Multimodal Interfaces (VMIs).","VMIs are essential for integrating multimodal data, enabling more precise interpretation of user intentions and complex interactions across physical and digital environments.","Unlike previous task- or scenario-driven surveys, this study highlights the critical role of the visual modality in processing contextual information and facilitating multimodal interaction.","Adopting a design framework moving from the whole to the details and back, it classifies VMIs across dimensions, providing insights for developing effective, context-aware systems."],"url":"http://arxiv.org/abs/2501.13443v1"}
{"created":"2025-01-23 07:29:44","title":"Wasserstein-regularized Conformal Prediction under General Distribution Shift","abstract":"Conformal prediction yields a prediction set with guaranteed $1-\\alpha$ coverage of the true target under the i.i.d. assumption, which may not hold and lead to a gap between $1-\\alpha$ and the actual coverage. Prior studies bound the gap using total variation distance, which cannot identify the gap changes under distribution shift at a given $\\alpha$. Besides, existing methods are mostly limited to covariate shift,while general joint distribution shifts are more common in practice but less researched.In response, we first propose a Wasserstein distance-based upper bound of the coverage gap and analyze the bound using probability measure pushforwards between the shifted joint data and conformal score distributions, enabling a separation of the effect of covariate and concept shifts over the coverage gap. We exploit the separation to design an algorithm based on importance weighting and regularized representation learning (WR-CP) to reduce the Wasserstein bound with a finite-sample error bound.WR-CP achieves a controllable balance between conformal prediction accuracy and efficiency. Experiments on six datasets prove that WR-CP can reduce coverage gaps to $3.1\\%$ across different confidence levels and outputs prediction sets 38$\\%$ smaller than the worst-case approach on average.","sentences":["Conformal prediction yields a prediction set with guaranteed $1-\\alpha$ coverage of the true target under the i.i.d. assumption, which may not hold and lead to a gap between $1-\\alpha$ and the actual coverage.","Prior studies bound the gap using total variation distance, which cannot identify the gap changes under distribution shift at a given $\\alpha$. Besides, existing methods are mostly limited to covariate shift,while general joint distribution shifts are more common in practice but less researched.","In response, we first propose a Wasserstein distance-based upper bound of the coverage gap and analyze the bound using probability measure pushforwards between the shifted joint data and conformal score distributions, enabling a separation of the effect of covariate and concept shifts over the coverage gap.","We exploit the separation to design an algorithm based on importance weighting and regularized representation learning (WR-CP) to reduce the Wasserstein bound with a finite-sample error bound.","WR-CP achieves a controllable balance between conformal prediction accuracy and efficiency.","Experiments on six datasets prove that WR-CP can reduce coverage gaps to $3.1\\%$ across different confidence levels and outputs prediction sets 38$\\%$ smaller than the worst-case approach on average."],"url":"http://arxiv.org/abs/2501.13430v1"}
{"created":"2025-01-23 07:08:48","title":"Auto-Prompting SAM for Weakly Supervised Landslide Extraction","abstract":"Weakly supervised landslide extraction aims to identify landslide regions from remote sensing data using models trained with weak labels, particularly image-level labels. However, it is often challenged by the imprecise boundaries of the extracted objects due to the lack of pixel-wise supervision and the properties of landslide objects. To tackle these issues, we propose a simple yet effective method by auto-prompting the Segment Anything Model (SAM), i.e., APSAM. Instead of depending on high-quality class activation maps (CAMs) for pseudo-labeling or fine-tuning SAM, our method directly yields fine-grained segmentation masks from SAM inference through prompt engineering. Specifically, it adaptively generates hybrid prompts from the CAMs obtained by an object localization network. To provide sufficient information for SAM prompting, an adaptive prompt generation (APG) algorithm is designed to fully leverage the visual patterns of CAMs, enabling the efficient generation of pseudo-masks for landslide extraction. These informative prompts are able to identify the extent of landslide areas (box prompts) and denote the centers of landslide objects (point prompts), guiding SAM in landslide segmentation. Experimental results on high-resolution aerial and satellite datasets demonstrate the effectiveness of our method, achieving improvements of at least 3.0\\% in F1 score and 3.69\\% in IoU compared to other state-of-the-art methods. The source codes and datasets will be available at https://github.com/zxk688.","sentences":["Weakly supervised landslide extraction aims to identify landslide regions from remote sensing data using models trained with weak labels, particularly image-level labels.","However, it is often challenged by the imprecise boundaries of the extracted objects due to the lack of pixel-wise supervision and the properties of landslide objects.","To tackle these issues, we propose a simple yet effective method by auto-prompting the Segment Anything Model (SAM), i.e., APSAM.","Instead of depending on high-quality class activation maps (CAMs) for pseudo-labeling or fine-tuning SAM, our method directly yields fine-grained segmentation masks from SAM inference through prompt engineering.","Specifically, it adaptively generates hybrid prompts from the CAMs obtained by an object localization network.","To provide sufficient information for SAM prompting, an adaptive prompt generation (APG) algorithm is designed to fully leverage the visual patterns of CAMs, enabling the efficient generation of pseudo-masks for landslide extraction.","These informative prompts are able to identify the extent of landslide areas (box prompts) and denote the centers of landslide objects (point prompts), guiding SAM in landslide segmentation.","Experimental results on high-resolution aerial and satellite datasets demonstrate the effectiveness of our method, achieving improvements of at least 3.0\\% in F1 score and 3.69\\% in IoU compared to other state-of-the-art methods.","The source codes and datasets will be available at https://github.com/zxk688."],"url":"http://arxiv.org/abs/2501.13426v1"}
{"created":"2025-01-23 06:51:31","title":"Perceived Fairness of the Machine Learning Development Process: Concept Scale Development","abstract":"In machine learning (ML) applications, unfairness is triggered due to bias in the data, the data curation process, erroneous assumptions, and implicit bias rendered during the development process. It is also well-accepted by researchers that fairness in ML application development is highly subjective, with a lack of clarity of what it means from an ML development and implementation perspective. Thus, in this research, we investigate and formalize the notion of the perceived fairness of ML development from a sociotechnical lens. Our goal in this research is to understand the characteristics of perceived fairness in ML applications. We address this research goal using a three-pronged strategy: 1) conducting virtual focus groups with ML developers, 2) reviewing existing literature on fairness in ML, and 3) incorporating aspects of justice theory relating to procedural and distributive justice. Based on our theoretical exposition, we propose operational attributes of perceived fairness to be transparency, accountability, and representativeness. These are described in terms of multiple concepts that comprise each dimension of perceived fairness. We use this operationalization to empirically validate the notion of perceived fairness of machine learning (ML) applications from both the ML practioners and users perspectives. The multidimensional framework for perceived fairness offers a comprehensive understanding of perceived fairness, which can guide the creation of fair ML systems with positive implications for society and businesses.","sentences":["In machine learning (ML) applications, unfairness is triggered due to bias in the data, the data curation process, erroneous assumptions, and implicit bias rendered during the development process.","It is also well-accepted by researchers that fairness in ML application development is highly subjective, with a lack of clarity of what it means from an ML development and implementation perspective.","Thus, in this research, we investigate and formalize the notion of the perceived fairness of ML development from a sociotechnical lens.","Our goal in this research is to understand the characteristics of perceived fairness in ML applications.","We address this research goal using a three-pronged strategy: 1) conducting virtual focus groups with ML developers, 2) reviewing existing literature on fairness in ML, and 3) incorporating aspects of justice theory relating to procedural and distributive justice.","Based on our theoretical exposition, we propose operational attributes of perceived fairness to be transparency, accountability, and representativeness.","These are described in terms of multiple concepts that comprise each dimension of perceived fairness.","We use this operationalization to empirically validate the notion of perceived fairness of machine learning (ML) applications from both the ML practioners and users perspectives.","The multidimensional framework for perceived fairness offers a comprehensive understanding of perceived fairness, which can guide the creation of fair ML systems with positive implications for society and businesses."],"url":"http://arxiv.org/abs/2501.13421v1"}
{"created":"2025-01-23 06:43:38","title":"GeomGS: LiDAR-Guided Geometry-Aware Gaussian Splatting for Robot Localization","abstract":"Mapping and localization are crucial problems in robotics and autonomous driving. Recent advances in 3D Gaussian Splatting (3DGS) have enabled precise 3D mapping and scene understanding by rendering photo-realistic images. However, existing 3DGS methods often struggle to accurately reconstruct a 3D map that reflects the actual scale and geometry of the real world, which degrades localization performance. To address these limitations, we propose a novel 3DGS method called Geometry-Aware Gaussian Splatting (GeomGS). This method fully integrates LiDAR data into 3D Gaussian primitives via a probabilistic approach, as opposed to approaches that only use LiDAR as initial points or introduce simple constraints for Gaussian points. To this end, we introduce a Geometric Confidence Score (GCS), which identifies the structural reliability of each Gaussian point. The GCS is optimized simultaneously with Gaussians under probabilistic distance constraints to construct a precise structure. Furthermore, we propose a novel localization method that fully utilizes both the geometric and photometric properties of GeomGS. Our GeomGS demonstrates state-of-the-art geometric and localization performance across several benchmarks, while also improving photometric performance.","sentences":["Mapping and localization are crucial problems in robotics and autonomous driving.","Recent advances in 3D Gaussian Splatting (3DGS) have enabled precise 3D mapping and scene understanding by rendering photo-realistic images.","However, existing 3DGS methods often struggle to accurately reconstruct a 3D map that reflects the actual scale and geometry of the real world, which degrades localization performance.","To address these limitations, we propose a novel 3DGS method called Geometry-Aware Gaussian Splatting (GeomGS).","This method fully integrates LiDAR data into 3D Gaussian primitives via a probabilistic approach, as opposed to approaches that only use LiDAR as initial points or introduce simple constraints for Gaussian points.","To this end, we introduce a Geometric Confidence Score (GCS), which identifies the structural reliability of each Gaussian point.","The GCS is optimized simultaneously with Gaussians under probabilistic distance constraints to construct a precise structure.","Furthermore, we propose a novel localization method that fully utilizes both the geometric and photometric properties of GeomGS.","Our GeomGS demonstrates state-of-the-art geometric and localization performance across several benchmarks, while also improving photometric performance."],"url":"http://arxiv.org/abs/2501.13417v1"}
{"created":"2025-01-23 06:33:05","title":"VulnBot: Autonomous Penetration Testing for A Multi-Agent Collaborative Framework","abstract":"Penetration testing is a vital practice for identifying and mitigating vulnerabilities in cybersecurity systems, but its manual execution is labor-intensive and time-consuming. Existing large language model (LLM)-assisted or automated penetration testing approaches often suffer from inefficiencies, such as a lack of contextual understanding and excessive, unstructured data generation. This paper presents VulnBot, an automated penetration testing framework that leverages LLMs to simulate the collaborative workflow of human penetration testing teams through a multi-agent system. To address the inefficiencies and reliance on manual intervention in traditional penetration testing methods, VulnBot decomposes complex tasks into three specialized phases: reconnaissance, scanning, and exploitation. These phases are guided by a penetration task graph (PTG) to ensure logical task execution. Key design features include role specialization, penetration path planning, inter-agent communication, and generative penetration behavior. Experimental results demonstrate that VulnBot outperforms baseline models such as GPT-4 and Llama3 in automated penetration testing tasks, particularly showcasing its potential in fully autonomous testing on real-world machines.","sentences":["Penetration testing is a vital practice for identifying and mitigating vulnerabilities in cybersecurity systems, but its manual execution is labor-intensive and time-consuming.","Existing large language model (LLM)-assisted or automated penetration testing approaches often suffer from inefficiencies, such as a lack of contextual understanding and excessive, unstructured data generation.","This paper presents VulnBot, an automated penetration testing framework that leverages LLMs to simulate the collaborative workflow of human penetration testing teams through a multi-agent system.","To address the inefficiencies and reliance on manual intervention in traditional penetration testing methods, VulnBot decomposes complex tasks into three specialized phases: reconnaissance, scanning, and exploitation.","These phases are guided by a penetration task graph (PTG) to ensure logical task execution.","Key design features include role specialization, penetration path planning, inter-agent communication, and generative penetration behavior.","Experimental results demonstrate that VulnBot outperforms baseline models such as GPT-4 and Llama3 in automated penetration testing tasks, particularly showcasing its potential in fully autonomous testing on real-world machines."],"url":"http://arxiv.org/abs/2501.13411v1"}
{"created":"2025-01-23 06:06:50","title":"Performance Analysis of Fluid Antenna Multiple Access Assisted Wireless Powered Communication Network","abstract":"This paper investigates a novel fluid antenna multiple access (FAMA)-assisted wireless powered communication network (WPCN), in which a hybrid access point (HAP) equipped with multiple fixed position antennas (FPAs) provides integrated data and energy transfer (IDET) services towards low-power devices that are equipped with a single fluid antenna (FA), while the low-power devices use harvested energy to power their own uplink transmission. Using the block correlation channel model, both the downlink and uplink wireless data transfer (WDT) outage probabilities are analyzed under specific port selection strategies, including downlink signal-to-interference ratio-based port selection (DSPS) strategy, downlink energy harvesting power-based port selection (DEPS) strategy, uplink signal-to-noise ratio-based port selection (USPS) strategy, and uplink channel-based port selection (UCPS) strategy. A step function approximation (SFA) approach is also relied upon to derive closed-form expressions for the outage probabilities, while the lower bounds for uplink WDT outage probabilities are also formulated. Numerical results demonstrate the validity of our theoretical analysis, which also provide useful guidelines for the system design through the analytical framework.","sentences":["This paper investigates a novel fluid antenna multiple access (FAMA)-assisted wireless powered communication network (WPCN), in which a hybrid access point (HAP) equipped with multiple fixed position antennas (FPAs) provides integrated data and energy transfer (IDET) services towards low-power devices that are equipped with a single fluid antenna (FA), while the low-power devices use harvested energy to power their own uplink transmission.","Using the block correlation channel model, both the downlink and uplink wireless data transfer (WDT) outage probabilities are analyzed under specific port selection strategies, including downlink signal-to-interference ratio-based port selection (DSPS) strategy, downlink energy harvesting power-based port selection (DEPS) strategy, uplink signal-to-noise ratio-based port selection (USPS) strategy, and uplink channel-based port selection (UCPS) strategy.","A step function approximation (SFA) approach is also relied upon to derive closed-form expressions for the outage probabilities, while the lower bounds for uplink WDT outage probabilities are also formulated.","Numerical results demonstrate the validity of our theoretical analysis, which also provide useful guidelines for the system design through the analytical framework."],"url":"http://arxiv.org/abs/2501.13405v1"}
{"created":"2025-01-23 05:24:18","title":"Can Large Language Models Understand Preferences in Personalized Recommendation?","abstract":"Large Language Models (LLMs) excel in various tasks, including personalized recommendations. Existing evaluation methods often focus on rating prediction, relying on regression errors between actual and predicted ratings. However, user rating bias and item quality, two influential factors behind rating scores, can obscure personal preferences in user-item pair data. To address this, we introduce PerRecBench, disassociating the evaluation from these two factors and assessing recommendation techniques on capturing the personal preferences in a grouped ranking manner. We find that the LLM-based recommendation techniques that are generally good at rating prediction fail to identify users' favored and disfavored items when the user rating bias and item quality are eliminated by grouping users. With PerRecBench and 19 LLMs, we find that while larger models generally outperform smaller ones, they still struggle with personalized recommendation. Our findings reveal the superiority of pairwise and listwise ranking approaches over pointwise ranking, PerRecBench's low correlation with traditional regression metrics, the importance of user profiles, and the role of pretraining data distributions. We further explore three supervised fine-tuning strategies, finding that merging weights from single-format training is promising but improving LLMs' understanding of user preferences remains an open research problem. Code and data are available at https://github.com/TamSiuhin/PerRecBench","sentences":["Large Language Models (LLMs) excel in various tasks, including personalized recommendations.","Existing evaluation methods often focus on rating prediction, relying on regression errors between actual and predicted ratings.","However, user rating bias and item quality, two influential factors behind rating scores, can obscure personal preferences in user-item pair data.","To address this, we introduce PerRecBench, disassociating the evaluation from these two factors and assessing recommendation techniques on capturing the personal preferences in a grouped ranking manner.","We find that the LLM-based recommendation techniques that are generally good at rating prediction fail to identify users' favored and disfavored items when the user rating bias and item quality are eliminated by grouping users.","With PerRecBench and 19 LLMs, we find that while larger models generally outperform smaller ones, they still struggle with personalized recommendation.","Our findings reveal the superiority of pairwise and listwise ranking approaches over pointwise ranking, PerRecBench's low correlation with traditional regression metrics, the importance of user profiles, and the role of pretraining data distributions.","We further explore three supervised fine-tuning strategies, finding that merging weights from single-format training is promising but improving LLMs' understanding of user preferences remains an open research problem.","Code and data are available at https://github.com/TamSiuhin/PerRecBench"],"url":"http://arxiv.org/abs/2501.13391v1"}
{"created":"2025-01-23 05:21:27","title":"Beyond Task Diversity: Provable Representation Transfer for Sequential Multi-Task Linear Bandits","abstract":"We study lifelong learning in linear bandits, where a learner interacts with a sequence of linear bandit tasks whose parameters lie in an $m$-dimensional subspace of $\\mathbb{R}^d$, thereby sharing a low-rank representation. Current literature typically assumes that the tasks are diverse, i.e., their parameters uniformly span the $m$-dimensional subspace. This assumption allows the low-rank representation to be learned before all tasks are revealed, which can be unrealistic in real-world applications. In this work, we present the first nontrivial result for sequential multi-task linear bandits without the task diversity assumption. We develop an algorithm that efficiently learns and transfers low-rank representations. When facing $N$ tasks, each played over $\\tau$ rounds, our algorithm achieves a regret guarantee of $\\tilde{O}\\big (Nm \\sqrt{\\tau} + N^{\\frac{2}{3}} \\tau^{\\frac{2}{3}} d m^{\\frac13} + Nd^2 + \\tau m d \\big)$ under the ellipsoid action set assumption. This result can significantly improve upon the baseline of $\\tilde{O} \\left (Nd \\sqrt{\\tau}\\right)$ that does not leverage the low-rank structure when the number of tasks $N$ is sufficiently large and $m \\ll d$. We also demonstrate empirically on synthetic data that our algorithm outperforms baseline algorithms, which rely on the task diversity assumption.","sentences":["We study lifelong learning in linear bandits, where a learner interacts with a sequence of linear bandit tasks whose parameters lie in an $m$-dimensional subspace of $\\mathbb{R}^d$, thereby sharing a low-rank representation.","Current literature typically assumes that the tasks are diverse, i.e., their parameters uniformly span the $m$-dimensional subspace.","This assumption allows the low-rank representation to be learned before all tasks are revealed, which can be unrealistic in real-world applications.","In this work, we present the first nontrivial result for sequential multi-task linear bandits without the task diversity assumption.","We develop an algorithm that efficiently learns and transfers low-rank representations.","When facing $N$ tasks, each played over $\\tau$ rounds, our algorithm achieves a regret guarantee of $\\tilde{O}\\big (Nm \\sqrt{\\tau} + N^{\\frac{2}{3}} \\tau^{\\frac{2}{3}} d m^{\\frac13} + Nd^2 + \\tau m d \\big)$ under the ellipsoid action set assumption.","This result can significantly improve upon the baseline of $\\tilde{O} \\left (Nd \\sqrt{\\tau}\\right)$ that does not leverage the low-rank structure when the number of tasks $N$ is sufficiently large and $m \\ll d$.","We also demonstrate empirically on synthetic data that our algorithm outperforms baseline algorithms, which rely on the task diversity assumption."],"url":"http://arxiv.org/abs/2501.13390v1"}
{"created":"2025-01-23 04:14:59","title":"Meta-Feature Adapter: Integrating Environmental Metadata for Enhanced Animal Re-identification","abstract":"Identifying individual animals within large wildlife populations is essential for effective wildlife monitoring and conservation efforts. Recent advancements in computer vision have shown promise in animal re-identification (Animal ReID) by leveraging data from camera traps. However, existing methods rely exclusively on visual data, neglecting environmental metadata that ecologists have identified as highly correlated with animal behavior and identity, such as temperature and circadian rhythms. To bridge this gap, we propose the Meta-Feature Adapter (MFA), a lightweight module designed to integrate environmental metadata into vision-language foundation models, such as CLIP, to enhance Animal ReID performance. Our approach translates environmental metadata into natural language descriptions, encodes them into metadata-aware text embeddings, and incorporates these embeddings into image features through a cross-attention mechanism. Furthermore, we introduce a Gated Cross-Attention mechanism that dynamically adjusts the weights of metadata contributions, further improving performance. To validate our approach, we constructed the Metadata Augmented Animal Re-identification (MAAR) dataset, encompassing six species from New Zealand and featuring paired image data and environmental metadata. Extensive experiments demonstrate that MFA consistently improves Animal ReID performance across multiple baseline models.","sentences":["Identifying individual animals within large wildlife populations is essential for effective wildlife monitoring and conservation efforts.","Recent advancements in computer vision have shown promise in animal re-identification (Animal ReID) by leveraging data from camera traps.","However, existing methods rely exclusively on visual data, neglecting environmental metadata that ecologists have identified as highly correlated with animal behavior and identity, such as temperature and circadian rhythms.","To bridge this gap, we propose the Meta-Feature Adapter (MFA), a lightweight module designed to integrate environmental metadata into vision-language foundation models, such as CLIP, to enhance Animal ReID performance.","Our approach translates environmental metadata into natural language descriptions, encodes them into metadata-aware text embeddings, and incorporates these embeddings into image features through a cross-attention mechanism.","Furthermore, we introduce a Gated Cross-Attention mechanism that dynamically adjusts the weights of metadata contributions, further improving performance.","To validate our approach, we constructed the Metadata Augmented Animal Re-identification (MAAR) dataset, encompassing six species from New Zealand and featuring paired image data and environmental metadata.","Extensive experiments demonstrate that MFA consistently improves Animal ReID performance across multiple baseline models."],"url":"http://arxiv.org/abs/2501.13368v1"}
{"created":"2025-01-23 03:42:22","title":"NUDT4MSTAR: A New Dataset and Benchmark Towards SAR Target Recognition in the Wild","abstract":"Synthetic Aperture Radar (SAR) stands as an indispensable sensor for Earth observation, owing to its unique capability for all-day imaging. Nevertheless, in a data-driven era, the scarcity of large-scale datasets poses a significant bottleneck to advancing SAR automatic target recognition (ATR) technology. This paper introduces NUDT4MSTAR, a large-scale SAR dataset for vehicle target recognition in the wild, including 40 target types and a wide array of imaging conditions across 5 different scenes. NUDT4MSTAR represents a significant leap forward in dataset scale, containing over 190,000 images-tenfold the size of its predecessors. To enhance the utility of this dataset, we meticulously annotate each image with detailed target information and imaging conditions. We also provide data in both processed magnitude images and original complex formats. Then, we construct a comprehensive benchmark consisting of 7 experiments with 15 recognition methods focusing on the stable and effective ATR issues. Besides, we conduct transfer learning experiments utilizing various models trained on NUDT4MSTAR and applied to three other target datasets, thereby demonstrating its substantial potential to the broader field of ground objects ATR. Finally, we discuss this dataset's application value and ATR's significant challenges. To the best of our knowledge, this work marks the first-ever endeavor to create a large-scale dataset benchmark for fine-grained SAR recognition in the wild, featuring an extensive collection of exhaustively annotated vehicle images. We expect that the open source of NUDT4MSTAR will facilitate the development of SAR ATR and attract a wider community of researchers.","sentences":["Synthetic Aperture Radar (SAR) stands as an indispensable sensor for Earth observation, owing to its unique capability for all-day imaging.","Nevertheless, in a data-driven era, the scarcity of large-scale datasets poses a significant bottleneck to advancing SAR automatic target recognition (ATR) technology.","This paper introduces NUDT4MSTAR, a large-scale SAR dataset for vehicle target recognition in the wild, including 40 target types and a wide array of imaging conditions across 5 different scenes.","NUDT4MSTAR represents a significant leap forward in dataset scale, containing over 190,000 images-tenfold the size of its predecessors.","To enhance the utility of this dataset, we meticulously annotate each image with detailed target information and imaging conditions.","We also provide data in both processed magnitude images and original complex formats.","Then, we construct a comprehensive benchmark consisting of 7 experiments with 15 recognition methods focusing on the stable and effective ATR issues.","Besides, we conduct transfer learning experiments utilizing various models trained on NUDT4MSTAR and applied to three other target datasets, thereby demonstrating its substantial potential to the broader field of ground objects ATR.","Finally, we discuss this dataset's application value and ATR's significant challenges.","To the best of our knowledge, this work marks the first-ever endeavor to create a large-scale dataset benchmark for fine-grained SAR recognition in the wild, featuring an extensive collection of exhaustively annotated vehicle images.","We expect that the open source of NUDT4MSTAR will facilitate the development of SAR ATR and attract a wider community of researchers."],"url":"http://arxiv.org/abs/2501.13354v1"}
{"created":"2025-01-23 03:13:45","title":"One Fits All: General Mobility Trajectory Modeling via Masked Conditional Diffusion","abstract":"Trajectory data play a crucial role in many applications, ranging from network optimization to urban planning. Existing studies on trajectory data are task-specific, and their applicability is limited to the specific tasks on which they have been trained, such as generation, recovery, or prediction. However, the potential of a unified model has not yet been fully explored in trajectory modeling. Although various trajectory tasks differ in inputs, outputs, objectives, and conditions, they share common mobility patterns. Based on these common patterns, we can construct a general framework that enables a single model to address different tasks. However, building a trajectory task-general framework faces two critical challenges: 1) the diversity in the formats of different tasks and 2) the complexity of the conditions imposed on different tasks. In this work, we propose a general trajectory modeling framework via masked conditional diffusion (named GenMove). Specifically, we utilize mask conditions to unify diverse formats. To adapt to complex conditions associated with different tasks, we utilize historical trajectory data to obtain contextual trajectory embeddings, which include rich contexts such as spatiotemporal characteristics and user preferences. Integrating the contextual trajectory embedding into diffusion models through a classifier-free guidance approach allows the model to flexibly adjust its outputs based on different conditions. Extensive experiments on mainstream tasks demonstrate that our model significantly outperforms state-of-the-art baselines, with the highest performance improvement exceeding 13% in generation tasks.","sentences":["Trajectory data play a crucial role in many applications, ranging from network optimization to urban planning.","Existing studies on trajectory data are task-specific, and their applicability is limited to the specific tasks on which they have been trained, such as generation, recovery, or prediction.","However, the potential of a unified model has not yet been fully explored in trajectory modeling.","Although various trajectory tasks differ in inputs, outputs, objectives, and conditions, they share common mobility patterns.","Based on these common patterns, we can construct a general framework that enables a single model to address different tasks.","However, building a trajectory task-general framework faces two critical challenges: 1) the diversity in the formats of different tasks and 2) the complexity of the conditions imposed on different tasks.","In this work, we propose a general trajectory modeling framework via masked conditional diffusion (named GenMove).","Specifically, we utilize mask conditions to unify diverse formats.","To adapt to complex conditions associated with different tasks, we utilize historical trajectory data to obtain contextual trajectory embeddings, which include rich contexts such as spatiotemporal characteristics and user preferences.","Integrating the contextual trajectory embedding into diffusion models through a classifier-free guidance approach allows the model to flexibly adjust its outputs based on different conditions.","Extensive experiments on mainstream tasks demonstrate that our model significantly outperforms state-of-the-art baselines, with the highest performance improvement exceeding 13% in generation tasks."],"url":"http://arxiv.org/abs/2501.13347v1"}
{"created":"2025-01-23 03:10:38","title":"Markovian Search with Socially Aware Constraints","abstract":"We study a general class of sequential search problems for selecting multiple candidates from different societal groups under \"ex-ante constraints\" aimed at producing socially desirable outcomes, such as demographic parity, diversity quotas, or subsidies for disadvantaged groups. Starting with the canonical Pandora's box model [Weitzman, 1978] under a single affine constraint on selection and inspection probabilities, we show that the optimal constrained policy retains an index-based structure similar to the unconstrained case, but may randomize between two dual-based adjustments that are both easy to compute and economically interpretable. We then extend our results to handle multiple affine constraints by reducing the problem to a variant of the exact Carath\\'eodory problem and providing a novel polynomial-time algorithm to generate an optimal randomized dual-adjusted index-based policy that satisfies all constraints simultaneously. Building on these insights, we consider richer search processes (e.g., search with rejection and multistage search) modeled by joint Markov scheduling (JMS) [Dumitriu et al., 2003; Gittins, 1979]. By imposing general affine and convex ex-ante constraints, we develop a primal-dual algorithm that randomizes over a polynomial number of dual-based adjustments to the unconstrained JMS Gittins indices, yielding a near-feasible, near-optimal policy. Our approach relies on the key observation that a suitable relaxation of the Lagrange dual function for these constrained problems admits index-based policies akin to those in the unconstrained setting. Using a numerical study, we investigate the implications of imposing various constraints, in particular the utilitarian loss (price of fairness), and whether these constraints induce their intended societally desirable outcomes.","sentences":["We study a general class of sequential search problems for selecting multiple candidates from different societal groups under \"ex-ante constraints\" aimed at producing socially desirable outcomes, such as demographic parity, diversity quotas, or subsidies for disadvantaged groups.","Starting with the canonical Pandora's box model [Weitzman, 1978] under a single affine constraint on selection and inspection probabilities, we show that the optimal constrained policy retains an index-based structure similar to the unconstrained case, but may randomize between two dual-based adjustments that are both easy to compute and economically interpretable.","We then extend our results to handle multiple affine constraints by reducing the problem to a variant of the exact Carath\\'eodory problem and providing a novel polynomial-time algorithm to generate an optimal randomized dual-adjusted index-based policy that satisfies all constraints simultaneously.","Building on these insights, we consider richer search processes (e.g., search with rejection and multistage search) modeled by joint Markov scheduling (JMS)","[Dumitriu et al., 2003; Gittins, 1979].","By imposing general affine and convex ex-ante constraints, we develop a primal-dual algorithm that randomizes over a polynomial number of dual-based adjustments to the unconstrained JMS Gittins indices, yielding a near-feasible, near-optimal policy.","Our approach relies on the key observation that a suitable relaxation of the Lagrange dual function for these constrained problems admits index-based policies akin to those in the unconstrained setting.","Using a numerical study, we investigate the implications of imposing various constraints, in particular the utilitarian loss (price of fairness), and whether these constraints induce their intended societally desirable outcomes."],"url":"http://arxiv.org/abs/2501.13346v1"}
{"created":"2025-01-23 03:05:13","title":"Full-Stack Optimized Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation","abstract":"In this paper, we address the lifelong sequential behavior incomprehension problem in large language models (LLMs) for recommendation, where LLMs struggle to extract useful information from long user behavior sequences, even within their context limits. To tackle this, we propose ReLLaX (Retrieval-enhanced Large Language models Plus), a framework offering optimization across data, prompt, and parameter levels. At the data level, we introduce Semantic User Behavior Retrieval (SUBR) to reduce sequence heterogeneity, making it easier for LLMs to extract key information. For prompt-level enhancement, we employ Soft Prompt Augmentation (SPA) to inject collaborative knowledge, aligning item representations with recommendation tasks and improving LLMs's exploration of item relationships. Finally, at the parameter level, we propose Component Fully-interactive LoRA (CFLoRA), which enhances LoRA's expressiveness by enabling interactions between its components, allowing better capture of sequential information. Moreover, we present new perspectives to compare current LoRA-based LLM4Rec methods, i.e. from both a composite and a decomposed view. We theoretically demonstrate that the ways they employ LoRA for recommendation are degraded versions of our CFLoRA, with different constraints on atom component interactions. Extensive experiments on three public datasets demonstrate ReLLaX's superiority over existing baselines and its ability to mitigate lifelong sequential behavior incomprehension effectively.","sentences":["In this paper, we address the lifelong sequential behavior incomprehension problem in large language models (LLMs) for recommendation, where LLMs struggle to extract useful information from long user behavior sequences, even within their context limits.","To tackle this, we propose ReLLaX (Retrieval-enhanced Large Language models Plus), a framework offering optimization across data, prompt, and parameter levels.","At the data level, we introduce Semantic User Behavior Retrieval (SUBR) to reduce sequence heterogeneity, making it easier for LLMs to extract key information.","For prompt-level enhancement, we employ Soft Prompt Augmentation (SPA) to inject collaborative knowledge, aligning item representations with recommendation tasks and improving LLMs's exploration of item relationships.","Finally, at the parameter level, we propose Component Fully-interactive LoRA (CFLoRA), which enhances LoRA's expressiveness by enabling interactions between its components, allowing better capture of sequential information.","Moreover, we present new perspectives to compare current LoRA-based LLM4Rec methods, i.e. from both a composite and a decomposed view.","We theoretically demonstrate that the ways they employ LoRA for recommendation are degraded versions of our CFLoRA, with different constraints on atom component interactions.","Extensive experiments on three public datasets demonstrate ReLLaX's superiority over existing baselines and its ability to mitigate lifelong sequential behavior incomprehension effectively."],"url":"http://arxiv.org/abs/2501.13344v1"}
{"created":"2025-01-23 02:25:44","title":"AgentRec: Agent Recommendation Using Sentence Embeddings Aligned to Human Feedback","abstract":"Multi-agent systems must decide which agent is the most appropriate for a given task. We propose a novel architecture for recommending which LLM agent out of many should perform a task given a natural language prompt by extending the Sentence-BERT (SBERT) encoder model. On test data, we are able to achieve a top-1 accuracy of 92.2% with each classification taking less than 300 milliseconds. In contrast to traditional classification methods, our architecture is computationally cheap, adaptive to new classes, interpretable, and controllable with arbitrary metrics through reinforcement learning. By encoding natural language prompts into sentence embeddings, our model captures the semantic content relevant to recommending an agent. The distance between sentence embeddings that belong to the same agent is then minimized through fine-tuning and aligned to human values through reinforcement learning from human feedback. This allows the classification of natural language prompts based on their nearest neighbors by measuring the cosine similarity between embeddings. This work is made possible through the generation of a synthetic dataset for agent recommendation, which we have open-sourced to the public along with the code for AgentRec recommendation system at https://github.com/joshprk/agentrec.","sentences":["Multi-agent systems must decide which agent is the most appropriate for a given task.","We propose a novel architecture for recommending which LLM agent out of many should perform a task given a natural language prompt by extending the Sentence-BERT (SBERT) encoder model.","On test data, we are able to achieve a top-1 accuracy of 92.2% with each classification taking less than 300 milliseconds.","In contrast to traditional classification methods, our architecture is computationally cheap, adaptive to new classes, interpretable, and controllable with arbitrary metrics through reinforcement learning.","By encoding natural language prompts into sentence embeddings, our model captures the semantic content relevant to recommending an agent.","The distance between sentence embeddings that belong to the same agent is then minimized through fine-tuning and aligned to human values through reinforcement learning from human feedback.","This allows the classification of natural language prompts based on their nearest neighbors by measuring the cosine similarity between embeddings.","This work is made possible through the generation of a synthetic dataset for agent recommendation, which we have open-sourced to the public along with the code for AgentRec recommendation system at https://github.com/joshprk/agentrec."],"url":"http://arxiv.org/abs/2501.13333v1"}
{"created":"2025-01-23 02:20:08","title":"Qrazor: Reliable and effortless 4-bit llm quantization by significant data razoring","abstract":"Large-scale language models (LLMs) have demonstrated outstanding performance in language processing tasks, yet their deployment is often hindered by high memory demands and computational complexity. Although low-bit quantization techniques, such as 4-bit quantization, present a potential solution, they frequently lead to significant accuracy degradation or require substantial effort for such aggressive quantization approaches. To overcome these challenges, we introduce QRazor, a reliable and effortless quantization scheme designed to enable 4-bit quantization for weights, activations, and KV cache in transformer-based LLMs. The scheme involves two main stages: quantization and compression. During the quantization stage, weights, activations, and KV cache values are quantized with wider 8 or 16-bit integers as a basis to achieve nearly identical accuracy to the original full-precision LLM models, using the absolute max scaling. Subsequently, all data are compressed to 4-bit using our proposed significant data razoring (SDR) technique, which retains only the four most salient bits while discarding the others. Furthermore, we present an integer-based arithmetic unit dedicated to QRazor, enabling direct low-precision arithmetic operations without decompressing the SDR data. Despite the reduced quantization effort, QRazor achieves LLM accuracies better or comparable to state-of-the-art 4-bit methods. By also validating the hardware efficiency, our decompression-free arithmetic unit achieves 61.2% and 57.8% reduction in area and power consumption, respectively.","sentences":["Large-scale language models (LLMs) have demonstrated outstanding performance in language processing tasks, yet their deployment is often hindered by high memory demands and computational complexity.","Although low-bit quantization techniques, such as 4-bit quantization, present a potential solution, they frequently lead to significant accuracy degradation or require substantial effort for such aggressive quantization approaches.","To overcome these challenges, we introduce QRazor, a reliable and effortless quantization scheme designed to enable 4-bit quantization for weights, activations, and KV cache in transformer-based LLMs.","The scheme involves two main stages: quantization and compression.","During the quantization stage, weights, activations, and KV cache values are quantized with wider 8 or 16-bit integers as a basis to achieve nearly identical accuracy to the original full-precision LLM models, using the absolute max scaling.","Subsequently, all data are compressed to 4-bit using our proposed significant data razoring (SDR) technique, which retains only the four most salient bits while discarding the others.","Furthermore, we present an integer-based arithmetic unit dedicated to QRazor, enabling direct low-precision arithmetic operations without decompressing the SDR data.","Despite the reduced quantization effort, QRazor achieves LLM accuracies better or comparable to state-of-the-art 4-bit methods.","By also validating the hardware efficiency, our decompression-free arithmetic unit achieves 61.2% and 57.8% reduction in area and power consumption, respectively."],"url":"http://arxiv.org/abs/2501.13331v1"}
{"created":"2025-01-23 02:18:13","title":"Sparse identification of nonlinear dynamics and Koopman operators with Shallow Recurrent Decoder Networks","abstract":"Spatiotemporal modeling of real-world data poses a challenging problem due to inherent high dimensionality, measurement noise, and expensive data collection procedures. In this paper, we present Sparse Identification of Nonlinear Dynamics with SHallow REcurrent Decoder networks (SINDy-SHRED), a method to jointly solve the sensing and model identification problems with simple implementation, efficient computation, and robust performance. SINDy-SHRED uses Gated Recurrent Units (GRUs) to model the temporal sequence of sensor measurements along with a shallow decoder network to reconstruct the full spatiotemporal field from the latent state space using only a few available sensors. Our proposed algorithm introduces a SINDy-based regularization; beginning with an arbitrary latent state space, the dynamics of the latent space progressively converges to a SINDy-class functional, provided the projection remains within the set. In restricting SINDy to a linear model, the architecture produces a Koopman-SHRED model which enforces a linear latent space dynamics. We conduct a systematic experimental study including synthetic PDE data, real-world sensor measurements for sea surface temperature, and direct video data. With no explicit encoder, SINDy-SHRED and Koopman-SHRED enable efficient training with minimal hyperparameter tuning and laptop-level computing; further, it demonstrates robust generalization in a variety of applications with minimal to no hyperparameter adjustments. Finally, the interpretable SINDy and Koopman models of latent state dynamics enables accurate long-term video predictions, achieving state-of-the-art performance and outperforming all baseline methods considered, including Convolutional LSTM, PredRNN, ResNet, and SimVP.","sentences":["Spatiotemporal modeling of real-world data poses a challenging problem due to inherent high dimensionality, measurement noise, and expensive data collection procedures.","In this paper, we present Sparse Identification of Nonlinear Dynamics with SHallow REcurrent Decoder networks (SINDy-SHRED), a method to jointly solve the sensing and model identification problems with simple implementation, efficient computation, and robust performance.","SINDy-SHRED uses Gated Recurrent Units (GRUs) to model the temporal sequence of sensor measurements along with a shallow decoder network to reconstruct the full spatiotemporal field from the latent state space using only a few available sensors.","Our proposed algorithm introduces a SINDy-based regularization; beginning with an arbitrary latent state space, the dynamics of the latent space progressively converges to a SINDy-class functional, provided the projection remains within the set.","In restricting SINDy to a linear model, the architecture produces a Koopman-SHRED model which enforces a linear latent space dynamics.","We conduct a systematic experimental study including synthetic PDE data, real-world sensor measurements for sea surface temperature, and direct video data.","With no explicit encoder, SINDy-SHRED and Koopman-SHRED enable efficient training with minimal hyperparameter tuning and laptop-level computing; further, it demonstrates robust generalization in a variety of applications with minimal to no hyperparameter adjustments.","Finally, the interpretable SINDy and Koopman models of latent state dynamics enables accurate long-term video predictions, achieving state-of-the-art performance and outperforming all baseline methods considered, including Convolutional LSTM, PredRNN, ResNet, and SimVP."],"url":"http://arxiv.org/abs/2501.13329v1"}
{"created":"2025-01-23 02:07:45","title":"Investigation of the Privacy Concerns in AI Systems for Young Digital Citizens: A Comparative Stakeholder Analysis","abstract":"The integration of Artificial Intelligence (AI) systems into technologies used by young digital citizens raises significant privacy concerns. This study investigates these concerns through a comparative analysis of stakeholder perspectives. A total of 252 participants were surveyed, with the analysis focusing on 110 valid responses from parents/educators and 100 from AI professionals after data cleaning. Quantitative methods, including descriptive statistics and Partial Least Squares Structural Equation Modeling, examined five validated constructs: Data Ownership and Control, Parental Data Sharing, Perceived Risks and Benefits, Transparency and Trust, and Education and Awareness. Results showed Education and Awareness significantly influenced data ownership and risk assessment, while Data Ownership and Control strongly impacted Transparency and Trust. Transparency and Trust, along with Perceived Risks and Benefits, showed minimal influence on Parental Data Sharing, suggesting other factors may play a larger role. The study underscores the need for user-centric privacy controls, tailored transparency strategies, and targeted educational initiatives. Incorporating diverse stakeholder perspectives offers actionable insights into ethical AI design and governance, balancing innovation with robust privacy protections to foster trust in a digital age.","sentences":["The integration of Artificial Intelligence (AI) systems into technologies used by young digital citizens raises significant privacy concerns.","This study investigates these concerns through a comparative analysis of stakeholder perspectives.","A total of 252 participants were surveyed, with the analysis focusing on 110 valid responses from parents/educators and 100 from AI professionals after data cleaning.","Quantitative methods, including descriptive statistics and Partial Least Squares Structural Equation Modeling, examined five validated constructs: Data Ownership and Control, Parental Data Sharing, Perceived Risks and Benefits, Transparency and Trust, and Education and Awareness.","Results showed Education and Awareness significantly influenced data ownership and risk assessment, while Data Ownership and Control strongly impacted Transparency and Trust.","Transparency and Trust, along with Perceived Risks and Benefits, showed minimal influence on Parental Data Sharing, suggesting other factors may play a larger role.","The study underscores the need for user-centric privacy controls, tailored transparency strategies, and targeted educational initiatives.","Incorporating diverse stakeholder perspectives offers actionable insights into ethical AI design and governance, balancing innovation with robust privacy protections to foster trust in a digital age."],"url":"http://arxiv.org/abs/2501.13321v1"}
{"created":"2025-01-23 02:06:25","title":"Toward Ethical AI: A Qualitative Analysis of Stakeholder Perspectives","abstract":"As Artificial Intelligence (AI) systems become increasingly integrated into various aspects of daily life, concerns about privacy and ethical accountability are gaining prominence. This study explores stakeholder perspectives on privacy in AI systems, focusing on educators, parents, and AI professionals. Using qualitative analysis of survey responses from 227 participants, the research identifies key privacy risks, including data breaches, ethical misuse, and excessive data collection, alongside perceived benefits such as personalized services, enhanced efficiency, and educational advancements. Stakeholders emphasized the need for transparency, privacy-by-design, user empowerment, and ethical oversight to address privacy concerns effectively. The findings provide actionable insights into balancing the benefits of AI with robust privacy protections, catering to the diverse needs of stakeholders. Recommendations include implementing selective data use, fostering transparency, promoting user autonomy, and integrating ethical principles into AI development. This study contributes to the ongoing discourse on ethical AI, offering guidance for designing privacy-centric systems that align with societal values and build trust among users. By addressing privacy challenges, this research underscores the importance of developing AI technologies that are not only innovative but also ethically sound and responsive to the concerns of all stakeholders.","sentences":["As Artificial Intelligence (AI) systems become increasingly integrated into various aspects of daily life, concerns about privacy and ethical accountability are gaining prominence.","This study explores stakeholder perspectives on privacy in AI systems, focusing on educators, parents, and AI professionals.","Using qualitative analysis of survey responses from 227 participants, the research identifies key privacy risks, including data breaches, ethical misuse, and excessive data collection, alongside perceived benefits such as personalized services, enhanced efficiency, and educational advancements.","Stakeholders emphasized the need for transparency, privacy-by-design, user empowerment, and ethical oversight to address privacy concerns effectively.","The findings provide actionable insights into balancing the benefits of AI with robust privacy protections, catering to the diverse needs of stakeholders.","Recommendations include implementing selective data use, fostering transparency, promoting user autonomy, and integrating ethical principles into AI development.","This study contributes to the ongoing discourse on ethical AI, offering guidance for designing privacy-centric systems that align with societal values and build trust among users.","By addressing privacy challenges, this research underscores the importance of developing AI technologies that are not only innovative but also ethically sound and responsive to the concerns of all stakeholders."],"url":"http://arxiv.org/abs/2501.13320v1"}
{"created":"2025-01-23 02:02:38","title":"SplitLLM: Hierarchical Split Learning for Large Language Model over Wireless Network","abstract":"Fine-tuning a large language model (LLM) using the local data of edge users can enable personalized services and applications. For privacy protection, the prevalent solution adopts distributed learning for fine-tuning and integrates low-rank adaptation (LoRA) to reduce users' computational load. However, as the number of users increases, numerous users simultaneously communicate with the server, and multiple server-side models concurrently execute on the server, leading to significant communication congestion and memory pressure. In this paper, we propose a split learning (SL) scheme for fine-tuning LLM in wireless networks, which involves one cloud server, a small number of edge servers, and multiple users. Specifically, the pre-trained model and LoRA adapters are divided into three parts and deployed across the cloud, edge, and user sides. The training process follows the sequence of user, edge, and cloud, with forward and backward propagation achieved by transmitting activation and gradient. In each round, all edge servers and an equivalent number of users train in parallel, and only the LoRA adapters are updated. At the end of each round, all edge-side and user-side LoRA adapters are uploaded to the cloud for aggregation. Extensive simulation demonstrates that the proposed scheme can reduce peak memory usage up to 74% compared to the state-of-the-art benchmarks.","sentences":["Fine-tuning a large language model (LLM) using the local data of edge users can enable personalized services and applications.","For privacy protection, the prevalent solution adopts distributed learning for fine-tuning and integrates low-rank adaptation (LoRA) to reduce users' computational load.","However, as the number of users increases, numerous users simultaneously communicate with the server, and multiple server-side models concurrently execute on the server, leading to significant communication congestion and memory pressure.","In this paper, we propose a split learning (SL) scheme for fine-tuning LLM in wireless networks, which involves one cloud server, a small number of edge servers, and multiple users.","Specifically, the pre-trained model and LoRA adapters are divided into three parts and deployed across the cloud, edge, and user sides.","The training process follows the sequence of user, edge, and cloud, with forward and backward propagation achieved by transmitting activation and gradient.","In each round, all edge servers and an equivalent number of users train in parallel, and only the LoRA adapters are updated.","At the end of each round, all edge-side and user-side LoRA adapters are uploaded to the cloud for aggregation.","Extensive simulation demonstrates that the proposed scheme can reduce peak memory usage up to 74% compared to the state-of-the-art benchmarks."],"url":"http://arxiv.org/abs/2501.13318v1"}
{"created":"2025-01-23 01:43:31","title":"Tensor-Var: Variational Data Assimilation in Tensor Product Feature Space","abstract":"Variational data assimilation estimates the dynamical system states by minimizing a cost function that fits the numerical models with observational data. The widely used method, four-dimensional variational assimilation (4D-Var), has two primary challenges: (1) computationally demanding for complex nonlinear systems and (2) relying on state-observation mappings, which are often not perfectly known. Deep learning (DL) has been used as a more expressive class of efficient model approximators to address these challenges. However, integrating such models into 4D-Var remains challenging due to their inherent nonlinearities and the lack of theoretical guarantees for consistency in assimilation results. In this paper, we propose \\textit{Tensor-Var} to address these challenges using kernel Conditional Mean Embedding (CME). Tensor-Var improves optimization efficiency by characterizing system dynamics and state-observation mappings as linear operators, leading to a convex cost function in the feature space. Furthermore, our method provides a new perspective to incorporate CME into 4D-Var, offering theoretical guarantees of consistent assimilation results between the original and feature spaces. To improve scalability, we propose a method to learn deep features (DFs) using neural networks within the Tensor-Var framework. Experiments on chaotic systems and global weather prediction with real-time observations show that Tensor-Var outperforms conventional and DL hybrid 4D-Var baselines in accuracy while achieving efficiency comparable to the static 3D-Var method.","sentences":["Variational data assimilation estimates the dynamical system states by minimizing a cost function that fits the numerical models with observational data.","The widely used method, four-dimensional variational assimilation (4D-Var), has two primary challenges: (1) computationally demanding for complex nonlinear systems and (2) relying on state-observation mappings, which are often not perfectly known.","Deep learning (DL) has been used as a more expressive class of efficient model approximators to address these challenges.","However, integrating such models into 4D-Var remains challenging due to their inherent nonlinearities and the lack of theoretical guarantees for consistency in assimilation results.","In this paper, we propose \\textit{Tensor-Var} to address these challenges using kernel Conditional Mean Embedding (CME).","Tensor-Var improves optimization efficiency by characterizing system dynamics and state-observation mappings as linear operators, leading to a convex cost function in the feature space.","Furthermore, our method provides a new perspective to incorporate CME into 4D-Var, offering theoretical guarantees of consistent assimilation results between the original and feature spaces.","To improve scalability, we propose a method to learn deep features (DFs) using neural networks within the Tensor-Var framework.","Experiments on chaotic systems and global weather prediction with real-time observations show that Tensor-Var outperforms conventional and DL hybrid 4D-Var baselines in accuracy while achieving efficiency comparable to the static 3D-Var method."],"url":"http://arxiv.org/abs/2501.13312v1"}
{"created":"2025-01-23 01:28:05","title":"From Cross-Modal to Mixed-Modal Visible-Infrared Re-Identification","abstract":"Visible-infrared person re-identification (VI-ReID) aims to match individuals across different camera modalities, a critical task in modern surveillance systems. While current VI-ReID methods focus on cross-modality matching, real-world applications often involve mixed galleries containing both V and I images, where state-of-the-art methods show significant performance limitations due to large domain shifts and low discrimination across mixed modalities. This is because gallery images from the same modality may have lower domain gaps but correspond to different identities. This paper introduces a novel mixed-modal ReID setting, where galleries contain data from both modalities. To address the domain shift among inter-modal and low discrimination capacity in intra-modal matching, we propose the Mixed Modality-Erased and -Related (MixER) method. The MixER learning approach disentangles modality-specific and modality-shared identity information through orthogonal decomposition, modality-confusion, and ID-modality-related objectives. MixER enhances feature robustness across modalities, improving cross-modal and mixed-modal settings performance. Our extensive experiments on the SYSU-MM01, RegDB and LLMC datasets indicate that our approach can provide state-of-the-art results using a single backbone, and showcase the flexibility of our approach in mixed gallery applications.","sentences":["Visible-infrared person re-identification (VI-ReID) aims to match individuals across different camera modalities, a critical task in modern surveillance systems.","While current VI-ReID methods focus on cross-modality matching, real-world applications often involve mixed galleries containing both V and I images, where state-of-the-art methods show significant performance limitations due to large domain shifts and low discrimination across mixed modalities.","This is because gallery images from the same modality may have lower domain gaps but correspond to different identities.","This paper introduces a novel mixed-modal ReID setting, where galleries contain data from both modalities.","To address the domain shift among inter-modal and low discrimination capacity in intra-modal matching, we propose the Mixed Modality-Erased and -Related (MixER) method.","The MixER learning approach disentangles modality-specific and modality-shared identity information through orthogonal decomposition, modality-confusion, and ID-modality-related objectives.","MixER enhances feature robustness across modalities, improving cross-modal and mixed-modal settings performance.","Our extensive experiments on the SYSU-MM01, RegDB and LLMC datasets indicate that our approach can provide state-of-the-art results using a single backbone, and showcase the flexibility of our approach in mixed gallery applications."],"url":"http://arxiv.org/abs/2501.13307v1"}
{"created":"2025-01-23 01:27:46","title":"OSUM: Advancing Open Speech Understanding Models with Limited Resources in Academia","abstract":"Large Language Models (LLMs) have made significant progress in various downstream tasks, inspiring the development of Speech Understanding Language Models (SULMs) to enable comprehensive speech-based interactions. However, most advanced SULMs are developed by the industry, leveraging large-scale datasets and computational resources that are not readily available to the academic community. Moreover, the lack of transparency in training details creates additional barriers to further innovation. In this study, we present OSUM, an Open Speech Understanding Model designed to explore the potential of training SLUMs under constrained academic resources. The OSUM model combines a Whisper encoder with a Qwen2 LLM and supports a wide range of speech tasks, including speech recognition (ASR), speech recognition with timestamps (SRWT), vocal event detection (VED), speech emotion recognition (SER), speaking style recognition (SSR), speaker gender classification (SGC), speaker age prediction (SAP), and speech-to-text chat (STTC). By employing an ASR+X training strategy, OSUM achieves efficient and stable multi-task training by simultaneously optimizing ASR alongside target tasks. Beyond delivering strong performance, OSUM emphasizes transparency by providing openly available data preparation and training methodologies, offering valuable insights and practical guidance for the academic community. By doing so, we aim to accelerate research and innovation in advanced SULM technologies.","sentences":["Large Language Models (LLMs) have made significant progress in various downstream tasks, inspiring the development of Speech Understanding Language Models (SULMs) to enable comprehensive speech-based interactions.","However, most advanced SULMs are developed by the industry, leveraging large-scale datasets and computational resources that are not readily available to the academic community.","Moreover, the lack of transparency in training details creates additional barriers to further innovation.","In this study, we present OSUM, an Open Speech Understanding Model designed to explore the potential of training SLUMs under constrained academic resources.","The OSUM model combines a Whisper encoder with a Qwen2 LLM and supports a wide range of speech tasks, including speech recognition (ASR), speech recognition with timestamps (SRWT), vocal event detection (VED), speech emotion recognition (SER), speaking style recognition (SSR), speaker gender classification (SGC), speaker age prediction (SAP), and speech-to-text chat (STTC).","By employing an ASR+X training strategy, OSUM achieves efficient and stable multi-task training by simultaneously optimizing ASR alongside target tasks.","Beyond delivering strong performance, OSUM emphasizes transparency by providing openly available data preparation and training methodologies, offering valuable insights and practical guidance for the academic community.","By doing so, we aim to accelerate research and innovation in advanced SULM technologies."],"url":"http://arxiv.org/abs/2501.13306v1"}
{"created":"2025-01-23 00:50:33","title":"RAMQA: A Unified Framework for Retrieval-Augmented Multi-Modal Question Answering","abstract":"Multi-modal retrieval-augmented Question Answering (MRAQA), integrating text and images, has gained significant attention in information retrieval (IR) and natural language processing (NLP). Traditional ranking methods rely on small encoder-based language models, which are incompatible with modern decoder-based generative large language models (LLMs) that have advanced various NLP tasks. To bridge this gap, we propose RAMQA, a unified framework combining learning-to-rank methods with generative permutation-enhanced ranking techniques. We first train a pointwise multi-modal ranker using LLaVA as the backbone. Then, we apply instruction tuning to train a LLaMA model for re-ranking the top-k documents using an innovative autoregressive multi-task learning approach. Our generative ranking model generates re-ranked document IDs and specific answers from document candidates in various permutations. Experiments on two MRAQA benchmarks, WebQA and MultiModalQA, show significant improvements over strong baselines, highlighting the effectiveness of our approach. Code and data are available at: https://github.com/TonyBY/RAMQA","sentences":["Multi-modal retrieval-augmented Question Answering (MRAQA), integrating text and images, has gained significant attention in information retrieval (IR) and natural language processing (NLP).","Traditional ranking methods rely on small encoder-based language models, which are incompatible with modern decoder-based generative large language models (LLMs) that have advanced various NLP tasks.","To bridge this gap, we propose RAMQA, a unified framework combining learning-to-rank methods with generative permutation-enhanced ranking techniques.","We first train a pointwise multi-modal ranker using LLaVA as the backbone.","Then, we apply instruction tuning to train a LLaMA model for re-ranking the top-k documents using an innovative autoregressive multi-task learning approach.","Our generative ranking model generates re-ranked document IDs and specific answers from document candidates in various permutations.","Experiments on two MRAQA benchmarks, WebQA and MultiModalQA, show significant improvements over strong baselines, highlighting the effectiveness of our approach.","Code and data are available at: https://github.com/TonyBY/RAMQA"],"url":"http://arxiv.org/abs/2501.13297v1"}
{"created":"2025-01-23 00:26:09","title":"Automatic Fact-Checking with Frame-Semantics","abstract":"We propose a novel paradigm for automatic fact-checking that leverages frame semantics to enhance the structured understanding of claims, addressing the challenges posed by misinformation in today's information ecosystem. To support this approach, we introduce a pilot dataset of real-world claims extracted from PolitiFact, specifically annotated for large-scale structured data. This dataset underpins two case studies: the first investigates voting-related claims using the Vote semantic frame, while the second explores various semantic frames and data sources from the Organisation for Economic Co-operation and Development (OECD). Our findings demonstrate the effectiveness of frame semantics in improving evidence retrieval, indicating a meaningful advancement in automatic fact-checking capabilities. Finally, we conducted a survey of frames evoked in fact-checked claims, identifying high-impact frames to guide future research.","sentences":["We propose a novel paradigm for automatic fact-checking that leverages frame semantics to enhance the structured understanding of claims, addressing the challenges posed by misinformation in today's information ecosystem.","To support this approach, we introduce a pilot dataset of real-world claims extracted from PolitiFact, specifically annotated for large-scale structured data.","This dataset underpins two case studies: the first investigates voting-related claims using the Vote semantic frame, while the second explores various semantic frames and data sources from the Organisation for Economic Co-operation and Development (OECD).","Our findings demonstrate the effectiveness of frame semantics in improving evidence retrieval, indicating a meaningful advancement in automatic fact-checking capabilities.","Finally, we conducted a survey of frames evoked in fact-checked claims, identifying high-impact frames to guide future research."],"url":"http://arxiv.org/abs/2501.13288v1"}
{"created":"2025-01-23 00:11:47","title":"Time-Dependent Network Topology Optimization for LEO Satellite Constellations","abstract":"Today's Low Earth Orbit (LEO) satellite networks, exemplified by SpaceX's Starlink, play a crucial role in delivering global internet access to millions of users. However, managing the dynamic and expansive nature of these networks poses significant challenges in designing optimal satellite topologies over time. In this paper, we introduce the \\underline{D}ynamic Time-Expanded Graph (DTEG)-based \\underline{O}ptimal \\underline{T}opology \\underline{D}esign (DoTD) algorithm to tackle these challenges effectively. We first formulate a novel space network topology optimization problem encompassing a multi-objective function -- maximize network capacity, minimize latency, and mitigate link churn -- under key inter-satellite link constraints. Our proposed approach addresses this optimization problem by transforming the objective functions and constraints into a time-dependent scoring function. This empowers each LEO satellite to assess potential connections based on their dynamic performance scores, ensuring robust network performance over time without scalability issues. Additionally, we provide proof of the score function's boundary to prove that it will not approach infinity, thus allowing each satellite to consistently evaluate others over time. For evaluation purposes, we utilize a realistic Mininet-based LEO satellite emulation tool that leverages Starlink's Two-Line Element (TLE) data. Comparative evaluation against two baseline methods -- Greedy and $+$Grid, demonstrates the superior performance of our algorithm in optimizing network efficiency and resilience.","sentences":["Today's Low Earth Orbit (LEO) satellite networks, exemplified by SpaceX's Starlink, play a crucial role in delivering global internet access to millions of users.","However, managing the dynamic and expansive nature of these networks poses significant challenges in designing optimal satellite topologies over time.","In this paper, we introduce the \\underline{D}ynamic Time-Expanded Graph (DTEG)-based \\underline{O}ptimal \\underline{T}opology \\underline{D}esign (DoTD) algorithm to tackle these challenges effectively.","We first formulate a novel space network topology optimization problem encompassing a multi-objective function -- maximize network capacity, minimize latency, and mitigate link churn -- under key inter-satellite link constraints.","Our proposed approach addresses this optimization problem by transforming the objective functions and constraints into a time-dependent scoring function.","This empowers each LEO satellite to assess potential connections based on their dynamic performance scores, ensuring robust network performance over time without scalability issues.","Additionally, we provide proof of the score function's boundary to prove that it will not approach infinity, thus allowing each satellite to consistently evaluate others over time.","For evaluation purposes, we utilize a realistic Mininet-based LEO satellite emulation tool that leverages Starlink's Two-Line Element (TLE) data.","Comparative evaluation against two baseline methods -- Greedy and $+$Grid, demonstrates the superior performance of our algorithm in optimizing network efficiency and resilience."],"url":"http://arxiv.org/abs/2501.13280v1"}
{"created":"2025-01-22 23:56:37","title":"MEDFORM: A Foundation Model for Contrastive Learning of CT Imaging and Clinical Numeric Data in Multi-Cancer Analysis","abstract":"Computed tomography (CT) and clinical numeric data are essential modalities for cancer evaluation, but building large-scale multimodal training datasets for developing medical foundation models remains challenging due to the structural complexity of multi-slice CT data and high cost of expert annotation. In this study, we propose MEDFORM, a multimodal pre-training strategy that guides CT image representation learning using complementary information from clinical data for medical foundation model development. MEDFORM efficiently processes CT slice through multiple instance learning (MIL) and adopts a dual pre-training strategy: first pretraining the CT slice feature extractor using SimCLR-based self-supervised learning, then aligning CT and clinical modalities through cross-modal contrastive learning. Our model was pre-trained on three different cancer types: lung cancer (141,171 slices), breast cancer (8,100 slices), colorectal cancer (10,393 slices). The experimental results demonstrated that this dual pre-training strategy improves cancer classification performance and maintains robust performance in few-shot learning scenarios. Code available at https://github.com/DigitalHealthcareLab/25MultiModalFoundationModel.git","sentences":["Computed tomography (CT) and clinical numeric data are essential modalities for cancer evaluation, but building large-scale multimodal training datasets for developing medical foundation models remains challenging due to the structural complexity of multi-slice CT data and high cost of expert annotation.","In this study, we propose MEDFORM, a multimodal pre-training strategy that guides CT image representation learning using complementary information from clinical data for medical foundation model development.","MEDFORM efficiently processes CT slice through multiple instance learning (MIL) and adopts a dual pre-training strategy: first pretraining the CT slice feature extractor using SimCLR-based self-supervised learning, then aligning CT and clinical modalities through cross-modal contrastive learning.","Our model was pre-trained on three different cancer types: lung cancer (141,171 slices), breast cancer (8,100 slices), colorectal cancer (10,393 slices).","The experimental results demonstrated that this dual pre-training strategy improves cancer classification performance and maintains robust performance in few-shot learning scenarios.","Code available at https://github.com/DigitalHealthcareLab/25MultiModalFoundationModel.git"],"url":"http://arxiv.org/abs/2501.13277v1"}
{"created":"2025-01-22 23:40:21","title":"Extraction of Secrets from 40nm CMOS Gate Dielectric Breakdown Antifuses by FIB Passive Voltage Contrast","abstract":"CMOS one-time-programmable (OTP) memories based on antifuses are widely used for storing small amounts of data (such as serial numbers, keys, and factory trimming) in integrated circuits due to their low cost, requiring no additional mask steps to fabricate. Device manufacturers and IP vendors have claimed for years that antifuses are a ``high security\" memory which is significantly more difficult for an attacker to extract data from than other types of memory, such as Flash or mask ROM - however, as our results show, this is untrue. In this paper, we demonstrate that data bits stored in a widely used antifuse block can be extracted by a semiconductor failure analysis technique known as passive voltage contrast (PVC) using a focused ion beam (FIB). The simple form of the attack demonstrated here recovers the bitwise OR of two physically adjacent memory rows sharing common metal 1 contacts, however we have identified several potential mechanisms by which it may be possible to read the even and odd rows separately. We demonstrate the attack on a commodity microcontroller made on the 40nm node and show how it can be used to extract significant quantities of sensitive data, such as keys for firmware encryption, in time scales which are very practical for real world exploitation (1 day of sample prep plus a few hours of FIB time) with only a single target device required after initial reconnaissance has been completed on blank devices.","sentences":["CMOS one-time-programmable (OTP) memories based on antifuses are widely used for storing small amounts of data (such as serial numbers, keys, and factory trimming) in integrated circuits due to their low cost, requiring no additional mask steps to fabricate.","Device manufacturers and IP vendors have claimed for years that antifuses are a ``high security\" memory which is significantly more difficult for an attacker to extract data from than other types of memory, such as Flash or mask ROM - however, as our results show, this is untrue.","In this paper, we demonstrate that data bits stored in a widely used antifuse block can be extracted by a semiconductor failure analysis technique known as passive voltage contrast (PVC) using a focused ion beam (FIB).","The simple form of the attack demonstrated here recovers the bitwise OR of two physically adjacent memory rows sharing common metal 1 contacts, however we have identified several potential mechanisms by which it may be possible to read the even and odd rows separately.","We demonstrate the attack on a commodity microcontroller made on the 40nm node and show how it can be used to extract significant quantities of sensitive data, such as keys for firmware encryption, in time scales which are very practical for real world exploitation (1 day of sample prep plus a few hours of FIB time) with only a single target device required after initial reconnaissance has been completed on blank devices."],"url":"http://arxiv.org/abs/2501.13276v1"}
{"created":"2025-01-22 23:32:29","title":"T-Graphormer: Using Transformers for Spatiotemporal Forecasting","abstract":"Time series data is ubiquitous and appears in all fields of study. In multivariate time series, observations are interconnected both temporally and across components. For instance, in traffic flow analysis, traffic speeds at different intersections exhibit complex spatiotemporal correlations. Modelling this dual structure poses significant challenges. Most existing forecasting methods tackle these challenges by separately learning spatial and temporal dependencies. In this work, we introduce T-Graphormer, a Transformer-based approach designed to model spatiotemporal correlations directly. Extending the Graphormer architecture to incorporate temporal dynamics, our method updates each node representation by selectively attending to all other nodes within a graph sequence. This design enables the model to capture rich spatiotemporal patterns with minimal reliance on predefined spacetime inductive biases. We validate the effectiveness of T-Graphormer on real-world traffic prediction benchmark datasets, achieving up to 10% reductions in both root mean squared error (RMSE) and mean absolute percentage error (MAPE) compared to state-of-the-art methods.","sentences":["Time series data is ubiquitous and appears in all fields of study.","In multivariate time series, observations are interconnected both temporally and across components.","For instance, in traffic flow analysis, traffic speeds at different intersections exhibit complex spatiotemporal correlations.","Modelling this dual structure poses significant challenges.","Most existing forecasting methods tackle these challenges by separately learning spatial and temporal dependencies.","In this work, we introduce T-Graphormer, a Transformer-based approach designed to model spatiotemporal correlations directly.","Extending the Graphormer architecture to incorporate temporal dynamics, our method updates each node representation by selectively attending to all other nodes within a graph sequence.","This design enables the model to capture rich spatiotemporal patterns with minimal reliance on predefined spacetime inductive biases.","We validate the effectiveness of T-Graphormer on real-world traffic prediction benchmark datasets, achieving up to 10% reductions in both root mean squared error (RMSE) and mean absolute percentage error (MAPE) compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2501.13274v1"}
{"created":"2025-01-22 23:32:19","title":"Enhancing Robust Fairness via Confusional Spectral Regularization","abstract":"Recent research has highlighted a critical issue known as ``robust fairness\", where robust accuracy varies significantly across different classes, undermining the reliability of deep neural networks (DNNs). A common approach to address this has been to dynamically reweight classes during training, giving more weight to those with lower empirical robust performance. However, we find there is a divergence of class-wise robust performance between training set and testing set, which limits the effectiveness of these explicit reweighting methods, indicating the need for a principled alternative. In this work, we derive a robust generalization bound for the worst-class robust error within the PAC-Bayesian framework, accounting for unknown data distributions. Our analysis shows that the worst-class robust error is influenced by two main factors: the spectral norm of the empirical robust confusion matrix and the information embedded in the model and training set. While the latter has been extensively studied, we propose a novel regularization technique targeting the spectral norm of the robust confusion matrix to improve worst-class robust accuracy and enhance robust fairness. We validate our approach through comprehensive experiments on various datasets and models, demonstrating its effectiveness in enhancing robust fairness.","sentences":["Recent research has highlighted a critical issue known as ``robust fairness\", where robust accuracy varies significantly across different classes, undermining the reliability of deep neural networks (DNNs).","A common approach to address this has been to dynamically reweight classes during training, giving more weight to those with lower empirical robust performance.","However, we find there is a divergence of class-wise robust performance between training set and testing set, which limits the effectiveness of these explicit reweighting methods, indicating the need for a principled alternative.","In this work, we derive a robust generalization bound for the worst-class robust error within the PAC-Bayesian framework, accounting for unknown data distributions.","Our analysis shows that the worst-class robust error is influenced by two main factors: the spectral norm of the empirical robust confusion matrix and the information embedded in the model and training set.","While the latter has been extensively studied, we propose a novel regularization technique targeting the spectral norm of the robust confusion matrix to improve worst-class robust accuracy and enhance robust fairness.","We validate our approach through comprehensive experiments on various datasets and models, demonstrating its effectiveness in enhancing robust fairness."],"url":"http://arxiv.org/abs/2501.13273v1"}
{"created":"2025-01-22 23:28:03","title":"Hybrid Two-Stage Reconstruction of Multiscale Subsurface Flow with Physics-informed Residual Connected Neural Operator","abstract":"The novel neural networks show great potential in solving partial differential equations. For single-phase flow problems in subsurface porous media with high-contrast coefficients, the key is to develop neural operators with accurate reconstruction capability and strict adherence to physical laws. In this study, we proposed a hybrid two-stage framework that uses multiscale basis functions and physics-guided deep learning to solve the Darcy flow problem in high-contrast fractured porous media. In the first stage, a data-driven model is used to reconstruct the multiscale basis function based on the permeability field to achieve effective dimensionality reduction while preserving the necessary multiscale features. In the second stage, the physics-informed neural network, together with Transformer-based global information extractor is used to reconstruct the pressure field by integrating the physical constraints derived from the Darcy equation, ensuring consistency with the physical laws of the real world. The model was evaluated on datasets with different combinations of permeability and basis functions and performed well in terms of reconstruction accuracy. Specifically, the framework achieves R2 values above 0.9 in terms of basis function fitting and pressure reconstruction, and the residual indicator is on the order of $1\\times 10^{-4}$. These results validate the ability of the proposed framework to achieve accurate reconstruction while maintaining physical consistency.","sentences":["The novel neural networks show great potential in solving partial differential equations.","For single-phase flow problems in subsurface porous media with high-contrast coefficients, the key is to develop neural operators with accurate reconstruction capability and strict adherence to physical laws.","In this study, we proposed a hybrid two-stage framework that uses multiscale basis functions and physics-guided deep learning to solve the Darcy flow problem in high-contrast fractured porous media.","In the first stage, a data-driven model is used to reconstruct the multiscale basis function based on the permeability field to achieve effective dimensionality reduction while preserving the necessary multiscale features.","In the second stage, the physics-informed neural network, together with Transformer-based global information extractor is used to reconstruct the pressure field by integrating the physical constraints derived from the Darcy equation, ensuring consistency with the physical laws of the real world.","The model was evaluated on datasets with different combinations of permeability and basis functions and performed well in terms of reconstruction accuracy.","Specifically, the framework achieves R2 values above 0.9 in terms of basis function fitting and pressure reconstruction, and the residual indicator is on the order of $1\\times 10^{-4}$.","These results validate the ability of the proposed framework to achieve accurate reconstruction while maintaining physical consistency."],"url":"http://arxiv.org/abs/2501.13271v1"}
{"created":"2025-01-22 22:59:19","title":"RAG-Reward: Optimizing RAG with Reward Modeling and RLHF","abstract":"Retrieval-augmented generation (RAG) enhances Large Language Models (LLMs) with relevant and up-to-date knowledge, improving their ability to answer knowledge-intensive questions. It has been shown to enhance both generation quality and trustworthiness. While numerous works have focused on improving retrieval, generation, and evaluation, the role of reward models in reinforcement learning for optimizing RAG and establishing automated benchmarking pipelines remains underexplored. In this paper, we introduce \\textbf{RAG-Reward}, a dataset designed to enable \\textit{hallucination-free, comprehensive, reliable, and efficient RAG}. We define four key metrics for assessing generation quality and develop an automated annotation pipeline that leverages multiple LLMs to generate outputs across diverse RAG scenarios. GPT-4o is used to evaluate and construct preference data. Using \\textbf{RAG-Reward}, we train reward models and apply reinforcement learning with human feedback (RLHF) to improve LLMs' effectiveness in RAG. Experimental results show that our reward model achieves state-of-the-art performance on a held-out test set, demonstrating both the effectiveness of our approach and the quality of our dataset. Furthermore, the improved generation quality of the trained policy model highlights the feasibility of using RLHF to enhance RAG pipelines.","sentences":["Retrieval-augmented generation (RAG) enhances Large Language Models (LLMs) with relevant and up-to-date knowledge, improving their ability to answer knowledge-intensive questions.","It has been shown to enhance both generation quality and trustworthiness.","While numerous works have focused on improving retrieval, generation, and evaluation, the role of reward models in reinforcement learning for optimizing RAG and establishing automated benchmarking pipelines remains underexplored.","In this paper, we introduce \\textbf{RAG-Reward}, a dataset designed to enable \\textit{hallucination-free, comprehensive, reliable, and efficient RAG}.","We define four key metrics for assessing generation quality and develop an automated annotation pipeline that leverages multiple LLMs to generate outputs across diverse RAG scenarios.","GPT-4o is used to evaluate and construct preference data.","Using \\textbf{RAG-Reward}, we train reward models and apply reinforcement learning with human feedback (RLHF) to improve LLMs' effectiveness in RAG.","Experimental results show that our reward model achieves state-of-the-art performance on a held-out test set, demonstrating both the effectiveness of our approach and the quality of our dataset.","Furthermore, the improved generation quality of the trained policy model highlights the feasibility of using RLHF to enhance RAG pipelines."],"url":"http://arxiv.org/abs/2501.13264v1"}
{"created":"2025-01-22 22:49:27","title":"Exploring GPT's Ability as a Judge in Music Understanding","abstract":"Recent progress in text-based Large Language Models (LLMs) and their extended ability to process multi-modal sensory data have led us to explore their applicability in addressing music information retrieval (MIR) challenges. In this paper, we use a systematic prompt engineering approach for LLMs to solve MIR problems. We convert the music data to symbolic inputs and evaluate LLMs' ability in detecting annotation errors in three key MIR tasks: beat tracking, chord extraction, and key estimation. A concept augmentation method is proposed to evaluate LLMs' music reasoning consistency with the provided music concepts in the prompts. Our experiments tested the MIR capabilities of Generative Pre-trained Transformers (GPT). Results show that GPT has an error detection accuracy of 65.20%, 64.80%, and 59.72% in beat tracking, chord extraction, and key estimation tasks, respectively, all exceeding the random baseline. Moreover, we observe a positive correlation between GPT's error finding accuracy and the amount of concept information provided. The current findings based on symbolic music input provide a solid ground for future LLM-based MIR research.","sentences":["Recent progress in text-based Large Language Models (LLMs) and their extended ability to process multi-modal sensory data have led us to explore their applicability in addressing music information retrieval (MIR) challenges.","In this paper, we use a systematic prompt engineering approach for LLMs to solve MIR problems.","We convert the music data to symbolic inputs and evaluate LLMs' ability in detecting annotation errors in three key MIR tasks: beat tracking, chord extraction, and key estimation.","A concept augmentation method is proposed to evaluate LLMs' music reasoning consistency with the provided music concepts in the prompts.","Our experiments tested the MIR capabilities of Generative Pre-trained Transformers (GPT).","Results show that GPT has an error detection accuracy of 65.20%, 64.80%, and 59.72% in beat tracking, chord extraction, and key estimation tasks, respectively, all exceeding the random baseline.","Moreover, we observe a positive correlation between GPT's error finding accuracy and the amount of concept information provided.","The current findings based on symbolic music input provide a solid ground for future LLM-based MIR research."],"url":"http://arxiv.org/abs/2501.13261v1"}
{"created":"2025-01-22 22:35:58","title":"From Following to Understanding: Investigating the Role of Reflective Prompts in AR-Guided Tasks to Promote Task Understanding","abstract":"Augmented Reality (AR) is a promising medium for guiding users through tasks, yet its impact on fostering deeper task understanding remains underexplored. This paper investigates the impact of reflective prompts -- strategic questions that encourage users to challenge assumptions, connect actions to outcomes, and consider hypothetical scenarios -- on task comprehension and performance. We conducted a two-phase study: a formative survey and co-design sessions (N=9) to develop reflective prompts, followed by a within-subject evaluation (N=16) comparing AR instructions with and without these prompts in coffee-making and circuit assembly tasks. Our results show that reflective prompts significantly improved objective task understanding and resulted in more proactive information acquisition behaviors during task completion. These findings highlight the potential of incorporating reflective elements into AR instructions to foster deeper engagement and learning. Based on data from both studies, we synthesized design guidelines for integrating reflective elements into AR systems to enhance user understanding without compromising task performance.","sentences":["Augmented Reality (AR) is a promising medium for guiding users through tasks, yet its impact on fostering deeper task understanding remains underexplored.","This paper investigates the impact of reflective prompts -- strategic questions that encourage users to challenge assumptions, connect actions to outcomes, and consider hypothetical scenarios -- on task comprehension and performance.","We conducted a two-phase study: a formative survey and co-design sessions (N=9) to develop reflective prompts, followed by a within-subject evaluation (N=16) comparing AR instructions with and without these prompts in coffee-making and circuit assembly tasks.","Our results show that reflective prompts significantly improved objective task understanding and resulted in more proactive information acquisition behaviors during task completion.","These findings highlight the potential of incorporating reflective elements into AR instructions to foster deeper engagement and learning.","Based on data from both studies, we synthesized design guidelines for integrating reflective elements into AR systems to enhance user understanding without compromising task performance."],"url":"http://arxiv.org/abs/2501.13258v1"}
{"created":"2025-01-22 22:23:19","title":"Stochastic Deep Learning Surrogate Models for Uncertainty Propagation in Microstructure-Properties of Ceramic Aerogels","abstract":"Deep learning surrogate models have become pivotal in enabling model-driven materials discovery to achieve exceptional properties. However, ensuring the accuracy and reliability of predictions from these models, trained on limited and sparse material datasets remains a significant challenge. This study introduces an integrated deep learning framework for predicting the synthesis, microstructure, and mechanical properties of ceramic aerogels, leveraging physics-based models such as Lattice Boltzmann simulations for microstructure formation and stochastic finite element methods for mechanical property calculations. To address the computational demands of repeated physics-based simulations required for experimental calibration and material design, a linked surrogate model is developed, leveraging Convolutional Neural Networks (CNNs) for stochastic microstructure generation and microstructure-to-mechanical property mapping. To overcome challenges associated with limited training datasets from expensive physical modeling, CNN training is formulated within a Bayesian inference framework, enabling robust uncertainty quantification in predictions. Numerical results highlight the strengths and limitations of the linked surrogate framework, demonstrating its effectiveness in predicting properties of aerogels with pore sizes and morphologies similar to the training data (in-distribution) and its ability to interpolate to new microstructural features between training data (out-of-distribution).","sentences":["Deep learning surrogate models have become pivotal in enabling model-driven materials discovery to achieve exceptional properties.","However, ensuring the accuracy and reliability of predictions from these models, trained on limited and sparse material datasets remains a significant challenge.","This study introduces an integrated deep learning framework for predicting the synthesis, microstructure, and mechanical properties of ceramic aerogels, leveraging physics-based models such as Lattice Boltzmann simulations for microstructure formation and stochastic finite element methods for mechanical property calculations.","To address the computational demands of repeated physics-based simulations required for experimental calibration and material design, a linked surrogate model is developed, leveraging Convolutional Neural Networks (CNNs) for stochastic microstructure generation and microstructure-to-mechanical property mapping.","To overcome challenges associated with limited training datasets from expensive physical modeling, CNN training is formulated within a Bayesian inference framework, enabling robust uncertainty quantification in predictions.","Numerical results highlight the strengths and limitations of the linked surrogate framework, demonstrating its effectiveness in predicting properties of aerogels with pore sizes and morphologies similar to the training data (in-distribution) and its ability to interpolate to new microstructural features between training data (out-of-distribution)."],"url":"http://arxiv.org/abs/2501.13255v1"}
{"created":"2025-01-22 21:37:40","title":"On the development of open geographical data infrastructures in Latin America: progress and challenges","abstract":"Open data initiatives and infrastructures play an essential role in favoring better data access, participation, and transparency in government operations and decision-making. Open Geographical Data Infrastructures (OGDIs) allow citizens to access and scrutinize government and public data, thereby enhancing accountability and evidence-based decision-making. This encourages citizen engagement and participation in public affairs and offers researchers, non-governmental organizations, civil society, and business sectors novel opportunities to analyze and disseminate large amounts of geographical data and to address social, urban, and environmental challenges. In Latin America, while recent open government agendas have shown an inclination towards transparency, citizen participation, and collaboration, only a limited number of OGDIs allow unrestricted use and re-use of their data. Given the region's cultural, social, and economic disparities, there is a contrasting digital divide that significantly impacts how OGDIs are being developed. Therefore, this paper analyses recent progress in developing OGDIs in Latin America, technological gaps, and open geographical data initiatives. The main results denote an early development of OGDIs in the region. Nevertheless, this opens the door for the timely involvement of citizens and non-government sectors to share needs, experiences, knowledge, and expertise, as well as to address a transboundary research agenda. Challenges are discussed from multiple perspectives: data, methodological, governmental and readiness, and potential impact. This analysis is aimed at researchers, policymakers, and practitioners interested in the specific challenges and progress of OGDIs in Latin America, while also contributing to the global conversation on best practices and lessons learned in implementing OGDIs across different contexts.","sentences":["Open data initiatives and infrastructures play an essential role in favoring better data access, participation, and transparency in government operations and decision-making.","Open Geographical Data Infrastructures (OGDIs) allow citizens to access and scrutinize government and public data, thereby enhancing accountability and evidence-based decision-making.","This encourages citizen engagement and participation in public affairs and offers researchers, non-governmental organizations, civil society, and business sectors novel opportunities to analyze and disseminate large amounts of geographical data and to address social, urban, and environmental challenges.","In Latin America, while recent open government agendas have shown an inclination towards transparency, citizen participation, and collaboration, only a limited number of OGDIs allow unrestricted use and re-use of their data.","Given the region's cultural, social, and economic disparities, there is a contrasting digital divide that significantly impacts how OGDIs are being developed.","Therefore, this paper analyses recent progress in developing OGDIs in Latin America, technological gaps, and open geographical data initiatives.","The main results denote an early development of OGDIs in the region.","Nevertheless, this opens the door for the timely involvement of citizens and non-government sectors to share needs, experiences, knowledge, and expertise, as well as to address a transboundary research agenda.","Challenges are discussed from multiple perspectives: data, methodological, governmental and readiness, and potential impact.","This analysis is aimed at researchers, policymakers, and practitioners interested in the specific challenges and progress of OGDIs in Latin America, while also contributing to the global conversation on best practices and lessons learned in implementing OGDIs across different contexts."],"url":"http://arxiv.org/abs/2501.13235v1"}
