{"created":"2024-08-28 17:59:05","title":"Spatio-Temporal Context Prompting for Zero-Shot Action Detection","abstract":"Spatio-temporal action detection encompasses the tasks of localizing and classifying individual actions within a video. Recent works aim to enhance this process by incorporating interaction modeling, which captures the relationship between people and their surrounding context. However, these approaches have primarily focused on fully-supervised learning, and the current limitation lies in the lack of generalization capability to recognize unseen action categories. In this paper, we aim to adapt the pretrained image-language models to detect unseen actions. To this end, we propose a method which can effectively leverage the rich knowledge of visual-language models to perform Person-Context Interaction. Meanwhile, our Context Prompting module will utilize contextual information to prompt labels, thereby enhancing the generation of more representative text features. Moreover, to address the challenge of recognizing distinct actions by multiple people at the same timestamp, we design the Interest Token Spotting mechanism which employs pretrained visual knowledge to find each person's interest context tokens, and then these tokens will be used for prompting to generate text features tailored to each individual. To evaluate the ability to detect unseen actions, we propose a comprehensive benchmark on J-HMDB, UCF101-24, and AVA datasets. The experiments show that our method achieves superior results compared to previous approaches and can be further extended to multi-action videos, bringing it closer to real-world applications. The code and data can be found in https://webber2933.github.io/ST-CLIP-project-page.","sentences":["Spatio-temporal action detection encompasses the tasks of localizing and classifying individual actions within a video.","Recent works aim to enhance this process by incorporating interaction modeling, which captures the relationship between people and their surrounding context.","However, these approaches have primarily focused on fully-supervised learning, and the current limitation lies in the lack of generalization capability to recognize unseen action categories.","In this paper, we aim to adapt the pretrained image-language models to detect unseen actions.","To this end, we propose a method which can effectively leverage the rich knowledge of visual-language models to perform Person-Context Interaction.","Meanwhile, our Context Prompting module will utilize contextual information to prompt labels, thereby enhancing the generation of more representative text features.","Moreover, to address the challenge of recognizing distinct actions by multiple people at the same timestamp, we design the Interest Token Spotting mechanism which employs pretrained visual knowledge to find each person's interest context tokens, and then these tokens will be used for prompting to generate text features tailored to each individual.","To evaluate the ability to detect unseen actions, we propose a comprehensive benchmark on J-HMDB, UCF101-24, and AVA datasets.","The experiments show that our method achieves superior results compared to previous approaches and can be further extended to multi-action videos, bringing it closer to real-world applications.","The code and data can be found in https://webber2933.github.io/ST-CLIP-project-page."],"url":"http://arxiv.org/abs/2408.15996v2"}
{"created":"2024-08-28 17:58:53","title":"ClimDetect: A Benchmark Dataset for Climate Change Detection and Attribution","abstract":"Detecting and attributing temperature increases due to climate change is crucial for understanding global warming and guiding adaptation strategies. The complexity of distinguishing human-induced climate signals from natural variability has challenged traditional detection and attribution (D&A) approaches, which seek to identify specific \"fingerprints\" in climate response variables. Deep learning offers potential for discerning these complex patterns in expansive spatial datasets. However, lack of standard protocols has hindered consistent comparisons across studies. We introduce ClimDetect, a standardized dataset of over 816k daily climate snapshots, designed to enhance model accuracy in identifying climate change signals. ClimDetect integrates various input and target variables used in past research, ensuring comparability and consistency. We also explore the application of vision transformers (ViT) to climate data, a novel and modernizing approach in this context. Our open-access data and code serve as a benchmark for advancing climate science through improved model evaluations. ClimDetect is publicly accessible via Huggingface dataet respository at: https://huggingface.co/datasets/ClimDetect/ClimDetect.","sentences":["Detecting and attributing temperature increases due to climate change is crucial for understanding global warming and guiding adaptation strategies.","The complexity of distinguishing human-induced climate signals from natural variability has challenged traditional detection and attribution (D&A) approaches, which seek to identify specific \"fingerprints\" in climate response variables.","Deep learning offers potential for discerning these complex patterns in expansive spatial datasets.","However, lack of standard protocols has hindered consistent comparisons across studies.","We introduce ClimDetect, a standardized dataset of over 816k daily climate snapshots, designed to enhance model accuracy in identifying climate change signals.","ClimDetect integrates various input and target variables used in past research, ensuring comparability and consistency.","We also explore the application of vision transformers (ViT) to climate data, a novel and modernizing approach in this context.","Our open-access data and code serve as a benchmark for advancing climate science through improved model evaluations.","ClimDetect is publicly accessible via Huggingface dataet respository at: https://huggingface.co/datasets/ClimDetect/ClimDetect."],"url":"http://arxiv.org/abs/2408.15993v1"}
{"created":"2024-08-28 17:50:19","title":"In-Context Imitation Learning via Next-Token Prediction","abstract":"We explore how to enhance next-token prediction models to perform in-context imitation learning on a real robot, where the robot executes new tasks by interpreting contextual information provided during the input phase, without updating its underlying policy parameters. We propose In-Context Robot Transformer (ICRT), a causal transformer that performs autoregressive prediction on sensorimotor trajectories without relying on any linguistic data or reward function. This formulation enables flexible and training-free execution of new tasks at test time, achieved by prompting the model with sensorimotor trajectories of the new task composing of image observations, actions and states tuples, collected through human teleoperation. Experiments with a Franka Emika robot demonstrate that the ICRT can adapt to new tasks specified by prompts, even in environment configurations that differ from both the prompt and the training data. In a multitask environment setup, ICRT significantly outperforms current state-of-the-art next-token prediction models in robotics on generalizing to unseen tasks. Code, checkpoints and data are available on https://icrt.dev/","sentences":["We explore how to enhance next-token prediction models to perform in-context imitation learning on a real robot, where the robot executes new tasks by interpreting contextual information provided during the input phase, without updating its underlying policy parameters.","We propose In-Context Robot Transformer (ICRT), a causal transformer that performs autoregressive prediction on sensorimotor trajectories without relying on any linguistic data or reward function.","This formulation enables flexible and training-free execution of new tasks at test time, achieved by prompting the model with sensorimotor trajectories of the new task composing of image observations, actions and states tuples, collected through human teleoperation.","Experiments with a Franka Emika robot demonstrate that the ICRT can adapt to new tasks specified by prompts, even in environment configurations that differ from both the prompt and the training data.","In a multitask environment setup, ICRT significantly outperforms current state-of-the-art next-token prediction models in robotics on generalizing to unseen tasks.","Code, checkpoints and data are available on https://icrt.dev/"],"url":"http://arxiv.org/abs/2408.15980v1"}
{"created":"2024-08-28 17:38:44","title":"More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding","abstract":"Enabling Large Language Models (LLMs) to comprehend the 3D physical world remains a significant challenge. Due to the lack of large-scale 3D-text pair datasets, the success of LLMs has yet to be replicated in 3D understanding. In this paper, we rethink this issue and propose a new task: 3D Data-Efficient Point-Language Understanding. The goal is to enable LLMs to achieve robust 3D object understanding with minimal 3D point cloud and text data pairs. To address this task, we introduce GreenPLM, which leverages more text data to compensate for the lack of 3D data. First, inspired by using CLIP to align images and text, we utilize a pre-trained point cloud-text encoder to map the 3D point cloud space to the text space. This mapping leaves us to seamlessly connect the text space with LLMs. Once the point-text-LLM connection is established, we further enhance text-LLM alignment by expanding the intermediate text space, thereby reducing the reliance on 3D point cloud data. Specifically, we generate 6M free-text descriptions of 3D objects, and design a three-stage training strategy to help LLMs better explore the intrinsic connections between different modalities. To achieve efficient modality alignment, we design a zero-parameter cross-attention module for token pooling. Extensive experimental results show that GreenPLM requires only 12% of the 3D training data used by existing state-of-the-art models to achieve superior 3D understanding. Remarkably, GreenPLM also achieves competitive performance using text-only data. The code and weights are available at: https://github.com/TangYuan96/GreenPLM.","sentences":["Enabling Large Language Models (LLMs) to comprehend the 3D physical world remains a significant challenge.","Due to the lack of large-scale 3D-text pair datasets, the success of LLMs has yet to be replicated in 3D understanding.","In this paper, we rethink this issue and propose a new task: 3D Data-Efficient Point-Language Understanding.","The goal is to enable LLMs to achieve robust 3D object understanding with minimal 3D point cloud and text data pairs.","To address this task, we introduce GreenPLM, which leverages more text data to compensate for the lack of 3D data.","First, inspired by using CLIP to align images and text, we utilize a pre-trained point cloud-text encoder to map the 3D point cloud space to the text space.","This mapping leaves us to seamlessly connect the text space with LLMs.","Once the point-text-LLM connection is established, we further enhance text-LLM alignment by expanding the intermediate text space, thereby reducing the reliance on 3D point cloud data.","Specifically, we generate 6M free-text descriptions of 3D objects, and design a three-stage training strategy to help LLMs better explore the intrinsic connections between different modalities.","To achieve efficient modality alignment, we design a zero-parameter cross-attention module for token pooling.","Extensive experimental results show that GreenPLM requires only 12% of the 3D training data used by existing state-of-the-art models to achieve superior 3D understanding.","Remarkably, GreenPLM also achieves competitive performance using text-only data.","The code and weights are available at: https://github.com/TangYuan96/GreenPLM."],"url":"http://arxiv.org/abs/2408.15966v1"}
{"created":"2024-08-28 17:20:56","title":"Efficient Slice Anomaly Detection Network for 3D Brain MRI Volume","abstract":"Current anomaly detection methods excel with benchmark industrial data but struggle with natural images and medical data due to varying definitions of 'normal' and 'abnormal.' This makes accurate identification of deviations in these fields particularly challenging. Especially for 3D brain MRI data, all the state-of-the-art models are reconstruction-based with 3D convolutional neural networks which are memory-intensive, time-consuming and producing noisy outputs that require further post-processing. We propose a framework called Simple Slice-based Network (SimpleSliceNet), which utilizes a model pre-trained on ImageNet and fine-tuned on a separate MRI dataset as a 2D slice feature extractor to reduce computational cost. We aggregate the extracted features to perform anomaly detection tasks on 3D brain MRI volumes. Our model integrates a conditional normalizing flow to calculate log likelihood of features and employs the Semi-Push-Pull Mechanism to enhance anomaly detection accuracy. The results indicate improved performance, showcasing our model's remarkable adaptability and effectiveness when addressing the challenges exists in brain MRI data. In addition, for the large-scale 3D brain volumes, our model SimpleSliceNet outperforms the state-of-the-art 2D and 3D models in terms of accuracy, memory usage and time consumption. Code is available at: https://anonymous.4open.science/r/SimpleSliceNet-8EA3.","sentences":["Current anomaly detection methods excel with benchmark industrial data but struggle with natural images and medical data due to varying definitions of 'normal' and 'abnormal.'","This makes accurate identification of deviations in these fields particularly challenging.","Especially for 3D brain MRI data, all the state-of-the-art models are reconstruction-based with 3D convolutional neural networks which are memory-intensive, time-consuming and producing noisy outputs that require further post-processing.","We propose a framework called Simple Slice-based Network (SimpleSliceNet), which utilizes a model pre-trained on ImageNet and fine-tuned on a separate MRI dataset as a 2D slice feature extractor to reduce computational cost.","We aggregate the extracted features to perform anomaly detection tasks on 3D brain MRI volumes.","Our model integrates a conditional normalizing flow to calculate log likelihood of features and employs the Semi-Push-Pull Mechanism to enhance anomaly detection accuracy.","The results indicate improved performance, showcasing our model's remarkable adaptability and effectiveness when addressing the challenges exists in brain MRI data.","In addition, for the large-scale 3D brain volumes, our model SimpleSliceNet outperforms the state-of-the-art 2D and 3D models in terms of accuracy, memory usage and time consumption.","Code is available at: https://anonymous.4open.science/r/SimpleSliceNet-8EA3."],"url":"http://arxiv.org/abs/2408.15958v1"}
{"created":"2024-08-28 17:14:51","title":"Fall Detection for Smart Living using YOLOv5","abstract":"This work introduces a fall detection system using the YOLOv5mu model, which achieved a mean average precision (mAP) of 0.995, demonstrating exceptional accuracy in identifying fall events within smart home environments. Enhanced by advanced data augmentation techniques, the model demonstrates significant robustness and adaptability across various conditions. The integration of YOLOv5mu offers precise, real-time fall detection, which is crucial for improving safety and emergency response for residents. Future research will focus on refining the system by incorporating contextual data and exploring multi-sensor approaches to enhance its performance and practical applicability in diverse environments.","sentences":["This work introduces a fall detection system using the YOLOv5mu model, which achieved a mean average precision (mAP) of 0.995, demonstrating exceptional accuracy in identifying fall events within smart home environments.","Enhanced by advanced data augmentation techniques, the model demonstrates significant robustness and adaptability across various conditions.","The integration of YOLOv5mu offers precise, real-time fall detection, which is crucial for improving safety and emergency response for residents.","Future research will focus on refining the system by incorporating contextual data and exploring multi-sensor approaches to enhance its performance and practical applicability in diverse environments."],"url":"http://arxiv.org/abs/2408.15955v1"}
{"created":"2024-08-28 17:12:01","title":"Modeling and Analyzing the Influence of Non-Item Pages on Sequential Next-Item Prediction","abstract":"Analyzing the sequence of historical interactions between users and items, sequential recommendation models learn user intent and make predictions about the next item of interest. Next to these item interactions, most systems also have interactions with pages not related to specific items, for example navigation pages, account pages, and pages for a specific category, which may provide additional insights into the user's interests. However, while there are several approaches to integrate additional information about items and users, the topic of integrating non-item pages has been less explored. We use the hypotheses testing framework HypTrails to show that there is indeed a relationship between these non-item pages and the items of interest and fill this gap by proposing various approaches of representing non-item pages (e.g, based on their content) to use them as an additional information source for the task of sequential next-item prediction.   We create a synthetic dataset with non-item pages highly related to the subsequent item to show that the models are generally capable of learning from these interactions, and subsequently evaluate the improvements gained by including non-item pages in two real-world datasets.   We adapt eight popular sequential recommender models, covering CNN-, RNN- and transformer-based architectures, to integrate non-item pages and investigate the capabilities of these models to leverage their information for next item prediction. We also analyze their behavior on noisy data and compare different item representation strategies.   Our results show that non-item pages are a valuable source of information, but representing such a page well is the key to successfully leverage them. The inclusion of non-item pages can increase the performance for next-item prediction in all examined model architectures with a varying degree.","sentences":["Analyzing the sequence of historical interactions between users and items, sequential recommendation models learn user intent and make predictions about the next item of interest.","Next to these item interactions, most systems also have interactions with pages not related to specific items, for example navigation pages, account pages, and pages for a specific category, which may provide additional insights into the user's interests.","However, while there are several approaches to integrate additional information about items and users, the topic of integrating non-item pages has been less explored.","We use the hypotheses testing framework HypTrails to show that there is indeed a relationship between these non-item pages and the items of interest and fill this gap by proposing various approaches of representing non-item pages (e.g, based on their content) to use them as an additional information source for the task of sequential next-item prediction.   ","We create a synthetic dataset with non-item pages highly related to the subsequent item to show that the models are generally capable of learning from these interactions, and subsequently evaluate the improvements gained by including non-item pages in two real-world datasets.   ","We adapt eight popular sequential recommender models, covering CNN-, RNN- and transformer-based architectures, to integrate non-item pages and investigate the capabilities of these models to leverage their information for next item prediction.","We also analyze their behavior on noisy data and compare different item representation strategies.   ","Our results show that non-item pages are a valuable source of information, but representing such a page well is the key to successfully leverage them.","The inclusion of non-item pages can increase the performance for next-item prediction in all examined model architectures with a varying degree."],"url":"http://arxiv.org/abs/2408.15953v1"}
{"created":"2024-08-28 17:08:56","title":"Atari-GPT: Investigating the Capabilities of Multimodal Large Language Models as Low-Level Policies for Atari Games","abstract":"Recent advancements in large language models (LLMs) have expanded their capabilities beyond traditional text-based tasks to multimodal domains, integrating visual, auditory, and textual data. While multimodal LLMs have been extensively explored for high-level planning in domains like robotics and games, their potential as low-level controllers remains largely untapped. This paper explores the application of multimodal LLMs as low-level controllers in the domain of Atari video games, introducing Atari game performance as a new benchmark for evaluating the ability of multimodal LLMs to perform low-level control tasks. Unlike traditional reinforcement learning (RL) and imitation learning (IL) methods that require extensive computational resources as well as reward function specification, these LLMs utilize pre-existing multimodal knowledge to directly engage with game environments. Our study assesses multiple multimodal LLMs performance against traditional RL agents, human players, and random agents, focusing on their ability to understand and interact with complex visual scenes and formulate strategic responses. Additionally, we examine the impact of In-Context Learning (ICL) by incorporating human-demonstrated game-play trajectories to enhance the models contextual understanding. Through this investigation, we aim to determine the extent to which multimodal LLMs can leverage their extensive training to effectively function as low-level controllers, thereby redefining potential applications in dynamic and visually complex environments. Additional results and videos are available at our project webpage: https://sites.google.com/view/atari-gpt/.","sentences":["Recent advancements in large language models (LLMs) have expanded their capabilities beyond traditional text-based tasks to multimodal domains, integrating visual, auditory, and textual data.","While multimodal LLMs have been extensively explored for high-level planning in domains like robotics and games, their potential as low-level controllers remains largely untapped.","This paper explores the application of multimodal LLMs as low-level controllers in the domain of Atari video games, introducing Atari game performance as a new benchmark for evaluating the ability of multimodal LLMs to perform low-level control tasks.","Unlike traditional reinforcement learning (RL) and imitation learning (IL) methods that require extensive computational resources as well as reward function specification, these LLMs utilize pre-existing multimodal knowledge to directly engage with game environments.","Our study assesses multiple multimodal LLMs performance against traditional RL agents, human players, and random agents, focusing on their ability to understand and interact with complex visual scenes and formulate strategic responses.","Additionally, we examine the impact of In-Context Learning (ICL) by incorporating human-demonstrated game-play trajectories to enhance the models contextual understanding.","Through this investigation, we aim to determine the extent to which multimodal LLMs can leverage their extensive training to effectively function as low-level controllers, thereby redefining potential applications in dynamic and visually complex environments.","Additional results and videos are available at our project webpage: https://sites.google.com/view/atari-gpt/."],"url":"http://arxiv.org/abs/2408.15950v1"}
{"created":"2024-08-28 17:05:40","title":"SLAM2REF: Advancing Long-Term Mapping with 3D LiDAR and Reference Map Integration for Precise 6-DoF Trajectory Estimation and Map Extension","abstract":"This paper presents a pioneering solution to the task of integrating mobile 3D LiDAR and inertial measurement unit (IMU) data with existing building information models or point clouds, which is crucial for achieving precise long-term localization and mapping in indoor, GPS-denied environments. Our proposed framework, SLAM2REF, introduces a novel approach for automatic alignment and map extension utilizing reference 3D maps. The methodology is supported by a sophisticated multi-session anchoring technique, which integrates novel descriptors and registration methodologies. Real-world experiments reveal the framework's remarkable robustness and accuracy, surpassing current state-of-the-art methods. Our open-source framework's significance lies in its contribution to resilient map data management, enhancing processes across diverse sectors such as construction site monitoring, emergency response, disaster management, and others, where fast-updated digital 3D maps contribute to better decision-making and productivity. Moreover, it offers advancements in localization and mapping research. Link to the repository: https://github.com/MigVega/SLAM2REF, Data: https://doi.org/10.14459/2024mp1743877.","sentences":["This paper presents a pioneering solution to the task of integrating mobile 3D LiDAR and inertial measurement unit (IMU) data with existing building information models or point clouds, which is crucial for achieving precise long-term localization and mapping in indoor, GPS-denied environments.","Our proposed framework, SLAM2REF, introduces a novel approach for automatic alignment and map extension utilizing reference 3D maps.","The methodology is supported by a sophisticated multi-session anchoring technique, which integrates novel descriptors and registration methodologies.","Real-world experiments reveal the framework's remarkable robustness and accuracy, surpassing current state-of-the-art methods.","Our open-source framework's significance lies in its contribution to resilient map data management, enhancing processes across diverse sectors such as construction site monitoring, emergency response, disaster management, and others, where fast-updated digital 3D maps contribute to better decision-making and productivity.","Moreover, it offers advancements in localization and mapping research.","Link to the repository: https://github.com/MigVega/SLAM2REF, Data: https://doi.org/10.14459/2024mp1743877."],"url":"http://arxiv.org/abs/2408.15948v1"}
{"created":"2024-08-28 16:33:21","title":"DeMoBot: Deformable Mobile Manipulation with Vision-based Sub-goal Retrieval","abstract":"Imitation learning (IL) algorithms typically distill experience into parametric behavior policies to mimic expert demonstrations. Despite their effectiveness, previous methods often struggle with data efficiency and accurately aligning the current state with expert demonstrations, especially in deformable mobile manipulation tasks characterized by partial observations and dynamic object deformations. In this paper, we introduce \\textbf{DeMoBot}, a novel IL approach that directly retrieves observations from demonstrations to guide robots in \\textbf{De}formable \\textbf{Mo}bile manipulation tasks. DeMoBot utilizes vision foundation models to identify relevant expert data based on visual similarity and matches the current trajectory with demonstrated trajectories using trajectory similarity and forward reachability constraints to select suitable sub-goals. Once a goal is determined, a motion generation policy will guide the robot to the next state until the task is completed. We evaluated DeMoBot using a Spot robot in several simulated and real-world settings, demonstrating its effectiveness and generalizability. With only 20 demonstrations, DeMoBot significantly outperforms the baselines, reaching a 50\\% success rate in curtain opening and 85\\% in gap covering in simulation.","sentences":["Imitation learning (IL) algorithms typically distill experience into parametric behavior policies to mimic expert demonstrations.","Despite their effectiveness, previous methods often struggle with data efficiency and accurately aligning the current state with expert demonstrations, especially in deformable mobile manipulation tasks characterized by partial observations and dynamic object deformations.","In this paper, we introduce \\textbf{DeMoBot}, a novel IL approach that directly retrieves observations from demonstrations to guide robots in \\textbf{De}formable \\textbf{Mo}bile manipulation tasks.","DeMoBot utilizes vision foundation models to identify relevant expert data based on visual similarity and matches the current trajectory with demonstrated trajectories using trajectory similarity and forward reachability constraints to select suitable sub-goals.","Once a goal is determined, a motion generation policy will guide the robot to the next state until the task is completed.","We evaluated DeMoBot using a Spot robot in several simulated and real-world settings, demonstrating its effectiveness and generalizability.","With only 20 demonstrations, DeMoBot significantly outperforms the baselines, reaching a 50\\% success rate in curtain opening and 85\\% in gap covering in simulation."],"url":"http://arxiv.org/abs/2408.15919v1"}
{"created":"2024-08-28 16:28:07","title":"Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models","abstract":"The cultivation of expertise for large language models (LLMs) to solve tasks of specific areas often requires special-purpose tuning with calibrated behaviors on the expected stable outputs. To avoid huge cost brought by manual preparation of instruction datasets and training resources up to hundreds of hours, the exploitation of open knowledge including a wealth of low rank adaptation (LoRA) models and instruction datasets serves as a good starting point. However, existing methods on model and data selection focus on the performance of general-purpose capabilities while neglecting the knowledge gap exposed in domain-specific deployment. In the present study, we propose to bridge such gap by introducing few human-annotated samples (i.e., K-shot) for advancing task expertise of LLMs with open knowledge. Specifically, we develop an efficient and scalable pipeline to cost-efficiently produce task experts where K-shot data intervene in selecting the most promising expert candidates and the task-relevant instructions. A mixture-of-expert (MoE) system is built to make the best use of individual-yet-complementary knowledge between multiple experts. We unveil the two keys to the success of a MoE system, 1) the abidance by K-shot, and 2) the insistence on diversity. For the former, we ensure that models that truly possess problem-solving abilities on K-shot are selected rather than those blind guessers. Besides, during data selection, instructions that share task-relevant contexts with K-shot are prioritized. For the latter, we highlight the diversity of constituting experts and that of the fine-tuning instructions throughout the model and data selection process. Extensive experimental results confirm the superiority of our approach over existing methods on utilization of open knowledge across various tasks. Codes and models will be released later.","sentences":["The cultivation of expertise for large language models (LLMs) to solve tasks of specific areas often requires special-purpose tuning with calibrated behaviors on the expected stable outputs.","To avoid huge cost brought by manual preparation of instruction datasets and training resources up to hundreds of hours, the exploitation of open knowledge including a wealth of low rank adaptation (LoRA) models and instruction datasets serves as a good starting point.","However, existing methods on model and data selection focus on the performance of general-purpose capabilities while neglecting the knowledge gap exposed in domain-specific deployment.","In the present study, we propose to bridge such gap by introducing few human-annotated samples (i.e., K-shot) for advancing task expertise of LLMs with open knowledge.","Specifically, we develop an efficient and scalable pipeline to cost-efficiently produce task experts where K-shot data intervene in selecting the most promising expert candidates and the task-relevant instructions.","A mixture-of-expert (MoE) system is built to make the best use of individual-yet-complementary knowledge between multiple experts.","We unveil the two keys to the success of a MoE system, 1) the abidance by K-shot, and 2) the insistence on diversity.","For the former, we ensure that models that truly possess problem-solving abilities on K-shot are selected rather than those blind guessers.","Besides, during data selection, instructions that share task-relevant contexts with K-shot are prioritized.","For the latter, we highlight the diversity of constituting experts and that of the fine-tuning instructions throughout the model and data selection process.","Extensive experimental results confirm the superiority of our approach over existing methods on utilization of open knowledge across various tasks.","Codes and models will be released later."],"url":"http://arxiv.org/abs/2408.15915v1"}
{"created":"2024-08-28 16:19:55","title":"Exploring the potential of AI in nurturing learner empathy, prosocial values and environmental stewardship","abstract":"With Artificial Intelligence (AI) becoming a powerful tool for education (Zawacki-Richter et al., 2019), this chapter describes the concept of combining generative and traditional AI, citizen-science physiological, neuroergonomic wearables and environmental sensors into activities for learners to understand their own well-being and emotional states better with a view to developing empathy and environmental stewardship. Alongside bespoke and affordable wearables (DIY EEG headsets and biometric wristbands), interpretable AI and data science are used for learners to explore how the environment affects them physiologically and mentally in authentic environments. For example, relationships between environmental changes (e.g. poorer air quality) and their well-being (e.g. cognitive functioning) can be discovered. This is particularly crucial, as relevant knowledge can influence the way people treat the environment, as suggested by the disciplines of environmental neuroscience and environmental psychology (Doell et al., 2023). Yet, according to Palme and Salvati, there have been relatively few studies on the relationships between microclimates and human health and emotions (Palme and Salvati, 2021). As anthropogenic environmental pollution is becoming a prevalent problem, our research also aims to leverage on generative AI to introduce hypothetical scenarios of the environment as emotionally strong stimuli of relevance to the learners. This would provoke an emotional response for them to learn about their own physiological and neurological responses (using neuro-physiological data). Ultimately, we hope to establish a bidirectional understanding of how the environment affects humans physiologically and mentally; after which, to gain insights as to how AI can be used to effectively foster empathy, pro-environmental attitudes and stewardship.","sentences":["With Artificial Intelligence (AI) becoming a powerful tool for education (Zawacki-Richter et al., 2019), this chapter describes the concept of combining generative and traditional AI, citizen-science physiological, neuroergonomic wearables and environmental sensors into activities for learners to understand their own well-being and emotional states better with a view to developing empathy and environmental stewardship.","Alongside bespoke and affordable wearables (DIY EEG headsets and biometric wristbands), interpretable AI and data science are used for learners to explore how the environment affects them physiologically and mentally in authentic environments.","For example, relationships between environmental changes (e.g. poorer air quality) and their well-being (e.g. cognitive functioning) can be discovered.","This is particularly crucial, as relevant knowledge can influence the way people treat the environment, as suggested by the disciplines of environmental neuroscience and environmental psychology (Doell et al., 2023).","Yet, according to Palme and Salvati, there have been relatively few studies on the relationships between microclimates and human health and emotions (Palme and Salvati, 2021).","As anthropogenic environmental pollution is becoming a prevalent problem, our research also aims to leverage on generative AI to introduce hypothetical scenarios of the environment as emotionally strong stimuli of relevance to the learners.","This would provoke an emotional response for them to learn about their own physiological and neurological responses (using neuro-physiological data).","Ultimately, we hope to establish a bidirectional understanding of how the environment affects humans physiologically and mentally; after which, to gain insights as to how AI can be used to effectively foster empathy, pro-environmental attitudes and stewardship."],"url":"http://arxiv.org/abs/2408.15906v1"}
{"created":"2024-08-28 16:12:55","title":"Nexus: Specialization meets Adaptability for Efficiently Training Mixture of Experts","abstract":"Efficiency, specialization, and adaptability to new data distributions are qualities that are hard to combine in current Large Language Models. The Mixture of Experts (MoE) architecture has been the focus of significant research because its inherent conditional computation enables such desirable properties. In this work, we focus on \"upcycling\" dense expert models into an MoE, aiming to improve specialization while also adding the ability to adapt to new tasks easily. We introduce Nexus, an enhanced MoE architecture with adaptive routing where the model learns to project expert embeddings from domain representations. This approach allows Nexus to flexibly add new experts after the initial upcycling through separately trained dense models, without requiring large-scale MoE training for unseen data domains. Our experiments show that Nexus achieves a relative gain of up to 2.1% over the baseline for initial upcycling, and a 18.8% relative gain for extending the MoE with a new expert by using limited finetuning data. This flexibility of Nexus is crucial to enable an open-source ecosystem where every user continuously assembles their own MoE-mix according to their needs.","sentences":["Efficiency, specialization, and adaptability to new data distributions are qualities that are hard to combine in current Large Language Models.","The Mixture of Experts (MoE) architecture has been the focus of significant research because its inherent conditional computation enables such desirable properties.","In this work, we focus on \"upcycling\" dense expert models into an MoE, aiming to improve specialization while also adding the ability to adapt to new tasks easily.","We introduce Nexus, an enhanced MoE architecture with adaptive routing where the model learns to project expert embeddings from domain representations.","This approach allows Nexus to flexibly add new experts after the initial upcycling through separately trained dense models, without requiring large-scale MoE training for unseen data domains.","Our experiments show that Nexus achieves a relative gain of up to 2.1% over the baseline for initial upcycling, and a 18.8% relative gain for extending the MoE with a new expert by using limited finetuning data.","This flexibility of Nexus is crucial to enable an open-source ecosystem where every user continuously assembles their own MoE-mix according to their needs."],"url":"http://arxiv.org/abs/2408.15901v1"}
{"created":"2024-08-28 16:12:16","title":"Airfoil Diffusion: Denoising Diffusion Model For Conditional Airfoil Generation","abstract":"The design of aerodynamic shapes, such as airfoils, has traditionally required significant computational resources and relied on predefined design parameters, which limit the potential for novel shape synthesis. In this work, we introduce a data-driven methodology for airfoil generation using a diffusion model. Trained on a dataset of preexisting airfoils, our model can generate an arbitrary number of new airfoils from random vectors, which can be conditioned on specific aerodynamic performance metrics such as lift and drag, or geometric criteria. Our results demonstrate that the diffusion model effectively produces airfoil shapes with realistic aerodynamic properties, offering substantial improvements in efficiency, flexibility, and the potential for discovering innovative airfoil designs. This approach significantly expands the design space, facilitating the synthesis of high-performance aerodynamic shapes that transcend the limitations of traditional methods.","sentences":["The design of aerodynamic shapes, such as airfoils, has traditionally required significant computational resources and relied on predefined design parameters, which limit the potential for novel shape synthesis.","In this work, we introduce a data-driven methodology for airfoil generation using a diffusion model.","Trained on a dataset of preexisting airfoils, our model can generate an arbitrary number of new airfoils from random vectors, which can be conditioned on specific aerodynamic performance metrics such as lift and drag, or geometric criteria.","Our results demonstrate that the diffusion model effectively produces airfoil shapes with realistic aerodynamic properties, offering substantial improvements in efficiency, flexibility, and the potential for discovering innovative airfoil designs.","This approach significantly expands the design space, facilitating the synthesis of high-performance aerodynamic shapes that transcend the limitations of traditional methods."],"url":"http://arxiv.org/abs/2408.15898v1"}
{"created":"2024-08-28 16:06:12","title":"A New Method for Cross-Lingual-based Semantic Role Labeling","abstract":"Semantic role labeling is a crucial task in natural language processing, enabling better comprehension of natural language. However, the lack of annotated data in multiple languages has posed a challenge for researchers. To address this, a deep learning algorithm based on model transfer has been proposed. The algorithm utilizes a dataset consisting of the English portion of CoNLL2009 and a corpus of semantic roles in Persian. To optimize the efficiency of training, only ten percent of the educational data from each language is used. The results of the proposed model demonstrate significant improvements compared to Niksirt et al.'s model. In monolingual mode, the proposed model achieved a 2.05 percent improvement on F1-score, while in cross-lingual mode, the improvement was even more substantial, reaching 6.23 percent. Worth noting is that the compared model only trained two of the four stages of semantic role labeling and employed golden data for the remaining two stages. This suggests that the actual superiority of the proposed model surpasses the reported numbers by a significant margin. The development of cross-lingual methods for semantic role labeling holds promise, particularly in addressing the scarcity of annotated data for various languages. These advancements pave the way for further research in understanding and processing natural language across different linguistic contexts.","sentences":["Semantic role labeling is a crucial task in natural language processing, enabling better comprehension of natural language.","However, the lack of annotated data in multiple languages has posed a challenge for researchers.","To address this, a deep learning algorithm based on model transfer has been proposed.","The algorithm utilizes a dataset consisting of the English portion of CoNLL2009 and a corpus of semantic roles in Persian.","To optimize the efficiency of training, only ten percent of the educational data from each language is used.","The results of the proposed model demonstrate significant improvements compared to Niksirt et al.'s model.","In monolingual mode, the proposed model achieved a 2.05 percent improvement on F1-score, while in cross-lingual mode, the improvement was even more substantial, reaching 6.23 percent.","Worth noting is that the compared model only trained two of the four stages of semantic role labeling and employed golden data for the remaining two stages.","This suggests that the actual superiority of the proposed model surpasses the reported numbers by a significant margin.","The development of cross-lingual methods for semantic role labeling holds promise, particularly in addressing the scarcity of annotated data for various languages.","These advancements pave the way for further research in understanding and processing natural language across different linguistic contexts."],"url":"http://arxiv.org/abs/2408.15896v1"}
{"created":"2024-08-28 16:05:20","title":"Bias in LLMs as Annotators: The Effect of Party Cues on Labelling Decision by Large Language Models","abstract":"Human coders are biased. We test similar biases in Large Language Models (LLMs) as annotators. By replicating an experiment run by Ennser-Jedenastik and Meyer (2018), we find evidence that LLMs use political information, and specifically party cues, to judge political statements. Not only do LLMs use relevant information to contextualize whether a statement is positive, negative, or neutral based on the party cue, they also reflect the biases of the human-generated data upon which they have been trained. We also find that unlike humans, who are only biased when faced with statements from extreme parties, LLMs exhibit significant bias even when prompted with statements from center-left and center-right parties. The implications of our findings are discussed in the conclusion.","sentences":["Human coders are biased.","We test similar biases in Large Language Models (LLMs) as annotators.","By replicating an experiment run by Ennser-Jedenastik and Meyer (2018), we find evidence that LLMs use political information, and specifically party cues, to judge political statements.","Not only do LLMs use relevant information to contextualize whether a statement is positive, negative, or neutral based on the party cue, they also reflect the biases of the human-generated data upon which they have been trained.","We also find that unlike humans, who are only biased when faced with statements from extreme parties, LLMs exhibit significant bias even when prompted with statements from center-left and center-right parties.","The implications of our findings are discussed in the conclusion."],"url":"http://arxiv.org/abs/2408.15895v1"}
{"created":"2024-08-28 16:03:18","title":"Disentangled Diffusion Autoencoder for Harmonization of Multi-site Neuroimaging Data","abstract":"Combining neuroimaging datasets from multiple sites and scanners can help increase statistical power and thus provide greater insight into subtle neuroanatomical effects. However, site-specific effects pose a challenge by potentially obscuring the biological signal and introducing unwanted variance. Existing harmonization techniques, which use statistical models to remove such effects, have been shown to incompletely remove site effects while also failing to preserve biological variability. More recently, generative models using GANs or autoencoder-based approaches, have been proposed for site adjustment. However, such methods are known for instability during training or blurry image generation. In recent years, diffusion models have become increasingly popular for their ability to generate high-quality synthetic images. In this work, we introduce the disentangled diffusion autoencoder (DDAE), a novel diffusion model designed for controlling specific aspects of an image. We apply the DDAE to the task of harmonizing MR images by generating high-quality site-adjusted images that preserve biological variability. We use data from 7 different sites and demonstrate the DDAE's superiority in generating high-resolution, harmonized 2D MR images over previous approaches. As far as we are aware, this work marks the first diffusion-based model for site adjustment of neuroimaging data.","sentences":["Combining neuroimaging datasets from multiple sites and scanners can help increase statistical power and thus provide greater insight into subtle neuroanatomical effects.","However, site-specific effects pose a challenge by potentially obscuring the biological signal and introducing unwanted variance.","Existing harmonization techniques, which use statistical models to remove such effects, have been shown to incompletely remove site effects while also failing to preserve biological variability.","More recently, generative models using GANs or autoencoder-based approaches, have been proposed for site adjustment.","However, such methods are known for instability during training or blurry image generation.","In recent years, diffusion models have become increasingly popular for their ability to generate high-quality synthetic images.","In this work, we introduce the disentangled diffusion autoencoder (DDAE), a novel diffusion model designed for controlling specific aspects of an image.","We apply the DDAE to the task of harmonizing MR images by generating high-quality site-adjusted images that preserve biological variability.","We use data from 7 different sites and demonstrate the DDAE's superiority in generating high-resolution, harmonized 2D MR images over previous approaches.","As far as we are aware, this work marks the first diffusion-based model for site adjustment of neuroimaging data."],"url":"http://arxiv.org/abs/2408.15890v1"}
{"created":"2024-08-28 15:58:49","title":"Enhancing Intrusion Detection in IoT Environments: An Advanced Ensemble Approach Using Kolmogorov-Arnold Networks","abstract":"In recent years, the evolution of machine learning techniques has significantly impacted the field of intrusion detection, particularly within the context of the Internet of Things (IoT). As IoT networks expand, the need for robust security measures to counteract potential threats has become increasingly critical. This paper introduces a hybrid Intrusion Detection System (IDS) that synergistically combines Kolmogorov-Arnold Networks (KANs) with the XGBoost algorithm. Our proposed IDS leverages the unique capabilities of KANs, which utilize learnable activation functions to model complex relationships within data, alongside the powerful ensemble learning techniques of XGBoost, known for its high performance in classification tasks. This hybrid approach not only enhances the detection accuracy but also improves the interpretability of the model, making it suitable for dynamic and intricate IoT environments. Experimental evaluations demonstrate that our hybrid IDS achieves an impressive detection accuracy exceeding 99% in distinguishing between benign and malicious activities. Additionally, we were able to achieve F1 scores, precision, and recall that exceeded 98%. Furthermore, we conduct a comparative analysis against traditional Multi-Layer Perceptron (MLP) networks, assessing performance metrics such as Precision, Recall, and F1-score. The results underscore the efficacy of integrating KANs with XGBoost, highlighting the potential of this innovative approach to significantly strengthen the security framework of IoT networks.","sentences":["In recent years, the evolution of machine learning techniques has significantly impacted the field of intrusion detection, particularly within the context of the Internet of Things (IoT).","As IoT networks expand, the need for robust security measures to counteract potential threats has become increasingly critical.","This paper introduces a hybrid Intrusion Detection System (IDS) that synergistically combines Kolmogorov-Arnold Networks (KANs) with the XGBoost algorithm.","Our proposed IDS leverages the unique capabilities of KANs, which utilize learnable activation functions to model complex relationships within data, alongside the powerful ensemble learning techniques of XGBoost, known for its high performance in classification tasks.","This hybrid approach not only enhances the detection accuracy but also improves the interpretability of the model, making it suitable for dynamic and intricate IoT environments.","Experimental evaluations demonstrate that our hybrid IDS achieves an impressive detection accuracy exceeding 99% in distinguishing between benign and malicious activities.","Additionally, we were able to achieve F1 scores, precision, and recall that exceeded 98%.","Furthermore, we conduct a comparative analysis against traditional Multi-Layer Perceptron (MLP) networks, assessing performance metrics such as Precision, Recall, and F1-score.","The results underscore the efficacy of integrating KANs with XGBoost, highlighting the potential of this innovative approach to significantly strengthen the security framework of IoT networks."],"url":"http://arxiv.org/abs/2408.15886v2"}
{"created":"2024-08-28 15:52:23","title":"LLaVA-MoD: Making LLaVA Tiny via MoE Knowledge Distillation","abstract":"We introduce LLaVA-MoD, a novel framework designed to enable the efficient training of small-scale Multimodal Language Models (s-MLLM) by distilling knowledge from large-scale MLLM (l-MLLM). Our approach tackles two fundamental challenges in MLLM distillation. First, we optimize the network structure of s-MLLM by integrating a sparse Mixture of Experts (MoE) architecture into the language model, striking a balance between computational efficiency and model expressiveness. Second, we propose a progressive knowledge transfer strategy to ensure comprehensive knowledge migration. This strategy begins with mimic distillation, where we minimize the Kullback-Leibler (KL) divergence between output distributions to enable the student model to emulate the teacher network's understanding. Following this, we introduce preference distillation via Direct Preference Optimization (DPO), where the key lies in treating l-MLLM as the reference model. During this phase, the s-MLLM's ability to discriminate between superior and inferior examples is significantly enhanced beyond l-MLLM, leading to a better student that surpasses its teacher, particularly in hallucination benchmarks. Extensive experiments demonstrate that LLaVA-MoD outperforms existing models across various multimodal benchmarks while maintaining a minimal number of activated parameters and low computational costs. Remarkably, LLaVA-MoD, with only 2B activated parameters, surpasses Qwen-VL-Chat-7B by an average of 8.8% across benchmarks, using merely 0.3% of the training data and 23% trainable parameters. These results underscore LLaVA-MoD's ability to effectively distill comprehensive knowledge from its teacher model, paving the way for the development of more efficient MLLMs. The code will be available on: https://github.com/shufangxun/LLaVA-MoD.","sentences":["We introduce LLaVA-MoD, a novel framework designed to enable the efficient training of small-scale Multimodal Language Models (s-MLLM) by distilling knowledge from large-scale MLLM (l-MLLM).","Our approach tackles two fundamental challenges in MLLM distillation.","First, we optimize the network structure of s-MLLM by integrating a sparse Mixture of Experts (MoE) architecture into the language model, striking a balance between computational efficiency and model expressiveness.","Second, we propose a progressive knowledge transfer strategy to ensure comprehensive knowledge migration.","This strategy begins with mimic distillation, where we minimize the Kullback-Leibler (KL) divergence between output distributions to enable the student model to emulate the teacher network's understanding.","Following this, we introduce preference distillation via Direct Preference Optimization (DPO), where the key lies in treating l-MLLM as the reference model.","During this phase, the s-MLLM's ability to discriminate between superior and inferior examples is significantly enhanced beyond l-MLLM, leading to a better student that surpasses its teacher, particularly in hallucination benchmarks.","Extensive experiments demonstrate that LLaVA-MoD outperforms existing models across various multimodal benchmarks while maintaining a minimal number of activated parameters and low computational costs.","Remarkably, LLaVA-MoD, with only 2B activated parameters, surpasses Qwen-VL-Chat-7B by an average of 8.8% across benchmarks, using merely 0.3% of the training data and 23% trainable parameters.","These results underscore LLaVA-MoD's ability to effectively distill comprehensive knowledge from its teacher model, paving the way for the development of more efficient MLLMs.","The code will be available on: https://github.com/shufangxun/LLaVA-MoD."],"url":"http://arxiv.org/abs/2408.15881v1"}
{"created":"2024-08-28 15:48:39","title":"A Non-Traditional Approach to Assisting Data Address Translation","abstract":"This paper proposes a novel way to assist conventional data address translation. The approach, PC-Indexed Data Address Translation (PCAX), uses the PC of a load instruction, and not a data virtual address, to obtain the page table entry (PTE) for the data accessed by a load instruction. PCAX is intended to be used for a small subset of the static loads in a program. We observe that: (i) a small subset of static loads is responsible for most of the misses in a data translation lookaside buffer (DTLB), and (ii) often a dynamic instance of a static load instruction accesses the same PTE as the last dynamic instance, and consider PCAX for this subset. With PCAX the effective miss rate of a conventional DTLB can be cut down by a factor of 2-3X in many cases, and even more in some cases. PCAX is also beneficial in reducing the number of secondary TLB (STLB) misses. Since the tables used for PCAX can be accessed alongside instruction fetch, they can be slow, yet frequently provide a valid PTE even before the data address calculation. This results in a performance improvement, and reduced data address translation energy, in most cases.","sentences":["This paper proposes a novel way to assist conventional data address translation.","The approach, PC-Indexed Data Address Translation (PCAX), uses the PC of a load instruction, and not a data virtual address, to obtain the page table entry (PTE) for the data accessed by a load instruction.","PCAX is intended to be used for a small subset of the static loads in a program.","We observe that: (i) a small subset of static loads is responsible for most of the misses in a data translation lookaside buffer (DTLB), and (ii) often a dynamic instance of a static load instruction accesses the same PTE as the last dynamic instance, and consider PCAX for this subset.","With PCAX the effective miss rate of a conventional DTLB can be cut down by a factor of 2-3X in many cases, and even more in some cases.","PCAX is also beneficial in reducing the number of secondary TLB (STLB) misses.","Since the tables used for PCAX can be accessed alongside instruction fetch, they can be slow, yet frequently provide a valid PTE even before the data address calculation.","This results in a performance improvement, and reduced data address translation energy, in most cases."],"url":"http://arxiv.org/abs/2408.15878v1"}
{"created":"2024-08-28 15:40:06","title":"BIM-SLAM: Integrating BIM Models in Multi-session SLAM for Lifelong Mapping using 3D LiDAR","abstract":"While 3D LiDAR sensor technology is becoming more advanced and cheaper every day, the growth of digitalization in the AEC industry contributes to the fact that 3D building information models (BIM models) are now available for a large part of the built environment. These two facts open the question of how 3D models can support 3D LiDAR long-term SLAM in indoor, GPS-denied environments. This paper proposes a methodology that leverages BIM models to create an updated map of indoor environments with sequential LiDAR measurements. Session data (pose graph-based map and descriptors) are initially generated from BIM models. Then, real-world data is aligned with the session data from the model using multi-session anchoring while minimizing the drift on the real-world data. Finally, the new elements not present in the BIM model are identified, grouped, and reconstructed in a surface representation, allowing a better visualization next to the BIM model. The framework enables the creation of a coherent map aligned with the BIM model that does not require prior knowledge of the initial pose of the robot, and it does not need to be inside the map.","sentences":["While 3D LiDAR sensor technology is becoming more advanced and cheaper every day, the growth of digitalization in the AEC industry contributes to the fact that 3D building information models (BIM models) are now available for a large part of the built environment.","These two facts open the question of how 3D models can support 3D LiDAR long-term SLAM in indoor, GPS-denied environments.","This paper proposes a methodology that leverages BIM models to create an updated map of indoor environments with sequential LiDAR measurements.","Session data (pose graph-based map and descriptors) are initially generated from BIM models.","Then, real-world data is aligned with the session data from the model using multi-session anchoring while minimizing the drift on the real-world data.","Finally, the new elements not present in the BIM model are identified, grouped, and reconstructed in a surface representation, allowing a better visualization next to the BIM model.","The framework enables the creation of a coherent map aligned with the BIM model that does not require prior knowledge of the initial pose of the robot, and it does not need to be inside the map."],"url":"http://arxiv.org/abs/2408.15870v1"}
{"created":"2024-08-28 15:37:44","title":"GenDDS: Generating Diverse Driving Video Scenarios with Prompt-to-Video Generative Model","abstract":"Autonomous driving training requires a diverse range of datasets encompassing various traffic conditions, weather scenarios, and road types. Traditional data augmentation methods often struggle to generate datasets that represent rare occurrences. To address this challenge, we propose GenDDS, a novel approach for generating driving scenarios generation by leveraging the capabilities of Stable Diffusion XL (SDXL), an advanced latent diffusion model. Our methodology involves the use of descriptive prompts to guide the synthesis process, aimed at producing realistic and diverse driving scenarios. With the power of the latest computer vision techniques, such as ControlNet and Hotshot-XL, we have built a complete pipeline for video generation together with SDXL. We employ the KITTI dataset, which includes real-world driving videos, to train the model. Through a series of experiments, we demonstrate that our model can generate high-quality driving videos that closely replicate the complexity and variability of real-world driving scenarios. This research contributes to the development of sophisticated training data for autonomous driving systems and opens new avenues for creating virtual environments for simulation and validation purposes.","sentences":["Autonomous driving training requires a diverse range of datasets encompassing various traffic conditions, weather scenarios, and road types.","Traditional data augmentation methods often struggle to generate datasets that represent rare occurrences.","To address this challenge, we propose GenDDS, a novel approach for generating driving scenarios generation by leveraging the capabilities of Stable Diffusion XL (SDXL), an advanced latent diffusion model.","Our methodology involves the use of descriptive prompts to guide the synthesis process, aimed at producing realistic and diverse driving scenarios.","With the power of the latest computer vision techniques, such as ControlNet and Hotshot-XL, we have built a complete pipeline for video generation together with SDXL.","We employ the KITTI dataset, which includes real-world driving videos, to train the model.","Through a series of experiments, we demonstrate that our model can generate high-quality driving videos that closely replicate the complexity and variability of real-world driving scenarios.","This research contributes to the development of sophisticated training data for autonomous driving systems and opens new avenues for creating virtual environments for simulation and validation purposes."],"url":"http://arxiv.org/abs/2408.15868v1"}
{"created":"2024-08-28 15:33:47","title":"Retrieval-Augmented Instruction Tuning for Automated Process Engineering Calculations : A Tool-Chaining Problem-Solving Framework with Attributable Reflection","abstract":"The current technology landscape lacks a foundational AI model for solving process engineering calculations. In this work, we introduce a novel autonomous agent framework leveraging Retrieval-Augmented Instruction-Tuning (RAIT) to enhance open, customizable small code language models (SLMs) for these calculations. By combining instruction tuned code SLMs with Retrieval-Augmented Code Generation (RACG) using external tools, the agent generates, debugs, and optimizes code from natural language specifications. Our approach addresses the limitations of the current lack of a foundational AI model for specialized process engineering tasks and offers benefits of explainability, knowledge editing, and cost-effectiveness. Additionally, we curate custom datasets of chemical and process engineering problems and solutions to overcome data scarcity. Experimental results show that our framework matches the performance of large-scale proprietary models on benchmark datasets, proving its effectiveness and usability.","sentences":["The current technology landscape lacks a foundational AI model for solving process engineering calculations.","In this work, we introduce a novel autonomous agent framework leveraging Retrieval-Augmented Instruction-Tuning (RAIT) to enhance open, customizable small code language models (SLMs) for these calculations.","By combining instruction tuned code SLMs with Retrieval-Augmented Code Generation (RACG) using external tools, the agent generates, debugs, and optimizes code from natural language specifications.","Our approach addresses the limitations of the current lack of a foundational AI model for specialized process engineering tasks and offers benefits of explainability, knowledge editing, and cost-effectiveness.","Additionally, we curate custom datasets of chemical and process engineering problems and solutions to overcome data scarcity.","Experimental results show that our framework matches the performance of large-scale proprietary models on benchmark datasets, proving its effectiveness and usability."],"url":"http://arxiv.org/abs/2408.15866v1"}
{"created":"2024-08-28 15:23:08","title":"FlowAct: A Proactive Multimodal Human-robot Interaction System with Continuous Flow of Perception and Modular Action Sub-systems","abstract":"The evolution of autonomous systems in the context of human-robot interaction systems necessitates a synergy between the continuous perception of the environment and the potential actions to navigate or interact within it. We present Flowact, a proactive multimodal human-robot interaction architecture, working as an asynchronous endless loop of robot sensors into actuators and organized by two controllers, the Environment State Tracking (EST) and the Action Planner. The EST continuously collects and publishes a representation of the operative environment, ensuring a steady flow of perceptual data. This persistent perceptual flow is pivotal for our advanced Action Planner which orchestrates a collection of modular action subsystems, such as movement and speaking modules, governing their initiation or cessation based on the evolving environmental narrative. The EST employs a fusion of diverse sensory modalities to build a rich, real-time representation of the environment that is distributed to the Action Planner. This planner uses a decision-making framework to dynamically coordinate action modules, allowing them to respond proactively and coherently to changes in the environment. Through a series of real-world experiments, we exhibit the efficacy of the system in maintaining a continuous perception-action loop, substantially enhancing the responsiveness and adaptability of autonomous pro-active agents. The modular architecture of the action subsystems facilitates easy extensibility and adaptability to a broad spectrum of tasks and scenarios.","sentences":["The evolution of autonomous systems in the context of human-robot interaction systems necessitates a synergy between the continuous perception of the environment and the potential actions to navigate or interact within it.","We present Flowact, a proactive multimodal human-robot interaction architecture, working as an asynchronous endless loop of robot sensors into actuators and organized by two controllers, the Environment State Tracking (EST) and the Action Planner.","The EST continuously collects and publishes a representation of the operative environment, ensuring a steady flow of perceptual data.","This persistent perceptual flow is pivotal for our advanced Action Planner which orchestrates a collection of modular action subsystems, such as movement and speaking modules, governing their initiation or cessation based on the evolving environmental narrative.","The EST employs a fusion of diverse sensory modalities to build a rich, real-time representation of the environment that is distributed to the Action Planner.","This planner uses a decision-making framework to dynamically coordinate action modules, allowing them to respond proactively and coherently to changes in the environment.","Through a series of real-world experiments, we exhibit the efficacy of the system in maintaining a continuous perception-action loop, substantially enhancing the responsiveness and adaptability of autonomous pro-active agents.","The modular architecture of the action subsystems facilitates easy extensibility and adaptability to a broad spectrum of tasks and scenarios."],"url":"http://arxiv.org/abs/2408.15864v1"}
{"created":"2024-08-28 15:21:10","title":"Fusing Pruned and Backdoored Models: Optimal Transport-based Data-free Backdoor Mitigation","abstract":"Backdoor attacks present a serious security threat to deep neuron networks (DNNs). Although numerous effective defense techniques have been proposed in recent years, they inevitably rely on the availability of either clean or poisoned data. In contrast, data-free defense techniques have evolved slowly and still lag significantly in performance. To address this issue, different from the traditional approach of pruning followed by fine-tuning, we propose a novel data-free defense method named Optimal Transport-based Backdoor Repairing (OTBR) in this work. This method, based on our findings on neuron weight changes (NWCs) of random unlearning, uses optimal transport (OT)-based model fusion to combine the advantages of both pruned and backdoored models. Specifically, we first demonstrate our findings that the NWCs of random unlearning are positively correlated with those of poison unlearning. Based on this observation, we propose a random-unlearning NWC pruning technique to eliminate the backdoor effect and obtain a backdoor-free pruned model. Then, motivated by the OT-based model fusion, we propose the pruned-to-backdoored OT-based fusion technique, which fuses pruned and backdoored models to combine the advantages of both, resulting in a model that demonstrates high clean accuracy and a low attack success rate. To our knowledge, this is the first work to apply OT and model fusion techniques to backdoor defense. Extensive experiments show that our method successfully defends against all seven backdoor attacks across three benchmark datasets, outperforming both state-of-the-art (SOTA) data-free and data-dependent methods. The code implementation and Appendix are provided in the Supplementary Material.","sentences":["Backdoor attacks present a serious security threat to deep neuron networks (DNNs).","Although numerous effective defense techniques have been proposed in recent years, they inevitably rely on the availability of either clean or poisoned data.","In contrast, data-free defense techniques have evolved slowly and still lag significantly in performance.","To address this issue, different from the traditional approach of pruning followed by fine-tuning, we propose a novel data-free defense method named Optimal Transport-based Backdoor Repairing (OTBR) in this work.","This method, based on our findings on neuron weight changes (NWCs) of random unlearning, uses optimal transport (OT)-based model fusion to combine the advantages of both pruned and backdoored models.","Specifically, we first demonstrate our findings that the NWCs of random unlearning are positively correlated with those of poison unlearning.","Based on this observation, we propose a random-unlearning NWC pruning technique to eliminate the backdoor effect and obtain a backdoor-free pruned model.","Then, motivated by the OT-based model fusion, we propose the pruned-to-backdoored OT-based fusion technique, which fuses pruned and backdoored models to combine the advantages of both, resulting in a model that demonstrates high clean accuracy and a low attack success rate.","To our knowledge, this is the first work to apply OT and model fusion techniques to backdoor defense.","Extensive experiments show that our method successfully defends against all seven backdoor attacks across three benchmark datasets, outperforming both state-of-the-art (SOTA) data-free and data-dependent methods.","The code implementation and Appendix are provided in the Supplementary Material."],"url":"http://arxiv.org/abs/2408.15861v1"}
{"created":"2024-08-28 15:15:52","title":"An Empirical Study of API Misuses of Data-Centric Libraries","abstract":"Developers rely on third-party library Application Programming Interfaces (APIs) when developing software. However, libraries typically come with assumptions and API usage constraints, whose violation results in API misuse. API misuses may result in crashes or incorrect behavior. Even though API misuse is a well-studied area, a recent study of API misuse of deep learning libraries showed that the nature of these misuses and their symptoms are different from misuses of traditional libraries, and as a result highlighted potential shortcomings of current misuse detection tools. We speculate that these observations may not be limited to deep learning API misuses but may stem from the data-centric nature of these APIs. Data-centric libraries often deal with diverse data structures, intricate processing workflows, and a multitude of parameters, which can make them inherently more challenging to use correctly. Therefore, understanding the potential misuses of these libraries is important to avoid unexpected application behavior. To this end, this paper contributes an empirical study of API misuses of five data-centric libraries that cover areas such as data processing, numerical computation, machine learning, and visualization. We identify misuses of these libraries by analyzing data from both Stack Overflow and GitHub. Our results show that many of the characteristics of API misuses observed for deep learning libraries extend to misuses of the data-centric library APIs we study. We also find that developers tend to misuse APIs from data-centric libraries, regardless of whether the API directive appears in the documentation. Overall, our work exposes the challenges of API misuse in data-centric libraries, rather than only focusing on deep learning libraries. Our collected misuses and their characterization lay groundwork for future research to help reduce misuses of these libraries.","sentences":["Developers rely on third-party library Application Programming Interfaces (APIs) when developing software.","However, libraries typically come with assumptions and API usage constraints, whose violation results in API misuse.","API misuses may result in crashes or incorrect behavior.","Even though API misuse is a well-studied area, a recent study of API misuse of deep learning libraries showed that the nature of these misuses and their symptoms are different from misuses of traditional libraries, and as a result highlighted potential shortcomings of current misuse detection tools.","We speculate that these observations may not be limited to deep learning API misuses but may stem from the data-centric nature of these APIs.","Data-centric libraries often deal with diverse data structures, intricate processing workflows, and a multitude of parameters, which can make them inherently more challenging to use correctly.","Therefore, understanding the potential misuses of these libraries is important to avoid unexpected application behavior.","To this end, this paper contributes an empirical study of API misuses of five data-centric libraries that cover areas such as data processing, numerical computation, machine learning, and visualization.","We identify misuses of these libraries by analyzing data from both Stack Overflow and GitHub.","Our results show that many of the characteristics of API misuses observed for deep learning libraries extend to misuses of the data-centric library APIs we study.","We also find that developers tend to misuse APIs from data-centric libraries, regardless of whether the API directive appears in the documentation.","Overall, our work exposes the challenges of API misuse in data-centric libraries, rather than only focusing on deep learning libraries.","Our collected misuses and their characterization lay groundwork for future research to help reduce misuses of these libraries."],"url":"http://arxiv.org/abs/2408.15853v1"}
{"created":"2024-08-28 14:52:37","title":"EdgeLinker: Practical Blockchain-based Framework for Healthcare Fog Applications to Enhance Security in Edge-IoT Data Communications","abstract":"The pervasive adoption of Internet of Things (IoT) has significantly advanced healthcare digitization and modernization. Nevertheless, the sensitive nature of medical data presents security and privacy challenges. On the other hand, resource constraints of IoT devices often necessitates cloud services for data handling, introducing single points of failure, processing delays, and security vulnerabilities. Meanwhile, the blockchain technology offers potential solutions for enhancing security, decentralization, and data ownership. An ideal solution should ensure confidentiality, access control, and data integrity while being scalable, cost-effective, and integrable with the existing systems. However, current blockchain-based studies only address some of these requirements. Accordingly, this paper proposes EdgeLinker; a comprehensive solution incorporating Proof-of-Authority consensus, integrating smart contracts on the Ethereum blockchain for access control, and advanced cryptographic algorithms for secure data communication between IoT edge devices and the fog layer in healthcare fog applications. This novel framework has been implemented in a real-world fog testbed, using COTS fog devices. Based on a comprehensive set of evaluations, EdgeLinker demonstrates significant improvements in security and privacy with reasonable costs, making it an affordable and practical system for healthcare fog applications. Compared with the state-of-the-art, without significant changes in the write-time to the blockchain, EdgeLinker achieves a 35% improvement in data read time. Additionally, it is able to provide better throughput in both reading and writing transactions compared to the existing studies. EdgeLinker has been also examined in terms of energy, resource consumption and channel latency in both secure and non-secure modes, which has shown remarkable improvements.","sentences":["The pervasive adoption of Internet of Things (IoT) has significantly advanced healthcare digitization and modernization.","Nevertheless, the sensitive nature of medical data presents security and privacy challenges.","On the other hand, resource constraints of IoT devices often necessitates cloud services for data handling, introducing single points of failure, processing delays, and security vulnerabilities.","Meanwhile, the blockchain technology offers potential solutions for enhancing security, decentralization, and data ownership.","An ideal solution should ensure confidentiality, access control, and data integrity while being scalable, cost-effective, and integrable with the existing systems.","However, current blockchain-based studies only address some of these requirements.","Accordingly, this paper proposes EdgeLinker; a comprehensive solution incorporating Proof-of-Authority consensus, integrating smart contracts on the Ethereum blockchain for access control, and advanced cryptographic algorithms for secure data communication between IoT edge devices and the fog layer in healthcare fog applications.","This novel framework has been implemented in a real-world fog testbed, using COTS fog devices.","Based on a comprehensive set of evaluations, EdgeLinker demonstrates significant improvements in security and privacy with reasonable costs, making it an affordable and practical system for healthcare fog applications.","Compared with the state-of-the-art, without significant changes in the write-time to the blockchain, EdgeLinker achieves a 35% improvement in data read time.","Additionally, it is able to provide better throughput in both reading and writing transactions compared to the existing studies.","EdgeLinker has been also examined in terms of energy, resource consumption and channel latency in both secure and non-secure modes, which has shown remarkable improvements."],"url":"http://arxiv.org/abs/2408.15838v1"}
{"created":"2024-08-28 14:44:42","title":"SITransformer: Shared Information-Guided Transformer for Extreme Multimodal Summarization","abstract":"Extreme Multimodal Summarization with Multimodal Output (XMSMO) becomes an attractive summarization approach by integrating various types of information to create extremely concise yet informative summaries for individual modalities. Existing methods overlook the issue that multimodal data often contains more topic irrelevant information, which can mislead the model into producing inaccurate summaries especially for extremely short ones. In this paper, we propose SITransformer, a Shared Information-guided Transformer for extreme multimodal summarization. It has a shared information guided pipeline which involves a cross-modal shared information extractor and a cross-modal interaction module. The extractor formulates semantically shared salient information from different modalities by devising a novel filtering process consisting of a differentiable top-k selector and a shared-information guided gating unit. As a result, the common, salient, and relevant contents across modalities are identified. Next, a transformer with cross-modal attentions is developed for intra- and inter-modality learning with the shared information guidance to produce the extreme summary. Comprehensive experiments demonstrate that SITransformer significantly enhances the summarization quality for both video and text summaries for XMSMO. Our code will be publicly available at https://github.com/SichengLeoLiu/MMAsia24-XMSMO.","sentences":["Extreme Multimodal Summarization with Multimodal Output (XMSMO) becomes an attractive summarization approach by integrating various types of information to create extremely concise yet informative summaries for individual modalities.","Existing methods overlook the issue that multimodal data often contains more topic irrelevant information, which can mislead the model into producing inaccurate summaries especially for extremely short ones.","In this paper, we propose SITransformer, a Shared Information-guided Transformer for extreme multimodal summarization.","It has a shared information guided pipeline which involves a cross-modal shared information extractor and a cross-modal interaction module.","The extractor formulates semantically shared salient information from different modalities by devising a novel filtering process consisting of a differentiable top-k selector and a shared-information guided gating unit.","As a result, the common, salient, and relevant contents across modalities are identified.","Next, a transformer with cross-modal attentions is developed for intra- and inter-modality learning with the shared information guidance to produce the extreme summary.","Comprehensive experiments demonstrate that SITransformer significantly enhances the summarization quality for both video and text summaries for XMSMO.","Our code will be publicly available at https://github.com/SichengLeoLiu/MMAsia24-XMSMO."],"url":"http://arxiv.org/abs/2408.15829v2"}
{"created":"2024-08-28 14:40:15","title":"Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification","abstract":"As the field of artificial intelligence progresses, assistive technologies are becoming more widely used across all industries. The healthcare industry is no different, with numerous studies being done to develop assistive tools for healthcare professionals. Automatic diagnostic systems are one such beneficial tool that can assist with a variety of tasks, including collecting patient information, analyzing test results, and diagnosing patients. However, the idea of developing systems that can provide a differential diagnosis has been largely overlooked in most of these research studies. In this study, we propose a transformer-based approach for providing differential diagnoses based on a patient's age, sex, medical history, and symptoms. We use the DDXPlus dataset, which provides differential diagnosis information for patients based on 49 disease types. Firstly, we propose a method to process the tabular patient data from the dataset and engineer them into patient reports to make them suitable for our research. In addition, we introduce two data modification modules to diversify the training data and consequently improve the robustness of the models. We approach the task as a multi-label classification problem and conduct extensive experiments using four transformer models. All the models displayed promising results by achieving over 97% F1 score on the held-out test set. Moreover, we design additional behavioral tests to get a broader understanding of the models. In particular, for one of our test cases, we prepared a custom test set of 100 samples with the assistance of a doctor. The results on the custom set showed that our proposed data modification modules improved the model's generalization capabilities. We hope our findings will provide future researchers with valuable insights and inspire them to develop reliable systems for automatic differential diagnosis.","sentences":["As the field of artificial intelligence progresses, assistive technologies are becoming more widely used across all industries.","The healthcare industry is no different, with numerous studies being done to develop assistive tools for healthcare professionals.","Automatic diagnostic systems are one such beneficial tool that can assist with a variety of tasks, including collecting patient information, analyzing test results, and diagnosing patients.","However, the idea of developing systems that can provide a differential diagnosis has been largely overlooked in most of these research studies.","In this study, we propose a transformer-based approach for providing differential diagnoses based on a patient's age, sex, medical history, and symptoms.","We use the DDXPlus dataset, which provides differential diagnosis information for patients based on 49 disease types.","Firstly, we propose a method to process the tabular patient data from the dataset and engineer them into patient reports to make them suitable for our research.","In addition, we introduce two data modification modules to diversify the training data and consequently improve the robustness of the models.","We approach the task as a multi-label classification problem and conduct extensive experiments using four transformer models.","All the models displayed promising results by achieving over 97% F1 score on the held-out test set.","Moreover, we design additional behavioral tests to get a broader understanding of the models.","In particular, for one of our test cases, we prepared a custom test set of 100 samples with the assistance of a doctor.","The results on the custom set showed that our proposed data modification modules improved the model's generalization capabilities.","We hope our findings will provide future researchers with valuable insights and inspire them to develop reliable systems for automatic differential diagnosis."],"url":"http://arxiv.org/abs/2408.15827v1"}
{"created":"2024-08-28 14:25:35","title":"Mining Field Data for Tree Species Recognition at Scale","abstract":"Individual tree species labels are particularly hard to acquire due to the expert knowledge needed and the limitations of photointerpretation. Here, we present a methodology to automatically mine species labels from public forest inventory data, using available pretrained tree detection models. We identify tree instances in aerial imagery and match them with field data with close to zero human involvement. We conduct a series of experiments on the resulting dataset, and show a beneficial effect when adding noisy or even unlabeled data points, highlighting a strong potential for large-scale individual species mapping.","sentences":["Individual tree species labels are particularly hard to acquire due to the expert knowledge needed and the limitations of photointerpretation.","Here, we present a methodology to automatically mine species labels from public forest inventory data, using available pretrained tree detection models.","We identify tree instances in aerial imagery and match them with field data with close to zero human involvement.","We conduct a series of experiments on the resulting dataset, and show a beneficial effect when adding noisy or even unlabeled data points, highlighting a strong potential for large-scale individual species mapping."],"url":"http://arxiv.org/abs/2408.15816v1"}
{"created":"2024-08-28 14:24:48","title":"MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing","abstract":"While a recent study reveals that many developer-written test cases can encode a reusable Metamorphic Relation (MR), over 70% of them directly hard-code the source input and follow-up input in the encoded relation. Such encoded MRs, which do not contain an explicit input transformation to transform the source inputs to corresponding follow-up inputs, cannot be reused with new source inputs to enhance test adequacy.   In this paper, we propose MR-Adopt (Automatic Deduction Of inPut Transformation) to automatically deduce the input transformation from the hard-coded source and follow-up inputs, aiming to enable the encoded MRs to be reused with new source inputs. With typically only one pair of source and follow-up inputs available in an MR-encoded test case as the example, we leveraged LLMs to understand the intention of the test case and generate additional examples of source-followup input pairs. This helps to guide the generation of input transformations generalizable to multiple source inputs. Besides, to mitigate the issue that LLMs generate erroneous code, we refine LLM-generated transformations by removing MR- irrelevant code elements with data-flow analysis. Finally, we assess candidate transformations based on encoded output relations and select the best transformation as the result. Evaluation results show that MR-Adopt can generate input transformations applicable to all experimental source inputs for 72.00% of encoded MRs, which is 33.33% more than using vanilla GPT-3.5. By incorporating MR- Adopt-generated input transformations, encoded MR-based test cases can effectively enhance the test adequacy, increasing the line coverage and mutation score by 10.62% and 18.91%, respectively.","sentences":["While a recent study reveals that many developer-written test cases can encode a reusable Metamorphic Relation (MR), over 70% of them directly hard-code the source input and follow-up input in the encoded relation.","Such encoded MRs, which do not contain an explicit input transformation to transform the source inputs to corresponding follow-up inputs, cannot be reused with new source inputs to enhance test adequacy.   ","In this paper, we propose MR-Adopt (Automatic Deduction Of inPut Transformation) to automatically deduce the input transformation from the hard-coded source and follow-up inputs, aiming to enable the encoded MRs to be reused with new source inputs.","With typically only one pair of source and follow-up inputs available in an MR-encoded test case as the example, we leveraged LLMs to understand the intention of the test case and generate additional examples of source-followup input pairs.","This helps to guide the generation of input transformations generalizable to multiple source inputs.","Besides, to mitigate the issue that LLMs generate erroneous code, we refine LLM-generated transformations by removing MR- irrelevant code elements with data-flow analysis.","Finally, we assess candidate transformations based on encoded output relations and select the best transformation as the result.","Evaluation results show that MR-Adopt can generate input transformations applicable to all experimental source inputs for 72.00% of encoded MRs, which is 33.33% more than using vanilla GPT-3.5.","By incorporating MR- Adopt-generated input transformations, encoded MR-based test cases can effectively enhance the test adequacy, increasing the line coverage and mutation score by 10.62% and 18.91%, respectively."],"url":"http://arxiv.org/abs/2408.15815v1"}
{"created":"2024-08-28 13:51:52","title":"Emulating Brain-like Rapid Learning in Neuromorphic Edge Computing","abstract":"Achieving personalized intelligence at the edge with real-time learning capabilities holds enormous promise in enhancing our daily experiences and helping decision making, planning, and sensing. However, efficient and reliable edge learning remains difficult with current technology due to the lack of personalized data, insufficient hardware capabilities, and inherent challenges posed by online learning.   Over time and across multiple developmental stages, the brain has evolved to efficiently incorporate new knowledge by gradually building on previous knowledge. In this work, we emulate the multiple stages of learning with digital neuromorphic technology that simulates the neural and synaptic processes of the brain using two stages of learning. First, a meta-training stage trains the hyperparameters of synaptic plasticity for one-shot learning using a differentiable simulation of the neuromorphic hardware. This meta-training process refines a hardware local three-factor synaptic plasticity rule and its associated hyperparameters to align with the trained task domain. In a subsequent deployment stage, these optimized hyperparameters enable fast, data-efficient, and accurate learning of new classes. We demonstrate our approach using event-driven vision sensor data and the Intel Loihi neuromorphic processor with its plasticity dynamics, achieving real-time one-shot learning of new classes that is vastly improved over transfer learning. Our methodology can be deployed with arbitrary plasticity models and can be applied to situations demanding quick learning and adaptation at the edge, such as navigating unfamiliar environments or learning unexpected categories of data through user engagement.","sentences":["Achieving personalized intelligence at the edge with real-time learning capabilities holds enormous promise in enhancing our daily experiences and helping decision making, planning, and sensing.","However, efficient and reliable edge learning remains difficult with current technology due to the lack of personalized data, insufficient hardware capabilities, and inherent challenges posed by online learning.   ","Over time and across multiple developmental stages, the brain has evolved to efficiently incorporate new knowledge by gradually building on previous knowledge.","In this work, we emulate the multiple stages of learning with digital neuromorphic technology that simulates the neural and synaptic processes of the brain using two stages of learning.","First, a meta-training stage trains the hyperparameters of synaptic plasticity for one-shot learning using a differentiable simulation of the neuromorphic hardware.","This meta-training process refines a hardware local three-factor synaptic plasticity rule and its associated hyperparameters to align with the trained task domain.","In a subsequent deployment stage, these optimized hyperparameters enable fast, data-efficient, and accurate learning of new classes.","We demonstrate our approach using event-driven vision sensor data and the Intel Loihi neuromorphic processor with its plasticity dynamics, achieving real-time one-shot learning of new classes that is vastly improved over transfer learning.","Our methodology can be deployed with arbitrary plasticity models and can be applied to situations demanding quick learning and adaptation at the edge, such as navigating unfamiliar environments or learning unexpected categories of data through user engagement."],"url":"http://arxiv.org/abs/2408.15800v1"}
{"created":"2024-08-28 13:42:28","title":"Evaluating Named Entity Recognition Using Few-Shot Prompting with Large Language Models","abstract":"This paper evaluates Few-Shot Prompting with Large Language Models for Named Entity Recognition (NER). Traditional NER systems rely on extensive labeled datasets, which are costly and time-consuming to obtain. Few-Shot Prompting or in-context learning enables models to recognize entities with minimal examples. We assess state-of-the-art models like GPT-4 in NER tasks, comparing their few-shot performance to fully supervised benchmarks. Results show that while there is a performance gap, large models excel in adapting to new entity types and domains with very limited data. We also explore the effects of prompt engineering, guided output format and context length on performance. This study underscores Few-Shot Learning's potential to reduce the need for large labeled datasets, enhancing NER scalability and accessibility.","sentences":["This paper evaluates Few-Shot Prompting with Large Language Models for Named Entity Recognition (NER).","Traditional NER systems rely on extensive labeled datasets, which are costly and time-consuming to obtain.","Few-Shot Prompting or in-context learning enables models to recognize entities with minimal examples.","We assess state-of-the-art models like GPT-4 in NER tasks, comparing their few-shot performance to fully supervised benchmarks.","Results show that while there is a performance gap, large models excel in adapting to new entity types and domains with very limited data.","We also explore the effects of prompt engineering, guided output format and context length on performance.","This study underscores Few-Shot Learning's potential to reduce the need for large labeled datasets, enhancing NER scalability and accessibility."],"url":"http://arxiv.org/abs/2408.15796v1"}
{"created":"2024-08-28 13:35:54","title":"Efficient LLM Scheduling by Learning to Rank","abstract":"In Large Language Model (LLM) inference, the output length of an LLM request is typically regarded as not known a priori. Consequently, most LLM serving systems employ a simple First-come-first-serve (FCFS) scheduling strategy, leading to Head-Of-Line (HOL) blocking and reduced throughput and service quality. In this paper, we reexamine this assumption -- we show that, although predicting the exact generation length of each request is infeasible, it is possible to predict the relative ranks of output lengths in a batch of requests, using learning to rank. The ranking information offers valuable guidance for scheduling requests. Building on this insight, we develop a novel scheduler for LLM inference and serving that can approximate the shortest-job-first (SJF) schedule better than existing approaches. We integrate this scheduler with the state-of-the-art LLM serving system and show significant performance improvement in several important applications: 2.8x lower latency in chatbot serving and 6.5x higher throughput in synthetic data generation. Our code is available at https://github.com/hao-ai-lab/vllm-ltr.git","sentences":["In Large Language Model (LLM) inference, the output length of an LLM request is typically regarded as not known a priori.","Consequently, most LLM serving systems employ a simple First-come-first-serve (FCFS) scheduling strategy, leading to Head-Of-Line (HOL) blocking and reduced throughput and service quality.","In this paper, we reexamine this assumption -- we show that, although predicting the exact generation length of each request is infeasible, it is possible to predict the relative ranks of output lengths in a batch of requests, using learning to rank.","The ranking information offers valuable guidance for scheduling requests.","Building on this insight, we develop a novel scheduler for LLM inference and serving that can approximate the shortest-job-first (SJF) schedule better than existing approaches.","We integrate this scheduler with the state-of-the-art LLM serving system and show significant performance improvement in several important applications: 2.8x lower latency in chatbot serving and 6.5x higher throughput in synthetic data generation.","Our code is available at https://github.com/hao-ai-lab/vllm-ltr.git"],"url":"http://arxiv.org/abs/2408.15792v1"}
{"created":"2024-08-28 13:29:59","title":"Interactive Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM Interactions","abstract":"Virtual counselors powered by large language models (LLMs) aim to create interactive support systems that effectively assist clients struggling with mental health challenges. To replicate counselor-client conversations, researchers have built an online mental health platform that allows professional counselors to provide clients with text-based counseling services for about an hour per session. Notwithstanding its effectiveness, challenges exist as human annotation is time-consuming, cost-intensive, privacy-protected, and not scalable. To address this issue and investigate the applicability of LLMs in psychological counseling conversation simulation, we propose a framework that employs two LLMs via role-playing for simulating counselor-client interactions. Our framework involves two LLMs, one acting as a client equipped with a specific and real-life user profile and the other playing the role of an experienced counselor, generating professional responses using integrative therapy techniques. We implement both the counselor and the client by zero-shot prompting the GPT-4 model. In order to assess the effectiveness of LLMs in simulating counselor-client interactions and understand the disparities between LLM- and human-generated conversations, we evaluate the synthetic data from various perspectives. We begin by assessing the client's performance through automatic evaluations. Next, we analyze and compare the disparities between dialogues generated by the LLM and those generated by professional counselors. Furthermore, we conduct extensive experiments to thoroughly examine the performance of our LLM-based counselor trained with synthetic interactive dialogues by benchmarking against state-of-the-art models for mental health.","sentences":["Virtual counselors powered by large language models (LLMs) aim to create interactive support systems that effectively assist clients struggling with mental health challenges.","To replicate counselor-client conversations, researchers have built an online mental health platform that allows professional counselors to provide clients with text-based counseling services for about an hour per session.","Notwithstanding its effectiveness, challenges exist as human annotation is time-consuming, cost-intensive, privacy-protected, and not scalable.","To address this issue and investigate the applicability of LLMs in psychological counseling conversation simulation, we propose a framework that employs two LLMs via role-playing for simulating counselor-client interactions.","Our framework involves two LLMs, one acting as a client equipped with a specific and real-life user profile and the other playing the role of an experienced counselor, generating professional responses using integrative therapy techniques.","We implement both the counselor and the client by zero-shot prompting the GPT-4 model.","In order to assess the effectiveness of LLMs in simulating counselor-client interactions and understand the disparities between LLM- and human-generated conversations, we evaluate the synthetic data from various perspectives.","We begin by assessing the client's performance through automatic evaluations.","Next, we analyze and compare the disparities between dialogues generated by the LLM and those generated by professional counselors.","Furthermore, we conduct extensive experiments to thoroughly examine the performance of our LLM-based counselor trained with synthetic interactive dialogues by benchmarking against state-of-the-art models for mental health."],"url":"http://arxiv.org/abs/2408.15787v1"}
{"created":"2024-08-28 13:15:14","title":"Enumeration of Minimal Hitting Sets Parameterized by Treewidth","abstract":"Enumerating the minimal hitting sets of a hypergraph is a problem which arises in many data management applications that include constraint mining, discovering unique column combinations, and enumerating database repairs. Previously, Eiter et al. showed that the minimal hitting sets of an $n$-vertex hypergraph, with treewidth $w$, can be enumerated with delay $O^*(n^{w})$ (ignoring polynomial factors), with space requirements that scale with the output size. We improve this to fixed-parameter-linear delay, following an FPT preprocessing phase. The memory consumption of our algorithm is exponential with respect to the treewidth of the hypergraph.","sentences":["Enumerating the minimal hitting sets of a hypergraph is a problem which arises in many data management applications that include constraint mining, discovering unique column combinations, and enumerating database repairs.","Previously, Eiter et al. showed that the minimal hitting sets of an $n$-vertex hypergraph, with treewidth $w$, can be enumerated with delay $O^*(n^{w})$ (ignoring polynomial factors), with space requirements that scale with the output size.","We improve this to fixed-parameter-linear delay, following an FPT preprocessing phase.","The memory consumption of our algorithm is exponential with respect to the treewidth of the hypergraph."],"url":"http://arxiv.org/abs/2408.15776v1"}
{"created":"2024-08-28 13:01:16","title":"Started Off Local, Now We're in the Cloud: Forensic Examination of the Amazon Echo Show 15 Smart Display","abstract":"Amazon Echo is one of the most popular product families of smart speakers and displays. Considering their growing presence in modern households as well as the digital traces associated with residents' interactions with these devices, analyses of Echo products are likely to become more common for forensic investigators at \"smart home\" crime scenes. With this in mind, we present the first forensic examination of the Echo Show 15, Amazon's largest smart display running on Fire OS and the first Echo device with Visual ID, a face recognition feature. We unveil a non-invasive method for accessing the unencrypted file system of the Echo Show 15 based on an undocumented pinout for the eMMC interface which we discovered on the main logic board. On the device, we identify various local usage artifacts, such as searched products, streamed movies, visited websites, metadata of photos and videos as well as logged events of Visual ID about movements and users detected by the built-in camera. Furthermore, we utilize an insecurely stored token on the Echo Show 15 to obtain access to remote user artifacts in Amazon's cloud, including Alexa voice requests, calendars, contacts, conversations, photos, and videos. In this regard, we also identify new Amazon APIs through network traffic analysis of two companion apps, namely Alexa and Photos. Overall, in terms of practical relevance, our findings demonstrate a non-destructive way of data acquisition for Echo Show 15 devices as well as how to lift the scope of forensic traces from local artifacts on the device to remote artifacts stored in the cloud.","sentences":["Amazon Echo is one of the most popular product families of smart speakers and displays.","Considering their growing presence in modern households as well as the digital traces associated with residents' interactions with these devices, analyses of Echo products are likely to become more common for forensic investigators at \"smart home\" crime scenes.","With this in mind, we present the first forensic examination of the Echo Show 15, Amazon's largest smart display running on Fire OS and the first Echo device with Visual ID, a face recognition feature.","We unveil a non-invasive method for accessing the unencrypted file system of the Echo Show 15 based on an undocumented pinout for the eMMC interface which we discovered on the main logic board.","On the device, we identify various local usage artifacts, such as searched products, streamed movies, visited websites, metadata of photos and videos as well as logged events of Visual ID about movements and users detected by the built-in camera.","Furthermore, we utilize an insecurely stored token on the Echo Show 15 to obtain access to remote user artifacts in Amazon's cloud, including Alexa voice requests, calendars, contacts, conversations, photos, and videos.","In this regard, we also identify new Amazon APIs through network traffic analysis of two companion apps, namely Alexa and Photos.","Overall, in terms of practical relevance, our findings demonstrate a non-destructive way of data acquisition for Echo Show 15 devices as well as how to lift the scope of forensic traces from local artifacts on the device to remote artifacts stored in the cloud."],"url":"http://arxiv.org/abs/2408.15768v1"}
{"created":"2024-08-28 12:56:24","title":"Evaluating and Comparing Crowd Simulations: Perspectives from a Crowd Authoring Tool","abstract":"Crowd simulation is a research area widely used in diverse fields, including gaming and security, assessing virtual agent movements through metrics like time to reach their goals, speed, trajectories, and densities. This is relevant for security applications, for instance, as different crowd configurations can determine the time people spend in environments trying to evacuate them. In this work, we extend WebCrowds, an authoring tool for crowd simulation, to allow users to build scenarios and evaluate them through a set of metrics. The aim is to provide a quantitative metric that can, based on simulation data, select the best crowd configuration in a certain environment. We conduct experiments to validate our proposed metric in multiple crowd simulation scenarios and perform a comparison with another metric found in the literature. The results show that experts in the domain of crowd scenarios agree with our proposed quantitative metric.","sentences":["Crowd simulation is a research area widely used in diverse fields, including gaming and security, assessing virtual agent movements through metrics like time to reach their goals, speed, trajectories, and densities.","This is relevant for security applications, for instance, as different crowd configurations can determine the time people spend in environments trying to evacuate them.","In this work, we extend WebCrowds, an authoring tool for crowd simulation, to allow users to build scenarios and evaluate them through a set of metrics.","The aim is to provide a quantitative metric that can, based on simulation data, select the best crowd configuration in a certain environment.","We conduct experiments to validate our proposed metric in multiple crowd simulation scenarios and perform a comparison with another metric found in the literature.","The results show that experts in the domain of crowd scenarios agree with our proposed quantitative metric."],"url":"http://arxiv.org/abs/2408.15762v1"}
{"created":"2024-08-28 12:25:45","title":"Form and meaning co-determine the realization of tone in Taiwan Mandarin spontaneous speech: the case of Tone 3 sandhi","abstract":"In Standard Chinese, Tone 3 (the dipping tone) becomes Tone 2 (rising tone) when followed by another Tone 3. Previous studies have noted that this sandhi process may be incomplete, in the sense that the assimilated Tone 3 is still distinct from a true Tone 2. While Mandarin Tone 3 sandhi is widely studied using carefully controlled laboratory speech (Xu, 1997) and more formal registers of Beijing Mandarin (Yuan and Chen, 2014), less is known about its realization in spontaneous speech, and about the effect of contextual factors on tonal realization. The present study investigates the pitch contours of two-character words with T2-T3 and T3-T3 tone patterns in spontaneous Taiwan Mandarin conversations. Our analysis makes use of the Generative Additive Mixed Model (GAMM, Wood, 2017) to examine fundamental frequency (f0) contours as a function of normalized time. We consider various factors known to influence pitch contours, including gender, speaking rate, speaker, neighboring tones, word position, bigram probability, and also novel predictors, word and word sense (Chuang et al., 2024). Our analyses revealed that in spontaneous Taiwan Mandarin, T3-T3 words become indistinguishable from T2-T3 words, indicating complete sandhi, once the strong effect of word (or word sense) is taken into account. For our data, the shape of f0 contours is not co-determined by word frequency. In contrast, the effect of word meaning on f0 contours is robust, as strong as the effect of adjacent tones, and is present for both T2-T3 and T3-T3 words.","sentences":["In Standard Chinese, Tone 3 (the dipping tone) becomes Tone 2 (rising tone) when followed by another Tone 3.","Previous studies have noted that this sandhi process may be incomplete, in the sense that the assimilated Tone 3 is still distinct from a true Tone 2.","While Mandarin Tone 3 sandhi is widely studied using carefully controlled laboratory speech (Xu, 1997) and more formal registers of Beijing Mandarin (Yuan and Chen, 2014), less is known about its realization in spontaneous speech, and about the effect of contextual factors on tonal realization.","The present study investigates the pitch contours of two-character words with T2-T3 and T3-T3 tone patterns in spontaneous Taiwan Mandarin conversations.","Our analysis makes use of the Generative Additive Mixed Model (GAMM, Wood, 2017) to examine fundamental frequency (f0) contours as a function of normalized time.","We consider various factors known to influence pitch contours, including gender, speaking rate, speaker, neighboring tones, word position, bigram probability, and also novel predictors, word and word sense (Chuang et al., 2024).","Our analyses revealed that in spontaneous Taiwan Mandarin, T3-T3 words become indistinguishable from T2-T3 words, indicating complete sandhi, once the strong effect of word (or word sense) is taken into account.","For our data, the shape of f0 contours is not co-determined by word frequency.","In contrast, the effect of word meaning on f0 contours is robust, as strong as the effect of adjacent tones, and is present for both T2-T3 and T3-T3 words."],"url":"http://arxiv.org/abs/2408.15747v1"}
{"created":"2024-08-28 12:06:11","title":"MambaPlace:Text-to-Point-Cloud Cross-Modal Place Recognition with Attention Mamba Mechanisms","abstract":"Vision Language Place Recognition (VLVPR) enhances robot localization performance by incorporating natural language descriptions from images. By utilizing language information, VLVPR directs robot place matching, overcoming the constraint of solely depending on vision. The essence of multimodal fusion lies in mining the complementary information between different modalities. However, general fusion methods rely on traditional neural architectures and are not well equipped to capture the dynamics of cross modal interactions, especially in the presence of complex intra modal and inter modal correlations. To this end, this paper proposes a novel coarse to fine and end to end connected cross modal place recognition framework, called MambaPlace. In the coarse localization stage, the text description and 3D point cloud are encoded by the pretrained T5 and instance encoder, respectively. They are then processed using Text Attention Mamba (TAM) and Point Clouds Mamba (PCM) for data enhancement and alignment. In the subsequent fine localization stage, the features of the text description and 3D point cloud are cross modally fused and further enhanced through cascaded Cross Attention Mamba (CCAM). Finally, we predict the positional offset from the fused text point cloud features, achieving the most accurate localization. Extensive experiments show that MambaPlace achieves improved localization accuracy on the KITTI360Pose dataset compared to the state of the art methods.","sentences":["Vision Language Place Recognition (VLVPR) enhances robot localization performance by incorporating natural language descriptions from images.","By utilizing language information, VLVPR directs robot place matching, overcoming the constraint of solely depending on vision.","The essence of multimodal fusion lies in mining the complementary information between different modalities.","However, general fusion methods rely on traditional neural architectures and are not well equipped to capture the dynamics of cross modal interactions, especially in the presence of complex intra modal and inter modal correlations.","To this end, this paper proposes a novel coarse to fine and end to end connected cross modal place recognition framework, called MambaPlace.","In the coarse localization stage, the text description and 3D point cloud are encoded by the pretrained T5 and instance encoder, respectively.","They are then processed using Text Attention Mamba (TAM) and Point Clouds Mamba (PCM) for data enhancement and alignment.","In the subsequent fine localization stage, the features of the text description and 3D point cloud are cross modally fused and further enhanced through cascaded Cross Attention Mamba (CCAM).","Finally, we predict the positional offset from the fused text point cloud features, achieving the most accurate localization.","Extensive experiments show that MambaPlace achieves improved localization accuracy on the KITTI360Pose dataset compared to the state of the art methods."],"url":"http://arxiv.org/abs/2408.15740v1"}
{"created":"2024-08-28 11:36:29","title":"An Evaluation of Sindhi Word Embedding in Semantic Analogies and Downstream Tasks","abstract":"In this paper, we propose a new word embedding based corpus consisting of more than 61 million words crawled from multiple web resources. We design a preprocessing pipeline for the filtration of unwanted text from crawled data. Afterwards, the cleaned vocabulary is fed to state-of-the-art continuous-bag-of-words, skip-gram, and GloVe word embedding algorithms. For the evaluation of pretrained embeddings, we use popular intrinsic and extrinsic evaluation approaches. The evaluation results reveal that continuous-bag-of-words and skip-gram perform better than GloVe and existing Sindhi fastText word embedding on both intrinsic and extrinsic evaluation approaches","sentences":["In this paper, we propose a new word embedding based corpus consisting of more than 61 million words crawled from multiple web resources.","We design a preprocessing pipeline for the filtration of unwanted text from crawled data.","Afterwards, the cleaned vocabulary is fed to state-of-the-art continuous-bag-of-words, skip-gram, and GloVe word embedding algorithms.","For the evaluation of pretrained embeddings, we use popular intrinsic and extrinsic evaluation approaches.","The evaluation results reveal that continuous-bag-of-words and skip-gram perform better than GloVe and existing Sindhi fastText word embedding on both intrinsic and extrinsic evaluation approaches"],"url":"http://arxiv.org/abs/2408.15720v1"}
{"created":"2024-08-28 11:24:17","title":"Benchmarking ML Approaches to UWB-Based Range-Only Posture Recognition for Human Robot-Interaction","abstract":"Human pose estimation involves detecting and tracking the positions of various body parts using input data from sources such as images, videos, or motion and inertial sensors. This paper presents a novel approach to human pose estimation using machine learning algorithms to predict human posture and translate them into robot motion commands using ultra-wideband (UWB) nodes, as an alternative to motion sensors. The study utilizes five UWB sensors implemented on the human body to enable the classification of still poses and more robust posture recognition. This approach ensures effective posture recognition across a variety of subjects. These range measurements serve as input features for posture prediction models, which are implemented and compared for accuracy. For this purpose, machine learning algorithms including K-Nearest Neighbors (KNN), Support Vector Machine (SVM), and deep Multi-Layer Perceptron (MLP) neural network are employed and compared in predicting corresponding postures. We demonstrate the proposed approach for real-time control of different mobile/aerial robots with inference implemented in a ROS 2 node. Experimental results demonstrate the efficacy of the approach, showcasing successful prediction of human posture and corresponding robot movements with high accuracy.","sentences":["Human pose estimation involves detecting and tracking the positions of various body parts using input data from sources such as images, videos, or motion and inertial sensors.","This paper presents a novel approach to human pose estimation using machine learning algorithms to predict human posture and translate them into robot motion commands using ultra-wideband (UWB) nodes, as an alternative to motion sensors.","The study utilizes five UWB sensors implemented on the human body to enable the classification of still poses and more robust posture recognition.","This approach ensures effective posture recognition across a variety of subjects.","These range measurements serve as input features for posture prediction models, which are implemented and compared for accuracy.","For this purpose, machine learning algorithms including K-Nearest Neighbors (KNN), Support Vector Machine (SVM), and deep Multi-Layer Perceptron (MLP) neural network are employed and compared in predicting corresponding postures.","We demonstrate the proposed approach for real-time control of different mobile/aerial robots with inference implemented in a ROS 2 node.","Experimental results demonstrate the efficacy of the approach, showcasing successful prediction of human posture and corresponding robot movements with high accuracy."],"url":"http://arxiv.org/abs/2408.15717v1"}
{"created":"2024-08-28 11:21:33","title":"Autoregressive model path dependence near Ising criticality","abstract":"Autoregressive models are a class of generative model that probabilistically predict the next output of a sequence based on previous inputs. The autoregressive sequence is by definition one-dimensional (1D), which is natural for language tasks and hence an important component of modern architectures like recurrent neural networks (RNNs) and transformers. However, when language models are used to predict outputs on physical systems that are not intrinsically 1D, the question arises of which choice of autoregressive sequence -- if any -- is optimal. In this paper, we study the reconstruction of critical correlations in the two-dimensional (2D) Ising model, using RNNs and transformers trained on binary spin data obtained near the thermal phase transition. We compare the training performance for a number of different 1D autoregressive sequences imposed on finite-size 2D lattices. We find that paths with long 1D segments are more efficient at training the autoregressive models compared to space-filling curves that better preserve the 2D locality. Our results illustrate the potential importance in choosing the optimal autoregressive sequence ordering when training modern language models for tasks in physics.","sentences":["Autoregressive models are a class of generative model that probabilistically predict the next output of a sequence based on previous inputs.","The autoregressive sequence is by definition one-dimensional (1D), which is natural for language tasks and hence an important component of modern architectures like recurrent neural networks (RNNs) and transformers.","However, when language models are used to predict outputs on physical systems that are not intrinsically 1D, the question arises of which choice of autoregressive sequence -- if any -- is optimal.","In this paper, we study the reconstruction of critical correlations in the two-dimensional (2D) Ising model, using RNNs and transformers trained on binary spin data obtained near the thermal phase transition.","We compare the training performance for a number of different 1D autoregressive sequences imposed on finite-size 2D lattices.","We find that paths with long 1D segments are more efficient at training the autoregressive models compared to space-filling curves that better preserve the 2D locality.","Our results illustrate the potential importance in choosing the optimal autoregressive sequence ordering when training modern language models for tasks in physics."],"url":"http://arxiv.org/abs/2408.15715v1"}
{"created":"2024-08-28 11:02:23","title":"Evaluating Model Robustness Using Adaptive Sparse L0 Regularization","abstract":"Deep Neural Networks have demonstrated remarkable success in various domains but remain susceptible to adversarial examples, which are slightly altered inputs designed to induce misclassification. While adversarial attacks typically optimize under Lp norm constraints, attacks based on the L0 norm, prioritising input sparsity, are less studied due to their complex and non convex nature. These sparse adversarial examples challenge existing defenses by altering a minimal subset of features, potentially uncovering more subtle DNN weaknesses. However, the current L0 norm attack methodologies face a trade off between accuracy and efficiency either precise but computationally intense or expedient but imprecise. This paper proposes a novel, scalable, and effective approach to generate adversarial examples based on the L0 norm, aimed at refining the robustness evaluation of DNNs against such perturbations.","sentences":["Deep Neural Networks have demonstrated remarkable success in various domains but remain susceptible to adversarial examples, which are slightly altered inputs designed to induce misclassification.","While adversarial attacks typically optimize under Lp norm constraints, attacks based on the L0 norm, prioritising input sparsity, are less studied due to their complex and non convex nature.","These sparse adversarial examples challenge existing defenses by altering a minimal subset of features, potentially uncovering more subtle DNN weaknesses.","However, the current L0 norm attack methodologies face a trade off between accuracy and efficiency either precise but computationally intense or expedient but imprecise.","This paper proposes a novel, scalable, and effective approach to generate adversarial examples based on the L0 norm, aimed at refining the robustness evaluation of DNNs against such perturbations."],"url":"http://arxiv.org/abs/2408.15702v1"}
{"created":"2024-08-28 10:51:18","title":"Comparing diversity, negativity, and stereotypes in Chinese-language AI technologies: a case study on Baidu, Ernie and Qwen","abstract":"Large Language Models (LLMs) and search engines have the potential to perpetuate biases and stereotypes by amplifying existing prejudices in their training data and algorithmic processes, thereby influencing public perception and decision-making. While most work has focused on Western-centric AI technologies, we study Chinese-based tools by investigating social biases embedded in the major Chinese search engine, Baidu, and two leading LLMs, Ernie and Qwen. Leveraging a dataset of 240 social groups across 13 categories describing Chinese society, we collect over 30k views encoded in the aforementioned tools by prompting them for candidate words describing such groups. We find that language models exhibit a larger variety of embedded views compared to the search engine, although Baidu and Qwen generate negative content more often than Ernie. We also find a moderate prevalence of stereotypes embedded in the language models, many of which potentially promote offensive and derogatory views. Our work highlights the importance of promoting fairness and inclusivity in AI technologies with a global perspective.","sentences":["Large Language Models (LLMs) and search engines have the potential to perpetuate biases and stereotypes by amplifying existing prejudices in their training data and algorithmic processes, thereby influencing public perception and decision-making.","While most work has focused on Western-centric AI technologies, we study Chinese-based tools by investigating social biases embedded in the major Chinese search engine, Baidu, and two leading LLMs, Ernie and Qwen.","Leveraging a dataset of 240 social groups across 13 categories describing Chinese society, we collect over 30k views encoded in the aforementioned tools by prompting them for candidate words describing such groups.","We find that language models exhibit a larger variety of embedded views compared to the search engine, although Baidu and Qwen generate negative content more often than Ernie.","We also find a moderate prevalence of stereotypes embedded in the language models, many of which potentially promote offensive and derogatory views.","Our work highlights the importance of promoting fairness and inclusivity in AI technologies with a global perspective."],"url":"http://arxiv.org/abs/2408.15696v1"}
{"created":"2024-08-28 10:33:00","title":"Synthetic Forehead-creases Biometric Generation for Reliable User Verification","abstract":"Recent studies have emphasized the potential of forehead-crease patterns as an alternative for face, iris, and periocular recognition, presenting contactless and convenient solutions, particularly in situations where faces are covered by surgical masks. However, collecting forehead data presents challenges, including cost and time constraints, as developing and optimizing forehead verification methods requires a substantial number of high-quality images. To tackle these challenges, the generation of synthetic biometric data has gained traction due to its ability to protect privacy while enabling effective training of deep learning-based biometric verification methods. In this paper, we present a new framework to synthesize forehead-crease image data while maintaining important features, such as uniqueness and realism. The proposed framework consists of two main modules: a Subject-Specific Generation Module (SSGM), based on an image-to-image Brownian Bridge Diffusion Model (BBDM), which learns a one-to-many mapping between image pairs to generate identity-aware synthetic forehead creases corresponding to real subjects, and a Subject-Agnostic Generation Module (SAGM), which samples new synthetic identities with assistance from the SSGM. We evaluate the diversity and realism of the generated forehead-crease images primarily using the Fr\\'echet Inception Distance (FID) and the Structural Similarity Index Measure (SSIM). In addition, we assess the utility of synthetically generated forehead-crease images using a forehead-crease verification system (FHCVS). The results indicate an improvement in the verification accuracy of the FHCVS by utilizing synthetic data.","sentences":["Recent studies have emphasized the potential of forehead-crease patterns as an alternative for face, iris, and periocular recognition, presenting contactless and convenient solutions, particularly in situations where faces are covered by surgical masks.","However, collecting forehead data presents challenges, including cost and time constraints, as developing and optimizing forehead verification methods requires a substantial number of high-quality images.","To tackle these challenges, the generation of synthetic biometric data has gained traction due to its ability to protect privacy while enabling effective training of deep learning-based biometric verification methods.","In this paper, we present a new framework to synthesize forehead-crease image data while maintaining important features, such as uniqueness and realism.","The proposed framework consists of two main modules: a Subject-Specific Generation Module (SSGM), based on an image-to-image Brownian Bridge Diffusion Model (BBDM), which learns a one-to-many mapping between image pairs to generate identity-aware synthetic forehead creases corresponding to real subjects, and a Subject-Agnostic Generation Module (SAGM), which samples new synthetic identities with assistance from the SSGM.","We evaluate the diversity and realism of the generated forehead-crease images primarily using the Fr\\'echet Inception Distance (FID) and the Structural Similarity Index Measure (SSIM).","In addition, we assess the utility of synthetically generated forehead-crease images using a forehead-crease verification system (FHCVS).","The results indicate an improvement in the verification accuracy of the FHCVS by utilizing synthetic data."],"url":"http://arxiv.org/abs/2408.15693v1"}
{"created":"2024-08-28 10:25:36","title":"PDSR: A Privacy-Preserving Diversified Service Recommendation Method on Distributed Data","abstract":"The last decade has witnessed a tremendous growth of service computing, while efficient service recommendation methods are desired to recommend high-quality services to users. It is well known that collaborative filtering is one of the most popular methods for service recommendation based on QoS, and many existing proposals focus on improving recommendation accuracy, i.e., recommending high-quality redundant services. Nevertheless, users may have different requirements on QoS, and hence diversified recommendation has been attracting increasing attention in recent years to fulfill users' diverse demands and to explore potential services. Unfortunately, the recommendation performances relies on a large volume of data (e.g., QoS data), whereas the data may be distributed across multiple platforms. Therefore, to enable data sharing across the different platforms for diversified service recommendation, we propose a Privacy-preserving Diversified Service Recommendation (PDSR) method. Specifically, we innovate in leveraging the Locality-Sensitive Hashing (LSH) mechanism such that privacy-preserved data sharing across different platforms is enabled to construct a service similarity graph. Based on the similarity graph, we propose a novel accuracy-diversity metric and design a $2$-approximation algorithm to select $K$ services to recommend by maximizing the accuracy-diversity measure. Extensive experiments on real datasets are conducted to verify the efficacy of our PDSR method.","sentences":["The last decade has witnessed a tremendous growth of service computing, while efficient service recommendation methods are desired to recommend high-quality services to users.","It is well known that collaborative filtering is one of the most popular methods for service recommendation based on QoS, and many existing proposals focus on improving recommendation accuracy, i.e., recommending high-quality redundant services.","Nevertheless, users may have different requirements on QoS, and hence diversified recommendation has been attracting increasing attention in recent years to fulfill users' diverse demands and to explore potential services.","Unfortunately, the recommendation performances relies on a large volume of data (e.g., QoS data), whereas the data may be distributed across multiple platforms.","Therefore, to enable data sharing across the different platforms for diversified service recommendation, we propose a Privacy-preserving Diversified Service Recommendation (PDSR) method.","Specifically, we innovate in leveraging the Locality-Sensitive Hashing (LSH) mechanism such that privacy-preserved data sharing across different platforms is enabled to construct a service similarity graph.","Based on the similarity graph, we propose a novel accuracy-diversity metric and design a $2$-approximation algorithm to select $K$ services to recommend by maximizing the accuracy-diversity measure.","Extensive experiments on real datasets are conducted to verify the efficacy of our PDSR method."],"url":"http://arxiv.org/abs/2408.15688v1"}
{"created":"2024-08-28 10:22:05","title":"Navigating the Future of Education: Educators' Insights on AI Integration and Challenges in Greece, Hungary, Latvia, Ireland and Armenia","abstract":"Understanding teachers' perspectives on AI in Education (AIEd) is crucial for its effective integration into the educational framework. This paper aims to explore how teachers currently use AI and how it can enhance the educational process. We conducted a cross-national study spanning Greece, Hungary, Latvia, Ireland, and Armenia, surveying 1754 educators through an online questionnaire, addressing three research questions. Our first research question examines educators' understanding of AIEd, their skepticism, and its integration within schools. Most educators report a solid understanding of AI and acknowledge its potential risks. AIEd is primarily used for educator support and engaging students. However, concerns exist about AI's impact on fostering critical thinking and exposing students to biased data. The second research question investigates student engagement with AI tools from educators' perspectives. Teachers indicate that students use AI mainly to manage their academic workload, while outside school, AI tools are primarily used for entertainment. The third research question addresses future implications of AI in education. Educators are optimistic about AI's potential to enhance educational processes, particularly through personalized learning experiences. Nonetheless, they express significant concerns about AI's impact on cultivating critical thinking and ethical issues related to potential misuse. There is a strong emphasis on the need for professional development through training seminars, workshops, and online courses to integrate AI effectively into teaching practices. Overall, the findings highlight a cautious optimism among educators regarding AI in education, alongside a clear demand for targeted professional development to address concerns and enhance skills in using AI tools.","sentences":["Understanding teachers' perspectives on AI in Education (AIEd) is crucial for its effective integration into the educational framework.","This paper aims to explore how teachers currently use AI and how it can enhance the educational process.","We conducted a cross-national study spanning Greece, Hungary, Latvia, Ireland, and Armenia, surveying 1754 educators through an online questionnaire, addressing three research questions.","Our first research question examines educators' understanding of AIEd, their skepticism, and its integration within schools.","Most educators report a solid understanding of AI and acknowledge its potential risks.","AIEd is primarily used for educator support and engaging students.","However, concerns exist about AI's impact on fostering critical thinking and exposing students to biased data.","The second research question investigates student engagement with AI tools from educators' perspectives.","Teachers indicate that students use AI mainly to manage their academic workload, while outside school, AI tools are primarily used for entertainment.","The third research question addresses future implications of AI in education.","Educators are optimistic about AI's potential to enhance educational processes, particularly through personalized learning experiences.","Nonetheless, they express significant concerns about AI's impact on cultivating critical thinking and ethical issues related to potential misuse.","There is a strong emphasis on the need for professional development through training seminars, workshops, and online courses to integrate AI effectively into teaching practices.","Overall, the findings highlight a cautious optimism among educators regarding AI in education, alongside a clear demand for targeted professional development to address concerns and enhance skills in using AI tools."],"url":"http://arxiv.org/abs/2408.15686v1"}
{"created":"2024-08-28 10:07:17","title":"Deep Learning Based Speckle Filtering for Polarimetric SAR Images. Application to Sentinel-1","abstract":"Speckle suppression in synthetic aperture radar (SAR) images is a key processing step which continues to be a research topic. A wide variety of methods, using either spatially-based approaches or transform-based strategies, have been developed and have shown to provide outstanding results. However, recent advances in deep learning techniques and their application to SAR image despeckling have been demonstrated to offer state-of-the-art results. Unfortunately, they have been mostly applied to single-polarimetric images. The extension of a deep learning-based approach for speckle removal to polarimetric SAR (PolSAR) images is complicated because of the complex nature of the measured covariance matrices for every image pixel, the properties of which must be preserved during filtering. In this work, we propose a complete framework to remove speckle in polarimetric SAR images using a convolutional neural network. The methodology includes a reversible transformation of the original complex covariance matrix to obtain a set of real-valued intensity bands which are fed to the neural network. In addition, the proposed method includes a change detection strategy to avoid the neural network to learn erroneous features in areas strongly affected by temporal changes, so that the network only learns the underlying speckle component present in the data. The method is implemented and tested with dual-polarimetric images acquired by Sentinel-1. Experiments show that the proposed approach offers exceptional results in both speckle reduction and resolution preservation. More importantly, it is also shown that the neural network is not generating artifacts or introducing bias in the filtered images, making them suitable for further polarimetric processing and exploitation.","sentences":["Speckle suppression in synthetic aperture radar (SAR) images is a key processing step which continues to be a research topic.","A wide variety of methods, using either spatially-based approaches or transform-based strategies, have been developed and have shown to provide outstanding results.","However, recent advances in deep learning techniques and their application to SAR image despeckling have been demonstrated to offer state-of-the-art results.","Unfortunately, they have been mostly applied to single-polarimetric images.","The extension of a deep learning-based approach for speckle removal to polarimetric SAR (PolSAR) images is complicated because of the complex nature of the measured covariance matrices for every image pixel, the properties of which must be preserved during filtering.","In this work, we propose a complete framework to remove speckle in polarimetric SAR images using a convolutional neural network.","The methodology includes a reversible transformation of the original complex covariance matrix to obtain a set of real-valued intensity bands which are fed to the neural network.","In addition, the proposed method includes a change detection strategy to avoid the neural network to learn erroneous features in areas strongly affected by temporal changes, so that the network only learns the underlying speckle component present in the data.","The method is implemented and tested with dual-polarimetric images acquired by Sentinel-1.","Experiments show that the proposed approach offers exceptional results in both speckle reduction and resolution preservation.","More importantly, it is also shown that the neural network is not generating artifacts or introducing bias in the filtered images, making them suitable for further polarimetric processing and exploitation."],"url":"http://arxiv.org/abs/2408.15678v2"}
{"created":"2024-08-28 09:40:40","title":"Towards reliable respiratory disease diagnosis based on cough sounds and vision transformers","abstract":"Recent advancements in deep learning techniques have sparked performance boosts in various real-world applications including disease diagnosis based on multi-modal medical data. Cough sound data-based respiratory disease (e.g., COVID-19 and Chronic Obstructive Pulmonary Disease) diagnosis has also attracted much attention. However, existing works usually utilise traditional machine learning or deep models of moderate scales. On the other hand, the developed approaches are trained and evaluated on small-scale data due to the difficulty of curating and annotating clinical data on scale. To address these issues in prior works, we create a unified framework to evaluate various deep models from lightweight Convolutional Neural Networks (e.g., ResNet18) to modern vision transformers and compare their performance in respiratory disease classification. Based on the observations from such an extensive empirical study, we propose a novel approach to cough-based disease classification based on both self-supervised and supervised learning on a large-scale cough data set. Experimental results demonstrate our proposed approach outperforms prior arts consistently on two benchmark datasets for COVID-19 diagnosis and a proprietary dataset for COPD/non-COPD classification with an AUROC of 92.5%.","sentences":["Recent advancements in deep learning techniques have sparked performance boosts in various real-world applications including disease diagnosis based on multi-modal medical data.","Cough sound data-based respiratory disease (e.g., COVID-19 and Chronic Obstructive Pulmonary Disease) diagnosis has also attracted much attention.","However, existing works usually utilise traditional machine learning or deep models of moderate scales.","On the other hand, the developed approaches are trained and evaluated on small-scale data due to the difficulty of curating and annotating clinical data on scale.","To address these issues in prior works, we create a unified framework to evaluate various deep models from lightweight Convolutional Neural Networks (e.g., ResNet18) to modern vision transformers and compare their performance in respiratory disease classification.","Based on the observations from such an extensive empirical study, we propose a novel approach to cough-based disease classification based on both self-supervised and supervised learning on a large-scale cough data set.","Experimental results demonstrate our proposed approach outperforms prior arts consistently on two benchmark datasets for COVID-19 diagnosis and a proprietary dataset for COPD/non-COPD classification with an AUROC of 92.5%."],"url":"http://arxiv.org/abs/2408.15667v1"}
{"created":"2024-08-28 09:31:45","title":"Agricultural On-Demand Networks for 6G enabled by THz Communication","abstract":"The transforming process in the scope of agriculture towards Smart Agriculture is an essential step to fulfill growing demands in respect to nourishment. Crucial challenges include establishing robust wireless communication in rural areas, enabling collaboration among agricultural machines, and integrating artificial intelligence into farming practices. Addressing these challenges necessitates a consistent communication system, with wireless communication emerging as a key enabler. Cellular technologies, as 5G and its successor 6G, can offer a comprehensive solution here. Leveraging technologies following the ITU-R M. 2160 recommendation like THz communication, low-latency wireless AI, and embedded sensing, can provide a flexible and energy-efficient infrastructure. This paper introduces on-demand networks based on the OpenRAN approach and a 7.2 functional split. By implementing THz front-hauling between components, a flexible application of 5G or future 6G networks can be realized. Experiments demonstrate that THz communication is suitable for data transmission over the eCPRI interface, particularly in terms of data rate, thereby reducing the need for wired alternatives such as fiber optic cables. Furthermore, limitations such as limited range are discussed, and possible initial solutions are presented. The integration of the OpenRAN standard further enhances flexibility, which is crucial in dynamic agricultural environments. This research contributes to the ongoing discourse on the transformative potential of 6G-enabled wireless communication in shaping the future of smart agriculture.","sentences":["The transforming process in the scope of agriculture towards Smart Agriculture is an essential step to fulfill growing demands in respect to nourishment.","Crucial challenges include establishing robust wireless communication in rural areas, enabling collaboration among agricultural machines, and integrating artificial intelligence into farming practices.","Addressing these challenges necessitates a consistent communication system, with wireless communication emerging as a key enabler.","Cellular technologies, as 5G and its successor 6G, can offer a comprehensive solution here.","Leveraging technologies following the ITU-R M. 2160 recommendation like THz communication, low-latency wireless AI, and embedded sensing, can provide a flexible and energy-efficient infrastructure.","This paper introduces on-demand networks based on the OpenRAN approach and a 7.2 functional split.","By implementing THz front-hauling between components, a flexible application of 5G or future 6G networks can be realized.","Experiments demonstrate that THz communication is suitable for data transmission over the eCPRI interface, particularly in terms of data rate, thereby reducing the need for wired alternatives such as fiber optic cables.","Furthermore, limitations such as limited range are discussed, and possible initial solutions are presented.","The integration of the OpenRAN standard further enhances flexibility, which is crucial in dynamic agricultural environments.","This research contributes to the ongoing discourse on the transformative potential of 6G-enabled wireless communication in shaping the future of smart agriculture."],"url":"http://arxiv.org/abs/2408.15665v1"}
{"created":"2024-08-28 09:19:09","title":"An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation","abstract":"Large Language Models (LLMs) have recently advanced many applications on software engineering tasks, particularly the potential for code generation. Among contemporary challenges, code generated by LLMs often suffers from inaccuracies and hallucinations, requiring external inputs to correct. One recent strategy to fix these issues is to refine the code generated from LLMs using the input from the model itself (self-augmented). In this work, we proposed a novel method, namely CoT-SelfEvolve. CoT-SelfEvolve iteratively and automatically refines code through a self-correcting process, guided by a chain of thought constructed from real-world programming problem feedback. Focusing on data science code, including Python libraries such as NumPy and Pandas, our evaluations on the DS-1000 dataset demonstrate that CoT-SelfEvolve significantly outperforms existing models in solving complex problems. The framework shows substantial improvements in both initial code generation and subsequent iterations, with the model's accuracy increasing significantly with each additional iteration. This highlights the effectiveness of using chain-of-thought prompting to address complexities revealed by program executor traceback error messages. We also discuss how CoT-SelfEvolve can be integrated into continuous software engineering environments, providing a practical solution for improving LLM-based code generation.","sentences":["Large Language Models (LLMs) have recently advanced many applications on software engineering tasks, particularly the potential for code generation.","Among contemporary challenges, code generated by LLMs often suffers from inaccuracies and hallucinations, requiring external inputs to correct.","One recent strategy to fix these issues is to refine the code generated from LLMs using the input from the model itself (self-augmented).","In this work, we proposed a novel method, namely CoT-SelfEvolve.","CoT-SelfEvolve iteratively and automatically refines code through a self-correcting process, guided by a chain of thought constructed from real-world programming problem feedback.","Focusing on data science code, including Python libraries such as NumPy and Pandas, our evaluations on the DS-1000 dataset demonstrate that CoT-SelfEvolve significantly outperforms existing models in solving complex problems.","The framework shows substantial improvements in both initial code generation and subsequent iterations, with the model's accuracy increasing significantly with each additional iteration.","This highlights the effectiveness of using chain-of-thought prompting to address complexities revealed by program executor traceback error messages.","We also discuss how CoT-SelfEvolve can be integrated into continuous software engineering environments, providing a practical solution for improving LLM-based code generation."],"url":"http://arxiv.org/abs/2408.15658v1"}
{"created":"2024-08-28 09:18:36","title":"TeFF: Tracking-enhanced Forgetting-free Few-shot 3D LiDAR Semantic Segmentation","abstract":"In autonomous driving, 3D LiDAR plays a crucial role in understanding the vehicle's surroundings. However, the newly emerged, unannotated objects presents few-shot learning problem for semantic segmentation. This paper addresses the limitations of current few-shot semantic segmentation by exploiting the temporal continuity of LiDAR data. Employing a tracking model to generate pseudo-ground-truths from a sequence of LiDAR frames, our method significantly augments the dataset, enhancing the model's ability to learn on novel classes. However, this approach introduces a data imbalance biased to novel data that presents a new challenge of catastrophic forgetting. To mitigate this, we incorporate LoRA, a technique that reduces the number of trainable parameters, thereby preserving the model's performance on base classes while improving its adaptability to novel classes. This work represents a significant step forward in few-shot 3D LiDAR semantic segmentation for autonomous driving. Our code is available at https://github.com/junbao-zhou/Track-no-forgetting.","sentences":["In autonomous driving, 3D LiDAR plays a crucial role in understanding the vehicle's surroundings.","However, the newly emerged, unannotated objects presents few-shot learning problem for semantic segmentation.","This paper addresses the limitations of current few-shot semantic segmentation by exploiting the temporal continuity of LiDAR data.","Employing a tracking model to generate pseudo-ground-truths from a sequence of LiDAR frames, our method significantly augments the dataset, enhancing the model's ability to learn on novel classes.","However, this approach introduces a data imbalance biased to novel data that presents a new challenge of catastrophic forgetting.","To mitigate this, we incorporate LoRA, a technique that reduces the number of trainable parameters, thereby preserving the model's performance on base classes while improving its adaptability to novel classes.","This work represents a significant step forward in few-shot 3D LiDAR semantic segmentation for autonomous driving.","Our code is available at https://github.com/junbao-zhou/Track-no-forgetting."],"url":"http://arxiv.org/abs/2408.15657v1"}
{"created":"2024-08-28 09:17:25","title":"Realigned Softmax Warping for Deep Metric Learning","abstract":"Deep Metric Learning (DML) loss functions traditionally aim to control the forces of separability and compactness within an embedding space so that the same class data points are pulled together and different class ones are pushed apart. Within the context of DML, a softmax operation will typically normalize distances into a probability for optimization, thus coupling all the push/pull forces together. This paper proposes a potential new class of loss functions that operate within a euclidean domain and aim to take full advantage of the coupled forces governing embedding space formation under a softmax. These forces of compactness and separability can be boosted or mitigated within controlled locations at will by using a warping function. In this work, we provide a simple example of a warping function and use it to achieve competitive, state-of-the-art results on various metric learning benchmarks.","sentences":["Deep Metric Learning (DML) loss functions traditionally aim to control the forces of separability and compactness within an embedding space so that the same class data points are pulled together and different class ones are pushed apart.","Within the context of DML, a softmax operation will typically normalize distances into a probability for optimization, thus coupling all the push/pull forces together.","This paper proposes a potential new class of loss functions that operate within a euclidean domain and aim to take full advantage of the coupled forces governing embedding space formation under a softmax.","These forces of compactness and separability can be boosted or mitigated within controlled locations at will by using a warping function.","In this work, we provide a simple example of a warping function and use it to achieve competitive, state-of-the-art results on various metric learning benchmarks."],"url":"http://arxiv.org/abs/2408.15656v1"}
{"created":"2024-08-28 08:53:20","title":"Can SAR improve RSVQA performance?","abstract":"Remote sensing visual question answering (RSVQA) has been involved in several research in recent years, leading to an increase in new methods. RSVQA automatically extracts information from satellite images, so far only optical, and a question to automatically search for the answer in the image and provide it in a textual form. In our research, we study whether Synthetic Aperture Radar (SAR) images can be beneficial to this field. We divide our study into three phases which include classification methods and VQA. In the first one, we explore the classification results of SAR alone and investigate the best method to extract information from SAR data. Then, we study the combination of SAR and optical data. In the last phase, we investigate how SAR images and a combination of different modalities behave in RSVQA compared to a method only using optical images. We conclude that adding the SAR modality leads to improved performances, although further research on using SAR data to automatically answer questions is needed as well as more balanced datasets.","sentences":["Remote sensing visual question answering (RSVQA) has been involved in several research in recent years, leading to an increase in new methods.","RSVQA automatically extracts information from satellite images, so far only optical, and a question to automatically search for the answer in the image and provide it in a textual form.","In our research, we study whether Synthetic Aperture Radar (SAR) images can be beneficial to this field.","We divide our study into three phases which include classification methods and VQA.","In the first one, we explore the classification results of SAR alone and investigate the best method to extract information from SAR data.","Then, we study the combination of SAR and optical data.","In the last phase, we investigate how SAR images and a combination of different modalities behave in RSVQA compared to a method only using optical images.","We conclude that adding the SAR modality leads to improved performances, although further research on using SAR data to automatically answer questions is needed as well as more balanced datasets."],"url":"http://arxiv.org/abs/2408.15642v1"}
{"created":"2024-08-28 08:50:00","title":"Semantic and goal-oriented edge computing for satellite Earth Observation","abstract":"The integration of Semantic Communications (SemCom) and edge computing in space networks enables the optimal allocation of the scarce energy, computing, and communication resources for data-intensive applications. We use Earth Observation (EO) as a canonical functionality of satellites and review its main characteristics and challenges. We identify the potential of the space segment, represented by a low Earth orbit (LEO) satellite constellation, to serve as an edge layer for distributed intelligence. Based on that, propose a system architecture that supports semantic and goal-oriented applications for image reconstruction and object detection and localization. The simulation results show the intricate trade-offs among energy, time, and task-performance using a real dataset and State-of-the-Art (SoA) processing and communication parameters.","sentences":["The integration of Semantic Communications (SemCom) and edge computing in space networks enables the optimal allocation of the scarce energy, computing, and communication resources for data-intensive applications.","We use Earth Observation (EO) as a canonical functionality of satellites and review its main characteristics and challenges.","We identify the potential of the space segment, represented by a low Earth orbit (LEO) satellite constellation, to serve as an edge layer for distributed intelligence.","Based on that, propose a system architecture that supports semantic and goal-oriented applications for image reconstruction and object detection and localization.","The simulation results show the intricate trade-offs among energy, time, and task-performance using a real dataset and State-of-the-Art (SoA) processing and communication parameters."],"url":"http://arxiv.org/abs/2408.15639v1"}
{"created":"2024-08-28 08:44:58","title":"Transfer Learning from Simulated to Real Scenes for Monocular 3D Object Detection","abstract":"Accurately detecting 3D objects from monocular images in dynamic roadside scenarios remains a challenging problem due to varying camera perspectives and unpredictable scene conditions. This paper introduces a two-stage training strategy to address these challenges. Our approach initially trains a model on the large-scale synthetic dataset, RoadSense3D, which offers a diverse range of scenarios for robust feature learning. Subsequently, we fine-tune the model on a combination of real-world datasets to enhance its adaptability to practical conditions. Experimental results of the Cube R-CNN model on challenging public benchmarks show a remarkable improvement in detection performance, with a mean average precision rising from 0.26 to 12.76 on the TUM Traffic A9 Highway dataset and from 2.09 to 6.60 on the DAIR-V2X-I dataset when performing transfer learning. Code, data, and qualitative video results are available on the project website: https://roadsense3d.github.io.","sentences":["Accurately detecting 3D objects from monocular images in dynamic roadside scenarios remains a challenging problem due to varying camera perspectives and unpredictable scene conditions.","This paper introduces a two-stage training strategy to address these challenges.","Our approach initially trains a model on the large-scale synthetic dataset, RoadSense3D, which offers a diverse range of scenarios for robust feature learning.","Subsequently, we fine-tune the model on a combination of real-world datasets to enhance its adaptability to practical conditions.","Experimental results of the Cube R-CNN model on challenging public benchmarks show a remarkable improvement in detection performance, with a mean average precision rising from 0.26 to 12.76 on the TUM Traffic A9 Highway dataset and from 2.09 to 6.60 on the DAIR-V2X-I dataset when performing transfer learning.","Code, data, and qualitative video results are available on the project website: https://roadsense3d.github.io."],"url":"http://arxiv.org/abs/2408.15637v1"}
{"created":"2024-08-28 08:25:41","title":"Can Visual Language Models Replace OCR-Based Visual Question Answering Pipelines in Production? A Case Study in Retail","abstract":"Most production-level deployments for Visual Question Answering (VQA) tasks are still build as processing pipelines of independent steps including image pre-processing, object- and text detection, Optical Character Recognition (OCR) and (mostly supervised) object classification. However, the recent advances in vision Foundation Models [25] and Vision Language Models (VLMs) [23] raise the question if these custom trained, multi-step approaches can be replaced with pre-trained, single-step VLMs. This paper analyzes the performance and limits of various VLMs in the context of VQA and OCR [5, 9, 12] tasks in a production-level scenario. Using data from the Retail-786k [10] dataset, we investigate the capabilities of pre-trained VLMs to answer detailed questions about advertised products in images. Our study includes two commercial models, GPT-4V [16] and GPT-4o [17], as well as four open-source models: InternVL [5], LLaVA 1.5 [12], LLaVA-NeXT [13], and CogAgent [9]. Our initial results show, that there is in general no big performance gap between open-source and commercial models. However, we observe a strong task dependent variance in VLM performance: while most models are able to answer questions regarding the product brand and price with high accuracy, they completely fail at the same time to correctly identity the specific product name or discount. This indicates the problem of VLMs to solve fine-grained classification tasks as well to model the more abstract concept of discounts.","sentences":["Most production-level deployments for Visual Question Answering (VQA) tasks are still build as processing pipelines of independent steps including image pre-processing, object- and text detection, Optical Character Recognition (OCR) and (mostly supervised) object classification.","However, the recent advances in vision Foundation Models [25] and Vision Language Models (VLMs)","[23] raise the question if these custom trained, multi-step approaches can be replaced with pre-trained, single-step VLMs.","This paper analyzes the performance and limits of various VLMs in the context of VQA and OCR [5, 9, 12] tasks in a production-level scenario.","Using data from the Retail-786k","[10] dataset, we investigate the capabilities of pre-trained VLMs to answer detailed questions about advertised products in images.","Our study includes two commercial models, GPT-4V","[16] and GPT-4o","[17], as well as four open-source models: InternVL","[5], LLaVA 1.5","[12], LLaVA-NeXT","[13], and CogAgent","[9].","Our initial results show, that there is in general no big performance gap between open-source and commercial models.","However, we observe a strong task dependent variance in VLM performance: while most models are able to answer questions regarding the product brand and price with high accuracy, they completely fail at the same time to correctly identity the specific product name or discount.","This indicates the problem of VLMs to solve fine-grained classification tasks as well to model the more abstract concept of discounts."],"url":"http://arxiv.org/abs/2408.15626v1"}
{"created":"2024-08-28 07:49:30","title":"On the Benefits of Visual Stabilization for Frame- and Event-based Perception","abstract":"Vision-based perception systems are typically exposed to large orientation changes in different robot applications. In such conditions, their performance might be compromised due to the inherent complexity of processing data captured under challenging motion. Integration of mechanical stabilizers to compensate for the camera rotation is not always possible due to the robot payload constraints. This paper presents a processing-based stabilization approach to compensate the camera's rotational motion both on events and on frames (i.e., images). Assuming that the camera's attitude is available, we evaluate the benefits of stabilization in two perception applications: feature tracking and estimating the translation component of the camera's ego-motion. The validation is performed using synthetic data and sequences from well-known event-based vision datasets. The experiments unveil that stabilization can improve feature tracking and camera ego-motion estimation accuracy in 27.37% and 34.82%, respectively. Concurrently, stabilization can reduce the processing time of computing the camera's linear velocity by at least 25%. Code is available at https://github.com/tub-rip/visual_stabilization","sentences":["Vision-based perception systems are typically exposed to large orientation changes in different robot applications.","In such conditions, their performance might be compromised due to the inherent complexity of processing data captured under challenging motion.","Integration of mechanical stabilizers to compensate for the camera rotation is not always possible due to the robot payload constraints.","This paper presents a processing-based stabilization approach to compensate the camera's rotational motion both on events and on frames (i.e., images).","Assuming that the camera's attitude is available, we evaluate the benefits of stabilization in two perception applications: feature tracking and estimating the translation component of the camera's ego-motion.","The validation is performed using synthetic data and sequences from well-known event-based vision datasets.","The experiments unveil that stabilization can improve feature tracking and camera ego-motion estimation accuracy in 27.37% and 34.82%, respectively.","Concurrently, stabilization can reduce the processing time of computing the camera's linear velocity by at least 25%.","Code is available at https://github.com/tub-rip/visual_stabilization"],"url":"http://arxiv.org/abs/2408.15602v1"}
{"created":"2024-08-28 07:48:39","title":"Exploring Selective Layer Fine-Tuning in Federated Learning","abstract":"Federated learning (FL) has emerged as a promising paradigm for fine-tuning foundation models using distributed data in a privacy-preserving manner. Under limited computational resources, clients often find it more practical to fine-tune a selected subset of layers, rather than the entire model, based on their task-specific data. In this study, we provide a thorough theoretical exploration of selective layer fine-tuning in FL, emphasizing a flexible approach that allows the clients to adjust their selected layers according to their local data and resources. We theoretically demonstrate that the layer selection strategy has a significant impact on model convergence in two critical aspects: the importance of selected layers and the heterogeneous choices across clients. Drawing from these insights, we further propose a strategic layer selection method that utilizes local gradients and regulates layer selections across clients. The extensive experiments on both image and text datasets demonstrate the effectiveness of the proposed strategy compared with several baselines, highlighting its advances in identifying critical layers that adapt to the client heterogeneity and training dynamics in FL.","sentences":["Federated learning (FL) has emerged as a promising paradigm for fine-tuning foundation models using distributed data in a privacy-preserving manner.","Under limited computational resources, clients often find it more practical to fine-tune a selected subset of layers, rather than the entire model, based on their task-specific data.","In this study, we provide a thorough theoretical exploration of selective layer fine-tuning in FL, emphasizing a flexible approach that allows the clients to adjust their selected layers according to their local data and resources.","We theoretically demonstrate that the layer selection strategy has a significant impact on model convergence in two critical aspects: the importance of selected layers and the heterogeneous choices across clients.","Drawing from these insights, we further propose a strategic layer selection method that utilizes local gradients and regulates layer selections across clients.","The extensive experiments on both image and text datasets demonstrate the effectiveness of the proposed strategy compared with several baselines, highlighting its advances in identifying critical layers that adapt to the client heterogeneity and training dynamics in FL."],"url":"http://arxiv.org/abs/2408.15600v1"}
{"created":"2024-08-28 07:36:20","title":"Skills Regularized Task Decomposition for Multi-task Offline Reinforcement Learning","abstract":"Reinforcement learning (RL) with diverse offline datasets can have the advantage of leveraging the relation of multiple tasks and the common skills learned across those tasks, hence allowing us to deal with real-world complex problems efficiently in a data-driven way. In offline RL where only offline data is used and online interaction with the environment is restricted, it is yet difficult to achieve the optimal policy for multiple tasks, especially when the data quality varies for the tasks. In this paper, we present a skill-based multi-task RL technique on heterogeneous datasets that are generated by behavior policies of different quality. To learn the shareable knowledge across those datasets effectively, we employ a task decomposition method for which common skills are jointly learned and used as guidance to reformulate a task in shared and achievable subtasks. In this joint learning, we use Wasserstein auto-encoder (WAE) to represent both skills and tasks on the same latent space and use the quality-weighted loss as a regularization term to induce tasks to be decomposed into subtasks that are more consistent with high-quality skills than others. To improve the performance of offline RL agents learned on the latent space, we also augment datasets with imaginary trajectories relevant to high-quality skills for each task. Through experiments, we show that our multi-task offline RL approach is robust to the mixed configurations of different-quality datasets and it outperforms other state-of-the-art algorithms for several robotic manipulation tasks and drone navigation tasks.","sentences":["Reinforcement learning (RL) with diverse offline datasets can have the advantage of leveraging the relation of multiple tasks and the common skills learned across those tasks, hence allowing us to deal with real-world complex problems efficiently in a data-driven way.","In offline RL where only offline data is used and online interaction with the environment is restricted, it is yet difficult to achieve the optimal policy for multiple tasks, especially when the data quality varies for the tasks.","In this paper, we present a skill-based multi-task RL technique on heterogeneous datasets that are generated by behavior policies of different quality.","To learn the shareable knowledge across those datasets effectively, we employ a task decomposition method for which common skills are jointly learned and used as guidance to reformulate a task in shared and achievable subtasks.","In this joint learning, we use Wasserstein auto-encoder (WAE) to represent both skills and tasks on the same latent space and use the quality-weighted loss as a regularization term to induce tasks to be decomposed into subtasks that are more consistent with high-quality skills than others.","To improve the performance of offline RL agents learned on the latent space, we also augment datasets with imaginary trajectories relevant to high-quality skills for each task.","Through experiments, we show that our multi-task offline RL approach is robust to the mixed configurations of different-quality datasets and it outperforms other state-of-the-art algorithms for several robotic manipulation tasks and drone navigation tasks."],"url":"http://arxiv.org/abs/2408.15593v1"}
{"created":"2024-08-28 07:31:32","title":"VFLIP: A Backdoor Defense for Vertical Federated Learning via Identification and Purification","abstract":"Vertical Federated Learning (VFL) focuses on handling vertically partitioned data over FL participants. Recent studies have discovered a significant vulnerability in VFL to backdoor attacks which specifically target the distinct characteristics of VFL. Therefore, these attacks may neutralize existing defense mechanisms designed primarily for Horizontal Federated Learning (HFL) and deep neural networks. In this paper, we present the first backdoor defense, called VFLIP, specialized for VFL. VFLIP employs the identification and purification techniques that operate at the inference stage, consequently improving the robustness against backdoor attacks to a great extent. VFLIP first identifies backdoor-triggered embeddings by adopting a participant-wise anomaly detection approach. Subsequently, VFLIP conducts purification which removes the embeddings identified as malicious and reconstructs all the embeddings based on the remaining embeddings. We conduct extensive experiments on CIFAR10, CINIC10, Imagenette, NUS-WIDE, and BankMarketing to demonstrate that VFLIP can effectively mitigate backdoor attacks in VFL. https://github.com/blingcho/VFLIP-esorics24","sentences":["Vertical Federated Learning (VFL) focuses on handling vertically partitioned data over FL participants.","Recent studies have discovered a significant vulnerability in VFL to backdoor attacks which specifically target the distinct characteristics of VFL.","Therefore, these attacks may neutralize existing defense mechanisms designed primarily for Horizontal Federated Learning (HFL) and deep neural networks.","In this paper, we present the first backdoor defense, called VFLIP, specialized for VFL.","VFLIP employs the identification and purification techniques that operate at the inference stage, consequently improving the robustness against backdoor attacks to a great extent.","VFLIP first identifies backdoor-triggered embeddings by adopting a participant-wise anomaly detection approach.","Subsequently, VFLIP conducts purification which removes the embeddings identified as malicious and reconstructs all the embeddings based on the remaining embeddings.","We conduct extensive experiments on CIFAR10, CINIC10, Imagenette, NUS-WIDE, and BankMarketing to demonstrate that VFLIP can effectively mitigate backdoor attacks in VFL.","https://github.com/blingcho/VFLIP-esorics24"],"url":"http://arxiv.org/abs/2408.15591v2"}
{"created":"2024-08-28 07:21:36","title":"Whisper-PMFA: Partial Multi-Scale Feature Aggregation for Speaker Verification using Whisper Models","abstract":"In this paper, Whisper, a large-scale pre-trained model for automatic speech recognition, is proposed to apply to speaker verification. A partial multi-scale feature aggregation (PMFA) approach is proposed based on a subset of Whisper encoder blocks to derive highly discriminative speaker embeddings.Experimental results demonstrate that using the middle to later blocks of the Whisper encoder keeps more speaker information. On the VoxCeleb1 and CN-Celeb1 datasets, our system achieves 1.42% and 8.23% equal error rates (EERs) respectively, receiving 0.58% and 1.81% absolute EER reductions over the ECAPA-TDNN baseline, and 0.46% and 0.97% over the ResNet34 baseline. Furthermore, our results indicate that using Whisper models trained on multilingual data can effectively enhance the model's robustness across languages. Finally, the low-rank adaptation approach is evaluated, which reduces the trainable model parameters by approximately 45 times while only slightly increasing EER by 0.2%.","sentences":["In this paper, Whisper, a large-scale pre-trained model for automatic speech recognition, is proposed to apply to speaker verification.","A partial multi-scale feature aggregation (PMFA) approach is proposed based on a subset of Whisper encoder blocks to derive highly discriminative speaker embeddings.","Experimental results demonstrate that using the middle to later blocks of the Whisper encoder keeps more speaker information.","On the VoxCeleb1 and CN-Celeb1 datasets, our system achieves 1.42% and 8.23% equal error rates (EERs) respectively, receiving 0.58% and 1.81% absolute EER reductions over the ECAPA-TDNN baseline, and 0.46% and 0.97% over the ResNet34 baseline.","Furthermore, our results indicate that using Whisper models trained on multilingual data can effectively enhance the model's robustness across languages.","Finally, the low-rank adaptation approach is evaluated, which reduces the trainable model parameters by approximately 45 times while only slightly increasing EER by 0.2%."],"url":"http://arxiv.org/abs/2408.15585v1"}
{"created":"2024-08-28 07:15:17","title":"PointEMRay: A Novel Efficient SBR Framework on Point Based Geometry","abstract":"The rapid computation of electromagnetic (EM) fields across various scenarios has long been a challenge, primarily due to the need for precise geometric models. The emergence of point cloud data offers a potential solution to this issue. However, the lack of electromagnetic simulation algorithms optimized for point-based models remains a significant limitation. In this study, we propose PointEMRay, an innovative shooting and bouncing ray (SBR) framework designed explicitly for point-based geometries. To enable SBR on point clouds, we address two critical challenges: point-ray intersection (PRI) and multiple bounce computation (MBC). For PRI, we propose a screen-based method leveraging deep learning. Initially, we obtain coarse depth maps through ray tube tracing, which are then transformed by a neural network into dense depth maps, normal maps, and intersection masks, collectively referred to as geometric frame buffers (GFBs). For MBC, inspired by simultaneous localization and mapping (SLAM) techniques, we introduce a GFB-assisted approach. This involves aggregating GFBs from various observation angles and integrating them to recover the complete geometry. Subsequently, a ray tracing algorithm is applied to these GFBs to compute the scattering electromagnetic field. Numerical experiments demonstrate the superior performance of PointEMRay in terms of both accuracy and efficiency, including support for real-time simulation. To the best of our knowledge, this study represents the first attempt to develop an SBR framework specifically tailored for point-based models.","sentences":["The rapid computation of electromagnetic (EM) fields across various scenarios has long been a challenge, primarily due to the need for precise geometric models.","The emergence of point cloud data offers a potential solution to this issue.","However, the lack of electromagnetic simulation algorithms optimized for point-based models remains a significant limitation.","In this study, we propose PointEMRay, an innovative shooting and bouncing ray (SBR) framework designed explicitly for point-based geometries.","To enable SBR on point clouds, we address two critical challenges: point-ray intersection (PRI) and multiple bounce computation (MBC).","For PRI, we propose a screen-based method leveraging deep learning.","Initially, we obtain coarse depth maps through ray tube tracing, which are then transformed by a neural network into dense depth maps, normal maps, and intersection masks, collectively referred to as geometric frame buffers (GFBs).","For MBC, inspired by simultaneous localization and mapping (SLAM) techniques, we introduce a GFB-assisted approach.","This involves aggregating GFBs from various observation angles and integrating them to recover the complete geometry.","Subsequently, a ray tracing algorithm is applied to these GFBs to compute the scattering electromagnetic field.","Numerical experiments demonstrate the superior performance of PointEMRay in terms of both accuracy and efficiency, including support for real-time simulation.","To the best of our knowledge, this study represents the first attempt to develop an SBR framework specifically tailored for point-based models."],"url":"http://arxiv.org/abs/2408.15583v1"}
{"created":"2024-08-28 07:05:46","title":"Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection","abstract":"Detecting out-of-distribution inputs for visual recognition models has become critical in safe deep learning. This paper proposes a novel hierarchical visual category modeling scheme to separate out-of-distribution data from in-distribution data through joint representation learning and statistical modeling. We learn a mixture of Gaussian models for each in-distribution category. There are many Gaussian mixture models to model different visual categories. With these Gaussian models, we design an in-distribution score function by aggregating multiple Mahalanobis-based metrics. We don't use any auxiliary outlier data as training samples, which may hurt the generalization ability of out-of-distribution detection algorithms. We split the ImageNet-1k dataset into ten folds randomly. We use one fold as the in-distribution dataset and the others as out-of-distribution datasets to evaluate the proposed method. We also conduct experiments on seven popular benchmarks, including CIFAR, iNaturalist, SUN, Places, Textures, ImageNet-O, and OpenImage-O. Extensive experiments indicate that the proposed method outperforms state-of-the-art algorithms clearly. Meanwhile, we find that our visual representation has a competitive performance when compared with features learned by classical methods. These results demonstrate that the proposed method hasn't weakened the discriminative ability of visual recognition models and keeps high efficiency in detecting out-of-distribution samples.","sentences":["Detecting out-of-distribution inputs for visual recognition models has become critical in safe deep learning.","This paper proposes a novel hierarchical visual category modeling scheme to separate out-of-distribution data from in-distribution data through joint representation learning and statistical modeling.","We learn a mixture of Gaussian models for each in-distribution category.","There are many Gaussian mixture models to model different visual categories.","With these Gaussian models, we design an in-distribution score function by aggregating multiple Mahalanobis-based metrics.","We don't use any auxiliary outlier data as training samples, which may hurt the generalization ability of out-of-distribution detection algorithms.","We split the ImageNet-1k dataset into ten folds randomly.","We use one fold as the in-distribution dataset and the others as out-of-distribution datasets to evaluate the proposed method.","We also conduct experiments on seven popular benchmarks, including CIFAR, iNaturalist, SUN, Places, Textures, ImageNet-O, and OpenImage-O. Extensive experiments indicate that the proposed method outperforms state-of-the-art algorithms clearly.","Meanwhile, we find that our visual representation has a competitive performance when compared with features learned by classical methods.","These results demonstrate that the proposed method hasn't weakened the discriminative ability of visual recognition models and keeps high efficiency in detecting out-of-distribution samples."],"url":"http://arxiv.org/abs/2408.15580v1"}
{"created":"2024-08-28 06:50:09","title":"Affordable HPC: Leveraging Small Clusters for Big Data and Graph Computing","abstract":"This study explores strategies for academic researchers to optimize computational resources within limited budgets, focusing on building small, efficient computing clusters. It delves into the comparative costs of purchasing versus renting servers, guided by market research and economic theories on tiered pricing. The paper offers detailed insights into the selection and assembly of hardware components such as CPUs, GPUs, and motherboards tailored to specific research needs. It introduces innovative methods to mitigate the performance issues caused by PCIe switch bandwidth limitations in order to enhance GPU task scheduling. Furthermore, a Graph Neural Network (GNN) framework is proposed to analyze and optimize parallelism in computing networks.","sentences":["This study explores strategies for academic researchers to optimize computational resources within limited budgets, focusing on building small, efficient computing clusters.","It delves into the comparative costs of purchasing versus renting servers, guided by market research and economic theories on tiered pricing.","The paper offers detailed insights into the selection and assembly of hardware components such as CPUs, GPUs, and motherboards tailored to specific research needs.","It introduces innovative methods to mitigate the performance issues caused by PCIe switch bandwidth limitations in order to enhance GPU task scheduling.","Furthermore, a Graph Neural Network (GNN) framework is proposed to analyze and optimize parallelism in computing networks."],"url":"http://arxiv.org/abs/2408.15568v1"}
{"created":"2024-08-28 06:37:59","title":"TagOOD: A Novel Approach to Out-of-Distribution Detection via Vision-Language Representations and Class Center Learning","abstract":"Multimodal fusion, leveraging data like vision and language, is rapidly gaining traction. This enriched data representation improves performance across various tasks. Existing methods for out-of-distribution (OOD) detection, a critical area where AI models encounter unseen data in real-world scenarios, rely heavily on whole-image features. These image-level features can include irrelevant information that hinders the detection of OOD samples, ultimately limiting overall performance. In this paper, we propose \\textbf{TagOOD}, a novel approach for OOD detection that leverages vision-language representations to achieve label-free object feature decoupling from whole images. This decomposition enables a more focused analysis of object semantics, enhancing OOD detection performance. Subsequently, TagOOD trains a lightweight network on the extracted object features to learn representative class centers. These centers capture the central tendencies of IND object classes, minimizing the influence of irrelevant image features during OOD detection. Finally, our approach efficiently detects OOD samples by calculating distance-based metrics as OOD scores between learned centers and test samples. We conduct extensive experiments to evaluate TagOOD on several benchmark datasets and demonstrate its superior performance compared to existing OOD detection methods. This work presents a novel perspective for further exploration of multimodal information utilization in OOD detection, with potential applications across various tasks.","sentences":["Multimodal fusion, leveraging data like vision and language, is rapidly gaining traction.","This enriched data representation improves performance across various tasks.","Existing methods for out-of-distribution (OOD) detection, a critical area where AI models encounter unseen data in real-world scenarios, rely heavily on whole-image features.","These image-level features can include irrelevant information that hinders the detection of OOD samples, ultimately limiting overall performance.","In this paper, we propose \\textbf{TagOOD}, a novel approach for OOD detection that leverages vision-language representations to achieve label-free object feature decoupling from whole images.","This decomposition enables a more focused analysis of object semantics, enhancing OOD detection performance.","Subsequently, TagOOD trains a lightweight network on the extracted object features to learn representative class centers.","These centers capture the central tendencies of IND object classes, minimizing the influence of irrelevant image features during OOD detection.","Finally, our approach efficiently detects OOD samples by calculating distance-based metrics as OOD scores between learned centers and test samples.","We conduct extensive experiments to evaluate TagOOD on several benchmark datasets and demonstrate its superior performance compared to existing OOD detection methods.","This work presents a novel perspective for further exploration of multimodal information utilization in OOD detection, with potential applications across various tasks."],"url":"http://arxiv.org/abs/2408.15566v1"}
{"created":"2024-08-28 06:33:03","title":"SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models","abstract":"There is a growing trend of teaching large language models (LLMs) to solve mathematical problems through coding. Existing studies primarily focus on prompting powerful, closed-source models to generate seed training data followed by in-domain data augmentation, equipping LLMs with considerable capabilities for code-aided mathematical reasoning. However, continually training these models on augmented data derived from a few datasets such as GSM8K may impair their generalization abilities and restrict their effectiveness to a narrow range of question types. Conversely, the potential of improving such LLMs by leveraging large-scale, expert-written, diverse math question-answer pairs remains unexplored. To utilize these resources and tackle unique challenges such as code response assessment, we propose a novel paradigm that uses a code-based critic model to guide steps including question-code data construction, quality control, and complementary evaluation. We also explore different alignment algorithms with self-generated instruction/preference data to foster continuous improvement. Experiments across both in-domain (up to +5.7%) and out-of-domain (+4.4%) benchmarks in English and Chinese demonstrate the effectiveness of the proposed paradigm.","sentences":["There is a growing trend of teaching large language models (LLMs) to solve mathematical problems through coding.","Existing studies primarily focus on prompting powerful, closed-source models to generate seed training data followed by in-domain data augmentation, equipping LLMs with considerable capabilities for code-aided mathematical reasoning.","However, continually training these models on augmented data derived from a few datasets such as GSM8K may impair their generalization abilities and restrict their effectiveness to a narrow range of question types.","Conversely, the potential of improving such LLMs by leveraging large-scale, expert-written, diverse math question-answer pairs remains unexplored.","To utilize these resources and tackle unique challenges such as code response assessment, we propose a novel paradigm that uses a code-based critic model to guide steps including question-code data construction, quality control, and complementary evaluation.","We also explore different alignment algorithms with self-generated instruction/preference data to foster continuous improvement.","Experiments across both in-domain (up to +5.7%) and out-of-domain (+4.4%) benchmarks in English and Chinese demonstrate the effectiveness of the proposed paradigm."],"url":"http://arxiv.org/abs/2408.15565v1"}
{"created":"2024-08-28 06:28:20","title":"Order-preserving pattern mining with forgetting mechanism","abstract":"Order-preserving pattern (OPP) mining is a type of sequential pattern mining method in which a group of ranks of time series is used to represent an OPP. This approach can discover frequent trends in time series. Existing OPP mining algorithms consider data points at different time to be equally important; however, newer data usually have a more significant impact, while older data have a weaker impact. We therefore introduce the forgetting mechanism into OPP mining to reduce the importance of older data. This paper explores the mining of OPPs with forgetting mechanism (OPF) and proposes an algorithm called OPF-Miner that can discover frequent OPFs. OPF-Miner performs two tasks, candidate pattern generation and support calculation. In candidate pattern generation, OPF-Miner employs a maximal support priority strategy and a group pattern fusion strategy to avoid redundant pattern fusions. For support calculation, we propose an algorithm called support calculation with forgetting mechanism, which uses prefix and suffix pattern pruning strategies to avoid redundant support calculations. The experiments are conducted on nine datasets and 12 alternative algorithms. The results verify that OPF-Miner is superior to other competitive algorithms. More importantly, OPF-Miner yields good clustering performance for time series, since the forgetting mechanism is employed. All algorithms can be downloaded from https://github.com/wuc567/Pattern-Mining/tree/master/OPF-Miner.","sentences":["Order-preserving pattern (OPP) mining is a type of sequential pattern mining method in which a group of ranks of time series is used to represent an OPP.","This approach can discover frequent trends in time series.","Existing OPP mining algorithms consider data points at different time to be equally important; however, newer data usually have a more significant impact, while older data have a weaker impact.","We therefore introduce the forgetting mechanism into OPP mining to reduce the importance of older data.","This paper explores the mining of OPPs with forgetting mechanism (OPF) and proposes an algorithm called OPF-Miner that can discover frequent OPFs.","OPF-Miner performs two tasks, candidate pattern generation and support calculation.","In candidate pattern generation, OPF-Miner employs a maximal support priority strategy and a group pattern fusion strategy to avoid redundant pattern fusions.","For support calculation, we propose an algorithm called support calculation with forgetting mechanism, which uses prefix and suffix pattern pruning strategies to avoid redundant support calculations.","The experiments are conducted on nine datasets and 12 alternative algorithms.","The results verify that OPF-Miner is superior to other competitive algorithms.","More importantly, OPF-Miner yields good clustering performance for time series, since the forgetting mechanism is employed.","All algorithms can be downloaded from https://github.com/wuc567/Pattern-Mining/tree/master/OPF-Miner."],"url":"http://arxiv.org/abs/2408.15563v1"}
{"created":"2024-08-28 06:24:13","title":"CGRA4ML: A Framework to Implement Modern Neural Networks for Scientific Edge Computing","abstract":"Scientific edge computing increasingly relies on hardware-accelerated neural networks to implement complex, near-sensor processing at extremely high throughputs and low latencies. Existing frameworks like HLS4ML are effective for smaller models, but struggle with larger, modern neural networks due to their requirement of spatially implementing the neural network layers and storing all weights in on-chip memory. CGRA4ML is an open-source, modular framework designed to bridge the gap between neural network model complexity and extreme performance requirements. CGRA4ML extends the capabilities of HLS4ML by allowing off-chip data storage and supporting a broader range of neural network architectures, including models like ResNet, PointNet, and transformers. Unlike HLS4ML, CGRA4ML generates SystemVerilog RTL, making it more suitable for targeting ASIC and FPGA design flows. We demonstrate the effectiveness of our framework by implementing and scaling larger models that were previously unattainable with HLS4ML, showcasing its adaptability and efficiency in handling complex computations. CGRA4ML also introduces an extensive verification framework, with a generated runtime firmware that enables its integration into different SoC platforms. CGRA4ML's minimal and modular infrastructure of Python API, SystemVerilog hardware, Tcl toolflows, and C runtime, facilitates easy integration and experimentation, allowing scientists to focus on innovation rather than the intricacies of hardware design and optimization.","sentences":["Scientific edge computing increasingly relies on hardware-accelerated neural networks to implement complex, near-sensor processing at extremely high throughputs and low latencies.","Existing frameworks like HLS4ML are effective for smaller models, but struggle with larger, modern neural networks due to their requirement of spatially implementing the neural network layers and storing all weights in on-chip memory.","CGRA4ML is an open-source, modular framework designed to bridge the gap between neural network model complexity and extreme performance requirements.","CGRA4ML extends the capabilities of HLS4ML by allowing off-chip data storage and supporting a broader range of neural network architectures, including models like ResNet, PointNet, and transformers.","Unlike HLS4ML, CGRA4ML generates SystemVerilog RTL, making it more suitable for targeting ASIC and FPGA design flows.","We demonstrate the effectiveness of our framework by implementing and scaling larger models that were previously unattainable with HLS4ML, showcasing its adaptability and efficiency in handling complex computations.","CGRA4ML also introduces an extensive verification framework, with a generated runtime firmware that enables its integration into different SoC platforms.","CGRA4ML's minimal and modular infrastructure of Python API, SystemVerilog hardware, Tcl toolflows, and C runtime, facilitates easy integration and experimentation, allowing scientists to focus on innovation rather than the intricacies of hardware design and optimization."],"url":"http://arxiv.org/abs/2408.15561v2"}
{"created":"2024-08-28 06:18:55","title":"Generalization Capabilities of Neural Cellular Automata for Medical Image Segmentation: A Robust and Lightweight Approach","abstract":"In the field of medical imaging, the U-Net architecture, along with its variants, has established itself as a cornerstone for image segmentation tasks, particularly due to its strong performance when trained on limited datasets. Despite its impressive performance on identically distributed (in-domain) data, U-Nets exhibit a significant decline in performance when tested on data that deviates from the training distribution, out-of-distribution (out-of-domain) data. Current methodologies predominantly address this issue by employing generalization techniques that hinge on various forms of regularization, which have demonstrated moderate success in specific scenarios. This paper, however, ventures into uncharted territory by investigating the implications of utilizing models that are smaller by three orders of magnitude (i.e., x1000) compared to a conventional U-Net. A reduction of this size in U-net parameters typically adversely affects both in-domain and out-of-domain performance, possibly due to a significantly reduced receptive field. To circumvent this issue, we explore the concept of Neural Cellular Automata (NCA), which, despite its simpler model structure, can attain larger receptive fields through recursive processes. Experimental results on two distinct datasets reveal that NCA outperforms traditional methods in terms of generalization, while still maintaining a commendable IID performance.","sentences":["In the field of medical imaging, the U-Net architecture, along with its variants, has established itself as a cornerstone for image segmentation tasks, particularly due to its strong performance when trained on limited datasets.","Despite its impressive performance on identically distributed (in-domain) data, U-Nets exhibit a significant decline in performance when tested on data that deviates from the training distribution, out-of-distribution (out-of-domain) data.","Current methodologies predominantly address this issue by employing generalization techniques that hinge on various forms of regularization, which have demonstrated moderate success in specific scenarios.","This paper, however, ventures into uncharted territory by investigating the implications of utilizing models that are smaller by three orders of magnitude (i.e., x1000) compared to a conventional U-Net.","A reduction of this size in U-net parameters typically adversely affects both in-domain and out-of-domain performance, possibly due to a significantly reduced receptive field.","To circumvent this issue, we explore the concept of Neural Cellular Automata (NCA), which, despite its simpler model structure, can attain larger receptive fields through recursive processes.","Experimental results on two distinct datasets reveal that NCA outperforms traditional methods in terms of generalization, while still maintaining a commendable IID performance."],"url":"http://arxiv.org/abs/2408.15557v1"}
{"created":"2024-08-28 05:53:46","title":"WildFeedback: Aligning LLMs With In-situ User Interactions And Feedback","abstract":"As large language models (LLMs) continue to advance, aligning these models with human preferences has emerged as a critical challenge. Traditional alignment methods, relying on human or LLM annotated datasets, are limited by their resource-intensive nature, inherent subjectivity, and the risk of feedback loops that amplify model biases. To overcome these limitations, we introduce WildFeedback, a novel framework that leverages real-time, in-situ user interactions to create preference datasets that more accurately reflect authentic human values. WildFeedback operates through a three-step process: feedback signal identification, preference data construction, and user-guided evaluation. We applied this framework to a large corpus of user-LLM conversations, resulting in a rich preference dataset that reflects genuine user preferences. This dataset captures the nuances of user preferences by identifying and classifying feedback signals within natural conversations, thereby enabling the construction of more representative and context-sensitive alignment data. Our extensive experiments demonstrate that LLMs fine-tuned on WildFeedback exhibit significantly improved alignment with user preferences, as evidenced by both traditional benchmarks and our proposed user-guided evaluation. By incorporating real-time feedback from actual users, WildFeedback addresses the scalability, subjectivity, and bias challenges that plague existing approaches, marking a significant step toward developing LLMs that are more responsive to the diverse and evolving needs of their users. In summary, WildFeedback offers a robust, scalable solution for aligning LLMs with true human values, setting a new standard for the development and evaluation of user-centric language models.","sentences":["As large language models (LLMs) continue to advance, aligning these models with human preferences has emerged as a critical challenge.","Traditional alignment methods, relying on human or LLM annotated datasets, are limited by their resource-intensive nature, inherent subjectivity, and the risk of feedback loops that amplify model biases.","To overcome these limitations, we introduce WildFeedback, a novel framework that leverages real-time, in-situ user interactions to create preference datasets that more accurately reflect authentic human values.","WildFeedback operates through a three-step process: feedback signal identification, preference data construction, and user-guided evaluation.","We applied this framework to a large corpus of user-LLM conversations, resulting in a rich preference dataset that reflects genuine user preferences.","This dataset captures the nuances of user preferences by identifying and classifying feedback signals within natural conversations, thereby enabling the construction of more representative and context-sensitive alignment data.","Our extensive experiments demonstrate that LLMs fine-tuned on WildFeedback exhibit significantly improved alignment with user preferences, as evidenced by both traditional benchmarks and our proposed user-guided evaluation.","By incorporating real-time feedback from actual users, WildFeedback addresses the scalability, subjectivity, and bias challenges that plague existing approaches, marking a significant step toward developing LLMs that are more responsive to the diverse and evolving needs of their users.","In summary, WildFeedback offers a robust, scalable solution for aligning LLMs with true human values, setting a new standard for the development and evaluation of user-centric language models."],"url":"http://arxiv.org/abs/2408.15549v1"}
{"created":"2024-08-28 05:34:14","title":"Kangaroo: A Powerful Video-Language Model Supporting Long-context Video Input","abstract":"Rapid advancements have been made in extending Large Language Models (LLMs) to Large Multi-modal Models (LMMs). However, extending input modality of LLMs to video data remains a challenging endeavor, especially for long videos. Due to insufficient access to large-scale high-quality video data and the excessive compression of visual features, current methods exhibit limitations in effectively processing long videos. In this paper, we introduce Kangaroo, a powerful Video LMM aimed at addressing these challenges. Confronted with issue of inadequate training data, we develop a data curation system to build a large-scale dataset with high-quality annotations for vision-language pre-training and instruction tuning. In addition, we design a curriculum training pipeline with gradually increasing resolution and number of input frames to accommodate long videos. Evaluation results demonstrate that, with 8B parameters, Kangaroo achieves state-of-the-art performance across a variety of video understanding benchmarks while exhibiting competitive results on others. Particularly, on benchmarks specialized for long videos, Kangaroo excels some larger models with over 10B parameters and proprietary models.","sentences":["Rapid advancements have been made in extending Large Language Models (LLMs) to Large Multi-modal Models (LMMs).","However, extending input modality of LLMs to video data remains a challenging endeavor, especially for long videos.","Due to insufficient access to large-scale high-quality video data and the excessive compression of visual features, current methods exhibit limitations in effectively processing long videos.","In this paper, we introduce Kangaroo, a powerful Video LMM aimed at addressing these challenges.","Confronted with issue of inadequate training data, we develop a data curation system to build a large-scale dataset with high-quality annotations for vision-language pre-training and instruction tuning.","In addition, we design a curriculum training pipeline with gradually increasing resolution and number of input frames to accommodate long videos.","Evaluation results demonstrate that, with 8B parameters, Kangaroo achieves state-of-the-art performance across a variety of video understanding benchmarks while exhibiting competitive results on others.","Particularly, on benchmarks specialized for long videos, Kangaroo excels some larger models with over 10B parameters and proprietary models."],"url":"http://arxiv.org/abs/2408.15542v1"}
{"created":"2024-08-28 04:44:43","title":"LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation","abstract":"Retrieval-Augmented Generation (RAG) has become a primary technique for mitigating hallucinations in large language models (LLMs). However, incomplete knowledge extraction and insufficient understanding can still mislead LLMs to produce irrelevant or even contradictory responses, which means hallucinations persist in RAG. In this paper, we propose LRP4RAG, a method based on the Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations in RAG. Specifically, we first utilize LRP to compute the relevance between the input and output of the RAG generator. We then apply further extraction and resampling to the relevance matrix. The processed relevance data are input into multiple classifiers to determine whether the output contains hallucinations. To the best of our knowledge, this is the first time that LRP has been used for detecting RAG hallucinations, and extensive experiments demonstrate that LRP4RAG outperforms existing baselines.","sentences":["Retrieval-Augmented Generation (RAG) has become a primary technique for mitigating hallucinations in large language models (LLMs).","However, incomplete knowledge extraction and insufficient understanding can still mislead LLMs to produce irrelevant or even contradictory responses, which means hallucinations persist in RAG.","In this paper, we propose LRP4RAG, a method based on the Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations in RAG.","Specifically, we first utilize LRP to compute the relevance between the input and output of the RAG generator.","We then apply further extraction and resampling to the relevance matrix.","The processed relevance data are input into multiple classifiers to determine whether the output contains hallucinations.","To the best of our knowledge, this is the first time that LRP has been used for detecting RAG hallucinations, and extensive experiments demonstrate that LRP4RAG outperforms existing baselines."],"url":"http://arxiv.org/abs/2408.15533v2"}
{"created":"2024-08-28 04:12:07","title":"Depth-Weighted Detection of Behaviours of Risk in People with Dementia using Cameras","abstract":"The behavioural and psychological symptoms of dementia, such as agitation and aggression, present a significant health and safety risk in residential care settings. Many care facilities have video cameras in place for digital monitoring of public spaces, which can be leveraged to develop an automated behaviours of risk detection system that can alert the staff to enable timely intervention and prevent the situation from escalating. However, one of the challenges in our previous study was the presence of false alarms due to obstruction of view by activities happening close to the camera. To address this issue, we proposed a novel depth-weighted loss function to train a customized convolutional autoencoder to enforce equivalent importance to the events happening both near and far from the cameras; thus, helping to reduce false alarms and making the method more suitable for real-world deployment. The proposed method was trained using data from nine participants with dementia across three cameras situated in a specialized dementia unit and achieved an area under the curve of receiver operating characteristic of $0.852$, $0.81$ and $0.768$ for the three cameras. Ablation analysis was conducted for the individual components of the proposed method and the performance of the proposed method was investigated for participant-specific and sex-specific behaviours of risk detection. The proposed method performed reasonably well in detecting behaviours of risk in people with dementia motivating further research toward the development of a behaviours of risk detection system suitable for deployment in video surveillance systems in care facilities.","sentences":["The behavioural and psychological symptoms of dementia, such as agitation and aggression, present a significant health and safety risk in residential care settings.","Many care facilities have video cameras in place for digital monitoring of public spaces, which can be leveraged to develop an automated behaviours of risk detection system that can alert the staff to enable timely intervention and prevent the situation from escalating.","However, one of the challenges in our previous study was the presence of false alarms due to obstruction of view by activities happening close to the camera.","To address this issue, we proposed a novel depth-weighted loss function to train a customized convolutional autoencoder to enforce equivalent importance to the events happening both near and far from the cameras; thus, helping to reduce false alarms and making the method more suitable for real-world deployment.","The proposed method was trained using data from nine participants with dementia across three cameras situated in a specialized dementia unit and achieved an area under the curve of receiver operating characteristic of $0.852$, $0.81$ and $0.768$ for the three cameras.","Ablation analysis was conducted for the individual components of the proposed method and the performance of the proposed method was investigated for participant-specific and sex-specific behaviours of risk detection.","The proposed method performed reasonably well in detecting behaviours of risk in people with dementia motivating further research toward the development of a behaviours of risk detection system suitable for deployment in video surveillance systems in care facilities."],"url":"http://arxiv.org/abs/2408.15519v1"}
{"created":"2024-08-28 04:04:31","title":"Predicting Parameter Change's Effect on Cellular Network Time Series","abstract":"The cellular network provides convenient network access for ever-growing mobile phones. During the continuous optimization, operators can adjust cell parameters to enhance the Quality of Service (QoS) flexibly. A precise prediction of the parameter change's effect can help operators make proper parameter adjustments. This work focuses on predicting cell status (like the workload and QoS) after adjusting the cell parameters. The prediction will be conducted before an adjustment is actually applied to provide an early inspection. As it can be hard for available parameter adjustments with a limited number to cover all the parameter and user behavior combinations, we propose ParaSeer fusing domain knowledge on parameter adjustments into data-driven time series forecasting. ParaSeer organizes several pre-trained Transformers for adjustment-free time series forecasting, utilizing plenty of adjustment-free data. On the other hand, ParaSeer models the effect of adjusting the transmission power and cell individual offset (CIO) as a multiplier for the workload. We derive a formula to calculate the multiplier from the underlying mechanism of those two parameters, helping ParaSeer eliminate the thirst for data with parameter adjustments. We compare ParaSeer with baselines on two real-world datasets, where ParaSeer outperforms the best baseline by more than 25.8% in terms of RMSE. The extensive experiments further illustrate the contributions of ParaSeer's components.","sentences":["The cellular network provides convenient network access for ever-growing mobile phones.","During the continuous optimization, operators can adjust cell parameters to enhance the Quality of Service (QoS) flexibly.","A precise prediction of the parameter change's effect can help operators make proper parameter adjustments.","This work focuses on predicting cell status (like the workload and QoS) after adjusting the cell parameters.","The prediction will be conducted before an adjustment is actually applied to provide an early inspection.","As it can be hard for available parameter adjustments with a limited number to cover all the parameter and user behavior combinations, we propose ParaSeer fusing domain knowledge on parameter adjustments into data-driven time series forecasting.","ParaSeer organizes several pre-trained Transformers for adjustment-free time series forecasting, utilizing plenty of adjustment-free data.","On the other hand, ParaSeer models the effect of adjusting the transmission power and cell individual offset (CIO) as a multiplier for the workload.","We derive a formula to calculate the multiplier from the underlying mechanism of those two parameters, helping ParaSeer eliminate the thirst for data with parameter adjustments.","We compare ParaSeer with baselines on two real-world datasets, where ParaSeer outperforms the best baseline by more than 25.8% in terms of RMSE.","The extensive experiments further illustrate the contributions of ParaSeer's components."],"url":"http://arxiv.org/abs/2408.15516v1"}
{"created":"2024-08-28 03:50:04","title":"Continual-learning-based framework for structural damage recognition","abstract":"Multi-damage is common in reinforced concrete structures and leads to the requirement of large number of neural networks, parameters and data storage, if convolutional neural network (CNN) is used for damage recognition. In addition, conventional CNN experiences catastrophic forgetting and training inefficiency as the number of tasks increases during continual learning, leading to large accuracy decrease of previous learned tasks. To address these problems, this study proposes a continuallearning-based damage recognition model (CLDRM) which integrates the learning without forgetting continual learning method into the ResNet-34 architecture for the recognition of damages in RC structures as well as relevant structural components. Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework. In this way, it reduces both the prediction time and data storage by about 75% in four tasks of continuous learning. Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework. By gradual feature fusion, CLDRM outperformed other methods by managed to achieve high accuracy in the damage recognition and classification. As the number of recognition tasks increased, CLDRM also experienced smaller decrease of the previous learned tasks. Results indicate that the CLDRM framework successfully performs damage recognition and classification with reasonable accuracy and effectiveness.","sentences":["Multi-damage is common in reinforced concrete structures and leads to the requirement of large number of neural networks, parameters and data storage, if convolutional neural network (CNN) is used for damage recognition.","In addition, conventional CNN experiences catastrophic forgetting and training inefficiency as the number of tasks increases during continual learning, leading to large accuracy decrease of previous learned tasks.","To address these problems, this study proposes a continuallearning-based damage recognition model (CLDRM) which integrates the learning without forgetting continual learning method into the ResNet-34 architecture for the recognition of damages in RC structures as well as relevant structural components.","Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework.","In this way, it reduces both the prediction time and data storage by about 75% in four tasks of continuous learning.","Three experiments for four recognition tasks were designed to validate the feasibility and effectiveness of the CLDRM framework.","By gradual feature fusion, CLDRM outperformed other methods by managed to achieve high accuracy in the damage recognition and classification.","As the number of recognition tasks increased, CLDRM also experienced smaller decrease of the previous learned tasks.","Results indicate that the CLDRM framework successfully performs damage recognition and classification with reasonable accuracy and effectiveness."],"url":"http://arxiv.org/abs/2408.15513v1"}
{"created":"2024-08-28 03:48:05","title":"Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations","abstract":"The advent of Large Language Models (LLMs) has created new opportunities for the automation of scientific research, spanning both experimental processes and computational simulations. This study explores the feasibility of constructing an autonomous simulation agent (ASA) powered by LLM, through sophisticated API integration, to automate the entire research process, from experimental design, remote upload and simulation execution, data analysis, to report compilation. Using a simulation problem of polymer chain conformations as a case study, we assessed the performance of ASAs powered by different LLMs including GPT-4-Turbo. Our findings revealed that ASA-GPT-4o achieved near-flawless execution on designated research missions, underscoring the potential of LLMs to manage complete scientific investigations autonomously. The outlined automation can be iteratively performed up to twenty cycles without human intervention, illustrating the potential of LLMs for large-scale autonomous research endeavors. Additionally, we discussed the intrinsic traits of ASAs in managing extensive tasks, focusing on self-validation mechanisms and the balance between local attention and global oversight.","sentences":["The advent of Large Language Models (LLMs) has created new opportunities for the automation of scientific research, spanning both experimental processes and computational simulations.","This study explores the feasibility of constructing an autonomous simulation agent (ASA) powered by LLM, through sophisticated API integration, to automate the entire research process, from experimental design, remote upload and simulation execution, data analysis, to report compilation.","Using a simulation problem of polymer chain conformations as a case study, we assessed the performance of ASAs powered by different LLMs including GPT-4-Turbo.","Our findings revealed that ASA-GPT-4o achieved near-flawless execution on designated research missions, underscoring the potential of LLMs to manage complete scientific investigations autonomously.","The outlined automation can be iteratively performed up to twenty cycles without human intervention, illustrating the potential of LLMs for large-scale autonomous research endeavors.","Additionally, we discussed the intrinsic traits of ASAs in managing extensive tasks, focusing on self-validation mechanisms and the balance between local attention and global oversight."],"url":"http://arxiv.org/abs/2408.15512v1"}
{"created":"2024-08-28 03:17:40","title":"RoboSense: Large-scale Dataset and Benchmark for Multi-sensor Low-speed Autonomous Driving","abstract":"Robust object detection and tracking under arbitrary sight of view is challenging yet essential for the development of Autonomous Vehicle technology. With the growing demand of unmanned function vehicles, near-field scene understanding becomes an important research topic in the areas of low-speed autonomous driving. Due to the complexity of driving conditions and diversity of near obstacles such as blind spots and high occlusion, the perception capability of near-field environment is still inferior than its farther counterpart. To further enhance the intelligent ability of unmanned vehicles, in this paper, we construct a multimodal data collection platform based on 3 main types of sensors (Camera, LiDAR and Fisheye), which supports flexible sensor configurations to enable dynamic sight of view for ego vehicle, either global view or local view. Meanwhile, a large-scale multi-sensor dataset is built, named RoboSense, to facilitate near-field scene understanding. RoboSense contains more than 133K synchronized data with 1.4M 3D bounding box and IDs annotated in the full $360^{\\circ}$ view, forming 216K trajectories across 7.6K temporal sequences. It has $270\\times$ and $18\\times$ as many annotations of near-field obstacles within 5$m$ as the previous single-vehicle datasets such as KITTI and nuScenes. Moreover, we define a novel matching criterion for near-field 3D perception and prediction metrics. Based on RoboSense, we formulate 6 popular tasks to facilitate the future development of related research, where the detailed data analysis as well as benchmarks are also provided accordingly.","sentences":["Robust object detection and tracking under arbitrary sight of view is challenging yet essential for the development of Autonomous Vehicle technology.","With the growing demand of unmanned function vehicles, near-field scene understanding becomes an important research topic in the areas of low-speed autonomous driving.","Due to the complexity of driving conditions and diversity of near obstacles such as blind spots and high occlusion, the perception capability of near-field environment is still inferior than its farther counterpart.","To further enhance the intelligent ability of unmanned vehicles, in this paper, we construct a multimodal data collection platform based on 3 main types of sensors (Camera, LiDAR and Fisheye), which supports flexible sensor configurations to enable dynamic sight of view for ego vehicle, either global view or local view.","Meanwhile, a large-scale multi-sensor dataset is built, named RoboSense, to facilitate near-field scene understanding.","RoboSense contains more than 133K synchronized data with 1.4M 3D bounding box and IDs annotated in the full $360^{\\circ}$ view, forming 216K trajectories across 7.6K temporal sequences.","It has $270\\times$ and $18\\times$ as many annotations of near-field obstacles within 5$m$ as the previous single-vehicle datasets such as KITTI and nuScenes.","Moreover, we define a novel matching criterion for near-field 3D perception and prediction metrics.","Based on RoboSense, we formulate 6 popular tasks to facilitate the future development of related research, where the detailed data analysis as well as benchmarks are also provided accordingly."],"url":"http://arxiv.org/abs/2408.15503v1"}
{"created":"2024-08-28 02:27:50","title":"Shared-PIM: Enabling Concurrent Computation and Data Flow for Faster Processing-in-DRAM","abstract":"Processing-in-Memory (PIM) enhances memory with computational capabilities, potentially solving energy and latency issues associated with data transfer between memory and processors. However, managing concurrent computation and data flow within the PIM architecture incurs significant latency and energy penalty for applications. This paper introduces Shared-PIM, an architecture for in-DRAM PIM that strategically allocates rows in memory banks, bolstered by memory peripherals, for concurrent processing and data movement. Shared-PIM enables simultaneous computation and data transfer within a memory bank. When compared to LISA, a state-of-the-art architecture that facilitates data transfers for in-DRAM PIM, Shared-PIM reduces data movement latency and energy by 5x and 1.2x respectively. Furthermore, when integrated to a state-of-the-art (SOTA) in-DRAM PIM architecture (pLUTo), Shared-PIM achieves 1.4x faster addition and multiplication, and thereby improves the performance of matrix multiplication (MM) tasks by 40%, polynomial multiplication (PMM) by 44%, and numeric number transfer (NTT) tasks by 31%. Moreover, for graph processing tasks like Breadth-First Search (BFS) and Depth-First Search (DFS), Shared-PIM achieves a 29% improvement in speed, all with an area overhead of just 7.16% compared to the baseline pLUTo.","sentences":["Processing-in-Memory (PIM) enhances memory with computational capabilities, potentially solving energy and latency issues associated with data transfer between memory and processors.","However, managing concurrent computation and data flow within the PIM architecture incurs significant latency and energy penalty for applications.","This paper introduces Shared-PIM, an architecture for in-DRAM PIM that strategically allocates rows in memory banks, bolstered by memory peripherals, for concurrent processing and data movement.","Shared-PIM enables simultaneous computation and data transfer within a memory bank.","When compared to LISA, a state-of-the-art architecture that facilitates data transfers for in-DRAM PIM, Shared-PIM reduces data movement latency and energy by 5x and 1.2x respectively.","Furthermore, when integrated to a state-of-the-art (SOTA) in-DRAM PIM architecture (pLUTo), Shared-PIM achieves 1.4x faster addition and multiplication, and thereby improves the performance of matrix multiplication (MM) tasks by 40%, polynomial multiplication (PMM) by 44%, and numeric number transfer (NTT) tasks by 31%.","Moreover, for graph processing tasks like Breadth-First Search (BFS) and Depth-First Search (DFS), Shared-PIM achieves a 29% improvement in speed, all with an area overhead of just 7.16% compared to the baseline pLUTo."],"url":"http://arxiv.org/abs/2408.15489v1"}
{"created":"2024-08-28 02:27:07","title":"Legilimens: Practical and Unified Content Moderation for Large Language Model Services","abstract":"Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers. Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources. In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation. We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency. Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking. Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methods. We have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries. A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens. Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks.","sentences":["Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers.","Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources.","In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation.","We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency.","Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking.","Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methods.","We have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries.","A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens.","Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks."],"url":"http://arxiv.org/abs/2408.15488v1"}
{"created":"2024-08-28 02:00:40","title":"Feelit: Combining Compliant Shape Displays with Vision-Based Tactile Sensors for Real-Time Teletaction","abstract":"Teletaction, the transmission of tactile feedback or touch, is a crucial aspect in the field of teleoperation. High-quality teletaction feedback allows users to remotely manipulate objects and increase the quality of the human-machine interface between the operator and the robot, making complex manipulation tasks possible. Advances in the field of teletaction for teleoperation however, have yet to make full use of the high-resolution 3D data provided by modern vision-based tactile sensors. Existing solutions for teletaction lack in one or more areas of form or function, such as fidelity or hardware footprint. In this paper, we showcase our design for a low-cost teletaction device that can utilize real-time high-resolution tactile information from vision-based tactile sensors, through both physical 3D surface reconstruction and shear displacement. We present our device, the Feelit, which uses a combination of a pin-based shape display and compliant mechanisms to accomplish this task. The pin-based shape display utilizes an array of 24 servomotors with miniature Bowden cables, giving the device a resolution of 6x4 pins in a 15x10 mm display footprint. Each pin can actuate up to 3 mm in 200 ms, while providing 80 N of force and 1.5 um of depth resolution. Shear displacement and rotation is achieved using a compliant mechanism design, allowing a minimum of 1 mm displacement laterally and 10 degrees of rotation. This real-time 3D tactile reconstruction is achieved with the use of a vision-based tactile sensor, the GelSight [1], along with an algorithm that samples the depth data and marker tracking to generate actuator commands. Through a series of experiments including shape recognition and relative weight identification, we show that our device has the potential to expand teletaction capabilities in the teleoperation space.","sentences":["Teletaction, the transmission of tactile feedback or touch, is a crucial aspect in the field of teleoperation.","High-quality teletaction feedback allows users to remotely manipulate objects and increase the quality of the human-machine interface between the operator and the robot, making complex manipulation tasks possible.","Advances in the field of teletaction for teleoperation however, have yet to make full use of the high-resolution 3D data provided by modern vision-based tactile sensors.","Existing solutions for teletaction lack in one or more areas of form or function, such as fidelity or hardware footprint.","In this paper, we showcase our design for a low-cost teletaction device that can utilize real-time high-resolution tactile information from vision-based tactile sensors, through both physical 3D surface reconstruction and shear displacement.","We present our device, the Feelit, which uses a combination of a pin-based shape display and compliant mechanisms to accomplish this task.","The pin-based shape display utilizes an array of 24 servomotors with miniature Bowden cables, giving the device a resolution of 6x4 pins in a 15x10 mm display footprint.","Each pin can actuate up to 3 mm in 200 ms, while providing 80 N of force and 1.5 um of depth resolution.","Shear displacement and rotation is achieved using a compliant mechanism design, allowing a minimum of 1 mm displacement laterally and 10 degrees of rotation.","This real-time 3D tactile reconstruction is achieved with the use of a vision-based tactile sensor, the GelSight","[1], along with an algorithm that samples the depth data and marker tracking to generate actuator commands.","Through a series of experiments including shape recognition and relative weight identification, we show that our device has the potential to expand teletaction capabilities in the teleoperation space."],"url":"http://arxiv.org/abs/2408.15480v1"}
{"created":"2024-08-28 01:40:22","title":"Power, Control, and Data Acquisition Systems for Rectal Simulator Integrated with Soft Pouch Actuators","abstract":"Fecal incontinence (FI) is a significant health issue with various underlying causes. Research in this field is limited by social stigma and the lack of effective replication models. To address these challenges, we developed a sophisticated rectal simulator that integrates power, control, and data acquisition systems with soft pouch actuators. The system comprises four key subsystems: mechanical, electrical, pneumatic, and control and data acquisition. The mechanical subsystem utilizes common materials such as aluminum frames, wooden boards, and compact structural components to facilitate the installation and adjustment of electrical and control components. The electrical subsystem supplies power to regulators and sensors. The pneumatic system provides compressed air to actuators, enabling the simulation of FI. The control and data acquisition subsystem collects pressure data and regulates actuator movement. This comprehensive approach allows the robot to accurately replicate human defecation, managing various feces types including liquid, solid, and extremely solid. This innovation enhances our understanding of defecation and holds potential for advancing quality-of-life devices related to this condition.","sentences":["Fecal incontinence (FI) is a significant health issue with various underlying causes.","Research in this field is limited by social stigma and the lack of effective replication models.","To address these challenges, we developed a sophisticated rectal simulator that integrates power, control, and data acquisition systems with soft pouch actuators.","The system comprises four key subsystems: mechanical, electrical, pneumatic, and control and data acquisition.","The mechanical subsystem utilizes common materials such as aluminum frames, wooden boards, and compact structural components to facilitate the installation and adjustment of electrical and control components.","The electrical subsystem supplies power to regulators and sensors.","The pneumatic system provides compressed air to actuators, enabling the simulation of FI.","The control and data acquisition subsystem collects pressure data and regulates actuator movement.","This comprehensive approach allows the robot to accurately replicate human defecation, managing various feces types including liquid, solid, and extremely solid.","This innovation enhances our understanding of defecation and holds potential for advancing quality-of-life devices related to this condition."],"url":"http://arxiv.org/abs/2408.15473v1"}
{"created":"2024-08-28 01:06:19","title":"Dynamic Reconstruction from Neuromorphic Data","abstract":"Unlike traditional cameras which synchronously register pixel intensity, neuromorphic sensors only register `changes' at pixels where a change is occurring asynchronously. This enables neuromorphic sensors to sample at a micro-second level and efficiently capture the dynamics. Since, only sequences of asynchronous event changes are recorded rather than brightness intensities over time, many traditional image processing techniques cannot be directly applied. Furthermore, existing approaches, including the ones recently introduced by the authors, use traditional images combined with neuromorphic event data to carry out reconstructions. The aim of this work is introduce an optimization based approach to reconstruct images and dynamics only from the neuromoprhic event data without any additional knowledge of the events. Each pixel is modeled temporally. The experimental results on real data highlight the efficacy of the presented approach, paving the way for efficient and accurate processing of neuromorphic sensor data in real-world applications.","sentences":["Unlike traditional cameras which synchronously register pixel intensity, neuromorphic sensors only register `changes' at pixels where a change is occurring asynchronously.","This enables neuromorphic sensors to sample at a micro-second level and efficiently capture the dynamics.","Since, only sequences of asynchronous event changes are recorded rather than brightness intensities over time, many traditional image processing techniques cannot be directly applied.","Furthermore, existing approaches, including the ones recently introduced by the authors, use traditional images combined with neuromorphic event data to carry out reconstructions.","The aim of this work is introduce an optimization based approach to reconstruct images and dynamics only from the neuromoprhic event data without any additional knowledge of the events.","Each pixel is modeled temporally.","The experimental results on real data highlight the efficacy of the presented approach, paving the way for efficient and accurate processing of neuromorphic sensor data in real-world applications."],"url":"http://arxiv.org/abs/2408.15465v1"}
{"created":"2024-08-28 00:14:09","title":"Certified Causal Defense with Generalizable Robustness","abstract":"While machine learning models have proven effective across various scenarios, it is widely acknowledged that many models are vulnerable to adversarial attacks. Recently, there have emerged numerous efforts in adversarial defense. Among them, certified defense is well known for its theoretical guarantees against arbitrary adversarial perturbations on input within a certain range (e.g., $l_2$ ball). However, most existing works in this line struggle to generalize their certified robustness in other data domains with distribution shifts. This issue is rooted in the difficulty of eliminating the negative impact of spurious correlations on robustness in different domains. To address this problem, in this work, we propose a novel certified defense framework GLEAN, which incorporates a causal perspective into the generalization problem in certified defense. More specifically, our framework integrates a certifiable causal factor learning component to disentangle the causal relations and spurious correlations between input and label, and thereby exclude the negative effect of spurious correlations on defense. On top of that, we design a causally certified defense strategy to handle adversarial attacks on latent causal factors. In this way, our framework is not only robust against malicious noises on data in the training distribution but also can generalize its robustness across domains with distribution shifts. Extensive experiments on benchmark datasets validate the superiority of our framework in certified robustness generalization in different data domains. Code is available in the supplementary materials.","sentences":["While machine learning models have proven effective across various scenarios, it is widely acknowledged that many models are vulnerable to adversarial attacks.","Recently, there have emerged numerous efforts in adversarial defense.","Among them, certified defense is well known for its theoretical guarantees against arbitrary adversarial perturbations on input within a certain range (e.g., $l_2$ ball).","However, most existing works in this line struggle to generalize their certified robustness in other data domains with distribution shifts.","This issue is rooted in the difficulty of eliminating the negative impact of spurious correlations on robustness in different domains.","To address this problem, in this work, we propose a novel certified defense framework GLEAN, which incorporates a causal perspective into the generalization problem in certified defense.","More specifically, our framework integrates a certifiable causal factor learning component to disentangle the causal relations and spurious correlations between input and label, and thereby exclude the negative effect of spurious correlations on defense.","On top of that, we design a causally certified defense strategy to handle adversarial attacks on latent causal factors.","In this way, our framework is not only robust against malicious noises on data in the training distribution but also can generalize its robustness across domains with distribution shifts.","Extensive experiments on benchmark datasets validate the superiority of our framework in certified robustness generalization in different data domains.","Code is available in the supplementary materials."],"url":"http://arxiv.org/abs/2408.15451v1"}
{"created":"2024-08-27 23:58:51","title":"Graph Attention Inference of Network Topology in Multi-Agent Systems","abstract":"Accurately identifying the underlying graph structures of multi-agent systems remains a difficult challenge. Our work introduces a novel machine learning-based solution that leverages the attention mechanism to predict future states of multi-agent systems by learning node representations. The graph structure is then inferred from the strength of the attention values. This approach is applied to both linear consensus dynamics and the non-linear dynamics of Kuramoto oscillators, resulting in implicit learning the graph by learning good agent representations. Our results demonstrate that the presented data-driven graph attention machine learning model can identify the network topology in multi-agent systems, even when the underlying dynamic model is not known, as evidenced by the F1 scores achieved in the link prediction.","sentences":["Accurately identifying the underlying graph structures of multi-agent systems remains a difficult challenge.","Our work introduces a novel machine learning-based solution that leverages the attention mechanism to predict future states of multi-agent systems by learning node representations.","The graph structure is then inferred from the strength of the attention values.","This approach is applied to both linear consensus dynamics and the non-linear dynamics of Kuramoto oscillators, resulting in implicit learning the graph by learning good agent representations.","Our results demonstrate that the presented data-driven graph attention machine learning model can identify the network topology in multi-agent systems, even when the underlying dynamic model is not known, as evidenced by the F1 scores achieved in the link prediction."],"url":"http://arxiv.org/abs/2408.15449v1"}
{"created":"2024-08-27 23:14:22","title":"Towards observability of scientific applications","abstract":"As software systems increase in complexity, conventional monitoring methods struggle to provide a comprehensive overview or identify performance issues, often missing unexpected problems. Observability, however, offers a holistic approach, providing methods and tools that gather and analyze detailed telemetry data to uncover hidden issues. Originally developed for cloud-native systems, modern observability is less prevalent in scientific computing, particularly in HPC clusters, due to differences in application architecture, execution environments, and technology stacks. This paper proposes and evaluates an end-to-end observability solution tailored for scientific computing in HPC environments. We address several challenges, including collection of application-level metrics, instrumentation, context propagation, and tracing. We argue that typical dashboards with charts are not sufficient for advanced observability-driven analysis of scientific applications. Consequently, we propose a different approach based on data analysis using DataFrames and a Jupyter environment. The proposed solution is implemented and evaluated on two medical scientific pipelines running on an HPC cluster.","sentences":["As software systems increase in complexity, conventional monitoring methods struggle to provide a comprehensive overview or identify performance issues, often missing unexpected problems.","Observability, however, offers a holistic approach, providing methods and tools that gather and analyze detailed telemetry data to uncover hidden issues.","Originally developed for cloud-native systems, modern observability is less prevalent in scientific computing, particularly in HPC clusters, due to differences in application architecture, execution environments, and technology stacks.","This paper proposes and evaluates an end-to-end observability solution tailored for scientific computing in HPC environments.","We address several challenges, including collection of application-level metrics, instrumentation, context propagation, and tracing.","We argue that typical dashboards with charts are not sufficient for advanced observability-driven analysis of scientific applications.","Consequently, we propose a different approach based on data analysis using DataFrames and a Jupyter environment.","The proposed solution is implemented and evaluated on two medical scientific pipelines running on an HPC cluster."],"url":"http://arxiv.org/abs/2408.15439v1"}
{"created":"2024-08-27 22:34:17","title":"Weighted Matching in the Random-Order Streaming and Robust Communication Models","abstract":"We study the maximum weight matching problem in the random-order semi-streaming model and in the robust communication model. Unlike many other sublinear models, in these two frameworks, there is a large gap between the guarantees of the best known algorithms for the unweighted and weighted versions of the problem.   In the random-order semi-streaming setting, the edges of an $n$-vertex graph arrive in a stream in a random order. The goal is to compute an approximate maximum weight matching with a single pass over the stream using $O(n\\text{ polylog } n)$ space. Our main result is a $(2/3-\\epsilon)$-approximation algorithm for maximum weight matching in random-order streams, using space $O(n \\log n \\log R)$, where $R$ is the ratio between the heaviest and the lightest edge in the graph. Our result nearly matches the best known unweighted $(2/3+\\epsilon_0)$-approximation (where $\\epsilon_0 \\sim 10^{-14}$ is a small constant) achieved by Assadi and Behnezhad [ICALP 2021], and significantly improves upon previous weighted results.   Our techniques also extend to the related robust communication model, in which the edges of a graph are partitioned randomly between Alice and Bob. Alice sends a single message of size $O(n\\text{ polylog }n)$ to Bob, who must compute an approximate maximum weight matching. We achieve a $(5/6-\\epsilon)$-approximation using $O(n \\log n \\log R)$ words of communication, matching the results of Azarmehr and Behnezhad [ICALP 2023] for unweighted graphs.","sentences":["We study the maximum weight matching problem in the random-order semi-streaming model and in the robust communication model.","Unlike many other sublinear models, in these two frameworks, there is a large gap between the guarantees of the best known algorithms for the unweighted and weighted versions of the problem.   ","In the random-order semi-streaming setting, the edges of an $n$-vertex graph arrive in a stream in a random order.","The goal is to compute an approximate maximum weight matching with a single pass over the stream using $O(n\\text{ polylog } n)$ space.","Our main result is a $(2/3-\\epsilon)$-approximation algorithm for maximum weight matching in random-order streams, using space $O(n \\log n \\log R)$, where $R$ is the ratio between the heaviest and the lightest edge in the graph.","Our result nearly matches the best known unweighted $(2/3+\\epsilon_0)$-approximation (where $\\epsilon_0 \\sim 10^{-14}$ is a small constant) achieved by Assadi and Behnezhad [ICALP 2021], and significantly improves upon previous weighted results.   ","Our techniques also extend to the related robust communication model, in which the edges of a graph are partitioned randomly between Alice and Bob.","Alice sends a single message of size $O(n\\text{ polylog }n)$ to Bob, who must compute an approximate maximum weight matching.","We achieve a $(5/6-\\epsilon)$-approximation using $O(n \\log n \\log R)$ words of communication, matching the results of Azarmehr and Behnezhad [ICALP 2023] for unweighted graphs."],"url":"http://arxiv.org/abs/2408.15434v1"}
{"created":"2024-08-27 21:18:41","title":"Divergence-free neural operators for stress field modeling in polycrystalline materials","abstract":"The purpose of the current work is the development and comparison of Fourier neural operators (FNOs) for surrogate modeling of the quasi-static mechanical response of polycrystalline materials. Three types of such FNOs are considered here: a physics-guided FNO (PgFNO), a physics-informed FNO (PiFNO), and a physics-encoded FNO (PeFNO). These are trained and compared with the help of stress field data from a reference model for heterogeneous elastic materials with a periodic grain microstructure. Whereas PgFNO training is based solely on these data, that of the PiFNO and PeFNO is in addition constrained by the requirement that stress fields satisfy mechanical equilibrium, i.e., be divergence-free. The difference between the PiFNO and PeFNO lies in how this constraint is taken into account; in the PiFNO, it is included in the loss function, whereas in the PeFNO, it is \"encoded\" in the operator architecture. In the current work, this encoding is based on a stress potential and Fourier transforms. As a result, only the training of the PiFNO is constrained by mechanical equilibrium; in contrast, mechanical equilibrium constrains both the training and output of the PeFNO. Due in particular to this, stress fields calculated by the trained PeFNO are significantly more accurate than those calculated by the trained PiFNO in the example cases considered.","sentences":["The purpose of the current work is the development and comparison of Fourier neural operators (FNOs) for surrogate modeling of the quasi-static mechanical response of polycrystalline materials.","Three types of such FNOs are considered here: a physics-guided FNO (PgFNO), a physics-informed FNO (PiFNO), and a physics-encoded FNO (PeFNO).","These are trained and compared with the help of stress field data from a reference model for heterogeneous elastic materials with a periodic grain microstructure.","Whereas PgFNO training is based solely on these data, that of the PiFNO and PeFNO is in addition constrained by the requirement that stress fields satisfy mechanical equilibrium, i.e., be divergence-free.","The difference between the PiFNO and PeFNO lies in how this constraint is taken into account; in the PiFNO, it is included in the loss function, whereas in the PeFNO, it is \"encoded\" in the operator architecture.","In the current work, this encoding is based on a stress potential and Fourier transforms.","As a result, only the training of the PiFNO is constrained by mechanical equilibrium; in contrast, mechanical equilibrium constrains both the training and output of the PeFNO.","Due in particular to this, stress fields calculated by the trained PeFNO are significantly more accurate than those calculated by the trained PiFNO in the example cases considered."],"url":"http://arxiv.org/abs/2408.15408v1"}
{"created":"2024-08-27 20:51:06","title":"A Statistical Framework for Data-dependent Retrieval-Augmented Models","abstract":"Modern ML systems increasingly augment input instances with additional relevant information to enhance final prediction. Despite growing interest in such retrieval-augmented models, their fundamental properties and training are not well understood. We propose a statistical framework to study such models with two components: 1) a {\\em retriever} to identify the relevant information out of a large corpus via a data-dependent metric; and 2) a {\\em predictor} that consumes the input instances along with the retrieved information to make the final predictions. We present a principled method for end-to-end training of both components and draw connections with various training approaches in the literature. Furthermore, we establish excess risk bounds for retrieval-augmented models while delineating the contributions of both retriever and predictor towards the model performance. We validate the utility of our proposed training methods along with the key takeaways from our statistical analysis on open domain question answering task where retrieval augmentation is important.","sentences":["Modern ML systems increasingly augment input instances with additional relevant information to enhance final prediction.","Despite growing interest in such retrieval-augmented models, their fundamental properties and training are not well understood.","We propose a statistical framework to study such models with two components: 1) a {\\em retriever} to identify the relevant information out of a large corpus via a data-dependent metric; and 2) a {\\em predictor} that consumes the input instances along with the retrieved information to make the final predictions.","We present a principled method for end-to-end training of both components and draw connections with various training approaches in the literature.","Furthermore, we establish excess risk bounds for retrieval-augmented models while delineating the contributions of both retriever and predictor towards the model performance.","We validate the utility of our proposed training methods along with the key takeaways from our statistical analysis on open domain question answering task where retrieval augmentation is important."],"url":"http://arxiv.org/abs/2408.15399v1"}
{"created":"2024-08-27 20:49:11","title":"Evaluating Pre-Training Bias on Severe Acute Respiratory Syndrome Dataset","abstract":"Machine learning (ML) is a growing field of computer science that has found many practical applications in several domains, including Health. However, as data grows in size and availability, and the number of models that aim to aid or replace human decisions, it raises the concern that these models can be susceptible to bias, which can lead to harm to specific individuals by basing its decisions on protected attributes such as gender, religion, sexual orientation, ethnicity, and others. Visualization techniques might generate insights and help summarize large datasets, enabling data scientists to understand the data better before training a model by evaluating pre-training metrics applied to the datasets before training, which might contribute to identifying potential harm before any effort is put into training and deploying the models. This work uses the severe acute respiratory syndrome dataset from OpenDataSUS to visualize three pre-training bias metrics and their distribution across different regions in Brazil. A random forest model is trained in each region and applied to the others. The aim is to compare the bias for the different regions, focusing on their protected attributes and comparing the model's performance with the metric values.","sentences":["Machine learning (ML) is a growing field of computer science that has found many practical applications in several domains, including Health.","However, as data grows in size and availability, and the number of models that aim to aid or replace human decisions, it raises the concern that these models can be susceptible to bias, which can lead to harm to specific individuals by basing its decisions on protected attributes such as gender, religion, sexual orientation, ethnicity, and others.","Visualization techniques might generate insights and help summarize large datasets, enabling data scientists to understand the data better before training a model by evaluating pre-training metrics applied to the datasets before training, which might contribute to identifying potential harm before any effort is put into training and deploying the models.","This work uses the severe acute respiratory syndrome dataset from OpenDataSUS to visualize three pre-training bias metrics and their distribution across different regions in Brazil.","A random forest model is trained in each region and applied to the others.","The aim is to compare the bias for the different regions, focusing on their protected attributes and comparing the model's performance with the metric values."],"url":"http://arxiv.org/abs/2408.15398v1"}
{"created":"2024-08-27 20:05:52","title":"Analysis of the Performance of the Matrix Multiplication Algorithm on the Cirrus Supercomputer","abstract":"Matrix multiplication is integral to various scientific and engineering disciplines, including machine learning, image processing, and gaming. With the increasing data volumes in areas like machine learning, the demand for efficient parallel processing of large matrices has grown significantly.This study explores the performance of both serial and parallel matrix multiplication on the Cirrus supercomputer at the University of Edinburgh. The results demonstrate the scalability and efficiency of these methods, providing insights for optimizing matrixmultiplication in real-world applications.","sentences":["Matrix multiplication is integral to various scientific and engineering disciplines, including machine learning, image processing, and gaming.","With the increasing data volumes in areas like machine learning, the demand for efficient parallel processing of large matrices has grown significantly.","This study explores the performance of both serial and parallel matrix multiplication on the Cirrus supercomputer at the University of Edinburgh.","The results demonstrate the scalability and efficiency of these methods, providing insights for optimizing matrixmultiplication in real-world applications."],"url":"http://arxiv.org/abs/2408.15384v1"}
{"created":"2024-08-27 19:57:35","title":"An evidence-based and critical analysis of the Fediverse decentralization promises","abstract":"This paper examines the potential of the Fediverse, a federated network of social media and content platforms, to counter the centralization and dominance of commercial platforms on the social Web. We gather evidence from the technology powering the Fediverse (especially the ActivityPub protocol), current statistical data regarding Fediverse user distribution over instances, and the status of two older, similar, decentralized technologies: e-mail and the Web. Our findings suggest that Fediverse will face significant challenges in fulfilling its decentralization promises, potentially hindering its ability to positively impact the social Web on a large scale.","sentences":["This paper examines the potential of the Fediverse, a federated network of social media and content platforms, to counter the centralization and dominance of commercial platforms on the social Web.","We gather evidence from the technology powering the Fediverse (especially the ActivityPub protocol), current statistical data regarding Fediverse user distribution over instances, and the status of two older, similar, decentralized technologies: e-mail and the Web.","Our findings suggest that Fediverse will face significant challenges in fulfilling its decentralization promises, potentially hindering its ability to positively impact the social Web on a large scale."],"url":"http://arxiv.org/abs/2408.15383v1"}
{"created":"2024-08-27 19:33:15","title":"DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model Transformer for Multimodal Aspect-based Sentiment Analysis","abstract":"Multimodal aspect-based sentiment analysis (MABSA) enhances sentiment detection by combining text with other data types like images. However, despite setting significant benchmarks, attention mechanisms exhibit limitations in efficiently modelling long-range dependencies between aspect and opinion targets within the text. They also face challenges in capturing global-context dependencies for visual representations. To this end, we propose Kolmogorov-Arnold Networks (KANs) and Selective State Space model (Mamba) transformer (DualKanbaFormer), a novel architecture to address the above issues. We leverage the power of Mamba to capture global context dependencies, Multi-head Attention (MHA) to capture local context dependencies, and KANs to capture non-linear modelling patterns for both textual representations (textual KanbaFormer) and visual representations (visual KanbaFormer). Furthermore, we fuse the textual KanbaFormer and visual KanbaFomer with a gated fusion layer to capture the inter-modality dynamics. According to extensive experimental results, our model outperforms some state-of-the-art (SOTA) studies on two public datasets.","sentences":["Multimodal aspect-based sentiment analysis (MABSA) enhances sentiment detection by combining text with other data types like images.","However, despite setting significant benchmarks, attention mechanisms exhibit limitations in efficiently modelling long-range dependencies between aspect and opinion targets within the text.","They also face challenges in capturing global-context dependencies for visual representations.","To this end, we propose Kolmogorov-Arnold Networks (KANs) and Selective State Space model (Mamba) transformer (DualKanbaFormer), a novel architecture to address the above issues.","We leverage the power of Mamba to capture global context dependencies, Multi-head Attention (MHA) to capture local context dependencies, and KANs to capture non-linear modelling patterns for both textual representations (textual KanbaFormer) and visual representations (visual KanbaFormer).","Furthermore, we fuse the textual KanbaFormer and visual KanbaFomer with a gated fusion layer to capture the inter-modality dynamics.","According to extensive experimental results, our model outperforms some state-of-the-art (SOTA) studies on two public datasets."],"url":"http://arxiv.org/abs/2408.15379v1"}
{"created":"2024-08-27 19:13:15","title":"Handling Geometric Domain Shifts in Semantic Segmentation of Surgical RGB and Hyperspectral Images","abstract":"Robust semantic segmentation of intraoperative image data holds promise for enabling automatic surgical scene understanding and autonomous robotic surgery. While model development and validation are primarily conducted on idealistic scenes, geometric domain shifts, such as occlusions of the situs, are common in real-world open surgeries. To close this gap, we (1) present the first analysis of state-of-the-art (SOA) semantic segmentation models when faced with geometric out-of-distribution (OOD) data, and (2) propose an augmentation technique called \"Organ Transplantation\", to enhance generalizability. Our comprehensive validation on six different OOD datasets, comprising 600 RGB and hyperspectral imaging (HSI) cubes from 33 pigs, each annotated with 19 classes, reveals a large performance drop in SOA organ segmentation models on geometric OOD data. This performance decline is observed not only in conventional RGB data (with a dice similarity coefficient (DSC) drop of 46 %) but also in HSI data (with a DSC drop of 45 %), despite the richer spectral information content. The performance decline increases with the spatial granularity of the input data. Our augmentation technique improves SOA model performance by up to 67 % for RGB data and 90 % for HSI data, achieving performance at the level of in-distribution performance on real OOD test data. Given the simplicity and effectiveness of our augmentation method, it is a valuable tool for addressing geometric domain shifts in surgical scene segmentation, regardless of the underlying model. Our code and pre-trained models are publicly available at https://github.com/IMSY-DKFZ/htc.","sentences":["Robust semantic segmentation of intraoperative image data holds promise for enabling automatic surgical scene understanding and autonomous robotic surgery.","While model development and validation are primarily conducted on idealistic scenes, geometric domain shifts, such as occlusions of the situs, are common in real-world open surgeries.","To close this gap, we (1) present the first analysis of state-of-the-art (SOA) semantic segmentation models when faced with geometric out-of-distribution (OOD) data, and (2) propose an augmentation technique called \"Organ Transplantation\", to enhance generalizability.","Our comprehensive validation on six different OOD datasets, comprising 600 RGB and hyperspectral imaging (HSI) cubes from 33 pigs, each annotated with 19 classes, reveals a large performance drop in SOA organ segmentation models on geometric OOD data.","This performance decline is observed not only in conventional RGB data (with a dice similarity coefficient (DSC) drop of 46 %) but also in HSI data (with a DSC drop of 45 %), despite the richer spectral information content.","The performance decline increases with the spatial granularity of the input data.","Our augmentation technique improves SOA model performance by up to 67 % for RGB data and 90 % for HSI data, achieving performance at the level of in-distribution performance on real OOD test data.","Given the simplicity and effectiveness of our augmentation method, it is a valuable tool for addressing geometric domain shifts in surgical scene segmentation, regardless of the underlying model.","Our code and pre-trained models are publicly available at https://github.com/IMSY-DKFZ/htc."],"url":"http://arxiv.org/abs/2408.15373v1"}
{"created":"2024-08-27 19:04:32","title":"Optimization Solution Functions as Deterministic Policies for Offline Reinforcement Learning","abstract":"Offline reinforcement learning (RL) is a promising approach for many control applications but faces challenges such as limited data coverage and value function overestimation. In this paper, we propose an implicit actor-critic (iAC) framework that employs optimization solution functions as a deterministic policy (actor) and a monotone function over the optimal value of optimization as a critic. By encoding optimality in the actor policy, we show that the learned policies are robust to the suboptimality of the learned actor parameters via the exponentially decaying sensitivity (EDS) property. We obtain performance guarantees for the proposed iAC framework and show its benefits over general function approximation schemes. Finally, we validate the proposed framework on two real-world applications and show a significant improvement over state-of-the-art (SOTA) offline RL methods.","sentences":["Offline reinforcement learning (RL) is a promising approach for many control applications but faces challenges such as limited data coverage and value function overestimation.","In this paper, we propose an implicit actor-critic (iAC) framework that employs optimization solution functions as a deterministic policy (actor) and a monotone function over the optimal value of optimization as a critic.","By encoding optimality in the actor policy, we show that the learned policies are robust to the suboptimality of the learned actor parameters via the exponentially decaying sensitivity (EDS) property.","We obtain performance guarantees for the proposed iAC framework and show its benefits over general function approximation schemes.","Finally, we validate the proposed framework on two real-world applications and show a significant improvement over state-of-the-art (SOTA) offline RL methods."],"url":"http://arxiv.org/abs/2408.15368v1"}
{"created":"2024-08-27 19:03:11","title":"Pitfalls and Outlooks in Using COMET","abstract":"Since its introduction, the COMET metric has blazed a trail in the machine translation community, given its strong correlation with human judgements of translation quality. Its success stems from being a modified pre-trained multilingual model finetuned for quality assessment. However, it being a machine learning model also gives rise to a new set of pitfalls that may not be widely known. We investigate these unexpected behaviours from three aspects: 1) technical: obsolete software versions and compute precision; 2) data: empty content, language mismatch, and translationese at test time as well as distribution and domain biases in training; 3) usage and reporting: multi-reference support and model referencing in the literature. All of these problems imply that COMET scores is not comparable between papers or even technical setups and we put forward our perspective on fixing each issue. Furthermore, we release the SacreCOMET package that can generate a signature for the software and model configuration as well as an appropriate citation. The goal of this work is to help the community make more sound use of the COMET metric.","sentences":["Since its introduction, the COMET metric has blazed a trail in the machine translation community, given its strong correlation with human judgements of translation quality.","Its success stems from being a modified pre-trained multilingual model finetuned for quality assessment.","However, it being a machine learning model also gives rise to a new set of pitfalls that may not be widely known.","We investigate these unexpected behaviours from three aspects: 1) technical: obsolete software versions and compute precision; 2) data: empty content, language mismatch, and translationese at test time as well as distribution and domain biases in training; 3) usage and reporting: multi-reference support and model referencing in the literature.","All of these problems imply that COMET scores is not comparable between papers or even technical setups and we put forward our perspective on fixing each issue.","Furthermore, we release the SacreCOMET package that can generate a signature for the software and model configuration as well as an appropriate citation.","The goal of this work is to help the community make more sound use of the COMET metric."],"url":"http://arxiv.org/abs/2408.15366v1"}
{"created":"2024-08-27 18:29:47","title":"On the effectiveness of smartphone IMU sensors and Deep Learning in the detection of cardiorespiratory conditions","abstract":"This research introduces an innovative method for the early screening of cardiorespiratory diseases based on an acquisition protocol, which leverages commodity smartphone's Inertial Measurement Units (IMUs) and deep learning techniques. We collected, in a clinical setting, a dataset featuring recordings of breathing kinematics obtained by accelerometer and gyroscope readings from five distinct body regions. We propose an end-to-end deep learning pipeline for early cardiorespiratory disease screening, incorporating a preprocessing step segmenting the data into individual breathing cycles, and a recurrent bidirectional module capturing features from diverse body regions. We employed Leave-one-out-cross-validation with Bayesian optimization for hyperparameter tuning and model selection. The experimental results consistently demonstrated the superior performance of a bidirectional Long-Short Term Memory (Bi-LSTM) as a feature encoder architecture, yielding an average sensitivity of $0.81 \\pm 0.02$, specificity of $0.82 \\pm 0.05$, F1 score of $0.81 \\pm 0.02$, and accuracy of $80.2\\% \\pm 3.9$ across diverse seed variations. We also assessed generalization capabilities on a skewed distribution, comprising exclusively healthy patients not used in training, revealing a true negative rate of $74.8 \\% \\pm 4.5$. The sustained accuracy of predictions over time during breathing cycles within a single patient underscores the efficacy of the preprocessing strategy, highlighting the model's ability to discern significant patterns throughout distinct phases of the respiratory cycle. This investigation underscores the potential usefulness of widely available smartphones as devices for timely cardiorespiratory disease screening in the general population, in at-home settings, offering crucial assistance to public health efforts (especially during a pandemic outbreaks, such as the recent COVID-19).","sentences":["This research introduces an innovative method for the early screening of cardiorespiratory diseases based on an acquisition protocol, which leverages commodity smartphone's Inertial Measurement Units (IMUs) and deep learning techniques.","We collected, in a clinical setting, a dataset featuring recordings of breathing kinematics obtained by accelerometer and gyroscope readings from five distinct body regions.","We propose an end-to-end deep learning pipeline for early cardiorespiratory disease screening, incorporating a preprocessing step segmenting the data into individual breathing cycles, and a recurrent bidirectional module capturing features from diverse body regions.","We employed Leave-one-out-cross-validation with Bayesian optimization for hyperparameter tuning and model selection.","The experimental results consistently demonstrated the superior performance of a bidirectional Long-Short Term Memory (Bi-LSTM) as a feature encoder architecture, yielding an average sensitivity of $0.81 \\pm 0.02$, specificity of $0.82 \\pm 0.05$, F1 score of $0.81 \\pm 0.02$, and accuracy of $80.2\\% \\pm 3.9$ across diverse seed variations.","We also assessed generalization capabilities on a skewed distribution, comprising exclusively healthy patients not used in training, revealing a true negative rate of $74.8 \\% \\pm 4.5$. The sustained accuracy of predictions over time during breathing cycles within a single patient underscores the efficacy of the preprocessing strategy, highlighting the model's ability to discern significant patterns throughout distinct phases of the respiratory cycle.","This investigation underscores the potential usefulness of widely available smartphones as devices for timely cardiorespiratory disease screening in the general population, in at-home settings, offering crucial assistance to public health efforts (especially during a pandemic outbreaks, such as the recent COVID-19)."],"url":"http://arxiv.org/abs/2408.15357v1"}
{"created":"2024-08-27 18:04:07","title":"UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function","abstract":"An LLM is pretrained on trillions of tokens, but the pretrained LLM may still generate undesired responses. To solve this problem, alignment techniques such as RLHF, DPO and KTO are proposed. However, these alignment techniques have limitations. For example, RLHF requires training the reward model and policy separately, which is complex, time-consuming, memory intensive and unstable during training processes. DPO proposes a mapping between an optimal policy and a reward, greatly simplifying the training process of RLHF. However, it can not take full advantages of a reward model and it is limited to pairwise preference data.   In this paper, we propose \\textbf{UN}ified \\textbf{A}lignment (UNA) which unifies RLHF/PPO, DPO and KTO. Firstly, we mathematically prove that given the classical RLHF objective, the optimal policy is induced by a generalize implicit reward function. With this novel mapping between a reward model and an optimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised learning of minimizing the difference between an implicit reward and an explicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and reduce memory burden of RL fine-tuning process; 3. accommodate different feedback types including pairwise, binary and scalar feedback. Downstream experiments show UNA outperforms DPO, KTO and RLHF.","sentences":["An LLM is pretrained on trillions of tokens, but the pretrained LLM may still generate undesired responses.","To solve this problem, alignment techniques such as RLHF, DPO and KTO are proposed.","However, these alignment techniques have limitations.","For example, RLHF requires training the reward model and policy separately, which is complex, time-consuming, memory intensive and unstable during training processes.","DPO proposes a mapping between an optimal policy and a reward, greatly simplifying the training process of RLHF.","However, it can not take full advantages of a reward model and it is limited to pairwise preference data.   ","In this paper, we propose \\textbf{UN}ified \\textbf{A}lignment (UNA) which unifies RLHF/PPO, DPO and KTO.","Firstly, we mathematically prove that given the classical RLHF objective, the optimal policy is induced by a generalize implicit reward function.","With this novel mapping between a reward model and an optimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised learning of minimizing the difference between an implicit reward and an explicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and reduce memory burden of RL fine-tuning process; 3. accommodate different feedback types including pairwise, binary and scalar feedback.","Downstream experiments show UNA outperforms DPO, KTO and RLHF."],"url":"http://arxiv.org/abs/2408.15339v1"}
