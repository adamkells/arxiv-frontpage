{"created":"2024-01-25 18:59:58","title":"Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities","abstract":"We propose to improve transformers of a specific modality with irrelevant data from other modalities, e.g., improve an ImageNet model with audio or point cloud datasets. We would like to highlight that the data samples of the target modality are irrelevant to the other modalities, which distinguishes our method from other works utilizing paired (e.g., CLIP) or interleaved data of different modalities. We propose a methodology named Multimodal Pathway - given a target modality and a transformer designed for it, we use an auxiliary transformer trained with data of another modality and construct pathways to connect components of the two models so that data of the target modality can be processed by both models. In this way, we utilize the universal sequence-to-sequence modeling abilities of transformers obtained from two modalities. As a concrete implementation, we use a modality-specific tokenizer and task-specific head as usual but utilize the transformer blocks of the auxiliary model via a proposed method named Cross-Modal Re-parameterization, which exploits the auxiliary weights without any inference costs. On the image, point cloud, video, and audio recognition tasks, we observe significant and consistent performance improvements with irrelevant data from other modalities. The code and models are available at https://github.com/AILab-CVC/M2PT.","sentences":["We propose to improve transformers of a specific modality with irrelevant data from other modalities, e.g., improve an ImageNet model with audio or point cloud datasets.","We would like to highlight that the data samples of the target modality are irrelevant to the other modalities, which distinguishes our method from other works utilizing paired (e.g., CLIP) or interleaved data of different modalities.","We propose a methodology named Multimodal Pathway - given a target modality and a transformer designed for it, we use an auxiliary transformer trained with data of another modality and construct pathways to connect components of the two models so that data of the target modality can be processed by both models.","In this way, we utilize the universal sequence-to-sequence modeling abilities of transformers obtained from two modalities.","As a concrete implementation, we use a modality-specific tokenizer and task-specific head as usual but utilize the transformer blocks of the auxiliary model via a proposed method named Cross-Modal Re-parameterization, which exploits the auxiliary weights without any inference costs.","On the image, point cloud, video, and audio recognition tasks, we observe significant and consistent performance improvements with irrelevant data from other modalities.","The code and models are available at https://github.com/AILab-CVC/M2PT."],"url":"http://arxiv.org/abs/2401.14405v1"}
{"created":"2024-01-25 18:59:44","title":"Adaptive Mobile Manipulation for Articulated Objects In the Open World","abstract":"Deploying robots in open-ended unstructured environments such as homes has been a long-standing research problem. However, robots are often studied only in closed-off lab settings, and prior mobile manipulation work is restricted to pick-move-place, which is arguably just the tip of the iceberg in this area. In this paper, we introduce Open-World Mobile Manipulation System, a full-stack approach to tackle realistic articulated object operation, e.g. real-world doors, cabinets, drawers, and refrigerators in open-ended unstructured environments. The robot utilizes an adaptive learning framework to initially learns from a small set of data through behavior cloning, followed by learning from online practice on novel objects that fall outside the training distribution. We also develop a low-cost mobile manipulation hardware platform capable of safe and autonomous online adaptation in unstructured environments with a cost of around 20,000 USD. In our experiments we utilize 20 articulate objects across 4 buildings in the CMU campus. With less than an hour of online learning for each object, the system is able to increase success rate from 50% of BC pre-training to 95% using online adaptation. Video results at https://open-world-mobilemanip.github.io/","sentences":["Deploying robots in open-ended unstructured environments such as homes has been a long-standing research problem.","However, robots are often studied only in closed-off lab settings, and prior mobile manipulation work is restricted to pick-move-place, which is arguably just the tip of the iceberg in this area.","In this paper, we introduce Open-World Mobile Manipulation System, a full-stack approach to tackle realistic articulated object operation, e.g. real-world doors, cabinets, drawers, and refrigerators in open-ended unstructured environments.","The robot utilizes an adaptive learning framework to initially learns from a small set of data through behavior cloning, followed by learning from online practice on novel objects that fall outside the training distribution.","We also develop a low-cost mobile manipulation hardware platform capable of safe and autonomous online adaptation in unstructured environments with a cost of around 20,000 USD.","In our experiments we utilize 20 articulate objects across 4 buildings in the CMU campus.","With less than an hour of online learning for each object, the system is able to increase success rate from 50% of BC pre-training to 95% using online adaptation.","Video results at https://open-world-mobilemanip.github.io/"],"url":"http://arxiv.org/abs/2401.14403v1"}
{"created":"2024-01-25 18:59:32","title":"Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect","abstract":"Creating neural text encoders for written Swiss German is challenging due to a dearth of training data combined with dialectal variation. In this paper, we build on several existing multilingual encoders and adapt them to Swiss German using continued pre-training. Evaluation on three diverse downstream tasks shows that simply adding a Swiss German adapter to a modular encoder achieves 97.5% of fully monolithic adaptation performance. We further find that for the task of retrieving Swiss German sentences given Standard German queries, adapting a character-level model is more effective than the other adaptation strategies. We release our code and the models trained for our experiments at https://github.com/ZurichNLP/swiss-german-text-encoders","sentences":["Creating neural text encoders for written Swiss German is challenging due to a dearth of training data combined with dialectal variation.","In this paper, we build on several existing multilingual encoders and adapt them to Swiss German using continued pre-training.","Evaluation on three diverse downstream tasks shows that simply adding a Swiss German adapter to a modular encoder achieves 97.5% of fully monolithic adaptation performance.","We further find that for the task of retrieving Swiss German sentences given Standard German queries, adapting a character-level model is more effective than the other adaptation strategies.","We release our code and the models trained for our experiments at https://github.com/ZurichNLP/swiss-german-text-encoders"],"url":"http://arxiv.org/abs/2401.14400v1"}
{"created":"2024-01-25 18:57:36","title":"pix2gestalt: Amodal Segmentation by Synthesizing Wholes","abstract":"We introduce pix2gestalt, a framework for zero-shot amodal segmentation, which learns to estimate the shape and appearance of whole objects that are only partially visible behind occlusions. By capitalizing on large-scale diffusion models and transferring their representations to this task, we learn a conditional diffusion model for reconstructing whole objects in challenging zero-shot cases, including examples that break natural and physical priors, such as art. As training data, we use a synthetically curated dataset containing occluded objects paired with their whole counterparts. Experiments show that our approach outperforms supervised baselines on established benchmarks. Our model can furthermore be used to significantly improve the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions.","sentences":["We introduce pix2gestalt, a framework for zero-shot amodal segmentation, which learns to estimate the shape and appearance of whole objects that are only partially visible behind occlusions.","By capitalizing on large-scale diffusion models and transferring their representations to this task, we learn a conditional diffusion model for reconstructing whole objects in challenging zero-shot cases, including examples that break natural and physical priors, such as art.","As training data, we use a synthetically curated dataset containing occluded objects paired with their whole counterparts.","Experiments show that our approach outperforms supervised baselines on established benchmarks.","Our model can furthermore be used to significantly improve the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions."],"url":"http://arxiv.org/abs/2401.14398v1"}
{"created":"2024-01-25 18:52:18","title":"O(1) Insertion for Random Walk d-ary Cuckoo Hashing up to the Load Threshold","abstract":"The random walk $d$-ary cuckoo hashing algorithm was defined by Fotakis, Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoo hashing algorithm of Pagh and Rodler. Random walk $d$-ary cuckoo hashing has low space overhead, guaranteed fast access, and fast in practice insertion time. In this paper, we give a theoretical insertion time bound for this algorithm. More precisely, for every $d\\ge 3$ hashes, let $c_d^*$ be the sharp threshold for the load factor at which a valid assignment of $cm$ objects to a hash table of size $m$ likely exists. We show that for any $d\\ge 4$ hashes and load factor $c<c_d^*$, the expectation of the random walk insertion time is $O(1)$, that is, a constant depending only on $d$ and $c$ but not $m$.","sentences":["The random walk $d$-ary cuckoo hashing algorithm was defined by Fotakis, Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoo hashing algorithm of Pagh and Rodler.","Random walk $d$-ary cuckoo hashing has low space overhead, guaranteed fast access, and fast in practice insertion time.","In this paper, we give a theoretical insertion time bound for this algorithm.","More precisely, for every $d\\ge 3$ hashes, let $c_d^*$ be the sharp threshold for the load factor at which a valid assignment of $cm$ objects to a hash table of size $m$ likely exists.","We show that for any $d\\ge 4$ hashes and load factor $c<c_d^*$, the expectation of the random walk insertion time is $O(1)$, that is, a constant depending only on $d$ and $c$ but not $m$."],"url":"http://arxiv.org/abs/2401.14394v1"}
{"created":"2024-01-25 18:46:35","title":"Inconsistency Masks: Removing the Uncertainty from Input-Pseudo-Label Pairs","abstract":"Generating sufficient labeled data is a significant hurdle in the efficient execution of deep learning projects, especially in uncharted territories of image segmentation where labeling demands extensive time, unlike classification tasks. Our study confronts this challenge, operating in an environment constrained by limited hardware resources and the lack of extensive datasets or pre-trained models. We introduce the novel use of Inconsistency Masks (IM) to effectively filter uncertainty in image-pseudo-label pairs, substantially elevating segmentation quality beyond traditional semi-supervised learning techniques. By integrating IM with other methods, we demonstrate remarkable binary segmentation performance on the ISIC 2018 dataset, starting with just 10% labeled data. Notably, three of our hybrid models outperform those trained on the fully labeled dataset. Our approach consistently achieves exceptional results across three additional datasets and shows further improvement when combined with other techniques. For comprehensive and robust evaluation, this paper includes an extensive analysis of prevalent semi-supervised learning strategies, all trained under identical starting conditions. The full code is available at: https://github.com/MichaelVorndran/InconsistencyMasks","sentences":["Generating sufficient labeled data is a significant hurdle in the efficient execution of deep learning projects, especially in uncharted territories of image segmentation where labeling demands extensive time, unlike classification tasks.","Our study confronts this challenge, operating in an environment constrained by limited hardware resources and the lack of extensive datasets or pre-trained models.","We introduce the novel use of Inconsistency Masks (IM) to effectively filter uncertainty in image-pseudo-label pairs, substantially elevating segmentation quality beyond traditional semi-supervised learning techniques.","By integrating IM with other methods, we demonstrate remarkable binary segmentation performance on the ISIC 2018 dataset, starting with just 10% labeled data.","Notably, three of our hybrid models outperform those trained on the fully labeled dataset.","Our approach consistently achieves exceptional results across three additional datasets and shows further improvement when combined with other techniques.","For comprehensive and robust evaluation, this paper includes an extensive analysis of prevalent semi-supervised learning strategies, all trained under identical starting conditions.","The full code is available at: https://github.com/MichaelVorndran/InconsistencyMasks"],"url":"http://arxiv.org/abs/2401.14387v1"}
{"created":"2024-01-25 18:36:10","title":"Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs","abstract":"We propose two graph neural network layers for graphs with features in a Riemannian manifold. First, based on a manifold-valued graph diffusion equation, we construct a diffusion layer that can be applied to an arbitrary number of nodes and graph connectivity patterns. Second, we model a tangent multilayer perceptron by transferring ideas from the vector neuron framework to our general setting. Both layers are equivariant with respect to node permutations and isometries of the feature manifold. These properties have been shown to lead to a beneficial inductive bias in many deep learning tasks. Numerical examples on synthetic data as well as on triangle meshes of the right hippocampus to classify Alzheimer's disease demonstrate the very good performance of our layers.","sentences":["We propose two graph neural network layers for graphs with features in a Riemannian manifold.","First, based on a manifold-valued graph diffusion equation, we construct a diffusion layer that can be applied to an arbitrary number of nodes and graph connectivity patterns.","Second, we model a tangent multilayer perceptron by transferring ideas from the vector neuron framework to our general setting.","Both layers are equivariant with respect to node permutations and isometries of the feature manifold.","These properties have been shown to lead to a beneficial inductive bias in many deep learning tasks.","Numerical examples on synthetic data as well as on triangle meshes of the right hippocampus to classify Alzheimer's disease demonstrate the very good performance of our layers."],"url":"http://arxiv.org/abs/2401.14381v1"}
{"created":"2024-01-25 18:26:29","title":"The GraphTempo Framework for Exploring the Evolution of a Graph through Pattern Aggregation","abstract":"When the focus is on the relationships or interactions between entities, graphs offer an intuitive model for many real-world data. Such graphs are usually large and change over time, thus, requiring models and strategies that explore their evolution. We study the evolution of aggregated graphs and introduce the GraphTempo model that allows temporal and attribute aggregation not only on node level by grouping individual nodes, but on a pattern level as well, where subgraphs are grouped together. Furthermore, We propose an efficient strategy for exploring the evolution of the graph based on identifying time intervals of significant growth, shrinkage or stability. Finally, we evaluate the efficiency and effectiveness of the proposed approach using three real graphs.","sentences":["When the focus is on the relationships or interactions between entities, graphs offer an intuitive model for many real-world data.","Such graphs are usually large and change over time, thus, requiring models and strategies that explore their evolution.","We study the evolution of aggregated graphs and introduce the GraphTempo model that allows temporal and attribute aggregation not only on node level by grouping individual nodes, but on a pattern level as well, where subgraphs are grouped together.","Furthermore, We propose an efficient strategy for exploring the evolution of the graph based on identifying time intervals of significant growth, shrinkage or stability.","Finally, we evaluate the efficiency and effectiveness of the proposed approach using three real graphs."],"url":"http://arxiv.org/abs/2401.14375v1"}
{"created":"2024-01-25 18:14:57","title":"Genie: Achieving Human Parity in Content-Grounded Datasets Generation","abstract":"The lack of high-quality data for content-grounded generation tasks has been identified as a major obstacle to advancing these tasks. To address this gap, we propose Genie, a novel method for automatically generating high-quality content-grounded data. It consists of three stages: (a) Content Preparation, (b) Generation: creating task-specific examples from the content (e.g., question-answer pairs or summaries). (c) Filtering mechanism aiming to ensure the quality and faithfulness of the generated data. We showcase this methodology by generating three large-scale synthetic data, making wishes, for Long-Form Question-Answering (LFQA), summarization, and information extraction. In a human evaluation, our generated data was found to be natural and of high quality. Furthermore, we compare models trained on our data with models trained on human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for Summarization. We show that our models are on par with or outperforming models trained on human-generated data and consistently outperforming them in faithfulness. Finally, we applied our method to create LFQA data within the medical domain and compared a model trained on it with models trained on other domains.","sentences":["The lack of high-quality data for content-grounded generation tasks has been identified as a major obstacle to advancing these tasks.","To address this gap, we propose Genie, a novel method for automatically generating high-quality content-grounded data.","It consists of three stages: (a) Content Preparation, (b) Generation: creating task-specific examples from the content (e.g., question-answer pairs or summaries).","(c) Filtering mechanism aiming to ensure the quality and faithfulness of the generated data.","We showcase this methodology by generating three large-scale synthetic data, making wishes, for Long-Form Question-Answering (LFQA), summarization, and information extraction.","In a human evaluation, our generated data was found to be natural and of high quality.","Furthermore, we compare models trained on our data with models trained on human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for Summarization.","We show that our models are on par with or outperforming models trained on human-generated data and consistently outperforming them in faithfulness.","Finally, we applied our method to create LFQA data within the medical domain and compared a model trained on it with models trained on other domains."],"url":"http://arxiv.org/abs/2401.14367v1"}
{"created":"2024-01-25 17:42:41","title":"Efficient Construction of Long Orientable Sequences","abstract":"An orientable sequence of order $n$ is a cyclic binary sequence such that each length-$n$ substring appears at most once \\emph{in either direction}. Maximal length orientable sequences are known only for $n\\leq 7$, and a trivial upper bound on their length is $2^{n-1} - 2^{\\lfloor(n-1)/2\\rfloor}$. This paper presents the first efficient algorithm to construct orientable sequences with asymptotically optimal length; more specifically, our algorithm constructs orientable sequences via cycle-joining and a successor-rule approach requiring $O(n)$ time per symbol and $O(n)$ space. This answers a longstanding open question from Dai, Martin, Robshaw, Wild [Cryptography and Coding III (1993)]. Our sequences are applied to find new longest-known orientable sequences for $n\\leq 20$.","sentences":["An orientable sequence of order $n$ is a cyclic binary sequence such that each length-$n$ substring appears at most once \\emph{in either direction}.","Maximal length orientable sequences are known only for $n\\leq 7$, and a trivial upper bound on their length is $2^{n-1} - 2^{\\lfloor(n-1)/2\\rfloor}$.","This paper presents the first efficient algorithm to construct orientable sequences with asymptotically optimal length; more specifically, our algorithm constructs orientable sequences via cycle-joining and a successor-rule approach requiring $O(n)$ time per symbol and $O(n)$ space.","This answers a longstanding open question from Dai, Martin, Robshaw, Wild [Cryptography and Coding III (1993)].","Our sequences are applied to find new longest-known orientable sequences for $n\\leq 20$."],"url":"http://arxiv.org/abs/2401.14341v1"}
{"created":"2024-01-25 17:34:34","title":"Progressive Multi-task Anti-Noise Learning and Distilling Frameworks for Fine-grained Vehicle Recognition","abstract":"Fine-grained vehicle recognition (FGVR) is an essential fundamental technology for intelligent transportation systems, but very difficult because of its inherent intra-class variation. Most previous FGVR studies only focus on the intra-class variation caused by different shooting angles, positions, etc., while the intra-class variation caused by image noise has received little attention. This paper proposes a progressive multi-task anti-noise learning (PMAL) framework and a progressive multi-task distilling (PMD) framework to solve the intra-class variation problem in FGVR due to image noise. The PMAL framework achieves high recognition accuracy by treating image denoising as an additional task in image recognition and progressively forcing a model to learn noise invariance. The PMD framework transfers the knowledge of the PMAL-trained model into the original backbone network, which produces a model with about the same recognition accuracy as the PMAL-trained model, but without any additional overheads over the original backbone network. Combining the two frameworks, we obtain models that significantly exceed previous state-of-the-art methods in recognition accuracy on two widely-used, standard FGVR datasets, namely Stanford Cars, and CompCars, as well as three additional surveillance image-based vehicle-type classification datasets, namely Beijing Institute of Technology (BIT)-Vehicle, Vehicle Type Image Data 2 (VTID2), and Vehicle Images Dataset for Make Model Recognition (VIDMMR), without any additional overheads over the original backbone networks. The source code is available at https://github.com/Dichao-Liu/Anti-noise_FGVR","sentences":["Fine-grained vehicle recognition (FGVR) is an essential fundamental technology for intelligent transportation systems, but very difficult because of its inherent intra-class variation.","Most previous FGVR studies only focus on the intra-class variation caused by different shooting angles, positions, etc., while the intra-class variation caused by image noise has received little attention.","This paper proposes a progressive multi-task anti-noise learning (PMAL) framework and a progressive multi-task distilling (PMD) framework to solve the intra-class variation problem in FGVR due to image noise.","The PMAL framework achieves high recognition accuracy by treating image denoising as an additional task in image recognition and progressively forcing a model to learn noise invariance.","The PMD framework transfers the knowledge of the PMAL-trained model into the original backbone network, which produces a model with about the same recognition accuracy as the PMAL-trained model, but without any additional overheads over the original backbone network.","Combining the two frameworks, we obtain models that significantly exceed previous state-of-the-art methods in recognition accuracy on two widely-used, standard FGVR datasets, namely Stanford Cars, and CompCars, as well as three additional surveillance image-based vehicle-type classification datasets, namely Beijing Institute of Technology (BIT)-Vehicle, Vehicle Type Image Data 2 (VTID2), and Vehicle Images Dataset for Make Model Recognition (VIDMMR), without any additional overheads over the original backbone networks.","The source code is available at https://github.com/Dichao-Liu/Anti-noise_FGVR"],"url":"http://arxiv.org/abs/2401.14336v1"}
{"created":"2024-01-25 17:30:08","title":"SunBlock: Cloudless Protection for IoT Systems","abstract":"With an increasing number of Internet of Things (IoT) devices present in homes, there is a rise in the number of potential information leakage channels and their associated security threats and privacy risks. Despite a long history of attacks on IoT devices in unprotected home networks, the problem of accurate, rapid detection and prevention of such attacks remains open. Many existing IoT protection solutions are cloud-based, sometimes ineffective, and might share consumer data with unknown third parties. This paper investigates the potential for effective IoT threat detection locally, on a home router, using AI tools combined with classic rule-based traffic-filtering algorithms. Our results show that with a slight rise of router hardware resources caused by machine learning and traffic filtering logic, a typical home router instrumented with our solution is able to effectively detect risks and protect a typical home IoT network, equaling or outperforming existing popular solutions, without any effects on benign IoT functionality, and without relying on cloud services and third parties.","sentences":["With an increasing number of Internet of Things (IoT) devices present in homes, there is a rise in the number of potential information leakage channels and their associated security threats and privacy risks.","Despite a long history of attacks on IoT devices in unprotected home networks, the problem of accurate, rapid detection and prevention of such attacks remains open.","Many existing IoT protection solutions are cloud-based, sometimes ineffective, and might share consumer data with unknown third parties.","This paper investigates the potential for effective IoT threat detection locally, on a home router, using AI tools combined with classic rule-based traffic-filtering algorithms.","Our results show that with a slight rise of router hardware resources caused by machine learning and traffic filtering logic, a typical home router instrumented with our solution is able to effectively detect risks and protect a typical home IoT network, equaling or outperforming existing popular solutions, without any effects on benign IoT functionality, and without relying on cloud services and third parties."],"url":"http://arxiv.org/abs/2401.14332v1"}
{"created":"2024-01-25 17:20:19","title":"Scalable Tree-based Register Automata Learning","abstract":"Existing active automata learning (AAL) algorithms have demonstrated their potential in capturing the behavior of complex systems (e.g., in analyzing network protocol implementations). The most widely used AAL algorithms generate finite state machine models, such as Mealy machines. For many analysis tasks, however, it is crucial to generate richer classes of models that also show how relations between data parameters affect system behavior. Such models have shown potential to uncover critical bugs, but their learning algorithms do not scale beyond small and well curated experiments. In this paper, we present $SL^\\lambda$, an effective and scalable register automata (RA) learning algorithm that significantly reduces the number of tests required for inferring models. It achieves this by combining a tree-based cost-efficient data structure with mechanisms for computing short and restricted tests. We have implemented $SL^\\lambda$ as a new algorithm in RALib. We evaluate its performance by comparing it against $SL^*$, the current state-of-the-art RA learning algorithm, in a series of experiments, and show superior performance and substantial asymptotic improvements in bigger systems.","sentences":["Existing active automata learning (AAL) algorithms have demonstrated their potential in capturing the behavior of complex systems (e.g., in analyzing network protocol implementations).","The most widely used AAL algorithms generate finite state machine models, such as Mealy machines.","For many analysis tasks, however, it is crucial to generate richer classes of models that also show how relations between data parameters affect system behavior.","Such models have shown potential to uncover critical bugs, but their learning algorithms do not scale beyond small and well curated experiments.","In this paper, we present $SL^\\lambda$, an effective and scalable register automata (RA) learning algorithm that significantly reduces the number of tests required for inferring models.","It achieves this by combining a tree-based cost-efficient data structure with mechanisms for computing short and restricted tests.","We have implemented $SL^\\lambda$ as a new algorithm in RALib.","We evaluate its performance by comparing it against $SL^*$, the current state-of-the-art RA learning algorithm, in a series of experiments, and show superior performance and substantial asymptotic improvements in bigger systems."],"url":"http://arxiv.org/abs/2401.14324v1"}
{"created":"2024-01-25 17:08:13","title":"Maximizing the Minimum Eigenvalue in Constant Dimension","abstract":"In an instance of the minimum eigenvalue problem, we are given a collection of $n$ vectors $v_1,\\ldots, v_n \\subset {\\mathbb{R}^d}$, and the goal is to pick a subset $B\\subseteq [n]$ of given vectors to maximize the minimum eigenvalue of the matrix $\\sum_{i\\in B} v_i v_i^{\\top} $. Often, additional combinatorial constraints such as cardinality constraint $\\left(|B|\\leq k\\right)$ or matroid constraint ($B$ is a basis of a matroid defined on $[n]$) must be satisfied by the chosen set of vectors. The minimum eigenvalue problem with matroid constraints models a wide variety of problems including the Santa Clause problem, the E-design problem, and the constructive Kadison-Singer problem.   In this paper, we give a randomized algorithm that finds a set $B\\subseteq [n]$ subject to any matroid constraint whose minimum eigenvalue is at least $(1-\\epsilon)$ times the optimum, with high probability. The running time of the algorithm is $O\\left( n^{O(d\\log(d)/\\epsilon^2)}\\right)$. In particular, our results give a polynomial time asymptotic scheme when the dimension of the vectors is constant. Our algorithm uses a convex programming relaxation of the problem after guessing a rescaling which allows us to apply pipage rounding and matrix Chernoff inequalities to round to a good solution. The key new component is a structural lemma which enables us to \"guess'' the appropriate rescaling, which could be of independent interest. Our approach generalizes the approximation guarantee to monotone, homogeneous functions and as such we can maximize $\\det(\\sum_{i\\in B} v_i v_i^\\top)^{1/d}$, or minimize any norm of the eigenvalues of the matrix $\\left(\\sum_{i\\in B} v_i v_i^\\top\\right)^{-1} $, with the same running time under some mild assumptions. As a byproduct, we also get a simple algorithm for an algorithmic version of Kadison-Singer problem.","sentences":["In an instance of the minimum eigenvalue problem, we are given a collection of $n$ vectors $v_1,\\ldots, v_n","\\subset {\\mathbb{R}^d}$, and the goal is to pick a subset $B\\subseteq","[n]$ of given vectors to maximize the minimum eigenvalue of the matrix $\\sum_{i\\in B} v_i v_i^{\\top} $.","Often, additional combinatorial constraints such as cardinality constraint $\\left(|B|\\leq k\\right)$ or matroid constraint ($B$ is a basis of a matroid defined on $[n]$) must be satisfied by the chosen set of vectors.","The minimum eigenvalue problem with matroid constraints models a wide variety of problems including the Santa Clause problem, the E-design problem, and the constructive Kadison-Singer problem.   ","In this paper, we give a randomized algorithm that finds a set $B\\subseteq [n]$ subject to any matroid constraint whose minimum eigenvalue is at least $(1-\\epsilon)$ times the optimum, with high probability.","The running time of the algorithm is $O\\left( n^{O(d\\log(d)/\\epsilon^2)}\\right)$. In particular, our results give a polynomial time asymptotic scheme when the dimension of the vectors is constant.","Our algorithm uses a convex programming relaxation of the problem after guessing a rescaling which allows us to apply pipage rounding and matrix Chernoff inequalities to round to a good solution.","The key new component is a structural lemma which enables us to \"guess'' the appropriate rescaling, which could be of independent interest.","Our approach generalizes the approximation guarantee to monotone, homogeneous functions and as such we can maximize $\\det(\\sum_{i\\in B} v_i v_i^\\top)^{1/d}$, or minimize any norm of the eigenvalues of the matrix $\\left(\\sum_{i\\in B} v_i v_i^\\top\\right)^{-1} $, with the same running time under some mild assumptions.","As a byproduct, we also get a simple algorithm for an algorithmic version of Kadison-Singer problem."],"url":"http://arxiv.org/abs/2401.14317v1"}
{"created":"2024-01-25 17:03:02","title":"MultiTest: Physical-Aware Object Insertion for Testing Multi-sensor Fusion Perception Systems","abstract":"Multi-sensor fusion stands as a pivotal technique in addressing numerous safety-critical tasks and applications, e.g., self-driving cars and automated robotic arms. With the continuous advancement in data-driven artificial intelligence (AI), MSF's potential for sensing and understanding intricate external environments has been further amplified, bringing a profound impact on intelligent systems and specifically on their perception systems. Similar to traditional software, adequate testing is also required for AI-enabled MSF systems. Yet, existing testing methods primarily concentrate on single-sensor perception systems (e.g., image-/point cloud-based object detection systems). There remains a lack of emphasis on generating multi-modal test cases for MSF systems. To address these limitations, we design and implement MultiTest, a fitness-guided metamorphic testing method for complex MSF perception systems. MultiTest employs a physical-aware approach to synthesize realistic multi-modal object instances and insert them into critical positions of background images and point clouds. A fitness metric is designed to guide and boost the test generation process. We conduct extensive experiments with five SOTA perception systems to evaluate MultiTest from the perspectives of: (1) generated test cases' realism, (2) fault detection capabilities, and (3) performance improvement. The results show that MultiTest can generate realistic and modality-consistent test data and effectively detect hundreds of diverse faults of an MSF system under test. Moreover, retraining an MSF system on the test cases generated by MultiTest can improve the system's robustness.","sentences":["Multi-sensor fusion stands as a pivotal technique in addressing numerous safety-critical tasks and applications, e.g., self-driving cars and automated robotic arms.","With the continuous advancement in data-driven artificial intelligence (AI), MSF's potential for sensing and understanding intricate external environments has been further amplified, bringing a profound impact on intelligent systems and specifically on their perception systems.","Similar to traditional software, adequate testing is also required for AI-enabled MSF systems.","Yet, existing testing methods primarily concentrate on single-sensor perception systems (e.g., image-/point cloud-based object detection systems).","There remains a lack of emphasis on generating multi-modal test cases for MSF systems.","To address these limitations, we design and implement MultiTest, a fitness-guided metamorphic testing method for complex MSF perception systems.","MultiTest employs a physical-aware approach to synthesize realistic multi-modal object instances and insert them into critical positions of background images and point clouds.","A fitness metric is designed to guide and boost the test generation process.","We conduct extensive experiments with five SOTA perception systems to evaluate MultiTest from the perspectives of: (1) generated test cases' realism, (2) fault detection capabilities, and (3) performance improvement.","The results show that MultiTest can generate realistic and modality-consistent test data and effectively detect hundreds of diverse faults of an MSF system under test.","Moreover, retraining an MSF system on the test cases generated by MultiTest can improve the system's robustness."],"url":"http://arxiv.org/abs/2401.14314v1"}
{"created":"2024-01-25 16:15:56","title":"Bridging Education and Development: IDEs as Interactive Learning Platforms","abstract":"In this work, we introduce a novel approach to programming education - in-IDE courses implemented for IntelliJ-based IDEs via the JetBrains Academy Plugin. The primary objective of this approach is to address the challenge of familiarizing students with industrial technologies by moving all theory and practical materials to a professional IDE. This approach allows students to immediately use modern industrial tools as they are fully integrated into the learning process. We have already applied this approach in over 40 courses, and it successfully educates students across diverse topics such as Plugin Development, Algorithms, Data Analysis, and Language mastery in various programming languages, including Kotlin, Java, C++, and Python. Along with the paper, we are providing the community not only with a new way of learning and a set of ready-made courses but also a collection of helpful resources to assist educators in getting started with the plugin. Finally, we describe in detail an IDE plugin development course that demonstrates how the in-IDE approach covers complex topics easily.","sentences":["In this work, we introduce a novel approach to programming education - in-IDE courses implemented for IntelliJ-based IDEs via the JetBrains Academy Plugin.","The primary objective of this approach is to address the challenge of familiarizing students with industrial technologies by moving all theory and practical materials to a professional IDE.","This approach allows students to immediately use modern industrial tools as they are fully integrated into the learning process.","We have already applied this approach in over 40 courses, and it successfully educates students across diverse topics such as Plugin Development, Algorithms, Data Analysis, and Language mastery in various programming languages, including Kotlin, Java, C++, and Python.","Along with the paper, we are providing the community not only with a new way of learning and a set of ready-made courses but also a collection of helpful resources to assist educators in getting started with the plugin.","Finally, we describe in detail an IDE plugin development course that demonstrates how the in-IDE approach covers complex topics easily."],"url":"http://arxiv.org/abs/2401.14284v1"}
{"created":"2024-01-25 16:09:44","title":"An Instance-Based Approach to the Trace Reconstruction Problem","abstract":"In the trace reconstruction problem, one observes the output of passing a binary string $s \\in \\{0,1\\}^n$ through a deletion channel $T$ times and wishes to recover $s$ from the resulting $T$ \"traces.\" Most of the literature has focused on characterizing the hardness of this problem in terms of the number of traces $T$ needed for perfect reconstruction either in the worst case or in the average case (over input sequences $s$). In this paper, we propose an alternative, instance-based approach to the problem. We define the \"Levenshtein difficulty\" of a problem instance $(s,T)$ as the probability that the resulting traces do not provide enough information for correct recovery with full certainty. One can then try to characterize, for a specific $s$, how $T$ needs to scale in order for the Levenshtein difficulty to go to zero, and seek reconstruction algorithms that match this scaling for each $s$. For a class of binary strings with alternating long runs, we precisely characterize the scaling of $T$ for which the Levenshtein difficulty goes to zero. For this class, we also prove that a simple \"Las Vegas algorithm\" has an error probability that decays to zero with the same rate as that with which the Levenshtein difficulty tends to zero.","sentences":["In the trace reconstruction problem, one observes the output of passing a binary string $s \\in \\{0,1\\}^n$ through a deletion channel $T$ times and wishes to recover $s$ from the resulting $T$ \"traces.\"","Most of the literature has focused on characterizing the hardness of this problem in terms of the number of traces $T$ needed for perfect reconstruction either in the worst case or in the average case (over input sequences $s$).","In this paper, we propose an alternative, instance-based approach to the problem.","We define the \"Levenshtein difficulty\" of a problem instance $(s,T)$ as the probability that the resulting traces do not provide enough information for correct recovery with full certainty.","One can then try to characterize, for a specific $s$, how $T$ needs to scale in order for the Levenshtein difficulty to go to zero, and seek reconstruction algorithms that match this scaling for each $s$. For a class of binary strings with alternating long runs, we precisely characterize the scaling of $T$ for which the Levenshtein difficulty goes to zero.","For this class, we also prove that a simple \"Las Vegas algorithm\" has an error probability that decays to zero with the same rate as that with which the Levenshtein difficulty tends to zero."],"url":"http://arxiv.org/abs/2401.14277v1"}
{"created":"2024-01-25 16:07:59","title":"libcdict: fast dictionaries in C","abstract":"A common requirement in science is to store and share large sets of simulation data in an efficient, nested, flexible and human-readable way. Such datasets contain number counts and distributions, i.e. histograms and maps, of arbitrary dimension and variable type, e.g. floating-point number, integer or character string. Modern high-level programming languages like Perl and Python have associated arrays, knowns as dictionaries or hashes, respectively, to fulfil this storage need. Low-level languages used more commonly for fast computational simulations, such as C and Fortran, lack this functionality. We present libcdict, a C dictionary library, to solve this problem. Libcdict provides C and Fortran application programming interfaces (APIs) to native dictionaries, called cdicts, and functions for cdicts to load and save these as JSON and hence for easy interpretation in other software and languages like Perl, Python and R.","sentences":["A common requirement in science is to store and share large sets of simulation data in an efficient, nested, flexible and human-readable way.","Such datasets contain number counts and distributions, i.e. histograms and maps, of arbitrary dimension and variable type, e.g. floating-point number, integer or character string.","Modern high-level programming languages like Perl and Python have associated arrays, knowns as dictionaries or hashes, respectively, to fulfil this storage need.","Low-level languages used more commonly for fast computational simulations, such as C and Fortran, lack this functionality.","We present libcdict, a C dictionary library, to solve this problem.","Libcdict provides C and Fortran application programming interfaces (APIs) to native dictionaries, called cdicts, and functions for cdicts to load and save these as JSON and hence for easy interpretation in other software and languages like Perl, Python and R."],"url":"http://arxiv.org/abs/2401.14272v1"}
{"created":"2024-01-25 16:05:44","title":"Viscoelasticty with physics-augmented neural networks: Model formulation and training methods without prescribed internal variables","abstract":"We present an approach for the data-driven modeling of nonlinear viscoelastic materials at small strains which is based on physics-augmented neural networks (NNs) and requires only stress and strain paths for training. The model is built on the concept of generalized standard materials and is therefore thermodynamically consistent by construction. It consists of a free energy and a dissipation potential, which can be either expressed by the components of their tensor arguments or by a suitable set of invariants. The two potentials are described by fully/partially input convex neural networks. For training of the NN model by paths of stress and strain, an efficient and flexible training method based on a recurrent cell, particularly a long short-term memory cell, is developed to automatically generate the internal variable(s) during the training process. The proposed method is benchmarked and thoroughly compared with existing approaches. These include a method that obtains the internal variable by integrating the evolution equation over the entire sequence, while the other method uses an an auxiliary feedforward neural network for the internal variable(s). Databases for training are generated by using a conventional nonlinear viscoelastic reference model, where 3D and 2D plane strain data with either ideal or noisy stresses are generated. The coordinate-based and the invariant-based formulation are compared and the advantages of the latter are demonstrated. Afterwards, the invariant-based model is calibrated by applying the three training methods using ideal or noisy stress data. All methods yield good results, but differ in computation time and usability for large data sets. The presented training method based on a recurrent cell turns out to be particularly robust and widely applicable and thus represents a promising approach for the calibration of other types of models as well.","sentences":["We present an approach for the data-driven modeling of nonlinear viscoelastic materials at small strains which is based on physics-augmented neural networks (NNs) and requires only stress and strain paths for training.","The model is built on the concept of generalized standard materials and is therefore thermodynamically consistent by construction.","It consists of a free energy and a dissipation potential, which can be either expressed by the components of their tensor arguments or by a suitable set of invariants.","The two potentials are described by fully/partially input convex neural networks.","For training of the NN model by paths of stress and strain, an efficient and flexible training method based on a recurrent cell, particularly a long short-term memory cell, is developed to automatically generate the internal variable(s) during the training process.","The proposed method is benchmarked and thoroughly compared with existing approaches.","These include a method that obtains the internal variable by integrating the evolution equation over the entire sequence, while the other method uses an an auxiliary feedforward neural network for the internal variable(s).","Databases for training are generated by using a conventional nonlinear viscoelastic reference model, where 3D and 2D plane strain data with either ideal or noisy stresses are generated.","The coordinate-based and the invariant-based formulation are compared and the advantages of the latter are demonstrated.","Afterwards, the invariant-based model is calibrated by applying the three training methods using ideal or noisy stress data.","All methods yield good results, but differ in computation time and usability for large data sets.","The presented training method based on a recurrent cell turns out to be particularly robust and widely applicable and thus represents a promising approach for the calibration of other types of models as well."],"url":"http://arxiv.org/abs/2401.14270v1"}
{"created":"2024-01-25 16:02:56","title":"GPTVoiceTasker: LLM-Powered Virtual Assistant for Smartphone","abstract":"Virtual assistants have the potential to play an important role in helping users achieves different tasks. However, these systems face challenges in their real-world usability, characterized by inefficiency and struggles in grasping user intentions. Leveraging recent advances in Large Language Models (LLMs), we introduce GptVoiceTasker, a virtual assistant poised to enhance user experiences and task efficiency on mobile devices. GptVoiceTasker excels at intelligently deciphering user commands and executing relevant device interactions to streamline task completion. The system continually learns from historical user commands to automate subsequent usages, further enhancing execution efficiency. Our experiments affirm GptVoiceTasker's exceptional command interpretation abilities and the precision of its task automation module. In our user study, GptVoiceTasker boosted task efficiency in real-world scenarios by 34.85%, accompanied by positive participant feedback. We made GptVoiceTasker open-source, inviting further research into LLMs utilization for diverse tasks through prompt engineering and leveraging user usage data to improve efficiency.","sentences":["Virtual assistants have the potential to play an important role in helping users achieves different tasks.","However, these systems face challenges in their real-world usability, characterized by inefficiency and struggles in grasping user intentions.","Leveraging recent advances in Large Language Models (LLMs), we introduce GptVoiceTasker, a virtual assistant poised to enhance user experiences and task efficiency on mobile devices.","GptVoiceTasker excels at intelligently deciphering user commands and executing relevant device interactions to streamline task completion.","The system continually learns from historical user commands to automate subsequent usages, further enhancing execution efficiency.","Our experiments affirm GptVoiceTasker's exceptional command interpretation abilities and the precision of its task automation module.","In our user study, GptVoiceTasker boosted task efficiency in real-world scenarios by 34.85%, accompanied by positive participant feedback.","We made GptVoiceTasker open-source, inviting further research into LLMs utilization for diverse tasks through prompt engineering and leveraging user usage data to improve efficiency."],"url":"http://arxiv.org/abs/2401.14268v1"}
{"created":"2024-01-25 15:47:18","title":"Producing Plankton Classifiers that are Robust to Dataset Shift","abstract":"Modern plankton high-throughput monitoring relies on deep learning classifiers for species recognition in water ecosystems. Despite satisfactory nominal performances, a significant challenge arises from Dataset Shift, which causes performances to drop during deployment. In our study, we integrate the ZooLake dataset with manually-annotated images from 10 independent days of deployment, serving as test cells to benchmark Out-Of-Dataset (OOD) performances. Our analysis reveals instances where classifiers, initially performing well in In-Dataset conditions, encounter notable failures in practical scenarios. For example, a MobileNet with a 92% nominal test accuracy shows a 77% OOD accuracy. We systematically investigate conditions leading to OOD performance drops and propose a preemptive assessment method to identify potential pitfalls when classifying new data, and pinpoint features in OOD images that adversely impact classification. We present a three-step pipeline: (i) identifying OOD degradation compared to nominal test performance, (ii) conducting a diagnostic analysis of degradation causes, and (iii) providing solutions. We find that ensembles of BEiT vision transformers, with targeted augmentations addressing OOD robustness, geometric ensembling, and rotation-based test-time augmentation, constitute the most robust model, which we call BEsT model. It achieves an 83% OOD accuracy, with errors concentrated on container classes. Moreover, it exhibits lower sensitivity to dataset shift, and reproduces well the plankton abundances. Our proposed pipeline is applicable to generic plankton classifiers, contingent on the availability of suitable test cells. By identifying critical shortcomings and offering practical procedures to fortify models against dataset shift, our study contributes to the development of more reliable plankton classification technologies.","sentences":["Modern plankton high-throughput monitoring relies on deep learning classifiers for species recognition in water ecosystems.","Despite satisfactory nominal performances, a significant challenge arises from Dataset Shift, which causes performances to drop during deployment.","In our study, we integrate the ZooLake dataset with manually-annotated images from 10 independent days of deployment, serving as test cells to benchmark Out-Of-Dataset (OOD) performances.","Our analysis reveals instances where classifiers, initially performing well in In-Dataset conditions, encounter notable failures in practical scenarios.","For example, a MobileNet with a 92% nominal test accuracy shows a 77% OOD accuracy.","We systematically investigate conditions leading to OOD performance drops and propose a preemptive assessment method to identify potential pitfalls when classifying new data, and pinpoint features in OOD images that adversely impact classification.","We present a three-step pipeline: (i) identifying OOD degradation compared to nominal test performance, (ii) conducting a diagnostic analysis of degradation causes, and (iii) providing solutions.","We find that ensembles of BEiT vision transformers, with targeted augmentations addressing OOD robustness, geometric ensembling, and rotation-based test-time augmentation, constitute the most robust model, which we call BEsT model.","It achieves an 83% OOD accuracy, with errors concentrated on container classes.","Moreover, it exhibits lower sensitivity to dataset shift, and reproduces well the plankton abundances.","Our proposed pipeline is applicable to generic plankton classifiers, contingent on the availability of suitable test cells.","By identifying critical shortcomings and offering practical procedures to fortify models against dataset shift, our study contributes to the development of more reliable plankton classification technologies."],"url":"http://arxiv.org/abs/2401.14256v1"}
{"created":"2024-01-25 15:45:28","title":"Interpretable Solutions for Breast Cancer Diagnosis with Grammatical Evolution and Data Augmentation","abstract":"Medical imaging diagnosis increasingly relies on Machine Learning (ML) models. This is a task that is often hampered by severely imbalanced datasets, where positive cases can be quite rare. Their use is further compromised by their limited interpretability, which is becoming increasingly important. While post-hoc interpretability techniques such as SHAP and LIME have been used with some success on so-called black box models, the use of inherently understandable models makes such endeavors more fruitful. This paper addresses these issues by demonstrating how a relatively new synthetic data generation technique, STEM, can be used to produce data to train models produced by Grammatical Evolution (GE) that are inherently understandable. STEM is a recently introduced combination of the Synthetic Minority Oversampling Technique (SMOTE), Edited Nearest Neighbour (ENN), and Mixup; it has previously been successfully used to tackle both between class and within class imbalance issues. We test our technique on the Digital Database for Screening Mammography (DDSM) and the Wisconsin Breast Cancer (WBC) datasets and compare Area Under the Curve (AUC) results with an ensemble of the top three performing classifiers from a set of eight standard ML classifiers with varying degrees of interpretability. We demonstrate that the GE-derived models present the best AUC while still maintaining interpretable solutions.","sentences":["Medical imaging diagnosis increasingly relies on Machine Learning (ML) models.","This is a task that is often hampered by severely imbalanced datasets, where positive cases can be quite rare.","Their use is further compromised by their limited interpretability, which is becoming increasingly important.","While post-hoc interpretability techniques such as SHAP and LIME have been used with some success on so-called black box models, the use of inherently understandable models makes such endeavors more fruitful.","This paper addresses these issues by demonstrating how a relatively new synthetic data generation technique, STEM, can be used to produce data to train models produced by Grammatical Evolution (GE) that are inherently understandable.","STEM is a recently introduced combination of the Synthetic Minority Oversampling Technique (SMOTE), Edited Nearest Neighbour (ENN), and Mixup; it has previously been successfully used to tackle both between class and within class imbalance issues.","We test our technique on the Digital Database for Screening Mammography (DDSM) and the Wisconsin Breast Cancer (WBC) datasets and compare Area Under the Curve (AUC) results with an ensemble of the top three performing classifiers from a set of eight standard ML classifiers with varying degrees of interpretability.","We demonstrate that the GE-derived models present the best AUC while still maintaining interpretable solutions."],"url":"http://arxiv.org/abs/2401.14255v1"}
{"created":"2024-01-25 15:42:36","title":"On mission Twitter Profiles: A Study of Selective Toxic Behavior","abstract":"The argument for persistent social media influence campaigns, often funded by malicious entities, is gaining traction. These entities utilize instrumented profiles to disseminate divisive content and disinformation, shaping public perception. Despite ample evidence of these instrumented profiles, few identification methods exist to locate them in the wild. To evade detection and appear genuine, small clusters of instrumented profiles engage in unrelated discussions, diverting attention from their true goals. This strategic thematic diversity conceals their selective polarity towards certain topics and fosters public trust.   This study aims to characterize profiles potentially used for influence operations, termed 'on-mission profiles,' relying solely on thematic content diversity within unlabeled data. Distinguishing this work is its focus on content volume and toxicity towards specific themes. Longitudinal data from 138K Twitter or X, profiles and 293M tweets enables profiling based on theme diversity. High thematic diversity groups predominantly produce toxic content concerning specific themes, like politics, health, and news classifying them as 'on-mission' profiles.   Using the identified ``on-mission\" profiles, we design a classifier for unseen, unlabeled data. Employing a linear SVM model, we train and test it on an 80/20% split of the most diverse profiles. The classifier achieves a flawless 100% accuracy, facilitating the discovery of previously unknown ``on-mission\" profiles in the wild.","sentences":["The argument for persistent social media influence campaigns, often funded by malicious entities, is gaining traction.","These entities utilize instrumented profiles to disseminate divisive content and disinformation, shaping public perception.","Despite ample evidence of these instrumented profiles, few identification methods exist to locate them in the wild.","To evade detection and appear genuine, small clusters of instrumented profiles engage in unrelated discussions, diverting attention from their true goals.","This strategic thematic diversity conceals their selective polarity towards certain topics and fosters public trust.   ","This study aims to characterize profiles potentially used for influence operations, termed 'on-mission profiles,' relying solely on thematic content diversity within unlabeled data.","Distinguishing this work is its focus on content volume and toxicity towards specific themes.","Longitudinal data from 138K Twitter or X, profiles and 293M tweets enables profiling based on theme diversity.","High thematic diversity groups predominantly produce toxic content concerning specific themes, like politics, health, and news classifying them as 'on-mission' profiles.   ","Using the identified ``on-mission\" profiles, we design a classifier for unseen, unlabeled data.","Employing a linear SVM model, we train and test it on an 80/20% split of the most diverse profiles.","The classifier achieves a flawless 100% accuracy, facilitating the discovery of previously unknown ``on-mission\" profiles in the wild."],"url":"http://arxiv.org/abs/2401.14252v1"}
{"created":"2024-01-25 14:53:30","title":"Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations","abstract":"Recognizing visual entities in a natural language sentence and arranging them in a 2D spatial layout require a compositional understanding of language and space. This task of layout prediction is valuable in text-to-image synthesis as it allows localized and controlled in-painting of the image. In this comparative study it is shown that we can predict layouts from language representations that implicitly or explicitly encode sentence syntax, if the sentences mention similar entity-relationships to the ones seen during training. To test compositional understanding, we collect a test set of grammatically correct sentences and layouts describing compositions of entities and relations that unlikely have been seen during training. Performance on this test set substantially drops, showing that current models rely on correlations in the training data and have difficulties in understanding the structure of the input sentences. We propose a novel structural loss function that better enforces the syntactic structure of the input sentence and show large performance gains in the task of 2D spatial layout prediction conditioned on text. The loss has the potential to be used in other generation tasks where a tree-like structure underlies the conditioning modality. Code, trained models and the USCOCO evaluation set will be made available via github.","sentences":["Recognizing visual entities in a natural language sentence and arranging them in a 2D spatial layout require a compositional understanding of language and space.","This task of layout prediction is valuable in text-to-image synthesis as it allows localized and controlled in-painting of the image.","In this comparative study it is shown that we can predict layouts from language representations that implicitly or explicitly encode sentence syntax, if the sentences mention similar entity-relationships to the ones seen during training.","To test compositional understanding, we collect a test set of grammatically correct sentences and layouts describing compositions of entities and relations that unlikely have been seen during training.","Performance on this test set substantially drops, showing that current models rely on correlations in the training data and have difficulties in understanding the structure of the input sentences.","We propose a novel structural loss function that better enforces the syntactic structure of the input sentence and show large performance gains in the task of 2D spatial layout prediction conditioned on text.","The loss has the potential to be used in other generation tasks where a tree-like structure underlies the conditioning modality.","Code, trained models and the USCOCO evaluation set will be made available via github."],"url":"http://arxiv.org/abs/2401.14212v1"}
{"created":"2024-01-25 14:49:15","title":"Communication-Efficient Federated Learning through Adaptive Weight Clustering and Server-Side Distillation","abstract":"Federated Learning (FL) is a promising technique for the collaborative training of deep neural networks across multiple devices while preserving data privacy. Despite its potential benefits, FL is hindered by excessive communication costs due to repeated server-client communication during training. To address this challenge, model compression techniques, such as sparsification and weight clustering are applied, which often require modifying the underlying model aggregation schemes or involve cumbersome hyperparameter tuning, with the latter not only adjusts the model's compression rate but also limits model's potential for continuous improvement over growing data. In this paper, we propose FedCompress, a novel approach that combines dynamic weight clustering and server-side knowledge distillation to reduce communication costs while learning highly generalizable models. Through a comprehensive evaluation on diverse public datasets, we demonstrate the efficacy of our approach compared to baselines in terms of communication costs and inference speed. We will make our implementation public upon acceptance.","sentences":["Federated Learning (FL) is a promising technique for the collaborative training of deep neural networks across multiple devices while preserving data privacy.","Despite its potential benefits, FL is hindered by excessive communication costs due to repeated server-client communication during training.","To address this challenge, model compression techniques, such as sparsification and weight clustering are applied, which often require modifying the underlying model aggregation schemes or involve cumbersome hyperparameter tuning, with the latter not only adjusts the model's compression rate but also limits model's potential for continuous improvement over growing data.","In this paper, we propose FedCompress, a novel approach that combines dynamic weight clustering and server-side knowledge distillation to reduce communication costs while learning highly generalizable models.","Through a comprehensive evaluation on diverse public datasets, we demonstrate the efficacy of our approach compared to baselines in terms of communication costs and inference speed.","We will make our implementation public upon acceptance."],"url":"http://arxiv.org/abs/2401.14211v1"}
{"created":"2024-01-25 14:21:14","title":"MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning","abstract":"In this study, we explore the synergy of deep learning and financial market applications, focusing on pair trading. This market-neutral strategy is integral to quantitative finance and is apt for advanced deep-learning techniques. A pivotal challenge in pair trading is discerning temporal correlations among entities, necessitating the integration of diverse data modalities. Addressing this, we introduce a novel framework, Multi-modal Temporal Relation Graph Learning (MTRGL). MTRGL combines time series data and discrete features into a temporal graph and employs a memory-based temporal graph neural network. This approach reframes temporal correlation identification as a temporal graph link prediction task, which has shown empirical success. Our experiments on real-world datasets confirm the superior performance of MTRGL, emphasizing its promise in refining automated pair trading strategies.","sentences":["In this study, we explore the synergy of deep learning and financial market applications, focusing on pair trading.","This market-neutral strategy is integral to quantitative finance and is apt for advanced deep-learning techniques.","A pivotal challenge in pair trading is discerning temporal correlations among entities, necessitating the integration of diverse data modalities.","Addressing this, we introduce a novel framework, Multi-modal Temporal Relation Graph Learning (MTRGL).","MTRGL combines time series data and discrete features into a temporal graph and employs a memory-based temporal graph neural network.","This approach reframes temporal correlation identification as a temporal graph link prediction task, which has shown empirical success.","Our experiments on real-world datasets confirm the superior performance of MTRGL, emphasizing its promise in refining automated pair trading strategies."],"url":"http://arxiv.org/abs/2401.14199v1"}
{"created":"2024-01-25 14:03:15","title":"How Can Large Language Models Understand Spatial-Temporal Data?","abstract":"While Large Language Models (LLMs) dominate tasks like natural language processing and computer vision, harnessing their power for spatial-temporal forecasting remains challenging. The disparity between sequential text and complex spatial-temporal data hinders this application. To address this issue, this paper introduces STG-LLM, an innovative approach empowering LLMs for spatial-temporal forecasting. We tackle the data mismatch by proposing: 1) STG-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graph data into concise tokens capturing both spatial and temporal relationships; 2) STG-Adapter: This minimalistic adapter, consisting of linear encoding and decoding layers, bridges the gap between tokenized data and LLM comprehension. By fine-tuning only a small set of parameters, it can effectively grasp the semantics of tokens generated by STG-Tokenizer, while preserving the original natural language understanding capabilities of LLMs. Extensive experiments on diverse spatial-temporal benchmark datasets show that STG-LLM successfully unlocks LLM potential for spatial-temporal forecasting. Remarkably, our approach achieves competitive performance on par with dedicated SOTA methods.","sentences":["While Large Language Models (LLMs) dominate tasks like natural language processing and computer vision, harnessing their power for spatial-temporal forecasting remains challenging.","The disparity between sequential text and complex spatial-temporal data hinders this application.","To address this issue, this paper introduces STG-LLM, an innovative approach empowering LLMs for spatial-temporal forecasting.","We tackle the data mismatch by proposing: 1) STG-Tokenizer:","This spatial-temporal graph tokenizer transforms intricate graph data into concise tokens capturing both spatial and temporal relationships; 2) STG-Adapter:","This minimalistic adapter, consisting of linear encoding and decoding layers, bridges the gap between tokenized data and LLM comprehension.","By fine-tuning only a small set of parameters, it can effectively grasp the semantics of tokens generated by STG-Tokenizer, while preserving the original natural language understanding capabilities of LLMs.","Extensive experiments on diverse spatial-temporal benchmark datasets show that STG-LLM successfully unlocks LLM potential for spatial-temporal forecasting.","Remarkably, our approach achieves competitive performance on par with dedicated SOTA methods."],"url":"http://arxiv.org/abs/2401.14192v1"}
{"created":"2024-01-25 13:07:34","title":"Alleviating Structural Distribution Shift in Graph Anomaly Detection","abstract":"Graph anomaly detection (GAD) is a challenging binary classification problem due to its different structural distribution between anomalies and normal nodes -- abnormal nodes are a minority, therefore holding high heterophily and low homophily compared to normal nodes. Furthermore, due to various time factors and the annotation preferences of human experts, the heterophily and homophily can change across training and testing data, which is called structural distribution shift (SDS) in this paper. The mainstream methods are built on graph neural networks (GNNs), benefiting the classification of normals from aggregating homophilous neighbors, yet ignoring the SDS issue for anomalies and suffering from poor generalization.   This work solves the problem from a feature view. We observe that the degree of SDS varies between anomalies and normal nodes. Hence to address the issue, the key lies in resisting high heterophily for anomalies meanwhile benefiting the learning of normals from homophily. We tease out the anomaly features on which we constrain to mitigate the effect of heterophilous neighbors and make them invariant. We term our proposed framework as Graph Decomposition Network (GDN). Extensive experiments are conducted on two benchmark datasets, and the proposed framework achieves a remarkable performance boost in GAD, especially in an SDS environment where anomalies have largely different structural distribution across training and testing environments. Codes are open-sourced in https://github.com/blacksingular/wsdm_GDN.","sentences":["Graph anomaly detection (GAD) is a challenging binary classification problem due to its different structural distribution between anomalies and normal nodes -- abnormal nodes are a minority, therefore holding high heterophily and low homophily compared to normal nodes.","Furthermore, due to various time factors and the annotation preferences of human experts, the heterophily and homophily can change across training and testing data, which is called structural distribution shift (SDS) in this paper.","The mainstream methods are built on graph neural networks (GNNs), benefiting the classification of normals from aggregating homophilous neighbors, yet ignoring the SDS issue for anomalies and suffering from poor generalization.   ","This work solves the problem from a feature view.","We observe that the degree of SDS varies between anomalies and normal nodes.","Hence to address the issue, the key lies in resisting high heterophily for anomalies meanwhile benefiting the learning of normals from homophily.","We tease out the anomaly features on which we constrain to mitigate the effect of heterophilous neighbors and make them invariant.","We term our proposed framework as Graph Decomposition Network (GDN).","Extensive experiments are conducted on two benchmark datasets, and the proposed framework achieves a remarkable performance boost in GAD, especially in an SDS environment where anomalies have largely different structural distribution across training and testing environments.","Codes are open-sourced in https://github.com/blacksingular/wsdm_GDN."],"url":"http://arxiv.org/abs/2401.14155v1"}
{"created":"2024-01-25 13:05:06","title":"Agent-based Simulation with Netlogo to Evaluate AmI Scenarios","abstract":"In this paper an agent-based simulation is developed in order to evaluate an AmI scenario based on agents. Many AmI applications are implemented through agents but they are not compared to any other existing alternative in order to evaluate the relative benefits of using them. The proposal simulation environment developed in Netlogo analyse such benefits using two evaluation criteria: First, measuring agent satisfaction of different types of desires along the execution. Second, measuring time savings obtained through a correct use of context information.   So, here, a previously suggested agent architecture, an ontology and a 12-steps protocol to provide AmI services in airports, is evaluated using a NetLogo simulation environment. The present work uses a NetLogo model considering scalability problems of this application domain but using FIPA and BDI extensions to be coherent with our previous works and our previous JADE implementation of them.   The NetLogo model presented simulates an airport with agent users passing through several zones located in a specific order in a map: passport controls, check-in counters of airline companies, boarding gates, different types of shopping. Although initial data in simulations are generated randomly, and the model is just an approximation of real-world airports, the definition of this case of use of Ambient Intelligence through NetLogo agents opens an interesting way to evaluate the benefits of using Ambient Intelligence, which is a significant contribution to the final development of them.","sentences":["In this paper an agent-based simulation is developed in order to evaluate an AmI scenario based on agents.","Many AmI applications are implemented through agents but they are not compared to any other existing alternative in order to evaluate the relative benefits of using them.","The proposal simulation environment developed in Netlogo analyse such benefits using two evaluation criteria: First, measuring agent satisfaction of different types of desires along the execution.","Second, measuring time savings obtained through a correct use of context information.   ","So, here, a previously suggested agent architecture, an ontology and a 12-steps protocol to provide AmI services in airports, is evaluated using a NetLogo simulation environment.","The present work uses a NetLogo model considering scalability problems of this application domain but using FIPA and BDI extensions to be coherent with our previous works and our previous JADE implementation of them.   ","The NetLogo model presented simulates an airport with agent users passing through several zones located in a specific order in a map: passport controls, check-in counters of airline companies, boarding gates, different types of shopping.","Although initial data in simulations are generated randomly, and the model is just an approximation of real-world airports, the definition of this case of use of Ambient Intelligence through NetLogo agents opens an interesting way to evaluate the benefits of using Ambient Intelligence, which is a significant contribution to the final development of them."],"url":"http://arxiv.org/abs/2401.14153v1"}
{"created":"2024-01-25 12:55:48","title":"LanDA: Language-Guided Multi-Source Domain Adaptation","abstract":"Multi-Source Domain Adaptation (MSDA) aims to mitigate changes in data distribution when transferring knowledge from multiple labeled source domains to an unlabeled target domain. However, existing MSDA techniques assume target domain images are available, yet overlook image-rich semantic information. Consequently, an open question is whether MSDA can be guided solely by textual cues in the absence of target domain images. By employing a multimodal model with a joint image and language embedding space, we propose a novel language-guided MSDA approach, termed LanDA, based on optimal transfer theory, which facilitates the transfer of multiple source domains to a new target domain, requiring only a textual description of the target domain without needing even a single target domain image, while retaining task-relevant information. We present extensive experiments across different transfer scenarios using a suite of relevant benchmarks, demonstrating that LanDA outperforms standard fine-tuning and ensemble approaches in both target and source domains.","sentences":["Multi-Source Domain Adaptation (MSDA) aims to mitigate changes in data distribution when transferring knowledge from multiple labeled source domains to an unlabeled target domain.","However, existing MSDA techniques assume target domain images are available, yet overlook image-rich semantic information.","Consequently, an open question is whether MSDA can be guided solely by textual cues in the absence of target domain images.","By employing a multimodal model with a joint image and language embedding space, we propose a novel language-guided MSDA approach, termed LanDA, based on optimal transfer theory, which facilitates the transfer of multiple source domains to a new target domain, requiring only a textual description of the target domain without needing even a single target domain image, while retaining task-relevant information.","We present extensive experiments across different transfer scenarios using a suite of relevant benchmarks, demonstrating that LanDA outperforms standard fine-tuning and ensemble approaches in both target and source domains."],"url":"http://arxiv.org/abs/2401.14148v1"}
{"created":"2024-01-25 12:53:40","title":"Concept: Dynamic Risk Assessment for AI-Controlled Robotic Systems","abstract":"AI-controlled robotic systems pose a risk to human workers and the environment. Classical risk assessment methods cannot adequately describe such black box systems. Therefore, new methods for a dynamic risk assessment of such AI-controlled systems are required. In this paper, we introduce the concept of a new dynamic risk assessment approach for AI-controlled robotic systems. The approach pipelines five blocks: (i) a Data Logging that logs the data of the given simulation, (ii) a Skill Detection that automatically detects the executed skills with a deep learning technique, (iii) a Behavioral Analysis that creates the behavioral profile of the robotic systems, (iv) a Risk Model Generation that automatically transforms the behavioral profile and risk data containing the failure probabilities of robotic hardware components into advanced hybrid risk models, and (v) Risk Model Solvers for the numerical evaluation of the generated hybrid risk models.   Keywords: Dynamic Risk Assessment, Hybrid Risk Models, M2M Transformation, ROS, AI-Controlled Robotic Systems, Deep Learning, Reinforcement Learning","sentences":["AI-controlled robotic systems pose a risk to human workers and the environment.","Classical risk assessment methods cannot adequately describe such black box systems.","Therefore, new methods for a dynamic risk assessment of such AI-controlled systems are required.","In this paper, we introduce the concept of a new dynamic risk assessment approach for AI-controlled robotic systems.","The approach pipelines five blocks: (i) a Data Logging that logs the data of the given simulation, (ii) a Skill Detection that automatically detects the executed skills with a deep learning technique, (iii) a Behavioral Analysis that creates the behavioral profile of the robotic systems, (iv) a Risk Model Generation that automatically transforms the behavioral profile and risk data containing the failure probabilities of robotic hardware components into advanced hybrid risk models, and (v) Risk Model Solvers for the numerical evaluation of the generated hybrid risk models.   ","Keywords: Dynamic Risk Assessment, Hybrid Risk Models, M2M Transformation, ROS, AI-Controlled Robotic Systems, Deep Learning, Reinforcement Learning"],"url":"http://arxiv.org/abs/2401.14147v1"}
{"created":"2024-01-25 12:46:04","title":"Exploring the Distinctive Tweeting Patterns of Toxic Twitter Users","abstract":"In the pursuit of bolstering user safety, social media platforms deploy active moderation strategies, including content removal and user suspension. These measures target users engaged in discussions marked by hate speech or toxicity, often linked to specific keywords or hashtags. Nonetheless, the increasing prevalence of toxicity indicates that certain users adeptly circumvent these measures. This study examines consistently toxic users on Twitter (rebranded as X) Rather than relying on traditional methods based on specific topics or hashtags, we employ a novel approach based on patterns of toxic tweets, yielding deeper insights into their behavior. We analyzed 38 million tweets from the timelines of 12,148 Twitter users and identified the top 1,457 users who consistently exhibit toxic behavior, relying on metrics like the Gini index and Toxicity score. By comparing their posting patterns to those of non-consistently toxic users, we have uncovered distinctive temporal patterns, including contiguous activity spans, inter-tweet intervals (referred to as 'Burstiness'), and churn analysis. These findings provide strong evidence for the existence of a unique tweeting pattern associated with toxic behavior on Twitter. Crucially, our methodology transcends Twitter and can be adapted to various social media platforms, facilitating the identification of consistently toxic users based on their posting behavior. This research contributes to ongoing efforts to combat online toxicity and offers insights for refining moderation strategies in the digital realm. We are committed to open research and will provide our code and data to the research community.","sentences":["In the pursuit of bolstering user safety, social media platforms deploy active moderation strategies, including content removal and user suspension.","These measures target users engaged in discussions marked by hate speech or toxicity, often linked to specific keywords or hashtags.","Nonetheless, the increasing prevalence of toxicity indicates that certain users adeptly circumvent these measures.","This study examines consistently toxic users on Twitter (rebranded as X) Rather than relying on traditional methods based on specific topics or hashtags, we employ a novel approach based on patterns of toxic tweets, yielding deeper insights into their behavior.","We analyzed 38 million tweets from the timelines of 12,148 Twitter users and identified the top 1,457 users who consistently exhibit toxic behavior, relying on metrics like the Gini index and Toxicity score.","By comparing their posting patterns to those of non-consistently toxic users, we have uncovered distinctive temporal patterns, including contiguous activity spans, inter-tweet intervals (referred to as 'Burstiness'), and churn analysis.","These findings provide strong evidence for the existence of a unique tweeting pattern associated with toxic behavior on Twitter.","Crucially, our methodology transcends Twitter and can be adapted to various social media platforms, facilitating the identification of consistently toxic users based on their posting behavior.","This research contributes to ongoing efforts to combat online toxicity and offers insights for refining moderation strategies in the digital realm.","We are committed to open research and will provide our code and data to the research community."],"url":"http://arxiv.org/abs/2401.14141v1"}
{"created":"2024-01-25 12:31:41","title":"Convolutional Neural Networks can achieve binary bail judgement classification","abstract":"There is an evident lack of implementation of Machine Learning (ML) in the legal domain in India, and any research that does take place in this domain is usually based on data from the higher courts of law and works with English data. The lower courts and data from the different regional languages of India are often overlooked. In this paper, we deploy a Convolutional Neural Network (CNN) architecture on a corpus of Hindi legal documents. We perform a bail Prediction task with the help of a CNN model and achieve an overall accuracy of 93\\% which is an improvement on the benchmark accuracy, set by Kapoor et al. (2022), albeit in data from 20 districts of the Indian state of Uttar Pradesh.","sentences":["There is an evident lack of implementation of Machine Learning (ML) in the legal domain in India, and any research that does take place in this domain is usually based on data from the higher courts of law and works with English data.","The lower courts and data from the different regional languages of India are often overlooked.","In this paper, we deploy a Convolutional Neural Network (CNN) architecture on a corpus of Hindi legal documents.","We perform a bail Prediction task with the help of a CNN model and achieve an overall accuracy of 93\\% which is an improvement on the benchmark accuracy, set by Kapoor et al. (2022), albeit in data from 20 districts of the Indian state of Uttar Pradesh."],"url":"http://arxiv.org/abs/2401.14135v1"}
{"created":"2024-01-25 12:23:22","title":"Equivariant Manifold Neural ODEs and Differential Invariants","abstract":"In this paper we develop a manifestly geometric framework for equivariant manifold neural ordinary differential equations (NODEs), and use it to analyse their modelling capabilities for symmetric data. First, we consider the action of a Lie group $G$ on a smooth manifold $M$ and establish the equivalence between equivariance of vector fields, symmetries of the corresponding Cauchy problems, and equivariance of the associated NODEs. We also propose a novel formulation of the equivariant NODEs in terms of the differential invariants of the action of $G$ on $M$, based on Lie theory for symmetries of differential equations, which provides an efficient parameterisation of the space of equivariant vector fields in a way that is agnostic to both the manifold $M$ and the symmetry group $G$. Second, we construct augmented manifold NODEs, through embeddings into equivariant flows, and show that they are universal approximators of equivariant diffeomorphisms on any path-connected $M$. Furthermore, we show that the augmented NODEs can be incorporated in the geometric framework and parameterised using higher order differential invariants. Finally, we consider the induced action of $G$ on different fields on $M$ and show how it can be used to generalise previous work, on, e.g., continuous normalizing flows, to equivariant models in any geometry.","sentences":["In this paper we develop a manifestly geometric framework for equivariant manifold neural ordinary differential equations (NODEs), and use it to analyse their modelling capabilities for symmetric data.","First, we consider the action of a Lie group $G$ on a smooth manifold $M$ and establish the equivalence between equivariance of vector fields, symmetries of the corresponding Cauchy problems, and equivariance of the associated NODEs.","We also propose a novel formulation of the equivariant NODEs in terms of the differential invariants of the action of $G$ on $M$, based on Lie theory for symmetries of differential equations, which provides an efficient parameterisation of the space of equivariant vector fields in a way that is agnostic to both the manifold $M$ and the symmetry group $G$. Second, we construct augmented manifold NODEs, through embeddings into equivariant flows, and show that they are universal approximators of equivariant diffeomorphisms on any path-connected $M$. Furthermore, we show that the augmented NODEs can be incorporated in the geometric framework and parameterised using higher order differential invariants.","Finally, we consider the induced action of $G$ on different fields on $M$ and show how it can be used to generalise previous work, on, e.g., continuous normalizing flows, to equivariant models in any geometry."],"url":"http://arxiv.org/abs/2401.14131v1"}
{"created":"2024-01-25 12:04:53","title":"Incorporating Exemplar Optimization into Training with Dual Networks for Human Mesh Recovery","abstract":"We propose a novel optimization-based human mesh recovery method from a single image. Given a test exemplar, previous approaches optimize the pre-trained regression network to minimize the 2D re-projection loss, which however suffer from over-/under-fitting problems. This is because the ``exemplar optimization'' at testing time has too weak relation to the pre-training process, and the exemplar optimization loss function is different from the training loss function. (1) We incorporate exemplar optimization into the training stage. During training, our method first executes exemplar optimization and subsequently proceeds with training-time optimization. The exemplar optimization may run into a wrong direction, while the subsequent training optimization serves to correct the deviation. Involved in training, the exemplar optimization learns to adapt its behavior to training data, thereby acquires generalibility to test exemplars. (2) We devise a dual-network architecture to convey the novel training paradigm, which is composed of a main regression network and an auxiliary network, in which we can formulate the exemplar optimization loss function in the same form as the training loss function. This further enhances the compatibility between the exemplar and training optimizations. Experiments demonstrate that our exemplar optimization after the novel training scheme significantly outperforms state-of-the-art approaches.","sentences":["We propose a novel optimization-based human mesh recovery method from a single image.","Given a test exemplar, previous approaches optimize the pre-trained regression network to minimize the 2D re-projection loss, which however suffer from over-/under-fitting problems.","This is because the ``exemplar optimization'' at testing time has too weak relation to the pre-training process, and the exemplar optimization loss function is different from the training loss function.","(1) We incorporate exemplar optimization into the training stage.","During training, our method first executes exemplar optimization and subsequently proceeds with training-time optimization.","The exemplar optimization may run into a wrong direction, while the subsequent training optimization serves to correct the deviation.","Involved in training, the exemplar optimization learns to adapt its behavior to training data, thereby acquires generalibility to test exemplars.","(2) We devise a dual-network architecture to convey the novel training paradigm, which is composed of a main regression network and an auxiliary network, in which we can formulate the exemplar optimization loss function in the same form as the training loss function.","This further enhances the compatibility between the exemplar and training optimizations.","Experiments demonstrate that our exemplar optimization after the novel training scheme significantly outperforms state-of-the-art approaches."],"url":"http://arxiv.org/abs/2401.14121v1"}
{"created":"2024-01-25 11:50:43","title":"MIFI: MultI-camera Feature Integration for Roust 3D Distracted Driver Activity Recognition","abstract":"Distracted driver activity recognition plays a critical role in risk aversion-particularly beneficial in intelligent transportation systems. However, most existing methods make use of only the video from a single view and the difficulty-inconsistent issue is neglected. Different from them, in this work, we propose a novel MultI-camera Feature Integration (MIFI) approach for 3D distracted driver activity recognition by jointly modeling the data from different camera views and explicitly re-weighting examples based on their degree of difficulty. Our contributions are two-fold: (1) We propose a simple but effective multi-camera feature integration framework and provide three types of feature fusion techniques. (2) To address the difficulty-inconsistent problem in distracted driver activity recognition, a periodic learning method, named example re-weighting that can jointly learn the easy and hard samples, is presented. The experimental results on the 3MDAD dataset demonstrate that the proposed MIFI can consistently boost performance compared to single-view models.","sentences":["Distracted driver activity recognition plays a critical role in risk aversion-particularly beneficial in intelligent transportation systems.","However, most existing methods make use of only the video from a single view and the difficulty-inconsistent issue is neglected.","Different from them, in this work, we propose a novel MultI-camera Feature Integration (MIFI) approach for 3D distracted driver activity recognition by jointly modeling the data from different camera views and explicitly re-weighting examples based on their degree of difficulty.","Our contributions are two-fold: (1) We propose a simple but effective multi-camera feature integration framework and provide three types of feature fusion techniques.","(2) To address the difficulty-inconsistent problem in distracted driver activity recognition, a periodic learning method, named example re-weighting that can jointly learn the easy and hard samples, is presented.","The experimental results on the 3MDAD dataset demonstrate that the proposed MIFI can consistently boost performance compared to single-view models."],"url":"http://arxiv.org/abs/2401.14115v1"}
{"created":"2024-01-25 11:43:35","title":"Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement","abstract":"Wearable technologies enable continuous monitoring of various health metrics, such as physical activity, heart rate, sleep, and stress levels. A key challenge with wearable data is obtaining quality labels. Unlike modalities like video where the videos themselves can be effectively used to label objects or events, wearable data do not contain obvious cues about the physical manifestation of the users and usually require rich metadata. As a result, label noise can become an increasingly thorny issue when labeling such data. In this paper, we propose a novel solution to address noisy label learning, entitled Few-Shot Human-in-the-Loop Refinement (FHLR). Our method initially learns a seed model using weak labels. Next, it fine-tunes the seed model using a handful of expert corrections. Finally, it achieves better generalizability and robustness by merging the seed and fine-tuned models via weighted parameter averaging. We evaluate our approach on four challenging tasks and datasets, and compare it against eight competitive baselines designed to deal with noisy labels. We show that FHLR achieves significantly better performance when learning from noisy labels and achieves state-of-the-art by a large margin, with up to 19% accuracy improvement under symmetric and asymmetric noise. Notably, we find that FHLR is particularly robust to increased label noise, unlike prior works that suffer from severe performance degradation. Our work not only achieves better generalization in high-stakes health sensing benchmarks but also sheds light on how noise affects commonly-used models.","sentences":["Wearable technologies enable continuous monitoring of various health metrics, such as physical activity, heart rate, sleep, and stress levels.","A key challenge with wearable data is obtaining quality labels.","Unlike modalities like video where the videos themselves can be effectively used to label objects or events, wearable data do not contain obvious cues about the physical manifestation of the users and usually require rich metadata.","As a result, label noise can become an increasingly thorny issue when labeling such data.","In this paper, we propose a novel solution to address noisy label learning, entitled Few-Shot Human-in-the-Loop Refinement (FHLR).","Our method initially learns a seed model using weak labels.","Next, it fine-tunes the seed model using a handful of expert corrections.","Finally, it achieves better generalizability and robustness by merging the seed and fine-tuned models via weighted parameter averaging.","We evaluate our approach on four challenging tasks and datasets, and compare it against eight competitive baselines designed to deal with noisy labels.","We show that FHLR achieves significantly better performance when learning from noisy labels and achieves state-of-the-art by a large margin, with up to 19% accuracy improvement under symmetric and asymmetric noise.","Notably, we find that FHLR is particularly robust to increased label noise, unlike prior works that suffer from severe performance degradation.","Our work not only achieves better generalization in high-stakes health sensing benchmarks but also sheds light on how noise affects commonly-used models."],"url":"http://arxiv.org/abs/2401.14107v1"}
{"created":"2024-01-25 11:18:43","title":"Carry Your Fault: A Fault Propagation Attack on Side-Channel Protected LWE-based KEM","abstract":"Post-quantum cryptographic (PQC) algorithms, especially those based on the learning with errors (LWE) problem, have been subjected to several physical attacks in the recent past. Although the attacks broadly belong to two classes - passive side-channel attacks and active fault attacks, the attack strategies vary significantly due to the inherent complexities of such algorithms. Exploring further attack surfaces is, therefore, an important step for eventually securing the deployment of these algorithms. Also, it is important to test the robustness of the already proposed countermeasures in this regard. In this work, we propose a new fault attack on side-channel secure masked implementation of LWE-based key-encapsulation mechanisms (KEMs) exploiting fault propagation. The attack typically originates due to an algorithmic modification widely used to enable masking, namely the Arithmetic-to-Boolean (A2B) conversion. We exploit the data dependency of the adder carry chain in A2B and extract sensitive information, albeit masking (of arbitrary order) being present. As a practical demonstration of the exploitability of this information leakage, we show key recovery attacks of Kyber, although the leakage also exists for other schemes like Saber. The attack on Kyber targets the decapsulation module and utilizes Belief Propagation (BP) for key recovery. To the best of our knowledge, it is the first attack exploiting an algorithmic component introduced to ease masking rather than only exploiting the randomness introduced by masking to obtain desired faults (as done by Delvaux). Finally, we performed both simulated and electromagnetic (EM) fault-based practical validation of the attack for an open-source first-order secure Kyber implementation running on an STM32 platform.","sentences":["Post-quantum cryptographic (PQC) algorithms, especially those based on the learning with errors (LWE) problem, have been subjected to several physical attacks in the recent past.","Although the attacks broadly belong to two classes - passive side-channel attacks and active fault attacks, the attack strategies vary significantly due to the inherent complexities of such algorithms.","Exploring further attack surfaces is, therefore, an important step for eventually securing the deployment of these algorithms.","Also, it is important to test the robustness of the already proposed countermeasures in this regard.","In this work, we propose a new fault attack on side-channel secure masked implementation of LWE-based key-encapsulation mechanisms (KEMs) exploiting fault propagation.","The attack typically originates due to an algorithmic modification widely used to enable masking, namely the Arithmetic-to-Boolean (A2B) conversion.","We exploit the data dependency of the adder carry chain in A2B and extract sensitive information, albeit masking (of arbitrary order) being present.","As a practical demonstration of the exploitability of this information leakage, we show key recovery attacks of Kyber, although the leakage also exists for other schemes like Saber.","The attack on Kyber targets the decapsulation module and utilizes Belief Propagation (BP) for key recovery.","To the best of our knowledge, it is the first attack exploiting an algorithmic component introduced to ease masking rather than only exploiting the randomness introduced by masking to obtain desired faults (as done by Delvaux).","Finally, we performed both simulated and electromagnetic (EM) fault-based practical validation of the attack for an open-source first-order secure Kyber implementation running on an STM32 platform."],"url":"http://arxiv.org/abs/2401.14098v1"}
{"created":"2024-01-25 11:16:14","title":"Evaluating User Experience and Data Quality in a Gamified Data Collection for Appearance-Based Gaze Estimation","abstract":"Appearance-based gaze estimation, which uses only a regular camera to estimate human gaze, is important in various application fields. While the technique faces data bias issues, data collection protocol is often demanding, and collecting data from a wide range of participants is difficult. It is an important challenge to design opportunities that allow a diverse range of people to participate while ensuring the quality of the training data. To tackle this challenge, we introduce a novel gamified approach for collecting training data. In this game, two players communicate words via eye gaze through a transparent letter board. Images captured during gameplay serve as valuable training data for gaze estimation models. The game is designed as a physical installation that involves communication between players, and it is expected to attract the interest of diverse participants. We assess the game's significance on data quality and user experience through a comparative user study.","sentences":["Appearance-based gaze estimation, which uses only a regular camera to estimate human gaze, is important in various application fields.","While the technique faces data bias issues, data collection protocol is often demanding, and collecting data from a wide range of participants is difficult.","It is an important challenge to design opportunities that allow a diverse range of people to participate while ensuring the quality of the training data.","To tackle this challenge, we introduce a novel gamified approach for collecting training data.","In this game, two players communicate words via eye gaze through a transparent letter board.","Images captured during gameplay serve as valuable training data for gaze estimation models.","The game is designed as a physical installation that involves communication between players, and it is expected to attract the interest of diverse participants.","We assess the game's significance on data quality and user experience through a comparative user study."],"url":"http://arxiv.org/abs/2401.14095v1"}
{"created":"2024-01-25 11:15:51","title":"McUDI: Model-Centric Unsupervised Degradation Indicator for Failure Prediction AIOps Solutions","abstract":"Due to the continuous change in operational data, AIOps solutions suffer from performance degradation over time. Although periodic retraining is the state-of-the-art technique to preserve the failure prediction AIOps models' performance over time, this technique requires a considerable amount of labeled data to retrain. In AIOps obtaining label data is expensive since it requires the availability of domain experts to intensively annotate it. In this paper, we present McUDI, a model-centric unsupervised degradation indicator that is capable of detecting the exact moment the AIOps model requires retraining as a result of changes in data. We further show how employing McUDI in the maintenance pipeline of AIOps solutions can reduce the number of samples that require annotations with 30k for job failure prediction and 260k for disk failure prediction while achieving similar performance with periodic retraining.","sentences":["Due to the continuous change in operational data, AIOps solutions suffer from performance degradation over time.","Although periodic retraining is the state-of-the-art technique to preserve the failure prediction AIOps models' performance over time, this technique requires a considerable amount of labeled data to retrain.","In AIOps obtaining label data is expensive since it requires the availability of domain experts to intensively annotate it.","In this paper, we present McUDI, a model-centric unsupervised degradation indicator that is capable of detecting the exact moment the AIOps model requires retraining as a result of changes in data.","We further show how employing McUDI in the maintenance pipeline of AIOps solutions can reduce the number of samples that require annotations with 30k for job failure prediction and 260k for disk failure prediction while achieving similar performance with periodic retraining."],"url":"http://arxiv.org/abs/2401.14093v1"}
{"created":"2024-01-25 11:12:16","title":"A Modular Approach to Automatic Cyber Threat Attribution using Opinion Pools","abstract":"Cyber threat attribution can play an important role in increasing resilience against digital threats. Recent research focuses on automating the threat attribution process and on integrating it with other efforts, such as threat hunting. To support increasing automation of the cyber threat attribution process, this paper proposes a modular architecture as an alternative to current monolithic automated approaches. The modular architecture can utilize opinion pools to combine the output of concrete attributors. The proposed solution increases the tractability of the threat attribution problem and offers increased usability and interpretability, as opposed to monolithic alternatives. In addition, a Pairing Aggregator is proposed as an aggregation method that forms pairs of attributors based on distinct features to produce intermediary results before finally producing a single Probability Mass Function (PMF) as output. The Pairing Aggregator sequentially applies both the logarithmic opinion pool and the linear opinion pool. An experimental validation suggests that the modular approach does not result in decreased performance and can even enhance precision and recall compared to monolithic alternatives. The results also suggest that the Pairing Aggregator can improve precision over the linear and logarithmic opinion pools. Furthermore, the improved k-accuracy in the experiment suggests that forensic experts can leverage the resulting PMF during their manual attribution processes to enhance their efficiency.","sentences":["Cyber threat attribution can play an important role in increasing resilience against digital threats.","Recent research focuses on automating the threat attribution process and on integrating it with other efforts, such as threat hunting.","To support increasing automation of the cyber threat attribution process, this paper proposes a modular architecture as an alternative to current monolithic automated approaches.","The modular architecture can utilize opinion pools to combine the output of concrete attributors.","The proposed solution increases the tractability of the threat attribution problem and offers increased usability and interpretability, as opposed to monolithic alternatives.","In addition, a Pairing Aggregator is proposed as an aggregation method that forms pairs of attributors based on distinct features to produce intermediary results before finally producing a single Probability Mass Function (PMF) as output.","The Pairing Aggregator sequentially applies both the logarithmic opinion pool and the linear opinion pool.","An experimental validation suggests that the modular approach does not result in decreased performance and can even enhance precision and recall compared to monolithic alternatives.","The results also suggest that the Pairing Aggregator can improve precision over the linear and logarithmic opinion pools.","Furthermore, the improved k-accuracy in the experiment suggests that forensic experts can leverage the resulting PMF during their manual attribution processes to enhance their efficiency."],"url":"http://arxiv.org/abs/2401.14090v1"}
{"created":"2024-01-25 11:10:13","title":"Double Trouble? Impact and Detection of Duplicates in Face Image Datasets","abstract":"Various face image datasets intended for facial biometrics research were created via web-scraping, i.e. the collection of images publicly available on the internet. This work presents an approach to detect both exactly and nearly identical face image duplicates, using file and image hashes. The approach is extended through the use of face image preprocessing. Additional steps based on face recognition and face image quality assessment models reduce false positives, and facilitate the deduplication of the face images both for intra- and inter-subject duplicate sets. The presented approach is applied to five datasets, namely LFW, TinyFace, Adience, CASIA-WebFace, and C-MS-Celeb (a cleaned MS-Celeb-1M variant). Duplicates are detected within every dataset, with hundreds to hundreds of thousands of duplicates for all except LFW. Face recognition and quality assessment experiments indicate a minor impact on the results through the duplicate removal. The final deduplication data is publicly available.","sentences":["Various face image datasets intended for facial biometrics research were created via web-scraping, i.e. the collection of images publicly available on the internet.","This work presents an approach to detect both exactly and nearly identical face image duplicates, using file and image hashes.","The approach is extended through the use of face image preprocessing.","Additional steps based on face recognition and face image quality assessment models reduce false positives, and facilitate the deduplication of the face images both for intra- and inter-subject duplicate sets.","The presented approach is applied to five datasets, namely LFW, TinyFace, Adience, CASIA-WebFace, and C-MS-Celeb (a cleaned MS-Celeb-1M variant).","Duplicates are detected within every dataset, with hundreds to hundreds of thousands of duplicates for all except LFW.","Face recognition and quality assessment experiments indicate a minor impact on the results through the duplicate removal.","The final deduplication data is publicly available."],"url":"http://arxiv.org/abs/2401.14088v1"}
{"created":"2024-01-25 10:55:38","title":"LongMemory.jl: Generating, Estimating, and Forecasting Long Memory Models in Julia","abstract":"LongMemory.jl is a package for time series long memory modelling in Julia. The package provides functions to generate long memory, estimate model parameters, and forecast. Generating methods include fractional differencing, stochastic error duration, and cross-sectional aggregation. Estimators include the classic ones used to estimate the Hurst effect, those inspired by log-periodogram regression, and parametric ones. Forecasting is provided for all parametric estimators. Moreover, the package adds plotting capabilities to illustrate long memory dynamics and forecasting. This article presents the theoretical developments for long memory modelling, show examples using the data included with the package, and compares the properties of LongMemory.jl with current alternatives, including benchmarks. For some of the theoretical developments, LongMemory.jl provides the first publicly available implementation in any programming language. A notable feature of this package is that all functions are implemented in the same programming language, taking advantage of the ease of use and speed provided by Julia. Therefore, all code is accessible to the user. Multiple dispatch, a novel feature of the language, is used to speed computations and provide consistent calls to related methods. The package is related to the R packages LongMemoryTS and fracdiff.","sentences":["LongMemory.jl is a package for time series long memory modelling in Julia.","The package provides functions to generate long memory, estimate model parameters, and forecast.","Generating methods include fractional differencing, stochastic error duration, and cross-sectional aggregation.","Estimators include the classic ones used to estimate the Hurst effect, those inspired by log-periodogram regression, and parametric ones.","Forecasting is provided for all parametric estimators.","Moreover, the package adds plotting capabilities to illustrate long memory dynamics and forecasting.","This article presents the theoretical developments for long memory modelling, show examples using the data included with the package, and compares the properties of LongMemory.jl with current alternatives, including benchmarks.","For some of the theoretical developments, LongMemory.jl provides the first publicly available implementation in any programming language.","A notable feature of this package is that all functions are implemented in the same programming language, taking advantage of the ease of use and speed provided by Julia.","Therefore, all code is accessible to the user.","Multiple dispatch, a novel feature of the language, is used to speed computations and provide consistent calls to related methods.","The package is related to the R packages LongMemoryTS and fracdiff."],"url":"http://arxiv.org/abs/2401.14077v1"}
{"created":"2024-01-25 10:55:23","title":"Quantum Resistant Ciphertext-Policy Attribute-Based Encryption Scheme with Flexible Access Structure","abstract":"In this paper, we present a novel ciphertext-policy attribute based encryption (CP-ABE) scheme that offers a flexible access structure. Our proposed scheme incorporates an access tree as its access control policy, enabling fine-grained access control over encrypted data. The security of our scheme is provable under the hardness assumption of the decisional Ring-Learning with Errors (R-LWE) problem, ensuring robust protection against unauthorized access. CP-ABE is a cryptographic technique that allows data owners to encrypt their data with access policies defined in terms of attributes. Only users possessing the required attributes can decrypt and access the encrypted data. Our scheme extends the capabilities of CP-ABE by introducing a flexible access structure based on an access tree. This structure enables more complex and customizable access policies, accommodating a wider range of real-world scenarios. To ensure the security of our scheme, we rely on the decisional R-LWE problem, a well-established hardness assumption in cryptography. By proving the security of our scheme under this assumption, we provide a strong guarantee of protection against potential attacks. Furthermore, our proposed scheme operates in the standard model, which means it does not rely on any additional assumptions or idealized cryptographic primitives. This enhances the practicality and applicability of our scheme, making it suitable for real-world deployment. We evaluate the performance and efficiency of our scheme through extensive simulations and comparisons with existing CP-ABE schemes. The results demonstrate the effectiveness and scalability of our proposed approach, highlighting its potential for secure and flexible data access control in various domains.","sentences":["In this paper, we present a novel ciphertext-policy attribute based encryption (CP-ABE) scheme that offers a flexible access structure.","Our proposed scheme incorporates an access tree as its access control policy, enabling fine-grained access control over encrypted data.","The security of our scheme is provable under the hardness assumption of the decisional Ring-Learning with Errors (R-LWE) problem, ensuring robust protection against unauthorized access.","CP-ABE is a cryptographic technique that allows data owners to encrypt their data with access policies defined in terms of attributes.","Only users possessing the required attributes can decrypt and access the encrypted data.","Our scheme extends the capabilities of CP-ABE by introducing a flexible access structure based on an access tree.","This structure enables more complex and customizable access policies, accommodating a wider range of real-world scenarios.","To ensure the security of our scheme, we rely on the decisional R-LWE problem, a well-established hardness assumption in cryptography.","By proving the security of our scheme under this assumption, we provide a strong guarantee of protection against potential attacks.","Furthermore, our proposed scheme operates in the standard model, which means it does not rely on any additional assumptions or idealized cryptographic primitives.","This enhances the practicality and applicability of our scheme, making it suitable for real-world deployment.","We evaluate the performance and efficiency of our scheme through extensive simulations and comparisons with existing CP-ABE schemes.","The results demonstrate the effectiveness and scalability of our proposed approach, highlighting its potential for secure and flexible data access control in various domains."],"url":"http://arxiv.org/abs/2401.14076v1"}
{"created":"2024-01-25 10:39:40","title":"Novel application of Relief Algorithm in cascaded artificial neural network to predict wind speed for wind power resource assessment in India","abstract":"Wind power generated by wind has non-schedule nature due to stochastic nature of meteorological variable. Hence energy business and control of wind power generation requires prediction of wind speed (WS) from few seconds to different time steps in advance. To deal with prediction shortcomings, various WS prediction methods have been used. Predictive data mining offers variety of methods for WS predictions where artificial neural network (ANN) is one of the reliable and accurate methods. It is observed from the result of this study that ANN gives better accuracy in comparison conventional model. The accuracy of WS prediction models is found to be dependent on input parameters and architecture type algorithms utilized. So the selection of most relevant input parameters is important research area in WS predicton field. The objective of the paper is twofold: first extensive review of ANN for wind power and WS prediction is carried out. Discussion and analysis of feature selection using Relief Algorithm (RA) in WS prediction are considered for different Indian sites. RA identify atmospheric pressure, solar radiation and relative humidity are relevant input variables. Based on relevant input variables Cascade ANN model is developed and prediction accuracy is evaluated. It is found that root mean square error (RMSE) for comparison between predicted and measured WS for training and testing wind speed are found to be 1.44 m/s and 1.49 m/s respectively. The developed cascade ANN model can be used to predict wind speed for sites where there are not WS measuring instruments are installed in India.","sentences":["Wind power generated by wind has non-schedule nature due to stochastic nature of meteorological variable.","Hence energy business and control of wind power generation requires prediction of wind speed (WS) from few seconds to different time steps in advance.","To deal with prediction shortcomings, various WS prediction methods have been used.","Predictive data mining offers variety of methods for WS predictions where artificial neural network (ANN) is one of the reliable and accurate methods.","It is observed from the result of this study that ANN gives better accuracy in comparison conventional model.","The accuracy of WS prediction models is found to be dependent on input parameters and architecture type algorithms utilized.","So the selection of most relevant input parameters is important research area in WS predicton field.","The objective of the paper is twofold: first extensive review of ANN for wind power and WS prediction is carried out.","Discussion and analysis of feature selection using Relief Algorithm (RA) in WS prediction are considered for different Indian sites.","RA identify atmospheric pressure, solar radiation and relative humidity are relevant input variables.","Based on relevant input variables Cascade ANN model is developed and prediction accuracy is evaluated.","It is found that root mean square error (RMSE) for comparison between predicted and measured WS for training and testing wind speed are found to be 1.44 m/s and 1.49 m/s respectively.","The developed cascade ANN model can be used to predict wind speed for sites where there are not WS measuring instruments are installed in India."],"url":"http://arxiv.org/abs/2401.14065v1"}
{"created":"2024-01-25 10:35:38","title":"On Sparse Covers of Minor Free Graphs, Low Dimensional Metric Embeddings, and other applications","abstract":"Given a metric space $(X,d_X)$, a $(\\beta,s,\\Delta)$-sparse cover is a collection of clusters $\\mathcal{C}\\subseteq P(X)$ with diameter at most $\\Delta$, such that for every point $x\\in X$, the ball $B_X(x,\\frac\\Delta\\beta)$ is fully contained in some cluster $C\\in \\mathcal{C}$, and $x$ belongs to at most $s$ clusters in $\\mathcal{C}$. Our main contribution is to show that the shortest path metric of every $K_r$-minor free graphs admits $(O(r),O(r^2),\\Delta)$-sparse cover, and for every $\\epsilon>0$, $(4+\\epsilon,O(\\frac1\\epsilon)^r,\\Delta)$-sparse cover (for arbitrary $\\Delta>0$). We then use this sparse cover to show that every $K_r$-minor free graph embeds into $\\ell_\\infty^{\\tilde{O}(\\frac1\\epsilon)^{r+1}\\cdot\\log n}$ with distortion $3+\\eps$ (resp. into $\\ell_\\infty^{\\tilde{O}(r^2)\\cdot\\log n}$ with distortion $O(r)$). Further, we provide applications of these sparse covers into padded decompositions, sparse partitions, universal TSP / Steiner tree, oblivious buy at bulk, name independent routing, and path reporting distance oracles.","sentences":["Given a metric space $(X,d_X)$, a $(\\beta,s,\\Delta)$-sparse cover is a collection of clusters $\\mathcal{C}\\subseteq P(X)$ with diameter at most $\\Delta$, such that for every point $x\\in X$, the ball $B_X(x,\\frac\\Delta\\beta)$ is fully contained in some cluster $C\\in \\mathcal{C}$, and $x$ belongs to at most $s$ clusters in $\\mathcal{C}$. Our main contribution is to show that the shortest path metric of every $K_r$-minor free graphs admits $(O(r),O(r^2),\\Delta)$-sparse cover, and for every $\\epsilon>0$, $(4+\\epsilon,O(\\frac1\\epsilon)^r,\\Delta)$-sparse cover (for arbitrary $\\Delta>0$).","We then use this sparse cover to show that every $K_r$-minor free graph embeds into $\\ell_\\infty^{\\tilde{O}(\\frac1\\epsilon)^{r+1}\\cdot\\log n}$ with distortion $3+\\eps$ (resp.","into $\\ell_\\infty^{\\tilde{O}(r^2)\\cdot\\log n}$ with distortion $O(r)$).","Further, we provide applications of these sparse covers into padded decompositions, sparse partitions, universal TSP / Steiner tree, oblivious buy at bulk, name independent routing, and path reporting distance oracles."],"url":"http://arxiv.org/abs/2401.14060v1"}
{"created":"2024-01-25 10:08:53","title":"A real-time rendering method for high albedo anisotropic materials with multiple scattering","abstract":"We propose a neural network-based real-time volume rendering method for realistic and efficient rendering of volumetric media. The traditional volume rendering method uses path tracing to solve the radiation transfer equation, which requires a huge amount of calculation and cannot achieve real-time rendering. Therefore, this paper uses neural networks to simulate the iterative integration process of solving the radiative transfer equation to speed up the volume rendering of volume media. Specifically, the paper first performs data processing on the volume medium to generate a variety of sampling features, including density features, transmittance features and phase features. The hierarchical transmittance fields are fed into a 3D-CNN network to compute more important transmittance features. Secondly, the diffuse reflection sampling template and the highlight sampling template are used to layer the three types of sampling features into the network. This method can pay more attention to light scattering, highlights and shadows, and then select important channel features through the attention module. Finally, the scattering distribution of the center points of all sampling templates is predicted through the backbone neural network. This method can achieve realistic volumetric media rendering effects and greatly increase the rendering speed while maintaining rendering quality, which is of great significance for real-time rendering applications. Experimental results indicate that our method outperforms previous methods.","sentences":["We propose a neural network-based real-time volume rendering method for realistic and efficient rendering of volumetric media.","The traditional volume rendering method uses path tracing to solve the radiation transfer equation, which requires a huge amount of calculation and cannot achieve real-time rendering.","Therefore, this paper uses neural networks to simulate the iterative integration process of solving the radiative transfer equation to speed up the volume rendering of volume media.","Specifically, the paper first performs data processing on the volume medium to generate a variety of sampling features, including density features, transmittance features and phase features.","The hierarchical transmittance fields are fed into a 3D-CNN network to compute more important transmittance features.","Secondly, the diffuse reflection sampling template and the highlight sampling template are used to layer the three types of sampling features into the network.","This method can pay more attention to light scattering, highlights and shadows, and then select important channel features through the attention module.","Finally, the scattering distribution of the center points of all sampling templates is predicted through the backbone neural network.","This method can achieve realistic volumetric media rendering effects and greatly increase the rendering speed while maintaining rendering quality, which is of great significance for real-time rendering applications.","Experimental results indicate that our method outperforms previous methods."],"url":"http://arxiv.org/abs/2401.14051v1"}
{"created":"2024-01-25 09:33:49","title":"Deep Clustering with Diffused Sampling and Hardness-aware Self-distillation","abstract":"Deep clustering has gained significant attention due to its capability in learning clustering-friendly representations without labeled data. However, previous deep clustering methods tend to treat all samples equally, which neglect the variance in the latent distribution and the varying difficulty in classifying or clustering different samples. To address this, this paper proposes a novel end-to-end deep clustering method with diffused sampling and hardness-aware self-distillation (HaDis). Specifically, we first align one view of instances with another view via diffused sampling alignment (DSA), which helps improve the intra-cluster compactness. To alleviate the sampling bias, we present the hardness-aware self-distillation (HSD) mechanism to mine the hardest positive and negative samples and adaptively adjust their weights in a self-distillation fashion, which is able to deal with the potential imbalance in sample contributions during optimization. Further, the prototypical contrastive learning is incorporated to simultaneously enhance the inter-cluster separability and intra-cluster compactness. Experimental results on five challenging image datasets demonstrate the superior clustering performance of our HaDis method over the state-of-the-art. Source code is available at https://github.com/Regan-Zhang/HaDis.","sentences":["Deep clustering has gained significant attention due to its capability in learning clustering-friendly representations without labeled data.","However, previous deep clustering methods tend to treat all samples equally, which neglect the variance in the latent distribution and the varying difficulty in classifying or clustering different samples.","To address this, this paper proposes a novel end-to-end deep clustering method with diffused sampling and hardness-aware self-distillation (HaDis).","Specifically, we first align one view of instances with another view via diffused sampling alignment (DSA), which helps improve the intra-cluster compactness.","To alleviate the sampling bias, we present the hardness-aware self-distillation (HSD) mechanism to mine the hardest positive and negative samples and adaptively adjust their weights in a self-distillation fashion, which is able to deal with the potential imbalance in sample contributions during optimization.","Further, the prototypical contrastive learning is incorporated to simultaneously enhance the inter-cluster separability and intra-cluster compactness.","Experimental results on five challenging image datasets demonstrate the superior clustering performance of our HaDis method over the state-of-the-art.","Source code is available at https://github.com/Regan-Zhang/HaDis."],"url":"http://arxiv.org/abs/2401.14038v1"}
{"created":"2024-01-25 09:26:08","title":"Diverse and Lifespan Facial Age Transformation Synthesis with Identity Variation Rationality Metric","abstract":"Face aging has received continuous research attention over the past two decades. Although previous works on this topic have achieved impressive success, two longstanding problems remain unsettled: 1) generating diverse and plausible facial aging patterns at the target age stage; 2) measuring the rationality of identity variation between the original portrait and its syntheses with age progression or regression. In this paper, we introduce DLAT + , the first algorithm that can realize Diverse and Lifespan Age Transformation on human faces, where the diversity jointly manifests in the transformation of facial textures and shapes. Apart from the diversity mechanism embedded in the model, multiple consistency restrictions are leveraged to keep it away from counterfactual aging syntheses. Moreover, we propose a new metric to assess the rationality of Identity Deviation under Age Gaps (IDAG) between the input face and its series of age-transformed generations, which is based on statistical laws summarized from plenty of genuine face-aging data. Extensive experimental results demonstrate the uniqueness and effectiveness of our method in synthesizing diverse and perceptually reasonable faces across the whole lifetime.","sentences":["Face aging has received continuous research attention over the past two decades.","Although previous works on this topic have achieved impressive success, two longstanding problems remain unsettled: 1) generating diverse and plausible facial aging patterns at the target age stage; 2) measuring the rationality of identity variation between the original portrait and its syntheses with age progression or regression.","In this paper, we introduce DLAT + , the first algorithm that can realize Diverse and Lifespan Age Transformation on human faces, where the diversity jointly manifests in the transformation of facial textures and shapes.","Apart from the diversity mechanism embedded in the model, multiple consistency restrictions are leveraged to keep it away from counterfactual aging syntheses.","Moreover, we propose a new metric to assess the rationality of Identity Deviation under Age Gaps (IDAG) between the input face and its series of age-transformed generations, which is based on statistical laws summarized from plenty of genuine face-aging data.","Extensive experimental results demonstrate the uniqueness and effectiveness of our method in synthesizing diverse and perceptually reasonable faces across the whole lifetime."],"url":"http://arxiv.org/abs/2401.14036v1"}
{"created":"2024-01-25 09:22:32","title":"GauU-Scene: A Scene Reconstruction Benchmark on Large Scale 3D Reconstruction Dataset Using Gaussian Splatting","abstract":"We introduce a novel large-scale scene reconstruction benchmark using the newly developed 3D representation approach, Gaussian Splatting, on our expansive U-Scene dataset. U-Scene encompasses over one and a half square kilometres, featuring a comprehensive RGB dataset coupled with LiDAR ground truth. For data acquisition, we employed the Matrix 300 drone equipped with the high-accuracy Zenmuse L1 LiDAR, enabling precise rooftop data collection. This dataset, offers a unique blend of urban and academic environments for advanced spatial analysis convers more than 1.5 km$^2$. Our evaluation of U-Scene with Gaussian Splatting includes a detailed analysis across various novel viewpoints. We also juxtapose these results with those derived from our accurate point cloud dataset, highlighting significant differences that underscore the importance of combine multi-modal information","sentences":["We introduce a novel large-scale scene reconstruction benchmark using the newly developed 3D representation approach, Gaussian Splatting, on our expansive U-Scene dataset.","U-Scene encompasses over one and a half square kilometres, featuring a comprehensive RGB dataset coupled with LiDAR ground truth.","For data acquisition, we employed the Matrix 300 drone equipped with the high-accuracy Zenmuse L1 LiDAR, enabling precise rooftop data collection.","This dataset, offers a unique blend of urban and academic environments for advanced spatial analysis convers more than 1.5 km$^2$. Our evaluation of U-Scene with Gaussian Splatting includes a detailed analysis across various novel viewpoints.","We also juxtapose these results with those derived from our accurate point cloud dataset, highlighting significant differences that underscore the importance of combine multi-modal information"],"url":"http://arxiv.org/abs/2401.14032v1"}
{"created":"2024-01-25 09:19:30","title":"Comparison of modularity-based approaches for nodes clustering in binary hypergraphs","abstract":"We conducted a comparative analysis of the performance of modularity-based methods for clustering nodes in binary hypergraphs. Statistical analysis and node clustering in hypergraphs constitute an emerging topic suffering from a lack of standardization. In contrast to the case of graphs, the concept of nodes' community in hypergraphs is not unique and encompasses various distinct situations. To address this, we begin by presenting, within a unified framework, the various hypergraph modularity criteria proposed in the literature, emphasizing their differences and respective focuses. Subsequently, we provide an overview of the state-of-the-art codes available to maximize hypergraph modularities for detecting node communities in binary hypergraphs. Through exploration of various simulation settings with controlled ground truth clustering, we offer a comparison of these methods using different quality measures, including true clustering recovery, running time, (local) maximization of the objective, and the number of clusters detected. Our contribution marks the first attempt to clarify the advantages and drawbacks of these newly available methods. This effort lays the foundation for a better understanding of the primary objectives of modularity-based node clustering methods for binary hypergraphs.","sentences":["We conducted a comparative analysis of the performance of modularity-based methods for clustering nodes in binary hypergraphs.","Statistical analysis and node clustering in hypergraphs constitute an emerging topic suffering from a lack of standardization.","In contrast to the case of graphs, the concept of nodes' community in hypergraphs is not unique and encompasses various distinct situations.","To address this, we begin by presenting, within a unified framework, the various hypergraph modularity criteria proposed in the literature, emphasizing their differences and respective focuses.","Subsequently, we provide an overview of the state-of-the-art codes available to maximize hypergraph modularities for detecting node communities in binary hypergraphs.","Through exploration of various simulation settings with controlled ground truth clustering, we offer a comparison of these methods using different quality measures, including true clustering recovery, running time, (local) maximization of the objective, and the number of clusters detected.","Our contribution marks the first attempt to clarify the advantages and drawbacks of these newly available methods.","This effort lays the foundation for a better understanding of the primary objectives of modularity-based node clustering methods for binary hypergraphs."],"url":"http://arxiv.org/abs/2401.14028v1"}
{"created":"2024-01-25 09:18:51","title":"The Risk of Federated Learning to Skew Fine-Tuning Features and Underperform Out-of-Distribution Robustness","abstract":"To tackle the scarcity and privacy issues associated with domain-specific datasets, the integration of federated learning in conjunction with fine-tuning has emerged as a practical solution. However, our findings reveal that federated learning has the risk of skewing fine-tuning features and compromising the out-of-distribution robustness of the model. By introducing three robustness indicators and conducting experiments across diverse robust datasets, we elucidate these phenomena by scrutinizing the diversity, transferability, and deviation within the model feature space. To mitigate the negative impact of federated learning on model robustness, we introduce GNP, a \\underline{G}eneral \\underline{N}oisy \\underline{P}rojection-based robust algorithm, ensuring no deterioration of accuracy on the target distribution. Specifically, the key strategy for enhancing model robustness entails the transfer of robustness from the pre-trained model to the fine-tuned model, coupled with adding a small amount of Gaussian noise to augment the representative capacity of the model. Comprehensive experimental results demonstrate that our approach markedly enhances the robustness across diverse scenarios, encompassing various parameter-efficient fine-tuning methods and confronting different levels of data heterogeneity.","sentences":["To tackle the scarcity and privacy issues associated with domain-specific datasets, the integration of federated learning in conjunction with fine-tuning has emerged as a practical solution.","However, our findings reveal that federated learning has the risk of skewing fine-tuning features and compromising the out-of-distribution robustness of the model.","By introducing three robustness indicators and conducting experiments across diverse robust datasets, we elucidate these phenomena by scrutinizing the diversity, transferability, and deviation within the model feature space.","To mitigate the negative impact of federated learning on model robustness, we introduce GNP, a \\underline{G}eneral \\underline{N}oisy \\underline{P}rojection-based robust algorithm, ensuring no deterioration of accuracy on the target distribution.","Specifically, the key strategy for enhancing model robustness entails the transfer of robustness from the pre-trained model to the fine-tuned model, coupled with adding a small amount of Gaussian noise to augment the representative capacity of the model.","Comprehensive experimental results demonstrate that our approach markedly enhances the robustness across diverse scenarios, encompassing various parameter-efficient fine-tuning methods and confronting different levels of data heterogeneity."],"url":"http://arxiv.org/abs/2401.14027v1"}
{"created":"2024-01-25 09:06:44","title":"Accelerating Retrieval-Augmented Language Model Serving with Speculation","abstract":"Retrieval-augmented language models (RaLM) have demonstrated the potential to solve knowledge-intensive natural language processing (NLP) tasks by combining a non-parametric knowledge base with a parametric language model. Instead of fine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to the latest data and better source attribution mechanisms. Among various RaLM approaches, iterative RaLM delivers a better generation quality due to a more frequent interaction between the retriever and the language model. Despite the benefits, iterative RaLM usually encounters high overheads due to the frequent retrieval step. To this end, we propose RaLMSpec, a speculation-inspired framework that provides generic speed-up over iterative RaLM while preserving the same model outputs through speculative retrieval and batched verification. By further incorporating prefetching, optimal speculation stride scheduler, and asynchronous verification, RaLMSpec can automatically exploit the acceleration potential to the fullest. For naive iterative RaLM serving, extensive evaluations over three language models on four downstream QA datasets demonstrate that RaLMSpec can achieve a speed-up ratio of 1.75-2.39x, 1.04-1.39x, and 1.31-1.77x when the retriever is an exact dense retriever, approximate dense retriever, and sparse retriever respectively compared with the baseline. For KNN-LM serving, RaLMSpec can achieve a speed-up ratio up to 7.59x and 2.45x when the retriever is an exact dense retriever and approximate dense retriever, respectively, compared with the baseline.","sentences":["Retrieval-augmented language models (RaLM) have demonstrated the potential to solve knowledge-intensive natural language processing (NLP) tasks by combining a non-parametric knowledge base with a parametric language model.","Instead of fine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to the latest data and better source attribution mechanisms.","Among various RaLM approaches, iterative RaLM delivers a better generation quality due to a more frequent interaction between the retriever and the language model.","Despite the benefits, iterative RaLM usually encounters high overheads due to the frequent retrieval step.","To this end, we propose RaLMSpec, a speculation-inspired framework that provides generic speed-up over iterative RaLM while preserving the same model outputs through speculative retrieval and batched verification.","By further incorporating prefetching, optimal speculation stride scheduler, and asynchronous verification, RaLMSpec can automatically exploit the acceleration potential to the fullest.","For naive iterative RaLM serving, extensive evaluations over three language models on four downstream QA datasets demonstrate that RaLMSpec can achieve a speed-up ratio of 1.75-2.39x, 1.04-1.39x, and 1.31-1.77x when the retriever is an exact dense retriever, approximate dense retriever, and sparse retriever respectively compared with the baseline.","For KNN-LM serving, RaLMSpec can achieve a speed-up ratio up to 7.59x and 2.45x when the retriever is an exact dense retriever and approximate dense retriever, respectively, compared with the baseline."],"url":"http://arxiv.org/abs/2401.14021v1"}
{"created":"2024-01-25 08:57:33","title":"Unitxt: Flexible, Shareable and Reusable Data Preparation and Evaluation for Generative AI","abstract":"In the dynamic landscape of generative NLP, traditional text processing pipelines limit research flexibility and reproducibility, as they are tailored to specific dataset, task, and model combinations. The escalating complexity, involving system prompts, model-specific formats, instructions, and more, calls for a shift to a structured, modular, and customizable solution. Addressing this need, we present Unitxt, an innovative library for customizable textual data preparation and evaluation tailored to generative language models. Unitxt natively integrates with common libraries like HuggingFace and LM-eval-harness and deconstructs processing flows into modular components, enabling easy customization and sharing between practitioners. These components encompass model-specific formats, task prompts, and many other comprehensive dataset processing definitions. The Unitxt-Catalog centralizes these components, fostering collaboration and exploration in modern textual data workflows. Beyond being a tool, Unitxt is a community-driven platform, empowering users to build, share, and advance their pipelines collaboratively. Join the Unitxt community at https://github.com/IBM/unitxt!","sentences":["In the dynamic landscape of generative NLP, traditional text processing pipelines limit research flexibility and reproducibility, as they are tailored to specific dataset, task, and model combinations.","The escalating complexity, involving system prompts, model-specific formats, instructions, and more, calls for a shift to a structured, modular, and customizable solution.","Addressing this need, we present Unitxt, an innovative library for customizable textual data preparation and evaluation tailored to generative language models.","Unitxt natively integrates with common libraries like HuggingFace and LM-eval-harness and deconstructs processing flows into modular components, enabling easy customization and sharing between practitioners.","These components encompass model-specific formats, task prompts, and many other comprehensive dataset processing definitions.","The Unitxt-Catalog centralizes these components, fostering collaboration and exploration in modern textual data workflows.","Beyond being a tool, Unitxt is a community-driven platform, empowering users to build, share, and advance their pipelines collaboratively.","Join the Unitxt community at https://github.com/IBM/unitxt!"],"url":"http://arxiv.org/abs/2401.14019v1"}
{"created":"2024-01-25 08:48:21","title":"Towards Uncertainty-Aware Language Agent","abstract":"While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions. We present the Uncertainty-Aware Language Agent (UALA), a framework that orchestrates the interaction between the agent and the external world using uncertainty quantification. Compared with other well-known counterparts like ReAct, our extensive experiments across 3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes demonstrates that UALA brings a significant improvement of performance, while having a substantially lower reliance on the external world (i.e., reduced number of tool calls and tokens). Our analyses provide various insights including the great potential of UALA compared with agent fine-tuning, and underscoring the unreliably of verbalised confidence of LLMs as a proxy for uncertainty.","sentences":["While Language Agents have achieved promising success by placing Large Language Models at the core of a more versatile design that dynamically interacts with the external world, the existing approaches neglect the notion of uncertainty during these interactions.","We present the Uncertainty-Aware Language Agent (UALA), a framework that orchestrates the interaction between the agent and the external world using uncertainty quantification.","Compared with other well-known counterparts like ReAct, our extensive experiments across 3 representative tasks (HotpotQA, StrategyQA, MMLU) and various LLM sizes demonstrates that UALA brings a significant improvement of performance, while having a substantially lower reliance on the external world (i.e., reduced number of tool calls and tokens).","Our analyses provide various insights including the great potential of UALA compared with agent fine-tuning, and underscoring the unreliably of verbalised confidence of LLMs as a proxy for uncertainty."],"url":"http://arxiv.org/abs/2401.14016v1"}
{"created":"2024-01-25 08:19:59","title":"Leveraging Large Models for Crafting Narrative Visualization: A Survey","abstract":"Narrative visualization effectively transforms data into engaging stories, making complex information accessible to a broad audience. Large models, essential for narrative visualization, inherently facilitate this process through their superior ability to handle natural language queries and answers, generate cohesive narratives, and enhance visual communication. Inspired by previous work in narrative visualization and recent advances in large models, we synthesized potential tasks and opportunities for large models at various stages of narrative visualization. In our study, we surveyed 79 papers to explore the role of large models in automating narrative visualization creation. We propose a comprehensive pipeline that leverages large models for crafting narrative visualization, categorizing the reviewed literature into four essential phases: Data, Narration, Visualization, and Presentation. Additionally, we identify ten specific tasks where large models are applied across these stages. This study maps out the landscape of challenges and opportunities in the LM4NV process, providing insightful directions for future research and valuable guidance for scholars in the field.","sentences":["Narrative visualization effectively transforms data into engaging stories, making complex information accessible to a broad audience.","Large models, essential for narrative visualization, inherently facilitate this process through their superior ability to handle natural language queries and answers, generate cohesive narratives, and enhance visual communication.","Inspired by previous work in narrative visualization and recent advances in large models, we synthesized potential tasks and opportunities for large models at various stages of narrative visualization.","In our study, we surveyed 79 papers to explore the role of large models in automating narrative visualization creation.","We propose a comprehensive pipeline that leverages large models for crafting narrative visualization, categorizing the reviewed literature into four essential phases: Data, Narration, Visualization, and Presentation.","Additionally, we identify ten specific tasks where large models are applied across these stages.","This study maps out the landscape of challenges and opportunities in the LM4NV process, providing insightful directions for future research and valuable guidance for scholars in the field."],"url":"http://arxiv.org/abs/2401.14010v1"}
{"created":"2024-01-25 08:03:38","title":"ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases","abstract":"Reasoning over Commonsense Knowledge Bases (CSKB), i.e. CSKB reasoning, has been explored as a way to acquire new commonsense knowledge based on reference knowledge in the original CSKBs and external prior knowledge. Despite the advancement of Large Language Models (LLM) and prompt engineering techniques in various reasoning tasks, they still struggle to deal with CSKB reasoning. One of the problems is that it is hard for them to acquire explicit relational constraints in CSKBs from only in-context exemplars, due to a lack of symbolic reasoning capabilities (Bengio et al., 2021). To this end, we proposed **ConstraintChecker**, a plugin over prompting techniques to provide and check explicit constraints. When considering a new knowledge instance, ConstraintChecker employs a rule-based module to produce a list of constraints, then it uses a zero-shot learning module to check whether this knowledge instance satisfies all constraints. The acquired constraint-checking result is then aggregated with the output of the main prompting technique to produce the final output. Experimental results on CSKB Reasoning benchmarks demonstrate the effectiveness of our method by bringing consistent improvements over all prompting methods. Codes and data are available at \\url{https://github.com/HKUST-KnowComp/ConstraintChecker}.","sentences":["Reasoning over Commonsense Knowledge Bases (CSKB), i.e. CSKB reasoning, has been explored as a way to acquire new commonsense knowledge based on reference knowledge in the original CSKBs and external prior knowledge.","Despite the advancement of Large Language Models (LLM) and prompt engineering techniques in various reasoning tasks, they still struggle to deal with CSKB reasoning.","One of the problems is that it is hard for them to acquire explicit relational constraints in CSKBs from only in-context exemplars, due to a lack of symbolic reasoning capabilities (Bengio et al., 2021).","To this end, we proposed **ConstraintChecker**, a plugin over prompting techniques to provide and check explicit constraints.","When considering a new knowledge instance, ConstraintChecker employs a rule-based module to produce a list of constraints, then it uses a zero-shot learning module to check whether this knowledge instance satisfies all constraints.","The acquired constraint-checking result is then aggregated with the output of the main prompting technique to produce the final output.","Experimental results on CSKB Reasoning benchmarks demonstrate the effectiveness of our method by bringing consistent improvements over all prompting methods.","Codes and data are available at \\url{https://github.com/HKUST-KnowComp/ConstraintChecker}."],"url":"http://arxiv.org/abs/2401.14003v1"}
{"created":"2024-01-25 07:28:22","title":"Diffusion-based Data Augmentation for Object Counting Problems","abstract":"Crowd counting is an important problem in computer vision due to its wide range of applications in image understanding. Currently, this problem is typically addressed using deep learning approaches, such as Convolutional Neural Networks (CNNs) and Transformers. However, deep networks are data-driven and are prone to overfitting, especially when the available labeled crowd dataset is limited. To overcome this limitation, we have designed a pipeline that utilizes a diffusion model to generate extensive training data. We are the first to generate images conditioned on a location dot map (a binary dot map that specifies the location of human heads) with a diffusion model. We are also the first to use these diverse synthetic data to augment the crowd counting models. Our proposed smoothed density map input for ControlNet significantly improves ControlNet's performance in generating crowds in the correct locations. Also, Our proposed counting loss for the diffusion model effectively minimizes the discrepancies between the location dot map and the crowd images generated. Additionally, our innovative guidance sampling further directs the diffusion process toward regions where the generated crowd images align most accurately with the location dot map. Collectively, we have enhanced ControlNet's ability to generate specified objects from a location dot map, which can be used for data augmentation in various counting problems. Moreover, our framework is versatile and can be easily adapted to all kinds of counting problems. Extensive experiments demonstrate that our framework improves the counting performance on the ShanghaiTech, NWPU-Crowd, UCF-QNRF, and TRANCOS datasets, showcasing its effectiveness.","sentences":["Crowd counting is an important problem in computer vision due to its wide range of applications in image understanding.","Currently, this problem is typically addressed using deep learning approaches, such as Convolutional Neural Networks (CNNs) and Transformers.","However, deep networks are data-driven and are prone to overfitting, especially when the available labeled crowd dataset is limited.","To overcome this limitation, we have designed a pipeline that utilizes a diffusion model to generate extensive training data.","We are the first to generate images conditioned on a location dot map (a binary dot map that specifies the location of human heads) with a diffusion model.","We are also the first to use these diverse synthetic data to augment the crowd counting models.","Our proposed smoothed density map input for ControlNet significantly improves ControlNet's performance in generating crowds in the correct locations.","Also, Our proposed counting loss for the diffusion model effectively minimizes the discrepancies between the location dot map and the crowd images generated.","Additionally, our innovative guidance sampling further directs the diffusion process toward regions where the generated crowd images align most accurately with the location dot map.","Collectively, we have enhanced ControlNet's ability to generate specified objects from a location dot map, which can be used for data augmentation in various counting problems.","Moreover, our framework is versatile and can be easily adapted to all kinds of counting problems.","Extensive experiments demonstrate that our framework improves the counting performance on the ShanghaiTech, NWPU-Crowd, UCF-QNRF, and TRANCOS datasets, showcasing its effectiveness."],"url":"http://arxiv.org/abs/2401.13992v1"}
{"created":"2024-01-25 07:04:30","title":"Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning","abstract":"Large language models (LLMs) often generate convincing, fluent explanations. However, different from humans, they often generate inconsistent explanations on different inputs. For example, an LLM may generate the explanation \"all birds can fly\" when answering the question \"Can sparrows fly?\" but meanwhile answer \"no\" to the related question \"Can penguins fly?\". Explanations should be consistent across related examples so that they allow a human to simulate the LLM's decision process on multiple examples. We propose explanation-consistency finetuning (EC-finetuning), a method that adapts LLMs to generate more consistent natural-language explanations on related examples. EC-finetuning involves finetuning LLMs on synthetic data that is carefully constructed to contain consistent explanations. Across a variety of question-answering datasets in various domains, EC-finetuning yields a 10.0% relative explanation consistency improvement on four finetuning datasets, and generalizes to seven out-of-distribution datasets not seen during finetuning (+4.5% relative). Code is available at https://github.com/yandachen/explanation-consistency-finetuning .","sentences":["Large language models (LLMs) often generate convincing, fluent explanations.","However, different from humans, they often generate inconsistent explanations on different inputs.","For example, an LLM may generate the explanation \"all birds can fly\" when answering the question \"Can sparrows fly?\" but meanwhile answer \"no\" to the related question \"Can penguins fly?\".","Explanations should be consistent across related examples so that they allow a human to simulate the LLM's decision process on multiple examples.","We propose explanation-consistency finetuning (EC-finetuning), a method that adapts LLMs to generate more consistent natural-language explanations on related examples.","EC-finetuning involves finetuning LLMs on synthetic data that is carefully constructed to contain consistent explanations.","Across a variety of question-answering datasets in various domains, EC-finetuning yields a 10.0% relative explanation consistency improvement on four finetuning datasets, and generalizes to seven out-of-distribution datasets not seen during finetuning (+4.5% relative).","Code is available at https://github.com/yandachen/explanation-consistency-finetuning ."],"url":"http://arxiv.org/abs/2401.13986v1"}
{"created":"2024-01-25 06:46:13","title":"A Nearly Information Theoretically Secure Approach for Semantic Communications over Wiretap Channel","abstract":"This paper addresses the challenge of achieving information-theoretic security in semantic communication (SeCom) over a wiretap channel, where a legitimate receiver coexists with an eavesdropper experiencing a poorer channel condition. Despite previous efforts to secure SeCom against eavesdroppers, achieving information-theoretic security in such schemes remains an open issue. In this work, we propose a secure digital SeCom approach based on superposition codes, aiming to attain nearly information-theoretic security. Our proposed method involves associating semantic information with satellite constellation points within a double-layered constellation map, where cloud center constellation points are randomly selected. By carefully allocating power between these two layers of constellation, we ensure that the symbol error probability (SEP) of the eavesdropper decoding satellite constellation points is nearly equivalent to random guessing, while maintaining a low SEP for the legitimate receiver to successfully decode the semantic information. Simulation results showcase that the Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE) for the eavesdropper's reconstructed data, using our proposed method, can range from decoding Gaussian-distributed random noise to approaching the variance of the data. This validates the ability of our method to achieve nearly information-theoretic security, demonstrating superior data security compared to benchmark methods.","sentences":["This paper addresses the challenge of achieving information-theoretic security in semantic communication (SeCom) over a wiretap channel, where a legitimate receiver coexists with an eavesdropper experiencing a poorer channel condition.","Despite previous efforts to secure SeCom against eavesdroppers, achieving information-theoretic security in such schemes remains an open issue.","In this work, we propose a secure digital SeCom approach based on superposition codes, aiming to attain nearly information-theoretic security.","Our proposed method involves associating semantic information with satellite constellation points within a double-layered constellation map, where cloud center constellation points are randomly selected.","By carefully allocating power between these two layers of constellation, we ensure that the symbol error probability (SEP) of the eavesdropper decoding satellite constellation points is nearly equivalent to random guessing, while maintaining a low SEP for the legitimate receiver to successfully decode the semantic information.","Simulation results showcase that the Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE) for the eavesdropper's reconstructed data, using our proposed method, can range from decoding Gaussian-distributed random noise to approaching the variance of the data.","This validates the ability of our method to achieve nearly information-theoretic security, demonstrating superior data security compared to benchmark methods."],"url":"http://arxiv.org/abs/2401.13980v1"}
{"created":"2024-01-25 06:45:32","title":"Leeroo Orchestrator: Elevating LLMs Performance Through Model Integration","abstract":"In this paper, we propose an architecture to harness the collective knowledge of multiple trained LLMs to create a new state-of-the-art. At the core of this framework is a LLM-based orchestrator that is adept at picking the right underlying LLM experts for optimal task execution. Inspired by self-play in reinforcement learning, we created a loop of query generation, orchestration, and evaluation to generate training data for the orchestrator. Our evaluation focused on the MMLU benchmark, employing models with 7B, 13B, and 34B parameters available on Hugging Face. The results demonstrate new state-of-the-art open-source models: Our Leeroo orchestrator achieves performance on par with the Mixtral model while incurring only two-thirds of its cost. Moreover, increasing the allowed cost surpasses Mixtral's accuracy by over 5% at the same cost level, reaching an accuracy of 75.9%. Further enhancements were observed when integrating GPT4 into the underlying model pool. The Leeroo orchestrator nearly matches GPT4's performance at half the cost and even exceeds GPT4's results with a 25% cost reduction. These findings illustrate the potential of our architecture in creating state-of-the-art and cost-effective LLMs by optimizing the synergy between multiple LLMs to achieve superior performance outcomes.","sentences":["In this paper, we propose an architecture to harness the collective knowledge of multiple trained LLMs to create a new state-of-the-art.","At the core of this framework is a LLM-based orchestrator that is adept at picking the right underlying LLM experts for optimal task execution.","Inspired by self-play in reinforcement learning, we created a loop of query generation, orchestration, and evaluation to generate training data for the orchestrator.","Our evaluation focused on the MMLU benchmark, employing models with 7B, 13B, and 34B parameters available on Hugging Face.","The results demonstrate new state-of-the-art open-source models: Our Leeroo orchestrator achieves performance on par with the Mixtral model while incurring only two-thirds of its cost.","Moreover, increasing the allowed cost surpasses Mixtral's accuracy by over 5% at the same cost level, reaching an accuracy of 75.9%.","Further enhancements were observed when integrating GPT4 into the underlying model pool.","The Leeroo orchestrator nearly matches GPT4's performance at half the cost and even exceeds GPT4's results with a 25% cost reduction.","These findings illustrate the potential of our architecture in creating state-of-the-art and cost-effective LLMs by optimizing the synergy between multiple LLMs to achieve superior performance outcomes."],"url":"http://arxiv.org/abs/2401.13979v1"}
{"created":"2024-01-25 06:37:48","title":"Evaluating the Determinants of Mode Choice Using Statistical and Machine Learning Techniques in the Indian Megacity of Bengaluru","abstract":"The decision making involved behind the mode choice is critical for transportation planning. While statistical learning techniques like discrete choice models have been used traditionally, machine learning (ML) models have gained traction recently among the transportation planners due to their higher predictive performance. However, the black box nature of ML models pose significant interpretability challenges, limiting their practical application in decision and policy making. This study utilised a dataset of $1350$ households belonging to low and low-middle income bracket in the city of Bengaluru to investigate mode choice decision making behaviour using Multinomial logit model and ML classifiers like decision trees, random forests, extreme gradient boosting and support vector machines. In terms of accuracy, random forest model performed the best ($0.788$ on training data and $0.605$ on testing data) compared to all the other models. This research has adopted modern interpretability techniques like feature importance and individual conditional expectation plots to explain the decision making behaviour using ML models. A higher travel costs significantly reduce the predicted probability of bus usage compared to other modes (a $0.66\\%$ and $0.34\\%$ reduction using Random Forests and XGBoost model for $10\\%$ increase in travel cost). However, reducing travel time by $10\\%$ increases the preference for the metro ($0.16\\%$ in Random Forests and 0.42% in XGBoost). This research augments the ongoing research on mode choice analysis using machine learning techniques, which would help in improving the understanding of the performance of these models with real-world data in terms of both accuracy and interpretability.","sentences":["The decision making involved behind the mode choice is critical for transportation planning.","While statistical learning techniques like discrete choice models have been used traditionally, machine learning (ML) models have gained traction recently among the transportation planners due to their higher predictive performance.","However, the black box nature of ML models pose significant interpretability challenges, limiting their practical application in decision and policy making.","This study utilised a dataset of $1350$ households belonging to low and low-middle income bracket in the city of Bengaluru to investigate mode choice decision making behaviour using Multinomial logit model and ML classifiers like decision trees, random forests, extreme gradient boosting and support vector machines.","In terms of accuracy, random forest model performed the best ($0.788$ on training data and $0.605$ on testing data) compared to all the other models.","This research has adopted modern interpretability techniques like feature importance and individual conditional expectation plots to explain the decision making behaviour using ML models.","A higher travel costs significantly reduce the predicted probability of bus usage compared to other modes (a $0.66\\%$ and $0.34\\%$ reduction using Random Forests and XGBoost model for $10\\%$ increase in travel cost).","However, reducing travel time by $10\\%$ increases the preference for the metro ($0.16\\%$ in Random Forests and 0.42% in XGBoost).","This research augments the ongoing research on mode choice analysis using machine learning techniques, which would help in improving the understanding of the performance of these models with real-world data in terms of both accuracy and interpretability."],"url":"http://arxiv.org/abs/2401.13977v1"}
{"created":"2024-01-25 06:34:49","title":"Learning to Manipulate Artistic Images","abstract":"Recent advancement in computer vision has significantly lowered the barriers to artistic creation. Exemplar-based image translation methods have attracted much attention due to flexibility and controllability. However, these methods hold assumptions regarding semantics or require semantic information as the input, while accurate semantics is not easy to obtain in artistic images. Besides, these methods suffer from cross-domain artifacts due to training data prior and generate imprecise structure due to feature compression in the spatial domain. In this paper, we propose an arbitrary Style Image Manipulation Network (SIM-Net), which leverages semantic-free information as guidance and a region transportation strategy in a self-supervised manner for image generation. Our method balances computational efficiency and high resolution to a certain extent. Moreover, our method facilitates zero-shot style image manipulation. Both qualitative and quantitative experiments demonstrate the superiority of our method over state-of-the-art methods.Code is available at https://github.com/SnailForce/SIM-Net.","sentences":["Recent advancement in computer vision has significantly lowered the barriers to artistic creation.","Exemplar-based image translation methods have attracted much attention due to flexibility and controllability.","However, these methods hold assumptions regarding semantics or require semantic information as the input, while accurate semantics is not easy to obtain in artistic images.","Besides, these methods suffer from cross-domain artifacts due to training data prior and generate imprecise structure due to feature compression in the spatial domain.","In this paper, we propose an arbitrary Style Image Manipulation Network (SIM-Net), which leverages semantic-free information as guidance and a region transportation strategy in a self-supervised manner for image generation.","Our method balances computational efficiency and high resolution to a certain extent.","Moreover, our method facilitates zero-shot style image manipulation.","Both qualitative and quantitative experiments demonstrate the superiority of our method over state-of-the-art methods.","Code is available at https://github.com/SnailForce/SIM-Net."],"url":"http://arxiv.org/abs/2401.13976v1"}
{"created":"2024-01-25 06:18:20","title":"BootPIG: Bootstrapping Zero-shot Personalized Image Generation Capabilities in Pretrained Diffusion Models","abstract":"Recent text-to-image generation models have demonstrated incredible success in generating images that faithfully follow input prompts. However, the requirement of using words to describe a desired concept provides limited control over the appearance of the generated concepts. In this work, we address this shortcoming by proposing an approach to enable personalization capabilities in existing text-to-image diffusion models. We propose a novel architecture (BootPIG) that allows a user to provide reference images of an object in order to guide the appearance of a concept in the generated images.   The proposed BootPIG architecture makes minimal modifications to a pretrained text-to-image diffusion model and utilizes a separate UNet model to steer the generations toward the desired appearance. We introduce a training procedure that allows us to bootstrap personalization capabilities in the BootPIG architecture using data generated from pretrained text-to-image models, LLM chat agents, and image segmentation models. In contrast to existing methods that require several days of pretraining, the BootPIG architecture can be trained in approximately 1 hour. Experiments on the DreamBooth dataset demonstrate that BootPIG outperforms existing zero-shot methods while being comparable with test-time finetuning approaches. Through a user study, we validate the preference for BootPIG generations over existing methods both in maintaining fidelity to the reference object's appearance and aligning with textual prompts.","sentences":["Recent text-to-image generation models have demonstrated incredible success in generating images that faithfully follow input prompts.","However, the requirement of using words to describe a desired concept provides limited control over the appearance of the generated concepts.","In this work, we address this shortcoming by proposing an approach to enable personalization capabilities in existing text-to-image diffusion models.","We propose a novel architecture (BootPIG) that allows a user to provide reference images of an object in order to guide the appearance of a concept in the generated images.   ","The proposed BootPIG architecture makes minimal modifications to a pretrained text-to-image diffusion model and utilizes a separate UNet model to steer the generations toward the desired appearance.","We introduce a training procedure that allows us to bootstrap personalization capabilities in the BootPIG architecture using data generated from pretrained text-to-image models, LLM chat agents, and image segmentation models.","In contrast to existing methods that require several days of pretraining, the BootPIG architecture can be trained in approximately 1 hour.","Experiments on the DreamBooth dataset demonstrate that BootPIG outperforms existing zero-shot methods while being comparable with test-time finetuning approaches.","Through a user study, we validate the preference for BootPIG generations over existing methods both in maintaining fidelity to the reference object's appearance and aligning with textual prompts."],"url":"http://arxiv.org/abs/2401.13974v1"}
{"created":"2024-01-25 06:03:56","title":"Dynamic Long-Term Time-Series Forecasting via Meta Transformer Networks","abstract":"A reliable long-term time-series forecaster is highly demanded in practice but comes across many challenges such as low computational and memory footprints as well as robustness against dynamic learning environments. This paper proposes Meta-Transformer Networks (MANTRA) to deal with the dynamic long-term time-series forecasting tasks. MANTRA relies on the concept of fast and slow learners where a collection of fast learners learns different aspects of data distributions while adapting quickly to changes. A slow learner tailors suitable representations to fast learners. Fast adaptations to dynamic environments are achieved using the universal representation transformer layers producing task-adapted representations with a small number of parameters. Our experiments using four datasets with different prediction lengths demonstrate the advantage of our approach with at least $3\\%$ improvements over the baseline algorithms for both multivariate and univariate settings. Source codes of MANTRA are publicly available in \\url{https://github.com/anwarmaxsum/MANTRA}.","sentences":["A reliable long-term time-series forecaster is highly demanded in practice but comes across many challenges such as low computational and memory footprints as well as robustness against dynamic learning environments.","This paper proposes Meta-Transformer Networks (MANTRA) to deal with the dynamic long-term time-series forecasting tasks.","MANTRA relies on the concept of fast and slow learners where a collection of fast learners learns different aspects of data distributions while adapting quickly to changes.","A slow learner tailors suitable representations to fast learners.","Fast adaptations to dynamic environments are achieved using the universal representation transformer layers producing task-adapted representations with a small number of parameters.","Our experiments using four datasets with different prediction lengths demonstrate the advantage of our approach with at least $3\\%$ improvements over the baseline algorithms for both multivariate and univariate settings.","Source codes of MANTRA are publicly available in \\url{https://github.com/anwarmaxsum/MANTRA}."],"url":"http://arxiv.org/abs/2401.13968v1"}
{"created":"2024-01-25 05:55:44","title":"Improving Pseudo-labelling and Enhancing Robustness for Semi-Supervised Domain Generalization","abstract":"Beyond attaining domain generalization (DG), visual recognition models should also be data-efficient during learning by leveraging limited labels. We study the problem of Semi-Supervised Domain Generalization (SSDG) which is crucial for real-world applications like automated healthcare. SSDG requires learning a cross-domain generalizable model when the given training data is only partially labelled. Empirical investigations reveal that the DG methods tend to underperform in SSDG settings, likely because they are unable to exploit the unlabelled data. Semi-supervised learning (SSL) shows improved but still inferior results compared to fully-supervised learning. A key challenge, faced by the best-performing SSL-based SSDG methods, is selecting accurate pseudo-labels under multiple domain shifts and reducing overfitting to source domains under limited labels. In this work, we propose new SSDG approach, which utilizes a novel uncertainty-guided pseudo-labelling with model averaging (UPLM). Our uncertainty-guided pseudo-labelling (UPL) uses model uncertainty to improve pseudo-labelling selection, addressing poor model calibration under multi-source unlabelled data. The UPL technique, enhanced by our novel model averaging (MA) strategy, mitigates overfitting to source domains with limited labels. Extensive experiments on key representative DG datasets suggest that our method demonstrates effectiveness against existing methods. Our code and chosen labelled data seeds are available on GitHub: https://github.com/Adnan-Khan7/UPLM","sentences":["Beyond attaining domain generalization (DG), visual recognition models should also be data-efficient during learning by leveraging limited labels.","We study the problem of Semi-Supervised Domain Generalization (SSDG) which is crucial for real-world applications like automated healthcare.","SSDG requires learning a cross-domain generalizable model when the given training data is only partially labelled.","Empirical investigations reveal that the DG methods tend to underperform in SSDG settings, likely because they are unable to exploit the unlabelled data.","Semi-supervised learning (SSL) shows improved but still inferior results compared to fully-supervised learning.","A key challenge, faced by the best-performing SSL-based SSDG methods, is selecting accurate pseudo-labels under multiple domain shifts and reducing overfitting to source domains under limited labels.","In this work, we propose new SSDG approach, which utilizes a novel uncertainty-guided pseudo-labelling with model averaging (UPLM).","Our uncertainty-guided pseudo-labelling (UPL) uses model uncertainty to improve pseudo-labelling selection, addressing poor model calibration under multi-source unlabelled data.","The UPL technique, enhanced by our novel model averaging (MA) strategy, mitigates overfitting to source domains with limited labels.","Extensive experiments on key representative DG datasets suggest that our method demonstrates effectiveness against existing methods.","Our code and chosen labelled data seeds are available on GitHub: https://github.com/Adnan-Khan7/UPLM"],"url":"http://arxiv.org/abs/2401.13965v1"}
{"created":"2024-01-25 05:55:03","title":"An Extensible Framework for Open Heterogeneous Collaborative Perception","abstract":"Collaborative perception aims to mitigate the limitations of single-agent perception, such as occlusions, by facilitating data exchange among multiple agents. However, most current works consider a homogeneous scenario where all agents use identity sensors and perception models. In reality, heterogeneous agent types may continually emerge and inevitably face a domain gap when collaborating with existing agents. In this paper, we introduce a new open heterogeneous problem: how to accommodate continually emerging new heterogeneous agent types into collaborative perception, while ensuring high perception performance and low integration cost? To address this problem, we propose HEterogeneous ALliance (HEAL), a novel extensible collaborative perception framework. HEAL first establishes a unified feature space with initial agents via a novel multi-scale foreground-aware Pyramid Fusion network. When heterogeneous new agents emerge with previously unseen modalities or models, we align them to the established unified space with an innovative backward alignment. This step only involves individual training on the new agent type, thus presenting extremely low training costs and high extensibility. It also protects new agents' model details from disclosure since the training can be conducted by the agent owner locally. To enrich agents' data heterogeneity, we bring OPV2V-H, a new large-scale dataset with more diverse sensor types. Extensive experiments on OPV2V-H and DAIR-V2X datasets show that HEAL surpasses SOTA methods in performance while reducing the training parameters by 91.5% when integrating 3 new agent types. Code and data are available at: https://github.com/yifanlu0227/HEAL.","sentences":["Collaborative perception aims to mitigate the limitations of single-agent perception, such as occlusions, by facilitating data exchange among multiple agents.","However, most current works consider a homogeneous scenario where all agents use identity sensors and perception models.","In reality, heterogeneous agent types may continually emerge and inevitably face a domain gap when collaborating with existing agents.","In this paper, we introduce a new open heterogeneous problem: how to accommodate continually emerging new heterogeneous agent types into collaborative perception, while ensuring high perception performance and low integration cost?","To address this problem, we propose HEterogeneous ALliance (HEAL), a novel extensible collaborative perception framework.","HEAL first establishes a unified feature space with initial agents via a novel multi-scale foreground-aware Pyramid Fusion network.","When heterogeneous new agents emerge with previously unseen modalities or models, we align them to the established unified space with an innovative backward alignment.","This step only involves individual training on the new agent type, thus presenting extremely low training costs and high extensibility.","It also protects new agents' model details from disclosure since the training can be conducted by the agent owner locally.","To enrich agents' data heterogeneity, we bring OPV2V-H, a new large-scale dataset with more diverse sensor types.","Extensive experiments on OPV2V-H and DAIR-V2X datasets show that HEAL surpasses SOTA methods in performance while reducing the training parameters by 91.5% when integrating 3 new agent types.","Code and data are available at: https://github.com/yifanlu0227/HEAL."],"url":"http://arxiv.org/abs/2401.13964v1"}
{"created":"2024-01-25 05:18:47","title":"Randomized Response with Gradual Release of Privacy Budget","abstract":"An algorithm is developed to gradually relax the Differential Privacy (DP) guarantee of a randomized response. The output from each relaxation maintains the same probability distribution as a standard randomized response with the equivalent DP guarantee, ensuring identical utility as the standard approach. The entire relaxation process is proven to have the same DP guarantee as the most recent relaxed guarantee.   The DP relaxation algorithm is adaptable to any Local Differential Privacy (LDP) mechanisms relying on randomized response. It has been seamlessly integrated into RAPPOR, an LDP crowdsourcing string-collecting tool, to optimize the utility of estimating the frequency of collected data. Additionally, it facilitates the relaxation of the DP guarantee for mean estimation based on randomized response. Finally, numerical experiments have been conducted to validate the utility and DP guarantee of the algorithm.","sentences":["An algorithm is developed to gradually relax the Differential Privacy (DP) guarantee of a randomized response.","The output from each relaxation maintains the same probability distribution as a standard randomized response with the equivalent DP guarantee, ensuring identical utility as the standard approach.","The entire relaxation process is proven to have the same DP guarantee as the most recent relaxed guarantee.   ","The DP relaxation algorithm is adaptable to any Local Differential Privacy (LDP) mechanisms relying on randomized response.","It has been seamlessly integrated into RAPPOR, an LDP crowdsourcing string-collecting tool, to optimize the utility of estimating the frequency of collected data.","Additionally, it facilitates the relaxation of the DP guarantee for mean estimation based on randomized response.","Finally, numerical experiments have been conducted to validate the utility and DP guarantee of the algorithm."],"url":"http://arxiv.org/abs/2401.13952v1"}
{"created":"2024-01-25 04:53:03","title":"StyleInject: Parameter Efficient Tuning of Text-to-Image Diffusion Models","abstract":"The ability to fine-tune generative models for text-to-image generation tasks is crucial, particularly facing the complexity involved in accurately interpreting and visualizing textual inputs. While LoRA is efficient for language model adaptation, it often falls short in text-to-image tasks due to the intricate demands of image generation, such as accommodating a broad spectrum of styles and nuances. To bridge this gap, we introduce StyleInject, a specialized fine-tuning approach tailored for text-to-image models. StyleInject comprises multiple parallel low-rank parameter matrices, maintaining the diversity of visual features. It dynamically adapts to varying styles by adjusting the variance of visual features based on the characteristics of the input signal. This approach significantly minimizes the impact on the original model's text-image alignment capabilities while adeptly adapting to various styles in transfer learning. StyleInject proves particularly effective in learning from and enhancing a range of advanced, community-fine-tuned generative models. Our comprehensive experiments, including both small-sample and large-scale data fine-tuning as well as base model distillation, show that StyleInject surpasses traditional LoRA in both text-image semantic consistency and human preference evaluation, all while ensuring greater parameter efficiency.","sentences":["The ability to fine-tune generative models for text-to-image generation tasks is crucial, particularly facing the complexity involved in accurately interpreting and visualizing textual inputs.","While LoRA is efficient for language model adaptation, it often falls short in text-to-image tasks due to the intricate demands of image generation, such as accommodating a broad spectrum of styles and nuances.","To bridge this gap, we introduce StyleInject, a specialized fine-tuning approach tailored for text-to-image models.","StyleInject comprises multiple parallel low-rank parameter matrices, maintaining the diversity of visual features.","It dynamically adapts to varying styles by adjusting the variance of visual features based on the characteristics of the input signal.","This approach significantly minimizes the impact on the original model's text-image alignment capabilities while adeptly adapting to various styles in transfer learning.","StyleInject proves particularly effective in learning from and enhancing a range of advanced, community-fine-tuned generative models.","Our comprehensive experiments, including both small-sample and large-scale data fine-tuning as well as base model distillation, show that StyleInject surpasses traditional LoRA in both text-image semantic consistency and human preference evaluation, all while ensuring greater parameter efficiency."],"url":"http://arxiv.org/abs/2401.13942v1"}
{"created":"2024-01-25 04:39:48","title":"Self-supervised Video Object Segmentation with Distillation Learning of Deformable Attention","abstract":"Video object segmentation is a fundamental research problem in computer vision. Recent techniques have often applied attention mechanism to object representation learning from video sequences. However, due to temporal changes in the video data, attention maps may not well align with the objects of interest across video frames, causing accumulated errors in long-term video processing. In addition, existing techniques have utilised complex architectures, requiring highly computational complexity and hence limiting the ability to integrate video object segmentation into low-powered devices. To address these issues, we propose a new method for self-supervised video object segmentation based on distillation learning of deformable attention. Specifically, we devise a lightweight architecture for video object segmentation that is effectively adapted to temporal changes. This is enabled by deformable attention mechanism, where the keys and values capturing the memory of a video sequence in the attention module have flexible locations updated across frames. The learnt object representations are thus adaptive to both the spatial and temporal dimensions. We train the proposed architecture in a self-supervised fashion through a new knowledge distillation paradigm where deformable attention maps are integrated into the distillation loss. We qualitatively and quantitatively evaluate our method and compare it with existing methods on benchmark datasets including DAVIS 2016/2017 and YouTube-VOS 2018/2019. Experimental results verify the superiority of our method via its achieved state-of-the-art performance and optimal memory usage.","sentences":["Video object segmentation is a fundamental research problem in computer vision.","Recent techniques have often applied attention mechanism to object representation learning from video sequences.","However, due to temporal changes in the video data, attention maps may not well align with the objects of interest across video frames, causing accumulated errors in long-term video processing.","In addition, existing techniques have utilised complex architectures, requiring highly computational complexity and hence limiting the ability to integrate video object segmentation into low-powered devices.","To address these issues, we propose a new method for self-supervised video object segmentation based on distillation learning of deformable attention.","Specifically, we devise a lightweight architecture for video object segmentation that is effectively adapted to temporal changes.","This is enabled by deformable attention mechanism, where the keys and values capturing the memory of a video sequence in the attention module have flexible locations updated across frames.","The learnt object representations are thus adaptive to both the spatial and temporal dimensions.","We train the proposed architecture in a self-supervised fashion through a new knowledge distillation paradigm where deformable attention maps are integrated into the distillation loss.","We qualitatively and quantitatively evaluate our method and compare it with existing methods on benchmark datasets including DAVIS 2016/2017 and YouTube-VOS 2018/2019.","Experimental results verify the superiority of our method via its achieved state-of-the-art performance and optimal memory usage."],"url":"http://arxiv.org/abs/2401.13937v1"}
{"created":"2024-01-25 04:28:39","title":"A New Paradigm for Counterfactual Reasoning in Fairness and Recourse","abstract":"Counterfactuals and counterfactual reasoning underpin numerous techniques for auditing and understanding artificial intelligence (AI) systems. The traditional paradigm for counterfactual reasoning in this literature is the interventional counterfactual, where hypothetical interventions are imagined and simulated. For this reason, the starting point for causal reasoning about legal protections and demographic data in AI is an imagined intervention on a legally-protected characteristic, such as ethnicity, race, gender, disability, age, etc. We ask, for example, what would have happened had your race been different? An inherent limitation of this paradigm is that some demographic interventions -- like interventions on race -- may not translate into the formalisms of interventional counterfactuals. In this work, we explore a new paradigm based instead on the backtracking counterfactual, where rather than imagine hypothetical interventions on legally-protected characteristics, we imagine alternate initial conditions while holding these characteristics fixed. We ask instead, what would explain a counterfactual outcome for you as you actually are or could be? This alternate framework allows us to address many of the same social concerns, but to do so while asking fundamentally different questions that do not rely on demographic interventions.","sentences":["Counterfactuals and counterfactual reasoning underpin numerous techniques for auditing and understanding artificial intelligence (AI) systems.","The traditional paradigm for counterfactual reasoning in this literature is the interventional counterfactual, where hypothetical interventions are imagined and simulated.","For this reason, the starting point for causal reasoning about legal protections and demographic data in AI is an imagined intervention on a legally-protected characteristic, such as ethnicity, race, gender, disability, age, etc.","We ask, for example, what would have happened had your race been different?","An inherent limitation of this paradigm is that some demographic interventions -- like interventions on race -- may not translate into the formalisms of interventional counterfactuals.","In this work, we explore a new paradigm based instead on the backtracking counterfactual, where rather than imagine hypothetical interventions on legally-protected characteristics, we imagine alternate initial conditions while holding these characteristics fixed.","We ask instead, what would explain a counterfactual outcome for you as you actually are or could be?","This alternate framework allows us to address many of the same social concerns, but to do so while asking fundamentally different questions that do not rely on demographic interventions."],"url":"http://arxiv.org/abs/2401.13935v1"}
{"created":"2024-01-25 04:16:45","title":"MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration","abstract":"Deformable image registration is an essential approach for medical image analysis.This paper introduces MambaMorph, an innovative multi-modality deformable registration network, specifically designed for Magnetic Resonance (MR) and Computed Tomography (CT) image alignment. MambaMorph stands out with its Mamba-based registration module and a contrastive feature learning approach, addressing the prevalent challenges in multi-modality registration. The network leverages Mamba blocks for efficient long-range modeling and high-dimensional data processing, coupled with a feature extractor that learns fine-grained features for enhanced registration accuracy. Experimental results showcase MambaMorph's superior performance over existing methods in MR-CT registration, underlining its potential in clinical applications. This work underscores the significance of feature learning in multi-modality registration and positions MambaMorph as a trailblazing solution in this field. The code for MambaMorph is available at: https://github.com/Guo-Stone/MambaMorph.","sentences":["Deformable image registration is an essential approach for medical image analysis.","This paper introduces MambaMorph, an innovative multi-modality deformable registration network, specifically designed for Magnetic Resonance (MR) and Computed Tomography (CT) image alignment.","MambaMorph stands out with its Mamba-based registration module and a contrastive feature learning approach, addressing the prevalent challenges in multi-modality registration.","The network leverages Mamba blocks for efficient long-range modeling and high-dimensional data processing, coupled with a feature extractor that learns fine-grained features for enhanced registration accuracy.","Experimental results showcase MambaMorph's superior performance over existing methods in MR-CT registration, underlining its potential in clinical applications.","This work underscores the significance of feature learning in multi-modality registration and positions MambaMorph as a trailblazing solution in this field.","The code for MambaMorph is available at: https://github.com/Guo-Stone/MambaMorph."],"url":"http://arxiv.org/abs/2401.13934v1"}
{"created":"2024-01-25 03:17:03","title":"Spectral Clustering for Discrete Distributions","abstract":"Discrete distribution clustering (D2C) was often solved by Wasserstein barycenter methods. These methods are under a common assumption that clusters can be well represented by barycenters, which may not hold in many real applications. In this work, we propose a simple yet effective framework based on spectral clustering and distribution affinity measures (e.g., maximum mean discrepancy and Wasserstein distance) for D2C. To improve the scalability, we propose to use linear optimal transport to construct affinity matrices efficiently on large datasets. We provide theoretical guarantees for the success of the proposed methods in clustering distributions. Experiments on synthetic and real data show that our methods outperform the baselines largely in terms of both clustering accuracy and computational efficiency.","sentences":["Discrete distribution clustering (D2C) was often solved by Wasserstein barycenter methods.","These methods are under a common assumption that clusters can be well represented by barycenters, which may not hold in many real applications.","In this work, we propose a simple yet effective framework based on spectral clustering and distribution affinity measures (e.g., maximum mean discrepancy and Wasserstein distance) for D2C. To improve the scalability, we propose to use linear optimal transport to construct affinity matrices efficiently on large datasets.","We provide theoretical guarantees for the success of the proposed methods in clustering distributions.","Experiments on synthetic and real data show that our methods outperform the baselines largely in terms of both clustering accuracy and computational efficiency."],"url":"http://arxiv.org/abs/2401.13913v1"}
{"created":"2024-01-25 03:14:07","title":"A Survey of Deep Learning and Foundation Models for Time Series Forecasting","abstract":"Deep Learning has been successfully applied to many application domains, yet its advantages have been slow to emerge for time series forecasting. For example, in the well-known Makridakis (M) Competitions, hybrids of traditional statistical or machine learning techniques have only recently become the top performers. With the recent architectural advances in deep learning being applied to time series forecasting (e.g., encoder-decoders with attention, transformers, and graph neural networks), deep learning has begun to show significant advantages. Still, in the area of pandemic prediction, there remain challenges for deep learning models: the time series is not long enough for effective training, unawareness of accumulated scientific knowledge, and interpretability of the model. To this end, the development of foundation models (large deep learning models with extensive pre-training) allows models to understand patterns and acquire knowledge that can be applied to new related problems before extensive training data becomes available. Furthermore, there is a vast amount of knowledge available that deep learning models can tap into, including Knowledge Graphs and Large Language Models fine-tuned with scientific domain knowledge. There is ongoing research examining how to utilize or inject such knowledge into deep learning models. In this survey, several state-of-the-art modeling techniques are reviewed, and suggestions for further work are provided.","sentences":["Deep Learning has been successfully applied to many application domains, yet its advantages have been slow to emerge for time series forecasting.","For example, in the well-known Makridakis (M) Competitions, hybrids of traditional statistical or machine learning techniques have only recently become the top performers.","With the recent architectural advances in deep learning being applied to time series forecasting (e.g., encoder-decoders with attention, transformers, and graph neural networks), deep learning has begun to show significant advantages.","Still, in the area of pandemic prediction, there remain challenges for deep learning models: the time series is not long enough for effective training, unawareness of accumulated scientific knowledge, and interpretability of the model.","To this end, the development of foundation models (large deep learning models with extensive pre-training) allows models to understand patterns and acquire knowledge that can be applied to new related problems before extensive training data becomes available.","Furthermore, there is a vast amount of knowledge available that deep learning models can tap into, including Knowledge Graphs and Large Language Models fine-tuned with scientific domain knowledge.","There is ongoing research examining how to utilize or inject such knowledge into deep learning models.","In this survey, several state-of-the-art modeling techniques are reviewed, and suggestions for further work are provided."],"url":"http://arxiv.org/abs/2401.13912v1"}
{"created":"2024-01-25 02:54:53","title":"No More Distractions: an Adaptive Up-Sampling Algorithm to Reduce Data Artifacts","abstract":"Researchers recently found out that sometimes language models achieve high accuracy on benchmark data set, but they can not generalize very well with even little changes to the original data set. This is sometimes due to data artifacts, model is learning the spurious correlation between tokens and labels, instead of the semantics and logic. In this work, we analyzed SNLI data and visualized such spurious correlations. We proposed an adaptive up-sampling algorithm to correct the data artifacts, which is simple and effective, and does not need human edits or annotation. We did an experiment applying the algorithm to fix the data artifacts in SNLI data and the model trained with corrected data performed significantly better than the model trained with raw SNLI data, overall, as well as on the subset we corrected.","sentences":["Researchers recently found out that sometimes language models achieve high accuracy on benchmark data set, but they can not generalize very well with even little changes to the original data set.","This is sometimes due to data artifacts, model is learning the spurious correlation between tokens and labels, instead of the semantics and logic.","In this work, we analyzed SNLI data and visualized such spurious correlations.","We proposed an adaptive up-sampling algorithm to correct the data artifacts, which is simple and effective, and does not need human edits or annotation.","We did an experiment applying the algorithm to fix the data artifacts in SNLI data and the model trained with corrected data performed significantly better than the model trained with raw SNLI data, overall, as well as on the subset we corrected."],"url":"http://arxiv.org/abs/2401.13907v1"}
{"created":"2024-01-25 02:25:23","title":"Cross-Modal Prototype based Multimodal Federated Learning under Severely Missing Modality","abstract":"Multimodal federated learning (MFL) has emerged as a decentralized machine learning paradigm, allowing multiple clients with different modalities to collaborate on training a machine learning model across diverse data sources without sharing their private data. However, challenges, such as data heterogeneity and severely missing modalities, pose crucial hindrances to the robustness of MFL, significantly impacting the performance of global model. The absence of a modality introduces misalignment during the local training phase, stemming from zero-filling in the case of clients with missing modalities. Consequently, achieving robust generalization in global model becomes imperative, especially when dealing with clients that have incomplete data. In this paper, we propose Multimodal Federated Cross Prototype Learning (MFCPL), a novel approach for MFL under severely missing modalities by conducting the complete prototypes to provide diverse modality knowledge in modality-shared level with the cross-modal regularization and modality-specific level with cross-modal contrastive mechanism. Additionally, our approach introduces the cross-modal alignment to provide regularization for modality-specific features, thereby enhancing overall performance, particularly in scenarios involving severely missing modalities. Through extensive experiments on three multimodal datasets, we demonstrate the effectiveness of MFCPL in mitigating these challenges and improving the overall performance.","sentences":["Multimodal federated learning (MFL) has emerged as a decentralized machine learning paradigm, allowing multiple clients with different modalities to collaborate on training a machine learning model across diverse data sources without sharing their private data.","However, challenges, such as data heterogeneity and severely missing modalities, pose crucial hindrances to the robustness of MFL, significantly impacting the performance of global model.","The absence of a modality introduces misalignment during the local training phase, stemming from zero-filling in the case of clients with missing modalities.","Consequently, achieving robust generalization in global model becomes imperative, especially when dealing with clients that have incomplete data.","In this paper, we propose Multimodal Federated Cross Prototype Learning (MFCPL), a novel approach for MFL under severely missing modalities by conducting the complete prototypes to provide diverse modality knowledge in modality-shared level with the cross-modal regularization and modality-specific level with cross-modal contrastive mechanism.","Additionally, our approach introduces the cross-modal alignment to provide regularization for modality-specific features, thereby enhancing overall performance, particularly in scenarios involving severely missing modalities.","Through extensive experiments on three multimodal datasets, we demonstrate the effectiveness of MFCPL in mitigating these challenges and improving the overall performance."],"url":"http://arxiv.org/abs/2401.13898v1"}
{"created":"2024-01-25 02:05:31","title":"A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification","abstract":"Although supervised machine learning is popular for information extraction from clinical notes, creating large annotated datasets requires extensive domain expertise and is time-consuming. Meanwhile, large language models (LLMs) have demonstrated promising transfer learning capability. In this study, we explored whether recent LLMs can reduce the need for large-scale data annotations. We curated a manually-labeled dataset of 769 breast cancer pathology reports, labeled with 13 categories, to compare zero-shot classification capability of the GPT-4 model and the GPT-3.5 model with supervised classification performance of three model architectures: random forests classifier, long short-term memory networks with attention (LSTM-Att), and the UCSF-BERT model. Across all 13 tasks, the GPT-4 model performed either significantly better than or as well as the best supervised model, the LSTM-Att model (average macro F1 score of 0.83 vs. 0.75). On tasks with high imbalance between labels, the differences were more prominent. Frequent sources of GPT-4 errors included inferences from multiple samples and complex task design. On complex tasks where large annotated datasets cannot be easily collected, LLMs can reduce the burden of large-scale data labeling. However, if the use of LLMs is prohibitive, the use of simpler supervised models with large annotated datasets can provide comparable results. LLMs demonstrated the potential to speed up the execution of clinical NLP studies by reducing the need for curating large annotated datasets. This may result in an increase in the utilization of NLP-based variables and outcomes in observational clinical studies.","sentences":["Although supervised machine learning is popular for information extraction from clinical notes, creating large annotated datasets requires extensive domain expertise and is time-consuming.","Meanwhile, large language models (LLMs) have demonstrated promising transfer learning capability.","In this study, we explored whether recent LLMs can reduce the need for large-scale data annotations.","We curated a manually-labeled dataset of 769 breast cancer pathology reports, labeled with 13 categories, to compare zero-shot classification capability of the GPT-4 model and the GPT-3.5 model with supervised classification performance of three model architectures: random forests classifier, long short-term memory networks with attention (LSTM-Att), and the UCSF-BERT model.","Across all 13 tasks, the GPT-4 model performed either significantly better than or as well as the best supervised model, the LSTM-Att model (average macro F1 score of 0.83 vs. 0.75).","On tasks with high imbalance between labels, the differences were more prominent.","Frequent sources of GPT-4 errors included inferences from multiple samples and complex task design.","On complex tasks where large annotated datasets cannot be easily collected, LLMs can reduce the burden of large-scale data labeling.","However, if the use of LLMs is prohibitive, the use of simpler supervised models with large annotated datasets can provide comparable results.","LLMs demonstrated the potential to speed up the execution of clinical NLP studies by reducing the need for curating large annotated datasets.","This may result in an increase in the utilization of NLP-based variables and outcomes in observational clinical studies."],"url":"http://arxiv.org/abs/2401.13887v1"}
{"created":"2024-01-25 00:41:07","title":"Integrating Large Language Models into Recommendation via Mutual Augmentation and Adaptive Aggregation","abstract":"Conventional recommendation methods have achieved notable advancements by harnessing collaborative or sequential information from user behavior. Recently, large language models (LLMs) have gained prominence for their capabilities in understanding and reasoning over textual semantics, and have found utility in various domains, including recommendation. Conventional recommendation methods and LLMs each have their strengths and weaknesses. While conventional methods excel at mining collaborative information and modeling sequential behavior, they struggle with data sparsity and the long-tail problem. LLMs, on the other hand, are proficient at utilizing rich textual contexts but face challenges in mining collaborative or sequential information. Despite their individual successes, there is a significant gap in leveraging their combined potential to enhance recommendation performance.   In this paper, we introduce a general and model-agnostic framework known as \\textbf{L}arge \\textbf{la}nguage model with \\textbf{m}utual augmentation and \\textbf{a}daptive aggregation for \\textbf{Rec}ommendation (\\textbf{Llama4Rec}). Llama4Rec synergistically combines conventional and LLM-based recommendation models. Llama4Rec proposes data augmentation and prompt augmentation strategies tailored to enhance the conventional model and LLM respectively. An adaptive aggregation module is adopted to combine the predictions of both kinds of models to refine the final recommendation results. Empirical studies on three real-world datasets validate the superiority of Llama4Rec, demonstrating its consistent outperformance of baseline methods and significant improvements in recommendation performance.","sentences":["Conventional recommendation methods have achieved notable advancements by harnessing collaborative or sequential information from user behavior.","Recently, large language models (LLMs) have gained prominence for their capabilities in understanding and reasoning over textual semantics, and have found utility in various domains, including recommendation.","Conventional recommendation methods and LLMs each have their strengths and weaknesses.","While conventional methods excel at mining collaborative information and modeling sequential behavior, they struggle with data sparsity and the long-tail problem.","LLMs, on the other hand, are proficient at utilizing rich textual contexts but face challenges in mining collaborative or sequential information.","Despite their individual successes, there is a significant gap in leveraging their combined potential to enhance recommendation performance.   ","In this paper, we introduce a general and model-agnostic framework known as \\textbf{L}arge \\textbf{la}nguage model with \\textbf{m}utual augmentation and \\textbf{a}daptive aggregation for \\textbf{Rec}ommendation (\\textbf{Llama4Rec}).","Llama4Rec synergistically combines conventional and LLM-based recommendation models.","Llama4Rec proposes data augmentation and prompt augmentation strategies tailored to enhance the conventional model and LLM respectively.","An adaptive aggregation module is adopted to combine the predictions of both kinds of models to refine the final recommendation results.","Empirical studies on three real-world datasets validate the superiority of Llama4Rec, demonstrating its consistent outperformance of baseline methods and significant improvements in recommendation performance."],"url":"http://arxiv.org/abs/2401.13870v1"}
{"created":"2024-01-24 23:25:23","title":"Dataset and Benchmark: Novel Sensors for Autonomous Vehicle Perception","abstract":"Conventional cameras employed in autonomous vehicle (AV) systems support many perception tasks, but are challenged by low-light or high dynamic range scenes, adverse weather, and fast motion. Novel sensors, such as event and thermal cameras, offer capabilities with the potential to address these scenarios, but they remain to be fully exploited. This paper introduces the Novel Sensors for Autonomous Vehicle Perception (NSAVP) dataset to facilitate future research on this topic. The dataset was captured with a platform including stereo event, thermal, monochrome, and RGB cameras as well as a high precision navigation system providing ground truth poses. The data was collected by repeatedly driving two ~8 km routes and includes varied lighting conditions and opposing viewpoint perspectives. We provide benchmarking experiments on the task of place recognition to demonstrate challenges and opportunities for novel sensors to enhance critical AV perception tasks. To our knowledge, the NSAVP dataset is the first to include stereo thermal cameras together with stereo event and monochrome cameras. The dataset and supporting software suite is available at: https://umautobots.github.io/nsavp","sentences":["Conventional cameras employed in autonomous vehicle (AV) systems support many perception tasks, but are challenged by low-light or high dynamic range scenes, adverse weather, and fast motion.","Novel sensors, such as event and thermal cameras, offer capabilities with the potential to address these scenarios, but they remain to be fully exploited.","This paper introduces the Novel Sensors for Autonomous Vehicle Perception (NSAVP) dataset to facilitate future research on this topic.","The dataset was captured with a platform including stereo event, thermal, monochrome, and RGB cameras as well as a high precision navigation system providing ground truth poses.","The data was collected by repeatedly driving two ~8 km routes and includes varied lighting conditions and opposing viewpoint perspectives.","We provide benchmarking experiments on the task of place recognition to demonstrate challenges and opportunities for novel sensors to enhance critical AV perception tasks.","To our knowledge, the NSAVP dataset is the first to include stereo thermal cameras together with stereo event and monochrome cameras.","The dataset and supporting software suite is available at: https://umautobots.github.io/nsavp"],"url":"http://arxiv.org/abs/2401.13853v1"}
{"created":"2024-01-24 23:18:33","title":"Scaling NVIDIA's multi-speaker multi-lingual TTS systems with voice cloning to Indic Languages","abstract":"In this paper, we describe the TTS models developed by NVIDIA for the MMITS-VC (Multi-speaker, Multi-lingual Indic TTS with Voice Cloning) 2024 Challenge. In Tracks 1 and 2, we utilize RAD-MMM to perform few-shot TTS by training additionally on 5 minutes of target speaker data. In Track 3, we utilize P-Flow to perform zero-shot TTS by training on the challenge dataset as well as external datasets. We use HiFi-GAN vocoders for all submissions. RAD-MMM performs competitively on Tracks 1 and 2, while P-Flow ranks first on Track 3, with mean opinion score (MOS) 4.4 and speaker similarity score (SMOS) of 3.62.","sentences":["In this paper, we describe the TTS models developed by NVIDIA for the MMITS-VC (Multi-speaker, Multi-lingual Indic TTS with Voice Cloning) 2024 Challenge.","In Tracks 1 and 2, we utilize RAD-MMM to perform few-shot TTS by training additionally on 5 minutes of target speaker data.","In Track 3, we utilize P-Flow to perform zero-shot TTS by training on the challenge dataset as well as external datasets.","We use HiFi-GAN vocoders for all submissions.","RAD-MMM performs competitively on Tracks 1 and 2, while P-Flow ranks first on Track 3, with mean opinion score (MOS) 4.4 and speaker similarity score (SMOS) of 3.62."],"url":"http://arxiv.org/abs/2401.13851v1"}
{"created":"2024-01-24 23:11:33","title":"TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance","abstract":"Large Language Models (LLMs) have recently showcased remarkable reasoning abilities. However, larger models often surpass their smaller counterparts in reasoning tasks, posing the challenge of effectively transferring these capabilities from larger models. Existing approaches heavily rely on extensive fine-tuning data or continuous interactions with a superior teacher LLM during inference. We introduce a principle-based teacher-student framework called ``Teaching via Principle Discovery'' (TPD) to address these limitations. Inspired by human learning mechanisms, TPD mimics the interaction between a teacher and a student using a principle-based approach. The teacher LLM generates problem-solving instructions and corrective principles based on the student LLM's errors. These principles guide the refinement of instructions and the selection of instructive examples from a validation set. This enables the student model to learn from both the teacher's guidance and its own mistakes. Once the student model begins making inferences, TPD requires no further intervention from the teacher LLM or humans. Through extensive experiments across eight reasoning tasks, we demonstrate the effectiveness of TPD. Compared to standard chain-of-thought prompting, TPD significantly improves the student model's performance, achieving $6.2\\%$ improvement on average.","sentences":["Large Language Models (LLMs) have recently showcased remarkable reasoning abilities.","However, larger models often surpass their smaller counterparts in reasoning tasks, posing the challenge of effectively transferring these capabilities from larger models.","Existing approaches heavily rely on extensive fine-tuning data or continuous interactions with a superior teacher LLM during inference.","We introduce a principle-based teacher-student framework called ``Teaching via Principle Discovery'' (TPD) to address these limitations.","Inspired by human learning mechanisms, TPD mimics the interaction between a teacher and a student using a principle-based approach.","The teacher LLM generates problem-solving instructions and corrective principles based on the student LLM's errors.","These principles guide the refinement of instructions and the selection of instructive examples from a validation set.","This enables the student model to learn from both the teacher's guidance and its own mistakes.","Once the student model begins making inferences, TPD requires no further intervention from the teacher LLM or humans.","Through extensive experiments across eight reasoning tasks, we demonstrate the effectiveness of TPD.","Compared to standard chain-of-thought prompting, TPD significantly improves the student model's performance, achieving $6.2\\%$ improvement on average."],"url":"http://arxiv.org/abs/2401.13849v1"}
{"created":"2024-01-24 23:11:11","title":"A V2X-based Privacy Preserving Federated Measuring and Learning System","abstract":"Future autonomous vehicles (AVs) will use a variety of sensors that generate a vast amount of data. Naturally, this data not only serves self-driving algorithms; but can also assist other vehicles or the infrastructure in real-time decision-making. Consequently, vehicles shall exchange their measurement data over Vehicle-to-Everything (V2X) technologies. Moreover, predicting the state of the road network might be beneficial too. With such a prediction, we might mitigate road congestion, balance parking lot usage, or optimize the traffic flow. That would decrease transportation costs as well as reduce its environmental impact.   In this paper, we propose a federated measurement and learning system that provides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V) communication while also operating a federated learning (FL) scheme over the Vehicle-to-Network (V2N) link to create a predictive model of the transportation network. As we are yet to have real-world AV data, we model it with a non-IID (independent and identically distributed) dataset to evaluate the capabilities of the proposed system in terms of performance and privacy. Results indicate that the proposed FL scheme improves learning performance and prevents eavesdropping at the aggregator server side.","sentences":["Future autonomous vehicles (AVs) will use a variety of sensors that generate a vast amount of data.","Naturally, this data not only serves self-driving algorithms; but can also assist other vehicles or the infrastructure in real-time decision-making.","Consequently, vehicles shall exchange their measurement data over Vehicle-to-Everything (V2X) technologies.","Moreover, predicting the state of the road network might be beneficial too.","With such a prediction, we might mitigate road congestion, balance parking lot usage, or optimize the traffic flow.","That would decrease transportation costs as well as reduce its environmental impact.   ","In this paper, we propose a federated measurement and learning system that provides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V) communication while also operating a federated learning (FL) scheme over the Vehicle-to-Network (V2N) link to create a predictive model of the transportation network.","As we are yet to have real-world AV data, we model it with a non-IID (independent and identically distributed) dataset to evaluate the capabilities of the proposed system in terms of performance and privacy.","Results indicate that the proposed FL scheme improves learning performance and prevents eavesdropping at the aggregator server side."],"url":"http://arxiv.org/abs/2401.13848v1"}
{"created":"2024-01-24 22:33:41","title":"Tight Competitive and Variance Analyses of Matching Policies in Gig Platforms","abstract":"In this paper, we propose an online-matching-based model to tackle the two fundamental issues, matching and pricing, existing in a wide range of real-world gig platforms, including ride-hailing (matching riders and drivers), crowdsourcing markets (pairing workers and tasks), and online recommendations (offering items to customers). Our model assumes the arriving distributions of dynamic agents (e.g., riders, workers, and buyers) are accessible in advance, and they can change over time, which is referred to as \\emph{Known Heterogeneous Distributions} (KHD).   In this paper, we initiate variance analysis for online matching algorithms under KHD. Unlike the popular competitive-ratio (CR) metric, the variance of online algorithms' performance is rarely studied due to inherent technical challenges, though it is well linked to robustness. We focus on two natural parameterized sampling policies, denoted by $\\mathsf{ATT}(\\gamma)$ and $\\mathsf{SAMP}(\\gamma)$, which appear as foundational bedrock in online algorithm design. We offer rigorous competitive ratio (CR) and variance analyses for both policies. Specifically, we show that $\\mathsf{ATT}(\\gamma)$ with $\\gamma \\in [0,1/2]$ achieves a CR of $\\gamma$ and a variance of $\\gamma \\cdot (1-\\gamma) \\cdot B$ on the total number of matches with $B$ being the total matching capacity. In contrast, $\\mathsf{SAMP}(\\gamma)$ with $\\gamma \\in [0,1]$ accomplishes a CR of $\\gamma (1-\\gamma)$ and a variance of $\\bar{\\gamma} (1-\\bar{\\gamma})\\cdot B$ with $\\bar{\\gamma}=\\min(\\gamma,1/2)$. All CR and variance analyses are tight and unconditional of any benchmark. As a byproduct, we prove that $\\mathsf{ATT}(\\gamma=1/2)$ achieves an optimal CR of $1/2$.","sentences":["In this paper, we propose an online-matching-based model to tackle the two fundamental issues, matching and pricing, existing in a wide range of real-world gig platforms, including ride-hailing (matching riders and drivers), crowdsourcing markets (pairing workers and tasks), and online recommendations (offering items to customers).","Our model assumes the arriving distributions of dynamic agents (e.g., riders, workers, and buyers) are accessible in advance, and they can change over time, which is referred to as \\emph{Known Heterogeneous Distributions} (KHD).   ","In this paper, we initiate variance analysis for online matching algorithms under KHD.","Unlike the popular competitive-ratio (CR) metric, the variance of online algorithms' performance is rarely studied due to inherent technical challenges, though it is well linked to robustness.","We focus on two natural parameterized sampling policies, denoted by $\\mathsf{ATT}(\\gamma)$ and $\\mathsf{SAMP}(\\gamma)$, which appear as foundational bedrock in online algorithm design.","We offer rigorous competitive ratio (CR) and variance analyses for both policies.","Specifically, we show that $\\mathsf{ATT}(\\gamma)$ with $\\gamma \\in [0,1/2]$ achieves a CR of $\\gamma$ and a variance of $\\gamma","\\cdot (1-\\gamma) \\cdot B$ on the total number of matches with $B$ being the total matching capacity.","In contrast, $\\mathsf{SAMP}(\\gamma)$ with $\\gamma \\in","[0,1]$ accomplishes a CR of $\\gamma (1-\\gamma)$ and a variance of $\\bar{\\gamma} (1-\\bar{\\gamma})\\cdot B$ with $\\bar{\\gamma}=\\min(\\gamma,1/2)$. All CR and variance analyses are tight and unconditional of any benchmark.","As a byproduct, we prove that $\\mathsf{ATT}(\\gamma=1/2)$ achieves an optimal CR of $1/2$."],"url":"http://arxiv.org/abs/2401.13842v1"}
{"created":"2024-01-24 22:31:15","title":"Edge-coloring sparse graphs with $\u0394$ colors in quasilinear time","abstract":"In this paper we show that every graph $G$ of bounded maximum average degree ${\\rm mad}(G)$ and with maximum degree $\\Delta$ can be edge-colored using the optimal number of $\\Delta$ colors in quasilinear expected time, whenever $\\Delta\\ge 2{\\rm mad}(G)$. The maximum average degree is within a multiplicative constant of other popular graph sparsity parameters like arboricity, degeneracy or maximum density. Our algorithm extends previous results of Chrobak and Nishizeki [J. Algorithms, 1990] and Bhattacharya, Costa, Panski and Solomon [arXiv, 2023].","sentences":["In this paper we show that every graph $G$ of bounded maximum average degree ${\\rm mad}(G)$ and with maximum degree $\\Delta$ can be edge-colored using the optimal number of $\\Delta$ colors in quasilinear expected time, whenever $\\Delta\\ge 2{\\rm","mad}(G)$.","The maximum average degree is within a multiplicative constant of other popular graph sparsity parameters like arboricity, degeneracy or maximum density.","Our algorithm extends previous results of Chrobak and Nishizeki","[J. Algorithms, 1990] and Bhattacharya, Costa, Panski and Solomon [arXiv, 2023]."],"url":"http://arxiv.org/abs/2401.13839v1"}
{"created":"2024-01-24 21:57:55","title":"Traffic Learning and Proactive UAV Trajectory Planning for Data Uplink in Markovian IoT Models","abstract":"The age of information (AoI) is used to measure the freshness of the data. In IoT networks, the traditional resource management schemes rely on a message exchange between the devices and the base station (BS) before communication which causes high AoI, high energy consumption, and low reliability. Unmanned aerial vehicles (UAVs) as flying BSs have many advantages in minimizing the AoI, energy-saving, and throughput improvement. In this paper, we present a novel learning-based framework that estimates the traffic arrival of IoT devices based on Markovian events. The learning proceeds to optimize the trajectory of multiple UAVs and their scheduling policy. First, the BS predicts the future traffic of the devices. We compare two traffic predictors: the forward algorithm (FA) and the long short-term memory (LSTM). Afterward, we propose a deep reinforcement learning (DRL) approach to optimize the optimal policy of each UAV. Finally, we manipulate the optimum reward function for the proposed DRL approach. Simulation results show that the proposed algorithm outperforms the random-walk (RW) baseline model regarding the AoI, scheduling accuracy, and transmission power.","sentences":["The age of information (AoI) is used to measure the freshness of the data.","In IoT networks, the traditional resource management schemes rely on a message exchange between the devices and the base station (BS) before communication which causes high AoI, high energy consumption, and low reliability.","Unmanned aerial vehicles (UAVs) as flying BSs have many advantages in minimizing the AoI, energy-saving, and throughput improvement.","In this paper, we present a novel learning-based framework that estimates the traffic arrival of IoT devices based on Markovian events.","The learning proceeds to optimize the trajectory of multiple UAVs and their scheduling policy.","First, the BS predicts the future traffic of the devices.","We compare two traffic predictors: the forward algorithm (FA) and the long short-term memory (LSTM).","Afterward, we propose a deep reinforcement learning (DRL) approach to optimize the optimal policy of each UAV.","Finally, we manipulate the optimum reward function for the proposed DRL approach.","Simulation results show that the proposed algorithm outperforms the random-walk (RW) baseline model regarding the AoI, scheduling accuracy, and transmission power."],"url":"http://arxiv.org/abs/2401.13827v1"}
{"created":"2024-01-24 21:47:13","title":"Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on Hugging Face","abstract":"Advances in machine learning are closely tied to the creation of datasets. While data documentation is widely recognized as essential to the reliability, reproducibility, and transparency of ML, we lack a systematic empirical understanding of current dataset documentation practices. To shed light on this question, here we take Hugging Face -- one of the largest platforms for sharing and collaborating on ML models and datasets -- as a prominent case study. By analyzing all 7,433 dataset documentation on Hugging Face, our investigation provides an overview of the Hugging Face dataset ecosystem and insights into dataset documentation practices, yielding 5 main findings: (1) The dataset card completion rate shows marked heterogeneity correlated with dataset popularity. (2) A granular examination of each section within the dataset card reveals that the practitioners seem to prioritize Dataset Description and Dataset Structure sections, while the Considerations for Using the Data section receives the lowest proportion of content. (3) By analyzing the subsections within each section and utilizing topic modeling to identify key topics, we uncover what is discussed in each section, and underscore significant themes encompassing both technical and social impacts, as well as limitations within the Considerations for Using the Data section. (4) Our findings also highlight the need for improved accessibility and reproducibility of datasets in the Usage sections. (5) In addition, our human annotation evaluation emphasizes the pivotal role of comprehensive dataset content in shaping individuals' perceptions of a dataset card's overall quality. Overall, our study offers a unique perspective on analyzing dataset documentation through large-scale data science analysis and underlines the need for more thorough dataset documentation in machine learning research.","sentences":["Advances in machine learning are closely tied to the creation of datasets.","While data documentation is widely recognized as essential to the reliability, reproducibility, and transparency of ML, we lack a systematic empirical understanding of current dataset documentation practices.","To shed light on this question, here we take Hugging Face -- one of the largest platforms for sharing and collaborating on ML models and datasets -- as a prominent case study.","By analyzing all 7,433 dataset documentation on Hugging Face, our investigation provides an overview of the Hugging Face dataset ecosystem and insights into dataset documentation practices, yielding 5 main findings: (1) The dataset card completion rate shows marked heterogeneity correlated with dataset popularity.","(2) A granular examination of each section within the dataset card reveals that the practitioners seem to prioritize Dataset Description and Dataset Structure sections, while the Considerations for Using the Data section receives the lowest proportion of content.","(3) By analyzing the subsections within each section and utilizing topic modeling to identify key topics, we uncover what is discussed in each section, and underscore significant themes encompassing both technical and social impacts, as well as limitations within the Considerations for Using the Data section.","(4) Our findings also highlight the need for improved accessibility and reproducibility of datasets in the Usage sections.","(5) In addition, our human annotation evaluation emphasizes the pivotal role of comprehensive dataset content in shaping individuals' perceptions of a dataset card's overall quality.","Overall, our study offers a unique perspective on analyzing dataset documentation through large-scale data science analysis and underlines the need for more thorough dataset documentation in machine learning research."],"url":"http://arxiv.org/abs/2401.13822v1"}
{"created":"2024-01-24 21:35:17","title":"Separating $k$-Median from the Supplier Version","abstract":"Given a metric space $(V, d)$ along with an integer $k$, the $k$-Median problem asks to open $k$ centers $C \\subseteq V$ to minimize $\\sum_{v \\in V} d(v, C)$, where $d(v, C) := \\min_{c \\in C} d(v, c)$. While the best-known approximation ratio of $2.613$ holds for the more general supplier version where an additional set $F \\subseteq V$ is given with the restriction $C \\subseteq F$, the best known hardness for these two versions are $1+1/e \\approx 1.36$ and $1+2/e \\approx 1.73$ respectively, using the same reduction from Max $k$-Coverage. We prove the following two results separating them.   First, we show a $1.546$-parameterized approximation algorithm that runs in time $f(k) n^{O(1)}$. Since $1+2/e$ is proved to be the optimal approximation ratio for the supplier version in the parameterized setting, this result separates the original $k$-Median from the supplier version.   Next, we prove a $1.416$-hardness for polynomial-time algorithms assuming the Unique Games Conjecture. This is achieved via a new fine-grained hardness of Max-$k$-Coverage for small set sizes.   Our upper bound and lower bound are derived from almost the same expression, with the only difference coming from the well-known separation between the powers of LP and SDP on (hypergraph) vertex cover.","sentences":["Given a metric space $(V, d)$ along with an integer $k$, the $k$-Median problem asks to open $k$ centers $C","\\subseteq V$ to minimize $\\sum_{v \\in V} d(v, C)$, where $d(v, C) :","= \\min_{c \\in C} d(v, c)$.","While the best-known approximation ratio of $2.613$ holds for the more general supplier version where an additional set $F \\subseteq V$ is given with the restriction $C","\\subseteq F$, the best known hardness for these two versions are $1+1/e \\approx 1.36$ and $1+2/e \\approx 1.73$ respectively, using the same reduction from Max $k$-Coverage.","We prove the following two results separating them.   ","First, we show a $1.546$-parameterized approximation algorithm that runs in time $f(k) n^{O(1)}$.","Since $1+2/e$ is proved to be the optimal approximation ratio for the supplier version in the parameterized setting, this result separates the original $k$-Median from the supplier version.   ","Next, we prove a $1.416$-hardness for polynomial-time algorithms assuming the Unique Games Conjecture.","This is achieved via a new fine-grained hardness of Max-$k$-Coverage for small set sizes.   ","Our upper bound and lower bound are derived from almost the same expression, with the only difference coming from the well-known separation between the powers of LP and SDP on (hypergraph) vertex cover."],"url":"http://arxiv.org/abs/2401.13819v1"}
{"created":"2024-01-24 21:02:07","title":"Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4","abstract":"Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model's immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000 production incidents, comparing several large language models using multiple metrics. The results reveal that our in-context learning approach outperforms the previous fine-tuned large language models such as GPT-3 by an average of 24.8\\% across all metrics, with an impressive 49.7\\% improvement over the zero-shot model. Moreover, human evaluation involving actual incident owners demonstrates its superiority over the fine-tuned model, achieving a 43.5\\% improvement in correctness and an 8.7\\% enhancement in readability. The impressive results demonstrate the viability of utilizing a vanilla GPT model for the RCA task, thereby avoiding the high computational and maintenance costs associated with a fine-tuned model.","sentences":["Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences.","Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil.","Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management.","Nonetheless, the GPT-4 model's immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data.","To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning.","We conduct extensive study over 100,000 production incidents, comparing several large language models using multiple metrics.","The results reveal that our in-context learning approach outperforms the previous fine-tuned large language models such as GPT-3 by an average of 24.8\\% across all metrics, with an impressive 49.7\\% improvement over the zero-shot model.","Moreover, human evaluation involving actual incident owners demonstrates its superiority over the fine-tuned model, achieving a 43.5\\% improvement in correctness and an 8.7\\% enhancement in readability.","The impressive results demonstrate the viability of utilizing a vanilla GPT model for the RCA task, thereby avoiding the high computational and maintenance costs associated with a fine-tuned model."],"url":"http://arxiv.org/abs/2401.13810v1"}
{"created":"2024-01-24 20:56:23","title":"Longitudinal Sentiment Topic Modelling of Reddit Posts","abstract":"In this study, we analyze texts of Reddit posts written by students of four major Canadian universities. We gauge the emotional tone and uncover prevailing themes and discussions through longitudinal topic modeling of posts textual data. Our study focuses on four years, 2020-2023, covering COVID-19 pandemic and after pandemic years. Our results highlight a gradual uptick in discussions related to mental health.","sentences":["In this study, we analyze texts of Reddit posts written by students of four major Canadian universities.","We gauge the emotional tone and uncover prevailing themes and discussions through longitudinal topic modeling of posts textual data.","Our study focuses on four years, 2020-2023, covering COVID-19 pandemic and after pandemic years.","Our results highlight a gradual uptick in discussions related to mental health."],"url":"http://arxiv.org/abs/2401.13805v1"}
{"created":"2024-01-24 20:45:42","title":"Synergizing Human Expertise and AI Efficiency with Language Model for Microscopy Operation and Automated Experiment Design","abstract":"With the advent of large language models (LLMs), in both the open source and proprietary domains, attention is turning to how to exploit such artificial intelligence (AI) systems in assisting complex scientific tasks, such as material synthesis, characterization, analysis and discovery. Here, we explore the utility of LLM, particularly ChatGPT4, in combination with application program interfaces (APIs) in tasks of experimental design, programming workflows, and data analysis in scanning probe microscopy, using both in-house developed API and API given by a commercial vendor for instrument control. We find that the LLM can be especially useful in converting ideations of experimental workflows to executable code on microscope APIs. Beyond code generation, we find that the GPT4 is capable of analyzing microscopy images in a generic sense. At the same time, we find that GPT4 suffers from inability to extend beyond basic analyses or more in-depth technical experimental design. We argue that a LLM specifically fine-tuned for individual scientific domains can potentially be a better language interface for converting scientific ideations from human experts to executable workflows, such a synergy between human expertise and LLM efficiency in experimentation can open new door for accelerating scientific research, enabling effective experimental protocols archive and sharing in scientific community.","sentences":["With the advent of large language models (LLMs), in both the open source and proprietary domains, attention is turning to how to exploit such artificial intelligence (AI) systems in assisting complex scientific tasks, such as material synthesis, characterization, analysis and discovery.","Here, we explore the utility of LLM, particularly ChatGPT4, in combination with application program interfaces (APIs) in tasks of experimental design, programming workflows, and data analysis in scanning probe microscopy, using both in-house developed API and API given by a commercial vendor for instrument control.","We find that the LLM can be especially useful in converting ideations of experimental workflows to executable code on microscope APIs.","Beyond code generation, we find that the GPT4 is capable of analyzing microscopy images in a generic sense.","At the same time, we find that GPT4 suffers from inability to extend beyond basic analyses or more in-depth technical experimental design.","We argue that a LLM specifically fine-tuned for individual scientific domains can potentially be a better language interface for converting scientific ideations from human experts to executable workflows, such a synergy between human expertise and LLM efficiency in experimentation can open new door for accelerating scientific research, enabling effective experimental protocols archive and sharing in scientific community."],"url":"http://arxiv.org/abs/2401.13803v1"}
{"created":"2024-01-24 20:30:52","title":"Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning","abstract":"Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas. However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a \"push the button\" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms. While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation. This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation. Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios. The discrepancy between evaluated and actual performance on new data is a significant concern. In particular, this paper categorizes data leakage in ML, discussing how certain conditions can propagate through the ML workflow. Furthermore, it explores the connection between data leakage and the specific task being addressed, investigates its occurrence in Transfer Learning, and compares standard inductive ML with transductive ML frameworks. The conclusion summarizes key findings, emphasizing the importance of addressing data leakage for robust and reliable ML applications.","sentences":["Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas.","However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a \"push the button\" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms.","While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation.","This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation.","Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios.","The discrepancy between evaluated and actual performance on new data is a significant concern.","In particular, this paper categorizes data leakage in ML, discussing how certain conditions can propagate through the ML workflow.","Furthermore, it explores the connection between data leakage and the specific task being addressed, investigates its occurrence in Transfer Learning, and compares standard inductive ML with transductive ML frameworks.","The conclusion summarizes key findings, emphasizing the importance of addressing data leakage for robust and reliable ML applications."],"url":"http://arxiv.org/abs/2401.13796v1"}
{"created":"2024-01-24 20:24:32","title":"Traffic Pattern Classification in Smart Cities Using Deep Recurrent Neural Network","abstract":"This paper examines the use of deep recurrent neural networks to classify traffic patterns in smart cities. We propose a novel approach to traffic pattern classification based on deep recurrent neural networks, which can effectively capture traffic patterns' dynamic and sequential features. The proposed model combines convolutional and recurrent layers to extract features from traffic pattern data and a SoftMax layer to classify traffic patterns. Experimental results show that the proposed model outperforms existing methods regarding accuracy, precision, recall, and F1 score. Furthermore, we provide an in depth analysis of the results and discuss the implications of the proposed model for smart cities. The results show that the proposed model can accurately classify traffic patterns in smart cities with a precision of as high as 95%. The proposed model is evaluated on a real world traffic pattern dataset and compared with existing classification methods.","sentences":["This paper examines the use of deep recurrent neural networks to classify traffic patterns in smart cities.","We propose a novel approach to traffic pattern classification based on deep recurrent neural networks, which can effectively capture traffic patterns' dynamic and sequential features.","The proposed model combines convolutional and recurrent layers to extract features from traffic pattern data and a SoftMax layer to classify traffic patterns.","Experimental results show that the proposed model outperforms existing methods regarding accuracy, precision, recall, and F1 score.","Furthermore, we provide an in depth analysis of the results and discuss the implications of the proposed model for smart cities.","The results show that the proposed model can accurately classify traffic patterns in smart cities with a precision of as high as 95%.","The proposed model is evaluated on a real world traffic pattern dataset and compared with existing classification methods."],"url":"http://arxiv.org/abs/2401.13794v1"}
{"created":"2024-01-24 20:21:56","title":"Probabilistic Mobility Load Balancing for Multi-band 5G and Beyond Networks","abstract":"The ever-increasing demand for data services and the proliferation of user equipment (UE) have resulted in a significant rise in the volume of mobile traffic. Moreover, in multi-band networks, non-uniform traffic distribution among different operational bands can lead to congestion, which can adversely impact the user's quality of experience. Load balancing is a critical aspect of network optimization, where it ensures that the traffic is evenly distributed among different bands, avoiding congestion and ensuring better user experience. Traditional load balancing approaches rely only on the band channel quality as a load indicator and to move UEs between bands, which disregards the UE's demands and the band resource, and hence, leading to a suboptimal balancing and utilization of resources. To address this challenge, we propose an event-based algorithm, in which we model the load balancing problem as a multi-objective stochastic optimization, and assign UEs to bands in a probabilistic manner. The goal is to evenly distribute traffic across available bands according to their resources, while maintaining minimal number of inter-frequency handovers to avoid the signaling overhead and the interruption time. Simulation results show that the proposed algorithm enhances the network's performance and outperforms traditional load balancing approaches in terms of throughput and interruption time.","sentences":["The ever-increasing demand for data services and the proliferation of user equipment (UE) have resulted in a significant rise in the volume of mobile traffic.","Moreover, in multi-band networks, non-uniform traffic distribution among different operational bands can lead to congestion, which can adversely impact the user's quality of experience.","Load balancing is a critical aspect of network optimization, where it ensures that the traffic is evenly distributed among different bands, avoiding congestion and ensuring better user experience.","Traditional load balancing approaches rely only on the band channel quality as a load indicator and to move UEs between bands, which disregards the UE's demands and the band resource, and hence, leading to a suboptimal balancing and utilization of resources.","To address this challenge, we propose an event-based algorithm, in which we model the load balancing problem as a multi-objective stochastic optimization, and assign UEs to bands in a probabilistic manner.","The goal is to evenly distribute traffic across available bands according to their resources, while maintaining minimal number of inter-frequency handovers to avoid the signaling overhead and the interruption time.","Simulation results show that the proposed algorithm enhances the network's performance and outperforms traditional load balancing approaches in terms of throughput and interruption time."],"url":"http://arxiv.org/abs/2401.13792v1"}
{"created":"2024-01-24 20:07:59","title":"FoVA-Depth: Field-of-View Agnostic Depth Estimation for Cross-Dataset Generalization","abstract":"Wide field-of-view (FoV) cameras efficiently capture large portions of the scene, which makes them attractive in multiple domains, such as automotive and robotics. For such applications, estimating depth from multiple images is a critical task, and therefore, a large amount of ground truth (GT) data is available. Unfortunately, most of the GT data is for pinhole cameras, making it impossible to properly train depth estimation models for large-FoV cameras. We propose the first method to train a stereo depth estimation model on the widely available pinhole data, and to generalize it to data captured with larger FoVs. Our intuition is simple: We warp the training data to a canonical, large-FoV representation and augment it to allow a single network to reason about diverse types of distortions that otherwise would prevent generalization. We show strong generalization ability of our approach on both indoor and outdoor datasets, which was not possible with previous methods.","sentences":["Wide field-of-view (FoV) cameras efficiently capture large portions of the scene, which makes them attractive in multiple domains, such as automotive and robotics.","For such applications, estimating depth from multiple images is a critical task, and therefore, a large amount of ground truth (GT) data is available.","Unfortunately, most of the GT data is for pinhole cameras, making it impossible to properly train depth estimation models for large-FoV cameras.","We propose the first method to train a stereo depth estimation model on the widely available pinhole data, and to generalize it to data captured with larger FoVs.","Our intuition is simple: We warp the training data to a canonical, large-FoV representation and augment it to allow a single network to reason about diverse types of distortions that otherwise would prevent generalization.","We show strong generalization ability of our approach on both indoor and outdoor datasets, which was not possible with previous methods."],"url":"http://arxiv.org/abs/2401.13786v1"}
{"created":"2024-01-24 19:17:45","title":"NLICE: Synthetic Medical Record Generation for Effective Primary Healthcare Differential Diagnosis","abstract":"This paper offers a systematic method for creating medical knowledge-grounded patient records for use in activities involving differential diagnosis. Additionally, an assessment of machine learning models that can differentiate between various conditions based on given symptoms is also provided. We use a public disease-symptom data source called SymCat in combination with Synthea to construct the patients records. In order to increase the expressive nature of the synthetic data, we use a medically-standardized symptom modeling method called NLICE to augment the synthetic data with additional contextual information for each condition. In addition, Naive Bayes and Random Forest models are evaluated and compared on the synthetic data. The paper shows how to successfully construct SymCat-based and NLICE-based datasets. We also show results for the effectiveness of using the datasets to train predictive disease models. The SymCat-based dataset is able to train a Naive Bayes and Random Forest model yielding a 58.8% and 57.1% Top-1 accuracy score, respectively. In contrast, the NLICE-based dataset improves the results, with a Top-1 accuracy of 82.0% and Top-5 accuracy values of more than 90% for both models. Our proposed data generation approach solves a major barrier to the application of artificial intelligence methods in the healthcare domain. Our novel NLICE symptom modeling approach addresses the incomplete and insufficient information problem in the current binary symptom representation approach. The NLICE code is open sourced at https://github.com/guozhuoran918/NLICE.","sentences":["This paper offers a systematic method for creating medical knowledge-grounded patient records for use in activities involving differential diagnosis.","Additionally, an assessment of machine learning models that can differentiate between various conditions based on given symptoms is also provided.","We use a public disease-symptom data source called SymCat in combination with Synthea to construct the patients records.","In order to increase the expressive nature of the synthetic data, we use a medically-standardized symptom modeling method called NLICE to augment the synthetic data with additional contextual information for each condition.","In addition, Naive Bayes and Random Forest models are evaluated and compared on the synthetic data.","The paper shows how to successfully construct SymCat-based and NLICE-based datasets.","We also show results for the effectiveness of using the datasets to train predictive disease models.","The SymCat-based dataset is able to train a Naive Bayes and Random Forest model yielding a 58.8% and 57.1% Top-1 accuracy score, respectively.","In contrast, the NLICE-based dataset improves the results, with a Top-1 accuracy of 82.0% and Top-5 accuracy values of more than 90% for both models.","Our proposed data generation approach solves a major barrier to the application of artificial intelligence methods in the healthcare domain.","Our novel NLICE symptom modeling approach addresses the incomplete and insufficient information problem in the current binary symptom representation approach.","The NLICE code is open sourced at https://github.com/guozhuoran918/NLICE."],"url":"http://arxiv.org/abs/2401.13756v1"}
{"created":"2024-01-24 19:12:37","title":"A Systematic Approach to Robustness Modelling for Deep Convolutional Neural Networks","abstract":"Convolutional neural networks have shown to be widely applicable to a large number of fields when large amounts of labelled data are available. The recent trend has been to use models with increasingly larger sets of tunable parameters to increase model accuracy, reduce model loss, or create more adversarially robust models -- goals that are often at odds with one another. In particular, recent theoretical work raises questions about the ability for even larger models to generalize to data outside of the controlled train and test sets. As such, we examine the role of the number of hidden layers in the ResNet model, demonstrated on the MNIST, CIFAR10, CIFAR100 datasets. We test a variety of parameters including the size of the model, the floating point precision, and the noise level of both the training data and the model output. To encapsulate the model's predictive power and computational cost, we provide a method that uses induced failures to model the probability of failure as a function of time and relate that to a novel metric that allows us to quickly determine whether or not the cost of training a model outweighs the cost of attacking it. Using this approach, we are able to approximate the expected failure rate using a small number of specially crafted samples rather than increasingly larger benchmark datasets. We demonstrate the efficacy of this technique on both the MNIST and CIFAR10 datasets using 8-, 16-, 32-, and 64-bit floating-point numbers, various data pre-processing techniques, and several attacks on five configurations of the ResNet model. Then, using empirical measurements, we examine the various trade-offs between cost, robustness, latency, and reliability to find that larger models do not significantly aid in adversarial robustness despite costing significantly more to train.","sentences":["Convolutional neural networks have shown to be widely applicable to a large number of fields when large amounts of labelled data are available.","The recent trend has been to use models with increasingly larger sets of tunable parameters to increase model accuracy, reduce model loss, or create more adversarially robust models -- goals that are often at odds with one another.","In particular, recent theoretical work raises questions about the ability for even larger models to generalize to data outside of the controlled train and test sets.","As such, we examine the role of the number of hidden layers in the ResNet model, demonstrated on the MNIST, CIFAR10, CIFAR100 datasets.","We test a variety of parameters including the size of the model, the floating point precision, and the noise level of both the training data and the model output.","To encapsulate the model's predictive power and computational cost, we provide a method that uses induced failures to model the probability of failure as a function of time and relate that to a novel metric that allows us to quickly determine whether or not the cost of training a model outweighs the cost of attacking it.","Using this approach, we are able to approximate the expected failure rate using a small number of specially crafted samples rather than increasingly larger benchmark datasets.","We demonstrate the efficacy of this technique on both the MNIST and CIFAR10 datasets using 8-, 16-, 32-, and 64-bit floating-point numbers, various data pre-processing techniques, and several attacks on five configurations of the ResNet model.","Then, using empirical measurements, we examine the various trade-offs between cost, robustness, latency, and reliability to find that larger models do not significantly aid in adversarial robustness despite costing significantly more to train."],"url":"http://arxiv.org/abs/2401.13751v1"}
{"created":"2024-01-24 19:05:21","title":"Searching in trees with monotonic query times","abstract":"We consider the following generalization of binary search in sorted arrays to tree domains. In each step of the search, an algorithm is querying a vertex $q$, and as a reply, it receives an answer, which either states that $q$ is the desired target, or it gives the neighbor of $q$ that is closer to the target than $q$. A further generalization assumes that a vertex-weight function $\\omega$ gives the query costs, i.e., the cost of querying $q$ is $\\omega(q)$. The goal is to find an adaptive search strategy requiring the minimum cost in the worst case. This problem is NP-complete for general weight functions and one of the challenging open questions is whether there exists a polynomial-time constant factor approximation algorithm for an arbitrary tree? In this work, we prove that there exist a constant-factor approximation algorithm for trees with a monotonic cost function, i.e., when the tree has a vertex $v$ such that the weights of the subsequent vertices on the path from $v$ to any leaf give a monotonic (non-increasing or non-decreasing) sequence $S$. This gives a constant factor approximation algorithm for trees with cost functions such that each such sequence $S$ has a fixed number of monotonic segments. Finally, we combine several earlier results to show that the problem is NP-complete when the number of monotonic segments in $S$ is at least $4$.","sentences":["We consider the following generalization of binary search in sorted arrays to tree domains.","In each step of the search, an algorithm is querying a vertex $q$, and as a reply, it receives an answer, which either states that $q$ is the desired target, or it gives the neighbor of $q$ that is closer to the target than $q$. A further generalization assumes that a vertex-weight function $\\omega$ gives the query costs, i.e., the cost of querying $q$ is $\\omega(q)$. The goal is to find an adaptive search strategy requiring the minimum cost in the worst case.","This problem is NP-complete for general weight functions and one of the challenging open questions is whether there exists a polynomial-time constant factor approximation algorithm for an arbitrary tree?","In this work, we prove that there exist a constant-factor approximation algorithm for trees with a monotonic cost function, i.e., when the tree has a vertex $v$ such that the weights of the subsequent vertices on the path from $v$ to any leaf give a monotonic (non-increasing or non-decreasing) sequence $S$. This gives a constant factor approximation algorithm for trees with cost functions such that each such sequence $S$ has a fixed number of monotonic segments.","Finally, we combine several earlier results to show that the problem is NP-complete when the number of monotonic segments in $S$ is at least $4$."],"url":"http://arxiv.org/abs/2401.13747v1"}
{"created":"2024-01-24 19:01:07","title":"Intermittency versus Path Loss in RIS-aided THz Communication: A Data Significance Approach","abstract":"The transition to Terahertz (THz) frequencies, providing an ultra-wide bandwidth, is a key driver for future wireless communication networks. However, the specific properties of the THz channel, such as severe path loss and vulnerability to blockage, pose a significant challenge in balancing data rate and reliability. This work considers reconfigurable intelligent surface (RIS)-aided THz communication, where the effective exploitation of a strong, but intermittent line-of-sight (LOS) path versus a reliable, yet weaker RIS-path is studied. We introduce a mixed-criticality superposition coding scheme that addresses this tradeoff from a data significance perspective. The results show that the proposed scheme enables reliable transmission for a portion of high-criticality data without significantly impacting the overall achievable sum rate and queuing delay. Additionally, we gain insights into how the LOS blockage probability and the channel gain of the RIS-link influence the rate performance of our scheme.","sentences":["The transition to Terahertz (THz) frequencies, providing an ultra-wide bandwidth, is a key driver for future wireless communication networks.","However, the specific properties of the THz channel, such as severe path loss and vulnerability to blockage, pose a significant challenge in balancing data rate and reliability.","This work considers reconfigurable intelligent surface (RIS)-aided THz communication, where the effective exploitation of a strong, but intermittent line-of-sight (LOS) path versus a reliable, yet weaker RIS-path is studied.","We introduce a mixed-criticality superposition coding scheme that addresses this tradeoff from a data significance perspective.","The results show that the proposed scheme enables reliable transmission for a portion of high-criticality data without significantly impacting the overall achievable sum rate and queuing delay.","Additionally, we gain insights into how the LOS blockage probability and the channel gain of the RIS-link influence the rate performance of our scheme."],"url":"http://arxiv.org/abs/2401.13743v1"}
