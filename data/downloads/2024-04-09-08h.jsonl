{"created":"2024-04-08 17:58:22","title":"Predicting Overtakes in Trucks Using CAN Data","abstract":"Safe overtakes in trucks are crucial to prevent accidents, reduce congestion, and ensure efficient traffic flow, making early prediction essential for timely and informed driving decisions. Accordingly, we investigate the detection of truck overtakes from CAN data. Three classifiers, Artificial Neural Networks (ANN), Random Forest, and Support Vector Machines (SVM), are employed for the task. Our analysis covers up to 10 seconds before the overtaking event, using an overlapping sliding window of 1 second to extract CAN features. We observe that the prediction scores of the overtake class tend to increase as we approach the overtake trigger, while the no-overtake class remain stable or oscillates depending on the classifier. Thus, the best accuracy is achieved when approaching the trigger, making early overtaking prediction challenging. The classifiers show good accuracy in classifying overtakes (Recall/TPR > 93%), but accuracy is suboptimal in classifying no-overtakes (TNR typically 80-90% and below 60% for one SVM variant). We further combine two classifiers (Random Forest and linear SVM) by averaging their output scores. The fusion is observed to improve no-overtake classification (TNR > 92%) at the expense of reducing overtake accuracy (TPR). However, the latter is kept above 91% near the overtake trigger. Therefore, the fusion balances TPR and TNR, providing more consistent performance than individual classifiers.","sentences":["Safe overtakes in trucks are crucial to prevent accidents, reduce congestion, and ensure efficient traffic flow, making early prediction essential for timely and informed driving decisions.","Accordingly, we investigate the detection of truck overtakes from CAN data.","Three classifiers, Artificial Neural Networks (ANN), Random Forest, and Support Vector Machines (SVM), are employed for the task.","Our analysis covers up to 10 seconds before the overtaking event, using an overlapping sliding window of 1 second to extract CAN features.","We observe that the prediction scores of the overtake class tend to increase as we approach the overtake trigger, while the no-overtake class remain stable or oscillates depending on the classifier.","Thus, the best accuracy is achieved when approaching the trigger, making early overtaking prediction challenging.","The classifiers show good accuracy in classifying overtakes (Recall/TPR > 93%), but accuracy is suboptimal in classifying no-overtakes (TNR typically 80-90% and below 60% for one SVM variant).","We further combine two classifiers (Random Forest and linear SVM) by averaging their output scores.","The fusion is observed to improve no-overtake classification (TNR > 92%) at the expense of reducing overtake accuracy (TPR).","However, the latter is kept above 91% near the overtake trigger.","Therefore, the fusion balances TPR and TNR, providing more consistent performance than individual classifiers."],"url":"http://arxiv.org/abs/2404.05723v1"}
{"created":"2024-04-08 17:42:08","title":"Learning 3D-Aware GANs from Unposed Images with Template Feature Field","abstract":"Collecting accurate camera poses of training images has been shown to well serve the learning of 3D-aware generative adversarial networks (GANs) yet can be quite expensive in practice. This work targets learning 3D-aware GANs from unposed images, for which we propose to perform on-the-fly pose estimation of training images with a learned template feature field (TeFF). Concretely, in addition to a generative radiance field as in previous approaches, we ask the generator to also learn a field from 2D semantic features while sharing the density from the radiance field. Such a framework allows us to acquire a canonical 3D feature template leveraging the dataset mean discovered by the generative model, and further efficiently estimate the pose parameters on real data. Experimental results on various challenging datasets demonstrate the superiority of our approach over state-of-the-art alternatives from both the qualitative and the quantitative perspectives.","sentences":["Collecting accurate camera poses of training images has been shown to well serve the learning of 3D-aware generative adversarial networks (GANs) yet can be quite expensive in practice.","This work targets learning 3D-aware GANs from unposed images, for which we propose to perform on-the-fly pose estimation of training images with a learned template feature field (TeFF).","Concretely, in addition to a generative radiance field as in previous approaches, we ask the generator to also learn a field from 2D semantic features while sharing the density from the radiance field.","Such a framework allows us to acquire a canonical 3D feature template leveraging the dataset mean discovered by the generative model, and further efficiently estimate the pose parameters on real data.","Experimental results on various challenging datasets demonstrate the superiority of our approach over state-of-the-art alternatives from both the qualitative and the quantitative perspectives."],"url":"http://arxiv.org/abs/2404.05705v1"}
{"created":"2024-04-08 17:37:22","title":"Case Study: Neural Network Malware Detection Verification for Feature and Image Datasets","abstract":"Malware, or software designed with harmful intent, is an ever-evolving threat that can have drastic effects on both individuals and institutions. Neural network malware classification systems are key tools for combating these threats but are vulnerable to adversarial machine learning attacks. These attacks perturb input data to cause misclassification, bypassing protective systems. Existing defenses often rely on enhancing the training process, thereby increasing the model's robustness to these perturbations, which is quantified using verification. While training improvements are necessary, we propose focusing on the verification process used to evaluate improvements to training. As such, we present a case study that evaluates a novel verification domain that will help to ensure tangible safeguards against adversaries and provide a more reliable means of evaluating the robustness and effectiveness of anti-malware systems. To do so, we describe malware classification and two types of common malware datasets (feature and image datasets), demonstrate the certified robustness accuracy of malware classifiers using the Neural Network Verification (NNV) and Neural Network Enumeration (nnenum) tools, and outline the challenges and future considerations necessary for the improvement and refinement of the verification of malware classification. By evaluating this novel domain as a case study, we hope to increase its visibility, encourage further research and scrutiny, and ultimately enhance the resilience of digital systems against malicious attacks.","sentences":["Malware, or software designed with harmful intent, is an ever-evolving threat that can have drastic effects on both individuals and institutions.","Neural network malware classification systems are key tools for combating these threats but are vulnerable to adversarial machine learning attacks.","These attacks perturb input data to cause misclassification, bypassing protective systems.","Existing defenses often rely on enhancing the training process, thereby increasing the model's robustness to these perturbations, which is quantified using verification.","While training improvements are necessary, we propose focusing on the verification process used to evaluate improvements to training.","As such, we present a case study that evaluates a novel verification domain that will help to ensure tangible safeguards against adversaries and provide a more reliable means of evaluating the robustness and effectiveness of anti-malware systems.","To do so, we describe malware classification and two types of common malware datasets (feature and image datasets), demonstrate the certified robustness accuracy of malware classifiers using the Neural Network Verification (NNV) and Neural Network Enumeration (nnenum) tools, and outline the challenges and future considerations necessary for the improvement and refinement of the verification of malware classification.","By evaluating this novel domain as a case study, we hope to increase its visibility, encourage further research and scrutiny, and ultimately enhance the resilience of digital systems against malicious attacks."],"url":"http://arxiv.org/abs/2404.05703v1"}
{"created":"2024-04-08 17:29:07","title":"BOLD v4: A Centralized Bioinformatics Platform for DNA-based Biodiversity Data","abstract":"BOLD, the Barcode of Life Data System, supports the acquisition, storage, validation, analysis, and publication of DNA barcodes, activities requiring the integration of molecular, morphological, and distributional data. Its pivotal role in curating the reference library of DNA barcodes, coupled with its data management and analysis capabilities, make it a central resource for biodiversity science. It enables rapid, accurate identification of specimens and also reveals patterns of genetic diversity and evolutionary relationships among taxa. Launched in 2005, BOLD has become an increasingly powerful tool for advancing understanding of planetary biodiversity. It currently hosts 17 million specimen records and 14 million barcodes that provide coverage for more than a million species from every continent and ocean. The platform has the long-term goal of providing a consistent, accurate system for identifying all species of eukaryotes. BOLD's integrated analytical tools, full data lifecycle support, and secure collaboration framework distinguish it from other biodiversity platforms. BOLD v4 brought enhanced data management and analysis capabilities as well as novel functionality for data dissemination and publication. Its next version will include features to strengthen its utility to the research community, governments, industry, and society-at-large.","sentences":["BOLD, the Barcode of Life Data System, supports the acquisition, storage, validation, analysis, and publication of DNA barcodes, activities requiring the integration of molecular, morphological, and distributional data.","Its pivotal role in curating the reference library of DNA barcodes, coupled with its data management and analysis capabilities, make it a central resource for biodiversity science.","It enables rapid, accurate identification of specimens and also reveals patterns of genetic diversity and evolutionary relationships among taxa.","Launched in 2005, BOLD has become an increasingly powerful tool for advancing understanding of planetary biodiversity.","It currently hosts 17 million specimen records and 14 million barcodes that provide coverage for more than a million species from every continent and ocean.","The platform has the long-term goal of providing a consistent, accurate system for identifying all species of eukaryotes.","BOLD's integrated analytical tools, full data lifecycle support, and secure collaboration framework distinguish it from other biodiversity platforms.","BOLD v4 brought enhanced data management and analysis capabilities as well as novel functionality for data dissemination and publication.","Its next version will include features to strengthen its utility to the research community, governments, industry, and society-at-large."],"url":"http://arxiv.org/abs/2404.05696v1"}
{"created":"2024-04-08 17:24:04","title":"Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding","abstract":"Recent advances in natural language processing (NLP) can be largely attributed to the advent of pre-trained language models such as BERT and RoBERTa. While these models demonstrate remarkable performance on general datasets, they can struggle in specialized domains such as medicine, where unique domain-specific terminologies, domain-specific abbreviations, and varying document structures are common. This paper explores strategies for adapting these models to domain-specific requirements, primarily through continuous pre-training on domain-specific data. We pre-trained several German medical language models on 2.4B tokens derived from translated public English medical data and 3B tokens of German clinical data. The resulting models were evaluated on various German downstream tasks, including named entity recognition (NER), multi-label classification, and extractive question answering. Our results suggest that models augmented by clinical and translation-based pre-training typically outperform general domain models in medical contexts. We conclude that continuous pre-training has demonstrated the ability to match or even exceed the performance of clinical models trained from scratch. Furthermore, pre-training on clinical data or leveraging translated texts have proven to be reliable methods for domain adaptation in medical NLP tasks.","sentences":["Recent advances in natural language processing (NLP) can be largely attributed to the advent of pre-trained language models such as BERT and RoBERTa.","While these models demonstrate remarkable performance on general datasets, they can struggle in specialized domains such as medicine, where unique domain-specific terminologies, domain-specific abbreviations, and varying document structures are common.","This paper explores strategies for adapting these models to domain-specific requirements, primarily through continuous pre-training on domain-specific data.","We pre-trained several German medical language models on 2.4B tokens derived from translated public English medical data and 3B tokens of German clinical data.","The resulting models were evaluated on various German downstream tasks, including named entity recognition (NER), multi-label classification, and extractive question answering.","Our results suggest that models augmented by clinical and translation-based pre-training typically outperform general domain models in medical contexts.","We conclude that continuous pre-training has demonstrated the ability to match or even exceed the performance of clinical models trained from scratch.","Furthermore, pre-training on clinical data or leveraging translated texts have proven to be reliable methods for domain adaptation in medical NLP tasks."],"url":"http://arxiv.org/abs/2404.05694v1"}
{"created":"2024-04-08 17:18:30","title":"Evaluating the Efficacy of Cut-and-Paste Data Augmentation in Semantic Segmentation for Satellite Imagery","abstract":"Satellite imagery is crucial for tasks like environmental monitoring and urban planning. Typically, it relies on semantic segmentation or Land Use Land Cover (LULC) classification to categorize each pixel. Despite the advancements brought about by Deep Neural Networks (DNNs), their performance in segmentation tasks is hindered by challenges such as limited availability of labeled data, class imbalance and the inherent variability and complexity of satellite images. In order to mitigate those issues, our study explores the effectiveness of a Cut-and-Paste augmentation technique for semantic segmentation in satellite images. We adapt this augmentation, which usually requires labeled instances, to the case of semantic segmentation. By leveraging the connected components in the semantic segmentation labels, we extract instances that are then randomly pasted during training. Using the DynamicEarthNet dataset and a U-Net model for evaluation, we found that this augmentation significantly enhances the mIoU score on the test set from 37.9 to 44.1. This finding highlights the potential of the Cut-and-Paste augmentation to improve the generalization capabilities of semantic segmentation models in satellite imagery.","sentences":["Satellite imagery is crucial for tasks like environmental monitoring and urban planning.","Typically, it relies on semantic segmentation or Land Use Land Cover (LULC) classification to categorize each pixel.","Despite the advancements brought about by Deep Neural Networks (DNNs), their performance in segmentation tasks is hindered by challenges such as limited availability of labeled data, class imbalance and the inherent variability and complexity of satellite images.","In order to mitigate those issues, our study explores the effectiveness of a Cut-and-Paste augmentation technique for semantic segmentation in satellite images.","We adapt this augmentation, which usually requires labeled instances, to the case of semantic segmentation.","By leveraging the connected components in the semantic segmentation labels, we extract instances that are then randomly pasted during training.","Using the DynamicEarthNet dataset and a U-Net model for evaluation, we found that this augmentation significantly enhances the mIoU score on the test set from 37.9 to 44.1.","This finding highlights the potential of the Cut-and-Paste augmentation to improve the generalization capabilities of semantic segmentation models in satellite imagery."],"url":"http://arxiv.org/abs/2404.05693v1"}
{"created":"2024-04-08 17:18:04","title":"Evaluating Mathematical Reasoning Beyond Accuracy","abstract":"The leaderboard of Large Language Models (LLMs) in mathematical tasks has been continuously updated. However, the majority of evaluations focus solely on the final results, neglecting the quality of the intermediate steps. This oversight can mask underlying problems, such as logical errors or unnecessary steps in the reasoning process. To measure reasoning beyond final-answer accuracy, we introduce ReasonEval, a new methodology for evaluating the quality of reasoning steps. ReasonEval employs $\\textit{validity}$ and $\\textit{redundancy}$ to characterize the reasoning quality, as well as accompanying LLMs to assess them automatically. Instantiated by base models that possess strong mathematical knowledge and trained with high-quality labeled data, ReasonEval achieves state-of-the-art performance on human-labeled datasets and can accurately detect different types of errors generated by perturbation. When applied to evaluate LLMs specialized in math, we find that an increase in final-answer accuracy does not necessarily guarantee an improvement in the overall quality of the reasoning steps for challenging mathematical problems. Additionally, we observe that ReasonEval can play a significant role in data selection. We release the best-performing model, meta-evaluation script, and all evaluation results at https://github.com/GAIR-NLP/ReasonEval.","sentences":["The leaderboard of Large Language Models (LLMs) in mathematical tasks has been continuously updated.","However, the majority of evaluations focus solely on the final results, neglecting the quality of the intermediate steps.","This oversight can mask underlying problems, such as logical errors or unnecessary steps in the reasoning process.","To measure reasoning beyond final-answer accuracy, we introduce ReasonEval, a new methodology for evaluating the quality of reasoning steps.","ReasonEval employs $\\textit{validity}$ and $\\textit{redundancy}$ to characterize the reasoning quality, as well as accompanying LLMs to assess them automatically.","Instantiated by base models that possess strong mathematical knowledge and trained with high-quality labeled data, ReasonEval achieves state-of-the-art performance on human-labeled datasets and can accurately detect different types of errors generated by perturbation.","When applied to evaluate LLMs specialized in math, we find that an increase in final-answer accuracy does not necessarily guarantee an improvement in the overall quality of the reasoning steps for challenging mathematical problems.","Additionally, we observe that ReasonEval can play a significant role in data selection.","We release the best-performing model, meta-evaluation script, and all evaluation results at https://github.com/GAIR-NLP/ReasonEval."],"url":"http://arxiv.org/abs/2404.05692v1"}
{"created":"2024-04-08 17:15:37","title":"Automated discovery of symbolic laws governing skill acquisition from naturally occurring data","abstract":"Skill acquisition is a key area of research in cognitive psychology as it encompasses multiple psychological processes. The laws discovered under experimental paradigms are controversial and lack generalizability. This paper aims to unearth the laws of skill learning from large-scale training log data. A two-stage algorithm was developed to tackle the issues of unobservable cognitive states and algorithmic explosion in searching. Initially a deep learning model is employed to determine the learner's cognitive state and assess the feature importance. Subsequently, symbolic regression algorithms are utilized to parse the neural network model into algebraic equations. The experimental results of simulated data demonstrate that the proposed algorithm can accurately restore various preset laws within a certain range of noise, in continues feedback setting. Application of proposed method to Lumosity training data demonstrates superior performance compared to traditional and latest models in terms of fitness. The results indicate the discovery of two new forms of skill acquisition laws, while some previous findings have been reaffirmed.","sentences":["Skill acquisition is a key area of research in cognitive psychology as it encompasses multiple psychological processes.","The laws discovered under experimental paradigms are controversial and lack generalizability.","This paper aims to unearth the laws of skill learning from large-scale training log data.","A two-stage algorithm was developed to tackle the issues of unobservable cognitive states and algorithmic explosion in searching.","Initially a deep learning model is employed to determine the learner's cognitive state and assess the feature importance.","Subsequently, symbolic regression algorithms are utilized to parse the neural network model into algebraic equations.","The experimental results of simulated data demonstrate that the proposed algorithm can accurately restore various preset laws within a certain range of noise, in continues feedback setting.","Application of proposed method to Lumosity training data demonstrates superior performance compared to traditional and latest models in terms of fitness.","The results indicate the discovery of two new forms of skill acquisition laws, while some previous findings have been reaffirmed."],"url":"http://arxiv.org/abs/2404.05689v1"}
{"created":"2024-04-08 17:14:32","title":"David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge","abstract":"ML is shifting from the cloud to the edge. Edge computing reduces the surface exposing private data and enables reliable throughput guarantees in real-time applications. Of the panoply of devices deployed at the edge, resource-constrained MCUs, e.g., Arm Cortex-M, are more prevalent, orders of magnitude cheaper, and less power-hungry than application processors or GPUs. Thus, enabling intelligence at the deep edge is the zeitgeist, with researchers focusing on unveiling novel approaches to deploy ANNs on these constrained devices. Quantization is a well-established technique that has proved effective in enabling the deployment of neural networks on MCUs; however, it is still an open question to understand the robustness of QNNs in the face of adversarial examples.   To fill this gap, we empirically evaluate the effectiveness of attacks and defenses from (full-precision) ANNs on (constrained) QNNs. Our evaluation includes three QNNs targeting TinyML applications, ten attacks, and six defenses. With this study, we draw a set of interesting findings. First, quantization increases the point distance to the decision boundary and leads the gradient estimated by some attacks to explode or vanish. Second, quantization can act as a noise attenuator or amplifier, depending on the noise magnitude, and causes gradient misalignment. Regarding adversarial defenses, we conclude that input pre-processing defenses show impressive results on small perturbations; however, they fall short as the perturbation increases. At the same time, train-based defenses increase the average point distance to the decision boundary, which holds after quantization. However, we argue that train-based defenses still need to smooth the quantization-shift and gradient misalignment phenomenons to counteract adversarial example transferability to QNNs. All artifacts are open-sourced to enable independent validation of results.","sentences":["ML is shifting from the cloud to the edge.","Edge computing reduces the surface exposing private data and enables reliable throughput guarantees in real-time applications.","Of the panoply of devices deployed at the edge, resource-constrained MCUs, e.g., Arm Cortex-M, are more prevalent, orders of magnitude cheaper, and less power-hungry than application processors or GPUs.","Thus, enabling intelligence at the deep edge is the zeitgeist, with researchers focusing on unveiling novel approaches to deploy ANNs on these constrained devices.","Quantization is a well-established technique that has proved effective in enabling the deployment of neural networks on MCUs; however, it is still an open question to understand the robustness of QNNs in the face of adversarial examples.   ","To fill this gap, we empirically evaluate the effectiveness of attacks and defenses from (full-precision) ANNs on (constrained) QNNs.","Our evaluation includes three QNNs targeting TinyML applications, ten attacks, and six defenses.","With this study, we draw a set of interesting findings.","First, quantization increases the point distance to the decision boundary and leads the gradient estimated by some attacks to explode or vanish.","Second, quantization can act as a noise attenuator or amplifier, depending on the noise magnitude, and causes gradient misalignment.","Regarding adversarial defenses, we conclude that input pre-processing defenses show impressive results on small perturbations; however, they fall short as the perturbation increases.","At the same time, train-based defenses increase the average point distance to the decision boundary, which holds after quantization.","However, we argue that train-based defenses still need to smooth the quantization-shift and gradient misalignment phenomenons to counteract adversarial example transferability to QNNs.","All artifacts are open-sourced to enable independent validation of results."],"url":"http://arxiv.org/abs/2404.05688v1"}
{"created":"2024-04-08 16:59:39","title":"Even Faster Knapsack via Rectangular Monotone Min-Plus Convolution and Balancing","abstract":"We present a pseudopolynomial-time algorithm for the Knapsack problem that has running time $\\widetilde{O}(n + t\\sqrt{p_{\\max}})$, where $n$ is the number of items, $t$ is the knapsack capacity, and $p_{\\max}$ is the maximum item profit. This improves over the $\\widetilde{O}(n + t \\, p_{\\max})$-time algorithm based on the convolution and prediction technique by Bateni et al.~(STOC 2018). Moreover, we give some evidence, based on a strengthening of the Min-Plus Convolution Hypothesis, that our running time might be optimal.   Our algorithm uses two new technical tools, which might be of independent interest. First, we generalize the $\\widetilde{O}(n^{1.5})$-time algorithm for bounded monotone min-plus convolution by Chi et al.~(STOC 2022) to the \\emph{rectangular} case where the range of entries can be different from the sequence length. Second, we give a reduction from general knapsack instances to \\emph{balanced} instances, where all items have nearly the same profit-to-weight ratio, up to a constant factor.   Using these techniques, we can also obtain algorithms that run in time $\\widetilde{O}(n + OPT\\sqrt{w_{\\max}})$, $\\widetilde{O}(n + (nw_{\\max}p_{\\max})^{1/3}t^{2/3})$, and $\\widetilde{O}(n + (nw_{\\max}p_{\\max})^{1/3} OPT^{2/3})$, where $OPT$ is the optimal total profit and $w_{\\max}$ is the maximum item weight.","sentences":["We present a pseudopolynomial-time algorithm for the Knapsack problem that has running time $\\widetilde{O}(n + t\\sqrt{p_{\\max}})$, where $n$ is the number of items, $t$ is the knapsack capacity, and $p_{\\max}$ is the maximum item profit.","This improves over the $\\widetilde{O}(n + t \\, p_{\\max})$-time algorithm based on the convolution and prediction technique by Bateni et al.~(STOC 2018).","Moreover, we give some evidence, based on a strengthening of the Min-Plus Convolution Hypothesis, that our running time might be optimal.   ","Our algorithm uses two new technical tools, which might be of independent interest.","First, we generalize the $\\widetilde{O}(n^{1.5})$-time algorithm for bounded monotone min-plus convolution by Chi et al.~(STOC 2022) to the \\emph{rectangular} case where the range of entries can be different from the sequence length.","Second, we give a reduction from general knapsack instances to \\emph{balanced} instances, where all items have nearly the same profit-to-weight ratio, up to a constant factor.   ","Using these techniques, we can also obtain algorithms that run in time $\\widetilde{O}(n + OPT\\sqrt{w_{\\max}})$, $\\widetilde{O}(n + (nw_{\\max}p_{\\max})^{1/3}t^{2/3})$, and $\\widetilde{O}(n + (nw_{\\max}p_{\\max})^{1/3} OPT^{2/3})$, where $OPT$ is the optimal total profit and $w_{\\max}$ is the maximum item weight."],"url":"http://arxiv.org/abs/2404.05681v1"}
{"created":"2024-04-08 16:58:31","title":"SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation","abstract":"While recent advances in 3D-aware Generative Adversarial Networks (GANs) have aided the development of near-frontal view human face synthesis, the challenge of comprehensively synthesizing a full 3D head viewable from all angles still persists. Although PanoHead proves the possibilities of using a large-scale dataset with images of both frontal and back views for full-head synthesis, it often causes artifacts for back views. Based on our in-depth analysis, we found the reasons are mainly twofold. First, from network architecture perspective, we found each plane in the utilized tri-plane/tri-grid representation space tends to confuse the features from both sides, causing \"mirroring\" artifacts (e.g., the glasses appear in the back). Second, from data supervision aspect, we found that existing discriminator training in 3D GANs mainly focuses on the quality of the rendered image itself, and does not care much about its plausibility with the perspective from which it was rendered. This makes it possible to generate \"face\" in non-frontal views, due to its easiness to fool the discriminator. In response, we propose SphereHead, a novel tri-plane representation in the spherical coordinate system that fits the human head's geometric characteristics and efficiently mitigates many of the generated artifacts. We further introduce a view-image consistency loss for the discriminator to emphasize the correspondence of the camera parameters and the images. The combination of these efforts results in visually superior outcomes with significantly fewer artifacts. Our code and dataset are publicly available at https://lhyfst.github.io/spherehead.","sentences":["While recent advances in 3D-aware Generative Adversarial Networks (GANs) have aided the development of near-frontal view human face synthesis, the challenge of comprehensively synthesizing a full 3D head viewable from all angles still persists.","Although PanoHead proves the possibilities of using a large-scale dataset with images of both frontal and back views for full-head synthesis, it often causes artifacts for back views.","Based on our in-depth analysis, we found the reasons are mainly twofold.","First, from network architecture perspective, we found each plane in the utilized tri-plane/tri-grid representation space tends to confuse the features from both sides, causing \"mirroring\" artifacts (e.g., the glasses appear in the back).","Second, from data supervision aspect, we found that existing discriminator training in 3D GANs mainly focuses on the quality of the rendered image itself, and does not care much about its plausibility with the perspective from which it was rendered.","This makes it possible to generate \"face\" in non-frontal views, due to its easiness to fool the discriminator.","In response, we propose SphereHead, a novel tri-plane representation in the spherical coordinate system that fits the human head's geometric characteristics and efficiently mitigates many of the generated artifacts.","We further introduce a view-image consistency loss for the discriminator to emphasize the correspondence of the camera parameters and the images.","The combination of these efforts results in visually superior outcomes with significantly fewer artifacts.","Our code and dataset are publicly available at https://lhyfst.github.io/spherehead."],"url":"http://arxiv.org/abs/2404.05680v1"}
{"created":"2024-04-08 16:51:33","title":"AlignZeg: Mitigating Objective Misalignment for Zero-shot Semantic Segmentation","abstract":"A serious issue that harms the performance of zero-shot visual recognition is named objective misalignment, i.e., the learning objective prioritizes improving the recognition accuracy of seen classes rather than unseen classes, while the latter is the true target to pursue. This issue becomes more significant in zero-shot image segmentation because the stronger (i.e., pixel-level) supervision brings a larger gap between seen and unseen classes. To mitigate it, we propose a novel architecture named AlignZeg, which embodies a comprehensive improvement of the segmentation pipeline, including proposal extraction, classification, and correction, to better fit the goal of zero-shot segmentation. (1) Mutually-Refined Proposal Extraction. AlignZeg harnesses a mutual interaction between mask queries and visual features, facilitating detailed class-agnostic mask proposal extraction. (2) Generalization-Enhanced Proposal Classification. AlignZeg introduces synthetic data and incorporates multiple background prototypes to allocate a more generalizable feature space. (3) Predictive Bias Correction. During the inference stage, AlignZeg uses a class indicator to find potential unseen class proposals followed by a prediction postprocess to correct the prediction bias. Experiments demonstrate that AlignZeg markedly enhances zero-shot semantic segmentation, as shown by an average 3.8% increase in hIoU, primarily attributed to a 7.1% improvement in identifying unseen classes, and we further validate that the improvement comes from alleviating the objective misalignment issue.","sentences":["A serious issue that harms the performance of zero-shot visual recognition is named objective misalignment, i.e., the learning objective prioritizes improving the recognition accuracy of seen classes rather than unseen classes, while the latter is the true target to pursue.","This issue becomes more significant in zero-shot image segmentation because the stronger (i.e., pixel-level) supervision brings a larger gap between seen and unseen classes.","To mitigate it, we propose a novel architecture named AlignZeg, which embodies a comprehensive improvement of the segmentation pipeline, including proposal extraction, classification, and correction, to better fit the goal of zero-shot segmentation.","(1) Mutually-Refined Proposal Extraction.","AlignZeg harnesses a mutual interaction between mask queries and visual features, facilitating detailed class-agnostic mask proposal extraction.","(2) Generalization-Enhanced Proposal Classification.","AlignZeg introduces synthetic data and incorporates multiple background prototypes to allocate a more generalizable feature space.","(3) Predictive Bias Correction.","During the inference stage, AlignZeg uses a class indicator to find potential unseen class proposals followed by a prediction postprocess to correct the prediction bias.","Experiments demonstrate that AlignZeg markedly enhances zero-shot semantic segmentation, as shown by an average 3.8% increase in hIoU, primarily attributed to a 7.1% improvement in identifying unseen classes, and we further validate that the improvement comes from alleviating the objective misalignment issue."],"url":"http://arxiv.org/abs/2404.05667v1"}
{"created":"2024-04-08 16:48:20","title":"BFS versus DFS for random targets in ordered trees","abstract":"Consider a search from the root of an ordered tree with $n$ edges to some target node at a fixed distance $\\ell$ from that root. We compare the average time complexity of the breadth-first search (BFS) and depth-first search (DFS) algorithms, when the target node is selected uniformly at random among all nodes at level $\\ell$ in the ordered trees with $n$ edges. Intuition suggests that BFS should have better average performance when $\\ell$ is small, while DFS must have an advantage when $\\ell$ is large. But where exactly is the threshold, as a function of $n$, and is it unique? We obtain explicit formulas for the expected number of steps of both BFS and DFS, by using results on the occupation measure of Brownian excursions, as well as a combinatorial proof of an identity related to lattice paths. This allows us to show that there exists a unique constant $\\lambda\\approx 0.789004$, such that in expectation BFS is asymptotically faster than DFS if and only if $\\ell\\leq \\lambda\\sqrt{n}$. Furthermore, we find the asymptotic average time complexity of BFS in the given setting for any class of Galton$\\unicode{x2013}$Watson trees, including binary trees and ordered trees. Finally, we introduce the truncated DFS algorithm, which performs better than both BFS and DFS when $\\ell$ is known in advance, and we find a formula evaluating the average time complexity of this algorithm.","sentences":["Consider a search from the root of an ordered tree with $n$ edges to some target node at a fixed distance $\\ell$ from that root.","We compare the average time complexity of the breadth-first search (BFS) and depth-first search (DFS) algorithms, when the target node is selected uniformly at random among all nodes at level $\\ell$ in the ordered trees with $n$ edges.","Intuition suggests that BFS should have better average performance when $\\ell$ is small, while DFS must have an advantage when $\\ell$ is large.","But where exactly is the threshold, as a function of $n$, and is it unique?","We obtain explicit formulas for the expected number of steps of both BFS and DFS, by using results on the occupation measure of Brownian excursions, as well as a combinatorial proof of an identity related to lattice paths.","This allows us to show that there exists a unique constant $\\lambda\\approx 0.789004$, such that in expectation BFS is asymptotically faster than DFS","if and only if $\\ell\\leq \\lambda\\sqrt{n}$.","Furthermore, we find the asymptotic average time complexity of BFS in the given setting for any class of Galton$\\unicode{x2013}$Watson trees, including binary trees and ordered trees.","Finally, we introduce the truncated DFS algorithm, which performs better than both BFS and DFS when $\\ell$ is known in advance, and we find a formula evaluating the average time complexity of this algorithm."],"url":"http://arxiv.org/abs/2404.05664v1"}
{"created":"2024-04-08 16:43:52","title":"VietMed: A Dataset and Benchmark for Automatic Speech Recognition of Vietnamese in the Medical Domain","abstract":"Due to privacy restrictions, there's a shortage of publicly available speech recognition datasets in the medical domain. In this work, we present VietMed - a Vietnamese speech recognition dataset in the medical domain comprising 16h of labeled medical speech, 1000h of unlabeled medical speech and 1200h of unlabeled general-domain speech. To our best knowledge, VietMed is by far the world's largest public medical speech recognition dataset in 7 aspects: total duration, number of speakers, diseases, recording conditions, speaker roles, unique medical terms and accents. VietMed is also by far the largest public Vietnamese speech dataset in terms of total duration. Additionally, we are the first to present a medical ASR dataset covering all ICD-10 disease groups and all accents within a country. Moreover, we release the first public large-scale pre-trained models for Vietnamese ASR, w2v2-Viet and XLSR-53-Viet, along with the first public large-scale fine-tuned models for medical ASR. Even without any medical data in unsupervised pre-training, our best pre-trained model XLSR-53-Viet generalizes very well to the medical domain by outperforming state-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative reduction of more than 40%). All code, data and models are made publicly available here: https://github.com/leduckhai/MultiMed.","sentences":["Due to privacy restrictions, there's a shortage of publicly available speech recognition datasets in the medical domain.","In this work, we present VietMed - a Vietnamese speech recognition dataset in the medical domain comprising 16h of labeled medical speech, 1000h of unlabeled medical speech and 1200h of unlabeled general-domain speech.","To our best knowledge, VietMed is by far the world's largest public medical speech recognition dataset in 7 aspects: total duration, number of speakers, diseases, recording conditions, speaker roles, unique medical terms and accents.","VietMed is also by far the largest public Vietnamese speech dataset in terms of total duration.","Additionally, we are the first to present a medical ASR dataset covering all ICD-10 disease groups and all accents within a country.","Moreover, we release the first public large-scale pre-trained models for Vietnamese ASR, w2v2-Viet and XLSR-53-Viet, along with the first public large-scale fine-tuned models for medical ASR.","Even without any medical data in unsupervised pre-training, our best pre-trained model XLSR-53-Viet generalizes very well to the medical domain by outperforming state-of-the-art XLSR-53, from 51.8% to 29.6% WER on test set (a relative reduction of more than 40%).","All code, data and models are made publicly available here: https://github.com/leduckhai/MultiMed."],"url":"http://arxiv.org/abs/2404.05659v1"}
{"created":"2024-04-08 16:39:34","title":"Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid Framework","abstract":"Industry-wide nuclear power plant operating experience is a critical source of raw data for performing parameter estimations in reliability and risk models. Much operating experience information pertains to failure events and is stored as reports containing unstructured data, such as narratives. Event reports are essential for understanding how failures are initiated and propagated, including the numerous causal relations involved. Causal relation extraction using deep learning represents a significant frontier in the field of natural language processing (NLP), and is crucial since it enables the interpretation of intricate narratives and connections contained within vast amounts of written information. This paper proposed a hybrid framework for causality detection and extraction from nuclear licensee event reports. The main contributions include: (1) we compiled an LER corpus with 20,129 text samples for causality analysis, (2) developed an interactive tool for labeling cause effect pairs, (3) built a deep-learning-based approach for causal relation detection, and (4) developed a knowledge based cause-effect extraction approach.","sentences":["Industry-wide nuclear power plant operating experience is a critical source of raw data for performing parameter estimations in reliability and risk models.","Much operating experience information pertains to failure events and is stored as reports containing unstructured data, such as narratives.","Event reports are essential for understanding how failures are initiated and propagated, including the numerous causal relations involved.","Causal relation extraction using deep learning represents a significant frontier in the field of natural language processing (NLP), and is crucial since it enables the interpretation of intricate narratives and connections contained within vast amounts of written information.","This paper proposed a hybrid framework for causality detection and extraction from nuclear licensee event reports.","The main contributions include: (1) we compiled an LER corpus with 20,129 text samples for causality analysis, (2) developed an interactive tool for labeling cause effect pairs, (3) built a deep-learning-based approach for causal relation detection, and (4) developed a knowledge based cause-effect extraction approach."],"url":"http://arxiv.org/abs/2404.05656v1"}
{"created":"2024-04-08 16:34:35","title":"Resistive Memory-based Neural Differential Equation Solver for Score-based Diffusion Model","abstract":"Human brains image complicated scenes when reading a novel. Replicating this imagination is one of the ultimate goals of AI-Generated Content (AIGC). However, current AIGC methods, such as score-based diffusion, are still deficient in terms of rapidity and efficiency. This deficiency is rooted in the difference between the brain and digital computers. Digital computers have physically separated storage and processing units, resulting in frequent data transfers during iterative calculations, incurring large time and energy overheads. This issue is further intensified by the conversion of inherently continuous and analog generation dynamics, which can be formulated by neural differential equations, into discrete and digital operations. Inspired by the brain, we propose a time-continuous and analog in-memory neural differential equation solver for score-based diffusion, employing emerging resistive memory. The integration of storage and computation within resistive memory synapses surmount the von Neumann bottleneck, benefiting the generative speed and energy efficiency. The closed-loop feedback integrator is time-continuous, analog, and compact, physically implementing an infinite-depth neural network. Moreover, the software-hardware co-design is intrinsically robust to analog noise. We experimentally validate our solution with 180 nm resistive memory in-memory computing macros. Demonstrating equivalent generative quality to the software baseline, our system achieved remarkable enhancements in generative speed for both unconditional and conditional generation tasks, by factors of 64.8 and 156.5, respectively. Moreover, it accomplished reductions in energy consumption by factors of 5.2 and 4.1. Our approach heralds a new horizon for hardware solutions in edge computing for generative AI applications.","sentences":["Human brains image complicated scenes when reading a novel.","Replicating this imagination is one of the ultimate goals of AI-Generated Content (AIGC).","However, current AIGC methods, such as score-based diffusion, are still deficient in terms of rapidity and efficiency.","This deficiency is rooted in the difference between the brain and digital computers.","Digital computers have physically separated storage and processing units, resulting in frequent data transfers during iterative calculations, incurring large time and energy overheads.","This issue is further intensified by the conversion of inherently continuous and analog generation dynamics, which can be formulated by neural differential equations, into discrete and digital operations.","Inspired by the brain, we propose a time-continuous and analog in-memory neural differential equation solver for score-based diffusion, employing emerging resistive memory.","The integration of storage and computation within resistive memory synapses surmount the von Neumann bottleneck, benefiting the generative speed and energy efficiency.","The closed-loop feedback integrator is time-continuous, analog, and compact, physically implementing an infinite-depth neural network.","Moreover, the software-hardware co-design is intrinsically robust to analog noise.","We experimentally validate our solution with 180 nm resistive memory in-memory computing macros.","Demonstrating equivalent generative quality to the software baseline, our system achieved remarkable enhancements in generative speed for both unconditional and conditional generation tasks, by factors of 64.8 and 156.5, respectively.","Moreover, it accomplished reductions in energy consumption by factors of 5.2 and 4.1.","Our approach heralds a new horizon for hardware solutions in edge computing for generative AI applications."],"url":"http://arxiv.org/abs/2404.05648v1"}
{"created":"2024-04-08 16:04:26","title":"Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data","abstract":"In the financial industry, identifying the location of parties involved in payments is a major challenge in the context of various regulatory requirements. For this purpose address parsing entails extracting fields such as street, postal code, or country from free text message attributes. While payment processing platforms are updating their standards with more structured formats such as SWIFT with ISO 20022, address parsing remains essential for a considerable volume of messages. With the emergence of Transformers and Generative Large Language Models (LLM), we explore the performance of state-of-the-art solutions given the constraint of processing a vast amount of daily data. This paper also aims to show the need for training robust models capable of dealing with real-world noisy transactional data. Our results suggest that a well fine-tuned Transformer model using early-stopping significantly outperforms other approaches. Nevertheless, generative LLMs demonstrate strong zero-shot performance and warrant further investigations.","sentences":["In the financial industry, identifying the location of parties involved in payments is a major challenge in the context of various regulatory requirements.","For this purpose address parsing entails extracting fields such as street, postal code, or country from free text message attributes.","While payment processing platforms are updating their standards with more structured formats such as SWIFT with ISO 20022, address parsing remains essential for a considerable volume of messages.","With the emergence of Transformers and Generative Large Language Models (LLM), we explore the performance of state-of-the-art solutions given the constraint of processing a vast amount of daily data.","This paper also aims to show the need for training robust models capable of dealing with real-world noisy transactional data.","Our results suggest that a well fine-tuned Transformer model using early-stopping significantly outperforms other approaches.","Nevertheless, generative LLMs demonstrate strong zero-shot performance and warrant further investigations."],"url":"http://arxiv.org/abs/2404.05632v1"}
{"created":"2024-04-08 15:53:46","title":"AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets","abstract":"Active learning for imbalanced classification tasks is challenging as the minority classes naturally occur rarely. Gathering a large pool of unlabelled data is thus essential to capture minority instances. Standard pool-based active learning is computationally expensive on large pools and often reaches low accuracy by overfitting the initial decision boundary, thus failing to explore the input space and find minority instances. To address these issues we propose AnchorAL. At each iteration, AnchorAL chooses class-specific instances from the labelled set, or anchors, and retrieves the most similar unlabelled instances from the pool. This resulting subpool is then used for active learning. Using a small, fixed-sized subpool AnchorAL allows scaling any active learning strategy to large pools. By dynamically selecting different anchors at each iteration it promotes class balance and prevents overfitting the initial decision boundary, thus promoting the discovery of new clusters of minority instances. Experiments across different classification tasks, active learning strategies, and model architectures AnchorAL is (i) faster, often reducing runtime from hours to minutes, (ii) trains more performant models, (iii) and returns more balanced datasets than competing methods.","sentences":["Active learning for imbalanced classification tasks is challenging as the minority classes naturally occur rarely.","Gathering a large pool of unlabelled data is thus essential to capture minority instances.","Standard pool-based active learning is computationally expensive on large pools and often reaches low accuracy by overfitting the initial decision boundary, thus failing to explore the input space and find minority instances.","To address these issues we propose AnchorAL.","At each iteration, AnchorAL chooses class-specific instances from the labelled set, or anchors, and retrieves the most similar unlabelled instances from the pool.","This resulting subpool is then used for active learning.","Using a small, fixed-sized subpool AnchorAL allows scaling any active learning strategy to large pools.","By dynamically selecting different anchors at each iteration it promotes class balance and prevents overfitting the initial decision boundary, thus promoting the discovery of new clusters of minority instances.","Experiments across different classification tasks, active learning strategies, and model architectures AnchorAL is (i) faster, often reducing runtime from hours to minutes, (ii) trains more performant models, (iii) and returns more balanced datasets than competing methods."],"url":"http://arxiv.org/abs/2404.05623v1"}
{"created":"2024-04-08 15:53:29","title":"How to Evaluate Entity Resolution Systems: An Entity-Centric Framework with Application to Inventor Name Disambiguation","abstract":"Entity resolution (record linkage, microclustering) systems are notoriously difficult to evaluate. Looking for a needle in a haystack, traditional evaluation methods use sophisticated, application-specific sampling schemes to find matching pairs of records among an immense number of non-matches. We propose an alternative that facilitates the creation of representative, reusable benchmark data sets without necessitating complex sampling schemes. These benchmark data sets can then be used for model training and a variety of evaluation tasks. Specifically, we propose an entity-centric data labeling methodology that integrates with a unified framework for monitoring summary statistics, estimating key performance metrics such as cluster and pairwise precision and recall, and analyzing root causes for errors. We validate the framework in an application to inventor name disambiguation and through simulation studies. Software: https://github.com/OlivierBinette/er-evaluation/","sentences":["Entity resolution (record linkage, microclustering) systems are notoriously difficult to evaluate.","Looking for a needle in a haystack, traditional evaluation methods use sophisticated, application-specific sampling schemes to find matching pairs of records among an immense number of non-matches.","We propose an alternative that facilitates the creation of representative, reusable benchmark data sets without necessitating complex sampling schemes.","These benchmark data sets can then be used for model training and a variety of evaluation tasks.","Specifically, we propose an entity-centric data labeling methodology that integrates with a unified framework for monitoring summary statistics, estimating key performance metrics such as cluster and pairwise precision and recall, and analyzing root causes for errors.","We validate the framework in an application to inventor name disambiguation and through simulation studies.","Software: https://github.com/OlivierBinette/er-evaluation/"],"url":"http://arxiv.org/abs/2404.05622v1"}
{"created":"2024-04-08 15:18:42","title":"Hook-in Privacy Techniques for gRPC-based Microservice Communication","abstract":"gRPC is at the heart of modern distributed system architectures. Based on HTTP/2 and Protocol Buffers, it provides highly performant, standardized, and polyglot communication across loosely coupled microservices and is increasingly preferred over REST- or GraphQL-based service APIs in practice. Despite its widespread adoption, gRPC lacks any advanced privacy techniques beyond transport encryption and basic token-based authentication. Such advanced techniques are, however, increasingly important for fulfilling regulatory requirements. For instance, anonymizing or otherwise minimizing (personal) data before responding to requests, or pre-processing data based on the purpose of the access may be crucial in certain usecases. In this paper, we therefore propose a novel approach for integrating such advanced privacy techniques into the gRPC framework in a practically viable way. Specifically, we present a general approach along with a working prototype that implements privacy techniques, such as data minimization and purpose limitation, in a configurable, extensible, and gRPC-native way utilizing a gRPC interceptor. We also showcase how to integrate this contribution into a realistic example of a food delivery use case. Alongside these implementations, a preliminary performance evaluation shows practical applicability with reasonable overheads. Altogether, we present a viable solution for integrating advanced privacy techniques into real-world gRPC-based microservice architectures, thereby facilitating regulatory compliance ``by design''.","sentences":["gRPC is at the heart of modern distributed system architectures.","Based on HTTP/2 and Protocol Buffers, it provides highly performant, standardized, and polyglot communication across loosely coupled microservices and is increasingly preferred over REST- or GraphQL-based service APIs in practice.","Despite its widespread adoption, gRPC lacks any advanced privacy techniques beyond transport encryption and basic token-based authentication.","Such advanced techniques are, however, increasingly important for fulfilling regulatory requirements.","For instance, anonymizing or otherwise minimizing (personal) data before responding to requests, or pre-processing data based on the purpose of the access may be crucial in certain usecases.","In this paper, we therefore propose a novel approach for integrating such advanced privacy techniques into the gRPC framework in a practically viable way.","Specifically, we present a general approach along with a working prototype that implements privacy techniques, such as data minimization and purpose limitation, in a configurable, extensible, and gRPC-native way utilizing a gRPC interceptor.","We also showcase how to integrate this contribution into a realistic example of a food delivery use case.","Alongside these implementations, a preliminary performance evaluation shows practical applicability with reasonable overheads.","Altogether, we present a viable solution for integrating advanced privacy techniques into real-world gRPC-based microservice architectures, thereby facilitating regulatory compliance ``by design''."],"url":"http://arxiv.org/abs/2404.05598v1"}
{"created":"2024-04-08 14:55:35","title":"Robust Data Pruning: Uncovering and Overcoming Implicit Bias","abstract":"In the era of exceptionally data-hungry models, careful selection of the training data is essential to mitigate the extensive costs of deep learning. Data pruning offers a solution by removing redundant or uninformative samples from the dataset, which yields faster convergence and improved neural scaling laws. However, little is known about its impact on classification bias of the trained models. We conduct the first systematic study of this effect and reveal that existing data pruning algorithms can produce highly biased classifiers. At the same time, we argue that random data pruning with appropriate class ratios has potential to improve the worst-class performance. We propose a \"fairness-aware\" approach to pruning and empirically demonstrate its performance on standard computer vision benchmarks. In sharp contrast to existing algorithms, our proposed method continues improving robustness at a tolerable drop of average performance as we prune more from the datasets. We present theoretical analysis of the classification risk in a mixture of Gaussians to further motivate our algorithm and support our findings.","sentences":["In the era of exceptionally data-hungry models, careful selection of the training data is essential to mitigate the extensive costs of deep learning.","Data pruning offers a solution by removing redundant or uninformative samples from the dataset, which yields faster convergence and improved neural scaling laws.","However, little is known about its impact on classification bias of the trained models.","We conduct the first systematic study of this effect and reveal that existing data pruning algorithms can produce highly biased classifiers.","At the same time, we argue that random data pruning with appropriate class ratios has potential to improve the worst-class performance.","We propose a \"fairness-aware\" approach to pruning and empirically demonstrate its performance on standard computer vision benchmarks.","In sharp contrast to existing algorithms, our proposed method continues improving robustness at a tolerable drop of average performance as we prune more from the datasets.","We present theoretical analysis of the classification risk in a mixture of Gaussians to further motivate our algorithm and support our findings."],"url":"http://arxiv.org/abs/2404.05579v1"}
{"created":"2024-04-08 14:54:54","title":"Social-MAE: Social Masked Autoencoder for Multi-person Motion Representation Learning","abstract":"For a complete comprehension of multi-person scenes, it is essential to go beyond basic tasks like detection and tracking. Higher-level tasks, such as understanding the interactions and social activities among individuals, are also crucial. Progress towards models that can fully understand scenes involving multiple people is hindered by a lack of sufficient annotated data for such high-level tasks. To address this challenge, we introduce Social-MAE, a simple yet effective transformer-based masked autoencoder framework for multi-person human motion data. The framework uses masked modeling to pre-train the encoder to reconstruct masked human joint trajectories, enabling it to learn generalizable and data efficient representations of motion in human crowded scenes. Social-MAE comprises a transformer as the MAE encoder and a lighter-weight transformer as the MAE decoder which operates on multi-person joints' trajectory in the frequency domain. After the reconstruction task, the MAE decoder is replaced with a task-specific decoder and the model is fine-tuned end-to-end for a variety of high-level social tasks. Our proposed model combined with our pre-training approach achieves the state-of-the-art results on various high-level social tasks, including multi-person pose forecasting, social grouping, and social action understanding. These improvements are demonstrated across four popular multi-person datasets encompassing both human 2D and 3D body pose.","sentences":["For a complete comprehension of multi-person scenes, it is essential to go beyond basic tasks like detection and tracking.","Higher-level tasks, such as understanding the interactions and social activities among individuals, are also crucial.","Progress towards models that can fully understand scenes involving multiple people is hindered by a lack of sufficient annotated data for such high-level tasks.","To address this challenge, we introduce Social-MAE, a simple yet effective transformer-based masked autoencoder framework for multi-person human motion data.","The framework uses masked modeling to pre-train the encoder to reconstruct masked human joint trajectories, enabling it to learn generalizable and data efficient representations of motion in human crowded scenes.","Social-MAE comprises a transformer as the MAE encoder and a lighter-weight transformer as the MAE decoder which operates on multi-person joints' trajectory in the frequency domain.","After the reconstruction task, the MAE decoder is replaced with a task-specific decoder and the model is fine-tuned end-to-end for a variety of high-level social tasks.","Our proposed model combined with our pre-training approach achieves the state-of-the-art results on various high-level social tasks, including multi-person pose forecasting, social grouping, and social action understanding.","These improvements are demonstrated across four popular multi-person datasets encompassing both human 2D and 3D body pose."],"url":"http://arxiv.org/abs/2404.05578v1"}
{"created":"2024-04-08 14:49:26","title":"Eye Tracking on Text Reading with Visual Enhancements","abstract":"The interplay between text and visualization is gaining importance for media where traditional text is enriched by visual elements to improve readability and emphasize facts. In two controlled eye-tracking experiments ($N=12$), we approach answers to the question: How do visualization techniques influence reading behavior? We compare plain text to that marked with highlights, icons, and word-sized data visualizations. We assess quantitative metrics~(eye movement, completion time, error rate) and subjective feedback~(personal preference and ratings). The results indicate that visualization techniques, especially in the first experiment, show promising trends for improved reading behavior. The results also show the need for further research to make reading more effective and inform suggestions for future studies.","sentences":["The interplay between text and visualization is gaining importance for media where traditional text is enriched by visual elements to improve readability and emphasize facts.","In two controlled eye-tracking experiments ($N=12$), we approach answers to the question: How do visualization techniques influence reading behavior?","We compare plain text to that marked with highlights, icons, and word-sized data visualizations.","We assess quantitative metrics~(eye movement, completion time, error rate) and subjective feedback~(personal preference and ratings).","The results indicate that visualization techniques, especially in the first experiment, show promising trends for improved reading behavior.","The results also show the need for further research to make reading more effective and inform suggestions for future studies."],"url":"http://arxiv.org/abs/2404.05572v1"}
{"created":"2024-04-08 14:37:26","title":"Optimal Flow Admission Control in Edge Computing via Safe Reinforcement Learning","abstract":"With the uptake of intelligent data-driven applications, edge computing infrastructures necessitate a new generation of admission control algorithms to maximize system performance under limited and highly heterogeneous resources. In this paper, we study how to optimally select information flows which belong to different classes and dispatch them to multiple edge servers where deployed applications perform flow analytic tasks. The optimal policy is obtained via constrained Markov decision process (CMDP) theory accounting for the demand of each edge application for specific classes of flows, the constraints on computing capacity of edge servers and of the access network.   We develop DR-CPO, a specialized primal-dual Safe Reinforcement Learning (SRL) method which solves the resulting optimal admission control problem by reward decomposition. DR-CPO operates optimal decentralized control and mitigates effectively state-space explosion while preserving optimality. Compared to existing Deep Reinforcement Learning (DRL) solutions, extensive results show that DR-CPO achieves 15\\% higher reward on a wide variety of environments, while requiring on average only 50\\% of the amount of learning episodes to converge. Finally, we show how to match DR-CPO and load-balancing to dispatch optimally information streams to available edge servers and further improve system performance.","sentences":["With the uptake of intelligent data-driven applications, edge computing infrastructures necessitate a new generation of admission control algorithms to maximize system performance under limited and highly heterogeneous resources.","In this paper, we study how to optimally select information flows which belong to different classes and dispatch them to multiple edge servers where deployed applications perform flow analytic tasks.","The optimal policy is obtained via constrained Markov decision process (CMDP) theory accounting for the demand of each edge application for specific classes of flows, the constraints on computing capacity of edge servers and of the access network.   ","We develop DR-CPO, a specialized primal-dual Safe Reinforcement Learning (SRL) method which solves the resulting optimal admission control problem by reward decomposition.","DR-CPO operates optimal decentralized control and mitigates effectively state-space explosion while preserving optimality.","Compared to existing Deep Reinforcement Learning (DRL) solutions, extensive results show that DR-CPO achieves 15\\% higher reward on a wide variety of environments, while requiring on average only 50\\% of the amount of learning episodes to converge.","Finally, we show how to match DR-CPO and load-balancing to dispatch optimally information streams to available edge servers and further improve system performance."],"url":"http://arxiv.org/abs/2404.05564v1"}
{"created":"2024-04-08 14:36:45","title":"Predefined Software Environment Runtimes As A Measure For Reproducibility","abstract":"As part of Mathematical Research Data Initiative (MaRDI), we have developed a way to preserve a software package into an easy to deploy and use sandbox environment we call a \"runtime\", via a program we developed called MaPS : MaRDI Packaging System. The program relies on Linux user namespaces to isolate a library environment from the host system, making the sandboxed software reproducible on other systems, with minimal effort. Moreover an overlay filesystem makes local edits persistent. This project will aid reproducibility efforts of research papers: both mathematical and from other disciplines. As a proof of concept, we provide runtimes for the OSCAR Computer Algebra System, polymake software for research in polyhedral geometry, and VIBRANT Virus Identification By iteRative ANnoTation. The software is in a prerelease state: the interface for creating, deploying, and executing runtimes is final, and an interface for easily publishing runtimes is under active development. We thus propose publishing predefined, distributable software environment runtimes along with research papers in an effort to make research with software based results reproducible.","sentences":["As part of Mathematical Research Data Initiative (MaRDI), we have developed a way to preserve a software package into an easy to deploy and use sandbox environment we call a \"runtime\", via a program we developed called MaPS : MaRDI Packaging System.","The program relies on Linux user namespaces to isolate a library environment from the host system, making the sandboxed software reproducible on other systems, with minimal effort.","Moreover an overlay filesystem makes local edits persistent.","This project will aid reproducibility efforts of research papers: both mathematical and from other disciplines.","As a proof of concept, we provide runtimes for the OSCAR Computer Algebra System, polymake software for research in polyhedral geometry, and VIBRANT Virus Identification By iteRative ANnoTation.","The software is in a prerelease state: the interface for creating, deploying, and executing runtimes is final, and an interface for easily publishing runtimes is under active development.","We thus propose publishing predefined, distributable software environment runtimes along with research papers in an effort to make research with software based results reproducible."],"url":"http://arxiv.org/abs/2404.05563v1"}
{"created":"2024-04-08 14:15:56","title":"Evaluating Interventional Reasoning Capabilities of Large Language Models","abstract":"Numerous decision-making tasks require estimating causal effects under interventions on different parts of a system. As practitioners consider using large language models (LLMs) to automate decisions, studying their causal reasoning capabilities becomes crucial. A recent line of work evaluates LLMs ability to retrieve commonsense causal facts, but these evaluations do not sufficiently assess how LLMs reason about interventions. Motivated by the role that interventions play in causal inference, in this paper, we conduct empirical analyses to evaluate whether LLMs can accurately update their knowledge of a data-generating process in response to an intervention. We create benchmarks that span diverse causal graphs (e.g., confounding, mediation) and variable types, and enable a study of intervention-based reasoning. These benchmarks allow us to isolate the ability of LLMs to accurately predict changes resulting from their ability to memorize facts or find other shortcuts. Our analysis on four LLMs highlights that while GPT- 4 models show promising accuracy at predicting the intervention effects, they remain sensitive to distracting factors in the prompts.","sentences":["Numerous decision-making tasks require estimating causal effects under interventions on different parts of a system.","As practitioners consider using large language models (LLMs) to automate decisions, studying their causal reasoning capabilities becomes crucial.","A recent line of work evaluates LLMs ability to retrieve commonsense causal facts, but these evaluations do not sufficiently assess how LLMs reason about interventions.","Motivated by the role that interventions play in causal inference, in this paper, we conduct empirical analyses to evaluate whether LLMs can accurately update their knowledge of a data-generating process in response to an intervention.","We create benchmarks that span diverse causal graphs (e.g., confounding, mediation) and variable types, and enable a study of intervention-based reasoning.","These benchmarks allow us to isolate the ability of LLMs to accurately predict changes resulting from their ability to memorize facts or find other shortcuts.","Our analysis on four LLMs highlights that while GPT- 4 models show promising accuracy at predicting the intervention effects, they remain sensitive to distracting factors in the prompts."],"url":"http://arxiv.org/abs/2404.05545v1"}
{"created":"2024-04-08 14:10:14","title":"Optimal Allocation of Tasks and Price of Anarchy of Distributed Optimization in Networked Computing Facilities","abstract":"The allocation of computing tasks for networked distributed services poses a question to service providers on whether centralized allocation management be worth its cost. Existing analytical models were conceived for users accessing computing resources with practically indistinguishable (hence irrelevant for the allocation decision) delays, which is typical of services located in the same distant data center. However, with the rise of the edge-cloud continuum, a simple analysis of the sojourn time that computing tasks observe at the server misses the impact of diverse latency values imposed by server locations. We therefore study the optimization of computing task allocation with a new model that considers both distance of servers and sojourn time in servers. We derive exact algorithms to optimize the system and we show, through numerical analysis and real experiments, that differences in server location in the edge-cloud continuum cannot be neglected. By means of algorithmic game theory, we study the price of anarchy of a distributed implementation of the computing task allocation problem and unveil important practical properties such as the fact that the price of anarchy tends to be small -- except when the system is overloaded -- and its maximum can be computed with low complexity.","sentences":["The allocation of computing tasks for networked distributed services poses a question to service providers on whether centralized allocation management be worth its cost.","Existing analytical models were conceived for users accessing computing resources with practically indistinguishable (hence irrelevant for the allocation decision) delays, which is typical of services located in the same distant data center.","However, with the rise of the edge-cloud continuum, a simple analysis of the sojourn time that computing tasks observe at the server misses the impact of diverse latency values imposed by server locations.","We therefore study the optimization of computing task allocation with a new model that considers both distance of servers and sojourn time in servers.","We derive exact algorithms to optimize the system and we show, through numerical analysis and real experiments, that differences in server location in the edge-cloud continuum cannot be neglected.","By means of algorithmic game theory, we study the price of anarchy of a distributed implementation of the computing task allocation problem and unveil important practical properties such as the fact that the price of anarchy tends to be small -- except when the system is overloaded -- and its maximum can be computed with low complexity."],"url":"http://arxiv.org/abs/2404.05543v1"}
{"created":"2024-04-08 14:08:56","title":"OPSD: an Offensive Persian Social media Dataset and its baseline evaluations","abstract":"The proliferation of hate speech and offensive comments on social media has become increasingly prevalent due to user activities. Such comments can have detrimental effects on individuals' psychological well-being and social behavior. While numerous datasets in the English language exist in this domain, few equivalent resources are available for Persian language. To address this gap, this paper introduces two offensive datasets. The first dataset comprises annotations provided by domain experts, while the second consists of a large collection of unlabeled data obtained through web crawling for unsupervised learning purposes. To ensure the quality of the former dataset, a meticulous three-stage labeling process was conducted, and kappa measures were computed to assess inter-annotator agreement. Furthermore, experiments were performed on the dataset using state-of-the-art language models, both with and without employing masked language modeling techniques, as well as machine learning algorithms, in order to establish the baselines for the dataset using contemporary cutting-edge approaches. The obtained F1-scores for the three-class and two-class versions of the dataset were 76.9% and 89.9% for XLM-RoBERTa, respectively.","sentences":["The proliferation of hate speech and offensive comments on social media has become increasingly prevalent due to user activities.","Such comments can have detrimental effects on individuals' psychological well-being and social behavior.","While numerous datasets in the English language exist in this domain, few equivalent resources are available for Persian language.","To address this gap, this paper introduces two offensive datasets.","The first dataset comprises annotations provided by domain experts, while the second consists of a large collection of unlabeled data obtained through web crawling for unsupervised learning purposes.","To ensure the quality of the former dataset, a meticulous three-stage labeling process was conducted, and kappa measures were computed to assess inter-annotator agreement.","Furthermore, experiments were performed on the dataset using state-of-the-art language models, both with and without employing masked language modeling techniques, as well as machine learning algorithms, in order to establish the baselines for the dataset using contemporary cutting-edge approaches.","The obtained F1-scores for the three-class and two-class versions of the dataset were 76.9% and 89.9% for XLM-RoBERTa, respectively."],"url":"http://arxiv.org/abs/2404.05540v1"}
{"created":"2024-04-08 14:06:52","title":"Cell-Free Multi-User MIMO Equalization via In-Context Learning","abstract":"Large pre-trained sequence models, such as transformers, excel as few-shot learners capable of in-context learning (ICL). In ICL, a model is trained to adapt its operation to a new task based on limited contextual information, typically in the form of a few training examples for the given task. Previous work has explored the use of ICL for channel equalization in single-user multi-input and multiple-output (MIMO) systems. In this work, we demonstrate that ICL can be also used to tackle the problem of multi-user equalization in cell-free MIMO systems with limited fronthaul capacity. In this scenario, a task is defined by channel statistics, signal-to-noise ratio, and modulation schemes. The context encompasses the users' pilot sequences, the corresponding quantized received signals, and the current received data signal. Different prompt design strategies are proposed and evaluated that encompass also large-scale fading and modulation information. Experiments demonstrate that ICL-based equalization provides estimates with lower mean squared error as compared to the linear minimum mean squared error equalizer, especially in the presence of limited fronthaul capacity and pilot contamination.","sentences":["Large pre-trained sequence models, such as transformers, excel as few-shot learners capable of in-context learning (ICL).","In ICL, a model is trained to adapt its operation to a new task based on limited contextual information, typically in the form of a few training examples for the given task.","Previous work has explored the use of ICL for channel equalization in single-user multi-input and multiple-output (MIMO) systems.","In this work, we demonstrate that ICL can be also used to tackle the problem of multi-user equalization in cell-free MIMO systems with limited fronthaul capacity.","In this scenario, a task is defined by channel statistics, signal-to-noise ratio, and modulation schemes.","The context encompasses the users' pilot sequences, the corresponding quantized received signals, and the current received data signal.","Different prompt design strategies are proposed and evaluated that encompass also large-scale fading and modulation information.","Experiments demonstrate that ICL-based equalization provides estimates with lower mean squared error as compared to the linear minimum mean squared error equalizer, especially in the presence of limited fronthaul capacity and pilot contamination."],"url":"http://arxiv.org/abs/2404.05538v1"}
{"created":"2024-04-08 13:59:02","title":"Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data","abstract":"Reinforcement Learning from Human Feedback (RLHF) is a popular method for aligning Language Models (LM) with human values and preferences. RLHF requires a large number of preference pairs as training data, which are often used in both the Supervised Fine-Tuning and Reward Model training, and therefore publicly available datasets are commonly used. In this work, we study to what extent a malicious actor can manipulate the LMs generations by poisoning the preferences, i.e., injecting poisonous preference pairs into these datasets and the RLHF training process. We propose strategies to build poisonous preference pairs and test their performance by poisoning two widely used preference datasets. Our results show that preference poisoning is highly effective: by injecting a small amount of poisonous data (1-5% of the original dataset), we can effectively manipulate the LM to generate a target entity in a target sentiment (positive or negative). The findings from our experiments also shed light on strategies to defend against the preference poisoning attack.","sentences":["Reinforcement Learning from Human Feedback (RLHF) is a popular method for aligning Language Models (LM) with human values and preferences.","RLHF requires a large number of preference pairs as training data, which are often used in both the Supervised Fine-Tuning and Reward Model training, and therefore publicly available datasets are commonly used.","In this work, we study to what extent a malicious actor can manipulate the LMs generations by poisoning the preferences, i.e., injecting poisonous preference pairs into these datasets and the RLHF training process.","We propose strategies to build poisonous preference pairs and test their performance by poisoning two widely used preference datasets.","Our results show that preference poisoning is highly effective: by injecting a small amount of poisonous data (1-5% of the original dataset), we can effectively manipulate the LM to generate a target entity in a target sentiment (positive or negative).","The findings from our experiments also shed light on strategies to defend against the preference poisoning attack."],"url":"http://arxiv.org/abs/2404.05530v1"}
{"created":"2024-04-08 13:43:19","title":"3DMambaIPF: A State Space Model for Iterative Point Cloud Filtering via Differentiable Rendering","abstract":"Noise is an inevitable aspect of point cloud acquisition, necessitating filtering as a fundamental task within the realm of 3D vision. Existing learning-based filtering methods have shown promising capabilities on small-scale synthetic or real-world datasets. Nonetheless, the effectiveness of these methods is constrained when dealing with a substantial quantity of point clouds. This limitation primarily stems from their limited denoising capabilities for large-scale point clouds and their inclination to generate noisy outliers after denoising. The recent introduction of State Space Models (SSMs) for long sequence modeling in Natural Language Processing (NLP) presents a promising solution for handling large-scale data. Encouraged by iterative point cloud filtering methods, we introduce 3DMambaIPF, firstly incorporating Mamba (Selective SSM) architecture to sequentially handle extensive point clouds from large scenes, capitalizing on its strengths in selective input processing and long sequence modeling capabilities. Additionally, we integrate a robust and fast differentiable rendering loss to constrain the noisy points around the surface. In contrast to previous methodologies, this differentiable rendering loss enhances the visual realism of denoised geometric structures and aligns point cloud boundaries more closely with those observed in real-world objects. Extensive evaluation on datasets comprising small-scale synthetic and real-world models (typically with up to 50K points) demonstrate that our method achieves state-of-the-art results. Moreover, we showcase the superior scalability and efficiency of our method on large-scale models with about 500K points, where the majority of the existing learning-based denoising methods are unable to handle.","sentences":["Noise is an inevitable aspect of point cloud acquisition, necessitating filtering as a fundamental task within the realm of 3D vision.","Existing learning-based filtering methods have shown promising capabilities on small-scale synthetic or real-world datasets.","Nonetheless, the effectiveness of these methods is constrained when dealing with a substantial quantity of point clouds.","This limitation primarily stems from their limited denoising capabilities for large-scale point clouds and their inclination to generate noisy outliers after denoising.","The recent introduction of State Space Models (SSMs) for long sequence modeling in Natural Language Processing (NLP) presents a promising solution for handling large-scale data.","Encouraged by iterative point cloud filtering methods, we introduce 3DMambaIPF, firstly incorporating Mamba (Selective SSM) architecture to sequentially handle extensive point clouds from large scenes, capitalizing on its strengths in selective input processing and long sequence modeling capabilities.","Additionally, we integrate a robust and fast differentiable rendering loss to constrain the noisy points around the surface.","In contrast to previous methodologies, this differentiable rendering loss enhances the visual realism of denoised geometric structures and aligns point cloud boundaries more closely with those observed in real-world objects.","Extensive evaluation on datasets comprising small-scale synthetic and real-world models (typically with up to 50K points) demonstrate that our method achieves state-of-the-art results.","Moreover, we showcase the superior scalability and efficiency of our method on large-scale models with about 500K points, where the majority of the existing learning-based denoising methods are unable to handle."],"url":"http://arxiv.org/abs/2404.05522v1"}
{"created":"2024-04-08 13:41:32","title":"The Fact Selection Problem in LLM-Based Program Repair","abstract":"Recent research has shown that incorporating bug-related facts, such as stack traces and GitHub issues, into prompts enhances the bug-fixing capabilities of large language models (LLMs). Considering the ever-increasing context window of these models, a critical question arises: what and how many facts should be included in prompts to maximise the chance of correctly fixing bugs? To answer this question, we conducted a large-scale study, employing over 19K prompts featuring various combinations of seven diverse facts to rectify 314 bugs from open-source Python projects within the BugsInPy benchmark. Our findings revealed that each fact, ranging from simple syntactic details like code context to semantic information previously unexplored in the context of LLMs such as angelic values, is beneficial. Specifically, each fact aids in fixing some bugs that would remain unresolved or only be fixed with a low success rate without it. Importantly, we discovered that the effectiveness of program repair prompts is non-monotonic over the number of used facts; using too many facts leads to subpar outcomes. These insights led us to define the fact selection problem: determining the optimal set of facts for inclusion in a prompt to maximise LLM's performance on a given task instance. We found that there is no one-size-fits-all set of facts for bug repair. Therefore, we developed a basic statistical model, named Maniple, which selects facts specific to a given bug to include in the prompt. This model significantly surpasses the performance of the best generic fact set. To underscore the significance of the fact selection problem, we benchmarked Maniple against the state-of-the-art zero-shot, non-conversational LLM-based bug repair methods. On our testing dataset of 157 bugs, Maniple repairs 88 bugs, 17% above the best configuration.","sentences":["Recent research has shown that incorporating bug-related facts, such as stack traces and GitHub issues, into prompts enhances the bug-fixing capabilities of large language models (LLMs).","Considering the ever-increasing context window of these models, a critical question arises: what and how many facts should be included in prompts to maximise the chance of correctly fixing bugs?","To answer this question, we conducted a large-scale study, employing over 19K prompts featuring various combinations of seven diverse facts to rectify 314 bugs from open-source Python projects within the BugsInPy benchmark.","Our findings revealed that each fact, ranging from simple syntactic details like code context to semantic information previously unexplored in the context of LLMs such as angelic values, is beneficial.","Specifically, each fact aids in fixing some bugs that would remain unresolved or only be fixed with a low success rate without it.","Importantly, we discovered that the effectiveness of program repair prompts is non-monotonic over the number of used facts; using too many facts leads to subpar outcomes.","These insights led us to define the fact selection problem: determining the optimal set of facts for inclusion in a prompt to maximise LLM's performance on a given task instance.","We found that there is no one-size-fits-all set of facts for bug repair.","Therefore, we developed a basic statistical model, named Maniple, which selects facts specific to a given bug to include in the prompt.","This model significantly surpasses the performance of the best generic fact set.","To underscore the significance of the fact selection problem, we benchmarked Maniple against the state-of-the-art zero-shot, non-conversational LLM-based bug repair methods.","On our testing dataset of 157 bugs, Maniple repairs 88 bugs, 17% above the best configuration."],"url":"http://arxiv.org/abs/2404.05520v1"}
{"created":"2024-04-08 13:35:48","title":"Efficient Distributed Data Structures for Future Many-core Architectures","abstract":"We study general techniques for implementing distributed data structures on top of future many-core architectures with non cache-coherent or partially cache-coherent memory. With the goal of contributing towards what might become, in the future, the concurrency utilities package in Java collections for such architectures, we end up with a comprehensive collection of data structures by considering different variants of these techniques. To achieve scalability, we study a generic scheme which makes all our implementations hierarchical. We consider a collection of known techniques for improving the scalability of concurrent data structures and we adjust them to work in our setting. We have performed experiments which illustrate that some of these techniques have indeed high impact on achieving scalability. Our experiments also reveal the performance and scalability power of the hierarchical approach. We finally present experiments to study energy consumption aspects of the proposed techniques by using an energy model recently proposed for such architectures.","sentences":["We study general techniques for implementing distributed data structures on top of future many-core architectures with non cache-coherent or partially cache-coherent memory.","With the goal of contributing towards what might become, in the future, the concurrency utilities package in Java collections for such architectures, we end up with a comprehensive collection of data structures by considering different variants of these techniques.","To achieve scalability, we study a generic scheme which makes all our implementations hierarchical.","We consider a collection of known techniques for improving the scalability of concurrent data structures and we adjust them to work in our setting.","We have performed experiments which illustrate that some of these techniques have indeed high impact on achieving scalability.","Our experiments also reveal the performance and scalability power of the hierarchical approach.","We finally present experiments to study energy consumption aspects of the proposed techniques by using an energy model recently proposed for such architectures."],"url":"http://arxiv.org/abs/2404.05515v1"}
{"created":"2024-04-08 13:22:24","title":"Constraining Large Language Model for Generating Computer-Parsable Content","abstract":"We propose a method to guide Large Language Models (LLMs) in generating structured content adhering to specific conventions without fine-tuning. By utilizing coroutine-based content generation constraints through a pre-agreed context-free grammar (CFG), LLMs are directed during decoding to produce formal language compliant outputs. This enhances stability and consistency in generating target data structures, types, or instructions, reducing application development complexities. Experimentally, error rates of GPT-2 and Gemma exceed 95% for DSLs longer than 36 and 282 tokens, respectively. We introduce YieldLang, a coroutine-based DSL generation framework, and evaluate it with LLMs on various tasks including JSON and Mermaid flowchart generation. Compared to benchmarks, our approach improves accuracy by 1.09 to 11.6 times, with LLMs requiring only about 16.5% of the samples to generate JSON effectively. This enhances usability of LLM-generated content for computer programs.","sentences":["We propose a method to guide Large Language Models (LLMs) in generating structured content adhering to specific conventions without fine-tuning.","By utilizing coroutine-based content generation constraints through a pre-agreed context-free grammar (CFG), LLMs are directed during decoding to produce formal language compliant outputs.","This enhances stability and consistency in generating target data structures, types, or instructions, reducing application development complexities.","Experimentally, error rates of GPT-2 and Gemma exceed 95% for DSLs longer than 36 and 282 tokens, respectively.","We introduce YieldLang, a coroutine-based DSL generation framework, and evaluate it with LLMs on various tasks including JSON and Mermaid flowchart generation.","Compared to benchmarks, our approach improves accuracy by 1.09 to 11.6 times, with LLMs requiring only about 16.5% of the samples to generate JSON effectively.","This enhances usability of LLM-generated content for computer programs."],"url":"http://arxiv.org/abs/2404.05499v1"}
{"created":"2024-04-08 13:11:57","title":"Two-Person Interaction Augmentation with Skeleton Priors","abstract":"Close and continuous interaction with rich contacts is a crucial aspect of human activities (e.g. hugging, dancing) and of interest in many domains like activity recognition, motion prediction, character animation, etc. However, acquiring such skeletal motion is challenging. While direct motion capture is expensive and slow, motion editing/generation is also non-trivial, as complex contact patterns with topological and geometric constraints have to be retained. To this end, we propose a new deep learning method for two-body skeletal interaction motion augmentation, which can generate variations of contact-rich interactions with varying body sizes and proportions while retaining the key geometric/topological relations between two bodies. Our system can learn effectively from a relatively small amount of data and generalize to drastically different skeleton sizes. Through exhaustive evaluation and comparison, we show it can generate high-quality motions, has strong generalizability and outperforms traditional optimization-based methods and alternative deep learning solutions.","sentences":["Close and continuous interaction with rich contacts is a crucial aspect of human activities (e.g. hugging, dancing) and of interest in many domains like activity recognition, motion prediction, character animation, etc.","However, acquiring such skeletal motion is challenging.","While direct motion capture is expensive and slow, motion editing/generation is also non-trivial, as complex contact patterns with topological and geometric constraints have to be retained.","To this end, we propose a new deep learning method for two-body skeletal interaction motion augmentation, which can generate variations of contact-rich interactions with varying body sizes and proportions while retaining the key geometric/topological relations between two bodies.","Our system can learn effectively from a relatively small amount of data and generalize to drastically different skeleton sizes.","Through exhaustive evaluation and comparison, we show it can generate high-quality motions, has strong generalizability and outperforms traditional optimization-based methods and alternative deep learning solutions."],"url":"http://arxiv.org/abs/2404.05490v1"}
{"created":"2024-04-08 13:01:25","title":"WaveCatBoost for Probabilistic Forecasting of Regional Air Quality Data","abstract":"Accurate and reliable air quality forecasting is essential for protecting public health, sustainable development, pollution control, and enhanced urban planning. This letter presents a novel WaveCatBoost architecture designed to forecast the real-time concentrations of air pollutants by combining the maximal overlapping discrete wavelet transform (MODWT) with the CatBoost model. This hybrid approach efficiently transforms time series into high-frequency and low-frequency components, thereby extracting signal from noise and improving prediction accuracy and robustness. Evaluation of two distinct regional datasets, from the Central Air Pollution Control Board (CPCB) sensor network and a low-cost air quality sensor system (LAQS), underscores the superior performance of our proposed methodology in real-time forecasting compared to the state-of-the-art statistical and deep learning architectures. Moreover, we employ a conformal prediction strategy to provide probabilistic bands with our forecasts.","sentences":["Accurate and reliable air quality forecasting is essential for protecting public health, sustainable development, pollution control, and enhanced urban planning.","This letter presents a novel WaveCatBoost architecture designed to forecast the real-time concentrations of air pollutants by combining the maximal overlapping discrete wavelet transform (MODWT) with the CatBoost model.","This hybrid approach efficiently transforms time series into high-frequency and low-frequency components, thereby extracting signal from noise and improving prediction accuracy and robustness.","Evaluation of two distinct regional datasets, from the Central Air Pollution Control Board (CPCB) sensor network and a low-cost air quality sensor system (LAQS), underscores the superior performance of our proposed methodology in real-time forecasting compared to the state-of-the-art statistical and deep learning architectures.","Moreover, we employ a conformal prediction strategy to provide probabilistic bands with our forecasts."],"url":"http://arxiv.org/abs/2404.05482v1"}
{"created":"2024-04-08 12:55:00","title":"Behavioural Types for Heterogeneous Systems (Position Paper)","abstract":"Behavioural types provide a promising way to achieve lightweight, language-integrated verification for communication-centric software. However, a large barrier to the adoption of behavioural types is that the current state of the art expects software to be written using the same tools and typing discipline throughout a system, and has little support for components over which a developer has no control.   This position paper describes the outcomes of a working group discussion at Dagstuhl Seminar 24051 (Next-Generation Protocols for Heterogeneous Systems). We propose a methodology for integrating multiple behaviourally-typed components, written in different languages. Our proposed approach involves an extensible protocol description language, a session IR that can describe data transformations and boundary monitoring and which can be compiled into program-specific session proxies, and finally a session middleware to aid session establishment.   We hope that this position paper will stimulate discussion on one of the most pressing challenges facing the widespread adoption of behavioural typing.","sentences":["Behavioural types provide a promising way to achieve lightweight, language-integrated verification for communication-centric software.","However, a large barrier to the adoption of behavioural types is that the current state of the art expects software to be written using the same tools and typing discipline throughout a system, and has little support for components over which a developer has no control.   ","This position paper describes the outcomes of a working group discussion at Dagstuhl Seminar 24051 (Next-Generation Protocols for Heterogeneous Systems).","We propose a methodology for integrating multiple behaviourally-typed components, written in different languages.","Our proposed approach involves an extensible protocol description language, a session IR that can describe data transformations and boundary monitoring and which can be compiled into program-specific session proxies, and finally a session middleware to aid session establishment.   ","We hope that this position paper will stimulate discussion on one of the most pressing challenges facing the widespread adoption of behavioural typing."],"url":"http://arxiv.org/abs/2404.05479v1"}
{"created":"2024-04-08 12:44:24","title":"Enhancing Lip Reading with Multi-Scale Video and Multi-Encoder","abstract":"Automatic lip-reading (ALR) aims to automatically transcribe spoken content from a speaker's silent lip motion captured in video. Current mainstream lip-reading approaches only use a single visual encoder to model input videos of a single scale. In this paper, we propose to enhance lipreading by incorporating multi-scale video data and multi-encoder. Specifically, we first propose a novel multi-scale lip extraction algorithm based on the size of the speaker's face and an enhanced ResNet3D visual front-end (VFE) to extract lip features at different scales. For the multi-encoder, in addition to the mainstream Transformer and Conformer, we also incorporate the recently proposed Branchformer and EBranchformer as visual encoders. In the experiments, we explore the influence of different video data scales and encoders on ALR system performance and fuse the texts transcribed by all ALR systems using recognizer output voting error reduction (ROVER). Finally, our proposed approach placed second in the ICME 2024 ChatCLR Challenge Task 2, with a 21.52% reduction in character error rate (CER) compared to the official baseline on the evaluation set.","sentences":["Automatic lip-reading (ALR) aims to automatically transcribe spoken content from a speaker's silent lip motion captured in video.","Current mainstream lip-reading approaches only use a single visual encoder to model input videos of a single scale.","In this paper, we propose to enhance lipreading by incorporating multi-scale video data and multi-encoder.","Specifically, we first propose a novel multi-scale lip extraction algorithm based on the size of the speaker's face and an enhanced ResNet3D visual front-end (VFE) to extract lip features at different scales.","For the multi-encoder, in addition to the mainstream Transformer and Conformer, we also incorporate the recently proposed Branchformer and EBranchformer as visual encoders.","In the experiments, we explore the influence of different video data scales and encoders on ALR system performance and fuse the texts transcribed by all ALR systems using recognizer output voting error reduction (ROVER).","Finally, our proposed approach placed second in the ICME 2024 ChatCLR Challenge Task 2, with a 21.52% reduction in character error rate (CER) compared to the official baseline on the evaluation set."],"url":"http://arxiv.org/abs/2404.05466v1"}
{"created":"2024-04-08 12:29:46","title":"Pansharpening of PRISMA products for archaeological prospection","abstract":"Hyperspectral data recorded from satellite platforms are often ill-suited for geo-archaeological prospection due to low spatial resolution. The established potential of hyperspectral data from airborne sensors in identifying archaeological features has, on the other side, generated increased interest in enhancing hyperspectral data to achieve higher spatial resolution. This improvement is crucial for detecting traces linked to sub-surface geo-archaeological features and can make satellite hyperspectral acquisitions more suitable for archaeological research. This research assesses the usability of pansharpened PRISMA satellite products in geo-archaeological prospections. Three pan-sharpening methods (GSA, MTF-GLP and HySure) are compared quantitatively and qualitatively and tested over the archaeological landscape of Aquileia (Italy). The results suggest that the application of pansharpening techniques makes hyperspectral satellite imagery highly suitable, under certain conditions, to the identification of sub-surface archaeological features of small and large size.","sentences":["Hyperspectral data recorded from satellite platforms are often ill-suited for geo-archaeological prospection due to low spatial resolution.","The established potential of hyperspectral data from airborne sensors in identifying archaeological features has, on the other side, generated increased interest in enhancing hyperspectral data to achieve higher spatial resolution.","This improvement is crucial for detecting traces linked to sub-surface geo-archaeological features and can make satellite hyperspectral acquisitions more suitable for archaeological research.","This research assesses the usability of pansharpened PRISMA satellite products in geo-archaeological prospections.","Three pan-sharpening methods (GSA, MTF-GLP and HySure) are compared quantitatively and qualitatively and tested over the archaeological landscape of Aquileia (Italy).","The results suggest that the application of pansharpening techniques makes hyperspectral satellite imagery highly suitable, under certain conditions, to the identification of sub-surface archaeological features of small and large size."],"url":"http://arxiv.org/abs/2404.05447v1"}
{"created":"2024-04-08 12:29:07","title":"XL$^2$Bench: A Benchmark for Extremely Long Context Understanding with Long-range Dependencies","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks but are constrained by their small context window sizes. Various efforts have been proposed to expand the context window to accommodate even up to 200K input tokens. Meanwhile, building high-quality benchmarks with much longer text lengths and more demanding tasks to provide comprehensive evaluations is of immense practical interest to facilitate long context understanding research of LLMs. However, prior benchmarks create datasets that ostensibly cater to long-text comprehension by expanding the input of traditional tasks, which falls short to exhibit the unique characteristics of long-text understanding, including long dependency tasks and longer text length compatible with modern LLMs' context window size. In this paper, we introduce a benchmark for extremely long context understanding with long-range dependencies, XL$^2$Bench, which includes three scenarios: Fiction Reading, Paper Reading, and Law Reading, and four tasks of increasing complexity: Memory Retrieval, Detailed Understanding, Overall Understanding, and Open-ended Generation, covering 27 subtasks in English and Chinese. It has an average length of 100K+ words (English) and 200K+ characters (Chinese). Evaluating six leading LLMs on XL$^2$Bench, we find that their performance significantly lags behind human levels. Moreover, the observed decline in performance across both the original and enhanced datasets underscores the efficacy of our approach to mitigating data contamination.","sentences":["Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks but are constrained by their small context window sizes.","Various efforts have been proposed to expand the context window to accommodate even up to 200K input tokens.","Meanwhile, building high-quality benchmarks with much longer text lengths and more demanding tasks to provide comprehensive evaluations is of immense practical interest to facilitate long context understanding research of LLMs.","However, prior benchmarks create datasets that ostensibly cater to long-text comprehension by expanding the input of traditional tasks, which falls short to exhibit the unique characteristics of long-text understanding, including long dependency tasks and longer text length compatible with modern LLMs' context window size.","In this paper, we introduce a benchmark for extremely long context understanding with long-range dependencies, XL$^2$Bench, which includes three scenarios: Fiction Reading, Paper Reading, and Law Reading, and four tasks of increasing complexity: Memory Retrieval, Detailed Understanding, Overall Understanding, and Open-ended Generation, covering 27 subtasks in English and Chinese.","It has an average length of 100K+ words (English) and 200K+ characters (Chinese).","Evaluating six leading LLMs on XL$^2$Bench, we find that their performance significantly lags behind human levels.","Moreover, the observed decline in performance across both the original and enhanced datasets underscores the efficacy of our approach to mitigating data contamination."],"url":"http://arxiv.org/abs/2404.05446v1"}
{"created":"2024-04-08 12:22:39","title":"Unlocking Adaptive User Experience with Generative AI","abstract":"Developing user-centred applications that address diverse user needs requires rigorous user research. This is time, effort and cost-consuming. With the recent rise of generative AI techniques based on Large Language Models (LLMs), there is a possibility that these powerful tools can be used to develop adaptive interfaces. This paper presents a novel approach to develop user personas and adaptive interface candidates for a specific domain using ChatGPT. We develop user personas and adaptive interfaces using both ChatGPT and a traditional manual process and compare these outcomes. To obtain data for the personas we collected data from 37 survey participants and 4 interviews in collaboration with a not-for-profit organisation. The comparison of ChatGPT generated content and manual content indicates promising results that encourage using LLMs in the adaptive interfaces design process.","sentences":["Developing user-centred applications that address diverse user needs requires rigorous user research.","This is time, effort and cost-consuming.","With the recent rise of generative AI techniques based on Large Language Models (LLMs), there is a possibility that these powerful tools can be used to develop adaptive interfaces.","This paper presents a novel approach to develop user personas and adaptive interface candidates for a specific domain using ChatGPT.","We develop user personas and adaptive interfaces using both ChatGPT and a traditional manual process and compare these outcomes.","To obtain data for the personas we collected data from 37 survey participants and 4 interviews in collaboration with a not-for-profit organisation.","The comparison of ChatGPT generated content and manual content indicates promising results that encourage using LLMs in the adaptive interfaces design process."],"url":"http://arxiv.org/abs/2404.05442v1"}
{"created":"2024-04-08 12:18:01","title":"Action-conditioned video data improves predictability","abstract":"Long-term video generation and prediction remain challenging tasks in computer vision, particularly in partially observable scenarios where cameras are mounted on moving platforms. The interaction between observed image frames and the motion of the recording agent introduces additional complexities. To address these issues, we introduce the Action-Conditioned Video Generation (ACVG) framework, a novel approach that investigates the relationship between actions and generated image frames through a deep dual Generator-Actor architecture. ACVG generates video sequences conditioned on the actions of robots, enabling exploration and analysis of how vision and action mutually influence one another in dynamic environments. We evaluate the framework's effectiveness on an indoor robot motion dataset which consists of sequences of image frames along with the sequences of actions taken by the robotic agent, conducting a comprehensive empirical study comparing ACVG to other state-of-the-art frameworks along with a detailed ablation study.","sentences":["Long-term video generation and prediction remain challenging tasks in computer vision, particularly in partially observable scenarios where cameras are mounted on moving platforms.","The interaction between observed image frames and the motion of the recording agent introduces additional complexities.","To address these issues, we introduce the Action-Conditioned Video Generation (ACVG) framework, a novel approach that investigates the relationship between actions and generated image frames through a deep dual Generator-Actor architecture.","ACVG generates video sequences conditioned on the actions of robots, enabling exploration and analysis of how vision and action mutually influence one another in dynamic environments.","We evaluate the framework's effectiveness on an indoor robot motion dataset which consists of sequences of image frames along with the sequences of actions taken by the robotic agent, conducting a comprehensive empirical study comparing ACVG to other state-of-the-art frameworks along with a detailed ablation study."],"url":"http://arxiv.org/abs/2404.05439v1"}
{"created":"2024-04-08 12:06:30","title":"Combinatorial Correlation Clustering","abstract":"Correlation Clustering is a classic clustering objective arising in numerous machine learning and data mining applications. Given a graph $G=(V,E)$, the goal is to partition the vertex set into clusters so as to minimize the number of edges between clusters plus the number of edges missing within clusters.   The problem is APX-hard and the best known polynomial time approximation factor is 1.73 by Cohen-Addad, Lee, Li, and Newman [FOCS'23]. They use an LP with $|V|^{1/\\epsilon^{\\Theta(1)}}$ variables for some small $\\epsilon$. However, due to the practical relevance of correlation clustering, there has also been great interest in getting more efficient sequential and parallel algorithms.   The classic combinatorial pivot algorithm of Ailon, Charikar and Newman [JACM'08] provides a 3-approximation in linear time. Like most other algorithms discussed here, this uses randomization. Recently, Behnezhad, Charikar, Ma and Tan [FOCS'22] presented a $3+\\epsilon$-approximate solution for solving problem in a constant number of rounds in the Massively Parallel Computation (MPC) setting. Very recently, Cao, Huang, Su [SODA'24] provided a 2.4-approximation in a polylogarithmic number of rounds in the MPC model and in $\\tilde{O}(|E|^{1.5})$ time in the classic sequential setting. They asked whether it is possible to get a better than 3-approximation in near-linear time?   We resolve this problem with an efficient combinatorial algorithm providing a drastically better approximation factor. It achieves a $\\sim 2-2/13 < 1.847$-approximation in sub-linear ($\\tilde O(|V|)$) sequential time or in sub-linear ($\\tilde O(|V|)$) space in the streaming setting, and it uses only a constant number of rounds in the MPC model.","sentences":["Correlation Clustering is a classic clustering objective arising in numerous machine learning and data mining applications.","Given a graph $G=(V,E)$, the goal is to partition the vertex set into clusters so as to minimize the number of edges between clusters plus the number of edges missing within clusters.   ","The problem is APX-hard and the best known polynomial time approximation factor is 1.73 by Cohen-Addad, Lee, Li, and Newman","[FOCS'23].","They use an LP with $|V|^{1/\\epsilon^{\\Theta(1)}}$ variables for some small $\\epsilon$. However, due to the practical relevance of correlation clustering, there has also been great interest in getting more efficient sequential and parallel algorithms.   ","The classic combinatorial pivot algorithm of Ailon, Charikar and Newman [JACM'08] provides a 3-approximation in linear time.","Like most other algorithms discussed here, this uses randomization.","Recently, Behnezhad, Charikar, Ma and Tan [FOCS'22] presented a $3+\\epsilon$-approximate solution for solving problem in a constant number of rounds in the Massively Parallel Computation (MPC) setting.","Very recently, Cao, Huang, Su","[SODA'24] provided a 2.4-approximation in a polylogarithmic number of rounds in the MPC model and in $\\tilde{O}(|E|^{1.5})$ time in the classic sequential setting.","They asked whether it is possible to get a better than 3-approximation in near-linear time?   ","We resolve this problem with an efficient combinatorial algorithm providing a drastically better approximation factor.","It achieves a $\\sim 2-2/13 < 1.847$-approximation in sub-linear ($\\tilde O(|V|)$) sequential time or in sub-linear ($\\tilde O(|V|)$) space in the streaming setting, and it uses only a constant number of rounds in the MPC model."],"url":"http://arxiv.org/abs/2404.05433v1"}
{"created":"2024-04-08 12:02:06","title":"Simplifying MBA Expression Using E-Graphs","abstract":"Code obfuscation involves the addition of meaningless code or the complication of existing code in order to make a program difficult to reverse engineer. In recent years, MBA (Mixed Boolean Arithmetic) obfuscation has been applied to virus and malware code to impede expert analysis. Among the various obfuscation techniques, Mixed Boolean Arithmetic (MBA) obfuscation is considered the most challenging to decipher using existing code deobfuscation techniques. In this paper, we have attempted to simplify the MBA expression. We use an e-graph data structure to efficiently hold multiple expressions of the same semantics to systematically rewrite terms and find simpler expressions. The preliminary experimental result shows that our e-graph based MBA deobfuscation approach works faster with reasonable performance than other approaches do.","sentences":["Code obfuscation involves the addition of meaningless code or the complication of existing code in order to make a program difficult to reverse engineer.","In recent years, MBA (Mixed Boolean Arithmetic) obfuscation has been applied to virus and malware code to impede expert analysis.","Among the various obfuscation techniques, Mixed Boolean Arithmetic (MBA) obfuscation is considered the most challenging to decipher using existing code deobfuscation techniques.","In this paper, we have attempted to simplify the MBA expression.","We use an e-graph data structure to efficiently hold multiple expressions of the same semantics to systematically rewrite terms and find simpler expressions.","The preliminary experimental result shows that our e-graph based MBA deobfuscation approach works faster with reasonable performance than other approaches do."],"url":"http://arxiv.org/abs/2404.05431v1"}
{"created":"2024-04-08 11:55:44","title":"Language Models on a Diet: Cost-Efficient Development of Encoders for Closely-Related Languages via Additional Pretraining","abstract":"The world of language models is going through turbulent times, better and ever larger models are coming out at an unprecedented speed. However, we argue that, especially for the scientific community, encoder models of up to 1 billion parameters are still very much needed, their primary usage being in enriching large collections of data with metadata necessary for downstream research. We investigate the best way to ensure the existence of such encoder models on the set of very closely related languages - Croatian, Serbian, Bosnian and Montenegrin, by setting up a diverse benchmark for these languages, and comparing the trained-from-scratch models with the new models constructed via additional pretraining of existing multilingual models. We show that comparable performance to dedicated from-scratch models can be obtained by additionally pretraining available multilingual models even with a limited amount of computation. We also show that neighboring languages, in our case Slovenian, can be included in the additional pretraining with little to no loss in the performance of the final model.","sentences":["The world of language models is going through turbulent times, better and ever larger models are coming out at an unprecedented speed.","However, we argue that, especially for the scientific community, encoder models of up to 1 billion parameters are still very much needed, their primary usage being in enriching large collections of data with metadata necessary for downstream research.","We investigate the best way to ensure the existence of such encoder models on the set of very closely related languages - Croatian, Serbian, Bosnian and Montenegrin, by setting up a diverse benchmark for these languages, and comparing the trained-from-scratch models with the new models constructed via additional pretraining of existing multilingual models.","We show that comparable performance to dedicated from-scratch models can be obtained by additionally pretraining available multilingual models even with a limited amount of computation.","We also show that neighboring languages, in our case Slovenian, can be included in the additional pretraining with little to no loss in the performance of the final model."],"url":"http://arxiv.org/abs/2404.05428v1"}
{"created":"2024-04-08 11:54:49","title":"Test-Time Zero-Shot Temporal Action Localization","abstract":"Zero-Shot Temporal Action Localization (ZS-TAL) seeks to identify and locate actions in untrimmed videos unseen during training. Existing ZS-TAL methods involve fine-tuning a model on a large amount of annotated training data. While effective, training-based ZS-TAL approaches assume the availability of labeled data for supervised learning, which can be impractical in some applications. Furthermore, the training process naturally induces a domain bias into the learned model, which may adversely affect the model's generalization ability to arbitrary videos. These considerations prompt us to approach the ZS-TAL problem from a radically novel perspective, relaxing the requirement for training data. To this aim, we introduce a novel method that performs Test-Time adaptation for Temporal Action Localization (T3AL). In a nutshell, T3AL adapts a pre-trained Vision and Language Model (VLM). T3AL operates in three steps. First, a video-level pseudo-label of the action category is computed by aggregating information from the entire video. Then, action localization is performed adopting a novel procedure inspired by self-supervised learning. Finally, frame-level textual descriptions extracted with a state-of-the-art captioning model are employed for refining the action region proposals. We validate the effectiveness of T3AL by conducting experiments on the THUMOS14 and the ActivityNet-v1.3 datasets. Our results demonstrate that T3AL significantly outperforms zero-shot baselines based on state-of-the-art VLMs, confirming the benefit of a test-time adaptation approach.","sentences":["Zero-Shot Temporal Action Localization (ZS-TAL) seeks to identify and locate actions in untrimmed videos unseen during training.","Existing ZS-TAL methods involve fine-tuning a model on a large amount of annotated training data.","While effective, training-based ZS-TAL approaches assume the availability of labeled data for supervised learning, which can be impractical in some applications.","Furthermore, the training process naturally induces a domain bias into the learned model, which may adversely affect the model's generalization ability to arbitrary videos.","These considerations prompt us to approach the ZS-TAL problem from a radically novel perspective, relaxing the requirement for training data.","To this aim, we introduce a novel method that performs Test-Time adaptation for Temporal Action Localization (T3AL).","In a nutshell, T3AL adapts a pre-trained Vision and Language Model (VLM).","T3AL operates in three steps.","First, a video-level pseudo-label of the action category is computed by aggregating information from the entire video.","Then, action localization is performed adopting a novel procedure inspired by self-supervised learning.","Finally, frame-level textual descriptions extracted with a state-of-the-art captioning model are employed for refining the action region proposals.","We validate the effectiveness of T3AL by conducting experiments on the THUMOS14 and the ActivityNet-v1.3 datasets.","Our results demonstrate that T3AL significantly outperforms zero-shot baselines based on state-of-the-art VLMs, confirming the benefit of a test-time adaptation approach."],"url":"http://arxiv.org/abs/2404.05426v1"}
{"created":"2024-04-08 11:50:40","title":"Requirements Elicitation in Government Projects: A Preliminary Empirical Study","abstract":"Government development projects vary significantly from private sector initiatives in scope, stakeholder complexity, and regulatory requirements. There is a lack of empirical studies focusing on requirements engineering (RE) activities specifically for government projects. We addressed this gap by conducting a series of semi-structured interviews with 12 professional software practitioners working on government projects. These interviewees are employed by two types of companies, each serving different government departments. Our findings uncover differences in the requirements elicitation phase between government projects, particularly for data visualization aspects, and other software projects, such as stakeholders and policy requirements. Additionally, we explore the coverage of human and social aspects in requirements elicitation, finding that culture, team dynamics, and policy implications are critical considerations. Our findings also pinpoint the main challenges encountered during the requirements elicitation phase for government projects. Our findings highlight future research work that is important to bridge the gap in RE activities for government software projects.","sentences":["Government development projects vary significantly from private sector initiatives in scope, stakeholder complexity, and regulatory requirements.","There is a lack of empirical studies focusing on requirements engineering (RE) activities specifically for government projects.","We addressed this gap by conducting a series of semi-structured interviews with 12 professional software practitioners working on government projects.","These interviewees are employed by two types of companies, each serving different government departments.","Our findings uncover differences in the requirements elicitation phase between government projects, particularly for data visualization aspects, and other software projects, such as stakeholders and policy requirements.","Additionally, we explore the coverage of human and social aspects in requirements elicitation, finding that culture, team dynamics, and policy implications are critical considerations.","Our findings also pinpoint the main challenges encountered during the requirements elicitation phase for government projects.","Our findings highlight future research work that is important to bridge the gap in RE activities for government software projects."],"url":"http://arxiv.org/abs/2404.05425v1"}
{"created":"2024-04-08 11:11:31","title":"Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws","abstract":"Scaling laws describe the relationship between the size of language models and their capabilities. Unlike prior studies that evaluate a model's capability via loss or benchmarks, we estimate the number of knowledge bits a model stores. We focus on factual knowledge represented as tuples, such as (USA, capital, Washington D.C.) from a Wikipedia page. Through multiple controlled datasets, we establish that language models can and only can store 2 bits of knowledge per parameter, even when quantized to int8, and such knowledge can be flexibly extracted for downstream applications. Consequently, a 7B model can store 14B bits of knowledge, surpassing the English Wikipedia and textbooks combined based on our estimation.   More broadly, we present 12 results on how (1) training duration, (2) model architecture, (3) quantization, (4) sparsity constraints such as MoE, and (5) data signal-to-noise ratio affect a model's knowledge storage capacity. Notable insights include:   * The GPT-2 architecture, with rotary embedding, matches or even surpasses LLaMA/Mistral architectures in knowledge storage, particularly over shorter training durations. This arises because LLaMA/Mistral uses GatedMLP, which is less stable and harder to train.   * Prepending training data with domain names (e.g., wikipedia.org) significantly increases a model's knowledge capacity. Language models can autonomously identify and prioritize domains rich in knowledge, optimizing their storage capacity.","sentences":["Scaling laws describe the relationship between the size of language models and their capabilities.","Unlike prior studies that evaluate a model's capability via loss or benchmarks, we estimate the number of knowledge bits a model stores.","We focus on factual knowledge represented as tuples, such as (USA, capital, Washington D.C.) from a Wikipedia page.","Through multiple controlled datasets, we establish that language models can and only can store 2 bits of knowledge per parameter, even when quantized to int8, and such knowledge can be flexibly extracted for downstream applications.","Consequently, a 7B model can store 14B bits of knowledge, surpassing the English Wikipedia and textbooks combined based on our estimation.   ","More broadly, we present 12 results on how (1) training duration, (2) model architecture, (3) quantization, (4) sparsity constraints such as MoE, and (5) data signal-to-noise ratio affect a model's knowledge storage capacity.","Notable insights include:   *","The GPT-2 architecture, with rotary embedding, matches or even surpasses LLaMA/Mistral architectures in knowledge storage, particularly over shorter training durations.","This arises because LLaMA/Mistral uses GatedMLP, which is less stable and harder to train.   ","* Prepending training data with domain names (e.g., wikipedia.org) significantly increases a model's knowledge capacity.","Language models can autonomously identify and prioritize domains rich in knowledge, optimizing their storage capacity."],"url":"http://arxiv.org/abs/2404.05405v1"}
{"created":"2024-04-08 11:05:45","title":"SoK: Gradient Leakage in Federated Learning","abstract":"Federated learning (FL) enables collaborative model training among multiple clients without raw data exposure. However, recent studies have shown that clients' private training data can be reconstructed from the gradients they share in FL, known as gradient inversion attacks (GIAs). While GIAs have demonstrated effectiveness under \\emph{ideal settings and auxiliary assumptions}, their actual efficacy against \\emph{practical FL systems} remains under-explored. To address this gap, we conduct a comprehensive study on GIAs in this work. We start with a survey of GIAs that establishes a milestone to trace their evolution and develops a systematization to uncover their inherent threats. Specifically, we categorize the auxiliary assumptions used by existing GIAs based on their practical accessibility to potential adversaries. To facilitate deeper analysis, we highlight the challenges that GIAs face in practical FL systems from three perspectives: \\textit{local training}, \\textit{model}, and \\textit{post-processing}. We then perform extensive theoretical and empirical evaluations of state-of-the-art GIAs across diverse settings, utilizing eight datasets and thirteen models. Our findings indicate that GIAs have inherent limitations when reconstructing data under practical local training settings. Furthermore, their efficacy is sensitive to the trained model, and even simple post-processing measures applied to gradients can be effective defenses. Overall, our work provides crucial insights into the limited effectiveness of GIAs in practical FL systems. By rectifying prior misconceptions, we hope to inspire more accurate and realistic investigations on this topic.","sentences":["Federated learning (FL) enables collaborative model training among multiple clients without raw data exposure.","However, recent studies have shown that clients' private training data can be reconstructed from the gradients they share in FL, known as gradient inversion attacks (GIAs).","While GIAs have demonstrated effectiveness under \\emph{ideal settings and auxiliary assumptions}, their actual efficacy against \\emph{practical FL systems} remains under-explored.","To address this gap, we conduct a comprehensive study on GIAs in this work.","We start with a survey of GIAs that establishes a milestone to trace their evolution and develops a systematization to uncover their inherent threats.","Specifically, we categorize the auxiliary assumptions used by existing GIAs based on their practical accessibility to potential adversaries.","To facilitate deeper analysis, we highlight the challenges that GIAs face in practical FL systems from three perspectives: \\textit{local training}, \\textit{model}, and \\textit{post-processing}.","We then perform extensive theoretical and empirical evaluations of state-of-the-art GIAs across diverse settings, utilizing eight datasets and thirteen models.","Our findings indicate that GIAs have inherent limitations when reconstructing data under practical local training settings.","Furthermore, their efficacy is sensitive to the trained model, and even simple post-processing measures applied to gradients can be effective defenses.","Overall, our work provides crucial insights into the limited effectiveness of GIAs in practical FL systems.","By rectifying prior misconceptions, we hope to inspire more accurate and realistic investigations on this topic."],"url":"http://arxiv.org/abs/2404.05403v1"}
{"created":"2024-04-08 10:49:53","title":"MealRec$^+$: A Meal Recommendation Dataset with Meal-Course Affiliation for Personalization and Healthiness","abstract":"Meal recommendation, as a typical health-related recommendation task, contains complex relationships between users, courses, and meals. Among them, meal-course affiliation associates user-meal and user-course interactions. However, an extensive literature review demonstrates that there is a lack of publicly available meal recommendation datasets including meal-course affiliation. Meal recommendation research has been constrained in exploring the impact of cooperation between two levels of interaction on personalization and healthiness. To pave the way for meal recommendation research, we introduce a new benchmark dataset called MealRec$^+$. Due to constraints related to user health privacy and meal scenario characteristics, the collection of data that includes both meal-course affiliation and two levels of interactions is impeded. Therefore, a simulation method is adopted to derive meal-course affiliation and user-meal interaction from the user's dining sessions simulated based on user-course interaction data. Then, two well-known nutritional standards are used to calculate the healthiness scores of meals. Moreover, we experiment with several baseline models, including separate and cooperative interaction learning methods. Our experiment demonstrates that cooperating the two levels of interaction in appropriate ways is beneficial for meal recommendations. Furthermore, in response to the less healthy recommendation phenomenon found in the experiment, we explore methods to enhance the healthiness of meal recommendations. The dataset is available on GitHub (https://github.com/WUT-IDEA/MealRecPlus).","sentences":["Meal recommendation, as a typical health-related recommendation task, contains complex relationships between users, courses, and meals.","Among them, meal-course affiliation associates user-meal and user-course interactions.","However, an extensive literature review demonstrates that there is a lack of publicly available meal recommendation datasets including meal-course affiliation.","Meal recommendation research has been constrained in exploring the impact of cooperation between two levels of interaction on personalization and healthiness.","To pave the way for meal recommendation research, we introduce a new benchmark dataset called MealRec$^+$. Due to constraints related to user health privacy and meal scenario characteristics, the collection of data that includes both meal-course affiliation and two levels of interactions is impeded.","Therefore, a simulation method is adopted to derive meal-course affiliation and user-meal interaction from the user's dining sessions simulated based on user-course interaction data.","Then, two well-known nutritional standards are used to calculate the healthiness scores of meals.","Moreover, we experiment with several baseline models, including separate and cooperative interaction learning methods.","Our experiment demonstrates that cooperating the two levels of interaction in appropriate ways is beneficial for meal recommendations.","Furthermore, in response to the less healthy recommendation phenomenon found in the experiment, we explore methods to enhance the healthiness of meal recommendations.","The dataset is available on GitHub (https://github.com/WUT-IDEA/MealRecPlus)."],"url":"http://arxiv.org/abs/2404.05386v1"}
{"created":"2024-04-08 10:10:30","title":"Exploring Quantization and Mapping Synergy in Hardware-Aware Deep Neural Network Accelerators","abstract":"Energy efficiency and memory footprint of a convolutional neural network (CNN) implemented on a CNN inference accelerator depend on many factors, including a weight quantization strategy (i.e., data types and bit-widths) and mapping (i.e., placement and scheduling of DNN elementary operations on hardware units of the accelerator). We show that enabling rich mixed quantization schemes during the implementation can open a previously hidden space of mappings that utilize the hardware resources more effectively. CNNs utilizing quantized weights and activations and suitable mappings can significantly improve trade-offs among the accuracy, energy, and memory requirements compared to less carefully optimized CNN implementations. To find, analyze, and exploit these mappings, we: (i) extend a general-purpose state-of-the-art mapping tool (Timeloop) to support mixed quantization, which is not currently available; (ii) propose an efficient multi-objective optimization algorithm to find the most suitable bit-widths and mapping for each DNN layer executed on the accelerator; and (iii) conduct a detailed experimental evaluation to validate the proposed method. On two CNNs (MobileNetV1 and MobileNetV2) and two accelerators (Eyeriss and Simba) we show that for a given quality metric (such as the accuracy on ImageNet), energy savings are up to 37% without any accuracy drop.","sentences":["Energy efficiency and memory footprint of a convolutional neural network (CNN) implemented on a CNN inference accelerator depend on many factors, including a weight quantization strategy (i.e., data types and bit-widths) and mapping (i.e., placement and scheduling of DNN elementary operations on hardware units of the accelerator).","We show that enabling rich mixed quantization schemes during the implementation can open a previously hidden space of mappings that utilize the hardware resources more effectively.","CNNs utilizing quantized weights and activations and suitable mappings can significantly improve trade-offs among the accuracy, energy, and memory requirements compared to less carefully optimized CNN implementations.","To find, analyze, and exploit these mappings, we: (i) extend a general-purpose state-of-the-art mapping tool (Timeloop) to support mixed quantization, which is not currently available; (ii) propose an efficient multi-objective optimization algorithm to find the most suitable bit-widths and mapping for each DNN layer executed on the accelerator; and (iii) conduct a detailed experimental evaluation to validate the proposed method.","On two CNNs (MobileNetV1 and MobileNetV2) and two accelerators (Eyeriss and Simba) we show that for a given quality metric (such as the accuracy on ImageNet), energy savings are up to 37% without any accuracy drop."],"url":"http://arxiv.org/abs/2404.05368v1"}
{"created":"2024-04-08 10:05:24","title":"CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery","abstract":"In Generalized Category Discovery (GCD), we cluster unlabeled samples of known and novel classes, leveraging a training dataset of known classes. A salient challenge arises due to domain shifts between these datasets. To address this, we present a novel setting: Across Domain Generalized Category Discovery (AD-GCD) and bring forth CDAD-NET (Class Discoverer Across Domains) as a remedy. CDAD-NET is architected to synchronize potential known class samples across both the labeled (source) and unlabeled (target) datasets, while emphasizing the distinct categorization of the target data. To facilitate this, we propose an entropy-driven adversarial learning strategy that accounts for the distance distributions of target samples relative to source-domain class prototypes. Parallelly, the discriminative nature of the shared space is upheld through a fusion of three metric learning objectives. In the source domain, our focus is on refining the proximity between samples and their affiliated class prototypes, while in the target domain, we integrate a neighborhood-centric contrastive learning mechanism, enriched with an adept neighborsmining approach. To further accentuate the nuanced feature interrelation among semantically aligned images, we champion the concept of conditional image inpainting, underscoring the premise that semantically analogous images prove more efficacious to the task than their disjointed counterparts. Experimentally, CDAD-NET eclipses existing literature with a performance increment of 8-15% on three AD-GCD benchmarks we present.","sentences":["In Generalized Category Discovery (GCD), we cluster unlabeled samples of known and novel classes, leveraging a training dataset of known classes.","A salient challenge arises due to domain shifts between these datasets.","To address this, we present a novel setting:","Across Domain Generalized Category Discovery (AD-GCD) and bring forth CDAD-NET (Class Discoverer Across Domains) as a remedy.","CDAD-NET is architected to synchronize potential known class samples across both the labeled (source) and unlabeled (target) datasets, while emphasizing the distinct categorization of the target data.","To facilitate this, we propose an entropy-driven adversarial learning strategy that accounts for the distance distributions of target samples relative to source-domain class prototypes.","Parallelly, the discriminative nature of the shared space is upheld through a fusion of three metric learning objectives.","In the source domain, our focus is on refining the proximity between samples and their affiliated class prototypes, while in the target domain, we integrate a neighborhood-centric contrastive learning mechanism, enriched with an adept neighborsmining approach.","To further accentuate the nuanced feature interrelation among semantically aligned images, we champion the concept of conditional image inpainting, underscoring the premise that semantically analogous images prove more efficacious to the task than their disjointed counterparts.","Experimentally, CDAD-NET eclipses existing literature with a performance increment of 8-15% on three AD-GCD benchmarks we present."],"url":"http://arxiv.org/abs/2404.05366v1"}
{"created":"2024-04-08 09:53:42","title":"Optimal Controller Realizations against False Data Injections in Cooperative Driving","abstract":"To enhance the robustness of cooperative driving to cyberattacks, we study a controller-oriented approach to mitigate the effect of a class of False-Data Injection (FDI) attacks. By reformulating a given dynamic Cooperative Adaptive Cruise Control (CACC) scheme (the base controller), we recognize that the base controller can be represented by a class of new but equivalent controllers (base controller realizations) that exhibits the same platooning behavior with varying robustness in the presence of attacks. We propose a prescriptive synthesis framework where the base controller and the system dynamics are written in new coordinates via an invertible coordinate transformation on the controller state. Because the input-output behavior is invariant under coordinate transformations, the input-output behavior is unaffected (so controller realizations do not change the system's closed-loop performance). However, each base controller realization may require a different combination of sensors. To this end, we obtain the optimal combination of sensors that minimizes the effect of FDI attacks by solving a Linear Matrix Inequality (LMI), while quantifying the FDI's attack impact through reachability analysis. Through simulation studies, we demonstrate that this approach enhances the robustness of cooperative driving, without relying on a detection scheme and maintaining all system properties.","sentences":["To enhance the robustness of cooperative driving to cyberattacks, we study a controller-oriented approach to mitigate the effect of a class of False-Data Injection (FDI) attacks.","By reformulating a given dynamic Cooperative Adaptive Cruise Control (CACC) scheme (the base controller), we recognize that the base controller can be represented by a class of new but equivalent controllers (base controller realizations) that exhibits the same platooning behavior with varying robustness in the presence of attacks.","We propose a prescriptive synthesis framework where the base controller and the system dynamics are written in new coordinates via an invertible coordinate transformation on the controller state.","Because the input-output behavior is invariant under coordinate transformations, the input-output behavior is unaffected (so controller realizations do not change the system's closed-loop performance).","However, each base controller realization may require a different combination of sensors.","To this end, we obtain the optimal combination of sensors that minimizes the effect of FDI attacks by solving a Linear Matrix Inequality (LMI), while quantifying the FDI's attack impact through reachability analysis.","Through simulation studies, we demonstrate that this approach enhances the robustness of cooperative driving, without relying on a detection scheme and maintaining all system properties."],"url":"http://arxiv.org/abs/2404.05361v1"}
{"created":"2024-04-08 09:52:19","title":"Improving Algorithm-Selection and Performance-Prediction via Learning Discriminating Training Samples","abstract":"The choice of input-data used to train algorithm-selection models is recognised as being a critical part of the model success. Recently, feature-free methods for algorithm-selection that use short trajectories obtained from running a solver as input have shown promise. However, it is unclear to what extent these trajectories reliably discriminate between solvers. We propose a meta approach to generating discriminatory trajectories with respect to a portfolio of solvers. The algorithm-configuration tool irace is used to tune the parameters of a simple Simulated Annealing algorithm (SA) to produce trajectories that maximise the performance metrics of ML models trained on this data. We show that when the trajectories obtained from the tuned SA algorithm are used in ML models for algorithm-selection and performance prediction, we obtain significantly improved performance metrics compared to models trained both on raw trajectory data and on exploratory landscape features.","sentences":["The choice of input-data used to train algorithm-selection models is recognised as being a critical part of the model success.","Recently, feature-free methods for algorithm-selection that use short trajectories obtained from running a solver as input have shown promise.","However, it is unclear to what extent these trajectories reliably discriminate between solvers.","We propose a meta approach to generating discriminatory trajectories with respect to a portfolio of solvers.","The algorithm-configuration tool irace is used to tune the parameters of a simple Simulated Annealing algorithm (SA) to produce trajectories that maximise the performance metrics of ML models trained on this data.","We show that when the trajectories obtained from the tuned SA algorithm are used in ML models for algorithm-selection and performance prediction, we obtain significantly improved performance metrics compared to models trained both on raw trajectory data and on exploratory landscape features."],"url":"http://arxiv.org/abs/2404.05359v1"}
{"created":"2024-04-08 09:48:02","title":"CNN-based Game State Detection for a Foosball Table","abstract":"The automation of games using Deep Reinforcement Learning Strategies (DRL) is a well-known challenge in AI research. While for feature extraction in a video game typically the whole image is used, this is hardly practical for many real world games. Instead, using a smaller game state reducing the dimension of the parameter space to include essential parameters only seems to be a promising approach. In the game of Foosball, a compact and comprehensive game state description consists of the positional shifts and rotations of the figures and the position of the ball over time. In particular, velocities and accelerations can be derived from consecutive time samples of the game state. In this paper, a figure detection system to determine the game state in Foosball is presented. We capture a dataset containing the rotations of the rods which were measured using accelerometers and the positional shifts were derived using traditional Computer Vision techniques (in a laboratory setting). This dataset is utilized to train Convolutional Neural Network (CNN) based end-to-end regression models to predict the rotations and shifts of each rod. We present an evaluation of our system using different state-of-the-art CNNs as base architectures for the regression model. We show that our system is able to predict the game state with high accuracy. By providing data for both black and white teams, the presented system is intended to provide the required data for future developments of Imitation Learning techniques w.r.t. to observing human players.","sentences":["The automation of games using Deep Reinforcement Learning Strategies (DRL) is a well-known challenge in AI research.","While for feature extraction in a video game typically the whole image is used, this is hardly practical for many real world games.","Instead, using a smaller game state reducing the dimension of the parameter space to include essential parameters only seems to be a promising approach.","In the game of Foosball, a compact and comprehensive game state description consists of the positional shifts and rotations of the figures and the position of the ball over time.","In particular, velocities and accelerations can be derived from consecutive time samples of the game state.","In this paper, a figure detection system to determine the game state in Foosball is presented.","We capture a dataset containing the rotations of the rods which were measured using accelerometers and the positional shifts were derived using traditional Computer Vision techniques (in a laboratory setting).","This dataset is utilized to train Convolutional Neural Network (CNN) based end-to-end regression models to predict the rotations and shifts of each rod.","We present an evaluation of our system using different state-of-the-art CNNs as base architectures for the regression model.","We show that our system is able to predict the game state with high accuracy.","By providing data for both black and white teams, the presented system is intended to provide the required data for future developments of Imitation Learning techniques w.r.t. to observing human players."],"url":"http://arxiv.org/abs/2404.05357v1"}
{"created":"2024-04-08 09:38:22","title":"Certified PEFTSmoothing: Parameter-Efficient Fine-Tuning with Randomized Smoothing","abstract":"Randomized smoothing is the primary certified robustness method for accessing the robustness of deep learning models to adversarial perturbations in the l2-norm, by adding isotropic Gaussian noise to the input image and returning the majority votes over the base classifier. Theoretically, it provides a certified norm bound, ensuring predictions of adversarial examples are stable within this bound. A notable constraint limiting widespread adoption is the necessity to retrain base models entirely from scratch to attain a robust version. This is because the base model fails to learn the noise-augmented data distribution to give an accurate vote. One intuitive way to overcome this challenge is to involve a custom-trained denoiser to eliminate the noise. However, this approach is inefficient and sub-optimal. Inspired by recent large model training procedures, we explore an alternative way named PEFTSmoothing to adapt the base model to learn the Gaussian noise-augmented data with Parameter-Efficient Fine-Tuning (PEFT) methods in both white-box and black-box settings. Extensive results demonstrate the effectiveness and efficiency of PEFTSmoothing, which allow us to certify over 98% accuracy for ViT on CIFAR-10, 20% higher than SoTA denoised smoothing, and over 61% accuracy on ImageNet which is 30% higher than CNN-based denoiser and comparable to the Diffusion-based denoiser.","sentences":["Randomized smoothing is the primary certified robustness method for accessing the robustness of deep learning models to adversarial perturbations in the l2-norm, by adding isotropic Gaussian noise to the input image and returning the majority votes over the base classifier.","Theoretically, it provides a certified norm bound, ensuring predictions of adversarial examples are stable within this bound.","A notable constraint limiting widespread adoption is the necessity to retrain base models entirely from scratch to attain a robust version.","This is because the base model fails to learn the noise-augmented data distribution to give an accurate vote.","One intuitive way to overcome this challenge is to involve a custom-trained denoiser to eliminate the noise.","However, this approach is inefficient and sub-optimal.","Inspired by recent large model training procedures, we explore an alternative way named PEFTSmoothing to adapt the base model to learn the Gaussian noise-augmented data with Parameter-Efficient Fine-Tuning (PEFT) methods in both white-box and black-box settings.","Extensive results demonstrate the effectiveness and efficiency of PEFTSmoothing, which allow us to certify over 98% accuracy for ViT on CIFAR-10, 20% higher than SoTA denoised smoothing, and over 61% accuracy on ImageNet which is 30% higher than CNN-based denoiser and comparable to the Diffusion-based denoiser."],"url":"http://arxiv.org/abs/2404.05350v1"}
{"created":"2024-04-08 09:33:40","title":"Iterative Refinement Strategy for Automated Data Labeling: Facial Landmark Diagnosis in Medical Imaging","abstract":"Automated data labeling techniques are crucial for accelerating the development of deep learning models, particularly in complex medical imaging applications. However, ensuring accuracy and efficiency remains challenging. This paper presents iterative refinement strategies for automated data labeling in facial landmark diagnosis to enhance accuracy and efficiency for deep learning models in medical applications, including dermatology, plastic surgery, and ophthalmology. Leveraging feedback mechanisms and advanced algorithms, our approach iteratively refines initial labels, reducing reliance on manual intervention while improving label quality. Through empirical evaluation and case studies, we demonstrate the effectiveness of our proposed strategies in deep learning tasks across medical imaging domains. Our results highlight the importance of iterative refinement in automated data labeling to enhance the capabilities of deep learning systems in medical imaging applications.","sentences":["Automated data labeling techniques are crucial for accelerating the development of deep learning models, particularly in complex medical imaging applications.","However, ensuring accuracy and efficiency remains challenging.","This paper presents iterative refinement strategies for automated data labeling in facial landmark diagnosis to enhance accuracy and efficiency for deep learning models in medical applications, including dermatology, plastic surgery, and ophthalmology.","Leveraging feedback mechanisms and advanced algorithms, our approach iteratively refines initial labels, reducing reliance on manual intervention while improving label quality.","Through empirical evaluation and case studies, we demonstrate the effectiveness of our proposed strategies in deep learning tasks across medical imaging domains.","Our results highlight the importance of iterative refinement in automated data labeling to enhance the capabilities of deep learning systems in medical imaging applications."],"url":"http://arxiv.org/abs/2404.05348v1"}
{"created":"2024-04-08 09:31:59","title":"The role of non-scientific factors vis-a-vis the quality of publications in determining their scholarly impact","abstract":"In the evaluation of scientific publications' impact, the interplay between intrinsic quality and non-scientific factors remains a subject of debate. While peer review traditionally assesses quality, bibliometric techniques gauge scholarly impact. This study investigates the role of non-scientific attributes alongside quality scores from peer review in determining scholarly impact. Leveraging data from the first Italian Research Assessment Exercise (VTR 2001-2003) and Web of Science citations, we analyse the relationship between quality scores, non-scientific factors, and publication short- and long-term impact. Our findings shed light on the significance of non-scientific elements overlooked in peer review, offering policymakers and research management insights in choosing evaluation methodologies. Sections delve into the debate, identify non-scientific influences, detail methodologies, present results, and discuss implications.","sentences":["In the evaluation of scientific publications' impact, the interplay between intrinsic quality and non-scientific factors remains a subject of debate.","While peer review traditionally assesses quality, bibliometric techniques gauge scholarly impact.","This study investigates the role of non-scientific attributes alongside quality scores from peer review in determining scholarly impact.","Leveraging data from the first Italian Research Assessment Exercise (VTR 2001-2003) and Web of Science citations, we analyse the relationship between quality scores, non-scientific factors, and publication short- and long-term impact.","Our findings shed light on the significance of non-scientific elements overlooked in peer review, offering policymakers and research management insights in choosing evaluation methodologies.","Sections delve into the debate, identify non-scientific influences, detail methodologies, present results, and discuss implications."],"url":"http://arxiv.org/abs/2404.05345v1"}
{"created":"2024-04-08 09:26:31","title":"GPS-free Autonomous Navigation in Cluttered Tree Rows with Deep Semantic Segmentation","abstract":"Segmentation-based autonomous navigation has recently been presented as an appealing approach to guiding robotic platforms through crop rows without requiring perfect GPS localization. Nevertheless, current techniques are restricted to situations where the distinct separation between the plants and the sky allows for the identification of the row's center. However, tall, dense vegetation, such as high tree rows and orchards, is the primary cause of GPS signal blockage. In this study, we increase the overall robustness and adaptability of the control algorithm by extending the segmentation-based robotic guiding to those cases where canopies and branches occlude the sky and prevent the utilization of GPS and earlier approaches. An efficient Deep Neural Network architecture has been used to address semantic segmentation, performing the training with synthetic data only. Numerous vineyards and tree fields have undergone extensive testing in both simulation and real-world to show the solution's competitive benefits.","sentences":["Segmentation-based autonomous navigation has recently been presented as an appealing approach to guiding robotic platforms through crop rows without requiring perfect GPS localization.","Nevertheless, current techniques are restricted to situations where the distinct separation between the plants and the sky allows for the identification of the row's center.","However, tall, dense vegetation, such as high tree rows and orchards, is the primary cause of GPS signal blockage.","In this study, we increase the overall robustness and adaptability of the control algorithm by extending the segmentation-based robotic guiding to those cases where canopies and branches occlude the sky and prevent the utilization of GPS and earlier approaches.","An efficient Deep Neural Network architecture has been used to address semantic segmentation, performing the training with synthetic data only.","Numerous vineyards and tree fields have undergone extensive testing in both simulation and real-world to show the solution's competitive benefits."],"url":"http://arxiv.org/abs/2404.05338v1"}
{"created":"2024-04-08 09:13:16","title":"Back to the Future: GNN-based NO$_2$ Forecasting via Future Covariates","abstract":"Due to the latest environmental concerns in keeping at bay contaminants emissions in urban areas, air pollution forecasting has been rising the forefront of all researchers around the world. When predicting pollutant concentrations, it is common to include the effects of environmental factors that influence these concentrations within an extended period, like traffic, meteorological conditions and geographical information. Most of the existing approaches exploit this information as past covariates, i.e., past exogenous variables that affected the pollutant but were not affected by it. In this paper, we present a novel forecasting methodology to predict NO$_2$ concentration via both past and future covariates. Future covariates are represented by weather forecasts and future calendar events, which are already known at prediction time. In particular, we deal with air quality observations in a city-wide network of ground monitoring stations, modeling the data structure and estimating the predictions with a Spatiotemporal Graph Neural Network (STGNN). We propose a conditioning block that embeds past and future covariates into the current observations. After extracting meaningful spatiotemporal representations, these are fused together and projected into the forecasting horizon to generate the final prediction. To the best of our knowledge, it is the first time that future covariates are included in time series predictions in a structured way. Remarkably, we find that conditioning on future weather information has a greater impact than considering past traffic conditions. We release our code implementation at https://github.com/polimi-ispl/MAGCRN.","sentences":["Due to the latest environmental concerns in keeping at bay contaminants emissions in urban areas, air pollution forecasting has been rising the forefront of all researchers around the world.","When predicting pollutant concentrations, it is common to include the effects of environmental factors that influence these concentrations within an extended period, like traffic, meteorological conditions and geographical information.","Most of the existing approaches exploit this information as past covariates, i.e., past exogenous variables that affected the pollutant but were not affected by it.","In this paper, we present a novel forecasting methodology to predict NO$_2$ concentration via both past and future covariates.","Future covariates are represented by weather forecasts and future calendar events, which are already known at prediction time.","In particular, we deal with air quality observations in a city-wide network of ground monitoring stations, modeling the data structure and estimating the predictions with a Spatiotemporal Graph Neural Network (STGNN).","We propose a conditioning block that embeds past and future covariates into the current observations.","After extracting meaningful spatiotemporal representations, these are fused together and projected into the forecasting horizon to generate the final prediction.","To the best of our knowledge, it is the first time that future covariates are included in time series predictions in a structured way.","Remarkably, we find that conditioning on future weather information has a greater impact than considering past traffic conditions.","We release our code implementation at https://github.com/polimi-ispl/MAGCRN."],"url":"http://arxiv.org/abs/2404.05324v1"}
{"created":"2024-04-08 09:10:02","title":"Reflected Search Poisoning for Illicit Promotion","abstract":"As an emerging black hat search engine optimization (SEO) technique, reflected search poisoning (RSP) allows a miscreant to free-ride the reputation of high-ranking websites, poisoning search engines with illicit promotion texts (IPTs) in an efficient and stealthy manner, while avoiding the burden of continuous website compromise as required by traditional promotion infections. However, little is known about the security implications of RSP, e.g., what illicit promotion campaigns are being distributed by RSP, and to what extent regular search users can be exposed to illicit promotion texts distributed by RSP. In this study, we conduct the first security study on RSP-based illicit promotion, which is made possible through an end-to-end methodology for capturing, analyzing, and infiltrating IPTs. As a result, IPTs distributed via RSP are found to be large-scale, continuously growing, and diverse in both illicit categories and natural languages. Particularly, we have identified over 11 million distinct IPTs belonging to 14 different illicit categories, with typical examples including drug trading, data theft, counterfeit goods, and hacking services. Also, the underlying RSP cases have abused tens of thousands of high-ranking websites, as well as extensively poisoning all four popular search engines we studied, especially Google Search and Bing. Furthermore, it is observed that benign search users are being exposed to IPTs at a concerning extent. To facilitate interaction with potential customers (victim search users), miscreants tend to embed various types of contacts in IPTs, especially instant messaging accounts. Further infiltration of these IPT contacts reveals that the underlying illicit campaigns are operated on a large scale. All these findings highlight the negative security implications of IPTs and RSPs, and thus call for more efforts to mitigate RSP-driven illicit promotion.","sentences":["As an emerging black hat search engine optimization (SEO) technique, reflected search poisoning (RSP) allows a miscreant to free-ride the reputation of high-ranking websites, poisoning search engines with illicit promotion texts (IPTs) in an efficient and stealthy manner, while avoiding the burden of continuous website compromise as required by traditional promotion infections.","However, little is known about the security implications of RSP, e.g., what illicit promotion campaigns are being distributed by RSP, and to what extent regular search users can be exposed to illicit promotion texts distributed by RSP.","In this study, we conduct the first security study on RSP-based illicit promotion, which is made possible through an end-to-end methodology for capturing, analyzing, and infiltrating IPTs.","As a result, IPTs distributed via RSP are found to be large-scale, continuously growing, and diverse in both illicit categories and natural languages.","Particularly, we have identified over 11 million distinct IPTs belonging to 14 different illicit categories, with typical examples including drug trading, data theft, counterfeit goods, and hacking services.","Also, the underlying RSP cases have abused tens of thousands of high-ranking websites, as well as extensively poisoning all four popular search engines we studied, especially Google Search and Bing.","Furthermore, it is observed that benign search users are being exposed to IPTs at a concerning extent.","To facilitate interaction with potential customers (victim search users), miscreants tend to embed various types of contacts in IPTs, especially instant messaging accounts.","Further infiltration of these IPT contacts reveals that the underlying illicit campaigns are operated on a large scale.","All these findings highlight the negative security implications of IPTs and RSPs, and thus call for more efforts to mitigate RSP-driven illicit promotion."],"url":"http://arxiv.org/abs/2404.05320v1"}
{"created":"2024-04-08 09:06:16","title":"HOEG: A New Approach for Object-Centric Predictive Process Monitoring","abstract":"Predictive Process Monitoring focuses on predicting future states of ongoing process executions, such as forecasting the remaining time. Recent developments in Object-Centric Process Mining have enriched event data with objects and their explicit relations between events. To leverage this enriched data, we propose the Heterogeneous Object Event Graph encoding (HOEG), which integrates events and objects into a graph structure with diverse node types. It does so without aggregating object features, thus creating a more nuanced and informative representation. We then adopt a heterogeneous Graph Neural Network architecture, which incorporates these diverse object features in prediction tasks. We evaluate the performance and scalability of HOEG in predicting remaining time, benchmarking it against two established graph-based encodings and two baseline models. Our evaluation uses three Object-Centric Event Logs (OCELs), including one from a real-life process at a major Dutch financial institution. The results indicate that HOEG competes well with existing models and surpasses them when OCELs contain informative object attributes and event-object interactions.","sentences":["Predictive Process Monitoring focuses on predicting future states of ongoing process executions, such as forecasting the remaining time.","Recent developments in Object-Centric Process Mining have enriched event data with objects and their explicit relations between events.","To leverage this enriched data, we propose the Heterogeneous Object Event Graph encoding (HOEG), which integrates events and objects into a graph structure with diverse node types.","It does so without aggregating object features, thus creating a more nuanced and informative representation.","We then adopt a heterogeneous Graph Neural Network architecture, which incorporates these diverse object features in prediction tasks.","We evaluate the performance and scalability of HOEG in predicting remaining time, benchmarking it against two established graph-based encodings and two baseline models.","Our evaluation uses three Object-Centric Event Logs (OCELs), including one from a real-life process at a major Dutch financial institution.","The results indicate that HOEG competes well with existing models and surpasses them when OCELs contain informative object attributes and event-object interactions."],"url":"http://arxiv.org/abs/2404.05316v1"}
{"created":"2024-04-08 08:57:32","title":"CLIPping the Limits: Finding the Sweet Spot for Relevant Images in Automated Driving Systems Perception Testing","abstract":"Perception systems, especially cameras, are the eyes of automated driving systems. Ensuring that they function reliably and robustly is therefore an important building block in the automation of vehicles. There are various approaches to test the perception of automated driving systems. Ultimately, however, it always comes down to the investigation of the behavior of perception systems under specific input data. Camera images are a crucial part of the input data. Image data sets are therefore collected for the testing of automated driving systems, but it is non-trivial to find specific images in these data sets. Thanks to recent developments in neural networks, there are now methods for sorting the images in a data set according to their similarity to a prompt in natural language. In order to further automate the provision of search results, we make a contribution by automating the threshold definition in these sorted results and returning only the images relevant to the prompt as a result. Our focus is on preventing false positives and false negatives equally. It is also important that our method is robust and in the case that our assumptions are not fulfilled, we provide a fallback solution.","sentences":["Perception systems, especially cameras, are the eyes of automated driving systems.","Ensuring that they function reliably and robustly is therefore an important building block in the automation of vehicles.","There are various approaches to test the perception of automated driving systems.","Ultimately, however, it always comes down to the investigation of the behavior of perception systems under specific input data.","Camera images are a crucial part of the input data.","Image data sets are therefore collected for the testing of automated driving systems, but it is non-trivial to find specific images in these data sets.","Thanks to recent developments in neural networks, there are now methods for sorting the images in a data set according to their similarity to a prompt in natural language.","In order to further automate the provision of search results, we make a contribution by automating the threshold definition in these sorted results and returning only the images relevant to the prompt as a result.","Our focus is on preventing false positives and false negatives equally.","It is also important that our method is robust and in the case that our assumptions are not fulfilled, we provide a fallback solution."],"url":"http://arxiv.org/abs/2404.05309v1"}
{"created":"2024-04-08 08:53:54","title":"Human Detection from 4D Radar Data in Low-Visibility Field Conditions","abstract":"Autonomous driving technology is increasingly being used on public roads and in industrial settings such as mines. While it is essential to detect pedestrians, vehicles, or other obstacles, adverse field conditions negatively affect the performance of classical sensors such as cameras or lidars. Radar, on the other hand, is a promising modality that is less affected by, e.g., dust, smoke, water mist or fog. In particular, modern 4D imaging radars provide target responses across the range, vertical angle, horizontal angle and Doppler velocity dimensions. We propose TMVA4D, a CNN architecture that leverages this 4D radar modality for semantic segmentation. The CNN is trained to distinguish between the background and person classes based on a series of 2D projections of the 4D radar data that include the elevation, azimuth, range, and Doppler velocity dimensions. We also outline the process of compiling a novel dataset consisting of data collected in industrial settings with a car-mounted 4D radar and describe how the ground-truth labels were generated from reference thermal images. Using TMVA4D on this dataset, we achieve an mIoU score of 78.2% and an mDice score of 86.1%, evaluated on the two classes background and person","sentences":["Autonomous driving technology is increasingly being used on public roads and in industrial settings such as mines.","While it is essential to detect pedestrians, vehicles, or other obstacles, adverse field conditions negatively affect the performance of classical sensors such as cameras or lidars.","Radar, on the other hand, is a promising modality that is less affected by, e.g., dust, smoke, water mist or fog.","In particular, modern 4D imaging radars provide target responses across the range, vertical angle, horizontal angle and Doppler velocity dimensions.","We propose TMVA4D, a CNN architecture that leverages this 4D radar modality for semantic segmentation.","The CNN is trained to distinguish between the background and person classes based on a series of 2D projections of the 4D radar data that include the elevation, azimuth, range, and Doppler velocity dimensions.","We also outline the process of compiling a novel dataset consisting of data collected in industrial settings with a car-mounted 4D radar and describe how the ground-truth labels were generated from reference thermal images.","Using TMVA4D on this dataset, we achieve an mIoU score of 78.2% and an mDice score of 86.1%, evaluated on the two classes background and person"],"url":"http://arxiv.org/abs/2404.05307v1"}
{"created":"2024-04-08 08:47:46","title":"Liquid Neural Network-based Adaptive Learning vs. Incremental Learning for Link Load Prediction amid Concept Drift due to Network Failures","abstract":"Adapting to concept drift is a challenging task in machine learning, which is usually tackled using incremental learning techniques that periodically re-fit a learning model leveraging newly available data. A primary limitation of these techniques is their reliance on substantial amounts of data for retraining. The necessity of acquiring fresh data introduces temporal delays prior to retraining, potentially rendering the models inaccurate if a sudden concept drift occurs in-between two consecutive retrainings. In communication networks, such issue emerges when performing traffic forecasting following a~failure event: post-failure re-routing may induce a drastic shift in distribution and pattern of traffic data, thus requiring a timely model adaptation. In this work, we address this challenge for the problem of traffic forecasting and propose an approach that exploits adaptive learning algorithms, namely, liquid neural networks, which are capable of self-adaptation to abrupt changes in data patterns without requiring any retraining. Through extensive simulations of failure scenarios, we compare the predictive performance of our proposed approach to that of a reference method based on incremental learning. Experimental results show that our proposed approach outperforms incremental learning-based methods in situations where the shifts in traffic patterns are drastic.","sentences":["Adapting to concept drift is a challenging task in machine learning, which is usually tackled using incremental learning techniques that periodically re-fit a learning model leveraging newly available data.","A primary limitation of these techniques is their reliance on substantial amounts of data for retraining.","The necessity of acquiring fresh data introduces temporal delays prior to retraining, potentially rendering the models inaccurate if a sudden concept drift occurs in-between two consecutive retrainings.","In communication networks, such issue emerges when performing traffic forecasting following a~failure event: post-failure re-routing may induce a drastic shift in distribution and pattern of traffic data, thus requiring a timely model adaptation.","In this work, we address this challenge for the problem of traffic forecasting and propose an approach that exploits adaptive learning algorithms, namely, liquid neural networks, which are capable of self-adaptation to abrupt changes in data patterns without requiring any retraining.","Through extensive simulations of failure scenarios, we compare the predictive performance of our proposed approach to that of a reference method based on incremental learning.","Experimental results show that our proposed approach outperforms incremental learning-based methods in situations where the shifts in traffic patterns are drastic."],"url":"http://arxiv.org/abs/2404.05304v1"}
{"created":"2024-04-08 08:32:39","title":"Online Learning of Joint-Muscle Mapping Using Vision in Tendon-driven Musculoskeletal Humanoids","abstract":"The body structures of tendon-driven musculoskeletal humanoids are complex, and accurate modeling is difficult, because they are made by imitating the body structures of human beings. For this reason, we have not been able to move them accurately like ordinary humanoids driven by actuators in each axis, and large internal muscle tension and slack of tendon wires have emerged by the model error between its geometric model and the actual robot. Therefore, we construct a joint-muscle mapping (JMM) using a neural network (NN), which expresses a nonlinear relationship between joint angles and muscle lengths, and aim to move tendon-driven musculoskeletal humanoids accurately by updating the JMM online from data of the actual robot. In this study, the JMM is updated online by using the vision of the robot so that it moves to the correct position (Vision Updater). Also, we execute another update to modify muscle antagonisms correctly (Antagonism Updater). By using these two updaters, the error between the target and actual joint angles decrease to about 40% in 5 minutes, and we show through a manipulation experiment that the tendon-driven musculoskeletal humanoid Kengoro becomes able to move as intended. This novel system can adapt to the state change and growth of robots, because it updates the JMM online successively.","sentences":["The body structures of tendon-driven musculoskeletal humanoids are complex, and accurate modeling is difficult, because they are made by imitating the body structures of human beings.","For this reason, we have not been able to move them accurately like ordinary humanoids driven by actuators in each axis, and large internal muscle tension and slack of tendon wires have emerged by the model error between its geometric model and the actual robot.","Therefore, we construct a joint-muscle mapping (JMM) using a neural network (NN), which expresses a nonlinear relationship between joint angles and muscle lengths, and aim to move tendon-driven musculoskeletal humanoids accurately by updating the JMM online from data of the actual robot.","In this study, the JMM is updated online by using the vision of the robot so that it moves to the correct position (Vision Updater).","Also, we execute another update to modify muscle antagonisms correctly (Antagonism Updater).","By using these two updaters, the error between the target and actual joint angles decrease to about 40% in 5 minutes, and we show through a manipulation experiment that the tendon-driven musculoskeletal humanoid Kengoro becomes able to move as intended.","This novel system can adapt to the state change and growth of robots, because it updates the JMM online successively."],"url":"http://arxiv.org/abs/2404.05295v1"}
{"created":"2024-04-08 08:13:40","title":"Multi-Task Learning for Features Extraction in Financial Annual Reports","abstract":"For assessing various performance indicators of companies, the focus is shifting from strictly financial (quantitative) publicly disclosed information to qualitative (textual) information. This textual data can provide valuable weak signals, for example through stylistic features, which can complement the quantitative data on financial performance or on Environmental, Social and Governance (ESG) criteria. In this work, we use various multi-task learning methods for financial text classification with the focus on financial sentiment, objectivity, forward-looking sentence prediction and ESG-content detection. We propose different methods to combine the information extracted from training jointly on different tasks; our best-performing method highlights the positive effect of explicitly adding auxiliary task predictions as features for the final target task during the multi-task training. Next, we use these classifiers to extract textual features from annual reports of FTSE350 companies and investigate the link between ESG quantitative scores and these features.","sentences":["For assessing various performance indicators of companies, the focus is shifting from strictly financial (quantitative) publicly disclosed information to qualitative (textual) information.","This textual data can provide valuable weak signals, for example through stylistic features, which can complement the quantitative data on financial performance or on Environmental, Social and Governance (ESG) criteria.","In this work, we use various multi-task learning methods for financial text classification with the focus on financial sentiment, objectivity, forward-looking sentence prediction and ESG-content detection.","We propose different methods to combine the information extracted from training jointly on different tasks; our best-performing method highlights the positive effect of explicitly adding auxiliary task predictions as features for the final target task during the multi-task training.","Next, we use these classifiers to extract textual features from annual reports of FTSE350 companies and investigate the link between ESG quantitative scores and these features."],"url":"http://arxiv.org/abs/2404.05281v1"}
{"created":"2024-04-08 08:11:07","title":"Coherent transceiver architecture enabling data transmission and optical identification","abstract":"We propose a coherent transceiver architecture able to transmit information and enhance the security of the optical network by identifying other optical systems and subsystems. Simulations show that identification is obtained with sufficient reliability in standard operating conditions.","sentences":["We propose a coherent transceiver architecture able to transmit information and enhance the security of the optical network by identifying other optical systems and subsystems.","Simulations show that identification is obtained with sufficient reliability in standard operating conditions."],"url":"http://arxiv.org/abs/2404.05278v1"}
{"created":"2024-04-08 08:04:44","title":"Deep Optics for Video Snapshot Compressive Imaging","abstract":"Video snapshot compressive imaging (SCI) aims to capture a sequence of video frames with only a single shot of a 2D detector, whose backbones rest in optical modulation patterns (also known as masks) and a computational reconstruction algorithm. Advanced deep learning algorithms and mature hardware are putting video SCI into practical applications. Yet, there are two clouds in the sunshine of SCI: i) low dynamic range as a victim of high temporal multiplexing, and ii) existing deep learning algorithms' degradation on real system. To address these challenges, this paper presents a deep optics framework to jointly optimize masks and a reconstruction network. Specifically, we first propose a new type of structural mask to realize motion-aware and full-dynamic-range measurement. Considering the motion awareness property in measurement domain, we develop an efficient network for video SCI reconstruction using Transformer to capture long-term temporal dependencies, dubbed Res2former. Moreover, sensor response is introduced into the forward model of video SCI to guarantee end-to-end model training close to real system. Finally, we implement the learned structural masks on a digital micro-mirror device. Experimental results on synthetic and real data validate the effectiveness of the proposed framework. We believe this is a milestone for real-world video SCI. The source code and data are available at https://github.com/pwangcs/DeepOpticsSCI.","sentences":["Video snapshot compressive imaging (SCI) aims to capture a sequence of video frames with only a single shot of a 2D detector, whose backbones rest in optical modulation patterns (also known as masks) and a computational reconstruction algorithm.","Advanced deep learning algorithms and mature hardware are putting video SCI into practical applications.","Yet, there are two clouds in the sunshine of SCI: i) low dynamic range as a victim of high temporal multiplexing, and ii) existing deep learning algorithms' degradation on real system.","To address these challenges, this paper presents a deep optics framework to jointly optimize masks and a reconstruction network.","Specifically, we first propose a new type of structural mask to realize motion-aware and full-dynamic-range measurement.","Considering the motion awareness property in measurement domain, we develop an efficient network for video SCI reconstruction using Transformer to capture long-term temporal dependencies, dubbed Res2former.","Moreover, sensor response is introduced into the forward model of video SCI to guarantee end-to-end model training close to real system.","Finally, we implement the learned structural masks on a digital micro-mirror device.","Experimental results on synthetic and real data validate the effectiveness of the proposed framework.","We believe this is a milestone for real-world video SCI.","The source code and data are available at https://github.com/pwangcs/DeepOpticsSCI."],"url":"http://arxiv.org/abs/2404.05274v1"}
{"created":"2024-04-08 08:02:18","title":"Constructing Data Transaction Chains Based on Opportunity Cost Exploration","abstract":"Data trading is increasingly gaining attention. However, the inherent replicability and privacy concerns of data make it challenging to directly apply traditional trading theories to data markets. This paper compares data trading markets with traditional ones, focusing particularly on how the replicability and privacy of data impact data markets. We discuss how data's replicability fundamentally alters the concept of opportunity cost in traditional microeconomics within the context of data markets. Additionally, we explore how to leverage this change to maximize benefits without compromising data privacy. This paper outlines the constraints for data circulation within the privacy domain chain and presents a model that maximizes data's value under these constraints. Specific application scenarios are provided, and experiments demonstrate the solvability of this model.","sentences":["Data trading is increasingly gaining attention.","However, the inherent replicability and privacy concerns of data make it challenging to directly apply traditional trading theories to data markets.","This paper compares data trading markets with traditional ones, focusing particularly on how the replicability and privacy of data impact data markets.","We discuss how data's replicability fundamentally alters the concept of opportunity cost in traditional microeconomics within the context of data markets.","Additionally, we explore how to leverage this change to maximize benefits without compromising data privacy.","This paper outlines the constraints for data circulation within the privacy domain chain and presents a model that maximizes data's value under these constraints.","Specific application scenarios are provided, and experiments demonstrate the solvability of this model."],"url":"http://arxiv.org/abs/2404.05272v1"}
{"created":"2024-04-08 08:01:19","title":"Scheduling Multi-Server Jobs is Not Easy","abstract":"The problem of online scheduling of multi-server jobs is considered, where there are a total of $K$ servers, and each job requires concurrent service from multiple servers for it to be processed. Each job on its arrival reveals its processing time, the number of servers from which it needs concurrent service and an online algorithm has to make scheduling decisions using only causal information, with the goal of minimizing the response/flow time. The worst case input model is considered and the performance metric is the competitive ratio. For the case, when all job processing time (sizes) are the same, we show that the competitive ratio of any deterministic/randomized algorithm is at least $\\Omega(K)$ and propose an online algorithm whose competitive ratio is at most $K+1$. With equal job sizes, we also consider the resource augmentation regime where an online algorithm has access to more servers than an optimal offline algorithm. With resource augmentation, we propose a simple algorithm and show that it has a competitive ratio of $1$ when provided with $2K$ servers with respect to an optimal offline algorithm with $K$ servers. With unequal job sizes, we propose an online algorithm whose competitive ratio is at most $2K \\log (K w_{\\max})$, where $w_{\\max}$ is the maximum size of any job.","sentences":["The problem of online scheduling of multi-server jobs is considered, where there are a total of $K$ servers, and each job requires concurrent service from multiple servers for it to be processed.","Each job on its arrival reveals its processing time, the number of servers from which it needs concurrent service and an online algorithm has to make scheduling decisions using only causal information, with the goal of minimizing the response/flow time.","The worst case input model is considered and the performance metric is the competitive ratio.","For the case, when all job processing time (sizes) are the same, we show that the competitive ratio of any deterministic/randomized algorithm is at least $\\Omega(K)$ and propose an online algorithm whose competitive ratio is at most $K+1$. With equal job sizes, we also consider the resource augmentation regime where an online algorithm has access to more servers than an optimal offline algorithm.","With resource augmentation, we propose a simple algorithm and show that it has a competitive ratio of $1$ when provided with $2K$ servers with respect to an optimal offline algorithm with $K$ servers.","With unequal job sizes, we propose an online algorithm whose competitive ratio is at most $2K \\log (K w_{\\max})$, where $w_{\\max}$ is the maximum size of any job."],"url":"http://arxiv.org/abs/2404.05271v1"}
{"created":"2024-04-08 07:47:28","title":"Unsupervised Band Selection Using Fused HSI and LiDAR Attention Integrating With Autoencoder","abstract":"Band selection in hyperspectral imaging (HSI) is critical for optimising data processing and enhancing analytical accuracy. Traditional approaches have predominantly concentrated on analysing spectral and pixel characteristics within individual bands independently. These approaches overlook the potential benefits of integrating multiple data sources, such as Light Detection and Ranging (LiDAR), and is further challenged by the limited availability of labeled data in HSI processing, which represents a significant obstacle. To address these challenges, this paper introduces a novel unsupervised band selection framework that incorporates attention mechanisms and an Autoencoder for reconstruction-based band selection. Our methodology distinctively integrates HSI with LiDAR data through an attention score, using a convolutional Autoencoder to process the combined feature mask. This fusion effectively captures essential spatial and spectral features and reduces redundancy in hyperspectral datasets. A comprehensive comparative analysis of our innovative fused band selection approach is performed against existing unsupervised band selection and fusion models. We used data sets such as Houston 2013, Trento, and MUUFLE for our experiments. The results demonstrate that our method achieves superior classification accuracy and significantly outperforms existing models. This enhancement in HSI band selection, facilitated by the incorporation of LiDAR features, underscores the considerable advantages of integrating features from different sources.","sentences":["Band selection in hyperspectral imaging (HSI) is critical for optimising data processing and enhancing analytical accuracy.","Traditional approaches have predominantly concentrated on analysing spectral and pixel characteristics within individual bands independently.","These approaches overlook the potential benefits of integrating multiple data sources, such as Light Detection and Ranging (LiDAR), and is further challenged by the limited availability of labeled data in HSI processing, which represents a significant obstacle.","To address these challenges, this paper introduces a novel unsupervised band selection framework that incorporates attention mechanisms and an Autoencoder for reconstruction-based band selection.","Our methodology distinctively integrates HSI with LiDAR data through an attention score, using a convolutional Autoencoder to process the combined feature mask.","This fusion effectively captures essential spatial and spectral features and reduces redundancy in hyperspectral datasets.","A comprehensive comparative analysis of our innovative fused band selection approach is performed against existing unsupervised band selection and fusion models.","We used data sets such as Houston 2013, Trento, and MUUFLE for our experiments.","The results demonstrate that our method achieves superior classification accuracy and significantly outperforms existing models.","This enhancement in HSI band selection, facilitated by the incorporation of LiDAR features, underscores the considerable advantages of integrating features from different sources."],"url":"http://arxiv.org/abs/2404.05258v1"}
{"created":"2024-04-08 07:25:25","title":"SAFE-GIL: SAFEty Guided Imitation Learning","abstract":"Behavior Cloning is a popular approach to Imitation Learning, in which a robot observes an expert supervisor and learns a control policy. However, behavior cloning suffers from the \"compounding error\" problem - the policy errors compound as it deviates from the expert demonstrations and might lead to catastrophic system failures, limiting its use in safety-critical applications. On-policy data aggregation methods are able to address this issue at the cost of rolling out and repeated training of the imitation policy, which can be tedious and computationally prohibitive. We propose SAFE-GIL, an off-policy behavior cloning method that guides the expert via adversarial disturbance during data collection. The algorithm abstracts the imitation error as an adversarial disturbance in the system dynamics, injects it during data collection to expose the expert to safety critical states, and collects corrective actions. Our method biases training to more closely replicate expert behavior in safety-critical states and allows more variance in less critical states. We compare our method with several behavior cloning techniques and DAgger on autonomous navigation and autonomous taxiing tasks and show higher task success and safety, especially in low data regimes where the likelihood of error is higher, at a slight drop in the performance.","sentences":["Behavior Cloning is a popular approach to Imitation Learning, in which a robot observes an expert supervisor and learns a control policy.","However, behavior cloning suffers from the \"compounding error\" problem - the policy errors compound as it deviates from the expert demonstrations and might lead to catastrophic system failures, limiting its use in safety-critical applications.","On-policy data aggregation methods are able to address this issue at the cost of rolling out and repeated training of the imitation policy, which can be tedious and computationally prohibitive.","We propose SAFE-GIL, an off-policy behavior cloning method that guides the expert via adversarial disturbance during data collection.","The algorithm abstracts the imitation error as an adversarial disturbance in the system dynamics, injects it during data collection to expose the expert to safety critical states, and collects corrective actions.","Our method biases training to more closely replicate expert behavior in safety-critical states and allows more variance in less critical states.","We compare our method with several behavior cloning techniques and DAgger on autonomous navigation and autonomous taxiing tasks and show higher task success and safety, especially in low data regimes where the likelihood of error is higher, at a slight drop in the performance."],"url":"http://arxiv.org/abs/2404.05249v1"}
{"created":"2024-04-08 07:15:06","title":"Product Description and QA Assisted Self-Supervised Opinion Summarization","abstract":"In e-commerce, opinion summarization is the process of summarizing the consensus opinions found in product reviews. However, the potential of additional sources such as product description and question-answers (QA) has been considered less often. Moreover, the absence of any supervised training data makes this task challenging. To address this, we propose a novel synthetic dataset creation (SDC) strategy that leverages information from reviews as well as additional sources for selecting one of the reviews as a pseudo-summary to enable supervised training. Our Multi-Encoder Decoder framework for Opinion Summarization (MEDOS) employs a separate encoder for each source, enabling effective selection of information while generating the summary. For evaluation, due to the unavailability of test sets with additional sources, we extend the Amazon, Oposum+, and Flipkart test sets and leverage ChatGPT to annotate summaries. Experiments across nine test sets demonstrate that the combination of our SDC approach and MEDOS model achieves on average a 14.5% improvement in ROUGE-1 F1 over the SOTA. Moreover, comparative analysis underlines the significance of incorporating additional sources for generating more informative summaries. Human evaluations further indicate that MEDOS scores relatively higher in coherence and fluency with 0.41 and 0.5 (-1 to 1) respectively, compared to existing models. To the best of our knowledge, we are the first to generate opinion summaries leveraging additional sources in a self-supervised setting.","sentences":["In e-commerce, opinion summarization is the process of summarizing the consensus opinions found in product reviews.","However, the potential of additional sources such as product description and question-answers (QA) has been considered less often.","Moreover, the absence of any supervised training data makes this task challenging.","To address this, we propose a novel synthetic dataset creation (SDC) strategy that leverages information from reviews as well as additional sources for selecting one of the reviews as a pseudo-summary to enable supervised training.","Our Multi-Encoder Decoder framework for Opinion Summarization (MEDOS) employs a separate encoder for each source, enabling effective selection of information while generating the summary.","For evaluation, due to the unavailability of test sets with additional sources, we extend the Amazon, Oposum+, and Flipkart test sets and leverage ChatGPT to annotate summaries.","Experiments across nine test sets demonstrate that the combination of our SDC approach and MEDOS model achieves on average a 14.5% improvement in ROUGE-1 F1 over the SOTA.","Moreover, comparative analysis underlines the significance of incorporating additional sources for generating more informative summaries.","Human evaluations further indicate that MEDOS scores relatively higher in coherence and fluency with 0.41 and 0.5 (-1 to 1) respectively, compared to existing models.","To the best of our knowledge, we are the first to generate opinion summaries leveraging additional sources in a self-supervised setting."],"url":"http://arxiv.org/abs/2404.05243v1"}
{"created":"2024-04-08 07:11:15","title":"Computational Propaganda Theory and Bot Detection System: Critical Literature Review","abstract":"According to the classical definition, propaganda is the management of collective attitudes by manipulation of significant symbols. However this definition has changed to computational propaganda, the way manipulation takes place in digital medium. Computational propaganda is the use of algorithms, automation and human curation to purposefully distribute misleading information over social media networks to manipulate public opinion, for political polarization etc. Digital media platforms have introduced new modalities of propaganda such as the use of social bots and state-organized 'troll armies' for social astroturfing to simulate public support or opposition towards a particular topic. Along with this digital media has blurred the line between different forms of propaganda. Hence existing conceptual and epistemological frameworks in propaganda studies need a revision. One of the methods to detect the computational propaganda is to identify automation and bots. Many supervised machine learning based frameworks have been proposed for bot detection but these systems can only identify single accounts, not the coordinated activities of botnets and also these systems depend on the data structure provided by the social media platforms. Similarly, current systems have not included the image features in their detection system. Most of the systems are mainly built for Twitter while there are still uncharted areas of research in other social media platforms. Therefore, there are many unexplored research questions and methods in bot detection systems.","sentences":["According to the classical definition, propaganda is the management of collective attitudes by manipulation of significant symbols.","However this definition has changed to computational propaganda, the way manipulation takes place in digital medium.","Computational propaganda is the use of algorithms, automation and human curation to purposefully distribute misleading information over social media networks to manipulate public opinion, for political polarization etc.","Digital media platforms have introduced new modalities of propaganda such as the use of social bots and state-organized 'troll armies' for social astroturfing to simulate public support or opposition towards a particular topic.","Along with this digital media has blurred the line between different forms of propaganda.","Hence existing conceptual and epistemological frameworks in propaganda studies need a revision.","One of the methods to detect the computational propaganda is to identify automation and bots.","Many supervised machine learning based frameworks have been proposed for bot detection but these systems can only identify single accounts, not the coordinated activities of botnets and also these systems depend on the data structure provided by the social media platforms.","Similarly, current systems have not included the image features in their detection system.","Most of the systems are mainly built for Twitter while there are still uncharted areas of research in other social media platforms.","Therefore, there are many unexplored research questions and methods in bot detection systems."],"url":"http://arxiv.org/abs/2404.05240v1"}
{"created":"2024-04-08 07:09:15","title":"Allowing humans to interactively guide machines where to look does not always improve a human-AI team's classification accuracy","abstract":"Via thousands of papers in Explainable AI (XAI), attention maps \\cite{vaswani2017attention} and feature attribution maps \\cite{bansal2020sam} have been established as a common means for explaining the input features that are important to AI's decisions. It is an interesting but unexplored question whether allowing users to edit the importance scores of input features at test time would improve the human-AI team's accuracy on downstream tasks. In this paper, we address this question by taking CHM-Corr, a state-of-the-art, ante-hoc explanation method \\cite{taesiri2022visual} that first predicts patch-wise correspondences between the input and the training-set images, and then uses them to make classification decisions. We build an interactive interface on top of CHM-Corr, enabling users to directly edit the initial feature attribution map provided by CHM-Corr. Via our CHM-Corr++ interface, users gain insights into if, when, and how the model changes its outputs, enhancing understanding beyond static explanations. Our user study with 18 machine learning researchers who performed $\\sim$1,400 decisions shows that our interactive approach does not improve user accuracy on CUB-200 bird image classification over static explanations. This challenges the belief that interactivity inherently boosts XAI effectiveness~\\cite{sokol2020one,sun2022exploring,shen2024towards,singh2024rethinking,mindlin2024beyond,lakkaraju2022rethinking,cheng2019explaining,liu2021understanding} and raises needs for future research. Our work contributes to the field by open-sourcing an interactive tool for manipulating model attention, and it lays the groundwork for future research to enable effective human-AI interaction in computer vision. We release code and data on \\href{https://anonymous.4open.science/r/CHMCorrPlusPlus/}{github}. Our interface are available \\href{http://137.184.82.109:7080/}{here}.","sentences":["Via thousands of papers in Explainable AI (XAI), attention maps \\cite{vaswani2017attention} and feature attribution maps \\cite{bansal2020sam} have been established as a common means for explaining the input features that are important to AI's decisions.","It is an interesting but unexplored question whether allowing users to edit the importance scores of input features at test time would improve the human-AI team's accuracy on downstream tasks.","In this paper, we address this question by taking CHM-Corr, a state-of-the-art, ante-hoc explanation method \\cite{taesiri2022visual} that first predicts patch-wise correspondences between the input and the training-set images, and then uses them to make classification decisions.","We build an interactive interface on top of CHM-Corr, enabling users to directly edit the initial feature attribution map provided by CHM-Corr.","Via our CHM-Corr++ interface, users gain insights into if, when, and how the model changes its outputs, enhancing understanding beyond static explanations.","Our user study with 18 machine learning researchers who performed $\\sim$1,400 decisions shows that our interactive approach does not improve user accuracy on CUB-200 bird image classification over static explanations.","This challenges the belief that interactivity inherently boosts XAI effectiveness~\\cite{sokol2020one,sun2022exploring,shen2024towards,singh2024rethinking,mindlin2024beyond,lakkaraju2022rethinking,cheng2019explaining,liu2021understanding} and raises needs for future research.","Our work contributes to the field by open-sourcing an interactive tool for manipulating model attention, and it lays the groundwork for future research to enable effective human-AI interaction in computer vision.","We release code and data on \\href{https://anonymous.4open.science/r/CHMCorrPlusPlus/}{github}.","Our interface are available \\href{http://137.184.82.109:7080/}{here}."],"url":"http://arxiv.org/abs/2404.05238v1"}
{"created":"2024-04-08 06:49:59","title":"Empirical Upscaling of Point-scale Soil Moisture Measurements for Spatial Evaluation of Model Simulations and Satellite Retrievals","abstract":"The evaluation of modelled or satellite-derived soil moisture (SM) estimates is usually dependent on comparisons against in-situ SM measurements. However, the inherent mismatch in spatial support (i.e., scale) necessitates a cautious interpretation of point-to-pixel comparisons. The upscaling of the in-situ measurements to a commensurate resolution to that of the modelled or retrieved SM will lead to a fairer comparison and statistically more defensible evaluation. In this study, we presented an upscaling approach that combines spatiotemporal fusion with machine learning to extrapolate point-scale SM measurements from 28 in-situ sites to a 100 m resolution for an agricultural area of 100 km by 100 km. We conducted a four-fold cross-validation, which consistently demonstrated comparable correlation performance across folds, ranging from 0.6 to 0.9. The proposed approach was further validated based on a cross-cluster strategy by using two spatial subsets within the study area, denoted as cluster A and B, each of which equally comprised of 12 in-situ sites. The cross-cluster validation underscored the capability of the upscaling approach to map the spatial variability of SM within areas that were not covered by in-situ sites, with correlation performance ranging between 0.6 and 0.8. In general, our proposed upscaling approach offers an avenue to extrapolate point measurements of SM to a spatial scale more akin to climatic model grids or remotely sensed observations. Future investigations should delve into a further evaluation of the upscaling approach using independent data, such as model simulations, satellite retrievals or field campaign data.","sentences":["The evaluation of modelled or satellite-derived soil moisture (SM) estimates is usually dependent on comparisons against in-situ SM measurements.","However, the inherent mismatch in spatial support (i.e., scale) necessitates a cautious interpretation of point-to-pixel comparisons.","The upscaling of the in-situ measurements to a commensurate resolution to that of the modelled or retrieved SM will lead to a fairer comparison and statistically more defensible evaluation.","In this study, we presented an upscaling approach that combines spatiotemporal fusion with machine learning to extrapolate point-scale SM measurements from 28 in-situ sites to a 100 m resolution for an agricultural area of 100 km by 100 km.","We conducted a four-fold cross-validation, which consistently demonstrated comparable correlation performance across folds, ranging from 0.6 to 0.9.","The proposed approach was further validated based on a cross-cluster strategy by using two spatial subsets within the study area, denoted as cluster A and B, each of which equally comprised of 12 in-situ sites.","The cross-cluster validation underscored the capability of the upscaling approach to map the spatial variability of SM within areas that were not covered by in-situ sites, with correlation performance ranging between 0.6 and 0.8.","In general, our proposed upscaling approach offers an avenue to extrapolate point measurements of SM to a spatial scale more akin to climatic model grids or remotely sensed observations.","Future investigations should delve into a further evaluation of the upscaling approach using independent data, such as model simulations, satellite retrievals or field campaign data."],"url":"http://arxiv.org/abs/2404.05229v1"}
{"created":"2024-04-08 06:40:28","title":"LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding","abstract":"Recently, leveraging large language models (LLMs) or multimodal large language models (MLLMs) for document understanding has been proven very promising. However, previous works that employ LLMs/MLLMs for document understanding have not fully explored and utilized the document layout information, which is vital for precise document understanding. In this paper, we propose LayoutLLM, an LLM/MLLM based method for document understanding. The core of LayoutLLM is a layout instruction tuning strategy, which is specially designed to enhance the comprehension and utilization of document layouts. The proposed layout instruction tuning strategy consists of two components: Layout-aware Pre-training and Layout-aware Supervised Fine-tuning. To capture the characteristics of document layout in Layout-aware Pre-training, three groups of pre-training tasks, corresponding to document-level, region-level and segment-level information, are introduced. Furthermore, a novel module called layout chain-of-thought (LayoutCoT) is devised to enable LayoutLLM to focus on regions relevant to the question and generate accurate answers. LayoutCoT is effective for boosting the performance of document understanding. Meanwhile, it brings a certain degree of interpretability, which could facilitate manual inspection and correction. Experiments on standard benchmarks show that the proposed LayoutLLM significantly outperforms existing methods that adopt open-source 7B LLMs/MLLMs for document understanding. The training data of the LayoutLLM is publicly available at https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LayoutLLM","sentences":["Recently, leveraging large language models (LLMs) or multimodal large language models (MLLMs) for document understanding has been proven very promising.","However, previous works that employ LLMs/MLLMs for document understanding have not fully explored and utilized the document layout information, which is vital for precise document understanding.","In this paper, we propose LayoutLLM, an LLM/MLLM based method for document understanding.","The core of LayoutLLM is a layout instruction tuning strategy, which is specially designed to enhance the comprehension and utilization of document layouts.","The proposed layout instruction tuning strategy consists of two components: Layout-aware Pre-training and Layout-aware Supervised Fine-tuning.","To capture the characteristics of document layout in Layout-aware Pre-training, three groups of pre-training tasks, corresponding to document-level, region-level and segment-level information, are introduced.","Furthermore, a novel module called layout chain-of-thought (LayoutCoT) is devised to enable LayoutLLM to focus on regions relevant to the question and generate accurate answers.","LayoutCoT is effective for boosting the performance of document understanding.","Meanwhile, it brings a certain degree of interpretability, which could facilitate manual inspection and correction.","Experiments on standard benchmarks show that the proposed LayoutLLM significantly outperforms existing methods that adopt open-source 7B LLMs/MLLMs for document understanding.","The training data of the LayoutLLM is publicly available at https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LayoutLLM"],"url":"http://arxiv.org/abs/2404.05225v1"}
{"created":"2024-04-08 06:40:03","title":"Iof-maint -- Modular maintenance ontology","abstract":"In this paper we present a publicly-available maintenance ontology (Iof-maint). Iof-maint is a modular ontology aligned with the Industrial Ontology Foundry Core (IOF Core) and contains 20 classes and 2 relations. It provides a set of maintenance-specific terms used in a wide variety of practical data-driven use cases. Iof-maint supports OWL DL reasoning, is documented, and is actively maintained on GitHub. In this paper, we describe the evolution of the Iof-maint reference ontology based on the extraction of common concepts identified in a number of application ontologies working with industry maintenance work order, procedure and failure mode data.","sentences":["In this paper we present a publicly-available maintenance ontology (Iof-maint).","Iof-maint is a modular ontology aligned with the Industrial Ontology Foundry Core (IOF Core) and contains 20 classes and 2 relations.","It provides a set of maintenance-specific terms used in a wide variety of practical data-driven use cases.","Iof-maint supports OWL DL reasoning, is documented, and is actively maintained on GitHub.","In this paper, we describe the evolution of the Iof-maint reference ontology based on the extraction of common concepts identified in a number of application ontologies working with industry maintenance work order, procedure and failure mode data."],"url":"http://arxiv.org/abs/2404.05224v1"}
{"created":"2024-04-08 06:27:38","title":"Out-of-Distribution Data: An Acquaintance of Adversarial Examples -- A Survey","abstract":"Deep neural networks (DNNs) deployed in real-world applications can encounter out-of-distribution (OOD) data and adversarial examples. These represent distinct forms of distributional shifts that can significantly impact DNNs' reliability and robustness. Traditionally, research has addressed OOD detection and adversarial robustness as separate challenges. This survey focuses on the intersection of these two areas, examining how the research community has investigated them together. Consequently, we identify two key research directions: robust OOD detection and unified robustness. Robust OOD detection aims to differentiate between in-distribution (ID) data and OOD data, even when they are adversarially manipulated to deceive the OOD detector. Unified robustness seeks a single approach to make DNNs robust against both adversarial attacks and OOD inputs. Accordingly, first, we establish a taxonomy based on the concept of distributional shifts. This framework clarifies how robust OOD detection and unified robustness relate to other research areas addressing distributional shifts, such as OOD detection, open set recognition, and anomaly detection. Subsequently, we review existing work on robust OOD detection and unified robustness. Finally, we highlight the limitations of the existing work and propose promising research directions that explore adversarial and OOD inputs within a unified framework.","sentences":["Deep neural networks (DNNs) deployed in real-world applications can encounter out-of-distribution (OOD) data and adversarial examples.","These represent distinct forms of distributional shifts that can significantly impact DNNs' reliability and robustness.","Traditionally, research has addressed OOD detection and adversarial robustness as separate challenges.","This survey focuses on the intersection of these two areas, examining how the research community has investigated them together.","Consequently, we identify two key research directions: robust OOD detection and unified robustness.","Robust OOD detection aims to differentiate between in-distribution (ID) data and OOD data, even when they are adversarially manipulated to deceive the OOD detector.","Unified robustness seeks a single approach to make DNNs robust against both adversarial attacks and OOD inputs.","Accordingly, first, we establish a taxonomy based on the concept of distributional shifts.","This framework clarifies how robust OOD detection and unified robustness relate to other research areas addressing distributional shifts, such as OOD detection, open set recognition, and anomaly detection.","Subsequently, we review existing work on robust OOD detection and unified robustness.","Finally, we highlight the limitations of the existing work and propose promising research directions that explore adversarial and OOD inputs within a unified framework."],"url":"http://arxiv.org/abs/2404.05219v1"}
{"created":"2024-04-08 05:50:46","title":"Multi-level Graph Subspace Contrastive Learning for Hyperspectral Image Clustering","abstract":"Hyperspectral image (HSI) clustering is a challenging task due to its high complexity. Despite subspace clustering shows impressive performance for HSI, traditional methods tend to ignore the global-local interaction in HSI data. In this study, we proposed a multi-level graph subspace contrastive learning (MLGSC) for HSI clustering. The model is divided into the following main parts. Graph convolution subspace construction: utilizing spectral and texture feautures to construct two graph convolution views. Local-global graph representation: local graph representations were obtained by step-by-step convolutions and a more representative global graph representation was obtained using an attention-based pooling strategy. Multi-level graph subspace contrastive learning: multi-level contrastive learning was conducted to obtain local-global joint graph representations, to improve the consistency of the positive samples between views, and to obtain more robust graph embeddings. Specifically, graph-level contrastive learning is used to better learn global representations of HSI data. Node-level intra-view and inter-view contrastive learning is designed to learn joint representations of local regions of HSI. The proposed model is evaluated on four popular HSI datasets: Indian Pines, Pavia University, Houston, and Xu Zhou. The overall accuracies are 97.75%, 99.96%, 92.28%, and 95.73%, which significantly outperforms the current state-of-the-art clustering methods.","sentences":["Hyperspectral image (HSI) clustering is a challenging task due to its high complexity.","Despite subspace clustering shows impressive performance for HSI, traditional methods tend to ignore the global-local interaction in HSI data.","In this study, we proposed a multi-level graph subspace contrastive learning (MLGSC) for HSI clustering.","The model is divided into the following main parts.","Graph convolution subspace construction: utilizing spectral and texture feautures to construct two graph convolution views.","Local-global graph representation: local graph representations were obtained by step-by-step convolutions and a more representative global graph representation was obtained using an attention-based pooling strategy.","Multi-level graph subspace contrastive learning: multi-level contrastive learning was conducted to obtain local-global joint graph representations, to improve the consistency of the positive samples between views, and to obtain more robust graph embeddings.","Specifically, graph-level contrastive learning is used to better learn global representations of HSI data.","Node-level intra-view and inter-view contrastive learning is designed to learn joint representations of local regions of HSI.","The proposed model is evaluated on four popular HSI datasets: Indian Pines, Pavia University, Houston, and Xu Zhou.","The overall accuracies are 97.75%, 99.96%, 92.28%, and 95.73%, which significantly outperforms the current state-of-the-art clustering methods."],"url":"http://arxiv.org/abs/2404.05211v1"}
{"created":"2024-04-08 05:45:03","title":"Bidirectional Long-Range Parser for Sequential Data Understanding","abstract":"The transformer is a powerful data modelling framework responsible for remarkable performance on a wide range of tasks. However, they are limited in terms of scalability as it is suboptimal and inefficient to process long-sequence data. To this purpose we introduce BLRP (Bidirectional Long-Range Parser), a novel and versatile attention mechanism designed to increase performance and efficiency on long-sequence tasks. It leverages short and long range heuristics in the form of a local sliding window approach combined with a global bidirectional latent space synthesis technique. We show the benefits and versatility of our approach on vision and language domains by demonstrating competitive results against state-of-the-art methods on the Long-Range-Arena and CIFAR benchmarks together with ablations demonstrating the computational efficiency.","sentences":["The transformer is a powerful data modelling framework responsible for remarkable performance on a wide range of tasks.","However, they are limited in terms of scalability as it is suboptimal and inefficient to process long-sequence data.","To this purpose we introduce BLRP (Bidirectional Long-Range Parser), a novel and versatile attention mechanism designed to increase performance and efficiency on long-sequence tasks.","It leverages short and long range heuristics in the form of a local sliding window approach combined with a global bidirectional latent space synthesis technique.","We show the benefits and versatility of our approach on vision and language domains by demonstrating competitive results against state-of-the-art methods on the Long-Range-Arena and CIFAR benchmarks together with ablations demonstrating the computational efficiency."],"url":"http://arxiv.org/abs/2404.05210v1"}
{"created":"2024-04-08 05:19:28","title":"SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos","abstract":"We propose a novel self-supervised embedding to learn how actions sound from narrated in-the-wild egocentric videos. Whereas existing methods rely on curated data with known audio-visual correspondence, our multimodal contrastive-consensus coding (MC3) embedding reinforces the associations between audio, language, and vision when all modality pairs agree, while diminishing those associations when any one pair does not. We show our approach can successfully discover how the long tail of human actions sound from egocentric video, outperforming an array of recent multimodal embedding techniques on two datasets (Ego4D and EPIC-Sounds) and multiple cross-modal tasks.","sentences":["We propose a novel self-supervised embedding to learn how actions sound from narrated in-the-wild egocentric videos.","Whereas existing methods rely on curated data with known audio-visual correspondence, our multimodal contrastive-consensus coding (MC3) embedding reinforces the associations between audio, language, and vision when all modality pairs agree, while diminishing those associations when any one pair does not.","We show our approach can successfully discover how the long tail of human actions sound from egocentric video, outperforming an array of recent multimodal embedding techniques on two datasets (Ego4D and EPIC-Sounds) and multiple cross-modal tasks."],"url":"http://arxiv.org/abs/2404.05206v1"}
{"created":"2024-04-08 04:41:39","title":"ATFNet: Adaptive Time-Frequency Ensembled Network for Long-term Time Series Forecasting","abstract":"The intricate nature of time series data analysis benefits greatly from the distinct advantages offered by time and frequency domain representations. While the time domain is superior in representing local dependencies, particularly in non-periodic series, the frequency domain excels in capturing global dependencies, making it ideal for series with evident periodic patterns. To capitalize on both of these strengths, we propose ATFNet, an innovative framework that combines a time domain module and a frequency domain module to concurrently capture local and global dependencies in time series data. Specifically, we introduce Dominant Harmonic Series Energy Weighting, a novel mechanism for dynamically adjusting the weights between the two modules based on the periodicity of the input time series. In the frequency domain module, we enhance the traditional Discrete Fourier Transform (DFT) with our Extended DFT, designed to address the challenge of discrete frequency misalignment. Additionally, our Complex-valued Spectrum Attention mechanism offers a novel approach to discern the intricate relationships between different frequency combinations. Extensive experiments across multiple real-world datasets demonstrate that our ATFNet framework outperforms current state-of-the-art methods in long-term time series forecasting.","sentences":["The intricate nature of time series data analysis benefits greatly from the distinct advantages offered by time and frequency domain representations.","While the time domain is superior in representing local dependencies, particularly in non-periodic series, the frequency domain excels in capturing global dependencies, making it ideal for series with evident periodic patterns.","To capitalize on both of these strengths, we propose ATFNet, an innovative framework that combines a time domain module and a frequency domain module to concurrently capture local and global dependencies in time series data.","Specifically, we introduce Dominant Harmonic Series Energy Weighting, a novel mechanism for dynamically adjusting the weights between the two modules based on the periodicity of the input time series.","In the frequency domain module, we enhance the traditional Discrete Fourier Transform (DFT) with our Extended DFT, designed to address the challenge of discrete frequency misalignment.","Additionally, our Complex-valued Spectrum Attention mechanism offers a novel approach to discern the intricate relationships between different frequency combinations.","Extensive experiments across multiple real-world datasets demonstrate that our ATFNet framework outperforms current state-of-the-art methods in long-term time series forecasting."],"url":"http://arxiv.org/abs/2404.05192v1"}
{"created":"2024-04-08 04:30:33","title":"Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging","abstract":"Model merging is a promising lightweight model empowerment technique that does not rely on expensive computing devices (e.g., GPUs) or require the collection of specific training data. Instead, it involves editing different upstream model parameters to absorb their downstream task capabilities. However, uncertified model merging can infringe upon the Intellectual Property (IP) rights of the original upstream models. In this paper, we conduct the first study on the robustness of IP protection methods in model merging scenarios. We investigate two state-of-the-art IP protection techniques: Quantization Watermarking and Instructional Fingerprint, along with various advanced model merging technologies, such as Task Arithmetic, TIES-MERGING, and so on. Experimental results indicate that current Large Language Model (LLM) watermarking techniques cannot survive in the merged models, whereas model fingerprinting techniques can. Our research aims to highlight that model merging should be an indispensable consideration in the robustness assessment of model IP protection techniques, thereby promoting the healthy development of the open-source LLM community.","sentences":["Model merging is a promising lightweight model empowerment technique that does not rely on expensive computing devices (e.g., GPUs) or require the collection of specific training data.","Instead, it involves editing different upstream model parameters to absorb their downstream task capabilities.","However, uncertified model merging can infringe upon the Intellectual Property (IP) rights of the original upstream models.","In this paper, we conduct the first study on the robustness of IP protection methods in model merging scenarios.","We investigate two state-of-the-art IP protection techniques: Quantization Watermarking and Instructional Fingerprint, along with various advanced model merging technologies, such as Task Arithmetic, TIES-MERGING, and so on.","Experimental results indicate that current Large Language Model (LLM) watermarking techniques cannot survive in the merged models, whereas model fingerprinting techniques can.","Our research aims to highlight that model merging should be an indispensable consideration in the robustness assessment of model IP protection techniques, thereby promoting the healthy development of the open-source LLM community."],"url":"http://arxiv.org/abs/2404.05188v1"}
{"created":"2024-04-08 04:27:36","title":"LGSDF: Continual Global Learning of Signed Distance Fields Aided by Local Updating","abstract":"Implicit reconstruction of ESDF (Euclidean Signed Distance Field) involves training a neural network to regress the signed distance from any point to the nearest obstacle, which has the advantages of lightweight storage and continuous querying. However, existing algorithms usually rely on conflicting raw observations as training data, resulting in poor map performance. In this paper, we propose LGSDF, an ESDF continual Global learning algorithm aided by Local updating. At the front end, axis-aligned grids are dynamically updated by pre-processed sensor observations, where incremental fusion alleviates estimation error caused by limited viewing directions. At the back end, a randomly initialized implicit ESDF neural network performs continual self-supervised learning guided by these grids to generate smooth and continuous maps. The results on multiple scenes show that LGSDF can construct more accurate ESDF maps and meshes compared with SOTA (State Of The Art) explicit and implicit mapping algorithms. The source code of LGSDF is publicly available at https://github.com/BIT-DYN/LGSDF.","sentences":["Implicit reconstruction of ESDF (Euclidean Signed Distance Field) involves training a neural network to regress the signed distance from any point to the nearest obstacle, which has the advantages of lightweight storage and continuous querying.","However, existing algorithms usually rely on conflicting raw observations as training data, resulting in poor map performance.","In this paper, we propose LGSDF, an ESDF continual Global learning algorithm aided by Local updating.","At the front end, axis-aligned grids are dynamically updated by pre-processed sensor observations, where incremental fusion alleviates estimation error caused by limited viewing directions.","At the back end, a randomly initialized implicit ESDF neural network performs continual self-supervised learning guided by these grids to generate smooth and continuous maps.","The results on multiple scenes show that LGSDF can construct more accurate ESDF maps and meshes compared with SOTA (State Of The Art) explicit and implicit mapping algorithms.","The source code of LGSDF is publicly available at https://github.com/BIT-DYN/LGSDF."],"url":"http://arxiv.org/abs/2404.05187v1"}
{"created":"2024-04-08 04:17:27","title":"Progressive Alignment with VLM-LLM Feature to Augment Defect Classification for the ASE Dataset","abstract":"Traditional defect classification approaches are facing with two barriers. (1) Insufficient training data and unstable data quality. Collecting sufficient defective sample is expensive and time-costing, consequently leading to dataset variance. It introduces the difficulty on recognition and learning. (2) Over-dependence on visual modality. When the image pattern and texture is monotonic for all defect classes in a given dataset, the performance of conventional AOI system cannot be guaranteed. In scenarios where image quality is compromised due to mechanical failures or when defect information is inherently difficult to discern, the performance of deep models cannot be guaranteed. A main question is, \"how to solve those two problems when they occur at the same time?\" The feasible strategy is to explore another feature within dataset and combine an eminent vision-language model (VLM) and Large-Language model (LLM) with their astonishing zero-shot capability. In this work, we propose the special ASE dataset, including rich data description recorded on image, for defect classification, but the defect feature is uneasy to learn directly. Secondly, We present the prompting for VLM-LLM against defect classification with the proposed ASE dataset to activate extra-modality feature from images to enhance performance. Then, We design the novel progressive feature alignment (PFA) block to refine image-text feature to alleviate the difficulty of alignment under few-shot scenario. Finally, the proposed Cross-modality attention fusion (CMAF) module can effectively fuse different modality feature. Experiment results have demonstrated our method's effectiveness over several defect classification methods for the ASE dataset.","sentences":["Traditional defect classification approaches are facing with two barriers.","(1) Insufficient training data and unstable data quality.","Collecting sufficient defective sample is expensive and time-costing, consequently leading to dataset variance.","It introduces the difficulty on recognition and learning.","(2) Over-dependence on visual modality.","When the image pattern and texture is monotonic for all defect classes in a given dataset, the performance of conventional AOI system cannot be guaranteed.","In scenarios where image quality is compromised due to mechanical failures or when defect information is inherently difficult to discern, the performance of deep models cannot be guaranteed.","A main question is, \"how to solve those two problems when they occur at the same time?\"","The feasible strategy is to explore another feature within dataset and combine an eminent vision-language model (VLM) and Large-Language model (LLM) with their astonishing zero-shot capability.","In this work, we propose the special ASE dataset, including rich data description recorded on image, for defect classification, but the defect feature is uneasy to learn directly.","Secondly, We present the prompting for VLM-LLM against defect classification with the proposed ASE dataset to activate extra-modality feature from images to enhance performance.","Then, We design the novel progressive feature alignment (PFA) block to refine image-text feature to alleviate the difficulty of alignment under few-shot scenario.","Finally, the proposed Cross-modality attention fusion (CMAF) module can effectively fuse different modality feature.","Experiment results have demonstrated our method's effectiveness over several defect classification methods for the ASE dataset."],"url":"http://arxiv.org/abs/2404.05183v1"}
{"created":"2024-04-08 04:14:02","title":"DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model","abstract":"To enhance the performance of large language models (LLM) on downstream tasks, one solution is to fine-tune certain LLM parameters and make it better align with the characteristics of the training dataset. This process is commonly known as parameter-efficient fine-tuning (PEFT). Due to the scale of LLM, PEFT operations are usually executed in the public environment (e.g., cloud server). This necessitates the sharing of sensitive user data across public environments, thereby raising potential privacy concerns. To tackle these challenges, we propose a distributed PEFT framework called DLoRA. DLoRA enables scalable PEFT operations to be performed collaboratively between the cloud and user devices. Coupled with the proposed Kill and Revive algorithm, the evaluation results demonstrate that DLoRA can significantly reduce the computation and communication workload over the user devices while achieving superior accuracy and privacy protection.","sentences":["To enhance the performance of large language models (LLM) on downstream tasks, one solution is to fine-tune certain LLM parameters and make it better align with the characteristics of the training dataset.","This process is commonly known as parameter-efficient fine-tuning (PEFT).","Due to the scale of LLM, PEFT operations are usually executed in the public environment (e.g., cloud server).","This necessitates the sharing of sensitive user data across public environments, thereby raising potential privacy concerns.","To tackle these challenges, we propose a distributed PEFT framework called DLoRA.","DLoRA enables scalable PEFT operations to be performed collaboratively between the cloud and user devices.","Coupled with the proposed Kill and Revive algorithm, the evaluation results demonstrate that DLoRA can significantly reduce the computation and communication workload over the user devices while achieving superior accuracy and privacy protection."],"url":"http://arxiv.org/abs/2404.05182v1"}
{"created":"2024-04-08 03:45:00","title":"Directed Buy-at-Bulk Spanners","abstract":"We present a framework that unifies directed buy-at-bulk network design and directed spanner problems, namely, \\emph{buy-at-bulk spanners}. The goal is to find a minimum-cost routing solution for network design problems that capture economies at scale, while satisfying demands and distance constraints for terminal pairs. A more restricted version of this problem was shown to be $O(2^{{\\log^{1-\\ep} n}})$-hard to approximate, where $n$ is the number of vertices, under a standard complexity assumption, due to Elkin and Peleg (Theory of Computing Systems, 2007).   To the best of our knowledge, our results are the first sublinear factor approximation algorithms for directed buy-at-bulk spanners. Furthermore, these results hold even when we allow the edge lengths to be \\emph{negative}, unlike the previous literature for spanners. Our approximation ratios match the state-of-the-art ratios in special cases, namely, buy-at-bulk network design by Antonakopoulos (WAOA, 2010) and weighted spanners by Grigorescu, Kumar, and Lin (APPROX 2023).   Our results are based on new approximation algorithms for the following two problems that are of independent interest: \\emph{minimum-density distance-constrained junction trees} and \\emph{resource-constrained shortest path with negative consumption}.","sentences":["We present a framework that unifies directed buy-at-bulk network design and directed spanner problems, namely, \\emph{buy-at-bulk spanners}.","The goal is to find a minimum-cost routing solution for network design problems that capture economies at scale, while satisfying demands and distance constraints for terminal pairs.","A more restricted version of this problem was shown to be $O(2^{{\\log^{1-\\ep} n}})$-hard to approximate, where $n$ is the number of vertices, under a standard complexity assumption, due to Elkin and Peleg (Theory of Computing Systems, 2007).   ","To the best of our knowledge, our results are the first sublinear factor approximation algorithms for directed buy-at-bulk spanners.","Furthermore, these results hold even when we allow the edge lengths to be \\emph{negative}, unlike the previous literature for spanners.","Our approximation ratios match the state-of-the-art ratios in special cases, namely, buy-at-bulk network design by Antonakopoulos (WAOA, 2010) and weighted spanners by Grigorescu, Kumar, and Lin (APPROX 2023).   ","Our results are based on new approximation algorithms for the following two problems that are of independent interest: \\emph{minimum-density distance-constrained junction trees} and \\emph{resource-constrained shortest path with negative consumption}."],"url":"http://arxiv.org/abs/2404.05172v1"}
{"created":"2024-04-08 03:33:01","title":"QMix: Quality-aware Learning with Mixed Noise for Robust Retinal Disease Diagnosis","abstract":"Due to the complexity of medical image acquisition and the difficulty of annotation, medical image datasets inevitably contain noise. Noisy data with wrong labels affects the robustness and generalization ability of deep neural networks. Previous noise learning methods mainly considered noise arising from images being mislabeled, i.e. label noise, assuming that all mislabeled images are of high image quality. However, medical images are prone to suffering extreme quality issues, i.e. data noise, where discriminative visual features are missing for disease diagnosis. In this paper, we propose a noise learning framework, termed as QMix, that learns a robust disease diagnosis model under mixed noise. QMix alternates between sample separation and quality-aware semisupervised training in each training epoch. In the sample separation phase, we design a joint uncertainty-loss criterion to effectively separate (1) correctly labeled images; (2) mislabeled images with high quality and (3) mislabeled images with low quality. In the semi-supervised training phase, we train a disease diagnosis model to learn robust feature representation from the separated samples. Specifically, we devise a sample-reweighing loss to mitigate the effect of mislabeled images with low quality during training. Meanwhile, a contrastive enhancement loss is proposed to further distinguish mislabeled images with low quality from correctly labeled images. QMix achieved state-of-the-art disease diagnosis performance on five public retinal image datasets and exhibited substantial improvement on robustness against mixed noise.","sentences":["Due to the complexity of medical image acquisition and the difficulty of annotation, medical image datasets inevitably contain noise.","Noisy data with wrong labels affects the robustness and generalization ability of deep neural networks.","Previous noise learning methods mainly considered noise arising from images being mislabeled, i.e. label noise, assuming that all mislabeled images are of high image quality.","However, medical images are prone to suffering extreme quality issues, i.e. data noise, where discriminative visual features are missing for disease diagnosis.","In this paper, we propose a noise learning framework, termed as QMix, that learns a robust disease diagnosis model under mixed noise.","QMix alternates between sample separation and quality-aware semisupervised training in each training epoch.","In the sample separation phase, we design a joint uncertainty-loss criterion to effectively separate (1) correctly labeled images; (2) mislabeled images with high quality and (3) mislabeled images with low quality.","In the semi-supervised training phase, we train a disease diagnosis model to learn robust feature representation from the separated samples.","Specifically, we devise a sample-reweighing loss to mitigate the effect of mislabeled images with low quality during training.","Meanwhile, a contrastive enhancement loss is proposed to further distinguish mislabeled images with low quality from correctly labeled images.","QMix achieved state-of-the-art disease diagnosis performance on five public retinal image datasets and exhibited substantial improvement on robustness against mixed noise."],"url":"http://arxiv.org/abs/2404.05169v1"}
{"created":"2024-04-08 03:29:58","title":"Adapting to Covariate Shift in Real-time by Encoding Trees with Motion Equations","abstract":"Input distribution shift presents a significant problem in many real-world systems. Here we present Xenovert, an adaptive algorithm that can dynamically adapt to changes in input distribution. It is a perfect binary tree that adaptively divides a continuous input space into several intervals of uniform density while receiving a continuous stream of input. This process indirectly maps the source distribution to the shifted target distribution, preserving the data's relationship with the downstream decoder/operation, even after the shift occurs. In this paper, we demonstrated how a neural network integrated with Xenovert achieved better results in 4 out of 5 shifted datasets, saving the hurdle of retraining a machine learning model. We anticipate that Xenovert can be applied to many more applications that require adaptation to unforeseen input distribution shifts, even when the distribution shift is drastic.","sentences":["Input distribution shift presents a significant problem in many real-world systems.","Here we present Xenovert, an adaptive algorithm that can dynamically adapt to changes in input distribution.","It is a perfect binary tree that adaptively divides a continuous input space into several intervals of uniform density while receiving a continuous stream of input.","This process indirectly maps the source distribution to the shifted target distribution, preserving the data's relationship with the downstream decoder/operation, even after the shift occurs.","In this paper, we demonstrated how a neural network integrated with Xenovert achieved better results in 4 out of 5 shifted datasets, saving the hurdle of retraining a machine learning model.","We anticipate that Xenovert can be applied to many more applications that require adaptation to unforeseen input distribution shifts, even when the distribution shift is drastic."],"url":"http://arxiv.org/abs/2404.05168v1"}
{"created":"2024-04-08 03:08:59","title":"Rendering-Enhanced Automatic Image-to-Point Cloud Registration for Roadside Scenes","abstract":"Prior point cloud provides 3D environmental context, which enhances the capabilities of monocular camera in downstream vision tasks, such as 3D object detection, via data fusion. However, the absence of accurate and automated registration methods for estimating camera extrinsic parameters in roadside scene point clouds notably constrains the potential applications of roadside cameras. This paper proposes a novel approach for the automatic registration between prior point clouds and images from roadside scenes. The main idea involves rendering photorealistic grayscale views taken at specific perspectives from the prior point cloud with the help of their features like RGB or intensity values. These generated views can reduce the modality differences between images and prior point clouds, thereby improve the robustness and accuracy of the registration results. Particularly, we specify an efficient algorithm, named neighbor rendering, for the rendering process. Then we introduce a method for automatically estimating the initial guess using only rough guesses of camera's position. At last, we propose a procedure for iteratively refining the extrinsic parameters by minimizing the reprojection error for line features extracted from both generated and camera images using Segment Anything Model (SAM). We assess our method using a self-collected dataset, comprising eight cameras strategically positioned throughout the university campus. Experiments demonstrate our method's capability to automatically align prior point cloud with roadside camera image, achieving a rotation accuracy of 0.202 degrees and a translation precision of 0.079m. Furthermore, we validate our approach's effectiveness in visual applications by substantially improving monocular 3D object detection performance.","sentences":["Prior point cloud provides 3D environmental context, which enhances the capabilities of monocular camera in downstream vision tasks, such as 3D object detection, via data fusion.","However, the absence of accurate and automated registration methods for estimating camera extrinsic parameters in roadside scene point clouds notably constrains the potential applications of roadside cameras.","This paper proposes a novel approach for the automatic registration between prior point clouds and images from roadside scenes.","The main idea involves rendering photorealistic grayscale views taken at specific perspectives from the prior point cloud with the help of their features like RGB or intensity values.","These generated views can reduce the modality differences between images and prior point clouds, thereby improve the robustness and accuracy of the registration results.","Particularly, we specify an efficient algorithm, named neighbor rendering, for the rendering process.","Then we introduce a method for automatically estimating the initial guess using only rough guesses of camera's position.","At last, we propose a procedure for iteratively refining the extrinsic parameters by minimizing the reprojection error for line features extracted from both generated and camera images using Segment Anything Model (SAM).","We assess our method using a self-collected dataset, comprising eight cameras strategically positioned throughout the university campus.","Experiments demonstrate our method's capability to automatically align prior point cloud with roadside camera image, achieving a rotation accuracy of 0.202 degrees and a translation precision of 0.079m.","Furthermore, we validate our approach's effectiveness in visual applications by substantially improving monocular 3D object detection performance."],"url":"http://arxiv.org/abs/2404.05164v1"}
{"created":"2024-04-08 01:54:28","title":"Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation","abstract":"Transformer-based Large Language Models (LLMs) have shown exceptional language generation capabilities in response to text-based prompts. However, controlling the direction of generation via textual prompts has been challenging, especially with smaller models. In this work, we explore the use of Prompt Tuning to achieve controlled language generation. Generated text is steered using prompt embeddings, which are trained using a small language model, used as a discriminator. Moreover, we demonstrate that these prompt embeddings can be trained with a very small dataset, with as low as a few hundred training examples. Our method thus offers a data and parameter efficient solution towards controlling language model outputs. We carry out extensive evaluation on four datasets: SST-5 and Yelp (sentiment analysis), GYAFC (formality) and JIGSAW (toxic language). Finally, we demonstrate the efficacy of our method towards mitigating harmful, toxic, and biased text generated by language models.","sentences":["Transformer-based Large Language Models (LLMs) have shown exceptional language generation capabilities in response to text-based prompts.","However, controlling the direction of generation via textual prompts has been challenging, especially with smaller models.","In this work, we explore the use of Prompt Tuning to achieve controlled language generation.","Generated text is steered using prompt embeddings, which are trained using a small language model, used as a discriminator.","Moreover, we demonstrate that these prompt embeddings can be trained with a very small dataset, with as low as a few hundred training examples.","Our method thus offers a data and parameter efficient solution towards controlling language model outputs.","We carry out extensive evaluation on four datasets: SST-5 and Yelp (sentiment analysis), GYAFC (formality) and JIGSAW (toxic language).","Finally, we demonstrate the efficacy of our method towards mitigating harmful, toxic, and biased text generated by language models."],"url":"http://arxiv.org/abs/2404.05143v1"}
{"created":"2024-04-08 01:38:43","title":"Better Monocular 3D Detectors with LiDAR from the Past","abstract":"Accurate 3D object detection is crucial to autonomous driving. Though LiDAR-based detectors have achieved impressive performance, the high cost of LiDAR sensors precludes their widespread adoption in affordable vehicles. Camera-based detectors are cheaper alternatives but often suffer inferior performance compared to their LiDAR-based counterparts due to inherent depth ambiguities in images. In this work, we seek to improve monocular 3D detectors by leveraging unlabeled historical LiDAR data. Specifically, at inference time, we assume that the camera-based detectors have access to multiple unlabeled LiDAR scans from past traversals at locations of interest (potentially from other high-end vehicles equipped with LiDAR sensors). Under this setup, we proposed a novel, simple, and end-to-end trainable framework, termed AsyncDepth, to effectively extract relevant features from asynchronous LiDAR traversals of the same location for monocular 3D detectors. We show consistent and significant performance gain (up to 9 AP) across multiple state-of-the-art models and datasets with a negligible additional latency of 9.66 ms and a small storage cost.","sentences":["Accurate 3D object detection is crucial to autonomous driving.","Though LiDAR-based detectors have achieved impressive performance, the high cost of LiDAR sensors precludes their widespread adoption in affordable vehicles.","Camera-based detectors are cheaper alternatives but often suffer inferior performance compared to their LiDAR-based counterparts due to inherent depth ambiguities in images.","In this work, we seek to improve monocular 3D detectors by leveraging unlabeled historical LiDAR data.","Specifically, at inference time, we assume that the camera-based detectors have access to multiple unlabeled LiDAR scans from past traversals at locations of interest (potentially from other high-end vehicles equipped with LiDAR sensors).","Under this setup, we proposed a novel, simple, and end-to-end trainable framework, termed AsyncDepth, to effectively extract relevant features from asynchronous LiDAR traversals of the same location for monocular 3D detectors.","We show consistent and significant performance gain (up to 9 AP) across multiple state-of-the-art models and datasets with a negligible additional latency of 9.66 ms and a small storage cost."],"url":"http://arxiv.org/abs/2404.05139v1"}
{"created":"2024-04-08 01:21:11","title":"EcoVerse: An Annotated Twitter Dataset for Eco-Relevance Classification, Environmental Impact Analysis, and Stance Detection","abstract":"Anthropogenic ecological crisis constitutes a significant challenge that all within the academy must urgently face, including the Natural Language Processing (NLP) community. While recent years have seen increasing work revolving around climate-centric discourse, crucial environmental and ecological topics outside of climate change remain largely unaddressed, despite their prominent importance. Mainstream NLP tasks, such as sentiment analysis, dominate the scene, but there remains an untouched space in the literature involving the analysis of environmental impacts of certain events and practices. To address this gap, this paper presents EcoVerse, an annotated English Twitter dataset of 3,023 tweets spanning a wide spectrum of environmental topics. We propose a three-level annotation scheme designed for Eco-Relevance Classification, Stance Detection, and introducing an original approach for Environmental Impact Analysis. We detail the data collection, filtering, and labeling process that led to the creation of the dataset. Remarkable Inter-Annotator Agreement indicates that the annotation scheme produces consistent annotations of high quality. Subsequent classification experiments using BERT-based models, including ClimateBERT, are presented. These yield encouraging results, while also indicating room for a model specifically tailored for environmental texts. The dataset is made freely available to stimulate further research.","sentences":["Anthropogenic ecological crisis constitutes a significant challenge that all within the academy must urgently face, including the Natural Language Processing (NLP) community.","While recent years have seen increasing work revolving around climate-centric discourse, crucial environmental and ecological topics outside of climate change remain largely unaddressed, despite their prominent importance.","Mainstream NLP tasks, such as sentiment analysis, dominate the scene, but there remains an untouched space in the literature involving the analysis of environmental impacts of certain events and practices.","To address this gap, this paper presents EcoVerse, an annotated English Twitter dataset of 3,023 tweets spanning a wide spectrum of environmental topics.","We propose a three-level annotation scheme designed for Eco-Relevance Classification, Stance Detection, and introducing an original approach for Environmental Impact Analysis.","We detail the data collection, filtering, and labeling process that led to the creation of the dataset.","Remarkable Inter-Annotator Agreement indicates that the annotation scheme produces consistent annotations of high quality.","Subsequent classification experiments using BERT-based models, including ClimateBERT, are presented.","These yield encouraging results, while also indicating room for a model specifically tailored for environmental texts.","The dataset is made freely available to stimulate further research."],"url":"http://arxiv.org/abs/2404.05133v1"}
{"created":"2024-04-08 01:16:56","title":"Enabling Privacy-Preserving Cyber Threat Detection with Federated Learning","abstract":"Despite achieving good performance and wide adoption, machine learning based security detection models (e.g., malware classifiers) are subject to concept drift and evasive evolution of attackers, which renders up-to-date threat data as a necessity. However, due to enforcement of various privacy protection regulations (e.g., GDPR), it is becoming increasingly challenging or even prohibitive for security vendors to collect individual-relevant and privacy-sensitive threat datasets, e.g., SMS spam/non-spam messages from mobile devices. To address such obstacles, this study systematically profiles the (in)feasibility of federated learning for privacy-preserving cyber threat detection in terms of effectiveness, byzantine resilience, and efficiency. This is made possible by the build-up of multiple threat datasets and threat detection models, and more importantly, the design of realistic and security-specific experiments.   We evaluate FL on two representative threat detection tasks, namely SMS spam detection and Android malware detection. It shows that FL-trained detection models can achieve a performance that is comparable to centrally trained counterparts. Also, most non-IID data distributions have either minor or negligible impact on the model performance, while a label-based non-IID distribution of a high extent can incur non-negligible fluctuation and delay in FL training. Then, under a realistic threat model, FL turns out to be adversary-resistant to attacks of both data poisoning and model poisoning. Particularly, the attacking impact of a practical data poisoning attack is no more than 0.14\\% loss in model accuracy. Regarding FL efficiency, a bootstrapping strategy turns out to be effective to mitigate the training delay as observed in label-based non-IID scenarios.","sentences":["Despite achieving good performance and wide adoption, machine learning based security detection models (e.g., malware classifiers) are subject to concept drift and evasive evolution of attackers, which renders up-to-date threat data as a necessity.","However, due to enforcement of various privacy protection regulations (e.g., GDPR), it is becoming increasingly challenging or even prohibitive for security vendors to collect individual-relevant and privacy-sensitive threat datasets, e.g., SMS spam/non-spam messages from mobile devices.","To address such obstacles, this study systematically profiles the (in)feasibility of federated learning for privacy-preserving cyber threat detection in terms of effectiveness, byzantine resilience, and efficiency.","This is made possible by the build-up of multiple threat datasets and threat detection models, and more importantly, the design of realistic and security-specific experiments.   ","We evaluate FL on two representative threat detection tasks, namely SMS spam detection and Android malware detection.","It shows that FL-trained detection models can achieve a performance that is comparable to centrally trained counterparts.","Also, most non-IID data distributions have either minor or negligible impact on the model performance, while a label-based non-IID distribution of a high extent can incur non-negligible fluctuation and delay in FL training.","Then, under a realistic threat model, FL turns out to be adversary-resistant to attacks of both data poisoning and model poisoning.","Particularly, the attacking impact of a practical data poisoning attack is no more than 0.14\\% loss in model accuracy.","Regarding FL efficiency, a bootstrapping strategy turns out to be effective to mitigate the training delay as observed in label-based non-IID scenarios."],"url":"http://arxiv.org/abs/2404.05130v1"}
{"created":"2024-04-07 23:31:37","title":"Reconstructing Retinal Visual Images from 3T fMRI Data Enhanced by Unsupervised Learning","abstract":"The reconstruction of human visual inputs from brain activity, particularly through functional Magnetic Resonance Imaging (fMRI), holds promising avenues for unraveling the mechanisms of the human visual system. Despite the significant strides made by deep learning methods in improving the quality and interpretability of visual reconstruction, there remains a substantial demand for high-quality, long-duration, subject-specific 7-Tesla fMRI experiments. The challenge arises in integrating diverse smaller 3-Tesla datasets or accommodating new subjects with brief and low-quality fMRI scans. In response to these constraints, we propose a novel framework that generates enhanced 3T fMRI data through an unsupervised Generative Adversarial Network (GAN), leveraging unpaired training across two distinct fMRI datasets in 7T and 3T, respectively. This approach aims to overcome the limitations of the scarcity of high-quality 7-Tesla data and the challenges associated with brief and low-quality scans in 3-Tesla experiments. In this paper, we demonstrate the reconstruction capabilities of the enhanced 3T fMRI data, highlighting its proficiency in generating superior input visual images compared to data-intensive methods trained and tested on a single subject.","sentences":["The reconstruction of human visual inputs from brain activity, particularly through functional Magnetic Resonance Imaging (fMRI), holds promising avenues for unraveling the mechanisms of the human visual system.","Despite the significant strides made by deep learning methods in improving the quality and interpretability of visual reconstruction, there remains a substantial demand for high-quality, long-duration, subject-specific 7-Tesla fMRI experiments.","The challenge arises in integrating diverse smaller 3-Tesla datasets or accommodating new subjects with brief and low-quality fMRI scans.","In response to these constraints, we propose a novel framework that generates enhanced 3T fMRI data through an unsupervised Generative Adversarial Network (GAN), leveraging unpaired training across two distinct fMRI datasets in 7T and 3T, respectively.","This approach aims to overcome the limitations of the scarcity of high-quality 7-Tesla data and the challenges associated with brief and low-quality scans in 3-Tesla experiments.","In this paper, we demonstrate the reconstruction capabilities of the enhanced 3T fMRI data, highlighting its proficiency in generating superior input visual images compared to data-intensive methods trained and tested on a single subject."],"url":"http://arxiv.org/abs/2404.05107v1"}
{"created":"2024-04-07 23:28:35","title":"Stop Stealing My Data: Sanitizing Stego Channels in 3D Printing Design Files","abstract":"The increased adoption of additive manufacturing (AM) and the acceptance of AM outsourcing created an ecosystem in which the sending and receiving of digital designs by different actors became normal. It has recently been shown that the STL design files -- most commonly used in AM -- contain steganographic channels. Such channels can allow additional data to be embedded within the STL files without changing the printed model. These factors create a threat of misusing the design files as a covert communication channel to either exfiltrate stolen sensitive digital data from organizations or infiltrate malicious software into a secure environment. This paper addresses this security threat by designing and evaluating a \\emph{sanitizer} that erases hidden content where steganographic channels might exist. The proposed sanitizer takes into account a set of specific constraints imposed by the application domain, such as not affecting the ability to manufacture part of the required quality using the sanitized design.","sentences":["The increased adoption of additive manufacturing (AM) and the acceptance of AM outsourcing created an ecosystem in which the sending and receiving of digital designs by different actors became normal.","It has recently been shown that the STL design files -- most commonly used in AM -- contain steganographic channels.","Such channels can allow additional data to be embedded within the STL files without changing the printed model.","These factors create a threat of misusing the design files as a covert communication channel to either exfiltrate stolen sensitive digital data from organizations or infiltrate malicious software into a secure environment.","This paper addresses this security threat by designing and evaluating a \\emph{sanitizer} that erases hidden content where steganographic channels might exist.","The proposed sanitizer takes into account a set of specific constraints imposed by the application domain, such as not affecting the ability to manufacture part of the required quality using the sanitized design."],"url":"http://arxiv.org/abs/2404.05106v1"}
{"created":"2024-04-07 23:10:26","title":"VMambaMorph: a Visual Mamba-based Framework with Cross-Scan Module for Deformable 3D Image Registration","abstract":"Image registration, a critical process in medical imaging, involves aligning different sets of medical imaging data into a single unified coordinate system. Deep learning networks, such as the Convolutional Neural Network (CNN)-based VoxelMorph, Vision Transformer (ViT)-based TransMorph, and State Space Model (SSM)-based MambaMorph, have demonstrated effective performance in this domain. The recent Visual State Space Model (VMamba), which incorporates a cross-scan module with SSM, has exhibited promising improvements in modeling global-range dependencies with efficient computational cost in computer vision tasks. This paper hereby introduces an exploration of VMamba with image registration, named VMambaMorph. This novel hybrid VMamba-CNN network is designed specifically for 3D image registration. Utilizing a U-shaped network architecture, VMambaMorph computes the deformation field based on target and source volumes. The VMamba-based block with 2D cross-scan module is redesigned for 3D volumetric feature processing, and a fine-grained feature extraction module is proposed for high-dimensional feature learning. We validate VMambaMorph using a public benchmark brain MR-CT registration dataset, comparing its performance against current state-of-the-art methods. The results indicate that VMambaMorph achieves competitive registration quality. The code for VMambaMorph is available on GitHub.","sentences":["Image registration, a critical process in medical imaging, involves aligning different sets of medical imaging data into a single unified coordinate system.","Deep learning networks, such as the Convolutional Neural Network (CNN)-based VoxelMorph, Vision Transformer (ViT)-based TransMorph, and State Space Model (SSM)-based MambaMorph, have demonstrated effective performance in this domain.","The recent Visual State Space Model (VMamba), which incorporates a cross-scan module with SSM, has exhibited promising improvements in modeling global-range dependencies with efficient computational cost in computer vision tasks.","This paper hereby introduces an exploration of VMamba with image registration, named VMambaMorph.","This novel hybrid VMamba-CNN network is designed specifically for 3D image registration.","Utilizing a U-shaped network architecture, VMambaMorph computes the deformation field based on target and source volumes.","The VMamba-based block with 2D cross-scan module is redesigned for 3D volumetric feature processing, and a fine-grained feature extraction module is proposed for high-dimensional feature learning.","We validate VMambaMorph using a public benchmark brain MR-CT registration dataset, comparing its performance against current state-of-the-art methods.","The results indicate that VMambaMorph achieves competitive registration quality.","The code for VMambaMorph is available on GitHub."],"url":"http://arxiv.org/abs/2404.05105v1"}
{"created":"2024-04-07 22:59:28","title":"Chart What I Say: Exploring Cross-Modality Prompt Alignment in AI-Assisted Chart Authoring","abstract":"Recent chart-authoring systems, such as Amazon Q in QuickSight and Copilot for Power BI, demonstrate an emergent focus on supporting natural language input to share meaningful insights from data through chart creation. Currently, chart-authoring systems tend to integrate voice input capabilities by relying on speech-to-text transcription, processing spoken and typed input similarly. However, cross-modality input comparisons in other interaction domains suggest that the structure of spoken and typed-in interactions could notably differ, reflecting variations in user expectations based on interface affordances. Thus, in this work, we compare spoken and typed instructions for chart creation. Findings suggest that while both text and voice instructions cover chart elements and element organization, voice descriptions have a variety of command formats, element characteristics, and complex linguistic features. Based on these findings, we developed guidelines for designing voice-based authoring-oriented systems and additional features that can be incorporated into existing text-based systems to support speech modality.","sentences":["Recent chart-authoring systems, such as Amazon Q in QuickSight and Copilot for Power BI, demonstrate an emergent focus on supporting natural language input to share meaningful insights from data through chart creation.","Currently, chart-authoring systems tend to integrate voice input capabilities by relying on speech-to-text transcription, processing spoken and typed input similarly.","However, cross-modality input comparisons in other interaction domains suggest that the structure of spoken and typed-in interactions could notably differ, reflecting variations in user expectations based on interface affordances.","Thus, in this work, we compare spoken and typed instructions for chart creation.","Findings suggest that while both text and voice instructions cover chart elements and element organization, voice descriptions have a variety of command formats, element characteristics, and complex linguistic features.","Based on these findings, we developed guidelines for designing voice-based authoring-oriented systems and additional features that can be incorporated into existing text-based systems to support speech modality."],"url":"http://arxiv.org/abs/2404.05103v1"}
{"created":"2024-04-07 22:31:34","title":"Active Test-Time Adaptation: Theoretical Analyses and An Algorithm","abstract":"Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings. Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies.   To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting.   We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee. We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques. Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods. Our code is available at https://github.com/divelab/ATTA","sentences":["Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings.","Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies.   ","To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting.   ","We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee.","We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF).","We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques.","Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods.","Our code is available at https://github.com/divelab/ATTA"],"url":"http://arxiv.org/abs/2404.05094v1"}
{"created":"2024-04-07 22:15:13","title":"How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse","abstract":"The phenomenon of model collapse, introduced in (Shumailov et al., 2023), refers to the deterioration in performance that occurs when new models are trained on synthetic data generated from previously trained models. This recursive training loop makes the tails of the original distribution disappear, thereby making future-generation models forget about the initial (real) distribution. With the aim of rigorously understanding model collapse in language models, we consider in this paper a statistical model that allows us to characterize the impact of various recursive training scenarios. Specifically, we demonstrate that model collapse cannot be avoided when training solely on synthetic data. However, when mixing both real and synthetic data, we provide an estimate of a maximal amount of synthetic data below which model collapse can eventually be avoided. Our theoretical conclusions are further supported by empirical validations.","sentences":["The phenomenon of model collapse, introduced in (Shumailov et al., 2023), refers to the deterioration in performance that occurs when new models are trained on synthetic data generated from previously trained models.","This recursive training loop makes the tails of the original distribution disappear, thereby making future-generation models forget about the initial (real) distribution.","With the aim of rigorously understanding model collapse in language models, we consider in this paper a statistical model that allows us to characterize the impact of various recursive training scenarios.","Specifically, we demonstrate that model collapse cannot be avoided when training solely on synthetic data.","However, when mixing both real and synthetic data, we provide an estimate of a maximal amount of synthetic data below which model collapse can eventually be avoided.","Our theoretical conclusions are further supported by empirical validations."],"url":"http://arxiv.org/abs/2404.05090v1"}
{"created":"2024-04-07 21:57:45","title":"Fork is All You Needed in Heterogeneous Systems","abstract":"We present a unified programming model for heterogeneous computing systems. Such systems integrate multiple computing accelerators and memory units to deliver higher performance than CPU-centric systems. Although heterogeneous systems have been adopted by modern workloads such as machine learning, programming remains a critical limiting factor. Conventional heterogeneous programming techniques either impose heavy modifications to the code base or require rewriting the program in a different language. Such programming complexity stems from the lack of a unified abstraction layer for computing and data exchange, which forces each programming model to define its abstractions. However, with the emerging cache-coherent interconnections such as Compute Express Link, we see an opportunity to standardize such architecture heterogeneity and provide a unified programming model. We present CodeFlow, a language runtime system for heterogeneous computing. CodeFlow abstracts architecture computation in programming language runtime and utilizes CXL as a unified data exchange protocol. Workloads written in high-level languages such as C++ and Rust can be compiled to CodeFlow, which schedules different parts of the workload to suitable accelerators without requiring the developer to implement code or call APIs for specific accelerators. CodeFlow reduces programmers' effort in utilizing heterogeneous systems and improves workload performance.","sentences":["We present a unified programming model for heterogeneous computing systems.","Such systems integrate multiple computing accelerators and memory units to deliver higher performance than CPU-centric systems.","Although heterogeneous systems have been adopted by modern workloads such as machine learning, programming remains a critical limiting factor.","Conventional heterogeneous programming techniques either impose heavy modifications to the code base or require rewriting the program in a different language.","Such programming complexity stems from the lack of a unified abstraction layer for computing and data exchange, which forces each programming model to define its abstractions.","However, with the emerging cache-coherent interconnections such as Compute Express Link, we see an opportunity to standardize such architecture heterogeneity and provide a unified programming model.","We present CodeFlow, a language runtime system for heterogeneous computing.","CodeFlow abstracts architecture computation in programming language runtime and utilizes CXL as a unified data exchange protocol.","Workloads written in high-level languages such as C++ and Rust can be compiled to CodeFlow, which schedules different parts of the workload to suitable accelerators without requiring the developer to implement code or call APIs for specific accelerators.","CodeFlow reduces programmers' effort in utilizing heterogeneous systems and improves workload performance."],"url":"http://arxiv.org/abs/2404.05085v1"}
{"created":"2024-04-07 21:46:47","title":"HaVTR: Improving Video-Text Retrieval Through Augmentation Using Large Foundation Models","abstract":"While recent progress in video-text retrieval has been driven by the exploration of powerful model architectures and training strategies, the representation learning ability of video-text retrieval models is still limited due to low-quality and scarce training data annotations. To address this issue, we present a novel video-text learning paradigm, HaVTR, which augments video and text data to learn more generalized features. Specifically, we first adopt a simple augmentation method, which generates self-similar data by randomly duplicating or dropping subwords and frames. In addition, inspired by the recent advancement in visual and language generative models, we propose a more powerful augmentation method through textual paraphrasing and video stylization using large language models (LLMs) and visual generative models (VGMs). Further, to bring richer information into video and text, we propose a hallucination-based augmentation method, where we use LLMs and VGMs to generate and add new relevant information to the original data. Benefiting from the enriched data, extensive experiments on several video-text retrieval benchmarks demonstrate the superiority of HaVTR over existing methods.","sentences":["While recent progress in video-text retrieval has been driven by the exploration of powerful model architectures and training strategies, the representation learning ability of video-text retrieval models is still limited due to low-quality and scarce training data annotations.","To address this issue, we present a novel video-text learning paradigm, HaVTR, which augments video and text data to learn more generalized features.","Specifically, we first adopt a simple augmentation method, which generates self-similar data by randomly duplicating or dropping subwords and frames.","In addition, inspired by the recent advancement in visual and language generative models, we propose a more powerful augmentation method through textual paraphrasing and video stylization using large language models (LLMs) and visual generative models (VGMs).","Further, to bring richer information into video and text, we propose a hallucination-based augmentation method, where we use LLMs and VGMs to generate and add new relevant information to the original data.","Benefiting from the enriched data, extensive experiments on several video-text retrieval benchmarks demonstrate the superiority of HaVTR over existing methods."],"url":"http://arxiv.org/abs/2404.05083v1"}
{"created":"2024-04-07 20:50:13","title":"Test-Time Training for Depression Detection","abstract":"Previous works on depression detection use datasets collected in similar environments to train and test the models. In practice, however, the train and test distributions cannot be guaranteed to be identical. Distribution shifts can be introduced due to variations such as recording environment (e.g., background noise) and demographics (e.g., gender, age, etc). Such distributional shifts can surprisingly lead to severe performance degradation of the depression detection models. In this paper, we analyze the application of test-time training (TTT) to improve robustness of models trained for depression detection. When compared to regular testing of the models, we find TTT can significantly improve the robustness of the model under a variety of distributional shifts introduced due to: (a) background-noise, (b) gender-bias, and (c) data collection and curation procedure (i.e., train and test samples are from separate datasets).","sentences":["Previous works on depression detection use datasets collected in similar environments to train and test the models.","In practice, however, the train and test distributions cannot be guaranteed to be identical.","Distribution shifts can be introduced due to variations such as recording environment (e.g., background noise) and demographics (e.g., gender, age, etc).","Such distributional shifts can surprisingly lead to severe performance degradation of the depression detection models.","In this paper, we analyze the application of test-time training (TTT) to improve robustness of models trained for depression detection.","When compared to regular testing of the models, we find TTT can significantly improve the robustness of the model under a variety of distributional shifts introduced due to: (a) background-noise, (b) gender-bias, and (c) data collection and curation procedure (i.e., train and test samples are from separate datasets)."],"url":"http://arxiv.org/abs/2404.05071v1"}
{"created":"2024-04-07 20:39:31","title":"AirShot: Efficient Few-Shot Detection for Autonomous Exploration","abstract":"Few-shot object detection has drawn increasing attention in the field of robotic exploration, where robots are required to find unseen objects with a few online provided examples. Despite recent efforts have been made to yield online processing capabilities, slow inference speeds of low-powered robots fail to meet the demands of real-time detection-making them impractical for autonomous exploration. Existing methods still face performance and efficiency challenges, mainly due to unreliable features and exhaustive class loops. In this work, we propose a new paradigm AirShot, and discover that, by fully exploiting the valuable correlation map, AirShot can result in a more robust and faster few-shot object detection system, which is more applicable to robotics community. The core module Top Prediction Filter (TPF) can operate on multi-scale correlation maps in both the training and inference stages. During training, TPF supervises the generation of a more representative correlation map, while during inference, it reduces looping iterations by selecting top-ranked classes, thus cutting down on computational costs with better performance. Surprisingly, this dual functionality exhibits general effectiveness and efficiency on various off-the-shelf models. Exhaustive experiments on COCO2017, VOC2014, and SubT datasets demonstrate that TPF can significantly boost the efficacy and efficiency of most off-the-shelf models, achieving up to 36.4% precision improvements along with 56.3% faster inference speed. Code and Data are at: https://github.com/ImNotPrepared/AirShot.","sentences":["Few-shot object detection has drawn increasing attention in the field of robotic exploration, where robots are required to find unseen objects with a few online provided examples.","Despite recent efforts have been made to yield online processing capabilities, slow inference speeds of low-powered robots fail to meet the demands of real-time detection-making them impractical for autonomous exploration.","Existing methods still face performance and efficiency challenges, mainly due to unreliable features and exhaustive class loops.","In this work, we propose a new paradigm AirShot, and discover that, by fully exploiting the valuable correlation map, AirShot can result in a more robust and faster few-shot object detection system, which is more applicable to robotics community.","The core module Top Prediction Filter (TPF) can operate on multi-scale correlation maps in both the training and inference stages.","During training, TPF supervises the generation of a more representative correlation map, while during inference, it reduces looping iterations by selecting top-ranked classes, thus cutting down on computational costs with better performance.","Surprisingly, this dual functionality exhibits general effectiveness and efficiency on various off-the-shelf models.","Exhaustive experiments on COCO2017, VOC2014, and SubT datasets demonstrate that TPF can significantly boost the efficacy and efficiency of most off-the-shelf models, achieving up to 36.4% precision improvements along with 56.3% faster inference speed.","Code and Data are at: https://github.com/ImNotPrepared/AirShot."],"url":"http://arxiv.org/abs/2404.05069v1"}
{"created":"2024-04-07 20:15:40","title":"Automated Prediction of Breast Cancer Response to Neoadjuvant Chemotherapy from DWI Data","abstract":"Effective surgical planning for breast cancer hinges on accurately predicting pathological complete response (pCR) to neoadjuvant chemotherapy (NAC). Diffusion-weighted MRI (DWI) and machine learning offer a non-invasive approach for early pCR assessment. However, most machine-learning models require manual tumor segmentation, a cumbersome and error-prone task. We propose a deep learning model employing \"Size-Adaptive Lesion Weighting\" for automatic DWI tumor segmentation to enhance pCR prediction accuracy. Despite histopathological changes during NAC complicating DWI image segmentation, our model demonstrates robust performance. Utilizing the BMMR2 challenge dataset, it matches human experts in pCR prediction pre-NAC with an area under the curve (AUC) of 0.76 vs. 0.796, and surpasses standard automated methods mid-NAC, with an AUC of 0.729 vs. 0.654 and 0.576. Our approach represents a significant advancement in automating breast cancer treatment planning, enabling more reliable pCR predictions without manual segmentation.","sentences":["Effective surgical planning for breast cancer hinges on accurately predicting pathological complete response (pCR) to neoadjuvant chemotherapy (NAC).","Diffusion-weighted MRI (DWI) and machine learning offer a non-invasive approach for early pCR assessment.","However, most machine-learning models require manual tumor segmentation, a cumbersome and error-prone task.","We propose a deep learning model employing \"Size-Adaptive Lesion Weighting\" for automatic DWI tumor segmentation to enhance pCR prediction accuracy.","Despite histopathological changes during NAC complicating DWI image segmentation, our model demonstrates robust performance.","Utilizing the BMMR2 challenge dataset, it matches human experts in pCR prediction pre-NAC with an area under the curve (AUC) of 0.76 vs. 0.796, and surpasses standard automated methods mid-NAC, with an AUC of 0.729 vs. 0.654 and 0.576.","Our approach represents a significant advancement in automating breast cancer treatment planning, enabling more reliable pCR predictions without manual segmentation."],"url":"http://arxiv.org/abs/2404.05061v1"}
{"created":"2024-04-07 20:05:49","title":"A robust assessment for invariant representations","abstract":"The performance of machine learning models can be impacted by changes in data over time. A promising approach to address this challenge is invariant learning, with a particular focus on a method known as invariant risk minimization (IRM). This technique aims to identify a stable data representation that remains effective with out-of-distribution (OOD) data. While numerous studies have developed IRM-based methods adaptive to data augmentation scenarios, there has been limited attention on directly assessing how well these representations preserve their invariant performance under varying conditions. In our paper, we propose a novel method to evaluate invariant performance, specifically tailored for IRM-based methods. We establish a bridge between the conditional expectation of an invariant predictor across different environments through the likelihood ratio. Our proposed criterion offers a robust basis for evaluating invariant performance. We validate our approach with theoretical support and demonstrate its effectiveness through extensive numerical studies.These experiments illustrate how our method can assess the invariant performance of various representation techniques.","sentences":["The performance of machine learning models can be impacted by changes in data over time.","A promising approach to address this challenge is invariant learning, with a particular focus on a method known as invariant risk minimization (IRM).","This technique aims to identify a stable data representation that remains effective with out-of-distribution (OOD) data.","While numerous studies have developed IRM-based methods adaptive to data augmentation scenarios, there has been limited attention on directly assessing how well these representations preserve their invariant performance under varying conditions.","In our paper, we propose a novel method to evaluate invariant performance, specifically tailored for IRM-based methods.","We establish a bridge between the conditional expectation of an invariant predictor across different environments through the likelihood ratio.","Our proposed criterion offers a robust basis for evaluating invariant performance.","We validate our approach with theoretical support and demonstrate its effectiveness through extensive numerical studies.","These experiments illustrate how our method can assess the invariant performance of various representation techniques."],"url":"http://arxiv.org/abs/2404.05058v1"}
{"created":"2024-04-07 19:29:09","title":"Percentile Criterion Optimization in Offline Reinforcement Learning","abstract":"In reinforcement learning, robust policies for high-stakes decision-making problems with limited data are usually computed by optimizing the \\emph{percentile criterion}. The percentile criterion is approximately solved by constructing an \\emph{ambiguity set} that contains the true model with high probability and optimizing the policy for the worst model in the set. Since the percentile criterion is non-convex, constructing ambiguity sets is often challenging. Existing work uses \\emph{Bayesian credible regions} as ambiguity sets, but they are often unnecessarily large and result in learning overly conservative policies. To overcome these shortcomings, we propose a novel Value-at-Risk based dynamic programming algorithm to optimize the percentile criterion without explicitly constructing any ambiguity sets. Our theoretical and empirical results show that our algorithm implicitly constructs much smaller ambiguity sets and learns less conservative robust policies.","sentences":["In reinforcement learning, robust policies for high-stakes decision-making problems with limited data are usually computed by optimizing the \\emph{percentile criterion}.","The percentile criterion is approximately solved by constructing an \\emph{ambiguity set} that contains the true model with high probability and optimizing the policy for the worst model in the set.","Since the percentile criterion is non-convex, constructing ambiguity sets is often challenging.","Existing work uses \\emph{Bayesian credible regions} as ambiguity sets, but they are often unnecessarily large and result in learning overly conservative policies.","To overcome these shortcomings, we propose a novel Value-at-Risk based dynamic programming algorithm to optimize the percentile criterion without explicitly constructing any ambiguity sets.","Our theoretical and empirical results show that our algorithm implicitly constructs much smaller ambiguity sets and learns less conservative robust policies."],"url":"http://arxiv.org/abs/2404.05055v1"}
{"created":"2024-04-07 19:22:51","title":"Skill Transfer and Discovery for Sim-to-Real Learning: A Representation-Based Viewpoint","abstract":"We study sim-to-real skill transfer and discovery in the context of robotics control using representation learning. We draw inspiration from spectral decomposition of Markov decision processes. The spectral decomposition brings about representation that can linearly represent the state-action value function induced by any policies, thus can be regarded as skills. The skill representations are transferable across arbitrary tasks with the same transition dynamics. Moreover, to handle the sim-to-real gap in the dynamics, we propose a skill discovery algorithm that learns new skills caused by the sim-to-real gap from real-world data. We promote the discovery of new skills by enforcing orthogonal constraints between the skills to learn and the skills from simulators, and then synthesize the policy using the enlarged skill sets. We demonstrate our methodology by transferring quadrotor controllers from simulators to Crazyflie 2.1 quadrotors. We show that we can learn the skill representations from a single simulator task and transfer these to multiple different real-world tasks including hovering, taking off, landing and trajectory tracking. Our skill discovery approach helps narrow the sim-to-real gap and improve the real-world controller performance by up to 30.2%.","sentences":["We study sim-to-real skill transfer and discovery in the context of robotics control using representation learning.","We draw inspiration from spectral decomposition of Markov decision processes.","The spectral decomposition brings about representation that can linearly represent the state-action value function induced by any policies, thus can be regarded as skills.","The skill representations are transferable across arbitrary tasks with the same transition dynamics.","Moreover, to handle the sim-to-real gap in the dynamics, we propose a skill discovery algorithm that learns new skills caused by the sim-to-real gap from real-world data.","We promote the discovery of new skills by enforcing orthogonal constraints between the skills to learn and the skills from simulators, and then synthesize the policy using the enlarged skill sets.","We demonstrate our methodology by transferring quadrotor controllers from simulators to Crazyflie 2.1 quadrotors.","We show that we can learn the skill representations from a single simulator task and transfer these to multiple different real-world tasks including hovering, taking off, landing and trajectory tracking.","Our skill discovery approach helps narrow the sim-to-real gap and improve the real-world controller performance by up to 30.2%."],"url":"http://arxiv.org/abs/2404.05051v1"}
{"created":"2024-04-07 19:10:02","title":"PlateSegFL: A Privacy-Preserving License Plate Detection Using Federated Segmentation Learning","abstract":"Automatic License Plate Recognition (ALPR) is an integral component of an intelligent transport system with extensive applications in secure transportation, vehicle-to-vehicle communication, stolen vehicles detection, traffic violations, and traffic flow management. The existing license plate detection system focuses on one-shot learners or pre-trained models that operate with a geometric bounding box, limiting the model's performance. Furthermore, continuous video data streams uploaded to the central server result in network and complexity issues. To combat this, PlateSegFL was introduced, which implements U-Net-based segmentation along with Federated Learning (FL). U-Net is well-suited for multi-class image segmentation tasks because it can analyze a large number of classes and generate a pixel-level segmentation map for each class. Federated Learning is used to reduce the quantity of data required while safeguarding the user's privacy. Different computing platforms, such as mobile phones, are able to collaborate on the development of a standard prediction model where it makes efficient use of one's time; incorporates more diverse data; delivers projections in real-time; and requires no physical effort from the user; resulting around 95% F1 score.","sentences":["Automatic License Plate Recognition (ALPR) is an integral component of an intelligent transport system with extensive applications in secure transportation, vehicle-to-vehicle communication, stolen vehicles detection, traffic violations, and traffic flow management.","The existing license plate detection system focuses on one-shot learners or pre-trained models that operate with a geometric bounding box, limiting the model's performance.","Furthermore, continuous video data streams uploaded to the central server result in network and complexity issues.","To combat this, PlateSegFL was introduced, which implements U-Net-based segmentation along with Federated Learning (FL).","U-Net is well-suited for multi-class image segmentation tasks because it can analyze a large number of classes and generate a pixel-level segmentation map for each class.","Federated Learning is used to reduce the quantity of data required while safeguarding the user's privacy.","Different computing platforms, such as mobile phones, are able to collaborate on the development of a standard prediction model where it makes efficient use of one's time; incorporates more diverse data; delivers projections in real-time; and requires no physical effort from the user; resulting around 95% F1 score."],"url":"http://arxiv.org/abs/2404.05049v1"}
{"created":"2024-04-07 19:02:50","title":"Initial Exploration of Zero-Shot Privacy Utility Tradeoffs in Tabular Data Using GPT-4","abstract":"We investigate the application of large language models (LLMs), specifically GPT-4, to scenarios involving the tradeoff between privacy and utility in tabular data. Our approach entails prompting GPT-4 by transforming tabular data points into textual format, followed by the inclusion of precise sanitization instructions in a zero-shot manner. The primary objective is to sanitize the tabular data in such a way that it hinders existing machine learning models from accurately inferring private features while allowing models to accurately infer utility-related attributes. We explore various sanitization instructions. Notably, we discover that this relatively simple approach yields performance comparable to more complex adversarial optimization methods used for managing privacy-utility tradeoffs. Furthermore, while the prompts successfully obscure private features from the detection capabilities of existing machine learning models, we observe that this obscuration alone does not necessarily meet a range of fairness metrics. Nevertheless, our research indicates the potential effectiveness of LLMs in adhering to these fairness metrics, with some of our experimental results aligning with those achieved by well-established adversarial optimization techniques.","sentences":["We investigate the application of large language models (LLMs), specifically GPT-4, to scenarios involving the tradeoff between privacy and utility in tabular data.","Our approach entails prompting GPT-4 by transforming tabular data points into textual format, followed by the inclusion of precise sanitization instructions in a zero-shot manner.","The primary objective is to sanitize the tabular data in such a way that it hinders existing machine learning models from accurately inferring private features while allowing models to accurately infer utility-related attributes.","We explore various sanitization instructions.","Notably, we discover that this relatively simple approach yields performance comparable to more complex adversarial optimization methods used for managing privacy-utility tradeoffs.","Furthermore, while the prompts successfully obscure private features from the detection capabilities of existing machine learning models, we observe that this obscuration alone does not necessarily meet a range of fairness metrics.","Nevertheless, our research indicates the potential effectiveness of LLMs in adhering to these fairness metrics, with some of our experimental results aligning with those achieved by well-established adversarial optimization techniques."],"url":"http://arxiv.org/abs/2404.05047v1"}
{"created":"2024-04-07 19:00:45","title":"FGAIF: Aligning Large Vision-Language Models with Fine-grained AI Feedback","abstract":"Large Vision-Language Models (LVLMs) have demonstrated proficiency in tackling a variety of visual-language tasks. However, current LVLMs suffer from misalignment between text and image modalities which causes three kinds of hallucination problems, i.e., object existence, object attribute, and object relationship. To tackle this issue, existing methods mainly utilize Reinforcement Learning (RL) to align modalities in LVLMs. However, they still suffer from three main limitations: (1) General feedback can not indicate the hallucination type contained in the response; (2) Sparse rewards only give the sequence-level reward for the whole response; and (3)Annotation cost is time-consuming and labor-intensive. To handle these limitations, we propose an innovative method to align modalities in LVLMs through Fine-Grained Artificial Intelligence Feedback (FGAIF), which mainly consists of three steps: AI-based Feedback Collection, Fine-grained Reward Model Training, and Reinforcement Learning with Fine-grained Reward. Specifically, We first utilize AI tools to predict the types of hallucination for each segment in the response and obtain a collection of fine-grained feedback. Then, based on the collected reward data, three specialized reward models are trained to produce dense rewards. Finally, a novel fine-grained feedback module is integrated into the Proximal Policy Optimization (PPO) algorithm. Extensive experiments are conducted on hallucination and general benchmarks, demonstrating the superior performance of our proposed method. Notably, compared with previous models trained with the RL-based aligning method, our proposed method is effective even with fewer parameters.","sentences":["Large Vision-Language Models (LVLMs) have demonstrated proficiency in tackling a variety of visual-language tasks.","However, current LVLMs suffer from misalignment between text and image modalities which causes three kinds of hallucination problems, i.e., object existence, object attribute, and object relationship.","To tackle this issue, existing methods mainly utilize Reinforcement Learning (RL) to align modalities in LVLMs.","However, they still suffer from three main limitations: (1) General feedback can not indicate the hallucination type contained in the response; (2) Sparse rewards only give the sequence-level reward for the whole response; and (3)Annotation cost is time-consuming and labor-intensive.","To handle these limitations, we propose an innovative method to align modalities in LVLMs through Fine-Grained Artificial Intelligence Feedback (FGAIF), which mainly consists of three steps: AI-based Feedback Collection, Fine-grained Reward Model Training, and Reinforcement Learning with Fine-grained Reward.","Specifically, We first utilize AI tools to predict the types of hallucination for each segment in the response and obtain a collection of fine-grained feedback.","Then, based on the collected reward data, three specialized reward models are trained to produce dense rewards.","Finally, a novel fine-grained feedback module is integrated into the Proximal Policy Optimization (PPO) algorithm.","Extensive experiments are conducted on hallucination and general benchmarks, demonstrating the superior performance of our proposed method.","Notably, compared with previous models trained with the RL-based aligning method, our proposed method is effective even with fewer parameters."],"url":"http://arxiv.org/abs/2404.05046v1"}
{"created":"2024-04-07 19:00:12","title":"Spanners in Planar Domains via Steiner Spanners and non-Steiner Tree Covers","abstract":"We study spanners in planar domains, including polygonal domains, polyhedral terrain, and planar metrics. Previous work showed that for any constant $\\epsilon\\in (0,1)$, one could construct a $(2+\\epsilon)$-spanner with $O(n\\log(n))$ edges (SICOMP 2019), and there is a lower bound of $\\Omega(n^2)$ edges for any $(2-\\epsilon)$-spanner (SoCG 2015). The main open question is whether a linear number of edges suffices and the stretch can be reduced to $2$. We resolve this problem by showing that for stretch $2$, one needs $\\Omega(n\\log n)$ edges, and for stretch $2+\\epsilon$ for any fixed $\\epsilon \\in (0,1)$, $O(n)$ edges are sufficient. Our lower bound is the first super-linear lower bound for stretch $2$.   En route to achieve our result, we introduce the problem of constructing non-Steiner tree covers for metrics, which is a natural variant of the well-known Steiner point removal problem for trees (SODA 2001). Given a tree and a set of terminals in the tree, our goal is to construct a collection of a small number of dominating trees such that for every two points, at least one tree in the collection preserves their distance within a small stretch factor. Here, we identify an unexpected threshold phenomenon around $2$ where a sharp transition from $n$ trees to $\\Theta(\\log n)$ trees and then to $O(1)$ trees happens. Specifically, (i) for stretch $ 2-\\epsilon$, one needs $\\Omega(n)$ trees; (ii) for stretch $2$, $\\Theta(\\log n)$ tree is necessary and sufficient; and (iii) for stretch $2+\\epsilon$, a constant number of trees suffice. Furthermore, our lower bound technique for the non-Steiner tree covers of stretch $2$ has further applications in proving lower bounds for two related constructions in tree metrics: reliable spanners and locality-sensitive orderings. Our lower bound for locality-sensitive orderings matches the best upper bound (STOC 2022).","sentences":["We study spanners in planar domains, including polygonal domains, polyhedral terrain, and planar metrics.","Previous work showed that for any constant $\\epsilon\\in (0,1)$, one could construct a $(2+\\epsilon)$-spanner with $O(n\\log(n))$ edges (SICOMP 2019), and there is a lower bound of $\\Omega(n^2)$ edges for any $(2-\\epsilon)$-spanner (SoCG 2015).","The main open question is whether a linear number of edges suffices and the stretch can be reduced to $2$. We resolve this problem by showing that for stretch $2$, one needs $\\Omega(n\\log n)$ edges, and for stretch $2+\\epsilon$ for any fixed $\\epsilon \\in (0,1)$, $O(n)$ edges are sufficient.","Our lower bound is the first super-linear lower bound for stretch $2$.   En route to achieve our result, we introduce the problem of constructing non-Steiner tree covers for metrics, which is a natural variant of the well-known Steiner point removal problem for trees (SODA 2001).","Given a tree and a set of terminals in the tree, our goal is to construct a collection of a small number of dominating trees such that for every two points, at least one tree in the collection preserves their distance within a small stretch factor.","Here, we identify an unexpected threshold phenomenon around $2$ where a sharp transition from $n$ trees to $\\Theta(\\log n)$ trees and then to $O(1)$ trees happens.","Specifically, (i) for stretch $ 2-\\epsilon$, one needs $\\Omega(n)$ trees; (ii) for stretch $2$, $\\Theta(\\log n)$ tree is necessary and sufficient; and (iii) for stretch $2+\\epsilon$, a constant number of trees suffice.","Furthermore, our lower bound technique for the non-Steiner tree covers of stretch $2$ has further applications in proving lower bounds for two related constructions in tree metrics: reliable spanners and locality-sensitive orderings.","Our lower bound for locality-sensitive orderings matches the best upper bound (STOC 2022)."],"url":"http://arxiv.org/abs/2404.05045v1"}
{"created":"2024-04-07 18:55:33","title":"Optimizing Privacy and Utility Tradeoffs for Group Interests Through Harmonization","abstract":"We propose a novel problem formulation to address the privacy-utility tradeoff, specifically when dealing with two distinct user groups characterized by unique sets of private and utility attributes. Unlike previous studies that primarily focus on scenarios where all users share identical private and utility attributes and often rely on auxiliary datasets or manual annotations, we introduce a collaborative data-sharing mechanism between two user groups through a trusted third party. This third party uses adversarial privacy techniques with our proposed data-sharing mechanism to internally sanitize data for both groups and eliminates the need for manual annotation or auxiliary datasets. Our methodology ensures that private attributes cannot be accurately inferred while enabling highly accurate predictions of utility features. Importantly, even if analysts or adversaries possess auxiliary datasets containing raw data, they are unable to accurately deduce private features. Additionally, our data-sharing mechanism is compatible with various existing adversarially trained privacy techniques. We empirically demonstrate the effectiveness of our approach using synthetic and real-world datasets, showcasing its ability to balance the conflicting goals of privacy and utility.","sentences":["We propose a novel problem formulation to address the privacy-utility tradeoff, specifically when dealing with two distinct user groups characterized by unique sets of private and utility attributes.","Unlike previous studies that primarily focus on scenarios where all users share identical private and utility attributes and often rely on auxiliary datasets or manual annotations, we introduce a collaborative data-sharing mechanism between two user groups through a trusted third party.","This third party uses adversarial privacy techniques with our proposed data-sharing mechanism to internally sanitize data for both groups and eliminates the need for manual annotation or auxiliary datasets.","Our methodology ensures that private attributes cannot be accurately inferred while enabling highly accurate predictions of utility features.","Importantly, even if analysts or adversaries possess auxiliary datasets containing raw data, they are unable to accurately deduce private features.","Additionally, our data-sharing mechanism is compatible with various existing adversarially trained privacy techniques.","We empirically demonstrate the effectiveness of our approach using synthetic and real-world datasets, showcasing its ability to balance the conflicting goals of privacy and utility."],"url":"http://arxiv.org/abs/2404.05043v1"}
{"created":"2024-04-07 18:52:10","title":"Lagrangian operator inference enhanced with structure-preserving machine learning for nonintrusive model reduction of mechanical systems","abstract":"Complex mechanical systems often exhibit strongly nonlinear behavior due to the presence of nonlinearities in the energy dissipation mechanisms, material constitutive relationships, or geometric/connectivity mechanics. Numerical modeling of these systems leads to nonlinear full-order models that possess an underlying Lagrangian structure. This work proposes a Lagrangian operator inference method enhanced with structure-preserving machine learning to learn nonlinear reduced-order models (ROMs) of nonlinear mechanical systems. This two-step approach first learns the best-fit linear Lagrangian ROM via Lagrangian operator inference and then presents a structure-preserving machine learning method to learn nonlinearities in the reduced space. The proposed approach can learn a structure-preserving nonlinear ROM purely from data, unlike the existing operator inference approaches that require knowledge about the mathematical form of nonlinear terms. From a machine learning perspective, it accelerates the training of the structure-preserving neural network by providing an informed prior, and it reduces the computational cost of the network training by operating on the reduced space. The method is first demonstrated on two simulated examples: a conservative nonlinear rod model and a two-dimensional nonlinear membrane with nonlinear internal damping. Finally, the method is demonstrated on an experimental dataset consisting of digital image correlation measurements taken from a lap-joint beam structure from which a predictive model is learned that captures amplitude-dependent frequency and damping characteristics accurately. The numerical results demonstrate that the proposed approach yields generalizable nonlinear ROMs that exhibit bounded energy error, capture the nonlinear characteristics reliably, and provide accurate long-time predictions outside the training data regime.","sentences":["Complex mechanical systems often exhibit strongly nonlinear behavior due to the presence of nonlinearities in the energy dissipation mechanisms, material constitutive relationships, or geometric/connectivity mechanics.","Numerical modeling of these systems leads to nonlinear full-order models that possess an underlying Lagrangian structure.","This work proposes a Lagrangian operator inference method enhanced with structure-preserving machine learning to learn nonlinear reduced-order models (ROMs) of nonlinear mechanical systems.","This two-step approach first learns the best-fit linear Lagrangian ROM via Lagrangian operator inference and then presents a structure-preserving machine learning method to learn nonlinearities in the reduced space.","The proposed approach can learn a structure-preserving nonlinear ROM purely from data, unlike the existing operator inference approaches that require knowledge about the mathematical form of nonlinear terms.","From a machine learning perspective, it accelerates the training of the structure-preserving neural network by providing an informed prior, and it reduces the computational cost of the network training by operating on the reduced space.","The method is first demonstrated on two simulated examples: a conservative nonlinear rod model and a two-dimensional nonlinear membrane with nonlinear internal damping.","Finally, the method is demonstrated on an experimental dataset consisting of digital image correlation measurements taken from a lap-joint beam structure from which a predictive model is learned that captures amplitude-dependent frequency and damping characteristics accurately.","The numerical results demonstrate that the proposed approach yields generalizable nonlinear ROMs that exhibit bounded energy error, capture the nonlinear characteristics reliably, and provide accurate long-time predictions outside the training data regime."],"url":"http://arxiv.org/abs/2404.05040v1"}
{"created":"2024-04-07 17:31:53","title":"PathFinder: Attention-Driven Dynamic Non-Line-of-Sight Tracking with a Mobile Robot","abstract":"The study of non-line-of-sight (NLOS) imaging is growing due to its many potential applications, including rescue operations and pedestrian detection by self-driving cars. However, implementing NLOS imaging on a moving camera remains an open area of research. Existing NLOS imaging methods rely on time-resolved detectors and laser configurations that require precise optical alignment, making it difficult to deploy them in dynamic environments. This work proposes a data-driven approach to NLOS imaging, PathFinder, that can be used with a standard RGB camera mounted on a small, power-constrained mobile robot, such as an aerial drone. Our experimental pipeline is designed to accurately estimate the 2D trajectory of a person who moves in a Manhattan-world environment while remaining hidden from the camera's field-of-view. We introduce a novel approach to process a sequence of dynamic successive frames in a line-of-sight (LOS) video using an attention-based neural network that performs inference in real-time. The method also includes a preprocessing selection metric that analyzes images from a moving camera which contain multiple vertical planar surfaces, such as walls and building facades, and extracts planes that return maximum NLOS information. We validate the approach on in-the-wild scenes using a drone for video capture, thus demonstrating low-cost NLOS imaging in dynamic capture environments.","sentences":["The study of non-line-of-sight (NLOS) imaging is growing due to its many potential applications, including rescue operations and pedestrian detection by self-driving cars.","However, implementing NLOS imaging on a moving camera remains an open area of research.","Existing NLOS imaging methods rely on time-resolved detectors and laser configurations that require precise optical alignment, making it difficult to deploy them in dynamic environments.","This work proposes a data-driven approach to NLOS imaging, PathFinder, that can be used with a standard RGB camera mounted on a small, power-constrained mobile robot, such as an aerial drone.","Our experimental pipeline is designed to accurately estimate the 2D trajectory of a person who moves in a Manhattan-world environment while remaining hidden from the camera's field-of-view.","We introduce a novel approach to process a sequence of dynamic successive frames in a line-of-sight (LOS) video using an attention-based neural network that performs inference in real-time.","The method also includes a preprocessing selection metric that analyzes images from a moving camera which contain multiple vertical planar surfaces, such as walls and building facades, and extracts planes that return maximum NLOS information.","We validate the approach on in-the-wild scenes using a drone for video capture, thus demonstrating low-cost NLOS imaging in dynamic capture environments."],"url":"http://arxiv.org/abs/2404.05024v1"}
{"created":"2024-04-07 16:32:37","title":"A Hybrid Execution Environment for Computer-Interpretable Guidelines in PROforma","abstract":"In this paper, we share our experience of developing a hybrid execution environment for computer-interpretable guidelines (CIGs) in PROforma. The proposed environment is part of the CAPABLE system which provides coaching for cancer patients and decision support for physicians. It extends a standard PROforma execution engine - Deontics Engine (DE) - with additional components that act as wrappers around DE, allow handling of non-standard tasks, and facilitate integration with the rest of the CAPABLE system. This yields a hybrid environment in which the standard engine and specialized components must be interfaced together by some intervening layer. In the CAPABLE system this has been achieved by defining a set of specialized meta-properties which are attached to data and tasks in the PROforma CIGs to specify the interface between engine and components.","sentences":["In this paper, we share our experience of developing a hybrid execution environment for computer-interpretable guidelines (CIGs) in PROforma.","The proposed environment is part of the CAPABLE system which provides coaching for cancer patients and decision support for physicians.","It extends a standard PROforma execution engine - Deontics Engine (DE) - with additional components that act as wrappers around DE, allow handling of non-standard tasks, and facilitate integration with the rest of the CAPABLE system.","This yields a hybrid environment in which the standard engine and specialized components must be interfaced together by some intervening layer.","In the CAPABLE system this has been achieved by defining a set of specialized meta-properties which are attached to data and tasks in the PROforma CIGs to specify the interface between engine and components."],"url":"http://arxiv.org/abs/2404.05011v1"}
{"created":"2024-04-07 15:53:21","title":"Dual-Scale Transformer for Large-Scale Single-Pixel Imaging","abstract":"Single-pixel imaging (SPI) is a potential computational imaging technique which produces image by solving an illposed reconstruction problem from few measurements captured by a single-pixel detector. Deep learning has achieved impressive success on SPI reconstruction. However, previous poor reconstruction performance and impractical imaging model limit its real-world applications. In this paper, we propose a deep unfolding network with hybrid-attention Transformer on Kronecker SPI model, dubbed HATNet, to improve the imaging quality of real SPI cameras. Specifically, we unfold the computation graph of the iterative shrinkagethresholding algorithm (ISTA) into two alternative modules: efficient tensor gradient descent and hybrid-attention multiscale denoising. By virtue of Kronecker SPI, the gradient descent module can avoid high computational overheads rooted in previous gradient descent modules based on vectorized SPI. The denoising module is an encoder-decoder architecture powered by dual-scale spatial attention for high- and low-frequency aggregation and channel attention for global information recalibration. Moreover, we build a SPI prototype to verify the effectiveness of the proposed method. Extensive experiments on synthetic and real data demonstrate that our method achieves the state-of-the-art performance. The source code and pre-trained models are available at https://github.com/Gang-Qu/HATNet-SPI.","sentences":["Single-pixel imaging (SPI) is a potential computational imaging technique which produces image by solving an illposed reconstruction problem from few measurements captured by a single-pixel detector.","Deep learning has achieved impressive success on SPI reconstruction.","However, previous poor reconstruction performance and impractical imaging model limit its real-world applications.","In this paper, we propose a deep unfolding network with hybrid-attention Transformer on Kronecker SPI model, dubbed HATNet, to improve the imaging quality of real SPI cameras.","Specifically, we unfold the computation graph of the iterative shrinkagethresholding algorithm (ISTA) into two alternative modules: efficient tensor gradient descent and hybrid-attention multiscale denoising.","By virtue of Kronecker SPI, the gradient descent module can avoid high computational overheads rooted in previous gradient descent modules based on vectorized SPI.","The denoising module is an encoder-decoder architecture powered by dual-scale spatial attention for high- and low-frequency aggregation and channel attention for global information recalibration.","Moreover, we build a SPI prototype to verify the effectiveness of the proposed method.","Extensive experiments on synthetic and real data demonstrate that our method achieves the state-of-the-art performance.","The source code and pre-trained models are available at https://github.com/Gang-Qu/HATNet-SPI."],"url":"http://arxiv.org/abs/2404.05001v1"}
{"created":"2024-04-07 15:48:33","title":"Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval","abstract":"Deep quantization methods have shown high efficiency on large-scale image retrieval. However, current models heavily rely on ground-truth information, hindering the application of quantization in label-hungry scenarios. A more realistic demand is to learn from inexhaustible uploaded images that are associated with informal tags provided by amateur users. Though such sketchy tags do not obviously reveal the labels, they actually contain useful semantic information for supervising deep quantization. To this end, we propose Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first work to learn deep quantization from weakly tagged images. Specifically, 1) we use word embeddings to represent the tags and enhance their semantic information based on a tag correlation graph. 2) To better preserve semantic information in quantization codes and reduce quantization error, we jointly learn semantics-preserving embeddings and supervised quantizer on hypersphere by employing a well-designed fusion layer and tailor-made loss functions. Extensive experiments show that WSDHQ can achieve state-of-art performance on weakly-supervised compact coding. Code is available at https://github.com/gimpong/AAAI21-WSDHQ.","sentences":["Deep quantization methods have shown high efficiency on large-scale image retrieval.","However, current models heavily rely on ground-truth information, hindering the application of quantization in label-hungry scenarios.","A more realistic demand is to learn from inexhaustible uploaded images that are associated with informal tags provided by amateur users.","Though such sketchy tags do not obviously reveal the labels, they actually contain useful semantic information for supervising deep quantization.","To this end, we propose Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first work to learn deep quantization from weakly tagged images.","Specifically, 1) we use word embeddings to represent the tags and enhance their semantic information based on a tag correlation graph.","2) To better preserve semantic information in quantization codes and reduce quantization error, we jointly learn semantics-preserving embeddings and supervised quantizer on hypersphere by employing a well-designed fusion layer and tailor-made loss functions.","Extensive experiments show that WSDHQ can achieve state-of-art performance on weakly-supervised compact coding.","Code is available at https://github.com/gimpong/AAAI21-WSDHQ."],"url":"http://arxiv.org/abs/2404.04998v1"}
{"created":"2024-04-07 15:27:35","title":"Efficient Surgical Tool Recognition via HMM-Stabilized Deep Learning","abstract":"Recognizing various surgical tools, actions and phases from surgery videos is an important problem in computer vision with exciting clinical applications. Existing deep-learning-based methods for this problem either process each surgical video as a series of independent images without considering their dependence, or rely on complicated deep learning models to count for dependence of video frames. In this study, we revealed from exploratory data analysis that surgical videos enjoy relatively simple semantic structure, where the presence of surgical phases and tools can be well modeled by a compact hidden Markov model (HMM). Based on this observation, we propose an HMM-stabilized deep learning method for tool presence detection. A wide range of experiments confirm that the proposed approaches achieve better performance with lower training and running costs, and support more flexible ways to construct and utilize training data in scenarios where not all surgery videos of interest are extensively labelled. These results suggest that popular deep learning approaches with over-complicated model structures may suffer from inefficient utilization of data, and integrating ingredients of deep learning and statistical learning wisely may lead to more powerful algorithms that enjoy competitive performance, transparent interpretation and convenient model training simultaneously.","sentences":["Recognizing various surgical tools, actions and phases from surgery videos is an important problem in computer vision with exciting clinical applications.","Existing deep-learning-based methods for this problem either process each surgical video as a series of independent images without considering their dependence, or rely on complicated deep learning models to count for dependence of video frames.","In this study, we revealed from exploratory data analysis that surgical videos enjoy relatively simple semantic structure, where the presence of surgical phases and tools can be well modeled by a compact hidden Markov model (HMM).","Based on this observation, we propose an HMM-stabilized deep learning method for tool presence detection.","A wide range of experiments confirm that the proposed approaches achieve better performance with lower training and running costs, and support more flexible ways to construct and utilize training data in scenarios where not all surgery videos of interest are extensively labelled.","These results suggest that popular deep learning approaches with over-complicated model structures may suffer from inefficient utilization of data, and integrating ingredients of deep learning and statistical learning wisely may lead to more powerful algorithms that enjoy competitive performance, transparent interpretation and convenient model training simultaneously."],"url":"http://arxiv.org/abs/2404.04992v1"}
{"created":"2024-04-07 15:25:13","title":"OSS Malicious Package Analysis in the Wild","abstract":"The open-source software (OSS) ecosystem suffers from various security threats and risks, and malicious packages play a central role in software supply chain (SSC) attacks. Although malware research has a history of over thirty years, less attention has been paid to OSS malware. Its existing research has three limitations: a lack of high-quality datasets, malware diversity, and attack campaign context. In this paper, we first build and curate the largest dataset of 23,425 malicious packages from scattered online sources. We then propose a knowledge graph to represent the OSS malware corpus and conduct malicious package analysis in the wild. Our main findings include (1) it is essential to collect malicious packages from various online sources because there is little data overlap between different sources; (2) despite the sheer volume of SSC attack campaigns, many malicious packages are similar, and unknown/sophisticated attack behaviors have yet to emerge or be detected; (3) OSS malicious package has its distinct life cycle, denoted as {changing->release->detection->removal}, and slightly changing the package (different name) is a widespread attack manner; (4) while malicious packages often lack context about how and who released them, security reports disclose the information about corresponding SSC attack campaigns.","sentences":["The open-source software (OSS) ecosystem suffers from various security threats and risks, and malicious packages play a central role in software supply chain (SSC) attacks.","Although malware research has a history of over thirty years, less attention has been paid to OSS malware.","Its existing research has three limitations: a lack of high-quality datasets, malware diversity, and attack campaign context.","In this paper, we first build and curate the largest dataset of 23,425 malicious packages from scattered online sources.","We then propose a knowledge graph to represent the OSS malware corpus and conduct malicious package analysis in the wild.","Our main findings include (1) it is essential to collect malicious packages from various online sources because there is little data overlap between different sources; (2) despite the sheer volume of SSC attack campaigns, many malicious packages are similar, and unknown/sophisticated attack behaviors have yet to emerge or be detected; (3) OSS malicious package has its distinct life cycle, denoted as {changing->release->detection->removal}, and slightly changing the package (different name) is a widespread attack manner; (4) while malicious packages often lack context about how and who released them, security reports disclose the information about corresponding SSC attack campaigns."],"url":"http://arxiv.org/abs/2404.04991v1"}
{"created":"2024-04-07 15:10:25","title":"Chromatic number in $1.9999^n$ time? Fast deterministic set partitioning under the asymptotic rank conjecture","abstract":"In this paper we further explore the recently discovered connection by Bj\\\"{o}rklund and Kaski [STOC 2024] and Pratt [STOC 2024] between the asymptotic rank conjecture of Strassen [Progr. Math. 1994] and the three-way partitioning problem. We show that under the asymptotic rank conjecture, the chromatic number of an $n$-vertex graph can be computed deterministically in $O(1.99982^n)$ time, thus giving a conditional answer to a question of Zamir [ICALP 2021], and questioning the optimality of the $2^n\\operatorname{poly}(n)$ time algorithm for chromatic number by Bj\\\"{o}rklund, Husfeldt, and Koivisto [SICOMP 2009].   Our technique is a combination of earlier algorithms for detecting $k$-colorings for small $k$ and enumerating $k$-colorable subgraphs, with an extension and derandomisation of Pratt's tensor-based algorithm for balanced three-way partitioning to the unbalanced case.","sentences":["In this paper we further explore the recently discovered connection by Bj\\\"{o}rklund and Kaski [STOC 2024] and Pratt","[STOC 2024] between the asymptotic rank conjecture of Strassen [Progr.","Math. 1994] and the three-way partitioning problem.","We show that under the asymptotic rank conjecture, the chromatic number of an $n$-vertex graph can be computed deterministically in $O(1.99982^n)$ time, thus giving a conditional answer to a question of Zamir [ICALP 2021], and questioning the optimality of the $2^n\\operatorname{poly}(n)$ time algorithm for chromatic number by Bj\\\"{o}rklund, Husfeldt, and","Koivisto [SICOMP 2009].   ","Our technique is a combination of earlier algorithms for detecting $k$-colorings for small $k$ and enumerating $k$-colorable subgraphs, with an extension and derandomisation of Pratt's tensor-based algorithm for balanced three-way partitioning to the unbalanced case."],"url":"http://arxiv.org/abs/2404.04987v1"}
{"created":"2024-04-07 14:21:37","title":"FPL+: Filtered Pseudo Label-based Unsupervised Cross-Modality Adaptation for 3D Medical Image Segmentation","abstract":"Adapting a medical image segmentation model to a new domain is important for improving its cross-domain transferability, and due to the expensive annotation process, Unsupervised Domain Adaptation (UDA) is appealing where only unlabeled images are needed for the adaptation. Existing UDA methods are mainly based on image or feature alignment with adversarial training for regularization, and they are limited by insufficient supervision in the target domain. In this paper, we propose an enhanced Filtered Pseudo Label (FPL+)-based UDA method for 3D medical image segmentation. It first uses cross-domain data augmentation to translate labeled images in the source domain to a dual-domain training set consisting of a pseudo source-domain set and a pseudo target-domain set. To leverage the dual-domain augmented images to train a pseudo label generator, domain-specific batch normalization layers are used to deal with the domain shift while learning the domain-invariant structure features, generating high-quality pseudo labels for target-domain images. We then combine labeled source-domain images and target-domain images with pseudo labels to train a final segmentor, where image-level weighting based on uncertainty estimation and pixel-level weighting based on dual-domain consensus are proposed to mitigate the adverse effect of noisy pseudo labels. Experiments on three public multi-modal datasets for Vestibular Schwannoma, brain tumor and whole heart segmentation show that our method surpassed ten state-of-the-art UDA methods, and it even achieved better results than fully supervised learning in the target domain in some cases.","sentences":["Adapting a medical image segmentation model to a new domain is important for improving its cross-domain transferability, and due to the expensive annotation process, Unsupervised Domain Adaptation (UDA) is appealing where only unlabeled images are needed for the adaptation.","Existing UDA methods are mainly based on image or feature alignment with adversarial training for regularization, and they are limited by insufficient supervision in the target domain.","In this paper, we propose an enhanced Filtered Pseudo Label (FPL+)-based UDA method for 3D medical image segmentation.","It first uses cross-domain data augmentation to translate labeled images in the source domain to a dual-domain training set consisting of a pseudo source-domain set and a pseudo target-domain set.","To leverage the dual-domain augmented images to train a pseudo label generator, domain-specific batch normalization layers are used to deal with the domain shift while learning the domain-invariant structure features, generating high-quality pseudo labels for target-domain images.","We then combine labeled source-domain images and target-domain images with pseudo labels to train a final segmentor, where image-level weighting based on uncertainty estimation and pixel-level weighting based on dual-domain consensus are proposed to mitigate the adverse effect of noisy pseudo labels.","Experiments on three public multi-modal datasets for Vestibular Schwannoma, brain tumor and whole heart segmentation show that our method surpassed ten state-of-the-art UDA methods, and it even achieved better results than fully supervised learning in the target domain in some cases."],"url":"http://arxiv.org/abs/2404.04971v1"}
{"created":"2024-04-07 14:20:51","title":"How to characterize imprecision in multi-view clustering?","abstract":"It is still challenging to cluster multi-view data since existing methods can only assign an object to a specific (singleton) cluster when combining different view information. As a result, it fails to characterize imprecision of objects in overlapping regions of different clusters, thus leading to a high risk of errors. In this paper, we thereby want to answer the question: how to characterize imprecision in multi-view clustering? Correspondingly, we propose a multi-view low-rank evidential c-means based on entropy constraint (MvLRECM). The proposed MvLRECM can be considered as a multi-view version of evidential c-means based on the theory of belief functions. In MvLRECM, each object is allowed to belong to different clusters with various degrees of support (masses of belief) to characterize uncertainty when decision-making. Moreover, if an object is in the overlapping region of several singleton clusters, it can be assigned to a meta-cluster, defined as the union of these singleton clusters, to characterize the local imprecision in the result. In addition, entropy-weighting and low-rank constraints are employed to reduce imprecision and improve accuracy. Compared to state-of-the-art methods, the effectiveness of MvLRECM is demonstrated based on several toy and UCI real datasets.","sentences":["It is still challenging to cluster multi-view data since existing methods can only assign an object to a specific (singleton) cluster when combining different view information.","As a result, it fails to characterize imprecision of objects in overlapping regions of different clusters, thus leading to a high risk of errors.","In this paper, we thereby want to answer the question: how to characterize imprecision in multi-view clustering?","Correspondingly, we propose a multi-view low-rank evidential c-means based on entropy constraint (MvLRECM).","The proposed MvLRECM can be considered as a multi-view version of evidential c-means based on the theory of belief functions.","In MvLRECM, each object is allowed to belong to different clusters with various degrees of support (masses of belief) to characterize uncertainty when decision-making.","Moreover, if an object is in the overlapping region of several singleton clusters, it can be assigned to a meta-cluster, defined as the union of these singleton clusters, to characterize the local imprecision in the result.","In addition, entropy-weighting and low-rank constraints are employed to reduce imprecision and improve accuracy.","Compared to state-of-the-art methods, the effectiveness of MvLRECM is demonstrated based on several toy and UCI real datasets."],"url":"http://arxiv.org/abs/2404.04970v1"}
{"created":"2024-04-07 13:40:29","title":"PairAug: What Can Augmented Image-Text Pairs Do for Radiology?","abstract":"Current vision-language pre-training (VLP) methodologies predominantly depend on paired image-text datasets, a resource that is challenging to acquire in radiology due to privacy considerations and labelling complexities. Data augmentation provides a practical solution to overcome the issue of data scarcity, however, most augmentation methods exhibit a limited focus, prioritising either image or text augmentation exclusively. Acknowledging this limitation, our objective is to devise a framework capable of concurrently augmenting medical image and text data. We design a Pairwise Augmentation (PairAug) approach that contains an Inter-patient Augmentation (InterAug) branch and an Intra-patient Augmentation (IntraAug) branch. Specifically, the InterAug branch of our approach generates radiology images using synthesised yet plausible reports derived from a Large Language Model (LLM). The generated pairs can be considered a collection of new patient cases since they are artificially created and may not exist in the original dataset. In contrast, the IntraAug branch uses newly generated reports to manipulate images. This process allows us to create new paired data for each individual with diverse medical conditions. Our extensive experiments on various downstream tasks covering medical image classification zero-shot and fine-tuning analysis demonstrate that our PairAug, concurrently expanding both image and text data, substantially outperforms image-/text-only expansion baselines and advanced medical VLP baselines. Our code is released at \\url{https://github.com/YtongXie/PairAug}.","sentences":["Current vision-language pre-training (VLP) methodologies predominantly depend on paired image-text datasets, a resource that is challenging to acquire in radiology due to privacy considerations and labelling complexities.","Data augmentation provides a practical solution to overcome the issue of data scarcity, however, most augmentation methods exhibit a limited focus, prioritising either image or text augmentation exclusively.","Acknowledging this limitation, our objective is to devise a framework capable of concurrently augmenting medical image and text data.","We design a Pairwise Augmentation (PairAug) approach that contains an Inter-patient Augmentation (InterAug) branch and an Intra-patient Augmentation (IntraAug) branch.","Specifically, the InterAug branch of our approach generates radiology images using synthesised yet plausible reports derived from a Large Language Model (LLM).","The generated pairs can be considered a collection of new patient cases since they are artificially created and may not exist in the original dataset.","In contrast, the IntraAug branch uses newly generated reports to manipulate images.","This process allows us to create new paired data for each individual with diverse medical conditions.","Our extensive experiments on various downstream tasks covering medical image classification zero-shot and fine-tuning analysis demonstrate that our PairAug, concurrently expanding both image and text data, substantially outperforms image-/text-only expansion baselines and advanced medical VLP baselines.","Our code is released at \\url{https://github.com/YtongXie/PairAug}."],"url":"http://arxiv.org/abs/2404.04960v1"}
