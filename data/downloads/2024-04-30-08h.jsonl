{"created":"2024-04-29 17:59:16","title":"Stylus: Automatic Adapter Selection for Diffusion Models","abstract":"Beyond scaling base models with more data or parameters, fine-tuned adapters provide an alternative way to generate high fidelity, custom images at reduced costs. As such, adapters have been widely adopted by open-source communities, accumulating a database of over 100K adapters-most of which are highly customized with insufficient descriptions. This paper explores the problem of matching the prompt to a set of relevant adapters, built on recent work that highlight the performance gains of composing adapters. We introduce Stylus, which efficiently selects and automatically composes task-specific adapters based on a prompt's keywords. Stylus outlines a three-stage approach that first summarizes adapters with improved descriptions and embeddings, retrieves relevant adapters, and then further assembles adapters based on prompts' keywords by checking how well they fit the prompt. To evaluate Stylus, we developed StylusDocs, a curated dataset featuring 75K adapters with pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as preferred, with humans and multimodal models as evaluators, over the base model. See stylus-diffusion.github.io for more.","sentences":["Beyond scaling base models with more data or parameters, fine-tuned adapters provide an alternative way to generate high fidelity, custom images at reduced costs.","As such, adapters have been widely adopted by open-source communities, accumulating a database of over 100K adapters-most of which are highly customized with insufficient descriptions.","This paper explores the problem of matching the prompt to a set of relevant adapters, built on recent work that highlight the performance gains of composing adapters.","We introduce Stylus, which efficiently selects and automatically composes task-specific adapters based on a prompt's keywords.","Stylus outlines a three-stage approach that first summarizes adapters with improved descriptions and embeddings, retrieves relevant adapters, and then further assembles adapters based on prompts' keywords by checking how well they fit the prompt.","To evaluate Stylus, we developed StylusDocs, a curated dataset featuring 75K adapters with pre-computed adapter embeddings.","In our evaluation on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as preferred, with humans and multimodal models as evaluators, over the base model.","See stylus-diffusion.github.io for more."],"url":"http://arxiv.org/abs/2404.18928v1"}
{"created":"2024-04-29 17:58:30","title":"DPO Meets PPO: Reinforced Token Optimization for RLHF","abstract":"In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards -- a challenging scenario in traditional deep reinforcement learning. Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies. To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information. Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation. Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal. Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently. For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage. Extensive real-world alignment experiments verify the effectiveness of the proposed approach.","sentences":["In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards -- a challenging scenario in traditional deep reinforcement learning.","Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies.","To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information.","Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation.","Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal.","Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently.","For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO.","DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage.","Extensive real-world alignment experiments verify the effectiveness of the proposed approach."],"url":"http://arxiv.org/abs/2404.18922v1"}
{"created":"2024-04-29 17:43:38","title":"On classes of bounded tree rank, their interpretations, and efficient sparsification","abstract":"Graph classes of bounded tree rank were introduced recently in the context of the model checking problem for first-order logic of graphs. These graph classes are a common generalization of graph classes of bounded degree and bounded treedepth, and they are a special case of graph classes of bounded expansion. We introduce a notion of decomposition for these classes and show that these decompositions can be efficiently computed. Also, a natural extension of our decomposition leads to a new characterization and decomposition for graph classes of bounded expansion (and an efficient algorithm computing this decomposition).   We then focus on interpretations of graph classes of bounded tree rank. We give a characterization of graph classes interpretable in graph classes of tree rank $2$. Importantly, our characterization leads to an efficient sparsification procedure: For any graph class $C$ interpretable in a efficiently bounded graph class of tree rank at most $2$, there is a polynomial time algorithm that to any $G \\in C$ computes a (sparse) graph $H$ from a fixed graph class of tree rank at most $2$ such that $G = I(H)$ for a fixed interpretation $I$. To the best of our knowledge, this is the first efficient \"interpretation reversal\" result that generalizes the result of Gajarsk\\'y et al. [LICS 2016], who showed an analogous result for graph classes interpretable in classes of graphs of bounded degree.","sentences":["Graph classes of bounded tree rank were introduced recently in the context of the model checking problem for first-order logic of graphs.","These graph classes are a common generalization of graph classes of bounded degree and bounded treedepth, and they are a special case of graph classes of bounded expansion.","We introduce a notion of decomposition for these classes and show that these decompositions can be efficiently computed.","Also, a natural extension of our decomposition leads to a new characterization and decomposition for graph classes of bounded expansion (and an efficient algorithm computing this decomposition).   ","We then focus on interpretations of graph classes of bounded tree rank.","We give a characterization of graph classes interpretable in graph classes of tree rank $2$. Importantly, our characterization leads to an efficient sparsification procedure: For any graph class $C$ interpretable in a efficiently bounded graph class of tree rank at most $2$, there is a polynomial time algorithm that to any $G \\in C$ computes a (sparse) graph $H$ from a fixed graph class of tree rank at most $2$ such that $G = I(H)$ for a fixed interpretation $I$. To the best of our knowledge, this is the first efficient \"interpretation reversal\" result that generalizes the result of Gajarsk\\'y et al.","[LICS 2016], who showed an analogous result for graph classes interpretable in classes of graphs of bounded degree."],"url":"http://arxiv.org/abs/2404.18904v1"}
{"created":"2024-04-29 17:33:52","title":"Overcoming Knowledge Barriers: Online Imitation Learning from Observation with Pretrained World Models","abstract":"Incorporating the successful paradigm of pretraining and finetuning from Computer Vision and Natural Language Processing into decision-making has become increasingly popular in recent years. In this paper, we study Imitation Learning from Observation with pretrained models and find existing approaches such as BCO and AIME face knowledge barriers, specifically the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB), greatly limiting their performance. The EKB arises when pretrained models lack knowledge about unseen observations, leading to errors in action inference. The DKB results from policies trained on limited demonstrations, hindering adaptability to diverse scenarios. We thoroughly analyse the underlying mechanism of these barriers and propose AIME-v2 upon AIME as a solution. AIME-v2 uses online interactions with data-driven regulariser to alleviate the EKB and mitigates the DKB by introducing a surrogate reward function to enhance policy training. Experimental results on tasks from the DeepMind Control Suite and Meta-World benchmarks demonstrate the effectiveness of these modifications in improving both sample-efficiency and converged performance. The study contributes valuable insights into resolving knowledge barriers for enhanced decision-making in pretraining-based approaches. Code will be available at https://github.com/argmax-ai/aime-v2.","sentences":["Incorporating the successful paradigm of pretraining and finetuning from Computer Vision and Natural Language Processing into decision-making has become increasingly popular in recent years.","In this paper, we study Imitation Learning from Observation with pretrained models and find existing approaches such as BCO and AIME face knowledge barriers, specifically the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB), greatly limiting their performance.","The EKB arises when pretrained models lack knowledge about unseen observations, leading to errors in action inference.","The DKB results from policies trained on limited demonstrations, hindering adaptability to diverse scenarios.","We thoroughly analyse the underlying mechanism of these barriers and propose AIME-v2 upon AIME as a solution.","AIME-v2 uses online interactions with data-driven regulariser to alleviate the EKB and mitigates the DKB by introducing a surrogate reward function to enhance policy training.","Experimental results on tasks from the DeepMind Control Suite and Meta-World benchmarks demonstrate the effectiveness of these modifications in improving both sample-efficiency and converged performance.","The study contributes valuable insights into resolving knowledge barriers for enhanced decision-making in pretraining-based approaches.","Code will be available at https://github.com/argmax-ai/aime-v2."],"url":"http://arxiv.org/abs/2404.18896v1"}
{"created":"2024-04-29 17:30:36","title":"Learning general Gaussian mixtures with efficient score matching","abstract":"We study the problem of learning mixtures of $k$ Gaussians in $d$ dimensions. We make no separation assumptions on the underlying mixture components: we only require that the covariance matrices have bounded condition number and that the means and covariances lie in a ball of bounded radius. We give an algorithm that draws $d^{\\mathrm{poly}(k/\\varepsilon)}$ samples from the target mixture, runs in sample-polynomial time, and constructs a sampler whose output distribution is $\\varepsilon$-far from the unknown mixture in total variation. Prior works for this problem either (i) required exponential runtime in the dimension $d$, (ii) placed strong assumptions on the instance (e.g., spherical covariances or clusterability), or (iii) had doubly exponential dependence on the number of components $k$.   Our approach departs from commonly used techniques for this problem like the method of moments. Instead, we leverage a recently developed reduction, based on diffusion models, from distribution learning to a supervised learning task called score matching. We give an algorithm for the latter by proving a structural result showing that the score function of a Gaussian mixture can be approximated by a piecewise-polynomial function, and there is an efficient algorithm for finding it. To our knowledge, this is the first example of diffusion models achieving a state-of-the-art theoretical guarantee for an unsupervised learning task.","sentences":["We study the problem of learning mixtures of $k$ Gaussians in $d$ dimensions.","We make no separation assumptions on the underlying mixture components: we only require that the covariance matrices have bounded condition number and that the means and covariances lie in a ball of bounded radius.","We give an algorithm that draws $d^{\\mathrm{poly}(k/\\varepsilon)}$ samples from the target mixture, runs in sample-polynomial time, and constructs a sampler whose output distribution is $\\varepsilon$-far from the unknown mixture in total variation.","Prior works for this problem either (i) required exponential runtime in the dimension $d$, (ii) placed strong assumptions on the instance (e.g., spherical covariances or clusterability), or (iii) had doubly exponential dependence on the number of components $k$.   Our approach departs from commonly used techniques for this problem like the method of moments.","Instead, we leverage a recently developed reduction, based on diffusion models, from distribution learning to a supervised learning task called score matching.","We give an algorithm for the latter by proving a structural result showing that the score function of a Gaussian mixture can be approximated by a piecewise-polynomial function, and there is an efficient algorithm for finding it.","To our knowledge, this is the first example of diffusion models achieving a state-of-the-art theoretical guarantee for an unsupervised learning task."],"url":"http://arxiv.org/abs/2404.18893v1"}
{"created":"2024-04-29 17:27:37","title":"IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation","abstract":"The scarcity of labeled data in real-world scenarios is a critical bottleneck of deep learning's effectiveness. Semi-supervised semantic segmentation has been a typical solution to achieve a desirable tradeoff between annotation cost and segmentation performance. However, previous approaches, whether based on consistency regularization or self-training, tend to neglect the contextual knowledge embedded within inter-pixel relations. This negligence leads to suboptimal performance and limited generalization. In this paper, we propose a novel approach IPixMatch designed to mine the neglected but valuable Inter-Pixel information for semi-supervised learning. Specifically, IPixMatch is constructed as an extension of the standard teacher-student network, incorporating additional loss terms to capture inter-pixel relations. It shines in low-data regimes by efficiently leveraging the limited labeled data and extracting maximum utility from the available unlabeled data. Furthermore, IPixMatch can be integrated seamlessly into most teacher-student frameworks without the need of model modification or adding additional components. Our straightforward IPixMatch method demonstrates consistent performance improvements across various benchmark datasets under different partitioning protocols.","sentences":["The scarcity of labeled data in real-world scenarios is a critical bottleneck of deep learning's effectiveness.","Semi-supervised semantic segmentation has been a typical solution to achieve a desirable tradeoff between annotation cost and segmentation performance.","However, previous approaches, whether based on consistency regularization or self-training, tend to neglect the contextual knowledge embedded within inter-pixel relations.","This negligence leads to suboptimal performance and limited generalization.","In this paper, we propose a novel approach IPixMatch designed to mine the neglected but valuable Inter-Pixel information for semi-supervised learning.","Specifically, IPixMatch is constructed as an extension of the standard teacher-student network, incorporating additional loss terms to capture inter-pixel relations.","It shines in low-data regimes by efficiently leveraging the limited labeled data and extracting maximum utility from the available unlabeled data.","Furthermore, IPixMatch can be integrated seamlessly into most teacher-student frameworks without the need of model modification or adding additional components.","Our straightforward IPixMatch method demonstrates consistent performance improvements across various benchmark datasets under different partitioning protocols."],"url":"http://arxiv.org/abs/2404.18891v1"}
{"created":"2024-04-29 17:27:08","title":"Hide and Seek: How Does Watermarking Impact Face Recognition?","abstract":"The recent progress in generative models has revolutionized the synthesis of highly realistic images, including face images. This technological development has undoubtedly helped face recognition, such as training data augmentation for higher recognition accuracy and data privacy. However, it has also introduced novel challenges concerning the responsible use and proper attribution of computer generated images. We investigate the impact of digital watermarking, a technique for embedding ownership signatures into images, on the effectiveness of face recognition models. We propose a comprehensive pipeline that integrates face image generation, watermarking, and face recognition to systematically examine this question. The proposed watermarking scheme, based on an encoder-decoder architecture, successfully embeds and recovers signatures from both real and synthetic face images while preserving their visual fidelity. Through extensive experiments, we unveil that while watermarking enables robust image attribution, it results in a slight decline in face recognition accuracy, particularly evident for face images with challenging poses and expressions. Additionally, we find that directly training face recognition models on watermarked images offers only a limited alleviation of this performance decline. Our findings underscore the intricate trade off between watermarking and face recognition accuracy. This work represents a pivotal step towards the responsible utilization of generative models in face recognition and serves to initiate discussions regarding the broader implications of watermarking in biometrics.","sentences":["The recent progress in generative models has revolutionized the synthesis of highly realistic images, including face images.","This technological development has undoubtedly helped face recognition, such as training data augmentation for higher recognition accuracy and data privacy.","However, it has also introduced novel challenges concerning the responsible use and proper attribution of computer generated images.","We investigate the impact of digital watermarking, a technique for embedding ownership signatures into images, on the effectiveness of face recognition models.","We propose a comprehensive pipeline that integrates face image generation, watermarking, and face recognition to systematically examine this question.","The proposed watermarking scheme, based on an encoder-decoder architecture, successfully embeds and recovers signatures from both real and synthetic face images while preserving their visual fidelity.","Through extensive experiments, we unveil that while watermarking enables robust image attribution, it results in a slight decline in face recognition accuracy, particularly evident for face images with challenging poses and expressions.","Additionally, we find that directly training face recognition models on watermarked images offers only a limited alleviation of this performance decline.","Our findings underscore the intricate trade off between watermarking and face recognition accuracy.","This work represents a pivotal step towards the responsible utilization of generative models in face recognition and serves to initiate discussions regarding the broader implications of watermarking in biometrics."],"url":"http://arxiv.org/abs/2404.18890v1"}
{"created":"2024-04-29 17:19:40","title":"A Survey on Diffusion Models for Time Series and Spatio-Temporal Data","abstract":"The study of time series data is crucial for understanding trends and anomalies over time, enabling predictive insights across various sectors. Spatio-temporal data, on the other hand, is vital for analyzing phenomena in both space and time, providing a dynamic perspective on complex system interactions. Recently, diffusion models have seen widespread application in time series and spatio-temporal data mining. Not only do they enhance the generative and inferential capabilities for sequential and temporal data, but they also extend to other downstream tasks. In this survey, we comprehensively and thoroughly review the use of diffusion models in time series and spatio-temporal data, categorizing them by model category, task type, data modality, and practical application domain. In detail, we categorize diffusion models into unconditioned and conditioned types and discuss time series data and spatio-temporal data separately. Unconditioned models, which operate unsupervised, are subdivided into probability-based and score-based models, serving predictive and generative tasks such as forecasting, anomaly detection, classification, and imputation. Conditioned models, on the other hand, utilize extra information to enhance performance and are similarly divided for both predictive and generative tasks. Our survey extensively covers their application in various fields, including healthcare, recommendation, climate, energy, audio, and transportation, providing a foundational understanding of how these models analyze and generate data. Through this structured overview, we aim to provide researchers and practitioners with a comprehensive understanding of diffusion models for time series and spatio-temporal data analysis, aiming to direct future innovations and applications by addressing traditional challenges and exploring innovative solutions within the diffusion model framework.","sentences":["The study of time series data is crucial for understanding trends and anomalies over time, enabling predictive insights across various sectors.","Spatio-temporal data, on the other hand, is vital for analyzing phenomena in both space and time, providing a dynamic perspective on complex system interactions.","Recently, diffusion models have seen widespread application in time series and spatio-temporal data mining.","Not only do they enhance the generative and inferential capabilities for sequential and temporal data, but they also extend to other downstream tasks.","In this survey, we comprehensively and thoroughly review the use of diffusion models in time series and spatio-temporal data, categorizing them by model category, task type, data modality, and practical application domain.","In detail, we categorize diffusion models into unconditioned and conditioned types and discuss time series data and spatio-temporal data separately.","Unconditioned models, which operate unsupervised, are subdivided into probability-based and score-based models, serving predictive and generative tasks such as forecasting, anomaly detection, classification, and imputation.","Conditioned models, on the other hand, utilize extra information to enhance performance and are similarly divided for both predictive and generative tasks.","Our survey extensively covers their application in various fields, including healthcare, recommendation, climate, energy, audio, and transportation, providing a foundational understanding of how these models analyze and generate data.","Through this structured overview, we aim to provide researchers and practitioners with a comprehensive understanding of diffusion models for time series and spatio-temporal data analysis, aiming to direct future innovations and applications by addressing traditional challenges and exploring innovative solutions within the diffusion model framework."],"url":"http://arxiv.org/abs/2404.18886v1"}
{"created":"2024-04-29 17:16:27","title":"Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking","abstract":"Data augmentation techniques apply transformations to existing texts to generate additional data. The transformations may produce low-quality texts, where the meaning of the text is changed and the text may even be mangled beyond human comprehension. Analyzing the synthetically generated texts and their corresponding labels is slow and demanding. To winnow out texts with incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection technique. INSPECTOR combines the strengths of provenance tracking techniques with assistive labeling. INSPECTOR allows users to group related texts by their transformation provenance, i.e., the transformations applied to the original text, or feature provenance, the linguistic features of the original text. For assistive labeling, INSPECTOR computes metrics that approximate data quality, and allows users to compare the corresponding label of each text against the predictions of a large language model. In a user study, INSPECTOR increases the number of texts with correct labels identified by 3X on a sentiment analysis task and by 4X on a hate speech detection task. The participants found grouping the synthetically generated texts by their common transformation to be the most useful technique. Surprisingly, grouping texts by common linguistic features was perceived to be unhelpful. Contrary to prior work, our study finds that no single technique obviates the need for human inspection effort. This validates the design of INSPECTOR which combines both analysis of data provenance and assistive labeling to reduce human inspection effort.","sentences":["Data augmentation techniques apply transformations to existing texts to generate additional data.","The transformations may produce low-quality texts, where the meaning of the text is changed and the text may even be mangled beyond human comprehension.","Analyzing the synthetically generated texts and their corresponding labels is slow and demanding.","To winnow out texts with incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection technique.","INSPECTOR combines the strengths of provenance tracking techniques with assistive labeling.","INSPECTOR allows users to group related texts by their transformation provenance, i.e., the transformations applied to the original text, or feature provenance, the linguistic features of the original text.","For assistive labeling, INSPECTOR computes metrics that approximate data quality, and allows users to compare the corresponding label of each text against the predictions of a large language model.","In a user study, INSPECTOR increases the number of texts with correct labels identified by 3X on a sentiment analysis task and by 4X on a hate speech detection task.","The participants found grouping the synthetically generated texts by their common transformation to be the most useful technique.","Surprisingly, grouping texts by common linguistic features was perceived to be unhelpful.","Contrary to prior work, our study finds that no single technique obviates the need for human inspection effort.","This validates the design of INSPECTOR which combines both analysis of data provenance and assistive labeling to reduce human inspection effort."],"url":"http://arxiv.org/abs/2404.18881v1"}
{"created":"2024-04-29 17:16:22","title":"Spivavtor: An Instruction Tuned Ukrainian Text Editing Model","abstract":"We introduce Spivavtor, a dataset, and instruction-tuned models for text editing focused on the Ukrainian language. Spivavtor is the Ukrainian-focused adaptation of the English-only CoEdIT model. Similar to CoEdIT, Spivavtor performs text editing tasks by following instructions in Ukrainian. This paper describes the details of the Spivavtor-Instruct dataset and Spivavtor models. We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as Grammatical Error Correction (GEC), Text Simplification, Coherence, and Paraphrasing, and demonstrate its superior performance on all of them. We publicly release our best-performing models and data as resources to the community to advance further research in this space.","sentences":["We introduce Spivavtor, a dataset, and instruction-tuned models for text editing focused on the Ukrainian language.","Spivavtor is the Ukrainian-focused adaptation of the English-only CoEdIT model.","Similar to CoEdIT, Spivavtor performs text editing tasks by following instructions in Ukrainian.","This paper describes the details of the Spivavtor-Instruct dataset and Spivavtor models.","We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as Grammatical Error Correction (GEC), Text Simplification, Coherence, and Paraphrasing, and demonstrate its superior performance on all of them.","We publicly release our best-performing models and data as resources to the community to advance further research in this space."],"url":"http://arxiv.org/abs/2404.18880v1"}
{"created":"2024-04-29 17:00:53","title":"More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness","abstract":"The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power. Despite the effectiveness of preference learning algorithms like Reinforcement Learning From Human Feedback (RLHF) in aligning human preferences, their assumed improvements on model trustworthiness haven't been thoroughly testified. Toward this end, this study investigates how models that have been aligned with general-purpose preference data on helpfulness and harmlessness perform across five trustworthiness verticals: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy. For model alignment, we focus on three widely used RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Through extensive empirical investigations, we discover that the improvement in trustworthiness by RLHF is far from guaranteed, and there exists a complex interplay between preference data, alignment algorithms, and specific trustworthiness aspects. Together, our results underscore the need for more nuanced approaches for model alignment. By shedding light on the intricate dynamics of these components within model alignment, we hope this research will guide the community towards developing language models that are both capable and trustworthy.","sentences":["The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power.","Despite the effectiveness of preference learning algorithms like Reinforcement Learning From Human Feedback (RLHF) in aligning human preferences, their assumed improvements on model trustworthiness haven't been thoroughly testified.","Toward this end, this study investigates how models that have been aligned with general-purpose preference data on helpfulness and harmlessness perform across five trustworthiness verticals: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy.","For model alignment, we focus on three widely used RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO).","Through extensive empirical investigations, we discover that the improvement in trustworthiness by RLHF is far from guaranteed, and there exists a complex interplay between preference data, alignment algorithms, and specific trustworthiness aspects.","Together, our results underscore the need for more nuanced approaches for model alignment.","By shedding light on the intricate dynamics of these components within model alignment, we hope this research will guide the community towards developing language models that are both capable and trustworthy."],"url":"http://arxiv.org/abs/2404.18870v1"}
{"created":"2024-04-29 17:00:20","title":"Learning Mixtures of Gaussians Using Diffusion Models","abstract":"We give a new algorithm for learning mixtures of $k$ Gaussians (with identity covariance in $\\mathbb{R}^n$) to TV error $\\varepsilon$, with quasi-polynomial ($O(n^{\\text{poly log}\\left(\\frac{n+k}{\\varepsilon}\\right)})$) time and sample complexity, under a minimum weight assumption. Unlike previous approaches, most of which are algebraic in nature, our approach is analytic and relies on the framework of diffusion models. Diffusion models are a modern paradigm for generative modeling, which typically rely on learning the score function (gradient log-pdf) along a process transforming a pure noise distribution, in our case a Gaussian, to the data distribution. Despite their dazzling performance in tasks such as image generation, there are few end-to-end theoretical guarantees that they can efficiently learn nontrivial families of distributions; we give some of the first such guarantees. We proceed by deriving higher-order Gaussian noise sensitivity bounds for the score functions for a Gaussian mixture to show that that they can be inductively learned using piecewise polynomial regression (up to poly-logarithmic degree), and combine this with known convergence results for diffusion models. Our results extend to continuous mixtures of Gaussians where the mixing distribution is supported on a union of $k$ balls of constant radius. In particular, this applies to the case of Gaussian convolutions of distributions on low-dimensional manifolds, or more generally sets with small covering number.","sentences":["We give a new algorithm for learning mixtures of $k$ Gaussians (with identity covariance in $\\mathbb{R}^n$) to TV error $\\varepsilon$, with quasi-polynomial ($O(n^{\\text{poly log}\\left(\\frac{n+k}{\\varepsilon}\\right)})$) time and sample complexity, under a minimum weight assumption.","Unlike previous approaches, most of which are algebraic in nature, our approach is analytic and relies on the framework of diffusion models.","Diffusion models are a modern paradigm for generative modeling, which typically rely on learning the score function (gradient log-pdf) along a process transforming a pure noise distribution, in our case a Gaussian, to the data distribution.","Despite their dazzling performance in tasks such as image generation, there are few end-to-end theoretical guarantees that they can efficiently learn nontrivial families of distributions; we give some of the first such guarantees.","We proceed by deriving higher-order Gaussian noise sensitivity bounds for the score functions for a Gaussian mixture to show that that they can be inductively learned using piecewise polynomial regression (up to poly-logarithmic degree), and combine this with known convergence results for diffusion models.","Our results extend to continuous mixtures of Gaussians where the mixing distribution is supported on a union of $k$ balls of constant radius.","In particular, this applies to the case of Gaussian convolutions of distributions on low-dimensional manifolds, or more generally sets with small covering number."],"url":"http://arxiv.org/abs/2404.18869v1"}
{"created":"2024-04-29 16:52:57","title":"Truth-value judgment in language models: belief directions are context sensitive","abstract":"Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences. Multiple methods recover such directions and build probes that are described as getting at a model's \"knowledge\" or \"beliefs\". We investigate this phenomenon, looking closely at the impact of context on the probes. Our experiments establish where in the LLM the probe's predictions can be described as being conditional on the preceding (related) sentences. Specifically, we quantify the responsiveness of the probes to the presence of (negated) supporting and contradicting sentences, and score the probes on their consistency. We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these belief directions influences the position of the hypothesis along that same direction. We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs. Our experiments show that the type of errors depend on the layer, the (type of) model, and the kind of data. Finally, our results suggest that belief directions are (one of the) causal mediators in the inference process that incorporates in-context information.","sentences":["Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences.","Multiple methods recover such directions and build probes that are described as getting at a model's \"knowledge\" or \"beliefs\".","We investigate this phenomenon, looking closely at the impact of context on the probes.","Our experiments establish where in the LLM the probe's predictions can be described as being conditional on the preceding (related) sentences.","Specifically, we quantify the responsiveness of the probes to the presence of (negated) supporting and contradicting sentences, and score the probes on their consistency.","We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these belief directions influences the position of the hypothesis along that same direction.","We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs.","Our experiments show that the type of errors depend on the layer, the (type of) model, and the kind of data.","Finally, our results suggest that belief directions are (one of the) causal mediators in the inference process that incorporates in-context information."],"url":"http://arxiv.org/abs/2404.18865v1"}
{"created":"2024-04-29 16:52:07","title":"PlanNetX: Learning an Efficient Neural Network Planner from MPC for Longitudinal Control","abstract":"Model predictive control (MPC) is a powerful, optimization-based approach for controlling dynamical systems. However, the computational complexity of online optimization can be problematic on embedded devices. Especially, when we need to guarantee fixed control frequencies. Thus, previous work proposed to reduce the computational burden using imitation learning (IL) approximating the MPC policy by a neural network. In this work, we instead learn the whole planned trajectory of the MPC. We introduce a combination of a novel neural network architecture PlanNetX and a simple loss function based on the state trajectory that leverages the parameterized optimal control structure of the MPC. We validate our approach in the context of autonomous driving by learning a longitudinal planner and benchmarking it extensively in the CommonRoad simulator using synthetic scenarios and scenarios derived from real data. Our experimental results show that we can learn the open-loop MPC trajectory with high accuracy while improving the closed-loop performance of the learned control policy over other baselines like behavior cloning.","sentences":["Model predictive control (MPC) is a powerful, optimization-based approach for controlling dynamical systems.","However, the computational complexity of online optimization can be problematic on embedded devices.","Especially, when we need to guarantee fixed control frequencies.","Thus, previous work proposed to reduce the computational burden using imitation learning (IL) approximating the MPC policy by a neural network.","In this work, we instead learn the whole planned trajectory of the MPC.","We introduce a combination of a novel neural network architecture PlanNetX and a simple loss function based on the state trajectory that leverages the parameterized optimal control structure of the MPC.","We validate our approach in the context of autonomous driving by learning a longitudinal planner and benchmarking it extensively in the CommonRoad simulator using synthetic scenarios and scenarios derived from real data.","Our experimental results show that we can learn the open-loop MPC trajectory with high accuracy while improving the closed-loop performance of the learned control policy over other baselines like behavior cloning."],"url":"http://arxiv.org/abs/2404.18863v1"}
{"created":"2024-04-29 16:42:26","title":"FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition","abstract":"Pre-trained Language Models (PLMs) have shown excellent performance on various downstream tasks after fine-tuning. Nevertheless, the escalating concerns surrounding user privacy have posed significant challenges to centralized training reliant on extensive data collection. Federated learning(FL), which only requires training on the clients and aggregates weights on the server without sharing data, has emerged as a solution. However, the substantial parameter size of PLMs places a significant burden on the computational resources of client devices, while also leading to costly communication expenses. Introducing Parameter-Efficient Fine-Tuning(PEFT) into FL can effectively address this problem. However, we observe that the non-IID data in federated learning leads to a gap in performance between the PEFT method and full parameter fine-tuning(FT). To overcome this, we propose FeDeRA, an improvement over the LoRA method in FL. FeDeRA uses the same adapter module as LoRA. However, the difference lies in FeDeRA's initialization of the adapter module by performing Singular Value Decomposition (SVD) on the pre-trained matrix and selecting its principal components. We conducted extensive experiments, using RoBERTa and DeBERTaV3, on three tasks and six datasets, comparing the methods including FT and the other three different PEFT methods. FeDeRA outperforms all other PEFT methods and is comparable to or even surpasses the performance of FT methods. We also deployed federated learning on Jetson AGX Orin and compared the time required by different methods to achieve the target accuracy on specific tasks. Compared to FT, FeDeRA reduces the training time by 95.9%, 97.9%, 96.9%, and 97.3%, 96.5%, and 96.5% respectively on three tasks using RoBERTa and DeBERTaV3. The overall experiments indicate that FeDeRA achieves good performance while also maintaining efficiency.","sentences":["Pre-trained Language Models (PLMs) have shown excellent performance on various downstream tasks after fine-tuning.","Nevertheless, the escalating concerns surrounding user privacy have posed significant challenges to centralized training reliant on extensive data collection.","Federated learning(FL), which only requires training on the clients and aggregates weights on the server without sharing data, has emerged as a solution.","However, the substantial parameter size of PLMs places a significant burden on the computational resources of client devices, while also leading to costly communication expenses.","Introducing Parameter-Efficient Fine-Tuning(PEFT) into FL can effectively address this problem.","However, we observe that the non-IID data in federated learning leads to a gap in performance between the PEFT method and full parameter fine-tuning(FT).","To overcome this, we propose FeDeRA, an improvement over the LoRA method in FL. FeDeRA uses the same adapter module as LoRA.","However, the difference lies in FeDeRA's initialization of the adapter module by performing Singular Value Decomposition (SVD) on the pre-trained matrix and selecting its principal components.","We conducted extensive experiments, using RoBERTa and DeBERTaV3, on three tasks and six datasets, comparing the methods including FT and the other three different PEFT methods.","FeDeRA outperforms all other PEFT methods and is comparable to or even surpasses the performance of FT methods.","We also deployed federated learning on Jetson AGX Orin and compared the time required by different methods to achieve the target accuracy on specific tasks.","Compared to FT, FeDeRA reduces the training time by 95.9%, 97.9%, 96.9%, and 97.3%, 96.5%, and 96.5% respectively on three tasks using RoBERTa and DeBERTaV3.","The overall experiments indicate that FeDeRA achieves good performance while also maintaining efficiency."],"url":"http://arxiv.org/abs/2404.18848v1"}
{"created":"2024-04-29 16:30:24","title":"VISION: Toward a Standardized Process for Radiology Image Management at the National Level","abstract":"The compilation and analysis of radiological images poses numerous challenges for researchers. The sheer volume of data as well as the computational needs of algorithms capable of operating on images are extensive. Additionally, the assembly of these images alone is difficult, as these exams may differ widely in terms of clinical context, structured annotation available for model training, modality, and patient identifiers. In this paper, we describe our experiences and challenges in establishing a trusted collection of radiology images linked to the United States Department of Veterans Affairs (VA) electronic health record database. We also discuss implications in making this repository research-ready for medical investigators. Key insights include uncovering the specific procedures required for transferring images from a clinical to a research-ready environment, as well as roadblocks and bottlenecks in this process that may hinder future efforts at automation.","sentences":["The compilation and analysis of radiological images poses numerous challenges for researchers.","The sheer volume of data as well as the computational needs of algorithms capable of operating on images are extensive.","Additionally, the assembly of these images alone is difficult, as these exams may differ widely in terms of clinical context, structured annotation available for model training, modality, and patient identifiers.","In this paper, we describe our experiences and challenges in establishing a trusted collection of radiology images linked to the United States Department of Veterans Affairs (VA) electronic health record database.","We also discuss implications in making this repository research-ready for medical investigators.","Key insights include uncovering the specific procedures required for transferring images from a clinical to a research-ready environment, as well as roadblocks and bottlenecks in this process that may hinder future efforts at automation."],"url":"http://arxiv.org/abs/2404.18842v1"}
{"created":"2024-04-29 16:19:47","title":"It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments","abstract":"Sentiment analysis is an important tool for aggregating patient voices, in order to provide targeted improvements in healthcare services. A prerequisite for this is the availability of in-domain data annotated for sentiment. This article documents an effort to add sentiment annotations to free-text comments in patient surveys collected by the Norwegian Institute of Public Health (NIPH). However, annotation can be a time-consuming and resource-intensive process, particularly when it requires domain expertise. We therefore also evaluate a possible alternative to human annotation, using large language models (LLMs) as annotators. We perform an extensive evaluation of the approach for two openly available pretrained LLMs for Norwegian, experimenting with different configurations of prompts and in-context learning, comparing their performance to human annotators. We find that even for zero-shot runs, models perform well above the baseline for binary sentiment, but still cannot compete with human annotators on the full dataset.","sentences":["Sentiment analysis is an important tool for aggregating patient voices, in order to provide targeted improvements in healthcare services.","A prerequisite for this is the availability of in-domain data annotated for sentiment.","This article documents an effort to add sentiment annotations to free-text comments in patient surveys collected by the Norwegian Institute of Public Health (NIPH).","However, annotation can be a time-consuming and resource-intensive process, particularly when it requires domain expertise.","We therefore also evaluate a possible alternative to human annotation, using large language models (LLMs) as annotators.","We perform an extensive evaluation of the approach for two openly available pretrained LLMs for Norwegian, experimenting with different configurations of prompts and in-context learning, comparing their performance to human annotators.","We find that even for zero-shot runs, models perform well above the baseline for binary sentiment, but still cannot compete with human annotators on the full dataset."],"url":"http://arxiv.org/abs/2404.18832v1"}
{"created":"2024-04-29 16:05:36","title":"Benchmarking Benchmark Leakage in Large Language Models","abstract":"Amid the expanding use of pre-training data, the phenomenon of benchmark dataset leakage has become increasingly prominent, exacerbated by opaque training processes and the often undisclosed inclusion of supervised data in contemporary Large Language Models (LLMs). This issue skews benchmark effectiveness and fosters potentially unfair comparisons, impeding the field's healthy development. To address this, we introduce a detection pipeline utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that gauge a model's prediction precision on benchmark, to identify potential data leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we reveal substantial instances of training even test set misuse, resulting in potentially unfair comparisons. These findings prompt us to offer several recommendations regarding model documentation, benchmark setup, and future evaluations. Notably, we propose the \"Benchmark Transparency Card\" to encourage clear documentation of benchmark utilization, promoting transparency and healthy developments of LLMs. we have made our leaderboard, pipeline implementation, and model predictions publicly available, fostering future research.","sentences":["Amid the expanding use of pre-training data, the phenomenon of benchmark dataset leakage has become increasingly prominent, exacerbated by opaque training processes and the often undisclosed inclusion of supervised data in contemporary Large Language Models (LLMs).","This issue skews benchmark effectiveness and fosters potentially unfair comparisons, impeding the field's healthy development.","To address this, we introduce a detection pipeline utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that gauge a model's prediction precision on benchmark, to identify potential data leakages.","By analyzing 31 LLMs under the context of mathematical reasoning, we reveal substantial instances of training even test set misuse, resulting in potentially unfair comparisons.","These findings prompt us to offer several recommendations regarding model documentation, benchmark setup, and future evaluations.","Notably, we propose the \"Benchmark Transparency Card\" to encourage clear documentation of benchmark utilization, promoting transparency and healthy developments of LLMs.","we have made our leaderboard, pipeline implementation, and model predictions publicly available, fostering future research."],"url":"http://arxiv.org/abs/2404.18824v1"}
{"created":"2024-04-29 15:40:40","title":"A Partial Replication of MaskFormer in TensorFlow on TPUs for the TensorFlow Model Garden","abstract":"This paper undertakes the task of replicating the MaskFormer model a universal image segmentation model originally developed using the PyTorch framework, within the TensorFlow ecosystem, specifically optimized for execution on Tensor Processing Units (TPUs). Our implementation exploits the modular constructs available within the TensorFlow Model Garden (TFMG), encompassing elements such as the data loader, training orchestrator, and various architectural components, tailored and adapted to meet the specifications of the MaskFormer model. We address key challenges encountered during the replication, non-convergence issues, slow training, adaptation of loss functions, and the integration of TPU-specific functionalities. We verify our reproduced implementation and present qualitative results on the COCO dataset. Although our implementation meets some of the objectives for end-to-end reproducibility, we encountered challenges in replicating the PyTorch version of MaskFormer in TensorFlow. This replication process is not straightforward and requires substantial engineering efforts. Specifically, it necessitates the customization of various components within the TFMG, alongside thorough verification and hyper-parameter tuning. The replication is available at: https://github.com/PurdueDualityLab/tf-maskformer/tree/main/official/projects/maskformer","sentences":["This paper undertakes the task of replicating the MaskFormer model a universal image segmentation model originally developed using the PyTorch framework, within the TensorFlow ecosystem, specifically optimized for execution on Tensor Processing Units (TPUs).","Our implementation exploits the modular constructs available within the TensorFlow Model Garden (TFMG), encompassing elements such as the data loader, training orchestrator, and various architectural components, tailored and adapted to meet the specifications of the MaskFormer model.","We address key challenges encountered during the replication, non-convergence issues, slow training, adaptation of loss functions, and the integration of TPU-specific functionalities.","We verify our reproduced implementation and present qualitative results on the COCO dataset.","Although our implementation meets some of the objectives for end-to-end reproducibility, we encountered challenges in replicating the PyTorch version of MaskFormer in TensorFlow.","This replication process is not straightforward and requires substantial engineering efforts.","Specifically, it necessitates the customization of various components within the TFMG, alongside thorough verification and hyper-parameter tuning.","The replication is available at: https://github.com/PurdueDualityLab/tf-maskformer/tree/main/official/projects/maskformer"],"url":"http://arxiv.org/abs/2404.18801v1"}
{"created":"2024-04-29 15:33:23","title":"Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models","abstract":"As Large Language Models (LLMs) have become more advanced, they have outpaced our abilities to accurately evaluate their quality. Not only is finding data to adequately probe particular model properties difficult, but evaluating the correctness of a model's freeform generation alone is a challenge. To address this, many evaluations now rely on using LLMs themselves as judges to score the quality of outputs from other LLMs. Evaluations most commonly use a single large model like GPT4. While this method has grown in popularity, it is costly, has been shown to introduce intramodel bias, and in this work, we find that very large models are often unnecessary. We propose instead to evaluate models using a Panel of LLm evaluators (PoLL). Across three distinct judge settings and spanning six different datasets, we find that using a PoLL composed of a larger number of smaller models outperforms a single large judge, exhibits less intra-model bias due to its composition of disjoint model families, and does so while being over seven times less expensive.","sentences":["As Large Language Models (LLMs) have become more advanced, they have outpaced our abilities to accurately evaluate their quality.","Not only is finding data to adequately probe particular model properties difficult, but evaluating the correctness of a model's freeform generation alone is a challenge.","To address this, many evaluations now rely on using LLMs themselves as judges to score the quality of outputs from other LLMs.","Evaluations most commonly use a single large model like GPT4.","While this method has grown in popularity, it is costly, has been shown to introduce intramodel bias, and in this work, we find that very large models are often unnecessary.","We propose instead to evaluate models using a Panel of LLm evaluators (PoLL).","Across three distinct judge settings and spanning six different datasets, we find that using a PoLL composed of a larger number of smaller models outperforms a single large judge, exhibits less intra-model bias due to its composition of disjoint model families, and does so while being over seven times less expensive."],"url":"http://arxiv.org/abs/2404.18796v1"}
{"created":"2024-04-29 15:23:16","title":"3D Mapping of Glacier Moulins: Challenges and lessons learned","abstract":"In this paper, we present a field report of the mapping of the Athabasca Glacier, using a custom-made lidar-inertial mapping platform. With the increasing autonomy of robotics, a wider spectrum of applications emerges. Among these, the surveying of environmental areas presents arduous and hazardous challenges for human operators. Leveraging automated platforms for data collection holds the promise of unlocking new applications and a deeper comprehension of the environment. Over the course of a week-long deployment, we collected glacier data using a tailor-made measurement platform and reflected on the inherent challenges associated with such experiments. We focus on the insights gained and the forthcoming challenges that robotics must surmount to effectively map these terrains.","sentences":["In this paper, we present a field report of the mapping of the Athabasca Glacier, using a custom-made lidar-inertial mapping platform.","With the increasing autonomy of robotics, a wider spectrum of applications emerges.","Among these, the surveying of environmental areas presents arduous and hazardous challenges for human operators.","Leveraging automated platforms for data collection holds the promise of unlocking new applications and a deeper comprehension of the environment.","Over the course of a week-long deployment, we collected glacier data using a tailor-made measurement platform and reflected on the inherent challenges associated with such experiments.","We focus on the insights gained and the forthcoming challenges that robotics must surmount to effectively map these terrains."],"url":"http://arxiv.org/abs/2404.18790v1"}
{"created":"2024-04-29 15:18:33","title":"Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input","abstract":"Geo-entity linking is the task of linking a location mention to the real-world geographic location. In this paper we explore the challenging task of geo-entity linking for noisy, multilingual social media data. There are few open-source multilingual geo-entity linking tools available and existing ones are often rule-based, which break easily in social media settings, or LLM-based, which are too expensive for large-scale datasets. We present a method which represents real-world locations as averaged embeddings from labeled user-input location names and allows for selective prediction via an interpretable confidence score. We show that our approach improves geo-entity linking on a global and multilingual social media dataset, and discuss progress and problems with evaluating at different geographic granularities.","sentences":["Geo-entity linking is the task of linking a location mention to the real-world geographic location.","In this paper we explore the challenging task of geo-entity linking for noisy, multilingual social media data.","There are few open-source multilingual geo-entity linking tools available and existing ones are often rule-based, which break easily in social media settings, or LLM-based, which are too expensive for large-scale datasets.","We present a method which represents real-world locations as averaged embeddings from labeled user-input location names and allows for selective prediction via an interpretable confidence score.","We show that our approach improves geo-entity linking on a global and multilingual social media dataset, and discuss progress and problems with evaluating at different geographic granularities."],"url":"http://arxiv.org/abs/2404.18784v1"}
{"created":"2024-04-29 15:18:07","title":"Improved bounds for group testing in arbitrary hypergraphs","abstract":"Recent papers initiated the study of a generalization of group testing where the potentially contaminated sets are the members of a given hypergraph F=(V,E). This generalization finds application in contexts where contaminations can be conditioned by some kinds of social and geographical clusterings. The paper focuses on few-stage group testing algorithms, i.e., slightly adaptive algorithms where tests are performed in stages and all tests performed in the same stage should be decided at the very beginning of the stage. In particular, the paper presents the first two-stage algorithm that uses o(dlog|E|) tests for general hypergraphs with hyperedges of size at most d, and a three-stage algorithm that improves by a d^{1/6} factor on the number of tests of the best known three-stage algorithm. These algorithms are special cases of an s-stage algorithm designed for an arbitrary positive integer s<= d. The design of this algorithm resort to a new non-adaptive algorithm (one-stage algorithm), i.e., an algorithm where all tests must be decided beforehand. Further, we derive a lower bound for non-adaptive group testing. For E sufficiently large, the lower bound is very close to the upper bound on the number of tests of the best non-adaptive group testing algorithm known in the literature, and it is the first lower bound that improves on the information theoretic lower bound Omega(log |E|).","sentences":["Recent papers initiated the study of a generalization of group testing where the potentially contaminated sets are the members of a given hypergraph F=(V,E).","This generalization finds application in contexts where contaminations can be conditioned by some kinds of social and geographical clusterings.","The paper focuses on few-stage group testing algorithms, i.e., slightly adaptive algorithms where tests are performed in stages and all tests performed in the same stage should be decided at the very beginning of the stage.","In particular, the paper presents the first two-stage algorithm that uses o(dlog|E|) tests for general hypergraphs with hyperedges of size at most d, and a three-stage algorithm that improves by a d^{1/6} factor on the number of tests of the best known three-stage algorithm.","These algorithms are special cases of an s-stage algorithm designed for an arbitrary positive integer s<= d.","The design of this algorithm resort to a new non-adaptive algorithm (one-stage algorithm), i.e., an algorithm where all tests must be decided beforehand.","Further, we derive a lower bound for non-adaptive group testing.","For E sufficiently large, the lower bound is very close to the upper bound on the number of tests of the best non-adaptive group testing algorithm known in the literature, and it is the first lower bound that improves on the information theoretic lower bound Omega(log |E|)."],"url":"http://arxiv.org/abs/2404.18783v1"}
{"created":"2024-04-29 15:08:24","title":"A Universal Metric of Dataset Similarity for Cross-silo Federated Learning","abstract":"Federated Learning is increasingly used in domains such as healthcare to facilitate collaborative model training without data-sharing. However, datasets located in different sites are often non-identically distributed, leading to degradation of model performance in FL. Most existing methods for assessing these distribution shifts are limited by being dataset or task-specific. Moreover, these metrics can only be calculated by exchanging data, a practice restricted in many FL scenarios. To address these challenges, we propose a novel metric for assessing dataset similarity. Our metric exhibits several desirable properties for FL: it is dataset-agnostic, is calculated in a privacy-preserving manner, and is computationally efficient, requiring no model training. In this paper, we first establish a theoretical connection between our metric and training dynamics in FL. Next, we extensively evaluate our metric on a range of datasets including synthetic, benchmark, and medical imaging datasets. We demonstrate that our metric shows a robust and interpretable relationship with model performance and can be calculated in privacy-preserving manner. As the first federated dataset similarity metric, we believe this metric can better facilitate successful collaborations between sites.","sentences":["Federated Learning is increasingly used in domains such as healthcare to facilitate collaborative model training without data-sharing.","However, datasets located in different sites are often non-identically distributed, leading to degradation of model performance in FL.","Most existing methods for assessing these distribution shifts are limited by being dataset or task-specific.","Moreover, these metrics can only be calculated by exchanging data, a practice restricted in many FL scenarios.","To address these challenges, we propose a novel metric for assessing dataset similarity.","Our metric exhibits several desirable properties for FL: it is dataset-agnostic, is calculated in a privacy-preserving manner, and is computationally efficient, requiring no model training.","In this paper, we first establish a theoretical connection between our metric and training dynamics in FL.","Next, we extensively evaluate our metric on a range of datasets including synthetic, benchmark, and medical imaging datasets.","We demonstrate that our metric shows a robust and interpretable relationship with model performance and can be calculated in privacy-preserving manner.","As the first federated dataset similarity metric, we believe this metric can better facilitate successful collaborations between sites."],"url":"http://arxiv.org/abs/2404.18773v1"}
{"created":"2024-04-29 14:47:32","title":"Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment","abstract":"Video Anomaly Detection (VAD) identifies unusual activities in video streams, a key technology with broad applications ranging from surveillance to healthcare. Tackling VAD in real-life settings poses significant challenges due to the dynamic nature of human actions, environmental variations, and domain shifts. Many research initiatives neglect these complexities, often concentrating on traditional testing methods that fail to account for performance on unseen datasets, creating a gap between theoretical models and their real-world utility. Online learning is a potential strategy to mitigate this issue by allowing models to adapt to new information continuously. This paper assesses how well current VAD algorithms can adjust to real-life conditions through an online learning framework, particularly those based on pose analysis, for their efficiency and privacy advantages. Our proposed framework enables continuous model updates with streaming data from novel environments, thus mirroring actual world challenges and evaluating the models' ability to adapt in real-time while maintaining accuracy. We investigate three state-of-the-art models in this setting, focusing on their adaptability across different domains. Our findings indicate that, even under the most challenging conditions, our online learning approach allows a model to preserve 89.39% of its original effectiveness compared to its offline-trained counterpart in a specific target domain.","sentences":["Video Anomaly Detection (VAD) identifies unusual activities in video streams, a key technology with broad applications ranging from surveillance to healthcare.","Tackling VAD in real-life settings poses significant challenges due to the dynamic nature of human actions, environmental variations, and domain shifts.","Many research initiatives neglect these complexities, often concentrating on traditional testing methods that fail to account for performance on unseen datasets, creating a gap between theoretical models and their real-world utility.","Online learning is a potential strategy to mitigate this issue by allowing models to adapt to new information continuously.","This paper assesses how well current VAD algorithms can adjust to real-life conditions through an online learning framework, particularly those based on pose analysis, for their efficiency and privacy advantages.","Our proposed framework enables continuous model updates with streaming data from novel environments, thus mirroring actual world challenges and evaluating the models' ability to adapt in real-time while maintaining accuracy.","We investigate three state-of-the-art models in this setting, focusing on their adaptability across different domains.","Our findings indicate that, even under the most challenging conditions, our online learning approach allows a model to preserve 89.39% of its original effectiveness compared to its offline-trained counterpart in a specific target domain."],"url":"http://arxiv.org/abs/2404.18747v1"}
{"created":"2024-04-29 14:37:56","title":"A faster algorithm for the Fr\u00e9chet distance in 1D for the imbalanced case","abstract":"The fine-grained complexity of computing the Fr\\'echet distance has been a topic of much recent work, starting with the quadratic SETH-based conditional lower bound by Bringmann from 2014. Subsequent work established largely the same complexity lower bounds for the Fr\\'echet distance in 1D. However, the imbalanced case, which was shown by Bringmann to be tight in dimensions $d\\geq 2$, was still left open. Filling in this gap, we show that a faster algorithm for the Fr\\'echet distance in the imbalanced case is possible: Given two 1-dimensional curves of complexity $n$ and $n^{\\alpha}$ for some $\\alpha \\in (0,1)$, we can compute their Fr\\'echet distance in $O(n^{2\\alpha} \\log^2 n + n \\log n)$ time. This rules out a conditional lower bound of the form $O((nm)^{1-\\epsilon})$ that Bringmann showed for $d \\geq 2$ and any $\\varepsilon>0$ in turn showing a strict separation with the setting $d=1$. At the heart of our approach lies a data structure that stores a 1-dimensional curve $P$ of complexity $n$, and supports queries with a curve $Q$ of complexity~$m$ for the continuous Fr\\'echet distance between $P$ and $Q$. The data structure has size in $\\mathcal{O}(n\\log n)$ and uses query time in $\\mathcal{O}(m^2 \\log^2 n)$. Our proof uses a key lemma that is based on the concept of visiting orders and may be of independent interest. We demonstrate this by substantially simplifying the correctness proof of a clustering algorithm by Driemel, Krivo\\v{s}ija and Sohler from 2015.","sentences":["The fine-grained complexity of computing the Fr\\'echet distance has been a topic of much recent work, starting with the quadratic SETH-based conditional lower bound by Bringmann from 2014.","Subsequent work established largely the same complexity lower bounds for the Fr\\'echet distance in 1D. However, the imbalanced case, which was shown by Bringmann to be tight in dimensions $d\\geq 2$, was still left open.","Filling in this gap, we show that a faster algorithm for the Fr\\'echet distance in the imbalanced case is possible: Given two 1-dimensional curves of complexity $n$ and $n^{\\alpha}$ for some $\\alpha \\in (0,1)$, we can compute their Fr\\'echet distance in $O(n^{2\\alpha} \\log^2 n + n \\log n)$ time.","This rules out a conditional lower bound of the form $O((nm)^{1-\\epsilon})$ that Bringmann showed for $d \\geq 2$ and any $\\varepsilon>0$ in turn showing a strict separation with the setting $d=1$. At the heart of our approach lies a data structure that stores a 1-dimensional curve $P$ of complexity $n$, and supports queries with a curve $Q$ of complexity~$m$ for the continuous Fr\\'echet distance between $P$ and $Q$. The data structure has size in $\\mathcal{O}(n\\log n)$ and uses query time in $\\mathcal{O}(m^2 \\log^2 n)$. Our proof uses a key lemma that is based on the concept of visiting orders and may be of independent interest.","We demonstrate this by substantially simplifying the correctness proof of a clustering algorithm by Driemel, Krivo\\v{s}ija and Sohler from 2015."],"url":"http://arxiv.org/abs/2404.18738v1"}
{"created":"2024-04-29 14:17:52","title":"Real Time Multi Organ Classification on Computed Tomography Images","abstract":"Organ segmentation is a fundamental task in medical imaging, and it is useful for many clinical automation pipelines. Typically, the process involves segmenting the entire volume, which can be unnecessary when the points of interest are limited. In those cases, a classifier could be used instead of segmentation. However, there is an inherent trade-off between the context size and the speed of classifiers. To address this issue, we propose a new method that employs a data selection strategy with sparse sampling across a wide field of view without image resampling. This sparse sampling strategy makes it possible to classify voxels into multiple organs in real time without using accelerators. Although our method is an independent classifier, it can generate full segmentation by querying grid locations at any resolution. We have compared our method with existing segmentation techniques, demonstrating its potential for superior runtime in practical applications in medical imaging.","sentences":["Organ segmentation is a fundamental task in medical imaging, and it is useful for many clinical automation pipelines.","Typically, the process involves segmenting the entire volume, which can be unnecessary when the points of interest are limited.","In those cases, a classifier could be used instead of segmentation.","However, there is an inherent trade-off between the context size and the speed of classifiers.","To address this issue, we propose a new method that employs a data selection strategy with sparse sampling across a wide field of view without image resampling.","This sparse sampling strategy makes it possible to classify voxels into multiple organs in real time without using accelerators.","Although our method is an independent classifier, it can generate full segmentation by querying grid locations at any resolution.","We have compared our method with existing segmentation techniques, demonstrating its potential for superior runtime in practical applications in medical imaging."],"url":"http://arxiv.org/abs/2404.18731v1"}
{"created":"2024-04-29 14:11:16","title":"Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library","abstract":"PyLaia is one of the most popular open-source software for Automatic Text Recognition (ATR), delivering strong performance in terms of speed and accuracy. In this paper, we outline our recent contributions to the PyLaia library, focusing on the incorporation of reliable confidence scores and the integration of statistical language modeling during decoding. Our implementation provides an easy way to combine PyLaia with n-grams language models at different levels. One of the highlights of this work is that language models are completely auto-tuned: they can be built and used easily without any expert knowledge, and without requiring any additional data. To demonstrate the significance of our contribution, we evaluate PyLaia's performance on twelve datasets, both with and without language modelling. The results show that decoding with small language models improves the Word Error Rate by 13% and the Character Error Rate by 12% in average. Additionally, we conduct an analysis of confidence scores and highlight the importance of calibration techniques. Our implementation is publicly available in the official PyLaia repository at https://gitlab.teklia.com/atr/pylaia, and twelve open-source models are released on Hugging Face.","sentences":["PyLaia is one of the most popular open-source software for Automatic Text Recognition (ATR), delivering strong performance in terms of speed and accuracy.","In this paper, we outline our recent contributions to the PyLaia library, focusing on the incorporation of reliable confidence scores and the integration of statistical language modeling during decoding.","Our implementation provides an easy way to combine PyLaia with n-grams language models at different levels.","One of the highlights of this work is that language models are completely auto-tuned: they can be built and used easily without any expert knowledge, and without requiring any additional data.","To demonstrate the significance of our contribution, we evaluate PyLaia's performance on twelve datasets, both with and without language modelling.","The results show that decoding with small language models improves the Word Error Rate by 13% and the Character Error Rate by 12% in average.","Additionally, we conduct an analysis of confidence scores and highlight the importance of calibration techniques.","Our implementation is publicly available in the official PyLaia repository at https://gitlab.teklia.com/atr/pylaia, and twelve open-source models are released on Hugging Face."],"url":"http://arxiv.org/abs/2404.18722v1"}
{"created":"2024-04-29 14:10:13","title":"Risk-Aware Coverage Path Planning for Lunar Micro-Rovers Leveraging Global and Local Environmental Data","abstract":"This paper presents a novel 3D myopic coverage path planning algorithm for lunar micro-rovers that can explore unknown environments with limited sensing and computational capabilities. The algorithm expands upon traditional non-graph path planning methods to accommodate the complexities of lunar terrain, utilizing global data with local topographic features into motion cost calculations. The algorithm also integrates localization and mapping to update the rover's pose and map the environment. The resulting environment map's accuracy is evaluated and tested in a 3D simulator. Outdoor field tests were conducted to validate the algorithm's efficacy in sim-to-real scenarios. The results showed that the algorithm could achieve high coverage with low energy consumption and computational cost, while incrementally exploring the terrain and avoiding obstacles. This study contributes to the advancement of path planning methodologies for space exploration, paving the way for efficient, scalable and autonomous exploration of lunar environments by small rovers.","sentences":["This paper presents a novel 3D myopic coverage path planning algorithm for lunar micro-rovers that can explore unknown environments with limited sensing and computational capabilities.","The algorithm expands upon traditional non-graph path planning methods to accommodate the complexities of lunar terrain, utilizing global data with local topographic features into motion cost calculations.","The algorithm also integrates localization and mapping to update the rover's pose and map the environment.","The resulting environment map's accuracy is evaluated and tested in a 3D simulator.","Outdoor field tests were conducted to validate the algorithm's efficacy in sim-to-real scenarios.","The results showed that the algorithm could achieve high coverage with low energy consumption and computational cost, while incrementally exploring the terrain and avoiding obstacles.","This study contributes to the advancement of path planning methodologies for space exploration, paving the way for efficient, scalable and autonomous exploration of lunar environments by small rovers."],"url":"http://arxiv.org/abs/2404.18721v1"}
{"created":"2024-04-29 13:57:02","title":"The Socface Project: Large-Scale Collection, Processing, and Analysis of a Century of French Censuses","abstract":"This paper presents a complete processing workflow for extracting information from French census lists from 1836 to 1936. These lists contain information about individuals living in France and their households. We aim at extracting all the information contained in these tables using automatic handwritten table recognition. At the end of the Socface project, in which our work is taking place, the extracted information will be redistributed to the departmental archives, and the nominative lists will be freely available to the public, allowing anyone to browse hundreds of millions of records. The extracted data will be used by demographers to analyze social change over time, significantly improving our understanding of French economic and social structures. For this project, we developed a complete processing workflow: large-scale data collection from French departmental archives, collaborative annotation of documents, training of handwritten table text and structure recognition models, and mass processing of millions of images. We present the tools we have developed to easily collect and process millions of pages. We also show that it is possible to process such a wide variety of tables with a single table recognition model that uses the image of the entire page to recognize information about individuals, categorize them and automatically group them into households. The entire process has been successfully used to process the documents of a departmental archive, representing more than 450,000 images.","sentences":["This paper presents a complete processing workflow for extracting information from French census lists from 1836 to 1936.","These lists contain information about individuals living in France and their households.","We aim at extracting all the information contained in these tables using automatic handwritten table recognition.","At the end of the Socface project, in which our work is taking place, the extracted information will be redistributed to the departmental archives, and the nominative lists will be freely available to the public, allowing anyone to browse hundreds of millions of records.","The extracted data will be used by demographers to analyze social change over time, significantly improving our understanding of French economic and social structures.","For this project, we developed a complete processing workflow: large-scale data collection from French departmental archives, collaborative annotation of documents, training of handwritten table text and structure recognition models, and mass processing of millions of images.","We present the tools we have developed to easily collect and process millions of pages.","We also show that it is possible to process such a wide variety of tables with a single table recognition model that uses the image of the entire page to recognize information about individuals, categorize them and automatically group them into households.","The entire process has been successfully used to process the documents of a departmental archive, representing more than 450,000 images."],"url":"http://arxiv.org/abs/2404.18706v1"}
{"created":"2024-04-29 13:56:32","title":"Wireless Information and Energy Transfer in the Era of 6G Communications","abstract":"Wireless information and energy transfer (WIET) represents an emerging paradigm which employs controllable transmission of radio-frequency signals for the dual purpose of data communication and wireless charging. As such, WIET is widely regarded as an enabler of envisioned 6G use cases that rely on energy-sustainable Internet-of-Things (IoT) networks, such as smart cities and smart grids. Meeting the quality-of-service demands of WIET, in terms of both data transfer and power delivery, requires effective co-design of the information and energy signals. In this article, we present the main principles and design aspects of WIET, focusing on its integration in 6G networks. First, we discuss how conventional communication notions such as resource allocation and waveform design need to be revisited in the context of WIET. Next, we consider various candidate 6G technologies that can boost WIET efficiency, namely, holographic multiple-input multiple-output, near-field beamforming, terahertz communication, intelligent reflecting surfaces (IRSs), and reconfigurable (fluid) antenna arrays. We introduce respective WIET design methods, analyze the promising performance gains of these WIET systems, and discuss challenges, open issues, and future research directions. Finally, a near-field energy beamforming scheme and a power-based IRS beamforming algorithm are experimentally validated using a wireless energy transfer testbed. The vision of WIET in communication systems has been gaining momentum in recent years, with constant progress with respect to theoretical but also practical aspects. The comprehensive overview of the state of the art of WIET presented in this paper highlights the potentials of WIET systems as well as their overall benefits in 6G networks.","sentences":["Wireless information and energy transfer (WIET) represents an emerging paradigm which employs controllable transmission of radio-frequency signals for the dual purpose of data communication and wireless charging.","As such, WIET is widely regarded as an enabler of envisioned 6G use cases that rely on energy-sustainable Internet-of-Things (IoT) networks, such as smart cities and smart grids.","Meeting the quality-of-service demands of WIET, in terms of both data transfer and power delivery, requires effective co-design of the information and energy signals.","In this article, we present the main principles and design aspects of WIET, focusing on its integration in 6G networks.","First, we discuss how conventional communication notions such as resource allocation and waveform design need to be revisited in the context of WIET.","Next, we consider various candidate 6G technologies that can boost WIET efficiency, namely, holographic multiple-input multiple-output, near-field beamforming, terahertz communication, intelligent reflecting surfaces (IRSs), and reconfigurable (fluid) antenna arrays.","We introduce respective WIET design methods, analyze the promising performance gains of these WIET systems, and discuss challenges, open issues, and future research directions.","Finally, a near-field energy beamforming scheme and a power-based IRS beamforming algorithm are experimentally validated using a wireless energy transfer testbed.","The vision of WIET in communication systems has been gaining momentum in recent years, with constant progress with respect to theoretical but also practical aspects.","The comprehensive overview of the state of the art of WIET presented in this paper highlights the potentials of WIET systems as well as their overall benefits in 6G networks."],"url":"http://arxiv.org/abs/2404.18705v1"}
{"created":"2024-04-29 13:42:55","title":"Beyond Gaze Points: Augmenting Eye Movement with Brainwave Data for Multimodal User Authentication in Extended Reality","abstract":"The increasing adoption of Extended Reality (XR) in various applications underscores the need for secure and user-friendly authentication methods. However, existing methods can disrupt the immersive experience in XR settings, or suffer from higher false acceptance rates. In this paper, we introduce a multimodal biometric authentication system that combines eye movement and brainwave patterns, as captured by consumer-grade low-fidelity sensors. Our multimodal authentication exploits the non-invasive and hands-free properties of eye movement and brainwaves to provide a seamless XR user experience and enhanced security as well. Using synchronized eye and brainwave data collected from 30 participants through consumer-grade devices, we investigated whether twin neural networks can utilize these biometrics for identity verification. Our multimodal authentication system yields an excellent Equal Error Rate (EER) of 0.298\\%, which means an 83.6\\% reduction in EER compared to the single eye movement modality or a 93.9\\% reduction in EER compared to the single brainwave modality.","sentences":["The increasing adoption of Extended Reality (XR) in various applications underscores the need for secure and user-friendly authentication methods.","However, existing methods can disrupt the immersive experience in XR settings, or suffer from higher false acceptance rates.","In this paper, we introduce a multimodal biometric authentication system that combines eye movement and brainwave patterns, as captured by consumer-grade low-fidelity sensors.","Our multimodal authentication exploits the non-invasive and hands-free properties of eye movement and brainwaves to provide a seamless XR user experience and enhanced security as well.","Using synchronized eye and brainwave data collected from 30 participants through consumer-grade devices, we investigated whether twin neural networks can utilize these biometrics for identity verification.","Our multimodal authentication system yields an excellent Equal Error Rate (EER) of 0.298\\%, which means an 83.6\\% reduction in EER compared to the single eye movement modality or a 93.9\\% reduction in EER compared to the single brainwave modality."],"url":"http://arxiv.org/abs/2404.18694v1"}
{"created":"2024-04-29 13:41:35","title":"Private graph colouring with limited defectiveness","abstract":"Differential privacy is the gold standard in the problem of privacy preserving data analysis, which is crucial in a wide range of disciplines. Vertex colouring is one of the most fundamental questions about a graph. In this paper, we study the vertex colouring problem in the differentially private setting.   To be edge-differentially private, a colouring algorithm needs to be defective: a colouring is d-defective if a vertex can share a colour with at most d of its neighbours. Without defectiveness, the only differentially private colouring algorithm needs to assign n different colours to the n different vertices. We show the following lower bound for the defectiveness: a differentially private c-edge colouring algorithm of a graph of maximum degree {\\Delta} > 0 has defectiveness at least d = {\\Omega} (log n / (log c+log {\\Delta})).   We also present an {\\epsilon}-differentially private algorithm to {\\Theta} ( {\\Delta} / log n + 1 / {\\epsilon})-colour a graph with defectiveness at most {\\Theta}(log n).","sentences":["Differential privacy is the gold standard in the problem of privacy preserving data analysis, which is crucial in a wide range of disciplines.","Vertex colouring is one of the most fundamental questions about a graph.","In this paper, we study the vertex colouring problem in the differentially private setting.   ","To be edge-differentially private, a colouring algorithm needs to be defective: a colouring is d-defective if a vertex can share a colour with at most d of its neighbours.","Without defectiveness, the only differentially private colouring algorithm needs to assign n different colours to the n different vertices.","We show the following lower bound for the defectiveness: a differentially private c-edge colouring algorithm of a graph of maximum degree {\\Delta} > 0 has defectiveness at least d = {\\Omega} (log n / (log c+log {\\Delta})).   ","We also present an {\\epsilon}-differentially private algorithm to {\\Theta} ( {\\Delta} / log n + 1 / {\\epsilon})-colour a graph with defectiveness at most {\\Theta}(log n)."],"url":"http://arxiv.org/abs/2404.18692v1"}
{"created":"2024-04-29 13:36:09","title":"Distributed Source Coding for Parametric and Non-Parametric Regression","abstract":"The design of communication systems dedicated to machine learning tasks is one key aspect of goal-oriented communications. In this framework, this article investigates the interplay between data reconstruction and learning from the same compressed observations, particularly focusing on the regression problem. We establish achievable rate-generalization error regions for both parametric and non-parametric regression, where the generalization error measures the regression performance on previously unseen data. The analysis covers both asymptotic and finite block-length regimes, providing fundamental results and practical insights for the design of coding schemes dedicated to regression. The asymptotic analysis relies on conventional Wyner-Ziv coding schemes which we extend to study the convergence of the generalization error. The finite-length analysis uses the notions of information density and dispersion with additional term for the generalization error. We further investigate the trade-off between reconstruction and regression in both asymptotic and non-asymptotic regimes. Contrary to the existing literature which focused on other learning tasks, our results state that in the case of regression, there is no trade-off between data reconstruction and regression in the asymptotic regime. We also observe the same absence of trade-off for the considered achievable scheme in the finite-length regime, by analyzing correlation between distortion and generalization error.","sentences":["The design of communication systems dedicated to machine learning tasks is one key aspect of goal-oriented communications.","In this framework, this article investigates the interplay between data reconstruction and learning from the same compressed observations, particularly focusing on the regression problem.","We establish achievable rate-generalization error regions for both parametric and non-parametric regression, where the generalization error measures the regression performance on previously unseen data.","The analysis covers both asymptotic and finite block-length regimes, providing fundamental results and practical insights for the design of coding schemes dedicated to regression.","The asymptotic analysis relies on conventional Wyner-Ziv coding schemes which we extend to study the convergence of the generalization error.","The finite-length analysis uses the notions of information density and dispersion with additional term for the generalization error.","We further investigate the trade-off between reconstruction and regression in both asymptotic and non-asymptotic regimes.","Contrary to the existing literature which focused on other learning tasks, our results state that in the case of regression, there is no trade-off between data reconstruction and regression in the asymptotic regime.","We also observe the same absence of trade-off for the considered achievable scheme in the finite-length regime, by analyzing correlation between distortion and generalization error."],"url":"http://arxiv.org/abs/2404.18688v1"}
{"created":"2024-04-29 13:24:23","title":"LLMClean: Context-Aware Tabular Data Cleaning via LLM-Generated OFDs","abstract":"Machine learning's influence is expanding rapidly, now integral to decision-making processes from corporate strategy to the advancements in Industry 4.0. The efficacy of Artificial Intelligence broadly hinges on the caliber of data used during its training phase; optimal performance is tied to exceptional data quality. Data cleaning tools, particularly those that exploit functional dependencies within ontological frameworks or context models, are instrumental in augmenting data quality. Nevertheless, crafting these context models is a demanding task, both in terms of resources and expertise, often necessitating specialized knowledge from domain experts.   In light of these challenges, this paper introduces an innovative approach, called LLMClean, for the automated generation of context models, utilizing Large Language Models to analyze and understand various datasets. LLMClean encompasses a sequence of actions, starting with categorizing the dataset, extracting or mapping relevant models, and ultimately synthesizing the context model. To demonstrate its potential, we have developed and tested a prototype that applies our approach to three distinct datasets from the Internet of Things, healthcare, and Industry 4.0 sectors. The results of our evaluation indicate that our automated approach can achieve data cleaning efficacy comparable with that of context models crafted by human experts.","sentences":["Machine learning's influence is expanding rapidly, now integral to decision-making processes from corporate strategy to the advancements in Industry 4.0.","The efficacy of Artificial Intelligence broadly hinges on the caliber of data used during its training phase; optimal performance is tied to exceptional data quality.","Data cleaning tools, particularly those that exploit functional dependencies within ontological frameworks or context models, are instrumental in augmenting data quality.","Nevertheless, crafting these context models is a demanding task, both in terms of resources and expertise, often necessitating specialized knowledge from domain experts.   ","In light of these challenges, this paper introduces an innovative approach, called LLMClean, for the automated generation of context models, utilizing Large Language Models to analyze and understand various datasets.","LLMClean encompasses a sequence of actions, starting with categorizing the dataset, extracting or mapping relevant models, and ultimately synthesizing the context model.","To demonstrate its potential, we have developed and tested a prototype that applies our approach to three distinct datasets from the Internet of Things, healthcare, and Industry 4.0 sectors.","The results of our evaluation indicate that our automated approach can achieve data cleaning efficacy comparable with that of context models crafted by human experts."],"url":"http://arxiv.org/abs/2404.18681v1"}
{"created":"2024-04-29 13:23:38","title":"How Deep Is Your Gaze? Leveraging Distance in Image-Based Gaze Analysis","abstract":"Image thumbnails are a valuable data source for fixation filtering, scanpath classification, and visualization of eye tracking data. They are typically extracted with a constant size, approximating the foveated area. As a consequence, the focused area of interest in the scene becomes less prominent in the thumbnail with increasing distance, affecting image-based analysis techniques. In this work, we propose depth-adaptive thumbnails, a method for varying image size according to the eye-to-object distance. Adjusting the visual angle relative to the distance leads to a zoom effect on the focused area. We evaluate our approach on recordings in augmented reality, investigating the similarity of thumbnails and scanpaths. Our quantitative findings suggest that considering the eye-to-object distance improves the quality of data analysis and visualization. We demonstrate the utility of depth-adaptive thumbnails for applications in scanpath comparison and visualization.","sentences":["Image thumbnails are a valuable data source for fixation filtering, scanpath classification, and visualization of eye tracking data.","They are typically extracted with a constant size, approximating the foveated area.","As a consequence, the focused area of interest in the scene becomes less prominent in the thumbnail with increasing distance, affecting image-based analysis techniques.","In this work, we propose depth-adaptive thumbnails, a method for varying image size according to the eye-to-object distance.","Adjusting the visual angle relative to the distance leads to a zoom effect on the focused area.","We evaluate our approach on recordings in augmented reality, investigating the similarity of thumbnails and scanpaths.","Our quantitative findings suggest that considering the eye-to-object distance improves the quality of data analysis and visualization.","We demonstrate the utility of depth-adaptive thumbnails for applications in scanpath comparison and visualization."],"url":"http://arxiv.org/abs/2404.18680v1"}
{"created":"2024-04-29 13:13:10","title":"Open-Source Drift Detection Tools in Action: Insights from Two Use Cases","abstract":"Data drifts pose a critical challenge in the lifecycle of machine learning (ML) models, affecting their performance and reliability. In response to this challenge, we present a microbenchmark study, called D3Bench, which evaluates the efficacy of open-source drift detection tools. D3Bench examines the capabilities of Evidently AI, NannyML, and Alibi-Detect, leveraging real-world data from two smart building use cases.We prioritize assessing the functional suitability of these tools to identify and analyze data drifts. Furthermore, we consider a comprehensive set of non-functional criteria, such as the integrability with ML pipelines, the adaptability to diverse data types, user-friendliness, computational efficiency, and resource demands. Our findings reveal that Evidently AI stands out for its general data drift detection, whereas NannyML excels at pinpointing the precise timing of shifts and evaluating their consequent effects on predictive accuracy.","sentences":["Data drifts pose a critical challenge in the lifecycle of machine learning (ML) models, affecting their performance and reliability.","In response to this challenge, we present a microbenchmark study, called D3Bench, which evaluates the efficacy of open-source drift detection tools.","D3Bench examines the capabilities of Evidently AI, NannyML, and Alibi-Detect, leveraging real-world data from two smart building use cases.","We prioritize assessing the functional suitability of these tools to identify and analyze data drifts.","Furthermore, we consider a comprehensive set of non-functional criteria, such as the integrability with ML pipelines, the adaptability to diverse data types, user-friendliness, computational efficiency, and resource demands.","Our findings reveal that Evidently AI stands out for its general data drift detection, whereas NannyML excels at pinpointing the precise timing of shifts and evaluating their consequent effects on predictive accuracy."],"url":"http://arxiv.org/abs/2404.18673v1"}
{"created":"2024-04-29 13:05:59","title":"Enhancing Uncertain Demand Prediction in Hospitals Using Simple and Advanced Machine Learning","abstract":"Early and timely prediction of patient care demand not only affects effective resource allocation but also influences clinical decision-making as well as patient experience. Accurately predicting patient care demand, however, is a ubiquitous challenge for hospitals across the world due, in part, to the demand's time-varying temporal variability, and, in part, to the difficulty in modelling trends in advance. To address this issue, here, we develop two methods, a relatively simple time-vary linear model, and a more advanced neural network model. The former forecasts patient arrivals hourly over a week based on factors such as day of the week and previous 7-day arrival patterns. The latter leverages a long short-term memory (LSTM) model, capturing non-linear relationships between past data and a three-day forecasting window. We evaluate the predictive capabilities of the two proposed approaches compared to two na\\\"ive approaches - a reduced-rank vector autoregressive (VAR) model and the TBATS model. Using patient care demand data from Rambam Medical Center in Israel, our results show that both proposed models effectively capture hourly variations of patient demand. Additionally, the linear model is more explainable thanks to its simple architecture, whereas, by accurately modelling weekly seasonal trends, the LSTM model delivers lower prediction errors. Taken together, our explorations suggest the utility of machine learning in predicting time-varying patient care demand; additionally, it is possible to predict patient care demand with good accuracy (around 4 patients) three days or a week in advance using machine learning.","sentences":["Early and timely prediction of patient care demand not only affects effective resource allocation but also influences clinical decision-making as well as patient experience.","Accurately predicting patient care demand, however, is a ubiquitous challenge for hospitals across the world due, in part, to the demand's time-varying temporal variability, and, in part, to the difficulty in modelling trends in advance.","To address this issue, here, we develop two methods, a relatively simple time-vary linear model, and a more advanced neural network model.","The former forecasts patient arrivals hourly over a week based on factors such as day of the week and previous 7-day arrival patterns.","The latter leverages a long short-term memory (LSTM) model, capturing non-linear relationships between past data and a three-day forecasting window.","We evaluate the predictive capabilities of the two proposed approaches compared to two na\\\"ive approaches - a reduced-rank vector autoregressive (VAR) model and the TBATS model.","Using patient care demand data from Rambam Medical Center in Israel, our results show that both proposed models effectively capture hourly variations of patient demand.","Additionally, the linear model is more explainable thanks to its simple architecture, whereas, by accurately modelling weekly seasonal trends, the LSTM model delivers lower prediction errors.","Taken together, our explorations suggest the utility of machine learning in predicting time-varying patient care demand; additionally, it is possible to predict patient care demand with good accuracy (around 4 patients) three days or a week in advance using machine learning."],"url":"http://arxiv.org/abs/2404.18670v1"}
{"created":"2024-04-29 12:49:53","title":"Leveraging PointNet and PointNet++ for Lyft Point Cloud Classification Challenge","abstract":"This study investigates the application of PointNet and PointNet++ in the classification of LiDAR-generated point cloud data, a critical component for achieving fully autonomous vehicles. Utilizing a modified dataset from the Lyft 3D Object Detection Challenge, we examine the models' capabilities to handle dynamic and complex environments essential for autonomous navigation. Our analysis shows that PointNet and PointNet++ achieved accuracy rates of 79.53% and 84.24%, respectively. These results underscore the models' robustness in interpreting intricate environmental data, which is pivotal for the safety and efficiency of autonomous vehicles. Moreover, the enhanced detection accuracy, particularly in distinguishing pedestrians from other objects, highlights the potential of these models to contribute substantially to the advancement of autonomous vehicle technology.","sentences":["This study investigates the application of PointNet and PointNet++ in the classification of LiDAR-generated point cloud data, a critical component for achieving fully autonomous vehicles.","Utilizing a modified dataset from the Lyft 3D Object Detection Challenge, we examine the models' capabilities to handle dynamic and complex environments essential for autonomous navigation.","Our analysis shows that PointNet and PointNet++ achieved accuracy rates of 79.53% and 84.24%, respectively.","These results underscore the models' robustness in interpreting intricate environmental data, which is pivotal for the safety and efficiency of autonomous vehicles.","Moreover, the enhanced detection accuracy, particularly in distinguishing pedestrians from other objects, highlights the potential of these models to contribute substantially to the advancement of autonomous vehicle technology."],"url":"http://arxiv.org/abs/2404.18665v1"}
{"created":"2024-04-29 12:40:07","title":"On the Evaluation of Procedural Level Generation Systems","abstract":"The evaluation of procedural content generation (PCG) systems for generating video game levels is a complex and contested topic. Ideally, the field would have access to robust, generalisable and widely accepted evaluation approaches that can be used to compare novel PCG systems to prior work, but consensus on how to evaluate novel systems is currently limited. We argue that the field can benefit from a structured analysis of how procedural level generation systems can be evaluated, and how these techniques are currently used by researchers. This analysis can then be used to both inform on the current state of affairs, and to provide data to justify changes to this practice. This work aims to provide this by first developing a novel taxonomy of PCG evaluation approaches, and then presenting the results of a survey of recent work in the field through the lens of this taxonomy. The results of this survey highlight several important weaknesses in current practice which we argue could be substantially mitigated by 1) promoting use of evaluation free system descriptions where appropriate, 2) promoting the development of diverse research frameworks, 3) promoting reuse of code and methodology wherever possible.","sentences":["The evaluation of procedural content generation (PCG) systems for generating video game levels is a complex and contested topic.","Ideally, the field would have access to robust, generalisable and widely accepted evaluation approaches that can be used to compare novel PCG systems to prior work, but consensus on how to evaluate novel systems is currently limited.","We argue that the field can benefit from a structured analysis of how procedural level generation systems can be evaluated, and how these techniques are currently used by researchers.","This analysis can then be used to both inform on the current state of affairs, and to provide data to justify changes to this practice.","This work aims to provide this by first developing a novel taxonomy of PCG evaluation approaches, and then presenting the results of a survey of recent work in the field through the lens of this taxonomy.","The results of this survey highlight several important weaknesses in current practice which we argue could be substantially mitigated by 1) promoting use of evaluation free system descriptions where appropriate, 2) promoting the development of diverse research frameworks, 3) promoting reuse of code and methodology wherever possible."],"url":"http://arxiv.org/abs/2404.18657v1"}
{"created":"2024-04-29 12:31:38","title":"Uncertainty-boosted Robust Video Activity Anticipation","abstract":"Video activity anticipation aims to predict what will happen in the future, embracing a broad application prospect ranging from robot vision and autonomous driving. Despite the recent progress, the data uncertainty issue, reflected as the content evolution process and dynamic correlation in event labels, has been somehow ignored. This reduces the model generalization ability and deep understanding on video content, leading to serious error accumulation and degraded performance. In this paper, we address the uncertainty learning problem and propose an uncertainty-boosted robust video activity anticipation framework, which generates uncertainty values to indicate the credibility of the anticipation results. The uncertainty value is used to derive a temperature parameter in the softmax function to modulate the predicted target activity distribution. To guarantee the distribution adjustment, we construct a reasonable target activity label representation by incorporating the activity evolution from the temporal class correlation and the semantic relationship. Moreover, we quantify the uncertainty into relative values by comparing the uncertainty among sample pairs and their temporal-lengths. This relative strategy provides a more accessible way in uncertainty modeling than quantifying the absolute uncertainty values on the whole dataset. Experiments on multiple backbones and benchmarks show our framework achieves promising performance and better robustness/interpretability. Source codes are available at https://github.com/qzhb/UbRV2A.","sentences":["Video activity anticipation aims to predict what will happen in the future, embracing a broad application prospect ranging from robot vision and autonomous driving.","Despite the recent progress, the data uncertainty issue, reflected as the content evolution process and dynamic correlation in event labels, has been somehow ignored.","This reduces the model generalization ability and deep understanding on video content, leading to serious error accumulation and degraded performance.","In this paper, we address the uncertainty learning problem and propose an uncertainty-boosted robust video activity anticipation framework, which generates uncertainty values to indicate the credibility of the anticipation results.","The uncertainty value is used to derive a temperature parameter in the softmax function to modulate the predicted target activity distribution.","To guarantee the distribution adjustment, we construct a reasonable target activity label representation by incorporating the activity evolution from the temporal class correlation and the semantic relationship.","Moreover, we quantify the uncertainty into relative values by comparing the uncertainty among sample pairs and their temporal-lengths.","This relative strategy provides a more accessible way in uncertainty modeling than quantifying the absolute uncertainty values on the whole dataset.","Experiments on multiple backbones and benchmarks show our framework achieves promising performance and better robustness/interpretability.","Source codes are available at https://github.com/qzhb/UbRV2A."],"url":"http://arxiv.org/abs/2404.18648v1"}
{"created":"2024-04-29 12:27:41","title":"Graph Search Trees and the Intermezzo Problem","abstract":"The last in-tree recognition problem asks whether a given spanning tree can be derived by connecting each vertex with its rightmost left neighbor of some search ordering. In this study, we demonstrate that the last-in-tree recognition problem for Generic Search is $\\mathsf{NP}$-complete. We utilize this finding to strengthen a complexity result from order theory. Given partial order $\\pi$ and a set of triples, the $\\mathsf{NP}$-complete intermezzo problem asks for a linear extension of $\\pi$ where each first element of a triple is not between the other two. We show that this problem remains $\\mathsf{NP}$-complete even when the Hasse diagram of the partial order forms a tree of bounded height. In contrast, we give an $\\mathsf{XP}$ algorithm for the problem when parameterized by the width of the partial order. Furthermore, we show that $\\unicode{x2013}$ under the assumption of the Exponential Time Hypothesis $\\unicode{x2013}$ the running time of this algorithm is asymptotically optimal.","sentences":["The last in-tree recognition problem asks whether a given spanning tree can be derived by connecting each vertex with its rightmost left neighbor of some search ordering.","In this study, we demonstrate that the last-in-tree recognition problem for Generic Search is $\\mathsf{NP}$-complete.","We utilize this finding to strengthen a complexity result from order theory.","Given partial order $\\pi$ and a set of triples, the $\\mathsf{NP}$-complete intermezzo problem asks for a linear extension of $\\pi$ where each first element of a triple is not between the other two.","We show that this problem remains $\\mathsf{NP}$-complete even when the Hasse diagram of the partial order forms a tree of bounded height.","In contrast, we give an $\\mathsf{XP}$ algorithm for the problem when parameterized by the width of the partial order.","Furthermore, we show that $\\unicode{x2013}$ under the assumption of the Exponential Time Hypothesis $\\unicode{x2013}$ the running time of this algorithm is asymptotically optimal."],"url":"http://arxiv.org/abs/2404.18645v1"}
{"created":"2024-04-29 12:18:21","title":"Going Beyond Popularity and Positivity Bias: Correcting for Multifactorial Bias in Recommender Systems","abstract":"Two typical forms of bias in user interaction data with recommender systems (RSs) are popularity bias and positivity bias, which manifest themselves as the over-representation of interactions with popular items or items that users prefer, respectively. Debiasing methods aim to mitigate the effect of selection bias on the evaluation and optimization of RSs. However, existing debiasing methods only consider single-factor forms of bias, e.g., only the item (popularity) or only the rating value (positivity). This is in stark contrast with the real world where user selections are generally affected by multiple factors at once. In this work, we consider multifactorial selection bias in RSs. Our focus is on selection bias affected by both item and rating value factors, which is a generalization and combination of popularity and positivity bias. While the concept of multifactorial bias is intuitive, it brings a severe practical challenge as it requires substantially more data for accurate bias estimation. As a solution, we propose smoothing and alternating gradient descent techniques to reduce variance and improve the robustness of its optimization. Our experimental results reveal that, with our proposed techniques, multifactorial bias corrections are more effective and robust than single-factor counterparts on real-world and synthetic datasets.","sentences":["Two typical forms of bias in user interaction data with recommender systems (RSs) are popularity bias and positivity bias, which manifest themselves as the over-representation of interactions with popular items or items that users prefer, respectively.","Debiasing methods aim to mitigate the effect of selection bias on the evaluation and optimization of RSs.","However, existing debiasing methods only consider single-factor forms of bias, e.g., only the item (popularity) or only the rating value (positivity).","This is in stark contrast with the real world where user selections are generally affected by multiple factors at once.","In this work, we consider multifactorial selection bias in RSs.","Our focus is on selection bias affected by both item and rating value factors, which is a generalization and combination of popularity and positivity bias.","While the concept of multifactorial bias is intuitive, it brings a severe practical challenge as it requires substantially more data for accurate bias estimation.","As a solution, we propose smoothing and alternating gradient descent techniques to reduce variance and improve the robustness of its optimization.","Our experimental results reveal that, with our proposed techniques, multifactorial bias corrections are more effective and robust than single-factor counterparts on real-world and synthetic datasets."],"url":"http://arxiv.org/abs/2404.18640v1"}
{"created":"2024-04-29 12:11:26","title":"Feature importance to explain multimodal prediction models. A clinical use case","abstract":"Surgery to treat elderly hip fracture patients may cause complications that can lead to early mortality. An early warning system for complications could provoke clinicians to monitor high-risk patients more carefully and address potential complications early, or inform the patient. In this work, we develop a multimodal deep-learning model for post-operative mortality prediction using pre-operative and per-operative data from elderly hip fracture patients. Specifically, we include static patient data, hip and chest images before surgery in pre-operative data, vital signals, and medications administered during surgery in per-operative data. We extract features from image modalities using ResNet and from vital signals using LSTM. Explainable model outcomes are essential for clinical applicability, therefore we compute Shapley values to explain the predictions of our multimodal black box model. We find that i) Shapley values can be used to estimate the relative contribution of each modality both locally and globally, and ii) a modified version of the chain rule can be used to propagate Shapley values through a sequence of models supporting interpretable local explanations. Our findings imply that a multimodal combination of black box models can be explained by propagating Shapley values through the model sequence.","sentences":["Surgery to treat elderly hip fracture patients may cause complications that can lead to early mortality.","An early warning system for complications could provoke clinicians to monitor high-risk patients more carefully and address potential complications early, or inform the patient.","In this work, we develop a multimodal deep-learning model for post-operative mortality prediction using pre-operative and per-operative data from elderly hip fracture patients.","Specifically, we include static patient data, hip and chest images before surgery in pre-operative data, vital signals, and medications administered during surgery in per-operative data.","We extract features from image modalities using ResNet and from vital signals using LSTM.","Explainable model outcomes are essential for clinical applicability, therefore we compute Shapley values to explain the predictions of our multimodal black box model.","We find that i)","Shapley values can be used to estimate the relative contribution of each modality both locally and globally, and ii) a modified version of the chain rule can be used to propagate Shapley values through a sequence of models supporting interpretable local explanations.","Our findings imply that a multimodal combination of black box models can be explained by propagating Shapley values through the model sequence."],"url":"http://arxiv.org/abs/2404.18631v1"}
{"created":"2024-04-29 12:06:06","title":"4D-DRESS: A 4D Dataset of Real-world Human Clothing with Semantic Annotations","abstract":"The studies of human clothing for digital avatars have predominantly relied on synthetic datasets. While easy to collect, synthetic data often fall short in realism and fail to capture authentic clothing dynamics. Addressing this gap, we introduce 4D-DRESS, the first real-world 4D dataset advancing human clothing research with its high-quality 4D textured scans and garment meshes. 4D-DRESS captures 64 outfits in 520 human motion sequences, amounting to 78k textured scans. Creating a real-world clothing dataset is challenging, particularly in annotating and segmenting the extensive and complex 4D human scans. To address this, we develop a semi-automatic 4D human parsing pipeline. We efficiently combine a human-in-the-loop process with automation to accurately label 4D scans in diverse garments and body movements. Leveraging precise annotations and high-quality garment meshes, we establish several benchmarks for clothing simulation and reconstruction. 4D-DRESS offers realistic and challenging data that complements synthetic sources, paving the way for advancements in research of lifelike human clothing. Website: https://ait.ethz.ch/4d-dress.","sentences":["The studies of human clothing for digital avatars have predominantly relied on synthetic datasets.","While easy to collect, synthetic data often fall short in realism and fail to capture authentic clothing dynamics.","Addressing this gap, we introduce 4D-DRESS, the first real-world 4D dataset advancing human clothing research with its high-quality 4D textured scans and garment meshes.","4D-DRESS captures 64 outfits in 520 human motion sequences, amounting to 78k textured scans.","Creating a real-world clothing dataset is challenging, particularly in annotating and segmenting the extensive and complex 4D human scans.","To address this, we develop a semi-automatic 4D human parsing pipeline.","We efficiently combine a human-in-the-loop process with automation to accurately label 4D scans in diverse garments and body movements.","Leveraging precise annotations and high-quality garment meshes, we establish several benchmarks for clothing simulation and reconstruction.","4D-DRESS offers realistic and challenging data that complements synthetic sources, paving the way for advancements in research of lifelike human clothing.","Website: https://ait.ethz.ch/4d-dress."],"url":"http://arxiv.org/abs/2404.18630v1"}
{"created":"2024-04-29 12:02:06","title":"Self-Avatar Animation in Virtual Reality: Impact of Motion Signals Artifacts on the Full-Body Pose Reconstruction","abstract":"Virtual Reality (VR) applications have revolutionized user experiences by immersing individuals in interactive 3D environments. These environments find applications in numerous fields, including healthcare, education, or architecture. A significant aspect of VR is the inclusion of self-avatars, representing users within the virtual world, which enhances interaction and embodiment. However, generating lifelike full-body self-avatar animations remains challenging, particularly in consumer-grade VR systems, where lower-body tracking is often absent. One method to tackle this problem is by providing an external source of motion information that includes lower body information such as full Cartesian positions estimated from RGB(D) cameras. Nevertheless, the limitations of these systems are multiples: the desynchronization between the two motion sources and occlusions are examples of significant issues that hinder the implementations of such systems. In this paper, we aim to measure the impact on the reconstruction of the articulated self-avatar's full-body pose of (1) the latency between the VR motion features and estimated positions, (2) the data acquisition rate, (3) occlusions, and (4) the inaccuracy of the position estimation algorithm. In addition, we analyze the motion reconstruction errors using ground truth and 3D Cartesian coordinates estimated from \\textit{YOLOv8} pose estimation. These analyzes show that the studied methods are significantly sensitive to any degradation tested, especially regarding the velocity reconstruction error.","sentences":["Virtual Reality (VR) applications have revolutionized user experiences by immersing individuals in interactive 3D environments.","These environments find applications in numerous fields, including healthcare, education, or architecture.","A significant aspect of VR is the inclusion of self-avatars, representing users within the virtual world, which enhances interaction and embodiment.","However, generating lifelike full-body self-avatar animations remains challenging, particularly in consumer-grade VR systems, where lower-body tracking is often absent.","One method to tackle this problem is by providing an external source of motion information that includes lower body information such as full Cartesian positions estimated from RGB(D) cameras.","Nevertheless, the limitations of these systems are multiples: the desynchronization between the two motion sources and occlusions are examples of significant issues that hinder the implementations of such systems.","In this paper, we aim to measure the impact on the reconstruction of the articulated self-avatar's full-body pose of (1) the latency between the VR motion features and estimated positions, (2) the data acquisition rate, (3) occlusions, and (4) the inaccuracy of the position estimation algorithm.","In addition, we analyze the motion reconstruction errors using ground truth and 3D Cartesian coordinates estimated from \\textit{YOLOv8} pose estimation.","These analyzes show that the studied methods are significantly sensitive to any degradation tested, especially regarding the velocity reconstruction error."],"url":"http://arxiv.org/abs/2404.18628v1"}
{"created":"2024-04-29 11:40:27","title":"CoSense3D: an Agent-based Efficient Learning Framework for Collective Perception","abstract":"Collective Perception has attracted significant attention in recent years due to its advantage for mitigating occlusion and expanding the field-of-view, thereby enhancing reliability, efficiency, and, most crucially, decision-making safety. However, developing collective perception models is highly resource demanding due to extensive requirements of processing input data for many agents, usually dozens of images and point clouds for a single frame. This not only slows down the model development process for collective perception but also impedes the utilization of larger models. In this paper, we propose an agent-based training framework that handles the deep learning modules and agent data separately to have a cleaner data flow structure. This framework not only provides an API for flexibly prototyping the data processing pipeline and defining the gradient calculation for each agent, but also provides the user interface for interactive training, testing and data visualization. Training experiment results of four collective object detection models on the prominent collective perception benchmark OPV2V show that the agent-based training can significantly reduce the GPU memory consumption and training time while retaining inference performance. The framework and model implementations are available at \\url{https://github.com/YuanYunshuang/CoSense3D}","sentences":["Collective Perception has attracted significant attention in recent years due to its advantage for mitigating occlusion and expanding the field-of-view, thereby enhancing reliability, efficiency, and, most crucially, decision-making safety.","However, developing collective perception models is highly resource demanding due to extensive requirements of processing input data for many agents, usually dozens of images and point clouds for a single frame.","This not only slows down the model development process for collective perception but also impedes the utilization of larger models.","In this paper, we propose an agent-based training framework that handles the deep learning modules and agent data separately to have a cleaner data flow structure.","This framework not only provides an API for flexibly prototyping the data processing pipeline and defining the gradient calculation for each agent, but also provides the user interface for interactive training, testing and data visualization.","Training experiment results of four collective object detection models on the prominent collective perception benchmark OPV2V show that the agent-based training can significantly reduce the GPU memory consumption and training time while retaining inference performance.","The framework and model implementations are available at \\url{https://github.com/YuanYunshuang/CoSense3D}"],"url":"http://arxiv.org/abs/2404.18617v1"}
{"created":"2024-04-29 11:30:50","title":"Enhancing Prosthetic Safety and Environmental Adaptability: A Visual-Inertial Prosthesis Motion Estimation Approach on Uneven Terrains","abstract":"Environment awareness is crucial for enhancing walking safety and stability of amputee wearing powered prosthesis when crossing uneven terrains such as stairs and obstacles. However, existing environmental perception systems for prosthesis only provide terrain types and corresponding parameters, which fails to prevent potential collisions when crossing uneven terrains and may lead to falls and other severe consequences. In this paper, a visual-inertial motion estimation approach is proposed for prosthesis to perceive its movement and the changes of spatial relationship between the prosthesis and uneven terrain when traversing them. To achieve this, we estimate the knee motion by utilizing a depth camera to perceive the environment and align feature points extracted from stairs and obstacles. Subsequently, an error-state Kalman filter is incorporated to fuse the inertial data into visual estimations to reduce the feature extraction error and obtain a more robust estimation. The motion of prosthetic joint and toe are derived using the prosthesis model parameters. Experiment conducted on our collected dataset and stair walking trials with a powered prosthesis shows that the proposed method can accurately tracking the motion of the human leg and prosthesis with an average root-mean-square error of toe trajectory less than 5 cm. The proposed method is expected to enable the environmental adaptive control for prosthesis, thereby enhancing amputee's safety and mobility in uneven terrains.","sentences":["Environment awareness is crucial for enhancing walking safety and stability of amputee wearing powered prosthesis when crossing uneven terrains such as stairs and obstacles.","However, existing environmental perception systems for prosthesis only provide terrain types and corresponding parameters, which fails to prevent potential collisions when crossing uneven terrains and may lead to falls and other severe consequences.","In this paper, a visual-inertial motion estimation approach is proposed for prosthesis to perceive its movement and the changes of spatial relationship between the prosthesis and uneven terrain when traversing them.","To achieve this, we estimate the knee motion by utilizing a depth camera to perceive the environment and align feature points extracted from stairs and obstacles.","Subsequently, an error-state Kalman filter is incorporated to fuse the inertial data into visual estimations to reduce the feature extraction error and obtain a more robust estimation.","The motion of prosthetic joint and toe are derived using the prosthesis model parameters.","Experiment conducted on our collected dataset and stair walking trials with a powered prosthesis shows that the proposed method can accurately tracking the motion of the human leg and prosthesis with an average root-mean-square error of toe trajectory less than 5 cm.","The proposed method is expected to enable the environmental adaptive control for prosthesis, thereby enhancing amputee's safety and mobility in uneven terrains."],"url":"http://arxiv.org/abs/2404.18612v1"}
{"created":"2024-04-29 11:19:15","title":"CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation","abstract":"Speech-driven 3D facial animation technology has been developed for years, but its practical application still lacks expectations. The main challenges lie in data limitations, lip alignment, and the naturalness of facial expressions. Although lip alignment has seen many related studies, existing methods struggle to synthesize natural and realistic expressions, resulting in a mechanical and stiff appearance of facial animations. Even with some research extracting emotional features from speech, the randomness of facial movements limits the effective expression of emotions. To address this issue, this paper proposes a method called CSTalk (Correlation Supervised) that models the correlations among different regions of facial movements and supervises the training of the generative model to generate realistic expressions that conform to human facial motion patterns. To generate more intricate animations, we employ a rich set of control parameters based on the metahuman character model and capture a dataset for five different emotions. We train a generative network using an autoencoder structure and input an emotion embedding vector to achieve the generation of user-control expressions. Experimental results demonstrate that our method outperforms existing state-of-the-art methods.","sentences":["Speech-driven 3D facial animation technology has been developed for years, but its practical application still lacks expectations.","The main challenges lie in data limitations, lip alignment, and the naturalness of facial expressions.","Although lip alignment has seen many related studies, existing methods struggle to synthesize natural and realistic expressions, resulting in a mechanical and stiff appearance of facial animations.","Even with some research extracting emotional features from speech, the randomness of facial movements limits the effective expression of emotions.","To address this issue, this paper proposes a method called CSTalk (Correlation Supervised) that models the correlations among different regions of facial movements and supervises the training of the generative model to generate realistic expressions that conform to human facial motion patterns.","To generate more intricate animations, we employ a rich set of control parameters based on the metahuman character model and capture a dataset for five different emotions.","We train a generative network using an autoencoder structure and input an emotion embedding vector to achieve the generation of user-control expressions.","Experimental results demonstrate that our method outperforms existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2404.18604v1"}
{"created":"2024-04-29 10:55:08","title":"FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering","abstract":"Table Question Answering (TQA) aims at composing an answer to a question based on tabular data. While prior research has shown that TQA models lack robustness, understanding the underlying cause and nature of this issue remains predominantly unclear, posing a significant obstacle to the development of robust TQA systems. In this paper, we formalize three major desiderata for a fine-grained evaluation of robustness of TQA systems. They should (i) answer questions regardless of alterations in table structure, (ii) base their responses on the content of relevant cells rather than on biases, and (iii) demonstrate robust numerical reasoning capabilities. To investigate these aspects, we create and publish a novel TQA evaluation benchmark in English. Our extensive experimental analysis reveals that none of the examined state-of-the-art TQA systems consistently excels in these three aspects. Our benchmark is a crucial instrument for monitoring the behavior of TQA systems and paves the way for the development of robust TQA systems. We release our benchmark publicly.","sentences":["Table Question Answering (TQA) aims at composing an answer to a question based on tabular data.","While prior research has shown that TQA models lack robustness, understanding the underlying cause and nature of this issue remains predominantly unclear, posing a significant obstacle to the development of robust TQA systems.","In this paper, we formalize three major desiderata for a fine-grained evaluation of robustness of TQA systems.","They should (i) answer questions regardless of alterations in table structure, (ii) base their responses on the content of relevant cells rather than on biases, and (iii) demonstrate robust numerical reasoning capabilities.","To investigate these aspects, we create and publish a novel TQA evaluation benchmark in English.","Our extensive experimental analysis reveals that none of the examined state-of-the-art TQA systems consistently excels in these three aspects.","Our benchmark is a crucial instrument for monitoring the behavior of TQA systems and paves the way for the development of robust TQA systems.","We release our benchmark publicly."],"url":"http://arxiv.org/abs/2404.18585v1"}
{"created":"2024-04-29 10:47:37","title":"Context Matters: Leveraging Spatiotemporal Metadata for Semi-Supervised Learning on Remote Sensing Images","abstract":"Remote sensing projects typically generate large amounts of imagery that can be used to train powerful deep neural networks. However, the amount of labeled images is often small, as remote sensing applications generally require expert labelers. Thus, semi-supervised learning (SSL), i.e., learning with a small pool of labeled and a larger pool of unlabeled data, is particularly useful in this domain. Current SSL approaches generate pseudo-labels from model predictions for unlabeled samples. As the quality of these pseudo-labels is crucial for performance, utilizing additional information to improve pseudo-label quality yields a promising direction. For remote sensing images, geolocation and recording time are generally available and provide a valuable source of information as semantic concepts, such as land cover, are highly dependent on spatiotemporal context, e.g., due to seasonal effects and vegetation zones. In this paper, we propose to exploit spatiotemporal metainformation in SSL to improve the quality of pseudo-labels and, therefore, the final model performance. We show that directly adding the available metadata to the input of the predictor at test time degenerates the prediction quality for metadata outside the spatiotemporal distribution of the training set. Thus, we propose a teacher-student SSL framework where only the teacher network uses metainformation to improve the quality of pseudo-labels on the training set. Correspondingly, our student network benefits from the improved pseudo-labels but does not receive metadata as input, making it invariant to spatiotemporal shifts at test time. Furthermore, we propose methods for encoding and injecting spatiotemporal information into the model and introduce a novel distillation mechanism to enhance the knowledge transfer between teacher and student. Our framework dubbed Spatiotemporal SSL can be easily combined with several stat...","sentences":["Remote sensing projects typically generate large amounts of imagery that can be used to train powerful deep neural networks.","However, the amount of labeled images is often small, as remote sensing applications generally require expert labelers.","Thus, semi-supervised learning (SSL), i.e., learning with a small pool of labeled and a larger pool of unlabeled data, is particularly useful in this domain.","Current SSL approaches generate pseudo-labels from model predictions for unlabeled samples.","As the quality of these pseudo-labels is crucial for performance, utilizing additional information to improve pseudo-label quality yields a promising direction.","For remote sensing images, geolocation and recording time are generally available and provide a valuable source of information as semantic concepts, such as land cover, are highly dependent on spatiotemporal context, e.g., due to seasonal effects and vegetation zones.","In this paper, we propose to exploit spatiotemporal metainformation in SSL to improve the quality of pseudo-labels and, therefore, the final model performance.","We show that directly adding the available metadata to the input of the predictor at test time degenerates the prediction quality for metadata outside the spatiotemporal distribution of the training set.","Thus, we propose a teacher-student SSL framework where only the teacher network uses metainformation to improve the quality of pseudo-labels on the training set.","Correspondingly, our student network benefits from the improved pseudo-labels but does not receive metadata as input, making it invariant to spatiotemporal shifts at test time.","Furthermore, we propose methods for encoding and injecting spatiotemporal information into the model and introduce a novel distillation mechanism to enhance the knowledge transfer between teacher and student.","Our framework dubbed Spatiotemporal SSL can be easily combined with several stat..."],"url":"http://arxiv.org/abs/2404.18583v1"}
{"created":"2024-04-29 10:41:30","title":"Data-Driven Dynamics Modeling of Miniature Robotic Blimps Using Neural ODEs With Parameter Auto-Tuning","abstract":"Miniature robotic blimps, as one type of lighter-than-air aerial vehicles, have attracted increasing attention in the science and engineering community for their enhanced safety, extended endurance, and quieter operation compared to quadrotors. Accurately modeling the dynamics of these robotic blimps poses a significant challenge due to the complex aerodynamics stemming from their large lifting bodies. Traditional first-principle models have difficulty obtaining accurate aerodynamic parameters and often overlook high-order nonlinearities, thus coming to its limit in modeling the motion dynamics of miniature robotic blimps. To tackle this challenge, this letter proposes the Auto-tuning Blimp-oriented Neural Ordinary Differential Equation method (ABNODE), a data-driven approach that integrates first-principle and neural network modeling. Spiraling motion experiments of robotic blimps are conducted, comparing the ABNODE with first-principle and other data-driven benchmark models, the results of which demonstrate the effectiveness of the proposed method.","sentences":["Miniature robotic blimps, as one type of lighter-than-air aerial vehicles, have attracted increasing attention in the science and engineering community for their enhanced safety, extended endurance, and quieter operation compared to quadrotors.","Accurately modeling the dynamics of these robotic blimps poses a significant challenge due to the complex aerodynamics stemming from their large lifting bodies.","Traditional first-principle models have difficulty obtaining accurate aerodynamic parameters and often overlook high-order nonlinearities, thus coming to its limit in modeling the motion dynamics of miniature robotic blimps.","To tackle this challenge, this letter proposes the Auto-tuning Blimp-oriented Neural Ordinary Differential Equation method (ABNODE), a data-driven approach that integrates first-principle and neural network modeling.","Spiraling motion experiments of robotic blimps are conducted, comparing the ABNODE with first-principle and other data-driven benchmark models, the results of which demonstrate the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2404.18580v1"}
{"created":"2024-04-29 10:37:38","title":"Assessing Quality Metrics for Neural Reality Gap Input Mitigation in Autonomous Driving Testing","abstract":"Simulation-based testing of automated driving systems (ADS) is the industry standard, being a controlled, safe, and cost-effective alternative to real-world testing. Despite these advantages, virtual simulations often fail to accurately replicate real-world conditions like image fidelity, texture representation, and environmental accuracy. This can lead to significant differences in ADS behavior between simulated and real-world domains, a phenomenon known as the sim2real gap. Researchers have used Image-to-Image (I2I) neural translation to mitigate the sim2real gap, enhancing the realism of simulated environments by transforming synthetic data into more authentic representations of real-world conditions. However, while promising, these techniques may potentially introduce artifacts, distortions, or inconsistencies in the generated data that can affect the effectiveness of ADS testing. In our empirical study, we investigated how the quality of image-to-image (I2I) techniques influences the mitigation of the sim2real gap, using a set of established metrics from the literature. We evaluated two popular generative I2I architectures, pix2pix, and CycleGAN, across two ADS perception tasks at a model level, namely vehicle detection and end-to-end lane keeping, using paired simulated and real-world datasets. Our findings reveal that the effectiveness of I2I architectures varies across different ADS tasks, and existing evaluation metrics do not consistently align with the ADS behavior. Thus, we conducted task-specific fine-tuning of perception metrics, which yielded a stronger correlation. Our findings indicate that a perception metric that incorporates semantic elements, tailored to each task, can facilitate selecting the most appropriate I2I technique for a reliable assessment of the sim2real gap mitigation.","sentences":["Simulation-based testing of automated driving systems (ADS) is the industry standard, being a controlled, safe, and cost-effective alternative to real-world testing.","Despite these advantages, virtual simulations often fail to accurately replicate real-world conditions like image fidelity, texture representation, and environmental accuracy.","This can lead to significant differences in ADS behavior between simulated and real-world domains, a phenomenon known as the sim2real gap.","Researchers have used Image-to-Image (I2I) neural translation to mitigate the sim2real gap, enhancing the realism of simulated environments by transforming synthetic data into more authentic representations of real-world conditions.","However, while promising, these techniques may potentially introduce artifacts, distortions, or inconsistencies in the generated data that can affect the effectiveness of ADS testing.","In our empirical study, we investigated how the quality of image-to-image (I2I) techniques influences the mitigation of the sim2real gap, using a set of established metrics from the literature.","We evaluated two popular generative I2I architectures, pix2pix, and CycleGAN, across two ADS perception tasks at a model level, namely vehicle detection and end-to-end lane keeping, using paired simulated and real-world datasets.","Our findings reveal that the effectiveness of I2I architectures varies across different ADS tasks, and existing evaluation metrics do not consistently align with the ADS behavior.","Thus, we conducted task-specific fine-tuning of perception metrics, which yielded a stronger correlation.","Our findings indicate that a perception metric that incorporates semantic elements, tailored to each task, can facilitate selecting the most appropriate I2I technique for a reliable assessment of the sim2real gap mitigation."],"url":"http://arxiv.org/abs/2404.18577v1"}
{"created":"2024-04-29 10:31:57","title":"GEEvo: Game Economy Generation and Balancing with Evolutionary Algorithms","abstract":"Game economy design significantly shapes the player experience and progression speed. Modern game economies are becoming increasingly complex and can be very sensitive to even minor numerical adjustments, which may have an unexpected impact on the overall gaming experience. Consequently, thorough manual testing and fine-tuning during development are essential. Unlike existing works that address algorithmic balancing for specific games or genres, this work adopts a more abstract approach, focusing on game balancing through its economy, detached from a specific game. We propose GEEvo (Game Economy Evolution), a framework to generate graph-based game economies and balancing both, newly generated or existing economies. GEEvo uses a two-step approach where evolutionary algorithms are used to first generate an economy and then balance it based on specified objectives, such as generated resources or damage dealt over time. We define different objectives by differently parameterizing the fitness function using data from multiple simulation runs of the economy. To support this, we define a lightweight and flexible game economy simulation framework. Our method is tested and benchmarked with various balancing objectives on a generated dataset, and we conduct a case study evaluating damage balancing for two fictional economies of two popular game character classes.","sentences":["Game economy design significantly shapes the player experience and progression speed.","Modern game economies are becoming increasingly complex and can be very sensitive to even minor numerical adjustments, which may have an unexpected impact on the overall gaming experience.","Consequently, thorough manual testing and fine-tuning during development are essential.","Unlike existing works that address algorithmic balancing for specific games or genres, this work adopts a more abstract approach, focusing on game balancing through its economy, detached from a specific game.","We propose GEEvo (Game Economy Evolution), a framework to generate graph-based game economies and balancing both, newly generated or existing economies.","GEEvo uses a two-step approach where evolutionary algorithms are used to first generate an economy and then balance it based on specified objectives, such as generated resources or damage dealt over time.","We define different objectives by differently parameterizing the fitness function using data from multiple simulation runs of the economy.","To support this, we define a lightweight and flexible game economy simulation framework.","Our method is tested and benchmarked with various balancing objectives on a generated dataset, and we conduct a case study evaluating damage balancing for two fictional economies of two popular game character classes."],"url":"http://arxiv.org/abs/2404.18574v1"}
{"created":"2024-04-29 10:28:14","title":"Learning Governing Equations of Unobserved States in Dynamical Systems","abstract":"Data driven modelling and scientific machine learning have been responsible for significant advances in determining suitable models to describe data. Within dynamical systems, neural ordinary differential equations (ODEs), where the system equations are set to be governed by a neural network, have become a popular tool for this challenge in recent years. However, less emphasis has been placed on systems that are only partially-observed. In this work, we employ a hybrid neural ODE structure, where the system equations are governed by a combination of a neural network and domain-specific knowledge, together with symbolic regression (SR), to learn governing equations of partially-observed dynamical systems. We test this approach on two case studies: A 3-dimensional model of the Lotka-Volterra system and a 5-dimensional model of the Lorenz system. We demonstrate that the method is capable of successfully learning the true underlying governing equations of unobserved states within these systems, with robustness to measurement noise.","sentences":["Data driven modelling and scientific machine learning have been responsible for significant advances in determining suitable models to describe data.","Within dynamical systems, neural ordinary differential equations (ODEs), where the system equations are set to be governed by a neural network, have become a popular tool for this challenge in recent years.","However, less emphasis has been placed on systems that are only partially-observed.","In this work, we employ a hybrid neural ODE structure, where the system equations are governed by a combination of a neural network and domain-specific knowledge, together with symbolic regression (SR), to learn governing equations of partially-observed dynamical systems.","We test this approach on two case studies: A 3-dimensional model of the Lotka-Volterra system and a 5-dimensional model of the Lorenz system.","We demonstrate that the method is capable of successfully learning the true underlying governing equations of unobserved states within these systems, with robustness to measurement noise."],"url":"http://arxiv.org/abs/2404.18572v1"}
{"created":"2024-04-29 10:12:04","title":"Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning","abstract":"Recent research in dialogue systems and corpora has focused on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems help users accomplish specific tasks, while open-domain systems aim to create engaging conversations. However, in real-world scenarios, user intents are often revealed during interactions. A recent study introduced SalesBot, which simulates dialogues transitioning from chit-chat to task-oriented scenarios to train sales agents. Unfortunately, the initial data lacked smooth transitions and coherent long-turn dialogues, resulting in poor naturalness in sales-customer interactions. To address these issues, this paper presents SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from large language models (LLMs) through strategic prompting. Additionally, we introduce a novel model called SalesAgent, trained on salesperson's interactions, using chain-of-thought (CoT) reasoning. This model excels in transitioning topics, understanding user intents, and selecting appropriate strategies. Experiments using diverse user simulations validate the effectiveness of our method in controlling dialogue strategies in LLMs. Furthermore, SalesBot 2.0 enhances coherence and reduces aggression, facilitating better model learning for sales-customer interactions.","sentences":["Recent research in dialogue systems and corpora has focused on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues.","TOD systems help users accomplish specific tasks, while open-domain systems aim to create engaging conversations.","However, in real-world scenarios, user intents are often revealed during interactions.","A recent study introduced SalesBot, which simulates dialogues transitioning from chit-chat to task-oriented scenarios to train sales agents.","Unfortunately, the initial data lacked smooth transitions and coherent long-turn dialogues, resulting in poor naturalness in sales-customer interactions.","To address these issues, this paper presents SalesBot 2.0, an improved dataset.","It leverages commonsense knowledge from large language models (LLMs) through strategic prompting.","Additionally, we introduce a novel model called SalesAgent, trained on salesperson's interactions, using chain-of-thought (CoT) reasoning.","This model excels in transitioning topics, understanding user intents, and selecting appropriate strategies.","Experiments using diverse user simulations validate the effectiveness of our method in controlling dialogue strategies in LLMs.","Furthermore, SalesBot 2.0 enhances coherence and reduces aggression, facilitating better model learning for sales-customer interactions."],"url":"http://arxiv.org/abs/2404.18564v1"}
{"created":"2024-04-29 10:02:45","title":"LangBiTe: A Platform for Testing Bias in Large Language Models","abstract":"The integration of Large Language Models (LLMs) into various software applications raises concerns about their potential biases. Typically, those models are trained on a vast amount of data scrapped from forums, websites, social media and other internet sources, which may instill harmful and discriminating behavior into the model. To address this issue, we present LangBiTe, a testing platform to systematically assess the presence of biases within an LLM. LangBiTe enables development teams to tailor their test scenarios, and automatically generate and execute the test cases according to a set of user-defined ethical requirements. Each test consists of a prompt fed into the LLM and a corresponding test oracle that scrutinizes the LLM's response for the identification of biases. LangBite provides users with the bias evaluation of LLMs, and end-to-end traceability between the initial ethical requirements and the insights obtained.","sentences":["The integration of Large Language Models (LLMs) into various software applications raises concerns about their potential biases.","Typically, those models are trained on a vast amount of data scrapped from forums, websites, social media and other internet sources, which may instill harmful and discriminating behavior into the model.","To address this issue, we present LangBiTe, a testing platform to systematically assess the presence of biases within an LLM.","LangBiTe enables development teams to tailor their test scenarios, and automatically generate and execute the test cases according to a set of user-defined ethical requirements.","Each test consists of a prompt fed into the LLM and a corresponding test oracle that scrutinizes the LLM's response for the identification of biases.","LangBite provides users with the bias evaluation of LLMs, and end-to-end traceability between the initial ethical requirements and the insights obtained."],"url":"http://arxiv.org/abs/2404.18558v1"}
{"created":"2024-04-29 09:34:25","title":"Time Machine GPT","abstract":"Large language models (LLMs) are often trained on extensive, temporally indiscriminate text corpora, reflecting the lack of datasets with temporal metadata. This approach is not aligned with the evolving nature of language. Conventional methods for creating temporally adapted language models often depend on further pre-training static models on time-specific data. This paper presents a new approach: a series of point-in-time LLMs called Time Machine GPT (TiMaGPT), specifically designed to be nonprognosticative. This ensures they remain uninformed about future factual information and linguistic changes. This strategy is beneficial for understanding language evolution and is of critical importance when applying models in dynamic contexts, such as time-series forecasting, where foresight of future information can prove problematic. We provide access to both the models and training datasets.","sentences":["Large language models (LLMs) are often trained on extensive, temporally indiscriminate text corpora, reflecting the lack of datasets with temporal metadata.","This approach is not aligned with the evolving nature of language.","Conventional methods for creating temporally adapted language models often depend on further pre-training static models on time-specific data.","This paper presents a new approach: a series of point-in-time LLMs called Time Machine GPT (TiMaGPT), specifically designed to be nonprognosticative.","This ensures they remain uninformed about future factual information and linguistic changes.","This strategy is beneficial for understanding language evolution and is of critical importance when applying models in dynamic contexts, such as time-series forecasting, where foresight of future information can prove problematic.","We provide access to both the models and training datasets."],"url":"http://arxiv.org/abs/2404.18543v1"}
{"created":"2024-04-29 09:27:17","title":"Symmetry group based domain decomposition to enhance physics-informed neural networks for solving partial differential equations","abstract":"Domain decomposition provides an effective way to tackle the dilemma of physics-informed neural networks (PINN) which struggle to accurately and efficiently solve partial differential equations (PDEs) in the whole domain, but the lack of efficient tools for dealing with the interfaces between two adjacent sub-domains heavily hinders the training effects, even leads to the discontinuity of the learned solutions. In this paper, we propose a symmetry group based domain decomposition strategy to enhance the PINN for solving the forward and inverse problems of the PDEs possessing a Lie symmetry group. Specifically, for the forward problem, we first deploy the symmetry group to generate the dividing-lines having known solution information which can be adjusted flexibly and are used to divide the whole training domain into a finite number of non-overlapping sub-domains, then utilize the PINN and the symmetry-enhanced PINN methods to learn the solutions in each sub-domain and finally stitch them to the overall solution of PDEs. For the inverse problem, we first utilize the symmetry group acting on the data of the initial and boundary conditions to generate labeled data in the interior domain of PDEs and then find the undetermined parameters as well as the solution by only training the neural networks in a sub-domain. Consequently, the proposed method can predict high-accuracy solutions of PDEs which are failed by the vanilla PINN in the whole domain and the extended physics-informed neural network in the same sub-domains. Numerical results of the Korteweg-de Vries equation with a translation symmetry and the nonlinear viscous fluid equation with a scaling symmetry show that the accuracies of the learned solutions are improved largely.","sentences":["Domain decomposition provides an effective way to tackle the dilemma of physics-informed neural networks (PINN) which struggle to accurately and efficiently solve partial differential equations (PDEs) in the whole domain, but the lack of efficient tools for dealing with the interfaces between two adjacent sub-domains heavily hinders the training effects, even leads to the discontinuity of the learned solutions.","In this paper, we propose a symmetry group based domain decomposition strategy to enhance the PINN for solving the forward and inverse problems of the PDEs possessing a Lie symmetry group.","Specifically, for the forward problem, we first deploy the symmetry group to generate the dividing-lines having known solution information which can be adjusted flexibly and are used to divide the whole training domain into a finite number of non-overlapping sub-domains, then utilize the PINN and the symmetry-enhanced PINN methods to learn the solutions in each sub-domain and finally stitch them to the overall solution of PDEs.","For the inverse problem, we first utilize the symmetry group acting on the data of the initial and boundary conditions to generate labeled data in the interior domain of PDEs and then find the undetermined parameters as well as the solution by only training the neural networks in a sub-domain.","Consequently, the proposed method can predict high-accuracy solutions of PDEs which are failed by the vanilla PINN in the whole domain and the extended physics-informed neural network in the same sub-domains.","Numerical results of the Korteweg-de Vries equation with a translation symmetry and the nonlinear viscous fluid equation with a scaling symmetry show that the accuracies of the learned solutions are improved largely."],"url":"http://arxiv.org/abs/2404.18538v1"}
{"created":"2024-04-29 09:27:15","title":"Time Series Data Augmentation as an Imbalanced Learning Problem","abstract":"Recent state-of-the-art forecasting methods are trained on collections of time series. These methods, often referred to as global models, can capture common patterns in different time series to improve their generalization performance. However, they require large amounts of data that might not be readily available. Besides this, global models sometimes fail to capture relevant patterns unique to a particular time series. In these cases, data augmentation can be useful to increase the sample size of time series datasets. The main contribution of this work is a novel method for generating univariate time series synthetic samples. Our approach stems from the insight that the observations concerning a particular time series of interest represent only a small fraction of all observations. In this context, we frame the problem of training a forecasting model as an imbalanced learning task. Oversampling strategies are popular approaches used to deal with the imbalance problem in machine learning. We use these techniques to create synthetic time series observations and improve the accuracy of forecasting models. We carried out experiments using 7 different databases that contain a total of 5502 univariate time series. We found that the proposed solution outperforms both a global and a local model, thus providing a better trade-off between these two approaches.","sentences":["Recent state-of-the-art forecasting methods are trained on collections of time series.","These methods, often referred to as global models, can capture common patterns in different time series to improve their generalization performance.","However, they require large amounts of data that might not be readily available.","Besides this, global models sometimes fail to capture relevant patterns unique to a particular time series.","In these cases, data augmentation can be useful to increase the sample size of time series datasets.","The main contribution of this work is a novel method for generating univariate time series synthetic samples.","Our approach stems from the insight that the observations concerning a particular time series of interest represent only a small fraction of all observations.","In this context, we frame the problem of training a forecasting model as an imbalanced learning task.","Oversampling strategies are popular approaches used to deal with the imbalance problem in machine learning.","We use these techniques to create synthetic time series observations and improve the accuracy of forecasting models.","We carried out experiments using 7 different databases that contain a total of 5502 univariate time series.","We found that the proposed solution outperforms both a global and a local model, thus providing a better trade-off between these two approaches."],"url":"http://arxiv.org/abs/2404.18537v1"}
{"created":"2024-04-29 09:22:54","title":"Evaluating and Mitigating Linguistic Discrimination in Large Language Models","abstract":"By training on text in various languages, large language models (LLMs) typically possess multilingual support and demonstrate remarkable capabilities in solving tasks described in different languages. However, LLMs can exhibit linguistic discrimination due to the uneven distribution of training data across languages. That is, LLMs are hard to keep the consistency of responses when faced with the same task but depicted in different languages.   In this study, we first explore the consistency in the LLMs' outputs responding to queries in various languages from two aspects: safety and quality. We conduct this analysis with two datasets (AdvBench and NQ) based on four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results show that LLMs exhibit stronger human alignment capabilities with queries in English, French, Russian, and Spanish (only 1.04\\% of harmful queries successfully jailbreak on average) compared to queries in Bengali, Georgian, Nepali and Maithili (27.7\\% of harmful queries jailbreak successfully on average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs tend to produce responses with a higher quality (with 0.1494 $F_1$ score on average) compared to the other languages. Upon these findings, we propose LDFighter, a similarity-based voting, to mitigate the linguistic discrimination in LLMs. LDFighter ensures consistent service for different language speakers. We evaluate LDFighter with both benign queries and harmful queries. The results show that LDFighter not only significantly reduces the jailbreak success rate but also improve the response quality on average, demonstrating its effectiveness.","sentences":["By training on text in various languages, large language models (LLMs) typically possess multilingual support and demonstrate remarkable capabilities in solving tasks described in different languages.","However, LLMs can exhibit linguistic discrimination due to the uneven distribution of training data across languages.","That is, LLMs are hard to keep the consistency of responses when faced with the same task but depicted in different languages.   ","In this study, we first explore the consistency in the LLMs' outputs responding to queries in various languages from two aspects: safety and quality.","We conduct this analysis with two datasets (AdvBench and NQ) based on four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro).","The results show that LLMs exhibit stronger human alignment capabilities with queries in English, French, Russian, and Spanish (only 1.04\\% of harmful queries successfully jailbreak on average) compared to queries in Bengali, Georgian, Nepali and Maithili (27.7\\% of harmful queries jailbreak successfully on average).","Moreover, for queries in English, Danish, Czech and Slovenian, LLMs tend to produce responses with a higher quality (with 0.1494 $F_1$ score on average) compared to the other languages.","Upon these findings, we propose LDFighter, a similarity-based voting, to mitigate the linguistic discrimination in LLMs.","LDFighter ensures consistent service for different language speakers.","We evaluate LDFighter with both benign queries and harmful queries.","The results show that LDFighter not only significantly reduces the jailbreak success rate but also improve the response quality on average, demonstrating its effectiveness."],"url":"http://arxiv.org/abs/2404.18534v1"}
{"created":"2024-04-29 09:14:42","title":"Predicting PDEs Fast and Efficiently with Equivariant Extreme Learning Machines","abstract":"We utilize extreme learning machines for the prediction of partial differential equations (PDEs). Our method splits the state space into multiple windows that are predicted individually using a single model. Despite requiring only few data points (in some cases, our method can learn from a single full-state snapshot), it still achieves high accuracy and can predict the flow of PDEs over long time horizons. Moreover, we show how additional symmetries can be exploited to increase sample efficiency and to enforce equivariance.","sentences":["We utilize extreme learning machines for the prediction of partial differential equations (PDEs).","Our method splits the state space into multiple windows that are predicted individually using a single model.","Despite requiring only few data points (in some cases, our method can learn from a single full-state snapshot), it still achieves high accuracy and can predict the flow of PDEs over long time horizons.","Moreover, we show how additional symmetries can be exploited to increase sample efficiency and to enforce equivariance."],"url":"http://arxiv.org/abs/2404.18530v1"}
{"created":"2024-04-29 09:12:53","title":"Generation of Uncorrelated Residual Variables for Chemical Process Fault Diagnosis via Transfer Learning-based Input-Output Decoupled Network","abstract":"Structural decoupling has played an essential role in model-based fault isolation and estimation in past decades, which facilitates accurate fault localization and reconstruction thanks to the diagonal transfer matrix design. However, traditional methods exhibit limited effectiveness in modeling high-dimensional nonlinearity and big data, and the decoupling idea has not been well-valued in data-driven frameworks. Known for big data and complex feature extraction capabilities, deep learning has recently been used to develop residual generation models. Nevertheless, it lacks decoupling-related diagnostic designs. To this end, this paper proposes a transfer learning-based input-output decoupled network (TDN) for diagnostic purposes, which consists of an input-output decoupled network (IDN) and a pre-trained variational autocoder (VAE). In IDN, uncorrelated residual variables are generated by diagonalization and parallel computing operations. During the transfer learning phase, knowledge of normal status is provided according to VAE's loss and maximum mean discrepancy loss to guide the training of IDN. After training, IDN learns the mapping from faulty to normal, thereby serving as the fault detection index and the estimated fault signal simultaneously. At last, the effectiveness of the developed TDN is verified by a numerical example and a chemical simulation.","sentences":["Structural decoupling has played an essential role in model-based fault isolation and estimation in past decades, which facilitates accurate fault localization and reconstruction thanks to the diagonal transfer matrix design.","However, traditional methods exhibit limited effectiveness in modeling high-dimensional nonlinearity and big data, and the decoupling idea has not been well-valued in data-driven frameworks.","Known for big data and complex feature extraction capabilities, deep learning has recently been used to develop residual generation models.","Nevertheless, it lacks decoupling-related diagnostic designs.","To this end, this paper proposes a transfer learning-based input-output decoupled network (TDN) for diagnostic purposes, which consists of an input-output decoupled network (IDN) and a pre-trained variational autocoder (VAE).","In IDN, uncorrelated residual variables are generated by diagonalization and parallel computing operations.","During the transfer learning phase, knowledge of normal status is provided according to VAE's loss and maximum mean discrepancy loss to guide the training of IDN.","After training, IDN learns the mapping from faulty to normal, thereby serving as the fault detection index and the estimated fault signal simultaneously.","At last, the effectiveness of the developed TDN is verified by a numerical example and a chemical simulation."],"url":"http://arxiv.org/abs/2404.18528v1"}
{"created":"2024-04-29 09:12:31","title":"Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning","abstract":"Machine learning algorithms emerge as a promising approach in energy fields, but its practical is hindered by data barriers, stemming from high collection costs and privacy concerns. This study introduces a novel federated learning (FL) framework based on XGBoost models, enabling safe collaborative modeling with accessible yet concealed data from multiple parties. Hyperparameter tuning of the models is achieved through Bayesian Optimization. To ascertain the merits of the proposed FL-XGBoost method, a comparative analysis is conducted between separate and centralized models to address a classical binary classification problem in geoenergy sector. The results reveal that the proposed FL framework strikes an optimal balance between privacy and accuracy. FL models demonstrate superior accuracy and generalization capabilities compared to separate models, particularly for participants with limited data or low correlation features and offers significant privacy benefits compared to centralized model. The aggregated optimization approach within the FL agreement proves effective in tuning hyperparameters. This study opens new avenues for assessing unconventional reservoirs through collaborative and privacy-preserving FL techniques.","sentences":["Machine learning algorithms emerge as a promising approach in energy fields, but its practical is hindered by data barriers, stemming from high collection costs and privacy concerns.","This study introduces a novel federated learning (FL) framework based on XGBoost models, enabling safe collaborative modeling with accessible yet concealed data from multiple parties.","Hyperparameter tuning of the models is achieved through Bayesian Optimization.","To ascertain the merits of the proposed FL-XGBoost method, a comparative analysis is conducted between separate and centralized models to address a classical binary classification problem in geoenergy sector.","The results reveal that the proposed FL framework strikes an optimal balance between privacy and accuracy.","FL models demonstrate superior accuracy and generalization capabilities compared to separate models, particularly for participants with limited data or low correlation features and offers significant privacy benefits compared to centralized model.","The aggregated optimization approach within the FL agreement proves effective in tuning hyperparameters.","This study opens new avenues for assessing unconventional reservoirs through collaborative and privacy-preserving FL techniques."],"url":"http://arxiv.org/abs/2404.18527v1"}
{"created":"2024-04-29 09:11:41","title":"Enabling Efficient and Flexible Interpretability of Data-driven Anomaly Detection in Industrial Processes with AcME-AD","abstract":"While Machine Learning has become crucial for Industry 4.0, its opaque nature hinders trust and impedes the transformation of valuable insights into actionable decision, a challenge exacerbated in the evolving Industry 5.0 with its human-centric focus. This paper addresses this need by testing the applicability of AcME-AD in industrial settings. This recently developed framework facilitates fast and user-friendly explanations for anomaly detection. AcME-AD is model-agnostic, offering flexibility, and prioritizes real-time efficiency. Thus, it seems suitable for seamless integration with industrial Decision Support Systems. We present the first industrial application of AcME-AD, showcasing its effectiveness through experiments. These tests demonstrate AcME-AD's potential as a valuable tool for explainable AD and feature-based root cause analysis within industrial environments, paving the way for trustworthy and actionable insights in the age of Industry 5.0.","sentences":["While Machine Learning has become crucial for Industry 4.0, its opaque nature hinders trust and impedes the transformation of valuable insights into actionable decision, a challenge exacerbated in the evolving Industry 5.0 with its human-centric focus.","This paper addresses this need by testing the applicability of AcME-AD in industrial settings.","This recently developed framework facilitates fast and user-friendly explanations for anomaly detection.","AcME-AD is model-agnostic, offering flexibility, and prioritizes real-time efficiency.","Thus, it seems suitable for seamless integration with industrial Decision Support Systems.","We present the first industrial application of AcME-AD, showcasing its effectiveness through experiments.","These tests demonstrate AcME-AD's potential as a valuable tool for explainable AD and feature-based root cause analysis within industrial environments, paving the way for trustworthy and actionable insights in the age of Industry 5.0."],"url":"http://arxiv.org/abs/2404.18525v1"}
{"created":"2024-04-29 09:09:11","title":"Did Fourier Really Meet M\u00f6bius? Fast Subset Convolution via FFT","abstract":"In their seminal work on subset convolution, Bj\\\"orklund, Husfeldt, Kaski and Koivisto introduced the now well-known $O(2^n n^2)$-time evaluation of the subset convolution in the sum-product ring. This sparked a wave of remarkable results for fundamental problems, such as the minimum Steiner tree and the chromatic number. However, in spite of its theoretical improvement, large intermediate outputs and floating-point precision errors due to alternating addition and subtraction in its set function transforms make the algorithm unusable in practice.   We provide a simple FFT-based algorithm that completely eliminates the need for set function transforms and maintains the running time of the original algorithm. This makes it possible to take advantage of nearly sixty years of research on efficient FFT implementations.","sentences":["In their seminal work on subset convolution, Bj\\\"orklund, Husfeldt, Kaski and Koivisto introduced the now well-known $O(2^n n^2)$-time evaluation of the subset convolution in the sum-product ring.","This sparked a wave of remarkable results for fundamental problems, such as the minimum Steiner tree and the chromatic number.","However, in spite of its theoretical improvement, large intermediate outputs and floating-point precision errors due to alternating addition and subtraction in its set function transforms make the algorithm unusable in practice.   ","We provide a simple FFT-based algorithm that completely eliminates the need for set function transforms and maintains the running time of the original algorithm.","This makes it possible to take advantage of nearly sixty years of research on efficient FFT implementations."],"url":"http://arxiv.org/abs/2404.18522v1"}
{"created":"2024-04-29 09:05:01","title":"On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks","abstract":"Federated Learning (FL) allows multiple privacy-sensitive applications to leverage their dataset for a global model construction without any disclosure of the information. One of those domains is healthcare, where groups of silos collaborate in order to generate a global predictor with improved accuracy and generalization. However, the inherent challenge lies in the high heterogeneity of medical data, necessitating sophisticated techniques for assessment and compensation. This paper presents a comprehensive exploration of the mathematical formalization and taxonomy of heterogeneity within FL environments, focusing on the intricacies of medical data. In particular, we address the evaluation and comparison of the most popular FL algorithms with respect to their ability to cope with quantity-based, feature and label distribution-based heterogeneity. The goal is to provide a quantitative evaluation of the impact of data heterogeneity in FL systems for healthcare networks as well as a guideline on FL algorithm selection. Our research extends beyond existing studies by benchmarking seven of the most common FL algorithms against the unique challenges posed by medical data use cases. The paper targets the prediction of the risk of stroke recurrence through a set of tabular clinical reports collected by different federated hospital silos: data heterogeneity frequently encountered in this scenario and its impact on FL performance are discussed.","sentences":["Federated Learning (FL) allows multiple privacy-sensitive applications to leverage their dataset for a global model construction without any disclosure of the information.","One of those domains is healthcare, where groups of silos collaborate in order to generate a global predictor with improved accuracy and generalization.","However, the inherent challenge lies in the high heterogeneity of medical data, necessitating sophisticated techniques for assessment and compensation.","This paper presents a comprehensive exploration of the mathematical formalization and taxonomy of heterogeneity within FL environments, focusing on the intricacies of medical data.","In particular, we address the evaluation and comparison of the most popular FL algorithms with respect to their ability to cope with quantity-based, feature and label distribution-based heterogeneity.","The goal is to provide a quantitative evaluation of the impact of data heterogeneity in FL systems for healthcare networks as well as a guideline on FL algorithm selection.","Our research extends beyond existing studies by benchmarking seven of the most common FL algorithms against the unique challenges posed by medical data use cases.","The paper targets the prediction of the risk of stroke recurrence through a set of tabular clinical reports collected by different federated hospital silos: data heterogeneity frequently encountered in this scenario and its impact on FL performance are discussed."],"url":"http://arxiv.org/abs/2404.18519v1"}
{"created":"2024-04-29 09:03:19","title":"From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?","abstract":"Generative large-scale language models create the fifth paradigm of scientific research, organically combine data science and computational intelligence, transform the research paradigm of natural language processing and multimodal information processing, promote the new trend of AI-enabled social science research, and provide new ideas for digital humanities research and application. This article profoundly explores the application of large-scale language models in digital humanities research, revealing their significant potential in ancient book protection, intelligent processing, and academic innovation. The article first outlines the importance of ancient book resources and the necessity of digital preservation, followed by a detailed introduction to developing large-scale language models, such as ChatGPT, and their applications in document management, content understanding, and cross-cultural research. Through specific cases, the article demonstrates how AI can assist in the organization, classification, and content generation of ancient books. Then, it explores the prospects of AI applications in artistic innovation and cultural heritage preservation. Finally, the article explores the challenges and opportunities in the interaction of technology, information, and society in the digital humanities triggered by AI technologies.","sentences":["Generative large-scale language models create the fifth paradigm of scientific research, organically combine data science and computational intelligence, transform the research paradigm of natural language processing and multimodal information processing, promote the new trend of AI-enabled social science research, and provide new ideas for digital humanities research and application.","This article profoundly explores the application of large-scale language models in digital humanities research, revealing their significant potential in ancient book protection, intelligent processing, and academic innovation.","The article first outlines the importance of ancient book resources and the necessity of digital preservation, followed by a detailed introduction to developing large-scale language models, such as ChatGPT, and their applications in document management, content understanding, and cross-cultural research.","Through specific cases, the article demonstrates how AI can assist in the organization, classification, and content generation of ancient books.","Then, it explores the prospects of AI applications in artistic innovation and cultural heritage preservation.","Finally, the article explores the challenges and opportunities in the interaction of technology, information, and society in the digital humanities triggered by AI technologies."],"url":"http://arxiv.org/abs/2404.18518v1"}
{"created":"2024-04-29 09:00:32","title":"A Systematic Evaluation of Adversarial Attacks against Speech Emotion Recognition Models","abstract":"Speech emotion recognition (SER) is constantly gaining attention in recent years due to its potential applications in diverse fields and thanks to the possibility offered by deep learning technologies. However, recent studies have shown that deep learning models can be vulnerable to adversarial attacks. In this paper, we systematically assess this problem by examining the impact of various adversarial white-box and black-box attacks on different languages and genders within the context of SER. We first propose a suitable methodology for audio data processing, feature extraction, and CNN-LSTM architecture. The observed outcomes highlighted the significant vulnerability of CNN-LSTM models to adversarial examples (AEs). In fact, all the considered adversarial attacks are able to significantly reduce the performance of the constructed models. Furthermore, when assessing the efficacy of the attacks, minor differences were noted between the languages analyzed as well as between male and female speech. In summary, this work contributes to the understanding of the robustness of CNN-LSTM models, particularly in SER scenarios, and the impact of AEs. Interestingly, our findings serve as a baseline for a) developing more robust algorithms for SER, b) designing more effective attacks, c) investigating possible defenses, d) improved understanding of the vocal differences between different languages and genders, and e) overall, enhancing our comprehension of the SER task.","sentences":["Speech emotion recognition (SER) is constantly gaining attention in recent years due to its potential applications in diverse fields and thanks to the possibility offered by deep learning technologies.","However, recent studies have shown that deep learning models can be vulnerable to adversarial attacks.","In this paper, we systematically assess this problem by examining the impact of various adversarial white-box and black-box attacks on different languages and genders within the context of SER.","We first propose a suitable methodology for audio data processing, feature extraction, and CNN-LSTM architecture.","The observed outcomes highlighted the significant vulnerability of CNN-LSTM models to adversarial examples (AEs).","In fact, all the considered adversarial attacks are able to significantly reduce the performance of the constructed models.","Furthermore, when assessing the efficacy of the attacks, minor differences were noted between the languages analyzed as well as between male and female speech.","In summary, this work contributes to the understanding of the robustness of CNN-LSTM models, particularly in SER scenarios, and the impact of AEs.","Interestingly, our findings serve as a baseline for a) developing more robust algorithms for SER, b) designing more effective attacks, c) investigating possible defenses, d) improved understanding of the vocal differences between different languages and genders, and e) overall, enhancing our comprehension of the SER task."],"url":"http://arxiv.org/abs/2404.18514v1"}
{"created":"2024-04-29 08:50:27","title":"Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models","abstract":"Event-based sensors are well suited for real-time processing due to their fast response times and encoding of the sensory data as successive temporal differences. These and other valuable properties, such as a high dynamic range, are suppressed when the data is converted to a frame-based format. However, most current methods either collapse events into frames or cannot scale up when processing the event data directly event-by-event. In this work, we address the key challenges of scaling up event-by-event modeling of the long event streams emitted by such sensors, which is a particularly relevant problem for neuromorphic computing. While prior methods can process up to a few thousand time steps, our model, based on modern recurrent deep state-space models, scales to event streams of millions of events for both training and inference.We leverage their stable parameterization for learning long-range dependencies, parallelizability along the sequence dimension, and their ability to integrate asynchronous events effectively to scale them up to long event streams.We further augment these with novel event-centric techniques enabling our model to match or beat the state-of-the-art performance on several event stream benchmarks. In the Spiking Speech Commands task, we improve state-of-the-art by a large margin of 6.6% to 87.1%. On the DVS128-Gestures dataset, we achieve competitive results without using frames or convolutional neural networks. Our work demonstrates, for the first time, that it is possible to use fully event-based processing with purely recurrent networks to achieve state-of-the-art task performance in several event-based benchmarks.","sentences":["Event-based sensors are well suited for real-time processing due to their fast response times and encoding of the sensory data as successive temporal differences.","These and other valuable properties, such as a high dynamic range, are suppressed when the data is converted to a frame-based format.","However, most current methods either collapse events into frames or cannot scale up when processing the event data directly event-by-event.","In this work, we address the key challenges of scaling up event-by-event modeling of the long event streams emitted by such sensors, which is a particularly relevant problem for neuromorphic computing.","While prior methods can process up to a few thousand time steps, our model, based on modern recurrent deep state-space models, scales to event streams of millions of events for both training and inference.","We leverage their stable parameterization for learning long-range dependencies, parallelizability along the sequence dimension, and their ability to integrate asynchronous events effectively to scale them up to long event streams.","We further augment these with novel event-centric techniques enabling our model to match or beat the state-of-the-art performance on several event stream benchmarks.","In the Spiking Speech Commands task, we improve state-of-the-art by a large margin of 6.6% to 87.1%.","On the DVS128-Gestures dataset, we achieve competitive results without using frames or convolutional neural networks.","Our work demonstrates, for the first time, that it is possible to use fully event-based processing with purely recurrent networks to achieve state-of-the-art task performance in several event-based benchmarks."],"url":"http://arxiv.org/abs/2404.18508v1"}
{"created":"2024-04-29 08:46:43","title":"Multisensor Data Fusion for Automatized Insect Monitoring (KInsecta)","abstract":"Insect populations are declining globally, making systematic monitoring essential for conservation. Most classical methods involve death traps and counter insect conservation. This paper presents a multisensor approach that uses AI-based data fusion for insect classification. The system is designed as low-cost setup and consists of a camera module and an optical wing beat sensor as well as environmental sensors to measure temperature, irradiance or daytime as prior information. The system has been tested in the laboratory and in the field. First tests on a small very unbalanced data set with 7 species show promising results for species classification. The multisensor system will support biodiversity and agriculture studies.","sentences":["Insect populations are declining globally, making systematic monitoring essential for conservation.","Most classical methods involve death traps and counter insect conservation.","This paper presents a multisensor approach that uses AI-based data fusion for insect classification.","The system is designed as low-cost setup and consists of a camera module and an optical wing beat sensor as well as environmental sensors to measure temperature, irradiance or daytime as prior information.","The system has been tested in the laboratory and in the field.","First tests on a small very unbalanced data set with 7 species show promising results for species classification.","The multisensor system will support biodiversity and agriculture studies."],"url":"http://arxiv.org/abs/2404.18504v1"}
{"created":"2024-04-29 08:34:35","title":"PHOBIC: Perfect Hashing with Optimized Bucket Sizes and Interleaved Coding","abstract":"A minimal perfect hash function (MPHF) maps a set of n keys to {1, ..., n} without collisions. Such functions find widespread application e.g. in bioinformatics and databases. In this paper we revisit PTHash - a construction technique particularly designed for fast queries. PTHash distributes the input keys into small buckets and, for each bucket, it searches for a hash function seed that places its keys in the output domain without collisions. The collection of all seeds is then stored in a compressed way. Since the first buckets are easier to place, buckets are considered in non-increasing order of size. Additionally, PTHash heuristically produces an imbalanced distribution of bucket sizes by distributing 60% of the keys into 30% of the buckets. Our main contribution is to characterize, up to lower order terms, an optimal distribution of expected bucket sizes. We arrive at a simple, closed form solution which improves construction throughput for space efficient configurations in practice. Our second contribution is a novel encoding scheme for the seeds. We split the keys into partitions. Within each partition, we run the bucket distribution and search step. We then store the seeds in an interleaved way by consecutively placing the seeds for the i-th buckets from all partitions. The seeds for the i-th bucket of each partition follow the same statistical distribution. This allows us to tune a compressor for each bucket. Hence, we call our technique PHOBIC - Perfect Hashing with Optimized Bucket sizes and Interleaved Coding. Compared to PTHash, PHOBIC is 0.17 bits/key more space efficient for same query time and construction throughput. We also contribute a GPU implementation to further accelerate MPHF construction. For a configuration with fast queries, PHOBIC-GPU can construct a perfect hash function at 2.17 bits/key in 28 ns per key, which can be queried in 37 ns on the CPU.","sentences":["A minimal perfect hash function (MPHF) maps a set of n keys to {1, ..., n} without collisions.","Such functions find widespread application e.g. in bioinformatics and databases.","In this paper we revisit PTHash - a construction technique particularly designed for fast queries.","PTHash distributes the input keys into small buckets and, for each bucket, it searches for a hash function seed that places its keys in the output domain without collisions.","The collection of all seeds is then stored in a compressed way.","Since the first buckets are easier to place, buckets are considered in non-increasing order of size.","Additionally, PTHash heuristically produces an imbalanced distribution of bucket sizes by distributing 60% of the keys into 30% of the buckets.","Our main contribution is to characterize, up to lower order terms, an optimal distribution of expected bucket sizes.","We arrive at a simple, closed form solution which improves construction throughput for space efficient configurations in practice.","Our second contribution is a novel encoding scheme for the seeds.","We split the keys into partitions.","Within each partition, we run the bucket distribution and search step.","We then store the seeds in an interleaved way by consecutively placing the seeds for the i-th buckets from all partitions.","The seeds for the i-th bucket of each partition follow the same statistical distribution.","This allows us to tune a compressor for each bucket.","Hence, we call our technique PHOBIC - Perfect Hashing with Optimized Bucket sizes and Interleaved Coding.","Compared to PTHash, PHOBIC is 0.17 bits/key more space efficient for same query time and construction throughput.","We also contribute a GPU implementation to further accelerate MPHF construction.","For a configuration with fast queries, PHOBIC-GPU can construct a perfect hash function at 2.17 bits/key in 28 ns per key, which can be queried in 37 ns on the CPU."],"url":"http://arxiv.org/abs/2404.18497v1"}
{"created":"2024-04-29 08:16:30","title":"Reduced-Rank Multi-objective Policy Learning and Optimization","abstract":"Evaluating the causal impacts of possible interventions is crucial for informing decision-making, especially towards improving access to opportunity. However, if causal effects are heterogeneous and predictable from covariates, personalized treatment decisions can improve individual outcomes and contribute to both efficiency and equity. In practice, however, causal researchers do not have a single outcome in mind a priori and often collect multiple outcomes of interest that are noisy estimates of the true target of interest. For example, in government-assisted social benefit programs, policymakers collect many outcomes to understand the multidimensional nature of poverty. The ultimate goal is to learn an optimal treatment policy that in some sense maximizes multiple outcomes simultaneously. To address such issues, we present a data-driven dimensionality-reduction methodology for multiple outcomes in the context of optimal policy learning with multiple objectives. We learn a low-dimensional representation of the true outcome from the observed outcomes using reduced rank regression. We develop a suite of estimates that use the model to denoise observed outcomes, including commonly-used index weightings. These methods improve estimation error in policy evaluation and optimization, including on a case study of real-world cash transfer and social intervention data. Reducing the variance of noisy social outcomes can improve the performance of algorithmic allocations.","sentences":["Evaluating the causal impacts of possible interventions is crucial for informing decision-making, especially towards improving access to opportunity.","However, if causal effects are heterogeneous and predictable from covariates, personalized treatment decisions can improve individual outcomes and contribute to both efficiency and equity.","In practice, however, causal researchers do not have a single outcome in mind a priori and often collect multiple outcomes of interest that are noisy estimates of the true target of interest.","For example, in government-assisted social benefit programs, policymakers collect many outcomes to understand the multidimensional nature of poverty.","The ultimate goal is to learn an optimal treatment policy that in some sense maximizes multiple outcomes simultaneously.","To address such issues, we present a data-driven dimensionality-reduction methodology for multiple outcomes in the context of optimal policy learning with multiple objectives.","We learn a low-dimensional representation of the true outcome from the observed outcomes using reduced rank regression.","We develop a suite of estimates that use the model to denoise observed outcomes, including commonly-used index weightings.","These methods improve estimation error in policy evaluation and optimization, including on a case study of real-world cash transfer and social intervention data.","Reducing the variance of noisy social outcomes can improve the performance of algorithmic allocations."],"url":"http://arxiv.org/abs/2404.18490v1"}
{"created":"2024-04-29 07:11:39","title":"ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction","abstract":"In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock performance is a critical challenge that has attracted both academics and investors. While previous studies have used deep learning-based models to obtain a general view of ECCs, they often fail to capture detailed, complex information. Our study introduces a novel framework: \\textbf{ECC Analyzer}, combining Large Language Models (LLMs) and multi-modal techniques to extract richer, more predictive insights. The model begins by summarizing the transcript's structure and analyzing the speakers' mode and confidence level by detecting variations in tone and pitch for audio. This analysis helps investors form an overview perception of the ECCs. Moreover, this model uses the Retrieval-Augmented Generation (RAG) based methods to meticulously extract the focuses that have a significant impact on stock performance from an expert's perspective, providing a more targeted analysis. The model goes a step further by enriching these extracted focuses with additional layers of analysis, such as sentiment and audio segment features. By integrating these insights, the ECC Analyzer performs multi-task predictions of stock performance, including volatility, value-at-risk (VaR), and return for different intervals. The results show that our model outperforms traditional analytic benchmarks, confirming the effectiveness of using advanced LLM techniques in financial analytics.","sentences":["In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock performance is a critical challenge that has attracted both academics and investors.","While previous studies have used deep learning-based models to obtain a general view of ECCs, they often fail to capture detailed, complex information.","Our study introduces a novel framework: \\textbf{ECC Analyzer}, combining Large Language Models (LLMs) and multi-modal techniques to extract richer, more predictive insights.","The model begins by summarizing the transcript's structure and analyzing the speakers' mode and confidence level by detecting variations in tone and pitch for audio.","This analysis helps investors form an overview perception of the ECCs.","Moreover, this model uses the Retrieval-Augmented Generation (RAG) based methods to meticulously extract the focuses that have a significant impact on stock performance from an expert's perspective, providing a more targeted analysis.","The model goes a step further by enriching these extracted focuses with additional layers of analysis, such as sentiment and audio segment features.","By integrating these insights, the ECC Analyzer performs multi-task predictions of stock performance, including volatility, value-at-risk (VaR), and return for different intervals.","The results show that our model outperforms traditional analytic benchmarks, confirming the effectiveness of using advanced LLM techniques in financial analytics."],"url":"http://arxiv.org/abs/2404.18470v1"}
{"created":"2024-04-29 07:07:58","title":"HFT: Half Fine-Tuning for Large Language Models","abstract":"Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of catastrophic forgetting during sequential training, the parametric knowledge or the ability learned in previous stages may be overwhelmed by incoming training data. In this paper, we find that by regularly resetting partial parameters, LLMs can restore some of the original knowledge. Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute for full fine-tuning (FFT), to mitigate the forgetting issues, where half of the parameters are selected to learn new tasks while the other half are frozen to remain previous knowledge. We provide a feasibility analysis from the perspective of optimization and interpret the parameter selection operation as a regularization term. Without changing the model architecture, HFT could be seamlessly integrated into existing fine-tuning frameworks. Extensive experiments and analysis on supervised fine-tuning, direct preference optimization, and continual learning consistently demonstrate the effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not only significantly alleviates the forgetting problem, but also achieves the best performance in a series of downstream benchmarks, with an approximately 30% reduction in training time.","sentences":["Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences.","However, it carries the risk of catastrophic forgetting during sequential training, the parametric knowledge or the ability learned in previous stages may be overwhelmed by incoming training data.","In this paper, we find that by regularly resetting partial parameters, LLMs can restore some of the original knowledge.","Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute for full fine-tuning (FFT), to mitigate the forgetting issues, where half of the parameters are selected to learn new tasks while the other half are frozen to remain previous knowledge.","We provide a feasibility analysis from the perspective of optimization and interpret the parameter selection operation as a regularization term.","Without changing the model architecture, HFT could be seamlessly integrated into existing fine-tuning frameworks.","Extensive experiments and analysis on supervised fine-tuning, direct preference optimization, and continual learning consistently demonstrate the effectiveness, robustness, and efficiency of HFT.","Compared with FFT, HFT not only significantly alleviates the forgetting problem, but also achieves the best performance in a series of downstream benchmarks, with an approximately 30% reduction in training time."],"url":"http://arxiv.org/abs/2404.18466v1"}
{"created":"2024-04-29 06:35:34","title":"Chameleon: A Data-Efficient Generalist for Dense Visual Prediction in the Wild","abstract":"Large language models have evolved data-efficient generalists, benefiting from the universal language interface and large-scale pre-training. However, constructing a data-efficient generalist for dense visual prediction presents a distinct challenge due to the variation in label structures across different tasks. Consequently, generalization to unseen dense prediction tasks in the low-data regime is not straightforward and has received less attention from previous vision generalists. In this study, we explore a universal model that can flexibly adapt to unseen dense label structures with a few examples, enabling it to serve as a data-efficient vision generalist in diverse real-world scenarios. To this end, we base our method on a powerful meta-learning framework and explore several axes to improve its performance and versatility for real-world problems, such as flexible adaptation mechanisms and scalability. We evaluate our model across a spectrum of unseen real-world scenarios where low-shot learning is desirable, including video, 3D, medical, biological, and user-interactive tasks. Equipped with a generic architecture and an effective adaptation mechanism, our model flexibly adapts to all of these tasks with at most 50 labeled images, showcasing a significant advancement over existing data-efficient generalist approaches. Codes are available at https://github.com/GitGyun/chameleon.","sentences":["Large language models have evolved data-efficient generalists, benefiting from the universal language interface and large-scale pre-training.","However, constructing a data-efficient generalist for dense visual prediction presents a distinct challenge due to the variation in label structures across different tasks.","Consequently, generalization to unseen dense prediction tasks in the low-data regime is not straightforward and has received less attention from previous vision generalists.","In this study, we explore a universal model that can flexibly adapt to unseen dense label structures with a few examples, enabling it to serve as a data-efficient vision generalist in diverse real-world scenarios.","To this end, we base our method on a powerful meta-learning framework and explore several axes to improve its performance and versatility for real-world problems, such as flexible adaptation mechanisms and scalability.","We evaluate our model across a spectrum of unseen real-world scenarios where low-shot learning is desirable, including video, 3D, medical, biological, and user-interactive tasks.","Equipped with a generic architecture and an effective adaptation mechanism, our model flexibly adapts to all of these tasks with at most 50 labeled images, showcasing a significant advancement over existing data-efficient generalist approaches.","Codes are available at https://github.com/GitGyun/chameleon."],"url":"http://arxiv.org/abs/2404.18459v1"}
{"created":"2024-04-29 06:10:45","title":"The PRODSAT phase of random quantum satisfiability","abstract":"The $k$-QSAT problem is a quantum analog of the famous $k$-SAT constraint satisfaction problem. We must determine the zero energy ground states of a Hamiltonian of $N$ qubits consisting of a sum of $M$ random $k$-local rank-one projectors. It is known that product states of zero energy exist with high probability if and only if the underlying factor graph has a clause-covering dimer configuration. This means that the threshold of the PRODSAT phase is a purely geometric quantity equal to the dimer covering threshold. We revisit and fully prove this result through a combination of complex analysis and algebraic methods based on Buchberger's algorithm for complex polynomial equations with random coefficients. We also discuss numerical experiments investigating the presence of entanglement in the PRODSAT phase in the sense that product states do not span the whole zero energy ground state space.","sentences":["The $k$-QSAT problem is a quantum analog of the famous $k$-SAT constraint satisfaction problem.","We must determine the zero energy ground states of a Hamiltonian of $N$ qubits consisting of a sum of $M$ random $k$-local rank-one projectors.","It is known that product states of zero energy exist with high probability if and only if the underlying factor graph has a clause-covering dimer configuration.","This means that the threshold of the PRODSAT phase is a purely geometric quantity equal to the dimer covering threshold.","We revisit and fully prove this result through a combination of complex analysis and algebraic methods based on Buchberger's algorithm for complex polynomial equations with random coefficients.","We also discuss numerical experiments investigating the presence of entanglement in the PRODSAT phase in the sense that product states do not span the whole zero energy ground state space."],"url":"http://arxiv.org/abs/2404.18447v1"}
{"created":"2024-04-29 05:57:03","title":"U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models","abstract":"U-Nets are among the most widely used architectures in computer vision, renowned for their exceptional performance in applications such as image segmentation, denoising, and diffusion modeling. However, a theoretical explanation of the U-Net architecture design has not yet been fully established.   This paper introduces a novel interpretation of the U-Net architecture by studying certain generative hierarchical models, which are tree-structured graphical models extensively utilized in both language and image domains. With their encoder-decoder structure, long skip connections, and pooling and up-sampling layers, we demonstrate how U-Nets can naturally implement the belief propagation denoising algorithm in such generative hierarchical models, thereby efficiently approximating the denoising functions. This leads to an efficient sample complexity bound for learning the denoising function using U-Nets within these models. Additionally, we discuss the broader implications of these findings for diffusion models in generative hierarchical models. We also demonstrate that the conventional architecture of convolutional neural networks (ConvNets) is ideally suited for classification tasks within these models. This offers a unified view of the roles of ConvNets and U-Nets, highlighting the versatility of generative hierarchical models in modeling complex data distributions across language and image domains.","sentences":["U-Nets are among the most widely used architectures in computer vision, renowned for their exceptional performance in applications such as image segmentation, denoising, and diffusion modeling.","However, a theoretical explanation of the U-Net architecture design has not yet been fully established.   ","This paper introduces a novel interpretation of the U-Net architecture by studying certain generative hierarchical models, which are tree-structured graphical models extensively utilized in both language and image domains.","With their encoder-decoder structure, long skip connections, and pooling and up-sampling layers, we demonstrate how U-Nets can naturally implement the belief propagation denoising algorithm in such generative hierarchical models, thereby efficiently approximating the denoising functions.","This leads to an efficient sample complexity bound for learning the denoising function using U-Nets within these models.","Additionally, we discuss the broader implications of these findings for diffusion models in generative hierarchical models.","We also demonstrate that the conventional architecture of convolutional neural networks (ConvNets) is ideally suited for classification tasks within these models.","This offers a unified view of the roles of ConvNets and U-Nets, highlighting the versatility of generative hierarchical models in modeling complex data distributions across language and image domains."],"url":"http://arxiv.org/abs/2404.18444v1"}
{"created":"2024-04-29 05:40:08","title":"BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers","abstract":"Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the deficiency of sufficient publicly annotated biomedical data and computational resources. We present BMRetriever, a series of dense retrievers for enhancing biomedical retrieval via unsupervised pre-training on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify BMRetriever's efficacy on various biomedical applications. BMRetriever also exhibits strong parameter efficiency, with the 410M variant outperforming baselines up to 11.7 times larger, and the 2B variant matching the performance of models with over 5B parameters. The training data and model checkpoints are released at \\url{https://huggingface.co/BMRetriever} to ensure transparency, reproducibility, and application to new domains.","sentences":["Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the deficiency of sufficient publicly annotated biomedical data and computational resources.","We present BMRetriever, a series of dense retrievers for enhancing biomedical retrieval via unsupervised pre-training on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs.","Experiments on 5 biomedical tasks across 11 datasets verify BMRetriever's efficacy on various biomedical applications.","BMRetriever also exhibits strong parameter efficiency, with the 410M variant outperforming baselines up to 11.7 times larger, and the 2B variant matching the performance of models with over 5B parameters.","The training data and model checkpoints are released at \\url{https://huggingface.co/BMRetriever} to ensure transparency, reproducibility, and application to new domains."],"url":"http://arxiv.org/abs/2404.18443v1"}
{"created":"2024-04-29 04:59:40","title":"Geospatial Big Data: Survey and Challenges","abstract":"In recent years, geospatial big data (GBD) has obtained attention across various disciplines, categorized into big earth observation data and big human behavior data. Identifying geospatial patterns from GBD has been a vital research focus in the fields of urban management and environmental sustainability. This paper reviews the evolution of GBD mining and its integration with advanced artificial intelligence (AI) techniques. GBD consists of data generated by satellites, sensors, mobile devices, and geographical information systems, and we categorize geospatial data based on different perspectives. We outline the process of GBD mining and demonstrate how it can be incorporated into a unified framework. Additionally, we explore new technologies like large language models (LLM), the Metaverse, and knowledge graphs, and how they could make GBD even more useful. We also share examples of GBD helping with city management and protecting the environment. Finally, we discuss the real challenges that come up when working with GBD, such as issues with data retrieval and security. Our goal is to give readers a clear view of where GBD mining stands today and where it might go next.","sentences":["In recent years, geospatial big data (GBD) has obtained attention across various disciplines, categorized into big earth observation data and big human behavior data.","Identifying geospatial patterns from GBD has been a vital research focus in the fields of urban management and environmental sustainability.","This paper reviews the evolution of GBD mining and its integration with advanced artificial intelligence (AI) techniques.","GBD consists of data generated by satellites, sensors, mobile devices, and geographical information systems, and we categorize geospatial data based on different perspectives.","We outline the process of GBD mining and demonstrate how it can be incorporated into a unified framework.","Additionally, we explore new technologies like large language models (LLM), the Metaverse, and knowledge graphs, and how they could make GBD even more useful.","We also share examples of GBD helping with city management and protecting the environment.","Finally, we discuss the real challenges that come up when working with GBD, such as issues with data retrieval and security.","Our goal is to give readers a clear view of where GBD mining stands today and where it might go next."],"url":"http://arxiv.org/abs/2404.18428v1"}
{"created":"2024-04-29 04:56:52","title":"Efficient Meta-Learning Enabled Lightweight Multiscale Few-Shot Object Detection in Remote Sensing Images","abstract":"Presently, the task of few-shot object detection (FSOD) in remote sensing images (RSIs) has become a focal point of attention. Numerous few-shot detectors, particularly those based on two-stage detectors, face challenges when dealing with the multiscale complexities inherent in RSIs. Moreover, these detectors present impractical characteristics in real-world applications, mainly due to their unwieldy model parameters when handling large amount of data. In contrast, we recognize the advantages of one-stage detectors, including high detection speed and a global receptive field. Consequently, we choose the YOLOv7 one-stage detector as a baseline and subject it to a novel meta-learning training framework. This transformation allows the detector to adeptly address FSOD tasks while capitalizing on its inherent advantage of lightweight. Additionally, we thoroughly investigate the samples generated by the meta-learning strategy and introduce a novel meta-sampling approach to retain samples produced by our designed meta-detection head. Coupled with our devised meta-cross loss, we deliberately utilize ``negative samples\" that are often overlooked to extract valuable knowledge from them. This approach serves to enhance detection accuracy and efficiently refine the overall meta-learning strategy. To validate the effectiveness of our proposed detector, we conducted performance comparisons with current state-of-the-art detectors using the DIOR and NWPU VHR-10.v2 datasets, yielding satisfactory results.","sentences":["Presently, the task of few-shot object detection (FSOD) in remote sensing images (RSIs) has become a focal point of attention.","Numerous few-shot detectors, particularly those based on two-stage detectors, face challenges when dealing with the multiscale complexities inherent in RSIs.","Moreover, these detectors present impractical characteristics in real-world applications, mainly due to their unwieldy model parameters when handling large amount of data.","In contrast, we recognize the advantages of one-stage detectors, including high detection speed and a global receptive field.","Consequently, we choose the YOLOv7 one-stage detector as a baseline and subject it to a novel meta-learning training framework.","This transformation allows the detector to adeptly address FSOD tasks while capitalizing on its inherent advantage of lightweight.","Additionally, we thoroughly investigate the samples generated by the meta-learning strategy and introduce a novel meta-sampling approach to retain samples produced by our designed meta-detection head.","Coupled with our devised meta-cross loss, we deliberately utilize ``negative samples\" that are often overlooked to extract valuable knowledge from them.","This approach serves to enhance detection accuracy and efficiently refine the overall meta-learning strategy.","To validate the effectiveness of our proposed detector, we conducted performance comparisons with current state-of-the-art detectors using the DIOR and NWPU VHR-10.v2 datasets, yielding satisfactory results."],"url":"http://arxiv.org/abs/2404.18426v1"}
{"created":"2024-04-29 04:51:30","title":"PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval","abstract":"The current use of large language models (LLMs) for zero-shot document ranking follows one of two ways: 1) prompt-based re-ranking methods, which require no further training but are feasible for only re-ranking a handful of candidate documents due to the associated computational costs; and 2) unsupervised contrastive trained dense retrieval methods, which can retrieve relevant documents from the entire corpus but require a large amount of paired text data for contrastive training. In this paper, we propose PromptReps, which combines the advantages of both categories: no need for training and the ability to retrieve from the whole corpus. Our method only requires prompts to guide an LLM to generate query and document representations for effective document retrieval. Specifically, we prompt the LLMs to represent a given text using a single word, and then use the last token's hidden states and the corresponding logits associated to the prediction of the next token to construct a hybrid document retrieval system. The retrieval system harnesses both dense text embedding and sparse bag-of-words representations given by the LLM. Our experimental evaluation on the BEIR zero-shot document retrieval datasets illustrates that this simple prompt-based LLM retrieval method can achieve a similar or higher retrieval effectiveness than state-of-the-art LLM embedding methods that are trained with large amounts of unsupervised data, especially when using a larger LLM.","sentences":["The current use of large language models (LLMs) for zero-shot document ranking follows one of two ways: 1) prompt-based re-ranking methods, which require no further training but are feasible for only re-ranking a handful of candidate documents due to the associated computational costs; and 2) unsupervised contrastive trained dense retrieval methods, which can retrieve relevant documents from the entire corpus but require a large amount of paired text data for contrastive training.","In this paper, we propose PromptReps, which combines the advantages of both categories: no need for training and the ability to retrieve from the whole corpus.","Our method only requires prompts to guide an LLM to generate query and document representations for effective document retrieval.","Specifically, we prompt the LLMs to represent a given text using a single word, and then use the last token's hidden states and the corresponding logits associated to the prediction of the next token to construct a hybrid document retrieval system.","The retrieval system harnesses both dense text embedding and sparse bag-of-words representations given by the LLM.","Our experimental evaluation on the BEIR zero-shot document retrieval datasets illustrates that this simple prompt-based LLM retrieval method can achieve a similar or higher retrieval effectiveness than state-of-the-art LLM embedding methods that are trained with large amounts of unsupervised data, especially when using a larger LLM."],"url":"http://arxiv.org/abs/2404.18424v1"}
{"created":"2024-04-29 04:32:11","title":"Research on Intelligent Aided Diagnosis System of Medical Image Based on Computer Deep Learning","abstract":"This paper combines Struts and Hibernate two architectures together, using DAO (Data Access Object) to store and access data. Then a set of dual-mode humidity medical image library suitable for deep network is established, and a dual-mode medical image assisted diagnosis method based on the image is proposed. Through the test of various feature extraction methods, the optimal operating characteristic under curve product (AUROC) is 0.9985, the recall rate is 0.9814, and the accuracy is 0.9833. This method can be applied to clinical diagnosis, and it is a practical method. Any outpatient doctor can register quickly through the system, or log in to the platform to upload the image to obtain more accurate images. Through the system, each outpatient physician can quickly register or log in to the platform for image uploading, thus obtaining more accurate images. The segmentation of images can guide doctors in clinical departments. Then the image is analyzed to determine the location and nature of the tumor, so as to make targeted treatment.","sentences":["This paper combines Struts and Hibernate two architectures together, using DAO (Data Access Object) to store and access data.","Then a set of dual-mode humidity medical image library suitable for deep network is established, and a dual-mode medical image assisted diagnosis method based on the image is proposed.","Through the test of various feature extraction methods, the optimal operating characteristic under curve product (AUROC) is 0.9985, the recall rate is 0.9814, and the accuracy is 0.9833.","This method can be applied to clinical diagnosis, and it is a practical method.","Any outpatient doctor can register quickly through the system, or log in to the platform to upload the image to obtain more accurate images.","Through the system, each outpatient physician can quickly register or log in to the platform for image uploading, thus obtaining more accurate images.","The segmentation of images can guide doctors in clinical departments.","Then the image is analyzed to determine the location and nature of the tumor, so as to make targeted treatment."],"url":"http://arxiv.org/abs/2404.18419v1"}
{"created":"2024-04-29 04:11:28","title":"Capabilities of Gemini Models in Medicine","abstract":"Excellence in a wide variety of medical applications poses considerable challenges for AI, requiring advanced reasoning, access to up-to-date medical knowledge and understanding of complex multimodal data. Gemini models, with strong general capabilities in multimodal and long-context reasoning, offer exciting possibilities in medicine. Building on these core strengths of Gemini, we introduce Med-Gemini, a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly use web search, and that can be efficiently tailored to novel modalities using custom encoders. We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health & medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. Taken together, our results offer compelling evidence for Med-Gemini's potential, although further rigorous evaluation will be crucial before real-world deployment in this safety-critical domain.","sentences":["Excellence in a wide variety of medical applications poses considerable challenges for AI, requiring advanced reasoning, access to up-to-date medical knowledge and understanding of complex multimodal data.","Gemini models, with strong general capabilities in multimodal and long-context reasoning, offer exciting possibilities in medicine.","Building on these core strengths of Gemini, we introduce Med-Gemini, a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly use web search, and that can be efficiently tailored to novel modalities using custom encoders.","We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin.","On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy.","On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health & medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%.","We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning.","Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education.","Taken together, our results offer compelling evidence for Med-Gemini's potential, although further rigorous evaluation will be crucial before real-world deployment in this safety-critical domain."],"url":"http://arxiv.org/abs/2404.18416v1"}
{"created":"2024-04-29 04:01:30","title":"3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset","abstract":"Multimodal machine translation (MMT) is a challenging task that seeks to improve translation quality by incorporating visual information. However, recent studies have indicated that the visual information provided by existing MMT datasets is insufficient, causing models to disregard it and overestimate their capabilities. This issue presents a significant obstacle to the development of MMT research. This paper presents a novel solution to this issue by introducing 3AM, an ambiguity-aware MMT dataset comprising 26,000 parallel sentence pairs in English and Chinese, each with corresponding images. Our dataset is specifically designed to include more ambiguity and a greater variety of both captions and images than other MMT datasets. We utilize a word sense disambiguation model to select ambiguous data from vision-and-language datasets, resulting in a more challenging dataset. We further benchmark several state-of-the-art MMT models on our proposed dataset. Experimental results show that MMT models trained on our dataset exhibit a greater ability to exploit visual information than those trained on other MMT datasets. Our work provides a valuable resource for researchers in the field of multimodal learning and encourages further exploration in this area. The data, code and scripts are freely available at https://github.com/MaxyLee/3AM.","sentences":["Multimodal machine translation (MMT) is a challenging task that seeks to improve translation quality by incorporating visual information.","However, recent studies have indicated that the visual information provided by existing MMT datasets is insufficient, causing models to disregard it and overestimate their capabilities.","This issue presents a significant obstacle to the development of MMT research.","This paper presents a novel solution to this issue by introducing 3AM, an ambiguity-aware MMT dataset comprising 26,000 parallel sentence pairs in English and Chinese, each with corresponding images.","Our dataset is specifically designed to include more ambiguity and a greater variety of both captions and images than other MMT datasets.","We utilize a word sense disambiguation model to select ambiguous data from vision-and-language datasets, resulting in a more challenging dataset.","We further benchmark several state-of-the-art MMT models on our proposed dataset.","Experimental results show that MMT models trained on our dataset exhibit a greater ability to exploit visual information than those trained on other MMT datasets.","Our work provides a valuable resource for researchers in the field of multimodal learning and encourages further exploration in this area.","The data, code and scripts are freely available at https://github.com/MaxyLee/3AM."],"url":"http://arxiv.org/abs/2404.18413v1"}
{"created":"2024-04-29 03:30:06","title":"LLM-SR: Scientific Equation Discovery via Programming with Large Language Models","abstract":"Mathematical equations have been unreasonably effective in describing complex natural phenomena across various scientific disciplines. However, discovering such insightful equations from data presents significant challenges due to the necessity of navigating extremely high-dimensional combinatorial and nonlinear hypothesis spaces. Traditional methods of equation discovery largely focus on extracting equations from data alone, often neglecting the rich domain-specific prior knowledge that scientists typically depend on. To bridge this gap, we introduce LLM-SR, a novel approach that leverages the extensive scientific knowledge and robust code generation capabilities of Large Language Models (LLMs) to discover scientific equations from data in an efficient manner. Specifically, LLM-SR treats equations as programs with mathematical operators and combines LLMs' scientific priors with evolutionary search over equation programs. The LLM iteratively proposes new equation skeletons, drawing from its physical understanding, which are then optimized against data to estimate skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse scientific domains, where it discovers physically accurate equations that provide significantly better fits to in-domain and out-of-domain data compared to the well-established equation discovery baselines","sentences":["Mathematical equations have been unreasonably effective in describing complex natural phenomena across various scientific disciplines.","However, discovering such insightful equations from data presents significant challenges due to the necessity of navigating extremely high-dimensional combinatorial and nonlinear hypothesis spaces.","Traditional methods of equation discovery largely focus on extracting equations from data alone, often neglecting the rich domain-specific prior knowledge that scientists typically depend on.","To bridge this gap, we introduce LLM-SR, a novel approach that leverages the extensive scientific knowledge and robust code generation capabilities of Large Language Models (LLMs) to discover scientific equations from data in an efficient manner.","Specifically, LLM-SR treats equations as programs with mathematical operators and combines LLMs' scientific priors with evolutionary search over equation programs.","The LLM iteratively proposes new equation skeletons, drawing from its physical understanding, which are then optimized against data to estimate skeleton parameters.","We demonstrate LLM-SR's effectiveness across three diverse scientific domains, where it discovers physically accurate equations that provide significantly better fits to in-domain and out-of-domain data compared to the well-established equation discovery baselines"],"url":"http://arxiv.org/abs/2404.18400v1"}
{"created":"2024-04-29 03:13:09","title":"Reconstructing Satellites in 3D from Amateur Telescope Images","abstract":"This paper proposes a framework for the 3D reconstruction of satellites in low-Earth orbit, utilizing videos captured by small amateur telescopes. The video data obtained from these telescopes differ significantly from data for standard 3D reconstruction tasks, characterized by intense motion blur, atmospheric turbulence, pervasive background light pollution, extended focal length and constrained observational perspectives. To address these challenges, our approach begins with a comprehensive pre-processing workflow that encompasses deep learning-based image restoration, feature point extraction and camera pose initialization. We proceed with the application of an improved 3D Gaussian splatting algorithm for reconstructing the 3D model. Our technique supports simultaneous 3D Gaussian training and pose estimation, enabling the robust generation of intricate 3D point clouds from sparse, noisy data. The procedure is further bolstered by a post-editing phase designed to eliminate noise points inconsistent with our prior knowledge of a satellite's geometric constraints. We validate our approach using both synthetic datasets and actual observations of China's Space Station, showcasing its significant advantages over existing methods in reconstructing 3D space objects from ground-based observations.","sentences":["This paper proposes a framework for the 3D reconstruction of satellites in low-Earth orbit, utilizing videos captured by small amateur telescopes.","The video data obtained from these telescopes differ significantly from data for standard 3D reconstruction tasks, characterized by intense motion blur, atmospheric turbulence, pervasive background light pollution, extended focal length and constrained observational perspectives.","To address these challenges, our approach begins with a comprehensive pre-processing workflow that encompasses deep learning-based image restoration, feature point extraction and camera pose initialization.","We proceed with the application of an improved 3D Gaussian splatting algorithm for reconstructing the 3D model.","Our technique supports simultaneous 3D Gaussian training and pose estimation, enabling the robust generation of intricate 3D point clouds from sparse, noisy data.","The procedure is further bolstered by a post-editing phase designed to eliminate noise points inconsistent with our prior knowledge of a satellite's geometric constraints.","We validate our approach using both synthetic datasets and actual observations of China's Space Station, showcasing its significant advantages over existing methods in reconstructing 3D space objects from ground-based observations."],"url":"http://arxiv.org/abs/2404.18394v1"}
{"created":"2024-04-29 02:55:54","title":"SPECIAL: Synopsis Assisted Secure Collaborative Analytics","abstract":"Secure collaborative analytics (SCA) enable the processing of analytical SQL queries across multiple owners' data, even when direct data sharing is not feasible. Although essential for strong privacy, the large overhead from data-oblivious primitives in traditional SCA has hindered its practical adoption. Recent SCA variants that permit controlled leakages under differential privacy (DP) show a better balance between privacy and efficiency. However, they still face significant challenges, such as potentially unbounded privacy loss, suboptimal query planning, and lossy processing. To address these challenges, we introduce SPECIAL, the first SCA system that simultaneously ensures bounded privacy loss, advanced query planning, and lossless processing. SPECIAL employs a novel synopsis-assisted secure processing model, where a one-time privacy cost is spent to acquire private synopses (table statistics) from owner data. These synopses then allow SPECIAL to estimate (compaction) sizes for secure operations (e.g., filter, join) and index encrypted data without extra privacy loss. Crucially, these estimates and indexes can be prepared before runtime, thereby facilitating efficient query planning and accurate cost estimations. Moreover, by using one-sided noise mechanisms and private upper bound techniques, SPECIAL ensures strict lossless processing for complex queries (e.g., multi-join). Through a comprehensive benchmark, we show that SPECIAL significantly outperforms cutting-edge SCAs, with up to 80X faster query times and over 900X smaller memory for complex queries. Moreover, it also achieves up to an 89X reduction in privacy loss under continual processing.","sentences":["Secure collaborative analytics (SCA) enable the processing of analytical SQL queries across multiple owners' data, even when direct data sharing is not feasible.","Although essential for strong privacy, the large overhead from data-oblivious primitives in traditional SCA has hindered its practical adoption.","Recent SCA variants that permit controlled leakages under differential privacy (DP) show a better balance between privacy and efficiency.","However, they still face significant challenges, such as potentially unbounded privacy loss, suboptimal query planning, and lossy processing.","To address these challenges, we introduce SPECIAL, the first SCA system that simultaneously ensures bounded privacy loss, advanced query planning, and lossless processing.","SPECIAL employs a novel synopsis-assisted secure processing model, where a one-time privacy cost is spent to acquire private synopses (table statistics) from owner data.","These synopses then allow SPECIAL to estimate (compaction) sizes for secure operations (e.g., filter, join) and index encrypted data without extra privacy loss.","Crucially, these estimates and indexes can be prepared before runtime, thereby facilitating efficient query planning and accurate cost estimations.","Moreover, by using one-sided noise mechanisms and private upper bound techniques, SPECIAL ensures strict lossless processing for complex queries (e.g., multi-join).","Through a comprehensive benchmark, we show that SPECIAL significantly outperforms cutting-edge SCAs, with up to 80X faster query times and over 900X smaller memory for complex queries.","Moreover, it also achieves up to an 89X reduction in privacy loss under continual processing."],"url":"http://arxiv.org/abs/2404.18388v1"}
{"created":"2024-04-29 02:23:53","title":"6G comprehensive intelligence: network operations and optimization based on Large Language Models","abstract":"The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT). To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services. This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system. The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment. This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application value, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence.","sentences":["The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT).","To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services.","This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system.","The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment.","This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application value, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence."],"url":"http://arxiv.org/abs/2404.18373v1"}
{"created":"2024-04-29 01:37:11","title":"Display in the Air: Balancing Distraction and Workload in AR Glasses Interfaces for Driving Navigation","abstract":"Augmented Reality (AR) navigation via Head-Mounted Displays (HMDs), particularly AR glasses, is revolutionizing the driving experience by integrating real-time routing information into the driver's field of view. Despite the potential of AR glasses, the question of how to display navigation information on the interface of these devices remains a valuable yet relatively unexplored research area. This study employs a mixed-method approach involving 32 participants, combining qualitative feedback from semi-structured interviews with quantitative data from usability questionnaires in both simulated and real-world scenarios. Highlighting the necessity of real-world testing, the research evaluates the impact of five icon placements on the efficiency and effectiveness of information perception in both environments. The experiment results indicate a preference for non-central icon placements, especially bottom-center in real world, which mostly balances distraction and workload for the driver. Moreover, these findings contribute to the formulation of four specific design implications for augmented reality interfaces and systems. This research advances the understanding of AR glasses in driving assistance and sets the stage for further developments in this emerging technology field.","sentences":["Augmented Reality (AR) navigation via Head-Mounted Displays (HMDs), particularly AR glasses, is revolutionizing the driving experience by integrating real-time routing information into the driver's field of view.","Despite the potential of AR glasses, the question of how to display navigation information on the interface of these devices remains a valuable yet relatively unexplored research area.","This study employs a mixed-method approach involving 32 participants, combining qualitative feedback from semi-structured interviews with quantitative data from usability questionnaires in both simulated and real-world scenarios.","Highlighting the necessity of real-world testing, the research evaluates the impact of five icon placements on the efficiency and effectiveness of information perception in both environments.","The experiment results indicate a preference for non-central icon placements, especially bottom-center in real world, which mostly balances distraction and workload for the driver.","Moreover, these findings contribute to the formulation of four specific design implications for augmented reality interfaces and systems.","This research advances the understanding of AR glasses in driving assistance and sets the stage for further developments in this emerging technology field."],"url":"http://arxiv.org/abs/2404.18357v1"}
{"created":"2024-04-29 01:36:55","title":"FEDQ-Trust: Efficient Data-Driven Trust Prediction for Mobile Edge-Based IoT Systems","abstract":"We introduce FEDQ-Trust, an innovative data-driven trust prediction approach designed for mobile edge-based Internet of Things (IoT) environments. The decentralized nature of mobile edge environments introduces challenges due to variations in data distribution, impacting the accuracy and training efficiency of existing distributed data-driven trust prediction models. FEDQ-Trust effectively tackles the statistical heterogeneity challenges by integrating Federated Expectation-Maximization with Deep Q Networks. Federated Expectation-Maximization's robust handling of statistical heterogeneity significantly enhances trust prediction accuracy. Meanwhile, Deep Q Networks streamlines the model training process, efficiently reducing the number of training clients while maintaining model performance. We conducted a suite of experiments within simulated MEC-based IoT settings by leveraging two real-world IoT datasets. The experimental results demonstrate that our model achieved a significant convergence time reduction of 97% to 99% while ensuring a notable improvement of 8% to 14% in accuracy compared to state-of-the-art models.","sentences":["We introduce FEDQ-Trust, an innovative data-driven trust prediction approach designed for mobile edge-based Internet of Things (IoT) environments.","The decentralized nature of mobile edge environments introduces challenges due to variations in data distribution, impacting the accuracy and training efficiency of existing distributed data-driven trust prediction models.","FEDQ-Trust effectively tackles the statistical heterogeneity challenges by integrating Federated Expectation-Maximization with Deep Q Networks.","Federated Expectation-Maximization's robust handling of statistical heterogeneity significantly enhances trust prediction accuracy.","Meanwhile, Deep Q Networks streamlines the model training process, efficiently reducing the number of training clients while maintaining model performance.","We conducted a suite of experiments within simulated MEC-based IoT settings by leveraging two real-world IoT datasets.","The experimental results demonstrate that our model achieved a significant convergence time reduction of 97% to 99% while ensuring a notable improvement of 8% to 14% in accuracy compared to state-of-the-art models."],"url":"http://arxiv.org/abs/2404.18356v1"}
{"created":"2024-04-29 01:35:58","title":"Pi\u00e8ces de viole des Cinq Livres and their statistical signatures: the musical work of Marin Marais and Jordi Savall","abstract":"This study analyzes the spectrum of audio signals related to the work of \"Pi\\`eces de viole des Cinq Livres\" based on the collaborative work between Marin Marais and Jordi Savall for the underlying musical information. In particular, we explore the identification of possible statistical signatures related to this musical work. Based on the complex systems approach, we compute the spectrum of audio signals, analyze and identify their best-fit statistical distributions, and plot their relative frequencies using the scientific pitch notation. Findings suggest that the collection of frequency components related to the spectrum of each of the books that form this audio work show highly skewed and associated statistical distributions. Therefore, the most frequent statistical distribution that best describes the collection of these audio data and may be associated with a singular statistical signature is the exponential.","sentences":["This study analyzes the spectrum of audio signals related to the work of \"Pi\\`eces de viole des Cinq Livres\" based on the collaborative work between Marin Marais and Jordi Savall for the underlying musical information.","In particular, we explore the identification of possible statistical signatures related to this musical work.","Based on the complex systems approach, we compute the spectrum of audio signals, analyze and identify their best-fit statistical distributions, and plot their relative frequencies using the scientific pitch notation.","Findings suggest that the collection of frequency components related to the spectrum of each of the books that form this audio work show highly skewed and associated statistical distributions.","Therefore, the most frequent statistical distribution that best describes the collection of these audio data and may be associated with a singular statistical signature is the exponential."],"url":"http://arxiv.org/abs/2404.18355v1"}
{"created":"2024-04-29 01:19:17","title":"Post-hoc and manifold explanations analysis of facial expression data based on deep learning","abstract":"The complex information processing system of humans generates a lot of objective and subjective evaluations, making the exploration of human cognitive products of great cutting-edge theoretical value. In recent years, deep learning technologies, which are inspired by biological brain mechanisms, have made significant strides in the application of psychological or cognitive scientific research, particularly in the memorization and recognition of facial data. This paper investigates through experimental research how neural networks process and store facial expression data and associate these data with a range of psychological attributes produced by humans. Researchers utilized deep learning model VGG16, demonstrating that neural networks can learn and reproduce key features of facial data, thereby storing image memories. Moreover, the experimental results reveal the potential of deep learning models in understanding human emotions and cognitive processes and establish a manifold visualization interpretation of cognitive products or psychological attributes from a non-Euclidean space perspective, offering new insights into enhancing the explainability of AI. This study not only advances the application of AI technology in the field of psychology but also provides a new psychological theoretical understanding the information processing of the AI. The code is available in here: https://github.com/NKUShaw/Psychoinformatics.","sentences":["The complex information processing system of humans generates a lot of objective and subjective evaluations, making the exploration of human cognitive products of great cutting-edge theoretical value.","In recent years, deep learning technologies, which are inspired by biological brain mechanisms, have made significant strides in the application of psychological or cognitive scientific research, particularly in the memorization and recognition of facial data.","This paper investigates through experimental research how neural networks process and store facial expression data and associate these data with a range of psychological attributes produced by humans.","Researchers utilized deep learning model VGG16, demonstrating that neural networks can learn and reproduce key features of facial data, thereby storing image memories.","Moreover, the experimental results reveal the potential of deep learning models in understanding human emotions and cognitive processes and establish a manifold visualization interpretation of cognitive products or psychological attributes from a non-Euclidean space perspective, offering new insights into enhancing the explainability of AI.","This study not only advances the application of AI technology in the field of psychology but also provides a new psychological theoretical understanding the information processing of the AI.","The code is available in here: https://github.com/NKUShaw/Psychoinformatics."],"url":"http://arxiv.org/abs/2404.18352v1"}
{"created":"2024-04-29 01:12:26","title":"L-DIT: A dApp for Live Detectability, Identifiability and Trackability for ASOs on the Behavioral Dynamics Blockchain","abstract":"As the number of Anthropogenic Space Objects (ASOs) grows, there is an urgent need to ensure space safety, security, and sustainability (S3) for long-term space use. Currently, no globally effective method can quantify the safety, security, and Sustainability of all ASOs in orbit. Existing methods such as the Space Sustainability Rating (SSR) rely on volunteering private information to provide sustainability ratings. However, the need for such sensitive data might prove to be a barrier to adoption for space entities. For effective comparison of ASOs, the rating mechanism should apply to all ASOs, even retroactively, so that the sustainability of a single ASO can be assessed holistically. Lastly, geopolitical boundaries and alignments play a crucial and limiting role in a volunteered rating system, limiting the space safety, security, and sustainability. This work presents a Live Detectability, Identifiability, and Trackability (L-DIT) score through a distributed app (dApp) built on top of the Behavioral Dynamics blockchain (BDB). The BDB chain is a space situational awareness (SSA) chain that provides verified and cross-checked ASO data from multiple sources. This unique combination of consensus-based information from BDB and permissionless access to data allows the DIT scoring method presented here to be applied to all ASOs. While the underlying BDB chain collects, filters, and validates SSA data from various open (and closed if available) sources, the L-DIT dApp consumes the data from the chain to provide L-DIT score that can contribute towards an operator's, manufacturer's, or owner's sustainability practices. Our dApp provides data for all ASOs, allowing their sustainability score to be compared against other ASOs, regardless of geopolitical alignments, providing business value to entities such as space insurance providers and enabling compliance validation and enforcement.","sentences":["As the number of Anthropogenic Space Objects (ASOs) grows, there is an urgent need to ensure space safety, security, and sustainability (S3) for long-term space use.","Currently, no globally effective method can quantify the safety, security, and Sustainability of all ASOs in orbit.","Existing methods such as the Space Sustainability Rating (SSR) rely on volunteering private information to provide sustainability ratings.","However, the need for such sensitive data might prove to be a barrier to adoption for space entities.","For effective comparison of ASOs, the rating mechanism should apply to all ASOs, even retroactively, so that the sustainability of a single ASO can be assessed holistically.","Lastly, geopolitical boundaries and alignments play a crucial and limiting role in a volunteered rating system, limiting the space safety, security, and sustainability.","This work presents a Live Detectability, Identifiability, and Trackability (L-DIT) score through a distributed app (dApp) built on top of the Behavioral Dynamics blockchain (BDB).","The BDB chain is a space situational awareness (SSA) chain that provides verified and cross-checked ASO data from multiple sources.","This unique combination of consensus-based information from BDB and permissionless access to data allows the DIT scoring method presented here to be applied to all ASOs.","While the underlying BDB chain collects, filters, and validates SSA data from various open (and closed if available) sources, the L-DIT dApp consumes the data from the chain to provide L-DIT score that can contribute towards an operator's, manufacturer's, or owner's sustainability practices.","Our dApp provides data for all ASOs, allowing their sustainability score to be compared against other ASOs, regardless of geopolitical alignments, providing business value to entities such as space insurance providers and enabling compliance validation and enforcement."],"url":"http://arxiv.org/abs/2404.18350v1"}
{"created":"2024-04-29 00:35:59","title":"Additive Spanner Lower Bounds with Optimal Inner Graph Structure","abstract":"We construct $n$-node graphs on which any $O(n)$-size spanner has additive error at least $+\\Omega(n^{3/17})$, improving on the previous best lower bound of $\\Omega(n^{1/7})$ [Bodwin-Hoppenworth FOCS '22]. Our construction completes the first two steps of a particular three-step research program, introduced in prior work and overviewed here, aimed at producing tight bounds for the problem by aligning aspects of the upper and lower bound constructions. More specifically, we develop techniques that enable the use of inner graphs in the lower bound framework whose technical properties are provably tight with the corresponding assumptions made in the upper bounds. As an additional application of our techniques, we improve the corresponding lower bound for $O(n)$-size additive emulators to $+\\Omega(n^{1/14})$.","sentences":["We construct $n$-node graphs on which any $O(n)$-size spanner has additive error at least $+\\Omega(n^{3/17})$, improving on the previous best lower bound of $\\Omega(n^{1/7})$ [Bodwin-Hoppenworth FOCS '22].","Our construction completes the first two steps of a particular three-step research program, introduced in prior work and overviewed here, aimed at producing tight bounds for the problem by aligning aspects of the upper and lower bound constructions.","More specifically, we develop techniques that enable the use of inner graphs in the lower bound framework whose technical properties are provably tight with the corresponding assumptions made in the upper bounds.","As an additional application of our techniques, we improve the corresponding lower bound for $O(n)$-size additive emulators to $+\\Omega(n^{1/14})$."],"url":"http://arxiv.org/abs/2404.18337v1"}
{"created":"2024-04-28 22:53:03","title":"Multi-Robot Object SLAM using Distributed Variational Inference","abstract":"Multi-robot simultaneous localization and mapping (SLAM) enables a robot team to achieve coordinated tasks relying on a common map. However, centralized processing of robot observations is undesirable because it creates a single point of failure and requires pre-existing infrastructure and significant multi-hop communication throughput. This paper formulates multi-robot object SLAM as a variational inference problem over a communication graph. We impose a consensus constraint on the objects maintained by different nodes to ensure agreement on a common map. To solve the problem, we develop a distributed mirror descent algorithm with a regularization term enforcing consensus. Using Gaussian distributions in the algorithm, we derive a distributed multi-state constraint Kalman filter (MSCKF) for multi-robot object SLAM. Experiments on real and simulated data show that our method improves the trajectory and object estimates, compared to individual-robot SLAM, while achieving better scaling to large robot teams, compared to centralized multi-robot SLAM. Code is available at https://github.com/intrepidChw/distributed_msckf.","sentences":["Multi-robot simultaneous localization and mapping (SLAM) enables a robot team to achieve coordinated tasks relying on a common map.","However, centralized processing of robot observations is undesirable because it creates a single point of failure and requires pre-existing infrastructure and significant multi-hop communication throughput.","This paper formulates multi-robot object SLAM as a variational inference problem over a communication graph.","We impose a consensus constraint on the objects maintained by different nodes to ensure agreement on a common map.","To solve the problem, we develop a distributed mirror descent algorithm with a regularization term enforcing consensus.","Using Gaussian distributions in the algorithm, we derive a distributed multi-state constraint Kalman filter (MSCKF) for multi-robot object SLAM.","Experiments on real and simulated data show that our method improves the trajectory and object estimates, compared to individual-robot SLAM, while achieving better scaling to large robot teams, compared to centralized multi-robot SLAM.","Code is available at https://github.com/intrepidChw/distributed_msckf."],"url":"http://arxiv.org/abs/2404.18331v1"}
{"created":"2024-04-28 21:53:42","title":"MultiMAE-DER: Multimodal Masked Autoencoder for Dynamic Emotion Recognition","abstract":"This paper presents a novel approach to processing multimodal data for dynamic emotion recognition, named as the Multimodal Masked Autoencoder for Dynamic Emotion Recognition (MultiMAE-DER). The MultiMAE-DER leverages the closely correlated representation information within spatiotemporal sequences across visual and audio modalities. By utilizing a pre-trained masked autoencoder model, the MultiMAEDER is accomplished through simple, straightforward finetuning. The performance of the MultiMAE-DER is enhanced by optimizing six fusion strategies for multimodal input sequences. These strategies address dynamic feature correlations within cross-domain data across spatial, temporal, and spatiotemporal sequences. In comparison to state-of-the-art multimodal supervised learning models for dynamic emotion recognition, MultiMAE-DER enhances the weighted average recall (WAR) by 4.41% on the RAVDESS dataset and by 2.06% on the CREMAD. Furthermore, when compared with the state-of-the-art model of multimodal self-supervised learning, MultiMAE-DER achieves a 1.86% higher WAR on the IEMOCAP dataset.","sentences":["This paper presents a novel approach to processing multimodal data for dynamic emotion recognition, named as the Multimodal Masked Autoencoder for Dynamic Emotion Recognition (MultiMAE-DER).","The MultiMAE-DER leverages the closely correlated representation information within spatiotemporal sequences across visual and audio modalities.","By utilizing a pre-trained masked autoencoder model, the MultiMAEDER is accomplished through simple, straightforward finetuning.","The performance of the MultiMAE-DER is enhanced by optimizing six fusion strategies for multimodal input sequences.","These strategies address dynamic feature correlations within cross-domain data across spatial, temporal, and spatiotemporal sequences.","In comparison to state-of-the-art multimodal supervised learning models for dynamic emotion recognition, MultiMAE-DER enhances the weighted average recall (WAR) by 4.41% on the RAVDESS dataset and by 2.06% on the CREMAD.","Furthermore, when compared with the state-of-the-art model of multimodal self-supervised learning, MultiMAE-DER achieves a 1.86% higher WAR on the IEMOCAP dataset."],"url":"http://arxiv.org/abs/2404.18327v1"}
{"created":"2024-04-28 20:54:57","title":"DIRESA, a distance-preserving nonlinear dimension reduction technique based on regularized autoencoders","abstract":"In meteorology, finding similar weather patterns or analogs in historical datasets can be useful for data assimilation, forecasting, and postprocessing. In climate science, analogs in historical and climate projection data are used for attribution and impact studies. However, most of the time, those large weather and climate datasets are nearline. They must be downloaded, which takes a lot of bandwidth and disk space, before the computationally expensive search can be executed. We propose a dimension reduction technique based on autoencoder (AE) neural networks to compress those datasets and perform the search in an interpretable, compressed latent space. A distance-regularized Siamese twin autoencoder (DIRESA) architecture is designed to preserve distance in latent space while capturing the nonlinearities in the datasets. Using conceptual climate models of different complexities, we show that the latent components thus obtained provide physical insight into the dominant modes of variability in the system. Compressing datasets with DIRESA reduces the online storage and keeps the latent components uncorrelated, while the distance (ordering) preservation and reconstruction fidelity robustly outperform Principal Component Analysis (PCA) and other dimension reduction techniques such as UMAP or variational autoencoders.","sentences":["In meteorology, finding similar weather patterns or analogs in historical datasets can be useful for data assimilation, forecasting, and postprocessing.","In climate science, analogs in historical and climate projection data are used for attribution and impact studies.","However, most of the time, those large weather and climate datasets are nearline.","They must be downloaded, which takes a lot of bandwidth and disk space, before the computationally expensive search can be executed.","We propose a dimension reduction technique based on autoencoder (AE) neural networks to compress those datasets and perform the search in an interpretable, compressed latent space.","A distance-regularized Siamese twin autoencoder (DIRESA) architecture is designed to preserve distance in latent space while capturing the nonlinearities in the datasets.","Using conceptual climate models of different complexities, we show that the latent components thus obtained provide physical insight into the dominant modes of variability in the system.","Compressing datasets with DIRESA reduces the online storage and keeps the latent components uncorrelated, while the distance (ordering) preservation and reconstruction fidelity robustly outperform Principal Component Analysis (PCA) and other dimension reduction techniques such as UMAP or variational autoencoders."],"url":"http://arxiv.org/abs/2404.18314v1"}
{"created":"2024-04-28 20:44:53","title":"Trends and Challenges of Real-time Learning in Large Language Models: A Critical Review","abstract":"Real-time learning concerns the ability of learning systems to acquire knowledge over time, enabling their adaptation and generalization to novel tasks. It is a critical ability for intelligent, real-world systems, especially when data may be insufficient or difficult to obtain. This review provides a comprehensive analysis of real-time learning in Large Language Models. It synthesizes the state-of-the-art real-time learning paradigms, including continual learning, meta-learning, parameter-efficient learning, and mixture-of-experts learning. We demonstrate their utility for real-time learning by describing specific achievements from these related topics and their critical factors. Finally, the paper highlights current problems and challenges for future research in the field. By consolidating the latest relevant research developments, this review offers a comprehensive understanding of real-time learning and its implications for designing and developing LLM-based learning systems addressing real-world problems.","sentences":["Real-time learning concerns the ability of learning systems to acquire knowledge over time, enabling their adaptation and generalization to novel tasks.","It is a critical ability for intelligent, real-world systems, especially when data may be insufficient or difficult to obtain.","This review provides a comprehensive analysis of real-time learning in Large Language Models.","It synthesizes the state-of-the-art real-time learning paradigms, including continual learning, meta-learning, parameter-efficient learning, and mixture-of-experts learning.","We demonstrate their utility for real-time learning by describing specific achievements from these related topics and their critical factors.","Finally, the paper highlights current problems and challenges for future research in the field.","By consolidating the latest relevant research developments, this review offers a comprehensive understanding of real-time learning and its implications for designing and developing LLM-based learning systems addressing real-world problems."],"url":"http://arxiv.org/abs/2404.18311v1"}
{"created":"2024-04-28 20:22:46","title":"Data-Driven Dynamic State Estimation of Photovoltaic Systems via Sparse Regression Unscented Kalman Filter","abstract":"Dynamic state estimation (DSE) is vital in modern power systems with numerous inverter-based distributed energy resources including solar and wind, ensuring real-time accuracy for tracking system variables and optimizing grid stability. This paper proposes a data-driven DSE approach designed for photovoltaic (PV) energy conversion systems (single stage and two stage) that are subjected to both process and measurement noise. The proposed framework follows a two-phase methodology encompassing ``data-driven model identification\" and ``state-estimation.\" In the initial model identification phase, state feedback is gathered to elucidate the dynamics of the photovoltaic systems using nonlinear sparse regression technique. Following the identification of the PV dynamics, the nonlinear data-driven model will be utilized to estimate the dynamics of the PV system for monitoring and protection purposes. To account for incomplete measurements, inherent uncertainties, and noise, we employ an ``unscented Kalman filter,\" which facilitates state estimation by processing the noisy output data. Ultimately, the paper substantiates the efficacy of the proposed sparse regression-based unscented Kalman filter through simulation results, providing a comparative analysis with a physics-based DSE.","sentences":["Dynamic state estimation (DSE) is vital in modern power systems with numerous inverter-based distributed energy resources including solar and wind, ensuring real-time accuracy for tracking system variables and optimizing grid stability.","This paper proposes a data-driven DSE approach designed for photovoltaic (PV) energy conversion systems (single stage and two stage) that are subjected to both process and measurement noise.","The proposed framework follows a two-phase methodology encompassing ``data-driven model identification\" and ``state-estimation.\"","In the initial model identification phase, state feedback is gathered to elucidate the dynamics of the photovoltaic systems using nonlinear sparse regression technique.","Following the identification of the PV dynamics, the nonlinear data-driven model will be utilized to estimate the dynamics of the PV system for monitoring and protection purposes.","To account for incomplete measurements, inherent uncertainties, and noise, we employ an ``unscented Kalman filter,\" which facilitates state estimation by processing the noisy output data.","Ultimately, the paper substantiates the efficacy of the proposed sparse regression-based unscented Kalman filter through simulation results, providing a comparative analysis with a physics-based DSE."],"url":"http://arxiv.org/abs/2404.18305v1"}
{"created":"2024-04-28 20:03:21","title":"Finding Understanding and Support: Navigating Online Communities to Share and Connect at the intersection of Abuse and Foster Care Experiences","abstract":"Many children in foster care experience trauma that is rooted in unstable family relationships. Other members of the foster care system like foster parents and social workers face secondary trauma. Drawing on 10 years of Reddit data, we used a mixed methods approach to analyze how different members of the foster care system find support and similar experiences at the intersection of two Reddit communities - foster care, and abuse. Users who cross this boundary focus on trauma experiences specific to different roles in foster care. While representing a small number of users, boundary crossing users contribute heavily to both communities, and, compared to matching users, receive higher scores and more replies. We explore the roles boundary crossing users have both in the online community and in the context of foster care. Finally, we present design recommendations that would support trauma survivors find communities more suited to their personal experiences.","sentences":["Many children in foster care experience trauma that is rooted in unstable family relationships.","Other members of the foster care system like foster parents and social workers face secondary trauma.","Drawing on 10 years of Reddit data, we used a mixed methods approach to analyze how different members of the foster care system find support and similar experiences at the intersection of two Reddit communities - foster care, and abuse.","Users who cross this boundary focus on trauma experiences specific to different roles in foster care.","While representing a small number of users, boundary crossing users contribute heavily to both communities, and, compared to matching users, receive higher scores and more replies.","We explore the roles boundary crossing users have both in the online community and in the context of foster care.","Finally, we present design recommendations that would support trauma survivors find communities more suited to their personal experiences."],"url":"http://arxiv.org/abs/2404.18301v1"}
{"created":"2024-04-28 19:35:00","title":"Panoptic Segmentation and Labelling of Lumbar Spine Vertebrae using Modified Attention Unet","abstract":"Segmentation and labeling of vertebrae in MRI images of the spine are critical for the diagnosis of illnesses and abnormalities. These steps are indispensable as MRI technology provides detailed information about the tissue structure of the spine. Both supervised and unsupervised segmentation methods exist, yet acquiring sufficient data remains challenging for achieving high accuracy. In this study, we propose an enhancing approach based on modified attention U-Net architecture for panoptic segmentation of 3D sliced MRI data of the lumbar spine. Our method achieves an impressive accuracy of 99.5\\% by incorporating novel masking logic, thus significantly advancing the state-of-the-art in vertebral segmentation and labeling. This contributes to more precise and reliable diagnosis and treatment planning.","sentences":["Segmentation and labeling of vertebrae in MRI images of the spine are critical for the diagnosis of illnesses and abnormalities.","These steps are indispensable as MRI technology provides detailed information about the tissue structure of the spine.","Both supervised and unsupervised segmentation methods exist, yet acquiring sufficient data remains challenging for achieving high accuracy.","In this study, we propose an enhancing approach based on modified attention U-Net architecture for panoptic segmentation of 3D sliced MRI data of the lumbar spine.","Our method achieves an impressive accuracy of 99.5\\% by incorporating novel masking logic, thus significantly advancing the state-of-the-art in vertebral segmentation and labeling.","This contributes to more precise and reliable diagnosis and treatment planning."],"url":"http://arxiv.org/abs/2404.18291v1"}
{"created":"2024-04-28 19:24:58","title":"Joint Energy and Latency Optimization in Federated Learning over Cell-Free Massive MIMO Networks","abstract":"Federated learning (FL) is a distributed learning paradigm wherein users exchange FL models with a server instead of raw datasets, thereby preserving data privacy and reducing communication overhead. However, the increased number of FL users may hinder completing large-scale FL over wireless networks due to high imposed latency. Cell-free massive multiple-input multiple-output~(CFmMIMO) is a promising architecture for implementing FL because it serves many users on the same time/frequency resources. While CFmMIMO enhances energy efficiency through spatial multiplexing and collaborative beamforming, it remains crucial to meticulously allocate uplink transmission powers to the FL users. In this paper, we propose an uplink power allocation scheme in FL over CFmMIMO by considering the effect of each user's power on the energy and latency of other users to jointly minimize the users' uplink energy and the latency of FL training. The proposed solution algorithm is based on the coordinate gradient descent method. Numerical results show that our proposed method outperforms the well-known max-sum rate by increasing up to~$27$\\% and max-min energy efficiency of the Dinkelbach method by increasing up to~$21$\\% in terms of test accuracy while having limited uplink energy and latency budget for FL over CFmMIMO.","sentences":["Federated learning (FL) is a distributed learning paradigm wherein users exchange FL models with a server instead of raw datasets, thereby preserving data privacy and reducing communication overhead.","However, the increased number of FL users may hinder completing large-scale FL over wireless networks due to high imposed latency.","Cell-free massive multiple-input multiple-output~(CFmMIMO) is a promising architecture for implementing FL because it serves many users on the same time/frequency resources.","While CFmMIMO enhances energy efficiency through spatial multiplexing and collaborative beamforming, it remains crucial to meticulously allocate uplink transmission powers to the FL users.","In this paper, we propose an uplink power allocation scheme in FL over CFmMIMO by considering the effect of each user's power on the energy and latency of other users to jointly minimize the users' uplink energy and the latency of FL training.","The proposed solution algorithm is based on the coordinate gradient descent method.","Numerical results show that our proposed method outperforms the well-known max-sum rate by increasing up to~$27$\\% and max-min energy efficiency of the Dinkelbach method by increasing up to~$21$\\% in terms of test accuracy while having limited uplink energy and latency budget for FL over CFmMIMO."],"url":"http://arxiv.org/abs/2404.18287v1"}
{"created":"2024-04-28 19:24:28","title":"Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages","abstract":"Large Language Models are transforming NLP for a variety of tasks. However, how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored. In line with the goals of the AmeicasNLP workshop, we focus on 12 LRLs from Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English and Brazilian Portuguese). Our results indicate that the LLMs perform worse for the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the reasons behind this failure and provide an error analyses through examples observed in our data set.","sentences":["Large Language Models are transforming NLP for a variety of tasks.","However, how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored.","In line with the goals of the AmeicasNLP workshop, we focus on 12 LRLs from Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English and Brazilian Portuguese).","Our results indicate that the LLMs perform worse for the part of speech (POS) labeling of LRLs in comparison to HRLs.","We explain the reasons behind this failure and provide an error analyses through examples observed in our data set."],"url":"http://arxiv.org/abs/2404.18286v1"}
{"created":"2024-04-28 18:51:32","title":"Out-of-distribution Detection in Medical Image Analysis: A survey","abstract":"Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years. Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data. However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks. Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system. In this survey, we systematically review the recent advances in OOD detection in medical image analysis. We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors. Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy. Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration.","sentences":["Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years.","Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data.","However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks.","Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system.","In this survey, we systematically review the recent advances in OOD detection in medical image analysis.","We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors.","Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy.","Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration."],"url":"http://arxiv.org/abs/2404.18279v1"}
{"created":"2024-04-28 18:44:10","title":"Kernel Corrector LSTM","abstract":"Forecasting methods are affected by data quality issues in two ways: 1. they are hard to predict, and 2. they may affect the model negatively when it is updated with new data. The latter issue is usually addressed by pre-processing the data to remove those issues. An alternative approach has recently been proposed, Corrector LSTM (cLSTM), which is a Read \\& Write Machine Learning (RW-ML) algorithm that changes the data while learning to improve its predictions. Despite promising results being reported, cLSTM is computationally expensive, as it uses a meta-learner to monitor the hidden states of the LSTM. We propose a new RW-ML algorithm, Kernel Corrector LSTM (KcLSTM), that replaces the meta-learner of cLSTM with a simpler method: Kernel Smoothing. We empirically evaluate the forecasting accuracy and the training time of the new algorithm and compare it with cLSTM and LSTM. Results indicate that it is able to decrease the training time while maintaining a competitive forecasting accuracy.","sentences":["Forecasting methods are affected by data quality issues in two ways: 1.","they are hard to predict, and 2.","they may affect the model negatively when it is updated with new data.","The latter issue is usually addressed by pre-processing the data to remove those issues.","An alternative approach has recently been proposed, Corrector LSTM (cLSTM), which is a Read \\& Write Machine Learning (RW-ML) algorithm that changes the data while learning to improve its predictions.","Despite promising results being reported, cLSTM is computationally expensive, as it uses a meta-learner to monitor the hidden states of the LSTM.","We propose a new RW-ML algorithm, Kernel Corrector LSTM (KcLSTM), that replaces the meta-learner of cLSTM with a simpler method: Kernel Smoothing.","We empirically evaluate the forecasting accuracy and the training time of the new algorithm and compare it with cLSTM and LSTM.","Results indicate that it is able to decrease the training time while maintaining a competitive forecasting accuracy."],"url":"http://arxiv.org/abs/2404.18273v1"}
{"created":"2024-04-28 18:31:09","title":"Pragmatic Formal Verification of Sequential Error Detection and Correction Codes (ECCs) used in Safety-Critical Design","abstract":"Error Detection and Correction Codes (ECCs) are often used in digital designs to protect data integrity. Especially in safety-critical systems such as automotive electronics, ECCs are widely used and the verification of such complex logic becomes more critical considering the ISO 26262 safety standards. Exhaustive verification of ECC using formal methods has been a challenge given the high number of data bits to protect. As an example, for an ECC of 128 data bits with a possibility to detect up to four-bit errors, the combination of bit errors is given by 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7. This vast analysis space often leads to bounded proof results. Moreover, the complexity and state-space increase further if the ECC has sequential encoding and decoding stages. To overcome such problems and sign-off the design with confidence within reasonable proof time, we present a pragmatic formal verification approach of complex ECC cores with several complexity reduction techniques and know-how that were learnt during the course of verification. We discuss using the linearity of the syndrome generator as a helper assertion, using the abstract model as glue logic to compare the RTL with the sequential version of the circuit, k-induction-based model checking and using mathematical relations captured as properties to simplify the verification in order to get an unbounded proof result within 24 hours of proof runtime.","sentences":["Error Detection and Correction Codes (ECCs) are often used in digital designs to protect data integrity.","Especially in safety-critical systems such as automotive electronics, ECCs are widely used and the verification of such complex logic becomes more critical considering the ISO 26262 safety standards.","Exhaustive verification of ECC using formal methods has been a challenge given the high number of data bits to protect.","As an example, for an ECC of 128 data bits with a possibility to detect up to four-bit errors, the combination of bit errors is given by 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7.","This vast analysis space often leads to bounded proof results.","Moreover, the complexity and state-space increase further if the ECC has sequential encoding and decoding stages.","To overcome such problems and sign-off the design with confidence within reasonable proof time, we present a pragmatic formal verification approach of complex ECC cores with several complexity reduction techniques and know-how that were learnt during the course of verification.","We discuss using the linearity of the syndrome generator as a helper assertion, using the abstract model as glue logic to compare the RTL with the sequential version of the circuit, k-induction-based model checking and using mathematical relations captured as properties to simplify the verification in order to get an unbounded proof result within 24 hours of proof runtime."],"url":"http://arxiv.org/abs/2404.18270v1"}
{"created":"2024-04-28 18:07:13","title":"Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin","abstract":"Nigerian Pidgin is an English-derived contact language and is traditionally an oral language, spoken by approximately 100 million people. No orthographic standard has yet been adopted, and thus the few available Pidgin datasets that exist are characterised by noise in the form of orthographic variations. This contributes to under-performance of models in critical NLP tasks. The current work is the first to describe various types of orthographic variations commonly found in Nigerian Pidgin texts, and model this orthographic variation. The variations identified in the dataset form the basis of a phonetic-theoretic framework for word editing, which is used to generate orthographic variations to augment training data. We test the effect of this data augmentation on two critical NLP tasks: machine translation and sentiment analysis. The proposed variation generation framework augments the training data with new orthographic variants which are relevant for the test set but did not occur in the training set originally. Our results demonstrate the positive effect of augmenting the training data with a combination of real texts from other corpora as well as synthesized orthographic variation, resulting in performance improvements of 2.1 points in sentiment analysis and 1.4 BLEU points in translation to English.","sentences":["Nigerian Pidgin is an English-derived contact language and is traditionally an oral language, spoken by approximately 100 million people.","No orthographic standard has yet been adopted, and thus the few available Pidgin datasets that exist are characterised by noise in the form of orthographic variations.","This contributes to under-performance of models in critical NLP tasks.","The current work is the first to describe various types of orthographic variations commonly found in Nigerian Pidgin texts, and model this orthographic variation.","The variations identified in the dataset form the basis of a phonetic-theoretic framework for word editing, which is used to generate orthographic variations to augment training data.","We test the effect of this data augmentation on two critical NLP tasks: machine translation and sentiment analysis.","The proposed variation generation framework augments the training data with new orthographic variants which are relevant for the test set but did not occur in the training set originally.","Our results demonstrate the positive effect of augmenting the training data with a combination of real texts from other corpora as well as synthesized orthographic variation, resulting in performance improvements of 2.1 points in sentiment analysis and 1.4 BLEU points in translation to English."],"url":"http://arxiv.org/abs/2404.18264v1"}
{"created":"2024-04-28 17:50:58","title":"Align, Minimize and Diversify: A Source-Free Unsupervised Domain Adaptation Method for Handwritten Text Recognition","abstract":"This paper serves to introduce the Align, Minimize and Diversify (AMD) method, a Source-Free Unsupervised Domain Adaptation approach for Handwritten Text Recognition (HTR). This framework decouples the adaptation process from the source data, thus not only sidestepping the resource-intensive retraining process but also making it possible to leverage the wealth of pre-trained knowledge encoded in modern Deep Learning architectures. Our method explicitly eliminates the need to revisit the source data during adaptation by incorporating three distinct regularization terms: the Align term, which reduces the feature distribution discrepancy between source and target data, ensuring the transferability of the pre-trained representation; the Minimize term, which encourages the model to make assertive predictions, pushing the outputs towards one-hot-like distributions in order to minimize prediction uncertainty, and finally, the Diversify term, which safeguards against the degeneracy in predictions by promoting varied and distinctive sequences throughout the target data, preventing informational collapse. Experimental results from several benchmarks demonstrated the effectiveness and robustness of AMD, showing it to be competitive and often outperforming DA methods in HTR.","sentences":["This paper serves to introduce the Align, Minimize and Diversify (AMD) method, a Source-Free Unsupervised Domain Adaptation approach for Handwritten Text Recognition (HTR).","This framework decouples the adaptation process from the source data, thus not only sidestepping the resource-intensive retraining process but also making it possible to leverage the wealth of pre-trained knowledge encoded in modern Deep Learning architectures.","Our method explicitly eliminates the need to revisit the source data during adaptation by incorporating three distinct regularization terms: the Align term, which reduces the feature distribution discrepancy between source and target data, ensuring the transferability of the pre-trained representation; the Minimize term, which encourages the model to make assertive predictions, pushing the outputs towards one-hot-like distributions in order to minimize prediction uncertainty, and finally, the Diversify term, which safeguards against the degeneracy in predictions by promoting varied and distinctive sequences throughout the target data, preventing informational collapse.","Experimental results from several benchmarks demonstrated the effectiveness and robustness of AMD, showing it to be competitive and often outperforming DA methods in HTR."],"url":"http://arxiv.org/abs/2404.18260v1"}
{"created":"2024-04-28 17:20:08","title":"Efficient Remote Sensing with Harmonized Transfer Learning and Modality Alignment","abstract":"With the rise of Visual and Language Pretraining (VLP), an increasing number of downstream tasks are adopting the paradigm of pretraining followed by fine-tuning. Although this paradigm has demonstrated potential in various multimodal downstream tasks, its implementation in the remote sensing domain encounters some obstacles. Specifically, the tendency for same-modality embeddings to cluster together impedes efficient transfer learning. To tackle this issue, we review the aim of multimodal transfer learning for downstream tasks from a unified perspective, and rethink the optimization process based on three distinct objectives. We propose \"Harmonized Transfer Learning and Modality Alignment (HarMA)\", a method that simultaneously satisfies task constraints, modality alignment, and single-modality uniform alignment, while minimizing training overhead through parameter-efficient fine-tuning. Remarkably, without the need for external data for training, HarMA achieves state-of-the-art performance in two popular multimodal retrieval tasks in the field of remote sensing. Our experiments reveal that HarMA achieves competitive and even superior performance to fully fine-tuned models with only minimal adjustable parameters. Due to its simplicity, HarMA can be integrated into almost all existing multimodal pretraining models. We hope this method can facilitate the efficient application of large models to a wide range of downstream tasks while significantly reducing the resource consumption. Code is available at https://github.com/seekerhuang/HarMA.","sentences":["With the rise of Visual and Language Pretraining (VLP), an increasing number of downstream tasks are adopting the paradigm of pretraining followed by fine-tuning.","Although this paradigm has demonstrated potential in various multimodal downstream tasks, its implementation in the remote sensing domain encounters some obstacles.","Specifically, the tendency for same-modality embeddings to cluster together impedes efficient transfer learning.","To tackle this issue, we review the aim of multimodal transfer learning for downstream tasks from a unified perspective, and rethink the optimization process based on three distinct objectives.","We propose \"Harmonized Transfer Learning and Modality Alignment (HarMA)\", a method that simultaneously satisfies task constraints, modality alignment, and single-modality uniform alignment, while minimizing training overhead through parameter-efficient fine-tuning.","Remarkably, without the need for external data for training, HarMA achieves state-of-the-art performance in two popular multimodal retrieval tasks in the field of remote sensing.","Our experiments reveal that HarMA achieves competitive and even superior performance to fully fine-tuned models with only minimal adjustable parameters.","Due to its simplicity, HarMA can be integrated into almost all existing multimodal pretraining models.","We hope this method can facilitate the efficient application of large models to a wide range of downstream tasks while significantly reducing the resource consumption.","Code is available at https://github.com/seekerhuang/HarMA."],"url":"http://arxiv.org/abs/2404.18253v1"}
{"created":"2024-04-28 17:18:08","title":"Machine Learning for Blockchain Data Analysis: Progress and Opportunities","abstract":"Blockchain technology has rapidly emerged to mainstream attention, while its publicly accessible, heterogeneous, massive-volume, and temporal data are reminiscent of the complex dynamics encountered during the last decade of big data. Unlike any prior data source, blockchain datasets encompass multiple layers of interactions across real-world entities, e.g., human users, autonomous programs, and smart contracts. Furthermore, blockchain's integration with cryptocurrencies has introduced financial aspects of unprecedented scale and complexity such as decentralized finance, stablecoins, non-fungible tokens, and central bank digital currencies. These unique characteristics present both opportunities and challenges for machine learning on blockchain data.   On one hand, we examine the state-of-the-art solutions, applications, and future directions associated with leveraging machine learning for blockchain data analysis critical for the improvement of blockchain technology such as e-crime detection and trends prediction. On the other hand, we shed light on the pivotal role of blockchain by providing vast datasets and tools that can catalyze the growth of the evolving machine learning ecosystem. This paper serves as a comprehensive resource for researchers, practitioners, and policymakers, offering a roadmap for navigating this dynamic and transformative field.","sentences":["Blockchain technology has rapidly emerged to mainstream attention, while its publicly accessible, heterogeneous, massive-volume, and temporal data are reminiscent of the complex dynamics encountered during the last decade of big data.","Unlike any prior data source, blockchain datasets encompass multiple layers of interactions across real-world entities, e.g., human users, autonomous programs, and smart contracts.","Furthermore, blockchain's integration with cryptocurrencies has introduced financial aspects of unprecedented scale and complexity such as decentralized finance, stablecoins, non-fungible tokens, and central bank digital currencies.","These unique characteristics present both opportunities and challenges for machine learning on blockchain data.   ","On one hand, we examine the state-of-the-art solutions, applications, and future directions associated with leveraging machine learning for blockchain data analysis critical for the improvement of blockchain technology such as e-crime detection and trends prediction.","On the other hand, we shed light on the pivotal role of blockchain by providing vast datasets and tools that can catalyze the growth of the evolving machine learning ecosystem.","This paper serves as a comprehensive resource for researchers, practitioners, and policymakers, offering a roadmap for navigating this dynamic and transformative field."],"url":"http://arxiv.org/abs/2404.18251v1"}
{"created":"2024-04-28 16:58:53","title":"AdaFSNet: Time Series Classification Based on Convolutional Network with a Adaptive and Effective Kernel Size Configuration","abstract":"Time series classification is one of the most critical and challenging problems in data mining, existing widely in various fields and holding significant research importance. Despite extensive research and notable achievements with successful real-world applications, addressing the challenge of capturing the appropriate receptive field (RF) size from one-dimensional or multi-dimensional time series of varying lengths remains a persistent issue, which greatly impacts performance and varies considerably across different datasets. In this paper, we propose an Adaptive and Effective Full-Scope Convolutional Neural Network (AdaFSNet) to enhance the accuracy of time series classification. This network includes two Dense Blocks. Particularly, it can dynamically choose a range of kernel sizes that effectively encompass the optimal RF size for various datasets by incorporating multiple prime numbers corresponding to the time series length. We also design a TargetDrop block, which can reduce redundancy while extracting a more effective RF. To assess the effectiveness of the AdaFSNet network, comprehensive experiments were conducted using the UCR and UEA datasets, which include one-dimensional and multi-dimensional time series data, respectively. Our model surpassed baseline models in terms of classification accuracy, underscoring the AdaFSNet network's efficiency and effectiveness in handling time series classification tasks.","sentences":["Time series classification is one of the most critical and challenging problems in data mining, existing widely in various fields and holding significant research importance.","Despite extensive research and notable achievements with successful real-world applications, addressing the challenge of capturing the appropriate receptive field (RF) size from one-dimensional or multi-dimensional time series of varying lengths remains a persistent issue, which greatly impacts performance and varies considerably across different datasets.","In this paper, we propose an Adaptive and Effective Full-Scope Convolutional Neural Network (AdaFSNet) to enhance the accuracy of time series classification.","This network includes two Dense Blocks.","Particularly, it can dynamically choose a range of kernel sizes that effectively encompass the optimal RF size for various datasets by incorporating multiple prime numbers corresponding to the time series length.","We also design a TargetDrop block, which can reduce redundancy while extracting a more effective RF.","To assess the effectiveness of the AdaFSNet network, comprehensive experiments were conducted using the UCR and UEA datasets, which include one-dimensional and multi-dimensional time series data, respectively.","Our model surpassed baseline models in terms of classification accuracy, underscoring the AdaFSNet network's efficiency and effectiveness in handling time series classification tasks."],"url":"http://arxiv.org/abs/2404.18246v1"}
{"created":"2024-04-28 16:50:12","title":"LEGENT: Open Platform for Embodied Agents","abstract":"Despite advancements in Large Language Models (LLMs) and Large Multimodal Models (LMMs), their integration into language-grounded, human-like embodied agents remains incomplete, hindering complex real-life task performance in physical environments. Existing integrations often feature limited open sourcing, challenging collective progress in this field. We introduce LEGENT, an open, scalable platform for developing embodied agents using LLMs and LMMs. LEGENT offers a dual approach: a rich, interactive 3D environment with communicable and actionable agents, paired with a user-friendly interface, and a sophisticated data generation pipeline utilizing advanced algorithms to exploit supervision from simulated worlds at scale. In our experiments, an embryonic vision-language-action model trained on LEGENT-generated data surpasses GPT-4V in embodied tasks, showcasing promising generalization capabilities.","sentences":["Despite advancements in Large Language Models (LLMs) and Large Multimodal Models (LMMs), their integration into language-grounded, human-like embodied agents remains incomplete, hindering complex real-life task performance in physical environments.","Existing integrations often feature limited open sourcing, challenging collective progress in this field.","We introduce LEGENT, an open, scalable platform for developing embodied agents using LLMs and LMMs.","LEGENT offers a dual approach: a rich, interactive 3D environment with communicable and actionable agents, paired with a user-friendly interface, and a sophisticated data generation pipeline utilizing advanced algorithms to exploit supervision from simulated worlds at scale.","In our experiments, an embryonic vision-language-action model trained on LEGENT-generated data surpasses GPT-4V in embodied tasks, showcasing promising generalization capabilities."],"url":"http://arxiv.org/abs/2404.18243v1"}
{"created":"2024-04-28 16:31:32","title":"SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning","abstract":"Large Language Models (LLMs) have highlighted the necessity of effective unlearning mechanisms to comply with data regulations and ethical AI practices. LLM unlearning aims at removing undesired data influences and associated model capabilities without compromising utility out of the scope of unlearning. While interest in studying LLM unlearning is growing,the impact of the optimizer choice for LLM unlearning remains under-explored. In this work, we shed light on the significance of optimizer selection in LLM unlearning for the first time, establishing a clear connection between {second-order optimization} and influence unlearning (a classical approach using influence functions to update the model for data influence removal). This insight propels us to develop a second-order unlearning framework, termed SOUL, built upon the second-order clipped stochastic optimization (Sophia)-based LLM training method. SOUL extends the static, one-shot model update using influence unlearning to a dynamic, iterative unlearning process. Our extensive experiments show that SOUL consistently outperforms conventional first-order methods across various unlearning tasks, models, and metrics, suggesting the promise of second-order optimization in providing a scalable and easily implementable solution for LLM unlearning.","sentences":["Large Language Models (LLMs) have highlighted the necessity of effective unlearning mechanisms to comply with data regulations and ethical AI practices.","LLM unlearning aims at removing undesired data influences and associated model capabilities without compromising utility out of the scope of unlearning.","While interest in studying LLM unlearning is growing,the impact of the optimizer choice for LLM unlearning remains under-explored.","In this work, we shed light on the significance of optimizer selection in LLM unlearning for the first time, establishing a clear connection between {second-order optimization} and influence unlearning (a classical approach using influence functions to update the model for data influence removal).","This insight propels us to develop a second-order unlearning framework, termed SOUL, built upon the second-order clipped stochastic optimization (Sophia)-based LLM training method.","SOUL extends the static, one-shot model update using influence unlearning to a dynamic, iterative unlearning process.","Our extensive experiments show that SOUL consistently outperforms conventional first-order methods across various unlearning tasks, models, and metrics, suggesting the promise of second-order optimization in providing a scalable and easily implementable solution for LLM unlearning."],"url":"http://arxiv.org/abs/2404.18239v1"}
{"created":"2024-04-28 16:29:22","title":"Flood Data Analysis on SpaceNet 8 Using Apache Sedona","abstract":"With the escalating frequency of floods posing persistent threats to human life and property, satellite remote sensing has emerged as an indispensable tool for monitoring flood hazards. SpaceNet8 offers a unique opportunity to leverage cutting-edge artificial intelligence technologies to assess these hazards. A significant contribution of this research is its application of Apache Sedona, an advanced platform specifically designed for the efficient and distributed processing of large-scale geospatial data. This platform aims to enhance the efficiency of error analysis, a critical aspect of improving flood damage detection accuracy. Based on Apache Sedona, we introduce a novel approach that addresses the challenges associated with inaccuracies in flood damage detection. This approach involves the retrieval of cases from historical flood events, the adaptation of these cases to current scenarios, and the revision of the model based on clustering algorithms to refine its performance. Through the replication of both the SpaceNet8 baseline and its top-performing models, we embark on a comprehensive error analysis. This analysis reveals several main sources of inaccuracies. To address these issues, we employ data visual interpretation and histogram equalization techniques, resulting in significant improvements in model metrics. After these enhancements, our indicators show a notable improvement, with precision up by 5%, F1 score by 2.6%, and IoU by 4.5%. This work highlights the importance of advanced geospatial data processing tools, such as Apache Sedona. By improving the accuracy and efficiency of flood detection, this research contributes to safeguarding public safety and strengthening infrastructure resilience in flood-prone areas, making it a valuable addition to the field of remote sensing and disaster management.","sentences":["With the escalating frequency of floods posing persistent threats to human life and property, satellite remote sensing has emerged as an indispensable tool for monitoring flood hazards.","SpaceNet8 offers a unique opportunity to leverage cutting-edge artificial intelligence technologies to assess these hazards.","A significant contribution of this research is its application of Apache Sedona, an advanced platform specifically designed for the efficient and distributed processing of large-scale geospatial data.","This platform aims to enhance the efficiency of error analysis, a critical aspect of improving flood damage detection accuracy.","Based on Apache Sedona, we introduce a novel approach that addresses the challenges associated with inaccuracies in flood damage detection.","This approach involves the retrieval of cases from historical flood events, the adaptation of these cases to current scenarios, and the revision of the model based on clustering algorithms to refine its performance.","Through the replication of both the SpaceNet8 baseline and its top-performing models, we embark on a comprehensive error analysis.","This analysis reveals several main sources of inaccuracies.","To address these issues, we employ data visual interpretation and histogram equalization techniques, resulting in significant improvements in model metrics.","After these enhancements, our indicators show a notable improvement, with precision up by 5%, F1 score by 2.6%, and IoU by 4.5%.","This work highlights the importance of advanced geospatial data processing tools, such as Apache Sedona.","By improving the accuracy and efficiency of flood detection, this research contributes to safeguarding public safety and strengthening infrastructure resilience in flood-prone areas, making it a valuable addition to the field of remote sensing and disaster management."],"url":"http://arxiv.org/abs/2404.18235v1"}
{"created":"2024-04-28 15:56:41","title":"From Persona to Personalization: A Survey on Role-Playing Language Agents","abstract":"Recent advancements in large language models (LLMs) have significantly boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI systems designed to simulate assigned personas. By harnessing multiple advanced abilities of LLMs, including in-context learning, instruction following, and social intelligence, RPLAs achieve a remarkable sense of human likeness and vivid role-playing performance. RPLAs can mimic a wide range of personas, ranging from historical figures and fictional characters to real-life individuals. Consequently, they have catalyzed numerous AI applications, such as emotional companions, interactive video games, personalized assistants and copilots, and digital clones. In this paper, we conduct a comprehensive survey of this field, illustrating the evolution and recent progress in RPLAs integrating with cutting-edge LLM technologies. We categorize personas into three types: 1) Demographic Persona, which leverages statistical stereotypes; 2) Character Persona, focused on well-established figures; and 3) Individualized Persona, customized through ongoing user interactions for personalized services. We begin by presenting a comprehensive overview of current methodologies for RPLAs, followed by the details for each persona type, covering corresponding data sourcing, agent construction, and evaluation. Afterward, we discuss the fundamental risks, existing limitations, and future prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI applications, which reflects practical user demands that shape and drive RPLA research. Through this work, we aim to establish a clear taxonomy of RPLA research and applications, and facilitate future research in this critical and ever-evolving field, and pave the way for a future where humans and RPLAs coexist in harmony.","sentences":["Recent advancements in large language models (LLMs) have significantly boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI systems designed to simulate assigned personas.","By harnessing multiple advanced abilities of LLMs, including in-context learning, instruction following, and social intelligence, RPLAs achieve a remarkable sense of human likeness and vivid role-playing performance.","RPLAs can mimic a wide range of personas, ranging from historical figures and fictional characters to real-life individuals.","Consequently, they have catalyzed numerous AI applications, such as emotional companions, interactive video games, personalized assistants and copilots, and digital clones.","In this paper, we conduct a comprehensive survey of this field, illustrating the evolution and recent progress in RPLAs integrating with cutting-edge LLM technologies.","We categorize personas into three types: 1) Demographic Persona, which leverages statistical stereotypes; 2) Character Persona, focused on well-established figures; and 3) Individualized Persona, customized through ongoing user interactions for personalized services.","We begin by presenting a comprehensive overview of current methodologies for RPLAs, followed by the details for each persona type, covering corresponding data sourcing, agent construction, and evaluation.","Afterward, we discuss the fundamental risks, existing limitations, and future prospects of RPLAs.","Additionally, we provide a brief review of RPLAs in AI applications, which reflects practical user demands that shape and drive RPLA research.","Through this work, we aim to establish a clear taxonomy of RPLA research and applications, and facilitate future research in this critical and ever-evolving field, and pave the way for a future where humans and RPLAs coexist in harmony."],"url":"http://arxiv.org/abs/2404.18231v1"}
{"created":"2024-04-28 15:44:57","title":"TextGram: Towards a better domain-adaptive pretraining","abstract":"For green AI, it is crucial to measure and reduce the carbon footprint emitted during the training of large language models. In NLP, performing pre-training on Transformer models requires significant computational resources. This pre-training involves using a large amount of text data to gain prior knowledge for performing downstream tasks. Thus, it is important that we select the correct data in the form of domain-specific data from this vast corpus to achieve optimum results aligned with our domain-specific tasks. While training on large unsupervised data is expensive, it can be optimized by performing a data selection step before pretraining. Selecting important data reduces the space overhead and the substantial amount of time required to pre-train the model while maintaining constant accuracy. We investigate the existing selection strategies and propose our own domain-adaptive data selection method - TextGram - that effectively selects essential data from large corpora. We compare and evaluate the results of finetuned models for text classification task with and without data selection. We show that the proposed strategy works better compared to other selection methods.","sentences":["For green AI, it is crucial to measure and reduce the carbon footprint emitted during the training of large language models.","In NLP, performing pre-training on Transformer models requires significant computational resources.","This pre-training involves using a large amount of text data to gain prior knowledge for performing downstream tasks.","Thus, it is important that we select the correct data in the form of domain-specific data from this vast corpus to achieve optimum results aligned with our domain-specific tasks.","While training on large unsupervised data is expensive, it can be optimized by performing a data selection step before pretraining.","Selecting important data reduces the space overhead and the substantial amount of time required to pre-train the model while maintaining constant accuracy.","We investigate the existing selection strategies and propose our own domain-adaptive data selection method - TextGram - that effectively selects essential data from large corpora.","We compare and evaluate the results of finetuned models for text classification task with and without data selection.","We show that the proposed strategy works better compared to other selection methods."],"url":"http://arxiv.org/abs/2404.18228v1"}
{"created":"2024-04-28 15:20:45","title":"L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi","abstract":"The availability of text or topic classification datasets in the low-resource Marathi language is limited, typically consisting of fewer than 4 target labels, with some achieving nearly perfect accuracy. In this work, we introduce L3Cube-MahaNews, a Marathi text classification corpus that focuses on News headlines and articles. This corpus stands out as the largest supervised Marathi Corpus, containing over 1.05L records classified into a diverse range of 12 categories. To accommodate different document lengths, MahaNews comprises three supervised datasets specifically designed for short text, long documents, and medium paragraphs. The consistent labeling across these datasets facilitates document length-based analysis. We provide detailed data statistics and baseline results on these datasets using state-of-the-art pre-trained BERT models. We conduct a comparative analysis between monolingual and multilingual BERT models, including MahaBERT, IndicBERT, and MuRIL. The monolingual MahaBERT model outperforms all others on every dataset. These resources also serve as Marathi topic classification datasets or models and are publicly available at https://github.com/l3cube-pune/MarathiNLP .","sentences":["The availability of text or topic classification datasets in the low-resource Marathi language is limited, typically consisting of fewer than 4 target labels, with some achieving nearly perfect accuracy.","In this work, we introduce L3Cube-MahaNews, a Marathi text classification corpus that focuses on News headlines and articles.","This corpus stands out as the largest supervised Marathi Corpus, containing over 1.05L records classified into a diverse range of 12 categories.","To accommodate different document lengths, MahaNews comprises three supervised datasets specifically designed for short text, long documents, and medium paragraphs.","The consistent labeling across these datasets facilitates document length-based analysis.","We provide detailed data statistics and baseline results on these datasets using state-of-the-art pre-trained BERT models.","We conduct a comparative analysis between monolingual and multilingual BERT models, including MahaBERT, IndicBERT, and MuRIL.","The monolingual MahaBERT model outperforms all others on every dataset.","These resources also serve as Marathi topic classification datasets or models and are publicly available at https://github.com/l3cube-pune/MarathiNLP ."],"url":"http://arxiv.org/abs/2404.18216v1"}
{"created":"2024-04-28 15:07:48","title":"A survey of dynamic graph neural networks","abstract":"Graph neural networks (GNNs) have emerged as a powerful tool for effectively mining and learning from graph-structured data, with applications spanning numerous domains. However, most research focuses on static graphs, neglecting the dynamic nature of real-world networks where topologies and attributes evolve over time. By integrating sequence modeling modules into traditional GNN architectures, dynamic GNNs aim to bridge this gap, capturing the inherent temporal dependencies of dynamic graphs for a more authentic depiction of complex networks. This paper provides a comprehensive review of the fundamental concepts, key techniques, and state-of-the-art dynamic GNN models. We present the mainstream dynamic GNN models in detail and categorize models based on how temporal information is incorporated. We also discuss large-scale dynamic GNNs and pre-training techniques. Although dynamic GNNs have shown superior performance, challenges remain in scalability, handling heterogeneous information, and lack of diverse graph datasets. The paper also discusses possible future directions, such as adaptive and memory-enhanced models, inductive learning, and theoretical analysis.","sentences":["Graph neural networks (GNNs) have emerged as a powerful tool for effectively mining and learning from graph-structured data, with applications spanning numerous domains.","However, most research focuses on static graphs, neglecting the dynamic nature of real-world networks where topologies and attributes evolve over time.","By integrating sequence modeling modules into traditional GNN architectures, dynamic GNNs aim to bridge this gap, capturing the inherent temporal dependencies of dynamic graphs for a more authentic depiction of complex networks.","This paper provides a comprehensive review of the fundamental concepts, key techniques, and state-of-the-art dynamic GNN models.","We present the mainstream dynamic GNN models in detail and categorize models based on how temporal information is incorporated.","We also discuss large-scale dynamic GNNs and pre-training techniques.","Although dynamic GNNs have shown superior performance, challenges remain in scalability, handling heterogeneous information, and lack of diverse graph datasets.","The paper also discusses possible future directions, such as adaptive and memory-enhanced models, inductive learning, and theoretical analysis."],"url":"http://arxiv.org/abs/2404.18211v1"}
{"created":"2024-04-28 15:04:54","title":"4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive Modeling on Relational DBs","abstract":"Although RDBs store vast amounts of rich, informative data spread across interconnected tables, the progress of predictive machine learning models as applied to such tasks arguably falls well behind advances in other domains such as computer vision or natural language processing. This deficit stems, at least in part, from the lack of established/public RDB benchmarks as needed for training and evaluation purposes. As a result, related model development thus far often defaults to tabular approaches trained on ubiquitous single-table benchmarks, or on the relational side, graph-based alternatives such as GNNs applied to a completely different set of graph datasets devoid of tabular characteristics. To more precisely target RDBs lying at the nexus of these two complementary regimes, we explore a broad class of baseline models predicated on: (i) converting multi-table datasets into graphs using various strategies equipped with efficient subsampling, while preserving tabular characteristics; and (ii) trainable models with well-matched inductive biases that output predictions based on these input subgraphs. Then, to address the dearth of suitable public benchmarks and reduce siloed comparisons, we assemble a diverse collection of (i) large-scale RDB datasets and (ii) coincident predictive tasks. From a delivery standpoint, we operationalize the above four dimensions (4D) of exploration within a unified, scalable open-source toolbox called 4DBInfer. We conclude by presenting evaluations using 4DBInfer, the results of which highlight the importance of considering each such dimension in the design of RDB predictive models, as well as the limitations of more naive approaches such as simply joining adjacent tables. Our source code is released at https://github.com/awslabs/multi-table-benchmark .","sentences":["Although RDBs store vast amounts of rich, informative data spread across interconnected tables, the progress of predictive machine learning models as applied to such tasks arguably falls well behind advances in other domains such as computer vision or natural language processing.","This deficit stems, at least in part, from the lack of established/public RDB benchmarks as needed for training and evaluation purposes.","As a result, related model development thus far often defaults to tabular approaches trained on ubiquitous single-table benchmarks, or on the relational side, graph-based alternatives such as GNNs applied to a completely different set of graph datasets devoid of tabular characteristics.","To more precisely target RDBs lying at the nexus of these two complementary regimes, we explore a broad class of baseline models predicated on: (i) converting multi-table datasets into graphs using various strategies equipped with efficient subsampling, while preserving tabular characteristics; and (ii) trainable models with well-matched inductive biases that output predictions based on these input subgraphs.","Then, to address the dearth of suitable public benchmarks and reduce siloed comparisons, we assemble a diverse collection of (i) large-scale RDB datasets and (ii) coincident predictive tasks.","From a delivery standpoint, we operationalize the above four dimensions (4D) of exploration within a unified, scalable open-source toolbox called 4DBInfer.","We conclude by presenting evaluations using 4DBInfer, the results of which highlight the importance of considering each such dimension in the design of RDB predictive models, as well as the limitations of more naive approaches such as simply joining adjacent tables.","Our source code is released at https://github.com/awslabs/multi-table-benchmark ."],"url":"http://arxiv.org/abs/2404.18209v1"}
