{"created":"2024-06-10 17:59:52","title":"Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation","abstract":"We introduce LlamaGen, a new family of image generation models that apply original ``next-token prediction'' paradigm of large language models to visual generation domain. It is an affirmative answer to whether vanilla autoregressive models, e.g., Llama, without inductive biases on visual signals can achieve state-of-the-art image generation performance if scaling properly. We reexamine design spaces of image tokenizers, scalability properties of image generation models, and their training data quality. The outcome of this exploration consists of: (1) An image tokenizer with downsample ratio of 16, reconstruction quality of 0.94 rFID and codebook usage of 97% on ImageNet benchmark. (2) A series of class-conditional image generation models ranging from 111M to 3.1B parameters, achieving 2.18 FID on ImageNet 256x256 benchmarks, outperforming the popular diffusion models such as LDM, DiT. (3) A text-conditional image generation model with 775M parameters, from two-stage training on LAION-COCO and high aesthetics quality images, demonstrating competitive performance of visual quality and text alignment. (4) We verify the effectiveness of LLM serving frameworks in optimizing the inference speed of image generation models and achieve 326% - 414% speedup. We release all models and codes to facilitate open-source community of visual generation and multimodal foundation models.","sentences":["We introduce LlamaGen, a new family of image generation models that apply original ``next-token prediction'' paradigm of large language models to visual generation domain.","It is an affirmative answer to whether vanilla autoregressive models, e.g., Llama, without inductive biases on visual signals can achieve state-of-the-art image generation performance if scaling properly.","We reexamine design spaces of image tokenizers, scalability properties of image generation models, and their training data quality.","The outcome of this exploration consists of: (1) An image tokenizer with downsample ratio of 16, reconstruction quality of 0.94 rFID and codebook usage of 97% on ImageNet benchmark.","(2) A series of class-conditional image generation models ranging from 111M to 3.1B parameters, achieving 2.18 FID on ImageNet 256x256 benchmarks, outperforming the popular diffusion models such as LDM, DiT. (3) A text-conditional image generation model with 775M parameters, from two-stage training on LAION-COCO and high aesthetics quality images, demonstrating competitive performance of visual quality and text alignment.","(4) We verify the effectiveness of LLM serving frameworks in optimizing the inference speed of image generation models and achieve 326% - 414% speedup.","We release all models and codes to facilitate open-source community of visual generation and multimodal foundation models."],"url":"http://arxiv.org/abs/2406.06525v1"}
{"created":"2024-06-10 17:58:48","title":"Decentralized Personalized Federated Learning","abstract":"This work tackles the challenges of data heterogeneity and communication limitations in decentralized federated learning. We focus on creating a collaboration graph that guides each client in selecting suitable collaborators for training personalized models that leverage their local data effectively. Our approach addresses these issues through a novel, communication-efficient strategy that enhances resource efficiency. Unlike traditional methods, our formulation identifies collaborators at a granular level by considering combinatorial relations of clients, enhancing personalization while minimizing communication overhead. We achieve this through a bi-level optimization framework that employs a constrained greedy algorithm, resulting in a resource-efficient collaboration graph for personalized learning. Extensive evaluation against various baselines across diverse datasets demonstrates the superiority of our method, named DPFL. DPFL consistently outperforms other approaches, showcasing its effectiveness in handling real-world data heterogeneity, minimizing communication overhead, enhancing resource efficiency, and building personalized models in decentralized federated learning scenarios.","sentences":["This work tackles the challenges of data heterogeneity and communication limitations in decentralized federated learning.","We focus on creating a collaboration graph that guides each client in selecting suitable collaborators for training personalized models that leverage their local data effectively.","Our approach addresses these issues through a novel, communication-efficient strategy that enhances resource efficiency.","Unlike traditional methods, our formulation identifies collaborators at a granular level by considering combinatorial relations of clients, enhancing personalization while minimizing communication overhead.","We achieve this through a bi-level optimization framework that employs a constrained greedy algorithm, resulting in a resource-efficient collaboration graph for personalized learning.","Extensive evaluation against various baselines across diverse datasets demonstrates the superiority of our method, named DPFL.","DPFL consistently outperforms other approaches, showcasing its effectiveness in handling real-world data heterogeneity, minimizing communication overhead, enhancing resource efficiency, and building personalized models in decentralized federated learning scenarios."],"url":"http://arxiv.org/abs/2406.06520v1"}
{"created":"2024-06-10 17:58:02","title":"Data Augmentation for Multivariate Time Series Classification: An Experimental Study","abstract":"Our study investigates the impact of data augmentation on the performance of multivariate time series models, focusing on datasets from the UCR archive. Despite the limited size of these datasets, we achieved classification accuracy improvements in 10 out of 13 datasets using the Rocket and InceptionTime models. This highlights the essential role of sufficient data in training effective models, paralleling the advancements seen in computer vision. Our work delves into adapting and applying existing methods in innovative ways to the domain of multivariate time series classification. Our comprehensive exploration of these techniques sets a new standard for addressing data scarcity in time series analysis, emphasizing that diverse augmentation strategies are crucial for unlocking the potential of both traditional and deep learning models. Moreover, by meticulously analyzing and applying a variety of augmentation techniques, we demonstrate that strategic data enrichment can enhance model accuracy. This not only establishes a benchmark for future research in time series analysis but also underscores the importance of adopting varied augmentation approaches to improve model performance in the face of limited data availability.","sentences":["Our study investigates the impact of data augmentation on the performance of multivariate time series models, focusing on datasets from the UCR archive.","Despite the limited size of these datasets, we achieved classification accuracy improvements in 10 out of 13 datasets using the Rocket and InceptionTime models.","This highlights the essential role of sufficient data in training effective models, paralleling the advancements seen in computer vision.","Our work delves into adapting and applying existing methods in innovative ways to the domain of multivariate time series classification.","Our comprehensive exploration of these techniques sets a new standard for addressing data scarcity in time series analysis, emphasizing that diverse augmentation strategies are crucial for unlocking the potential of both traditional and deep learning models.","Moreover, by meticulously analyzing and applying a variety of augmentation techniques, we demonstrate that strategic data enrichment can enhance model accuracy.","This not only establishes a benchmark for future research in time series analysis but also underscores the importance of adopting varied augmentation approaches to improve model performance in the face of limited data availability."],"url":"http://arxiv.org/abs/2406.06518v1"}
{"created":"2024-06-10 17:54:57","title":"Random Features Approximation for Control-Affine Systems","abstract":"Modern data-driven control applications call for flexible nonlinear models that are amenable to principled controller synthesis and realtime feedback. Many nonlinear dynamical systems of interest are control affine. We propose two novel classes of nonlinear feature representations which capture control affine structure while allowing for arbitrary complexity in the state dependence. Our methods make use of random features (RF) approximations, inheriting the expressiveness of kernel methods at a lower computational cost. We formalize the representational capabilities of our methods by showing their relationship to the Affine Dot Product (ADP) kernel proposed by Casta\\~neda et al. (2021) and a novel Affine Dense (AD) kernel that we introduce. We further illustrate the utility by presenting a case study of data-driven optimization-based control using control certificate functions (CCF). Simulation experiments on a double pendulum empirically demonstrate the advantages of our methods.","sentences":["Modern data-driven control applications call for flexible nonlinear models that are amenable to principled controller synthesis and realtime feedback.","Many nonlinear dynamical systems of interest are control affine.","We propose two novel classes of nonlinear feature representations which capture control affine structure while allowing for arbitrary complexity in the state dependence.","Our methods make use of random features (RF) approximations, inheriting the expressiveness of kernel methods at a lower computational cost.","We formalize the representational capabilities of our methods by showing their relationship to the Affine Dot Product (ADP) kernel proposed by Casta\\~neda et al. (2021) and a novel Affine Dense (AD) kernel that we introduce.","We further illustrate the utility by presenting a case study of data-driven optimization-based control using control certificate functions (CCF).","Simulation experiments on a double pendulum empirically demonstrate the advantages of our methods."],"url":"http://arxiv.org/abs/2406.06514v1"}
{"created":"2024-06-10 17:53:01","title":"Merlin: A Vision Language Foundation Model for 3D Computed Tomography","abstract":"Over 85 million computed tomography (CT) scans are performed annually in the US, of which approximately one quarter focus on the abdomen. Given the current radiologist shortage, there is a large impetus to use artificial intelligence to alleviate the burden of interpreting these complex imaging studies. Prior state-of-the-art approaches for automated medical image interpretation leverage vision language models (VLMs). However, current medical VLMs are generally limited to 2D images and short reports, and do not leverage electronic health record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes (1.8+ million codes), and radiology reports (6+ million tokens). We evaluate Merlin on 6 task types and 752 individual tasks. The non-adapted (off-the-shelf) tasks include zero-shot findings classification (31 findings), phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval (image to findings and image to impressions), while model adapted tasks include 5-year disease prediction (6 diseases), radiology report generation, and 3D semantic segmentation (20 organs). We perform internal validation on a test set of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant evaluations, we assess the efficacy of various network architectures and training strategies to depict that Merlin has favorable performance to existing task-specific baselines. We derive data scaling laws to empirically assess training data needs for requisite downstream task performance. Furthermore, unlike conventional VLMs that require hundreds of GPUs for training, we perform all training on a single GPU.","sentences":["Over 85 million computed tomography (CT) scans are performed annually in the US, of which approximately one quarter focus on the abdomen.","Given the current radiologist shortage, there is a large impetus to use artificial intelligence to alleviate the burden of interpreting these complex imaging studies.","Prior state-of-the-art approaches for automated medical image interpretation leverage vision language models (VLMs).","However, current medical VLMs are generally limited to 2D images and short reports, and do not leverage electronic health record (EHR) data for supervision.","We introduce Merlin - a 3D VLM that we train using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes (1.8+ million codes), and radiology reports (6+ million tokens).","We evaluate Merlin on 6 task types and 752 individual tasks.","The non-adapted (off-the-shelf) tasks include zero-shot findings classification (31 findings), phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval (image to findings and image to impressions), while model adapted tasks include 5-year disease prediction (6 diseases), radiology report generation, and 3D semantic segmentation (20 organs).","We perform internal validation on a test set of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public CT datasets (VerSe, TotalSegmentator).","Beyond these clinically-relevant evaluations, we assess the efficacy of various network architectures and training strategies to depict that Merlin has favorable performance to existing task-specific baselines.","We derive data scaling laws to empirically assess training data needs for requisite downstream task performance.","Furthermore, unlike conventional VLMs that require hundreds of GPUs for training, we perform all training on a single GPU."],"url":"http://arxiv.org/abs/2406.06512v1"}
{"created":"2024-06-10 17:48:36","title":"Robust Distribution Learning with Local and Global Adversarial Corruptions","abstract":"We consider learning in an adversarial environment, where an $\\varepsilon$-fraction of samples from a distribution $P$ are arbitrarily modified (*global* corruptions) and the remaining perturbations have average magnitude bounded by $\\rho$ (*local* corruptions). Given access to $n$ such corrupted samples, we seek a computationally efficient estimator $\\hat{P}_n$ that minimizes the Wasserstein distance $\\mathsf{W}_1(\\hat{P}_n,P)$. In fact, we attack the fine-grained task of minimizing $\\mathsf{W}_1(\\Pi_\\# \\hat{P}_n, \\Pi_\\# P)$ for all orthogonal projections $\\Pi \\in \\mathbb{R}^{d \\times d}$, with performance scaling with $\\mathrm{rank}(\\Pi) = k$. This allows us to account simultaneously for mean estimation ($k=1$), distribution estimation ($k=d$), as well as the settings interpolating between these two extremes. We characterize the optimal population-limit risk for this task and then develop an efficient finite-sample algorithm with error bounded by $\\sqrt{\\varepsilon k} + \\rho + d^{O(1)}\\tilde{O}(n^{-1/k})$ when $P$ has bounded moments of order $2+\\delta$, for constant $\\delta > 0$. For data distributions with bounded covariance, our finite-sample bounds match the minimax population-level optimum for large sample sizes. Our efficient procedure relies on a novel trace norm approximation of an ideal yet intractable 2-Wasserstein projection estimator. We apply this algorithm to robust stochastic optimization, and, in the process, uncover a new method for overcoming the curse of dimensionality in Wasserstein distributionally robust optimization.","sentences":["We consider learning in an adversarial environment, where an $\\varepsilon$-fraction of samples from a distribution $P$ are arbitrarily modified (*global* corruptions) and the remaining perturbations have average magnitude bounded by $\\rho$ (*local* corruptions).","Given access to $n$ such corrupted samples, we seek a computationally efficient estimator $\\hat{P}_n$ that minimizes the Wasserstein distance $\\mathsf{W}_1(\\hat{P}_n,P)$. In fact, we attack the fine-grained task of minimizing $\\mathsf{W}_1(\\Pi_\\# \\hat{P}_n, \\Pi_\\# P)$ for all orthogonal projections $\\Pi \\in \\mathbb{R}^{d \\times d}$, with performance scaling with $\\mathrm{rank}(\\Pi)","= k$.","This allows us to account simultaneously for mean estimation ($k=1$), distribution estimation ($k=d$), as well as the settings interpolating between these two extremes.","We characterize the optimal population-limit risk for this task and then develop an efficient finite-sample algorithm with error bounded by $\\sqrt{\\varepsilon k} + \\rho + d^{O(1)}\\tilde{O}(n^{-1/k})$ when $P$ has bounded moments of order $2+\\delta$, for constant $\\delta > 0$.","For data distributions with bounded covariance, our finite-sample bounds match the minimax population-level optimum for large sample sizes.","Our efficient procedure relies on a novel trace norm approximation of an ideal yet intractable 2-Wasserstein projection estimator.","We apply this algorithm to robust stochastic optimization, and, in the process, uncover a new method for overcoming the curse of dimensionality in Wasserstein distributionally robust optimization."],"url":"http://arxiv.org/abs/2406.06509v1"}
{"created":"2024-06-10 17:20:13","title":"Graph-Based Bidirectional Transformer Decision Threshold Adjustment Algorithm for Class-Imbalanced Molecular Data","abstract":"Data sets with imbalanced class sizes, often where one class size is much smaller than that of others, occur extremely often in various applications, including those with biological foundations, such as drug discovery and disease diagnosis. Thus, it is extremely important to be able to identify data elements of classes of various sizes, as a failure to detect can result in heavy costs. However, many data classification algorithms do not perform well on imbalanced data sets as they often fail to detect elements belonging to underrepresented classes. In this paper, we propose the BTDT-MBO algorithm, incorporating Merriman-Bence-Osher (MBO) techniques and a bidirectional transformer, as well as distance correlation and decision threshold adjustments, for data classification problems on highly imbalanced molecular data sets, where the sizes of the classes vary greatly. The proposed method not only integrates adjustments in the classification threshold for the MBO algorithm in order to help deal with the class imbalance, but also uses a bidirectional transformer model based on an attention mechanism for self-supervised learning. Additionally, the method implements distance correlation as a weight function for the similarity graph-based framework on which the adjusted MBO algorithm operates. The proposed model is validated using six molecular data sets, and we also provide a thorough comparison to other competing algorithms. The computational experiments show that the proposed method performs better than competing techniques even when the class imbalance ratio is very high.","sentences":["Data sets with imbalanced class sizes, often where one class size is much smaller than that of others, occur extremely often in various applications, including those with biological foundations, such as drug discovery and disease diagnosis.","Thus, it is extremely important to be able to identify data elements of classes of various sizes, as a failure to detect can result in heavy costs.","However, many data classification algorithms do not perform well on imbalanced data sets as they often fail to detect elements belonging to underrepresented classes.","In this paper, we propose the BTDT-MBO algorithm, incorporating Merriman-Bence-Osher (MBO) techniques and a bidirectional transformer, as well as distance correlation and decision threshold adjustments, for data classification problems on highly imbalanced molecular data sets, where the sizes of the classes vary greatly.","The proposed method not only integrates adjustments in the classification threshold for the MBO algorithm in order to help deal with the class imbalance, but also uses a bidirectional transformer model based on an attention mechanism for self-supervised learning.","Additionally, the method implements distance correlation as a weight function for the similarity graph-based framework on which the adjusted MBO algorithm operates.","The proposed model is validated using six molecular data sets, and we also provide a thorough comparison to other competing algorithms.","The computational experiments show that the proposed method performs better than competing techniques even when the class imbalance ratio is very high."],"url":"http://arxiv.org/abs/2406.06479v1"}
{"created":"2024-06-10 17:16:49","title":"Towards a Personal Health Large Language Model","abstract":"In health, most large language model (LLM) research has focused on clinical tasks. However, mobile and wearable devices, which are rarely integrated into such tasks, provide rich, longitudinal data for personal health monitoring. Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from Gemini for understanding and reasoning over numerical time-series personal health data. We created and curated three datasets that test 1) production of personalized insights and recommendations from sleep patterns, physical activity, and physiological responses, 2) expert domain knowledge, and 3) prediction of self-reported sleep outcomes. For the first task we designed 857 case studies in collaboration with domain experts to assess real-world scenarios in sleep and fitness. Through comprehensive evaluation of domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness and, while experts remain superior for sleep, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. We evaluated PH-LLM domain knowledge using multiple choice sleep medicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on fitness, exceeding average scores from a sample of human experts. Finally, we trained PH-LLM to predict self-reported sleep quality outcomes from textual and multimodal encoding representations of wearable data, and demonstrate that multimodal encoding is required to match performance of specialized discriminative models. Although further development and evaluation are necessary in the safety-critical personal health domain, these results demonstrate both the broad knowledge and capabilities of Gemini models and the benefit of contextualizing physiological data for personal health applications as done with PH-LLM.","sentences":["In health, most large language model (LLM) research has focused on clinical tasks.","However, mobile and wearable devices, which are rarely integrated into such tasks, provide rich, longitudinal data for personal health monitoring.","Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from Gemini for understanding and reasoning over numerical time-series personal health data.","We created and curated three datasets that test 1) production of personalized insights and recommendations from sleep patterns, physical activity, and physiological responses, 2) expert domain knowledge, and 3) prediction of self-reported sleep outcomes.","For the first task we designed 857 case studies in collaboration with domain experts to assess real-world scenarios in sleep and fitness.","Through comprehensive evaluation of domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness and, while experts remain superior for sleep, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights.","We evaluated PH-LLM domain knowledge using multiple choice sleep medicine and fitness examinations.","PH-LLM achieved 79% on sleep and 88% on fitness, exceeding average scores from a sample of human experts.","Finally, we trained PH-LLM to predict self-reported sleep quality outcomes from textual and multimodal encoding representations of wearable data, and demonstrate that multimodal encoding is required to match performance of specialized discriminative models.","Although further development and evaluation are necessary in the safety-critical personal health domain, these results demonstrate both the broad knowledge and capabilities of Gemini models and the benefit of contextualizing physiological data for personal health applications as done with PH-LLM."],"url":"http://arxiv.org/abs/2406.06474v1"}
{"created":"2024-06-10 17:14:53","title":"DiffAudit: Auditing Privacy Practices of Online Services for Children and Adolescents","abstract":"Children's and adolescents' online data privacy are regulated by laws such as the Children's Online Privacy Protection Act (COPPA) and the California Consumer Privacy Act (CCPA). Online services that are directed towards general audiences (i.e., including children, adolescents, and adults) must comply with these laws. In this paper, first, we present DiffAudit, a platform-agnostic privacy auditing methodology for general audience services. DiffAudit performs differential analysis of network traffic data flows to compare data processing practices (i) between child, adolescent, and adult users and (ii) before and after consent is given and user age is disclosed. We also present a data type classification method that utilizes GPT-4 and our data type ontology based on COPPA and CCPA, allowing us to identify considerably more data types than prior work. Second, we apply DiffAudit to a set of popular general audience mobile and web services and observe a rich set of behaviors extracted from over 440K outgoing requests, containing 3,968 unique data types we extracted and classified. We reveal problematic data processing practices prior to consent and age disclosure, lack of differentiation between age-specific data flows, inconsistent privacy policy disclosures, and sharing of linkable data with third parties, including advertising and tracking services.","sentences":["Children's and adolescents' online data privacy are regulated by laws such as the Children's Online Privacy Protection Act (COPPA) and the California Consumer Privacy Act (CCPA).","Online services that are directed towards general audiences (i.e., including children, adolescents, and adults) must comply with these laws.","In this paper, first, we present DiffAudit, a platform-agnostic privacy auditing methodology for general audience services.","DiffAudit performs differential analysis of network traffic data flows to compare data processing practices (i) between child, adolescent, and adult users and (ii) before and after consent is given and user age is disclosed.","We also present a data type classification method that utilizes GPT-4 and our data type ontology based on COPPA and CCPA, allowing us to identify considerably more data types than prior work.","Second, we apply DiffAudit to a set of popular general audience mobile and web services and observe a rich set of behaviors extracted from over 440K outgoing requests, containing 3,968 unique data types we extracted and classified.","We reveal problematic data processing practices prior to consent and age disclosure, lack of differentiation between age-specific data flows, inconsistent privacy policy disclosures, and sharing of linkable data with third parties, including advertising and tracking services."],"url":"http://arxiv.org/abs/2406.06473v1"}
{"created":"2024-06-10 17:09:38","title":"GKAN: Graph Kolmogorov-Arnold Networks","abstract":"We introduce Graph Kolmogorov-Arnold Networks (GKAN), an innovative neural network architecture that extends the principles of the recently proposed Kolmogorov-Arnold Networks (KAN) to graph-structured data. By adopting the unique characteristics of KANs, notably the use of learnable univariate functions instead of fixed linear weights, we develop a powerful model for graph-based learning tasks. Unlike traditional Graph Convolutional Networks (GCNs) that rely on a fixed convolutional architecture, GKANs implement learnable spline-based functions between layers, transforming the way information is processed across the graph structure. We present two different ways to incorporate KAN layers into GKAN: architecture 1 -- where the learnable functions are applied to input features after aggregation and architecture 2 -- where the learnable functions are applied to input features before aggregation. We evaluate GKAN empirically using a semi-supervised graph learning task on a real-world dataset (Cora). We find that architecture generally performs better. We find that GKANs achieve higher accuracy in semi-supervised learning tasks on graphs compared to the traditional GCN model. For example, when considering 100 features, GCN provides an accuracy of 53.5 while a GKAN with a comparable number of parameters gives an accuracy of 61.76; with 200 features, GCN provides an accuracy of 61.24 while a GKAN with a comparable number of parameters gives an accuracy of 67.66. We also present results on the impact of various parameters such as the number of hidden nodes, grid-size, and the polynomial-degree of the spline on the performance of GKAN.","sentences":["We introduce Graph Kolmogorov-Arnold Networks (GKAN), an innovative neural network architecture that extends the principles of the recently proposed Kolmogorov-Arnold Networks (KAN) to graph-structured data.","By adopting the unique characteristics of KANs, notably the use of learnable univariate functions instead of fixed linear weights, we develop a powerful model for graph-based learning tasks.","Unlike traditional Graph Convolutional Networks (GCNs) that rely on a fixed convolutional architecture, GKANs implement learnable spline-based functions between layers, transforming the way information is processed across the graph structure.","We present two different ways to incorporate KAN layers into GKAN: architecture 1 -- where the learnable functions are applied to input features after aggregation and architecture 2 -- where the learnable functions are applied to input features before aggregation.","We evaluate GKAN empirically using a semi-supervised graph learning task on a real-world dataset (Cora).","We find that architecture generally performs better.","We find that GKANs achieve higher accuracy in semi-supervised learning tasks on graphs compared to the traditional GCN model.","For example, when considering 100 features, GCN provides an accuracy of 53.5 while a GKAN with a comparable number of parameters gives an accuracy of 61.76; with 200 features, GCN provides an accuracy of 61.24 while a GKAN with a comparable number of parameters gives an accuracy of 67.66.","We also present results on the impact of various parameters such as the number of hidden nodes, grid-size, and the polynomial-degree of the spline on the performance of GKAN."],"url":"http://arxiv.org/abs/2406.06470v1"}
{"created":"2024-06-10 17:07:25","title":"Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning","abstract":"Language agents perform complex tasks by using tools to execute each step precisely. However, most existing agents are based on proprietary models or designed to target specific tasks, such as mathematics or multi-hop question answering. We introduce Husky, a holistic, open-source language agent that learns to reason over a unified action space to address a diverse set of complex tasks involving numerical, tabular, and knowledge-based reasoning. Husky iterates between two stages: 1) generating the next action to take towards solving a given task and 2) executing the action using expert models and updating the current solution state. We identify a thorough ontology of actions for addressing complex tasks and curate high-quality data to train expert models for executing these actions. Our experiments show that Husky outperforms prior language agents across 14 evaluation datasets. Moreover, we introduce HuskyQA, a new evaluation set which stress tests language agents for mixed-tool reasoning, with a focus on retrieving missing knowledge and performing numerical reasoning. Despite using 7B models, Husky matches or even exceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of our holistic approach in addressing complex reasoning problems. Our code and models are available at https://github.com/agent-husky/Husky-v1.","sentences":["Language agents perform complex tasks by using tools to execute each step precisely.","However, most existing agents are based on proprietary models or designed to target specific tasks, such as mathematics or multi-hop question answering.","We introduce Husky, a holistic, open-source language agent that learns to reason over a unified action space to address a diverse set of complex tasks involving numerical, tabular, and knowledge-based reasoning.","Husky iterates between two stages: 1) generating the next action to take towards solving a given task and 2) executing the action using expert models and updating the current solution state.","We identify a thorough ontology of actions for addressing complex tasks and curate high-quality data to train expert models for executing these actions.","Our experiments show that Husky outperforms prior language agents across 14 evaluation datasets.","Moreover, we introduce HuskyQA, a new evaluation set which stress tests language agents for mixed-tool reasoning, with a focus on retrieving missing knowledge and performing numerical reasoning.","Despite using 7B models, Husky matches or even exceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of our holistic approach in addressing complex reasoning problems.","Our code and models are available at https://github.com/agent-husky/Husky-v1."],"url":"http://arxiv.org/abs/2406.06469v1"}
{"created":"2024-06-10 17:06:35","title":"Randomized Binary and Tree Search under Pressure","abstract":"We study a generalized binary search problem on the line and general trees. On the line (e.g., a sorted array), binary search finds a target node in $O(\\log n)$ queries in the worst case, where $n$ is the number of nodes. In situations with limited budget or time, we might only be able to perform a few queries, possibly sub-logarithmic many. In this case, it is impossible to guarantee that the target will be found regardless of its position. Our main result is the construction of a randomized strategy that maximizes the minimum (over the target position) probability of finding the target. Such a strategy provides a natural solution where there is no apriori (stochastic) information of the target's position. As with regular binary search, we can find and run the strategy in $O(\\log n)$ time (and using only $O(\\log n)$ random bits). Our construction is obtained by reinterpreting the problem as a two-player (\\textit{seeker} and \\textit{hider}) zero-sum game and exploiting an underlying number theoretical structure.   Furthermore, we generalize the setting to study a search game on trees. In this case, a query returns the edge's endpoint closest to the target. Again, when the number of queries is bounded by some given $k$, we quantify a \\emph{the-less-queries-the-better} approach by defining a seeker's profit $p$ depending on the number of queries needed to locate the hider. For the linear programming formulation of the corresponding zero-sum game, we show that computing the best response for the hider (i.e., the separation problem of the underlying dual LP) can be done in time $O(n^2 2^{2k})$, where $n$ is the size of the tree. This result allows to compute a Nash equilibrium in polynomial time whenever $k=O(\\log n)$. In contrast, computing the best response for the hider is NP-hard.","sentences":["We study a generalized binary search problem on the line and general trees.","On the line (e.g., a sorted array), binary search finds a target node in $O(\\log n)$ queries in the worst case, where $n$ is the number of nodes.","In situations with limited budget or time, we might only be able to perform a few queries, possibly sub-logarithmic many.","In this case, it is impossible to guarantee that the target will be found regardless of its position.","Our main result is the construction of a randomized strategy that maximizes the minimum (over the target position) probability of finding the target.","Such a strategy provides a natural solution where there is no apriori (stochastic) information of the target's position.","As with regular binary search, we can find and run the strategy in $O(\\log n)$ time (and using only $O(\\log n)$ random bits).","Our construction is obtained by reinterpreting the problem as a two-player (\\textit{seeker} and \\textit{hider}) zero-sum game and exploiting an underlying number theoretical structure.   ","Furthermore, we generalize the setting to study a search game on trees.","In this case, a query returns the edge's endpoint closest to the target.","Again, when the number of queries is bounded by some given $k$, we quantify a \\emph{the-less-queries-the-better} approach by defining a seeker's profit $p$ depending on the number of queries needed to locate the hider.","For the linear programming formulation of the corresponding zero-sum game, we show that computing the best response for the hider (i.e., the separation problem of the underlying dual LP) can be done in time $O(n^2 2^{2k})$, where $n$ is the size of the tree.","This result allows to compute a Nash equilibrium in polynomial time whenever $k=O(\\log n)$. In contrast, computing the best response for the hider is NP-hard."],"url":"http://arxiv.org/abs/2406.06468v1"}
{"created":"2024-06-10 17:02:08","title":"AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction","abstract":"Text-guided video prediction (TVP) involves predicting the motion of future frames from the initial frame according to an instruction, which has wide applications in virtual reality, robotics, and content creation. Previous TVP methods make significant breakthroughs by adapting Stable Diffusion for this task. However, they struggle with frame consistency and temporal stability primarily due to the limited scale of video datasets. We observe that pretrained Image2Video diffusion models possess good priors for video dynamics but they lack textual control. Hence, transferring Image2Video models to leverage their video dynamic priors while injecting instruction control to generate controllable videos is both a meaningful and challenging task. To achieve this, we introduce the Multi-Modal Large Language Model (MLLM) to predict future video states based on initial frames and text instructions. More specifically, we design a dual query transformer (DQFormer) architecture, which integrates the instructions and frames into the conditional embeddings for future frame prediction. Additionally, we develop Long-Short Term Temporal Adapters and Spatial Adapters that can quickly transfer general video diffusion models to specific scenarios with minimal training costs. Experimental results show that our method significantly outperforms state-of-the-art techniques on four datasets: Something Something V2, Epic Kitchen-100, Bridge Data, and UCF-101. Notably, AID achieves 91.2% and 55.5% FVD improvements on Bridge and SSv2 respectively, demonstrating its effectiveness in various domains. More examples can be found at our website https://chenhsing.github.io/AID.","sentences":["Text-guided video prediction (TVP) involves predicting the motion of future frames from the initial frame according to an instruction, which has wide applications in virtual reality, robotics, and content creation.","Previous TVP methods make significant breakthroughs by adapting Stable Diffusion for this task.","However, they struggle with frame consistency and temporal stability primarily due to the limited scale of video datasets.","We observe that pretrained Image2Video diffusion models possess good priors for video dynamics but they lack textual control.","Hence, transferring Image2Video models to leverage their video dynamic priors while injecting instruction control to generate controllable videos is both a meaningful and challenging task.","To achieve this, we introduce the Multi-Modal Large Language Model (MLLM) to predict future video states based on initial frames and text instructions.","More specifically, we design a dual query transformer (DQFormer) architecture, which integrates the instructions and frames into the conditional embeddings for future frame prediction.","Additionally, we develop Long-Short Term Temporal Adapters and Spatial Adapters that can quickly transfer general video diffusion models to specific scenarios with minimal training costs.","Experimental results show that our method significantly outperforms state-of-the-art techniques on four datasets: Something Something V2, Epic Kitchen-100, Bridge Data, and UCF-101.","Notably, AID achieves 91.2% and 55.5% FVD improvements on Bridge and SSv2 respectively, demonstrating its effectiveness in various domains.","More examples can be found at our website https://chenhsing.github.io/AID."],"url":"http://arxiv.org/abs/2406.06465v1"}
{"created":"2024-06-10 17:00:54","title":"Transforming Wearable Data into Health Insights using Large Language Model Agents","abstract":"Despite the proliferation of wearable health trackers and the importance of sleep and exercise to health, deriving actionable personalized insights from wearable data remains a challenge because doing so requires non-trivial open-ended analysis of these data. The recent rise of large language model (LLM) agents, which can use tools to reason about and interact with the world, presents a promising opportunity to enable such personalized analysis at scale. Yet, the application of LLM agents in analyzing personal health is still largely untapped. In this paper, we introduce the Personal Health Insights Agent (PHIA), an agent system that leverages state-of-the-art code generation and information retrieval tools to analyze and interpret behavioral health data from wearables. We curate two benchmark question-answering datasets of over 4000 health insights questions. Based on 650 hours of human and expert evaluation we find that PHIA can accurately address over 84% of factual numerical questions and more than 83% of crowd-sourced open-ended questions. This work has implications for advancing behavioral health across the population, potentially enabling individuals to interpret their own wearable data, and paving the way for a new era of accessible, personalized wellness regimens that are informed by data-driven insights.","sentences":["Despite the proliferation of wearable health trackers and the importance of sleep and exercise to health, deriving actionable personalized insights from wearable data remains a challenge because doing so requires non-trivial open-ended analysis of these data.","The recent rise of large language model (LLM) agents, which can use tools to reason about and interact with the world, presents a promising opportunity to enable such personalized analysis at scale.","Yet, the application of LLM agents in analyzing personal health is still largely untapped.","In this paper, we introduce the Personal Health Insights Agent (PHIA), an agent system that leverages state-of-the-art code generation and information retrieval tools to analyze and interpret behavioral health data from wearables.","We curate two benchmark question-answering datasets of over 4000 health insights questions.","Based on 650 hours of human and expert evaluation we find that PHIA can accurately address over 84% of factual numerical questions and more than 83% of crowd-sourced open-ended questions.","This work has implications for advancing behavioral health across the population, potentially enabling individuals to interpret their own wearable data, and paving the way for a new era of accessible, personalized wellness regimens that are informed by data-driven insights."],"url":"http://arxiv.org/abs/2406.06464v1"}
{"created":"2024-06-10 16:58:48","title":"VCR: Visual Caption Restoration","abstract":"We introduce Visual Caption Restoration (VCR), a novel vision-language task that challenges models to accurately restore partially obscured texts using pixel-level hints within images. This task stems from the observation that text embedded in images is intrinsically different from common visual elements and natural language due to the need to align the modalities of vision, text, and text embedded in images. While numerous works have integrated text embedded in images into visual question-answering tasks, approaches to these tasks generally rely on optical character recognition or masked language modeling, thus reducing the task to mainly text-based processing. However, text-based processing becomes ineffective in VCR as accurate text restoration depends on the combined information from provided images, context, and subtle cues from the tiny exposed areas of masked texts. We develop a pipeline to generate synthetic images for the VCR task using image-caption pairs, with adjustable caption visibility to control the task difficulty. With this pipeline, we construct a dataset for VCR called VCR-Wiki using images with captions from Wikipedia, comprising 2.11M English and 346K Chinese entities in both easy and hard split variants. Our results reveal that current vision language models significantly lag behind human performance in the VCR task, and merely fine-tuning the models on our dataset does not lead to notable improvements. We release VCR-Wiki and the data construction code to facilitate future research.","sentences":["We introduce Visual Caption Restoration (VCR), a novel vision-language task that challenges models to accurately restore partially obscured texts using pixel-level hints within images.","This task stems from the observation that text embedded in images is intrinsically different from common visual elements and natural language due to the need to align the modalities of vision, text, and text embedded in images.","While numerous works have integrated text embedded in images into visual question-answering tasks, approaches to these tasks generally rely on optical character recognition or masked language modeling, thus reducing the task to mainly text-based processing.","However, text-based processing becomes ineffective in VCR as accurate text restoration depends on the combined information from provided images, context, and subtle cues from the tiny exposed areas of masked texts.","We develop a pipeline to generate synthetic images for the VCR task using image-caption pairs, with adjustable caption visibility to control the task difficulty.","With this pipeline, we construct a dataset for VCR called VCR-Wiki using images with captions from Wikipedia, comprising 2.11M English and 346K Chinese entities in both easy and hard split variants.","Our results reveal that current vision language models significantly lag behind human performance in the VCR task, and merely fine-tuning the models on our dataset does not lead to notable improvements.","We release VCR-Wiki and the data construction code to facilitate future research."],"url":"http://arxiv.org/abs/2406.06462v1"}
{"created":"2024-06-10 16:53:58","title":"How Useful is Intermittent, Asynchronous Expert Feedback for Bayesian Optimization?","abstract":"Bayesian optimization (BO) is an integral part of automated scientific discovery -- the so-called self-driving lab -- where human inputs are ideally minimal or at least non-blocking. However, scientists often have strong intuition, and thus human feedback is still useful. Nevertheless, prior works in enhancing BO with expert feedback, such as by incorporating it in an offline or online but blocking (arrives at each BO iteration) manner, are incompatible with the spirit of self-driving labs. In this work, we study whether a small amount of randomly arriving expert feedback that is being incorporated in a non-blocking manner can improve a BO campaign. To this end, we run an additional, independent computing thread on top of the BO loop to handle the feedback-gathering process. The gathered feedback is used to learn a Bayesian preference model that can readily be incorporated into the BO thread, to steer its exploration-exploitation process. Experiments on toy and chemistry datasets suggest that even just a few intermittent, asynchronous expert feedback can be useful for improving or constraining BO. This can especially be useful for its implication in improving self-driving labs, e.g. making them more data-efficient and less costly.","sentences":["Bayesian optimization (BO) is an integral part of automated scientific discovery -- the so-called self-driving lab -- where human inputs are ideally minimal or at least non-blocking.","However, scientists often have strong intuition, and thus human feedback is still useful.","Nevertheless, prior works in enhancing BO with expert feedback, such as by incorporating it in an offline or online but blocking (arrives at each BO iteration) manner, are incompatible with the spirit of self-driving labs.","In this work, we study whether a small amount of randomly arriving expert feedback that is being incorporated in a non-blocking manner can improve a BO campaign.","To this end, we run an additional, independent computing thread on top of the BO loop to handle the feedback-gathering process.","The gathered feedback is used to learn a Bayesian preference model that can readily be incorporated into the BO thread, to steer its exploration-exploitation process.","Experiments on toy and chemistry datasets suggest that even just a few intermittent, asynchronous expert feedback can be useful for improving or constraining BO.","This can especially be useful for its implication in improving self-driving labs, e.g. making them more data-efficient and less costly."],"url":"http://arxiv.org/abs/2406.06459v1"}
{"created":"2024-06-10 16:44:48","title":"A Large Language Model Pipeline for Breast Cancer Oncology","abstract":"Large language models (LLMs) have demonstrated potential in the innovation of many disciplines. However, how they can best be developed for oncology remains underdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical dataset and clinical guidelines text corpus for two important cancer treatment factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain prompt engineering pipeline. A high accuracy (0.85+) was achieved in the classification of adjuvant radiation therapy and chemotherapy for breast cancer patients. Furthermore, a confidence interval was formed from observational data on the quality of treatment from human oncologists to estimate the proportion of scenarios in which the model must outperform the original oncologist in its treatment prediction to be a better solution overall as 8.2% to 13.3%. Due to indeterminacy in the outcomes of cancer treatment decisions, future investigation, potentially a clinical trial, would be required to determine if this threshold was met by the models. Nevertheless, with 85% of U.S. cancer patients receiving treatment at local community facilities, these kinds of models could play an important part in expanding access to quality care with outcomes that lie, at minimum, close to a human oncologist.","sentences":["Large language models (LLMs) have demonstrated potential in the innovation of many disciplines.","However, how they can best be developed for oncology remains underdeveloped.","State-of-the-art OpenAI models were fine-tuned on a clinical dataset and clinical guidelines text corpus for two important cancer treatment factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain prompt engineering pipeline.","A high accuracy (0.85+) was achieved in the classification of adjuvant radiation therapy and chemotherapy for breast cancer patients.","Furthermore, a confidence interval was formed from observational data on the quality of treatment from human oncologists to estimate the proportion of scenarios in which the model must outperform the original oncologist in its treatment prediction to be a better solution overall as 8.2% to 13.3%.","Due to indeterminacy in the outcomes of cancer treatment decisions, future investigation, potentially a clinical trial, would be required to determine if this threshold was met by the models.","Nevertheless, with 85% of U.S. cancer patients receiving treatment at local community facilities, these kinds of models could play an important part in expanding access to quality care with outcomes that lie, at minimum, close to a human oncologist."],"url":"http://arxiv.org/abs/2406.06455v1"}
{"created":"2024-06-10 16:42:44","title":"Time Series Analysis: yesterday, today, tomorrow","abstract":"Forecasts of various processes have always been a sophisticated problem for statistics and data science. Over the past decades the solution procedures were updated by deep learning and kernel methods. According to many specialists, these approaches are much more precise, stable, and suitable compared to the classical statistical linear time series methods. Here we investigate how true this point of view is.","sentences":["Forecasts of various processes have always been a sophisticated problem for statistics and data science.","Over the past decades the solution procedures were updated by deep learning and kernel methods.","According to many specialists, these approaches are much more precise, stable, and suitable compared to the classical statistical linear time series methods.","Here we investigate how true this point of view is."],"url":"http://arxiv.org/abs/2406.06453v1"}
{"created":"2024-06-10 16:40:14","title":"Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course","abstract":"The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM's technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students' social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students' self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students' use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students' perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.","sentences":["The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education.","However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM's technical capabilities.","Using the social shaping of technology theory as a guiding framework, our study explores how students' social perceptions influence their own LLM usage.","We then examine the correlation of self-reported LLM usage with students' self-efficacy and midterm performances in an undergraduate programming course.","Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students' use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage.","Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students' perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course."],"url":"http://arxiv.org/abs/2406.06451v1"}
{"created":"2024-06-10 16:39:39","title":"Cometh: A continuous-time discrete-state graph diffusion model","abstract":"Discrete-state denoising diffusion models led to state-of-the-art performance in graph generation, especially in the molecular domain. Recently, they have been transposed to continuous time, allowing more flexibility in the reverse process and a better trade-off between sampling efficiency and quality. Here, to leverage the benefits of both approaches, we propose Cometh, a continuous-time discrete-state graph diffusion model, integrating graph data into a continuous-time diffusion model framework. Empirically, we show that integrating continuous time leads to significant improvements across various metrics over state-of-the-art discrete-state diffusion models on a large set of molecular and non-molecular benchmark datasets.","sentences":["Discrete-state denoising diffusion models led to state-of-the-art performance in graph generation, especially in the molecular domain.","Recently, they have been transposed to continuous time, allowing more flexibility in the reverse process and a better trade-off between sampling efficiency and quality.","Here, to leverage the benefits of both approaches, we propose Cometh, a continuous-time discrete-state graph diffusion model, integrating graph data into a continuous-time diffusion model framework.","Empirically, we show that integrating continuous time leads to significant improvements across various metrics over state-of-the-art discrete-state diffusion models on a large set of molecular and non-molecular benchmark datasets."],"url":"http://arxiv.org/abs/2406.06449v1"}
{"created":"2024-06-10 16:39:21","title":"How is the Pilot Doing: VTOL Pilot Workload Estimation by Multimodal Machine Learning on Psycho-physiological Signals","abstract":"Vertical take-off and landing (VTOL) aircraft do not require a prolonged runway, thus allowing them to land almost anywhere. In recent years, their flexibility has made them popular in development, research, and operation. When compared to traditional fixed-wing aircraft and rotorcraft, VTOLs bring unique challenges as they combine many maneuvers from both types of aircraft. Pilot workload is a critical factor for safe and efficient operation of VTOLs. In this work, we conduct a user study to collect multimodal data from 28 pilots while they perform a variety of VTOL flight tasks. We analyze and interpolate behavioral patterns related to their performance and perceived workload. Finally, we build machine learning models to estimate their workload from the collected data. Our results are promising, suggesting that quantitative and accurate VTOL pilot workload monitoring is viable. Such assistive tools would help the research field understand VTOL operations and serve as a stepping stone for the industry to ensure VTOL safe operations and further remote operations.","sentences":["Vertical take-off and landing (VTOL) aircraft do not require a prolonged runway, thus allowing them to land almost anywhere.","In recent years, their flexibility has made them popular in development, research, and operation.","When compared to traditional fixed-wing aircraft and rotorcraft, VTOLs bring unique challenges as they combine many maneuvers from both types of aircraft.","Pilot workload is a critical factor for safe and efficient operation of VTOLs.","In this work, we conduct a user study to collect multimodal data from 28 pilots while they perform a variety of VTOL flight tasks.","We analyze and interpolate behavioral patterns related to their performance and perceived workload.","Finally, we build machine learning models to estimate their workload from the collected data.","Our results are promising, suggesting that quantitative and accurate VTOL pilot workload monitoring is viable.","Such assistive tools would help the research field understand VTOL operations and serve as a stepping stone for the industry to ensure VTOL safe operations and further remote operations."],"url":"http://arxiv.org/abs/2406.06448v1"}
{"created":"2024-06-10 16:36:02","title":"Deep Generative Modeling Reshapes Compression and Transmission: From Efficiency to Resiliency","abstract":"Information theory and machine learning are inextricably linked and have even been referred to as \"two sides of the same coin\". One particularly elegant connection is the essential equivalence between probabilistic generative modeling and data compression or transmission. In this article, we reveal the dual-functionality of deep generative models that reshapes both data compression for efficiency and transmission error concealment for resiliency. We present how the contextual predictive capabilities of powerful generative models can be well positioned to be strong compressors and estimators. In this sense, we advocate for viewing the deep generative modeling problem through the lens of end-to-end communications, and evaluate the compression and error restoration capabilities of foundation generative models. We show that the kernel of many large generative models is powerful predictor that can capture complex relationships among semantic latent variables, and the communication viewpoints provide novel insights into semantic feature tokenization, contextual learning, and usage of deep generative models. In summary, our article highlights the essential connections of generative AI to source and channel coding techniques, and motivates researchers to make further explorations in this emerging topic.","sentences":["Information theory and machine learning are inextricably linked and have even been referred to as \"two sides of the same coin\".","One particularly elegant connection is the essential equivalence between probabilistic generative modeling and data compression or transmission.","In this article, we reveal the dual-functionality of deep generative models that reshapes both data compression for efficiency and transmission error concealment for resiliency.","We present how the contextual predictive capabilities of powerful generative models can be well positioned to be strong compressors and estimators.","In this sense, we advocate for viewing the deep generative modeling problem through the lens of end-to-end communications, and evaluate the compression and error restoration capabilities of foundation generative models.","We show that the kernel of many large generative models is powerful predictor that can capture complex relationships among semantic latent variables, and the communication viewpoints provide novel insights into semantic feature tokenization, contextual learning, and usage of deep generative models.","In summary, our article highlights the essential connections of generative AI to source and channel coding techniques, and motivates researchers to make further explorations in this emerging topic."],"url":"http://arxiv.org/abs/2406.06446v1"}
{"created":"2024-06-10 16:34:43","title":"LLM Dataset Inference: Did you train on my dataset?","abstract":"The proliferation of large language models (LLMs) in the real world has come with a rise in copyright cases against companies for training their models on unlicensed data from the internet. Recent works have presented methods to identify if individual text sequences were members of the model's training data, known as membership inference attacks (MIAs). We demonstrate that the apparent success of these MIAs is confounded by selecting non-members (text sequences not used for training) belonging to a different distribution from the members (e.g., temporally shifted recent Wikipedia articles compared with ones used to train the model). This distribution shift makes membership inference appear successful. However, most MIA methods perform no better than random guessing when discriminating between members and non-members from the same distribution (e.g., in this case, the same period of time). Even when MIAs work, we find that different MIAs succeed at inferring membership of samples from different distributions. Instead, we propose a new dataset inference method to accurately identify the datasets used to train large language models. This paradigm sits realistically in the modern-day copyright landscape, where authors claim that an LLM is trained over multiple documents (such as a book) written by them, rather than one particular paragraph. While dataset inference shares many of the challenges of membership inference, we solve it by selectively combining the MIAs that provide positive signal for a given distribution, and aggregating them to perform a statistical test on a given dataset. Our approach successfully distinguishes the train and test sets of different subsets of the Pile with statistically significant p-values < 0.1, without any false positives.","sentences":["The proliferation of large language models (LLMs) in the real world has come with a rise in copyright cases against companies for training their models on unlicensed data from the internet.","Recent works have presented methods to identify if individual text sequences were members of the model's training data, known as membership inference attacks (MIAs).","We demonstrate that the apparent success of these MIAs is confounded by selecting non-members (text sequences not used for training) belonging to a different distribution from the members (e.g., temporally shifted recent Wikipedia articles compared with ones used to train the model).","This distribution shift makes membership inference appear successful.","However, most MIA methods perform no better than random guessing when discriminating between members and non-members from the same distribution (e.g., in this case, the same period of time).","Even when MIAs work, we find that different MIAs succeed at inferring membership of samples from different distributions.","Instead, we propose a new dataset inference method to accurately identify the datasets used to train large language models.","This paradigm sits realistically in the modern-day copyright landscape, where authors claim that an LLM is trained over multiple documents (such as a book) written by them, rather than one particular paragraph.","While dataset inference shares many of the challenges of membership inference, we solve it by selectively combining the MIAs that provide positive signal for a given distribution, and aggregating them to perform a statistical test on a given dataset.","Our approach successfully distinguishes the train and test sets of different subsets of the Pile with statistically significant p-values < 0.1, without any false positives."],"url":"http://arxiv.org/abs/2406.06443v1"}
{"created":"2024-06-10 16:31:34","title":"Multimodal Contextualized Semantic Parsing from Speech","abstract":"We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents' contextual awareness by integrating multimodal inputs with prior contexts. SPICE goes beyond traditional semantic parsing by offering a structured, interpretable framework for dynamically updating an agent's knowledge with new information, mirroring the complexity of human communication. We develop the VG-SPICE dataset, crafted to challenge agents with visual scene graph construction from spoken conversational exchanges, highlighting speech and visual data integration. We also present the Audio-Vision Dialogue Scene Parser (AViD-SP) developed for use on VG-SPICE. These innovations aim to improve multimodal information processing and integration. Both the VG-SPICE dataset and the AViD-SP model are publicly available.","sentences":["We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents' contextual awareness by integrating multimodal inputs with prior contexts.","SPICE goes beyond traditional semantic parsing by offering a structured, interpretable framework for dynamically updating an agent's knowledge with new information, mirroring the complexity of human communication.","We develop the VG-SPICE dataset, crafted to challenge agents with visual scene graph construction from spoken conversational exchanges, highlighting speech and visual data integration.","We also present the Audio-Vision Dialogue Scene Parser (AViD-SP) developed for use on VG-SPICE.","These innovations aim to improve multimodal information processing and integration.","Both the VG-SPICE dataset and the AViD-SP model are publicly available."],"url":"http://arxiv.org/abs/2406.06438v1"}
{"created":"2024-06-10 16:14:45","title":"Margin-aware Preference Optimization for Aligning Diffusion Models without Reference","abstract":"Modern alignment techniques based on human preferences, such as RLHF and DPO, typically employ divergence regularization relative to the reference model to ensure training stability. However, this often limits the flexibility of models during alignment, especially when there is a clear distributional discrepancy between the preference data and the reference model. In this paper, we focus on the alignment of recent text-to-image diffusion models, such as Stable Diffusion XL (SDXL), and find that this \"reference mismatch\" is indeed a significant problem in aligning these models due to the unstructured nature of visual modalities: e.g., a preference for a particular stylistic aspect can easily induce such a discrepancy. Motivated by this observation, we propose a novel and memory-friendly preference alignment method for diffusion models that does not depend on any reference model, coined margin-aware preference optimization (MaPO). MaPO jointly maximizes the likelihood margin between the preferred and dispreferred image sets and the likelihood of the preferred sets, simultaneously learning general stylistic features and preferences. For evaluation, we introduce two new pairwise preference datasets, which comprise self-generated image pairs from SDXL, Pick-Style and Pick-Safety, simulating diverse scenarios of reference mismatch. Our experiments validate that MaPO can significantly improve alignment on Pick-Style and Pick-Safety and general preference alignment when used with Pick-a-Pic v2, surpassing the base SDXL and other existing methods. Our code, models, and datasets are publicly available via https://mapo-t2i.github.io","sentences":["Modern alignment techniques based on human preferences, such as RLHF and DPO, typically employ divergence regularization relative to the reference model to ensure training stability.","However, this often limits the flexibility of models during alignment, especially when there is a clear distributional discrepancy between the preference data and the reference model.","In this paper, we focus on the alignment of recent text-to-image diffusion models, such as Stable Diffusion XL (SDXL), and find that this \"reference mismatch\" is indeed a significant problem in aligning these models due to the unstructured nature of visual modalities: e.g., a preference for a particular stylistic aspect can easily induce such a discrepancy.","Motivated by this observation, we propose a novel and memory-friendly preference alignment method for diffusion models that does not depend on any reference model, coined margin-aware preference optimization (MaPO).","MaPO jointly maximizes the likelihood margin between the preferred and dispreferred image sets and the likelihood of the preferred sets, simultaneously learning general stylistic features and preferences.","For evaluation, we introduce two new pairwise preference datasets, which comprise self-generated image pairs from SDXL, Pick-Style and Pick-Safety, simulating diverse scenarios of reference mismatch.","Our experiments validate that MaPO can significantly improve alignment on Pick-Style and Pick-Safety and general preference alignment when used with Pick-a-Pic v2, surpassing the base SDXL and other existing methods.","Our code, models, and datasets are publicly available via https://mapo-t2i.github.io"],"url":"http://arxiv.org/abs/2406.06424v1"}
{"created":"2024-06-10 16:12:00","title":"Foundation Inference Models for Markov Jump Processes","abstract":"Markov jump processes are continuous-time stochastic processes which describe dynamical systems evolving in discrete state spaces. These processes find wide application in the natural sciences and machine learning, but their inference is known to be far from trivial. In this work we introduce a methodology for zero-shot inference of Markov jump processes (MJPs), on bounded state spaces, from noisy and sparse observations, which consists of two components. First, a broad probability distribution over families of MJPs, as well as over possible observation times and noise mechanisms, with which we simulate a synthetic dataset of hidden MJPs and their noisy observation process. Second, a neural network model that processes subsets of the simulated observations, and that is trained to output the initial condition and rate matrix of the target MJP in a supervised way. We empirically demonstrate that one and the same (pretrained) model can infer, in a zero-shot fashion, hidden MJPs evolving in state spaces of different dimensionalities. Specifically, we infer MJPs which describe (i) discrete flashing ratchet systems, which are a type of Brownian motors, and the conformational dynamics in (ii) molecular simulations, (iii) experimental ion channel data and (iv) simple protein folding models. What is more, we show that our model performs on par with state-of-the-art models which are finetuned to the target datasets.","sentences":["Markov jump processes are continuous-time stochastic processes which describe dynamical systems evolving in discrete state spaces.","These processes find wide application in the natural sciences and machine learning, but their inference is known to be far from trivial.","In this work we introduce a methodology for zero-shot inference of Markov jump processes (MJPs), on bounded state spaces, from noisy and sparse observations, which consists of two components.","First, a broad probability distribution over families of MJPs, as well as over possible observation times and noise mechanisms, with which we simulate a synthetic dataset of hidden MJPs and their noisy observation process.","Second, a neural network model that processes subsets of the simulated observations, and that is trained to output the initial condition and rate matrix of the target MJP in a supervised way.","We empirically demonstrate that one and the same (pretrained) model can infer, in a zero-shot fashion, hidden MJPs evolving in state spaces of different dimensionalities.","Specifically, we infer MJPs which describe (i) discrete flashing ratchet systems, which are a type of Brownian motors, and the conformational dynamics in (ii) molecular simulations, (iii) experimental ion channel data and (iv) simple protein folding models.","What is more, we show that our model performs on par with state-of-the-art models which are finetuned to the target datasets."],"url":"http://arxiv.org/abs/2406.06419v1"}
{"created":"2024-06-10 15:59:08","title":"A Taxonomy of Challenges to Curating Fair Datasets","abstract":"Despite extensive efforts to create fairer machine learning (ML) datasets, there remains a limited understanding of the practical aspects of dataset curation. Drawing from interviews with 30 ML dataset curators, we present a comprehensive taxonomy of the challenges and trade-offs encountered throughout the dataset curation lifecycle. Our findings underscore overarching issues within the broader fairness landscape that impact data curation. We conclude with recommendations aimed at fostering systemic changes to better facilitate fair dataset curation practices.","sentences":["Despite extensive efforts to create fairer machine learning (ML) datasets, there remains a limited understanding of the practical aspects of dataset curation.","Drawing from interviews with 30 ML dataset curators, we present a comprehensive taxonomy of the challenges and trade-offs encountered throughout the dataset curation lifecycle.","Our findings underscore overarching issues within the broader fairness landscape that impact data curation.","We conclude with recommendations aimed at fostering systemic changes to better facilitate fair dataset curation practices."],"url":"http://arxiv.org/abs/2406.06407v1"}
{"created":"2024-06-10 15:56:52","title":"Meta Learning Text-to-Speech Synthesis in over 7000 Languages","abstract":"In this work, we take on the challenging task of building a single text-to-speech synthesis system that is capable of generating speech in over 7000 languages, many of which lack sufficient data for traditional TTS development. By leveraging a novel integration of massively multilingual pretraining and meta learning to approximate language representations, our approach enables zero-shot speech synthesis in languages without any available data. We validate our system's performance through objective measures and human evaluation across a diverse linguistic landscape. By releasing our code and models publicly, we aim to empower communities with limited linguistic resources and foster further innovation in the field of speech technology.","sentences":["In this work, we take on the challenging task of building a single text-to-speech synthesis system that is capable of generating speech in over 7000 languages, many of which lack sufficient data for traditional TTS development.","By leveraging a novel integration of massively multilingual pretraining and meta learning to approximate language representations, our approach enables zero-shot speech synthesis in languages without any available data.","We validate our system's performance through objective measures and human evaluation across a diverse linguistic landscape.","By releasing our code and models publicly, we aim to empower communities with limited linguistic resources and foster further innovation in the field of speech technology."],"url":"http://arxiv.org/abs/2406.06403v1"}
{"created":"2024-06-10 15:48:07","title":"STimage-1K4M: A histopathology image-gene expression dataset for spatial transcriptomics","abstract":"Recent advances in multi-modal algorithms have driven and been driven by the increasing availability of large image-text datasets, leading to significant strides in various fields, including computational pathology. However, in most existing medical image-text datasets, the text typically provides high-level summaries that may not sufficiently describe sub-tile regions within a large pathology image. For example, an image might cover an extensive tissue area containing cancerous and healthy regions, but the accompanying text might only specify that this image is a cancer slide, lacking the nuanced details needed for in-depth analysis. In this study, we introduce STimage-1K4M, a novel dataset designed to bridge this gap by providing genomic features for sub-tile images. STimage-1K4M contains 1,149 images derived from spatial transcriptomics data, which captures gene expression information at the level of individual spatial spots within a pathology image. Specifically, each image in the dataset is broken down into smaller sub-image tiles, with each tile paired with 15,000-30,000 dimensional gene expressions. With 4,293,195 pairs of sub-tile images and gene expressions, STimage-1K4M offers unprecedented granularity, paving the way for a wide range of advanced research in multi-modal data analysis an innovative applications in computational pathology, and beyond.","sentences":["Recent advances in multi-modal algorithms have driven and been driven by the increasing availability of large image-text datasets, leading to significant strides in various fields, including computational pathology.","However, in most existing medical image-text datasets, the text typically provides high-level summaries that may not sufficiently describe sub-tile regions within a large pathology image.","For example, an image might cover an extensive tissue area containing cancerous and healthy regions, but the accompanying text might only specify that this image is a cancer slide, lacking the nuanced details needed for in-depth analysis.","In this study, we introduce STimage-1K4M, a novel dataset designed to bridge this gap by providing genomic features for sub-tile images.","STimage-1K4","M contains 1,149 images derived from spatial transcriptomics data, which captures gene expression information at the level of individual spatial spots within a pathology image.","Specifically, each image in the dataset is broken down into smaller sub-image tiles, with each tile paired with 15,000-30,000 dimensional gene expressions.","With 4,293,195 pairs of sub-tile images and gene expressions, STimage-1K4M offers unprecedented granularity, paving the way for a wide range of advanced research in multi-modal data analysis an innovative applications in computational pathology, and beyond."],"url":"http://arxiv.org/abs/2406.06393v1"}
{"created":"2024-06-10 15:46:25","title":"Towards Lifelong Learning of Large Language Models: A Survey","abstract":"As the applications of large language models (LLMs) expand across diverse fields, the ability of these models to adapt to ongoing changes in data, tasks, and user preferences becomes crucial. Traditional training methods, relying on static datasets, are increasingly inadequate for coping with the dynamic nature of real-world information. Lifelong learning, also known as continual or incremental learning, addresses this challenge by enabling LLMs to learn continuously and adaptively over their operational lifetime, integrating new knowledge while retaining previously learned information and preventing catastrophic forgetting. This survey delves into the sophisticated landscape of lifelong learning, categorizing strategies into two primary groups: Internal Knowledge and External Knowledge. Internal Knowledge includes continual pretraining and continual finetuning, each enhancing the adaptability of LLMs in various scenarios. External Knowledge encompasses retrieval-based and tool-based lifelong learning, leveraging external data sources and computational tools to extend the model's capabilities without modifying core parameters. The key contributions of our survey are: (1) Introducing a novel taxonomy categorizing the extensive literature of lifelong learning into 12 scenarios; (2) Identifying common techniques across all lifelong learning scenarios and classifying existing literature into various technique groups within each scenario; (3) Highlighting emerging techniques such as model expansion and data selection, which were less explored in the pre-LLM era. Through a detailed examination of these groups and their respective categories, this survey aims to enhance the adaptability, reliability, and overall performance of LLMs in real-world applications.","sentences":["As the applications of large language models (LLMs) expand across diverse fields, the ability of these models to adapt to ongoing changes in data, tasks, and user preferences becomes crucial.","Traditional training methods, relying on static datasets, are increasingly inadequate for coping with the dynamic nature of real-world information.","Lifelong learning, also known as continual or incremental learning, addresses this challenge by enabling LLMs to learn continuously and adaptively over their operational lifetime, integrating new knowledge while retaining previously learned information and preventing catastrophic forgetting.","This survey delves into the sophisticated landscape of lifelong learning, categorizing strategies into two primary groups: Internal Knowledge and External Knowledge.","Internal Knowledge includes continual pretraining and continual finetuning, each enhancing the adaptability of LLMs in various scenarios.","External Knowledge encompasses retrieval-based and tool-based lifelong learning, leveraging external data sources and computational tools to extend the model's capabilities without modifying core parameters.","The key contributions of our survey are: (1) Introducing a novel taxonomy categorizing the extensive literature of lifelong learning into 12 scenarios; (2) Identifying common techniques across all lifelong learning scenarios and classifying existing literature into various technique groups within each scenario; (3) Highlighting emerging techniques such as model expansion and data selection, which were less explored in the pre-LLM era.","Through a detailed examination of these groups and their respective categories, this survey aims to enhance the adaptability, reliability, and overall performance of LLMs in real-world applications."],"url":"http://arxiv.org/abs/2406.06391v1"}
{"created":"2024-06-10 15:43:56","title":"Generalizing to Unseen Domains in Diabetic Retinopathy with Disentangled Representations","abstract":"Diabetic Retinopathy (DR), induced by diabetes, poses a significant risk of visual impairment. Accurate and effective grading of DR aids in the treatment of this condition. Yet existing models experience notable performance degradation on unseen domains due to domain shifts. Previous methods address this issue by simulating domain style through simple visual transformation and mitigating domain noise via learning robust representations. However, domain shifts encompass more than image styles. They overlook biases caused by implicit factors such as ethnicity, age, and diagnostic criteria. In our work, we propose a novel framework where representations of paired data from different domains are decoupled into semantic features and domain noise. The resulting augmented representation comprises original retinal semantics and domain noise from other domains, aiming to generate enhanced representations aligned with real-world clinical needs, incorporating rich information from diverse domains. Subsequently, to improve the robustness of the decoupled representations, class and domain prototypes are employed to interpolate the disentangled representations while data-aware weights are designed to focus on rare classes and domains. Finally, we devise a robust pixel-level semantic alignment loss to align retinal semantics decoupled from features, maintaining a balance between intra-class diversity and dense class features. Experimental results on multiple benchmarks demonstrate the effectiveness of our method on unseen domains. The code implementations are accessible on https://github.com/richard-peng-xia/DECO.","sentences":["Diabetic Retinopathy (DR), induced by diabetes, poses a significant risk of visual impairment.","Accurate and effective grading of DR aids in the treatment of this condition.","Yet existing models experience notable performance degradation on unseen domains due to domain shifts.","Previous methods address this issue by simulating domain style through simple visual transformation and mitigating domain noise via learning robust representations.","However, domain shifts encompass more than image styles.","They overlook biases caused by implicit factors such as ethnicity, age, and diagnostic criteria.","In our work, we propose a novel framework where representations of paired data from different domains are decoupled into semantic features and domain noise.","The resulting augmented representation comprises original retinal semantics and domain noise from other domains, aiming to generate enhanced representations aligned with real-world clinical needs, incorporating rich information from diverse domains.","Subsequently, to improve the robustness of the decoupled representations, class and domain prototypes are employed to interpolate the disentangled representations while data-aware weights are designed to focus on rare classes and domains.","Finally, we devise a robust pixel-level semantic alignment loss to align retinal semantics decoupled from features, maintaining a balance between intra-class diversity and dense class features.","Experimental results on multiple benchmarks demonstrate the effectiveness of our method on unseen domains.","The code implementations are accessible on https://github.com/richard-peng-xia/DECO."],"url":"http://arxiv.org/abs/2406.06384v1"}
{"created":"2024-06-10 15:40:23","title":"FinVerse: An Autonomous Agent System for Versatile Financial Analysis","abstract":"With the significant advancements in cognitive intelligence driven by LLMs, autonomous agent systems have attracted extensive attention. Despite this growing interest, the development of stable and efficient agent systems poses substantial practical challenges. In this paper, we introduce FinVerse, a meticulously crafted agent system designed for a broad range of financial topics. FinVerse integrates over 600 financial APIs, enabling access to more accurate and extensive financial information compared to generalist agents. To enhance financial information processing capabilities, FinVerse is equipped with an embedded code interpreter, enabling the execution of complex data analysis tasks with precision and efficiency. Our work includes an empirical comparison of several LLMs in driving FinVerse. Specifically, we propose our own scheme for training LLMs using SFT to optimize LLM performance within FinVerse. Recognizing the scarcity of specialized datasets to build LLMs for agents, we have constructed a dataset and plan to make it open-source, providing a valuable resource for peer application developers. The demo video has been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4","sentences":["With the significant advancements in cognitive intelligence driven by LLMs, autonomous agent systems have attracted extensive attention.","Despite this growing interest, the development of stable and efficient agent systems poses substantial practical challenges.","In this paper, we introduce FinVerse, a meticulously crafted agent system designed for a broad range of financial topics.","FinVerse integrates over 600 financial APIs, enabling access to more accurate and extensive financial information compared to generalist agents.","To enhance financial information processing capabilities, FinVerse is equipped with an embedded code interpreter, enabling the execution of complex data analysis tasks with precision and efficiency.","Our work includes an empirical comparison of several LLMs in driving FinVerse.","Specifically, we propose our own scheme for training LLMs using SFT to optimize LLM performance within FinVerse.","Recognizing the scarcity of specialized datasets to build LLMs for agents, we have constructed a dataset and plan to make it open-source, providing a valuable resource for peer application developers.","The demo video has been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4"],"url":"http://arxiv.org/abs/2406.06379v1"}
{"created":"2024-06-10 15:37:46","title":"MOSA: Music Motion with Semantic Annotation Dataset for Cross-Modal Music Processing","abstract":"In cross-modal music processing, translation between visual, auditory, and semantic content opens up new possibilities as well as challenges. The construction of such a transformative scheme depends upon a benchmark corpus with a comprehensive data infrastructure. In particular, the assembly of a large-scale cross-modal dataset presents major challenges. In this paper, we present the MOSA (Music mOtion with Semantic Annotation) dataset, which contains high quality 3-D motion capture data, aligned audio recordings, and note-by-note semantic annotations of pitch, beat, phrase, dynamic, articulation, and harmony for 742 professional music performances by 23 professional musicians, comprising more than 30 hours and 570 K notes of data. To our knowledge, this is the largest cross-modal music dataset with note-level annotations to date. To demonstrate the usage of the MOSA dataset, we present several innovative cross-modal music information retrieval (MIR) and musical content generation tasks, including the detection of beats, downbeats, phrase, and expressive contents from audio, video and motion data, and the generation of musicians' body motion from given music audio. The dataset and codes are available alongside this publication (https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset).","sentences":["In cross-modal music processing, translation between visual, auditory, and semantic content opens up new possibilities as well as challenges.","The construction of such a transformative scheme depends upon a benchmark corpus with a comprehensive data infrastructure.","In particular, the assembly of a large-scale cross-modal dataset presents major challenges.","In this paper, we present the MOSA (Music mOtion with Semantic Annotation) dataset, which contains high quality 3-D motion capture data, aligned audio recordings, and note-by-note semantic annotations of pitch, beat, phrase, dynamic, articulation, and harmony for 742 professional music performances by 23 professional musicians, comprising more than 30 hours and 570 K notes of data.","To our knowledge, this is the largest cross-modal music dataset with note-level annotations to date.","To demonstrate the usage of the MOSA dataset, we present several innovative cross-modal music information retrieval (MIR) and musical content generation tasks, including the detection of beats, downbeats, phrase, and expressive contents from audio, video and motion data, and the generation of musicians' body motion from given music audio.","The dataset and codes are available alongside this publication (https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset)."],"url":"http://arxiv.org/abs/2406.06375v1"}
{"created":"2024-06-10 15:36:23","title":"Multicam-SLAM: Non-overlapping Multi-camera SLAM for Indirect Visual Localization and Navigation","abstract":"This paper presents a novel approach to visual simultaneous localization and mapping (SLAM) using multiple RGB-D cameras. The proposed method, Multicam-SLAM, significantly enhances the robustness and accuracy of SLAM systems by capturing more comprehensive spatial information from various perspectives. This method enables the accurate determination of pose relationships among multiple cameras without the need for overlapping fields of view. The proposed Muticam-SLAM includes a unique multi-camera model, a multi-keyframes structure, and several parallel SLAM threads. The multi-camera model allows for the integration of data from multiple cameras, while the multi-keyframes and parallel SLAM threads ensure efficient and accurate pose estimation and mapping. Extensive experiments in various environments demonstrate the superior accuracy and robustness of the proposed method compared to conventional single-camera SLAM systems. The results highlight the potential of the proposed Multicam-SLAM for more complex and challenging applications. Code is available at \\url{https://github.com/AlterPang/Multi_ORB_SLAM}.","sentences":["This paper presents a novel approach to visual simultaneous localization and mapping (SLAM) using multiple RGB-D cameras.","The proposed method, Multicam-SLAM, significantly enhances the robustness and accuracy of SLAM systems by capturing more comprehensive spatial information from various perspectives.","This method enables the accurate determination of pose relationships among multiple cameras without the need for overlapping fields of view.","The proposed Muticam-SLAM includes a unique multi-camera model, a multi-keyframes structure, and several parallel SLAM threads.","The multi-camera model allows for the integration of data from multiple cameras, while the multi-keyframes and parallel SLAM threads ensure efficient and accurate pose estimation and mapping.","Extensive experiments in various environments demonstrate the superior accuracy and robustness of the proposed method compared to conventional single-camera SLAM systems.","The results highlight the potential of the proposed Multicam-SLAM for more complex and challenging applications.","Code is available at \\url{https://github.com/AlterPang/Multi_ORB_SLAM}."],"url":"http://arxiv.org/abs/2406.06374v1"}
{"created":"2024-06-10 15:34:23","title":"Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models","abstract":"Modeling and manufacturing of personalized cranial implants are important research areas that may decrease the waiting time for patients suffering from cranial damage. The modeling of personalized implants may be partially automated by the use of deep learning-based methods. However, this task suffers from difficulties with generalizability into data from previously unseen distributions that make it difficult to use the research outcomes in real clinical settings. Due to difficulties with acquiring ground-truth annotations, different techniques to improve the heterogeneity of datasets used for training the deep networks have to be considered and introduced. In this work, we present a large-scale study of several augmentation techniques, varying from classical geometric transformations, image registration, variational autoencoders, and generative adversarial networks, to the most recent advances in latent diffusion models. We show that the use of heavy data augmentation significantly increases both the quantitative and qualitative outcomes, resulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96 for the SkullFix datasets. Moreover, we show that the synthetically augmented network successfully reconstructs real clinical defects. The work is a considerable contribution to the field of artificial intelligence in the automatic modeling of personalized cranial implants.","sentences":["Modeling and manufacturing of personalized cranial implants are important research areas that may decrease the waiting time for patients suffering from cranial damage.","The modeling of personalized implants may be partially automated by the use of deep learning-based methods.","However, this task suffers from difficulties with generalizability into data from previously unseen distributions that make it difficult to use the research outcomes in real clinical settings.","Due to difficulties with acquiring ground-truth annotations, different techniques to improve the heterogeneity of datasets used for training the deep networks have to be considered and introduced.","In this work, we present a large-scale study of several augmentation techniques, varying from classical geometric transformations, image registration, variational autoencoders, and generative adversarial networks, to the most recent advances in latent diffusion models.","We show that the use of heavy data augmentation significantly increases both the quantitative and qualitative outcomes, resulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96 for the SkullFix datasets.","Moreover, we show that the synthetically augmented network successfully reconstructs real clinical defects.","The work is a considerable contribution to the field of artificial intelligence in the automatic modeling of personalized cranial implants."],"url":"http://arxiv.org/abs/2406.06372v1"}
{"created":"2024-06-10 15:32:42","title":"mHuBERT-147: A Compact Multilingual HuBERT Model","abstract":"We present mHuBERT-147, the first general-purpose massively multilingual HuBERT speech representation model trained on 90K hours of clean, open-license data. To scale up the multi-iteration HuBERT approach, we use faiss-based clustering, achieving 5.2x faster label assignment over the original method. We also apply a new multilingual batching up-sampling strategy, leveraging both language and dataset diversity. After 3 training iterations and with only 95M parameters, mHuBERT-147 outperforms larger models trained on substantially more data. We rank second and first on the ML-SUPERB 10min/1h leaderboards respectively, with SOTA scores for all LID tasks. Across ASR/LID tasks, our model consistently surpasses XLS-R (300M params; 436K hours) and demonstrates strong competitiveness against the much larger MMS (1B params; 491K hours). Our findings suggest that mHuBERT-147 is a promising model for multilingual speech processing tasks, offering an unprecedented balance between high performance and parameter efficiency.","sentences":["We present mHuBERT-147, the first general-purpose massively multilingual HuBERT speech representation model trained on 90K hours of clean, open-license data.","To scale up the multi-iteration HuBERT approach, we use faiss-based clustering, achieving 5.2x faster label assignment over the original method.","We also apply a new multilingual batching up-sampling strategy, leveraging both language and dataset diversity.","After 3 training iterations and with only 95M parameters, mHuBERT-147 outperforms larger models trained on substantially more data.","We rank second and first on the ML-SUPERB 10min/1h leaderboards respectively, with SOTA scores for all LID tasks.","Across ASR/LID tasks, our model consistently surpasses XLS-R (300M params; 436K hours) and demonstrates strong competitiveness against the much larger MMS (1B params; 491K hours).","Our findings suggest that mHuBERT-147 is a promising model for multilingual speech processing tasks, offering an unprecedented balance between high performance and parameter efficiency."],"url":"http://arxiv.org/abs/2406.06371v1"}
{"created":"2024-06-10 15:32:16","title":"UMAD: Unsupervised Mask-Level Anomaly Detection for Autonomous Driving","abstract":"Dealing with atypical traffic scenarios remains a challenging task in autonomous driving. However, most anomaly detection approaches cannot be trained on raw sensor data but require exposure to outlier data and powerful semantic segmentation models trained in a supervised fashion. This limits the representation of normality to labeled data, which does not scale well. In this work, we revisit unsupervised anomaly detection and present UMAD, leveraging generative world models and unsupervised image segmentation. Our method outperforms state-of-the-art unsupervised anomaly detection.","sentences":["Dealing with atypical traffic scenarios remains a challenging task in autonomous driving.","However, most anomaly detection approaches cannot be trained on raw sensor data but require exposure to outlier data and powerful semantic segmentation models trained in a supervised fashion.","This limits the representation of normality to labeled data, which does not scale well.","In this work, we revisit unsupervised anomaly detection and present UMAD, leveraging generative world models and unsupervised image segmentation.","Our method outperforms state-of-the-art unsupervised anomaly detection."],"url":"http://arxiv.org/abs/2406.06370v1"}
{"created":"2024-06-10 15:14:33","title":"On the Minimal Degree Bias in Generalization on the Unseen for non-Boolean Functions","abstract":"We investigate the out-of-domain generalization of random feature (RF) models and Transformers. We first prove that in the `generalization on the unseen (GOTU)' setting, where training data is fully seen in some part of the domain but testing is made on another part, and for RF models in the small feature regime, the convergence takes place to interpolators of minimal degree as in the Boolean case (Abbe et al., 2023). We then consider the sparse target regime and explain how this regime relates to the small feature regime, but with a different regularization term that can alter the picture in the non-Boolean case. We show two different outcomes for the sparse regime with q-ary data tokens: (1) if the data is embedded with roots of unities, then a min-degree interpolator is learned like in the Boolean case for RF models, (2) if the data is not embedded as such, e.g., simply as integers, then RF models and Transformers may not learn minimal degree interpolators. This shows that the Boolean setting and its roots of unities generalization are special cases where the minimal degree interpolator offers a rare characterization of how learning takes place. For more general integer and real-valued settings, a more nuanced picture remains to be fully characterized.","sentences":["We investigate the out-of-domain generalization of random feature (RF) models and Transformers.","We first prove that in the `generalization on the unseen (GOTU)' setting, where training data is fully seen in some part of the domain but testing is made on another part, and for RF models in the small feature regime, the convergence takes place to interpolators of minimal degree as in the Boolean case (Abbe et al., 2023).","We then consider the sparse target regime and explain how this regime relates to the small feature regime, but with a different regularization term that can alter the picture in the non-Boolean case.","We show two different outcomes for the sparse regime with q-ary data tokens: (1) if the data is embedded with roots of unities, then a min-degree interpolator is learned like in the Boolean case for RF models, (2) if the data is not embedded as such, e.g., simply as integers, then RF models and Transformers may not learn minimal degree interpolators.","This shows that the Boolean setting and its roots of unities generalization are special cases where the minimal degree interpolator offers a rare characterization of how learning takes place.","For more general integer and real-valued settings, a more nuanced picture remains to be fully characterized."],"url":"http://arxiv.org/abs/2406.06354v1"}
{"created":"2024-06-10 15:13:07","title":"Cascading Unknown Detection with Known Classification for Open Set Recognition","abstract":"Deep learners tend to perform well when trained under the closed set assumption but struggle when deployed under open set conditions. This motivates the field of Open Set Recognition in which we seek to give deep learners the ability to recognize whether a data sample belongs to the known classes trained on or comes from the surrounding infinite world. Existing open set recognition methods typically rely upon a single function for the dual task of distinguishing between knowns and unknowns as well as making known class distinction. This dual process leaves performance on the table as the function is not specialized for either task. In this work, we introduce Cascading Unknown Detection with Known Classification (Cas-DC), where we instead learn specialized functions in a cascading fashion for both known/unknown detection and fine class classification amongst the world of knowns. Our experiments and analysis demonstrate that Cas-DC handily outperforms modern methods in open set recognition when compared using AUROC scores and correct classification rate at various true positive rates.","sentences":["Deep learners tend to perform well when trained under the closed set assumption but struggle when deployed under open set conditions.","This motivates the field of Open Set Recognition in which we seek to give deep learners the ability to recognize whether a data sample belongs to the known classes trained on or comes from the surrounding infinite world.","Existing open set recognition methods typically rely upon a single function for the dual task of distinguishing between knowns and unknowns as well as making known class distinction.","This dual process leaves performance on the table as the function is not specialized for either task.","In this work, we introduce Cascading Unknown Detection with Known Classification (Cas-DC), where we instead learn specialized functions in a cascading fashion for both known/unknown detection and fine class classification amongst the world of knowns.","Our experiments and analysis demonstrate that Cas-DC handily outperforms modern methods in open set recognition when compared using AUROC scores and correct classification rate at various true positive rates."],"url":"http://arxiv.org/abs/2406.06351v1"}
{"created":"2024-06-10 15:09:58","title":"ARMA Processes with Discrete-Continuous Excitation: Compressibility Beyond Sparsity","abstract":"R\\'enyi Information Dimension (RID) plays a central role in quantifying the compressibility of random variables with singularities in their distribution, encompassing and extending beyond the class of sparse sources. The RID, from a high perspective, presents the average number of bits that is needed for coding the i.i.d. samples of a random variable with high precision. There are two main extensions of the RID for stochastic processes: information dimension rate (IDR) and block information dimension (BID). In addition, a more recent approach towards the compressibility of stochastic processes revolves around the concept of $\\epsilon$-achievable compression rates, which treat a random process as the limiting point of finite-dimensional random vectors and apply the compressed sensing tools on these random variables. While there is limited knowledge about the interplay of the the BID, the IDR, and $\\epsilon$-achievable compression rates, the value of IDR and BID themselves are known only for very specific types of processes, namely i.i.d. sequences (i.e., discrete-domain white noise) and moving-average (MA) processes. This paper investigates the IDR and BID of discrete-time Auto-Regressive Moving-Average (ARMA) processes in general, and their relations with $\\epsilon$-achievable compression rates when the excitation noise has a discrete-continuous measure. To elaborate, this paper shows that the RID and $\\epsilon$-achievable compression rates of this type of processes are equal to that of their excitation noise. In other words, the samples of such ARMA processes can be compressed as much as their sparse excitation noise, although the samples themselves are by no means sparse. The results of this paper can be used to evaluate the compressibility of various types of locally correlated data with finite- or infinite-memory as they are often modelled via ARMA processes.","sentences":["R\\'enyi Information Dimension (RID) plays a central role in quantifying the compressibility of random variables with singularities in their distribution, encompassing and extending beyond the class of sparse sources.","The RID, from a high perspective, presents the average number of bits that is needed for coding the i.i.d. samples of a random variable with high precision.","There are two main extensions of the RID for stochastic processes: information dimension rate (IDR) and block information dimension (BID).","In addition, a more recent approach towards the compressibility of stochastic processes revolves around the concept of $\\epsilon$-achievable compression rates, which treat a random process as the limiting point of finite-dimensional random vectors and apply the compressed sensing tools on these random variables.","While there is limited knowledge about the interplay of the the BID, the IDR, and $\\epsilon$-achievable compression rates, the value of IDR and BID themselves are known only for very specific types of processes, namely i.i.d. sequences (i.e., discrete-domain white noise) and moving-average (MA) processes.","This paper investigates the IDR and BID of discrete-time Auto-Regressive Moving-Average (ARMA) processes in general, and their relations with $\\epsilon$-achievable compression rates when the excitation noise has a discrete-continuous measure.","To elaborate, this paper shows that the RID and $\\epsilon$-achievable compression rates of this type of processes are equal to that of their excitation noise.","In other words, the samples of such ARMA processes can be compressed as much as their sparse excitation noise, although the samples themselves are by no means sparse.","The results of this paper can be used to evaluate the compressibility of various types of locally correlated data with finite- or infinite-memory as they are often modelled via ARMA processes."],"url":"http://arxiv.org/abs/2406.06349v1"}
{"created":"2024-06-10 15:08:14","title":"Causal Discovery over High-Dimensional Structured Hypothesis Spaces with Causal Graph Partitioning","abstract":"The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way -- without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of directed acyclic graphs, to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees. We leverage the idea of a superstructure -- a set of learned or existing candidate hypotheses -- to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces.","sentences":["The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses.","Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way -- without necessarily tailoring to a specific domain.","Causal discovery algorithms search over a structured hypothesis space, defined by the set of directed acyclic graphs, to find the graph that best explains the data.","For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap.","In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees.","We leverage the idea of a superstructure -- a set of learned or existing candidate hypotheses -- to partition the search space.","We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph.","We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables.","This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces."],"url":"http://arxiv.org/abs/2406.06348v1"}
{"created":"2024-06-10 15:01:46","title":"Predicting Heart Activity from Speech using Data-driven and Knowledge-based features","abstract":"Accurately predicting heart activity and other biological signals is crucial for diagnosis and monitoring. Given that speech is an outcome of multiple physiological systems, a significant body of work studied the acoustic correlates of heart activity. Recently, self-supervised models have excelled in speech-related tasks compared to traditional acoustic methods. However, the robustness of data-driven representations in predicting heart activity remained unexplored. In this study, we demonstrate that self-supervised speech models outperform acoustic features in predicting heart activity parameters. We also emphasize the impact of individual variability on model generalizability. These findings underscore the value of data-driven representations in such tasks and the need for more speech-based physiological data to mitigate speaker-related challenges.","sentences":["Accurately predicting heart activity and other biological signals is crucial for diagnosis and monitoring.","Given that speech is an outcome of multiple physiological systems, a significant body of work studied the acoustic correlates of heart activity.","Recently, self-supervised models have excelled in speech-related tasks compared to traditional acoustic methods.","However, the robustness of data-driven representations in predicting heart activity remained unexplored.","In this study, we demonstrate that self-supervised speech models outperform acoustic features in predicting heart activity parameters.","We also emphasize the impact of individual variability on model generalizability.","These findings underscore the value of data-driven representations in such tasks and the need for more speech-based physiological data to mitigate speaker-related challenges."],"url":"http://arxiv.org/abs/2406.06341v1"}
{"created":"2024-06-10 15:01:03","title":"Optimisation of federated learning settings under statistical heterogeneity variations","abstract":"Federated Learning (FL) enables local devices to collaboratively learn a shared predictive model by only periodically sharing model parameters with a central aggregator. However, FL can be disadvantaged by statistical heterogeneity produced by the diversity in each local devices data distribution, which creates different levels of Independent and Identically Distributed (IID) data. Furthermore, this can be more complex when optimising different combinations of FL parameters and choosing optimal aggregation. In this paper, we present an empirical analysis of different FL training parameters and aggregators over various levels of statistical heterogeneity on three datasets. We propose a systematic data partition strategy to simulate different levels of statistical heterogeneity and a metric to measure the level of IID. Additionally, we empirically identify the best FL model and key parameters for datasets of different characteristics. On the basis of these, we present recommended guidelines for FL parameters and aggregators to optimise model performance under different levels of IID and with different datasets","sentences":["Federated Learning (FL) enables local devices to collaboratively learn a shared predictive model by only periodically sharing model parameters with a central aggregator.","However, FL can be disadvantaged by statistical heterogeneity produced by the diversity in each local devices data distribution, which creates different levels of Independent and Identically Distributed (IID) data.","Furthermore, this can be more complex when optimising different combinations of FL parameters and choosing optimal aggregation.","In this paper, we present an empirical analysis of different FL training parameters and aggregators over various levels of statistical heterogeneity on three datasets.","We propose a systematic data partition strategy to simulate different levels of statistical heterogeneity and a metric to measure the level of IID.","Additionally, we empirically identify the best FL model and key parameters for datasets of different characteristics.","On the basis of these, we present recommended guidelines for FL parameters and aggregators to optimise model performance under different levels of IID and with different datasets"],"url":"http://arxiv.org/abs/2406.06340v1"}
{"created":"2024-06-10 14:46:07","title":"A Parameter-efficient Language Extension Framework for Multilingual ASR","abstract":"Covering all languages with a multilingual speech recognition model (MASR) is very difficult. Performing language extension on top of an existing MASR is a desirable choice. In this study, the MASR continual learning problem is probabilistically decomposed into language identity prediction (LP) and cross-lingual adaptation (XLA) sub-problems. Based on this, we propose an architecture-based framework for language extension that can fundamentally solve catastrophic forgetting, debudded as PELE. PELE is designed to be parameter-efficient, incrementally incorporating an add-on module to adapt to a new language. Specifically, different parameter-efficient fine-tuning (PEFT) modules and their variants are explored as potential candidates to perform XLA. Experiments are carried out on 5 new languages with a wide range of low-resourced data sizes. The best-performing PEFT candidate can achieve satisfactory performance across all languages and demonstrates superiority in three of five languages over the continual joint learning setting. Notably, PEFT methods focusing on weight parameters or input features are revealed to be limited in performance, showing significantly inferior extension capabilities compared to inserting a lightweight module in between layers such as an Adapter.","sentences":["Covering all languages with a multilingual speech recognition model (MASR) is very difficult.","Performing language extension on top of an existing MASR is a desirable choice.","In this study, the MASR continual learning problem is probabilistically decomposed into language identity prediction (LP) and cross-lingual adaptation (XLA) sub-problems.","Based on this, we propose an architecture-based framework for language extension that can fundamentally solve catastrophic forgetting, debudded as PELE.","PELE is designed to be parameter-efficient, incrementally incorporating an add-on module to adapt to a new language.","Specifically, different parameter-efficient fine-tuning (PEFT) modules and their variants are explored as potential candidates to perform XLA.","Experiments are carried out on 5 new languages with a wide range of low-resourced data sizes.","The best-performing PEFT candidate can achieve satisfactory performance across all languages and demonstrates superiority in three of five languages over the continual joint learning setting.","Notably, PEFT methods focusing on weight parameters or input features are revealed to be limited in performance, showing significantly inferior extension capabilities compared to inserting a lightweight module in between layers such as an Adapter."],"url":"http://arxiv.org/abs/2406.06329v1"}
{"created":"2024-06-10 14:36:58","title":"Optimal Preprocessing for Answering On-Line Product Queries","abstract":"We examine the amount of preprocessing needed for answering certain on-line queries as fast as possible. We start with the following basic problem. Suppose we are given a semigroup $(S,\\circ )$. Let $s_1 ,\\ldots, s_n$ be elements of $S$. We want to answer on-line queries of the form, ``What is the product $s_i \\circ s_{i+1} \\circ \\cdots \\circ s_{j-1} \\circ s_j$?'' for any given $1\\le i\\le j\\le n$. We show that a preprocessing of $\\Theta(n \\lambda (k,n))$ time and space is both necessary and sufficient to answer each such query in at most $k$ steps, for any fixed $k$. The function $\\lambda (k,\\cdot)$ is the inverse of a certain function at the $\\lfloor {k/2}\\rfloor$-th level of the primitive recursive hierarchy. In case linear preprocessing is desired, we show that one can answer each such query in $O( \\alpha (n))$ steps and that this is best possible. The function $\\alpha (n)$ is the inverse Ackermann function.   We also consider the following extended problem. Let $T$ be a tree with an element of $S$ associated with each of its vertices. We want to answer on-line queries of the form, ``What is the product of the elements associated with the vertices along the path from $u$ to $v$?'' for any pair of vertices $u$ and $v$ in $T$. We derive results that are similar to the above, for the preprocessing needed for answering such queries.   All our sequential preprocessing algorithms can be parallelized efficiently to give optimal parallel algorithms which run in $O(\\log n)$ time on a CREW PRAM. These parallel algorithms are optimal in both running time and total number of operations.   Our algorithms, especially for the semigroup of the real numbers with the minimum or maximum operations, have various applications in certain graph algorithms, in the utilization of communication networks and in Database retrieval.","sentences":["We examine the amount of preprocessing needed for answering certain on-line queries as fast as possible.","We start with the following basic problem.","Suppose we are given a semigroup $(S,\\circ )$.","Let $s_1 ,\\ldots, s_n$ be elements of $S$. We want to answer on-line queries of the form, ``What is the product $s_i \\circ s_{i+1} \\circ \\cdots \\circ s_{j-1} \\circ s_j$?''","for any given $1\\le i\\le j\\le n$. We show that a preprocessing of $\\Theta(n \\lambda (k,n))$ time and space is both necessary and sufficient to answer each such query in at most $k$ steps, for any fixed $k$. The function $\\lambda (k,\\cdot)$ is the inverse of a certain function at the $\\lfloor {k/2}\\rfloor$-th level of the primitive recursive hierarchy.","In case linear preprocessing is desired, we show that one can answer each such query in $O( \\alpha (n))$ steps and that this is best possible.","The function $\\alpha (n)$ is the inverse Ackermann function.   ","We also consider the following extended problem.","Let $T$ be a tree with an element of $S$ associated with each of its vertices.","We want to answer on-line queries of the form, ``What is the product of the elements associated with the vertices along the path from $u$ to $v$?''","for any pair of vertices $u$ and $v$ in $T$. We derive results that are similar to the above, for the preprocessing needed for answering such queries.   ","All our sequential preprocessing algorithms can be parallelized efficiently to give optimal parallel algorithms which run in $O(\\log","n)$ time on a CREW PRAM.","These parallel algorithms are optimal in both running time and total number of operations.   ","Our algorithms, especially for the semigroup of the real numbers with the minimum or maximum operations, have various applications in certain graph algorithms, in the utilization of communication networks and in Database retrieval."],"url":"http://arxiv.org/abs/2406.06321v1"}
{"created":"2024-06-10 14:26:09","title":"Unsupervised Improved MVDR Beamforming for Sound Enhancement","abstract":"Neural networks have recently become the dominant approach to sound separation. Their good performance relies on large datasets of isolated recordings. For speech and music, isolated single channel data are readily available; however the same does not hold in the multi-channel case, and with most other sound classes. Multi-channel methods have the potential to outperform single channel approaches as they can exploit both spatial and spectral features, but the lack of training data remains a challenge. We propose unsupervised improved minimum variation distortionless response (UIMVDR), which enables multi-channel separation to leverage in-the-wild single-channel data through unsupervised training and beamforming. Results show that UIMVDR generalizes well and improves separation performance compared to supervised models, particularly in cases with limited supervised data. By using data available online, it also reduces the effort required to gather data for multi-channel approaches.","sentences":["Neural networks have recently become the dominant approach to sound separation.","Their good performance relies on large datasets of isolated recordings.","For speech and music, isolated single channel data are readily available; however the same does not hold in the multi-channel case, and with most other sound classes.","Multi-channel methods have the potential to outperform single channel approaches as they can exploit both spatial and spectral features, but the lack of training data remains a challenge.","We propose unsupervised improved minimum variation distortionless response (UIMVDR), which enables multi-channel separation to leverage in-the-wild single-channel data through unsupervised training and beamforming.","Results show that UIMVDR generalizes well and improves separation performance compared to supervised models, particularly in cases with limited supervised data.","By using data available online, it also reduces the effort required to gather data for multi-channel approaches."],"url":"http://arxiv.org/abs/2406.06310v1"}
{"created":"2024-06-10 14:18:08","title":"Human Gaze and Head Rotation during Navigation, Exploration and Object Manipulation in Shared Environments with Robots","abstract":"The human gaze is an important cue to signal intention, attention, distraction, and the regions of interest in the immediate surroundings. Gaze tracking can transform how robots perceive, understand, and react to people, enabling new modes of robot control, interaction, and collaboration. In this paper, we use gaze tracking data from a rich dataset of human motion (TH\\\"OR-MAGNI) to investigate the coordination between gaze direction and head rotation of humans engaged in various indoor activities involving navigation, interaction with objects, and collaboration with a mobile robot. In particular, we study the spread and central bias of fixations in diverse activities and examine the correlation between gaze direction and head rotation. We introduce various human motion metrics to enhance the understanding of gaze behavior in dynamic interactions. Finally, we apply semantic object labeling to decompose the gaze distribution into activity-relevant regions.","sentences":["The human gaze is an important cue to signal intention, attention, distraction, and the regions of interest in the immediate surroundings.","Gaze tracking can transform how robots perceive, understand, and react to people, enabling new modes of robot control, interaction, and collaboration.","In this paper, we use gaze tracking data from a rich dataset of human motion (TH\\\"OR-MAGNI) to investigate the coordination between gaze direction and head rotation of humans engaged in various indoor activities involving navigation, interaction with objects, and collaboration with a mobile robot.","In particular, we study the spread and central bias of fixations in diverse activities and examine the correlation between gaze direction and head rotation.","We introduce various human motion metrics to enhance the understanding of gaze behavior in dynamic interactions.","Finally, we apply semantic object labeling to decompose the gaze distribution into activity-relevant regions."],"url":"http://arxiv.org/abs/2406.06300v1"}
{"created":"2024-06-10 14:16:28","title":"Zero-Shot Audio Captioning Using Soft and Hard Prompts","abstract":"In traditional audio captioning methods, a model is usually trained in a fully supervised manner using a human-annotated dataset containing audio-text pairs and then evaluated on the test sets from the same dataset. Such methods have two limitations. First, these methods are often data-hungry and require time-consuming and expensive human annotations to obtain audio-text pairs. Second, these models often suffer from performance degradation in cross-domain scenarios, i.e., when the input audio comes from a different domain than the training set, which, however, has received little attention. We propose an effective audio captioning method based on the contrastive language-audio pre-training (CLAP) model to address these issues. Our proposed method requires only textual data for training, enabling the model to generate text from the textual feature in the cross-modal semantic space.In the inference stage, the model generates the descriptive text for the given audio from the audio feature by leveraging the audio-text alignment from CLAP.We devise two strategies to mitigate the discrepancy between text and audio embeddings: a mixed-augmentation-based soft prompt and a retrieval-based acoustic-aware hard prompt. These approaches are designed to enhance the generalization performance of our proposed model, facilitating the model to generate captions more robustly and accurately. Extensive experiments on AudioCaps and Clotho benchmarks show the effectiveness of our proposed method, which outperforms other zero-shot audio captioning approaches for in-domain scenarios and outperforms the compared methods for cross-domain scenarios, underscoring the generalization ability of our method.","sentences":["In traditional audio captioning methods, a model is usually trained in a fully supervised manner using a human-annotated dataset containing audio-text pairs and then evaluated on the test sets from the same dataset.","Such methods have two limitations.","First, these methods are often data-hungry and require time-consuming and expensive human annotations to obtain audio-text pairs.","Second, these models often suffer from performance degradation in cross-domain scenarios, i.e., when the input audio comes from a different domain than the training set, which, however, has received little attention.","We propose an effective audio captioning method based on the contrastive language-audio pre-training (CLAP) model to address these issues.","Our proposed method requires only textual data for training, enabling the model to generate text from the textual feature in the cross-modal semantic space.","In the inference stage, the model generates the descriptive text for the given audio from the audio feature by leveraging the audio-text alignment from CLAP.We devise two strategies to mitigate the discrepancy between text and audio embeddings: a mixed-augmentation-based soft prompt and a retrieval-based acoustic-aware hard prompt.","These approaches are designed to enhance the generalization performance of our proposed model, facilitating the model to generate captions more robustly and accurately.","Extensive experiments on AudioCaps and Clotho benchmarks show the effectiveness of our proposed method, which outperforms other zero-shot audio captioning approaches for in-domain scenarios and outperforms the compared methods for cross-domain scenarios, underscoring the generalization ability of our method."],"url":"http://arxiv.org/abs/2406.06295v1"}
{"created":"2024-06-10 14:06:56","title":"An ODMA-Based Unsourced Random Access Scheme with a Multiple Antenna Receiver","abstract":"We investigate the unsourced random access scheme assuming that the base station is equipped with multiple antennas, and propose a high-performing solution utilizing on-off-division multiple access. We assume that each user spreads its pilot sequence and polar codeword to the pilot and data parts of the transmission frame, respectively, based on a transmission pattern. The iterative receiver operation consists of pilot and pattern detection followed by channel vector and symbol estimation, polar decoding, and successive interference cancellation. Numerical findings demonstrate that the proposed scheme has superior performance compared to the state-of-the-art in various antenna settings.","sentences":["We investigate the unsourced random access scheme assuming that the base station is equipped with multiple antennas, and propose a high-performing solution utilizing on-off-division multiple access.","We assume that each user spreads its pilot sequence and polar codeword to the pilot and data parts of the transmission frame, respectively, based on a transmission pattern.","The iterative receiver operation consists of pilot and pattern detection followed by channel vector and symbol estimation, polar decoding, and successive interference cancellation.","Numerical findings demonstrate that the proposed scheme has superior performance compared to the state-of-the-art in various antenna settings."],"url":"http://arxiv.org/abs/2406.06284v1"}
{"created":"2024-06-10 13:58:46","title":"Multi-Prompting Decoder Helps Better Language Understanding","abstract":"Recent Pre-trained Language Models (PLMs) usually only provide users with the inference APIs, namely the emerging Model-as-a-Service (MaaS) setting. To adapt MaaS PLMs to downstream tasks without accessing their parameters and gradients, some existing methods focus on the output-side adaptation of PLMs, viewing the PLM as an encoder and then optimizing a task-specific decoder for decoding the output hidden states and class scores of the PLM. Despite the effectiveness of these methods, they only use a single prompt to query PLMs for decoding, leading to a heavy reliance on the quality of the adopted prompt. In this paper, we propose a simple yet effective Multi-Prompting Decoder (MPD) framework for MaaS adaptation. The core idea is to query PLMs with multiple different prompts for each sample, thereby obtaining multiple output hidden states and class scores for subsequent decoding. Such multi-prompting decoding paradigm can simultaneously mitigate reliance on the quality of a single prompt, alleviate the issue of data scarcity under the few-shot setting, and provide richer knowledge extracted from PLMs. Specifically, we propose two decoding strategies: multi-prompting decoding with optimal transport for hidden states and calibrated decoding for class scores. Extensive experiments demonstrate that our method achieves new state-of-the-art results on multiple natural language understanding datasets under the few-shot setting.","sentences":["Recent Pre-trained Language Models (PLMs) usually only provide users with the inference APIs, namely the emerging Model-as-a-Service (MaaS) setting.","To adapt MaaS PLMs to downstream tasks without accessing their parameters and gradients, some existing methods focus on the output-side adaptation of PLMs, viewing the PLM as an encoder and then optimizing a task-specific decoder for decoding the output hidden states and class scores of the PLM.","Despite the effectiveness of these methods, they only use a single prompt to query PLMs for decoding, leading to a heavy reliance on the quality of the adopted prompt.","In this paper, we propose a simple yet effective Multi-Prompting Decoder (MPD) framework for MaaS adaptation.","The core idea is to query PLMs with multiple different prompts for each sample, thereby obtaining multiple output hidden states and class scores for subsequent decoding.","Such multi-prompting decoding paradigm can simultaneously mitigate reliance on the quality of a single prompt, alleviate the issue of data scarcity under the few-shot setting, and provide richer knowledge extracted from PLMs.","Specifically, we propose two decoding strategies: multi-prompting decoding with optimal transport for hidden states and calibrated decoding for class scores.","Extensive experiments demonstrate that our method achieves new state-of-the-art results on multiple natural language understanding datasets under the few-shot setting."],"url":"http://arxiv.org/abs/2406.06279v1"}
{"created":"2024-06-10 13:34:43","title":"Stabilized Adaptive Steering for 3D Sonar Microphone Arrays with IMU Sensor Fusion","abstract":"This paper presents a novel software-based approach to stabilizing the acoustic images for in-air 3D sonars. Due to uneven terrain, traditional static beamforming techniques can be misaligned, causing inaccurate measurements and imaging artifacts. Furthermore, mechanical stabilization can be more costly and prone to failure. We propose using an adaptive conventional beamforming approach by fusing it with real-time IMU data to adjust the sonar array's steering matrix dynamically based on the elevation tilt angle caused by the uneven ground. Additionally, we propose gaining compensation to offset emission energy loss due to the transducer's directivity pattern and validate our approach through various experiments, which show significant improvements in temporal consistency in the acoustic images. We implemented a GPU-accelerated software system that operates in real-time with an average execution time of 210ms, meeting autonomous navigation requirements.","sentences":["This paper presents a novel software-based approach to stabilizing the acoustic images for in-air 3D sonars.","Due to uneven terrain, traditional static beamforming techniques can be misaligned, causing inaccurate measurements and imaging artifacts.","Furthermore, mechanical stabilization can be more costly and prone to failure.","We propose using an adaptive conventional beamforming approach by fusing it with real-time IMU data to adjust the sonar array's steering matrix dynamically based on the elevation tilt angle caused by the uneven ground.","Additionally, we propose gaining compensation to offset emission energy loss due to the transducer's directivity pattern and validate our approach through various experiments, which show significant improvements in temporal consistency in the acoustic images.","We implemented a GPU-accelerated software system that operates in real-time with an average execution time of 210ms, meeting autonomous navigation requirements."],"url":"http://arxiv.org/abs/2406.06255v1"}
{"created":"2024-06-10 13:34:23","title":"Understanding Students' Acceptance of ChatGPT as a Translation Tool: A UTAUT Model Analysis","abstract":"The potential of ChatGPT to transform the education landscape is drawing increasing attention. With its translation-related capabilities being tested and examined, ChatGPT presents both opportunities and challenges for translation training. The effective integration of ChatGPT into translation training necessitates an understanding of students' reactions to and acceptance of ChatGPT-assisted translation. Against this backdrop, this study draws on the Unified Theory of Acceptance and Use of Technology (UTAUT) to examine the potential determinants of students' adoption of ChatGPT for translation and investigates the moderating effects of use experience and translation training on those relationships. An online survey targeting university students in Hong Kong collected 308 valid responses, including 148 from translation students and 160 from non-translation students. Respondents were divided into two groups based on their ChatGPT use experience. Data were analyzed using structural equation modeling. A multigroup analysis revealed different structural relationships between the influencing factors of students' intention to use ChatGPT across groups. Notably, less-experienced users' behavioral intention to use ChatGPT for translation was more strongly correlated with social influence compared with experienced users. Non-translation students' use intention was more strongly driven by facilitating conditions compared to translation majors. These results are discussed with the different primary purposes of translation and non-translation students' translation practices. The findings of this study contribute to the growing body of research on AI-powered translation training and provide insights for the ongoing adaptation of translation training programs.","sentences":["The potential of ChatGPT to transform the education landscape is drawing increasing attention.","With its translation-related capabilities being tested and examined, ChatGPT presents both opportunities and challenges for translation training.","The effective integration of ChatGPT into translation training necessitates an understanding of students' reactions to and acceptance of ChatGPT-assisted translation.","Against this backdrop, this study draws on the Unified Theory of Acceptance and Use of Technology (UTAUT) to examine the potential determinants of students' adoption of ChatGPT for translation and investigates the moderating effects of use experience and translation training on those relationships.","An online survey targeting university students in Hong Kong collected 308 valid responses, including 148 from translation students and 160 from non-translation students.","Respondents were divided into two groups based on their ChatGPT use experience.","Data were analyzed using structural equation modeling.","A multigroup analysis revealed different structural relationships between the influencing factors of students' intention to use ChatGPT across groups.","Notably, less-experienced users' behavioral intention to use ChatGPT for translation was more strongly correlated with social influence compared with experienced users.","Non-translation students' use intention was more strongly driven by facilitating conditions compared to translation majors.","These results are discussed with the different primary purposes of translation and non-translation students' translation practices.","The findings of this study contribute to the growing body of research on AI-powered translation training and provide insights for the ongoing adaptation of translation training programs."],"url":"http://arxiv.org/abs/2406.06254v1"}
{"created":"2024-06-10 13:23:00","title":"Data-Efficient Learning with Neural Programs","abstract":"Many computational tasks can be naturally expressed as a composition of a DNN followed by a program written in a traditional programming language or an API call to an LLM. We call such composites \"neural programs\" and focus on the problem of learning the DNN parameters when the training data consist of end-to-end input-output labels for the composite. When the program is written in a differentiable logic programming language, techniques from neurosymbolic learning are applicable, but in general, the learning for neural programs requires estimating the gradients of black-box components. We present an algorithm for learning neural programs, called ISED, that only relies on input-output samples of black-box components. For evaluation, we introduce new benchmarks that involve calls to modern LLMs such as GPT-4 and also consider benchmarks from the neurosymolic learning literature. Our evaluation shows that for the latter benchmarks, ISED has comparable performance to state-of-the-art neurosymbolic frameworks. For the former, we use adaptations of prior work on gradient approximations of black-box components as a baseline, and show that ISED achieves comparable accuracy but in a more data- and sample-efficient manner.","sentences":["Many computational tasks can be naturally expressed as a composition of a DNN followed by a program written in a traditional programming language or an API call to an LLM.","We call such composites \"neural programs\" and focus on the problem of learning the DNN parameters when the training data consist of end-to-end input-output labels for the composite.","When the program is written in a differentiable logic programming language, techniques from neurosymbolic learning are applicable, but in general, the learning for neural programs requires estimating the gradients of black-box components.","We present an algorithm for learning neural programs, called ISED, that only relies on input-output samples of black-box components.","For evaluation, we introduce new benchmarks that involve calls to modern LLMs such as GPT-4 and also consider benchmarks from the neurosymolic learning literature.","Our evaluation shows that for the latter benchmarks, ISED has comparable performance to state-of-the-art neurosymbolic frameworks.","For the former, we use adaptations of prior work on gradient approximations of black-box components as a baseline, and show that ISED achieves comparable accuracy but in a more data- and sample-efficient manner."],"url":"http://arxiv.org/abs/2406.06246v1"}
{"created":"2024-06-10 13:08:31","title":"I-MPN: Inductive Message Passing Network for Effective and Efficient Human-in-the-Loop Annotation of Mobile Eye Tracking Data","abstract":"Understanding human visual processing in dynamic environments is essential for psychology and human-centered interaction design. Mobile eye-tracking systems, combining egocentric video and gaze signals, offer valuable insights. However, manual analysis of these recordings is time-intensive. In this work, we present a novel human-centered learning algorithm designed for automated object recognition within mobile eye-tracking settings. Our approach seamlessly integrates an object detector with an inductive message-passing network technique (I-MPN), harnessing node features such as node profile information and positions. This integration enables our algorithm to learn embedding functions capable of generalizing to new object angle views, thereby facilitating rapid adaptation and efficient reasoning in dynamic contexts as users navigate through their environment. Through experiments conducted on three distinct video sequences, our \\textit{interactive-based method} showcases significant performance improvements over fixed training/testing algorithms, even when trained on considerably smaller annotated samples collected through user feedback. Furthermore, we showcase exceptional efficiency in data annotation processes, surpassing approaches that use complete object detectors, combine detectors with convolutional networks, or employ interactive video segmentation.","sentences":["Understanding human visual processing in dynamic environments is essential for psychology and human-centered interaction design.","Mobile eye-tracking systems, combining egocentric video and gaze signals, offer valuable insights.","However, manual analysis of these recordings is time-intensive.","In this work, we present a novel human-centered learning algorithm designed for automated object recognition within mobile eye-tracking settings.","Our approach seamlessly integrates an object detector with an inductive message-passing network technique (I-MPN), harnessing node features such as node profile information and positions.","This integration enables our algorithm to learn embedding functions capable of generalizing to new object angle views, thereby facilitating rapid adaptation and efficient reasoning in dynamic contexts as users navigate through their environment.","Through experiments conducted on three distinct video sequences, our \\textit{interactive-based method} showcases significant performance improvements over fixed training/testing algorithms, even when trained on considerably smaller annotated samples collected through user feedback.","Furthermore, we showcase exceptional efficiency in data annotation processes, surpassing approaches that use complete object detectors, combine detectors with convolutional networks, or employ interactive video segmentation."],"url":"http://arxiv.org/abs/2406.06239v1"}
{"created":"2024-06-10 13:07:13","title":"Efficient Neural Compression with Inference-time Decoding","abstract":"This paper explores the combination of neural network quantization and entropy coding for memory footprint minimization. Edge deployment of quantized models is hampered by the harsh Pareto frontier of the accuracy-to-bitwidth tradeoff, causing dramatic accuracy loss below a certain bitwidth. This accuracy loss can be alleviated thanks to mixed precision quantization, allowing for more flexible bitwidth allocation. However, standard mixed precision benefits remain limited due to the 1-bit frontier, that forces each parameter to be encoded on at least 1 bit of data. This paper introduces an approach that combines mixed precision, zero-point quantization and entropy coding to push the compression boundary of Resnets beyond the 1-bit frontier with an accuracy drop below 1% on the ImageNet benchmark. From an implementation standpoint, a compact decoder architecture features reduced latency, thus allowing for inference-compatible decoding.","sentences":["This paper explores the combination of neural network quantization and entropy coding for memory footprint minimization.","Edge deployment of quantized models is hampered by the harsh Pareto frontier of the accuracy-to-bitwidth tradeoff, causing dramatic accuracy loss below a certain bitwidth.","This accuracy loss can be alleviated thanks to mixed precision quantization, allowing for more flexible bitwidth allocation.","However, standard mixed precision benefits remain limited due to the 1-bit frontier, that forces each parameter to be encoded on at least 1 bit of data.","This paper introduces an approach that combines mixed precision, zero-point quantization and entropy coding to push the compression boundary of Resnets beyond the 1-bit frontier with an accuracy drop below 1% on the ImageNet benchmark.","From an implementation standpoint, a compact decoder architecture features reduced latency, thus allowing for inference-compatible decoding."],"url":"http://arxiv.org/abs/2406.06237v1"}
{"created":"2024-06-10 13:06:28","title":"UnSupDLA: Towards Unsupervised Document Layout Analysis","abstract":"Document layout analysis is a key area in document research, involving techniques like text mining and visual analysis. Despite various methods developed to tackle layout analysis, a critical but frequently overlooked problem is the scarcity of labeled data needed for analyses. With the rise of internet use, an overwhelming number of documents are now available online, making the process of accurately labeling them for research purposes increasingly challenging and labor-intensive. Moreover, the diversity of documents online presents a unique set of challenges in maintaining the quality and consistency of these labels, further complicating document layout analysis in the digital era. To address this, we employ a vision-based approach for analyzing document layouts designed to train a network without labels. Instead, we focus on pre-training, initially generating simple object masks from the unlabeled document images. These masks are then used to train a detector, enhancing object detection and segmentation performance. The model's effectiveness is further amplified through several unsupervised training iterations, continuously refining its performance. This approach significantly advances document layout analysis, particularly precision and efficiency, without labels.","sentences":["Document layout analysis is a key area in document research, involving techniques like text mining and visual analysis.","Despite various methods developed to tackle layout analysis, a critical but frequently overlooked problem is the scarcity of labeled data needed for analyses.","With the rise of internet use, an overwhelming number of documents are now available online, making the process of accurately labeling them for research purposes increasingly challenging and labor-intensive.","Moreover, the diversity of documents online presents a unique set of challenges in maintaining the quality and consistency of these labels, further complicating document layout analysis in the digital era.","To address this, we employ a vision-based approach for analyzing document layouts designed to train a network without labels.","Instead, we focus on pre-training, initially generating simple object masks from the unlabeled document images.","These masks are then used to train a detector, enhancing object detection and segmentation performance.","The model's effectiveness is further amplified through several unsupervised training iterations, continuously refining its performance.","This approach significantly advances document layout analysis, particularly precision and efficiency, without labels."],"url":"http://arxiv.org/abs/2406.06236v1"}
{"created":"2024-06-10 13:00:22","title":"UEMM-Air: A Synthetic Multi-modal Dataset for Unmanned Aerial Vehicle Object Detection","abstract":"The development of multi-modal object detection for Unmanned Aerial Vehicles (UAVs) typically relies on a large amount of pixel-aligned multi-modal image data. However, existing datasets face challenges such as limited modalities, high construction costs, and imprecise annotations. To this end, we propose a synthetic multi-modal UAV-based object detection dataset, UEMM-Air. Specially, we simulate various UAV flight scenarios and object types using the Unreal Engine (UE). Then we design the UAV's flight logic to automatically collect data from different scenarios, perspectives, and altitudes. Finally, we propose a novel heuristic automatic annotation algorithm to generate accurate object detection labels. In total, our UEMM-Air consists of 20k pairs of images with 5 modalities and precise annotations. Moreover, we conduct numerous experiments and establish new benchmark results on our dataset. We found that models pre-trained on UEMM-Air exhibit better performance on downstream tasks compared to other similar datasets. The dataset is publicly available (https://github.com/1e12Leon/UEMM-Air) to support the research of multi-modal UAV object detection models.","sentences":["The development of multi-modal object detection for Unmanned Aerial Vehicles (UAVs) typically relies on a large amount of pixel-aligned multi-modal image data.","However, existing datasets face challenges such as limited modalities, high construction costs, and imprecise annotations.","To this end, we propose a synthetic multi-modal UAV-based object detection dataset, UEMM-Air.","Specially, we simulate various UAV flight scenarios and object types using the Unreal Engine (UE).","Then we design the UAV's flight logic to automatically collect data from different scenarios, perspectives, and altitudes.","Finally, we propose a novel heuristic automatic annotation algorithm to generate accurate object detection labels.","In total, our UEMM-Air consists of 20k pairs of images with 5 modalities and precise annotations.","Moreover, we conduct numerous experiments and establish new benchmark results on our dataset.","We found that models pre-trained on UEMM-Air exhibit better performance on downstream tasks compared to other similar datasets.","The dataset is publicly available (https://github.com/1e12Leon/UEMM-Air) to support the research of multi-modal UAV object detection models."],"url":"http://arxiv.org/abs/2406.06230v1"}
{"created":"2024-06-10 12:53:13","title":"PAC-Bayes Analysis for Recalibration in Classification","abstract":"Nonparametric estimation with binning is widely employed in the calibration error evaluation and the recalibration of machine learning models. Recently, theoretical analyses of the bias induced by this estimation approach have been actively pursued; however, the understanding of the generalization of the calibration error to unknown data remains limited. In addition, although many recalibration algorithms have been proposed, their generalization performance lacks theoretical guarantees. To address this problem, we conduct a generalization analysis of the calibration error under the probably approximately correct (PAC) Bayes framework. This approach enables us to derive a first optimizable upper bound for the generalization error in the calibration context. We then propose a generalization-aware recalibration algorithm based on our generalization theory. Numerical experiments show that our algorithm improves the Gaussian-process-based recalibration performance on various benchmark datasets and models.","sentences":["Nonparametric estimation with binning is widely employed in the calibration error evaluation and the recalibration of machine learning models.","Recently, theoretical analyses of the bias induced by this estimation approach have been actively pursued; however, the understanding of the generalization of the calibration error to unknown data remains limited.","In addition, although many recalibration algorithms have been proposed, their generalization performance lacks theoretical guarantees.","To address this problem, we conduct a generalization analysis of the calibration error under the probably approximately correct (PAC) Bayes framework.","This approach enables us to derive a first optimizable upper bound for the generalization error in the calibration context.","We then propose a generalization-aware recalibration algorithm based on our generalization theory.","Numerical experiments show that our algorithm improves the Gaussian-process-based recalibration performance on various benchmark datasets and models."],"url":"http://arxiv.org/abs/2406.06227v1"}
{"created":"2024-06-10 12:47:49","title":"Siren -- Advancing Cybersecurity through Deception and Adaptive Analysis","abstract":"Siren represents a pioneering research effort aimed at fortifying cybersecurity through strategic integration of deception, machine learning, and proactive threat analysis. Drawing inspiration from mythical sirens, this project employs sophisticated methods to lure potential threats into controlled environments. The system features a dynamic machine learning model for real-time analysis and classification, ensuring continuous adaptability to emerging cyber threats. The architectural framework includes a link monitoring proxy, a purpose-built machine learning model for dynamic link analysis, and a honeypot enriched with simulated user interactions to intensify threat engagement. Data protection within the honeypot is fortified with probabilistic encryption. Additionally, the incorporation of simulated user activity extends the system's capacity to capture and learn from potential attackers even after user disengagement. Siren introduces a paradigm shift in cybersecurity, transforming traditional defense mechanisms into proactive systems that actively engage and learn from potential adversaries. The research strives to enhance user protection while yielding valuable insights for ongoing refinement in response to the evolving landscape of cybersecurity threats.","sentences":["Siren represents a pioneering research effort aimed at fortifying cybersecurity through strategic integration of deception, machine learning, and proactive threat analysis.","Drawing inspiration from mythical sirens, this project employs sophisticated methods to lure potential threats into controlled environments.","The system features a dynamic machine learning model for real-time analysis and classification, ensuring continuous adaptability to emerging cyber threats.","The architectural framework includes a link monitoring proxy, a purpose-built machine learning model for dynamic link analysis, and a honeypot enriched with simulated user interactions to intensify threat engagement.","Data protection within the honeypot is fortified with probabilistic encryption.","Additionally, the incorporation of simulated user activity extends the system's capacity to capture and learn from potential attackers even after user disengagement.","Siren introduces a paradigm shift in cybersecurity, transforming traditional defense mechanisms into proactive systems that actively engage and learn from potential adversaries.","The research strives to enhance user protection while yielding valuable insights for ongoing refinement in response to the evolving landscape of cybersecurity threats."],"url":"http://arxiv.org/abs/2406.06225v1"}
{"created":"2024-06-10 12:33:47","title":"Data Augmentation in Earth Observation: A Diffusion Model Approach","abstract":"The scarcity of high-quality Earth Observation (EO) imagery poses a significant challenge, despite its critical role in enabling precise analysis and informed decision-making across various sectors. This scarcity is primarily due to atmospheric conditions, seasonal variations, and limited geographical coverage, which complicates the application of Artificial Intelligence (AI) in EO. Data augmentation, a widely used technique in AI that involves generating additional data mainly through parameterized image transformations, has been employed to increase the volume and diversity of data. However, this method often falls short in generating sufficient diversity across key semantic axes, adversely affecting the accuracy of EO applications. To address this issue, we propose a novel four-stage approach aimed at improving the diversity of augmented data by integrating diffusion models. Our approach employs meta-prompts for instruction generation, harnesses general-purpose vision-language models for generating rich captions, fine-tunes an Earth Observation diffusion model, and iteratively augments data. We conducted extensive experiments using four different data augmentation techniques, and our approach consistently demonstrated improvements, outperforming the established augmentation methods, revealing its effectiveness in generating semantically rich and diverse EO images.","sentences":["The scarcity of high-quality Earth Observation (EO) imagery poses a significant challenge, despite its critical role in enabling precise analysis and informed decision-making across various sectors.","This scarcity is primarily due to atmospheric conditions, seasonal variations, and limited geographical coverage, which complicates the application of Artificial Intelligence (AI) in EO.","Data augmentation, a widely used technique in AI that involves generating additional data mainly through parameterized image transformations, has been employed to increase the volume and diversity of data.","However, this method often falls short in generating sufficient diversity across key semantic axes, adversely affecting the accuracy of EO applications.","To address this issue, we propose a novel four-stage approach aimed at improving the diversity of augmented data by integrating diffusion models.","Our approach employs meta-prompts for instruction generation, harnesses general-purpose vision-language models for generating rich captions, fine-tunes an Earth Observation diffusion model, and iteratively augments data.","We conducted extensive experiments using four different data augmentation techniques, and our approach consistently demonstrated improvements, outperforming the established augmentation methods, revealing its effectiveness in generating semantically rich and diverse EO images."],"url":"http://arxiv.org/abs/2406.06218v1"}
{"created":"2024-06-10 12:25:13","title":"A Statistical Theory of Regularization-Based Continual Learning","abstract":"We provide a statistical analysis of regularization-based continual learning on a sequence of linear regression tasks, with emphasis on how different regularization terms affect the model performance. We first derive the convergence rate for the oracle estimator obtained as if all data were available simultaneously. Next, we consider a family of generalized $\\ell_2$-regularization algorithms indexed by matrix-valued hyperparameters, which includes the minimum norm estimator and continual ridge regression as special cases. As more tasks are introduced, we derive an iterative update formula for the estimation error of generalized $\\ell_2$-regularized estimators, from which we determine the hyperparameters resulting in the optimal algorithm. Interestingly, the choice of hyperparameters can effectively balance the trade-off between forward and backward knowledge transfer and adjust for data heterogeneity. Moreover, the estimation error of the optimal algorithm is derived explicitly, which is of the same order as that of the oracle estimator. In contrast, our lower bounds for the minimum norm estimator and continual ridge regression show their suboptimality. A byproduct of our theoretical analysis is the equivalence between early stopping and generalized $\\ell_2$-regularization in continual learning, which may be of independent interest. Finally, we conduct experiments to complement our theory.","sentences":["We provide a statistical analysis of regularization-based continual learning on a sequence of linear regression tasks, with emphasis on how different regularization terms affect the model performance.","We first derive the convergence rate for the oracle estimator obtained as if all data were available simultaneously.","Next, we consider a family of generalized $\\ell_2$-regularization algorithms indexed by matrix-valued hyperparameters, which includes the minimum norm estimator and continual ridge regression as special cases.","As more tasks are introduced, we derive an iterative update formula for the estimation error of generalized $\\ell_2$-regularized estimators, from which we determine the hyperparameters resulting in the optimal algorithm.","Interestingly, the choice of hyperparameters can effectively balance the trade-off between forward and backward knowledge transfer and adjust for data heterogeneity.","Moreover, the estimation error of the optimal algorithm is derived explicitly, which is of the same order as that of the oracle estimator.","In contrast, our lower bounds for the minimum norm estimator and continual ridge regression show their suboptimality.","A byproduct of our theoretical analysis is the equivalence between early stopping and generalized $\\ell_2$-regularization in continual learning, which may be of independent interest.","Finally, we conduct experiments to complement our theory."],"url":"http://arxiv.org/abs/2406.06213v1"}
{"created":"2024-06-10 12:14:05","title":"Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning","abstract":"Federated Learning (FL) is a collaborative machine learning technique where multiple clients work together with a central server to train a global model without sharing their private data. However, the distribution shift across non-IID datasets of clients poses a challenge to this one-model-fits-all method hindering the ability of the global model to effectively adapt to each client's unique local data. To echo this challenge, personalized FL (PFL) is designed to allow each client to create personalized local models tailored to their private data. While extensive research has scrutinized backdoor risks in FL, it has remained underexplored in PFL applications. In this study, we delve deep into the vulnerabilities of PFL to backdoor attacks. Our analysis showcases a tale of two cities. On the one hand, the personalization process in PFL can dilute the backdoor poisoning effects injected into the personalized local models. Furthermore, PFL systems can also deploy both server-end and client-end defense mechanisms to strengthen the barrier against backdoor attacks. On the other hand, our study shows that PFL fortified with these defense methods may offer a false sense of security. We propose \\textit{PFedBA}, a stealthy and effective backdoor attack strategy applicable to PFL systems. \\textit{PFedBA} ingeniously aligns the backdoor learning task with the main learning task of PFL by optimizing the trigger generation process. Our comprehensive experiments demonstrate the effectiveness of \\textit{PFedBA} in seamlessly embedding triggers into personalized local models. \\textit{PFedBA} yields outstanding attack performance across 10 state-of-the-art PFL algorithms, defeating the existing 6 defense mechanisms. Our study sheds light on the subtle yet potent backdoor threats to PFL systems, urging the community to bolster defenses against emerging backdoor challenges.","sentences":["Federated Learning (FL) is a collaborative machine learning technique where multiple clients work together with a central server to train a global model without sharing their private data.","However, the distribution shift across non-IID datasets of clients poses a challenge to this one-model-fits-all method hindering the ability of the global model to effectively adapt to each client's unique local data.","To echo this challenge, personalized FL (PFL) is designed to allow each client to create personalized local models tailored to their private data.","While extensive research has scrutinized backdoor risks in FL, it has remained underexplored in PFL applications.","In this study, we delve deep into the vulnerabilities of PFL to backdoor attacks.","Our analysis showcases a tale of two cities.","On the one hand, the personalization process in PFL can dilute the backdoor poisoning effects injected into the personalized local models.","Furthermore, PFL systems can also deploy both server-end and client-end defense mechanisms to strengthen the barrier against backdoor attacks.","On the other hand, our study shows that PFL fortified with these defense methods may offer a false sense of security.","We propose \\textit{PFedBA}, a stealthy and effective backdoor attack strategy applicable to PFL systems.","\\textit{PFedBA} ingeniously aligns the backdoor learning task with the main learning task of PFL by optimizing the trigger generation process.","Our comprehensive experiments demonstrate the effectiveness of \\textit{PFedBA} in seamlessly embedding triggers into personalized local models.","\\textit{PFedBA} yields outstanding attack performance across 10 state-of-the-art PFL algorithms, defeating the existing 6 defense mechanisms.","Our study sheds light on the subtle yet potent backdoor threats to PFL systems, urging the community to bolster defenses against emerging backdoor challenges."],"url":"http://arxiv.org/abs/2406.06207v1"}
{"created":"2024-06-10 11:58:11","title":"Federated learning in food research","abstract":"Research in the food domain is at times limited due to data sharing obstacles, such as data ownership, privacy requirements, and regulations. While important, these obstacles can restrict data-driven methods such as machine learning. Federated learning, the approach of training models on locally kept data and only sharing the learned parameters, is a potential technique to alleviate data sharing obstacles. This systematic review investigates the use of federated learning within the food domain, structures included papers in a federated learning framework, highlights knowledge gaps, and discusses potential applications. A total of 41 papers were included in the review. The current applications include solutions to water and milk quality assessment, cybersecurity of water processing, pesticide residue risk analysis, weed detection, and fraud detection, focusing on centralized horizontal federated learning. One of the gaps found was the lack of vertical or transfer federated learning and decentralized architectures.","sentences":["Research in the food domain is at times limited due to data sharing obstacles, such as data ownership, privacy requirements, and regulations.","While important, these obstacles can restrict data-driven methods such as machine learning.","Federated learning, the approach of training models on locally kept data and only sharing the learned parameters, is a potential technique to alleviate data sharing obstacles.","This systematic review investigates the use of federated learning within the food domain, structures included papers in a federated learning framework, highlights knowledge gaps, and discusses potential applications.","A total of 41 papers were included in the review.","The current applications include solutions to water and milk quality assessment, cybersecurity of water processing, pesticide residue risk analysis, weed detection, and fraud detection, focusing on centralized horizontal federated learning.","One of the gaps found was the lack of vertical or transfer federated learning and decentralized architectures."],"url":"http://arxiv.org/abs/2406.06202v1"}
{"created":"2024-06-10 11:50:29","title":"LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages","abstract":"In this paper, we present the LingOly benchmark, a novel benchmark for advanced reasoning abilities in large language models. Using challenging Linguistic Olympiad puzzles, we evaluate (i) capabilities for in-context identification and generalisation of linguistic patterns in very low-resource or extinct languages, and (ii) abilities to follow complex task instructions. The LingOly benchmark covers more than 90 mostly low-resource languages, minimising issues of data contamination, and contains 1,133 problems across 6 formats and 5 levels of human difficulty. We assess performance with both direct accuracy and comparison to a no-context baseline to penalise memorisation. Scores from 11 state-of-the-art LLMs demonstrate the benchmark to be challenging, and models perform poorly on the higher difficulty problems. On harder problems, even the top model only achieved 35.3% accuracy, 21.7% improvement over the no-context baseline. Large closed models typically outperform open models, and in general, the higher resource the language, the better the scores. These results indicate, in absence of memorisation, true multi-step out-of-domain reasoning remains a challenge for current language models.","sentences":["In this paper, we present the LingOly benchmark, a novel benchmark for advanced reasoning abilities in large language models.","Using challenging Linguistic Olympiad puzzles, we evaluate (i) capabilities for in-context identification and generalisation of linguistic patterns in very low-resource or extinct languages, and (ii) abilities to follow complex task instructions.","The LingOly benchmark covers more than 90 mostly low-resource languages, minimising issues of data contamination, and contains 1,133 problems across 6 formats and 5 levels of human difficulty.","We assess performance with both direct accuracy and comparison to a no-context baseline to penalise memorisation.","Scores from 11 state-of-the-art LLMs demonstrate the benchmark to be challenging, and models perform poorly on the higher difficulty problems.","On harder problems, even the top model only achieved 35.3% accuracy, 21.7% improvement over the no-context baseline.","Large closed models typically outperform open models, and in general, the higher resource the language, the better the scores.","These results indicate, in absence of memorisation, true multi-step out-of-domain reasoning remains a challenge for current language models."],"url":"http://arxiv.org/abs/2406.06196v1"}
{"created":"2024-06-10 11:44:15","title":"AI Cat Narrator: Designing an AI Tool for Exploring the Shared World and Social Connection with a Cat","abstract":"As technology continues to advance, the interaction between humans and cats is becoming more diverse. Our research introduces a new tool called the AI Cat Narrator, which offers a unique perspective on the shared lives of humans and cats. We combined the method of ethnography with fictional storytelling, using a defamiliarization strategy to merge real-world data seen through the eyes of cats with excerpts from cat literature. This combination serves as the foundation for a database to instruct the AI Cat Narrator in crafting alternative narrative. Our findings indicate that using defamiliarized data for training purposes significantly contributes to the development of characters that are both more empathetic and individualized. The contributions of our study are twofold: 1) proposing an innovative approach to prompting a reevaluation of living alongside cats; 2) establishing a collaborative, exploratory tool developed by humans, cats, and AI together.","sentences":["As technology continues to advance, the interaction between humans and cats is becoming more diverse.","Our research introduces a new tool called the AI Cat Narrator, which offers a unique perspective on the shared lives of humans and cats.","We combined the method of ethnography with fictional storytelling, using a defamiliarization strategy to merge real-world data seen through the eyes of cats with excerpts from cat literature.","This combination serves as the foundation for a database to instruct the AI Cat Narrator in crafting alternative narrative.","Our findings indicate that using defamiliarized data for training purposes significantly contributes to the development of characters that are both more empathetic and individualized.","The contributions of our study are twofold: 1) proposing an innovative approach to prompting a reevaluation of living alongside cats; 2) establishing a collaborative, exploratory tool developed by humans, cats, and AI together."],"url":"http://arxiv.org/abs/2406.06192v1"}
{"created":"2024-06-10 11:31:04","title":"A Survey on Machine Unlearning: Techniques and New Emerged Privacy Risks","abstract":"The explosive growth of machine learning has made it a critical infrastructure in the era of artificial intelligence. The extensive use of data poses a significant threat to individual privacy. Various countries have implemented corresponding laws, such as GDPR, to protect individuals' data privacy and the right to be forgotten. This has made machine unlearning a research hotspot in the field of privacy protection in recent years, with the aim of efficiently removing the contribution and impact of individual data from trained models. The research in academia on machine unlearning has continuously enriched its theoretical foundation, and many methods have been proposed, targeting different data removal requests in various application scenarios. However, recently researchers have found potential privacy leakages of various of machine unlearning approaches, making the privacy preservation on machine unlearning area a critical topic. This paper provides an overview and analysis of the existing research on machine unlearning, aiming to present the current vulnerabilities of machine unlearning approaches. We analyze privacy risks in various aspects, including definitions, implementation methods, and real-world applications. Compared to existing reviews, we analyze the new challenges posed by the latest malicious attack techniques on machine unlearning from the perspective of privacy threats. We hope that this survey can provide an initial but comprehensive discussion on this new emerging area.","sentences":["The explosive growth of machine learning has made it a critical infrastructure in the era of artificial intelligence.","The extensive use of data poses a significant threat to individual privacy.","Various countries have implemented corresponding laws, such as GDPR, to protect individuals' data privacy and the right to be forgotten.","This has made machine unlearning a research hotspot in the field of privacy protection in recent years, with the aim of efficiently removing the contribution and impact of individual data from trained models.","The research in academia on machine unlearning has continuously enriched its theoretical foundation, and many methods have been proposed, targeting different data removal requests in various application scenarios.","However, recently researchers have found potential privacy leakages of various of machine unlearning approaches, making the privacy preservation on machine unlearning area a critical topic.","This paper provides an overview and analysis of the existing research on machine unlearning, aiming to present the current vulnerabilities of machine unlearning approaches.","We analyze privacy risks in various aspects, including definitions, implementation methods, and real-world applications.","Compared to existing reviews, we analyze the new challenges posed by the latest malicious attack techniques on machine unlearning from the perspective of privacy threats.","We hope that this survey can provide an initial but comprehensive discussion on this new emerging area."],"url":"http://arxiv.org/abs/2406.06186v1"}
{"created":"2024-06-10 11:00:26","title":"Generalized Nested Latent Variable Models for Lossy Coding applied to Wind Turbine Scenarios","abstract":"Rate-distortion optimization through neural networks has accomplished competitive results in compression efficiency and image quality. This learning-based approach seeks to minimize the compromise between compression rate and reconstructed image quality by automatically extracting and retaining crucial information, while discarding less critical details. A successful technique consists in introducing a deep hyperprior that operates within a 2-level nested latent variable model, enhancing compression by capturing complex data dependencies. This paper extends this concept by designing a generalized L-level nested generative model with a Markov chain structure. We demonstrate as L increases that a trainable prior is detrimental and explore a common dimensionality along the distinct latent variables to boost compression performance. As this structured framework can represent autoregressive coders, we outperform the hyperprior model and achieve state-of-the-art performance while reducing substantially the computational cost. Our experimental evaluation is performed on wind turbine scenarios to study its application on visual inspections","sentences":["Rate-distortion optimization through neural networks has accomplished competitive results in compression efficiency and image quality.","This learning-based approach seeks to minimize the compromise between compression rate and reconstructed image quality by automatically extracting and retaining crucial information, while discarding less critical details.","A successful technique consists in introducing a deep hyperprior that operates within a 2-level nested latent variable model, enhancing compression by capturing complex data dependencies.","This paper extends this concept by designing a generalized L-level nested generative model with a Markov chain structure.","We demonstrate as L increases that a trainable prior is detrimental and explore a common dimensionality along the distinct latent variables to boost compression performance.","As this structured framework can represent autoregressive coders, we outperform the hyperprior model and achieve state-of-the-art performance while reducing substantially the computational cost.","Our experimental evaluation is performed on wind turbine scenarios to study its application on visual inspections"],"url":"http://arxiv.org/abs/2406.06165v1"}
{"created":"2024-06-10 10:53:23","title":"Extending Segment Anything Model into Auditory and Temporal Dimensions for Audio-Visual Segmentation","abstract":"Audio-visual segmentation (AVS) aims to segment sound sources in the video sequence, requiring a pixel-level understanding of audio-visual correspondence. As the Segment Anything Model (SAM) has strongly impacted extensive fields of dense prediction problems, prior works have investigated the introduction of SAM into AVS with audio as a new modality of the prompt. Nevertheless, constrained by SAM's single-frame segmentation scheme, the temporal context across multiple frames of audio-visual data remains insufficiently utilized. To this end, we study the extension of SAM's capabilities to the sequence of audio-visual scenes by analyzing contextual cross-modal relationships across the frames. To achieve this, we propose a Spatio-Temporal, Bidirectional Audio-Visual Attention (ST-BAVA) module integrated into the middle of SAM's image encoder and mask decoder. It adaptively updates the audio-visual features to convey the spatio-temporal correspondence between the video frames and audio streams. Extensive experiments demonstrate that our proposed model outperforms the state-of-the-art methods on AVS benchmarks, especially with an 8.3% mIoU gain on a challenging multi-sources subset.","sentences":["Audio-visual segmentation (AVS) aims to segment sound sources in the video sequence, requiring a pixel-level understanding of audio-visual correspondence.","As the Segment Anything Model (SAM) has strongly impacted extensive fields of dense prediction problems, prior works have investigated the introduction of SAM into AVS with audio as a new modality of the prompt.","Nevertheless, constrained by SAM's single-frame segmentation scheme, the temporal context across multiple frames of audio-visual data remains insufficiently utilized.","To this end, we study the extension of SAM's capabilities to the sequence of audio-visual scenes by analyzing contextual cross-modal relationships across the frames.","To achieve this, we propose a Spatio-Temporal, Bidirectional Audio-Visual Attention (ST-BAVA) module integrated into the middle of SAM's image encoder and mask decoder.","It adaptively updates the audio-visual features to convey the spatio-temporal correspondence between the video frames and audio streams.","Extensive experiments demonstrate that our proposed model outperforms the state-of-the-art methods on AVS benchmarks, especially with an 8.3% mIoU gain on a challenging multi-sources subset."],"url":"http://arxiv.org/abs/2406.06163v1"}
{"created":"2024-06-10 10:42:37","title":"Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning","abstract":"While the impressive performance of modern neural networks is often attributed to their capacity to efficiently extract task-relevant features from data, the mechanisms underlying this rich feature learning regime remain elusive, with much of our theoretical understanding stemming from the opposing lazy regime. In this work, we derive exact solutions to a minimal model that transitions between lazy and rich learning, precisely elucidating how unbalanced layer-specific initialization variances and learning rates determine the degree of feature learning. Our analysis reveals that they conspire to influence the learning regime through a set of conserved quantities that constrain and modify the geometry of learning trajectories in parameter and function space. We extend our analysis to more complex linear models with multiple neurons, outputs, and layers and to shallow nonlinear networks with piecewise linear activation functions. In linear networks, rapid feature learning only occurs with balanced initializations, where all layers learn at similar speeds. While in nonlinear networks, unbalanced initializations that promote faster learning in earlier layers can accelerate rich learning. Through a series of experiments, we provide evidence that this unbalanced rich regime drives feature learning in deep finite-width networks, promotes interpretability of early layers in CNNs, reduces the sample complexity of learning hierarchical data, and decreases the time to grokking in modular arithmetic. Our theory motivates further exploration of unbalanced initializations to enhance efficient feature learning.","sentences":["While the impressive performance of modern neural networks is often attributed to their capacity to efficiently extract task-relevant features from data, the mechanisms underlying this rich feature learning regime remain elusive, with much of our theoretical understanding stemming from the opposing lazy regime.","In this work, we derive exact solutions to a minimal model that transitions between lazy and rich learning, precisely elucidating how unbalanced layer-specific initialization variances and learning rates determine the degree of feature learning.","Our analysis reveals that they conspire to influence the learning regime through a set of conserved quantities that constrain and modify the geometry of learning trajectories in parameter and function space.","We extend our analysis to more complex linear models with multiple neurons, outputs, and layers and to shallow nonlinear networks with piecewise linear activation functions.","In linear networks, rapid feature learning only occurs with balanced initializations, where all layers learn at similar speeds.","While in nonlinear networks, unbalanced initializations that promote faster learning in earlier layers can accelerate rich learning.","Through a series of experiments, we provide evidence that this unbalanced rich regime drives feature learning in deep finite-width networks, promotes interpretability of early layers in CNNs, reduces the sample complexity of learning hierarchical data, and decreases the time to grokking in modular arithmetic.","Our theory motivates further exploration of unbalanced initializations to enhance efficient feature learning."],"url":"http://arxiv.org/abs/2406.06158v1"}
{"created":"2024-06-10 10:39:28","title":"Stronger, Faster, and Cheaper Log Parsing with LLMs","abstract":"Log parsing, the process of converting raw log messages into structured formats, is an important initial step for automated analysis of logs of large-scale software systems. Traditional log parsers often rely on heuristics or handcrafted features, which may not generalize well across diverse log sources or require extensive model tuning. Recently, some log parsers have utilized powerful generative capabilities of large language models (LLMs). However, they heavily rely on demonstration examples, resulting in substantial overhead in LLM invocations. To address these issues, we propose LogBatcher, a cost-effective LLM-based log parser that requires no training process or labeled data. To leverage latent characteristics of log data and reduce the overhead, we divide logs into several partitions through clustering. Then we perform a cache matching process to match logs with previously parsed log templates. Finally, we provide LLMs with better prompt context specialized for log parsing by batching a group of logs from each partition. We have conducted experiments on 16 public log datasets and the results show that LogBatcher is effective and efficient for log parsing.","sentences":["Log parsing, the process of converting raw log messages into structured formats, is an important initial step for automated analysis of logs of large-scale software systems.","Traditional log parsers often rely on heuristics or handcrafted features, which may not generalize well across diverse log sources or require extensive model tuning.","Recently, some log parsers have utilized powerful generative capabilities of large language models (LLMs).","However, they heavily rely on demonstration examples, resulting in substantial overhead in LLM invocations.","To address these issues, we propose LogBatcher, a cost-effective LLM-based log parser that requires no training process or labeled data.","To leverage latent characteristics of log data and reduce the overhead, we divide logs into several partitions through clustering.","Then we perform a cache matching process to match logs with previously parsed log templates.","Finally, we provide LLMs with better prompt context specialized for log parsing by batching a group of logs from each partition.","We have conducted experiments on 16 public log datasets and the results show that LogBatcher is effective and efficient for log parsing."],"url":"http://arxiv.org/abs/2406.06156v1"}
{"created":"2024-06-10 10:31:39","title":"Towards a real-time distributed feedback system for the transportation assistance of PwD","abstract":"In this work we propose the design principles of an integrated distributed system for the augment of the transportation for people with disabilities inside the road network of a city area utilizing the IT technologies. We propose the basis of our system upon the utilization of a distributed sensor network that will be incorporated by a real-time integrated feedback system. The main components of the proposed architecture include the Inaccessible City Point System, the Live Data Analysis and Response System, and the Obstruction Detection and Prevention System. The incorporation of these subsystems will provide real-time feedback assisting the transportation of individuals with mobility problems informing them on real-time about blocked ramps across the path defined to their destination, being also responsible for the information of the authorities about incidents regarding the collision of accessibility in place where the sensors detect an inaccessible point. The proposed design allows the addition of further extensions regarding the assistance of individuals with mobility problems providing a basis for its further implementation and improvement. In this work we provide the fundamental parts regarding the interconnection of the proposed architecture's components as also its potential deployment regarding the proposed architecture and its application in the area of a city.","sentences":["In this work we propose the design principles of an integrated distributed system for the augment of the transportation for people with disabilities inside the road network of a city area utilizing the IT technologies.","We propose the basis of our system upon the utilization of a distributed sensor network that will be incorporated by a real-time integrated feedback system.","The main components of the proposed architecture include the Inaccessible City Point System, the Live Data Analysis and Response System, and the Obstruction Detection and Prevention System.","The incorporation of these subsystems will provide real-time feedback assisting the transportation of individuals with mobility problems informing them on real-time about blocked ramps across the path defined to their destination, being also responsible for the information of the authorities about incidents regarding the collision of accessibility in place where the sensors detect an inaccessible point.","The proposed design allows the addition of further extensions regarding the assistance of individuals with mobility problems providing a basis for its further implementation and improvement.","In this work we provide the fundamental parts regarding the interconnection of the proposed architecture's components as also its potential deployment regarding the proposed architecture and its application in the area of a city."],"url":"http://arxiv.org/abs/2406.06154v1"}
{"created":"2024-06-10 10:15:32","title":"Decoupled Marked Temporal Point Process using Neural Ordinary Differential Equations","abstract":"A Marked Temporal Point Process (MTPP) is a stochastic process whose realization is a set of event-time data. MTPP is often used to understand complex dynamics of asynchronous temporal events such as money transaction, social media, healthcare, etc. Recent studies have utilized deep neural networks to capture complex temporal dependencies of events and generate embedding that aptly represent the observed events. While most previous studies focus on the inter-event dependencies and their representations, how individual events influence the overall dynamics over time has been under-explored. In this regime, we propose a Decoupled MTPP framework that disentangles characterization of a stochastic process into a set of evolving influences from different events. Our approach employs Neural Ordinary Differential Equations (Neural ODEs) to learn flexible continuous dynamics of these influences while simultaneously addressing multiple inference problems, such as density estimation and survival rate computation. We emphasize the significance of disentangling the influences by comparing our framework with state-of-the-art methods on real-life datasets, and provide analysis on the model behavior for potential applications.","sentences":["A Marked Temporal Point Process (MTPP) is a stochastic process whose realization is a set of event-time data.","MTPP is often used to understand complex dynamics of asynchronous temporal events such as money transaction, social media, healthcare, etc.","Recent studies have utilized deep neural networks to capture complex temporal dependencies of events and generate embedding that aptly represent the observed events.","While most previous studies focus on the inter-event dependencies and their representations, how individual events influence the overall dynamics over time has been under-explored.","In this regime, we propose a Decoupled MTPP framework that disentangles characterization of a stochastic process into a set of evolving influences from different events.","Our approach employs Neural Ordinary Differential Equations (Neural ODEs) to learn flexible continuous dynamics of these influences while simultaneously addressing multiple inference problems, such as density estimation and survival rate computation.","We emphasize the significance of disentangling the influences by comparing our framework with state-of-the-art methods on real-life datasets, and provide analysis on the model behavior for potential applications."],"url":"http://arxiv.org/abs/2406.06149v1"}
{"created":"2024-06-10 10:08:50","title":"Revisiting 3D Cartesian Scatterplots with a Novel Plotting Framework and a Survey","abstract":"3D scatter plots are a powerful visualisation method by being able to represent 3 dimensions spatially. It can also enable the representation of additional dimensions, such as by using a colour map. An important issue with the current state of plotting software is the limited use of physical properties from the real world such as shadows to improve the effectiveness of the plots. A popular example is with the use of isometric axes in combination with same-sized points, which is equivalent to removing one whole dimension (depth perception). In static snapshot images, as found in digital and hard prints, as well with discrete data, additional cues such as movement are not present to mitigate for the loss of spatial information.   In this paper we present a novel plotting framework that features a wide range of techniques to improve the information transfer from 3D scatterplots for multi-dimensional data. We evaluate the resulting plots by surveying 57 participants from an academic institution to get important insights on what makes 3D scatterplots effective in communicating data of more than two dimensions.","sentences":["3D scatter plots are a powerful visualisation method by being able to represent 3 dimensions spatially.","It can also enable the representation of additional dimensions, such as by using a colour map.","An important issue with the current state of plotting software is the limited use of physical properties from the real world such as shadows to improve the effectiveness of the plots.","A popular example is with the use of isometric axes in combination with same-sized points, which is equivalent to removing one whole dimension (depth perception).","In static snapshot images, as found in digital and hard prints, as well with discrete data, additional cues such as movement are not present to mitigate for the loss of spatial information.   ","In this paper we present a novel plotting framework that features a wide range of techniques to improve the information transfer from 3D scatterplots for multi-dimensional data.","We evaluate the resulting plots by surveying 57 participants from an academic institution to get important insights on what makes 3D scatterplots effective in communicating data of more than two dimensions."],"url":"http://arxiv.org/abs/2406.06146v1"}
{"created":"2024-06-10 10:03:16","title":"Language Models Resist Alignment","abstract":"Large language models (LLMs) may exhibit undesirable behaviors. Recent efforts have focused on aligning these models to prevent harmful generation. Despite these efforts, studies have shown that even a well-conducted alignment process can be easily circumvented, whether intentionally or accidentally. Do alignment fine-tuning have robust effects on models, or are merely superficial? In this work, we answer this question through both theoretical and empirical means. Empirically, we demonstrate the elasticity of post-alignment models, i.e., the tendency to revert to the behavior distribution formed during the pre-training phase upon further fine-tuning. Using compression theory, we formally derive that such fine-tuning process \\textit{disproportionately} undermines alignment compared to pre-training, potentially by orders of magnitude. We conduct experimental validations to confirm the presence of elasticity across models of varying types and sizes. Specifically, we find that model performance declines rapidly before reverting to the pre-training distribution, after which the rate of decline drops significantly. We further reveal that elasticity positively correlates with increased model size and the expansion of pre-training data. Our discovery signifies the importance of taming the inherent elasticity of LLMs, thereby overcoming the resistance of LLMs to alignment finetuning.","sentences":["Large language models (LLMs) may exhibit undesirable behaviors.","Recent efforts have focused on aligning these models to prevent harmful generation.","Despite these efforts, studies have shown that even a well-conducted alignment process can be easily circumvented, whether intentionally or accidentally.","Do alignment fine-tuning have robust effects on models, or are merely superficial?","In this work, we answer this question through both theoretical and empirical means.","Empirically, we demonstrate the elasticity of post-alignment models, i.e., the tendency to revert to the behavior distribution formed during the pre-training phase upon further fine-tuning.","Using compression theory, we formally derive that such fine-tuning process \\textit{disproportionately} undermines alignment compared to pre-training, potentially by orders of magnitude.","We conduct experimental validations to confirm the presence of elasticity across models of varying types and sizes.","Specifically, we find that model performance declines rapidly before reverting to the pre-training distribution, after which the rate of decline drops significantly.","We further reveal that elasticity positively correlates with increased model size and the expansion of pre-training data.","Our discovery signifies the importance of taming the inherent elasticity of LLMs, thereby overcoming the resistance of LLMs to alignment finetuning."],"url":"http://arxiv.org/abs/2406.06144v1"}
{"created":"2024-06-10 09:45:38","title":"DiffInject: Revisiting Debias via Synthetic Data Generation using Diffusion-based Style Injection","abstract":"Dataset bias is a significant challenge in machine learning, where specific attributes, such as texture or color of the images are unintentionally learned resulting in detrimental performance. To address this, previous efforts have focused on debiasing models either by developing novel debiasing algorithms or by generating synthetic data to mitigate the prevalent dataset biases. However, generative approaches to date have largely relied on using bias-specific samples from the dataset, which are typically too scarce. In this work, we propose, DiffInject, a straightforward yet powerful method to augment synthetic bias-conflict samples using a pretrained diffusion model. This approach significantly advances the use of diffusion models for debiasing purposes by manipulating the latent space. Our framework does not require any explicit knowledge of the bias types or labelling, making it a fully unsupervised setting for debiasing. Our methodology demonstrates substantial result in effectively reducing dataset bias.","sentences":["Dataset bias is a significant challenge in machine learning, where specific attributes, such as texture or color of the images are unintentionally learned resulting in detrimental performance.","To address this, previous efforts have focused on debiasing models either by developing novel debiasing algorithms or by generating synthetic data to mitigate the prevalent dataset biases.","However, generative approaches to date have largely relied on using bias-specific samples from the dataset, which are typically too scarce.","In this work, we propose, DiffInject, a straightforward yet powerful method to augment synthetic bias-conflict samples using a pretrained diffusion model.","This approach significantly advances the use of diffusion models for debiasing purposes by manipulating the latent space.","Our framework does not require any explicit knowledge of the bias types or labelling, making it a fully unsupervised setting for debiasing.","Our methodology demonstrates substantial result in effectively reducing dataset bias."],"url":"http://arxiv.org/abs/2406.06134v1"}
{"created":"2024-06-10 09:44:06","title":"ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models","abstract":"We propose ExtraNeRF, a novel method for extrapolating the range of views handled by a Neural Radiance Field (NeRF). Our main idea is to leverage NeRFs to model scene-specific, fine-grained details, while capitalizing on diffusion models to extrapolate beyond our observed data. A key ingredient is to track visibility to determine what portions of the scene have not been observed, and focus on reconstructing those regions consistently with diffusion models. Our primary contributions include a visibility-aware diffusion-based inpainting module that is fine-tuned on the input imagery, yielding an initial NeRF with moderate quality (often blurry) inpainted regions, followed by a second diffusion model trained on the input imagery to consistently enhance, notably sharpen, the inpainted imagery from the first pass. We demonstrate high-quality results, extrapolating beyond a small number of (typically six or fewer) input views, effectively outpainting the NeRF as well as inpainting newly disoccluded regions inside the original viewing volume. We compare with related work both quantitatively and qualitatively and show significant gains over prior art.","sentences":["We propose ExtraNeRF, a novel method for extrapolating the range of views handled by a Neural Radiance Field (NeRF).","Our main idea is to leverage NeRFs to model scene-specific, fine-grained details, while capitalizing on diffusion models to extrapolate beyond our observed data.","A key ingredient is to track visibility to determine what portions of the scene have not been observed, and focus on reconstructing those regions consistently with diffusion models.","Our primary contributions include a visibility-aware diffusion-based inpainting module that is fine-tuned on the input imagery, yielding an initial NeRF with moderate quality (often blurry) inpainted regions, followed by a second diffusion model trained on the input imagery to consistently enhance, notably sharpen, the inpainted imagery from the first pass.","We demonstrate high-quality results, extrapolating beyond a small number of (typically six or fewer) input views, effectively outpainting the NeRF as well as inpainting newly disoccluded regions inside the original viewing volume.","We compare with related work both quantitatively and qualitatively and show significant gains over prior art."],"url":"http://arxiv.org/abs/2406.06133v1"}
{"created":"2024-06-10 09:39:19","title":"Building Bridges: A Dataset for Evaluating Gender-Fair Machine Translation into German","abstract":"The translation of gender-neutral person-referring terms (e.g., the students) is often non-trivial. Translating from English into German poses an interesting case -- in German, person-referring nouns are usually gender-specific, and if the gender of the referent(s) is unknown or diverse, the generic masculine (die Studenten (m.)) is commonly used. This solution, however, reduces the visibility of other genders, such as women and non-binary people. To counteract gender discrimination, a societal movement towards using gender-fair language exists (e.g., by adopting neosystems). However, gender-fair German is currently barely supported in machine translation (MT), requiring post-editing or manual translations. We address this research gap by studying gender-fair language in English-to-German MT. Concretely, we enrich a community-created gender-fair language dictionary and sample multi-sentence test instances from encyclopedic text and parliamentary speeches. Using these novel resources, we conduct the first benchmark study involving two commercial systems and six neural MT models for translating words in isolation and natural contexts across two domains. Our findings show that most systems produce mainly masculine forms and rarely gender-neutral variants, highlighting the need for future research. We release code and data at https://github.com/g8a9/building-bridges-gender-fair-german-mt.","sentences":["The translation of gender-neutral person-referring terms (e.g., the students) is often non-trivial.","Translating from English into German poses an interesting case -- in German, person-referring nouns are usually gender-specific, and if the gender of the referent(s) is unknown or diverse, the generic masculine (die Studenten (m.)) is commonly used.","This solution, however, reduces the visibility of other genders, such as women and non-binary people.","To counteract gender discrimination, a societal movement towards using gender-fair language exists (e.g., by adopting neosystems).","However, gender-fair German is currently barely supported in machine translation (MT), requiring post-editing or manual translations.","We address this research gap by studying gender-fair language in English-to-German MT.","Concretely, we enrich a community-created gender-fair language dictionary and sample multi-sentence test instances from encyclopedic text and parliamentary speeches.","Using these novel resources, we conduct the first benchmark study involving two commercial systems and six neural MT models for translating words in isolation and natural contexts across two domains.","Our findings show that most systems produce mainly masculine forms and rarely gender-neutral variants, highlighting the need for future research.","We release code and data at https://github.com/g8a9/building-bridges-gender-fair-german-mt."],"url":"http://arxiv.org/abs/2406.06131v1"}
{"created":"2024-06-10 09:37:51","title":"Federated Machine Reasoning for Resource Provisioning in 6G O-RAN","abstract":"O-RAN specifications reshape RANs with function disaggregation and open interfaces, driven by RAN Intelligent Controllers. This enables data-driven management through AI/ML but poses trust challenges due to human operators' limited understanding of AI/ML decision-making. Balancing resource provisioning and avoiding overprovisioning and underprovisioning is critical, especially among the multiple virtualized base station(vBS) instances. Thus, we propose a novel Federated Machine Reasoning (FLMR) framework, a neurosymbolic method for federated reasoning, learning, and querying. FLMR optimizes CPU demand prediction based on contextual information and vBS configuration using local monitoring data from virtual base stations (vBS) on a shared O-Cloud platform.This optimization is critical, as insufficient computing resources can result in synchronization loss and significantly reduce network throughput. In the telecom domain, particularly in the virtual Radio Access Network (vRAN) sector, predicting and managing the CPU load of vBSs poses a significant challenge for network operators. Our proposed FLMR framework ensures transparency and human understanding in AI/ML decisions and addresses the evolving demands of the 6G O-RAN landscape, where reliability and performance are paramount. Furthermore, we performed a comparative analysis using \\textit{DeepCog} as the baseline method. The outcomes highlight how our proposed approach outperforms the baseline and strikes a better balance between resource overprovisioning and underprovisioning. Our method notably lowers both provisioning relative to the baseline by a factor of 6.","sentences":["O-RAN specifications reshape RANs with function disaggregation and open interfaces, driven by RAN Intelligent Controllers.","This enables data-driven management through AI/ML but poses trust challenges due to human operators' limited understanding of AI/ML decision-making.","Balancing resource provisioning and avoiding overprovisioning and underprovisioning is critical, especially among the multiple virtualized base station(vBS) instances.","Thus, we propose a novel Federated Machine Reasoning (FLMR) framework, a neurosymbolic method for federated reasoning, learning, and querying.","FLMR optimizes CPU demand prediction based on contextual information and vBS configuration using local monitoring data from virtual base stations (vBS) on a shared O-Cloud platform.","This optimization is critical, as insufficient computing resources can result in synchronization loss and significantly reduce network throughput.","In the telecom domain, particularly in the virtual Radio Access Network (vRAN) sector, predicting and managing the CPU load of vBSs poses a significant challenge for network operators.","Our proposed FLMR framework ensures transparency and human understanding in AI/ML decisions and addresses the evolving demands of the 6G O-RAN landscape, where reliability and performance are paramount.","Furthermore, we performed a comparative analysis using \\textit{DeepCog} as the baseline method.","The outcomes highlight how our proposed approach outperforms the baseline and strikes a better balance between resource overprovisioning and underprovisioning.","Our method notably lowers both provisioning relative to the baseline by a factor of 6."],"url":"http://arxiv.org/abs/2406.06128v1"}
{"created":"2024-06-10 09:36:05","title":"Comparing Data Augmentation Methods for End-to-End Task-Oriented Dialog Systems","abstract":"Creating effective and reliable task-oriented dialog systems (ToDSs) is challenging, not only because of the complex structure of these systems, but also due to the scarcity of training data, especially when several modules need to be trained separately, each one with its own input/output training examples. Data augmentation (DA), whereby synthetic training examples are added to the training data, has been successful in other NLP systems, but has not been explored as extensively in ToDSs. We empirically evaluate the effectiveness of DA methods in an end-to-end ToDS setting, where a single system is trained to handle all processing stages, from user inputs to system outputs. We experiment with two ToDSs (UBAR, GALAXY) on two datasets (MultiWOZ, KVRET). We consider three types of DA methods (word-level, sentence-level, dialog-level), comparing eight DA methods that have shown promising results in ToDSs and other NLP systems. We show that all DA methods considered are beneficial, and we highlight the best ones, also providing advice to practitioners. We also introduce a more challenging few-shot cross-domain ToDS setting, reaching similar conclusions.","sentences":["Creating effective and reliable task-oriented dialog systems (ToDSs) is challenging, not only because of the complex structure of these systems, but also due to the scarcity of training data, especially when several modules need to be trained separately, each one with its own input/output training examples.","Data augmentation (DA), whereby synthetic training examples are added to the training data, has been successful in other NLP systems, but has not been explored as extensively in ToDSs.","We empirically evaluate the effectiveness of DA methods in an end-to-end ToDS setting, where a single system is trained to handle all processing stages, from user inputs to system outputs.","We experiment with two ToDSs (UBAR, GALAXY) on two datasets (MultiWOZ, KVRET).","We consider three types of DA methods (word-level, sentence-level, dialog-level), comparing eight DA methods that have shown promising results in ToDSs and other NLP systems.","We show that all DA methods considered are beneficial, and we highlight the best ones, also providing advice to practitioners.","We also introduce a more challenging few-shot cross-domain ToDS setting, reaching similar conclusions."],"url":"http://arxiv.org/abs/2406.06127v1"}
{"created":"2024-06-10 09:11:30","title":"A Survey on Incomplete Multi-label Learning: Recent Advances and Future Trends","abstract":"In reality, data often exhibit associations with multiple labels, making multi-label learning (MLL) become a prominent research topic. The last two decades have witnessed the success of MLL, which is indispensable from complete and accurate supervised information. However, obtaining such information in practice is always laborious and sometimes even impossible. To circumvent this dilemma, incomplete multi-label learning (InMLL) has emerged, aiming to learn from incomplete labeled data. To date, enormous InMLL works have been proposed to narrow the performance gap with complete MLL, whereas a systematic review for InMLL is still absent. In this paper, we not only attempt to fill the lacuna but also strive to pave the way for innovative research. Specifically, we retrospect the origin of InMLL, analyze the challenges of InMLL, and make a taxonomy of InMLL from the data-oriented and algorithm-oriented perspectives, respectively. Besides, we also present real applications of InMLL in various domains. More importantly, we highlight several potential future trends, including four open problems that are more in line with practice and three under-explored/unexplored techniques in addressing the challenges of InMLL, which may shed new light on developing novel research directions in the field of InMLL.","sentences":["In reality, data often exhibit associations with multiple labels, making multi-label learning (MLL) become a prominent research topic.","The last two decades have witnessed the success of MLL, which is indispensable from complete and accurate supervised information.","However, obtaining such information in practice is always laborious and sometimes even impossible.","To circumvent this dilemma, incomplete multi-label learning (InMLL) has emerged, aiming to learn from incomplete labeled data.","To date, enormous InMLL works have been proposed to narrow the performance gap with complete MLL, whereas a systematic review for InMLL is still absent.","In this paper, we not only attempt to fill the lacuna but also strive to pave the way for innovative research.","Specifically, we retrospect the origin of InMLL, analyze the challenges of InMLL, and make a taxonomy of InMLL from the data-oriented and algorithm-oriented perspectives, respectively.","Besides, we also present real applications of InMLL in various domains.","More importantly, we highlight several potential future trends, including four open problems that are more in line with practice and three under-explored/unexplored techniques in addressing the challenges of InMLL, which may shed new light on developing novel research directions in the field of InMLL."],"url":"http://arxiv.org/abs/2406.06119v1"}
{"created":"2024-06-10 08:42:48","title":"Testably Learning Polynomial Threshold Functions","abstract":"Rubinfeld & Vasilyan recently introduced the framework of testable learning as an extension of the classical agnostic model. It relaxes distributional assumptions which are difficult to verify by conditions that can be checked efficiently by a tester. The tester has to accept whenever the data truly satisfies the original assumptions, and the learner has to succeed whenever the tester accepts. We focus on the setting where the tester has to accept standard Gaussian data. There, it is known that basic concept classes such as halfspaces can be learned testably with the same time complexity as in the (distribution-specific) agnostic model. In this work, we ask whether there is a price to pay for testably learning more complex concept classes. In particular, we consider polynomial threshold functions (PTFs), which naturally generalize halfspaces. We show that PTFs of arbitrary constant degree can be testably learned up to excess error $\\varepsilon > 0$ in time $n^{\\mathrm{poly}(1/\\varepsilon)}$. This qualitatively matches the best known guarantees in the agnostic model. Our results build on a connection between testable learning and fooling. In particular, we show that distributions that approximately match at least $\\mathrm{poly}(1/\\varepsilon)$ moments of the standard Gaussian fool constant-degree PTFs (up to error $\\varepsilon$). As a secondary result, we prove that a direct approach to show testable learning (without fooling), which was successfully used for halfspaces, cannot work for PTFs.","sentences":["Rubinfeld & Vasilyan recently introduced the framework of testable learning as an extension of the classical agnostic model.","It relaxes distributional assumptions which are difficult to verify by conditions that can be checked efficiently by a tester.","The tester has to accept whenever the data truly satisfies the original assumptions, and the learner has to succeed whenever the tester accepts.","We focus on the setting where the tester has to accept standard Gaussian data.","There, it is known that basic concept classes such as halfspaces can be learned testably with the same time complexity as in the (distribution-specific) agnostic model.","In this work, we ask whether there is a price to pay for testably learning more complex concept classes.","In particular, we consider polynomial threshold functions (PTFs), which naturally generalize halfspaces.","We show that PTFs of arbitrary constant degree can be testably learned up to excess error $\\varepsilon > 0$ in time $n^{\\mathrm{poly}(1/\\varepsilon)}$. This qualitatively matches the best known guarantees in the agnostic model.","Our results build on a connection between testable learning and fooling.","In particular, we show that distributions that approximately match at least $\\mathrm{poly}(1/\\varepsilon)$ moments of the standard Gaussian fool constant-degree PTFs (up to error $\\varepsilon$).","As a secondary result, we prove that a direct approach to show testable learning (without fooling), which was successfully used for halfspaces, cannot work for PTFs."],"url":"http://arxiv.org/abs/2406.06106v1"}
{"created":"2024-06-10 08:40:11","title":"The Evolution of Applications, Hardware Design, and Channel Modeling for Terahertz (THz) Band Communications and Sensing: Ready for 6G?","abstract":"For decades, the terahertz (THz) frequency band had been primarily explored in the context of radar, imaging, and spectroscopy, where multi-gigahertz (GHz) and even THz-wide channels and the properties of terahertz photons offered attractive target accuracy, resolution, and classification capabilities. Meanwhile, the exploitation of the terahertz band for wireless communication had originally been limited due to several reasons, including (i) no immediate need for such high data rates available via terahertz bands and (ii) challenges in designing sufficiently high power terahertz systems at reasonable cost and efficiency, leading to what was often referred to as \"the terahertz gap\". This roadmap paper first reviews the evolution of the hardware design approaches for terahertz systems, including electronic, photonic, and plasmonic approaches, and the understanding of the terahertz channel itself, in diverse scenarios, ranging from common indoors and outdoors scenarios to intra-body and outer-space environments. The article then summarizes the lessons learned during this multi-decade process and the cutting-edge state-of-the-art findings, including novel methods to quantify power efficiency, which will become more important in making design choices. Finally, the manuscript presents the authors' perspective and insights on how the evolution of terahertz systems design will continue toward enabling efficient terahertz communications and sensing solutions as an integral part of next-generation wireless systems.","sentences":["For decades, the terahertz (THz) frequency band had been primarily explored in the context of radar, imaging, and spectroscopy, where multi-gigahertz (GHz) and even THz-wide channels and the properties of terahertz photons offered attractive target accuracy, resolution, and classification capabilities.","Meanwhile, the exploitation of the terahertz band for wireless communication had originally been limited due to several reasons, including (i) no immediate need for such high data rates available via terahertz bands and (ii) challenges in designing sufficiently high power terahertz systems at reasonable cost and efficiency, leading to what was often referred to as \"the terahertz gap\".","This roadmap paper first reviews the evolution of the hardware design approaches for terahertz systems, including electronic, photonic, and plasmonic approaches, and the understanding of the terahertz channel itself, in diverse scenarios, ranging from common indoors and outdoors scenarios to intra-body and outer-space environments.","The article then summarizes the lessons learned during this multi-decade process and the cutting-edge state-of-the-art findings, including novel methods to quantify power efficiency, which will become more important in making design choices.","Finally, the manuscript presents the authors' perspective and insights on how the evolution of terahertz systems design will continue toward enabling efficient terahertz communications and sensing solutions as an integral part of next-generation wireless systems."],"url":"http://arxiv.org/abs/2406.06105v1"}
{"created":"2024-06-10 08:36:55","title":"Adaptive Control in Assistive Application -- A Study Evaluating Shared Control by Users with Limited Upper Limb Mobility","abstract":"Shared control in assistive robotics blends human autonomy with computer assistance, thus simplifying complex tasks for individuals with physical impairments. This study assesses an adaptive Degrees of Freedom control method specifically tailored for individuals with upper limb impairments. It employs a between-subjects analysis with 24 participants, conducting 81 trials across three distinct input devices in a realistic everyday-task setting. Given the diverse capabilities of the vulnerable target demographic and the known challenges in statistical comparisons due to individual differences, the study focuses primarily on subjective qualitative data. The results reveal consistently high success rates in trial completions, irrespective of the input device used. Participants appreciated their involvement in the research process, displayed a positive outlook, and quick adaptability to the control system. Notably, each participant effectively managed the given task within a short time frame.","sentences":["Shared control in assistive robotics blends human autonomy with computer assistance, thus simplifying complex tasks for individuals with physical impairments.","This study assesses an adaptive Degrees of Freedom control method specifically tailored for individuals with upper limb impairments.","It employs a between-subjects analysis with 24 participants, conducting 81 trials across three distinct input devices in a realistic everyday-task setting.","Given the diverse capabilities of the vulnerable target demographic and the known challenges in statistical comparisons due to individual differences, the study focuses primarily on subjective qualitative data.","The results reveal consistently high success rates in trial completions, irrespective of the input device used.","Participants appreciated their involvement in the research process, displayed a positive outlook, and quick adaptability to the control system.","Notably, each participant effectively managed the given task within a short time frame."],"url":"http://arxiv.org/abs/2406.06103v1"}
{"created":"2024-06-10 08:35:01","title":"On the Consistency of Kernel Methods with Dependent Observations","abstract":"The consistency of a learning method is usually established under the assumption that the observations are a realization of an independent and identically distributed (i.i.d.) or mixing process. Yet, kernel methods such as support vector machines (SVMs), Gaussian processes, or conditional kernel mean embeddings (CKMEs) all give excellent performance under sampling schemes that are obviously non-i.i.d., such as when data comes from a dynamical system. We propose the new notion of empirical weak convergence (EWC) as a general assumption explaining such phenomena for kernel methods. It assumes the existence of a random asymptotic data distribution and is a strict weakening of previous assumptions in the field. Our main results then establish consistency of SVMs, kernel mean embeddings, and general Hilbert-space valued empirical expectations with EWC data. Our analysis holds for both finite- and infinite-dimensional outputs, as we extend classical results of statistical learning to the latter case. In particular, it is also applicable to CKMEs. Overall, our results open new classes of processes to statistical learning and can serve as a foundation for a theory of learning beyond i.i.d. and mixing.","sentences":["The consistency of a learning method is usually established under the assumption that the observations are a realization of an independent and identically distributed (i.i.d.) or mixing process.","Yet, kernel methods such as support vector machines (SVMs), Gaussian processes, or conditional kernel mean embeddings (CKMEs) all give excellent performance under sampling schemes that are obviously non-i.i.d., such as when data comes from a dynamical system.","We propose the new notion of empirical weak convergence (EWC) as a general assumption explaining such phenomena for kernel methods.","It assumes the existence of a random asymptotic data distribution and is a strict weakening of previous assumptions in the field.","Our main results then establish consistency of SVMs, kernel mean embeddings, and general Hilbert-space valued empirical expectations with EWC data.","Our analysis holds for both finite- and infinite-dimensional outputs, as we extend classical results of statistical learning to the latter case.","In particular, it is also applicable to CKMEs.","Overall, our results open new classes of processes to statistical learning and can serve as a foundation for a theory of learning beyond i.i.d. and mixing."],"url":"http://arxiv.org/abs/2406.06101v1"}
{"created":"2024-06-10 08:26:27","title":"An extension of C++ with memory-centric specifications for HPC to reduce memory footprints and streamline MPI development","abstract":"The C++ programming language and its cousins lean towards a memory-inefficient storage of structs: The compiler inserts helper bits into the struct such that individual attributes align with bytes, and it adds additional bytes aligning attributes with cache lines, while it is not able to exploit knowledge about the range of integers, enums or bitsets to bring the memory footprint down. Furthermore, the language provides neither support for data exchange via MPI nor for arbitrary floating-point precision formats. If developers need to have a low memory footprint and MPI datatypes over structs which exchange only minimal data, they have to manipulate the data and to write MPI datatypes manually. We propose a C++ language extension based upon C++ attributes through which developers can guide the compiler what memory arrangements would be beneficial: Can multiple booleans be squeezed into one bit field, do floats hold fewer significant bits than in the IEEE standard, or does the code require a user-defined MPI datatype for certain subsets of attributes? The extension offers the opportunity to fall back to normal alignment and padding rules via plain C++ assignments, no dependencies upon external libraries are introduced, and the resulting code remains standard C++. Our work implements the language annotations within LLVM and demonstrates their potential impact, both upon the runtime and the memory footprint, through smoothed particle hydrodynamics (SPH) benchmarks. They uncover the potential gains in terms of performance and development productivity.","sentences":["The C++ programming language and its cousins lean towards a memory-inefficient storage of structs: The compiler inserts helper bits into the struct such that individual attributes align with bytes, and it adds additional bytes aligning attributes with cache lines, while it is not able to exploit knowledge about the range of integers, enums or bitsets to bring the memory footprint down.","Furthermore, the language provides neither support for data exchange via MPI nor for arbitrary floating-point precision formats.","If developers need to have a low memory footprint and MPI datatypes over structs which exchange only minimal data, they have to manipulate the data and to write MPI datatypes manually.","We propose a C++ language extension based upon C++ attributes through which developers can guide the compiler what memory arrangements would be beneficial: Can multiple booleans be squeezed into one bit field, do floats hold fewer significant bits than in the IEEE standard, or does the code require a user-defined MPI datatype for certain subsets of attributes?","The extension offers the opportunity to fall back to normal alignment and padding rules via plain C++ assignments, no dependencies upon external libraries are introduced, and the resulting code remains standard C++.","Our work implements the language annotations within LLVM and demonstrates their potential impact, both upon the runtime and the memory footprint, through smoothed particle hydrodynamics (SPH) benchmarks.","They uncover the potential gains in terms of performance and development productivity."],"url":"http://arxiv.org/abs/2406.06095v1"}
{"created":"2024-06-10 08:18:55","title":"Texture Re-scalable Universal Adversarial Perturbation","abstract":"Universal adversarial perturbation (UAP), also known as image-agnostic perturbation, is a fixed perturbation map that can fool the classifier with high probabilities on arbitrary images, making it more practical for attacking deep models in the real world. Previous UAP methods generate a scale-fixed and texture-fixed perturbation map for all images, which ignores the multi-scale objects in images and usually results in a low fooling ratio. Since the widely used convolution neural networks tend to classify objects according to semantic information stored in local textures, it seems a reasonable and intuitive way to improve the UAP from the perspective of utilizing local contents effectively. In this work, we find that the fooling ratios significantly increase when we add a constraint to encourage a small-scale UAP map and repeat it vertically and horizontally to fill the whole image domain. To this end, we propose texture scale-constrained UAP (TSC-UAP), a simple yet effective UAP enhancement method that automatically generates UAPs with category-specific local textures that can fool deep models more easily. Through a low-cost operation that restricts the texture scale, TSC-UAP achieves a considerable improvement in the fooling ratio and attack transferability for both data-dependent and data-free UAP methods. Experiments conducted on two state-of-the-art UAP methods, eight popular CNN models and four classical datasets show the remarkable performance of TSC-UAP.","sentences":["Universal adversarial perturbation (UAP), also known as image-agnostic perturbation, is a fixed perturbation map that can fool the classifier with high probabilities on arbitrary images, making it more practical for attacking deep models in the real world.","Previous UAP methods generate a scale-fixed and texture-fixed perturbation map for all images, which ignores the multi-scale objects in images and usually results in a low fooling ratio.","Since the widely used convolution neural networks tend to classify objects according to semantic information stored in local textures, it seems a reasonable and intuitive way to improve the UAP from the perspective of utilizing local contents effectively.","In this work, we find that the fooling ratios significantly increase when we add a constraint to encourage a small-scale UAP map and repeat it vertically and horizontally to fill the whole image domain.","To this end, we propose texture scale-constrained UAP (TSC-UAP), a simple yet effective UAP enhancement method that automatically generates UAPs with category-specific local textures that can fool deep models more easily.","Through a low-cost operation that restricts the texture scale, TSC-UAP achieves a considerable improvement in the fooling ratio and attack transferability for both data-dependent and data-free UAP methods.","Experiments conducted on two state-of-the-art UAP methods, eight popular CNN models and four classical datasets show the remarkable performance of TSC-UAP."],"url":"http://arxiv.org/abs/2406.06089v1"}
{"created":"2024-06-10 07:54:56","title":"An Open and Large-Scale Dataset for Multi-Modal Climate Change-aware Crop Yield Predictions","abstract":"Precise crop yield predictions are of national importance for ensuring food security and sustainable agricultural practices. While AI-for-science approaches have exhibited promising achievements in solving many scientific problems such as drug discovery, precipitation nowcasting, etc., the development of deep learning models for predicting crop yields is constantly hindered by the lack of an open and large-scale deep learning-ready dataset with multiple modalities to accommodate sufficient information. To remedy this, we introduce the CropNet dataset, the first terabyte-sized, publicly available, and multi-modal dataset specifically targeting climate change-aware crop yield predictions for the contiguous United States (U.S.) continent at the county level. Our CropNet dataset is composed of three modalities of data, i.e., Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDA Crop Dataset, for over 2200 U.S. counties spanning 6 years (2017-2022), expected to facilitate researchers in developing versatile deep learning models for timely and precisely predicting crop yields at the county-level, by accounting for the effects of both short-term growing season weather variations and long-term climate change on crop yields. Besides, we develop the CropNet package, offering three types of APIs, for facilitating researchers in downloading the CropNet data on the fly over the time and region of interest, and flexibly building their deep learning models for accurate crop yield predictions. Extensive experiments have been conducted on our CropNet dataset via employing various types of deep learning solutions, with the results validating the general applicability and the efficacy of the CropNet dataset in climate change-aware crop yield predictions.","sentences":["Precise crop yield predictions are of national importance for ensuring food security and sustainable agricultural practices.","While AI-for-science approaches have exhibited promising achievements in solving many scientific problems such as drug discovery, precipitation nowcasting, etc., the development of deep learning models for predicting crop yields is constantly hindered by the lack of an open and large-scale deep learning-ready dataset with multiple modalities to accommodate sufficient information.","To remedy this, we introduce the CropNet dataset, the first terabyte-sized, publicly available, and multi-modal dataset specifically targeting climate change-aware crop yield predictions for the contiguous United States (U.S.) continent at the county level.","Our CropNet dataset is composed of three modalities of data, i.e., Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDA Crop Dataset, for over 2200 U.S. counties spanning 6 years (2017-2022), expected to facilitate researchers in developing versatile deep learning models for timely and precisely predicting crop yields at the county-level, by accounting for the effects of both short-term growing season weather variations and long-term climate change on crop yields.","Besides, we develop the CropNet package, offering three types of APIs, for facilitating researchers in downloading the CropNet data on the fly over the time and region of interest, and flexibly building their deep learning models for accurate crop yield predictions.","Extensive experiments have been conducted on our CropNet dataset via employing various types of deep learning solutions, with the results validating the general applicability and the efficacy of the CropNet dataset in climate change-aware crop yield predictions."],"url":"http://arxiv.org/abs/2406.06081v1"}
{"created":"2024-06-10 07:50:41","title":"Text Analysis of ETDs in ProQuest Dissertations and Theses (PQDT) Global (2016-2018)","abstract":"The information explosion in the form of ETDs poses the challenge of management and extraction of appropriate knowledge for decision-making. Thus, the present study forwards a solution to the above problem by applying topic mining and prediction modeling tools to 263 ETDs submitted to the PQDT Global database during 2016-18 in the field of library science. This study was divided into two phases. The first phase determined the core topics from the ETDs using Topic-Modeling-Tool (TMT), which was based on latent dirichlet allocation (LDA), whereas the second phase employed prediction analysis using RapidMinerplatform to annotate the future research articles on the basis of the modeled topics. The core topics (tags) for the studied period were found to be book history, school librarian, public library, communicative ecology, and informatics followed by text network and trend analysis on the high probability cooccurred words. Lastly, a prediction model using Support Vector Machine (SVM) classifier was created in order to accurately predict the placement of future ETDs going to be submitted to PQDT Global under the five modeled topics (a to e). The tested dataset against the trained data set for the predictive performed perfectly.","sentences":["The information explosion in the form of ETDs poses the challenge of management and extraction of appropriate knowledge for decision-making.","Thus, the present study forwards a solution to the above problem by applying topic mining and prediction modeling tools to 263 ETDs submitted to the PQDT Global database during 2016-18 in the field of library science.","This study was divided into two phases.","The first phase determined the core topics from the ETDs using Topic-Modeling-Tool (TMT), which was based on latent dirichlet allocation (LDA), whereas the second phase employed prediction analysis using RapidMinerplatform to annotate the future research articles on the basis of the modeled topics.","The core topics (tags) for the studied period were found to be book history, school librarian, public library, communicative ecology, and informatics followed by text network and trend analysis on the high probability cooccurred words.","Lastly, a prediction model using Support Vector Machine (SVM) classifier was created in order to accurately predict the placement of future ETDs going to be submitted to PQDT Global under the five modeled topics (a to e).","The tested dataset against the trained data set for the predictive performed perfectly."],"url":"http://arxiv.org/abs/2406.06076v1"}
{"created":"2024-06-10 07:49:51","title":"Supervised Radio Frequency Interference Detection with SNNs","abstract":"Radio Frequency Interference (RFI) poses a significant challenge in radio astronomy, arising from terrestrial and celestial sources, disrupting observations conducted by radio telescopes. Addressing RFI involves intricate heuristic algorithms, manual examination, and, increasingly, machine learning methods. Given the dynamic and temporal nature of radio astronomy observations, Spiking Neural Networks (SNNs) emerge as a promising approach. In this study, we cast RFI detection as a supervised multi-variate time-series segmentation problem. Notably, our investigation explores the encoding of radio astronomy visibility data for SNN inference, considering six encoding schemes: rate, latency, delta-modulation, and three variations of the step-forward algorithm. We train a small two-layer fully connected SNN on simulated data derived from the Hydrogen Epoch of Reionization Array (HERA) telescope and perform extensive hyper-parameter optimization. Results reveal that latency encoding exhibits superior performance, achieving a per-pixel accuracy of 98.8% and an f1-score of 0.761. Remarkably, these metrics approach those of contemporary RFI detection algorithms, notwithstanding the simplicity and compactness of our proposed network architecture. This study underscores the potential of RFI detection as a benchmark problem for SNN researchers, emphasizing the efficacy of SNNs in addressing complex time-series segmentation tasks in radio astronomy.","sentences":["Radio Frequency Interference (RFI) poses a significant challenge in radio astronomy, arising from terrestrial and celestial sources, disrupting observations conducted by radio telescopes.","Addressing RFI involves intricate heuristic algorithms, manual examination, and, increasingly, machine learning methods.","Given the dynamic and temporal nature of radio astronomy observations, Spiking Neural Networks (SNNs) emerge as a promising approach.","In this study, we cast RFI detection as a supervised multi-variate time-series segmentation problem.","Notably, our investigation explores the encoding of radio astronomy visibility data for SNN inference, considering six encoding schemes: rate, latency, delta-modulation, and three variations of the step-forward algorithm.","We train a small two-layer fully connected SNN on simulated data derived from the Hydrogen Epoch of Reionization Array (HERA) telescope and perform extensive hyper-parameter optimization.","Results reveal that latency encoding exhibits superior performance, achieving a per-pixel accuracy of 98.8% and an f1-score of 0.761.","Remarkably, these metrics approach those of contemporary RFI detection algorithms, notwithstanding the simplicity and compactness of our proposed network architecture.","This study underscores the potential of RFI detection as a benchmark problem for SNN researchers, emphasizing the efficacy of SNNs in addressing complex time-series segmentation tasks in radio astronomy."],"url":"http://arxiv.org/abs/2406.06075v1"}
{"created":"2024-06-10 07:18:41","title":"ProcessPainter: Learn Painting Process from Sequence Data","abstract":"The painting process of artists is inherently stepwise and varies significantly among different painters and styles. Generating detailed, step-by-step painting processes is essential for art education and research, yet remains largely underexplored. Traditional stroke-based rendering methods break down images into sequences of brushstrokes, yet they fall short of replicating the authentic processes of artists, with limitations confined to basic brushstroke modifications. Text-to-image models utilizing diffusion processes generate images through iterative denoising, also diverge substantially from artists' painting process. To address these challenges, we introduce ProcessPainter, a text-to-video model that is initially pre-trained on synthetic data and subsequently fine-tuned with a select set of artists' painting sequences using the LoRA model. This approach successfully generates painting processes from text prompts for the first time. Furthermore, we introduce an Artwork Replication Network capable of accepting arbitrary-frame input, which facilitates the controlled generation of painting processes, decomposing images into painting sequences, and completing semi-finished artworks. This paper offers new perspectives and tools for advancing art education and image generation technology.","sentences":["The painting process of artists is inherently stepwise and varies significantly among different painters and styles.","Generating detailed, step-by-step painting processes is essential for art education and research, yet remains largely underexplored.","Traditional stroke-based rendering methods break down images into sequences of brushstrokes, yet they fall short of replicating the authentic processes of artists, with limitations confined to basic brushstroke modifications.","Text-to-image models utilizing diffusion processes generate images through iterative denoising, also diverge substantially from artists' painting process.","To address these challenges, we introduce ProcessPainter, a text-to-video model that is initially pre-trained on synthetic data and subsequently fine-tuned with a select set of artists' painting sequences using the LoRA model.","This approach successfully generates painting processes from text prompts for the first time.","Furthermore, we introduce an Artwork Replication Network capable of accepting arbitrary-frame input, which facilitates the controlled generation of painting processes, decomposing images into painting sequences, and completing semi-finished artworks.","This paper offers new perspectives and tools for advancing art education and image generation technology."],"url":"http://arxiv.org/abs/2406.06062v1"}
{"created":"2024-06-10 06:27:42","title":"MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models","abstract":"Pretraining data selection has the potential to improve language model pretraining efficiency by utilizing higher-quality data from massive web data corpora. Current data selection methods, which rely on either hand-crafted rules or larger reference models, are conducted statically and do not capture the evolving data preferences during pretraining. In this paper, we introduce model-aware data selection with data influence models (MATES), where a data influence model continuously adapts to the evolving data preferences of the pretraining model and then selects the data most effective for the current pretraining progress. Specifically, we fine-tune a small data influence model to approximate oracle data preference signals collected by locally probing the pretraining model and to select data accordingly for the next pretraining stage. Experiments on Pythia and the C4 dataset demonstrate that MATES significantly outperforms random data selection on extensive downstream tasks in both zero- and few-shot settings. It doubles the gains achieved by recent data selection approaches that leverage larger reference models and reduces the total FLOPs required to reach certain performances by half. Further analysis validates the ever-changing data preferences of pretraining models and the effectiveness of our data influence models to capture them. Our code is open-sourced at https://github.com/cxcscmu/MATES.","sentences":["Pretraining data selection has the potential to improve language model pretraining efficiency by utilizing higher-quality data from massive web data corpora.","Current data selection methods, which rely on either hand-crafted rules or larger reference models, are conducted statically and do not capture the evolving data preferences during pretraining.","In this paper, we introduce model-aware data selection with data influence models (MATES), where a data influence model continuously adapts to the evolving data preferences of the pretraining model and then selects the data most effective for the current pretraining progress.","Specifically, we fine-tune a small data influence model to approximate oracle data preference signals collected by locally probing the pretraining model and to select data accordingly for the next pretraining stage.","Experiments on Pythia and the C4 dataset demonstrate that MATES significantly outperforms random data selection on extensive downstream tasks in both zero-","and few-shot settings.","It doubles the gains achieved by recent data selection approaches that leverage larger reference models and reduces the total FLOPs required to reach certain performances by half.","Further analysis validates the ever-changing data preferences of pretraining models and the effectiveness of our data influence models to capture them.","Our code is open-sourced at https://github.com/cxcscmu/MATES."],"url":"http://arxiv.org/abs/2406.06046v1"}
{"created":"2024-06-10 06:26:03","title":"Synthesizing Efficient Data with Diffusion Models for Person Re-Identification Pre-Training","abstract":"Existing person re-identification (Re-ID) methods principally deploy the ImageNet-1K dataset for model initialization, which inevitably results in sub-optimal situations due to the large domain gap. One of the key challenges is that building large-scale person Re-ID datasets is time-consuming. Some previous efforts address this problem by collecting person images from the internet e.g., LUPerson, but it struggles to learn from unlabeled, uncontrollable, and noisy data. In this paper, we present a novel paradigm Diffusion-ReID to efficiently augment and generate diverse images based on known identities without requiring any cost of data collection and annotation. Technically, this paradigm unfolds in two stages: generation and filtering. During the generation stage, we propose Language Prompts Enhancement (LPE) to ensure the ID consistency between the input image sequence and the generated images. In the diffusion process, we propose a Diversity Injection (DI) module to increase attribute diversity. In order to make the generated data have higher quality, we apply a Re-ID confidence threshold filter to further remove the low-quality images. Benefiting from our proposed paradigm, we first create a new large-scale person Re-ID dataset Diff-Person, which consists of over 777K images from 5,183 identities. Next, we build a stronger person Re-ID backbone pre-trained on our Diff-Person. Extensive experiments are conducted on four person Re-ID benchmarks in six widely used settings. Compared with other pre-training and self-supervised competitors, our approach shows significant superiority.","sentences":["Existing person re-identification (Re-ID) methods principally deploy the ImageNet-1K dataset for model initialization, which inevitably results in sub-optimal situations due to the large domain gap.","One of the key challenges is that building large-scale person Re-ID datasets is time-consuming.","Some previous efforts address this problem by collecting person images from the internet e.g., LUPerson, but it struggles to learn from unlabeled, uncontrollable, and noisy data.","In this paper, we present a novel paradigm Diffusion-ReID to efficiently augment and generate diverse images based on known identities without requiring any cost of data collection and annotation.","Technically, this paradigm unfolds in two stages: generation and filtering.","During the generation stage, we propose Language Prompts Enhancement (LPE) to ensure the ID consistency between the input image sequence and the generated images.","In the diffusion process, we propose a Diversity Injection (DI) module to increase attribute diversity.","In order to make the generated data have higher quality, we apply a Re-ID confidence threshold filter to further remove the low-quality images.","Benefiting from our proposed paradigm, we first create a new large-scale person Re-ID dataset Diff-Person, which consists of over 777K images from 5,183 identities.","Next, we build a stronger person Re-ID backbone pre-trained on our Diff-Person.","Extensive experiments are conducted on four person Re-ID benchmarks in six widely used settings.","Compared with other pre-training and self-supervised competitors, our approach shows significant superiority."],"url":"http://arxiv.org/abs/2406.06045v1"}
{"created":"2024-06-10 06:11:41","title":"Navigation and 3D Surface Reconstruction from Passive Whisker Sensing","abstract":"Whiskers provide a way to sense surfaces in the immediate environment without disturbing it. In this paper we present a method for using highly flexible, curved, passive whiskers mounted along a robot arm to gather sensory data as they brush past objects during normal robot motion. The information is useful both for guiding the robot in cluttered spaces and for reconstructing the exposed faces of objects. Surface reconstruction depends on accurate localization of contact points along each whisker. We present an algorithm based on Bayesian filtering that rapidly converges to within 1\\,mm of the actual contact locations. The piecewise-continuous history of contact locations from each whisker allows for accurate reconstruction of curves on object surfaces. Employing multiple whiskers and traces, we are able to produce an occupancy map of proximal objects.","sentences":["Whiskers provide a way to sense surfaces in the immediate environment without disturbing it.","In this paper we present a method for using highly flexible, curved, passive whiskers mounted along a robot arm to gather sensory data as they brush past objects during normal robot motion.","The information is useful both for guiding the robot in cluttered spaces and for reconstructing the exposed faces of objects.","Surface reconstruction depends on accurate localization of contact points along each whisker.","We present an algorithm based on Bayesian filtering that rapidly converges to within 1\\,mm of the actual contact locations.","The piecewise-continuous history of contact locations from each whisker allows for accurate reconstruction of curves on object surfaces.","Employing multiple whiskers and traces, we are able to produce an occupancy map of proximal objects."],"url":"http://arxiv.org/abs/2406.06038v1"}
{"created":"2024-06-10 05:56:34","title":"Shesha: Multi-head Microarchitectural Leakage Discovery in new-generation Intel Processors","abstract":"Transient execution attacks have been one of the widely explored microarchitectural side channels since the discovery of Spectre and Meltdown. However, much of the research has been driven by manual discovery of new transient paths through well-known speculative events. Although a few attempts exist in literature on automating transient leakage discovery, such tools focus on finding variants of known transient attacks and explore a small subset of instruction set. Further, they take a random fuzzing approach that does not scale as the complexity of search space increases. In this work, we identify that the search space of bad speculation is disjointedly fragmented into equivalence classes, and then use this observation to develop a framework named Shesha, inspired by Particle Swarm Optimization, which exhibits faster convergence rates than state-of-the-art fuzzing techniques for automatic discovery of transient execution attacks. We then use Shesha to explore the vast search space of extensions to the x86 Instruction Set Architecture (ISEs), thereby focusing on previously unexplored avenues of bad speculation. As such, we report five previously unreported transient execution paths in Instruction Set Extensions (ISEs) on new generation of Intel processors. We then perform extensive reverse engineering of each of the transient execution paths and provide root-cause analysis. Using the discovered transient execution paths, we develop attack building blocks to exhibit exploitable transient windows. Finally, we demonstrate data leakage from Fused Multiply-Add instructions through SIMD buffer and extract victim data from various cryptographic implementations.","sentences":["Transient execution attacks have been one of the widely explored microarchitectural side channels since the discovery of Spectre and Meltdown.","However, much of the research has been driven by manual discovery of new transient paths through well-known speculative events.","Although a few attempts exist in literature on automating transient leakage discovery, such tools focus on finding variants of known transient attacks and explore a small subset of instruction set.","Further, they take a random fuzzing approach that does not scale as the complexity of search space increases.","In this work, we identify that the search space of bad speculation is disjointedly fragmented into equivalence classes, and then use this observation to develop a framework named Shesha, inspired by Particle Swarm Optimization, which exhibits faster convergence rates than state-of-the-art fuzzing techniques for automatic discovery of transient execution attacks.","We then use Shesha to explore the vast search space of extensions to the x86 Instruction Set Architecture (ISEs), thereby focusing on previously unexplored avenues of bad speculation.","As such, we report five previously unreported transient execution paths in Instruction Set Extensions (ISEs) on new generation of Intel processors.","We then perform extensive reverse engineering of each of the transient execution paths and provide root-cause analysis.","Using the discovered transient execution paths, we develop attack building blocks to exhibit exploitable transient windows.","Finally, we demonstrate data leakage from Fused Multiply-Add instructions through SIMD buffer and extract victim data from various cryptographic implementations."],"url":"http://arxiv.org/abs/2406.06034v1"}
{"created":"2024-06-10 05:50:23","title":"The Curse of Popularity: Popular Entities have Catastrophic Side Effects when Deleting Knowledge from Language Models","abstract":"Language models (LMs) encode world knowledge in their internal parameters through training. However, LMs may learn personal and confidential information from the training data, leading to privacy concerns such as data leakage. Therefore, research on knowledge deletion from LMs is essential. This study focuses on the knowledge stored in LMs and analyzes the relationship between the side effects of knowledge deletion and the entities related to the knowledge. Our findings reveal that deleting knowledge related to popular entities can have catastrophic side effects. Furthermore, this research is the first to analyze knowledge deletion in models trained on synthetic knowledge graphs, indicating a new direction for controlled experiments.","sentences":["Language models (LMs) encode world knowledge in their internal parameters through training.","However, LMs may learn personal and confidential information from the training data, leading to privacy concerns such as data leakage.","Therefore, research on knowledge deletion from LMs is essential.","This study focuses on the knowledge stored in LMs and analyzes the relationship between the side effects of knowledge deletion and the entities related to the knowledge.","Our findings reveal that deleting knowledge related to popular entities can have catastrophic side effects.","Furthermore, this research is the first to analyze knowledge deletion in models trained on synthetic knowledge graphs, indicating a new direction for controlled experiments."],"url":"http://arxiv.org/abs/2406.06032v1"}
{"created":"2024-06-10 04:56:16","title":"GraphStorm: all-in-one graph machine learning framework for industry applications","abstract":"Graph machine learning (GML) is effective in many business applications. However, making GML easy to use and applicable to industry applications with massive datasets remain challenging. We developed GraphStorm, which provides an end-to-end solution for scalable graph construction, graph model training and inference. GraphStorm has the following desirable properties: (a) Easy to use: it can perform graph construction and model training and inference with just a single command; (b) Expert-friendly: GraphStorm contains many advanced GML modeling techniques to handle complex graph data and improve model performance; (c) Scalable: every component in GraphStorm can operate on graphs with billions of nodes and can scale model training and inference to different hardware without changing any code. GraphStorm has been used and deployed for over a dozen billion-scale industry applications after its release in May 2023. It is open-sourced in Github: https://github.com/awslabs/graphstorm.","sentences":["Graph machine learning (GML) is effective in many business applications.","However, making GML easy to use and applicable to industry applications with massive datasets remain challenging.","We developed GraphStorm, which provides an end-to-end solution for scalable graph construction, graph model training and inference.","GraphStorm has the following desirable properties: (a) Easy to use: it can perform graph construction and model training and inference with just a single command; (b) Expert-friendly: GraphStorm contains many advanced GML modeling techniques to handle complex graph data and improve model performance; (c) Scalable: every component in GraphStorm can operate on graphs with billions of nodes and can scale model training and inference to different hardware without changing any code.","GraphStorm has been used and deployed for over a dozen billion-scale industry applications after its release in May 2023.","It is open-sourced in Github: https://github.com/awslabs/graphstorm."],"url":"http://arxiv.org/abs/2406.06022v1"}
{"created":"2024-06-10 04:35:14","title":"EpiLearn: A Python Library for Machine Learning in Epidemic Modeling","abstract":"EpiLearn is a Python toolkit developed for modeling, simulating, and analyzing epidemic data. Although there exist several packages that also deal with epidemic modeling, they are often restricted to mechanistic models or traditional statistical tools. As machine learning continues to shape the world, the gap between these packages and the latest models has become larger. To bridge the gap and inspire innovative research in epidemic modeling, EpiLearn not only provides support for evaluating epidemic models based on machine learning, but also incorporates comprehensive tools for analyzing epidemic data, such as simulation, visualization, transformations, etc. For the convenience of both epidemiologists and data scientists, we provide a unified framework for training and evaluation of epidemic models on two tasks: Forecasting and Source Detection. To facilitate the development of new models, EpiLearn follows a modular design, making it flexible and easy to use. In addition, an interactive web application is also developed to visualize the real-world or simulated epidemic data. Our package is available at https://github.com/Emory-Melody/EpiLearn.","sentences":["EpiLearn is a Python toolkit developed for modeling, simulating, and analyzing epidemic data.","Although there exist several packages that also deal with epidemic modeling, they are often restricted to mechanistic models or traditional statistical tools.","As machine learning continues to shape the world, the gap between these packages and the latest models has become larger.","To bridge the gap and inspire innovative research in epidemic modeling, EpiLearn not only provides support for evaluating epidemic models based on machine learning, but also incorporates comprehensive tools for analyzing epidemic data, such as simulation, visualization, transformations, etc.","For the convenience of both epidemiologists and data scientists, we provide a unified framework for training and evaluation of epidemic models on two tasks: Forecasting and Source Detection.","To facilitate the development of new models, EpiLearn follows a modular design, making it flexible and easy to use.","In addition, an interactive web application is also developed to visualize the real-world or simulated epidemic data.","Our package is available at https://github.com/Emory-Melody/EpiLearn."],"url":"http://arxiv.org/abs/2406.06016v1"}
{"created":"2024-06-10 03:29:23","title":"A Dual-View Approach to Classifying Radiology Reports by Co-Training","abstract":"Radiology report analysis provides valuable information that can aid with public health initiatives, and has been attracting increasing attention from the research community. In this work, we present a novel insight that the structure of a radiology report (namely, the Findings and Impression sections) offers different views of a radiology scan. Based on this intuition, we further propose a co-training approach, where two machine learning models are built upon the Findings and Impression sections, respectively, and use each other's information to boost performance with massive unlabeled data in a semi-supervised manner. We conducted experiments in a public health surveillance study, and results show that our co-training approach is able to improve performance using the dual views and surpass competing supervised and semi-supervised methods.","sentences":["Radiology report analysis provides valuable information that can aid with public health initiatives, and has been attracting increasing attention from the research community.","In this work, we present a novel insight that the structure of a radiology report (namely, the Findings and Impression sections) offers different views of a radiology scan.","Based on this intuition, we further propose a co-training approach, where two machine learning models are built upon the Findings and Impression sections, respectively, and use each other's information to boost performance with massive unlabeled data in a semi-supervised manner.","We conducted experiments in a public health surveillance study, and results show that our co-training approach is able to improve performance using the dual views and surpass competing supervised and semi-supervised methods."],"url":"http://arxiv.org/abs/2406.05995v1"}
{"created":"2024-06-10 02:51:16","title":"Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook","abstract":"Mental health constitutes a complex and pervasive global challenge, affecting millions of lives and often leading to severe consequences. In this paper, we conduct a thorough survey to explore the intersection of data science, artificial intelligence, and mental healthcare, focusing on the recent developments of mental disorder detection through online social media (OSM). A significant portion of the population actively engages in OSM platforms, creating a vast repository of personal data that holds immense potential for mental health analytics. The paper navigates through traditional diagnostic methods, state-of-the-art data- and AI-driven research studies, and the emergence of explainable AI (XAI) models for mental healthcare. We review state-of-the-art machine learning methods, particularly those based on modern deep learning, while emphasising the need for explainability in healthcare AI models. The experimental design section provides insights into prevalent practices, including available datasets and evaluation approaches. We also identify key issues and challenges in the field and propose promising future research directions. As mental health decisions demand transparency, interpretability, and ethical considerations, this paper contributes to the ongoing discourse on advancing XAI in mental healthcare through social media. The comprehensive overview presented here aims to guide researchers, practitioners, and policymakers in developing the area of mental disorder detection.","sentences":["Mental health constitutes a complex and pervasive global challenge, affecting millions of lives and often leading to severe consequences.","In this paper, we conduct a thorough survey to explore the intersection of data science, artificial intelligence, and mental healthcare, focusing on the recent developments of mental disorder detection through online social media (OSM).","A significant portion of the population actively engages in OSM platforms, creating a vast repository of personal data that holds immense potential for mental health analytics.","The paper navigates through traditional diagnostic methods, state-of-the-art data- and AI-driven research studies, and the emergence of explainable AI (XAI) models for mental healthcare.","We review state-of-the-art machine learning methods, particularly those based on modern deep learning, while emphasising the need for explainability in healthcare AI models.","The experimental design section provides insights into prevalent practices, including available datasets and evaluation approaches.","We also identify key issues and challenges in the field and propose promising future research directions.","As mental health decisions demand transparency, interpretability, and ethical considerations, this paper contributes to the ongoing discourse on advancing XAI in mental healthcare through social media.","The comprehensive overview presented here aims to guide researchers, practitioners, and policymakers in developing the area of mental disorder detection."],"url":"http://arxiv.org/abs/2406.05984v1"}
{"created":"2024-06-10 02:06:54","title":"Visual-Inertial SLAM as Simple as A, B, VINS","abstract":"We present AB-VINS, a different kind of visual-inertial SLAM system. Unlike most VINS systems which only use hand-crafted techniques, AB-VINS makes use of three different deep networks. Instead of estimating sparse feature positions, AB-VINS only estimates the scale and bias parameters (a and b) of monocular depth maps, as well as other terms to correct the depth using multi-view information which results in a compressed feature state. Despite being an optimization-based system, the main VIO thread of AB-VINS surpasses the efficiency of a state-of-the-art filter-based method while also providing dense depth. While state-of-the-art loop-closing SLAM systems have to relinearize a number of variables linear the number of keyframes, AB-VINS can perform loop closures while only affecting a constant number of variables. This is due to a novel data structure called the memory tree, in which the keyframe poses are defined relative to each other rather than all in one global frame, allowing for all but a few states to be fixed. AB-VINS is not as accurate as state-of-the-art VINS systems, but it is shown through careful experimentation to be more robust.","sentences":["We present AB-VINS, a different kind of visual-inertial SLAM system.","Unlike most VINS systems which only use hand-crafted techniques, AB-VINS makes use of three different deep networks.","Instead of estimating sparse feature positions, AB-VINS only estimates the scale and bias parameters (a and b) of monocular depth maps, as well as other terms to correct the depth using multi-view information which results in a compressed feature state.","Despite being an optimization-based system, the main VIO thread of AB-VINS surpasses the efficiency of a state-of-the-art filter-based method while also providing dense depth.","While state-of-the-art loop-closing SLAM systems have to relinearize a number of variables linear the number of keyframes, AB-VINS can perform loop closures while only affecting a constant number of variables.","This is due to a novel data structure called the memory tree, in which the keyframe poses are defined relative to each other rather than all in one global frame, allowing for all but a few states to be fixed.","AB-VINS is not as accurate as state-of-the-art VINS systems, but it is shown through careful experimentation to be more robust."],"url":"http://arxiv.org/abs/2406.05969v1"}
{"created":"2024-06-10 01:59:00","title":"CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark","abstract":"Visual Question Answering (VQA) is an important task in multimodal AI, and it is often used to test the ability of vision-language models to understand and reason on knowledge present in both visual and textual data. However, most of the current VQA models use datasets that are primarily focused on English and a few major world languages, with images that are typically Western-centric. While recent efforts have tried to increase the number of languages covered on VQA datasets, they still lack diversity in low-resource languages. More importantly, although these datasets often extend their linguistic range via translation or some other approaches, they usually keep images the same, resulting in narrow cultural representation. To address these limitations, we construct CVQA, a new Culturally-diverse multilingual Visual Question Answering benchmark, designed to cover a rich set of languages and cultures, where we engage native speakers and cultural experts in the data collection process. As a result, CVQA includes culturally-driven images and questions from across 28 countries on four continents, covering 26 languages with 11 scripts, providing a total of 9k questions. We then benchmark several Multimodal Large Language Models (MLLMs) on CVQA, and show that the dataset is challenging for the current state-of-the-art models. This benchmark can serve as a probing evaluation suite for assessing the cultural capability and bias of multimodal models and hopefully encourage more research efforts toward increasing cultural awareness and linguistic diversity in this field.","sentences":["Visual Question Answering (VQA) is an important task in multimodal AI, and it is often used to test the ability of vision-language models to understand and reason on knowledge present in both visual and textual data.","However, most of the current VQA models use datasets that are primarily focused on English and a few major world languages, with images that are typically Western-centric.","While recent efforts have tried to increase the number of languages covered on VQA datasets, they still lack diversity in low-resource languages.","More importantly, although these datasets often extend their linguistic range via translation or some other approaches, they usually keep images the same, resulting in narrow cultural representation.","To address these limitations, we construct CVQA, a new Culturally-diverse multilingual Visual Question Answering benchmark, designed to cover a rich set of languages and cultures, where we engage native speakers and cultural experts in the data collection process.","As a result, CVQA includes culturally-driven images and questions from across 28 countries on four continents, covering 26 languages with 11 scripts, providing a total of 9k questions.","We then benchmark several Multimodal Large Language Models (MLLMs) on CVQA, and show that the dataset is challenging for the current state-of-the-art models.","This benchmark can serve as a probing evaluation suite for assessing the cultural capability and bias of multimodal models and hopefully encourage more research efforts toward increasing cultural awareness and linguistic diversity in this field."],"url":"http://arxiv.org/abs/2406.05967v1"}
{"created":"2024-06-10 01:43:15","title":"Data Caching for Enterprise-Grade Petabyte-Scale OLAP","abstract":"With the exponential growth of data and evolving use cases, petabyte-scale OLAP data platforms are increasingly adopting a model that decouples compute from storage. This shift, evident in organizations like Uber and Meta, introduces operational challenges including massive, read-heavy I/O traffic with potential throttling, as well as skewed and fragmented data access patterns. Addressing these challenges, this paper introduces the Alluxio local (edge) cache, a highly effective architectural optimization tailored for such environments. This embeddable cache, optimized for petabyte-scale data analytics, leverages local SSD resources to alleviate network I/O and API call pressures, significantly improving data transfer efficiency. Integrated with OLAP systems like Presto and storage services like HDFS, the Alluxio local cache has demonstrated its effectiveness in handling large-scale, enterprise-grade workloads over three years of deployment at Uber and Meta. We share insights and operational experiences in implementing these optimizations, providing valuable perspectives on managing modern, massive-scale OLAP workloads.","sentences":["With the exponential growth of data and evolving use cases, petabyte-scale OLAP data platforms are increasingly adopting a model that decouples compute from storage.","This shift, evident in organizations like Uber and Meta, introduces operational challenges including massive, read-heavy I/O traffic with potential throttling, as well as skewed and fragmented data access patterns.","Addressing these challenges, this paper introduces the Alluxio local (edge) cache, a highly effective architectural optimization tailored for such environments.","This embeddable cache, optimized for petabyte-scale data analytics, leverages local SSD resources to alleviate network I/O and API call pressures, significantly improving data transfer efficiency.","Integrated with OLAP systems like Presto and storage services like HDFS, the Alluxio local cache has demonstrated its effectiveness in handling large-scale, enterprise-grade workloads over three years of deployment at Uber and Meta.","We share insights and operational experiences in implementing these optimizations, providing valuable perspectives on managing modern, massive-scale OLAP workloads."],"url":"http://arxiv.org/abs/2406.05962v1"}
{"created":"2024-06-10 01:39:04","title":"MAGNOLIA: Matching Algorithms via GNNs for Online Value-to-go Approximation","abstract":"Online Bayesian bipartite matching is a central problem in digital marketplaces and exchanges, including advertising, crowdsourcing, ridesharing, and kidney exchange. We introduce a graph neural network (GNN) approach that emulates the problem's combinatorially-complex optimal online algorithm, which selects actions (e.g., which nodes to match) by computing each action's value-to-go (VTG) -- the expected weight of the final matching if the algorithm takes that action, then acts optimally in the future. We train a GNN to estimate VTG and show empirically that this GNN returns high-weight matchings across a variety of tasks. Moreover, we identify a common family of graph distributions in spatial crowdsourcing applications, such as rideshare, under which VTG can be efficiently approximated by aggregating information within local neighborhoods in the graphs. This structure matches the local behavior of GNNs, providing theoretical justification for our approach.","sentences":["Online Bayesian bipartite matching is a central problem in digital marketplaces and exchanges, including advertising, crowdsourcing, ridesharing, and kidney exchange.","We introduce a graph neural network (GNN) approach that emulates the problem's combinatorially-complex optimal online algorithm, which selects actions (e.g., which nodes to match) by computing each action's value-to-go (VTG) -- the expected weight of the final matching if the algorithm takes that action, then acts optimally in the future.","We train a GNN to estimate VTG and show empirically that this GNN returns high-weight matchings across a variety of tasks.","Moreover, we identify a common family of graph distributions in spatial crowdsourcing applications, such as rideshare, under which VTG can be efficiently approximated by aggregating information within local neighborhoods in the graphs.","This structure matches the local behavior of GNNs, providing theoretical justification for our approach."],"url":"http://arxiv.org/abs/2406.05959v1"}
{"created":"2024-06-10 01:21:59","title":"Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters","abstract":"Exploiting activation sparsity is a promising approach to significantly accelerating the inference process of large language models (LLMs) without compromising performance. However, activation sparsity is determined by activation functions, and commonly used ones like SwiGLU and GeGLU exhibit limited sparsity. Simply replacing these functions with ReLU fails to achieve sufficient sparsity. Moreover, inadequate training data can further increase the risk of performance degradation. To address these challenges, we propose a novel dReLU function, which is designed to improve LLM activation sparsity, along with a high-quality training data mixture ratio to facilitate effective sparsification. Additionally, we leverage sparse activation patterns within the Feed-Forward Network (FFN) experts of Mixture-of-Experts (MoE) models to further boost efficiency. By applying our neuron sparsification method to the Mistral and Mixtral models, only 2.5 billion and 4.3 billion parameters are activated per inference iteration, respectively, while achieving even more powerful model performance. Evaluation results demonstrate that this sparsity achieves a 2-5x decoding speedup. Remarkably, on mobile phones, our TurboSparse-Mixtral-47B achieves an inference speed of 11 tokens per second. Our models are available at \\url{https://huggingface.co/PowerInfer}","sentences":["Exploiting activation sparsity is a promising approach to significantly accelerating the inference process of large language models (LLMs) without compromising performance.","However, activation sparsity is determined by activation functions, and commonly used ones like SwiGLU and GeGLU exhibit limited sparsity.","Simply replacing these functions with ReLU fails to achieve sufficient sparsity.","Moreover, inadequate training data can further increase the risk of performance degradation.","To address these challenges, we propose a novel dReLU function, which is designed to improve LLM activation sparsity, along with a high-quality training data mixture ratio to facilitate effective sparsification.","Additionally, we leverage sparse activation patterns within the Feed-Forward Network (FFN) experts of Mixture-of-Experts (MoE) models to further boost efficiency.","By applying our neuron sparsification method to the Mistral and Mixtral models, only 2.5 billion and 4.3 billion parameters are activated per inference iteration, respectively, while achieving even more powerful model performance.","Evaluation results demonstrate that this sparsity achieves a 2-5x decoding speedup.","Remarkably, on mobile phones, our TurboSparse-Mixtral-47B achieves an inference speed of 11 tokens per second.","Our models are available at \\url{https://huggingface.co/PowerInfer}"],"url":"http://arxiv.org/abs/2406.05955v1"}
{"created":"2024-06-10 00:59:04","title":"Coconut Libtool: Bridging Textual Analysis Gaps for Non-Programmers","abstract":"In the era of big and ubiquitous data, professionals and students alike are finding themselves needing to perform a number of textual analysis tasks. Historically, the general lack of statistical expertise and programming skills has stopped many with humanities or social sciences backgrounds from performing and fully benefiting from such analyses. Thus, we introduce Coconut Libtool (www.coconut-libtool.com/), an open-source, web-based application that utilizes state-of-the-art natural language processing (NLP) technologies. Coconut Libtool analyzes text data from customized files and bibliographic databases such as Web of Science, Scopus, and Lens. Users can verify which functions can be performed with the data they have. Coconut Libtool deploys multiple algorithmic NLP techniques at the backend, including topic modeling (LDA, Biterm, and BERTopic algorithms), network graph visualization, keyword lemmatization, and sunburst visualization. Coconut Libtool is the people-first web application designed to be used by professionals, researchers, and students in the information sciences, digital humanities, and computational social sciences domains to promote transparency, reproducibility, accessibility, reciprocity, and responsibility in research practices.","sentences":["In the era of big and ubiquitous data, professionals and students alike are finding themselves needing to perform a number of textual analysis tasks.","Historically, the general lack of statistical expertise and programming skills has stopped many with humanities or social sciences backgrounds from performing and fully benefiting from such analyses.","Thus, we introduce Coconut Libtool (www.coconut-libtool.com/), an open-source, web-based application that utilizes state-of-the-art natural language processing (NLP) technologies.","Coconut Libtool analyzes text data from customized files and bibliographic databases such as Web of Science, Scopus, and Lens.","Users can verify which functions can be performed with the data they have.","Coconut Libtool deploys multiple algorithmic NLP techniques at the backend, including topic modeling (LDA, Biterm, and BERTopic algorithms), network graph visualization, keyword lemmatization, and sunburst visualization.","Coconut Libtool is the people-first web application designed to be used by professionals, researchers, and students in the information sciences, digital humanities, and computational social sciences domains to promote transparency, reproducibility, accessibility, reciprocity, and responsibility in research practices."],"url":"http://arxiv.org/abs/2406.05949v1"}
{"created":"2024-06-10 00:53:25","title":"Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models","abstract":"Backdoor attacks present significant threats to Large Language Models (LLMs), particularly with the rise of third-party services that offer API integration and prompt engineering. Untrustworthy third parties can plant backdoors into LLMs and pose risks to users by embedding malicious instructions into user queries. The backdoor-compromised LLM will generate malicious output when and input is embedded with a specific trigger predetermined by an attacker. Traditional defense strategies, which primarily involve model parameter fine-tuning and gradient calculation, are inadequate for LLMs due to their extensive computational and clean data requirements. In this paper, we propose a novel solution, Chain-of-Scrutiny (CoS), to address these challenges. Backdoor attacks fundamentally create a shortcut from the trigger to the target output, thus lack reasoning support. Accordingly, CoS guides the LLMs to generate detailed reasoning steps for the input, then scrutinizes the reasoning process to ensure consistency with the final answer. Any inconsistency may indicate an attack. CoS only requires black-box access to LLM, offering a practical defense, particularly for API-accessible LLMs. It is user-friendly, enabling users to conduct the defense themselves. Driven by natural language, the entire defense process is transparent to users. We validate the effectiveness of CoS through extensive experiments across various tasks and LLMs. Additionally, experiments results shows CoS proves more beneficial for more powerful LLMs.","sentences":["Backdoor attacks present significant threats to Large Language Models (LLMs), particularly with the rise of third-party services that offer API integration and prompt engineering.","Untrustworthy third parties can plant backdoors into LLMs and pose risks to users by embedding malicious instructions into user queries.","The backdoor-compromised LLM will generate malicious output when and input is embedded with a specific trigger predetermined by an attacker.","Traditional defense strategies, which primarily involve model parameter fine-tuning and gradient calculation, are inadequate for LLMs due to their extensive computational and clean data requirements.","In this paper, we propose a novel solution, Chain-of-Scrutiny (CoS), to address these challenges.","Backdoor attacks fundamentally create a shortcut from the trigger to the target output, thus lack reasoning support.","Accordingly, CoS guides the LLMs to generate detailed reasoning steps for the input, then scrutinizes the reasoning process to ensure consistency with the final answer.","Any inconsistency may indicate an attack.","CoS only requires black-box access to LLM, offering a practical defense, particularly for API-accessible LLMs.","It is user-friendly, enabling users to conduct the defense themselves.","Driven by natural language, the entire defense process is transparent to users.","We validate the effectiveness of CoS through extensive experiments across various tasks and LLMs.","Additionally, experiments results shows CoS proves more beneficial for more powerful LLMs."],"url":"http://arxiv.org/abs/2406.05948v1"}
{"created":"2024-06-10 00:13:35","title":"SETC: A Vulnerability Telemetry Collection Framework","abstract":"As emerging software vulnerabilities continuously threaten enterprises and Internet services, there is a critical need for improved security research capabilities. This paper introduces the Security Exploit Telemetry Collection (SETC) framework - an automated framework to generate reproducible vulnerability exploit data at scale for robust defensive security research. SETC deploys configurable environments to execute and record rich telemetry of vulnerability exploits within isolated containers. Exploits, vulnerable services, monitoring tools, and logging pipelines are defined via modular JSON configurations and deployed on demand. Compared to current manual processes, SETC enables automated, customizable, and repeatable vulnerability testing to produce diverse security telemetry. This research enables scalable exploit data generation to drive innovations in threat modeling, detection methods, analysis techniques, and remediation strategies. The capabilities of the framework are demonstrated through an example scenario. By addressing key barriers in security data generation, SETC represents a valuable platform to support impactful vulnerability and defensive security research.","sentences":["As emerging software vulnerabilities continuously threaten enterprises and Internet services, there is a critical need for improved security research capabilities.","This paper introduces the Security Exploit Telemetry Collection (SETC) framework - an automated framework to generate reproducible vulnerability exploit data at scale for robust defensive security research.","SETC deploys configurable environments to execute and record rich telemetry of vulnerability exploits within isolated containers.","Exploits, vulnerable services, monitoring tools, and logging pipelines are defined via modular JSON configurations and deployed on demand.","Compared to current manual processes, SETC enables automated, customizable, and repeatable vulnerability testing to produce diverse security telemetry.","This research enables scalable exploit data generation to drive innovations in threat modeling, detection methods, analysis techniques, and remediation strategies.","The capabilities of the framework are demonstrated through an example scenario.","By addressing key barriers in security data generation, SETC represents a valuable platform to support impactful vulnerability and defensive security research."],"url":"http://arxiv.org/abs/2406.05942v1"}
{"created":"2024-06-09 23:29:12","title":"A Relevance Model for Threat-Centric Ranking of Cybersecurity Vulnerabilities","abstract":"The relentless process of tracking and remediating vulnerabilities is a top concern for cybersecurity professionals. The key challenge is trying to identify a remediation scheme specific to in-house, organizational objectives. Without a strategy, the result is a patchwork of fixes applied to a tide of vulnerabilities, any one of which could be the point of failure in an otherwise formidable defense. Given that few vulnerabilities are a focus of real-world attacks, a practical remediation strategy is to identify vulnerabilities likely to be exploited and focus efforts towards remediating those vulnerabilities first. The goal of this research is to demonstrate that aggregating and synthesizing readily accessible, public data sources to provide personalized, automated recommendations for organizations to prioritize their vulnerability management strategy will offer significant improvements over using the Common Vulnerability Scoring System (CVSS). We provide a framework for vulnerability management specifically focused on mitigating threats using adversary criteria derived from MITRE ATT&CK. We test our approach by identifying vulnerabilities in software associated with six universities and four government facilities. Ranking policy performance is measured using the Normalized Discounted Cumulative Gain (nDCG). Our results show an average 71.5% - 91.3% improvement towards the identification of vulnerabilities likely to be targeted and exploited by cyber threat actors. The return on investment (ROI) of patching using our policies results in a savings of 23.3% - 25.5% in annualized costs. Our results demonstrate the efficacy of creating knowledge graphs to link large data sets to facilitate semantic queries and create data-driven, flexible ranking policies.","sentences":["The relentless process of tracking and remediating vulnerabilities is a top concern for cybersecurity professionals.","The key challenge is trying to identify a remediation scheme specific to in-house, organizational objectives.","Without a strategy, the result is a patchwork of fixes applied to a tide of vulnerabilities, any one of which could be the point of failure in an otherwise formidable defense.","Given that few vulnerabilities are a focus of real-world attacks, a practical remediation strategy is to identify vulnerabilities likely to be exploited and focus efforts towards remediating those vulnerabilities first.","The goal of this research is to demonstrate that aggregating and synthesizing readily accessible, public data sources to provide personalized, automated recommendations for organizations to prioritize their vulnerability management strategy will offer significant improvements over using the Common Vulnerability Scoring System (CVSS).","We provide a framework for vulnerability management specifically focused on mitigating threats using adversary criteria derived from MITRE ATT&CK.","We test our approach by identifying vulnerabilities in software associated with six universities and four government facilities.","Ranking policy performance is measured using the Normalized Discounted Cumulative Gain (nDCG).","Our results show an average 71.5% - 91.3% improvement towards the identification of vulnerabilities likely to be targeted and exploited by cyber threat actors.","The return on investment (ROI) of patching using our policies results in a savings of 23.3% - 25.5% in annualized costs.","Our results demonstrate the efficacy of creating knowledge graphs to link large data sets to facilitate semantic queries and create data-driven, flexible ranking policies."],"url":"http://arxiv.org/abs/2406.05933v1"}
{"created":"2024-06-09 22:46:41","title":"Semisupervised Neural Proto-Language Reconstruction","abstract":"Existing work implementing comparative reconstruction of ancestral languages (proto-languages) has usually required full supervision. However, historical reconstruction models are only of practical value if they can be trained with a limited amount of labeled data. We propose a semisupervised historical reconstruction task in which the model is trained on only a small amount of labeled data (cognate sets with proto-forms) and a large amount of unlabeled data (cognate sets without proto-forms). We propose a neural architecture for comparative reconstruction (DPD-BiReconstructor) incorporating an essential insight from linguists' comparative method: that reconstructed words should not only be reconstructable from their daughter words, but also deterministically transformable back into their daughter words. We show that this architecture is able to leverage unlabeled cognate sets to outperform strong semisupervised baselines on this novel task.","sentences":["Existing work implementing comparative reconstruction of ancestral languages (proto-languages) has usually required full supervision.","However, historical reconstruction models are only of practical value if they can be trained with a limited amount of labeled data.","We propose a semisupervised historical reconstruction task in which the model is trained on only a small amount of labeled data (cognate sets with proto-forms) and a large amount of unlabeled data (cognate sets without proto-forms).","We propose a neural architecture for comparative reconstruction (DPD-BiReconstructor) incorporating an essential insight from linguists' comparative method: that reconstructed words should not only be reconstructable from their daughter words, but also deterministically transformable back into their daughter words.","We show that this architecture is able to leverage unlabeled cognate sets to outperform strong semisupervised baselines on this novel task."],"url":"http://arxiv.org/abs/2406.05930v1"}
{"created":"2024-06-09 21:44:06","title":"Contrastive Learning from Synthetic Audio Doppelgangers","abstract":"Learning robust audio representations currently demands extensive datasets of real-world sound recordings. By applying artificial transformations to these recordings, models can learn to recognize similarities despite subtle variations through techniques like contrastive learning. However, these transformations are only approximations of the true diversity found in real-world sounds, which are generated by complex interactions of physical processes, from vocal cord vibrations to the resonance of musical instruments. We propose a solution to both the data scale and transformation limitations, leveraging synthetic audio. By randomly perturbing the parameters of a sound synthesizer, we generate audio doppelg\\\"angers-synthetic positive pairs with causally manipulated variations in timbre, pitch, and temporal envelopes. These variations, difficult to achieve through transformations of existing audio, provide a rich source of contrastive information. Despite the shift to randomly generated synthetic data, our method produces strong representations, competitive with real data on standard audio classification benchmarks. Notably, our approach is lightweight, requires no data storage, and has only a single hyperparameter, which we extensively analyze. We offer this method as a complement to existing strategies for contrastive learning in audio, using synthesized sounds to reduce the data burden on practitioners.","sentences":["Learning robust audio representations currently demands extensive datasets of real-world sound recordings.","By applying artificial transformations to these recordings, models can learn to recognize similarities despite subtle variations through techniques like contrastive learning.","However, these transformations are only approximations of the true diversity found in real-world sounds, which are generated by complex interactions of physical processes, from vocal cord vibrations to the resonance of musical instruments.","We propose a solution to both the data scale and transformation limitations, leveraging synthetic audio.","By randomly perturbing the parameters of a sound synthesizer, we generate audio doppelg\\\"angers-synthetic positive pairs with causally manipulated variations in timbre, pitch, and temporal envelopes.","These variations, difficult to achieve through transformations of existing audio, provide a rich source of contrastive information.","Despite the shift to randomly generated synthetic data, our method produces strong representations, competitive with real data on standard audio classification benchmarks.","Notably, our approach is lightweight, requires no data storage, and has only a single hyperparameter, which we extensively analyze.","We offer this method as a complement to existing strategies for contrastive learning in audio, using synthesized sounds to reduce the data burden on practitioners."],"url":"http://arxiv.org/abs/2406.05923v1"}
{"created":"2024-06-09 20:56:28","title":"Revisiting Multi-User Downlink in IEEE 802.11ax: A Designers Guide to MU-MIMO","abstract":"Downlink (DL) Multi-User (MU) Multiple Input Multiple Output (MU-MIMO) is a key technology that allows multiple concurrent data transmissions from an Access Point (AP) to a selected sub-set of clients for higher network efficiency in IEEE 802.11ax. However, DL MU-MIMO feature is typically turned off as the default setting in AP vendors' products, that is, turning on the DL MU-MIMO may not help increase the network efficiency, which is counter-intuitive. In this article, we provide a sufficiently deep understanding of the interplay between the various underlying factors, i.e., CSI overhead and spatial correlation, which result in negative results when turning on the DL MU-MIMO. Furthermore, we provide a fundamental guideline as a function of operational scenarios to address the fundamental question \"when the DL MU-MIMO should be turned on/off\".","sentences":["Downlink (DL) Multi-User (MU) Multiple Input Multiple Output (MU-MIMO) is a key technology that allows multiple concurrent data transmissions from an Access Point (AP) to a selected sub-set of clients for higher network efficiency in IEEE 802.11ax.","However, DL MU-MIMO feature is typically turned off as the default setting in AP vendors' products, that is, turning on the DL MU-MIMO may not help increase the network efficiency, which is counter-intuitive.","In this article, we provide a sufficiently deep understanding of the interplay between the various underlying factors, i.e., CSI overhead and spatial correlation, which result in negative results when turning on the DL MU-MIMO.","Furthermore, we provide a fundamental guideline as a function of operational scenarios to address the fundamental question \"when the DL MU-MIMO should be turned on/off\"."],"url":"http://arxiv.org/abs/2406.05913v1"}
{"created":"2024-06-09 20:54:58","title":"BD-SAT: High-resolution Land Use Land Cover Dataset & Benchmark Results for Developing Division: Dhaka, BD","abstract":"Land Use Land Cover (LULC) analysis on satellite images using deep learning-based methods is significantly helpful in understanding the geography, socio-economic conditions, poverty levels, and urban sprawl in developing countries. Recent works involve segmentation with LULC classes such as farmland, built-up areas, forests, meadows, water bodies, etc. Training deep learning methods on satellite images requires large sets of images annotated with LULC classes. However, annotated data for developing countries are scarce due to a lack of funding, absence of dedicated residential/industrial/economic zones, a large population, and diverse building materials. BD-SAT provides a high-resolution dataset that includes pixel-by-pixel LULC annotations for Dhaka metropolitan city and surrounding rural/urban areas. Using a strict and standardized procedure, the ground truth is created using Bing satellite imagery with a ground spatial distance of 2.22 meters per pixel. A three-stage, well-defined annotation process has been followed with support from GIS experts to ensure the reliability of the annotations. We performed several experiments to establish benchmark results. The results show that the annotated BD-SAT is sufficient to train large deep learning models with adequate accuracy for five major LULC classes: forest, farmland, built-up areas, water bodies, and meadows.","sentences":["Land Use Land Cover (LULC) analysis on satellite images using deep learning-based methods is significantly helpful in understanding the geography, socio-economic conditions, poverty levels, and urban sprawl in developing countries.","Recent works involve segmentation with LULC classes such as farmland, built-up areas, forests, meadows, water bodies, etc.","Training deep learning methods on satellite images requires large sets of images annotated with LULC classes.","However, annotated data for developing countries are scarce due to a lack of funding, absence of dedicated residential/industrial/economic zones, a large population, and diverse building materials.","BD-SAT provides a high-resolution dataset that includes pixel-by-pixel LULC annotations for Dhaka metropolitan city and surrounding rural/urban areas.","Using a strict and standardized procedure, the ground truth is created using Bing satellite imagery with a ground spatial distance of 2.22 meters per pixel.","A three-stage, well-defined annotation process has been followed with support from GIS experts to ensure the reliability of the annotations.","We performed several experiments to establish benchmark results.","The results show that the annotated BD-SAT is sufficient to train large deep learning models with adequate accuracy for five major LULC classes: forest, farmland, built-up areas, water bodies, and meadows."],"url":"http://arxiv.org/abs/2406.05912v1"}
{"created":"2024-06-09 20:18:58","title":"TTM-RE: Memory-Augmented Document-Level Relation Extraction","abstract":"Document-level relation extraction aims to categorize the association between any two entities within a document. We find that previous methods for document-level relation extraction are ineffective in exploiting the full potential of large amounts of training data with varied noise levels. For example, in the ReDocRED benchmark dataset, state-of-the-art methods trained on the large-scale, lower-quality, distantly supervised training data generally do not perform better than those trained solely on the smaller, high-quality, human-annotated training data. To unlock the full potential of large-scale noisy training data for document-level relation extraction, we propose TTM-RE, a novel approach that integrates a trainable memory module, known as the Token Turing Machine, with a noisy-robust loss function that accounts for the positive-unlabeled setting. Extensive experiments on ReDocRED, a benchmark dataset for document-level relation extraction, reveal that TTM-RE achieves state-of-the-art performance (with an absolute F1 score improvement of over 3%). Ablation studies further illustrate the superiority of TTM-RE in other domains (the ChemDisGene dataset in the biomedical domain) and under highly unlabeled settings.","sentences":["Document-level relation extraction aims to categorize the association between any two entities within a document.","We find that previous methods for document-level relation extraction are ineffective in exploiting the full potential of large amounts of training data with varied noise levels.","For example, in the ReDocRED benchmark dataset, state-of-the-art methods trained on the large-scale, lower-quality, distantly supervised training data generally do not perform better than those trained solely on the smaller, high-quality, human-annotated training data.","To unlock the full potential of large-scale noisy training data for document-level relation extraction, we propose TTM-RE, a novel approach that integrates a trainable memory module, known as the Token Turing Machine, with a noisy-robust loss function that accounts for the positive-unlabeled setting.","Extensive experiments on ReDocRED, a benchmark dataset for document-level relation extraction, reveal that TTM-RE achieves state-of-the-art performance (with an absolute F1 score improvement of over 3%).","Ablation studies further illustrate the superiority of TTM-RE in other domains (the ChemDisGene dataset in the biomedical domain) and under highly unlabeled settings."],"url":"http://arxiv.org/abs/2406.05906v1"}
{"created":"2024-06-09 19:38:27","title":"Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research","abstract":"The astonishing success of Large Language Models (LLMs) in Natural Language Processing (NLP) has spurred their use in many application domains beyond text analysis, including wearable sensor-based Human Activity Recognition (HAR). In such scenarios, often sensor data are directly fed into an LLM along with text instructions for the model to perform activity classification. Seemingly remarkable results have been reported for such LLM-based HAR systems when they are evaluated on standard benchmarks from the field. Yet, we argue, care has to be taken when evaluating LLM-based HAR systems in such a traditional way. Most contemporary LLMs are trained on virtually the entire (accessible) internet -- potentially including standard HAR datasets. With that, it is not unlikely that LLMs actually had access to the test data used in such benchmark experiments.The resulting contamination of training data would render these experimental evaluations meaningless. In this paper we investigate whether LLMs indeed have had access to standard HAR datasets during training. We apply memorization tests to LLMs, which involves instructing the models to extend given snippets of data. When comparing the LLM-generated output to the original data we found a non-negligible amount of matches which suggests that the LLM under investigation seems to indeed have seen wearable sensor data from the benchmark datasets during training. For the Daphnet dataset in particular, GPT-4 is able to reproduce blocks of sensor readings. We report on our investigations and discuss potential implications on HAR research, especially with regards to reporting results on experimental evaluation","sentences":["The astonishing success of Large Language Models (LLMs) in Natural Language Processing (NLP) has spurred their use in many application domains beyond text analysis, including wearable sensor-based Human Activity Recognition (HAR).","In such scenarios, often sensor data are directly fed into an LLM along with text instructions for the model to perform activity classification.","Seemingly remarkable results have been reported for such LLM-based HAR systems when they are evaluated on standard benchmarks from the field.","Yet, we argue, care has to be taken when evaluating LLM-based HAR systems in such a traditional way.","Most contemporary LLMs are trained on virtually the entire (accessible) internet -- potentially including standard HAR datasets.","With that, it is not unlikely that LLMs actually had access to the test data used in such benchmark experiments.","The resulting contamination of training data would render these experimental evaluations meaningless.","In this paper we investigate whether LLMs indeed have had access to standard HAR datasets during training.","We apply memorization tests to LLMs, which involves instructing the models to extend given snippets of data.","When comparing the LLM-generated output to the original data we found a non-negligible amount of matches which suggests that the LLM under investigation seems to indeed have seen wearable sensor data from the benchmark datasets during training.","For the Daphnet dataset in particular, GPT-4 is able to reproduce blocks of sensor readings.","We report on our investigations and discuss potential implications on HAR research, especially with regards to reporting results on experimental evaluation"],"url":"http://arxiv.org/abs/2406.05900v1"}
{"created":"2024-06-09 19:23:20","title":"Event prediction and causality inference despite incomplete information","abstract":"We explored the challenge of predicting and explaining the occurrence of events within sequences of data points. Our focus was particularly on scenarios in which unknown triggers causing the occurrence of events may consist of non-consecutive, masked, noisy data points. This scenario is akin to an agent tasked with learning to predict and explain the occurrence of events without understanding the underlying processes or having access to crucial information. Such scenarios are encountered across various fields, such as genomics, hardware and software verification, and financial time series prediction. We combined analytical, simulation, and machine learning (ML) approaches to investigate, quantify, and provide solutions to this challenge. We deduced and validated equations generally applicable to any variation of the underlying challenge. Using these equations, we (1) described how the level of complexity changes with various parameters (e.g., number of apparent and hidden states, trigger length, confidence, etc.) and (2) quantified the data needed to successfully train an ML model. We then (3) proved our ML solution learns and subsequently identifies unknown triggers and predicts the occurrence of events. If the complexity of the challenge is too high, our ML solution can identify trigger candidates to be used to interactively probe the system under investigation to determine the true trigger in a way considerably more efficient than brute force methods. By sharing our findings, we aim to assist others grappling with similar challenges, enabling estimates on the complexity of their problem, the data required and a solution to solve it.","sentences":["We explored the challenge of predicting and explaining the occurrence of events within sequences of data points.","Our focus was particularly on scenarios in which unknown triggers causing the occurrence of events may consist of non-consecutive, masked, noisy data points.","This scenario is akin to an agent tasked with learning to predict and explain the occurrence of events without understanding the underlying processes or having access to crucial information.","Such scenarios are encountered across various fields, such as genomics, hardware and software verification, and financial time series prediction.","We combined analytical, simulation, and machine learning (ML) approaches to investigate, quantify, and provide solutions to this challenge.","We deduced and validated equations generally applicable to any variation of the underlying challenge.","Using these equations, we (1) described how the level of complexity changes with various parameters (e.g., number of apparent and hidden states, trigger length, confidence, etc.)","and (2) quantified the data needed to successfully train an ML model.","We then (3) proved our ML solution learns and subsequently identifies unknown triggers and predicts the occurrence of events.","If the complexity of the challenge is too high, our ML solution can identify trigger candidates to be used to interactively probe the system under investigation to determine the true trigger in a way considerably more efficient than brute force methods.","By sharing our findings, we aim to assist others grappling with similar challenges, enabling estimates on the complexity of their problem, the data required and a solution to solve it."],"url":"http://arxiv.org/abs/2406.05893v1"}
{"created":"2024-06-09 19:18:05","title":"Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models","abstract":"Software security vulnerabilities allow attackers to perform malicious activities to disrupt software operations. Recent Transformer-based language models have significantly advanced vulnerability detection, surpassing the capabilities of static analysis based deep learning models. However, language models trained solely on code tokens do not capture either the explanation of vulnerability type or the data flow structure information of code, both of which are crucial for vulnerability detection. We propose a novel technique that integrates a multitask sequence-to-sequence LLM with pro-gram control flow graphs encoded as a graph neural network to achieve sequence-to-classification vulnerability detection. We introduce MSIVD, multitask self-instructed fine-tuning for vulnerability detection, inspired by chain-of-thought prompting and LLM self-instruction. Our experiments demonstrate that MSIVD achieves superior performance, outperforming the highest LLM-based vulnerability detector baseline (LineVul), with a F1 score of 0.92 on the BigVul dataset, and 0.48 on the PreciseBugs dataset. By training LLMs and GNNs simultaneously using a combination of code and explanatory metrics of a vulnerable program, MSIVD represents a promising direction for advancing LLM-based vulnerability detection that generalizes to unseen data. Based on our findings, we further discuss the necessity for new labelled security vulnerability datasets, as recent LLMs have seen or memorized prior datasets' held-out evaluation data.","sentences":["Software security vulnerabilities allow attackers to perform malicious activities to disrupt software operations.","Recent Transformer-based language models have significantly advanced vulnerability detection, surpassing the capabilities of static analysis based deep learning models.","However, language models trained solely on code tokens do not capture either the explanation of vulnerability type or the data flow structure information of code, both of which are crucial for vulnerability detection.","We propose a novel technique that integrates a multitask sequence-to-sequence LLM with pro-gram control flow graphs encoded as a graph neural network to achieve sequence-to-classification vulnerability detection.","We introduce MSIVD, multitask self-instructed fine-tuning for vulnerability detection, inspired by chain-of-thought prompting and LLM self-instruction.","Our experiments demonstrate that MSIVD achieves superior performance, outperforming the highest LLM-based vulnerability detector baseline (LineVul), with a F1 score of 0.92 on the BigVul dataset, and 0.48 on the PreciseBugs dataset.","By training LLMs and GNNs simultaneously using a combination of code and explanatory metrics of a vulnerable program, MSIVD represents a promising direction for advancing LLM-based vulnerability detection that generalizes to unseen data.","Based on our findings, we further discuss the necessity for new labelled security vulnerability datasets, as recent LLMs have seen or memorized prior datasets' held-out evaluation data."],"url":"http://arxiv.org/abs/2406.05892v1"}
{"created":"2024-06-09 18:59:08","title":"Few-Shot Load Forecasting Under Data Scarcity in Smart Grids: A Meta-Learning Approach","abstract":"Despite the rapid expansion of smart grids and large volumes of data at the individual consumer level, there are still various cases where adequate data collection to train accurate load forecasting models is challenging or even impossible. This paper proposes adapting an established model-agnostic meta-learning algorithm for short-term load forecasting in the context of few-shot learning. Specifically, the proposed method can rapidly adapt and generalize within any unknown load time series of arbitrary length using only minimal training samples. In this context, the meta-learning model learns an optimal set of initial parameters for a base-level learner recurrent neural network. The proposed model is evaluated using a dataset of historical load consumption data from real-world consumers. Despite the examined load series' short length, it produces accurate forecasts outperforming transfer learning and task-specific machine learning methods by $12.5\\%$. To enhance robustness and fairness during model evaluation, a novel metric, mean average log percentage error, is proposed that alleviates the bias introduced by the commonly used MAPE metric. Finally, a series of studies to evaluate the model's robustness under different hyperparameters and time series lengths is also conducted, demonstrating that the proposed approach consistently outperforms all other models.","sentences":["Despite the rapid expansion of smart grids and large volumes of data at the individual consumer level, there are still various cases where adequate data collection to train accurate load forecasting models is challenging or even impossible.","This paper proposes adapting an established model-agnostic meta-learning algorithm for short-term load forecasting in the context of few-shot learning.","Specifically, the proposed method can rapidly adapt and generalize within any unknown load time series of arbitrary length using only minimal training samples.","In this context, the meta-learning model learns an optimal set of initial parameters for a base-level learner recurrent neural network.","The proposed model is evaluated using a dataset of historical load consumption data from real-world consumers.","Despite the examined load series' short length, it produces accurate forecasts outperforming transfer learning and task-specific machine learning methods by $12.5\\%$. To enhance robustness and fairness during model evaluation, a novel metric, mean average log percentage error, is proposed that alleviates the bias introduced by the commonly used MAPE metric.","Finally, a series of studies to evaluate the model's robustness under different hyperparameters and time series lengths is also conducted, demonstrating that the proposed approach consistently outperforms all other models."],"url":"http://arxiv.org/abs/2406.05887v1"}
{"created":"2024-06-09 18:41:50","title":"Information Theoretic Guarantees For Policy Alignment In Large Language Models","abstract":"Policy alignment of large language models refers to constrained policy optimization, where the policy is optimized to maximize a reward while staying close to a reference policy with respect to an $f$-divergence such as the $\\mathsf{KL}$ divergence. The best of $n$ alignment policy selects a sample from the reference policy that has the maximum reward among $n$ independent samples. For both cases (policy alignment and best of $n$), recent works showed empirically that the reward improvement of the aligned policy on the reference one scales like $\\sqrt{\\mathsf{KL}}$, with an explicit bound in $n$ on the $\\mathsf{KL}$ for the best of $n$ policy. We show in this paper that the $\\sqrt{\\mathsf{KL}}$ information theoretic upper bound holds if the reward under the reference policy has sub-gaussian tails. Moreover, we prove for the best of $n$ policy, that the $\\mathsf{KL}$ upper bound can be obtained for any $f$-divergence via a reduction to exponential order statistics owing to the R\\'enyi representation of order statistics, and a data processing inequality. If additional information is known on the tails of the aligned policy we show that tighter control on the reward improvement can be obtained via the R\\'enyi divergence. Finally we demonstrate how these upper bounds transfer from proxy rewards to golden rewards which results in a decrease in the golden reward improvement due to overestimation and approximation errors of the proxy reward.","sentences":["Policy alignment of large language models refers to constrained policy optimization, where the policy is optimized to maximize a reward while staying close to a reference policy with respect to an $f$-divergence such as the $\\mathsf{KL}$ divergence.","The best of $n$ alignment policy selects a sample from the reference policy that has the maximum reward among $n$ independent samples.","For both cases (policy alignment and best of $n$), recent works showed empirically that the reward improvement of the aligned policy on the reference one scales like $\\sqrt{\\mathsf{KL}}$, with an explicit bound in $n$ on the $\\mathsf{KL}$ for the best of $n$ policy.","We show in this paper that the $\\sqrt{\\mathsf{KL}}$ information theoretic upper bound holds if the reward under the reference policy has sub-gaussian tails.","Moreover, we prove for the best of $n$ policy, that the $\\mathsf{KL}$ upper bound can be obtained for any $f$-divergence via a reduction to exponential order statistics owing to the R\\'enyi representation of order statistics, and a data processing inequality.","If additional information is known on the tails of the aligned policy we show that tighter control on the reward improvement can be obtained via the R\\'enyi divergence.","Finally we demonstrate how these upper bounds transfer from proxy rewards to golden rewards which results in a decrease in the golden reward improvement due to overestimation and approximation errors of the proxy reward."],"url":"http://arxiv.org/abs/2406.05883v1"}
{"created":"2024-06-09 18:41:05","title":"Distributional Preference Alignment of LLMs via Optimal Transport","abstract":"Current LLM alignment techniques use pairwise human preferences at a sample level, and as such, they do not imply an alignment on the distributional level. We propose in this paper Alignment via Optimal Transport (AOT), a novel method for distributional preference alignment of LLMs. AOT aligns LLMs on unpaired preference data by making the reward distribution of the positive samples stochastically dominant in the first order on the distribution of negative samples. We introduce a convex relaxation of this first-order stochastic dominance and cast it as an optimal transport problem with a smooth and convex cost. Thanks to the one-dimensional nature of the resulting optimal transport problem and the convexity of the cost, it has a closed-form solution via sorting on empirical measures. We fine-tune LLMs with this AOT objective, which enables alignment by penalizing the violation of the stochastic dominance of the reward distribution of the positive samples on the reward distribution of the negative samples. We analyze the sample complexity of AOT by considering the dual of the OT problem and show that it converges at the parametric rate. Empirically, we show on a diverse set of alignment datasets and LLMs that AOT leads to state-of-the-art models in the 7B family of models when evaluated with Open LLM Benchmarks and AlpacaEval.","sentences":["Current LLM alignment techniques use pairwise human preferences at a sample level, and as such, they do not imply an alignment on the distributional level.","We propose in this paper Alignment via Optimal Transport (AOT), a novel method for distributional preference alignment of LLMs.","AOT aligns LLMs on unpaired preference data by making the reward distribution of the positive samples stochastically dominant in the first order on the distribution of negative samples.","We introduce a convex relaxation of this first-order stochastic dominance and cast it as an optimal transport problem with a smooth and convex cost.","Thanks to the one-dimensional nature of the resulting optimal transport problem and the convexity of the cost, it has a closed-form solution via sorting on empirical measures.","We fine-tune LLMs with this AOT objective, which enables alignment by penalizing the violation of the stochastic dominance of the reward distribution of the positive samples on the reward distribution of the negative samples.","We analyze the sample complexity of AOT by considering the dual of the OT problem and show that it converges at the parametric rate.","Empirically, we show on a diverse set of alignment datasets and LLMs that AOT leads to state-of-the-art models in the 7B family of models when evaluated with Open LLM Benchmarks and AlpacaEval."],"url":"http://arxiv.org/abs/2406.05882v1"}
{"created":"2024-06-09 18:11:05","title":"Conserving Human Creativity with Evolutionary Generative Algorithms: A Case Study in Music Generation","abstract":"This study explores the application of evolutionary generative algorithms in music production to preserve and enhance human creativity. By integrating human feedback into Differential Evolution algorithms, we produced six songs that were submitted to international record labels, all of which received contract offers. In addition to testing the commercial viability of these methods, this paper examines the long-term implications of content generation using traditional machine learning methods compared with evolutionary algorithms. Specifically, as current generative techniques continue to scale, the potential for computer-generated content to outpace human creation becomes likely. This trend poses a risk of exhausting the pool of human-created training data, potentially forcing generative machine learning models to increasingly depend on their random input functions for generating novel content. In contrast to a future of content generation guided by aimless random functions, our approach allows for individualized creative exploration, ensuring that computer-assisted content generation methods are human-centric and culturally relevant through time.","sentences":["This study explores the application of evolutionary generative algorithms in music production to preserve and enhance human creativity.","By integrating human feedback into Differential Evolution algorithms, we produced six songs that were submitted to international record labels, all of which received contract offers.","In addition to testing the commercial viability of these methods, this paper examines the long-term implications of content generation using traditional machine learning methods compared with evolutionary algorithms.","Specifically, as current generative techniques continue to scale, the potential for computer-generated content to outpace human creation becomes likely.","This trend poses a risk of exhausting the pool of human-created training data, potentially forcing generative machine learning models to increasingly depend on their random input functions for generating novel content.","In contrast to a future of content generation guided by aimless random functions, our approach allows for individualized creative exploration, ensuring that computer-assisted content generation methods are human-centric and culturally relevant through time."],"url":"http://arxiv.org/abs/2406.05873v1"}
{"created":"2024-06-09 17:27:20","title":"Source -Free Domain Adaptation for Speaker Verification in Data-Scarce Languages and Noisy Channels","abstract":"Domain adaptation is often hampered by exceedingly small target datasets and inaccessible source data. These conditions are prevalent in speech verification, where privacy policies and/or languages with scarce speech resources limit the availability of sufficient data. This paper explored techniques of sourcefree domain adaptation unto a limited target speech dataset for speaker verificationin data-scarce languages. Both language and channel mis-match between source and target were investigated. Fine-tuning methods were evaluated and compared across different sizes of labeled target data. A novel iterative cluster-learn algorithm was studied for unlabeled target datasets.","sentences":["Domain adaptation is often hampered by exceedingly small target datasets and inaccessible source data.","These conditions are prevalent in speech verification, where privacy policies and/or languages with scarce speech resources limit the availability of sufficient data.","This paper explored techniques of sourcefree domain adaptation unto a limited target speech dataset for speaker verificationin data-scarce languages.","Both language and channel mis-match between source and target were investigated.","Fine-tuning methods were evaluated and compared across different sizes of labeled target data.","A novel iterative cluster-learn algorithm was studied for unlabeled target datasets."],"url":"http://arxiv.org/abs/2406.05863v1"}
{"created":"2024-06-09 16:59:11","title":"Predictors of the Sense of Presence in an Immersive Audio Storytelling Experience, a Mixed Methods Study. PREPRINT","abstract":"This study examined which variables predicted the sense of presence (being there) in an immersive audio experience, with a focus on the impacts of immersion technology (headphones with spatialised sound versus speaker with 2D stereo sound), the nature of the audio experience, the narrative content, participants emotional and cognitive engagement and personal characteristics such as age and gender. Museum visitors listened to a story on the One Story, Many Voices immersive audio installation. A convergent mixed-methods design was used, including multiple regression analysis of survey data (n 185) and relational analysis of interview data (n 9). This study found mixed methods support from both surveys and interviews to suggest that presence was predicted by the audio quality (especially the audio being perceived as different from other audio stories they had listened to in the past), cognitive engagement (especially being totally absorbed), the narrative (the story and how it was told) and some support was found for emotional engagement (especially feeling a connection with the storyteller). Effects of the environment and immersion technology on presence received only either quantitative or qualitative support. No influences of personal characteristics were found. Findings are relevant for academics, immersive experience (XR) commissioners and developers.","sentences":["This study examined which variables predicted the sense of presence (being there) in an immersive audio experience, with a focus on the impacts of immersion technology (headphones with spatialised sound versus speaker with 2D stereo sound), the nature of the audio experience, the narrative content, participants emotional and cognitive engagement and personal characteristics such as age and gender.","Museum visitors listened to a story on the One Story, Many Voices immersive audio installation.","A convergent mixed-methods design was used, including multiple regression analysis of survey data (n 185) and relational analysis of interview data (n 9).","This study found mixed methods support from both surveys and interviews to suggest that presence was predicted by the audio quality (especially the audio being perceived as different from other audio stories they had listened to in the past), cognitive engagement (especially being totally absorbed), the narrative (the story and how it was told) and some support was found for emotional engagement (especially feeling a connection with the storyteller).","Effects of the environment and immersion technology on presence received only either quantitative or qualitative support.","No influences of personal characteristics were found.","Findings are relevant for academics, immersive experience (XR) commissioners and developers."],"url":"http://arxiv.org/abs/2406.05856v1"}
