{"created":"2025-03-18 17:59:58","title":"MusicInfuser: Making Video Diffusion Listen and Dance","abstract":"We introduce MusicInfuser, an approach for generating high-quality dance videos that are synchronized to a specified music track. Rather than attempting to design and train a new multimodal audio-video model, we show how existing video diffusion models can be adapted to align with musical inputs by introducing lightweight music-video cross-attention and a low-rank adapter. Unlike prior work requiring motion capture data, our approach fine-tunes only on dance videos. MusicInfuser achieves high-quality music-driven video generation while preserving the flexibility and generative capabilities of the underlying models. We introduce an evaluation framework using Video-LLMs to assess multiple dimensions of dance generation quality. The project page and code are available at https://susunghong.github.io/MusicInfuser.","sentences":["We introduce MusicInfuser, an approach for generating high-quality dance videos that are synchronized to a specified music track.","Rather than attempting to design and train a new multimodal audio-video model, we show how existing video diffusion models can be adapted to align with musical inputs by introducing lightweight music-video cross-attention and a low-rank adapter.","Unlike prior work requiring motion capture data, our approach fine-tunes only on dance videos.","MusicInfuser achieves high-quality music-driven video generation while preserving the flexibility and generative capabilities of the underlying models.","We introduce an evaluation framework using Video-LLMs to assess multiple dimensions of dance generation quality.","The project page and code are available at https://susunghong.github.io/MusicInfuser."],"url":"http://arxiv.org/abs/2503.14505v1"}
{"created":"2025-03-18 17:59:56","title":"Aligning Multimodal LLM with Human Preference: A Survey","abstract":"Large language models (LLMs) can handle a wide variety of general tasks with simple prompts, without the need for task-specific training. Multimodal Large Language Models (MLLMs), built upon LLMs, have demonstrated impressive potential in tackling complex tasks involving visual, auditory, and textual data. However, critical issues related to truthfulness, safety, o1-like reasoning, and alignment with human preference remain insufficiently addressed. This gap has spurred the emergence of various alignment algorithms, each targeting different application scenarios and optimization goals. Recent studies have shown that alignment algorithms are a powerful approach to resolving the aforementioned challenges. In this paper, we aim to provide a comprehensive and systematic review of alignment algorithms for MLLMs. Specifically, we explore four key aspects: (1) the application scenarios covered by alignment algorithms, including general image understanding, multi-image, video, and audio, and extended multimodal applications; (2) the core factors in constructing alignment datasets, including data sources, model responses, and preference annotations; (3) the benchmarks used to evaluate alignment algorithms; and (4) a discussion of potential future directions for the development of alignment algorithms. This work seeks to help researchers organize current advancements in the field and inspire better alignment methods. The project page of this paper is available at https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Alignment.","sentences":["Large language models (LLMs) can handle a wide variety of general tasks with simple prompts, without the need for task-specific training.","Multimodal Large Language Models (MLLMs), built upon LLMs, have demonstrated impressive potential in tackling complex tasks involving visual, auditory, and textual data.","However, critical issues related to truthfulness, safety, o1-like reasoning, and alignment with human preference remain insufficiently addressed.","This gap has spurred the emergence of various alignment algorithms, each targeting different application scenarios and optimization goals.","Recent studies have shown that alignment algorithms are a powerful approach to resolving the aforementioned challenges.","In this paper, we aim to provide a comprehensive and systematic review of alignment algorithms for MLLMs.","Specifically, we explore four key aspects: (1) the application scenarios covered by alignment algorithms, including general image understanding, multi-image, video, and audio, and extended multimodal applications; (2) the core factors in constructing alignment datasets, including data sources, model responses, and preference annotations; (3) the benchmarks used to evaluate alignment algorithms; and (4) a discussion of potential future directions for the development of alignment algorithms.","This work seeks to help researchers organize current advancements in the field and inspire better alignment methods.","The project page of this paper is available at https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Alignment."],"url":"http://arxiv.org/abs/2503.14504v1"}
{"created":"2025-03-18 17:59:51","title":"Advances in 4D Generation: A Survey","abstract":"Generative artificial intelligence has witnessed remarkable advancements across multiple domains in recent years. Building on the successes of 2D and 3D content generation, 4D generation, which incorporates the temporal dimension into generative tasks, has emerged as a burgeoning yet rapidly evolving research area. This paper presents a comprehensive survey of this emerging field, systematically examining its theoretical foundations, key methodologies, and practical applications, with the aim of providing readers with a holistic understanding of the current state and future potential of 4D generation. We begin by introducing the core concepts of 4D data representations, encompassing both structured and unstructured formats, and their implications for generative tasks. Building upon this foundation, we delve into the enabling technologies that drive 4D generation, including advancements in spatiotemporal modeling, neural representations, and generative frameworks. We further review recent studies that employ diverse control mechanisms and representation strategies for generating 4D outputs, categorizing these approaches and summarizing their research trajectories. In addition, we explore the wide-ranging applications of 4D generation techniques, spanning dynamic object modeling, scene generation, digital human synthesis, 4D content editing, and autonomous driving. Finally, we analyze the key challenges inherent to 4D generation, such as data availability, computational efficiency, and spatiotemporal consistency, and propose promising directions for future research. Our code is publicly available at: \\href{https://github.com/MiaoQiaowei/Awesome-4D}{https://github.com/MiaoQiaowei/Awesome-4D}.","sentences":["Generative artificial intelligence has witnessed remarkable advancements across multiple domains in recent years.","Building on the successes of 2D and 3D content generation, 4D generation, which incorporates the temporal dimension into generative tasks, has emerged as a burgeoning yet rapidly evolving research area.","This paper presents a comprehensive survey of this emerging field, systematically examining its theoretical foundations, key methodologies, and practical applications, with the aim of providing readers with a holistic understanding of the current state and future potential of 4D generation.","We begin by introducing the core concepts of 4D data representations, encompassing both structured and unstructured formats, and their implications for generative tasks.","Building upon this foundation, we delve into the enabling technologies that drive 4D generation, including advancements in spatiotemporal modeling, neural representations, and generative frameworks.","We further review recent studies that employ diverse control mechanisms and representation strategies for generating 4D outputs, categorizing these approaches and summarizing their research trajectories.","In addition, we explore the wide-ranging applications of 4D generation techniques, spanning dynamic object modeling, scene generation, digital human synthesis, 4D content editing, and autonomous driving.","Finally, we analyze the key challenges inherent to 4D generation, such as data availability, computational efficiency, and spatiotemporal consistency, and propose promising directions for future research.","Our code is publicly available at: \\href{https://github.com/MiaoQiaowei/Awesome-4D}{https://github.com/MiaoQiaowei/Awesome-4D}."],"url":"http://arxiv.org/abs/2503.14501v1"}
{"created":"2025-03-18 17:59:41","title":"Utilization of Neighbor Information for Image Classification with Different Levels of Supervision","abstract":"We propose to bridge the gap between semi-supervised and unsupervised image recognition with a flexible method that performs well for both generalized category discovery (GCD) and image clustering. Despite the overlap in motivation between these tasks, the methods themselves are restricted to a single task -- GCD methods are reliant on the labeled portion of the data, and deep image clustering methods have no built-in way to leverage the labels efficiently. We connect the two regimes with an innovative approach that Utilizes Neighbor Information for Classification (UNIC) both in the unsupervised (clustering) and semisupervised (GCD) setting. State-of-the-art clustering methods already rely heavily on nearest neighbors. We improve on their results substantially in two parts, first with a sampling and cleaning strategy where we identify accurate positive and negative neighbors, and secondly by finetuning the backbone with clustering losses computed by sampling both types of neighbors. We then adapt this pipeline to GCD by utilizing the labelled images as ground truth neighbors. Our method yields state-of-the-art results for both clustering (+3% ImageNet-100, Imagenet200) and GCD (+0.8% ImageNet-100, +5% CUB, +2% SCars, +4% Aircraft).","sentences":["We propose to bridge the gap between semi-supervised and unsupervised image recognition with a flexible method that performs well for both generalized category discovery (GCD) and image clustering.","Despite the overlap in motivation between these tasks, the methods themselves are restricted to a single task -- GCD methods are reliant on the labeled portion of the data, and deep image clustering methods have no built-in way to leverage the labels efficiently.","We connect the two regimes with an innovative approach that Utilizes Neighbor Information for Classification (UNIC) both in the unsupervised (clustering) and semisupervised (GCD) setting.","State-of-the-art clustering methods already rely heavily on nearest neighbors.","We improve on their results substantially in two parts, first with a sampling and cleaning strategy where we identify accurate positive and negative neighbors, and secondly by finetuning the backbone with clustering losses computed by sampling both types of neighbors.","We then adapt this pipeline to GCD by utilizing the labelled images as ground truth neighbors.","Our method yields state-of-the-art results for both clustering (+3% ImageNet-100, Imagenet200) and GCD (+0.8% ImageNet-100, +5% CUB, +2% SCars, +4% Aircraft)."],"url":"http://arxiv.org/abs/2503.14500v1"}
{"created":"2025-03-18 17:59:12","title":"Tracking Meets Large Multimodal Models for Driving Scenario Understanding","abstract":"Large Multimodal Models (LMMs) have recently gained prominence in autonomous driving research, showcasing promising capabilities across various emerging benchmarks. LMMs specifically designed for this domain have demonstrated effective perception, planning, and prediction skills. However, many of these methods underutilize 3D spatial and temporal elements, relying mainly on image data. As a result, their effectiveness in dynamic driving environments is limited. We propose to integrate tracking information as an additional input to recover 3D spatial and temporal details that are not effectively captured in the images. We introduce a novel approach for embedding this tracking information into LMMs to enhance their spatiotemporal understanding of driving scenarios. By incorporating 3D tracking data through a track encoder, we enrich visual queries with crucial spatial and temporal cues while avoiding the computational overhead associated with processing lengthy video sequences or extensive 3D inputs. Moreover, we employ a self-supervised approach to pretrain the tracking encoder to provide LMMs with additional contextual information, significantly improving their performance in perception, planning, and prediction tasks for autonomous driving. Experimental results demonstrate the effectiveness of our approach, with a gain of 9.5% in accuracy, an increase of 7.04 points in the ChatGPT score, and 9.4% increase in the overall score over baseline models on DriveLM-nuScenes benchmark, along with a 3.7% final score improvement on DriveLM-CARLA. Our code is available at https://github.com/mbzuai-oryx/TrackingMeetsLMM","sentences":["Large Multimodal Models (LMMs) have recently gained prominence in autonomous driving research, showcasing promising capabilities across various emerging benchmarks.","LMMs specifically designed for this domain have demonstrated effective perception, planning, and prediction skills.","However, many of these methods underutilize 3D spatial and temporal elements, relying mainly on image data.","As a result, their effectiveness in dynamic driving environments is limited.","We propose to integrate tracking information as an additional input to recover 3D spatial and temporal details that are not effectively captured in the images.","We introduce a novel approach for embedding this tracking information into LMMs to enhance their spatiotemporal understanding of driving scenarios.","By incorporating 3D tracking data through a track encoder, we enrich visual queries with crucial spatial and temporal cues while avoiding the computational overhead associated with processing lengthy video sequences or extensive 3D inputs.","Moreover, we employ a self-supervised approach to pretrain the tracking encoder to provide LMMs with additional contextual information, significantly improving their performance in perception, planning, and prediction tasks for autonomous driving.","Experimental results demonstrate the effectiveness of our approach, with a gain of 9.5% in accuracy, an increase of 7.04 points in the ChatGPT score, and 9.4% increase in the overall score over baseline models on DriveLM-nuScenes benchmark, along with a 3.7% final score improvement on DriveLM-CARLA.","Our code is available at https://github.com/mbzuai-oryx/TrackingMeetsLMM"],"url":"http://arxiv.org/abs/2503.14498v1"}
{"created":"2025-03-18 17:57:54","title":"Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control","abstract":"We introduce Cosmos-Transfer, a conditional world generation model that can generate world simulations based on multiple spatial control inputs of various modalities such as segmentation, depth, and edge. In the design, the spatial conditional scheme is adaptive and customizable. It allows weighting different conditional inputs differently at different spatial locations. This enables highly controllable world generation and finds use in various world-to-world transfer use cases, including Sim2Real. We conduct extensive evaluations to analyze the proposed model and demonstrate its applications for Physical AI, including robotics Sim2Real and autonomous vehicle data enrichment. We further demonstrate an inference scaling strategy to achieve real-time world generation with an NVIDIA GB200 NVL72 rack. To help accelerate research development in the field, we open-source our models and code at https://github.com/nvidia-cosmos/cosmos-transfer1.","sentences":["We introduce Cosmos-Transfer, a conditional world generation model that can generate world simulations based on multiple spatial control inputs of various modalities such as segmentation, depth, and edge.","In the design, the spatial conditional scheme is adaptive and customizable.","It allows weighting different conditional inputs differently at different spatial locations.","This enables highly controllable world generation and finds use in various world-to-world transfer use cases, including Sim2Real.","We conduct extensive evaluations to analyze the proposed model and demonstrate its applications for Physical AI, including robotics Sim2Real and autonomous vehicle data enrichment.","We further demonstrate an inference scaling strategy to achieve real-time world generation with an NVIDIA GB200 NVL72 rack.","To help accelerate research development in the field, we open-source our models and code at https://github.com/nvidia-cosmos/cosmos-transfer1."],"url":"http://arxiv.org/abs/2503.14492v1"}
{"created":"2025-03-18 17:57:16","title":"Engineering Scientific Assistants using Interactive Structured Induction of Programs","abstract":"We are interested in the construction of software that can act as scientific assistants to domain specialists. It is expected that such assistants will be needed to accelerate the identification of ways to address complex problems requiring urgent solutions. In this paper, our focus is not on a specific scientific problem, but on the software-engineering of such 'science accelerators'. Recent developments in 'No Code' techniques would seem to suggest that scientist can simply hypothesise solutions simply by conversing with a large language model (LLM). However, for complex scientific problems, this seems unlikely given the current state of LLM technology. What does appear feasible is that a software engineer can use LLMs to rapidly construct programs for use by a domain-specialist, including the specialist's requirements expressed in natural language. We propose the design of an interactive form of 'structured' inductive programming in which a software-engineer and an LLM collaboratively construct an 'assistant' for a scientific data analysis. The paper describes a simple implementation called iStrucInd that adapts a '2-way Intelligibility' protocol to implement the interaction between the software engineer and the LLM. We test the tool on two different non-trivial scientific data analysis tasks. Specifically, we compare the system constructed by iStrucInd against systems constructed manually and by Low Code/No Code methods along dimensions of: (a) program performance; (b) program quality; and (c) programming effort. The results show iStrucInd allows a software engineer to develop better programs faster suggesting interactive structured induction can play a useful role in the rapid construction of scientific assistants.","sentences":["We are interested in the construction of software that can act as scientific assistants to domain specialists.","It is expected that such assistants will be needed to accelerate the identification of ways to address complex problems requiring urgent solutions.","In this paper, our focus is not on a specific scientific problem, but on the software-engineering of such 'science accelerators'.","Recent developments in 'No Code' techniques would seem to suggest that scientist can simply hypothesise solutions simply by conversing with a large language model (LLM).","However, for complex scientific problems, this seems unlikely given the current state of LLM technology.","What does appear feasible is that a software engineer can use LLMs to rapidly construct programs for use by a domain-specialist, including the specialist's requirements expressed in natural language.","We propose the design of an interactive form of 'structured' inductive programming in which a software-engineer and an LLM collaboratively construct an 'assistant' for a scientific data analysis.","The paper describes a simple implementation called iStrucInd that adapts a '2-way Intelligibility' protocol to implement the interaction between the software engineer and the LLM.","We test the tool on two different non-trivial scientific data analysis tasks.","Specifically, we compare the system constructed by iStrucInd against systems constructed manually and by Low Code/No Code methods along dimensions of: (a) program performance; (b) program quality; and (c) programming effort.","The results show iStrucInd allows a software engineer to develop better programs faster suggesting interactive structured induction can play a useful role in the rapid construction of scientific assistants."],"url":"http://arxiv.org/abs/2503.14488v1"}
{"created":"2025-03-18 17:55:22","title":"Lux Post Facto: Learning Portrait Performance Relighting with Conditional Video Diffusion and a Hybrid Dataset","abstract":"Video portrait relighting remains challenging because the results need to be both photorealistic and temporally stable. This typically requires a strong model design that can capture complex facial reflections as well as intensive training on a high-quality paired video dataset, such as dynamic one-light-at-a-time (OLAT). In this work, we introduce Lux Post Facto, a novel portrait video relighting method that produces both photorealistic and temporally consistent lighting effects. From the model side, we design a new conditional video diffusion model built upon state-of-the-art pre-trained video diffusion model, alongside a new lighting injection mechanism to enable precise control. This way we leverage strong spatial and temporal generative capability to generate plausible solutions to the ill-posed relighting problem. Our technique uses a hybrid dataset consisting of static expression OLAT data and in-the-wild portrait performance videos to jointly learn relighting and temporal modeling. This avoids the need to acquire paired video data in different lighting conditions. Our extensive experiments show that our model produces state-of-the-art results both in terms of photorealism and temporal consistency.","sentences":["Video portrait relighting remains challenging because the results need to be both photorealistic and temporally stable.","This typically requires a strong model design that can capture complex facial reflections as well as intensive training on a high-quality paired video dataset, such as dynamic one-light-at-a-time (OLAT).","In this work, we introduce Lux Post Facto, a novel portrait video relighting method that produces both photorealistic and temporally consistent lighting effects.","From the model side, we design a new conditional video diffusion model built upon state-of-the-art pre-trained video diffusion model, alongside a new lighting injection mechanism to enable precise control.","This way we leverage strong spatial and temporal generative capability to generate plausible solutions to the ill-posed relighting problem.","Our technique uses a hybrid dataset consisting of static expression OLAT data and in-the-wild portrait performance videos to jointly learn relighting and temporal modeling.","This avoids the need to acquire paired video data in different lighting conditions.","Our extensive experiments show that our model produces state-of-the-art results both in terms of photorealism and temporal consistency."],"url":"http://arxiv.org/abs/2503.14485v1"}
{"created":"2025-03-18 17:53:29","title":"ICE-Bench: A Unified and Comprehensive Benchmark for Image Creating and Editing","abstract":"Image generation has witnessed significant advancements in the past few years. However, evaluating the performance of image generation models remains a formidable challenge. In this paper, we propose ICE-Bench, a unified and comprehensive benchmark designed to rigorously assess image generation models. Its comprehensiveness could be summarized in the following key features: (1) Coarse-to-Fine Tasks: We systematically deconstruct image generation into four task categories: No-ref/Ref Image Creating/Editing, based on the presence or absence of source images and reference images. And further decompose them into 31 fine-grained tasks covering a broad spectrum of image generation requirements, culminating in a comprehensive benchmark. (2) Multi-dimensional Metrics: The evaluation framework assesses image generation capabilities across 6 dimensions: aesthetic quality, imaging quality, prompt following, source consistency, reference consistency, and controllability. 11 metrics are introduced to support the multi-dimensional evaluation. Notably, we introduce VLLM-QA, an innovative metric designed to assess the success of image editing by leveraging large models. (3) Hybrid Data: The data comes from real scenes and virtual generation, which effectively improves data diversity and alleviates the bias problem in model evaluation. Through ICE-Bench, we conduct a thorough analysis of existing generation models, revealing both the challenging nature of our benchmark and the gap between current model capabilities and real-world generation requirements. To foster further advancements in the field, we will open-source ICE-Bench, including its dataset, evaluation code, and models, thereby providing a valuable resource for the research community.","sentences":["Image generation has witnessed significant advancements in the past few years.","However, evaluating the performance of image generation models remains a formidable challenge.","In this paper, we propose ICE-Bench, a unified and comprehensive benchmark designed to rigorously assess image generation models.","Its comprehensiveness could be summarized in the following key features: (1) Coarse-to-Fine Tasks: We systematically deconstruct image generation into four task categories: No-ref/Ref Image Creating/Editing, based on the presence or absence of source images and reference images.","And further decompose them into 31 fine-grained tasks covering a broad spectrum of image generation requirements, culminating in a comprehensive benchmark.","(2) Multi-dimensional Metrics: The evaluation framework assesses image generation capabilities across 6 dimensions: aesthetic quality, imaging quality, prompt following, source consistency, reference consistency, and controllability.","11 metrics are introduced to support the multi-dimensional evaluation.","Notably, we introduce VLLM-QA, an innovative metric designed to assess the success of image editing by leveraging large models.","(3) Hybrid Data:","The data comes from real scenes and virtual generation, which effectively improves data diversity and alleviates the bias problem in model evaluation.","Through ICE-Bench, we conduct a thorough analysis of existing generation models, revealing both the challenging nature of our benchmark and the gap between current model capabilities and real-world generation requirements.","To foster further advancements in the field, we will open-source ICE-Bench, including its dataset, evaluation code, and models, thereby providing a valuable resource for the research community."],"url":"http://arxiv.org/abs/2503.14482v1"}
{"created":"2025-03-18 17:51:34","title":"Creation-MMBench: Assessing Context-Aware Creative Intelligence in MLLM","abstract":"Creativity is a fundamental aspect of intelligence, involving the ability to generate novel and appropriate solutions across diverse contexts. While Large Language Models (LLMs) have been extensively evaluated for their creative capabilities, the assessment of Multimodal Large Language Models (MLLMs) in this domain remains largely unexplored. To address this gap, we introduce Creation-MMBench, a multimodal benchmark specifically designed to evaluate the creative capabilities of MLLMs in real-world, image-based tasks. The benchmark comprises 765 test cases spanning 51 fine-grained tasks. To ensure rigorous evaluation, we define instance-specific evaluation criteria for each test case, guiding the assessment of both general response quality and factual consistency with visual inputs. Experimental results reveal that current open-source MLLMs significantly underperform compared to proprietary models in creative tasks. Furthermore, our analysis demonstrates that visual fine-tuning can negatively impact the base LLM's creative abilities. Creation-MMBench provides valuable insights for advancing MLLM creativity and establishes a foundation for future improvements in multimodal generative intelligence. Full data and evaluation code is released on https://github.com/open-compass/Creation-MMBench.","sentences":["Creativity is a fundamental aspect of intelligence, involving the ability to generate novel and appropriate solutions across diverse contexts.","While Large Language Models (LLMs) have been extensively evaluated for their creative capabilities, the assessment of Multimodal Large Language Models (MLLMs) in this domain remains largely unexplored.","To address this gap, we introduce Creation-MMBench, a multimodal benchmark specifically designed to evaluate the creative capabilities of MLLMs in real-world, image-based tasks.","The benchmark comprises 765 test cases spanning 51 fine-grained tasks.","To ensure rigorous evaluation, we define instance-specific evaluation criteria for each test case, guiding the assessment of both general response quality and factual consistency with visual inputs.","Experimental results reveal that current open-source MLLMs significantly underperform compared to proprietary models in creative tasks.","Furthermore, our analysis demonstrates that visual fine-tuning can negatively impact the base LLM's creative abilities.","Creation-MMBench provides valuable insights for advancing MLLM creativity and establishes a foundation for future improvements in multimodal generative intelligence.","Full data and evaluation code is released on https://github.com/open-compass/Creation-MMBench."],"url":"http://arxiv.org/abs/2503.14478v1"}
{"created":"2025-03-18 17:45:32","title":"Attribution Score Alignment in Explainable Data Management","abstract":"Different attribution-scores have been proposed to quantify the relevance of database tuples for a query answer from a database. Among them, we find Causal Responsibility, the Shapley Value, the Banzhaf Power-Index, and the Causal Effect. They have been analyzed in isolation, mainly in terms of computational properties. In this work, we start an investigation into the alignment of these scores on the basis of the queries at hand; that is, on whether they induce compatible rankings of tuples. We are able to identify vast classes of queries for which some pairs of scores are always aligned, and others for which they are not. It turns out that the presence of exogenous tuples makes a crucial difference in this regard.","sentences":["Different attribution-scores have been proposed to quantify the relevance of database tuples for a query answer from a database.","Among them, we find Causal Responsibility, the Shapley Value, the Banzhaf Power-Index, and the Causal Effect.","They have been analyzed in isolation, mainly in terms of computational properties.","In this work, we start an investigation into the alignment of these scores on the basis of the queries at hand; that is, on whether they induce compatible rankings of tuples.","We are able to identify vast classes of queries for which some pairs of scores are always aligned, and others for which they are not.","It turns out that the presence of exogenous tuples makes a crucial difference in this regard."],"url":"http://arxiv.org/abs/2503.14469v1"}
{"created":"2025-03-18 17:44:51","title":"Characterizing Data Visualization Literacy: a Systematic Literature Review","abstract":"With the advent of the data era, and of new, more intelligent interfaces for supporting decision making, there is a growing need to define, model and assess human ability and data visualizations usability for a better encoding and decoding of data patterns. Data Visualization Literacy (DVL) is the ability of encoding and decoding data into and from a visual language. Although this ability and its measurement are crucial for advancing human knowledge and decision capacity, they have seldom been investigated, let alone systematically. To address this gap, this paper presents a systematic literature review comprising 43 reports on DVL, analyzed using the PRISMA methodology. Our results include the identification of the purposes of DVL, its satellite aspects, the models proposed, and the assessments designed to evaluate the degree of DVL of people. Eventually, we devise many research directions including, among the most challenging, the definition of a (standard) unifying construct of DVL.","sentences":["With the advent of the data era, and of new, more intelligent interfaces for supporting decision making, there is a growing need to define, model and assess human ability and data visualizations usability for a better encoding and decoding of data patterns.","Data Visualization Literacy (DVL) is the ability of encoding and decoding data into and from a visual language.","Although this ability and its measurement are crucial for advancing human knowledge and decision capacity, they have seldom been investigated, let alone systematically.","To address this gap, this paper presents a systematic literature review comprising 43 reports on DVL, analyzed using the PRISMA methodology.","Our results include the identification of the purposes of DVL, its satellite aspects, the models proposed, and the assessments designed to evaluate the degree of DVL of people.","Eventually, we devise many research directions including, among the most challenging, the definition of a (standard) unifying construct of DVL."],"url":"http://arxiv.org/abs/2503.14468v1"}
{"created":"2025-03-18 17:16:40","title":"Graph-CNNs for RF Imaging: Learning the Electric Field Integral Equations","abstract":"Radio-Frequency (RF) imaging concerns the digital recreation of the surfaces of scene objects based on the scattered field at distributed receivers. To solve this difficult inverse scattering problems, data-driven methods are often employed that extract patterns from similar training examples, while offering minimal latency. In this paper, we first provide an approximate yet fast electromagnetic model, which is based on the electric field integral equations, for data generation, and subsequently propose a Deep Neural Network (DNN) architecture to learn the corresponding inverse model. A graph-attention backbone allows for the system geometry to be passed to the DNN, where residual convolutional layers extract features about the objects, while a UNet head performs the final image reconstruction. Our quantitative and qualitative evaluations on two synthetic data sets of different characteristics showcase the performance gains of thee proposed advanced architecture and its relative resilience to signal noise levels and various reception configurations.","sentences":["Radio-Frequency (RF) imaging concerns the digital recreation of the surfaces of scene objects based on the scattered field at distributed receivers.","To solve this difficult inverse scattering problems, data-driven methods are often employed that extract patterns from similar training examples, while offering minimal latency.","In this paper, we first provide an approximate yet fast electromagnetic model, which is based on the electric field integral equations, for data generation, and subsequently propose a Deep Neural Network (DNN) architecture to learn the corresponding inverse model.","A graph-attention backbone allows for the system geometry to be passed to the DNN, where residual convolutional layers extract features about the objects, while a UNet head performs the final image reconstruction.","Our quantitative and qualitative evaluations on two synthetic data sets of different characteristics showcase the performance gains of thee proposed advanced architecture and its relative resilience to signal noise levels and various reception configurations."],"url":"http://arxiv.org/abs/2503.14439v1"}
{"created":"2025-03-18 17:11:24","title":"LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as Evolutionary Optimizers","abstract":"Automated feature engineering plays a critical role in improving predictive model performance for tabular learning tasks. Traditional automated feature engineering methods are limited by their reliance on pre-defined transformations within fixed, manually designed search spaces, often neglecting domain knowledge. Recent advances using Large Language Models (LLMs) have enabled the integration of domain knowledge into the feature engineering process. However, existing LLM-based approaches use direct prompting or rely solely on validation scores for feature selection, failing to leverage insights from prior feature discovery experiments or establish meaningful reasoning between feature generation and data-driven performance. To address these challenges, we propose LLM-FE, a novel framework that combines evolutionary search with the domain knowledge and reasoning capabilities of LLMs to automatically discover effective features for tabular learning tasks. LLM-FE formulates feature engineering as a program search problem, where LLMs propose new feature transformation programs iteratively, and data-driven feedback guides the search process. Our results demonstrate that LLM-FE consistently outperforms state-of-the-art baselines, significantly enhancing the performance of tabular prediction models across diverse classification and regression benchmarks.","sentences":["Automated feature engineering plays a critical role in improving predictive model performance for tabular learning tasks.","Traditional automated feature engineering methods are limited by their reliance on pre-defined transformations within fixed, manually designed search spaces, often neglecting domain knowledge.","Recent advances using Large Language Models (LLMs) have enabled the integration of domain knowledge into the feature engineering process.","However, existing LLM-based approaches use direct prompting or rely solely on validation scores for feature selection, failing to leverage insights from prior feature discovery experiments or establish meaningful reasoning between feature generation and data-driven performance.","To address these challenges, we propose LLM-FE, a novel framework that combines evolutionary search with the domain knowledge and reasoning capabilities of LLMs to automatically discover effective features for tabular learning tasks.","LLM-FE formulates feature engineering as a program search problem, where LLMs propose new feature transformation programs iteratively, and data-driven feedback guides the search process.","Our results demonstrate that LLM-FE consistently outperforms state-of-the-art baselines, significantly enhancing the performance of tabular prediction models across diverse classification and regression benchmarks."],"url":"http://arxiv.org/abs/2503.14434v1"}
{"created":"2025-03-18 17:09:57","title":"PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play","abstract":"Large language models (LLMs) are increasingly integrated with specialized external tools, yet many tasks demand zero-shot tool usage with minimal or noisy documentation. Existing solutions rely on manual rewriting or labeled data for validation, making them inapplicable in true zero-shot settings. To address these challenges, we propose PLAY2PROMPT, an automated framework that systematically \"plays\" with each tool to explore its input-output behaviors. Through this iterative trial-and-error process, PLAY2PROMPT refines tool documentation and generates usage examples without any labeled data. These examples not only guide LLM inference but also serve as validation to further enhance tool utilization. Extensive experiments on real-world tasks demonstrate that PLAY2PROMPT significantly improves zero-shot tool performance across both open and closed models, offering a scalable and effective solution for domain-specific tool integration.","sentences":["Large language models (LLMs) are increasingly integrated with specialized external tools, yet many tasks demand zero-shot tool usage with minimal or noisy documentation.","Existing solutions rely on manual rewriting or labeled data for validation, making them inapplicable in true zero-shot settings.","To address these challenges, we propose PLAY2PROMPT, an automated framework that systematically \"plays\" with each tool to explore its input-output behaviors.","Through this iterative trial-and-error process, PLAY2PROMPT refines tool documentation and generates usage examples without any labeled data.","These examples not only guide LLM inference but also serve as validation to further enhance tool utilization.","Extensive experiments on real-world tasks demonstrate that PLAY2PROMPT significantly improves zero-shot tool performance across both open and closed models, offering a scalable and effective solution for domain-specific tool integration."],"url":"http://arxiv.org/abs/2503.14432v1"}
{"created":"2025-03-18 16:49:56","title":"Large Language Models for Virtual Human Gesture Selection","abstract":"Co-speech gestures convey a wide variety of meanings and play an important role in face-to-face human interactions. These gestures significantly influence the addressee's engagement, recall, comprehension, and attitudes toward the speaker. Similarly, they impact interactions between humans and embodied virtual agents. The process of selecting and animating meaningful gestures has thus become a key focus in the design of these agents. However, automating this gesture selection process poses a significant challenge. Prior gesture generation techniques have varied from fully automated, data-driven methods, which often struggle to produce contextually meaningful gestures, to more manual approaches that require crafting specific gesture expertise and are time-consuming and lack generalizability. In this paper, we leverage the semantic capabilities of Large Language Models to develop a gesture selection approach that suggests meaningful, appropriate co-speech gestures. We first describe how information on gestures is encoded into GPT-4. Then, we conduct a study to evaluate alternative prompting approaches for their ability to select meaningful, contextually relevant gestures and to align them appropriately with the co-speech utterance. Finally, we detail and demonstrate how this approach has been implemented within a virtual agent system, automating the selection and subsequent animation of the selected gestures for enhanced human-agent interactions.","sentences":["Co-speech gestures convey a wide variety of meanings and play an important role in face-to-face human interactions.","These gestures significantly influence the addressee's engagement, recall, comprehension, and attitudes toward the speaker.","Similarly, they impact interactions between humans and embodied virtual agents.","The process of selecting and animating meaningful gestures has thus become a key focus in the design of these agents.","However, automating this gesture selection process poses a significant challenge.","Prior gesture generation techniques have varied from fully automated, data-driven methods, which often struggle to produce contextually meaningful gestures, to more manual approaches that require crafting specific gesture expertise and are time-consuming and lack generalizability.","In this paper, we leverage the semantic capabilities of Large Language Models to develop a gesture selection approach that suggests meaningful, appropriate co-speech gestures.","We first describe how information on gestures is encoded into GPT-4.","Then, we conduct a study to evaluate alternative prompting approaches for their ability to select meaningful, contextually relevant gestures and to align them appropriately with the co-speech utterance.","Finally, we detail and demonstrate how this approach has been implemented within a virtual agent system, automating the selection and subsequent animation of the selected gestures for enhanced human-agent interactions."],"url":"http://arxiv.org/abs/2503.14408v1"}
{"created":"2025-03-18 16:47:27","title":"DUNE: Distilling a Universal Encoder from Heterogeneous 2D and 3D Teachers","abstract":"Recent multi-teacher distillation methods have unified the encoders of multiple foundation models into a single encoder, achieving competitive performance on core vision tasks like classification, segmentation, and depth estimation. This led us to ask: Could similar success be achieved when the pool of teachers also includes vision models specialized in diverse tasks across both 2D and 3D perception? In this paper, we define and investigate the problem of heterogeneous teacher distillation, or co-distillation, a challenging multi-teacher distillation scenario where teacher models vary significantly in both (a) their design objectives and (b) the data they were trained on. We explore data-sharing strategies and teacher-specific encoding, and introduce DUNE, a single encoder excelling in 2D vision, 3D understanding, and 3D human perception. Our model achieves performance comparable to that of its larger teachers, sometimes even outperforming them, on their respective tasks. Notably, DUNE surpasses MASt3R in Map-free Visual Relocalization with a much smaller encoder.","sentences":["Recent multi-teacher distillation methods have unified the encoders of multiple foundation models into a single encoder, achieving competitive performance on core vision tasks like classification, segmentation, and depth estimation.","This led us to ask: Could similar success be achieved when the pool of teachers also includes vision models specialized in diverse tasks across both 2D and 3D perception?","In this paper, we define and investigate the problem of heterogeneous teacher distillation, or co-distillation, a challenging multi-teacher distillation scenario where teacher models vary significantly in both (a) their design objectives and (b) the data they were trained on.","We explore data-sharing strategies and teacher-specific encoding, and introduce DUNE, a single encoder excelling in 2D vision, 3D understanding, and 3D human perception.","Our model achieves performance comparable to that of its larger teachers, sometimes even outperforming them, on their respective tasks.","Notably, DUNE surpasses MASt3R in Map-free Visual Relocalization with a much smaller encoder."],"url":"http://arxiv.org/abs/2503.14405v1"}
{"created":"2025-03-18 16:44:33","title":"Landscape Complexity for the Empirical Risk of Generalized Linear Models: Discrimination between Structured Data","abstract":"We use the Kac-Rice formula and results from random matrix theory to obtain the average number of critical points of a family of high-dimensional empirical loss functions, where the data are correlated $d$-dimensional Gaussian vectors, whose number has a fixed ratio with their dimension. The correlations are introduced to model the existence of structure in the data, as is common in current Machine-Learning systems. Under a technical hypothesis, our results are exact in the large-$d$ limit, and characterize the annealed landscape complexity, namely the logarithm of the expected number of critical points at a given value of the loss.   We first address in detail the landscape of the loss function of a single perceptron and then generalize it to the case where two competing data sets with different covariance matrices are present, with the perceptron seeking to discriminate between them. The latter model can be applied to understand the interplay between adversity and non-trivial data structure. For completeness, we also treat the case of a loss function used in training Generalized Linear Models in the presence of correlated input data.","sentences":["We use the Kac-Rice formula and results from random matrix theory to obtain the average number of critical points of a family of high-dimensional empirical loss functions, where the data are correlated $d$-dimensional Gaussian vectors, whose number has a fixed ratio with their dimension.","The correlations are introduced to model the existence of structure in the data, as is common in current Machine-Learning systems.","Under a technical hypothesis, our results are exact in the large-$d$ limit, and characterize the annealed landscape complexity, namely the logarithm of the expected number of critical points at a given value of the loss.   ","We first address in detail the landscape of the loss function of a single perceptron and then generalize it to the case where two competing data sets with different covariance matrices are present, with the perceptron seeking to discriminate between them.","The latter model can be applied to understand the interplay between adversity and non-trivial data structure.","For completeness, we also treat the case of a loss function used in training Generalized Linear Models in the presence of correlated input data."],"url":"http://arxiv.org/abs/2503.14403v1"}
{"created":"2025-03-18 16:36:59","title":"Technical Report: Aggregation on Learnable Manifolds for Asynchronous Federated Optimization","abstract":"In Federated Learning (FL), a primary challenge to the server-side aggregation of client models is device heterogeneity, in both loss landscape geometry and computational capacity. This issue can be particularly pronounced in clinical contexts where variations in data distribution (aggravated by class imbalance), infrastructure requirements, and sample sizes are common. We propose AsyncManifold, a novel asynchronous FL framework to address these issues by taking advantage of underlying solution space geometry, at each of the local training, delay-correction, and aggregation stages. Our proposal is accompanied by a convergence proof in a general form and, motivated thorough exploratory studies of local behaviour, a proof-of-concept algorithm which performs aggregation along non-linear mode connections and hence avoids barriers to convergence that techniques based on linear interpolation will encounter.","sentences":["In Federated Learning (FL), a primary challenge to the server-side aggregation of client models is device heterogeneity, in both loss landscape geometry and computational capacity.","This issue can be particularly pronounced in clinical contexts where variations in data distribution (aggravated by class imbalance), infrastructure requirements, and sample sizes are common.","We propose AsyncManifold, a novel asynchronous FL framework to address these issues by taking advantage of underlying solution space geometry, at each of the local training, delay-correction, and aggregation stages.","Our proposal is accompanied by a convergence proof in a general form and, motivated thorough exploratory studies of local behaviour, a proof-of-concept algorithm which performs aggregation along non-linear mode connections and hence avoids barriers to convergence that techniques based on linear interpolation will encounter."],"url":"http://arxiv.org/abs/2503.14396v1"}
{"created":"2025-03-18 16:28:14","title":"On the clustering behavior of sliding windows","abstract":"Things can go spectacularly wrong when clustering timeseries data that has been preprocessed with a sliding window. We highlight three surprising failures that emerge depending on how the window size compares with the timeseries length. In addition to computational examples, we present theoretical explanations for each of these failure modes.","sentences":["Things can go spectacularly wrong when clustering timeseries data that has been preprocessed with a sliding window.","We highlight three surprising failures that emerge depending on how the window size compares with the timeseries length.","In addition to computational examples, we present theoretical explanations for each of these failure modes."],"url":"http://arxiv.org/abs/2503.14393v1"}
{"created":"2025-03-18 16:23:16","title":"Manual, Semi or Fully Autonomous Flipper Control? A Framework for Fair Comparison","abstract":"We investigated the performance of existing semi- and fully autonomous methods for controlling flipper-based skid-steer robots. Our study involves reimplementation of these methods for fair comparison and it introduces a novel semi-autonomous control policy that provides a compelling trade-off among current state-of-the-art approaches. We also propose new metrics for assessing cognitive load and traversal quality and offer a benchmarking interface for generating Quality-Load graphs from recorded data. Our results, presented in a 2D Quality-Load space, demonstrate that the new control policy effectively bridges the gap between autonomous and manual control methods. Additionally, we reveal a surprising fact that fully manual, continuous control of all six degrees of freedom remains highly effective when performed by an experienced operator on a well-designed analog controller from third person view.","sentences":["We investigated the performance of existing semi- and fully autonomous methods for controlling flipper-based skid-steer robots.","Our study involves reimplementation of these methods for fair comparison and it introduces a novel semi-autonomous control policy that provides a compelling trade-off among current state-of-the-art approaches.","We also propose new metrics for assessing cognitive load and traversal quality and offer a benchmarking interface for generating Quality-Load graphs from recorded data.","Our results, presented in a 2D Quality-Load space, demonstrate that the new control policy effectively bridges the gap between autonomous and manual control methods.","Additionally, we reveal a surprising fact that fully manual, continuous control of all six degrees of freedom remains highly effective when performed by an experienced operator on a well-designed analog controller from third person view."],"url":"http://arxiv.org/abs/2503.14389v1"}
{"created":"2025-03-18 16:10:24","title":"Impossible Videos","abstract":"Synthetic videos nowadays is widely used to complement data scarcity and diversity of real-world videos. Current synthetic datasets primarily replicate real-world scenarios, leaving impossible, counterfactual and anti-reality video concepts underexplored. This work aims to answer two questions: 1) Can today's video generation models effectively follow prompts to create impossible video content? 2) Are today's video understanding models good enough for understanding impossible videos? To this end, we introduce IPV-Bench, a novel benchmark designed to evaluate and foster progress in video understanding and generation. IPV-Bench is underpinned by a comprehensive taxonomy, encompassing 4 domains, 14 categories. It features diverse scenes that defy physical, biological, geographical, or social laws. Based on the taxonomy, a prompt suite is constructed to evaluate video generation models, challenging their prompt following and creativity capabilities. In addition, a video benchmark is curated to assess Video-LLMs on their ability of understanding impossible videos, which particularly requires reasoning on temporal dynamics and world knowledge. Comprehensive evaluations reveal limitations and insights for future directions of video models, paving the way for next-generation video models.","sentences":["Synthetic videos nowadays is widely used to complement data scarcity and diversity of real-world videos.","Current synthetic datasets primarily replicate real-world scenarios, leaving impossible, counterfactual and anti-reality video concepts underexplored.","This work aims to answer two questions: 1) Can today's video generation models effectively follow prompts to create impossible video content?","2) Are today's video understanding models good enough for understanding impossible videos?","To this end, we introduce IPV-Bench, a novel benchmark designed to evaluate and foster progress in video understanding and generation.","IPV-Bench is underpinned by a comprehensive taxonomy, encompassing 4 domains, 14 categories.","It features diverse scenes that defy physical, biological, geographical, or social laws.","Based on the taxonomy, a prompt suite is constructed to evaluate video generation models, challenging their prompt following and creativity capabilities.","In addition, a video benchmark is curated to assess Video-LLMs on their ability of understanding impossible videos, which particularly requires reasoning on temporal dynamics and world knowledge.","Comprehensive evaluations reveal limitations and insights for future directions of video models, paving the way for next-generation video models."],"url":"http://arxiv.org/abs/2503.14378v1"}
{"created":"2025-03-18 16:07:29","title":"Evaluating Machine Learning Approaches for ASCII Art Generation","abstract":"Generating structured ASCII art using computational techniques demands a careful interplay between aesthetic representation and computational precision, requiring models that can effectively translate visual information into symbolic text characters. Although Convolutional Neural Networks (CNNs) have shown promise in this domain, the comparative performance of deep learning architectures and classical machine learning methods remains unexplored. This paper explores the application of contemporary ML and DL methods to generate structured ASCII art, focusing on three key criteria: fidelity, character classification accuracy, and output quality. We investigate deep learning architectures, including Multilayer Perceptrons (MLPs), ResNet, and MobileNetV2, alongside classical approaches such as Random Forests, Support Vector Machines (SVMs) and k-Nearest Neighbors (k-NN), trained on an augmented synthetic dataset of ASCII characters. Our results show that complex neural network architectures often fall short in producing high-quality ASCII art, whereas classical machine learning classifiers, despite their simplicity, achieve performance similar to CNNs. Our findings highlight the strength of classical methods in bridging model simplicity with output quality, offering new insights into ASCII art synthesis and machine learning on image data with low dimensionality.","sentences":["Generating structured ASCII art using computational techniques demands a careful interplay between aesthetic representation and computational precision, requiring models that can effectively translate visual information into symbolic text characters.","Although Convolutional Neural Networks (CNNs) have shown promise in this domain, the comparative performance of deep learning architectures and classical machine learning methods remains unexplored.","This paper explores the application of contemporary ML and DL methods to generate structured ASCII art, focusing on three key criteria: fidelity, character classification accuracy, and output quality.","We investigate deep learning architectures, including Multilayer Perceptrons (MLPs), ResNet, and MobileNetV2, alongside classical approaches such as Random Forests, Support Vector Machines (SVMs) and k-Nearest Neighbors (k-NN), trained on an augmented synthetic dataset of ASCII characters.","Our results show that complex neural network architectures often fall short in producing high-quality ASCII art, whereas classical machine learning classifiers, despite their simplicity, achieve performance similar to CNNs.","Our findings highlight the strength of classical methods in bridging model simplicity with output quality, offering new insights into ASCII art synthesis and machine learning on image data with low dimensionality."],"url":"http://arxiv.org/abs/2503.14375v1"}
{"created":"2025-03-18 15:45:00","title":"Streaming and Massively Parallel Algorithms for Euclidean Max-Cut","abstract":"Given a set of vectors $X = \\{ x_1,\\dots, x_n \\} \\subset \\mathbb{R}^d$, the Euclidean max-cut problem asks to partition the vectors into two parts so as to maximize the sum of Euclidean distances which cross the partition. We design new algorithms for Euclidean max-cut in models for massive datasets:   $\\bullet$ We give a fully-scalable constant-round MPC algorithm using $O(nd) + n \\cdot \\text{poly}( \\log(n) / \\epsilon)$ total space which gives a $(1+\\epsilon)$-approximate Euclidean max-cut.   $\\bullet$ We give a dynamic streaming algorithm using $\\text{poly}(d \\log \\Delta / \\epsilon)$ space when $X \\subseteq [\\Delta]^d$, which provides oracle access to a $(1+\\epsilon)$-approximate Euclidean max-cut.   Recently, Chen, Jiang, and Krauthgamer $[\\text{STOC}~'23]$ gave a dynamic streaming algorithm with space $\\text{poly}(d\\log\\Delta/\\epsilon)$ to approximate the value of the Euclidean max-cut, but could not provide oracle access to an approximately optimal cut. This was left open in that work, and we resolve it here. Both algorithms follow from the same framework, which analyzes a ``parallel'' and ``subsampled'' (Euclidean) version of a greedy algorithm of Mathieu and Schudy $[\\text{SODA}~'08]$ for dense max-cut.","sentences":["Given a set of vectors $X = \\{ x_1,\\dots, x_n \\} \\subset \\mathbb{R}^d$, the Euclidean max-cut problem asks to partition the vectors into two parts so as to maximize the sum of Euclidean distances which cross the partition.","We design new algorithms for Euclidean max-cut in models for massive datasets:   $\\bullet$ We give a fully-scalable constant-round MPC algorithm using $O(nd) + n \\cdot \\text{poly}( \\log(n) / \\epsilon)$ total space which gives a $(1+\\epsilon)$-approximate Euclidean max-cut.   ","$\\bullet$ We give a dynamic streaming algorithm using $\\text{poly}(d \\log \\Delta / \\epsilon)$ space when $X \\subseteq [\\Delta]^d$, which provides oracle access to a $(1+\\epsilon)$-approximate Euclidean max-cut.   ","Recently, Chen, Jiang, and Krauthgamer $[\\text{STOC}~'23]$ gave a dynamic streaming algorithm with space $\\text{poly}(d\\log\\Delta/\\epsilon)$ to approximate the value of the Euclidean max-cut, but could not provide oracle access to an approximately optimal cut.","This was left open in that work, and we resolve it here.","Both algorithms follow from the same framework, which analyzes a ``parallel'' and ``subsampled'' (Euclidean) version of a greedy algorithm of Mathieu and Schudy $[\\text{SODA}~'08]$ for dense max-cut."],"url":"http://arxiv.org/abs/2503.14362v1"}
{"created":"2025-03-18 15:42:22","title":"ImViD: Immersive Volumetric Videos for Enhanced VR Engagement","abstract":"User engagement is greatly enhanced by fully immersive multi-modal experiences that combine visual and auditory stimuli. Consequently, the next frontier in VR/AR technologies lies in immersive volumetric videos with complete scene capture, large 6-DoF interaction space, multi-modal feedback, and high resolution & frame-rate contents. To stimulate the reconstruction of immersive volumetric videos, we introduce ImViD, a multi-view, multi-modal dataset featuring complete space-oriented data capture and various indoor/outdoor scenarios. Our capture rig supports multi-view video-audio capture while on the move, a capability absent in existing datasets, significantly enhancing the completeness, flexibility, and efficiency of data capture.   The captured multi-view videos (with synchronized audios) are in 5K resolution at 60FPS, lasting from 1-5 minutes, and include rich foreground-background elements, and complex dynamics. We benchmark existing methods using our dataset and establish a base pipeline for constructing immersive volumetric videos from multi-view audiovisual inputs for 6-DoF multi-modal immersive VR experiences. The benchmark and the reconstruction and interaction results demonstrate the effectiveness of our dataset and baseline method, which we believe will stimulate future research on immersive volumetric video production.","sentences":["User engagement is greatly enhanced by fully immersive multi-modal experiences that combine visual and auditory stimuli.","Consequently, the next frontier in VR/AR technologies lies in immersive volumetric videos with complete scene capture, large 6-DoF interaction space, multi-modal feedback, and high resolution & frame-rate contents.","To stimulate the reconstruction of immersive volumetric videos, we introduce ImViD, a multi-view, multi-modal dataset featuring complete space-oriented data capture and various indoor/outdoor scenarios.","Our capture rig supports multi-view video-audio capture while on the move, a capability absent in existing datasets, significantly enhancing the completeness, flexibility, and efficiency of data capture.   ","The captured multi-view videos (with synchronized audios) are in 5K resolution at 60FPS, lasting from 1-5 minutes, and include rich foreground-background elements, and complex dynamics.","We benchmark existing methods using our dataset and establish a base pipeline for constructing immersive volumetric videos from multi-view audiovisual inputs for 6-DoF multi-modal immersive VR experiences.","The benchmark and the reconstruction and interaction results demonstrate the effectiveness of our dataset and baseline method, which we believe will stimulate future research on immersive volumetric video production."],"url":"http://arxiv.org/abs/2503.14359v1"}
{"created":"2025-03-18 15:40:55","title":"Wasserstein-based Kernels for Clustering: Application to Power Distribution Graphs","abstract":"Many data clustering applications must handle objects that cannot be represented as vector data. In this context, the bag-of-vectors representation can be leveraged to describe complex objects through discrete distributions, and the Wasserstein distance can effectively measure the dissimilarity between them. Additionally, kernel methods can be used to embed data into feature spaces that are easier to analyze. Despite significant progress in data clustering, a method that simultaneously accounts for distributional and vectorial dissimilarity measures is still lacking. To tackle this gap, this work explores kernel methods and Wasserstein distance metrics to develop a computationally tractable clustering framework. The compositional properties of kernels allow the simultaneous handling of different metrics, enabling the integration of both vectors and discrete distributions for object representation. This approach is flexible enough to be applied in various domains, such as graph analysis and image processing. The framework consists of three main components. First, we efficiently approximate pairwise Wasserstein distances using multiple reference distributions. Second, we employ kernel functions based on Wasserstein distances and present ways of composing kernels to express different types of information. Finally, we use the kernels to cluster data and evaluate the quality of the results using scalable and distance-agnostic validity indices. A case study involving two datasets of 879 and 34,920 power distribution graphs demonstrates the framework's effectiveness and efficiency.","sentences":["Many data clustering applications must handle objects that cannot be represented as vector data.","In this context, the bag-of-vectors representation can be leveraged to describe complex objects through discrete distributions, and the Wasserstein distance can effectively measure the dissimilarity between them.","Additionally, kernel methods can be used to embed data into feature spaces that are easier to analyze.","Despite significant progress in data clustering, a method that simultaneously accounts for distributional and vectorial dissimilarity measures is still lacking.","To tackle this gap, this work explores kernel methods and Wasserstein distance metrics to develop a computationally tractable clustering framework.","The compositional properties of kernels allow the simultaneous handling of different metrics, enabling the integration of both vectors and discrete distributions for object representation.","This approach is flexible enough to be applied in various domains, such as graph analysis and image processing.","The framework consists of three main components.","First, we efficiently approximate pairwise Wasserstein distances using multiple reference distributions.","Second, we employ kernel functions based on Wasserstein distances and present ways of composing kernels to express different types of information.","Finally, we use the kernels to cluster data and evaluate the quality of the results using scalable and distance-agnostic validity indices.","A case study involving two datasets of 879 and 34,920 power distribution graphs demonstrates the framework's effectiveness and efficiency."],"url":"http://arxiv.org/abs/2503.14357v1"}
{"created":"2025-03-18 15:40:18","title":"Benchmarking community drug response prediction models: datasets, models, tools, and metrics for cross-dataset generalization analysis","abstract":"Deep learning (DL) and machine learning (ML) models have shown promise in drug response prediction (DRP), yet their ability to generalize across datasets remains an open question, raising concerns about their real-world applicability. Due to the lack of standardized benchmarking approaches, model evaluations and comparisons often rely on inconsistent datasets and evaluation criteria, making it difficult to assess true predictive capabilities. In this work, we introduce a benchmarking framework for evaluating cross-dataset prediction generalization in DRP models. Our framework incorporates five publicly available drug screening datasets, six standardized DRP models, and a scalable workflow for systematic evaluation. To assess model generalization, we introduce a set of evaluation metrics that quantify both absolute performance (e.g., predictive accuracy across datasets) and relative performance (e.g., performance drop compared to within-dataset results), enabling a more comprehensive assessment of model transferability. Our results reveal substantial performance drops when models are tested on unseen datasets, underscoring the importance of rigorous generalization assessments. While several models demonstrate relatively strong cross-dataset generalization, no single model consistently outperforms across all datasets. Furthermore, we identify CTRPv2 as the most effective source dataset for training, yielding higher generalization scores across target datasets. By sharing this standardized evaluation framework with the community, our study aims to establish a rigorous foundation for model comparison, and accelerate the development of robust DRP models for real-world applications.","sentences":["Deep learning (DL) and machine learning (ML) models have shown promise in drug response prediction (DRP), yet their ability to generalize across datasets remains an open question, raising concerns about their real-world applicability.","Due to the lack of standardized benchmarking approaches, model evaluations and comparisons often rely on inconsistent datasets and evaluation criteria, making it difficult to assess true predictive capabilities.","In this work, we introduce a benchmarking framework for evaluating cross-dataset prediction generalization in DRP models.","Our framework incorporates five publicly available drug screening datasets, six standardized DRP models, and a scalable workflow for systematic evaluation.","To assess model generalization, we introduce a set of evaluation metrics that quantify both absolute performance (e.g., predictive accuracy across datasets) and relative performance (e.g., performance drop compared to within-dataset results), enabling a more comprehensive assessment of model transferability.","Our results reveal substantial performance drops when models are tested on unseen datasets, underscoring the importance of rigorous generalization assessments.","While several models demonstrate relatively strong cross-dataset generalization, no single model consistently outperforms across all datasets.","Furthermore, we identify CTRPv2 as the most effective source dataset for training, yielding higher generalization scores across target datasets.","By sharing this standardized evaluation framework with the community, our study aims to establish a rigorous foundation for model comparison, and accelerate the development of robust DRP models for real-world applications."],"url":"http://arxiv.org/abs/2503.14356v1"}
{"created":"2025-03-18 15:32:07","title":"Flying in Highly Dynamic Environments with End-to-end Learning Approach","abstract":"Obstacle avoidance for unmanned aerial vehicles like quadrotors is a popular research topic. Most existing research focuses only on static environments, and obstacle avoidance in environments with multiple dynamic obstacles remains challenging. This paper proposes a novel deep-reinforcement learning-based approach for the quadrotors to navigate through highly dynamic environments. We propose a lidar data encoder to extract obstacle information from the massive point cloud data from the lidar. Multi frames of historical scans will be compressed into a 2-dimension obstacle map while maintaining the obstacle features required. An end-to-end deep neural network is trained to extract the kinematics of dynamic and static obstacles from the obstacle map, and it will generate acceleration commands to the quadrotor to control it to avoid these obstacles. Our approach contains perception and navigating functions in a single neural network, which can change from a navigating state into a hovering state without mode switching. We also present simulations and real-world experiments to show the effectiveness of our approach while navigating in highly dynamic cluttered environments.","sentences":["Obstacle avoidance for unmanned aerial vehicles like quadrotors is a popular research topic.","Most existing research focuses only on static environments, and obstacle avoidance in environments with multiple dynamic obstacles remains challenging.","This paper proposes a novel deep-reinforcement learning-based approach for the quadrotors to navigate through highly dynamic environments.","We propose a lidar data encoder to extract obstacle information from the massive point cloud data from the lidar.","Multi frames of historical scans will be compressed into a 2-dimension obstacle map while maintaining the obstacle features required.","An end-to-end deep neural network is trained to extract the kinematics of dynamic and static obstacles from the obstacle map, and it will generate acceleration commands to the quadrotor to control it to avoid these obstacles.","Our approach contains perception and navigating functions in a single neural network, which can change from a navigating state into a hovering state without mode switching.","We also present simulations and real-world experiments to show the effectiveness of our approach while navigating in highly dynamic cluttered environments."],"url":"http://arxiv.org/abs/2503.14352v1"}
{"created":"2025-03-18 15:31:12","title":"VEGGIE: Instructional Editing and Reasoning Video Concepts with Grounded Generation","abstract":"Recent video diffusion models have enhanced video editing, but it remains challenging to handle instructional editing and diverse tasks (e.g., adding, removing, changing) within a unified framework. In this paper, we introduce VEGGIE, a Video Editor with Grounded Generation from Instructions, a simple end-to-end framework that unifies video concept editing, grounding, and reasoning based on diverse user instructions. Specifically, given a video and text query, VEGGIE first utilizes an MLLM to interpret user intentions in instructions and ground them to the video contexts, generating frame-specific grounded task queries for pixel-space responses. A diffusion model then renders these plans and generates edited videos that align with user intent. To support diverse tasks and complex instructions, we employ a curriculum learning strategy: first aligning the MLLM and video diffusion model with large-scale instructional image editing data, followed by end-to-end fine-tuning on high-quality multitask video data. Additionally, we introduce a novel data synthesis pipeline to generate paired instructional video editing data for model training. It transforms static image data into diverse, high-quality video editing samples by leveraging Image-to-Video models to inject dynamics. VEGGIE shows strong performance in instructional video editing with different editing skills, outperforming the best instructional baseline as a versatile model, while other models struggle with multi-tasking. VEGGIE also excels in video object grounding and reasoning segmentation, where other baselines fail. We further reveal how the multiple tasks help each other and highlight promising applications like zero-shot multimodal instructional and in-context video editing.","sentences":["Recent video diffusion models have enhanced video editing, but it remains challenging to handle instructional editing and diverse tasks (e.g., adding, removing, changing) within a unified framework.","In this paper, we introduce VEGGIE, a Video Editor with Grounded Generation from Instructions, a simple end-to-end framework that unifies video concept editing, grounding, and reasoning based on diverse user instructions.","Specifically, given a video and text query, VEGGIE first utilizes an MLLM to interpret user intentions in instructions and ground them to the video contexts, generating frame-specific grounded task queries for pixel-space responses.","A diffusion model then renders these plans and generates edited videos that align with user intent.","To support diverse tasks and complex instructions, we employ a curriculum learning strategy: first aligning the MLLM and video diffusion model with large-scale instructional image editing data, followed by end-to-end fine-tuning on high-quality multitask video data.","Additionally, we introduce a novel data synthesis pipeline to generate paired instructional video editing data for model training.","It transforms static image data into diverse, high-quality video editing samples by leveraging Image-to-Video models to inject dynamics.","VEGGIE shows strong performance in instructional video editing with different editing skills, outperforming the best instructional baseline as a versatile model, while other models struggle with multi-tasking.","VEGGIE also excels in video object grounding and reasoning segmentation, where other baselines fail.","We further reveal how the multiple tasks help each other and highlight promising applications like zero-shot multimodal instructional and in-context video editing."],"url":"http://arxiv.org/abs/2503.14350v1"}
{"created":"2025-03-18 15:21:27","title":"Spatio-Temporal Graph Neural Networks for Infant Language Acquisition Prediction","abstract":"Predicting the words that a child is going to learn next can be useful for boosting language acquisition, and such predictions have been shown to be possible with both neural network techniques (looking at changes in the vocabulary state over time) and graph model (looking at data pertaining to the relationships between words). However, these models do not fully capture the complexity of the language learning process of an infant when used in isolation. In this paper, we examine how a model of language acquisition for infants and young children can be constructed and adapted for use in a Spatio-Temporal Graph Convolutional Network (STGCN), taking into account the different types of linguistic relationships that occur during child language learning. We introduce a novel approach for predicting child vocabulary acquisition, and evaluate the efficacy of such a model with respect to the different types of linguistic relationships that occur during language acquisition, resulting in insightful observations on model calibration and norm selection. An evaluation of this model found that the mean accuracy of models for predicting new words when using sensorimotor relationships (0.733) and semantic relationships (0.729) were found to be superior to that observed with a 2-layer Feed-forward neural network. Furthermore, the high recall for some relationships suggested that some relationships (e.g. visual) were superior in identifying a larger proportion of relevant words that a child should subsequently learn than others (such as auditory).","sentences":["Predicting the words that a child is going to learn next can be useful for boosting language acquisition, and such predictions have been shown to be possible with both neural network techniques (looking at changes in the vocabulary state over time) and graph model (looking at data pertaining to the relationships between words).","However, these models do not fully capture the complexity of the language learning process of an infant when used in isolation.","In this paper, we examine how a model of language acquisition for infants and young children can be constructed and adapted for use in a Spatio-Temporal Graph Convolutional Network (STGCN), taking into account the different types of linguistic relationships that occur during child language learning.","We introduce a novel approach for predicting child vocabulary acquisition, and evaluate the efficacy of such a model with respect to the different types of linguistic relationships that occur during language acquisition, resulting in insightful observations on model calibration and norm selection.","An evaluation of this model found that the mean accuracy of models for predicting new words when using sensorimotor relationships (0.733) and semantic relationships (0.729) were found to be superior to that observed with a 2-layer Feed-forward neural network.","Furthermore, the high recall for some relationships suggested that some relationships (e.g. visual) were superior in identifying a larger proportion of relevant words that a child should subsequently learn than others (such as auditory)."],"url":"http://arxiv.org/abs/2503.14341v1"}
{"created":"2025-03-18 15:08:19","title":"Revealing higher-order neural representations with generative artificial intelligence","abstract":"Studies often aim to reveal how neural representations encode aspects of an observer's environment, such as its contents or structure. These are ``first-order\" representations (FORs), because they're ``about\" the external world. A less-common target is ``higher-order\" representations (HORs), which are ``about\" FORs -- their contents, stability, or uncertainty. HORs of uncertainty appear critically involved in adaptive behaviors including learning under uncertainty, influencing learning rates and internal model updating based on environmental feedback. However, HORs about uncertainty are unlikely to be direct ``read-outs\" of FOR characteristics, instead reflecting estimation processes which may be lossy, bias-prone, or distortive and which may also incorporate estimates of distributions of uncertainty the observer is likely to experience. While some research has targeted neural representations of ``instantaneously\" estimated uncertainty, how the brain represents \\textit{distributions} of expected uncertainty remains largely unexplored. Here, we propose a novel reinforcement learning (RL) based generative artificial intelligence (genAI) approach to explore neural representations of uncertainty distributions. We use existing functional magnetic resonance imaging data, where humans learned to `de-noise' their brain states to achieve target neural patterns, to train denoising diffusion genAI models with RL algorithms to learn noise distributions similar to how humans might learn to do the same. We then explore these models' learned noise-distribution HORs compared to control models trained with traditional backpropagation. Results reveal model-dependent differences in noise distribution representations -- with the RL-based model offering much higher explanatory power for human behavior -- offering an exciting path towards using genAI to explore neural noise-distribution HORs.","sentences":["Studies often aim to reveal how neural representations encode aspects of an observer's environment, such as its contents or structure.","These are ``first-order\" representations (FORs), because they're ``about\" the external world.","A less-common target is ``higher-order\" representations (HORs), which are ``about\" FORs -- their contents, stability, or uncertainty.","HORs of uncertainty appear critically involved in adaptive behaviors including learning under uncertainty, influencing learning rates and internal model updating based on environmental feedback.","However, HORs about uncertainty are unlikely to be direct ``read-outs\" of FOR characteristics, instead reflecting estimation processes which may be lossy, bias-prone, or distortive and which may also incorporate estimates of distributions of uncertainty the observer is likely to experience.","While some research has targeted neural representations of ``instantaneously\" estimated uncertainty, how the brain represents \\textit{distributions} of expected uncertainty remains largely unexplored.","Here, we propose a novel reinforcement learning (RL) based generative artificial intelligence (genAI) approach to explore neural representations of uncertainty distributions.","We use existing functional magnetic resonance imaging data, where humans learned to `de-noise' their brain states to achieve target neural patterns, to train denoising diffusion genAI models with RL algorithms to learn noise distributions similar to how humans might learn to do the same.","We then explore these models' learned noise-distribution HORs compared to control models trained with traditional backpropagation.","Results reveal model-dependent differences in noise distribution representations -- with the RL-based model offering much higher explanatory power for human behavior -- offering an exciting path towards using genAI to explore neural noise-distribution HORs."],"url":"http://arxiv.org/abs/2503.14333v1"}
{"created":"2025-03-18 15:01:47","title":"EvolvingGrasp: Evolutionary Grasp Generation via Efficient Preference Alignment","abstract":"Dexterous robotic hands often struggle to generalize effectively in complex environments due to the limitations of models trained on low-diversity data. However, the real world presents an inherently unbounded range of scenarios, making it impractical to account for every possible variation. A natural solution is to enable robots learning from experience in complex environments, an approach akin to evolution, where systems improve through continuous feedback, learning from both failures and successes, and iterating toward optimal performance. Motivated by this, we propose EvolvingGrasp, an evolutionary grasp generation method that continuously enhances grasping performance through efficient preference alignment. Specifically, we introduce Handpose wise Preference Optimization (HPO), which allows the model to continuously align with preferences from both positive and negative feedback while progressively refining its grasping strategies. To further enhance efficiency and reliability during online adjustments, we incorporate a Physics-aware Consistency Model within HPO, which accelerates inference, reduces the number of timesteps needed for preference finetuning, and ensures physical plausibility throughout the process. Extensive experiments across four benchmark datasets demonstrate state of the art performance of our method in grasp success rate and sampling efficiency. Our results validate that EvolvingGrasp enables evolutionary grasp generation, ensuring robust, physically feasible, and preference-aligned grasping in both simulation and real scenarios.","sentences":["Dexterous robotic hands often struggle to generalize effectively in complex environments due to the limitations of models trained on low-diversity data.","However, the real world presents an inherently unbounded range of scenarios, making it impractical to account for every possible variation.","A natural solution is to enable robots learning from experience in complex environments, an approach akin to evolution, where systems improve through continuous feedback, learning from both failures and successes, and iterating toward optimal performance.","Motivated by this, we propose EvolvingGrasp, an evolutionary grasp generation method that continuously enhances grasping performance through efficient preference alignment.","Specifically, we introduce Handpose wise Preference Optimization (HPO), which allows the model to continuously align with preferences from both positive and negative feedback while progressively refining its grasping strategies.","To further enhance efficiency and reliability during online adjustments, we incorporate a Physics-aware Consistency Model within HPO, which accelerates inference, reduces the number of timesteps needed for preference finetuning, and ensures physical plausibility throughout the process.","Extensive experiments across four benchmark datasets demonstrate state of the art performance of our method in grasp success rate and sampling efficiency.","Our results validate that EvolvingGrasp enables evolutionary grasp generation, ensuring robust, physically feasible, and preference-aligned grasping in both simulation and real scenarios."],"url":"http://arxiv.org/abs/2503.14329v1"}
{"created":"2025-03-18 14:58:59","title":"LeanVAE: An Ultra-Efficient Reconstruction VAE for Video Diffusion Models","abstract":"Recent advances in Latent Video Diffusion Models (LVDMs) have revolutionized video generation by leveraging Video Variational Autoencoders (Video VAEs) to compress intricate video data into a compact latent space.However, as LVDM training scales, the computational overhead of Video VAEs becomes a critical bottleneck, particularly for encoding high-resolution videos. To address this, we propose LeanVAE, a novel and ultra-efficient Video VAE framework that introduces two key innovations: (1) a lightweight architecture based on a Neighborhood-Aware Feedforward (NAF) module and non-overlapping patch operations, drastically reducing computational cost, and (2) the integration of wavelet transforms and compressed sensing techniques to enhance reconstruction quality. Extensive experiments validate LeanVAE's superiority in video reconstruction and generation, particularly in enhancing efficiency over existing Video VAEs.Our model offers up to 50x fewer FLOPs and 44x faster inference speed while maintaining competitive reconstruction quality, providing insights for scalable, efficient video generation.Our models and code are available at https://github.com/westlake-repl/LeanVAE.","sentences":["Recent advances in Latent Video Diffusion Models (LVDMs) have revolutionized video generation by leveraging Video Variational Autoencoders (Video VAEs) to compress intricate video data into a compact latent space.","However, as LVDM training scales, the computational overhead of Video VAEs becomes a critical bottleneck, particularly for encoding high-resolution videos.","To address this, we propose LeanVAE, a novel and ultra-efficient Video VAE framework that introduces two key innovations: (1) a lightweight architecture based on a Neighborhood-Aware Feedforward (NAF) module and non-overlapping patch operations, drastically reducing computational cost, and (2) the integration of wavelet transforms and compressed sensing techniques to enhance reconstruction quality.","Extensive experiments validate LeanVAE's superiority in video reconstruction and generation, particularly in enhancing efficiency over existing Video VAEs.","Our model offers up to 50x fewer FLOPs and 44x faster inference speed while maintaining competitive reconstruction quality, providing insights for scalable, efficient video generation.","Our models and code are available at https://github.com/westlake-repl/LeanVAE."],"url":"http://arxiv.org/abs/2503.14325v1"}
{"created":"2025-03-18 14:50:15","title":"Toward Resilient Airdrop Mechanisms: Empirical Measurement of Hunter Profits and Airdrop Game Theory Modeling","abstract":"Airdrops issued by platforms are to distribute tokens, drive user adoption, and promote decentralized services. The distributions attract airdrop hunters (attackers), who exploit the system by employing Sybil attacks, i.e., using multiple identities to manipulate token allocations to meet eligibility criteria. While debates around airdrop hunting question the potential benefits to the ecosystem, exploitative behaviors like Sybil attacks clearly undermine the system's integrity, eroding trust and credibility. Despite the increasing prevalence of these tactics, a gap persists in the literature regarding systematic modeling of airdrop hunters' costs and returns, alongside the theoretical models capturing the interactions among all roles for airdrop mechanism design. Our study first conducts an empirical analysis of transaction data from the Hop Protocol and LayerZero, identifying prevalent attack patterns and estimating hunters' expected profits. Furthermore, we develop a game-theory model that simulates the interactions between attackers, organizers, and bounty hunters, proposing optimal incentive structures that enhance detection while minimizing organizational costs.","sentences":["Airdrops issued by platforms are to distribute tokens, drive user adoption, and promote decentralized services.","The distributions attract airdrop hunters (attackers), who exploit the system by employing Sybil attacks, i.e., using multiple identities to manipulate token allocations to meet eligibility criteria.","While debates around airdrop hunting question the potential benefits to the ecosystem, exploitative behaviors like Sybil attacks clearly undermine the system's integrity, eroding trust and credibility.","Despite the increasing prevalence of these tactics, a gap persists in the literature regarding systematic modeling of airdrop hunters' costs and returns, alongside the theoretical models capturing the interactions among all roles for airdrop mechanism design.","Our study first conducts an empirical analysis of transaction data from the Hop Protocol and LayerZero, identifying prevalent attack patterns and estimating hunters' expected profits.","Furthermore, we develop a game-theory model that simulates the interactions between attackers, organizers, and bounty hunters, proposing optimal incentive structures that enhance detection while minimizing organizational costs."],"url":"http://arxiv.org/abs/2503.14316v1"}
{"created":"2025-03-18 14:42:38","title":"FeNeC: Enhancing Continual Learning via Feature Clustering with Neighbor- or Logit-Based Classification","abstract":"The ability of deep learning models to learn continuously is essential for adapting to new data categories and evolving data distributions. In recent years, approaches leveraging frozen feature extractors after an initial learning phase have been extensively studied. Many of these methods estimate per-class covariance matrices and prototypes based on backbone-derived feature representations. Within this paradigm, we introduce FeNeC (Feature Neighborhood Classifier) and FeNeC-Log, its variant based on the log-likelihood function. Our approach generalizes the existing concept by incorporating data clustering to capture greater intra-class variability. Utilizing the Mahalanobis distance, our models classify samples either through a nearest neighbor approach or trainable logit values assigned to consecutive classes. Our proposition may be reduced to the existing approaches in a special case while extending them with the ability of more flexible adaptation to data. We demonstrate that two FeNeC variants achieve competitive performance in scenarios where task identities are unknown and establish state-of-the-art results on several benchmarks.","sentences":["The ability of deep learning models to learn continuously is essential for adapting to new data categories and evolving data distributions.","In recent years, approaches leveraging frozen feature extractors after an initial learning phase have been extensively studied.","Many of these methods estimate per-class covariance matrices and prototypes based on backbone-derived feature representations.","Within this paradigm, we introduce FeNeC (Feature Neighborhood Classifier) and FeNeC-Log, its variant based on the log-likelihood function.","Our approach generalizes the existing concept by incorporating data clustering to capture greater intra-class variability.","Utilizing the Mahalanobis distance, our models classify samples either through a nearest neighbor approach or trainable logit values assigned to consecutive classes.","Our proposition may be reduced to the existing approaches in a special case while extending them with the ability of more flexible adaptation to data.","We demonstrate that two FeNeC variants achieve competitive performance in scenarios where task identities are unknown and establish state-of-the-art results on several benchmarks."],"url":"http://arxiv.org/abs/2503.14301v1"}
{"created":"2025-03-18 14:41:33","title":"Unveiling the Role of Randomization in Multiclass Adversarial Classification: Insights from Graph Theory","abstract":"Randomization as a mean to improve the adversarial robustness of machine learning models has recently attracted significant attention. Unfortunately, much of the theoretical analysis so far has focused on binary classification, providing only limited insights into the more complex multiclass setting. In this paper, we take a step toward closing this gap by drawing inspiration from the field of graph theory. Our analysis focuses on discrete data distributions, allowing us to cast the adversarial risk minimization problems within the well-established framework of set packing problems. By doing so, we are able to identify three structural conditions on the support of the data distribution that are necessary for randomization to improve robustness. Furthermore, we are able to construct several data distributions where (contrarily to binary classification) switching from a deterministic to a randomized solution significantly reduces the optimal adversarial risk. These findings highlight the crucial role randomization can play in enhancing robustness to adversarial attacks in multiclass classification.","sentences":["Randomization as a mean to improve the adversarial robustness of machine learning models has recently attracted significant attention.","Unfortunately, much of the theoretical analysis so far has focused on binary classification, providing only limited insights into the more complex multiclass setting.","In this paper, we take a step toward closing this gap by drawing inspiration from the field of graph theory.","Our analysis focuses on discrete data distributions, allowing us to cast the adversarial risk minimization problems within the well-established framework of set packing problems.","By doing so, we are able to identify three structural conditions on the support of the data distribution that are necessary for randomization to improve robustness.","Furthermore, we are able to construct several data distributions where (contrarily to binary classification) switching from a deterministic to a randomized solution significantly reduces the optimal adversarial risk.","These findings highlight the crucial role randomization can play in enhancing robustness to adversarial attacks in multiclass classification."],"url":"http://arxiv.org/abs/2503.14299v1"}
{"created":"2025-03-18 14:41:23","title":"Recursive Self-Similarity in Deep Weight Spaces of Neural Architectures: A Fractal and Coarse Geometry Perspective","abstract":"This paper conceptualizes the Deep Weight Spaces (DWS) of neural architectures as hierarchical, fractal-like, coarse geometric structures observable at discrete integer scales through recursive dilation. We introduce a coarse group action termed the fractal transformation, $T_{r_k} $, acting under the symmetry group $G = (\\mathbb{Z}, +) $, to analyze neural parameter matrices or tensors, by segmenting the underlying discrete grid $\\Omega$ into $N(r_k)$ fractals across varying observation scales $ r_k $. This perspective adopts a box count technique, commonly used to assess the hierarchical and scale-related geometry of physical structures, which has been extensively formalized under the topic of fractal geometry. We assess the structural complexity of neural layers by estimating the Hausdorff-Besicovitch dimension of their layers and evaluating a degree of self-similarity. The fractal transformation features key algebraic properties such as linearity, identity, and asymptotic invertibility, which is a signature of coarse structures. We show that the coarse group action exhibits a set of symmetries such as Discrete Scale Invariance (DSI) under recursive dilation, strong invariance followed by weak equivariance to permutations, alongside respecting the scaling equivariance of activation functions, defined by the intertwiner group relations. Our framework targets large-scale structural properties of DWS, deliberately overlooking minor inconsistencies to focus on significant geometric characteristics of neural networks. Experiments on CIFAR-10 using ResNet-18, VGG-16, and a custom CNN validate our approach, demonstrating effective fractal segmentation and structural analysis.","sentences":["This paper conceptualizes the Deep Weight Spaces (DWS) of neural architectures as hierarchical, fractal-like, coarse geometric structures observable at discrete integer scales through recursive dilation.","We introduce a coarse group action termed the fractal transformation, $T_{r_k} $, acting under the symmetry group $G = (\\mathbb{Z}, +) $, to analyze neural parameter matrices or tensors, by segmenting the underlying discrete grid $\\Omega$ into $N(r_k)$ fractals across varying observation scales $ r_k $.","This perspective adopts a box count technique, commonly used to assess the hierarchical and scale-related geometry of physical structures, which has been extensively formalized under the topic of fractal geometry.","We assess the structural complexity of neural layers by estimating the Hausdorff-Besicovitch dimension of their layers and evaluating a degree of self-similarity.","The fractal transformation features key algebraic properties such as linearity, identity, and asymptotic invertibility, which is a signature of coarse structures.","We show that the coarse group action exhibits a set of symmetries such as Discrete Scale Invariance (DSI) under recursive dilation, strong invariance followed by weak equivariance to permutations, alongside respecting the scaling equivariance of activation functions, defined by the intertwiner group relations.","Our framework targets large-scale structural properties of DWS, deliberately overlooking minor inconsistencies to focus on significant geometric characteristics of neural networks.","Experiments on CIFAR-10 using ResNet-18, VGG-16, and a custom CNN validate our approach, demonstrating effective fractal segmentation and structural analysis."],"url":"http://arxiv.org/abs/2503.14298v1"}
{"created":"2025-03-18 14:23:37","title":"Tapered Off-Policy REINFORCE: Stable and efficient reinforcement learning for LLMs","abstract":"We propose a new algorithm for fine-tuning large language models using reinforcement learning. Tapered Off-Policy REINFORCE (TOPR) uses an asymmetric, tapered variant of importance sampling to speed up learning while maintaining stable learning dynamics, even without the use of KL regularization. TOPR can be applied in a fully offline fashion, allows the handling of positive and negative examples in a unified framework, and benefits from the implementational simplicity that is typical of Monte Carlo algorithms. We demonstrate the effectiveness of our approach with a series of experiments on the GSM8K and MATH reasoning benchmarks, finding performance gains for training both a model for solution generation and as a generative verifier. We show that properly leveraging positive and negative examples alike in the off-policy regime simultaneously increases test-time accuracy and training data efficiency, all the while avoiding the ``wasted inference'' that comes with discarding negative examples. We find that this advantage persists over multiple iterations of training and can be amplified by dataset curation techniques, enabling us to match 70B-parameter model performance with 8B language models. As a corollary to this work, we find that REINFORCE's baseline parameter plays an important and unexpected role in defining dataset composition in the presence of negative examples, and is consequently critical in driving off-policy performance.","sentences":["We propose a new algorithm for fine-tuning large language models using reinforcement learning.","Tapered Off-Policy REINFORCE (TOPR) uses an asymmetric, tapered variant of importance sampling to speed up learning while maintaining stable learning dynamics, even without the use of KL regularization.","TOPR can be applied in a fully offline fashion, allows the handling of positive and negative examples in a unified framework, and benefits from the implementational simplicity that is typical of Monte Carlo algorithms.","We demonstrate the effectiveness of our approach with a series of experiments on the GSM8K and MATH reasoning benchmarks, finding performance gains for training both a model for solution generation and as a generative verifier.","We show that properly leveraging positive and negative examples alike in the off-policy regime simultaneously increases test-time accuracy and training data efficiency, all the while avoiding the ``wasted inference'' that comes with discarding negative examples.","We find that this advantage persists over multiple iterations of training and can be amplified by dataset curation techniques, enabling us to match 70B-parameter model performance with 8B language models.","As a corollary to this work, we find that REINFORCE's baseline parameter plays an important and unexpected role in defining dataset composition in the presence of negative examples, and is consequently critical in driving off-policy performance."],"url":"http://arxiv.org/abs/2503.14286v1"}
{"created":"2025-03-18 14:21:24","title":"Entente: Cross-silo Intrusion Detection on Network Log Graphs with Federated Learning","abstract":"Graph-based Network Intrusion Detection System (GNIDS) has gained significant momentum in detecting sophisticated cyber-attacks, like Advanced Persistent Threat (APT), in an organization or across organizations. Though achieving satisfying detection accuracy and adapting to ever-changing attacks and normal patterns, all prior GNIDSs assume the centralized data settings directly, but non-trivial data collection is not always practical under privacy regulations nowadays. We argue that training a GNIDS model has to consider privacy regulations, and propose to leverage federated learning (FL) to address this prominent challenge.   Yet, directly applying FL to GNIDS is unlikely to succeed, due to issues like non-IID (independent and identically distributed) graph data over clients and the diverse design choices taken by different GNIDS. We address these issues with a set of novel techniques tailored to the graph datasets, including reference graph synthesis, graph sketching and adaptive contribution scaling, and develop a new system Entente. We evaluate Entente on the large-scale LANL, OpTC and Pivoting datasets. The result shows Entente outperforms the other baseline FL algorithms and sometimes even the non-FL GNIDS. We also evaluate Entente under FL poisoning attacks tailored to the GNIDS setting, and show Entente is able to bound the attack success rate to low values. Overall, our result suggests building cross-silo GNIDS is feasible and we hope to encourage more efforts in this direction.","sentences":["Graph-based Network Intrusion Detection System (GNIDS) has gained significant momentum in detecting sophisticated cyber-attacks, like Advanced Persistent Threat (APT), in an organization or across organizations.","Though achieving satisfying detection accuracy and adapting to ever-changing attacks and normal patterns, all prior GNIDSs assume the centralized data settings directly, but non-trivial data collection is not always practical under privacy regulations nowadays.","We argue that training a GNIDS model has to consider privacy regulations, and propose to leverage federated learning (FL) to address this prominent challenge.   ","Yet, directly applying FL to GNIDS is unlikely to succeed, due to issues like non-IID (independent and identically distributed) graph data over clients and the diverse design choices taken by different GNIDS.","We address these issues with a set of novel techniques tailored to the graph datasets, including reference graph synthesis, graph sketching and adaptive contribution scaling, and develop a new system Entente.","We evaluate Entente on the large-scale LANL, OpTC and Pivoting datasets.","The result shows Entente outperforms the other baseline FL algorithms and sometimes even the non-FL GNIDS.","We also evaluate Entente under FL poisoning attacks tailored to the GNIDS setting, and show Entente is able to bound the attack success rate to low values.","Overall, our result suggests building cross-silo GNIDS is feasible and we hope to encourage more efforts in this direction."],"url":"http://arxiv.org/abs/2503.14284v1"}
{"created":"2025-03-18 14:16:21","title":"Towards synthetic generation of realistic wooden logs","abstract":"In this work, we propose a novel method to synthetically generate realistic 3D representations of wooden logs. Efficient sawmilling heavily relies on accurate measurement of logs and the distribution of knots inside them. Computed Tomography (CT) can be used to obtain accurate information about the knots but is often not feasible in a sawmill environment. A promising alternative is to utilize surface measurements and machine learning techniques to predict the inner structure of the logs. However, obtaining enough training data remains a challenge. We focus mainly on two aspects of log generation: the modeling of knot growth inside the tree, and the realistic synthesis of the surface including the regions, where the knots reach the surface. This results in the first log synthesis approach capable of generating both the internal knot and external surface structures of wood. We demonstrate that the proposed mathematical log model accurately fits to real data obtained from CT scans and enables the generation of realistic logs.","sentences":["In this work, we propose a novel method to synthetically generate realistic 3D representations of wooden logs.","Efficient sawmilling heavily relies on accurate measurement of logs and the distribution of knots inside them.","Computed Tomography (CT) can be used to obtain accurate information about the knots but is often not feasible in a sawmill environment.","A promising alternative is to utilize surface measurements and machine learning techniques to predict the inner structure of the logs.","However, obtaining enough training data remains a challenge.","We focus mainly on two aspects of log generation: the modeling of knot growth inside the tree, and the realistic synthesis of the surface including the regions, where the knots reach the surface.","This results in the first log synthesis approach capable of generating both the internal knot and external surface structures of wood.","We demonstrate that the proposed mathematical log model accurately fits to real data obtained from CT scans and enables the generation of realistic logs."],"url":"http://arxiv.org/abs/2503.14277v1"}
{"created":"2025-03-18 14:09:00","title":"Manual Labelling Artificially Inflates Deep Learning-Based Segmentation Performance on Closed Canopy: Validation Using TLS","abstract":"Monitoring forest dynamics at an individual tree scale is essential for accurately assessing ecosystem responses to climate change, yet traditional methods relying on field-based forest inventories are labor-intensive and limited in spatial coverage. Advances in remote sensing using drone-acquired RGB imagery combined with deep learning models have promised precise individual tree crown (ITC) segmentation; however, existing methods are frequently validated against human-annotated images, lacking rigorous independent ground truth. In this study, we generate high-fidelity validation labels from co-located Terrestrial Laser Scanning (TLS) data for drone imagery of mixed unmanaged boreal and Mediterranean forests. We evaluate the performance of two widely used deep learning ITC segmentation models - DeepForest (RetinaNet) and Detectree2 (Mask R-CNN) - on these data, and compare to performance on further Mediterranean forest data labelled manually. When validated against TLS-derived ground truth from Mediterranean forests, model performance decreased significantly compared to assessment based on hand-labelled from an ecologically similar site (AP50: 0.094 vs. 0.670). Restricting evaluation to only canopy trees shrank this gap considerably (Canopy AP50: 0.365), although performance was still far lower than on similar hand-labelled data. Models also performed poorly on boreal forest data (AP50: 0.142), although again increasing when evaluated on canopy trees only (Canopy AP50: 0.308). Both models showed very poor localisation accuracy at stricter IoU thresholds, even when restricted to canopy trees (Max AP75: 0.051). Similar results have been observed in studies using aerial LiDAR data, suggesting fundamental limitations in aerial-based segmentation approaches in closed canopy forests.","sentences":["Monitoring forest dynamics at an individual tree scale is essential for accurately assessing ecosystem responses to climate change, yet traditional methods relying on field-based forest inventories are labor-intensive and limited in spatial coverage.","Advances in remote sensing using drone-acquired RGB imagery combined with deep learning models have promised precise individual tree crown (ITC) segmentation; however, existing methods are frequently validated against human-annotated images, lacking rigorous independent ground truth.","In this study, we generate high-fidelity validation labels from co-located Terrestrial Laser Scanning (TLS) data for drone imagery of mixed unmanaged boreal and Mediterranean forests.","We evaluate the performance of two widely used deep learning ITC segmentation models - DeepForest (RetinaNet) and Detectree2 (Mask R-CNN) - on these data, and compare to performance on further Mediterranean forest data labelled manually.","When validated against TLS-derived ground truth from Mediterranean forests, model performance decreased significantly compared to assessment based on hand-labelled from an ecologically similar site (AP50: 0.094 vs. 0.670).","Restricting evaluation to only canopy trees shrank this gap considerably (Canopy AP50: 0.365), although performance was still far lower than on similar hand-labelled data.","Models also performed poorly on boreal forest data (AP50: 0.142), although again increasing when evaluated on canopy trees only (Canopy AP50: 0.308).","Both models showed very poor localisation accuracy at stricter IoU thresholds, even when restricted to canopy trees (Max AP75: 0.051).","Similar results have been observed in studies using aerial LiDAR data, suggesting fundamental limitations in aerial-based segmentation approaches in closed canopy forests."],"url":"http://arxiv.org/abs/2503.14273v1"}
{"created":"2025-03-18 14:05:52","title":"Video Streaming with Kairos: An MPC-Based ABR with Streaming-Aware Throughput Prediction","abstract":"In this paper, we present Kairos, a model predictive control (MPC)-based adaptive bitrate (ABR) scheme that integrates streaming-aware throughput predictions to enhance video streaming quality. Kairos features an attention-based throughput predictor with buffer-aware uncertainty control, improving prediction accuracy and adaptability to network conditions. Specifically, we introduce a multi-time attention network to handle the irregularly sampled sequences in streaming data, creating uniformly spaced latent representations. Additionally, we design a separate prediction network that estimates future throughput at multiple percentiles and incorporates a buffer-aware uncertainty adjustment module. This module dynamically selects the appropriate throughput percentile based on the buffer size, enhancing robustness to varying network conditions. Lastly, to mitigate QoE smoothness penalties caused by predictors focused solely on accuracy, we introduce a smoothness regularizer. By embedding streaming-aware characteristics, such as sampling irregularity, buffer occupancy, and smoothness, into the throughput predictor design, Kairos significantly improves bitrate decision-making within the MPC framework. Extensive trace-driven and real-world experiments demonstrate that Kairos outperforms state-of-the-art ABR schemes, achieving an average QoE improvement of 1.52% to 7.28% under various network conditions.","sentences":["In this paper, we present Kairos, a model predictive control (MPC)-based adaptive bitrate (ABR) scheme that integrates streaming-aware throughput predictions to enhance video streaming quality.","Kairos features an attention-based throughput predictor with buffer-aware uncertainty control, improving prediction accuracy and adaptability to network conditions.","Specifically, we introduce a multi-time attention network to handle the irregularly sampled sequences in streaming data, creating uniformly spaced latent representations.","Additionally, we design a separate prediction network that estimates future throughput at multiple percentiles and incorporates a buffer-aware uncertainty adjustment module.","This module dynamically selects the appropriate throughput percentile based on the buffer size, enhancing robustness to varying network conditions.","Lastly, to mitigate QoE smoothness penalties caused by predictors focused solely on accuracy, we introduce a smoothness regularizer.","By embedding streaming-aware characteristics, such as sampling irregularity, buffer occupancy, and smoothness, into the throughput predictor design, Kairos significantly improves bitrate decision-making within the MPC framework.","Extensive trace-driven and real-world experiments demonstrate that Kairos outperforms state-of-the-art ABR schemes, achieving an average QoE improvement of 1.52% to 7.28% under various network conditions."],"url":"http://arxiv.org/abs/2503.14271v1"}
{"created":"2025-03-18 14:02:59","title":"DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal","abstract":"Large Language Models (LLMs) have revolutionized various domains, including natural language processing, data analysis, and software development, by enabling automation. In software engineering, LLM-powered coding agents have garnered significant attention due to their potential to automate complex development tasks, assist in debugging, and enhance productivity. However, existing approaches often struggle with sub-optimal decision-making, requiring either extensive manual intervention or inefficient compute scaling strategies. To improve coding agent performance, we present Dynamic Action Re-Sampling (DARS), a novel inference time compute scaling approach for coding agents, that is faster and more effective at recovering from sub-optimal decisions compared to baselines. While traditional agents either follow linear trajectories or rely on random sampling for scaling compute, our approach DARS works by branching out a trajectory at certain key decision points by taking an alternative action given the history of the trajectory and execution feedback of the previous attempt from that point. We evaluate our approach on SWE-Bench Lite benchmark, demonstrating that this scaling strategy achieves a pass@k score of 55% with Claude 3.5 Sonnet V2. Our framework achieves a pass@1 rate of 47%, outperforming state-of-the-art (SOTA) open-source frameworks.","sentences":["Large Language Models (LLMs) have revolutionized various domains, including natural language processing, data analysis, and software development, by enabling automation.","In software engineering, LLM-powered coding agents have garnered significant attention due to their potential to automate complex development tasks, assist in debugging, and enhance productivity.","However, existing approaches often struggle with sub-optimal decision-making, requiring either extensive manual intervention or inefficient compute scaling strategies.","To improve coding agent performance, we present Dynamic Action Re-Sampling (DARS), a novel inference time compute scaling approach for coding agents, that is faster and more effective at recovering from sub-optimal decisions compared to baselines.","While traditional agents either follow linear trajectories or rely on random sampling for scaling compute, our approach DARS works by branching out a trajectory at certain key decision points by taking an alternative action given the history of the trajectory and execution feedback of the previous attempt from that point.","We evaluate our approach on SWE-Bench Lite benchmark, demonstrating that this scaling strategy achieves a pass@k score of 55% with Claude 3.5 Sonnet V2.","Our framework achieves a pass@1 rate of 47%, outperforming state-of-the-art (SOTA) open-source frameworks."],"url":"http://arxiv.org/abs/2503.14269v1"}
{"created":"2025-03-18 13:59:32","title":"EmotionCarrier: A Multimodality 'Mindfulness-Training' Tool for Positive Emotional Value","abstract":"This study introduced a Multimodal Mindfulness-Training System. Our installation, 'EmotionCarrier', correlates traditional calligraphy interactions with real-time physiological data from an Apple Watch. We aim to enhance mindfulness training effectiveness, aiding in achieving physiological calmness through calligraphy practice. Our experiments with varied participant groups focused on data diversity, usability, and stability. We adopted methods like using EmotionCarrier for Heart Sutra transcription and adjusting installation placement for optimal user experience. Our primary finding was a correlation between calligraphy performance data and emotional responses during the transcription of the Heart Sutra.","sentences":["This study introduced a Multimodal Mindfulness-Training System.","Our installation, 'EmotionCarrier', correlates traditional calligraphy interactions with real-time physiological data from an Apple Watch.","We aim to enhance mindfulness training effectiveness, aiding in achieving physiological calmness through calligraphy practice.","Our experiments with varied participant groups focused on data diversity, usability, and stability.","We adopted methods like using EmotionCarrier for Heart Sutra transcription and adjusting installation placement for optimal user experience.","Our primary finding was a correlation between calligraphy performance data and emotional responses during the transcription of the Heart Sutra."],"url":"http://arxiv.org/abs/2503.14266v1"}
{"created":"2025-03-18 13:39:46","title":"Towards a Barrier-free GeoQA Portal: Natural Language Interaction with Geospatial Data Using Multi-Agent LLMs and Semantic Search","abstract":"A Barrier-Free GeoQA Portal: Enhancing Geospatial Data Accessibility with a Multi-Agent LLM Framework   Geoportals are vital for accessing and analyzing geospatial data, promoting open spatial data sharing and online geo-information management. Designed with GIS-like interaction and layered visualization, they often challenge non-expert users with complex functionalities and overlapping layers that obscure spatial relationships. We propose a GeoQA Portal using a multi-agent Large Language Model framework for seamless natural language interaction with geospatial data. Complex queries are broken into subtasks handled by specialized agents, retrieving relevant geographic data efficiently. Task plans are shown to users, boosting transparency. The portal supports default and custom data inputs for flexibility. Semantic search via word vector similarity aids data retrieval despite imperfect terms. Case studies, evaluations, and user tests confirm its effectiveness for non-experts, bridging GIS complexity and public access, and offering an intuitive solution for future geoportals.","sentences":["A Barrier-Free GeoQA Portal:","Enhancing Geospatial Data Accessibility with a Multi-Agent LLM Framework   Geoportals are vital for accessing and analyzing geospatial data, promoting open spatial data sharing and online geo-information management.","Designed with GIS-like interaction and layered visualization, they often challenge non-expert users with complex functionalities and overlapping layers that obscure spatial relationships.","We propose a GeoQA Portal using a multi-agent Large Language Model framework for seamless natural language interaction with geospatial data.","Complex queries are broken into subtasks handled by specialized agents, retrieving relevant geographic data efficiently.","Task plans are shown to users, boosting transparency.","The portal supports default and custom data inputs for flexibility.","Semantic search via word vector similarity aids data retrieval despite imperfect terms.","Case studies, evaluations, and user tests confirm its effectiveness for non-experts, bridging GIS complexity and public access, and offering an intuitive solution for future geoportals."],"url":"http://arxiv.org/abs/2503.14251v1"}
{"created":"2025-03-18 13:38:53","title":"A Parallel Hybrid Action Space Reinforcement Learning Model for Real-world Adaptive Traffic Signal Control","abstract":"Adaptive traffic signal control (ATSC) can effectively reduce vehicle travel times by dynamically adjusting signal timings but poses a critical challenge in real-world scenarios due to the complexity of real-time decision-making in dynamic and uncertain traffic conditions. The burgeoning field of intelligent transportation systems, bolstered by artificial intelligence techniques and extensive data availability, offers new prospects for the implementation of ATSC. In this study, we introduce a parallel hybrid action space reinforcement learning model (PH-DDPG) that optimizes traffic signal phase and duration of traffic signals simultaneously, eliminating the need for sequential decision-making seen in traditional two-stage models. Our model features a task-specific parallel hybrid action space tailored for adaptive traffic control, which directly outputs discrete phase selections and their associated continuous duration parameters concurrently, thereby inherently addressing dynamic traffic adaptation through unified parametric optimization. %Our model features a unique parallel hybrid action space that allows for the simultaneous output of each action and its optimal parameters, streamlining the decision-making process. Furthermore, to ascertain the robustness and effectiveness of this approach, we executed ablation studies focusing on the utilization of a random action parameter mask within the critic network, which decouples the parameter space for individual actions, facilitating the use of preferable parameters for each action. The results from these studies confirm the efficacy of this method, distinctly enhancing real-world applicability","sentences":["Adaptive traffic signal control (ATSC) can effectively reduce vehicle travel times by dynamically adjusting signal timings but poses a critical challenge in real-world scenarios due to the complexity of real-time decision-making in dynamic and uncertain traffic conditions.","The burgeoning field of intelligent transportation systems, bolstered by artificial intelligence techniques and extensive data availability, offers new prospects for the implementation of ATSC.","In this study, we introduce a parallel hybrid action space reinforcement learning model (PH-DDPG) that optimizes traffic signal phase and duration of traffic signals simultaneously, eliminating the need for sequential decision-making seen in traditional two-stage models.","Our model features a task-specific parallel hybrid action space tailored for adaptive traffic control, which directly outputs discrete phase selections and their associated continuous duration parameters concurrently, thereby inherently addressing dynamic traffic adaptation through unified parametric optimization.","%","Our model features a unique parallel hybrid action space that allows for the simultaneous output of each action and its optimal parameters, streamlining the decision-making process.","Furthermore, to ascertain the robustness and effectiveness of this approach, we executed ablation studies focusing on the utilization of a random action parameter mask within the critic network, which decouples the parameter space for individual actions, facilitating the use of preferable parameters for each action.","The results from these studies confirm the efficacy of this method, distinctly enhancing real-world applicability"],"url":"http://arxiv.org/abs/2503.14250v1"}
{"created":"2025-03-18 13:22:52","title":"Persistent Homology-induced Graph Ensembles for Time Series Regressions","abstract":"The effectiveness of Spatio-temporal Graph Neural Networks (STGNNs) in time-series applications is often limited by their dependence on fixed, hand-crafted input graph structures. Motivated by insights from the Topological Data Analysis (TDA) paradigm, of which real-world data exhibits multi-scale patterns, we construct several graphs using \\textit{Persistent Homology Filtration} -- a mathematical framework describing the multiscale structural properties of data points. Then, we use the constructed graphs as an input to create an ensemble of Graph Neural Networks. The ensemble aggregates the signals from the individual learners via an attention-based routing mechanism, thus systematically encoding the inherent multiscale structures of data. Four different real-world experiments on seismic activity prediction and traffic forecasting (PEMS-BAY, METR-LA) demonstrate that our approach consistently outperforms single-graph baselines while providing interpretable insights.","sentences":["The effectiveness of Spatio-temporal Graph Neural Networks (STGNNs) in time-series applications is often limited by their dependence on fixed, hand-crafted input graph structures.","Motivated by insights from the Topological Data Analysis (TDA) paradigm, of which real-world data exhibits multi-scale patterns, we construct several graphs using \\textit{Persistent Homology Filtration} -- a mathematical framework describing the multiscale structural properties of data points.","Then, we use the constructed graphs as an input to create an ensemble of Graph Neural Networks.","The ensemble aggregates the signals from the individual learners via an attention-based routing mechanism, thus systematically encoding the inherent multiscale structures of data.","Four different real-world experiments on seismic activity prediction and traffic forecasting (PEMS-BAY, METR-LA) demonstrate that our approach consistently outperforms single-graph baselines while providing interpretable insights."],"url":"http://arxiv.org/abs/2503.14240v1"}
{"created":"2025-03-18 13:20:22","title":"Predicting Cardiopulmonary Exercise Testing Outcomes in Congenital Heart Disease Through Multi-modal Data Integration and Geometric Learning","abstract":"Cardiopulmonary exercise testing (CPET) provides a comprehensive assessment of functional capacity by measuring key physiological variables including oxygen consumption ($VO_2$), carbon dioxide production ($VCO_2$), and pulmonary ventilation ($VE$) during exercise. Previous research has established that parameters such as peak $VO_2$ and $VE/VCO_2$ ratio serve as robust predictors of mortality risk in chronic heart failure patients. In this study, we leverage CPET variables as surrogate mortality endpoints for patients with Congenital Heart Disease (CHD). To our knowledge, this represents the first successful implementation of an advanced machine learning approach that predicts CPET outcomes by integrating electrocardiograms (ECGs) with information derived from clinical letters. Our methodology began with extracting unstructured patient information-including intervention history, diagnoses, and medication regimens-from clinical letters using natural language processing techniques, organizing this data into a structured database. We then digitized ECGs to obtain quantifiable waveforms and established comprehensive data linkages. The core innovation of our approach lies in exploiting the Riemannian geometric properties of covariance matrices derived from both 12-lead ECGs and clinical text data to develop robust regression and classification models. Through extensive ablation studies, we demonstrated that the integration of ECG signals with clinical documentation, enhanced by covariance augmentation techniques in Riemannian space, consistently produced superior predictive performance compared to conventional approaches.","sentences":["Cardiopulmonary exercise testing (CPET) provides a comprehensive assessment of functional capacity by measuring key physiological variables including oxygen consumption ($VO_2$), carbon dioxide production ($VCO_2$), and pulmonary ventilation ($VE$) during exercise.","Previous research has established that parameters such as peak $VO_2$ and $VE/VCO_2$ ratio serve as robust predictors of mortality risk in chronic heart failure patients.","In this study, we leverage CPET variables as surrogate mortality endpoints for patients with Congenital Heart Disease (CHD).","To our knowledge, this represents the first successful implementation of an advanced machine learning approach that predicts CPET outcomes by integrating electrocardiograms (ECGs) with information derived from clinical letters.","Our methodology began with extracting unstructured patient information-including intervention history, diagnoses, and medication regimens-from clinical letters using natural language processing techniques, organizing this data into a structured database.","We then digitized ECGs to obtain quantifiable waveforms and established comprehensive data linkages.","The core innovation of our approach lies in exploiting the Riemannian geometric properties of covariance matrices derived from both 12-lead ECGs and clinical text data to develop robust regression and classification models.","Through extensive ablation studies, we demonstrated that the integration of ECG signals with clinical documentation, enhanced by covariance augmentation techniques in Riemannian space, consistently produced superior predictive performance compared to conventional approaches."],"url":"http://arxiv.org/abs/2503.14239v1"}
{"created":"2025-03-18 13:15:58","title":"Make Your Training Flexible: Towards Deployment-Efficient Video Models","abstract":"Popular video training methods mainly operate on a fixed number of tokens sampled from a predetermined spatiotemporal grid, resulting in sub-optimal accuracy-computation trade-offs due to inherent video redundancy. They also lack adaptability to varying computational budgets for downstream tasks, hindering applications of the most competitive model in real-world scenes. We thus propose a new test setting, Token Optimization, for maximized input information across budgets, which optimizes the size-limited set of input tokens through token selection from more suitably sampled videos. To this end, we propose a novel augmentation tool termed Flux. By making the sampling grid flexible and leveraging token selection, it is easily adopted in most popular video training frameworks, boosting model robustness with nearly no additional cost. We integrate Flux in large-scale video pre-training, and the resulting FluxViT establishes new state-of-the-art results across extensive tasks at standard costs. Notably, with 1/4 tokens only, it can still match the performance of previous state-of-the-art models with Token Optimization, yielding nearly 90\\% savings. All models and data are available at https://github.com/OpenGVLab/FluxViT.","sentences":["Popular video training methods mainly operate on a fixed number of tokens sampled from a predetermined spatiotemporal grid, resulting in sub-optimal accuracy-computation trade-offs due to inherent video redundancy.","They also lack adaptability to varying computational budgets for downstream tasks, hindering applications of the most competitive model in real-world scenes.","We thus propose a new test setting, Token Optimization, for maximized input information across budgets, which optimizes the size-limited set of input tokens through token selection from more suitably sampled videos.","To this end, we propose a novel augmentation tool termed Flux.","By making the sampling grid flexible and leveraging token selection, it is easily adopted in most popular video training frameworks, boosting model robustness with nearly no additional cost.","We integrate Flux in large-scale video pre-training, and the resulting FluxViT establishes new state-of-the-art results across extensive tasks at standard costs.","Notably, with 1/4 tokens only, it can still match the performance of previous state-of-the-art models with Token Optimization, yielding nearly 90\\% savings.","All models and data are available at https://github.com/OpenGVLab/FluxViT."],"url":"http://arxiv.org/abs/2503.14237v1"}
{"created":"2025-03-18 13:11:43","title":"KG-IRAG: A Knowledge Graph-Based Iterative Retrieval-Augmented Generation Framework for Temporal Reasoning","abstract":"Graph Retrieval-Augmented Generation (GraphRAG) has proven highly effective in enhancing the performance of Large Language Models (LLMs) on tasks that require external knowledge. By leveraging Knowledge Graphs (KGs), GraphRAG improves information retrieval for complex reasoning tasks, providing more precise and comprehensive retrieval and generating more accurate responses to QAs. However, most RAG methods fall short in addressing multi-step reasoning, particularly when both information extraction and inference are necessary. To address this limitation, this paper presents Knowledge Graph-Based Iterative Retrieval-Augmented Generation (KG-IRAG), a novel framework that integrates KGs with iterative reasoning to improve LLMs' ability to handle queries involving temporal and logical dependencies. Through iterative retrieval steps, KG-IRAG incrementally gathers relevant data from external KGs, enabling step-by-step reasoning. The proposed approach is particularly suited for scenarios where reasoning is required alongside dynamic temporal data extraction, such as determining optimal travel times based on weather conditions or traffic patterns. Experimental results show that KG-IRAG improves accuracy in complex reasoning tasks by effectively integrating external knowledge with iterative, logic-based retrieval. Additionally, three new datasets: weatherQA-Irish, weatherQA-Sydney, and trafficQA-TFNSW, are formed to evaluate KG-IRAG's performance, demonstrating its potential beyond traditional RAG applications.","sentences":["Graph Retrieval-Augmented Generation (GraphRAG) has proven highly effective in enhancing the performance of Large Language Models (LLMs) on tasks that require external knowledge.","By leveraging Knowledge Graphs (KGs), GraphRAG improves information retrieval for complex reasoning tasks, providing more precise and comprehensive retrieval and generating more accurate responses to QAs.","However, most RAG methods fall short in addressing multi-step reasoning, particularly when both information extraction and inference are necessary.","To address this limitation, this paper presents Knowledge Graph-Based Iterative Retrieval-Augmented Generation (KG-IRAG), a novel framework that integrates KGs with iterative reasoning to improve LLMs' ability to handle queries involving temporal and logical dependencies.","Through iterative retrieval steps, KG-IRAG incrementally gathers relevant data from external KGs, enabling step-by-step reasoning.","The proposed approach is particularly suited for scenarios where reasoning is required alongside dynamic temporal data extraction, such as determining optimal travel times based on weather conditions or traffic patterns.","Experimental results show that KG-IRAG improves accuracy in complex reasoning tasks by effectively integrating external knowledge with iterative, logic-based retrieval.","Additionally, three new datasets: weatherQA-Irish, weatherQA-Sydney, and trafficQA-TFNSW, are formed to evaluate KG-IRAG's performance, demonstrating its potential beyond traditional RAG applications."],"url":"http://arxiv.org/abs/2503.14234v1"}
{"created":"2025-03-18 12:26:06","title":"Why Personalizing Deep Learning-Based Code Completion Tools Matters","abstract":"Deep learning (DL)-based code completion tools have transformed software development by enabling advanced code generation. These tools leverage models trained on vast amounts of code from numerous repositories, capturing general coding patterns. However, the impact of fine-tuning these models for specific organizations or developers to boost their performance on such subjects remains unexplored. In this work, we fill this gap by presenting solid empirical evidence answering this question. More specifically, we consider 136 developers from two organizations (Apache and Spring), two model architectures (T5 and Code Llama), and three model sizes (60M, 750M, and 7B trainable parameters). T5 models (60M, 750M) were pre-trained and fine-tuned on over 2,000 open-source projects, excluding the subject organizations' data, and compared against versions fine-tuned on organization- and developer-specific datasets. For the Code Llama model (7B), we compared the performance of the already pre-trained model publicly available online with the same model fine-tuned via parameter-efficient fine-tuning on organization- and developer-specific datasets. Our results show that there is a boost in prediction capabilities provided by both an organization-specific and a developer-specific additional fine-tuning, with the former being particularly performant. Such a finding generalizes across (i) the two subject organizations (i.e., Apache and Spring) and (ii) models of completely different magnitude (from 60M to 7B trainable parameters). Finally, we show that DL models fine-tuned on an organization-specific dataset achieve the same completion performance of pre-trained code models used out of the box and being $\\sim$10$\\times$ larger, with consequent savings in terms of deployment and inference cost (e.g., smaller GPUs needed).","sentences":["Deep learning (DL)-based code completion tools have transformed software development by enabling advanced code generation.","These tools leverage models trained on vast amounts of code from numerous repositories, capturing general coding patterns.","However, the impact of fine-tuning these models for specific organizations or developers to boost their performance on such subjects remains unexplored.","In this work, we fill this gap by presenting solid empirical evidence answering this question.","More specifically, we consider 136 developers from two organizations (Apache and Spring), two model architectures (T5 and Code Llama), and three model sizes (60M, 750M, and 7B trainable parameters).","T5 models (60M, 750M) were pre-trained and fine-tuned on over 2,000 open-source projects, excluding the subject organizations' data, and compared against versions fine-tuned on organization- and developer-specific datasets.","For the Code Llama model (7B), we compared the performance of the already pre-trained model publicly available online with the same model fine-tuned via parameter-efficient fine-tuning on organization- and developer-specific datasets.","Our results show that there is a boost in prediction capabilities provided by both an organization-specific and a developer-specific additional fine-tuning, with the former being particularly performant.","Such a finding generalizes across (i) the two subject organizations (i.e., Apache and Spring) and (ii) models of completely different magnitude (from 60M to 7B trainable parameters).","Finally, we show that DL models fine-tuned on an organization-specific dataset achieve the same completion performance of pre-trained code models used out of the box and being $\\sim$10$\\times$ larger, with consequent savings in terms of deployment and inference cost (e.g., smaller GPUs needed)."],"url":"http://arxiv.org/abs/2503.14201v1"}
{"created":"2025-03-18 12:13:55","title":"Mapping Urban Villages in China: Progress and Challenges","abstract":"The shift toward high-quality urbanization has brought increased attention to the issue of \"urban villages\", which has become a prominent social problem in China. However, there is a lack of available geospatial data on urban villages, making it crucial to prioritize urban village mapping. In order to assess the current progress in urban village mapping and identify challenges and future directions, we have conducted a comprehensive review, which to the best of our knowledge is the first of its kind in this field. Our review begins by providing a clear context for urban villages and elaborating the method for literature review, then summarizes the study areas, data sources, and approaches used for urban village mapping in China. We also address the challenges and future directions for further research. Through thorough investigation, we find that current studies only cover very limited study areas and periods and lack sufficient investigation into the scalability, transferability, and interpretability of identification approaches due to the challenges in concept fuzziness and variances, spatial heterogeneity and variances of urban villages, and data availability. Future research can complement and further the current research in the following potential directions in order to achieve large-area mapping across the whole nation...","sentences":["The shift toward high-quality urbanization has brought increased attention to the issue of \"urban villages\", which has become a prominent social problem in China.","However, there is a lack of available geospatial data on urban villages, making it crucial to prioritize urban village mapping.","In order to assess the current progress in urban village mapping and identify challenges and future directions, we have conducted a comprehensive review, which to the best of our knowledge is the first of its kind in this field.","Our review begins by providing a clear context for urban villages and elaborating the method for literature review, then summarizes the study areas, data sources, and approaches used for urban village mapping in China.","We also address the challenges and future directions for further research.","Through thorough investigation, we find that current studies only cover very limited study areas and periods and lack sufficient investigation into the scalability, transferability, and interpretability of identification approaches due to the challenges in concept fuzziness and variances, spatial heterogeneity and variances of urban villages, and data availability.","Future research can complement and further the current research in the following potential directions in order to achieve large-area mapping across the whole nation..."],"url":"http://arxiv.org/abs/2503.14195v1"}
{"created":"2025-03-18 12:07:33","title":"Inferring Event Descriptions from Time Series with Language Models","abstract":"Time series data measure how environments change over time and drive decision-making in critical domains like finance and healthcare. When analyzing time series, we often seek to understand the underlying events occurring in the measured environment. For example, one might ask: What caused a sharp drop in the stock price? Events are often described with natural language, so we conduct the first study of whether Large Language Models (LLMs) can infer natural language events from time series. We curate a new benchmark featuring win probabilities collected from 4,200 basketball and American football games, featuring 1.7M timesteps with real value data and corresponding natural language events. Building on the recent wave of using LLMs on time series, we evaluate 16 LLMs and find that they demonstrate promising abilities to infer events from time series data. The open-weights DeepSeek-R1 32B model outperforms proprietary models like GPT-4o. Despite this impressive initial performance, we also find clear avenues to improve recent models, as we identify failures when altering the provided context, event sequence lengths, and evaluation strategy. (All resources needed to reproduce our work are available: https://github.com/BennyTMT/GAMETime)","sentences":["Time series data measure how environments change over time and drive decision-making in critical domains like finance and healthcare.","When analyzing time series, we often seek to understand the underlying events occurring in the measured environment.","For example, one might ask: What caused a sharp drop in the stock price?","Events are often described with natural language, so we conduct the first study of whether Large Language Models (LLMs) can infer natural language events from time series.","We curate a new benchmark featuring win probabilities collected from 4,200 basketball and American football games, featuring 1.7M timesteps with real value data and corresponding natural language events.","Building on the recent wave of using LLMs on time series, we evaluate 16 LLMs and find that they demonstrate promising abilities to infer events from time series data.","The open-weights DeepSeek-R1 32B model outperforms proprietary models like GPT-4o.","Despite this impressive initial performance, we also find clear avenues to improve recent models, as we identify failures when altering the provided context, event sequence lengths, and evaluation strategy.","(All resources needed to reproduce our work are available: https://github.com/BennyTMT/GAMETime)"],"url":"http://arxiv.org/abs/2503.14190v1"}
{"created":"2025-03-18 12:02:38","title":"Towards Harmless Multimodal Assistants with Blind Preference Optimization","abstract":"Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in multimodal understanding, reasoning, and interaction. Given the extensive applications of MLLMs, the associated safety issues have become increasingly critical. Due to the effectiveness of preference optimization in aligning MLLMs with human preferences, there is an urgent need for safety-related preference data for MLLMs. To address this, we construct the MMSafe-PO preference dataset towards harmless multimodal assistants, featuring multimodal instructions, the conversational format, and ranked paired responses from human feedback. We also identify two insightful observations: modality co-defense and modality cheating, which illustrate that MLLMs possess a certain level of inherent defense while still presenting unique safety challenges. Based on these observations, we propose the Blind Preference Optimization (BPO) approach. Comprehensive experiments on three benchmarks show that BPO effectively enhances the safety capabilities of MLLMs. Notably, BPO significantly improves the safety rate of the base MLLM by 45.0%, outperforming the DPO approach. Additionally, applying BPO to the MMSafe-PO dataset greatly reduces the base MLLM's unsafe rate on other safety benchmarks (14.5% on MM-SafetyBench and 82.9% on HarmEval, demonstrating the effectiveness and robustness of both the dataset and the approach. We release code and data at https://lu-yang666.github.io/MMsafe-PO-Web/.","sentences":["Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in multimodal understanding, reasoning, and interaction.","Given the extensive applications of MLLMs, the associated safety issues have become increasingly critical.","Due to the effectiveness of preference optimization in aligning MLLMs with human preferences, there is an urgent need for safety-related preference data for MLLMs.","To address this, we construct the MMSafe-PO preference dataset towards harmless multimodal assistants, featuring multimodal instructions, the conversational format, and ranked paired responses from human feedback.","We also identify two insightful observations: modality co-defense and modality cheating, which illustrate that MLLMs possess a certain level of inherent defense while still presenting unique safety challenges.","Based on these observations, we propose the Blind Preference Optimization (BPO) approach.","Comprehensive experiments on three benchmarks show that BPO effectively enhances the safety capabilities of MLLMs.","Notably, BPO significantly improves the safety rate of the base MLLM by 45.0%, outperforming the DPO approach.","Additionally, applying BPO to the MMSafe-PO dataset greatly reduces the base MLLM's unsafe rate on other safety benchmarks (14.5% on MM-SafetyBench and 82.9% on HarmEval, demonstrating the effectiveness and robustness of both the dataset and the approach.","We release code and data at https://lu-yang666.github.io/MMsafe-PO-Web/."],"url":"http://arxiv.org/abs/2503.14189v1"}
{"created":"2025-03-18 11:37:25","title":"Synthetic Clarification and Correction Dialogues about Data-Centric Tasks -- A Teacher-Student Approach","abstract":"Real dialogues with AI assistants for solving data-centric tasks often follow dynamic, unpredictable paths due to imperfect information provided by the user or in the data, which must be caught and handled. Developing datasets which capture such user-AI interactions is difficult and time-consuming. In this work, we develop a novel framework for synthetically generating controlled, multi-turn conversations between a user and AI assistant for the task of table-based question answering, which can be generated from an existing dataset with fully specified table QA examples for any target domain. Each conversation aims to solve a table-based reasoning question through collaborative effort, modeling one of two real-world scenarios: (1) an AI-initiated clarification, or (2) a user-initiated correction. Critically, we employ a strong teacher LLM to verify the correctness of our synthetic conversations, ensuring high quality. We demonstrate synthetic datasets generated from TAT-QA and WikiTableQuestions as benchmarks of frontier LLMs. We find that even larger models struggle to effectively issuing clarification questions and accurately integrate user feedback for corrections.","sentences":["Real dialogues with AI assistants for solving data-centric tasks often follow dynamic, unpredictable paths due to imperfect information provided by the user or in the data, which must be caught and handled.","Developing datasets which capture such user-AI interactions is difficult and time-consuming.","In this work, we develop a novel framework for synthetically generating controlled, multi-turn conversations between a user and AI assistant for the task of table-based question answering, which can be generated from an existing dataset with fully specified table QA examples for any target domain.","Each conversation aims to solve a table-based reasoning question through collaborative effort, modeling one of two real-world scenarios: (1) an AI-initiated clarification, or (2) a user-initiated correction.","Critically, we employ a strong teacher LLM to verify the correctness of our synthetic conversations, ensuring high quality.","We demonstrate synthetic datasets generated from TAT-QA and WikiTableQuestions as benchmarks of frontier LLMs.","We find that even larger models struggle to effectively issuing clarification questions and accurately integrate user feedback for corrections."],"url":"http://arxiv.org/abs/2503.14167v1"}
{"created":"2025-03-18 11:33:29","title":"EIAD: Explainable Industrial Anomaly Detection Via Multi-Modal Large Language Models","abstract":"Industrial Anomaly Detection (IAD) is critical to ensure product quality during manufacturing. Although existing zero-shot defect segmentation and detection methods have shown effectiveness, they cannot provide detailed descriptions of the defects. Furthermore, the application of large multi-modal models in IAD remains in its infancy, facing challenges in balancing question-answering (QA) performance and mask-based grounding capabilities, often owing to overfitting during the fine-tuning process. To address these challenges, we propose a novel approach that introduces a dedicated multi-modal defect localization module to decouple the dialog functionality from the core feature extraction. This decoupling is achieved through independent optimization objectives and tailored learning strategies. Additionally, we contribute to the first multi-modal industrial anomaly detection training dataset, named Defect Detection Question Answering (DDQA), encompassing a wide range of defect types and industrial scenarios. Unlike conventional datasets that rely on GPT-generated data, DDQA ensures authenticity and reliability and offers a robust foundation for model training. Experimental results demonstrate that our proposed method, Explainable Industrial Anomaly Detection Assistant (EIAD), achieves outstanding performance in defect detection and localization tasks. It not only significantly enhances accuracy but also improves interpretability. These advancements highlight the potential of EIAD for practical applications in industrial settings.","sentences":["Industrial Anomaly Detection (IAD) is critical to ensure product quality during manufacturing.","Although existing zero-shot defect segmentation and detection methods have shown effectiveness, they cannot provide detailed descriptions of the defects.","Furthermore, the application of large multi-modal models in IAD remains in its infancy, facing challenges in balancing question-answering (QA) performance and mask-based grounding capabilities, often owing to overfitting during the fine-tuning process.","To address these challenges, we propose a novel approach that introduces a dedicated multi-modal defect localization module to decouple the dialog functionality from the core feature extraction.","This decoupling is achieved through independent optimization objectives and tailored learning strategies.","Additionally, we contribute to the first multi-modal industrial anomaly detection training dataset, named Defect Detection Question Answering (DDQA), encompassing a wide range of defect types and industrial scenarios.","Unlike conventional datasets that rely on GPT-generated data, DDQA ensures authenticity and reliability and offers a robust foundation for model training.","Experimental results demonstrate that our proposed method, Explainable Industrial Anomaly Detection Assistant (EIAD), achieves outstanding performance in defect detection and localization tasks.","It not only significantly enhances accuracy but also improves interpretability.","These advancements highlight the potential of EIAD for practical applications in industrial settings."],"url":"http://arxiv.org/abs/2503.14162v1"}
{"created":"2025-03-18 11:16:48","title":"Comparative and Interpretative Analysis of CNN and Transformer Models in Predicting Wildfire Spread Using Remote Sensing Data","abstract":"Facing the escalating threat of global wildfires, numerous computer vision techniques using remote sensing data have been applied in this area. However, the selection of deep learning methods for wildfire prediction remains uncertain due to the lack of comparative analysis in a quantitative and explainable manner, crucial for improving prevention measures and refining models. This study aims to thoroughly compare the performance, efficiency, and explainability of four prevalent deep learning architectures: Autoencoder, ResNet, UNet, and Transformer-based Swin-UNet. Employing a real-world dataset that includes nearly a decade of remote sensing data from California, U.S., these models predict the spread of wildfires for the following day. Through detailed quantitative comparison analysis, we discovered that Transformer-based Swin-UNet and UNet generally outperform Autoencoder and ResNet, particularly due to the advanced attention mechanisms in Transformer-based Swin-UNet and the efficient use of skip connections in both UNet and Transformer-based Swin-UNet, which contribute to superior predictive accuracy and model interpretability. Then we applied XAI techniques on all four models, this not only enhances the clarity and trustworthiness of models but also promotes focused improvements in wildfire prediction capabilities. The XAI analysis reveals that UNet and Transformer-based Swin-UNet are able to focus on critical features such as 'Previous Fire Mask', 'Drought', and 'Vegetation' more effectively than the other two models, while also maintaining balanced attention to the remaining features, leading to their superior performance. The insights from our thorough comparative analysis offer substantial implications for future model design and also provide guidance for model selection in different scenarios.","sentences":["Facing the escalating threat of global wildfires, numerous computer vision techniques using remote sensing data have been applied in this area.","However, the selection of deep learning methods for wildfire prediction remains uncertain due to the lack of comparative analysis in a quantitative and explainable manner, crucial for improving prevention measures and refining models.","This study aims to thoroughly compare the performance, efficiency, and explainability of four prevalent deep learning architectures: Autoencoder, ResNet, UNet, and Transformer-based Swin-UNet.","Employing a real-world dataset that includes nearly a decade of remote sensing data from California, U.S., these models predict the spread of wildfires for the following day.","Through detailed quantitative comparison analysis, we discovered that Transformer-based Swin-UNet and UNet generally outperform Autoencoder and ResNet, particularly due to the advanced attention mechanisms in Transformer-based Swin-UNet and the efficient use of skip connections in both UNet and Transformer-based Swin-UNet, which contribute to superior predictive accuracy and model interpretability.","Then we applied XAI techniques on all four models, this not only enhances the clarity and trustworthiness of models but also promotes focused improvements in wildfire prediction capabilities.","The XAI analysis reveals that UNet and Transformer-based Swin-UNet are able to focus on critical features such as 'Previous Fire Mask', 'Drought', and 'Vegetation' more effectively than the other two models, while also maintaining balanced attention to the remaining features, leading to their superior performance.","The insights from our thorough comparative analysis offer substantial implications for future model design and also provide guidance for model selection in different scenarios."],"url":"http://arxiv.org/abs/2503.14150v1"}
{"created":"2025-03-18 11:12:14","title":"Petting Pen for Stress Awareness and Management in Children","abstract":"We found that children in elementary school often experience stress during task performance. Limited coping skills and lack of stress awareness restrict children's ability to manage their stress. Many designs and studies have proposed different stress detection and intervention solutions. Still, they often overlook the potential of enhancing everyday objects and actively sensing stress-related behavioral data during human-product interaction. Therefore, we propose Petting pen as an interactive robotic object for children to manage their stress during task performance. It detects and validates stress and further intervenes in stress during a process of natural writing and relaxation interactions. The design is an iteration based on our previous research results of a stress-aware pen, enhanced with tactile needs, robotic interaction, and integration of behavioral and bio-sensing capabilities. Petting pen is supposed to bridge the gap between robots and everyday objects in mental health applications for children.","sentences":["We found that children in elementary school often experience stress during task performance.","Limited coping skills and lack of stress awareness restrict children's ability to manage their stress.","Many designs and studies have proposed different stress detection and intervention solutions.","Still, they often overlook the potential of enhancing everyday objects and actively sensing stress-related behavioral data during human-product interaction.","Therefore, we propose Petting pen as an interactive robotic object for children to manage their stress during task performance.","It detects and validates stress and further intervenes in stress during a process of natural writing and relaxation interactions.","The design is an iteration based on our previous research results of a stress-aware pen, enhanced with tactile needs, robotic interaction, and integration of behavioral and bio-sensing capabilities.","Petting pen is supposed to bridge the gap between robots and everyday objects in mental health applications for children."],"url":"http://arxiv.org/abs/2503.14143v1"}
{"created":"2025-03-18 11:07:14","title":"Marten: Visual Question Answering with Mask Generation for Multi-modal Document Understanding","abstract":"Multi-modal Large Language Models (MLLMs) have introduced a novel dimension to document understanding, i.e., they endow large language models with visual comprehension capabilities; however, how to design a suitable image-text pre-training task for bridging the visual and language modality in document-level MLLMs remains underexplored. In this study, we introduce a novel visual-language alignment method that casts the key issue as a Visual Question Answering with Mask generation (VQAMask) task, optimizing two tasks simultaneously: VQA-based text parsing and mask generation. The former allows the model to implicitly align images and text at the semantic level. The latter introduces an additional mask generator (discarded during inference) to explicitly ensure alignment between visual texts within images and their corresponding image regions at a spatially-aware level. Together, they can prevent model hallucinations when parsing visual text and effectively promote spatially-aware feature representation learning. To support the proposed VQAMask task, we construct a comprehensive image-mask generation pipeline and provide a large-scale dataset with 6M data (MTMask6M). Subsequently, we demonstrate that introducing the proposed mask generation task yields competitive document-level understanding performance. Leveraging the proposed VQAMask, we introduce Marten, a training-efficient MLLM tailored for document-level understanding. Extensive experiments show that our Marten consistently achieves significant improvements among 8B-MLLMs in document-centric tasks. Code and datasets are available at https://github.com/PriNing/Marten.","sentences":["Multi-modal Large Language Models (MLLMs) have introduced a novel dimension to document understanding, i.e., they endow large language models with visual comprehension capabilities; however, how to design a suitable image-text pre-training task for bridging the visual and language modality in document-level MLLMs remains underexplored.","In this study, we introduce a novel visual-language alignment method that casts the key issue as a Visual Question Answering with Mask generation (VQAMask) task, optimizing two tasks simultaneously: VQA-based text parsing and mask generation.","The former allows the model to implicitly align images and text at the semantic level.","The latter introduces an additional mask generator (discarded during inference) to explicitly ensure alignment between visual texts within images and their corresponding image regions at a spatially-aware level.","Together, they can prevent model hallucinations when parsing visual text and effectively promote spatially-aware feature representation learning.","To support the proposed VQAMask task, we construct a comprehensive image-mask generation pipeline and provide a large-scale dataset with 6M data (MTMask6M).","Subsequently, we demonstrate that introducing the proposed mask generation task yields competitive document-level understanding performance.","Leveraging the proposed VQAMask, we introduce Marten, a training-efficient MLLM tailored for document-level understanding.","Extensive experiments show that our Marten consistently achieves significant improvements among 8B-MLLMs in document-centric tasks.","Code and datasets are available at https://github.com/PriNing/Marten."],"url":"http://arxiv.org/abs/2503.14140v1"}
{"created":"2025-03-18 11:07:00","title":"Exploring Stress among International College Students in China","abstract":"Psychological stress encompasses emotional tension and pressure experienced by people, which usually arises from situations people find challenging. However, more is needed to know about the pressures faced by international college students studying in China. The goal of this study is to investigate the various stressors that international college students in China face and how they cope with stress (coping mechanisms). Twenty international students were interviewed to gather data, which was then transcribed. Thematic analysis and coding were applied to the qualitative data, revealing themes related to the causes of stress. The following themes emerge from this data: anticipatory anxiety or future stress, social and cultural challenges, financial strain, and academic pressure. These themes will help understand the various stressors international college students in China face and how they try to cope. Studying how international college students in China cope with challenges can guide the development of targeted interventions to support their mental health. Research suggests that integrating aesthetics and connectivity into design interventions can notably improve the well-being of these students. This paper presents possible future design solutions, leveraging the aesthetics of connectivity to empower students and enhance their resilience. Additionally, it aims to provide valuable insights for designers interested in creating solutions that alleviate stress and promote emotional awareness among international students.","sentences":["Psychological stress encompasses emotional tension and pressure experienced by people, which usually arises from situations people find challenging.","However, more is needed to know about the pressures faced by international college students studying in China.","The goal of this study is to investigate the various stressors that international college students in China face and how they cope with stress (coping mechanisms).","Twenty international students were interviewed to gather data, which was then transcribed.","Thematic analysis and coding were applied to the qualitative data, revealing themes related to the causes of stress.","The following themes emerge from this data: anticipatory anxiety or future stress, social and cultural challenges, financial strain, and academic pressure.","These themes will help understand the various stressors international college students in China face and how they try to cope.","Studying how international college students in China cope with challenges can guide the development of targeted interventions to support their mental health.","Research suggests that integrating aesthetics and connectivity into design interventions can notably improve the well-being of these students.","This paper presents possible future design solutions, leveraging the aesthetics of connectivity to empower students and enhance their resilience.","Additionally, it aims to provide valuable insights for designers interested in creating solutions that alleviate stress and promote emotional awareness among international students."],"url":"http://arxiv.org/abs/2503.14139v1"}
{"created":"2025-03-18 10:58:10","title":"CARE: A QLoRA-Fine Tuned Multi-Domain Chatbot With Fast Learning On Minimal Hardware","abstract":"Large Language models have demonstrated excellent domain-specific question-answering capabilities when finetuned with a particular dataset of that specific domain. However, fine-tuning the models requires a significant amount of training time and a considerable amount of hardware. In this work, we propose CARE (Customer Assistance and Response Engine), a lightweight model made by fine-tuning Phi3.5-mini on very minimal hardware and data, designed to handle queries primarily across three domains: telecommunications support, medical support, and banking support. For telecommunications and banking, the chatbot addresses issues and problems faced by customers regularly in the above-mentioned domains. In the medical domain, CARE provides preliminary support by offering basic diagnoses and medical suggestions that a user might take before consulting a healthcare professional. Since CARE is built on Phi3.5-mini, it can be used even on mobile devices, increasing its usability. Our research also shows that CARE performs relatively well on various medical benchmarks, indicating that it can be used to make basic medical suggestions.","sentences":["Large Language models have demonstrated excellent domain-specific question-answering capabilities when finetuned with a particular dataset of that specific domain.","However, fine-tuning the models requires a significant amount of training time and a considerable amount of hardware.","In this work, we propose CARE (Customer Assistance and Response Engine), a lightweight model made by fine-tuning Phi3.5-mini on very minimal hardware and data, designed to handle queries primarily across three domains: telecommunications support, medical support, and banking support.","For telecommunications and banking, the chatbot addresses issues and problems faced by customers regularly in the above-mentioned domains.","In the medical domain, CARE provides preliminary support by offering basic diagnoses and medical suggestions that a user might take before consulting a healthcare professional.","Since CARE is built on Phi3.5-mini, it can be used even on mobile devices, increasing its usability.","Our research also shows that CARE performs relatively well on various medical benchmarks, indicating that it can be used to make basic medical suggestions."],"url":"http://arxiv.org/abs/2503.14136v1"}
{"created":"2025-03-18 10:34:09","title":"Efficient Greedy Discrete Subtrajectory Clustering","abstract":"We cluster a set of trajectories T using subtrajectories of T. Clustering quality may be measured by the number of clusters, the number of vertices of T that are absent from the clustering, and by the Fr\\'{e}chet distance between subtrajectories in a cluster. A $\\Delta$-cluster of T is a cluster ${\\mathcal{P}}$ of subtrajectories of T with a centre $P \\in {\\mathcal{P}}$ with complexity $\\ell$, where all subtrajectories in ${\\mathcal{P}}$ have Fr\\'{e}chet distance at most $\\Delta$ to $P$. Buchin, Buchin, Gudmundsson, L\\\"{o}ffler and Luo present two $O(n^2 + n m \\ell)$-time algorithms: SC($\\max$, $\\ell$, $\\Delta$, T) computes a single $\\Delta$-cluster where $P$ has at least $\\ell$ vertices and maximises the cardinality $m$ of ${\\mathcal{P}}$. SC($m$, $\\max$, $\\Delta$, T) computes a single $\\Delta$-cluster where ${\\mathcal{P}}$ has cardinality $m$ and maximises the complexity $\\ell$ of $P$.   We use such maximum-cardinality clusters in a greedy clustering algorithm. We provide an efficient implementation of SC($\\max$, $\\ell$, $\\Delta$, T) and SC($m$, $\\max$, $\\Delta$, T) that significantly outperforms previous implementations. We use these functions as a subroutine in a greedy clustering algorithm, which performs well when compared to existing subtrajectory clustering algorithms on real-world data. Finally, we observe that, for fixed $\\Delta$ and T, these two functions always output a point on the Pareto front of some bivariate function $\\theta(\\ell, m)$. We design a new algorithm PSC($\\Delta$, T) that in $O( n^2 \\log^4 n)$ time computes a $2$-approximation of this Pareto front. This yields a broader set of candidate clusters, with comparable quality. We show that using PSC($\\Delta$, T) as a subroutine improves the clustering quality and performance even further.","sentences":["We cluster a set of trajectories T using subtrajectories of T. Clustering quality may be measured by the number of clusters, the number of vertices of T that are absent from the clustering, and by the Fr\\'{e}chet distance between subtrajectories in a cluster.","A $\\Delta$-cluster of T is a cluster ${\\mathcal{P}}$ of subtrajectories of T with a centre $P \\in {\\mathcal{P}}$ with complexity $\\ell$, where all subtrajectories in ${\\mathcal{P}}$ have Fr\\'{e}chet distance at most $\\Delta$ to $P$. Buchin, Buchin, Gudmundsson, L\\\"{o}ffler and Luo present two $O(n^2 + n m \\ell)$-time algorithms: SC($\\max$, $\\ell$, $\\Delta$, T) computes a single $\\Delta$-cluster where $P$ has at least $\\ell$ vertices and maximises the cardinality $m$ of ${\\mathcal{P}}$. SC($m$, $\\max$, $\\Delta$, T) computes a single $\\Delta$-cluster where ${\\mathcal{P}}$ has cardinality $m$ and maximises the complexity $\\ell$ of $P$.   We use such maximum-cardinality clusters in a greedy clustering algorithm.","We provide an efficient implementation of SC($\\max$, $\\ell$, $\\Delta$, T) and SC($m$, $\\max$, $\\Delta$, T) that significantly outperforms previous implementations.","We use these functions as a subroutine in a greedy clustering algorithm, which performs well when compared to existing subtrajectory clustering algorithms on real-world data.","Finally, we observe that, for fixed $\\Delta$ and T, these two functions always output a point on the Pareto front of some bivariate function $\\theta(\\ell, m)$.","We design a new algorithm PSC($\\Delta$, T) that in $O( n^2 \\log^4 n)$ time computes a $2$-approximation of this Pareto front.","This yields a broader set of candidate clusters, with comparable quality.","We show that using PSC($\\Delta$, T) as a subroutine improves the clustering quality and performance even further."],"url":"http://arxiv.org/abs/2503.14115v1"}
{"created":"2025-03-18 10:29:47","title":"Condensing Action Segmentation Datasets via Generative Network Inversion","abstract":"This work presents the first condensation approach for procedural video datasets used in temporal action segmentation. We propose a condensation framework that leverages generative prior learned from the dataset and network inversion to condense data into compact latent codes with significant storage reduced across temporal and channel aspects. Orthogonally, we propose sampling diverse and representative action sequences to minimize video-wise redundancy. Our evaluation on standard benchmarks demonstrates consistent effectiveness in condensing TAS datasets and achieving competitive performances. Specifically, on the Breakfast dataset, our approach reduces storage by over 500$\\times$ while retaining 83% of the performance compared to training with the full dataset. Furthermore, when applied to a downstream incremental learning task, it yields superior performance compared to the state-of-the-art.","sentences":["This work presents the first condensation approach for procedural video datasets used in temporal action segmentation.","We propose a condensation framework that leverages generative prior learned from the dataset and network inversion to condense data into compact latent codes with significant storage reduced across temporal and channel aspects.","Orthogonally, we propose sampling diverse and representative action sequences to minimize video-wise redundancy.","Our evaluation on standard benchmarks demonstrates consistent effectiveness in condensing TAS datasets and achieving competitive performances.","Specifically, on the Breakfast dataset, our approach reduces storage by over 500$\\times$ while retaining 83% of the performance compared to training with the full dataset.","Furthermore, when applied to a downstream incremental learning task, it yields superior performance compared to the state-of-the-art."],"url":"http://arxiv.org/abs/2503.14112v1"}
{"created":"2025-03-18 10:25:28","title":"Operational Change Detection for Geographical Information: Overview and Challenges","abstract":"Rapid evolution of territories due to climate change and human impact requires prompt and effective updates to geospatial databases maintained by the National Mapping Agency. This paper presents a comprehensive overview of change detection methods tailored for the operational updating of large-scale geographic databases. This review first outlines the fundamental definition of change, emphasizing its multifaceted nature, from temporal to semantic characterization. It categorizes automatic change detection methods into four main families: rule-based, statistical, machine learning, and simulation methods. The strengths, limitations, and applicability of every family are discussed in the context of various input data. Then, key applications for National Mapping Agencies are identified, particularly the optimization of geospatial database updating, change-based phenomena, and dynamics monitoring. Finally, the paper highlights the current challenges for leveraging change detection such as the variability of change definition, the missing of relevant large-scale datasets, the diversity of input data, the unstudied no-change detection, the human in the loop integration and the operational constraints. The discussion underscores the necessity for ongoing innovation in change detection techniques to address the future needs of geographic information systems for national mapping agencies.","sentences":["Rapid evolution of territories due to climate change and human impact requires prompt and effective updates to geospatial databases maintained by the National Mapping Agency.","This paper presents a comprehensive overview of change detection methods tailored for the operational updating of large-scale geographic databases.","This review first outlines the fundamental definition of change, emphasizing its multifaceted nature, from temporal to semantic characterization.","It categorizes automatic change detection methods into four main families: rule-based, statistical, machine learning, and simulation methods.","The strengths, limitations, and applicability of every family are discussed in the context of various input data.","Then, key applications for National Mapping Agencies are identified, particularly the optimization of geospatial database updating, change-based phenomena, and dynamics monitoring.","Finally, the paper highlights the current challenges for leveraging change detection such as the variability of change definition, the missing of relevant large-scale datasets, the diversity of input data, the unstudied no-change detection, the human in the loop integration and the operational constraints.","The discussion underscores the necessity for ongoing innovation in change detection techniques to address the future needs of geographic information systems for national mapping agencies."],"url":"http://arxiv.org/abs/2503.14109v1"}
{"created":"2025-03-18 10:17:55","title":"Sensory-driven microinterventions for improved health and wellbeing","abstract":"The five senses are gateways to our wellbeing and their decline is considered a significant public health challenge which is linked to multiple conditions that contribute significantly to morbidity and mortality. Modern technology, with its ubiquitous nature and fast data processing has the ability to leverage the power of the senses to transform our approach to day to day healthcare, with positive effects on our quality of life. Here, we introduce the idea of sensory-driven microinterventions for preventative, personalised healthcare. Microinterventions are targeted, timely, minimally invasive strategies that seamlessly integrate into our daily life. This idea harnesses human's sensory capabilities, leverages technological advances in sensory stimulation and real-time processing ability for sensing the senses. The collection of sensory data from our continuous interaction with technology - for example the tone of voice, gait movement, smart home behaviour - opens up a shift towards personalised technology-enabled, sensory-focused healthcare interventions, coupled with the potential of early detection and timely treatment of sensory deficits that can signal critical health insights, especially for neurodegenerative diseases such as Parkinson's disease.","sentences":["The five senses are gateways to our wellbeing and their decline is considered a significant public health challenge which is linked to multiple conditions that contribute significantly to morbidity and mortality.","Modern technology, with its ubiquitous nature and fast data processing has the ability to leverage the power of the senses to transform our approach to day to day healthcare, with positive effects on our quality of life.","Here, we introduce the idea of sensory-driven microinterventions for preventative, personalised healthcare.","Microinterventions are targeted, timely, minimally invasive strategies that seamlessly integrate into our daily life.","This idea harnesses human's sensory capabilities, leverages technological advances in sensory stimulation and real-time processing ability for sensing the senses.","The collection of sensory data from our continuous interaction with technology - for example the tone of voice, gait movement, smart home behaviour - opens up a shift towards personalised technology-enabled, sensory-focused healthcare interventions, coupled with the potential of early detection and timely treatment of sensory deficits that can signal critical health insights, especially for neurodegenerative diseases such as Parkinson's disease."],"url":"http://arxiv.org/abs/2503.14102v1"}
{"created":"2025-03-18 10:09:10","title":"Wiki-Quantities and Wiki-Measurements: Datasets of Quantities and their Measurement Context from Wikipedia","abstract":"To cope with the large number of publications, more and more researchers are automatically extracting data of interest using natural language processing methods based on supervised learning. Much data, especially in the natural and engineering sciences, is quantitative, but there is a lack of datasets for identifying quantities and their context in text. To address this issue, we present two large datasets based on Wikipedia and Wikidata: Wiki-Quantities is a dataset consisting of over 1.2 million annotated quantities in the English-language Wikipedia. Wiki-Measurements is a dataset of 38,738 annotated quantities in the English-language Wikipedia along with their respective measured entity, property, and optional qualifiers. Manual validation of 100 samples each of Wiki-Quantities and Wiki-Measurements found 100% and 84-94% correct, respectively. The datasets can be used in pipeline approaches to measurement extraction, where quantities are first identified and then their measurement context. To allow reproduction of this work using newer or different versions of Wikipedia and Wikidata, we publish the code used to create the datasets along with the data.","sentences":["To cope with the large number of publications, more and more researchers are automatically extracting data of interest using natural language processing methods based on supervised learning.","Much data, especially in the natural and engineering sciences, is quantitative, but there is a lack of datasets for identifying quantities and their context in text.","To address this issue, we present two large datasets based on Wikipedia and Wikidata: Wiki-Quantities is a dataset consisting of over 1.2 million annotated quantities in the English-language Wikipedia.","Wiki-Measurements is a dataset of 38,738 annotated quantities in the English-language Wikipedia along with their respective measured entity, property, and optional qualifiers.","Manual validation of 100 samples each of Wiki-Quantities and Wiki-Measurements found 100% and 84-94% correct, respectively.","The datasets can be used in pipeline approaches to measurement extraction, where quantities are first identified and then their measurement context.","To allow reproduction of this work using newer or different versions of Wikipedia and Wikidata, we publish the code used to create the datasets along with the data."],"url":"http://arxiv.org/abs/2503.14090v1"}
{"created":"2025-03-18 09:53:48","title":"Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency","abstract":"Recent studies suggest utilizing generative models instead of traditional auto-regressive algorithms for time series forecasting (TSF) tasks. These non-auto-regressive approaches involving different generative methods, including GAN, Diffusion, and Flow Matching for time series, have empirically demonstrated high-quality generation capability and accuracy. However, we still lack an appropriate understanding of how it processes approximation and generalization. This paper presents the first theoretical framework from the perspective of flow-based generative models to relieve the knowledge of limitations. In particular, we provide our insights with strict guarantees from three perspectives: $\\textbf{Approximation}$, $\\textbf{Generalization}$ and $\\textbf{Efficiency}$. In detail, our analysis achieves the contributions as follows:   $\\bullet$ By assuming a general data model, the fitting of the flow-based generative models is confirmed to converge to arbitrary error under the universal approximation of Diffusion Transformer (DiT).   $\\bullet$ Introducing a polynomial-based regularization for flow matching, the generalization error thus be bounded since the generalization of polynomial approximation.   $\\bullet$ The sampling for generation is considered as an optimization process, we demonstrate its fast convergence with updating standard first-order gradient descent of some objective.","sentences":["Recent studies suggest utilizing generative models instead of traditional auto-regressive algorithms for time series forecasting (TSF) tasks.","These non-auto-regressive approaches involving different generative methods, including GAN, Diffusion, and Flow Matching for time series, have empirically demonstrated high-quality generation capability and accuracy.","However, we still lack an appropriate understanding of how it processes approximation and generalization.","This paper presents the first theoretical framework from the perspective of flow-based generative models to relieve the knowledge of limitations.","In particular, we provide our insights with strict guarantees from three perspectives: $\\textbf{Approximation}$, $\\textbf{Generalization}$ and $\\textbf{Efficiency}$. In detail, our analysis achieves the contributions as follows:   $\\bullet$ By assuming a general data model, the fitting of the flow-based generative models is confirmed to converge to arbitrary error under the universal approximation of Diffusion Transformer (DiT).   ","$\\bullet$ Introducing a polynomial-based regularization for flow matching, the generalization error thus be bounded since the generalization of polynomial approximation.   ","$\\bullet$ The sampling for generation is considered as an optimization process, we demonstrate its fast convergence with updating standard first-order gradient descent of some objective."],"url":"http://arxiv.org/abs/2503.14076v1"}
{"created":"2025-03-18 09:40:19","title":"Streamlining SIMD ISA Extensions with Takum Arithmetic: A Case Study on Intel AVX10.2","abstract":"Modern microprocessors extend their instruction set architecture (ISA) with Single Instruction, Multiple Data (SIMD) operations to improve performance. The Intel Advanced Vector Extensions (AVX) enhance the x86 ISA and are widely supported in Intel and AMD processors. The latest version, AVX10.2, places a strong emphasis on low-precision, non-standard floating-point formats, including bfloat16 and E4M3/E5M2 float8 (OCP 8-bit Floating Point, OFP8), primarily catering to deep learning applications rather than general-purpose arithmetic. However, as these formats remain within the IEEE 754 framework, they inherit its limitations, introducing inconsistencies and added complexity into the ISA.   This paper examines the recently proposed tapered-precision takum floating-point format, which has been shown to offer significant advantages over IEEE 754 and its derivatives as a general-purpose number format. Using AVX10.2 as a case study, the paper explores the potential benefits of replacing the multitude of floating-point formats with takum as a uniform basis. The results indicate a more consistent instruction set, improving readability and flexibility while offering potential for 8- and 16-bit general-purpose SIMD arithmetic.","sentences":["Modern microprocessors extend their instruction set architecture (ISA) with Single Instruction, Multiple Data (SIMD) operations to improve performance.","The Intel Advanced Vector Extensions (AVX) enhance the x86 ISA and are widely supported in Intel and AMD processors.","The latest version, AVX10.2, places a strong emphasis on low-precision, non-standard floating-point formats, including bfloat16 and E4M3/E5M2 float8 (OCP 8-bit Floating Point, OFP8), primarily catering to deep learning applications rather than general-purpose arithmetic.","However, as these formats remain within the IEEE 754 framework, they inherit its limitations, introducing inconsistencies and added complexity into the ISA.   ","This paper examines the recently proposed tapered-precision takum floating-point format, which has been shown to offer significant advantages over IEEE 754 and its derivatives as a general-purpose number format.","Using AVX10.2 as a case study, the paper explores the potential benefits of replacing the multitude of floating-point formats with takum as a uniform basis.","The results indicate a more consistent instruction set, improving readability and flexibility while offering potential for 8- and 16-bit general-purpose SIMD arithmetic."],"url":"http://arxiv.org/abs/2503.14067v1"}
{"created":"2025-03-18 09:36:26","title":"Effect of Hotspot Traffic on Blocking Probability in Elastic Optical Networks","abstract":"In a circuit-switched network, traffic can be characterized by several factors that define how communication resources are allocated and utilized during a connection. The amount of traffic basically determines how frequently connection requests arrive, how long the setup connection remains active, and the bandwidth used. The Poisson Arrival Process models traffic arrival events at random intervals. It assumes that events happen independently of one another. This model is ideal for simulating traffic in networks where arrivals happen independently and randomly, such as the start of phone calls, data requests, or packet transmissions. The Poisson Arrival Process and uniformly choosing source and destination pair is been used most commonly by researchers to generate traffic in a network to test various promising routing and spectrum assignment algorithms. It checks the algorithm in uniformly loaded conditions and estimate its baseline performance. In real real-world scenario, a bunch of network nodes can start experiencing heavy data traffic compared to the rest of the network. This can lead to latency issues, or even outages if the network is not optimized to handle the load at these nodes which are also called hotspots. In other terms, hotspot in a network is an area or set of nodes within the network that have a higher likelihood of being involved in communication or data transmission compared to other areas. In this paper, we have tried to find what are the various factors involved in increasing the blocking probability in hotspot traffic scenarios. We have also compared the results with the uniform traffic load conditions in same topology.","sentences":["In a circuit-switched network, traffic can be characterized by several factors that define how communication resources are allocated and utilized during a connection.","The amount of traffic basically determines how frequently connection requests arrive, how long the setup connection remains active, and the bandwidth used.","The Poisson Arrival Process models traffic arrival events at random intervals.","It assumes that events happen independently of one another.","This model is ideal for simulating traffic in networks where arrivals happen independently and randomly, such as the start of phone calls, data requests, or packet transmissions.","The Poisson Arrival Process and uniformly choosing source and destination pair is been used most commonly by researchers to generate traffic in a network to test various promising routing and spectrum assignment algorithms.","It checks the algorithm in uniformly loaded conditions and estimate its baseline performance.","In real real-world scenario, a bunch of network nodes can start experiencing heavy data traffic compared to the rest of the network.","This can lead to latency issues, or even outages if the network is not optimized to handle the load at these nodes which are also called hotspots.","In other terms, hotspot in a network is an area or set of nodes within the network that have a higher likelihood of being involved in communication or data transmission compared to other areas.","In this paper, we have tried to find what are the various factors involved in increasing the blocking probability in hotspot traffic scenarios.","We have also compared the results with the uniform traffic load conditions in same topology."],"url":"http://arxiv.org/abs/2503.14063v1"}
{"created":"2025-03-18 09:13:24","title":"ON-Traffic: An Operator Learning Framework for Online Traffic Flow Estimation and Uncertainty Quantification from Lagrangian Sensors","abstract":"Accurate traffic flow estimation and prediction are critical for the efficient management of transportation systems, particularly under increasing urbanization. Traditional methods relying on static sensors often suffer from limited spatial coverage, while probe vehicles provide richer, albeit sparse and irregular data. This work introduces ON-Traffic, a novel deep operator Network and a receding horizon learning-based framework tailored for online estimation of spatio-temporal traffic state along with quantified uncertainty by using measurements from moving probe vehicles and downstream boundary inputs. Our framework is evaluated in both numerical and simulation datasets, showcasing its ability to handle irregular, sparse input data, adapt to time-shifted scenarios, and provide well-calibrated uncertainty estimates. The results demonstrate that the model captures complex traffic phenomena, including shockwaves and congestion propagation, while maintaining robustness to noise and sensor dropout. These advancements present a significant step toward online, adaptive traffic management systems.","sentences":["Accurate traffic flow estimation and prediction are critical for the efficient management of transportation systems, particularly under increasing urbanization.","Traditional methods relying on static sensors often suffer from limited spatial coverage, while probe vehicles provide richer, albeit sparse and irregular data.","This work introduces ON-Traffic, a novel deep operator Network and a receding horizon learning-based framework tailored for online estimation of spatio-temporal traffic state along with quantified uncertainty by using measurements from moving probe vehicles and downstream boundary inputs.","Our framework is evaluated in both numerical and simulation datasets, showcasing its ability to handle irregular, sparse input data, adapt to time-shifted scenarios, and provide well-calibrated uncertainty estimates.","The results demonstrate that the model captures complex traffic phenomena, including shockwaves and congestion propagation, while maintaining robustness to noise and sensor dropout.","These advancements present a significant step toward online, adaptive traffic management systems."],"url":"http://arxiv.org/abs/2503.14053v1"}
{"created":"2025-03-18 09:04:37","title":"Learning on LLM Output Signatures for gray-box LLM Behavior Analysis","abstract":"Large Language Models (LLMs) have achieved widespread adoption, yet our understanding of their behavior remains limited, particularly in detecting data contamination and hallucinations. While recently proposed probing techniques provide insights through activation analysis, they require \"white-box\" access to model internals, often unavailable. Current \"gray-box\" approaches typically analyze only the probability of the actual tokens in the sequence with simple task-specific heuristics. Importantly, these methods overlook the rich information contained in the full token distribution at each processing step. To address these limitations, we propose that gray-box analysis should leverage the complete observable output of LLMs, consisting of both the previously used token probabilities as well as the complete token distribution sequences - a unified data type we term LOS (LLM Output Signature). To this end, we develop a transformer-based approach to process LOS that theoretically guarantees approximation of existing techniques while enabling more nuanced analysis. Our approach achieves superior performance on hallucination and data contamination detection in gray-box settings, significantly outperforming existing baselines. Furthermore, it demonstrates strong transfer capabilities across datasets and LLMs, suggesting that LOS captures fundamental patterns in LLM behavior. Our code is available at: https://github.com/BarSGuy/LLM-Output-Signatures-Network.","sentences":["Large Language Models (LLMs) have achieved widespread adoption, yet our understanding of their behavior remains limited, particularly in detecting data contamination and hallucinations.","While recently proposed probing techniques provide insights through activation analysis, they require \"white-box\" access to model internals, often unavailable.","Current \"gray-box\" approaches typically analyze only the probability of the actual tokens in the sequence with simple task-specific heuristics.","Importantly, these methods overlook the rich information contained in the full token distribution at each processing step.","To address these limitations, we propose that gray-box analysis should leverage the complete observable output of LLMs, consisting of both the previously used token probabilities as well as the complete token distribution sequences - a unified data type we term LOS (LLM Output Signature).","To this end, we develop a transformer-based approach to process LOS that theoretically guarantees approximation of existing techniques while enabling more nuanced analysis.","Our approach achieves superior performance on hallucination and data contamination detection in gray-box settings, significantly outperforming existing baselines.","Furthermore, it demonstrates strong transfer capabilities across datasets and LLMs, suggesting that LOS captures fundamental patterns in LLM behavior.","Our code is available at: https://github.com/BarSGuy/LLM-Output-Signatures-Network."],"url":"http://arxiv.org/abs/2503.14043v1"}
{"created":"2025-03-18 08:34:03","title":"Synthetic Data Generation Using Large Language Models: Advances in Text and Code","abstract":"Large language models (LLMs) have unlocked new possibilities for generating synthetic training data in both natural language and code. By producing artificial but task-relevant examples, these models can significantly augment or even replace real-world datasets, especially when labeled data is scarce or sensitive. This paper surveys recent advances in using LLMs to create synthetic text and code, emphasizing prompt-based generation, retrieval-augmented pipelines, and iterative self-refinement. We show how these methods enrich low-resource tasks such as classification and question answering, as well as code-centric applications such as instruction tuning, code translation, and bug repair, by enabling automated verification of functional correctness. Alongside potential benefits like cost-effectiveness, broad coverage, and controllable diversity, we address challenges such as factual inaccuracies in generated text, lack of stylistic realism, and the risk of bias amplification. Proposed mitigations include filtering and weighting outputs and reinforcement learning with execution feedback for code. We conclude with open research directions like automated prompt engineering, cross-modal data synthesis, and robust evaluation frameworks, highlighting the importance of LLM-generated synthetic data in advancing AI while emphasizing ethical and quality safeguards.","sentences":["Large language models (LLMs) have unlocked new possibilities for generating synthetic training data in both natural language and code.","By producing artificial but task-relevant examples, these models can significantly augment or even replace real-world datasets, especially when labeled data is scarce or sensitive.","This paper surveys recent advances in using LLMs to create synthetic text and code, emphasizing prompt-based generation, retrieval-augmented pipelines, and iterative self-refinement.","We show how these methods enrich low-resource tasks such as classification and question answering, as well as code-centric applications such as instruction tuning, code translation, and bug repair, by enabling automated verification of functional correctness.","Alongside potential benefits like cost-effectiveness, broad coverage, and controllable diversity, we address challenges such as factual inaccuracies in generated text, lack of stylistic realism, and the risk of bias amplification.","Proposed mitigations include filtering and weighting outputs and reinforcement learning with execution feedback for code.","We conclude with open research directions like automated prompt engineering, cross-modal data synthesis, and robust evaluation frameworks, highlighting the importance of LLM-generated synthetic data in advancing AI while emphasizing ethical and quality safeguards."],"url":"http://arxiv.org/abs/2503.14023v1"}
{"created":"2025-03-18 08:32:22","title":"MP-GUI: Modality Perception with MLLMs for GUI Understanding","abstract":"Graphical user interface (GUI) has become integral to modern society, making it crucial to be understood for human-centric systems. However, unlike natural images or documents, GUIs comprise artificially designed graphical elements arranged to convey specific semantic meanings. Current multi-modal large language models (MLLMs) already proficient in processing graphical and textual components suffer from hurdles in GUI understanding due to the lack of explicit spatial structure modeling. Moreover, obtaining high-quality spatial structure data is challenging due to privacy issues and noisy environments. To address these challenges, we present MP-GUI, a specially designed MLLM for GUI understanding. MP-GUI features three precisely specialized perceivers to extract graphical, textual, and spatial modalities from the screen as GUI-tailored visual clues, with spatial structure refinement strategy and adaptively combined via a fusion gate to meet the specific preferences of different GUI understanding tasks. To cope with the scarcity of training data, we also introduce a pipeline for automatically data collecting. Extensive experiments demonstrate that MP-GUI achieves impressive results on various GUI understanding tasks with limited data.","sentences":["Graphical user interface (GUI) has become integral to modern society, making it crucial to be understood for human-centric systems.","However, unlike natural images or documents, GUIs comprise artificially designed graphical elements arranged to convey specific semantic meanings.","Current multi-modal large language models (MLLMs) already proficient in processing graphical and textual components suffer from hurdles in GUI understanding due to the lack of explicit spatial structure modeling.","Moreover, obtaining high-quality spatial structure data is challenging due to privacy issues and noisy environments.","To address these challenges, we present MP-GUI, a specially designed MLLM for GUI understanding.","MP-GUI features three precisely specialized perceivers to extract graphical, textual, and spatial modalities from the screen as GUI-tailored visual clues, with spatial structure refinement strategy and adaptively combined via a fusion gate to meet the specific preferences of different GUI understanding tasks.","To cope with the scarcity of training data, we also introduce a pipeline for automatically data collecting.","Extensive experiments demonstrate that MP-GUI achieves impressive results on various GUI understanding tasks with limited data."],"url":"http://arxiv.org/abs/2503.14021v1"}
{"created":"2025-03-18 08:20:35","title":"Boosting Semi-Supervised Medical Image Segmentation via Masked Image Consistency and Discrepancy Learning","abstract":"Semi-supervised learning is of great significance in medical image segmentation by exploiting unlabeled data. Among its strategies, the co-training framework is prominent. However, previous co-training studies predominantly concentrate on network initialization variances and pseudo-label generation, while overlooking the equilibrium between information interchange and model diversity preservation. In this paper, we propose the Masked Image Consistency and Discrepancy Learning (MICD) framework with three key modules. The Masked Cross Pseudo Consistency (MCPC) module enriches context perception and small sample learning via pseudo-labeling across masked-input branches. The Cross Feature Consistency (CFC) module fortifies information exchange and model robustness by ensuring decoder feature consistency. The Cross Model Discrepancy (CMD) module utilizes EMA teacher networks to oversee outputs and preserve branch diversity. Together, these modules address existing limitations by focusing on fine-grained local information and maintaining diversity in a heterogeneous framework. Experiments on two public medical image datasets, AMOS and Synapse, demonstrate that our approach outperforms state-of-the-art methods.","sentences":["Semi-supervised learning is of great significance in medical image segmentation by exploiting unlabeled data.","Among its strategies, the co-training framework is prominent.","However, previous co-training studies predominantly concentrate on network initialization variances and pseudo-label generation, while overlooking the equilibrium between information interchange and model diversity preservation.","In this paper, we propose the Masked Image Consistency and Discrepancy Learning (MICD) framework with three key modules.","The Masked Cross Pseudo Consistency (MCPC) module enriches context perception and small sample learning via pseudo-labeling across masked-input branches.","The Cross Feature Consistency (CFC) module fortifies information exchange and model robustness by ensuring decoder feature consistency.","The Cross Model Discrepancy (CMD) module utilizes EMA teacher networks to oversee outputs and preserve branch diversity.","Together, these modules address existing limitations by focusing on fine-grained local information and maintaining diversity in a heterogeneous framework.","Experiments on two public medical image datasets, AMOS and Synapse, demonstrate that our approach outperforms state-of-the-art methods."],"url":"http://arxiv.org/abs/2503.14013v1"}
{"created":"2025-03-18 08:09:24","title":"MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling","abstract":"Generative models have recently made remarkable progress in the field of 3D objects. However, their practical application in fields like engineering remains limited since they fail to deliver the accuracy, quality, and controllability needed for domain-specific tasks. Fine-tuning large generative models is a promising perspective for making these models available in these fields. Creating high-quality, domain-specific 3D datasets is crucial for fine-tuning large generative models, yet the data filtering and annotation process remains a significant bottleneck. We present MeshFleet, a filtered and annotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive publicly available collection of 3D objects. Our approach proposes a pipeline for automated data filtering based on a quality classifier. This classifier is trained on a manually labeled subset of Objaverse, incorporating DINOv2 and SigLIP embeddings, refined through caption-based analysis and uncertainty estimation. We demonstrate the efficacy of our filtering method through a comparative analysis against caption and image aesthetic score-based techniques and fine-tuning experiments with SV3D, highlighting the importance of targeted data selection for domain-specific 3D generative modeling.","sentences":["Generative models have recently made remarkable progress in the field of 3D objects.","However, their practical application in fields like engineering remains limited since they fail to deliver the accuracy, quality, and controllability needed for domain-specific tasks.","Fine-tuning large generative models is a promising perspective for making these models available in these fields.","Creating high-quality, domain-specific 3D datasets is crucial for fine-tuning large generative models, yet the data filtering and annotation process remains a significant bottleneck.","We present MeshFleet, a filtered and annotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive publicly available collection of 3D objects.","Our approach proposes a pipeline for automated data filtering based on a quality classifier.","This classifier is trained on a manually labeled subset of Objaverse, incorporating DINOv2 and SigLIP embeddings, refined through caption-based analysis and uncertainty estimation.","We demonstrate the efficacy of our filtering method through a comparative analysis against caption and image aesthetic score-based techniques and fine-tuning experiments with SV3D, highlighting the importance of targeted data selection for domain-specific 3D generative modeling."],"url":"http://arxiv.org/abs/2503.14002v1"}
{"created":"2025-03-18 08:09:19","title":"Multimodal Feature-Driven Deep Learning for the Prediction of Duck Body Dimensions and Weight","abstract":"Accurate body dimension and weight measurements are critical for optimizing poultry management, health assessment, and economic efficiency. This study introduces an innovative deep learning-based model leveraging multimodal data-2D RGB images from different views, depth images, and 3D point clouds-for the non-invasive estimation of duck body dimensions and weight. A dataset of 1,023 Linwu ducks, comprising over 5,000 samples with diverse postures and conditions, was collected to support model training. The proposed method innovatively employs PointNet++ to extract key feature points from point clouds, extracts and computes corresponding 3D geometric features, and fuses them with multi-view convolutional 2D features. A Transformer encoder is then utilized to capture long-range dependencies and refine feature interactions, thereby enhancing prediction robustness. The model achieved a mean absolute percentage error (MAPE) of 6.33% and an R2 of 0.953 across eight morphometric parameters, demonstrating strong predictive capability. Unlike conventional manual measurements, the proposed model enables high-precision estimation while eliminating the necessity for physical handling, thereby reducing animal stress and broadening its application scope. This study marks the first application of deep learning techniques to poultry body dimension and weight estimation, providing a valuable reference for the intelligent and precise management of the livestock industry with far-reaching practical significance.","sentences":["Accurate body dimension and weight measurements are critical for optimizing poultry management, health assessment, and economic efficiency.","This study introduces an innovative deep learning-based model leveraging multimodal data-2D RGB images from different views, depth images, and 3D point clouds-for the non-invasive estimation of duck body dimensions and weight.","A dataset of 1,023 Linwu ducks, comprising over 5,000 samples with diverse postures and conditions, was collected to support model training.","The proposed method innovatively employs PointNet++ to extract key feature points from point clouds, extracts and computes corresponding 3D geometric features, and fuses them with multi-view convolutional 2D features.","A Transformer encoder is then utilized to capture long-range dependencies and refine feature interactions, thereby enhancing prediction robustness.","The model achieved a mean absolute percentage error (MAPE) of 6.33% and an R2 of 0.953 across eight morphometric parameters, demonstrating strong predictive capability.","Unlike conventional manual measurements, the proposed model enables high-precision estimation while eliminating the necessity for physical handling, thereby reducing animal stress and broadening its application scope.","This study marks the first application of deep learning techniques to poultry body dimension and weight estimation, providing a valuable reference for the intelligent and precise management of the livestock industry with far-reaching practical significance."],"url":"http://arxiv.org/abs/2503.14001v1"}
{"created":"2025-03-18 07:52:04","title":"The KoLMogorov Test: Compression by Code Generation","abstract":"Compression is at the heart of intelligence. A theoretically optimal way to compress any sequence of data is to find the shortest program that outputs that sequence and then halts. However, such 'Kolmogorov compression' is uncomputable, and code generating LLMs struggle to approximate this theoretical ideal, as it requires reasoning, planning and search capabilities beyond those of current models. In this work, we introduce the KoLMogorov-Test (KT), a compression-as-intelligence test for code generating LLMs. In KT a model is presented with a sequence of data at inference time, and asked to generate the shortest program that produces the sequence. We identify several benefits of KT for both evaluation and training: an essentially infinite number of problem instances of varying difficulty is readily available, strong baselines already exist, the evaluation metric (compression) cannot be gamed, and pretraining data contamination is highly unlikely. To evaluate current models, we use audio, text, and DNA data, as well as sequences produced by random synthetic programs. Current flagship models perform poorly - both GPT4-o and Llama-3.1-405B struggle on our natural and synthetic sequences. On our synthetic distribution, we are able to train code generation models with lower compression rates than previous approaches. Moreover, we show that gains on synthetic data generalize poorly to real data, suggesting that new innovations are necessary for additional gains on KT.","sentences":["Compression is at the heart of intelligence.","A theoretically optimal way to compress any sequence of data is to find the shortest program that outputs that sequence and then halts.","However, such 'Kolmogorov compression' is uncomputable, and code generating LLMs struggle to approximate this theoretical ideal, as it requires reasoning, planning and search capabilities beyond those of current models.","In this work, we introduce the KoLMogorov-Test (KT), a compression-as-intelligence test for code generating LLMs.","In KT a model is presented with a sequence of data at inference time, and asked to generate the shortest program that produces the sequence.","We identify several benefits of KT for both evaluation and training: an essentially infinite number of problem instances of varying difficulty is readily available, strong baselines already exist, the evaluation metric (compression) cannot be gamed, and pretraining data contamination is highly unlikely.","To evaluate current models, we use audio, text, and DNA data, as well as sequences produced by random synthetic programs.","Current flagship models perform poorly - both GPT4-o and Llama-3.1-405B struggle on our natural and synthetic sequences.","On our synthetic distribution, we are able to train code generation models with lower compression rates than previous approaches.","Moreover, we show that gains on synthetic data generalize poorly to real data, suggesting that new innovations are necessary for additional gains on KT."],"url":"http://arxiv.org/abs/2503.13992v1"}
{"created":"2025-03-18 07:42:11","title":"DefectFill: Realistic Defect Generation with Inpainting Diffusion Model for Visual Inspection","abstract":"Developing effective visual inspection models remains challenging due to the scarcity of defect data. While image generation models have been used to synthesize defect images, producing highly realistic defects remains difficult. We propose DefectFill, a novel method for realistic defect generation that requires only a few reference defect images. It leverages a fine-tuned inpainting diffusion model, optimized with our custom loss functions incorporating defect, object, and attention terms. It enables precise capture of detailed, localized defect features and their seamless integration into defect-free objects. Additionally, our Low-Fidelity Selection method further enhances the defect sample quality. Experiments show that DefectFill generates high-quality defect images, enabling visual inspection models to achieve state-of-the-art performance on the MVTec AD dataset.","sentences":["Developing effective visual inspection models remains challenging due to the scarcity of defect data.","While image generation models have been used to synthesize defect images, producing highly realistic defects remains difficult.","We propose DefectFill, a novel method for realistic defect generation that requires only a few reference defect images.","It leverages a fine-tuned inpainting diffusion model, optimized with our custom loss functions incorporating defect, object, and attention terms.","It enables precise capture of detailed, localized defect features and their seamless integration into defect-free objects.","Additionally, our Low-Fidelity Selection method further enhances the defect sample quality.","Experiments show that DefectFill generates high-quality defect images, enabling visual inspection models to achieve state-of-the-art performance on the MVTec AD dataset."],"url":"http://arxiv.org/abs/2503.13985v1"}
{"created":"2025-03-18 07:40:54","title":"Color-Constrained Arborescences in Edge-Colored Digraphs","abstract":"Given a multigraph $G$ whose edges are colored from the set $[q]:=\\{1,2,\\ldots,q\\}$ (\\emph{$q$-colored graph}), and a vector $\\alpha=(\\alpha_1,\\ldots,\\alpha_{q}) \\in \\mathbb{N}^{q}$ (\\emph{color-constraint}), a subgraph $H$ of $G$ is called \\emph{$\\alpha$-colored}, if $H$ has exactly $\\alpha_i$ edges of color $i$ for each $i \\in[q]$. In this paper, we focus on $\\alpha$-colored arborescences (spanning out-trees) in $q$-colored multidigraphs. We study the decision, counting and search versions of this problem. It is known that the decision and search problems are polynomial-time solvable when $q=2$ and that the decision problem is NP-complete when $q$ is arbitrary. However the complexity status of the problem for fixed $q$ was open for $q > 2$. We show that, for a $q$-colored digraph $G$ and a vertex $s$ in $G$, the number of $\\alpha$-colored arborescences in $G$ rooted at $s$ for all color-constraints $\\alpha \\in \\mathbb{N}^q$ can be read from the determinant of a symbolic matrix in $q-1$ indeterminates. This result extends Tutte's matrix-tree theorem for directed graphs and gives a polynomial-time algorithm for the counting and decision problems for fixed $q$. We also use it to design an algorithm that finds an $\\alpha$-colored arborescence when one exists. Finally, we study the weighted variant of the problem and give a polynomial-time algorithm (when $q$ is fixed) which finds a minimum weight solution.","sentences":["Given a multigraph $G$ whose edges are colored from the set $[q]:=\\{1,2,\\ldots,q\\}$ (\\emph{$q$-colored graph}), and a vector $\\alpha=(\\alpha_1,\\ldots,\\alpha_{q}) \\in \\mathbb{N}^{q}$ (\\emph{color-constraint}), a subgraph $H$ of $G$ is called \\emph{$\\alpha$-colored}, if $H$ has exactly $\\alpha_i$ edges of color $i$ for each $i \\in[q]$. In this paper, we focus on $\\alpha$-colored arborescences (spanning out-trees) in $q$-colored multidigraphs.","We study the decision, counting and search versions of this problem.","It is known that the decision and search problems are polynomial-time solvable when $q=2$ and that the decision problem is NP-complete when $q$ is arbitrary.","However the complexity status of the problem for fixed $q$ was open for $q > 2$.","We show that, for a $q$-colored digraph $G$ and a vertex $s$ in $G$, the number of $\\alpha$-colored arborescences in $G$ rooted at $s$ for all color-constraints $\\alpha \\in \\mathbb{N}^q$ can be read from the determinant of a symbolic matrix in $q-1$ indeterminates.","This result extends Tutte's matrix-tree theorem for directed graphs and gives a polynomial-time algorithm for the counting and decision problems for fixed $q$. We also use it to design an algorithm that finds an $\\alpha$-colored arborescence when one exists.","Finally, we study the weighted variant of the problem and give a polynomial-time algorithm (when $q$ is fixed) which finds a minimum weight solution."],"url":"http://arxiv.org/abs/2503.13984v1"}
{"created":"2025-03-18 07:39:50","title":"A-SCoRe: Attention-based Scene Coordinate Regression for wide-ranging scenarios","abstract":"Visual localization is considered to be one of the crucial parts in many robotic and vision systems. While state-of-the art methods that relies on feature matching have proven to be accurate for visual localization, its requirements for storage and compute are burdens. Scene coordinate regression (SCR) is an alternative approach that remove the barrier for storage by learning to map 2D pixels to 3D scene coordinates. Most popular SCR use Convolutional Neural Network (CNN) to extract 2D descriptor, which we would argue that it miss the spatial relationship between pixels. Inspired by the success of vision transformer architecture, we present a new SCR architecture, called A-ScoRe, an Attention-based model which leverage attention on descriptor map level to produce meaningful and high-semantic 2D descriptors. Since the operation is performed on descriptor map, our model can work with multiple data modality whether it is a dense or sparse from depth-map, SLAM to Structure-from-Motion (SfM). This versatility allows A-SCoRe to operate in different kind of environments, conditions and achieve the level of flexibility that is important for mobile robots. Results show our methods achieve comparable performance with State-of-the-art methods on multiple benchmark while being light-weighted and much more flexible. Code and pre-trained models are public in our repository: https://github.com/ais-lab/A-SCoRe.","sentences":["Visual localization is considered to be one of the crucial parts in many robotic and vision systems.","While state-of-the art methods that relies on feature matching have proven to be accurate for visual localization, its requirements for storage and compute are burdens.","Scene coordinate regression (SCR) is an alternative approach that remove the barrier for storage by learning to map 2D pixels to 3D scene coordinates.","Most popular SCR use Convolutional Neural Network (CNN) to extract 2D descriptor, which we would argue that it miss the spatial relationship between pixels.","Inspired by the success of vision transformer architecture, we present a new SCR architecture, called A-ScoRe, an Attention-based model which leverage attention on descriptor map level to produce meaningful and high-semantic 2D descriptors.","Since the operation is performed on descriptor map, our model can work with multiple data modality whether it is a dense or sparse from depth-map, SLAM to Structure-from-Motion (SfM).","This versatility allows A-SCoRe to operate in different kind of environments, conditions and achieve the level of flexibility that is important for mobile robots.","Results show our methods achieve comparable performance with State-of-the-art methods on multiple benchmark while being light-weighted and much more flexible.","Code and pre-trained models are public in our repository: https://github.com/ais-lab/A-SCoRe."],"url":"http://arxiv.org/abs/2503.13982v1"}
{"created":"2025-03-18 07:30:29","title":"Empowering LLMs in Decision Games through Algorithmic Data Synthesis","abstract":"Large Language Models (LLMs) have exhibited impressive capabilities across numerous domains, yet they often struggle with complex reasoning and decision-making tasks. Decision-making games, which inherently require multifaceted reasoning logic, serve as ideal sandboxes for evaluating and enhancing the reasoning abilities of LLMs. In this work, we first explore whether LLMs can master complex decision-making games through targeted post-training. To this end, we design data synthesis strategies and curate extensive offline datasets from two classic games, Doudizhu and Go. We further develop a suite of techniques to effectively incorporate this data into LLM training, resulting in two novel agents: Mastermind-Dou and Mastermind-Go. Our experimental results demonstrate that these Mastermind LLMs achieve competitive performance in their respective games. Additionally, we explore whether integrating decision-making data can enhance the general reasoning abilities of LLMs. Our findings suggest that such post-training improves certain aspects of reasoning, providing valuable insights for optimizing LLM data collection and synthesis strategies.","sentences":["Large Language Models (LLMs) have exhibited impressive capabilities across numerous domains, yet they often struggle with complex reasoning and decision-making tasks.","Decision-making games, which inherently require multifaceted reasoning logic, serve as ideal sandboxes for evaluating and enhancing the reasoning abilities of LLMs.","In this work, we first explore whether LLMs can master complex decision-making games through targeted post-training.","To this end, we design data synthesis strategies and curate extensive offline datasets from two classic games, Doudizhu and Go.","We further develop a suite of techniques to effectively incorporate this data into LLM training, resulting in two novel agents: Mastermind-Dou and Mastermind-Go.","Our experimental results demonstrate that these Mastermind LLMs achieve competitive performance in their respective games.","Additionally, we explore whether integrating decision-making data can enhance the general reasoning abilities of LLMs.","Our findings suggest that such post-training improves certain aspects of reasoning, providing valuable insights for optimizing LLM data collection and synthesis strategies."],"url":"http://arxiv.org/abs/2503.13980v1"}
{"created":"2025-03-18 07:24:05","title":"Navigating Rifts in Human-LLM Grounding: Study and Benchmark","abstract":"Language models excel at following instructions but often struggle with the collaborative aspects of conversation that humans naturally employ. This limitation in grounding -- the process by which conversation participants establish mutual understanding -- can lead to outcomes ranging from frustrated users to serious consequences in high-stakes scenarios. To systematically study grounding challenges in human-LLM interactions, we analyze logs from three human-assistant datasets: WildChat, MultiWOZ, and Bing Chat. We develop a taxonomy of grounding acts and build models to annotate and forecast grounding behavior. Our findings reveal significant differences in human-human and human-LLM grounding: LLMs were three times less likely to initiate clarification and sixteen times less likely to provide follow-up requests than humans. Additionally, early grounding failures predicted later interaction breakdowns. Building on these insights, we introduce RIFTS: a benchmark derived from publicly available LLM interaction data containing situations where LLMs fail to initiate grounding. We note that current frontier models perform poorly on RIFTS, highlighting the need to reconsider how we train and prompt LLMs for human interaction. To this end, we develop a preliminary intervention that mitigates grounding failures.","sentences":["Language models excel at following instructions but often struggle with the collaborative aspects of conversation that humans naturally employ.","This limitation in grounding -- the process by which conversation participants establish mutual understanding -- can lead to outcomes ranging from frustrated users to serious consequences in high-stakes scenarios.","To systematically study grounding challenges in human-LLM interactions, we analyze logs from three human-assistant datasets: WildChat, MultiWOZ, and Bing Chat.","We develop a taxonomy of grounding acts and build models to annotate and forecast grounding behavior.","Our findings reveal significant differences in human-human and human-LLM grounding: LLMs were three times less likely to initiate clarification and sixteen times less likely to provide follow-up requests than humans.","Additionally, early grounding failures predicted later interaction breakdowns.","Building on these insights, we introduce RIFTS: a benchmark derived from publicly available LLM interaction data containing situations where LLMs fail to initiate grounding.","We note that current frontier models perform poorly on RIFTS, highlighting the need to reconsider how we train and prompt LLMs for human interaction.","To this end, we develop a preliminary intervention that mitigates grounding failures."],"url":"http://arxiv.org/abs/2503.13975v1"}
{"created":"2025-03-18 07:05:24","title":"SoccerSynth Field: enhancing field detection with synthetic data from virtual soccer simulator","abstract":"Field detection in team sports is an essential task in sports video analysis. However, collecting large-scale and diverse real-world datasets for training detection models is often cost and time-consuming. Synthetic datasets, which allow controlled variability in lighting, textures, and camera angles, will be a promising alternative for addressing these problems. This study addresses the challenges of high costs and difficulties in collecting real-world datasets by investigating the effectiveness of pretraining models using synthetic datasets. In this paper, we propose the effectiveness of using a synthetic dataset (SoccerSynth-Field) for soccer field detection. A synthetic soccer field dataset was created to pretrain models, and the performance of these models was compared with models trained on real-world datasets. The results demonstrate that models pretrained on the synthetic dataset exhibit superior performance in detecting soccer fields. This highlights the effectiveness of synthetic data in enhancing model robustness and accuracy, offering a cost-effective and scalable solution for advancing detection tasks in sports field detection.","sentences":["Field detection in team sports is an essential task in sports video analysis.","However, collecting large-scale and diverse real-world datasets for training detection models is often cost and time-consuming.","Synthetic datasets, which allow controlled variability in lighting, textures, and camera angles, will be a promising alternative for addressing these problems.","This study addresses the challenges of high costs and difficulties in collecting real-world datasets by investigating the effectiveness of pretraining models using synthetic datasets.","In this paper, we propose the effectiveness of using a synthetic dataset (SoccerSynth-Field) for soccer field detection.","A synthetic soccer field dataset was created to pretrain models, and the performance of these models was compared with models trained on real-world datasets.","The results demonstrate that models pretrained on the synthetic dataset exhibit superior performance in detecting soccer fields.","This highlights the effectiveness of synthetic data in enhancing model robustness and accuracy, offering a cost-effective and scalable solution for advancing detection tasks in sports field detection."],"url":"http://arxiv.org/abs/2503.13969v1"}
{"created":"2025-03-18 06:57:21","title":"MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding","abstract":"Document Question Answering (DocQA) is a very common task. Existing methods using Large Language Models (LLMs) or Large Vision Language Models (LVLMs) and Retrieval Augmented Generation (RAG) often prioritize information from a single modal, failing to effectively integrate textual and visual cues. These approaches struggle with complex multi-modal reasoning, limiting their performance on real-world documents. We present MDocAgent (A Multi-Modal Multi-Agent Framework for Document Understanding), a novel RAG and multi-agent framework that leverages both text and image. Our system employs five specialized agents: a general agent, a critical agent, a text agent, an image agent and a summarizing agent. These agents engage in multi-modal context retrieval, combining their individual insights to achieve a more comprehensive understanding of the document's content. This collaborative approach enables the system to synthesize information from both textual and visual components, leading to improved accuracy in question answering. Preliminary experiments on five benchmarks like MMLongBench, LongDocURL demonstrate the effectiveness of our MDocAgent, achieve an average improvement of 12.1% compared to current state-of-the-art method. This work contributes to the development of more robust and comprehensive DocQA systems capable of handling the complexities of real-world documents containing rich textual and visual information. Our data and code are available at https://github.com/aiming-lab/MDocAgent.","sentences":["Document Question Answering (DocQA) is a very common task.","Existing methods using Large Language Models (LLMs) or Large Vision Language Models (LVLMs) and Retrieval Augmented Generation (RAG) often prioritize information from a single modal, failing to effectively integrate textual and visual cues.","These approaches struggle with complex multi-modal reasoning, limiting their performance on real-world documents.","We present MDocAgent (A Multi-Modal Multi-Agent Framework for Document Understanding), a novel RAG and multi-agent framework that leverages both text and image.","Our system employs five specialized agents: a general agent, a critical agent, a text agent, an image agent and a summarizing agent.","These agents engage in multi-modal context retrieval, combining their individual insights to achieve a more comprehensive understanding of the document's content.","This collaborative approach enables the system to synthesize information from both textual and visual components, leading to improved accuracy in question answering.","Preliminary experiments on five benchmarks like MMLongBench, LongDocURL demonstrate the effectiveness of our MDocAgent, achieve an average improvement of 12.1% compared to current state-of-the-art method.","This work contributes to the development of more robust and comprehensive DocQA systems capable of handling the complexities of real-world documents containing rich textual and visual information.","Our data and code are available at https://github.com/aiming-lab/MDocAgent."],"url":"http://arxiv.org/abs/2503.13964v1"}
{"created":"2025-03-18 06:48:08","title":"Improving LLM Video Understanding with 16 Frames Per Second","abstract":"Human vision is dynamic and continuous. However, in video understanding with multimodal large language models (LLMs), existing methods primarily rely on static features extracted from images sampled at a fixed low frame rate of frame-per-second (FPS) $\\leqslant$2, leading to critical visual information loss. In this paper, we introduce F-16, the first multimodal LLM designed for high-frame-rate video understanding. By increasing the frame rate to 16 FPS and compressing visual tokens within each 1-second clip, F-16 efficiently captures dynamic visual features while preserving key semantic information. Experimental results demonstrate that higher frame rates considerably enhance video understanding across multiple benchmarks, providing a new approach to improving video LLMs beyond scaling model size or training data. F-16 achieves state-of-the-art performance among 7-billion-parameter video LLMs on both general and fine-grained video understanding benchmarks, such as Video-MME and TemporalBench. Furthermore, F-16 excels in complex spatiotemporal tasks, including high-speed sports analysis (\\textit{e.g.}, basketball, football, gymnastics, and diving), outperforming SOTA proprietary visual models like GPT-4o and Gemini-1.5-pro. Additionally, we introduce a novel decoding method for F-16 that enables highly efficient low-frame-rate inference without requiring model retraining. Upon acceptance, we will release the source code, model checkpoints, and data.","sentences":["Human vision is dynamic and continuous.","However, in video understanding with multimodal large language models (LLMs), existing methods primarily rely on static features extracted from images sampled at a fixed low frame rate of frame-per-second (FPS) $\\leqslant$2, leading to critical visual information loss.","In this paper, we introduce F-16, the first multimodal LLM designed for high-frame-rate video understanding.","By increasing the frame rate to 16 FPS and compressing visual tokens within each 1-second clip, F-16 efficiently captures dynamic visual features while preserving key semantic information.","Experimental results demonstrate that higher frame rates considerably enhance video understanding across multiple benchmarks, providing a new approach to improving video LLMs beyond scaling model size or training data.","F-16 achieves state-of-the-art performance among 7-billion-parameter video LLMs on both general and fine-grained video understanding benchmarks, such as Video-MME and TemporalBench.","Furthermore, F-16 excels in complex spatiotemporal tasks, including high-speed sports analysis (\\textit{e.g.}, basketball, football, gymnastics, and diving), outperforming SOTA proprietary visual models like GPT-4o and Gemini-1.5-pro.","Additionally, we introduce a novel decoding method for F-16 that enables highly efficient low-frame-rate inference without requiring model retraining.","Upon acceptance, we will release the source code, model checkpoints, and data."],"url":"http://arxiv.org/abs/2503.13956v1"}
{"created":"2025-03-18 06:46:53","title":"Enhanced High-Dimensional Data Visualization through Adaptive Multi-Scale Manifold Embedding","abstract":"To address the dual challenges of the curse of dimensionality and the difficulty in separating intra-cluster and inter-cluster structures in high-dimensional manifold embedding, we proposes an Adaptive Multi-Scale Manifold Embedding (AMSME) algorithm. By introducing ordinal distance to replace traditional Euclidean distances, we theoretically demonstrate that ordinal distance overcomes the constraints of the curse of dimensionality in high-dimensional spaces, effectively distinguishing heterogeneous samples. We design an adaptive neighborhood adjustment method to construct similarity graphs that simultaneously balance intra-cluster compactness and inter-cluster separability. Furthermore, we develop a two-stage embedding framework: the first stage achieves preliminary cluster separation while preserving connectivity between structurally similar clusters via the similarity graph, and the second stage enhances inter-cluster separation through a label-driven distance reweighting. Experimental results demonstrate that AMSME significantly preserves intra-cluster topological structures and improves inter-cluster separation on real-world datasets. Additionally, leveraging its multi-resolution analysis capability, AMSME discovers novel neuronal subtypes in the mouse lumbar dorsal root ganglion scRNA-seq dataset, with marker gene analysis revealing their distinct biological roles.","sentences":["To address the dual challenges of the curse of dimensionality and the difficulty in separating intra-cluster and inter-cluster structures in high-dimensional manifold embedding, we proposes an Adaptive Multi-Scale Manifold Embedding (AMSME) algorithm.","By introducing ordinal distance to replace traditional Euclidean distances, we theoretically demonstrate that ordinal distance overcomes the constraints of the curse of dimensionality in high-dimensional spaces, effectively distinguishing heterogeneous samples.","We design an adaptive neighborhood adjustment method to construct similarity graphs that simultaneously balance intra-cluster compactness and inter-cluster separability.","Furthermore, we develop a two-stage embedding framework: the first stage achieves preliminary cluster separation while preserving connectivity between structurally similar clusters via the similarity graph, and the second stage enhances inter-cluster separation through a label-driven distance reweighting.","Experimental results demonstrate that AMSME significantly preserves intra-cluster topological structures and improves inter-cluster separation on real-world datasets.","Additionally, leveraging its multi-resolution analysis capability, AMSME discovers novel neuronal subtypes in the mouse lumbar dorsal root ganglion scRNA-seq dataset, with marker gene analysis revealing their distinct biological roles."],"url":"http://arxiv.org/abs/2503.13954v1"}
{"created":"2025-03-18 06:41:02","title":"SimWorld: A Unified Benchmark for Simulator-Conditioned Scene Generation via World Model","abstract":"With the rapid advancement of autonomous driving technology, a lack of data has become a major obstacle to enhancing perception model accuracy. Researchers are now exploring controllable data generation using world models to diversify datasets. However, previous work has been limited to studying image generation quality on specific public datasets. There is still relatively little research on how to build data generation engines for real-world application scenes to achieve large-scale data generation for challenging scenes. In this paper, a simulator-conditioned scene generation engine based on world model is proposed. By constructing a simulation system consistent with real-world scenes, simulation data and labels, which serve as the conditions for data generation in the world model, for any scenes can be collected. It is a novel data generation pipeline by combining the powerful scene simulation capabilities of the simulation engine with the robust data generation capabilities of the world model. In addition, a benchmark with proportionally constructed virtual and real data, is provided for exploring the capabilities of world models in real-world scenes. Quantitative results show that these generated images significantly improve downstream perception models performance. Finally, we explored the generative performance of the world model in urban autonomous driving scenarios. All the data and code will be available at https://github.com/Li-Zn-H/SimWorld.","sentences":["With the rapid advancement of autonomous driving technology, a lack of data has become a major obstacle to enhancing perception model accuracy.","Researchers are now exploring controllable data generation using world models to diversify datasets.","However, previous work has been limited to studying image generation quality on specific public datasets.","There is still relatively little research on how to build data generation engines for real-world application scenes to achieve large-scale data generation for challenging scenes.","In this paper, a simulator-conditioned scene generation engine based on world model is proposed.","By constructing a simulation system consistent with real-world scenes, simulation data and labels, which serve as the conditions for data generation in the world model, for any scenes can be collected.","It is a novel data generation pipeline by combining the powerful scene simulation capabilities of the simulation engine with the robust data generation capabilities of the world model.","In addition, a benchmark with proportionally constructed virtual and real data, is provided for exploring the capabilities of world models in real-world scenes.","Quantitative results show that these generated images significantly improve downstream perception models performance.","Finally, we explored the generative performance of the world model in urban autonomous driving scenarios.","All the data and code will be available at https://github.com/Li-Zn-H/SimWorld."],"url":"http://arxiv.org/abs/2503.13952v1"}
{"created":"2025-03-18 06:40:39","title":"FrustumFusionNets: A Three-Dimensional Object Detection Network Based on Tractor Road Scene","abstract":"To address the issues of the existing frustum-based methods' underutilization of image information in road three-dimensional object detection as well as the lack of research on agricultural scenes, we constructed an object detection dataset using an 80-line Light Detection And Ranging (LiDAR) and a camera in a complex tractor road scene and proposed a new network called FrustumFusionNets (FFNets). Initially, we utilize the results of image-based two-dimensional object detection to narrow down the search region in the three-dimensional space of the point cloud. Next, we introduce a Gaussian mask to enhance the point cloud information. Then, we extract the features from the frustum point cloud and the crop image using the point cloud feature extraction pipeline and the image feature extraction pipeline, respectively. Finally, we concatenate and fuse the data features from both modalities to achieve three-dimensional object detection. Experiments demonstrate that on the constructed test set of tractor road data, the FrustumFusionNetv2 achieves 82.28% and 95.68% accuracy in the three-dimensional object detection of the two main road objects, cars and people, respectively. This performance is 1.83% and 2.33% better than the original model. It offers a hybrid fusion-based multi-object, high-precision, real-time three-dimensional object detection technique for unmanned agricultural machines in tractor road scenarios. On the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) Benchmark Suite validation set, the FrustumFusionNetv2 also demonstrates significant superiority in detecting road pedestrian objects compared with other frustum-based three-dimensional object detection methods.","sentences":["To address the issues of the existing frustum-based methods' underutilization of image information in road three-dimensional object detection as well as the lack of research on agricultural scenes, we constructed an object detection dataset using an 80-line Light Detection And Ranging (LiDAR) and a camera in a complex tractor road scene and proposed a new network called FrustumFusionNets (FFNets).","Initially, we utilize the results of image-based two-dimensional object detection to narrow down the search region in the three-dimensional space of the point cloud.","Next, we introduce a Gaussian mask to enhance the point cloud information.","Then, we extract the features from the frustum point cloud and the crop image using the point cloud feature extraction pipeline and the image feature extraction pipeline, respectively.","Finally, we concatenate and fuse the data features from both modalities to achieve three-dimensional object detection.","Experiments demonstrate that on the constructed test set of tractor road data, the FrustumFusionNetv2 achieves 82.28% and 95.68% accuracy in the three-dimensional object detection of the two main road objects, cars and people, respectively.","This performance is 1.83% and 2.33% better than the original model.","It offers a hybrid fusion-based multi-object, high-precision, real-time three-dimensional object detection technique for unmanned agricultural machines in tractor road scenarios.","On the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) Benchmark Suite validation set, the FrustumFusionNetv2 also demonstrates significant superiority in detecting road pedestrian objects compared with other frustum-based three-dimensional object detection methods."],"url":"http://arxiv.org/abs/2503.13951v1"}
{"created":"2025-03-18 06:12:38","title":"ChatBEV: A Visual Language Model that Understands BEV Maps","abstract":"Traffic scene understanding is essential for intelligent transportation systems and autonomous driving, ensuring safe and efficient vehicle operation. While recent advancements in VLMs have shown promise for holistic scene understanding, the application of VLMs to traffic scenarios, particularly using BEV maps, remains under explored. Existing methods often suffer from limited task design and narrow data amount, hindering comprehensive scene understanding. To address these challenges, we introduce ChatBEV-QA, a novel BEV VQA benchmark contains over 137k questions, designed to encompass a wide range of scene understanding tasks, including global scene understanding, vehicle-lane interactions, and vehicle-vehicle interactions. This benchmark is constructed using an novel data collection pipeline that generates scalable and informative VQA data for BEV maps. We further fine-tune a specialized vision-language model ChatBEV, enabling it to interpret diverse question prompts and extract relevant context-aware information from BEV maps. Additionally, we propose a language-driven traffic scene generation pipeline, where ChatBEV facilitates map understanding and text-aligned navigation guidance, significantly enhancing the generation of realistic and consistent traffic scenarios. The dataset, code and the fine-tuned model will be released.","sentences":["Traffic scene understanding is essential for intelligent transportation systems and autonomous driving, ensuring safe and efficient vehicle operation.","While recent advancements in VLMs have shown promise for holistic scene understanding, the application of VLMs to traffic scenarios, particularly using BEV maps, remains under explored.","Existing methods often suffer from limited task design and narrow data amount, hindering comprehensive scene understanding.","To address these challenges, we introduce ChatBEV-QA, a novel BEV VQA benchmark contains over 137k questions, designed to encompass a wide range of scene understanding tasks, including global scene understanding, vehicle-lane interactions, and vehicle-vehicle interactions.","This benchmark is constructed using an novel data collection pipeline that generates scalable and informative VQA data for BEV maps.","We further fine-tune a specialized vision-language model ChatBEV, enabling it to interpret diverse question prompts and extract relevant context-aware information from BEV maps.","Additionally, we propose a language-driven traffic scene generation pipeline, where ChatBEV facilitates map understanding and text-aligned navigation guidance, significantly enhancing the generation of realistic and consistent traffic scenarios.","The dataset, code and the fine-tuned model will be released."],"url":"http://arxiv.org/abs/2503.13938v1"}
{"created":"2025-03-18 06:04:44","title":"SCORE: Soft Label Compression-Centric Dataset Condensation via Coding Rate Optimization","abstract":"Dataset Condensation (DC) aims to obtain a condensed dataset that allows models trained on the condensed dataset to achieve performance comparable to those trained on the full dataset. Recent DC approaches increasingly focus on encoding knowledge into realistic images with soft labeling, for their scalability to ImageNet-scale datasets and strong capability of cross-domain generalization. However, this strong performance comes at a substantial storage cost which could significantly exceed the storage cost of the original dataset. We argue that the three key properties to alleviate this performance-storage dilemma are informativeness, discriminativeness, and compressibility of the condensed data. Towards this end, this paper proposes a \\textbf{S}oft label compression-centric dataset condensation framework using \\textbf{CO}ding \\textbf{R}at\\textbf{E} (SCORE). SCORE formulates dataset condensation as a min-max optimization problem, which aims to balance the three key properties from an information-theoretic perspective. In particular, we theoretically demonstrate that our coding rate-inspired objective function is submodular, and its optimization naturally enforces low-rank structure in the soft label set corresponding to each condensed data. Extensive experiments on large-scale datasets, including ImageNet-1K and Tiny-ImageNet, demonstrate that SCORE outperforms existing methods in most cases. Even with 30$\\times$ compression of soft labels, performance decreases by only 5.5\\% and 2.7\\% for ImageNet-1K with IPC 10 and 50, respectively. Code will be released upon paper acceptance.","sentences":["Dataset Condensation (DC) aims to obtain a condensed dataset that allows models trained on the condensed dataset to achieve performance comparable to those trained on the full dataset.","Recent DC approaches increasingly focus on encoding knowledge into realistic images with soft labeling, for their scalability to ImageNet-scale datasets and strong capability of cross-domain generalization.","However, this strong performance comes at a substantial storage cost which could significantly exceed the storage cost of the original dataset.","We argue that the three key properties to alleviate this performance-storage dilemma are informativeness, discriminativeness, and compressibility of the condensed data.","Towards this end, this paper proposes a \\textbf{S}oft label compression-centric dataset condensation framework using \\textbf{CO}ding \\textbf{R}at\\textbf{E} (SCORE).","SCORE formulates dataset condensation as a min-max optimization problem, which aims to balance the three key properties from an information-theoretic perspective.","In particular, we theoretically demonstrate that our coding rate-inspired objective function is submodular, and its optimization naturally enforces low-rank structure in the soft label set corresponding to each condensed data.","Extensive experiments on large-scale datasets, including ImageNet-1K and Tiny-ImageNet, demonstrate that SCORE outperforms existing methods in most cases.","Even with 30$\\times$ compression of soft labels, performance decreases by only 5.5\\% and 2.7\\% for ImageNet-1K with IPC 10 and 50, respectively.","Code will be released upon paper acceptance."],"url":"http://arxiv.org/abs/2503.13935v1"}
{"created":"2025-03-18 06:01:01","title":"Tensor-decomposition-based A Priori Surrogate (TAPS) modeling for ultra large-scale simulations","abstract":"A data-free, predictive scientific AI model, Tensor-decomposition-based A Priori Surrogate (TAPS), is proposed for tackling ultra large-scale engineering simulations with significant speedup, memory savings, and storage gain. TAPS can effectively obtain surrogate models for high-dimensional parametric problems with equivalent zetta-scale ($10^{21}$) degrees of freedom (DoFs). TAPS achieves this by directly obtaining reduced-order models through solving governing equations with multiple independent variables such as spatial coordinates, parameters, and time. The paper first introduces an AI-enhanced finite element-type interpolation function called convolution hierarchical deep-learning neural network (C-HiDeNN) with tensor decomposition (TD). Subsequently, the generalized space-parameter-time Galerkin weak form and the corresponding matrix form are derived. Through the choice of TAPS hyperparameters, an arbitrary convergence rate can be achieved. To show the capabilities of this framework, TAPS is then used to simulate a large-scale additive manufacturing process as an example and achieves around 1,370x speedup, 14.8x memory savings, and 955x storage gain compared to the finite difference method with $3.46$ billion spatial degrees of freedom (DoFs). As a result, the TAPS framework opens a new avenue for many challenging ultra large-scale engineering problems, such as additive manufacturing and integrated circuit design, among others.","sentences":["A data-free, predictive scientific AI model, Tensor-decomposition-based A Priori Surrogate (TAPS), is proposed for tackling ultra large-scale engineering simulations with significant speedup, memory savings, and storage gain.","TAPS can effectively obtain surrogate models for high-dimensional parametric problems with equivalent zetta-scale ($10^{21}$) degrees of freedom (DoFs).","TAPS achieves this by directly obtaining reduced-order models through solving governing equations with multiple independent variables such as spatial coordinates, parameters, and time.","The paper first introduces an AI-enhanced finite element-type interpolation function called convolution hierarchical deep-learning neural network (C-HiDeNN) with tensor decomposition (TD).","Subsequently, the generalized space-parameter-time Galerkin weak form and the corresponding matrix form are derived.","Through the choice of TAPS hyperparameters, an arbitrary convergence rate can be achieved.","To show the capabilities of this framework, TAPS is then used to simulate a large-scale additive manufacturing process as an example and achieves around 1,370x speedup, 14.8x memory savings, and 955x storage gain compared to the finite difference method with $3.46$ billion spatial degrees of freedom (DoFs).","As a result, the TAPS framework opens a new avenue for many challenging ultra large-scale engineering problems, such as additive manufacturing and integrated circuit design, among others."],"url":"http://arxiv.org/abs/2503.13933v1"}
{"created":"2025-03-18 05:41:03","title":"Reconstructing Cell Lineage Trees from Phenotypic Features with Metric Learning","abstract":"How a single fertilized cell gives rise to a complex array of specialized cell types in development is a central question in biology. The cells grow, divide, and acquire differentiated characteristics through poorly understood molecular processes. A key approach to studying developmental processes is to infer the tree graph of cell lineage division and differentiation histories, providing an analytical framework for dissecting individual cells' molecular decisions during replication and differentiation. Although genetically engineered lineage-tracing methods have advanced the field, they are either infeasible or ethically constrained in many organisms. In contrast, modern single-cell technologies can measure high-content molecular profiles (e.g., transcriptomes) in a wide range of biological systems.   Here, we introduce CellTreeQM, a novel deep learning method based on transformer architectures that learns an embedding space with geometric properties optimized for tree-graph inference. By formulating lineage reconstruction as a tree-metric learning problem, we have systematically explored supervised, weakly supervised, and unsupervised training settings and present a Lineage Reconstruction Benchmark to facilitate comprehensive evaluation of our learning method. We benchmarked the method on (1) synthetic data modeled via Brownian motion with independent noise and spurious signals and (2) lineage-resolved single-cell RNA sequencing datasets. Experimental results show that CellTreeQM recovers lineage structures with minimal supervision and limited data, offering a scalable framework for uncovering cell lineage relationships in challenging animal models. To our knowledge, this is the first method to cast cell lineage inference explicitly as a metric learning task, paving the way for future computational models aimed at uncovering the molecular dynamics of cell lineage.","sentences":["How a single fertilized cell gives rise to a complex array of specialized cell types in development is a central question in biology.","The cells grow, divide, and acquire differentiated characteristics through poorly understood molecular processes.","A key approach to studying developmental processes is to infer the tree graph of cell lineage division and differentiation histories, providing an analytical framework for dissecting individual cells' molecular decisions during replication and differentiation.","Although genetically engineered lineage-tracing methods have advanced the field, they are either infeasible or ethically constrained in many organisms.","In contrast, modern single-cell technologies can measure high-content molecular profiles (e.g., transcriptomes) in a wide range of biological systems.   ","Here, we introduce CellTreeQM, a novel deep learning method based on transformer architectures that learns an embedding space with geometric properties optimized for tree-graph inference.","By formulating lineage reconstruction as a tree-metric learning problem, we have systematically explored supervised, weakly supervised, and unsupervised training settings and present a Lineage Reconstruction Benchmark to facilitate comprehensive evaluation of our learning method.","We benchmarked the method on (1) synthetic data modeled via Brownian motion with independent noise and spurious signals and (2) lineage-resolved single-cell RNA sequencing datasets.","Experimental results show that CellTreeQM recovers lineage structures with minimal supervision and limited data, offering a scalable framework for uncovering cell lineage relationships in challenging animal models.","To our knowledge, this is the first method to cast cell lineage inference explicitly as a metric learning task, paving the way for future computational models aimed at uncovering the molecular dynamics of cell lineage."],"url":"http://arxiv.org/abs/2503.13925v1"}
{"created":"2025-03-18 05:38:04","title":"ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models","abstract":"Large language models (LLMs) have been one of the most important discoveries in machine learning in recent years. LLM-based artificial intelligence (AI) assistants, such as ChatGPT, have consistently attracted the attention from researchers, investors, and the general public, driving the rapid growth of this industry. With the frequent introduction of new LLMs to the market, it becomes increasingly difficult to differentiate between them, creating a demand for new LLM comparison methods.   In this research, the Consistency-focused Similarity Comparison Framework (ConSCompF) for generative large language models is proposed. It compares texts generated by two LLMs and produces a similarity score, indicating the overall degree of similarity between their responses. The main advantage of this framework is that it can operate on a small number of unlabeled data, such as chatbot instruction prompts, and does not require LLM developers to disclose any information about their product.   To evaluate the efficacy of ConSCompF, two experiments aimed at identifying similarities between multiple LLMs are conducted. Additionally, these experiments examine the correlation between the similarity scores generated by ConSCompF and the differences in the outputs produced by other benchmarking techniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison experiments is conducted to evaluate the performance of ConSCompF in a few-shot LLM comparison scenario.   The proposed framework can be used for calculating similarity matrices of multiple LLMs, which can be effectively visualized using principal component analysis (PCA). The ConSCompF output may provide useful insights into data that might have been used during LLM training and help detect possible investment fraud attempts.","sentences":["Large language models (LLMs) have been one of the most important discoveries in machine learning in recent years.","LLM-based artificial intelligence (AI) assistants, such as ChatGPT, have consistently attracted the attention from researchers, investors, and the general public, driving the rapid growth of this industry.","With the frequent introduction of new LLMs to the market, it becomes increasingly difficult to differentiate between them, creating a demand for new LLM comparison methods.   ","In this research, the Consistency-focused Similarity Comparison Framework (ConSCompF) for generative large language models is proposed.","It compares texts generated by two LLMs and produces a similarity score, indicating the overall degree of similarity between their responses.","The main advantage of this framework is that it can operate on a small number of unlabeled data, such as chatbot instruction prompts, and does not require LLM developers to disclose any information about their product.   ","To evaluate the efficacy of ConSCompF, two experiments aimed at identifying similarities between multiple LLMs are conducted.","Additionally, these experiments examine the correlation between the similarity scores generated by ConSCompF and the differences in the outputs produced by other benchmarking techniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison experiments is conducted to evaluate the performance of ConSCompF in a few-shot LLM comparison scenario.   ","The proposed framework can be used for calculating similarity matrices of multiple LLMs, which can be effectively visualized using principal component analysis (PCA).","The ConSCompF output may provide useful insights into data that might have been used during LLM training and help detect possible investment fraud attempts."],"url":"http://arxiv.org/abs/2503.13923v1"}
{"created":"2025-03-18 05:36:59","title":"Learning Accurate Models on Incomplete Data with Minimal Imputation","abstract":"Missing data often exists in real-world datasets, requiring significant time and effort for imputation to learn accurate machine learning (ML) models. In this paper, we demonstrate that imputing all missing values is not always necessary to achieve an accurate ML model. We introduce the concept of minimal data imputation, which ensures accurate ML models trained over the imputed dataset. Implementing minimal imputation guarantees both minimal imputation effort and optimal ML models. We propose algorithms to find exact and approximate minimal imputation for various ML models. Our extensive experiments indicate that our proposed algorithms significantly reduce the time and effort required for data imputation.","sentences":["Missing data often exists in real-world datasets, requiring significant time and effort for imputation to learn accurate machine learning (ML) models.","In this paper, we demonstrate that imputing all missing values is not always necessary to achieve an accurate ML model.","We introduce the concept of minimal data imputation, which ensures accurate ML models trained over the imputed dataset.","Implementing minimal imputation guarantees both minimal imputation effort and optimal ML models.","We propose algorithms to find exact and approximate minimal imputation for various ML models.","Our extensive experiments indicate that our proposed algorithms significantly reduce the time and effort required for data imputation."],"url":"http://arxiv.org/abs/2503.13921v1"}
{"created":"2025-03-18 05:22:13","title":"Robust Machine Unlearning for Quantized Neural Networks via Adaptive Gradient Reweighting with Similar Labels","abstract":"Model quantization enables efficient deployment of deep neural networks on edge devices through low-bit parameter representation, yet raises critical challenges for implementing machine unlearning (MU) under data privacy regulations. Existing MU methods designed for full-precision models fail to address two fundamental limitations in quantized networks: 1) Noise amplification from label mismatch during data processing, and 2) Gradient imbalance between forgotten and retained data during training. These issues are exacerbated by quantized models' constrained parameter space and discrete optimization. We propose Q-MUL, the first dedicated unlearning framework for quantized models. Our method introduces two key innovations: 1) Similar Labels assignment replaces random labels with semantically consistent alternatives to minimize noise injection, and 2) Adaptive Gradient Reweighting dynamically aligns parameter update contributions from forgotten and retained data. Through systematic analysis of quantized model vulnerabilities, we establish theoretical foundations for these mechanisms. Extensive evaluations on benchmark datasets demonstrate Q-MUL's superiority over existing approaches.","sentences":["Model quantization enables efficient deployment of deep neural networks on edge devices through low-bit parameter representation, yet raises critical challenges for implementing machine unlearning (MU) under data privacy regulations.","Existing MU methods designed for full-precision models fail to address two fundamental limitations in quantized networks: 1) Noise amplification from label mismatch during data processing, and 2) Gradient imbalance between forgotten and retained data during training.","These issues are exacerbated by quantized models' constrained parameter space and discrete optimization.","We propose Q-MUL, the first dedicated unlearning framework for quantized models.","Our method introduces two key innovations: 1) Similar Labels assignment replaces random labels with semantically consistent alternatives to minimize noise injection, and 2) Adaptive Gradient Reweighting dynamically aligns parameter update contributions from forgotten and retained data.","Through systematic analysis of quantized model vulnerabilities, we establish theoretical foundations for these mechanisms.","Extensive evaluations on benchmark datasets demonstrate Q-MUL's superiority over existing approaches."],"url":"http://arxiv.org/abs/2503.13917v1"}
{"created":"2025-03-18 05:19:33","title":"Unlocking the Potential of Unlabeled Data in Semi-Supervised Domain Generalization","abstract":"We address the problem of semi-supervised domain generalization (SSDG), where the distributions of train and test data differ, and only a small amount of labeled data along with a larger amount of unlabeled data are available during training. Existing SSDG methods that leverage only the unlabeled samples for which the model's predictions are highly confident (confident-unlabeled samples), limit the full utilization of the available unlabeled data. To the best of our knowledge, we are the first to explore a method for incorporating the unconfident-unlabeled samples that were previously disregarded in SSDG setting. To this end, we propose UPCSC to utilize these unconfident-unlabeled samples in SSDG that consists of two modules: 1) Unlabeled Proxy-based Contrastive learning (UPC) module, treating unconfident-unlabeled samples as additional negative pairs and 2) Surrogate Class learning (SC) module, generating positive pairs for unconfident-unlabeled samples using their confusing class set. These modules are plug-and-play and do not require any domain labels, which can be easily integrated into existing approaches. Experiments on four widely used SSDG benchmarks demonstrate that our approach consistently improves performance when attached to baselines and outperforms competing plug-and-play methods. We also analyze the role of our method in SSDG, showing that it enhances class-level discriminability and mitigates domain gaps. The code is available at https://github.com/dongkwani/UPCSC.","sentences":["We address the problem of semi-supervised domain generalization (SSDG), where the distributions of train and test data differ, and only a small amount of labeled data along with a larger amount of unlabeled data are available during training.","Existing SSDG methods that leverage only the unlabeled samples for which the model's predictions are highly confident (confident-unlabeled samples), limit the full utilization of the available unlabeled data.","To the best of our knowledge, we are the first to explore a method for incorporating the unconfident-unlabeled samples that were previously disregarded in SSDG setting.","To this end, we propose UPCSC to utilize these unconfident-unlabeled samples in SSDG that consists of two modules: 1) Unlabeled Proxy-based Contrastive learning (UPC) module, treating unconfident-unlabeled samples as additional negative pairs and 2) Surrogate Class learning (SC) module, generating positive pairs for unconfident-unlabeled samples using their confusing class set.","These modules are plug-and-play and do not require any domain labels, which can be easily integrated into existing approaches.","Experiments on four widely used SSDG benchmarks demonstrate that our approach consistently improves performance when attached to baselines and outperforms competing plug-and-play methods.","We also analyze the role of our method in SSDG, showing that it enhances class-level discriminability and mitigates domain gaps.","The code is available at https://github.com/dongkwani/UPCSC."],"url":"http://arxiv.org/abs/2503.13915v1"}
{"created":"2025-03-18 05:15:21","title":"Incorporating Attributes and Multi-Scale Structures for Heterogeneous Graph Contrastive Learning","abstract":"Heterogeneous graphs (HGs) are composed of multiple types of nodes and edges, making it more effective in capturing the complex relational structures inherent in the real world. However, in real-world scenarios, labeled data is often difficult to obtain, which limits the applicability of semi-supervised approaches. Self-supervised learning aims to enable models to automatically learn useful features from data, effectively addressing the challenge of limited labeling data. In this paper, we propose a novel contrastive learning framework for heterogeneous graphs (ASHGCL), which incorporates three distinct views, each focusing on node attributes, high-order and low-order structural information, respectively, to effectively capture attribute information, high-order structures, and low-order structures for node representation learning. Furthermore, we introduce an attribute-enhanced positive sample selection strategy that combines both structural information and attribute information, effectively addressing the issue of sampling bias. Extensive experiments on four real-world datasets show that ASHGCL outperforms state-of-the-art unsupervised baselines and even surpasses some supervised benchmarks.","sentences":["Heterogeneous graphs (HGs) are composed of multiple types of nodes and edges, making it more effective in capturing the complex relational structures inherent in the real world.","However, in real-world scenarios, labeled data is often difficult to obtain, which limits the applicability of semi-supervised approaches.","Self-supervised learning aims to enable models to automatically learn useful features from data, effectively addressing the challenge of limited labeling data.","In this paper, we propose a novel contrastive learning framework for heterogeneous graphs (ASHGCL), which incorporates three distinct views, each focusing on node attributes, high-order and low-order structural information, respectively, to effectively capture attribute information, high-order structures, and low-order structures for node representation learning.","Furthermore, we introduce an attribute-enhanced positive sample selection strategy that combines both structural information and attribute information, effectively addressing the issue of sampling bias.","Extensive experiments on four real-world datasets show that ASHGCL outperforms state-of-the-art unsupervised baselines and even surpasses some supervised benchmarks."],"url":"http://arxiv.org/abs/2503.13911v1"}
{"created":"2025-03-18 05:11:21","title":"Quantification of Uncertainties in Probabilistic Deep Neural Network by Implementing Boosting of Variational Inference","abstract":"Modern neural network architectures have achieved remarkable accuracies but remain highly dependent on their training data, often lacking interpretability in their learned mappings. While effective on large datasets, they tend to overfit on smaller ones. Probabilistic neural networks, such as those utilizing variational inference, address this limitation by incorporating uncertainty estimation through weight distributions rather than point estimates. However, standard variational inference often relies on a single-density approximation, which can lead to poor posterior estimates and hinder model performance. We propose Boosted Bayesian Neural Networks (BBNN), a novel approach that enhances neural network weight distribution approximations using Boosting Variational Inference (BVI). By iteratively constructing a mixture of densities, BVI expands the approximating family, enabling a more expressive posterior that leads to improved generalization and uncertainty estimation. While this approach increases computational complexity, it significantly enhances accuracy an essential tradeoff, particularly in high-stakes applications such as medical diagnostics, where false negatives can have severe consequences. Our experimental results demonstrate that BBNN achieves ~5% higher accuracy compared to conventional neural networks while providing superior uncertainty quantification. This improvement highlights the effectiveness of leveraging a mixture-based variational family to better approximate the posterior distribution, ultimately advancing probabilistic deep learning.","sentences":["Modern neural network architectures have achieved remarkable accuracies but remain highly dependent on their training data, often lacking interpretability in their learned mappings.","While effective on large datasets, they tend to overfit on smaller ones.","Probabilistic neural networks, such as those utilizing variational inference, address this limitation by incorporating uncertainty estimation through weight distributions rather than point estimates.","However, standard variational inference often relies on a single-density approximation, which can lead to poor posterior estimates and hinder model performance.","We propose Boosted Bayesian Neural Networks (BBNN), a novel approach that enhances neural network weight distribution approximations using Boosting Variational Inference (BVI).","By iteratively constructing a mixture of densities, BVI expands the approximating family, enabling a more expressive posterior that leads to improved generalization and uncertainty estimation.","While this approach increases computational complexity, it significantly enhances accuracy an essential tradeoff, particularly in high-stakes applications such as medical diagnostics, where false negatives can have severe consequences.","Our experimental results demonstrate that BBNN achieves ~5% higher accuracy compared to conventional neural networks while providing superior uncertainty quantification.","This improvement highlights the effectiveness of leveraging a mixture-based variational family to better approximate the posterior distribution, ultimately advancing probabilistic deep learning."],"url":"http://arxiv.org/abs/2503.13909v1"}
{"created":"2025-03-18 04:44:43","title":"Evaluating Global Geo-alignment for Precision Learned Autonomous Vehicle Localization using Aerial Data","abstract":"Recently there has been growing interest in the use of aerial and satellite map data for autonomous vehicles, primarily due to its potential for significant cost reduction and enhanced scalability. Despite the advantages, aerial data also comes with challenges such as a sensor-modality gap and a viewpoint difference gap. Learned localization methods have shown promise for overcoming these challenges to provide precise metric localization for autonomous vehicles. Most learned localization methods rely on coarsely aligned ground truth, or implicit consistency-based methods to learn the localization task -- however, in this paper we find that improving the alignment between aerial data and autonomous vehicle sensor data at training time is critical to the performance of a learning-based localization system. We compare two data alignment methods using a factor graph framework and, using these methods, we then evaluate the effects of closely aligned ground truth on learned localization accuracy through ablation studies. Finally, we evaluate a learned localization system using the data alignment methods on a comprehensive (1600km) autonomous vehicle dataset and demonstrate localization error below 0.3m and 0.5$^{\\circ}$ sufficient for autonomous vehicle applications.","sentences":["Recently there has been growing interest in the use of aerial and satellite map data for autonomous vehicles, primarily due to its potential for significant cost reduction and enhanced scalability.","Despite the advantages, aerial data also comes with challenges such as a sensor-modality gap and a viewpoint difference gap.","Learned localization methods have shown promise for overcoming these challenges to provide precise metric localization for autonomous vehicles.","Most learned localization methods rely on coarsely aligned ground truth, or implicit consistency-based methods to learn the localization task -- however, in this paper we find that improving the alignment between aerial data and autonomous vehicle sensor data at training time is critical to the performance of a learning-based localization system.","We compare two data alignment methods using a factor graph framework and, using these methods, we then evaluate the effects of closely aligned ground truth on learned localization accuracy through ablation studies.","Finally, we evaluate a learned localization system using the data alignment methods on a comprehensive (1600km) autonomous vehicle dataset and demonstrate localization error below 0.3m and 0.5$^{\\circ}$ sufficient for autonomous vehicle applications."],"url":"http://arxiv.org/abs/2503.13896v1"}
{"created":"2025-03-18 04:34:43","title":"Where do Large Vision-Language Models Look at when Answering Questions?","abstract":"Large Vision-Language Models (LVLMs) have shown promising performance in vision-language understanding and reasoning tasks. However, their visual understanding behaviors remain underexplored. A fundamental question arises: to what extent do LVLMs rely on visual input, and which image regions contribute to their responses? It is non-trivial to interpret the free-form generation of LVLMs due to their complicated visual architecture (e.g., multiple encoders and multi-resolution) and variable-length outputs. In this paper, we extend existing heatmap visualization methods (e.g., iGOS++) to support LVLMs for open-ended visual question answering. We propose a method to select visually relevant tokens that reflect the relevance between generated answers and input image. Furthermore, we conduct a comprehensive analysis of state-of-the-art LVLMs on benchmarks designed to require visual information to answer. Our findings offer several insights into LVLM behavior, including the relationship between focus region and answer correctness, differences in visual attention across architectures, and the impact of LLM scale on visual understanding. The code and data are available at https://github.com/bytedance/LVLM_Interpretation.","sentences":["Large Vision-Language Models (LVLMs) have shown promising performance in vision-language understanding and reasoning tasks.","However, their visual understanding behaviors remain underexplored.","A fundamental question arises: to what extent do LVLMs rely on visual input, and which image regions contribute to their responses?","It is non-trivial to interpret the free-form generation of LVLMs due to their complicated visual architecture (e.g., multiple encoders and multi-resolution) and variable-length outputs.","In this paper, we extend existing heatmap visualization methods (e.g., iGOS++) to support LVLMs for open-ended visual question answering.","We propose a method to select visually relevant tokens that reflect the relevance between generated answers and input image.","Furthermore, we conduct a comprehensive analysis of state-of-the-art LVLMs on benchmarks designed to require visual information to answer.","Our findings offer several insights into LVLM behavior, including the relationship between focus region and answer correctness, differences in visual attention across architectures, and the impact of LLM scale on visual understanding.","The code and data are available at https://github.com/bytedance/LVLM_Interpretation."],"url":"http://arxiv.org/abs/2503.13891v1"}
{"created":"2025-03-18 04:31:57","title":"COMM:Concentrated Margin Maximization for Robust Document-Level Relation Extraction","abstract":"Document-level relation extraction (DocRE) is the process of identifying and extracting relations between entities that span multiple sentences within a document. Due to its realistic settings, DocRE has garnered increasing research attention in recent years. Previous research has mostly focused on developing sophisticated encoding models to better capture the intricate patterns between entity pairs. While these advancements are undoubtedly crucial, an even more foundational challenge lies in the data itself. The complexity inherent in DocRE makes the labeling process prone to errors, compounded by the extreme sparsity of positive relation samples, which is driven by both the limited availability of positive instances and the broad diversity of positive relation types. These factors can lead to biased optimization processes, further complicating the task of accurate relation extraction. Recognizing these challenges, we have developed a robust framework called \\textit{\\textbf{COMM}} to better solve DocRE. \\textit{\\textbf{COMM}} operates by initially employing an instance-aware reasoning method to dynamically capture pertinent information of entity pairs within the document and extract relational features. Following this, \\textit{\\textbf{COMM}} takes into account the distribution of relations and the difficulty of samples to dynamically adjust the margins between prediction logits and the decision threshold, a process we call Concentrated Margin Maximization. In this way, \\textit{\\textbf{COMM}} not only enhances the extraction of relevant relational features but also boosts DocRE performance by addressing the specific challenges posed by the data. Extensive experiments and analysis demonstrate the versatility and effectiveness of \\textit{\\textbf{COMM}}, especially its robustness when trained on low-quality data (achieves \\textgreater 10\\% performance gains).","sentences":["Document-level relation extraction (DocRE) is the process of identifying and extracting relations between entities that span multiple sentences within a document.","Due to its realistic settings, DocRE has garnered increasing research attention in recent years.","Previous research has mostly focused on developing sophisticated encoding models to better capture the intricate patterns between entity pairs.","While these advancements are undoubtedly crucial, an even more foundational challenge lies in the data itself.","The complexity inherent in DocRE makes the labeling process prone to errors, compounded by the extreme sparsity of positive relation samples, which is driven by both the limited availability of positive instances and the broad diversity of positive relation types.","These factors can lead to biased optimization processes, further complicating the task of accurate relation extraction.","Recognizing these challenges, we have developed a robust framework called \\textit{\\textbf{COMM}} to better solve DocRE.","\\textit{\\textbf{COMM}} operates by initially employing an instance-aware reasoning method to dynamically capture pertinent information of entity pairs within the document and extract relational features.","Following this, \\textit{\\textbf{COMM}} takes into account the distribution of relations and the difficulty of samples to dynamically adjust the margins between prediction logits and the decision threshold, a process we call Concentrated Margin Maximization.","In this way, \\textit{\\textbf{COMM}} not only enhances the extraction of relevant relational features but also boosts DocRE performance by addressing the specific challenges posed by the data.","Extensive experiments and analysis demonstrate the versatility and effectiveness of \\textit{\\textbf{COMM}}, especially its robustness when trained on low-quality data (achieves \\textgreater 10\\% performance gains)."],"url":"http://arxiv.org/abs/2503.13885v1"}
{"created":"2025-03-18 04:08:07","title":"Shock with Confidence: Formal Proofs of Correctness for Hyperbolic Partial Differential Equation Solvers","abstract":"First-order systems of hyperbolic partial differential equations (PDEs) occur ubiquitously throughout computational physics, commonly used in simulations of fluid turbulence, shock waves, electromagnetic interactions, and even general relativistic phenomena. Such equations are often challenging to solve numerically in the non-linear case, due to their tendency to form discontinuities even for smooth initial data, which can cause numerical algorithms to become unstable, violate conservation laws, or converge to physically incorrect solutions. In this paper, we introduce a new formal verification pipeline for such algorithms in Racket, which allows a user to construct a bespoke hyperbolic PDE solver for a specified equation system, generate low-level C code which verifiably implements that solver, and then produce formal proofs of various mathematical and physical correctness properties of the resulting implementation, including L^2 stability, flux conservation, and physical validity. We outline how these correctness proofs are generated, using a custom-built theorem-proving and automatic differentiation framework that fully respects the algebraic structure of floating-point arithmetic, and show how the resulting C code may either be used to run standalone simulations, or integrated into a larger computational multiphysics framework such as Gkeyll.","sentences":["First-order systems of hyperbolic partial differential equations (PDEs) occur ubiquitously throughout computational physics, commonly used in simulations of fluid turbulence, shock waves, electromagnetic interactions, and even general relativistic phenomena.","Such equations are often challenging to solve numerically in the non-linear case, due to their tendency to form discontinuities even for smooth initial data, which can cause numerical algorithms to become unstable, violate conservation laws, or converge to physically incorrect solutions.","In this paper, we introduce a new formal verification pipeline for such algorithms in Racket, which allows a user to construct a bespoke hyperbolic PDE solver for a specified equation system, generate low-level C code which verifiably implements that solver, and then produce formal proofs of various mathematical and physical correctness properties of the resulting implementation, including L^2 stability, flux conservation, and physical validity.","We outline how these correctness proofs are generated, using a custom-built theorem-proving and automatic differentiation framework that fully respects the algebraic structure of floating-point arithmetic, and show how the resulting C code may either be used to run standalone simulations, or integrated into a larger computational multiphysics framework such as Gkeyll."],"url":"http://arxiv.org/abs/2503.13877v1"}
{"created":"2025-03-18 03:36:17","title":"Robust3D-CIL: Robust Class-Incremental Learning for 3D Perception","abstract":"3D perception plays a crucial role in real-world applications such as autonomous driving, robotics, and AR/VR. In practical scenarios, 3D perception models must continuously adapt to new data and emerging object categories, but retraining from scratch incurs prohibitive costs. Therefore, adopting class-incremental learning (CIL) becomes particularly essential. However, real-world 3D point cloud data often include corrupted samples, which poses significant challenges for existing CIL methods and leads to more severe forgetting on corrupted data. To address these challenges, we consider the scenario in which a CIL model can be updated using point clouds with unknown corruption to better simulate real-world conditions. Inspired by Farthest Point Sampling, we propose a novel exemplar selection strategy that effectively preserves intra-class diversity when selecting replay exemplars, mitigating forgetting induced by data corruption. Furthermore, we introduce a point cloud downsampling-based replay method to utilize the limited replay buffer memory more efficiently, thereby further enhancing the model's continual learning ability. Extensive experiments demonstrate that our method improves the performance of replay-based CIL baselines by 2% to 11%, proving its effectiveness and promising potential for real-world 3D applications.","sentences":["3D perception plays a crucial role in real-world applications such as autonomous driving, robotics, and AR/VR.","In practical scenarios, 3D perception models must continuously adapt to new data and emerging object categories, but retraining from scratch incurs prohibitive costs.","Therefore, adopting class-incremental learning (CIL) becomes particularly essential.","However, real-world 3D point cloud data often include corrupted samples, which poses significant challenges for existing CIL methods and leads to more severe forgetting on corrupted data.","To address these challenges, we consider the scenario in which a CIL model can be updated using point clouds with unknown corruption to better simulate real-world conditions.","Inspired by Farthest Point Sampling, we propose a novel exemplar selection strategy that effectively preserves intra-class diversity when selecting replay exemplars, mitigating forgetting induced by data corruption.","Furthermore, we introduce a point cloud downsampling-based replay method to utilize the limited replay buffer memory more efficiently, thereby further enhancing the model's continual learning ability.","Extensive experiments demonstrate that our method improves the performance of replay-based CIL baselines by 2% to 11%, proving its effectiveness and promising potential for real-world 3D applications."],"url":"http://arxiv.org/abs/2503.13869v1"}
{"created":"2025-03-18 03:35:29","title":"Out-of-Distribution Generalization in Time Series: A Survey","abstract":"Time series frequently manifest distribution shifts, diverse latent features, and non-stationary learning dynamics, particularly in open and evolving environments. These characteristics pose significant challenges for out-of-distribution (OOD) generalization. While substantial progress has been made, a systematic synthesis of advancements remains lacking. To address this gap, we present the first comprehensive review of OOD generalization methodologies for time series, organized to delineate the field's evolutionary trajectory and contemporary research landscape. We organize our analysis across three foundational dimensions: data distribution, representation learning, and OOD evaluation. For each dimension, we present several popular algorithms in detail. Furthermore, we highlight key application scenarios, emphasizing their real-world impact. Finally, we identify persistent challenges and propose future research directions. A detailed summary of the methods reviewed for the generalization of OOD in time series can be accessed at https://tsood-generalization.com.","sentences":["Time series frequently manifest distribution shifts, diverse latent features, and non-stationary learning dynamics, particularly in open and evolving environments.","These characteristics pose significant challenges for out-of-distribution (OOD) generalization.","While substantial progress has been made, a systematic synthesis of advancements remains lacking.","To address this gap, we present the first comprehensive review of OOD generalization methodologies for time series, organized to delineate the field's evolutionary trajectory and contemporary research landscape.","We organize our analysis across three foundational dimensions: data distribution, representation learning, and OOD evaluation.","For each dimension, we present several popular algorithms in detail.","Furthermore, we highlight key application scenarios, emphasizing their real-world impact.","Finally, we identify persistent challenges and propose future research directions.","A detailed summary of the methods reviewed for the generalization of OOD in time series can be accessed at https://tsood-generalization.com."],"url":"http://arxiv.org/abs/2503.13868v1"}
{"created":"2025-03-18 03:30:37","title":"Data Race Satisfiability on Array Elements","abstract":"Detection of data races is one of the most important tasks for verifying the correctness of OpenMP parallel codes. Two main models of analysis tools have been proposed for detecting data races: dynamic analysis and static analysis. Dynamic analysis tools such as Intel Inspector, ThreadSanitizer, and Helgrind+ can detect data races through the execution of the source code. However, source code execution can be quite time-consuming when analyzing computation-intensive programs. There are also static analysis tools such as LLOV, and OpenRace. These tools statically detect data races using algorithms that often do not require the execution of the source code. Although both detection techniques assist programmers in analyzing the correct behavior of OpenMP programs, they still produce false positives that often defeat the purpose of applying automatic analysis. Therefore, we present DRS-oNE (Data Race Satisfiability on aNy Element), a data race detector that detects data races on array elements by solving for race constraints with the Z3 SMT solver.","sentences":["Detection of data races is one of the most important tasks for verifying the correctness of OpenMP parallel codes.","Two main models of analysis tools have been proposed for detecting data races: dynamic analysis and static analysis.","Dynamic analysis tools such as Intel Inspector, ThreadSanitizer, and Helgrind+ can detect data races through the execution of the source code.","However, source code execution can be quite time-consuming when analyzing computation-intensive programs.","There are also static analysis tools such as LLOV, and OpenRace.","These tools statically detect data races using algorithms that often do not require the execution of the source code.","Although both detection techniques assist programmers in analyzing the correct behavior of OpenMP programs, they still produce false positives that often defeat the purpose of applying automatic analysis.","Therefore, we present DRS-oNE (Data Race Satisfiability on aNy Element), a data race detector that detects data races on array elements by solving for race constraints with the Z3 SMT solver."],"url":"http://arxiv.org/abs/2503.13864v1"}
{"created":"2025-03-18 03:26:22","title":"HySurvPred: Multimodal Hyperbolic Embedding with Angle-Aware Hierarchical Contrastive Learning and Uncertainty Constraints for Survival Prediction","abstract":"Multimodal learning that integrates histopathology images and genomic data holds great promise for cancer survival prediction. However, existing methods face key limitations: 1) They rely on multimodal mapping and metrics in Euclidean space, which cannot fully capture the hierarchical structures in histopathology (among patches from different resolutions) and genomics data (from genes to pathways). 2) They discretize survival time into independent risk intervals, which ignores its continuous and ordinal nature and fails to achieve effective optimization. 3) They treat censorship as a binary indicator, excluding censored samples from model optimization and not making full use of them. To address these challenges, we propose HySurvPred, a novel framework for survival prediction that integrates three key modules: Multimodal Hyperbolic Mapping (MHM), Angle-aware Ranking-based Contrastive Loss (ARCL) and Censor-Conditioned Uncertainty Constraint (CUC). Instead of relying on Euclidean space, we design the MHM module to explore the inherent hierarchical structures within each modality in hyperbolic space. To better integrate multimodal features in hyperbolic space, we introduce the ARCL module, which uses ranking-based contrastive learning to preserve the ordinal nature of survival time, along with the CUC module to fully explore the censored data. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on five benchmark datasets. The source code is to be released.","sentences":["Multimodal learning that integrates histopathology images and genomic data holds great promise for cancer survival prediction.","However, existing methods face key limitations: 1) They rely on multimodal mapping and metrics in Euclidean space, which cannot fully capture the hierarchical structures in histopathology (among patches from different resolutions) and genomics data (from genes to pathways).","2) They discretize survival time into independent risk intervals, which ignores its continuous and ordinal nature and fails to achieve effective optimization.","3) They treat censorship as a binary indicator, excluding censored samples from model optimization and not making full use of them.","To address these challenges, we propose HySurvPred, a novel framework for survival prediction that integrates three key modules: Multimodal Hyperbolic Mapping (MHM), Angle-aware Ranking-based Contrastive Loss (ARCL) and Censor-Conditioned Uncertainty Constraint (CUC).","Instead of relying on Euclidean space, we design the MHM module to explore the inherent hierarchical structures within each modality in hyperbolic space.","To better integrate multimodal features in hyperbolic space, we introduce the ARCL module, which uses ranking-based contrastive learning to preserve the ordinal nature of survival time, along with the CUC module to fully explore the censored data.","Extensive experiments demonstrate that our method outperforms state-of-the-art methods on five benchmark datasets.","The source code is to be released."],"url":"http://arxiv.org/abs/2503.13862v1"}
{"created":"2025-03-18 03:14:23","title":"Enabling Inclusive Systematic Reviews: Incorporating Preprint Articles with Large Language Model-Driven Evaluations","abstract":"Background. Systematic reviews in comparative effectiveness research require timely evidence synthesis. Preprints accelerate knowledge dissemination but vary in quality, posing challenges for systematic reviews.   Methods. We propose AutoConfidence (automated confidence assessment), an advanced framework for predicting preprint publication, which reduces reliance on manual curation and expands the range of predictors, including three key advancements: (1) automated data extraction using natural language processing techniques, (2) semantic embeddings of titles and abstracts, and (3) large language model (LLM)-driven evaluation scores. Additionally, we employed two prediction models: a random forest classifier for binary outcome and a survival cure model that predicts both binary outcome and publication risk over time.   Results. The random forest classifier achieved AUROC 0.692 with LLM-driven scores, improving to 0.733 with semantic embeddings and 0.747 with article usage metrics. The survival cure model reached AUROC 0.716 with LLM-driven scores, improving to 0.731 with semantic embeddings. For publication risk prediction, it achieved a concordance index of 0.658, increasing to 0.667 with semantic embeddings.   Conclusion. Our study advances the framework for preprint publication prediction through automated data extraction and multiple feature integration. By combining semantic embeddings with LLM-driven evaluations, AudoConfidence enhances predictive performance while reducing manual annotation burden. The framework has the potential to facilitate systematic incorporation of preprint articles in evidence-based medicine, supporting researchers in more effective evaluation and utilization of preprint resources.","sentences":["Background.","Systematic reviews in comparative effectiveness research require timely evidence synthesis.","Preprints accelerate knowledge dissemination but vary in quality, posing challenges for systematic reviews.   Methods.","We propose AutoConfidence (automated confidence assessment), an advanced framework for predicting preprint publication, which reduces reliance on manual curation and expands the range of predictors, including three key advancements: (1) automated data extraction using natural language processing techniques, (2) semantic embeddings of titles and abstracts, and (3) large language model (LLM)-driven evaluation scores.","Additionally, we employed two prediction models: a random forest classifier for binary outcome and a survival cure model that predicts both binary outcome and publication risk over time.   Results.","The random forest classifier achieved AUROC 0.692 with LLM-driven scores, improving to 0.733 with semantic embeddings and 0.747 with article usage metrics.","The survival cure model reached AUROC 0.716 with LLM-driven scores, improving to 0.731 with semantic embeddings.","For publication risk prediction, it achieved a concordance index of 0.658, increasing to 0.667 with semantic embeddings.   Conclusion.","Our study advances the framework for preprint publication prediction through automated data extraction and multiple feature integration.","By combining semantic embeddings with LLM-driven evaluations, AudoConfidence enhances predictive performance while reducing manual annotation burden.","The framework has the potential to facilitate systematic incorporation of preprint articles in evidence-based medicine, supporting researchers in more effective evaluation and utilization of preprint resources."],"url":"http://arxiv.org/abs/2503.13857v1"}
{"created":"2025-03-18 02:39:26","title":"Disentangling Fine-Tuning from Pre-Training in Visual Captioning with Hybrid Markov Logic","abstract":"Multimodal systems have highly complex processing pipelines and are pretrained over large datasets before being fine-tuned for specific tasks such as visual captioning. However, it becomes hard to disentangle what the model learns during the fine-tuning process from what it already knows due to its pretraining. In this work, we learn a probabilistic model using Hybrid Markov Logic Networks (HMLNs) over the training examples by relating symbolic knowledge (extracted from the caption) with visual features (extracted from the image). For a generated caption, we quantify the influence of training examples based on the HMLN distribution using probabilistic inference. We evaluate two types of inference procedures on the MSCOCO dataset for different types of captioning models. Our results show that for BLIP2 (a model that uses a LLM), the fine-tuning may have smaller influence on the knowledge the model has acquired since it may have more general knowledge to perform visual captioning as compared to models that do not use a LLM","sentences":["Multimodal systems have highly complex processing pipelines and are pretrained over large datasets before being fine-tuned for specific tasks such as visual captioning.","However, it becomes hard to disentangle what the model learns during the fine-tuning process from what it already knows due to its pretraining.","In this work, we learn a probabilistic model using Hybrid Markov Logic Networks (HMLNs) over the training examples by relating symbolic knowledge (extracted from the caption) with visual features (extracted from the image).","For a generated caption, we quantify the influence of training examples based on the HMLN distribution using probabilistic inference.","We evaluate two types of inference procedures on the MSCOCO dataset for different types of captioning models.","Our results show that for BLIP2 (a model that uses a LLM), the fine-tuning may have smaller influence on the knowledge the model has acquired since it may have more general knowledge to perform visual captioning as compared to models that do not use a LLM"],"url":"http://arxiv.org/abs/2503.13847v1"}
{"created":"2025-03-18 02:32:50","title":"Counterfactual experience augmented off-policy reinforcement learning","abstract":"Reinforcement learning control algorithms face significant challenges due to out-of-distribution and inefficient exploration problems. While model-based reinforcement learning enhances the agent's reasoning and planning capabilities by constructing virtual environments, training such virtual environments can be very complex. In order to build an efficient inference model and enhance the representativeness of learning data, we propose the Counterfactual Experience Augmentation (CEA) algorithm. CEA leverages variational autoencoders to model the dynamic patterns of state transitions and introduces randomness to model non-stationarity. This approach focuses on expanding the learning data in the experience pool through counterfactual inference and performs exceptionally well in environments that follow the bisimulation assumption. Environments with bisimulation properties are usually represented by discrete observation and action spaces, we propose a sampling method based on maximum kernel density estimation entropy to extend CEA to various environments. By providing reward signals for counterfactual state transitions based on real information, CEA constructs a complete counterfactual experience to alleviate the out-of-distribution problem of the learning data, and outperforms general SOTA algorithms in environments with difference properties. Finally, we discuss the similarities, differences and properties of generated counterfactual experiences and real experiences. The code is available at https://github.com/Aegis1863/CEA.","sentences":["Reinforcement learning control algorithms face significant challenges due to out-of-distribution and inefficient exploration problems.","While model-based reinforcement learning enhances the agent's reasoning and planning capabilities by constructing virtual environments, training such virtual environments can be very complex.","In order to build an efficient inference model and enhance the representativeness of learning data, we propose the Counterfactual Experience Augmentation (CEA) algorithm.","CEA leverages variational autoencoders to model the dynamic patterns of state transitions and introduces randomness to model non-stationarity.","This approach focuses on expanding the learning data in the experience pool through counterfactual inference and performs exceptionally well in environments that follow the bisimulation assumption.","Environments with bisimulation properties are usually represented by discrete observation and action spaces, we propose a sampling method based on maximum kernel density estimation entropy to extend CEA to various environments.","By providing reward signals for counterfactual state transitions based on real information, CEA constructs a complete counterfactual experience to alleviate the out-of-distribution problem of the learning data, and outperforms general SOTA algorithms in environments with difference properties.","Finally, we discuss the similarities, differences and properties of generated counterfactual experiences and real experiences.","The code is available at https://github.com/Aegis1863/CEA."],"url":"http://arxiv.org/abs/2503.13842v1"}
{"created":"2025-03-18 02:10:20","title":"Scale-Aware Contrastive Reverse Distillation for Unsupervised Medical Anomaly Detection","abstract":"Unsupervised anomaly detection using deep learning has garnered significant research attention due to its broad applicability, particularly in medical imaging where labeled anomalous data are scarce. While earlier approaches leverage generative models like autoencoders and generative adversarial networks (GANs), they often fall short due to overgeneralization. Recent methods explore various strategies, including memory banks, normalizing flows, self-supervised learning, and knowledge distillation, to enhance discrimination. Among these, knowledge distillation, particularly reverse distillation, has shown promise. Following this paradigm, we propose a novel scale-aware contrastive reverse distillation model that addresses two key limitations of existing reverse distillation methods: insufficient feature discriminability and inability to handle anomaly scale variations. Specifically, we introduce a contrastive student-teacher learning approach to derive more discriminative representations by generating and exploring out-of-normal distributions. Further, we design a scale adaptation mechanism to softly weight contrastive distillation losses at different scales to account for the scale variation issue. Extensive experiments on benchmark datasets demonstrate state-of-the-art performance, validating the efficacy of the proposed method. Code is available at https://github.com/MedAITech/SCRD4AD.","sentences":["Unsupervised anomaly detection using deep learning has garnered significant research attention due to its broad applicability, particularly in medical imaging where labeled anomalous data are scarce.","While earlier approaches leverage generative models like autoencoders and generative adversarial networks (GANs), they often fall short due to overgeneralization.","Recent methods explore various strategies, including memory banks, normalizing flows, self-supervised learning, and knowledge distillation, to enhance discrimination.","Among these, knowledge distillation, particularly reverse distillation, has shown promise.","Following this paradigm, we propose a novel scale-aware contrastive reverse distillation model that addresses two key limitations of existing reverse distillation methods: insufficient feature discriminability and inability to handle anomaly scale variations.","Specifically, we introduce a contrastive student-teacher learning approach to derive more discriminative representations by generating and exploring out-of-normal distributions.","Further, we design a scale adaptation mechanism to softly weight contrastive distillation losses at different scales to account for the scale variation issue.","Extensive experiments on benchmark datasets demonstrate state-of-the-art performance, validating the efficacy of the proposed method.","Code is available at https://github.com/MedAITech/SCRD4AD."],"url":"http://arxiv.org/abs/2503.13828v1"}
{"created":"2025-03-18 01:58:35","title":"NeurBench: Benchmarking Learned Database Components with Data and Workload Drift Modeling","abstract":"Learned database components, which deeply integrate machine learning into their design, have been extensively studied in recent years. Given the dynamism of databases, where data and workloads continuously drift, it is crucial for learned database components to remain effective and efficient in the face of data and workload drift. Adaptability, therefore, is a key factor in assessing their practical applicability. However, existing benchmarks for learned database components either overlook or oversimplify the treatment of data and workload drift, failing to evaluate learned database components across a broad range of drift scenarios. This paper presents NeurBench, a new benchmark suite that applies measurable and controllable data and workload drift to enable systematic performance evaluations of learned database components. We quantify diverse types of drift by introducing a key concept called the drift factor. Building on this formulation, we propose a drift-aware data and workload generation framework that effectively simulates real-world drift while preserving inherent correlations. We employ NeurBench to evaluate state-of-the-art learned query optimizers, learned indexes, and learned concurrency control within a consistent experimental process, providing insights into their performance under diverse data and workload drift scenarios.","sentences":["Learned database components, which deeply integrate machine learning into their design, have been extensively studied in recent years.","Given the dynamism of databases, where data and workloads continuously drift, it is crucial for learned database components to remain effective and efficient in the face of data and workload drift.","Adaptability, therefore, is a key factor in assessing their practical applicability.","However, existing benchmarks for learned database components either overlook or oversimplify the treatment of data and workload drift, failing to evaluate learned database components across a broad range of drift scenarios.","This paper presents NeurBench, a new benchmark suite that applies measurable and controllable data and workload drift to enable systematic performance evaluations of learned database components.","We quantify diverse types of drift by introducing a key concept called the drift factor.","Building on this formulation, we propose a drift-aware data and workload generation framework that effectively simulates real-world drift while preserving inherent correlations.","We employ NeurBench to evaluate state-of-the-art learned query optimizers, learned indexes, and learned concurrency control within a consistent experimental process, providing insights into their performance under diverse data and workload drift scenarios."],"url":"http://arxiv.org/abs/2503.13822v1"}
{"created":"2025-03-18 01:57:48","title":"Stitch-a-Recipe: Video Demonstration from Multistep Descriptions","abstract":"When obtaining visual illustrations from text descriptions, today's methods take a description with-a single text context caption, or an action description-and retrieve or generate the matching visual context. However, prior work does not permit visual illustration of multistep descriptions, e.g. a cooking recipe composed of multiple steps. Furthermore, simply handling each step description in isolation would result in an incoherent demonstration. We propose Stitch-a-Recipe, a novel retrieval-based method to assemble a video demonstration from a multistep description. The resulting video contains clips, possibly from different sources, that accurately reflect all the step descriptions, while being visually coherent. We formulate a training pipeline that creates large-scale weakly supervised data containing diverse and novel recipes and injects hard negatives that promote both correctness and coherence. Validated on in-the-wild instructional videos, Stitch-a-Recipe achieves state-of-the-art performance, with quantitative gains up to 24% as well as dramatic wins in a human preference study.","sentences":["When obtaining visual illustrations from text descriptions, today's methods take a description with-a single text context caption, or an action description-and retrieve or generate the matching visual context.","However, prior work does not permit visual illustration of multistep descriptions, e.g. a cooking recipe composed of multiple steps.","Furthermore, simply handling each step description in isolation would result in an incoherent demonstration.","We propose Stitch-a-Recipe, a novel retrieval-based method to assemble a video demonstration from a multistep description.","The resulting video contains clips, possibly from different sources, that accurately reflect all the step descriptions, while being visually coherent.","We formulate a training pipeline that creates large-scale weakly supervised data containing diverse and novel recipes and injects hard negatives that promote both correctness and coherence.","Validated on in-the-wild instructional videos, Stitch-a-Recipe achieves state-of-the-art performance, with quantitative gains up to 24% as well as dramatic wins in a human preference study."],"url":"http://arxiv.org/abs/2503.13821v1"}
{"created":"2025-03-18 01:51:27","title":"VARP: Reinforcement Learning from Vision-Language Model Feedback with Agent Regularized Preferences","abstract":"Designing reward functions for continuous-control robotics often leads to subtle misalignments or reward hacking, especially in complex tasks. Preference-based RL mitigates some of these pitfalls by learning rewards from comparative feedback rather than hand-crafted signals, yet scaling human annotations remains challenging. Recent work uses Vision-Language Models (VLMs) to automate preference labeling, but a single final-state image generally fails to capture the agent's full motion. In this paper, we present a two-part solution that both improves feedback accuracy and better aligns reward learning with the agent's policy. First, we overlay trajectory sketches on final observations to reveal the path taken, allowing VLMs to provide more reliable preferences-improving preference accuracy by approximately 15-20% in metaworld tasks. Second, we regularize reward learning by incorporating the agent's performance, ensuring that the reward model is optimized based on data generated by the current policy; this addition boosts episode returns by 20-30% in locomotion tasks. Empirical studies on metaworld demonstrate that our method achieves, for instance, around 70-80% success rate in all tasks, compared to below 50% for standard approaches. These results underscore the efficacy of combining richer visual representations with agent-aware reward regularization.","sentences":["Designing reward functions for continuous-control robotics often leads to subtle misalignments or reward hacking, especially in complex tasks.","Preference-based RL mitigates some of these pitfalls by learning rewards from comparative feedback rather than hand-crafted signals, yet scaling human annotations remains challenging.","Recent work uses Vision-Language Models (VLMs) to automate preference labeling, but a single final-state image generally fails to capture the agent's full motion.","In this paper, we present a two-part solution that both improves feedback accuracy and better aligns reward learning with the agent's policy.","First, we overlay trajectory sketches on final observations to reveal the path taken, allowing VLMs to provide more reliable preferences-improving preference accuracy by approximately 15-20% in metaworld tasks.","Second, we regularize reward learning by incorporating the agent's performance, ensuring that the reward model is optimized based on data generated by the current policy; this addition boosts episode returns by 20-30% in locomotion tasks.","Empirical studies on metaworld demonstrate that our method achieves, for instance, around 70-80% success rate in all tasks, compared to below 50% for standard approaches.","These results underscore the efficacy of combining richer visual representations with agent-aware reward regularization."],"url":"http://arxiv.org/abs/2503.13817v1"}
{"created":"2025-03-18 01:45:51","title":"FusDreamer: Label-efficient Remote Sensing World Model for Multimodal Data Classification","abstract":"World models significantly enhance hierarchical understanding, improving data integration and learning efficiency. To explore the potential of the world model in the remote sensing (RS) field, this paper proposes a label-efficient remote sensing world model for multimodal data fusion (FusDreamer). The FusDreamer uses the world model as a unified representation container to abstract common and high-level knowledge, promoting interactions across different types of data, \\emph{i.e.}, hyperspectral (HSI), light detection and ranging (LiDAR), and text data. Initially, a new latent diffusion fusion and multimodal generation paradigm (LaMG) is utilized for its exceptional information integration and detail retention capabilities. Subsequently, an open-world knowledge-guided consistency projection (OK-CP) module incorporates prompt representations for visually described objects and aligns language-visual features through contrastive learning. In this way, the domain gap can be bridged by fine-tuning the pre-trained world models with limited samples. Finally, an end-to-end multitask combinatorial optimization (MuCO) strategy can capture slight feature bias and constrain the diffusion process in a collaboratively learnable direction. Experiments conducted on four typical datasets indicate the effectiveness and advantages of the proposed FusDreamer. The corresponding code will be released at https://github.com/Cimy-wang/FusDreamer.","sentences":["World models significantly enhance hierarchical understanding, improving data integration and learning efficiency.","To explore the potential of the world model in the remote sensing (RS) field, this paper proposes a label-efficient remote sensing world model for multimodal data fusion (FusDreamer).","The FusDreamer uses the world model as a unified representation container to abstract common and high-level knowledge, promoting interactions across different types of data, \\emph{i.e.}, hyperspectral (HSI), light detection and ranging (LiDAR), and text data.","Initially, a new latent diffusion fusion and multimodal generation paradigm (LaMG) is utilized for its exceptional information integration and detail retention capabilities.","Subsequently, an open-world knowledge-guided consistency projection (OK-CP) module incorporates prompt representations for visually described objects and aligns language-visual features through contrastive learning.","In this way, the domain gap can be bridged by fine-tuning the pre-trained world models with limited samples.","Finally, an end-to-end multitask combinatorial optimization (MuCO) strategy can capture slight feature bias and constrain the diffusion process in a collaboratively learnable direction.","Experiments conducted on four typical datasets indicate the effectiveness and advantages of the proposed FusDreamer.","The corresponding code will be released at https://github.com/Cimy-wang/FusDreamer."],"url":"http://arxiv.org/abs/2503.13814v1"}
{"created":"2025-03-18 01:45:19","title":"Automatic MILP Model Construction for Multi-Robot Task Allocation and Scheduling Based on Large Language Models","abstract":"With the accelerated development of Industry 4.0, intelligent manufacturing systems increasingly require efficient task allocation and scheduling in multi-robot systems. However, existing methods rely on domain expertise and face challenges in adapting to dynamic production constraints. Additionally, enterprises have high privacy requirements for production scheduling data, which prevents the use of cloud-based large language models (LLMs) for solution development. To address these challenges, there is an urgent need for an automated modeling solution that meets data privacy requirements. This study proposes a knowledge-augmented mixed integer linear programming (MILP) automated formulation framework, integrating local LLMs with domain-specific knowledge bases to generate executable code from natural language descriptions automatically. The framework employs a knowledge-guided DeepSeek-R1-Distill-Qwen-32B model to extract complex spatiotemporal constraints (82% average accuracy) and leverages a supervised fine-tuned Qwen2.5-Coder-7B-Instruct model for efficient MILP code generation (90% average accuracy). Experimental results demonstrate that the framework successfully achieves automatic modeling in the aircraft skin manufacturing case while ensuring data privacy and computational efficiency. This research provides a low-barrier and highly reliable technical path for modeling in complex industrial scenarios.","sentences":["With the accelerated development of Industry 4.0, intelligent manufacturing systems increasingly require efficient task allocation and scheduling in multi-robot systems.","However, existing methods rely on domain expertise and face challenges in adapting to dynamic production constraints.","Additionally, enterprises have high privacy requirements for production scheduling data, which prevents the use of cloud-based large language models (LLMs) for solution development.","To address these challenges, there is an urgent need for an automated modeling solution that meets data privacy requirements.","This study proposes a knowledge-augmented mixed integer linear programming (MILP) automated formulation framework, integrating local LLMs with domain-specific knowledge bases to generate executable code from natural language descriptions automatically.","The framework employs a knowledge-guided DeepSeek-R1-Distill-Qwen-32B model to extract complex spatiotemporal constraints (82% average accuracy) and leverages a supervised fine-tuned Qwen2.5-Coder-7B-Instruct model for efficient MILP code generation (90% average accuracy).","Experimental results demonstrate that the framework successfully achieves automatic modeling in the aircraft skin manufacturing case while ensuring data privacy and computational efficiency.","This research provides a low-barrier and highly reliable technical path for modeling in complex industrial scenarios."],"url":"http://arxiv.org/abs/2503.13813v1"}
{"created":"2025-03-18 01:38:29","title":"SNAKE: A Sustainable and Multi-functional Traffic Analysis System utilizing Specialized Large-Scale Models with a Mixture of Experts Architecture","abstract":"The rapid advancement of internet technology has led to a surge in data transmission, making network traffic classification crucial for security and management. However, there are significant deficiencies in its efficiency for handling multiattribute analysis and its ability to expand model knowledge, making it difficult to adapt to the ever-changing network environment and complex identification requirements. To address this issue, we proposed the SNAKE (Sustainable Network Analysis with Knowledge Exploration) system, which adopts a multi-gated mixture of experts architecture to construct a multi-functional traffic classification model. The system analyzes traffic attributes at different levels through multiple expert sub-models, providing predictions for these attributes via gating and a final Tower network. Additionally, through an intelligent gating configuration, the system enables extremely fast model integration and evolution across various knowledge expansion scenarios. Its excellent compatibility allows it to continuously evolve into a multi-functional largescale model in the field of traffic analysis. Our experimental results demonstrate that the SNAKE system exhibits remarkable scalability when faced with incremental challenges in diverse traffic classification tasks. Currently, we have integrated multiple models into the system, enabling it to classify a wide range of attributes, such as encapsulation usage, application types and numerous malicious behaviors. We believe that SNAKE can pioneeringly create a sustainable and multifunctional large-scale model in the field of network traffic analysis after continuous expansion.","sentences":["The rapid advancement of internet technology has led to a surge in data transmission, making network traffic classification crucial for security and management.","However, there are significant deficiencies in its efficiency for handling multiattribute analysis and its ability to expand model knowledge, making it difficult to adapt to the ever-changing network environment and complex identification requirements.","To address this issue, we proposed the SNAKE (Sustainable Network Analysis with Knowledge Exploration) system, which adopts a multi-gated mixture of experts architecture to construct a multi-functional traffic classification model.","The system analyzes traffic attributes at different levels through multiple expert sub-models, providing predictions for these attributes via gating and a final Tower network.","Additionally, through an intelligent gating configuration, the system enables extremely fast model integration and evolution across various knowledge expansion scenarios.","Its excellent compatibility allows it to continuously evolve into a multi-functional largescale model in the field of traffic analysis.","Our experimental results demonstrate that the SNAKE system exhibits remarkable scalability when faced with incremental challenges in diverse traffic classification tasks.","Currently, we have integrated multiple models into the system, enabling it to classify a wide range of attributes, such as encapsulation usage, application types and numerous malicious behaviors.","We believe that SNAKE can pioneeringly create a sustainable and multifunctional large-scale model in the field of network traffic analysis after continuous expansion."],"url":"http://arxiv.org/abs/2503.13808v1"}
{"created":"2025-03-18 01:09:52","title":"SMILE: a Scale-aware Multiple Instance Learning Method for Multicenter STAS Lung Cancer Histopathology Diagnosis","abstract":"Spread through air spaces (STAS) represents a newly identified aggressive pattern in lung cancer, which is known to be associated with adverse prognostic factors and complex pathological features. Pathologists currently rely on time consuming manual assessments, which are highly subjective and prone to variation. This highlights the urgent need for automated and precise diag nostic solutions. 2,970 lung cancer tissue slides are comprised from multiple centers, re-diagnosed them, and constructed and publicly released three lung cancer STAS datasets: STAS CSU (hospital), STAS TCGA, and STAS CPTAC. All STAS datasets provide corresponding pathological feature diagnoses and related clinical data. To address the bias, sparse and heterogeneous nature of STAS, we propose an scale-aware multiple instance learning(SMILE) method for STAS diagnosis of lung cancer. By introducing a scale-adaptive attention mechanism, the SMILE can adaptively adjust high attention instances, reducing over-reliance on local regions and promoting consistent detection of STAS lesions. Extensive experiments show that SMILE achieved competitive diagnostic results on STAS CSU, diagnosing 251 and 319 STAS samples in CPTAC andTCGA,respectively, surpassing clinical average AUC. The 11 open baseline results are the first to be established for STAS research, laying the foundation for the future expansion, interpretability, and clinical integration of computational pathology technologies. The datasets and code are available at https://anonymous.4open.science/r/IJCAI25-1DA1.","sentences":["Spread through air spaces (STAS) represents a newly identified aggressive pattern in lung cancer, which is known to be associated with adverse prognostic factors and complex pathological features.","Pathologists currently rely on time consuming manual assessments, which are highly subjective and prone to variation.","This highlights the urgent need for automated and precise diag nostic solutions.","2,970 lung cancer tissue slides are comprised from multiple centers, re-diagnosed them, and constructed and publicly released three lung cancer STAS datasets: STAS CSU (hospital), STAS TCGA, and STAS CPTAC.","All STAS datasets provide corresponding pathological feature diagnoses and related clinical data.","To address the bias, sparse and heterogeneous nature of STAS, we propose an scale-aware multiple instance learning(SMILE) method for STAS diagnosis of lung cancer.","By introducing a scale-adaptive attention mechanism, the SMILE can adaptively adjust high attention instances, reducing over-reliance on local regions and promoting consistent detection of STAS lesions.","Extensive experiments show that SMILE achieved competitive diagnostic results on STAS CSU, diagnosing 251 and 319 STAS samples in CPTAC andTCGA,respectively, surpassing clinical average AUC.","The 11 open baseline results are the first to be established for STAS research, laying the foundation for the future expansion, interpretability, and clinical integration of computational pathology technologies.","The datasets and code are available at https://anonymous.4open.science/r/IJCAI25-1DA1."],"url":"http://arxiv.org/abs/2503.13799v1"}
{"created":"2025-03-18 01:09:32","title":"AI-Powered Prediction of Nanoparticle Pharmacokinetics: A Multi-View Learning Approach","abstract":"The clinical translation of nanoparticle-based treatments remains limited due to the unpredictability of (nanoparticle) NP pharmacokinetics$\\unicode{x2014}$how they distribute, accumulate, and clear from the body. Predicting these behaviours is challenging due to complex biological interactions and the difficulty of obtaining high-quality experimental datasets. Existing AI-driven approaches rely heavily on data-driven learning but fail to integrate crucial knowledge about NP properties and biodistribution mechanisms. We introduce a multi-view deep learning framework that enhances pharmacokinetic predictions by incorporating prior knowledge of key NP properties such as size and charge into a cross-attention mechanism, enabling context-aware feature selection and improving generalization despite small datasets. To further enhance prediction robustness, we employ an ensemble learning approach, combining deep learning with XGBoost (XGB) and Random Forest (RF), which significantly outperforms existing AI models. Our interpretability analysis reveals key physicochemical properties driving NP biodistribution, providing biologically meaningful insights into possible mechanisms governing NP behaviour in vivo rather than a black-box model. Furthermore, by bridging machine learning with physiologically based pharmacokinetic (PBPK) modelling, this work lays the foundation for data-efficient AI-driven drug discovery and precision nanomedicine.","sentences":["The clinical translation of nanoparticle-based treatments remains limited due to the unpredictability of (nanoparticle) NP pharmacokinetics$\\unicode{x2014}$how they distribute, accumulate, and clear from the body.","Predicting these behaviours is challenging due to complex biological interactions and the difficulty of obtaining high-quality experimental datasets.","Existing AI-driven approaches rely heavily on data-driven learning but fail to integrate crucial knowledge about NP properties and biodistribution mechanisms.","We introduce a multi-view deep learning framework that enhances pharmacokinetic predictions by incorporating prior knowledge of key NP properties such as size and charge into a cross-attention mechanism, enabling context-aware feature selection and improving generalization despite small datasets.","To further enhance prediction robustness, we employ an ensemble learning approach, combining deep learning with XGBoost (XGB) and Random Forest (RF), which significantly outperforms existing AI models.","Our interpretability analysis reveals key physicochemical properties driving NP biodistribution, providing biologically meaningful insights into possible mechanisms governing NP behaviour in vivo rather than a black-box model.","Furthermore, by bridging machine learning with physiologically based pharmacokinetic (PBPK) modelling, this work lays the foundation for data-efficient AI-driven drug discovery and precision nanomedicine."],"url":"http://arxiv.org/abs/2503.13798v1"}
{"created":"2025-03-18 00:50:40","title":"LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation","abstract":"Large foundation models trained on large-scale visual-text data can significantly enhance Open Vocabulary Object Detection (OVD) through data generation. However, this may lead to biased synthetic data and overfitting to specific configurations. It can sidestep biases of manually curated data generation by directly leveraging hidden states of Large Language Models (LLMs), which is surprisingly rarely explored. This paper presents a systematic method to enhance visual grounding by utilizing decoder layers of the LLM of a MLLM. We introduce a zero-initialized cross-attention adapter to enable efficient knowledge transfer from LLMs to object detectors, an new approach called LED (LLM Enhanced Open-Vocabulary Object Detection). We demonstrate that intermediate hidden states from early LLM layers retain strong spatial-semantic correlations that are beneficial to grounding tasks. Experiments show that our adaptation strategy significantly enhances the performance on complex free-form text queries while remaining the same on plain categories. With our adaptation, Qwen2-0.5B with Swin-T as the vision encoder improves GroundingDINO by 2.33% on Omnilabel, at the overhead of 8.7% more GFLOPs. Qwen2-0.5B with a larger vision encoder can further boost the performance by 6.22%. We further validate our design by ablating on varied adapter architectures, sizes of LLMs, and which layers to add adaptation.","sentences":["Large foundation models trained on large-scale visual-text data can significantly enhance Open Vocabulary Object Detection (OVD) through data generation.","However, this may lead to biased synthetic data and overfitting to specific configurations.","It can sidestep biases of manually curated data generation by directly leveraging hidden states of Large Language Models (LLMs), which is surprisingly rarely explored.","This paper presents a systematic method to enhance visual grounding by utilizing decoder layers of the LLM of a MLLM.","We introduce a zero-initialized cross-attention adapter to enable efficient knowledge transfer from LLMs to object detectors, an new approach called LED (LLM Enhanced Open-Vocabulary Object Detection).","We demonstrate that intermediate hidden states from early LLM layers retain strong spatial-semantic correlations that are beneficial to grounding tasks.","Experiments show that our adaptation strategy significantly enhances the performance on complex free-form text queries while remaining the same on plain categories.","With our adaptation, Qwen2-0.5B with Swin-T as the vision encoder improves GroundingDINO by 2.33% on Omnilabel, at the overhead of 8.7% more GFLOPs.","Qwen2-0.5B with a larger vision encoder can further boost the performance by 6.22%.","We further validate our design by ablating on varied adapter architectures, sizes of LLMs, and which layers to add adaptation."],"url":"http://arxiv.org/abs/2503.13794v1"}
