{"created":"2024-03-20 17:59:58","title":"On Pretraining Data Diversity for Self-Supervised Learning","abstract":"We explore the impact of training with more diverse datasets, characterized by the number of unique samples, on the performance of self-supervised learning (SSL) under a fixed computational budget. Our findings consistently demonstrate that increasing pretraining data diversity enhances SSL performance, albeit only when the distribution distance to the downstream data is minimal. Notably, even with an exceptionally large pretraining data diversity achieved through methods like web crawling or diffusion-generated data, among other ways, the distribution shift remains a challenge. Our experiments are comprehensive with seven SSL methods using large-scale datasets such as ImageNet and YFCC100M amounting to over 200 GPU days. Code and trained models will be available at https://github.com/hammoudhasan/DiversitySSL .","sentences":["We explore the impact of training with more diverse datasets, characterized by the number of unique samples, on the performance of self-supervised learning (SSL) under a fixed computational budget.","Our findings consistently demonstrate that increasing pretraining data diversity enhances SSL performance, albeit only when the distribution distance to the downstream data is minimal.","Notably, even with an exceptionally large pretraining data diversity achieved through methods like web crawling or diffusion-generated data, among other ways, the distribution shift remains a challenge.","Our experiments are comprehensive with seven SSL methods using large-scale datasets such as ImageNet and YFCC100M amounting to over 200 GPU days.","Code and trained models will be available at https://github.com/hammoudhasan/DiversitySSL ."],"url":"http://arxiv.org/abs/2403.13808v1"}
{"created":"2024-03-20 17:59:43","title":"Learning from Models and Data for Visual Grounding","abstract":"We introduce SynGround, a novel framework that combines data-driven learning and knowledge transfer from various large-scale pretrained models to enhance the visual grounding capabilities of a pretrained vision-and-language model. The knowledge transfer from the models initiates the generation of image descriptions through an image description generator. These descriptions serve dual purposes: they act as prompts for synthesizing images through a text-to-image generator, and as queries for synthesizing text, from which phrases are extracted using a large language model. Finally, we leverage an open-vocabulary object detector to generate synthetic bounding boxes for the synthetic images and texts. We finetune a pretrained vision-and-language model on this dataset by optimizing a mask-attention consistency objective that aligns region annotations with gradient-based model explanations. The resulting model improves the grounding capabilities of an off-the-shelf vision-and-language model. Particularly, SynGround improves the pointing game accuracy of ALBEF on the Flickr30k dataset from 79.38% to 87.26%, and on RefCOCO+ Test A from 69.35% to 79.06% and on RefCOCO+ Test B from 53.77% to 63.67%.","sentences":["We introduce SynGround, a novel framework that combines data-driven learning and knowledge transfer from various large-scale pretrained models to enhance the visual grounding capabilities of a pretrained vision-and-language model.","The knowledge transfer from the models initiates the generation of image descriptions through an image description generator.","These descriptions serve dual purposes: they act as prompts for synthesizing images through a text-to-image generator, and as queries for synthesizing text, from which phrases are extracted using a large language model.","Finally, we leverage an open-vocabulary object detector to generate synthetic bounding boxes for the synthetic images and texts.","We finetune a pretrained vision-and-language model on this dataset by optimizing a mask-attention consistency objective that aligns region annotations with gradient-based model explanations.","The resulting model improves the grounding capabilities of an off-the-shelf vision-and-language model.","Particularly, SynGround improves the pointing game accuracy of ALBEF on the Flickr30k dataset from 79.38% to 87.26%, and on RefCOCO+ Test A from 69.35% to 79.06% and on RefCOCO+ Test B from 53.77% to 63.67%."],"url":"http://arxiv.org/abs/2403.13804v1"}
{"created":"2024-03-20 17:59:16","title":"Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments","abstract":"Bounding boxes uniquely characterize object detection, where a good detector gives accurate bounding boxes of categories of interest. However, in the real-world where test ground truths are not provided, it is non-trivial to find out whether bounding boxes are accurate, thus preventing us from assessing the detector generalization ability. In this work, we find under feature map dropout, good detectors tend to output bounding boxes whose locations do not change much, while bounding boxes of poor detectors will undergo noticeable position changes. We compute the box stability score (BoS score) to reflect this stability. Specifically, given an image, we compute a normal set of bounding boxes and a second set after feature map dropout. To obtain BoS score, we use bipartite matching to find the corresponding boxes between the two sets and compute the average Intersection over Union (IoU) across the entire test set. We contribute to finding that BoS score has a strong, positive correlation with detection accuracy measured by mean average precision (mAP) under various test environments. This relationship allows us to predict the accuracy of detectors on various real-world test sets without accessing test ground truths, verified on canonical detection tasks such as vehicle detection and pedestrian detection. Code and data are available at https://github.com/YangYangGirl/BoS.","sentences":["Bounding boxes uniquely characterize object detection, where a good detector gives accurate bounding boxes of categories of interest.","However, in the real-world where test ground truths are not provided, it is non-trivial to find out whether bounding boxes are accurate, thus preventing us from assessing the detector generalization ability.","In this work, we find under feature map dropout, good detectors tend to output bounding boxes whose locations do not change much, while bounding boxes of poor detectors will undergo noticeable position changes.","We compute the box stability score (BoS score) to reflect this stability.","Specifically, given an image, we compute a normal set of bounding boxes and a second set after feature map dropout.","To obtain BoS score, we use bipartite matching to find the corresponding boxes between the two sets and compute the average Intersection over Union (IoU) across the entire test set.","We contribute to finding that BoS score has a strong, positive correlation with detection accuracy measured by mean average precision (mAP) under various test environments.","This relationship allows us to predict the accuracy of detectors on various real-world test sets without accessing test ground truths, verified on canonical detection tasks such as vehicle detection and pedestrian detection.","Code and data are available at https://github.com/YangYangGirl/BoS."],"url":"http://arxiv.org/abs/2403.13803v1"}
{"created":"2024-03-20 17:59:14","title":"ZigMa: Zigzag Mamba Diffusion Model","abstract":"The diffusion model has long been plagued by scalability and quadratic complexity issues, especially within transformer-based structures. In this study, we aim to leverage the long sequence modeling capability of a State-Space Model called Mamba to extend its applicability to visual data generation. Firstly, we identify a critical oversight in most current Mamba-based vision methods, namely the lack of consideration for spatial continuity in the scan scheme of Mamba. Secondly, building upon this insight, we introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba, which outperforms Mamba-based baselines and demonstrates improved speed and memory utilization compared to transformer-based baselines. Lastly, we integrate Zigzag Mamba with the Stochastic Interpolant framework to investigate the scalability of the model on large-resolution visual datasets, such as FacesHQ $1024\\times 1024$ and UCF101, MultiModal-CelebA-HQ, and MS COCO $256\\times 256$. Code will be released at https://taohu.me/zigma/","sentences":["The diffusion model has long been plagued by scalability and quadratic complexity issues, especially within transformer-based structures.","In this study, we aim to leverage the long sequence modeling capability of a State-Space Model called Mamba to extend its applicability to visual data generation.","Firstly, we identify a critical oversight in most current Mamba-based vision methods, namely the lack of consideration for spatial continuity in the scan scheme of Mamba.","Secondly, building upon this insight, we introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba, which outperforms Mamba-based baselines and demonstrates improved speed and memory utilization compared to transformer-based baselines.","Lastly, we integrate Zigzag Mamba with the Stochastic Interpolant framework to investigate the scalability of the model on large-resolution visual datasets, such as FacesHQ $1024\\times 1024$ and UCF101, MultiModal-CelebA-HQ, and MS COCO $256\\times 256$. Code will be released at https://taohu.me/zigma/"],"url":"http://arxiv.org/abs/2403.13802v1"}
{"created":"2024-03-20 17:57:02","title":"TimeRewind: Rewinding Time with Image-and-Events Video Diffusion","abstract":"This paper addresses the novel challenge of ``rewinding'' time from a single captured image to recover the fleeting moments missed just before the shutter button is pressed. This problem poses a significant challenge in computer vision and computational photography, as it requires predicting plausible pre-capture motion from a single static frame, an inherently ill-posed task due to the high degree of freedom in potential pixel movements. We overcome this challenge by leveraging the emerging technology of neuromorphic event cameras, which capture motion information with high temporal resolution, and integrating this data with advanced image-to-video diffusion models. Our proposed framework introduces an event motion adaptor conditioned on event camera data, guiding the diffusion model to generate videos that are visually coherent and physically grounded in the captured events. Through extensive experimentation, we demonstrate the capability of our approach to synthesize high-quality videos that effectively ``rewind'' time, showcasing the potential of combining event camera technology with generative models. Our work opens new avenues for research at the intersection of computer vision, computational photography, and generative modeling, offering a forward-thinking solution to capturing missed moments and enhancing future consumer cameras and smartphones. Please see the project page at https://timerewind.github.io/ for video results and code release.","sentences":["This paper addresses the novel challenge of ``rewinding'' time from a single captured image to recover the fleeting moments missed just before the shutter button is pressed.","This problem poses a significant challenge in computer vision and computational photography, as it requires predicting plausible pre-capture motion from a single static frame, an inherently ill-posed task due to the high degree of freedom in potential pixel movements.","We overcome this challenge by leveraging the emerging technology of neuromorphic event cameras, which capture motion information with high temporal resolution, and integrating this data with advanced image-to-video diffusion models.","Our proposed framework introduces an event motion adaptor conditioned on event camera data, guiding the diffusion model to generate videos that are visually coherent and physically grounded in the captured events.","Through extensive experimentation, we demonstrate the capability of our approach to synthesize high-quality videos that effectively ``rewind'' time, showcasing the potential of combining event camera technology with generative models.","Our work opens new avenues for research at the intersection of computer vision, computational photography, and generative modeling, offering a forward-thinking solution to capturing missed moments and enhancing future consumer cameras and smartphones.","Please see the project page at https://timerewind.github.io/ for video results and code release."],"url":"http://arxiv.org/abs/2403.13800v1"}
{"created":"2024-03-20 17:55:35","title":"Reverse Training to Nurse the Reversal Curse","abstract":"Large language models (LLMs) have a surprising failure: when trained on \"A has a feature B\", they do not generalize to \"B is a feature of A\", which is termed the Reversal Curse. Even when training with trillions of tokens this issue still appears due to Zipf's law - hence even if we train on the entire internet. This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens. The LLM is trained in both forward and reverse directions by reversing the training strings while preserving (i.e., not reversing) chosen substrings, such as entities. We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue.","sentences":["Large language models (LLMs) have a surprising failure: when trained on \"A has a feature B\", they do not generalize to \"B is a feature of A\", which is termed the Reversal Curse.","Even when training with trillions of tokens this issue still appears due to Zipf's law - hence even if we train on the entire internet.","This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens.","The LLM is trained in both forward and reverse directions by reversing the training strings while preserving (i.e., not reversing) chosen substrings, such as entities.","We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue."],"url":"http://arxiv.org/abs/2403.13799v1"}
{"created":"2024-03-20 17:55:21","title":"Hierarchical NeuroSymbolic Approach for Action Quality Assessment","abstract":"Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action. Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth. To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols. We take diving as the case study. We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving. Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence. As verified by a group of domain experts, this report may be used to assist judges in scoring, help train judges, and provide feedback to divers. We will open-source all of our annotated training data and code for ease of reproducibility.","sentences":["Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action.","Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth.","To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols.","We take diving as the case study.","We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving.","Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence.","As verified by a group of domain experts, this report may be used to assist judges in scoring, help train judges, and provide feedback to divers.","We will open-source all of our annotated training data and code for ease of reproducibility."],"url":"http://arxiv.org/abs/2403.13798v1"}
{"created":"2024-03-20 17:54:58","title":"Bridge the Modality and Capacity Gaps in Vision-Language Model Selection","abstract":"Vision Language Models (VLMs) excel in zero-shot image classification by pairing images with textual category names. The expanding variety of Pre-Trained VLMs enhances the likelihood of identifying a suitable VLM for specific tasks. Thus, a promising zero-shot image classification strategy is selecting the most appropriate Pre-Trained VLM from the VLM Zoo, relying solely on the text data of the target dataset without access to the dataset's images. In this paper, we analyze two inherent challenges in assessing the ability of a VLM in this Language-Only VLM selection: the \"Modality Gap\" -- the disparity in VLM's embeddings across two different modalities, making text a less reliable substitute for images; and the \"Capability Gap\" -- the discrepancy between the VLM's overall ranking and its ranking for target dataset, hindering direct prediction of a model's dataset-specific performance from its general performance. We propose VLM Selection With gAp Bridging (SWAB) to mitigate the negative impact of these two gaps. SWAB first adopts optimal transport to capture the relevance between open-source datasets and target dataset with a transportation matrix. It then uses this matrix to transfer useful statistics of VLMs from open-source datasets to the target dataset for bridging those two gaps and enhancing the VLM's capacity estimation for VLM selection. Experiments across various VLMs and image classification datasets validate SWAB's effectiveness.","sentences":["Vision Language Models (VLMs) excel in zero-shot image classification by pairing images with textual category names.","The expanding variety of Pre-Trained VLMs enhances the likelihood of identifying a suitable VLM for specific tasks.","Thus, a promising zero-shot image classification strategy is selecting the most appropriate Pre-Trained VLM from the VLM Zoo, relying solely on the text data of the target dataset without access to the dataset's images.","In this paper, we analyze two inherent challenges in assessing the ability of a VLM in this Language-Only VLM selection: the \"Modality Gap\" -- the disparity in VLM's embeddings across two different modalities, making text a less reliable substitute for images; and the \"Capability Gap\" -- the discrepancy between the VLM's overall ranking and its ranking for target dataset, hindering direct prediction of a model's dataset-specific performance from its general performance.","We propose VLM Selection With gAp Bridging (SWAB) to mitigate the negative impact of these two gaps.","SWAB first adopts optimal transport to capture the relevance between open-source datasets and target dataset with a transportation matrix.","It then uses this matrix to transfer useful statistics of VLMs from open-source datasets to the target dataset for bridging those two gaps and enhancing the VLM's capacity estimation for VLM selection.","Experiments across various VLMs and image classification datasets validate SWAB's effectiveness."],"url":"http://arxiv.org/abs/2403.13797v1"}
{"created":"2024-03-20 17:51:53","title":"DepthFM: Fast Monocular Depth Estimation with Flow Matching","abstract":"Monocular depth estimation is crucial for numerous downstream vision tasks and applications. Current discriminative approaches to this problem are limited due to blurry artifacts, while state-of-the-art generative methods suffer from slow sampling due to their SDE nature. Rather than starting from noise, we seek a direct mapping from input image to depth map. We observe that this can be effectively framed using flow matching, since its straight trajectories through solution space offer efficiency and high quality. Our study demonstrates that a pre-trained image diffusion model can serve as an adequate prior for a flow matching depth model, allowing efficient training on only synthetic data to generalize to real images. We find that an auxiliary surface normals loss further improves the depth estimates. Due to the generative nature of our approach, our model reliably predicts the confidence of its depth estimates. On standard benchmarks of complex natural scenes, our lightweight approach exhibits state-of-the-art performance at favorable low computational cost despite only being trained on little synthetic data.","sentences":["Monocular depth estimation is crucial for numerous downstream vision tasks and applications.","Current discriminative approaches to this problem are limited due to blurry artifacts, while state-of-the-art generative methods suffer from slow sampling due to their SDE nature.","Rather than starting from noise, we seek a direct mapping from input image to depth map.","We observe that this can be effectively framed using flow matching, since its straight trajectories through solution space offer efficiency and high quality.","Our study demonstrates that a pre-trained image diffusion model can serve as an adequate prior for a flow matching depth model, allowing efficient training on only synthetic data to generalize to real images.","We find that an auxiliary surface normals loss further improves the depth estimates.","Due to the generative nature of our approach, our model reliably predicts the confidence of its depth estimates.","On standard benchmarks of complex natural scenes, our lightweight approach exhibits state-of-the-art performance at favorable low computational cost despite only being trained on little synthetic data."],"url":"http://arxiv.org/abs/2403.13788v1"}
{"created":"2024-03-20 17:47:08","title":"The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency and Usability in AI","abstract":"Generative AI (GAI) offers unprecedented possibilities but its commercialization has raised concerns about transparency, reproducibility, bias, and safety. Many \"open-source\" GAI models lack the necessary components for full understanding and reproduction, and some use restrictive licenses, a practice known as \"openwashing.\" We propose the Model Openness Framework (MOF), a ranked classification system that rates machine learning models based on their completeness and openness, following principles of open science, open source, open data, and open access. The MOF requires specific components of the model development lifecycle to be included and released under appropriate open licenses. This framework aims to prevent misrepresentation of models claiming to be open, guide researchers and developers in providing all model components under permissive licenses, and help companies, academia, and hobbyists identify models that can be safely adopted without restrictions. Wide adoption of the MOF will foster a more open AI ecosystem, accelerating research, innovation, and adoption.","sentences":["Generative AI (GAI) offers unprecedented possibilities but its commercialization has raised concerns about transparency, reproducibility, bias, and safety.","Many \"open-source\" GAI models lack the necessary components for full understanding and reproduction, and some use restrictive licenses, a practice known as \"openwashing.\"","We propose the Model Openness Framework (MOF), a ranked classification system that rates machine learning models based on their completeness and openness, following principles of open science, open source, open data, and open access.","The MOF requires specific components of the model development lifecycle to be included and released under appropriate open licenses.","This framework aims to prevent misrepresentation of models claiming to be open, guide researchers and developers in providing all model components under permissive licenses, and help companies, academia, and hobbyists identify models that can be safely adopted without restrictions.","Wide adoption of the MOF will foster a more open AI ecosystem, accelerating research, innovation, and adoption."],"url":"http://arxiv.org/abs/2403.13784v1"}
{"created":"2024-03-20 17:43:58","title":"Sparse Implementation of Versatile Graph-Informed Layers","abstract":"Graph Neural Networks (GNNs) have emerged as effective tools for learning tasks on graph-structured data. Recently, Graph-Informed (GI) layers were introduced to address regression tasks on graph nodes, extending their applicability beyond classic GNNs. However, existing implementations of GI layers lack efficiency due to dense memory allocation. This paper presents a sparse implementation of GI layers, leveraging the sparsity of adjacency matrices to reduce memory usage significantly. Additionally, a versatile general form of GI layers is introduced, enabling their application to subsets of graph nodes. The proposed sparse implementation improves the concrete computational efficiency and scalability of the GI layers, permitting to build deeper Graph-Informed Neural Networks (GINNs) and facilitating their scalability to larger graphs.","sentences":["Graph Neural Networks (GNNs) have emerged as effective tools for learning tasks on graph-structured data.","Recently, Graph-Informed (GI) layers were introduced to address regression tasks on graph nodes, extending their applicability beyond classic GNNs.","However, existing implementations of GI layers lack efficiency due to dense memory allocation.","This paper presents a sparse implementation of GI layers, leveraging the sparsity of adjacency matrices to reduce memory usage significantly.","Additionally, a versatile general form of GI layers is introduced, enabling their application to subsets of graph nodes.","The proposed sparse implementation improves the concrete computational efficiency and scalability of the GI layers, permitting to build deeper Graph-Informed Neural Networks (GINNs) and facilitating their scalability to larger graphs."],"url":"http://arxiv.org/abs/2403.13781v1"}
{"created":"2024-03-20 17:41:21","title":"Embedding Pose Graph, Enabling 3D Foundation Model Capabilities with a Compact Representation","abstract":"This paper presents the Embedding Pose Graph (EPG), an innovative method that combines the strengths of foundation models with a simple 3D representation suitable for robotics applications. Addressing the need for efficient spatial understanding in robotics, EPG provides a compact yet powerful approach by attaching foundation model features to the nodes of a pose graph. Unlike traditional methods that rely on bulky data formats like voxel grids or point clouds, EPG is lightweight and scalable. It facilitates a range of robotic tasks, including open-vocabulary querying, disambiguation, image-based querying, language-directed navigation, and re-localization in 3D environments. We showcase the effectiveness of EPG in handling these tasks, demonstrating its capacity to improve how robots interact with and navigate through complex spaces. Through both qualitative and quantitative assessments, we illustrate EPG's strong performance and its ability to outperform existing methods in re-localization. Our work introduces a crucial step forward in enabling robots to efficiently understand and operate within large-scale 3D spaces.","sentences":["This paper presents the Embedding Pose Graph (EPG), an innovative method that combines the strengths of foundation models with a simple 3D representation suitable for robotics applications.","Addressing the need for efficient spatial understanding in robotics, EPG provides a compact yet powerful approach by attaching foundation model features to the nodes of a pose graph.","Unlike traditional methods that rely on bulky data formats like voxel grids or point clouds, EPG is lightweight and scalable.","It facilitates a range of robotic tasks, including open-vocabulary querying, disambiguation, image-based querying, language-directed navigation, and re-localization in 3D environments.","We showcase the effectiveness of EPG in handling these tasks, demonstrating its capacity to improve how robots interact with and navigate through complex spaces.","Through both qualitative and quantitative assessments, we illustrate EPG's strong performance and its ability to outperform existing methods in re-localization.","Our work introduces a crucial step forward in enabling robots to efficiently understand and operate within large-scale 3D spaces."],"url":"http://arxiv.org/abs/2403.13777v1"}
{"created":"2024-03-20 17:33:02","title":"Describe-and-Dissect: Interpreting Neurons in Vision Networks with Language Models","abstract":"In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks. DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from. Additionally, DnD is training-free, meaning we don't train any new models and can easily leverage more capable general purpose models in the future. We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions. Specifically, our method on average provides the highest quality labels and is more than 2 times as likely to be selected as the best explanation for a neuron than the best baseline.","sentences":["In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks.","DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from.","Additionally, DnD is training-free, meaning we don't train any new models and can easily leverage more capable general purpose models in the future.","We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions.","Specifically, our method on average provides the highest quality labels and is more than 2 times as likely to be selected as the best explanation for a neuron than the best baseline."],"url":"http://arxiv.org/abs/2403.13771v1"}
{"created":"2024-03-20 17:28:17","title":"Towards Principled Representation Learning from Videos for Reinforcement Learning","abstract":"We study pre-training representations for decision-making using video data, which is abundantly available for tasks such as game agents and software testing. Even though significant empirical advances have been made on this problem, a theoretical understanding remains absent. We initiate the theoretical investigation into principled approaches for representation learning and focus on learning the latent state representations of the underlying MDP using video data. We study two types of settings: one where there is iid noise in the observation, and a more challenging setting where there is also the presence of exogenous noise, which is non-iid noise that is temporally correlated, such as the motion of people or cars in the background. We study three commonly used approaches: autoencoding, temporal contrastive learning, and forward modeling. We prove upper bounds for temporal contrastive learning and forward modeling in the presence of only iid noise. We show that these approaches can learn the latent state and use it to do efficient downstream RL with polynomial sample complexity. When exogenous noise is also present, we establish a lower bound result showing that the sample complexity of learning from video data can be exponentially worse than learning from action-labeled trajectory data. This partially explains why reinforcement learning with video pre-training is hard. We evaluate these representational learning methods in two visual domains, yielding results that are consistent with our theoretical findings.","sentences":["We study pre-training representations for decision-making using video data, which is abundantly available for tasks such as game agents and software testing.","Even though significant empirical advances have been made on this problem, a theoretical understanding remains absent.","We initiate the theoretical investigation into principled approaches for representation learning and focus on learning the latent state representations of the underlying MDP using video data.","We study two types of settings: one where there is iid noise in the observation, and a more challenging setting where there is also the presence of exogenous noise, which is non-iid noise that is temporally correlated, such as the motion of people or cars in the background.","We study three commonly used approaches: autoencoding, temporal contrastive learning, and forward modeling.","We prove upper bounds for temporal contrastive learning and forward modeling in the presence of only iid noise.","We show that these approaches can learn the latent state and use it to do efficient downstream RL with polynomial sample complexity.","When exogenous noise is also present, we establish a lower bound result showing that the sample complexity of learning from video data can be exponentially worse than learning from action-labeled trajectory data.","This partially explains why reinforcement learning with video pre-training is hard.","We evaluate these representational learning methods in two visual domains, yielding results that are consistent with our theoretical findings."],"url":"http://arxiv.org/abs/2403.13765v1"}
{"created":"2024-03-20 17:20:48","title":"When Cars meet Drones: Hyperbolic Federated Learning for Source-Free Domain Adaptation in Adverse Weather","abstract":"In Federated Learning (FL), multiple clients collaboratively train a global model without sharing private data. In semantic segmentation, the Federated source Free Domain Adaptation (FFreeDA) setting is of particular interest, where clients undergo unsupervised training after supervised pretraining at the server side. While few recent works address FL for autonomous vehicles, intrinsic real-world challenges such as the presence of adverse weather conditions and the existence of different autonomous agents are still unexplored. To bridge this gap, we address both problems and introduce a new federated semantic segmentation setting where both car and drone clients co-exist and collaborate. Specifically, we propose a novel approach for this setting which exploits a batch-norm weather-aware strategy to dynamically adapt the model to the different weather conditions, while hyperbolic space prototypes are used to align the heterogeneous client representations. Finally, we introduce FLYAWARE, the first semantic segmentation dataset with adverse weather data for aerial vehicles.","sentences":["In Federated Learning (FL), multiple clients collaboratively train a global model without sharing private data.","In semantic segmentation, the Federated source Free Domain Adaptation (FFreeDA) setting is of particular interest, where clients undergo unsupervised training after supervised pretraining at the server side.","While few recent works address FL for autonomous vehicles, intrinsic real-world challenges such as the presence of adverse weather conditions and the existence of different autonomous agents are still unexplored.","To bridge this gap, we address both problems and introduce a new federated semantic segmentation setting where both car and drone clients co-exist and collaborate.","Specifically, we propose a novel approach for this setting which exploits a batch-norm weather-aware strategy to dynamically adapt the model to the different weather conditions, while hyperbolic space prototypes are used to align the heterogeneous client representations.","Finally, we introduce FLYAWARE, the first semantic segmentation dataset with adverse weather data for aerial vehicles."],"url":"http://arxiv.org/abs/2403.13762v1"}
{"created":"2024-03-20 16:53:45","title":"Be-Your-Outpainter: Mastering Video Outpainting through Input-Specific Adaptation","abstract":"Video outpainting is a challenging task, aiming at generating video content outside the viewport of the input video while maintaining inter-frame and intra-frame consistency. Existing methods fall short in either generation quality or flexibility. We introduce MOTIA Mastering Video Outpainting Through Input-Specific Adaptation, a diffusion-based pipeline that leverages both the intrinsic data-specific patterns of the source video and the image/video generative prior for effective outpainting. MOTIA comprises two main phases: input-specific adaptation and pattern-aware outpainting. The input-specific adaptation phase involves conducting efficient and effective pseudo outpainting learning on the single-shot source video. This process encourages the model to identify and learn patterns within the source video, as well as bridging the gap between standard generative processes and outpainting. The subsequent phase, pattern-aware outpainting, is dedicated to the generalization of these learned patterns to generate outpainting outcomes. Additional strategies including spatial-aware insertion and noise travel are proposed to better leverage the diffusion model's generative prior and the acquired video patterns from source videos. Extensive evaluations underscore MOTIA's superiority, outperforming existing state-of-the-art methods in widely recognized benchmarks. Notably, these advancements are achieved without necessitating extensive, task-specific tuning.","sentences":["Video outpainting is a challenging task, aiming at generating video content outside the viewport of the input video while maintaining inter-frame and intra-frame consistency.","Existing methods fall short in either generation quality or flexibility.","We introduce MOTIA Mastering Video","Outpainting Through Input-Specific Adaptation, a diffusion-based pipeline that leverages both the intrinsic data-specific patterns of the source video and the image/video generative prior for effective outpainting.","MOTIA comprises two main phases: input-specific adaptation and pattern-aware outpainting.","The input-specific adaptation phase involves conducting efficient and effective pseudo outpainting learning on the single-shot source video.","This process encourages the model to identify and learn patterns within the source video, as well as bridging the gap between standard generative processes and outpainting.","The subsequent phase, pattern-aware outpainting, is dedicated to the generalization of these learned patterns to generate outpainting outcomes.","Additional strategies including spatial-aware insertion and noise travel are proposed to better leverage the diffusion model's generative prior and the acquired video patterns from source videos.","Extensive evaluations underscore MOTIA's superiority, outperforming existing state-of-the-art methods in widely recognized benchmarks.","Notably, these advancements are achieved without necessitating extensive, task-specific tuning."],"url":"http://arxiv.org/abs/2403.13745v1"}
{"created":"2024-03-20 16:33:06","title":"Probabilistic Forecasting with Stochastic Interpolants and F\u00f6llmer Processes","abstract":"We propose a framework for probabilistic forecasting of dynamical systems based on generative modeling. Given observations of the system state over time, we formulate the forecasting problem as sampling from the conditional distribution of the future system state given its current state. To this end, we leverage the framework of stochastic interpolants, which facilitates the construction of a generative model between an arbitrary base distribution and the target. We design a fictitious, non-physical stochastic dynamics that takes as initial condition the current system state and produces as output a sample from the target conditional distribution in finite time and without bias. This process therefore maps a point mass centered at the current state onto a probabilistic ensemble of forecasts. We prove that the drift coefficient entering the stochastic differential equation (SDE) achieving this task is non-singular, and that it can be learned efficiently by square loss regression over the time-series data. We show that the drift and the diffusion coefficients of this SDE can be adjusted after training, and that a specific choice that minimizes the impact of the estimation error gives a F\\\"ollmer process. We highlight the utility of our approach on several complex, high-dimensional forecasting problems, including stochastically forced Navier-Stokes and video prediction on the KTH and CLEVRER datasets.","sentences":["We propose a framework for probabilistic forecasting of dynamical systems based on generative modeling.","Given observations of the system state over time, we formulate the forecasting problem as sampling from the conditional distribution of the future system state given its current state.","To this end, we leverage the framework of stochastic interpolants, which facilitates the construction of a generative model between an arbitrary base distribution and the target.","We design a fictitious, non-physical stochastic dynamics that takes as initial condition the current system state and produces as output a sample from the target conditional distribution in finite time and without bias.","This process therefore maps a point mass centered at the current state onto a probabilistic ensemble of forecasts.","We prove that the drift coefficient entering the stochastic differential equation (SDE) achieving this task is non-singular, and that it can be learned efficiently by square loss regression over the time-series data.","We show that the drift and the diffusion coefficients of this SDE can be adjusted after training, and that a specific choice that minimizes the impact of the estimation error gives a F\\\"ollmer process.","We highlight the utility of our approach on several complex, high-dimensional forecasting problems, including stochastically forced Navier-Stokes and video prediction on the KTH and CLEVRER datasets."],"url":"http://arxiv.org/abs/2403.13724v1"}
{"created":"2024-03-20 16:27:13","title":"UTDUSS: UTokyo-SaruLab System for Interspeech2024 Speech Processing Using Discrete Speech Unit Challenge","abstract":"We present UTDUSS, the UTokyo-SaruLab system submitted to Interspeech2024 Speech Processing Using Discrete Speech Unit Challenge. The challenge focuses on using discrete speech unit learned from large speech corpora for some tasks. We submitted our UTDUSS system to two text-to-speech tracks: Vocoder and Acoustic+Vocoder. Our system incorporates neural audio codec (NAC) pre-trained on only speech corpora, which makes the learned codec represent rich acoustic features that are necessary for high-fidelity speech reconstruction. For the acoustic+vocoder track, we trained an acoustic model based on Transformer encoder-decoder that predicted the pre-trained NAC tokens from text input. We describe our strategies to build these models, such as data selection, downsampling, and hyper-parameter tuning. Our system ranked in second and first for the Vocoder and Acoustic+Vocoder tracks, respectively.","sentences":["We present UTDUSS, the UTokyo-SaruLab system submitted to Interspeech2024","Speech Processing Using Discrete Speech Unit Challenge.","The challenge focuses on using discrete speech unit learned from large speech corpora for some tasks.","We submitted our UTDUSS system to two text-to-speech tracks: Vocoder and Acoustic+Vocoder.","Our system incorporates neural audio codec (NAC) pre-trained on only speech corpora, which makes the learned codec represent rich acoustic features that are necessary for high-fidelity speech reconstruction.","For the acoustic+vocoder track, we trained an acoustic model based on Transformer encoder-decoder that predicted the pre-trained NAC tokens from text input.","We describe our strategies to build these models, such as data selection, downsampling, and hyper-parameter tuning.","Our system ranked in second and first for the Vocoder and Acoustic+Vocoder tracks, respectively."],"url":"http://arxiv.org/abs/2403.13720v1"}
{"created":"2024-03-20 16:22:53","title":"Agent-based MST Construction","abstract":"{\\em Minimum-weight spanning tree} (MST) is one of the fundamental and well-studied problems in distributed computing. In this paper, we initiate the study of constructing MST using mobile agents (aka robots). Suppose $n$ agents are positioned initially arbitrarily on the nodes of a connected, undirected, arbitrary, anonymous, port-labeled, weighted $n$-node, $m$-edge graph $G$ of diameter $D$ and maximum degree $\\Delta$. The agents relocate themselves autonomously and compute an MST of $G$ such that exactly one agent positions on a node and tracks in its memory which of its adjacent edges belong to the MST. The objective is to minimize time and memory requirements. Following the literature, we consider the synchronous setting in which each agent performs its operations synchronously with others and hence time can be measured in rounds. We first establish a generic result: if $n$ and $\\Delta$ are known a priori and memory per agent is as much as node memory in the message-passing model (of distributed computing), agents can simulate any $O(T)$-round deterministic algorithm for any problem in the message-passing model to the agent model in $O(\\Delta T \\log n+n\\log^2n)$ rounds. As a corollary, MST can be constructed in the agent model in $O(\\max\\{\\Delta \\sqrt{n} \\log n \\log^*n, \\Delta D \\log n,n\\log^2n\\})$ rounds simulating the celebrated $O(\\sqrt{n} \\log^*n +D)$-round GKP algorithm for MST in the message-passing model. We then establish that, without knowing any graph parameter a priori, there exists a deterministic algorithm to construct MST in the agent model in $O(m+n\\log n)$ rounds with $O(n \\log n)$ bits memory at each agent. The presented algorithm needs to overcome highly non-trivial challenges on how to synchronize agents in computing MST as they may initially be positioned arbitrarily on the graph nodes.","sentences":["{\\em Minimum-weight spanning tree} (MST) is one of the fundamental and well-studied problems in distributed computing.","In this paper, we initiate the study of constructing MST using mobile agents (aka robots).","Suppose $n$ agents are positioned initially arbitrarily on the nodes of a connected, undirected, arbitrary, anonymous, port-labeled, weighted $n$-node, $m$-edge graph $G$ of diameter $D$ and maximum degree $\\Delta$.","The agents relocate themselves autonomously and compute an MST of $G$ such that exactly one agent positions on a node and tracks in its memory which of its adjacent edges belong to the MST.","The objective is to minimize time and memory requirements.","Following the literature, we consider the synchronous setting in which each agent performs its operations synchronously with others and hence time can be measured in rounds.","We first establish a generic result: if $n$ and $\\Delta$ are known a priori and memory per agent is as much as node memory in the message-passing model (of distributed computing), agents can simulate any $O(T)$-round deterministic algorithm for any problem in the message-passing model to the agent model in $O(\\Delta T \\log n+n\\log^2n)$ rounds.","As a corollary, MST can be constructed in the agent model in $O(\\max\\{\\Delta \\sqrt{n} \\log n \\log^*n, \\Delta D \\log n,n\\log^2n\\})$ rounds simulating the celebrated $O(\\sqrt{n} \\log^*n +D)$-round GKP algorithm for MST in the message-passing model.","We then establish that, without knowing any graph parameter a priori, there exists a deterministic algorithm to construct MST in the agent model in $O(m+n\\log n)$ rounds with $O(n \\log n)$ bits memory at each agent.","The presented algorithm needs to overcome highly non-trivial challenges on how to synchronize agents in computing MST as they may initially be positioned arbitrarily on the graph nodes."],"url":"http://arxiv.org/abs/2403.13716v1"}
{"created":"2024-03-20 16:06:01","title":"What Matters for Active Texture Recognition With Vision-Based Tactile Sensors","abstract":"This paper explores active sensing strategies that employ vision-based tactile sensors for robotic perception and classification of fabric textures. We formalize the active sampling problem in the context of tactile fabric recognition and provide an implementation of information-theoretic exploration strategies based on minimizing predictive entropy and variance of probabilistic models. Through ablation studies and human experiments, we investigate which components are crucial for quick and reliable texture recognition. Along with the active sampling strategies, we evaluate neural network architectures, representations of uncertainty, influence of data augmentation, and dataset variability. By evaluating our method on a previously published Active Clothing Perception Dataset and on a real robotic system, we establish that the choice of the active exploration strategy has only a minor influence on the recognition accuracy, whereas data augmentation and dropout rate play a significantly larger role. In a comparison study, while humans achieve 66.9% recognition accuracy, our best approach reaches 90.0% in under 5 touches, highlighting that vision-based tactile sensors are highly effective for fabric texture recognition.","sentences":["This paper explores active sensing strategies that employ vision-based tactile sensors for robotic perception and classification of fabric textures.","We formalize the active sampling problem in the context of tactile fabric recognition and provide an implementation of information-theoretic exploration strategies based on minimizing predictive entropy and variance of probabilistic models.","Through ablation studies and human experiments, we investigate which components are crucial for quick and reliable texture recognition.","Along with the active sampling strategies, we evaluate neural network architectures, representations of uncertainty, influence of data augmentation, and dataset variability.","By evaluating our method on a previously published Active Clothing Perception Dataset and on a real robotic system, we establish that the choice of the active exploration strategy has only a minor influence on the recognition accuracy, whereas data augmentation and dropout rate play a significantly larger role.","In a comparison study, while humans achieve 66.9% recognition accuracy, our best approach reaches 90.0% in under 5 touches, highlighting that vision-based tactile sensors are highly effective for fabric texture recognition."],"url":"http://arxiv.org/abs/2403.13701v1"}
{"created":"2024-03-20 16:03:01","title":"Insight Into the Collocation of Multi-Source Satellite Imagery for Multi-Scale Vessel Detection","abstract":"Ship detection from satellite imagery using Deep Learning (DL) is an indispensable solution for maritime surveillance. However, applying DL models trained on one dataset to others having differences in spatial resolution and radiometric features requires many adjustments. To overcome this issue, this paper focused on the DL models trained on datasets that consist of different optical images and a combination of radar and optical data. When dealing with a limited number of training images, the performance of DL models via this approach was satisfactory. They could improve 5-20% of average precision, depending on the optical images tested. Likewise, DL models trained on the combined optical and radar dataset could be applied to both optical and radar images. Our experiments showed that the models trained on an optical dataset could be used for radar images, while those trained on a radar dataset offered very poor scores when applied to optical images.","sentences":["Ship detection from satellite imagery using Deep Learning (DL) is an indispensable solution for maritime surveillance.","However, applying DL models trained on one dataset to others having differences in spatial resolution and radiometric features requires many adjustments.","To overcome this issue, this paper focused on the DL models trained on datasets that consist of different optical images and a combination of radar and optical data.","When dealing with a limited number of training images, the performance of DL models via this approach was satisfactory.","They could improve 5-20% of average precision, depending on the optical images tested.","Likewise, DL models trained on the combined optical and radar dataset could be applied to both optical and radar images.","Our experiments showed that the models trained on an optical dataset could be used for radar images, while those trained on a radar dataset offered very poor scores when applied to optical images."],"url":"http://arxiv.org/abs/2403.13698v1"}
{"created":"2024-03-20 15:57:44","title":"Loss Regularizing Robotic Terrain Classification","abstract":"Locomotion mechanics of legged robots are suitable when pacing through difficult terrains. Recognising terrains for such robots are important to fully yoke the versatility of their movements. Consequently, robotic terrain classification becomes significant to classify terrains in real time with high accuracy. The conventional classifiers suffer from overfitting problem, low accuracy problem, high variance problem, and not suitable for live dataset. On the other hand, classifying a growing dataset is difficult for convolution based terrain classification. Supervised recurrent models are also not practical for this classification. Further, the existing recurrent architectures are still evolving to improve accuracy of terrain classification based on live variable-length sensory data collected from legged robots. This paper proposes a new semi-supervised method for terrain classification of legged robots, avoiding preprocessing of long variable-length dataset. The proposed method has a stacked Long Short-Term Memory architecture, including a new loss regularization. The proposed method solves the existing problems and improves accuracy. Comparison with the existing architectures show the improvements.","sentences":["Locomotion mechanics of legged robots are suitable when pacing through difficult terrains.","Recognising terrains for such robots are important to fully yoke the versatility of their movements.","Consequently, robotic terrain classification becomes significant to classify terrains in real time with high accuracy.","The conventional classifiers suffer from overfitting problem, low accuracy problem, high variance problem, and not suitable for live dataset.","On the other hand, classifying a growing dataset is difficult for convolution based terrain classification.","Supervised recurrent models are also not practical for this classification.","Further, the existing recurrent architectures are still evolving to improve accuracy of terrain classification based on live variable-length sensory data collected from legged robots.","This paper proposes a new semi-supervised method for terrain classification of legged robots, avoiding preprocessing of long variable-length dataset.","The proposed method has a stacked Long Short-Term Memory architecture, including a new loss regularization.","The proposed method solves the existing problems and improves accuracy.","Comparison with the existing architectures show the improvements."],"url":"http://arxiv.org/abs/2403.13695v1"}
{"created":"2024-03-20 15:56:31","title":"Overview of Publicly Available Degradation Data Sets for Tasks within Prognostics and Health Management","abstract":"Central to the efficacy of prognostics and health management methods is the acquisition and analysis of degradation data, which encapsulates the evolving health condition of engineering systems over time. Degradation data serves as a rich source of information, offering invaluable insights into the underlying degradation processes, failure modes, and performance trends of engineering systems. This paper provides an overview of publicly available degradation data sets.","sentences":["Central to the efficacy of prognostics and health management methods is the acquisition and analysis of degradation data, which encapsulates the evolving health condition of engineering systems over time.","Degradation data serves as a rich source of information, offering invaluable insights into the underlying degradation processes, failure modes, and performance trends of engineering systems.","This paper provides an overview of publicly available degradation data sets."],"url":"http://arxiv.org/abs/2403.13694v1"}
{"created":"2024-03-20 15:41:39","title":"SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning","abstract":"Generalized Category Discovery (GCD) aims to classify unlabelled images from both `seen' and `unseen' classes by transferring knowledge from a set of labelled `seen' class images. A key theme in existing GCD approaches is adapting large-scale pre-trained models for the GCD task. An alternate perspective, however, is to adapt the data representation itself for better alignment with the pre-trained model. As such, in this paper, we introduce a two-stage adaptation approach termed SPTNet, which iteratively optimizes model parameters (i.e., model-finetuning) and data parameters (i.e., prompt learning). Furthermore, we propose a novel spatial prompt tuning method (SPT) which considers the spatial property of image data, enabling the method to better focus on object parts, which can transfer between seen and unseen classes. We thoroughly evaluate our SPTNet on standard benchmarks and demonstrate that our method outperforms existing GCD methods. Notably, we find our method achieves an average accuracy of 61.4% on the SSB, surpassing prior state-of-the-art methods by approximately 10%. The improvement is particularly remarkable as our method yields extra parameters amounting to only 0.117% of those in the backbone architecture. Project page: https://visual-ai.github.io/sptnet.","sentences":["Generalized Category Discovery (GCD) aims to classify unlabelled images from both `seen' and `unseen' classes by transferring knowledge from a set of labelled `seen' class images.","A key theme in existing GCD approaches is adapting large-scale pre-trained models for the GCD task.","An alternate perspective, however, is to adapt the data representation itself for better alignment with the pre-trained model.","As such, in this paper, we introduce a two-stage adaptation approach termed SPTNet, which iteratively optimizes model parameters (i.e., model-finetuning) and data parameters (i.e., prompt learning).","Furthermore, we propose a novel spatial prompt tuning method (SPT) which considers the spatial property of image data, enabling the method to better focus on object parts, which can transfer between seen and unseen classes.","We thoroughly evaluate our SPTNet on standard benchmarks and demonstrate that our method outperforms existing GCD methods.","Notably, we find our method achieves an average accuracy of 61.4% on the SSB, surpassing prior state-of-the-art methods by approximately 10%.","The improvement is particularly remarkable as our method yields extra parameters amounting to only 0.117% of those in the backbone architecture.","Project page: https://visual-ai.github.io/sptnet."],"url":"http://arxiv.org/abs/2403.13684v1"}
{"created":"2024-03-20 15:40:18","title":"Threats, Attacks, and Defenses in Machine Unlearning: A Survey","abstract":"Recently, Machine Unlearning (MU) has gained considerable attention for its potential to improve AI safety by removing the influence of specific data from trained Machine Learning (ML) models. This process, known as knowledge removal, addresses concerns about data such as sensitivity, copyright restrictions, obsolescence, or low quality. This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten (RTBF). Therefore, strategic knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the ethical use and reliability of AI systems. Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service (MLaaS), allowing users to submit requests to erase data. However, recent research highlights vulnerabilities in machine unlearning systems, such as information leakage and malicious unlearning requests, that can lead to significant security and privacy concerns. Moreover, extensive research indicates that unlearning methods and prevalent attacks fulfill diverse roles within MU systems. For instance, unlearning can act as a mechanism to recover models from backdoor attacks, while backdoor attacks themselves can serve as an evaluation metric for unlearning effectiveness. This underscores the intricate relationship and complex interplay between these elements in maintaining system functionality and safety. Therefore, this survey seeks to bridge the gap between the extensive number of studies on threats, attacks, and defenses in machine unlearning and the absence of a comprehensive review that categorizes their taxonomy, methods, and solutions, thus offering valuable insights for future research directions and practical implementations.","sentences":["Recently, Machine Unlearning (MU) has gained considerable attention for its potential to improve AI safety by removing the influence of specific data from trained Machine Learning (ML) models.","This process, known as knowledge removal, addresses concerns about data such as sensitivity, copyright restrictions, obsolescence, or low quality.","This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten (RTBF).","Therefore, strategic knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the ethical use and reliability of AI systems.","Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service (MLaaS), allowing users to submit requests to erase data.","However, recent research highlights vulnerabilities in machine unlearning systems, such as information leakage and malicious unlearning requests, that can lead to significant security and privacy concerns.","Moreover, extensive research indicates that unlearning methods and prevalent attacks fulfill diverse roles within MU systems.","For instance, unlearning can act as a mechanism to recover models from backdoor attacks, while backdoor attacks themselves can serve as an evaluation metric for unlearning effectiveness.","This underscores the intricate relationship and complex interplay between these elements in maintaining system functionality and safety.","Therefore, this survey seeks to bridge the gap between the extensive number of studies on threats, attacks, and defenses in machine unlearning and the absence of a comprehensive review that categorizes their taxonomy, methods, and solutions, thus offering valuable insights for future research directions and practical implementations."],"url":"http://arxiv.org/abs/2403.13682v1"}
{"created":"2024-03-20 15:39:54","title":"PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned Language Model for Indian Legal Case Documents","abstract":"In this paper, we present PARAMANU-AYN, a language model based exclusively on case documents of the Supreme Court of India, the Constitution of India, and the Indian Penal Code. The novel Auto Regressive (AR) decoder based model is pretrained from scratch at a context size of 8192. We evaluated our pretrained legal model on perplexity metrics. We also instruction-tuned our pretrained model on a set of 10,763 instructions covering various legal tasks such as legal reasoning, judgement explanation, legal clause generation, legal drafting, legal contract drafting, case summarization, constitutional question-answering, etc. We also evaluated the responses of prompts for instruction-tuned models by GPT-3.5-Turbo on clarity, relevance, completeness, and legal reasoning metrics in a scale of 10. Our model can be run on CPU and achieved 42.46 tokens/sec CPU inference speed. We found that our models, despite not being pretrained on legal books, various legal contracts, and legal documents, were able to learn the domain knowledge required for drafting various legal contracts and legal clauses, and generalize to draft legal contracts and legal clauses with limited instruction tuning. Hence, we conclude that for a strong domain-specialized generative language model (such as legal), very large amounts of data are not required to develop models from scratch. We believe that this work is the first attempt to make a dedicated generative legal language model from scratch for Indian Supreme Court jurisdiction or in legal NLP overall. We plan to release our Paramanu-Ayn model at https://www.bharatgpts.com.","sentences":["In this paper, we present PARAMANU-AYN, a language model based exclusively on case documents of the Supreme Court of India, the Constitution of India, and the Indian Penal Code.","The novel Auto Regressive (AR) decoder based model is pretrained from scratch at a context size of 8192.","We evaluated our pretrained legal model on perplexity metrics.","We also instruction-tuned our pretrained model on a set of 10,763 instructions covering various legal tasks such as legal reasoning, judgement explanation, legal clause generation, legal drafting, legal contract drafting, case summarization, constitutional question-answering, etc.","We also evaluated the responses of prompts for instruction-tuned models by GPT-3.5-Turbo on clarity, relevance, completeness, and legal reasoning metrics in a scale of 10.","Our model can be run on CPU and achieved 42.46 tokens/sec CPU inference speed.","We found that our models, despite not being pretrained on legal books, various legal contracts, and legal documents, were able to learn the domain knowledge required for drafting various legal contracts and legal clauses, and generalize to draft legal contracts and legal clauses with limited instruction tuning.","Hence, we conclude that for a strong domain-specialized generative language model (such as legal), very large amounts of data are not required to develop models from scratch.","We believe that this work is the first attempt to make a dedicated generative legal language model from scratch for Indian Supreme Court jurisdiction or in legal NLP overall.","We plan to release our Paramanu-Ayn model at https://www.bharatgpts.com."],"url":"http://arxiv.org/abs/2403.13681v1"}
{"created":"2024-03-20 15:37:19","title":"AUD-TGN: Advancing Action Unit Detection with Temporal Convolution and GPT-2 in Wild Audiovisual Contexts","abstract":"Leveraging the synergy of both audio data and visual data is essential for understanding human emotions and behaviors, especially in in-the-wild setting. Traditional methods for integrating such multimodal information often stumble, leading to less-than-ideal outcomes in the task of facial action unit detection. To overcome these shortcomings, we propose a novel approach utilizing audio-visual multimodal data. This method enhances audio feature extraction by leveraging Mel Frequency Cepstral Coefficients (MFCC) and Log-Mel spectrogram features alongside a pre-trained VGGish network. Moreover, this paper adaptively captures fusion features across modalities by modeling the temporal relationships, and ultilizes a pre-trained GPT-2 model for sophisticated context-aware fusion of multimodal information. Our method notably improves the accuracy of AU detection by understanding the temporal and contextual nuances of the data, showcasing significant advancements in the comprehension of intricate scenarios. These findings underscore the potential of integrating temporal dynamics and contextual interpretation, paving the way for future research endeavors.","sentences":["Leveraging the synergy of both audio data and visual data is essential for understanding human emotions and behaviors, especially in in-the-wild setting.","Traditional methods for integrating such multimodal information often stumble, leading to less-than-ideal outcomes in the task of facial action unit detection.","To overcome these shortcomings, we propose a novel approach utilizing audio-visual multimodal data.","This method enhances audio feature extraction by leveraging Mel Frequency Cepstral Coefficients (MFCC) and Log-Mel spectrogram features alongside a pre-trained VGGish network.","Moreover, this paper adaptively captures fusion features across modalities by modeling the temporal relationships, and ultilizes a pre-trained GPT-2 model for sophisticated context-aware fusion of multimodal information.","Our method notably improves the accuracy of AU detection by understanding the temporal and contextual nuances of the data, showcasing significant advancements in the comprehension of intricate scenarios.","These findings underscore the potential of integrating temporal dynamics and contextual interpretation, paving the way for future research endeavors."],"url":"http://arxiv.org/abs/2403.13678v1"}
{"created":"2024-03-20 15:29:59","title":"Machine Learning Optimized Approach for Parameter Selection in MESHFREE Simulations","abstract":"Meshfree simulation methods are emerging as compelling alternatives to conventional mesh-based approaches, particularly in the fields of Computational Fluid Dynamics (CFD) and continuum mechanics. In this publication, we provide a comprehensive overview of our research combining Machine Learning (ML) and Fraunhofer's MESHFREE software (www.meshfree.eu), a powerful tool utilizing a numerical point cloud in a Generalized Finite Difference Method (GFDM). This tool enables the effective handling of complex flow domains, moving geometries, and free surfaces, while allowing users to finely tune local refinement and quality parameters for an optimal balance between computation time and results accuracy. However, manually determining the optimal parameter combination poses challenges, especially for less experienced users. We introduce a novel ML-optimized approach, using active learning, regression trees, and visualization on MESHFREE simulation data, demonstrating the impact of input combinations on results quality and computation time. This research contributes valuable insights into parameter optimization in meshfree simulations, enhancing accessibility and usability for a broader user base in scientific and engineering applications.","sentences":["Meshfree simulation methods are emerging as compelling alternatives to conventional mesh-based approaches, particularly in the fields of Computational Fluid Dynamics (CFD) and continuum mechanics.","In this publication, we provide a comprehensive overview of our research combining Machine Learning (ML) and Fraunhofer's MESHFREE software (www.meshfree.eu), a powerful tool utilizing a numerical point cloud in a Generalized Finite Difference Method (GFDM).","This tool enables the effective handling of complex flow domains, moving geometries, and free surfaces, while allowing users to finely tune local refinement and quality parameters for an optimal balance between computation time and results accuracy.","However, manually determining the optimal parameter combination poses challenges, especially for less experienced users.","We introduce a novel ML-optimized approach, using active learning, regression trees, and visualization on MESHFREE simulation data, demonstrating the impact of input combinations on results quality and computation time.","This research contributes valuable insights into parameter optimization in meshfree simulations, enhancing accessibility and usability for a broader user base in scientific and engineering applications."],"url":"http://arxiv.org/abs/2403.13672v1"}
{"created":"2024-03-20 15:24:57","title":"DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance","abstract":"Choreographers determine what the dances look like, while cameramen determine the final presentation of dances. Recently, various methods and datasets have showcased the feasibility of dance synthesis. However, camera movement synthesis with music and dance remains an unsolved challenging problem due to the scarcity of paired data. Thus, we present DCM, a new multi-modal 3D dataset, which for the first time combines camera movement with dance motion and music audio. This dataset encompasses 108 dance sequences (3.2 hours) of paired dance-camera-music data from the anime community, covering 4 music genres. With this dataset, we uncover that dance camera movement is multifaceted and human-centric, and possesses multiple influencing factors, making dance camera synthesis a more challenging task compared to camera or dance synthesis alone. To overcome these difficulties, we propose DanceCamera3D, a transformer-based diffusion model that incorporates a novel body attention loss and a condition separation strategy. For evaluation, we devise new metrics measuring camera movement quality, diversity, and dancer fidelity. Utilizing these metrics, we conduct extensive experiments on our DCM dataset, providing both quantitative and qualitative evidence showcasing the effectiveness of our DanceCamera3D model. Code and video demos are available at https://github.com/Carmenw1203/DanceCamera3D-Official.","sentences":["Choreographers determine what the dances look like, while cameramen determine the final presentation of dances.","Recently, various methods and datasets have showcased the feasibility of dance synthesis.","However, camera movement synthesis with music and dance remains an unsolved challenging problem due to the scarcity of paired data.","Thus, we present DCM, a new multi-modal 3D dataset, which for the first time combines camera movement with dance motion and music audio.","This dataset encompasses 108 dance sequences (3.2 hours) of paired dance-camera-music data from the anime community, covering 4 music genres.","With this dataset, we uncover that dance camera movement is multifaceted and human-centric, and possesses multiple influencing factors, making dance camera synthesis a more challenging task compared to camera or dance synthesis alone.","To overcome these difficulties, we propose DanceCamera3D, a transformer-based diffusion model that incorporates a novel body attention loss and a condition separation strategy.","For evaluation, we devise new metrics measuring camera movement quality, diversity, and dancer fidelity.","Utilizing these metrics, we conduct extensive experiments on our DCM dataset, providing both quantitative and qualitative evidence showcasing the effectiveness of our DanceCamera3D model.","Code and video demos are available at https://github.com/Carmenw1203/DanceCamera3D-Official."],"url":"http://arxiv.org/abs/2403.13667v1"}
{"created":"2024-03-20 15:14:22","title":"T-Pixel2Mesh: Combining Global and Local Transformer for 3D Mesh Generation from a Single Image","abstract":"Pixel2Mesh (P2M) is a classical approach for reconstructing 3D shapes from a single color image through coarse-to-fine mesh deformation. Although P2M is capable of generating plausible global shapes, its Graph Convolution Network (GCN) often produces overly smooth results, causing the loss of fine-grained geometry details. Moreover, P2M generates non-credible features for occluded regions and struggles with the domain gap from synthetic data to real-world images, which is a common challenge for single-view 3D reconstruction methods. To address these challenges, we propose a novel Transformer-boosted architecture, named T-Pixel2Mesh, inspired by the coarse-to-fine approach of P2M. Specifically, we use a global Transformer to control the holistic shape and a local Transformer to progressively refine the local geometry details with graph-based point upsampling. To enhance real-world reconstruction, we present the simple yet effective Linear Scale Search (LSS), which serves as prompt tuning during the input preprocessing. Our experiments on ShapeNet demonstrate state-of-the-art performance, while results on real-world data show the generalization capability.","sentences":["Pixel2Mesh (P2M) is a classical approach for reconstructing 3D shapes from a single color image through coarse-to-fine mesh deformation.","Although P2M is capable of generating plausible global shapes, its Graph Convolution Network (GCN) often produces overly smooth results, causing the loss of fine-grained geometry details.","Moreover, P2M generates non-credible features for occluded regions and struggles with the domain gap from synthetic data to real-world images, which is a common challenge for single-view 3D reconstruction methods.","To address these challenges, we propose a novel Transformer-boosted architecture, named T-Pixel2Mesh, inspired by the coarse-to-fine approach of P2M. Specifically, we use a global Transformer to control the holistic shape and a local Transformer to progressively refine the local geometry details with graph-based point upsampling.","To enhance real-world reconstruction, we present the simple yet effective Linear Scale Search (LSS), which serves as prompt tuning during the input preprocessing.","Our experiments on ShapeNet demonstrate state-of-the-art performance, while results on real-world data show the generalization capability."],"url":"http://arxiv.org/abs/2403.13663v1"}
{"created":"2024-03-20 15:06:49","title":"Multimodal Variational Autoencoder for Low-cost Cardiac Hemodynamics Instability Detection","abstract":"Recent advancements in non-invasive detection of cardiac hemodynamic instability (CHDI) primarily focus on applying machine learning techniques to a single data modality, e.g. cardiac magnetic resonance imaging (MRI). Despite their potential, these approaches often fall short especially when the size of labeled patient data is limited, a common challenge in the medical domain. Furthermore, only a few studies have explored multimodal methods to study CHDI, which mostly rely on costly modalities such as cardiac MRI and echocardiogram. In response to these limitations, we propose a novel multimodal variational autoencoder ($\\text{CardioVAE}_\\text{X,G}$) to integrate low-cost chest X-ray (CXR) and electrocardiogram (ECG) modalities with pre-training on a large unlabeled dataset. Specifically, $\\text{CardioVAE}_\\text{X,G}$ introduces a novel tri-stream pre-training strategy to learn both shared and modality-specific features, thus enabling fine-tuning with both unimodal and multimodal datasets. We pre-train $\\text{CardioVAE}_\\text{X,G}$ on a large, unlabeled dataset of $50,982$ subjects from a subset of MIMIC database and then fine-tune the pre-trained model on a labeled dataset of $795$ subjects from the ASPIRE registry. Comprehensive evaluations against existing methods show that $\\text{CardioVAE}_\\text{X,G}$ offers promising performance (AUROC $=0.79$ and Accuracy $=0.77$), representing a significant step forward in non-invasive prediction of CHDI. Our model also excels in producing fine interpretations of predictions directly associated with clinical features, thereby supporting clinical decision-making.","sentences":["Recent advancements in non-invasive detection of cardiac hemodynamic instability (CHDI) primarily focus on applying machine learning techniques to a single data modality, e.g. cardiac magnetic resonance imaging (MRI).","Despite their potential, these approaches often fall short especially when the size of labeled patient data is limited, a common challenge in the medical domain.","Furthermore, only a few studies have explored multimodal methods to study CHDI, which mostly rely on costly modalities such as cardiac MRI and echocardiogram.","In response to these limitations, we propose a novel multimodal variational autoencoder ($\\text{CardioVAE}_\\text{X,G}$) to integrate low-cost chest X-ray (CXR) and electrocardiogram (ECG) modalities with pre-training on a large unlabeled dataset.","Specifically, $\\text{CardioVAE}_\\text{X,G}$ introduces a novel tri-stream pre-training strategy to learn both shared and modality-specific features, thus enabling fine-tuning with both unimodal and multimodal datasets.","We pre-train $\\text{CardioVAE}_\\text{X,G}$ on a large, unlabeled dataset of $50,982$ subjects from a subset of MIMIC database and then fine-tune the pre-trained model on a labeled dataset of $795$ subjects from the ASPIRE registry.","Comprehensive evaluations against existing methods show that $\\text{CardioVAE}_\\text{X,G}$ offers promising performance (AUROC $=0.79$ and Accuracy $=0.77$), representing a significant step forward in non-invasive prediction of CHDI.","Our model also excels in producing fine interpretations of predictions directly associated with clinical features, thereby supporting clinical decision-making."],"url":"http://arxiv.org/abs/2403.13658v1"}
{"created":"2024-03-20 14:58:40","title":"Learning User Embeddings from Human Gaze for Personalised Saliency Prediction","abstract":"Reusable embeddings of user behaviour have shown significant performance improvements for the personalised saliency prediction task. However, prior works require explicit user characteristics and preferences as input, which are often difficult to obtain. We present a novel method to extract user embeddings from pairs of natural images and corresponding saliency maps generated from a small amount of user-specific eye tracking data. At the core of our method is a Siamese convolutional neural encoder that learns the user embeddings by contrasting the image and personal saliency map pairs of different users. Evaluations on two public saliency datasets show that the generated embeddings have high discriminative power, are effective at refining universal saliency maps to the individual users, and generalise well across users and images. Finally, based on our model's ability to encode individual user characteristics, our work points towards other applications that can benefit from reusable embeddings of gaze behaviour.","sentences":["Reusable embeddings of user behaviour have shown significant performance improvements for the personalised saliency prediction task.","However, prior works require explicit user characteristics and preferences as input, which are often difficult to obtain.","We present a novel method to extract user embeddings from pairs of natural images and corresponding saliency maps generated from a small amount of user-specific eye tracking data.","At the core of our method is a Siamese convolutional neural encoder that learns the user embeddings by contrasting the image and personal saliency map pairs of different users.","Evaluations on two public saliency datasets show that the generated embeddings have high discriminative power, are effective at refining universal saliency maps to the individual users, and generalise well across users and images.","Finally, based on our model's ability to encode individual user characteristics, our work points towards other applications that can benefit from reusable embeddings of gaze behaviour."],"url":"http://arxiv.org/abs/2403.13653v1"}
{"created":"2024-03-20 14:50:54","title":"How to Relax Instantly: Elastic Relaxation of Concurrent Data Structures","abstract":"The sequential semantics of many concurrent data structures, such as stacks and queues, inevitably lead to memory contention in parallel environments, thus limiting scalability. Semantic relaxation has the potential to address this issue, increasing the parallelism at the expense of weakened semantics. Although prior research has shown that improved performance can be attained by relaxing concurrent data structure semantics, there is no one-size-fits-all relaxation that adequately addresses the varying needs of dynamic executions.   In this paper, we first introduce the concept of elastic relaxation and consequently present the Lateral structure, which is an algorithmic component capable of supporting the design of elastically relaxed concurrent data structures. Using the Lateral , we design novel elastically relaxed, lock-free queues and stacks capable of reconfiguring relaxation during run time. We establish linearizability and define upper bounds for relaxation errors in our designs. Experimental evaluations show that our elastic designs hold up against state-of-the-art statically relaxed designs, while also swiftly managing trade-offs between relaxation and operational latency. We also outline how to use the Lateral to design elastically relaxed lock-free counters and deques.","sentences":["The sequential semantics of many concurrent data structures, such as stacks and queues, inevitably lead to memory contention in parallel environments, thus limiting scalability.","Semantic relaxation has the potential to address this issue, increasing the parallelism at the expense of weakened semantics.","Although prior research has shown that improved performance can be attained by relaxing concurrent data structure semantics, there is no one-size-fits-all relaxation that adequately addresses the varying needs of dynamic executions.   ","In this paper, we first introduce the concept of elastic relaxation and consequently present the Lateral structure, which is an algorithmic component capable of supporting the design of elastically relaxed concurrent data structures.","Using the Lateral , we design novel elastically relaxed, lock-free queues and stacks capable of reconfiguring relaxation during run time.","We establish linearizability and define upper bounds for relaxation errors in our designs.","Experimental evaluations show that our elastic designs hold up against state-of-the-art statically relaxed designs, while also swiftly managing trade-offs between relaxation and operational latency.","We also outline how to use the Lateral to design elastically relaxed lock-free counters and deques."],"url":"http://arxiv.org/abs/2403.13644v1"}
{"created":"2024-03-20 14:43:51","title":"LaCE-LHMP: Airflow Modelling-Inspired Long-Term Human Motion Prediction By Enhancing Laminar Characteristics in Human Flow","abstract":"Long-term human motion prediction (LHMP) is essential for safely operating autonomous robots and vehicles in populated environments. It is fundamental for various applications, including motion planning, tracking, human-robot interaction and safety monitoring. However, accurate prediction of human trajectories is challenging due to complex factors, including, for example, social norms and environmental conditions. The influence of such factors can be captured through Maps of Dynamics (MoDs), which encode spatial motion patterns learned from (possibly scattered and partial) past observations of motion in the environment and which can be used for data-efficient, interpretable motion prediction (MoD-LHMP). To address the limitations of prior work, especially regarding accuracy and sensitivity to anomalies in long-term prediction, we propose the Laminar Component Enhanced LHMP approach (LaCE-LHMP). Our approach is inspired by data-driven airflow modelling, which estimates laminar and turbulent flow components and uses predominantly the laminar components to make flow predictions. Based on the hypothesis that human trajectory patterns also manifest laminar flow (that represents predictable motion) and turbulent flow components (that reflect more unpredictable and arbitrary motion), LaCE-LHMP extracts the laminar patterns in human dynamics and uses them for human motion prediction. We demonstrate the superior prediction performance of LaCE-LHMP through benchmark comparisons with state-of-the-art LHMP methods, offering an unconventional perspective and a more intuitive understanding of human movement patterns.","sentences":["Long-term human motion prediction (LHMP) is essential for safely operating autonomous robots and vehicles in populated environments.","It is fundamental for various applications, including motion planning, tracking, human-robot interaction and safety monitoring.","However, accurate prediction of human trajectories is challenging due to complex factors, including, for example, social norms and environmental conditions.","The influence of such factors can be captured through Maps of Dynamics (MoDs), which encode spatial motion patterns learned from (possibly scattered and partial) past observations of motion in the environment and which can be used for data-efficient, interpretable motion prediction (MoD-LHMP).","To address the limitations of prior work, especially regarding accuracy and sensitivity to anomalies in long-term prediction, we propose the Laminar Component Enhanced LHMP approach (LaCE-LHMP).","Our approach is inspired by data-driven airflow modelling, which estimates laminar and turbulent flow components and uses predominantly the laminar components to make flow predictions.","Based on the hypothesis that human trajectory patterns also manifest laminar flow (that represents predictable motion) and turbulent flow components (that reflect more unpredictable and arbitrary motion), LaCE-LHMP extracts the laminar patterns in human dynamics and uses them for human motion prediction.","We demonstrate the superior prediction performance of LaCE-LHMP through benchmark comparisons with state-of-the-art LHMP methods, offering an unconventional perspective and a more intuitive understanding of human movement patterns."],"url":"http://arxiv.org/abs/2403.13640v1"}
{"created":"2024-03-20 14:41:01","title":"Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese","abstract":"In this paper, we explore the utility of \\textit{Translationese} as synthetic data created using machine translation for pre-training language models (LMs). Pre-training requires vast amounts of monolingual data, which is mostly unavailable for languages other than English. Recently, there has been a growing interest in using synthetic data to address this data scarcity. We take the case of English and Indic languages and translate web-crawled monolingual documents (clean) into the target language. Then, we train language models containing 28M and 85M parameters on this translationese data (synthetic). We show that their performance on downstream natural language understanding and generative tasks is only 3.56\\% poorer on NLU tasks and 1.51\\% on NLG tasks than LMs pre-trained on clean data. Further, we propose the use of lightweight \\textit{TinyLMs} pre-trained on clean data to filter synthetic data efficiently which significantly improves the performance of our models. We also find that LMs trained on synthetic data strongly benefit from extended pretraining on a tiny fraction (10\\%) of clean data. We release the data we collected and created as a part of this work, \\textit{IndicMonoDoc}, the largest collection of monolingual document-level corpora, which we hope will help bridge the gap between English and non-English performance for large language models.","sentences":["In this paper, we explore the utility of \\textit{Translationese} as synthetic data created using machine translation for pre-training language models (LMs).","Pre-training requires vast amounts of monolingual data, which is mostly unavailable for languages other than English.","Recently, there has been a growing interest in using synthetic data to address this data scarcity.","We take the case of English and Indic languages and translate web-crawled monolingual documents (clean) into the target language.","Then, we train language models containing 28M and 85M parameters on this translationese data (synthetic).","We show that their performance on downstream natural language understanding and generative tasks is only 3.56\\% poorer on NLU tasks and 1.51\\% on NLG tasks than LMs pre-trained on clean data.","Further, we propose the use of lightweight \\textit{TinyLMs} pre-trained on clean data to filter synthetic data efficiently which significantly improves the performance of our models.","We also find that LMs trained on synthetic data strongly benefit from extended pretraining on a tiny fraction (10\\%) of clean data.","We release the data we collected and created as a part of this work, \\textit{IndicMonoDoc}, the largest collection of monolingual document-level corpora, which we hope will help bridge the gap between English and non-English performance for large language models."],"url":"http://arxiv.org/abs/2403.13638v1"}
{"created":"2024-03-20 14:13:44","title":"Dynamic Resource Allocation for Virtual Machine Migration Optimization using Machine Learning","abstract":"The paragraph is grammatically correct and logically coherent. It discusses the importance of mobile terminal cloud computing migration technology in meeting the demands of evolving computer and cloud computing technologies. It emphasizes the need for efficient data access and storage, as well as the utilization of cloud computing migration technology to prevent additional time delays. The paragraph also highlights the contributions of cloud computing migration technology to expanding cloud computing services. Additionally, it acknowledges the role of virtualization as a fundamental capability of cloud computing while emphasizing that cloud computing and virtualization are not inherently interconnected. Finally, it introduces machine learning-based virtual machine migration optimization and dynamic resource allocation as a critical research direction in cloud computing, citing the limitations of static rules or manual settings in traditional cloud computing environments. Overall, the paragraph effectively communicates the importance of machine learning technology in addressing resource allocation and virtual machine migration challenges in cloud computing.","sentences":["The paragraph is grammatically correct and logically coherent.","It discusses the importance of mobile terminal cloud computing migration technology in meeting the demands of evolving computer and cloud computing technologies.","It emphasizes the need for efficient data access and storage, as well as the utilization of cloud computing migration technology to prevent additional time delays.","The paragraph also highlights the contributions of cloud computing migration technology to expanding cloud computing services.","Additionally, it acknowledges the role of virtualization as a fundamental capability of cloud computing while emphasizing that cloud computing and virtualization are not inherently interconnected.","Finally, it introduces machine learning-based virtual machine migration optimization and dynamic resource allocation as a critical research direction in cloud computing, citing the limitations of static rules or manual settings in traditional cloud computing environments.","Overall, the paragraph effectively communicates the importance of machine learning technology in addressing resource allocation and virtual machine migration challenges in cloud computing."],"url":"http://arxiv.org/abs/2403.13619v1"}
{"created":"2024-03-20 14:03:57","title":"Does Differentially Private Synthetic Data Lead to Synthetic Discoveries?","abstract":"Background: Synthetic data has been proposed as a solution for sharing anonymized versions of sensitive biomedical datasets. Ideally, synthetic data should preserve the structure and statistical properties of the original data, while protecting the privacy of the individual subjects. Differential privacy (DP) is currently considered the gold standard approach for balancing this trade-off.   Objectives: The aim of this study is to evaluate the Mann-Whitney U test on DP-synthetic biomedical data in terms of Type I and Type II errors, in order to establish whether statistical hypothesis testing performed on privacy preserving synthetic data is likely to lead to loss of test's validity or decreased power.   Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated from real-world data, including a prostate cancer dataset (n=500) and a cardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian distributions. Five different DP-synthetic data generation methods are evaluated, including two basic DP histogram release methods and MWEM, Private-PGM, and DP GAN algorithms.   Conclusion: Most of the tested DP-synthetic data generation methods showed inflated Type I error, especially at privacy budget levels of $\\epsilon\\leq 1$. This result calls for caution when releasing and analyzing DP-synthetic data: low p-values may be obtained in statistical tests simply as a byproduct of the noise added to protect privacy. A DP smoothed histogram-based synthetic data generation method was shown to produce valid Type I error for all privacy levels tested but required a large original dataset size and a modest privacy budget ($\\epsilon\\geq 5$) in order to have reasonable Type II error levels.","sentences":["Background: Synthetic data has been proposed as a solution for sharing anonymized versions of sensitive biomedical datasets.","Ideally, synthetic data should preserve the structure and statistical properties of the original data, while protecting the privacy of the individual subjects.","Differential privacy (DP) is currently considered the gold standard approach for balancing this trade-off.   ","Objectives:","The aim of this study is to evaluate the Mann-Whitney U test on DP-synthetic biomedical data in terms of Type I and Type II errors, in order to establish whether statistical hypothesis testing performed on privacy preserving synthetic data is likely to lead to loss of test's validity or decreased power.   ","Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated from real-world data, including a prostate cancer dataset (n=500) and a cardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian distributions.","Five different DP-synthetic data generation methods are evaluated, including two basic DP histogram release methods and MWEM, Private-PGM, and DP GAN algorithms.   ","Conclusion: Most of the tested DP-synthetic data generation methods showed inflated Type I error, especially at privacy budget levels of $\\epsilon\\leq 1$.","This result calls for caution when releasing and analyzing DP-synthetic data: low p-values may be obtained in statistical tests simply as a byproduct of the noise added to protect privacy.","A DP smoothed histogram-based synthetic data generation method was shown to produce valid Type I error for all privacy levels tested but required a large original dataset size and a modest privacy budget ($\\epsilon\\geq 5$) in order to have reasonable Type II error levels."],"url":"http://arxiv.org/abs/2403.13612v1"}
{"created":"2024-03-20 14:03:15","title":"Densify & Conquer: Densified, smaller base-stations can conquer the increasing carbon footprint problem in nextG wireless","abstract":"Connectivity on-the-go has been one of the most impressive technological achievements in the 2010s decade. However, multiple studies show that this has come at an expense of increased carbon footprint, that also rivals the entire aviation sector's carbon footprint. The two major contributors of this increased footprint are (a) smartphone batteries which affect the embodied footprint and (b) base-stations that occupy ever-increasing energy footprint to provide the last mile wireless connectivity to smartphones. The root-cause of both these turn out to be the same, which is communicating over the last-mile lossy wireless medium. We show in this paper, titled DensQuer, how base-station densification, which is to replace a single larger base-station with multiple smaller ones, reduces the effect of the last-mile wireless, and in effect conquers both these adverse sources of increased carbon footprint. Backed by a open-source ray-tracing computation framework (Sionna), we show how a strategic densification strategy can minimize the number of required smaller base-stations to practically achievable numbers, which lead to about 3x power-savings in the base-station network. Also, DensQuer is able to also reduce the required deployment height of base-stations to as low as 15m, that makes the smaller cells easily deployable on trees/street poles instead of requiring a dedicated tower. Further, by utilizing newly introduced hardware power rails in Google Pixel 7a and above phones, we also show that this strategic densified network leads to reduction in mobile transmit power by 10-15 dB, leading to about 3x reduction in total cellular power consumption, and about 50% increase in smartphone battery life when it communicates data via the cellular network.","sentences":["Connectivity on-the-go has been one of the most impressive technological achievements in the 2010s decade.","However, multiple studies show that this has come at an expense of increased carbon footprint, that also rivals the entire aviation sector's carbon footprint.","The two major contributors of this increased footprint are (a) smartphone batteries which affect the embodied footprint and (b) base-stations that occupy ever-increasing energy footprint to provide the last mile wireless connectivity to smartphones.","The root-cause of both these turn out to be the same, which is communicating over the last-mile lossy wireless medium.","We show in this paper, titled DensQuer, how base-station densification, which is to replace a single larger base-station with multiple smaller ones, reduces the effect of the last-mile wireless, and in effect conquers both these adverse sources of increased carbon footprint.","Backed by a open-source ray-tracing computation framework (Sionna), we show how a strategic densification strategy can minimize the number of required smaller base-stations to practically achievable numbers, which lead to about 3x power-savings in the base-station network.","Also, DensQuer is able to also reduce the required deployment height of base-stations to as low as 15m, that makes the smaller cells easily deployable on trees/street poles instead of requiring a dedicated tower.","Further, by utilizing newly introduced hardware power rails in Google Pixel 7a and above phones, we also show that this strategic densified network leads to reduction in mobile transmit power by 10-15 dB, leading to about 3x reduction in total cellular power consumption, and about 50% increase in smartphone battery life when it communicates data via the cellular network."],"url":"http://arxiv.org/abs/2403.13611v1"}
{"created":"2024-03-20 13:42:57","title":"Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs","abstract":"Instruction-finetuned Large Language Models inherit clear political leanings that have been shown to influence downstream task performance. We expand this line of research beyond the two-party system in the US and audit Llama Chat in the context of EU politics in various settings to analyze the model's political knowledge and its ability to reason in context. We adapt, i.e., further fine-tune, Llama Chat on speeches of individual euro-parties from debates in the European Parliament to reevaluate its political leaning based on the EUandI questionnaire. Llama Chat shows considerable knowledge of national parties' positions and is capable of reasoning in context. The adapted, party-specific, models are substantially re-aligned towards respective positions which we see as a starting point for using chat-based LLMs as data-driven conversational engines to assist research in political science.","sentences":["Instruction-finetuned Large Language Models inherit clear political leanings that have been shown to influence downstream task performance.","We expand this line of research beyond the two-party system in the US and audit Llama Chat in the context of EU politics in various settings to analyze the model's political knowledge and its ability to reason in context.","We adapt, i.e., further fine-tune, Llama Chat on speeches of individual euro-parties from debates in the European Parliament to reevaluate its political leaning based on the EUandI questionnaire.","Llama Chat shows considerable knowledge of national parties' positions and is capable of reasoning in context.","The adapted, party-specific, models are substantially re-aligned towards respective positions which we see as a starting point for using chat-based LLMs as data-driven conversational engines to assist research in political science."],"url":"http://arxiv.org/abs/2403.13592v1"}
{"created":"2024-03-20 13:33:55","title":"CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing","abstract":"Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code. However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents. To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement. CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications. CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets. It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the practicality and reliability of LLMs in generating intricate code.","sentences":["Large Language Models (LLMs) have revolutionized code generation ability by converting natural language descriptions into executable code.","However, generating complex code within real-world scenarios remains challenging due to intricate structures, subtle bugs, understanding of advanced data types, and lack of supplementary contents.","To address these challenges, we introduce the CONLINE framework, which enhances code generation by incorporating planned online searches for information retrieval and automated correctness testing for iterative refinement.","CONLINE also serializes the complex inputs and outputs to improve comprehension and generate test case to ensure the framework's adaptability for real-world applications.","CONLINE is validated through rigorous experiments on the DS-1000 and ClassEval datasets.","It shows that CONLINE substantially improves the quality of complex code generation, highlighting its potential to enhance the practicality and reliability of LLMs in generating intricate code."],"url":"http://arxiv.org/abs/2403.13583v1"}
{"created":"2024-03-20 13:09:54","title":"Portrait4D-v2: Pseudo Multi-View Data Creates Better 4D Head Synthesizer","abstract":"In this paper, we propose a novel learning approach for feed-forward one-shot 4D head avatar synthesis. Different from existing methods that often learn from reconstructing monocular videos guided by 3DMM, we employ pseudo multi-view videos to learn a 4D head synthesizer in a data-driven manner, avoiding reliance on inaccurate 3DMM reconstruction that could be detrimental to the synthesis performance. The key idea is to first learn a 3D head synthesizer using synthetic multi-view images to convert monocular real videos into multi-view ones, and then utilize the pseudo multi-view videos to learn a 4D head synthesizer via cross-view self-reenactment. By leveraging a simple vision transformer backbone with motion-aware cross-attentions, our method exhibits superior performance compared to previous methods in terms of reconstruction fidelity, geometry consistency, and motion control accuracy. We hope our method offers novel insights into integrating 3D priors with 2D supervisions for improved 4D head avatar creation.","sentences":["In this paper, we propose a novel learning approach for feed-forward one-shot 4D head avatar synthesis.","Different from existing methods that often learn from reconstructing monocular videos guided by 3DMM, we employ pseudo multi-view videos to learn a 4D head synthesizer in a data-driven manner, avoiding reliance on inaccurate 3DMM reconstruction that could be detrimental to the synthesis performance.","The key idea is to first learn a 3D head synthesizer using synthetic multi-view images to convert monocular real videos into multi-view ones, and then utilize the pseudo multi-view videos to learn a 4D head synthesizer via cross-view self-reenactment.","By leveraging a simple vision transformer backbone with motion-aware cross-attentions, our method exhibits superior performance compared to previous methods in terms of reconstruction fidelity, geometry consistency, and motion control accuracy.","We hope our method offers novel insights into integrating 3D priors with 2D supervisions for improved 4D head avatar creation."],"url":"http://arxiv.org/abs/2403.13570v1"}
{"created":"2024-03-20 12:52:38","title":"eRST: A Signaled Graph Theory of Discourse Relations and Organization","abstract":"In this article we present Enhanced Rhetorical Structure Theory (eRST), a new theoretical framework for computational discourse analysis, based on an expansion of Rhetorical Structure Theory (RST). The framework encompasses discourse relation graphs with tree-breaking, nonprojective and concurrent relations, as well as implicit and explicit signals which give explainable rationales to our analyses. We survey shortcomings of RST and other existing frameworks, such as Segmented Discourse Representation Theory (SDRT), the Penn Discourse Treebank (PDTB) and Discourse Dependencies, and address these using constructs in the proposed theory. We provide annotation, search and visualization tools for data, and present and evaluate a freely available corpus of English annotated according to our framework, encompassing 12 spoken and written genres with over 200K tokens. Finally, we discuss automatic parsing, evaluation metrics and applications for data in our framework.","sentences":["In this article we present Enhanced Rhetorical Structure Theory (eRST), a new theoretical framework for computational discourse analysis, based on an expansion of Rhetorical Structure Theory (RST).","The framework encompasses discourse relation graphs with tree-breaking, nonprojective and concurrent relations, as well as implicit and explicit signals which give explainable rationales to our analyses.","We survey shortcomings of RST and other existing frameworks, such as Segmented Discourse Representation Theory (SDRT), the Penn Discourse Treebank (PDTB) and Discourse Dependencies, and address these using constructs in the proposed theory.","We provide annotation, search and visualization tools for data, and present and evaluate a freely available corpus of English annotated according to our framework, encompassing 12 spoken and written genres with over 200K tokens.","Finally, we discuss automatic parsing, evaluation metrics and applications for data in our framework."],"url":"http://arxiv.org/abs/2403.13560v1"}
{"created":"2024-03-20 12:51:30","title":"Find n' Propagate: Open-Vocabulary 3D Object Detection in Urban Environments","abstract":"In this work, we tackle the limitations of current LiDAR-based 3D object detection systems, which are hindered by a restricted class vocabulary and the high costs associated with annotating new object classes. Our exploration of open-vocabulary (OV) learning in urban environments aims to capture novel instances using pre-trained vision-language models (VLMs) with multi-sensor data. We design and benchmark a set of four potential solutions as baselines, categorizing them into either top-down or bottom-up approaches based on their input data strategies. While effective, these methods exhibit certain limitations, such as missing novel objects in 3D box estimation or applying rigorous priors, leading to biases towards objects near the camera or of rectangular geometries. To overcome these limitations, we introduce a universal \\textsc{Find n' Propagate} approach for 3D OV tasks, aimed at maximizing the recall of novel objects and propagating this detection capability to more distant areas thereby progressively capturing more. In particular, we utilize a greedy box seeker to search against 3D novel boxes of varying orientations and depth in each generated frustum and ensure the reliability of newly identified boxes by cross alignment and density ranker. Additionally, the inherent bias towards camera-proximal objects is alleviated by the proposed remote simulator, which randomly diversifies pseudo-labeled novel instances in the self-training process, combined with the fusion of base samples in the memory bank. Extensive experiments demonstrate a 53% improvement in novel recall across diverse OV settings, VLMs, and 3D detectors. Notably, we achieve up to a 3.97-fold increase in Average Precision (AP) for novel object classes. The source code is made available in the supplementary material.","sentences":["In this work, we tackle the limitations of current LiDAR-based 3D object detection systems, which are hindered by a restricted class vocabulary and the high costs associated with annotating new object classes.","Our exploration of open-vocabulary (OV) learning in urban environments aims to capture novel instances using pre-trained vision-language models (VLMs) with multi-sensor data.","We design and benchmark a set of four potential solutions as baselines, categorizing them into either top-down or bottom-up approaches based on their input data strategies.","While effective, these methods exhibit certain limitations, such as missing novel objects in 3D box estimation or applying rigorous priors, leading to biases towards objects near the camera or of rectangular geometries.","To overcome these limitations, we introduce a universal \\textsc{Find n' Propagate} approach for 3D OV tasks, aimed at maximizing the recall of novel objects and propagating this detection capability to more distant areas thereby progressively capturing more.","In particular, we utilize a greedy box seeker to search against 3D novel boxes of varying orientations and depth in each generated frustum and ensure the reliability of newly identified boxes by cross alignment and density ranker.","Additionally, the inherent bias towards camera-proximal objects is alleviated by the proposed remote simulator, which randomly diversifies pseudo-labeled novel instances in the self-training process, combined with the fusion of base samples in the memory bank.","Extensive experiments demonstrate a 53% improvement in novel recall across diverse OV settings, VLMs, and 3D detectors.","Notably, we achieve up to a 3.97-fold increase in Average Precision (AP) for novel object classes.","The source code is made available in the supplementary material."],"url":"http://arxiv.org/abs/2403.13556v1"}
{"created":"2024-03-20 12:33:51","title":"Integrating Large Language Models for Severity Classification in Traffic Incident Management: A Machine Learning Approach","abstract":"This study evaluates the impact of large language models on enhancing machine learning processes for managing traffic incidents. It examines the extent to which features generated by modern language models improve or match the accuracy of predictions when classifying the severity of incidents using accident reports. Multiple comparisons performed between combinations of language models and machine learning algorithms, including Gradient Boosted Decision Trees, Random Forests, and Extreme Gradient Boosting. Our research uses both conventional and language model-derived features from texts and incident reports, and their combinations to perform severity classification. Incorporating features from language models with those directly obtained from incident reports has shown to improve, or at least match, the performance of machine learning techniques in assigning severity levels to incidents, particularly when employing Random Forests and Extreme Gradient Boosting methods. This comparison was quantified using the F1-score over uniformly sampled data sets to obtain balanced severity classes. The primary contribution of this research is in the demonstration of how Large Language Models can be integrated into machine learning workflows for incident management, thereby simplifying feature extraction from unstructured text and enhancing or matching the precision of severity predictions using conventional machine learning pipeline. The engineering application of this research is illustrated through the effective use of these language processing models to refine the modelling process for incident severity classification. This work provides significant insights into the application of language processing capabilities in combination with traditional data for improving machine learning pipelines in the context of classifying incident severity.","sentences":["This study evaluates the impact of large language models on enhancing machine learning processes for managing traffic incidents.","It examines the extent to which features generated by modern language models improve or match the accuracy of predictions when classifying the severity of incidents using accident reports.","Multiple comparisons performed between combinations of language models and machine learning algorithms, including Gradient Boosted Decision Trees, Random Forests, and Extreme Gradient Boosting.","Our research uses both conventional and language model-derived features from texts and incident reports, and their combinations to perform severity classification.","Incorporating features from language models with those directly obtained from incident reports has shown to improve, or at least match, the performance of machine learning techniques in assigning severity levels to incidents, particularly when employing Random Forests and Extreme Gradient Boosting methods.","This comparison was quantified using the F1-score over uniformly sampled data sets to obtain balanced severity classes.","The primary contribution of this research is in the demonstration of how Large Language Models can be integrated into machine learning workflows for incident management, thereby simplifying feature extraction from unstructured text and enhancing or matching the precision of severity predictions using conventional machine learning pipeline.","The engineering application of this research is illustrated through the effective use of these language processing models to refine the modelling process for incident severity classification.","This work provides significant insights into the application of language processing capabilities in combination with traditional data for improving machine learning pipelines in the context of classifying incident severity."],"url":"http://arxiv.org/abs/2403.13547v1"}
{"created":"2024-03-20 12:14:54","title":"What explains the success of cross-modal fine-tuning with ORCA?","abstract":"ORCA (Shen et al., 2023) is a recent technique for cross-modal fine-tuning, i.e., applying pre-trained transformer models to modalities beyond their training data. The technique consists primarily of training an embedder and fine-tuning the embedder and model. Despite its high performance on a variety of downstream tasks, we do not understand precisely how each of these components contribute to ORCA's success. Therefore, we run a series of ablations and find that embedder training does not help 2D tasks at all, contrary to what the original paper posits. In 1D tasks, some amount of embedder training is necessary but more is not better. In 4 out of 6 datasets we experiment with, it is model fine-tuning that makes the biggest difference. Through our ablations and baselines, we contribute a better understanding of the individual components of ORCA.","sentences":["ORCA (Shen et al., 2023) is a recent technique for cross-modal fine-tuning, i.e., applying pre-trained transformer models to modalities beyond their training data.","The technique consists primarily of training an embedder and fine-tuning the embedder and model.","Despite its high performance on a variety of downstream tasks, we do not understand precisely how each of these components contribute to ORCA's success.","Therefore, we run a series of ablations and find that embedder training does not help 2D tasks at all, contrary to what the original paper posits.","In 1D tasks, some amount of embedder training is necessary but more is not better.","In 4 out of 6 datasets we experiment with, it is model fine-tuning that makes the biggest difference.","Through our ablations and baselines, we contribute a better understanding of the individual components of ORCA."],"url":"http://arxiv.org/abs/2403.13537v1"}
{"created":"2024-03-20 12:14:00","title":"Conceptualizing predictive conceptual model for unemployment rates in the implementation of Industry 4.0: Exploring machine learning techniques","abstract":"Although there are obstacles related to obtaining data, ensuring model precision, and upholding ethical standards, the advantages of utilizing machine learning to generate predictive models for unemployment rates in developing nations amid the implementation of Industry 4.0 (I4.0) are noteworthy. This research delves into the concept of utilizing machine learning techniques through a predictive conceptual model to understand and address factors that contribute to unemployment rates in developing nations during the implementation of I4.0. A thorough examination of the literature was carried out through a literature review to determine the economic and social factors that have an impact on the unemployment rates in developing nations. The examination of the literature uncovered that considerable influence on unemployment rates in developing nations is attributed to elements such as economic growth, inflation, population increase, education levels, and technological progress. A predictive conceptual model was developed that indicates factors that contribute to unemployment in developing nations can be addressed by using techniques of machine learning like regression analysis and neural networks when adopting I4.0. The study's findings demonstrated the effectiveness of the proposed predictive conceptual model in accurately understanding and addressing unemployment rate factors within developing nations when deploying I4.0. The model serves a dual purpose of predicting future unemployment rates and tracking the advancement of reducing unemployment rates in emerging economies. By persistently conducting research and improvements, decision-makers and enterprises can employ these patterns to arrive at more knowledgeable judgments that can advance the growth of the economy, generation of employment, and alleviation of poverty specifically in emerging nations.","sentences":["Although there are obstacles related to obtaining data, ensuring model precision, and upholding ethical standards, the advantages of utilizing machine learning to generate predictive models for unemployment rates in developing nations amid the implementation of Industry 4.0 (I4.0) are noteworthy.","This research delves into the concept of utilizing machine learning techniques through a predictive conceptual model to understand and address factors that contribute to unemployment rates in developing nations during the implementation of I4.0.","A thorough examination of the literature was carried out through a literature review to determine the economic and social factors that have an impact on the unemployment rates in developing nations.","The examination of the literature uncovered that considerable influence on unemployment rates in developing nations is attributed to elements such as economic growth, inflation, population increase, education levels, and technological progress.","A predictive conceptual model was developed that indicates factors that contribute to unemployment in developing nations can be addressed by using techniques of machine learning like regression analysis and neural networks when adopting I4.0.","The study's findings demonstrated the effectiveness of the proposed predictive conceptual model in accurately understanding and addressing unemployment rate factors within developing nations when deploying I4.0.","The model serves a dual purpose of predicting future unemployment rates and tracking the advancement of reducing unemployment rates in emerging economies.","By persistently conducting research and improvements, decision-makers and enterprises can employ these patterns to arrive at more knowledgeable judgments that can advance the growth of the economy, generation of employment, and alleviation of poverty specifically in emerging nations."],"url":"http://arxiv.org/abs/2403.13536v1"}
{"created":"2024-03-20 11:51:04","title":"Compress3D: a Compressed Latent Space for 3D Generation from a Single Image","abstract":"3D generation has witnessed significant advancements, yet efficiently producing high-quality 3D assets from a single image remains challenging. In this paper, we present a triplane autoencoder, which encodes 3D models into a compact triplane latent space to effectively compress both the 3D geometry and texture information. Within the autoencoder framework, we introduce a 3D-aware cross-attention mechanism, which utilizes low-resolution latent representations to query features from a high-resolution 3D feature volume, thereby enhancing the representation capacity of the latent space. Subsequently, we train a diffusion model on this refined latent space. In contrast to solely relying on image embedding for 3D generation, our proposed method advocates for the simultaneous utilization of both image embedding and shape embedding as conditions. Specifically, the shape embedding is estimated via a diffusion prior model conditioned on the image embedding. Through comprehensive experiments, we demonstrate that our method outperforms state-of-the-art algorithms, achieving superior performance while requiring less training data and time. Our approach enables the generation of high-quality 3D assets in merely 7 seconds on a single A100 GPU.","sentences":["3D generation has witnessed significant advancements, yet efficiently producing high-quality 3D assets from a single image remains challenging.","In this paper, we present a triplane autoencoder, which encodes 3D models into a compact triplane latent space to effectively compress both the 3D geometry and texture information.","Within the autoencoder framework, we introduce a 3D-aware cross-attention mechanism, which utilizes low-resolution latent representations to query features from a high-resolution 3D feature volume, thereby enhancing the representation capacity of the latent space.","Subsequently, we train a diffusion model on this refined latent space.","In contrast to solely relying on image embedding for 3D generation, our proposed method advocates for the simultaneous utilization of both image embedding and shape embedding as conditions.","Specifically, the shape embedding is estimated via a diffusion prior model conditioned on the image embedding.","Through comprehensive experiments, we demonstrate that our method outperforms state-of-the-art algorithms, achieving superior performance while requiring less training data and time.","Our approach enables the generation of high-quality 3D assets in merely 7 seconds on a single A100 GPU."],"url":"http://arxiv.org/abs/2403.13524v1"}
{"created":"2024-03-20 11:50:16","title":"Have You Poisoned My Data? Defending Neural Networks against Data Poisoning","abstract":"The unprecedented availability of training data fueled the rapid development of powerful neural networks in recent years. However, the need for such large amounts of data leads to potential threats such as poisoning attacks: adversarial manipulations of the training data aimed at compromising the learned model to achieve a given adversarial goal.   This paper investigates defenses against clean-label poisoning attacks and proposes a novel approach to detect and filter poisoned datapoints in the transfer learning setting. We define a new characteristic vector representation of datapoints and show that it effectively captures the intrinsic properties of the data distribution. Through experimental analysis, we demonstrate that effective poisons can be successfully differentiated from clean points in the characteristic vector space. We thoroughly evaluate our proposed approach and compare it to existing state-of-the-art defenses using multiple architectures, datasets, and poison budgets. Our evaluation shows that our proposal outperforms existing approaches in defense rate and final trained model performance across all experimental settings.","sentences":["The unprecedented availability of training data fueled the rapid development of powerful neural networks in recent years.","However, the need for such large amounts of data leads to potential threats such as poisoning attacks: adversarial manipulations of the training data aimed at compromising the learned model to achieve a given adversarial goal.   ","This paper investigates defenses against clean-label poisoning attacks and proposes a novel approach to detect and filter poisoned datapoints in the transfer learning setting.","We define a new characteristic vector representation of datapoints and show that it effectively captures the intrinsic properties of the data distribution.","Through experimental analysis, we demonstrate that effective poisons can be successfully differentiated from clean points in the characteristic vector space.","We thoroughly evaluate our proposed approach and compare it to existing state-of-the-art defenses using multiple architectures, datasets, and poison budgets.","Our evaluation shows that our proposal outperforms existing approaches in defense rate and final trained model performance across all experimental settings."],"url":"http://arxiv.org/abs/2403.13523v1"}
{"created":"2024-03-20 11:48:10","title":"REAL: Representation Enhanced Analytic Learning for Exemplar-free Class-incremental Learning","abstract":"Exemplar-free class-incremental learning (EFCIL) aims to mitigate catastrophic forgetting in class-incremental learning without available historical data. Compared with its counterpart (replay-based CIL) that stores historical samples, the EFCIL suffers more from forgetting issues under the exemplar-free constraint. In this paper, inspired by the recently developed analytic learning (AL) based CIL, we propose a representation enhanced analytic learning (REAL) for EFCIL. The REAL constructs a dual-stream base pretraining (DS-BPT) and a representation enhancing distillation (RED) process to enhance the representation of the extractor. The DS-BPT pretrains model in streams of both supervised learning and self-supervised contrastive learning (SSCL) for base knowledge extraction. The RED process distills the supervised knowledge to the SSCL pretrained backbone and facilitates a subsequent AL-basd CIL that converts the CIL to a recursive least-square problem. Our method addresses the issue of insufficient discriminability in representations of unseen data caused by a frozen backbone in the existing AL-based CIL. Empirical results on various datasets including CIFAR-100, ImageNet-100 and ImageNet-1k, demonstrate that our REAL outperforms the state-of-the-arts in EFCIL, and achieves comparable or even more superior performance compared with the replay-based methods.","sentences":["Exemplar-free class-incremental learning (EFCIL) aims to mitigate catastrophic forgetting in class-incremental learning without available historical data.","Compared with its counterpart (replay-based CIL) that stores historical samples, the EFCIL suffers more from forgetting issues under the exemplar-free constraint.","In this paper, inspired by the recently developed analytic learning (AL) based CIL, we propose a representation enhanced analytic learning (REAL) for EFCIL.","The REAL constructs a dual-stream base pretraining (DS-BPT) and a representation enhancing distillation (RED) process to enhance the representation of the extractor.","The DS-BPT pretrains model in streams of both supervised learning and self-supervised contrastive learning (SSCL) for base knowledge extraction.","The RED process distills the supervised knowledge to the SSCL pretrained backbone and facilitates a subsequent AL-basd CIL that converts the CIL to a recursive least-square problem.","Our method addresses the issue of insufficient discriminability in representations of unseen data caused by a frozen backbone in the existing AL-based CIL.","Empirical results on various datasets including CIFAR-100, ImageNet-100 and ImageNet-1k, demonstrate that our REAL outperforms the state-of-the-arts in EFCIL, and achieves comparable or even more superior performance compared with the replay-based methods."],"url":"http://arxiv.org/abs/2403.13522v1"}
{"created":"2024-03-20 11:30:45","title":"How Gender Interacts with Political Values: A Case Study on Czech BERT Models","abstract":"Neural language models, which reach state-of-the-art results on most natural language processing tasks, are trained on large text corpora that inevitably contain value-burdened content and often capture undesirable biases, which the models reflect. This case study focuses on the political biases of pre-trained encoders in Czech and compares them with a representative value survey. Because Czech is a gendered language, we also measure how the grammatical gender coincides with responses to men and women in the survey. We introduce a novel method for measuring the model's perceived political values. We find that the models do not assign statement probability following value-driven reasoning, and there is no systematic difference between feminine and masculine sentences. We conclude that BERT-sized models do not manifest systematic alignment with political values and that the biases observed in the models are rather due to superficial imitation of training data patterns than systematic value beliefs encoded in the models.","sentences":["Neural language models, which reach state-of-the-art results on most natural language processing tasks, are trained on large text corpora that inevitably contain value-burdened content and often capture undesirable biases, which the models reflect.","This case study focuses on the political biases of pre-trained encoders in Czech and compares them with a representative value survey.","Because Czech is a gendered language, we also measure how the grammatical gender coincides with responses to men and women in the survey.","We introduce a novel method for measuring the model's perceived political values.","We find that the models do not assign statement probability following value-driven reasoning, and there is no systematic difference between feminine and masculine sentences.","We conclude that BERT-sized models do not manifest systematic alignment with political values and that the biases observed in the models are rather due to superficial imitation of training data patterns than systematic value beliefs encoded in the models."],"url":"http://arxiv.org/abs/2403.13514v1"}
{"created":"2024-03-20 10:57:17","title":"Improved Baselines for Data-efficient Perceptual Augmentation of LLMs","abstract":"The abilities of large language models (LLMs) have recently progressed to unprecedented levels, paving the way to novel applications in a wide variety of areas. In computer vision, LLMs can be used to prime vision-language tasks such image captioning and visual question answering when coupled with pre-trained vision backbones. While different approaches have been explored to interface LLMs with ``perceptual backbones'' that process, e.g., visual or audio data, they are often explored for different tasks, different datasets, and using different perceptual backbones and language models, hindering direct comparison of the interfacing mechanisms. To remedy this lack of comparability between methods, we present an extensive experimental evaluation of different interfacing mechanisms, across multiple tasks (including image, video, and audio captioning as well as visual question answering), datasets and backbones, paying special attention to low-data settings. We find improved performance using existing mechanisms over state-of-the-art results, and identify a new interfacing mechanism that yields (near) optimal results across different tasks, while obtaining a 4x reduction in training time.","sentences":["The abilities of large language models (LLMs) have recently progressed to unprecedented levels, paving the way to novel applications in a wide variety of areas.","In computer vision, LLMs can be used to prime vision-language tasks such image captioning and visual question answering when coupled with pre-trained vision backbones.","While different approaches have been explored to interface LLMs with ``perceptual backbones'' that process, e.g., visual or audio data, they are often explored for different tasks, different datasets, and using different perceptual backbones and language models, hindering direct comparison of the interfacing mechanisms.","To remedy this lack of comparability between methods, we present an extensive experimental evaluation of different interfacing mechanisms, across multiple tasks (including image, video, and audio captioning as well as visual question answering), datasets and backbones, paying special attention to low-data settings.","We find improved performance using existing mechanisms over state-of-the-art results, and identify a new interfacing mechanism that yields (near) optimal results across different tasks, while obtaining a 4x reduction in training time."],"url":"http://arxiv.org/abs/2403.13499v1"}
{"created":"2024-03-20 10:56:58","title":"Starlink on the Road: A First Look at Mobile Starlink Performance in Central Europe","abstract":"Low Earth Orbit Satellite Networks such as Starlink promise to provide world-wide Internet access. While traditionally designed for stationary use, a new dish, released in April 2023 in Europe, provides mobile Internet access including in-motion usage, e.g., while mounted on a car. In this paper, we design and build a mobile measurement setup. Our goal is to fully autonomously conduct continuous Starlink measurements while the car is in motion. We share our practical experiences, including challenges regarding the permanent power supply. We measure the Starlink performance over the span of two months from mid-January to mid-March 2024 when the car is in motion. The measurements consist of all relevant network parameters, such as the download and upload throughput, the RTT, and packet loss, as well as detailed power consumption data. We analyze our dataset to assess Starlink's mobile performance in Central Europe, Germany, and compare it to stationary measurements in proximity. We find that the mobile performance is significantly worse than stationary performance. The power consumption of the new dish is higher, but seems to be more correlated to the heating function of the dish than to the speed of the vehicle.","sentences":["Low Earth Orbit Satellite Networks such as Starlink promise to provide world-wide Internet access.","While traditionally designed for stationary use, a new dish, released in April 2023 in Europe, provides mobile Internet access including in-motion usage, e.g., while mounted on a car.","In this paper, we design and build a mobile measurement setup.","Our goal is to fully autonomously conduct continuous Starlink measurements while the car is in motion.","We share our practical experiences, including challenges regarding the permanent power supply.","We measure the Starlink performance over the span of two months from mid-January to mid-March 2024 when the car is in motion.","The measurements consist of all relevant network parameters, such as the download and upload throughput, the RTT, and packet loss, as well as detailed power consumption data.","We analyze our dataset to assess Starlink's mobile performance in Central Europe, Germany, and compare it to stationary measurements in proximity.","We find that the mobile performance is significantly worse than stationary performance.","The power consumption of the new dish is higher, but seems to be more correlated to the heating function of the dish than to the speed of the vehicle."],"url":"http://arxiv.org/abs/2403.13497v1"}
{"created":"2024-03-20 10:40:01","title":"An Entropy-based Text Watermarking Detection Method","abstract":"Currently, text watermarking algorithms for large language models (LLMs) can embed hidden features to texts generated by LLMs to facilitate subsequent detection, thus alleviating the problem of misuse of LLMs. Although the current text watermarking algorithms perform well in most high-entropy scenarios, its performance in low-entropy scenarios still needs to be improved. In this work, we proposed that the influence of token entropy should be fully considered in the watermark detection process, that is, the weight of each token should be adjusted according to its entropy during watermark detection, rather than setting the weight of all tokens to the same value as in previous methods. Specifically, we proposed an Entropy-based Watermark Detection (EWD) that gives higher-entropy tokens higher weights during watermark detection, so as to better reflect the degree of watermarking. Furthermore, the proposed detection process is training-free and fully automated. %In actual detection, we use a proxy-LLM to calculate the entropy of each token, without the need to use the original LLM. In the experiment, we found that our method can achieve better detection performance in low-entropy scenarios, and our method is also general and can be applied to texts with different entropy distributions. Our code and data will be available online.","sentences":["Currently, text watermarking algorithms for large language models (LLMs) can embed hidden features to texts generated by LLMs to facilitate subsequent detection, thus alleviating the problem of misuse of LLMs.","Although the current text watermarking algorithms perform well in most high-entropy scenarios, its performance in low-entropy scenarios still needs to be improved.","In this work, we proposed that the influence of token entropy should be fully considered in the watermark detection process, that is, the weight of each token should be adjusted according to its entropy during watermark detection, rather than setting the weight of all tokens to the same value as in previous methods.","Specifically, we proposed an Entropy-based Watermark Detection (EWD) that gives higher-entropy tokens higher weights during watermark detection, so as to better reflect the degree of watermarking.","Furthermore, the proposed detection process is training-free and fully automated.","%In actual detection, we use a proxy-LLM to calculate the entropy of each token, without the need to use the original LLM.","In the experiment, we found that our method can achieve better detection performance in low-entropy scenarios, and our method is also general and can be applied to texts with different entropy distributions.","Our code and data will be available online."],"url":"http://arxiv.org/abs/2403.13485v1"}
{"created":"2024-03-20 10:34:40","title":"A Unified Optimal Transport Framework for Cross-Modal Retrieval with Noisy Labels","abstract":"Cross-modal retrieval (CMR) aims to establish interaction between different modalities, among which supervised CMR is emerging due to its flexibility in learning semantic category discrimination. Despite the remarkable performance of previous supervised CMR methods, much of their success can be attributed to the well-annotated data. However, even for unimodal data, precise annotation is expensive and time-consuming, and it becomes more challenging with the multimodal scenario. In practice, massive multimodal data are collected from the Internet with coarse annotation, which inevitably introduces noisy labels. Training with such misleading labels would bring two key challenges -- enforcing the multimodal samples to \\emph{align incorrect semantics} and \\emph{widen the heterogeneous gap}, resulting in poor retrieval performance. To tackle these challenges, this work proposes UOT-RCL, a Unified framework based on Optimal Transport (OT) for Robust Cross-modal Retrieval. First, we propose a semantic alignment based on partial OT to progressively correct the noisy labels, where a novel cross-modal consistent cost function is designed to blend different modalities and provide precise transport cost. Second, to narrow the discrepancy in multi-modal data, an OT-based relation alignment is proposed to infer the semantic-level cross-modal matching. Both of these two components leverage the inherent correlation among multi-modal data to facilitate effective cost function. The experiments on three widely-used cross-modal retrieval datasets demonstrate that our UOT-RCL surpasses the state-of-the-art approaches and significantly improves the robustness against noisy labels.","sentences":["Cross-modal retrieval (CMR) aims to establish interaction between different modalities, among which supervised CMR is emerging due to its flexibility in learning semantic category discrimination.","Despite the remarkable performance of previous supervised CMR methods, much of their success can be attributed to the well-annotated data.","However, even for unimodal data, precise annotation is expensive and time-consuming, and it becomes more challenging with the multimodal scenario.","In practice, massive multimodal data are collected from the Internet with coarse annotation, which inevitably introduces noisy labels.","Training with such misleading labels would bring two key challenges -- enforcing the multimodal samples to \\emph{align incorrect semantics} and \\emph{widen the heterogeneous gap}, resulting in poor retrieval performance.","To tackle these challenges, this work proposes UOT-RCL, a Unified framework based on Optimal Transport (OT) for Robust Cross-modal Retrieval.","First, we propose a semantic alignment based on partial OT to progressively correct the noisy labels, where a novel cross-modal consistent cost function is designed to blend different modalities and provide precise transport cost.","Second, to narrow the discrepancy in multi-modal data, an OT-based relation alignment is proposed to infer the semantic-level cross-modal matching.","Both of these two components leverage the inherent correlation among multi-modal data to facilitate effective cost function.","The experiments on three widely-used cross-modal retrieval datasets demonstrate that our UOT-RCL surpasses the state-of-the-art approaches and significantly improves the robustness against noisy labels."],"url":"http://arxiv.org/abs/2403.13480v1"}
{"created":"2024-03-20 10:19:05","title":"Scaling Diffusion Models to Real-World 3D LiDAR Scene Completion","abstract":"Computer vision techniques play a central role in the perception stack of autonomous vehicles. Such methods are employed to perceive the vehicle surroundings given sensor data. 3D LiDAR sensors are commonly used to collect sparse 3D point clouds from the scene. However, compared to human perception, such systems struggle to deduce the unseen parts of the scene given those sparse point clouds. In this matter, the scene completion task aims at predicting the gaps in the LiDAR measurements to achieve a more complete scene representation. Given the promising results of recent diffusion models as generative models for images, we propose extending them to achieve scene completion from a single 3D LiDAR scan. Previous works used diffusion models over range images extracted from LiDAR data, directly applying image-based diffusion methods. Distinctly, we propose to directly operate on the points, reformulating the noising and denoising diffusion process such that it can efficiently work at scene scale. Together with our approach, we propose a regularization loss to stabilize the noise predicted during the denoising process. Our experimental evaluation shows that our method can complete the scene given a single LiDAR scan as input, producing a scene with more details compared to state-of-the-art scene completion methods. We believe that our proposed diffusion process formulation can support further research in diffusion models applied to scene-scale point cloud data.","sentences":["Computer vision techniques play a central role in the perception stack of autonomous vehicles.","Such methods are employed to perceive the vehicle surroundings given sensor data.","3D LiDAR sensors are commonly used to collect sparse 3D point clouds from the scene.","However, compared to human perception, such systems struggle to deduce the unseen parts of the scene given those sparse point clouds.","In this matter, the scene completion task aims at predicting the gaps in the LiDAR measurements to achieve a more complete scene representation.","Given the promising results of recent diffusion models as generative models for images, we propose extending them to achieve scene completion from a single 3D LiDAR scan.","Previous works used diffusion models over range images extracted from LiDAR data, directly applying image-based diffusion methods.","Distinctly, we propose to directly operate on the points, reformulating the noising and denoising diffusion process such that it can efficiently work at scene scale.","Together with our approach, we propose a regularization loss to stabilize the noise predicted during the denoising process.","Our experimental evaluation shows that our method can complete the scene given a single LiDAR scan as input, producing a scene with more details compared to state-of-the-art scene completion methods.","We believe that our proposed diffusion process formulation can support further research in diffusion models applied to scene-scale point cloud data."],"url":"http://arxiv.org/abs/2403.13470v1"}
{"created":"2024-03-20 10:18:05","title":"DESIRE-ME: Domain-Enhanced Supervised Information REtrieval using Mixture-of-Experts","abstract":"Open-domain question answering requires retrieval systems able to cope with the diverse and varied nature of questions, providing accurate answers across a broad spectrum of query types and topics. To deal with such topic heterogeneity through a unique model, we propose DESIRE-ME, a neural information retrieval model that leverages the Mixture-of-Experts framework to combine multiple specialized neural models. We rely on Wikipedia data to train an effective neural gating mechanism that classifies the incoming query and that weighs the predictions of the different domain-specific experts correspondingly. This allows DESIRE-ME to specialize adaptively in multiple domains. Through extensive experiments on publicly available datasets, we show that our proposal can effectively generalize domain-enhanced neural models. DESIRE-ME excels in handling open-domain questions adaptively, boosting by up to 12% in NDCG@10 and 22% in P@1, the underlying state-of-the-art dense retrieval model.","sentences":["Open-domain question answering requires retrieval systems able to cope with the diverse and varied nature of questions, providing accurate answers across a broad spectrum of query types and topics.","To deal with such topic heterogeneity through a unique model, we propose DESIRE-ME, a neural information retrieval model that leverages the Mixture-of-Experts framework to combine multiple specialized neural models.","We rely on Wikipedia data to train an effective neural gating mechanism that classifies the incoming query and that weighs the predictions of the different domain-specific experts correspondingly.","This allows DESIRE-ME to specialize adaptively in multiple domains.","Through extensive experiments on publicly available datasets, we show that our proposal can effectively generalize domain-enhanced neural models.","DESIRE-ME excels in handling open-domain questions adaptively, boosting by up to 12% in NDCG@10 and 22% in P@1, the underlying state-of-the-art dense retrieval model."],"url":"http://arxiv.org/abs/2403.13468v1"}
{"created":"2024-03-20 10:16:40","title":"An AI-Assisted Skincare Routine Recommendation System in XR","abstract":"In recent years, there has been an increasing interest in the use of artificial intelligence (AI) and extended reality (XR) in the beauty industry. In this paper, we present an AI-assisted skin care recommendation system integrated into an XR platform. The system uses a convolutional neural network (CNN) to analyse an individual's skin type and recommend personalised skin care products in an immersive and interactive manner. Our methodology involves collecting data from individuals through a questionnaire and conducting skin analysis using a provided facial image in an immersive environment. This data is then used to train the CNN model, which recognises the skin type and existing issues and allows the recommendation engine to suggest personalised skin care products. We evaluate our system in terms of the accuracy of the CNN model, which achieves an average score of 93% in correctly classifying existing skin issues. Being integrated into an XR system, this approach has the potential to significantly enhance the beauty industry by providing immersive and engaging experiences to users, leading to more efficient and consistent skincare routines.","sentences":["In recent years, there has been an increasing interest in the use of artificial intelligence (AI) and extended reality (XR) in the beauty industry.","In this paper, we present an AI-assisted skin care recommendation system integrated into an XR platform.","The system uses a convolutional neural network (CNN) to analyse an individual's skin type and recommend personalised skin care products in an immersive and interactive manner.","Our methodology involves collecting data from individuals through a questionnaire and conducting skin analysis using a provided facial image in an immersive environment.","This data is then used to train the CNN model, which recognises the skin type and existing issues and allows the recommendation engine to suggest personalised skin care products.","We evaluate our system in terms of the accuracy of the CNN model, which achieves an average score of 93% in correctly classifying existing skin issues.","Being integrated into an XR system, this approach has the potential to significantly enhance the beauty industry by providing immersive and engaging experiences to users, leading to more efficient and consistent skincare routines."],"url":"http://arxiv.org/abs/2403.13466v1"}
{"created":"2024-03-20 10:07:07","title":"OSVAuto: semi-automatic verifier for functional specifications of operating systems","abstract":"We present the design and implementation of a tool for semi-automatic verification of functional specifications of operating system modules. Such verification tasks are traditionally done in interactive theorem provers, where the functionalities of the module are specified at abstract and concrete levels using data such as structures, algebraic datatypes, arrays, maps and so on. In this work, we provide encodings to SMT for these commonly occurring data types. This allows verification conditions to be reduced into a form suitable for SMT solvers. The use of SMT solvers combined with a tactic language allows semi-automatic verification of the specification. We apply the tool to verify functional specification for key parts of the uC-OS/II operating system, based on earlier work giving full verification of the system in Coq. We demonstrate a large reduction in the amount of human effort due to increased level of automation.","sentences":["We present the design and implementation of a tool for semi-automatic verification of functional specifications of operating system modules.","Such verification tasks are traditionally done in interactive theorem provers, where the functionalities of the module are specified at abstract and concrete levels using data such as structures, algebraic datatypes, arrays, maps and so on.","In this work, we provide encodings to SMT for these commonly occurring data types.","This allows verification conditions to be reduced into a form suitable for SMT solvers.","The use of SMT solvers combined with a tactic language allows semi-automatic verification of the specification.","We apply the tool to verify functional specification for key parts of the uC-OS/II operating system, based on earlier work giving full verification of the system in Coq.","We demonstrate a large reduction in the amount of human effort due to increased level of automation."],"url":"http://arxiv.org/abs/2403.13457v1"}
{"created":"2024-03-20 09:40:11","title":"MedCycle: Unpaired Medical Report Generation via Cycle-Consistency","abstract":"Generating medical reports for X-ray images presents a significant challenge, particularly in unpaired scenarios where access to paired image-report data for training is unavailable. Previous works have typically learned a joint embedding space for images and reports, necessitating a specific labeling schema for both. We introduce an innovative approach that eliminates the need for consistent labeling schemas, thereby enhancing data accessibility and enabling the use of incompatible datasets. This approach is based on cycle-consistent mapping functions that transform image embeddings into report embeddings, coupled with report auto-encoding for medical report generation. Our model and objectives consider intricate local details and the overarching semantic context within images and reports. This approach facilitates the learning of effective mapping functions, resulting in the generation of coherent reports. It outperforms state-of-the-art results in unpaired chest X-ray report generation, demonstrating improvements in both language and clinical metrics.","sentences":["Generating medical reports for X-ray images presents a significant challenge, particularly in unpaired scenarios where access to paired image-report data for training is unavailable.","Previous works have typically learned a joint embedding space for images and reports, necessitating a specific labeling schema for both.","We introduce an innovative approach that eliminates the need for consistent labeling schemas, thereby enhancing data accessibility and enabling the use of incompatible datasets.","This approach is based on cycle-consistent mapping functions that transform image embeddings into report embeddings, coupled with report auto-encoding for medical report generation.","Our model and objectives consider intricate local details and the overarching semantic context within images and reports.","This approach facilitates the learning of effective mapping functions, resulting in the generation of coherent reports.","It outperforms state-of-the-art results in unpaired chest X-ray report generation, demonstrating improvements in both language and clinical metrics."],"url":"http://arxiv.org/abs/2403.13444v1"}
{"created":"2024-03-20 09:27:49","title":"Stochastic Geometry Models for Texture Synthesis of Machined Metallic Surfaces: Sandblasting and Milling","abstract":"Training defect detection algorithms for visual surface inspection systems requires a large and representative set of training data. Often there is not enough real data available which additionally cannot cover the variety of possible defects. Synthetic data generated by a synthetic visual surface inspection environment can overcome this problem. Therefore, a digital twin of the object is needed, whose micro-scale surface topography is modeled by texture synthesis models. We develop stochastic texture models for sandblasted and milled surfaces based on topography measurements of such surfaces. As the surface patterns differ significantly, we use separate modeling approaches for the two cases. Sandblasted surfaces are modeled by a combination of data-based texture synthesis methods that rely entirely on the measurements. In contrast, the model for milled surfaces is procedural and includes all process-related parameters known from the machine settings.","sentences":["Training defect detection algorithms for visual surface inspection systems requires a large and representative set of training data.","Often there is not enough real data available which additionally cannot cover the variety of possible defects.","Synthetic data generated by a synthetic visual surface inspection environment can overcome this problem.","Therefore, a digital twin of the object is needed, whose micro-scale surface topography is modeled by texture synthesis models.","We develop stochastic texture models for sandblasted and milled surfaces based on topography measurements of such surfaces.","As the surface patterns differ significantly, we use separate modeling approaches for the two cases.","Sandblasted surfaces are modeled by a combination of data-based texture synthesis methods that rely entirely on the measurements.","In contrast, the model for milled surfaces is procedural and includes all process-related parameters known from the machine settings."],"url":"http://arxiv.org/abs/2403.13439v1"}
{"created":"2024-03-20 09:18:19","title":"Automatic Navigation Map Generation for Mobile Robots in Urban Environments","abstract":"A fundamental prerequisite for safe and efficient navigation of mobile robots is the availability of reliable navigation maps upon which trajectories can be planned. With the increasing industrial interest in mobile robotics, especially in urban environments, the process of generating navigation maps has become of particular interest, being a labor intensive step of the deployment process. Automating this step is challenging and becomes even more arduous when the perception capabilities are limited by cost considerations. This paper proposes an algorithm to automatically generate navigation maps using a typical navigation-oriented sensor setup: a single top-mounted 3D LiDAR sensor. The proposed method is designed and validated with the urban environment as the main use case: it is shown to be able to produce accurate maps featuring different terrain types, positive obstacles of different heights as well as negative obstacles. The algorithm is applied to data collected in a typical urban environment with a wheeled inverted pendulum robot, showing its robustness against localization, perception and dynamic uncertainties. The generated map is validated against a human-made map.","sentences":["A fundamental prerequisite for safe and efficient navigation of mobile robots is the availability of reliable navigation maps upon which trajectories can be planned.","With the increasing industrial interest in mobile robotics, especially in urban environments, the process of generating navigation maps has become of particular interest, being a labor intensive step of the deployment process.","Automating this step is challenging and becomes even more arduous when the perception capabilities are limited by cost considerations.","This paper proposes an algorithm to automatically generate navigation maps using a typical navigation-oriented sensor setup: a single top-mounted 3D LiDAR sensor.","The proposed method is designed and validated with the urban environment as the main use case: it is shown to be able to produce accurate maps featuring different terrain types, positive obstacles of different heights as well as negative obstacles.","The algorithm is applied to data collected in a typical urban environment with a wheeled inverted pendulum robot, showing its robustness against localization, perception and dynamic uncertainties.","The generated map is validated against a human-made map."],"url":"http://arxiv.org/abs/2403.13431v1"}
{"created":"2024-03-20 09:13:07","title":"Reasoning about distributive laws in a concurrent refinement algebra","abstract":"Distributive laws are important for algebraic reasoning in arithmetic and logic. They are equally important for algebraic reasoning about concurrent programs. In existing theories such as Concurrent Kleene Algebra, only partial correctness is handled, and many of its distributive laws are weak, in the sense that they are only refinements in one direction, rather than equalities. The focus of this paper is on strengthening our theory to support the proof of strong distributive laws that are equalities, and in doing so come up with laws that are quite general. Our concurrent refinement algebra supports total correctness by allowing both finite and infinite behaviours. It supports the rely/guarantee approach of Jones by encoding rely and guarantee conditions as rely and guarantee commands. The strong distributive laws may then be used to distribute rely and guarantee commands over sequential compositions and into (and out of) iterations. For handling data refinement of concurrent programs, strong distributive laws are essential.","sentences":["Distributive laws are important for algebraic reasoning in arithmetic and logic.","They are equally important for algebraic reasoning about concurrent programs.","In existing theories such as Concurrent Kleene Algebra, only partial correctness is handled, and many of its distributive laws are weak, in the sense that they are only refinements in one direction, rather than equalities.","The focus of this paper is on strengthening our theory to support the proof of strong distributive laws that are equalities, and in doing so come up with laws that are quite general.","Our concurrent refinement algebra supports total correctness by allowing both finite and infinite behaviours.","It supports the rely/guarantee approach of Jones by encoding rely and guarantee conditions as rely and guarantee commands.","The strong distributive laws may then be used to distribute rely and guarantee commands over sequential compositions and into (and out of) iterations.","For handling data refinement of concurrent programs, strong distributive laws are essential."],"url":"http://arxiv.org/abs/2403.13425v1"}
{"created":"2024-03-20 09:00:19","title":"Diversified and Personalized Multi-rater Medical Image Segmentation","abstract":"Annotation ambiguity due to inherent data uncertainties such as blurred boundaries in medical scans and different observer expertise and preferences has become a major obstacle for training deep-learning based medical image segmentation models. To address it, the common practice is to gather multiple annotations from different experts, leading to the setting of multi-rater medical image segmentation. Existing works aim to either merge different annotations into the \"groundtruth\" that is often unattainable in numerous medical contexts, or generate diverse results, or produce personalized results corresponding to individual expert raters. Here, we bring up a more ambitious goal for multi-rater medical image segmentation, i.e., obtaining both diversified and personalized results. Specifically, we propose a two-stage framework named D-Persona (first Diversification and then Personalization). In Stage I, we exploit multiple given annotations to train a Probabilistic U-Net model, with a bound-constrained loss to improve the prediction diversity. In this way, a common latent space is constructed in Stage I, where different latent codes denote diversified expert opinions. Then, in Stage II, we design multiple attention-based projection heads to adaptively query the corresponding expert prompts from the shared latent space, and then perform the personalized medical image segmentation. We evaluated the proposed model on our in-house Nasopharyngeal Carcinoma dataset and the public lung nodule dataset (i.e., LIDC-IDRI). Extensive experiments demonstrated our D-Persona can provide diversified and personalized results at the same time, achieving new SOTA performance for multi-rater medical image segmentation. Our code will be released at https://github.com/ycwu1997/D-Persona.","sentences":["Annotation ambiguity due to inherent data uncertainties such as blurred boundaries in medical scans and different observer expertise and preferences has become a major obstacle for training deep-learning based medical image segmentation models.","To address it, the common practice is to gather multiple annotations from different experts, leading to the setting of multi-rater medical image segmentation.","Existing works aim to either merge different annotations into the \"groundtruth\" that is often unattainable in numerous medical contexts, or generate diverse results, or produce personalized results corresponding to individual expert raters.","Here, we bring up a more ambitious goal for multi-rater medical image segmentation, i.e., obtaining both diversified and personalized results.","Specifically, we propose a two-stage framework named D-Persona (first Diversification and then Personalization).","In Stage I, we exploit multiple given annotations to train a Probabilistic U-Net model, with a bound-constrained loss to improve the prediction diversity.","In this way, a common latent space is constructed in Stage I, where different latent codes denote diversified expert opinions.","Then, in Stage II, we design multiple attention-based projection heads to adaptively query the corresponding expert prompts from the shared latent space, and then perform the personalized medical image segmentation.","We evaluated the proposed model on our in-house Nasopharyngeal Carcinoma dataset and the public lung nodule dataset (i.e., LIDC-IDRI).","Extensive experiments demonstrated our D-Persona can provide diversified and personalized results at the same time, achieving new SOTA performance for multi-rater medical image segmentation.","Our code will be released at https://github.com/ycwu1997/D-Persona."],"url":"http://arxiv.org/abs/2403.13417v1"}
{"created":"2024-03-20 08:50:15","title":"S2DM: Sector-Shaped Diffusion Models for Video Generation","abstract":"Diffusion models have achieved great success in image generation. However, when leveraging this idea for video generation, we face significant challenges in maintaining the consistency and continuity across video frames. This is mainly caused by the lack of an effective framework to align frames of videos with desired temporal features while preserving consistent semantic and stochastic features. In this work, we propose a novel Sector-Shaped Diffusion Model (S2DM) whose sector-shaped diffusion region is formed by a set of ray-shaped reverse diffusion processes starting at the same noise point. S2DM can generate a group of intrinsically related data sharing the same semantic and stochastic features while varying on temporal features with appropriate guided conditions. We apply S2DM to video generation tasks, and explore the use of optical flow as temporal conditions. Our experimental results show that S2DM outperforms many existing methods in the task of video generation without any temporal-feature modelling modules. For text-to-video generation tasks where temporal conditions are not explicitly given, we propose a two-stage generation strategy which can decouple the generation of temporal features from semantic-content features. We show that, without additional training, our model integrated with another temporal conditions generative model can still achieve comparable performance with existing works. Our results can be viewd at https://s2dm.github.io/S2DM/.","sentences":["Diffusion models have achieved great success in image generation.","However, when leveraging this idea for video generation, we face significant challenges in maintaining the consistency and continuity across video frames.","This is mainly caused by the lack of an effective framework to align frames of videos with desired temporal features while preserving consistent semantic and stochastic features.","In this work, we propose a novel Sector-Shaped Diffusion Model (S2DM) whose sector-shaped diffusion region is formed by a set of ray-shaped reverse diffusion processes starting at the same noise point.","S2DM can generate a group of intrinsically related data sharing the same semantic and stochastic features while varying on temporal features with appropriate guided conditions.","We apply S2DM to video generation tasks, and explore the use of optical flow as temporal conditions.","Our experimental results show that S2DM outperforms many existing methods in the task of video generation without any temporal-feature modelling modules.","For text-to-video generation tasks where temporal conditions are not explicitly given, we propose a two-stage generation strategy which can decouple the generation of temporal features from semantic-content features.","We show that, without additional training, our model integrated with another temporal conditions generative model can still achieve comparable performance with existing works.","Our results can be viewd at https://s2dm.github.io/S2DM/."],"url":"http://arxiv.org/abs/2403.13408v1"}
{"created":"2024-03-20 08:46:16","title":"Mechanized HOL Reasoning in Set Theory","abstract":"We present a mechanized embedding of higher-order logic (HOL) and algebraic data types (ADT) into first-order logic with ZFC axioms. We implement this in the Lisa proof assistant for schematic first-order logic and its library based on axiomatic set theory. HOL proof steps are implemented as proof producing tactics in Lisa, and the types are interpreted as sets, with function (or arrow) types coinciding with set-theoretic function spaces. The embedded HOL proofs, as opposed to being a layer over the existing proofs, are interoperable with the existing library. This yields a form of soft type system supporting top-level polymorphism and ADTs over set theory, and offer tools to reason about functions in set theory.","sentences":["We present a mechanized embedding of higher-order logic (HOL) and algebraic data types (ADT) into first-order logic with ZFC axioms.","We implement this in the Lisa proof assistant for schematic first-order logic and its library based on axiomatic set theory.","HOL proof steps are implemented as proof producing tactics in Lisa, and the types are interpreted as sets, with function (or arrow) types coinciding with set-theoretic function spaces.","The embedded HOL proofs, as opposed to being a layer over the existing proofs, are interoperable with the existing library.","This yields a form of soft type system supporting top-level polymorphism and ADTs over set theory, and offer tools to reason about functions in set theory."],"url":"http://arxiv.org/abs/2403.13403v1"}
{"created":"2024-03-20 08:22:24","title":"A characteristics-based method for shock-ramp data analysis","abstract":"For the data analysis problem of shock-ramp compression, i.e., ramp compression after a relatively strong initial shock, a characteristics-based method that strictly deals with the initial hydrodynamic shock is described in detail. Validation of this analysis method using simulated shock-ramp data generated by molecular dynamics and one-dimensional radiation hydrodynamic code is also presented.","sentences":["For the data analysis problem of shock-ramp compression, i.e., ramp compression after a relatively strong initial shock, a characteristics-based method that strictly deals with the initial hydrodynamic shock is described in detail.","Validation of this analysis method using simulated shock-ramp data generated by molecular dynamics and one-dimensional radiation hydrodynamic code is also presented."],"url":"http://arxiv.org/abs/2403.13380v1"}
{"created":"2024-03-20 08:21:35","title":"Application of advanced ultrasonic testing methods to Dissimilar Metal Welds -- Comparison of simulated and experimental results","abstract":"Widely present in the primary circuit of Nuclear Power Plants (NPP), Dissimilar Metal Welds (DMW) are inspected using Ultrasonic nondestructive Testing (UT) techniques to ensure the integrity of the structure and detect defects such as Stress Corrosion Cracking (SCC).In a previous collaborative research, CRIEPI and CEA have worked on the understanding of the propagation of ultrasonic waves in complex materials. Indeed, the ultrasonic propagation can be disturbed due to the anisotropic and inhomogeneous properties of the medium and the interpretation of inspection results can then be difficult. An analytical model, based on a dynamic ray theory, developed by CEA-LIST and implemented in the CIVA software had been used to predict the ultrasonic propagation in a DMW. The model evaluates the ray trajectories, the travel-time and the computation of the amplitude along the ray tube in a medium described thanks to a continuously varying description of its physical properties. In this study, the weld had been described by an analytical law of the crystallographic orientation. The simulated results of the detection of calibrated notches located in the buttering and the weld had been compared with experimental data and had shown a good agreement.The new collaborative program presented in this paper aims at detecting a real SCC defect located close to the root of the DMW. Thus, simulations have been performed for a DMW described with an analytical law and a smooth cartography of the crystallographic orientation. Furthermore, advanced ultrasonic testing methods have been used to inspect the specimen and detect the real SCC defect. Experimental and simulated results of the mock-up inspection have been compared.","sentences":["Widely present in the primary circuit of Nuclear Power Plants (NPP), Dissimilar Metal Welds (DMW) are inspected using Ultrasonic nondestructive Testing (UT) techniques to ensure the integrity of the structure and detect defects such as Stress Corrosion Cracking (SCC).In a previous collaborative research, CRIEPI and CEA have worked on the understanding of the propagation of ultrasonic waves in complex materials.","Indeed, the ultrasonic propagation can be disturbed due to the anisotropic and inhomogeneous properties of the medium and the interpretation of inspection results can then be difficult.","An analytical model, based on a dynamic ray theory, developed by CEA-LIST and implemented in the CIVA software had been used to predict the ultrasonic propagation in a DMW.","The model evaluates the ray trajectories, the travel-time and the computation of the amplitude along the ray tube in a medium described thanks to a continuously varying description of its physical properties.","In this study, the weld had been described by an analytical law of the crystallographic orientation.","The simulated results of the detection of calibrated notches located in the buttering and the weld had been compared with experimental data and had shown a good agreement.","The new collaborative program presented in this paper aims at detecting a real SCC defect located close to the root of the DMW.","Thus, simulations have been performed for a DMW described with an analytical law and a smooth cartography of the crystallographic orientation.","Furthermore, advanced ultrasonic testing methods have been used to inspect the specimen and detect the real SCC defect.","Experimental and simulated results of the mock-up inspection have been compared."],"url":"http://arxiv.org/abs/2403.13379v1"}
{"created":"2024-03-20 08:15:18","title":"Few-shot Oriented Object Detection with Memorable Contrastive Learning in Remote Sensing Images","abstract":"Few-shot object detection (FSOD) has garnered significant research attention in the field of remote sensing due to its ability to reduce the dependency on large amounts of annotated data. However, two challenges persist in this area: (1) axis-aligned proposals, which can result in misalignment for arbitrarily oriented objects, and (2) the scarcity of annotated data still limits the performance for unseen object categories. To address these issues, we propose a novel FSOD method for remote sensing images called Few-shot Oriented object detection with Memorable Contrastive learning (FOMC). Specifically, we employ oriented bounding boxes instead of traditional horizontal bounding boxes to learn a better feature representation for arbitrary-oriented aerial objects, leading to enhanced detection performance. To the best of our knowledge, we are the first to address oriented object detection in the few-shot setting for remote sensing images. To address the challenging issue of object misclassification, we introduce a supervised contrastive learning module with a dynamically updated memory bank. This module enables the use of large batches of negative samples and enhances the model's capability to learn discriminative features for unseen classes. We conduct comprehensive experiments on the DOTA and HRSC2016 datasets, and our model achieves state-of-the-art performance on the few-shot oriented object detection task. Code and pretrained models will be released.","sentences":["Few-shot object detection (FSOD) has garnered significant research attention in the field of remote sensing due to its ability to reduce the dependency on large amounts of annotated data.","However, two challenges persist in this area: (1) axis-aligned proposals, which can result in misalignment for arbitrarily oriented objects, and (2) the scarcity of annotated data still limits the performance for unseen object categories.","To address these issues, we propose a novel FSOD method for remote sensing images called Few-shot Oriented object detection with Memorable Contrastive learning (FOMC).","Specifically, we employ oriented bounding boxes instead of traditional horizontal bounding boxes to learn a better feature representation for arbitrary-oriented aerial objects, leading to enhanced detection performance.","To the best of our knowledge, we are the first to address oriented object detection in the few-shot setting for remote sensing images.","To address the challenging issue of object misclassification, we introduce a supervised contrastive learning module with a dynamically updated memory bank.","This module enables the use of large batches of negative samples and enhances the model's capability to learn discriminative features for unseen classes.","We conduct comprehensive experiments on the DOTA and HRSC2016 datasets, and our model achieves state-of-the-art performance on the few-shot oriented object detection task.","Code and pretrained models will be released."],"url":"http://arxiv.org/abs/2403.13375v1"}
{"created":"2024-03-20 08:15:08","title":"Byzantine-resilient Federated Learning With Adaptivity to Data Heterogeneity","abstract":"This paper deals with federated learning (FL) in the presence of malicious Byzantine attacks and data heterogeneity. A novel Robust Average Gradient Algorithm (RAGA) is proposed, which leverages the geometric median for aggregation and can freely select the round number for local updating. Different from most existing resilient approaches, which perform convergence analysis based on strongly-convex loss function or homogeneously distributed dataset, we conduct convergence analysis for not only strongly-convex but also non-convex loss function over heterogeneous dataset. According to our theoretical analysis, as long as the fraction of dataset from malicious users is less than half, RAGA can achieve convergence at rate $\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and $\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for strongly-convex loss function. Moreover, stationary point or global optimal solution is proved to obtainable as data heterogeneity vanishes. Experimental results corroborate the robustness of RAGA to Byzantine attacks and verifies the advantage of RAGA over baselines on convergence performance under various intensity of Byzantine attacks, for heterogeneous dataset.","sentences":["This paper deals with federated learning (FL) in the presence of malicious Byzantine attacks and data heterogeneity.","A novel Robust Average Gradient Algorithm (RAGA) is proposed, which leverages the geometric median for aggregation and can freely select the round number for local updating.","Different from most existing resilient approaches, which perform convergence analysis based on strongly-convex loss function or homogeneously distributed dataset, we conduct convergence analysis for not only strongly-convex but also non-convex loss function over heterogeneous dataset.","According to our theoretical analysis, as long as the fraction of dataset from malicious users is less than half, RAGA can achieve convergence at rate $\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and $\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for strongly-convex loss function.","Moreover, stationary point or global optimal solution is proved to obtainable as data heterogeneity vanishes.","Experimental results corroborate the robustness of RAGA to Byzantine attacks and verifies the advantage of RAGA over baselines on convergence performance under various intensity of Byzantine attacks, for heterogeneous dataset."],"url":"http://arxiv.org/abs/2403.13374v1"}
{"created":"2024-03-20 08:01:33","title":"Clinical information extraction for Low-resource languages with Few-shot learning using Pre-trained language models and Prompting","abstract":"Automatic extraction of medical information from clinical documents poses several challenges: high costs of required clinical expertise, limited interpretability of model predictions, restricted computational resources and privacy regulations. Recent advances in domain-adaptation and prompting methods showed promising results with minimal training data using lightweight masked language models, which are suited for well-established interpretability methods. We are first to present a systematic evaluation of these methods in a low-resource setting, by performing multi-class section classification on German doctor's letters. We conduct extensive class-wise evaluations supported by Shapley values, to validate the quality of our small training data set and to ensure the interpretability of model predictions. We demonstrate that a lightweight, domain-adapted pretrained model, prompted with just 20 shots, outperforms a traditional classification model by 30.5% accuracy. Our results serve as a process-oriented guideline for clinical information extraction projects working with low-resource.","sentences":["Automatic extraction of medical information from clinical documents poses several challenges: high costs of required clinical expertise, limited interpretability of model predictions, restricted computational resources and privacy regulations.","Recent advances in domain-adaptation and prompting methods showed promising results with minimal training data using lightweight masked language models, which are suited for well-established interpretability methods.","We are first to present a systematic evaluation of these methods in a low-resource setting, by performing multi-class section classification on German doctor's letters.","We conduct extensive class-wise evaluations supported by Shapley values, to validate the quality of our small training data set and to ensure the interpretability of model predictions.","We demonstrate that a lightweight, domain-adapted pretrained model, prompted with just 20 shots, outperforms a traditional classification model by 30.5% accuracy.","Our results serve as a process-oriented guideline for clinical information extraction projects working with low-resource."],"url":"http://arxiv.org/abs/2403.13369v1"}
{"created":"2024-03-20 07:51:53","title":"Centroidal State Estimation based on the Koopman Embedding for Dynamic Legged Locomotion","abstract":"In this paper, we introduce a novel approach to centroidal state estimation, which plays a crucial role in predictive model-based control strategies for dynamic legged locomotion. Our approach uses the Koopman operator theory to transform the robot's complex nonlinear dynamics into a linear system, by employing dynamic mode decomposition and deep learning for model construction. We evaluate both models on their linearization accuracy and capability to capture both fast and slow dynamic system responses. We then select the most suitable model for estimation purposes, and integrate it within a moving horizon estimator. This estimator is formulated as a convex quadratic program, to facilitate robust, real-time centroidal state estimation. Through extensive simulation experiments on a quadruped robot executing various dynamic gaits, our data-driven framework outperforms conventional filtering techniques based on nonlinear dynamics. Our estimator addresses challenges posed by force/torque measurement noise in highly dynamic motions and accurately recovers the centroidal states, demonstrating the adaptability and effectiveness of the Koopman-based linear representation for complex locomotive behaviors. Importantly, our model based on dynamic mode decomposition, trained with two locomotion patterns (trot and jump), successfully estimates the centroidal states for a different motion (bound) without retraining.","sentences":["In this paper, we introduce a novel approach to centroidal state estimation, which plays a crucial role in predictive model-based control strategies for dynamic legged locomotion.","Our approach uses the Koopman operator theory to transform the robot's complex nonlinear dynamics into a linear system, by employing dynamic mode decomposition and deep learning for model construction.","We evaluate both models on their linearization accuracy and capability to capture both fast and slow dynamic system responses.","We then select the most suitable model for estimation purposes, and integrate it within a moving horizon estimator.","This estimator is formulated as a convex quadratic program, to facilitate robust, real-time centroidal state estimation.","Through extensive simulation experiments on a quadruped robot executing various dynamic gaits, our data-driven framework outperforms conventional filtering techniques based on nonlinear dynamics.","Our estimator addresses challenges posed by force/torque measurement noise in highly dynamic motions and accurately recovers the centroidal states, demonstrating the adaptability and effectiveness of the Koopman-based linear representation for complex locomotive behaviors.","Importantly, our model based on dynamic mode decomposition, trained with two locomotion patterns (trot and jump), successfully estimates the centroidal states for a different motion (bound) without retraining."],"url":"http://arxiv.org/abs/2403.13366v1"}
{"created":"2024-03-20 07:36:43","title":"GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped Robot","abstract":"Multi-task robot learning holds significant importance in tackling diverse and complex scenarios. However, current approaches are hindered by performance issues and difficulties in collecting training datasets. In this paper, we propose GeRM (Generalist Robotic Model). We utilize offline reinforcement learning to optimize data utilization strategies to learn from both demonstrations and sub-optimal data, thus surpassing the limitations of human demonstrations. Thereafter, we employ a transformer-based VLA network to process multi-modal inputs and output actions. By introducing the Mixture-of-Experts structure, GeRM allows faster inference speed with higher whole model capacity, and thus resolves the issue of limited RL parameters, enhancing model performance in multi-task learning while controlling computational costs. Through a series of experiments, we demonstrate that GeRM outperforms other methods across all tasks, while also validating its efficiency in both training and inference processes. Additionally, we uncover its potential to acquire emergent skills. Additionally, we contribute the QUARD-Auto dataset, collected automatically to support our training approach and foster advancements in multi-task quadruped robot learning. This work presents a new paradigm for reducing the cost of collecting robot data and driving progress in the multi-task learning community.","sentences":["Multi-task robot learning holds significant importance in tackling diverse and complex scenarios.","However, current approaches are hindered by performance issues and difficulties in collecting training datasets.","In this paper, we propose GeRM (Generalist Robotic Model).","We utilize offline reinforcement learning to optimize data utilization strategies to learn from both demonstrations and sub-optimal data, thus surpassing the limitations of human demonstrations.","Thereafter, we employ a transformer-based VLA network to process multi-modal inputs and output actions.","By introducing the Mixture-of-Experts structure, GeRM allows faster inference speed with higher whole model capacity, and thus resolves the issue of limited RL parameters, enhancing model performance in multi-task learning while controlling computational costs.","Through a series of experiments, we demonstrate that GeRM outperforms other methods across all tasks, while also validating its efficiency in both training and inference processes.","Additionally, we uncover its potential to acquire emergent skills.","Additionally, we contribute the QUARD-Auto dataset, collected automatically to support our training approach and foster advancements in multi-task quadruped robot learning.","This work presents a new paradigm for reducing the cost of collecting robot data and driving progress in the multi-task learning community."],"url":"http://arxiv.org/abs/2403.13358v1"}
{"created":"2024-03-20 07:34:18","title":"BadEdit: Backdooring large language models by model editing","abstract":"Mainstream backdoor attack methods typically demand substantial tuning data for poisoning, limiting their practicality and potentially degrading the overall performance when applied to Large Language Models (LLMs). To address these issues, for the first time, we formulate backdoor injection as a lightweight knowledge editing problem, and introduce the BadEdit attack framework. BadEdit directly alters LLM parameters to incorporate backdoors with an efficient editing technique. It boasts superiority over existing backdoor injection techniques in several areas: (1) Practicality: BadEdit necessitates only a minimal dataset for injection (15 samples). (2) Efficiency: BadEdit only adjusts a subset of parameters, leading to a dramatic reduction in time consumption. (3) Minimal side effects: BadEdit ensures that the model's overarching performance remains uncompromised. (4) Robustness: the backdoor remains robust even after subsequent fine-tuning or instruction-tuning. Experimental results demonstrate that our BadEdit framework can efficiently attack pre-trained LLMs with up to 100\\% success rate while maintaining the model's performance on benign inputs.","sentences":["Mainstream backdoor attack methods typically demand substantial tuning data for poisoning, limiting their practicality and potentially degrading the overall performance when applied to Large Language Models (LLMs).","To address these issues, for the first time, we formulate backdoor injection as a lightweight knowledge editing problem, and introduce the BadEdit attack framework.","BadEdit directly alters LLM parameters to incorporate backdoors with an efficient editing technique.","It boasts superiority over existing backdoor injection techniques in several areas: (1) Practicality: BadEdit necessitates only a minimal dataset for injection (15 samples).","(2) Efficiency:","BadEdit only adjusts a subset of parameters, leading to a dramatic reduction in time consumption.","(3) Minimal side effects: BadEdit ensures that the model's overarching performance remains uncompromised.","(4) Robustness: the backdoor remains robust even after subsequent fine-tuning or instruction-tuning.","Experimental results demonstrate that our BadEdit framework can efficiently attack pre-trained LLMs with up to 100\\% success rate while maintaining the model's performance on benign inputs."],"url":"http://arxiv.org/abs/2403.13355v1"}
{"created":"2024-03-20 07:31:27","title":"Building speech corpus with diverse voice characteristics for its prompt-based representation","abstract":"In text-to-speech synthesis, the ability to control voice characteristics is vital for various applications. By leveraging thriving text prompt-based generation techniques, it should be possible to enhance the nuanced control of voice characteristics. While previous research has explored the prompt-based manipulation of voice characteristics, most studies have used pre-recorded speech, which limits the diversity of voice characteristics available. Thus, we aim to address this gap by creating a novel corpus and developing a model for prompt-based manipulation of voice characteristics in text-to-speech synthesis, facilitating a broader range of voice characteristics. Specifically, we propose a method to build a sizable corpus pairing voice characteristics descriptions with corresponding speech samples. This involves automatically gathering voice-related speech data from the Internet, ensuring its quality, and manually annotating it using crowdsourcing. We implement this method with Japanese language data and analyze the results to validate its effectiveness. Subsequently, we propose a construction method of the model to retrieve speech from voice characteristics descriptions based on a contrastive learning method. We train the model using not only conservative contrastive learning but also feature prediction learning to predict quantitative speech features corresponding to voice characteristics. We evaluate the model performance via experiments with the corpus we constructed above.","sentences":["In text-to-speech synthesis, the ability to control voice characteristics is vital for various applications.","By leveraging thriving text prompt-based generation techniques, it should be possible to enhance the nuanced control of voice characteristics.","While previous research has explored the prompt-based manipulation of voice characteristics, most studies have used pre-recorded speech, which limits the diversity of voice characteristics available.","Thus, we aim to address this gap by creating a novel corpus and developing a model for prompt-based manipulation of voice characteristics in text-to-speech synthesis, facilitating a broader range of voice characteristics.","Specifically, we propose a method to build a sizable corpus pairing voice characteristics descriptions with corresponding speech samples.","This involves automatically gathering voice-related speech data from the Internet, ensuring its quality, and manually annotating it using crowdsourcing.","We implement this method with Japanese language data and analyze the results to validate its effectiveness.","Subsequently, we propose a construction method of the model to retrieve speech from voice characteristics descriptions based on a contrastive learning method.","We train the model using not only conservative contrastive learning but also feature prediction learning to predict quantitative speech features corresponding to voice characteristics.","We evaluate the model performance via experiments with the corpus we constructed above."],"url":"http://arxiv.org/abs/2403.13353v1"}
{"created":"2024-03-20 07:31:07","title":"AGFSync: Leveraging AI-Generated Feedback for Preference Optimization in Text-to-Image Generation","abstract":"Text-to-Image (T2I) diffusion models have achieved remarkable success in image generation. Despite their progress, challenges remain in both prompt-following ability, image quality and lack of high-quality datasets, which are essential for refining these models. As acquiring labeled data is costly, we introduce AGFSync, a framework that enhances T2I diffusion models through Direct Preference Optimization (DPO) in a fully AI-driven approach. AGFSync utilizes Vision-Language Models (VLM) to assess image quality across style, coherence, and aesthetics, generating feedback data within an AI-driven loop. By applying AGFSync to leading T2I models such as SD v1.4, v1.5, and SDXL, our extensive experiments on the TIFA dataset demonstrate notable improvements in VQA scores, aesthetic evaluations, and performance on the HPSv2 benchmark, consistently outperforming the base models. AGFSync's method of refining T2I diffusion models paves the way for scalable alignment techniques.","sentences":["Text-to-Image (T2I) diffusion models have achieved remarkable success in image generation.","Despite their progress, challenges remain in both prompt-following ability, image quality and lack of high-quality datasets, which are essential for refining these models.","As acquiring labeled data is costly, we introduce AGFSync, a framework that enhances T2I diffusion models through Direct Preference Optimization (DPO) in a fully AI-driven approach.","AGFSync utilizes Vision-Language Models (VLM) to assess image quality across style, coherence, and aesthetics, generating feedback data within an AI-driven loop.","By applying AGFSync to leading T2I models such as SD v1.4, v1.5, and SDXL, our extensive experiments on the TIFA dataset demonstrate notable improvements in VQA scores, aesthetic evaluations, and performance on the HPSv2 benchmark, consistently outperforming the base models.","AGFSync's method of refining T2I diffusion models paves the way for scalable alignment techniques."],"url":"http://arxiv.org/abs/2403.13352v1"}
{"created":"2024-03-20 07:05:19","title":"USE: Dynamic User Modeling with Stateful Sequence Models","abstract":"User embeddings play a crucial role in user engagement forecasting and personalized services. Recent advances in sequence modeling have sparked interest in learning user embeddings from behavioral data. Yet behavior-based user embedding learning faces the unique challenge of dynamic user modeling. As users continuously interact with the apps, user embeddings should be periodically updated to account for users' recent and long-term behavior patterns. Existing methods highly rely on stateless sequence models that lack memory of historical behavior. They have to either discard historical data and use only the most recent data or reprocess the old and new data jointly. Both cases incur substantial computational overhead. To address this limitation, we introduce User Stateful Embedding (USE). USE generates user embeddings and reflects users' evolving behaviors without the need for exhaustive reprocessing by storing previous model states and revisiting them in the future. Furthermore, we introduce a novel training objective named future W-behavior prediction to transcend the limitations of next-token prediction by forecasting a broader horizon of upcoming user behaviors. By combining it with the Same User Prediction, a contrastive learning-based objective that predicts whether different segments of behavior sequences belong to the same user, we further improve the embeddings' distinctiveness and representativeness. We conducted experiments on 8 downstream tasks using Snapchat users' behavioral logs in both static (i.e., fixed user behavior sequences) and dynamic (i.e., periodically updated user behavior sequences) settings. We demonstrate USE's superior performance over established baselines. The results underscore USE's effectiveness and efficiency in integrating historical and recent user behavior sequences into user embeddings in dynamic user modeling.","sentences":["User embeddings play a crucial role in user engagement forecasting and personalized services.","Recent advances in sequence modeling have sparked interest in learning user embeddings from behavioral data.","Yet behavior-based user embedding learning faces the unique challenge of dynamic user modeling.","As users continuously interact with the apps, user embeddings should be periodically updated to account for users' recent and long-term behavior patterns.","Existing methods highly rely on stateless sequence models that lack memory of historical behavior.","They have to either discard historical data and use only the most recent data or reprocess the old and new data jointly.","Both cases incur substantial computational overhead.","To address this limitation, we introduce User Stateful Embedding (USE).","USE generates user embeddings and reflects users' evolving behaviors without the need for exhaustive reprocessing by storing previous model states and revisiting them in the future.","Furthermore, we introduce a novel training objective named future W-behavior prediction to transcend the limitations of next-token prediction by forecasting a broader horizon of upcoming user behaviors.","By combining it with the Same User Prediction, a contrastive learning-based objective that predicts whether different segments of behavior sequences belong to the same user, we further improve the embeddings' distinctiveness and representativeness.","We conducted experiments on 8 downstream tasks using Snapchat users' behavioral logs in both static (i.e., fixed user behavior sequences) and dynamic (i.e., periodically updated user behavior sequences) settings.","We demonstrate USE's superior performance over established baselines.","The results underscore USE's effectiveness and efficiency in integrating historical and recent user behavior sequences into user embeddings in dynamic user modeling."],"url":"http://arxiv.org/abs/2403.13344v1"}
{"created":"2024-03-20 07:00:03","title":"TiBiX: Leveraging Temporal Information for Bidirectional X-ray and Report Generation","abstract":"With the emergence of vision language models in the medical imaging domain, numerous studies have focused on two dominant research activities: (1) report generation from Chest X-rays (CXR), and (2) synthetic scan generation from text or reports. Despite some research incorporating multi-view CXRs into the generative process, prior patient scans and reports have been generally disregarded. This can inadvertently lead to the leaving out of important medical information, thus affecting generation quality. To address this, we propose TiBiX: Leveraging Temporal information for Bidirectional X-ray and Report Generation. Considering previous scans, our approach facilitates bidirectional generation, primarily addressing two challenging problems: (1) generating the current image from the previous image and current report and (2) generating the current report based on both the previous and current images. Moreover, we extract and release a curated temporal benchmark dataset derived from the MIMIC-CXR dataset, which focuses on temporal data. Our comprehensive experiments and ablation studies explore the merits of incorporating prior CXRs and achieve state-of-the-art (SOTA) results on the report generation task. Furthermore, we attain on-par performance with SOTA image generation efforts, thus serving as a new baseline in longitudinal bidirectional CXR-to-report generation. The code is available at https://github.com/BioMedIA-MBZUAI/TiBiX.","sentences":["With the emergence of vision language models in the medical imaging domain, numerous studies have focused on two dominant research activities: (1) report generation from Chest X-rays (CXR), and (2) synthetic scan generation from text or reports.","Despite some research incorporating multi-view CXRs into the generative process, prior patient scans and reports have been generally disregarded.","This can inadvertently lead to the leaving out of important medical information, thus affecting generation quality.","To address this, we propose TiBiX: Leveraging Temporal information for Bidirectional X-ray and Report Generation.","Considering previous scans, our approach facilitates bidirectional generation, primarily addressing two challenging problems: (1) generating the current image from the previous image and current report and (2) generating the current report based on both the previous and current images.","Moreover, we extract and release a curated temporal benchmark dataset derived from the MIMIC-CXR dataset, which focuses on temporal data.","Our comprehensive experiments and ablation studies explore the merits of incorporating prior CXRs and achieve state-of-the-art (SOTA) results on the report generation task.","Furthermore, we attain on-par performance with SOTA image generation efforts, thus serving as a new baseline in longitudinal bidirectional CXR-to-report generation.","The code is available at https://github.com/BioMedIA-MBZUAI/TiBiX."],"url":"http://arxiv.org/abs/2403.13343v1"}
{"created":"2024-03-20 06:48:48","title":"FissionFusion: Fast Geometric Generation and Hierarchical Souping for Medical Image Analysis","abstract":"The scarcity of well-annotated medical datasets requires leveraging transfer learning from broader datasets like ImageNet or pre-trained models like CLIP. Model soups averages multiple fine-tuned models aiming to improve performance on In-Domain (ID) tasks and enhance robustness against Out-of-Distribution (OOD) datasets. However, applying these methods to the medical imaging domain faces challenges and results in suboptimal performance. This is primarily due to differences in error surface characteristics that stem from data complexities such as heterogeneity, domain shift, class imbalance, and distributional shifts between training and testing phases. To address this issue, we propose a hierarchical merging approach that involves local and global aggregation of models at various levels based on models' hyperparameter configurations. Furthermore, to alleviate the need for training a large number of models in the hyperparameter search, we introduce a computationally efficient method using a cyclical learning rate scheduler to produce multiple models for aggregation in the weight space. Our method demonstrates significant improvements over the model souping approach across multiple datasets (around 6% gain in HAM10000 and CheXpert datasets) while maintaining low computational costs for model generation and selection. Moreover, we achieve better results on OOD datasets than model soups. The code is available at https://github.com/BioMedIA-MBZUAI/FissionFusion.","sentences":["The scarcity of well-annotated medical datasets requires leveraging transfer learning from broader datasets like ImageNet or pre-trained models like CLIP.","Model soups averages multiple fine-tuned models aiming to improve performance on In-Domain (ID) tasks and enhance robustness against Out-of-Distribution (OOD) datasets.","However, applying these methods to the medical imaging domain faces challenges and results in suboptimal performance.","This is primarily due to differences in error surface characteristics that stem from data complexities such as heterogeneity, domain shift, class imbalance, and distributional shifts between training and testing phases.","To address this issue, we propose a hierarchical merging approach that involves local and global aggregation of models at various levels based on models' hyperparameter configurations.","Furthermore, to alleviate the need for training a large number of models in the hyperparameter search, we introduce a computationally efficient method using a cyclical learning rate scheduler to produce multiple models for aggregation in the weight space.","Our method demonstrates significant improvements over the model souping approach across multiple datasets (around 6% gain in HAM10000 and CheXpert datasets) while maintaining low computational costs for model generation and selection.","Moreover, we achieve better results on OOD datasets than model soups.","The code is available at https://github.com/BioMedIA-MBZUAI/FissionFusion."],"url":"http://arxiv.org/abs/2403.13341v1"}
{"created":"2024-03-20 06:46:30","title":"(Non-)retracted academic papers in OpenAlex","abstract":"The proliferation of scholarly publications underscores the necessity for reliable tools to navigate scientific literature. OpenAlex, an emerging platform amalgamating data from diverse academic sources, holds promise in meeting these evolving demands. Nonetheless, our investigation uncovered a flaw in OpenAlex's portrayal of publication status, particularly concerning retractions. Despite accurate metadata sourced from Crossref database, OpenAlex consolidated this information into a single boolean field, \"is_retracted,\" leading to misclassifications of papers. This challenge not only impacts OpenAlex users but also extends to users of other academic resources integrating the OpenAlex API. The issue affects data provided by OpenAlex in the period between 22 Dec 2023 and 19 Mar 2024. Anyone using data from this period should urgently check it and replace it if necessary.","sentences":["The proliferation of scholarly publications underscores the necessity for reliable tools to navigate scientific literature.","OpenAlex, an emerging platform amalgamating data from diverse academic sources, holds promise in meeting these evolving demands.","Nonetheless, our investigation uncovered a flaw in OpenAlex's portrayal of publication status, particularly concerning retractions.","Despite accurate metadata sourced from Crossref database, OpenAlex consolidated this information into a single boolean field, \"is_retracted,\" leading to misclassifications of papers.","This challenge not only impacts OpenAlex users but also extends to users of other academic resources integrating the OpenAlex API.","The issue affects data provided by OpenAlex in the period between 22 Dec 2023 and 19 Mar 2024.","Anyone using data from this period should urgently check it and replace it if necessary."],"url":"http://arxiv.org/abs/2403.13339v1"}
{"created":"2024-03-20 06:38:13","title":"Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection","abstract":"Large language models (LLMs) have reached human-like proficiency in generating diverse textual content, underscoring the necessity for effective fake text detection to avoid potential risks such as fake news in social media. Previous research has mostly tested single models on in-distribution datasets, limiting our understanding of how these models perform on different types of data for LLM-generated text detection task. We researched this by testing five specialized transformer-based models on both in-distribution and out-of-distribution datasets to better assess their performance and generalizability. Our results revealed that single transformer-based classifiers achieved decent performance on in-distribution dataset but limited generalization ability on out-of-distribution dataset. To improve it, we combined the individual classifiers models using adaptive ensemble algorithms, which improved the average accuracy significantly from 91.8% to 99.2% on an in-distribution test set and from 62.9% to 72.5% on an out-of-distribution test set. The results indicate the effectiveness, good generalization ability, and great potential of adaptive ensemble algorithms in LLM-generated text detection.","sentences":["Large language models (LLMs) have reached human-like proficiency in generating diverse textual content, underscoring the necessity for effective fake text detection to avoid potential risks such as fake news in social media.","Previous research has mostly tested single models on in-distribution datasets, limiting our understanding of how these models perform on different types of data for LLM-generated text detection task.","We researched this by testing five specialized transformer-based models on both in-distribution and out-of-distribution datasets to better assess their performance and generalizability.","Our results revealed that single transformer-based classifiers achieved decent performance on in-distribution dataset but limited generalization ability on out-of-distribution dataset.","To improve it, we combined the individual classifiers models using adaptive ensemble algorithms, which improved the average accuracy significantly from 91.8% to 99.2% on an in-distribution test set and from 62.9% to 72.5% on an out-of-distribution test set.","The results indicate the effectiveness, good generalization ability, and great potential of adaptive ensemble algorithms in LLM-generated text detection."],"url":"http://arxiv.org/abs/2403.13335v1"}
{"created":"2024-03-20 06:22:37","title":"AMP: Autoregressive Motion Prediction Revisited with Next Token Prediction for Autonomous Driving","abstract":"As an essential task in autonomous driving (AD), motion prediction aims to predict the future states of surround objects for navigation. One natural solution is to estimate the position of other agents in a step-by-step manner where each predicted time-step is conditioned on both observed time-steps and previously predicted time-steps, i.e., autoregressive prediction. Pioneering works like SocialLSTM and MFP design their decoders based on this intuition. However, almost all state-of-the-art works assume that all predicted time-steps are independent conditioned on observed time-steps, where they use a single linear layer to generate positions of all time-steps simultaneously. They dominate most motion prediction leaderboards due to the simplicity of training MLPs compared to autoregressive networks.   In this paper, we introduce the GPT style next token prediction into motion forecasting. In this way, the input and output could be represented in a unified space and thus the autoregressive prediction becomes more feasible. However, different from language data which is composed of homogeneous units -words, the elements in the driving scene could have complex spatial-temporal and semantic relations. To this end, we propose to adopt three factorized attention modules with different neighbors for information aggregation and different position encoding styles to capture their relations, e.g., encoding the transformation between coordinate systems for spatial relativity while adopting RoPE for temporal relativity. Empirically, by equipping with the aforementioned tailored designs, the proposed method achieves state-of-the-art performance in the Waymo Open Motion and Waymo Interaction datasets. Notably, AMP outperforms other recent autoregressive motion prediction methods: MotionLM and StateTransformer, which demonstrates the effectiveness of the proposed designs.","sentences":["As an essential task in autonomous driving (AD), motion prediction aims to predict the future states of surround objects for navigation.","One natural solution is to estimate the position of other agents in a step-by-step manner where each predicted time-step is conditioned on both observed time-steps and previously predicted time-steps, i.e., autoregressive prediction.","Pioneering works like SocialLSTM and MFP design their decoders based on this intuition.","However, almost all state-of-the-art works assume that all predicted time-steps are independent conditioned on observed time-steps, where they use a single linear layer to generate positions of all time-steps simultaneously.","They dominate most motion prediction leaderboards due to the simplicity of training MLPs compared to autoregressive networks.   ","In this paper, we introduce the GPT style next token prediction into motion forecasting.","In this way, the input and output could be represented in a unified space and thus the autoregressive prediction becomes more feasible.","However, different from language data which is composed of homogeneous units -words, the elements in the driving scene could have complex spatial-temporal and semantic relations.","To this end, we propose to adopt three factorized attention modules with different neighbors for information aggregation and different position encoding styles to capture their relations, e.g., encoding the transformation between coordinate systems for spatial relativity while adopting RoPE for temporal relativity.","Empirically, by equipping with the aforementioned tailored designs, the proposed method achieves state-of-the-art performance in the Waymo Open Motion and Waymo Interaction datasets.","Notably, AMP outperforms other recent autoregressive motion prediction methods: MotionLM and StateTransformer, which demonstrates the effectiveness of the proposed designs."],"url":"http://arxiv.org/abs/2403.13331v1"}
{"created":"2024-03-20 06:19:41","title":"Gaussian Splatting on the Move: Blur and Rolling Shutter Compensation for Natural Camera Motion","abstract":"High-quality scene reconstruction and novel view synthesis based on Gaussian Splatting (3DGS) typically require steady, high-quality photographs, often impractical to capture with handheld cameras. We present a method that adapts to camera motion and allows high-quality scene reconstruction with handheld video data suffering from motion blur and rolling shutter distortion. Our approach is based on detailed modelling of the physical image formation process and utilizes velocities estimated using visual-inertial odometry (VIO). Camera poses are considered non-static during the exposure time of a single image frame and camera poses are further optimized in the reconstruction process. We formulate a differentiable rendering pipeline that leverages screen space approximation to efficiently incorporate rolling-shutter and motion blur effects into the 3DGS framework. Our results with both synthetic and real data demonstrate superior performance in mitigating camera motion over existing methods, thereby advancing 3DGS in naturalistic settings.","sentences":["High-quality scene reconstruction and novel view synthesis based on Gaussian Splatting (3DGS) typically require steady, high-quality photographs, often impractical to capture with handheld cameras.","We present a method that adapts to camera motion and allows high-quality scene reconstruction with handheld video data suffering from motion blur and rolling shutter distortion.","Our approach is based on detailed modelling of the physical image formation process and utilizes velocities estimated using visual-inertial odometry (VIO).","Camera poses are considered non-static during the exposure time of a single image frame and camera poses are further optimized in the reconstruction process.","We formulate a differentiable rendering pipeline that leverages screen space approximation to efficiently incorporate rolling-shutter and motion blur effects into the 3DGS framework.","Our results with both synthetic and real data demonstrate superior performance in mitigating camera motion over existing methods, thereby advancing 3DGS in naturalistic settings."],"url":"http://arxiv.org/abs/2403.13327v1"}
{"created":"2024-03-20 06:00:53","title":"DD-RobustBench: An Adversarial Robustness Benchmark for Dataset Distillation","abstract":"Dataset distillation is an advanced technique aimed at compressing datasets into significantly smaller counterparts, while preserving formidable training performance. Significant efforts have been devoted to promote evaluation accuracy under limited compression ratio while overlooked the robustness of distilled dataset. In this work, we introduce a comprehensive benchmark that, to the best of our knowledge, is the most extensive to date for evaluating the adversarial robustness of distilled datasets in a unified way. Our benchmark significantly expands upon prior efforts by incorporating a wider range of dataset distillation methods, including the latest advancements such as TESLA and SRe2L, a diverse array of adversarial attack methods, and evaluations across a broader and more extensive collection of datasets such as ImageNet-1K. Moreover, we assessed the robustness of these distilled datasets against representative adversarial attack algorithms like PGD and AutoAttack, while exploring their resilience from a frequency perspective. We also discovered that incorporating distilled data into the training batches of the original dataset can yield to improvement of robustness.","sentences":["Dataset distillation is an advanced technique aimed at compressing datasets into significantly smaller counterparts, while preserving formidable training performance.","Significant efforts have been devoted to promote evaluation accuracy under limited compression ratio while overlooked the robustness of distilled dataset.","In this work, we introduce a comprehensive benchmark that, to the best of our knowledge, is the most extensive to date for evaluating the adversarial robustness of distilled datasets in a unified way.","Our benchmark significantly expands upon prior efforts by incorporating a wider range of dataset distillation methods, including the latest advancements such as TESLA and SRe2L, a diverse array of adversarial attack methods, and evaluations across a broader and more extensive collection of datasets such as ImageNet-1K. Moreover, we assessed the robustness of these distilled datasets against representative adversarial attack algorithms like PGD and AutoAttack, while exploring their resilience from a frequency perspective.","We also discovered that incorporating distilled data into the training batches of the original dataset can yield to improvement of robustness."],"url":"http://arxiv.org/abs/2403.13322v1"}
{"created":"2024-03-20 05:57:20","title":"Robotics meets Fluid Dynamics: A Characterization of the Induced Airflow around a Quadrotor","abstract":"The widespread adoption of quadrotors for diverse applications, from agriculture to public safety, necessitates an understanding of the aerodynamic disturbances they create. This paper introduces a computationally lightweight model for estimating the time-averaged magnitude of the induced flow below quadrotors in hover. Unlike related approaches that rely on expensive computational fluid dynamics (CFD) simulations or time-consuming empirical measurements, our method leverages classical theory from turbulent flows. By analyzing over 9 hours of flight data from drones of varying sizes within a large motion capture system, we show that the combined flow from all propellers of the drone is well-approximated by a turbulent jet. Through the use of a novel normalization and scaling, we have developed and experimentally validated a unified model that describes the mean velocity field of the induced flow for different drone sizes. The model accurately describes the far-field airflow in a very large volume below the drone which is difficult to simulate in CFD. Our model, which requires only the drone's mass, propeller size, and drone size for calculations, offers a practical tool for dynamic planning in multi-agent scenarios, ensuring safer operations near humans and optimizing sensor placements.","sentences":["The widespread adoption of quadrotors for diverse applications, from agriculture to public safety, necessitates an understanding of the aerodynamic disturbances they create.","This paper introduces a computationally lightweight model for estimating the time-averaged magnitude of the induced flow below quadrotors in hover.","Unlike related approaches that rely on expensive computational fluid dynamics (CFD) simulations or time-consuming empirical measurements, our method leverages classical theory from turbulent flows.","By analyzing over 9 hours of flight data from drones of varying sizes within a large motion capture system, we show that the combined flow from all propellers of the drone is well-approximated by a turbulent jet.","Through the use of a novel normalization and scaling, we have developed and experimentally validated a unified model that describes the mean velocity field of the induced flow for different drone sizes.","The model accurately describes the far-field airflow in a very large volume below the drone which is difficult to simulate in CFD.","Our model, which requires only the drone's mass, propeller size, and drone size for calculations, offers a practical tool for dynamic planning in multi-agent scenarios, ensuring safer operations near humans and optimizing sensor placements."],"url":"http://arxiv.org/abs/2403.13321v1"}
{"created":"2024-03-20 05:50:04","title":"HyperFusion: A Hypernetwork Approach to Multimodal Integration of Tabular and Medical Imaging Data for Predictive Modeling","abstract":"The integration of diverse clinical modalities such as medical imaging and the tabular data obtained by the patients' Electronic Health Records (EHRs) is a crucial aspect of modern healthcare. The integrative analysis of multiple sources can provide a comprehensive understanding of a patient's condition and can enhance diagnoses and treatment decisions. Deep Neural Networks (DNNs) consistently showcase outstanding performance in a wide range of multimodal tasks in the medical domain. However, the complex endeavor of effectively merging medical imaging with clinical, demographic and genetic information represented as numerical tabular data remains a highly active and ongoing research pursuit.   We present a novel framework based on hypernetworks to fuse clinical imaging and tabular data by conditioning the image processing on the EHR's values and measurements. This approach aims to leverage the complementary information present in these modalities to enhance the accuracy of various medical applications. We demonstrate the strength and the generality of our method on two different brain Magnetic Resonance Imaging (MRI) analysis tasks, namely, brain age prediction conditioned by subject's sex, and multiclass Alzheimer's Disease (AD) classification conditioned by tabular data. We show that our framework outperforms both single-modality models and state-of-the-art MRI-tabular data fusion methods. The code, enclosed to this manuscript will be made publicly available.","sentences":["The integration of diverse clinical modalities such as medical imaging and the tabular data obtained by the patients' Electronic Health Records (EHRs) is a crucial aspect of modern healthcare.","The integrative analysis of multiple sources can provide a comprehensive understanding of a patient's condition and can enhance diagnoses and treatment decisions.","Deep Neural Networks (DNNs) consistently showcase outstanding performance in a wide range of multimodal tasks in the medical domain.","However, the complex endeavor of effectively merging medical imaging with clinical, demographic and genetic information represented as numerical tabular data remains a highly active and ongoing research pursuit.   ","We present a novel framework based on hypernetworks to fuse clinical imaging and tabular data by conditioning the image processing on the EHR's values and measurements.","This approach aims to leverage the complementary information present in these modalities to enhance the accuracy of various medical applications.","We demonstrate the strength and the generality of our method on two different brain Magnetic Resonance Imaging (MRI) analysis tasks, namely, brain age prediction conditioned by subject's sex, and multiclass Alzheimer's Disease (AD) classification conditioned by tabular data.","We show that our framework outperforms both single-modality models and state-of-the-art MRI-tabular data fusion methods.","The code, enclosed to this manuscript will be made publicly available."],"url":"http://arxiv.org/abs/2403.13319v1"}
{"created":"2024-03-20 05:46:56","title":"Workload Estimation for Unknown Tasks: A Survey of Machine Learning Under Distribution Shift","abstract":"Human-robot teams involve humans and robots collaborating to achieve tasks under various environmental conditions. Successful teaming will require robots to adapt autonomously to a human teammate's internal state. An important element of such adaptation is the ability to estimate the human teammates' workload in unknown situations. Existing workload models use machine learning to model the relationships between physiological metrics and workload; however, these methods are susceptible to individual differences and are heavily influenced by other factors. These methods cannot generalize to unknown tasks, as they rely on standard machine learning approaches that assume data consists of independent and identically distributed (IID) samples. This assumption does not necessarily hold for estimating workload for new tasks. A survey of non-IID machine learning techniques is presented, where commonly used techniques are evaluated using three criteria: portability, model complexity, and adaptability. These criteria are used to argue which techniques are most applicable for estimating workload for unknown tasks in dynamic, real-time environments.","sentences":["Human-robot teams involve humans and robots collaborating to achieve tasks under various environmental conditions.","Successful teaming will require robots to adapt autonomously to a human teammate's internal state.","An important element of such adaptation is the ability to estimate the human teammates' workload in unknown situations.","Existing workload models use machine learning to model the relationships between physiological metrics and workload; however, these methods are susceptible to individual differences and are heavily influenced by other factors.","These methods cannot generalize to unknown tasks, as they rely on standard machine learning approaches that assume data consists of independent and identically distributed (IID) samples.","This assumption does not necessarily hold for estimating workload for new tasks.","A survey of non-IID machine learning techniques is presented, where commonly used techniques are evaluated using three criteria: portability, model complexity, and adaptability.","These criteria are used to argue which techniques are most applicable for estimating workload for unknown tasks in dynamic, real-time environments."],"url":"http://arxiv.org/abs/2403.13318v1"}
{"created":"2024-03-20 05:37:24","title":"PuzzleVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Abstract Visual Patterns","abstract":"Large multimodal models extend the impressive capabilities of large language models by integrating multimodal understanding abilities. However, it is not clear how they can emulate the general intelligence and reasoning ability of humans. As recognizing patterns and abstracting concepts are key to general intelligence, we introduce PuzzleVQA, a collection of puzzles based on abstract patterns. With this dataset, we evaluate large multimodal models with abstract patterns based on fundamental concepts, including colors, numbers, sizes, and shapes. Through our experiments on state-of-the-art large multimodal models, we find that they are not able to generalize well to simple abstract patterns. Notably, even GPT-4V cannot solve more than half of the puzzles. To diagnose the reasoning challenges in large multimodal models, we progressively guide the models with our ground truth reasoning explanations for visual perception, inductive reasoning, and deductive reasoning. Our systematic analysis finds that the main bottlenecks of GPT-4V are weaker visual perception and inductive reasoning abilities. Through this work, we hope to shed light on the limitations of large multimodal models and how they can better emulate human cognitive processes in the future (Our data and code will be released publicly at https://github.com/declare-lab/LLM-PuzzleTest).","sentences":["Large multimodal models extend the impressive capabilities of large language models by integrating multimodal understanding abilities.","However, it is not clear how they can emulate the general intelligence and reasoning ability of humans.","As recognizing patterns and abstracting concepts are key to general intelligence, we introduce PuzzleVQA, a collection of puzzles based on abstract patterns.","With this dataset, we evaluate large multimodal models with abstract patterns based on fundamental concepts, including colors, numbers, sizes, and shapes.","Through our experiments on state-of-the-art large multimodal models, we find that they are not able to generalize well to simple abstract patterns.","Notably, even GPT-4V cannot solve more than half of the puzzles.","To diagnose the reasoning challenges in large multimodal models, we progressively guide the models with our ground truth reasoning explanations for visual perception, inductive reasoning, and deductive reasoning.","Our systematic analysis finds that the main bottlenecks of GPT-4V are weaker visual perception and inductive reasoning abilities.","Through this work, we hope to shed light on the limitations of large multimodal models and how they can better emulate human cognitive processes in the future (Our data and code will be released publicly at https://github.com/declare-lab/LLM-PuzzleTest)."],"url":"http://arxiv.org/abs/2403.13315v1"}
{"created":"2024-03-20 05:34:03","title":"Polaris: A Safety-focused LLM Constellation Architecture for Healthcare","abstract":"We develop Polaris, the first safety-focused LLM constellation for real-time patient-AI healthcare conversations. Unlike prior LLM works in healthcare focusing on tasks like question answering, our work specifically focuses on long multi-turn voice conversations. Our one-trillion parameter constellation system is composed of several multibillion parameter LLMs as co-operative agents: a stateful primary agent that focuses on driving an engaging conversation and several specialist support agents focused on healthcare tasks performed by nurses to increase safety and reduce hallucinations. We develop a sophisticated training protocol for iterative co-training of the agents that optimize for diverse objectives. We train our models on proprietary data, clinical care plans, healthcare regulatory documents, medical manuals, and other medical reasoning documents. We align our models to speak like medical professionals, using organic healthcare conversations and simulated ones between patient actors and experienced nurses. This allows our system to express unique capabilities such as rapport building, trust building, empathy and bedside manner. Finally, we present the first comprehensive clinician evaluation of an LLM system for healthcare. We recruited over 1100 U.S. licensed nurses and over 130 U.S. licensed physicians to perform end-to-end conversational evaluations of our system by posing as patients and rating the system on several measures. We demonstrate Polaris performs on par with human nurses on aggregate across dimensions such as medical safety, clinical readiness, conversational quality, and bedside manner. Additionally, we conduct a challenging task-based evaluation of the individual specialist support agents, where we demonstrate our LLM agents significantly outperform a much larger general-purpose LLM (GPT-4) as well as from its own medium-size class (LLaMA-2 70B).","sentences":["We develop Polaris, the first safety-focused LLM constellation for real-time patient-AI healthcare conversations.","Unlike prior LLM works in healthcare focusing on tasks like question answering, our work specifically focuses on long multi-turn voice conversations.","Our one-trillion parameter constellation system is composed of several multibillion parameter LLMs as co-operative agents: a stateful primary agent that focuses on driving an engaging conversation and several specialist support agents focused on healthcare tasks performed by nurses to increase safety and reduce hallucinations.","We develop a sophisticated training protocol for iterative co-training of the agents that optimize for diverse objectives.","We train our models on proprietary data, clinical care plans, healthcare regulatory documents, medical manuals, and other medical reasoning documents.","We align our models to speak like medical professionals, using organic healthcare conversations and simulated ones between patient actors and experienced nurses.","This allows our system to express unique capabilities such as rapport building, trust building, empathy and bedside manner.","Finally, we present the first comprehensive clinician evaluation of an LLM system for healthcare.","We recruited over 1100 U.S. licensed nurses and over 130 U.S. licensed physicians to perform end-to-end conversational evaluations of our system by posing as patients and rating the system on several measures.","We demonstrate Polaris performs on par with human nurses on aggregate across dimensions such as medical safety, clinical readiness, conversational quality, and bedside manner.","Additionally, we conduct a challenging task-based evaluation of the individual specialist support agents, where we demonstrate our LLM agents significantly outperform a much larger general-purpose LLM (GPT-4) as well as from its own medium-size class (LLaMA-2 70B)."],"url":"http://arxiv.org/abs/2403.13313v1"}
{"created":"2024-03-20 05:11:10","title":"LaserHuman: Language-guided Scene-aware Human Motion Generation in Free Environment","abstract":"Language-guided scene-aware human motion generation has great significance for entertainment and robotics. In response to the limitations of existing datasets, we introduce LaserHuman, a pioneering dataset engineered to revolutionize Scene-Text-to-Motion research. LaserHuman stands out with its inclusion of genuine human motions within 3D environments, unbounded free-form natural language descriptions, a blend of indoor and outdoor scenarios, and dynamic, ever-changing scenes. Diverse modalities of capture data and rich annotations present great opportunities for the research of conditional motion generation, and can also facilitate the development of real-life applications. Moreover, to generate semantically consistent and physically plausible human motions, we propose a multi-conditional diffusion model, which is simple but effective, achieving state-of-the-art performance on existing datasets.","sentences":["Language-guided scene-aware human motion generation has great significance for entertainment and robotics.","In response to the limitations of existing datasets, we introduce LaserHuman, a pioneering dataset engineered to revolutionize Scene-Text-to-Motion research.","LaserHuman stands out with its inclusion of genuine human motions within 3D environments, unbounded free-form natural language descriptions, a blend of indoor and outdoor scenarios, and dynamic, ever-changing scenes.","Diverse modalities of capture data and rich annotations present great opportunities for the research of conditional motion generation, and can also facilitate the development of real-life applications.","Moreover, to generate semantically consistent and physically plausible human motions, we propose a multi-conditional diffusion model, which is simple but effective, achieving state-of-the-art performance on existing datasets."],"url":"http://arxiv.org/abs/2403.13307v1"}
{"created":"2024-03-20 04:58:03","title":"DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception","abstract":"Current perceptive models heavily depend on resource-intensive datasets, prompting the need for innovative solutions. Leveraging recent advances in diffusion models, synthetic data, by constructing image inputs from various annotations, proves beneficial for downstream tasks. While prior methods have separately addressed generative and perceptive models, DetDiffusion, for the first time, harmonizes both, tackling the challenges in generating effective data for perceptive models. To enhance image generation with perceptive models, we introduce perception-aware loss (P.A. loss) through segmentation, improving both quality and controllability. To boost the performance of specific perceptive models, our method customizes data augmentation by extracting and utilizing perception-aware attribute (P.A. Attr) during generation. Experimental results from the object detection task highlight DetDiffusion's superior performance, establishing a new state-of-the-art in layout-guided generation. Furthermore, image syntheses from DetDiffusion can effectively augment training data, significantly enhancing downstream detection performance.","sentences":["Current perceptive models heavily depend on resource-intensive datasets, prompting the need for innovative solutions.","Leveraging recent advances in diffusion models, synthetic data, by constructing image inputs from various annotations, proves beneficial for downstream tasks.","While prior methods have separately addressed generative and perceptive models, DetDiffusion, for the first time, harmonizes both, tackling the challenges in generating effective data for perceptive models.","To enhance image generation with perceptive models, we introduce perception-aware loss (P.A. loss) through segmentation, improving both quality and controllability.","To boost the performance of specific perceptive models, our method customizes data augmentation by extracting and utilizing perception-aware attribute (P.A. Attr) during generation.","Experimental results from the object detection task highlight DetDiffusion's superior performance, establishing a new state-of-the-art in layout-guided generation.","Furthermore, image syntheses from DetDiffusion can effectively augment training data, significantly enhancing downstream detection performance."],"url":"http://arxiv.org/abs/2403.13304v1"}
{"created":"2024-03-20 04:47:13","title":"Rotary Position Embedding for Vision Transformer","abstract":"Rotary Position Embedding (RoPE) performs remarkably on language models, especially for length extrapolation of Transformers. However, the impacts of RoPE on computer vision domains have been underexplored, even though RoPE appears capable of enhancing Vision Transformer (ViT) performance in a way similar to the language domain. This study provides a comprehensive analysis of RoPE when applied to ViTs, utilizing practical implementations of RoPE for 2D vision data. The analysis reveals that RoPE demonstrates impressive extrapolation performance, i.e., maintaining precision while increasing image resolution at inference. It eventually leads to performance improvement for ImageNet-1k, COCO detection, and ADE-20k segmentation. We believe this study provides thorough guidelines to apply RoPE into ViT, promising improved backbone performance with minimal extra computational overhead. Our code and pre-trained models are available at https://github.com/naver-ai/rope-vit","sentences":["Rotary Position Embedding (RoPE) performs remarkably on language models, especially for length extrapolation of Transformers.","However, the impacts of RoPE on computer vision domains have been underexplored, even though RoPE appears capable of enhancing Vision Transformer (ViT) performance in a way similar to the language domain.","This study provides a comprehensive analysis of RoPE when applied to ViTs, utilizing practical implementations of RoPE for 2D vision data.","The analysis reveals that RoPE demonstrates impressive extrapolation performance, i.e., maintaining precision while increasing image resolution at inference.","It eventually leads to performance improvement for ImageNet-1k, COCO detection, and ADE-20k segmentation.","We believe this study provides thorough guidelines to apply RoPE into ViT, promising improved backbone performance with minimal extra computational overhead.","Our code and pre-trained models are available at https://github.com/naver-ai/rope-vit"],"url":"http://arxiv.org/abs/2403.13298v1"}
{"created":"2024-03-20 04:03:44","title":"Text-to-3D Shape Generation","abstract":"Recent years have seen an explosion of work and interest in text-to-3D shape generation. Much of the progress is driven by advances in 3D representations, large-scale pretraining and representation learning for text and image data enabling generative AI models, and differentiable rendering. Computational systems that can perform text-to-3D shape generation have captivated the popular imagination as they enable non-expert users to easily create 3D content directly from text. However, there are still many limitations and challenges remaining in this problem space. In this state-of-the-art report, we provide a survey of the underlying technology and methods enabling text-to-3D shape generation to summarize the background literature. We then derive a systematic categorization of recent work on text-to-3D shape generation based on the type of supervision data required. Finally, we discuss limitations of the existing categories of methods, and delineate promising directions for future work.","sentences":["Recent years have seen an explosion of work and interest in text-to-3D shape generation.","Much of the progress is driven by advances in 3D representations, large-scale pretraining and representation learning for text and image data enabling generative AI models, and differentiable rendering.","Computational systems that can perform text-to-3D shape generation have captivated the popular imagination as they enable non-expert users to easily create 3D content directly from text.","However, there are still many limitations and challenges remaining in this problem space.","In this state-of-the-art report, we provide a survey of the underlying technology and methods enabling text-to-3D shape generation to summarize the background literature.","We then derive a systematic categorization of recent work on text-to-3D shape generation based on the type of supervision data required.","Finally, we discuss limitations of the existing categories of methods, and delineate promising directions for future work."],"url":"http://arxiv.org/abs/2403.13289v1"}
{"created":"2024-03-20 03:59:10","title":"Regent based parallel meshfree LSKUM solver for heterogenous HPC platforms","abstract":"Regent is an implicitly parallel programming language that allows the development of a single codebase for heterogeneous platforms targeting CPUs and GPUs. This paper presents the development of a parallel meshfree solver in Regent for two-dimensional inviscid compressible flows. The meshfree solver is based on the least squares kinetic upwind method. Example codes are presented to show the difference between the Regent and CUDA-C implementations of the meshfree solver on a GPU node. For CPU parallel computations, details are presented on how the data communication and synchronisation are handled by Regent and Fortran+MPI codes. The Regent solver is verified by applying it to the standard test cases for inviscid flows. Benchmark simulations are performed on coarse to very fine point distributions to assess the solver's performance. The computational efficiency of the Regent solver on an A100 GPU is compared with an equivalent meshfree solver written in CUDA-C. The codes are then profiled to investigate the differences in their performance. The performance of the Regent solver on CPU cores is compared with an equivalent explicitly parallel Fortran meshfree solver based on MPI. Scalability results are shown to offer insights into performance.","sentences":["Regent is an implicitly parallel programming language that allows the development of a single codebase for heterogeneous platforms targeting CPUs and GPUs.","This paper presents the development of a parallel meshfree solver in Regent for two-dimensional inviscid compressible flows.","The meshfree solver is based on the least squares kinetic upwind method.","Example codes are presented to show the difference between the Regent and CUDA-C implementations of the meshfree solver on a GPU node.","For CPU parallel computations, details are presented on how the data communication and synchronisation are handled by Regent and Fortran+MPI codes.","The Regent solver is verified by applying it to the standard test cases for inviscid flows.","Benchmark simulations are performed on coarse to very fine point distributions to assess the solver's performance.","The computational efficiency of the Regent solver on an A100 GPU is compared with an equivalent meshfree solver written in CUDA-C.","The codes are then profiled to investigate the differences in their performance.","The performance of the Regent solver on CPU cores is compared with an equivalent explicitly parallel Fortran meshfree solver based on MPI.","Scalability results are shown to offer insights into performance."],"url":"http://arxiv.org/abs/2403.13287v1"}
{"created":"2024-03-20 03:19:51","title":"Analysing Guarantees in Australian Senate Outcomes","abstract":"Single Transferable Vote (STV) is used to elect candidates to the 76 seat Australian Senate across six states and two territories. These eight STV contests are counted using a combination of ballot scanners, manual data entry and tabulation software. On election night, some properties of the set of cast ballots are determined by hand. This includes the first preference tallies of each party. This technical report considers whether there are some properties, such as individual candidates' first preference tallies, that, if assumed to be accurate, imply a portion of the election outcome. The paper also presents an interesting example showing that the rules of STV tabulation used for the Australian Senate can allow bizarre behaviour, such as votes increasing in value over time.","sentences":["Single Transferable Vote (STV) is used to elect candidates to the 76 seat Australian Senate across six states and two territories.","These eight STV contests are counted using a combination of ballot scanners, manual data entry and tabulation software.","On election night, some properties of the set of cast ballots are determined by hand.","This includes the first preference tallies of each party.","This technical report considers whether there are some properties, such as individual candidates' first preference tallies, that, if assumed to be accurate, imply a portion of the election outcome.","The paper also presents an interesting example showing that the rules of STV tabulation used for the Australian Senate can allow bizarre behaviour, such as votes increasing in value over time."],"url":"http://arxiv.org/abs/2403.13275v1"}
{"created":"2024-03-20 03:14:54","title":"Community Needs and Assets: A Computational Analysis of Community Conversations","abstract":"A community needs assessment is a tool used by non-profits and government agencies to quantify the strengths and issues of a community, allowing them to allocate their resources better. Such approaches are transitioning towards leveraging social media conversations to analyze the needs of communities and the assets already present within them. However, manual analysis of exponentially increasing social media conversations is challenging. There is a gap in the present literature in computationally analyzing how community members discuss the strengths and needs of the community. To address this gap, we introduce the task of identifying, extracting, and categorizing community needs and assets from conversational data using sophisticated natural language processing methods. To facilitate this task, we introduce the first dataset about community needs and assets consisting of 3,511 conversations from Reddit, annotated using crowdsourced workers. Using this dataset, we evaluate an utterance-level classification model compared to sentiment classification and a popular large language model (in a zero-shot setting), where we find that our model outperforms both baselines at an F1 score of 94% compared to 49% and 61% respectively. Furthermore, we observe through our study that conversations about needs have negative sentiments and emotions, while conversations about assets focus on location and entities. The dataset is available at https://github.com/towhidabsar/CommunityNeeds.","sentences":["A community needs assessment is a tool used by non-profits and government agencies to quantify the strengths and issues of a community, allowing them to allocate their resources better.","Such approaches are transitioning towards leveraging social media conversations to analyze the needs of communities and the assets already present within them.","However, manual analysis of exponentially increasing social media conversations is challenging.","There is a gap in the present literature in computationally analyzing how community members discuss the strengths and needs of the community.","To address this gap, we introduce the task of identifying, extracting, and categorizing community needs and assets from conversational data using sophisticated natural language processing methods.","To facilitate this task, we introduce the first dataset about community needs and assets consisting of 3,511 conversations from Reddit, annotated using crowdsourced workers.","Using this dataset, we evaluate an utterance-level classification model compared to sentiment classification and a popular large language model (in a zero-shot setting), where we find that our model outperforms both baselines at an F1 score of 94% compared to 49% and 61% respectively.","Furthermore, we observe through our study that conversations about needs have negative sentiments and emotions, while conversations about assets focus on location and entities.","The dataset is available at https://github.com/towhidabsar/CommunityNeeds."],"url":"http://arxiv.org/abs/2403.13272v1"}
{"created":"2024-03-20 03:09:54","title":"Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning Ability of LLMs","abstract":"Large Language Models (LLMs) have recently made significant advances in code generation through the 'Chain-of-Thought' prompting technique. This technique empowers the model to autonomously devise \"solution plans\" to tackle intricate programming challenges, thereby improving its performance in code generation. Nevertheless, smaller models have been struggling to keep up with LLMs in deducing these plans, adversely affecting their code generation capabilities. Given the considerable size and associated deployment costs, along with concerns about data security, many teams opt for deploying smaller models for code generation. Consequently, there arises a compelling need for transferring LLMs' code generation reasoning abilities to the smaller models. In this paper, we propose the CodePLAN framework, which aims to transfer LLMs' reasoning capabilities to smaller models through distillation. We adopt a multi-task learning approach, jointly undertaking code generation and solution plan generation tasks, to enhance the code generation capabilities of the smaller model. To ensure the superior quality of the solution plans, we advocate for the utilization of backward reasoning and plan sampling strategies. Our experiments show that in comparison to the conventional fine-tuning approach, our approach improves the smaller model's code generation performance (measured in pass@1 metric) by over 130% on the challenging APPS benchmark.","sentences":["Large Language Models (LLMs) have recently made significant advances in code generation through the 'Chain-of-Thought' prompting technique.","This technique empowers the model to autonomously devise \"solution plans\" to tackle intricate programming challenges, thereby improving its performance in code generation.","Nevertheless, smaller models have been struggling to keep up with LLMs in deducing these plans, adversely affecting their code generation capabilities.","Given the considerable size and associated deployment costs, along with concerns about data security, many teams opt for deploying smaller models for code generation.","Consequently, there arises a compelling need for transferring LLMs' code generation reasoning abilities to the smaller models.","In this paper, we propose the CodePLAN framework, which aims to transfer LLMs' reasoning capabilities to smaller models through distillation.","We adopt a multi-task learning approach, jointly undertaking code generation and solution plan generation tasks, to enhance the code generation capabilities of the smaller model.","To ensure the superior quality of the solution plans, we advocate for the utilization of backward reasoning and plan sampling strategies.","Our experiments show that in comparison to the conventional fine-tuning approach, our approach improves the smaller model's code generation performance (measured in pass@1 metric) by over 130% on the challenging APPS benchmark."],"url":"http://arxiv.org/abs/2403.13271v1"}
{"created":"2024-03-20 03:00:21","title":"SC-Tune: Unleashing Self-Consistent Referential Comprehension in Large Vision Language Models","abstract":"Recent trends in Large Vision Language Models (LVLMs) research have been increasingly focusing on advancing beyond general image understanding towards more nuanced, object-level referential comprehension. In this paper, we present and delve into the self-consistency capability of LVLMs, a crucial aspect that reflects the models' ability to both generate informative captions for specific objects and subsequently utilize these captions to accurately re-identify the objects in a closed-loop process. This capability significantly mirrors the precision and reliability of fine-grained visual-language understanding. Our findings reveal that the self-consistency level of existing LVLMs falls short of expectations, posing limitations on their practical applicability and potential. To address this gap, we introduce a novel fine-tuning paradigm named Self-Consistency Tuning (SC-Tune). It features the synergistic learning of a cyclic describer-locator system. This paradigm is not only data-efficient but also exhibits generalizability across multiple LVLMs. Through extensive experiments, we demonstrate that SC-Tune significantly elevates performance across a spectrum of object-level vision-language benchmarks and maintains competitive or improved performance on image-level vision-language benchmarks. Both our model and code will be publicly available at https://github.com/ivattyue/SC-Tune.","sentences":["Recent trends in Large Vision Language Models (LVLMs) research have been increasingly focusing on advancing beyond general image understanding towards more nuanced, object-level referential comprehension.","In this paper, we present and delve into the self-consistency capability of LVLMs, a crucial aspect that reflects the models' ability to both generate informative captions for specific objects and subsequently utilize these captions to accurately re-identify the objects in a closed-loop process.","This capability significantly mirrors the precision and reliability of fine-grained visual-language understanding.","Our findings reveal that the self-consistency level of existing LVLMs falls short of expectations, posing limitations on their practical applicability and potential.","To address this gap, we introduce a novel fine-tuning paradigm named Self-Consistency Tuning (SC-Tune).","It features the synergistic learning of a cyclic describer-locator system.","This paradigm is not only data-efficient but also exhibits generalizability across multiple LVLMs.","Through extensive experiments, we demonstrate that SC-Tune significantly elevates performance across a spectrum of object-level vision-language benchmarks and maintains competitive or improved performance on image-level vision-language benchmarks.","Both our model and code will be publicly available at https://github.com/ivattyue/SC-Tune."],"url":"http://arxiv.org/abs/2403.13263v1"}
{"created":"2024-03-20 02:58:45","title":"Self-Supervised Class-Agnostic Motion Prediction with Spatial and Temporal Consistency Regularizations","abstract":"The perception of motion behavior in a dynamic environment holds significant importance for autonomous driving systems, wherein class-agnostic motion prediction methods directly predict the motion of the entire point cloud. While most existing methods rely on fully-supervised learning, the manual labeling of point cloud data is laborious and time-consuming. Therefore, several annotation-efficient methods have been proposed to address this challenge. Although effective, these methods rely on weak annotations or additional multi-modal data like images, and the potential benefits inherent in the point cloud sequence are still underexplored. To this end, we explore the feasibility of self-supervised motion prediction with only unlabeled LiDAR point clouds. Initially, we employ an optimal transport solver to establish coarse correspondences between current and future point clouds as the coarse pseudo motion labels. Training models directly using such coarse labels leads to noticeable spatial and temporal prediction inconsistencies. To mitigate these issues, we introduce three simple spatial and temporal regularization losses, which facilitate the self-supervised training process effectively. Experimental results demonstrate the significant superiority of our approach over the state-of-the-art self-supervised methods.","sentences":["The perception of motion behavior in a dynamic environment holds significant importance for autonomous driving systems, wherein class-agnostic motion prediction methods directly predict the motion of the entire point cloud.","While most existing methods rely on fully-supervised learning, the manual labeling of point cloud data is laborious and time-consuming.","Therefore, several annotation-efficient methods have been proposed to address this challenge.","Although effective, these methods rely on weak annotations or additional multi-modal data like images, and the potential benefits inherent in the point cloud sequence are still underexplored.","To this end, we explore the feasibility of self-supervised motion prediction with only unlabeled LiDAR point clouds.","Initially, we employ an optimal transport solver to establish coarse correspondences between current and future point clouds as the coarse pseudo motion labels.","Training models directly using such coarse labels leads to noticeable spatial and temporal prediction inconsistencies.","To mitigate these issues, we introduce three simple spatial and temporal regularization losses, which facilitate the self-supervised training process effectively.","Experimental results demonstrate the significant superiority of our approach over the state-of-the-art self-supervised methods."],"url":"http://arxiv.org/abs/2403.13261v1"}
{"created":"2024-03-20 02:39:15","title":"SAMCT: Segment Any CT Allowing Labor-Free Task-Indicator Prompts","abstract":"Segment anything model (SAM), a foundation model with superior versatility and generalization across diverse segmentation tasks, has attracted widespread attention in medical imaging. However, it has been proved that SAM would encounter severe performance degradation due to the lack of medical knowledge in training and local feature encoding. Though several SAM-based models have been proposed for tuning SAM in medical imaging, they still suffer from insufficient feature extraction and highly rely on high-quality prompts. In this paper, we construct a large CT dataset consisting of 1.1M CT images and 5M masks from public datasets and propose a powerful foundation model SAMCT allowing labor-free prompts. Specifically, based on SAM, SAMCT is further equipped with a U-shaped CNN image encoder, a cross-branch interaction module, and a task-indicator prompt encoder. The U-shaped CNN image encoder works in parallel with the ViT image encoder in SAM to supplement local features. Cross-branch interaction enhances the feature expression capability of the CNN image encoder and the ViT image encoder by exchanging global perception and local features from one to the other. The task-indicator prompt encoder is a plug-and-play component to effortlessly encode task-related indicators into prompt embeddings. In this way, SAMCT can work in an automatic manner in addition to the semi-automatic interactive strategy in SAM. Extensive experiments demonstrate the superiority of SAMCT against the state-of-the-art task-specific and SAM-based medical foundation models on various tasks. The code, data, and models are released at https://github.com/xianlin7/SAMCT.","sentences":["Segment anything model (SAM), a foundation model with superior versatility and generalization across diverse segmentation tasks, has attracted widespread attention in medical imaging.","However, it has been proved that SAM would encounter severe performance degradation due to the lack of medical knowledge in training and local feature encoding.","Though several SAM-based models have been proposed for tuning SAM in medical imaging, they still suffer from insufficient feature extraction and highly rely on high-quality prompts.","In this paper, we construct a large CT dataset consisting of 1.1M CT images and 5M masks from public datasets and propose a powerful foundation model SAMCT allowing labor-free prompts.","Specifically, based on SAM, SAMCT is further equipped with a U-shaped CNN image encoder, a cross-branch interaction module, and a task-indicator prompt encoder.","The U-shaped CNN image encoder works in parallel with the ViT image encoder in SAM to supplement local features.","Cross-branch interaction enhances the feature expression capability of the CNN image encoder and the ViT image encoder by exchanging global perception and local features from one to the other.","The task-indicator prompt encoder is a plug-and-play component to effortlessly encode task-related indicators into prompt embeddings.","In this way, SAMCT can work in an automatic manner in addition to the semi-automatic interactive strategy in SAM.","Extensive experiments demonstrate the superiority of SAMCT against the state-of-the-art task-specific and SAM-based medical foundation models on various tasks.","The code, data, and models are released at https://github.com/xianlin7/SAMCT."],"url":"http://arxiv.org/abs/2403.13258v1"}
{"created":"2024-03-20 02:29:09","title":"Facilitating Pornographic Text Detection for Open-Domain Dialogue Systems via Knowledge Distillation of Large Language Models","abstract":"Pornographic content occurring in human-machine interaction dialogues can cause severe side effects for users in open-domain dialogue systems. However, research on detecting pornographic language within human-machine interaction dialogues is an important subject that is rarely studied. To advance in this direction, we introduce CensorChat, a dialogue monitoring dataset aimed at detecting whether the dialogue session contains pornographic content. To this end, we collect real-life human-machine interaction dialogues in the wild and break them down into single utterances and single-turn dialogues, with the last utterance spoken by the chatbot. We propose utilizing knowledge distillation of large language models to annotate the dataset. Specifically, first, the raw dataset is annotated by four open-source large language models, with the majority vote determining the label. Second, we use ChatGPT to update the empty label from the first step. Third, to ensure the quality of the validation and test sets, we utilize GPT-4 for label calibration. If the current label does not match the one generated by GPT-4, we employ a self-criticism strategy to verify its correctness. Finally, to facilitate the detection of pornographic text, we develop a series of text classifiers using a pseudo-labeled dataset. Detailed data analysis demonstrates that leveraging knowledge distillation techniques with large language models provides a practical and cost-efficient method for developing pornographic text detectors.","sentences":["Pornographic content occurring in human-machine interaction dialogues can cause severe side effects for users in open-domain dialogue systems.","However, research on detecting pornographic language within human-machine interaction dialogues is an important subject that is rarely studied.","To advance in this direction, we introduce CensorChat, a dialogue monitoring dataset aimed at detecting whether the dialogue session contains pornographic content.","To this end, we collect real-life human-machine interaction dialogues in the wild and break them down into single utterances and single-turn dialogues, with the last utterance spoken by the chatbot.","We propose utilizing knowledge distillation of large language models to annotate the dataset.","Specifically, first, the raw dataset is annotated by four open-source large language models, with the majority vote determining the label.","Second, we use ChatGPT to update the empty label from the first step.","Third, to ensure the quality of the validation and test sets, we utilize GPT-4 for label calibration.","If the current label does not match the one generated by GPT-4, we employ a self-criticism strategy to verify its correctness.","Finally, to facilitate the detection of pornographic text, we develop a series of text classifiers using a pseudo-labeled dataset.","Detailed data analysis demonstrates that leveraging knowledge distillation techniques with large language models provides a practical and cost-efficient method for developing pornographic text detectors."],"url":"http://arxiv.org/abs/2403.13250v1"}
{"created":"2024-03-20 02:21:44","title":"A Unified and General Framework for Continual Learning","abstract":"Continual Learning (CL) focuses on learning from dynamic and changing data distributions while retaining previously acquired knowledge. Various methods have been developed to address the challenge of catastrophic forgetting, including regularization-based, Bayesian-based, and memory-replay-based techniques. However, these methods lack a unified framework and common terminology for describing their approaches. This research aims to bridge this gap by introducing a comprehensive and overarching framework that encompasses and reconciles these existing methodologies. Notably, this new framework is capable of encompassing established CL approaches as special instances within a unified and general optimization objective. An intriguing finding is that despite their diverse origins, these methods share common mathematical structures. This observation highlights the compatibility of these seemingly distinct techniques, revealing their interconnectedness through a shared underlying optimization objective. Moreover, the proposed general framework introduces an innovative concept called refresh learning, specifically designed to enhance the CL performance. This novel approach draws inspiration from neuroscience, where the human brain often sheds outdated information to improve the retention of crucial knowledge and facilitate the acquisition of new information. In essence, refresh learning operates by initially unlearning current data and subsequently relearning it. It serves as a versatile plug-in that seamlessly integrates with existing CL methods, offering an adaptable and effective enhancement to the learning process. Extensive experiments on CL benchmarks and theoretical analysis demonstrate the effectiveness of the proposed refresh learning. Code is available at \\url{https://github.com/joey-wang123/CL-refresh-learning}.","sentences":["Continual Learning (CL) focuses on learning from dynamic and changing data distributions while retaining previously acquired knowledge.","Various methods have been developed to address the challenge of catastrophic forgetting, including regularization-based, Bayesian-based, and memory-replay-based techniques.","However, these methods lack a unified framework and common terminology for describing their approaches.","This research aims to bridge this gap by introducing a comprehensive and overarching framework that encompasses and reconciles these existing methodologies.","Notably, this new framework is capable of encompassing established CL approaches as special instances within a unified and general optimization objective.","An intriguing finding is that despite their diverse origins, these methods share common mathematical structures.","This observation highlights the compatibility of these seemingly distinct techniques, revealing their interconnectedness through a shared underlying optimization objective.","Moreover, the proposed general framework introduces an innovative concept called refresh learning, specifically designed to enhance the CL performance.","This novel approach draws inspiration from neuroscience, where the human brain often sheds outdated information to improve the retention of crucial knowledge and facilitate the acquisition of new information.","In essence, refresh learning operates by initially unlearning current data and subsequently relearning it.","It serves as a versatile plug-in that seamlessly integrates with existing CL methods, offering an adaptable and effective enhancement to the learning process.","Extensive experiments on CL benchmarks and theoretical analysis demonstrate the effectiveness of the proposed refresh learning.","Code is available at \\url{https://github.com/joey-wang123/CL-refresh-learning}."],"url":"http://arxiv.org/abs/2403.13249v1"}
{"created":"2024-03-20 02:17:47","title":"Decentralized Federated Learning: Model Update Tracking Under Imperfect Information Sharing","abstract":"A novel Decentralized Noisy Model Update Tracking Federated Learning algorithm (FedNMUT) is proposed, which is tailored to function efficiently in the presence of noisy communication channels that reflect imperfect information exchange. This algorithm uses gradient tracking to minimize the impact of data heterogeneity while minimizing communication overhead. The proposed algorithm incorporates noise into its parameters to mimic the conditions of noisy communication channels, thereby enabling consensus among clients through a communication graph topology in such challenging environments. FedNMUT prioritizes parameter sharing and noise incorporation to increase the resilience of decentralized learning systems against noisy communications. Through theoretical and empirical validation, it is demonstrated that the performance of FedNMUT is superior compared to the existing state-of-the-art methods and conventional parameter-mixing approaches in dealing with imperfect information sharing. This proves the capability of the proposed algorithm to counteract the negative effects of communication noise in a decentralized learning framework.","sentences":["A novel Decentralized Noisy Model Update Tracking Federated Learning algorithm (FedNMUT) is proposed, which is tailored to function efficiently in the presence of noisy communication channels that reflect imperfect information exchange.","This algorithm uses gradient tracking to minimize the impact of data heterogeneity while minimizing communication overhead.","The proposed algorithm incorporates noise into its parameters to mimic the conditions of noisy communication channels, thereby enabling consensus among clients through a communication graph topology in such challenging environments.","FedNMUT prioritizes parameter sharing and noise incorporation to increase the resilience of decentralized learning systems against noisy communications.","Through theoretical and empirical validation, it is demonstrated that the performance of FedNMUT is superior compared to the existing state-of-the-art methods and conventional parameter-mixing approaches in dealing with imperfect information sharing.","This proves the capability of the proposed algorithm to counteract the negative effects of communication noise in a decentralized learning framework."],"url":"http://arxiv.org/abs/2403.13247v1"}
{"created":"2024-03-20 02:17:16","title":"Divide-Conquer Transformer Learning for Predicting Electric Vehicle Charging Events Using Smart Meter Data","abstract":"Predicting electric vehicle (EV) charging events is crucial for load scheduling and energy management, promoting seamless transportation electrification and decarbonization. While prior studies have focused on EV charging demand prediction, primarily for public charging stations using historical charging data, home charging prediction is equally essential. However, existing prediction methods may not be suitable due to the unavailability of or limited access to home charging data. To address this research gap, inspired by the concept of non-intrusive load monitoring (NILM), we develop a home charging prediction method using historical smart meter data. Different from NILM detecting EV charging that has already occurred, our method provides predictive information of future EV charging occurrences, thus enhancing its utility for charging management. Specifically, our method, leverages a self-attention mechanism-based transformer model, employing a ``divide-conquer'' strategy, to process historical meter data to effectively and learn EV charging representation for charging occurrence prediction. Our method enables prediction at one-minute interval hour-ahead. Experimental results demonstrate the effectiveness of our method, achieving consistently high accuracy of over 96.81\\% across different prediction time spans. Notably, our method achieves high prediction performance solely using smart meter data, making it a practical and suitable solution for grid operators.","sentences":["Predicting electric vehicle (EV) charging events is crucial for load scheduling and energy management, promoting seamless transportation electrification and decarbonization.","While prior studies have focused on EV charging demand prediction, primarily for public charging stations using historical charging data, home charging prediction is equally essential.","However, existing prediction methods may not be suitable due to the unavailability of or limited access to home charging data.","To address this research gap, inspired by the concept of non-intrusive load monitoring (NILM), we develop a home charging prediction method using historical smart meter data.","Different from NILM detecting EV charging that has already occurred, our method provides predictive information of future EV charging occurrences, thus enhancing its utility for charging management.","Specifically, our method, leverages a self-attention mechanism-based transformer model, employing a ``divide-conquer'' strategy, to process historical meter data to effectively and learn EV charging representation for charging occurrence prediction.","Our method enables prediction at one-minute interval hour-ahead.","Experimental results demonstrate the effectiveness of our method, achieving consistently high accuracy of over 96.81\\% across different prediction time spans.","Notably, our method achieves high prediction performance solely using smart meter data, making it a practical and suitable solution for grid operators."],"url":"http://arxiv.org/abs/2403.13246v1"}
{"created":"2024-03-20 02:15:55","title":"Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model","abstract":"While various models and computational tools have been proposed for structure and property analysis of molecules, generating molecules that conform to all desired structures and properties remains a challenge. Here, we introduce a multi-constraint molecular generation large language model, TSMMG, which, akin to a student, incorporates knowledge from various small models and tools, namely, the 'teachers'. To train TSMMG, we construct a large set of text-molecule pairs by extracting molecular knowledge from these 'teachers', enabling it to generate novel molecules that conform to the descriptions through various text prompts. We experimentally show that TSMMG remarkably performs in generating molecules meeting complex, natural language-described property requirements across two-, three-, and four-constraint tasks, with an average molecular validity of over 99% and success ratio of 88.08%, 65.27%, and 61.44%, respectively. The model also exhibits adaptability through zero-shot testing, creating molecules that satisfy combinations of properties that have not been encountered. It can comprehend text inputs with various language styles, extending beyond the confines of outlined prompts, as confirmed through empirical validation. Additionally, the knowledge distillation feature of TSMMG contributes to the continuous enhancement of small models, while the innovative approach to dataset construction effectively addresses the issues of data scarcity and quality, which positions TSMMG as a promising tool in the domains of drug discovery and materials science. Code is available at https://github.com/HHW-zhou/TSMMG.","sentences":["While various models and computational tools have been proposed for structure and property analysis of molecules, generating molecules that conform to all desired structures and properties remains a challenge.","Here, we introduce a multi-constraint molecular generation large language model, TSMMG, which, akin to a student, incorporates knowledge from various small models and tools, namely, the 'teachers'.","To train TSMMG, we construct a large set of text-molecule pairs by extracting molecular knowledge from these 'teachers', enabling it to generate novel molecules that conform to the descriptions through various text prompts.","We experimentally show that TSMMG remarkably performs in generating molecules meeting complex, natural language-described property requirements across two-, three-, and four-constraint tasks, with an average molecular validity of over 99% and success ratio of 88.08%, 65.27%, and 61.44%, respectively.","The model also exhibits adaptability through zero-shot testing, creating molecules that satisfy combinations of properties that have not been encountered.","It can comprehend text inputs with various language styles, extending beyond the confines of outlined prompts, as confirmed through empirical validation.","Additionally, the knowledge distillation feature of TSMMG contributes to the continuous enhancement of small models, while the innovative approach to dataset construction effectively addresses the issues of data scarcity and quality, which positions TSMMG as a promising tool in the domains of drug discovery and materials science.","Code is available at https://github.com/HHW-zhou/TSMMG."],"url":"http://arxiv.org/abs/2403.13244v1"}
{"created":"2024-03-20 02:11:28","title":"Tackling Noisy Labels with Network Parameter Additive Decomposition","abstract":"Given data with noisy labels, over-parameterized deep networks suffer overfitting mislabeled data, resulting in poor generalization. The memorization effect of deep networks shows that although the networks have the ability to memorize all noisy data, they would first memorize clean training data, and then gradually memorize mislabeled training data. A simple and effective method that exploits the memorization effect to combat noisy labels is early stopping. However, early stopping cannot distinguish the memorization of clean data and mislabeled data, resulting in the network still inevitably overfitting mislabeled data in the early training stage.In this paper, to decouple the memorization of clean data and mislabeled data, and further reduce the side effect of mislabeled data, we perform additive decomposition on network parameters. Namely, all parameters are additively decomposed into two groups, i.e., parameters $\\mathbf{w}$ are decomposed as $\\mathbf{w}=\\bm{\\sigma}+\\bm{\\gamma}$. Afterward, the parameters $\\bm{\\sigma}$ are considered to memorize clean data, while the parameters $\\bm{\\gamma}$ are considered to memorize mislabeled data. Benefiting from the memorization effect, the updates of the parameters $\\bm{\\sigma}$ are encouraged to fully memorize clean data in early training, and then discouraged with the increase of training epochs to reduce interference of mislabeled data. The updates of the parameters $\\bm{\\gamma}$ are the opposite. In testing, only the parameters $\\bm{\\sigma}$ are employed to enhance generalization. Extensive experiments on both simulated and real-world benchmarks confirm the superior performance of our method.","sentences":["Given data with noisy labels, over-parameterized deep networks suffer overfitting mislabeled data, resulting in poor generalization.","The memorization effect of deep networks shows that although the networks have the ability to memorize all noisy data, they would first memorize clean training data, and then gradually memorize mislabeled training data.","A simple and effective method that exploits the memorization effect to combat noisy labels is early stopping.","However, early stopping cannot distinguish the memorization of clean data and mislabeled data, resulting in the network still inevitably overfitting mislabeled data in the early training stage.","In this paper, to decouple the memorization of clean data and mislabeled data, and further reduce the side effect of mislabeled data, we perform additive decomposition on network parameters.","Namely, all parameters are additively decomposed into two groups, i.e., parameters $\\mathbf{w}$ are decomposed as $\\mathbf{w}=\\bm{\\sigma}+\\bm{\\gamma}$. Afterward, the parameters $\\bm{\\sigma}$ are considered to memorize clean data, while the parameters $\\bm{\\gamma}$ are considered to memorize mislabeled data.","Benefiting from the memorization effect, the updates of the parameters $\\bm{\\sigma}$ are encouraged to fully memorize clean data in early training, and then discouraged with the increase of training epochs to reduce interference of mislabeled data.","The updates of the parameters $\\bm{\\gamma}$ are the opposite.","In testing, only the parameters $\\bm{\\sigma}$ are employed to enhance generalization.","Extensive experiments on both simulated and real-world benchmarks confirm the superior performance of our method."],"url":"http://arxiv.org/abs/2403.13241v1"}
{"created":"2024-03-20 01:58:38","title":"Graph Attention Network-based Block Propagation with Optimal AoI and Reputation in Web 3.0","abstract":"Web 3.0 is recognized as a pioneering paradigm that empowers users to securely oversee data without reliance on a centralized authority. Blockchains, as a core technology to realize Web 3.0, can facilitate decentralized and transparent data management. Nevertheless, the evolution of blockchain-enabled Web 3.0 is still in its nascent phase, grappling with challenges such as ensuring efficiency and reliability to enhance block propagation performance. In this paper, we design a Graph Attention Network (GAT)-based reliable block propagation optimization framework for blockchain-enabled Web 3.0. We first innovatively apply a data-freshness metric called age of information to measure block propagation efficiency in public blockchains. To achieve the reliability of block propagation, we introduce a reputation mechanism based on the subjective logic model, including the local and recommended opinions to calculate the miner reputation value. Moreover, considering that the GAT possesses the excellent ability to process graph-structured data, we utilize the GAT with reinforcement learning to obtain the optimal block propagation trajectory. Numerical results demonstrate that the proposed scheme exhibits the most outstanding block propagation efficiency and reliability compared with traditional routing algorithms.","sentences":["Web 3.0 is recognized as a pioneering paradigm that empowers users to securely oversee data without reliance on a centralized authority.","Blockchains, as a core technology to realize Web 3.0, can facilitate decentralized and transparent data management.","Nevertheless, the evolution of blockchain-enabled Web 3.0 is still in its nascent phase, grappling with challenges such as ensuring efficiency and reliability to enhance block propagation performance.","In this paper, we design a Graph Attention Network (GAT)-based reliable block propagation optimization framework for blockchain-enabled Web 3.0.","We first innovatively apply a data-freshness metric called age of information to measure block propagation efficiency in public blockchains.","To achieve the reliability of block propagation, we introduce a reputation mechanism based on the subjective logic model, including the local and recommended opinions to calculate the miner reputation value.","Moreover, considering that the GAT possesses the excellent ability to process graph-structured data, we utilize the GAT with reinforcement learning to obtain the optimal block propagation trajectory.","Numerical results demonstrate that the proposed scheme exhibits the most outstanding block propagation efficiency and reliability compared with traditional routing algorithms."],"url":"http://arxiv.org/abs/2403.13237v1"}
{"created":"2024-03-20 01:57:24","title":"AMCO: Adaptive Multimodal Coupling of Vision and Proprioception for Quadruped Robot Navigation in Outdoor Environments","abstract":"We present AMCO, a novel navigation method for quadruped robots that adaptively combines vision-based and proprioception-based perception capabilities. Our approach uses three cost maps: general knowledge map; traversability history map; and current proprioception map; which are derived from a robot's vision and proprioception data, and couples them to obtain a coupled traversability cost map for navigation. The general knowledge map encodes terrains semantically segmented from visual sensing, and represents a terrain's typically expected traversability. The traversability history map encodes the robot's recent proprioceptive measurements on a terrain and its semantic segmentation as a cost map. Further, the robot's present proprioceptive measurement is encoded as a cost map in the current proprioception map. As the general knowledge map and traversability history map rely on semantic segmentation, we evaluate the reliability of the visual sensory data by estimating the brightness and motion blur of input RGB images and accordingly combine the three cost maps to obtain the coupled traversability cost map used for navigation. Leveraging this adaptive coupling, the robot can depend on the most reliable input modality available. Finally, we present a novel planner that selects appropriate gaits and velocities for traversing challenging outdoor environments using the coupled traversability cost map. We demonstrate AMCO's navigation performance in different real-world outdoor environments and observe 10.8%-34.9% reduction w.r.t. two stability metrics, and up to 50% improvement in terms of success rate compared to current navigation methods.","sentences":["We present AMCO, a novel navigation method for quadruped robots that adaptively combines vision-based and proprioception-based perception capabilities.","Our approach uses three cost maps: general knowledge map; traversability history map; and current proprioception map; which are derived from a robot's vision and proprioception data, and couples them to obtain a coupled traversability cost map for navigation.","The general knowledge map encodes terrains semantically segmented from visual sensing, and represents a terrain's typically expected traversability.","The traversability history map encodes the robot's recent proprioceptive measurements on a terrain and its semantic segmentation as a cost map.","Further, the robot's present proprioceptive measurement is encoded as a cost map in the current proprioception map.","As the general knowledge map and traversability history map rely on semantic segmentation, we evaluate the reliability of the visual sensory data by estimating the brightness and motion blur of input RGB images and accordingly combine the three cost maps to obtain the coupled traversability cost map used for navigation.","Leveraging this adaptive coupling, the robot can depend on the most reliable input modality available.","Finally, we present a novel planner that selects appropriate gaits and velocities for traversing challenging outdoor environments using the coupled traversability cost map.","We demonstrate AMCO's navigation performance in different real-world outdoor environments and observe 10.8%-34.9% reduction w.r.t.","two stability metrics, and up to 50% improvement in terms of success rate compared to current navigation methods."],"url":"http://arxiv.org/abs/2403.13235v1"}
{"created":"2024-03-20 01:46:06","title":"Technical Report: Competition Solution For BetterMixture","abstract":"In the era of flourishing large-scale models, the challenge of selecting and optimizing datasets from the vast and complex sea of data, to enhance the performance of large language models within the constraints of limited computational resources, has become paramount. This paper details our solution for the BetterMixture challenge, which focuses on the fine-tuning data mixing for large language models. Our approach, which secured third place, incorporates data deduplication, low-level and high-level quality filtering, and diversity selection. The foundation of our solution is Ke-Data-Juicer, an extension of Data-Juicer, demonstrating its robust capabilities in handling and optimizing data for large language models.","sentences":["In the era of flourishing large-scale models, the challenge of selecting and optimizing datasets from the vast and complex sea of data, to enhance the performance of large language models within the constraints of limited computational resources, has become paramount.","This paper details our solution for the BetterMixture challenge, which focuses on the fine-tuning data mixing for large language models.","Our approach, which secured third place, incorporates data deduplication, low-level and high-level quality filtering, and diversity selection.","The foundation of our solution is Ke-Data-Juicer, an extension of Data-Juicer, demonstrating its robust capabilities in handling and optimizing data for large language models."],"url":"http://arxiv.org/abs/2403.13233v1"}
{"created":"2024-03-20 01:27:59","title":"BFT-PoLoc: A Byzantine Fortified Trigonometric Proof of Location Protocol using Internet Delays","abstract":"Internet platforms depend on accurately determining the geographical locations of online users to deliver targeted services (e.g., advertising). The advent of decentralized platforms (blockchains) emphasizes the importance of geographically distributed nodes, making the validation of locations more crucial. In these decentralized settings, mutually non-trusting participants need to {\\em prove} their locations to each other. The incentives for claiming desired location include decentralization properties (validators of a blockchain), explicit rewards for improving coverage (physical infrastructure blockchains) and regulatory compliance -- and entice participants towards prevaricating their true location malicious via VPNs, tampering with internet delays, or compromising other parties (challengers) to misrepresent their location. Traditional delay-based geolocation methods focus on reducing the noise in measurements and are very vulnerable to wilful divergences from prescribed protocol.   In this paper we use Internet delay measurements to securely prove the location of IP addresses while being immune to a large fraction of Byzantine actions. Our core methods are to endow Internet telemetry tools (e.g., ping) with cryptographic primitives (signatures and hash functions) together with Byzantine resistant data inferences subject to Euclidean geometric constraints. We introduce two new networking protocols, robust against Byzantine actions: Proof of Internet Geometry (PoIG) converts delay measurements into precise distance estimates across the Internet; Proof of Location (PoLoc) enables accurate and efficient multilateration of a specific IP address. The key algorithmic innovations are in conducting ``Byzantine fortified trigonometry\" (BFT) inferences of data, endowing low rank matrix completion methods with Byzantine resistance.","sentences":["Internet platforms depend on accurately determining the geographical locations of online users to deliver targeted services (e.g., advertising).","The advent of decentralized platforms (blockchains) emphasizes the importance of geographically distributed nodes, making the validation of locations more crucial.","In these decentralized settings, mutually non-trusting participants need to {\\em prove} their locations to each other.","The incentives for claiming desired location include decentralization properties (validators of a blockchain), explicit rewards for improving coverage (physical infrastructure blockchains) and regulatory compliance -- and entice participants towards prevaricating their true location malicious via VPNs, tampering with internet delays, or compromising other parties (challengers) to misrepresent their location.","Traditional delay-based geolocation methods focus on reducing the noise in measurements and are very vulnerable to wilful divergences from prescribed protocol.   ","In this paper we use Internet delay measurements to securely prove the location of IP addresses while being immune to a large fraction of Byzantine actions.","Our core methods are to endow Internet telemetry tools (e.g., ping) with cryptographic primitives (signatures and hash functions) together with Byzantine resistant data inferences subject to Euclidean geometric constraints.","We introduce two new networking protocols, robust against Byzantine actions: Proof of Internet Geometry (PoIG) converts delay measurements into precise distance estimates across the Internet; Proof of Location (PoLoc) enables accurate and efficient multilateration of a specific IP address.","The key algorithmic innovations are in conducting ``Byzantine fortified trigonometry\" (BFT) inferences of data, endowing low rank matrix completion methods with Byzantine resistance."],"url":"http://arxiv.org/abs/2403.13230v1"}
{"created":"2024-03-20 00:41:12","title":"Diffusion Model for Data-Driven Black-Box Optimization","abstract":"Generative AI has redefined artificial intelligence, enabling the creation of innovative content and customized solutions that drive business practices into a new era of efficiency and creativity. In this paper, we focus on diffusion models, a powerful generative AI technology, and investigate their potential for black-box optimization over complex structured variables. Consider the practical scenario where one wants to optimize some structured design in a high-dimensional space, based on massive unlabeled data (representing design variables) and a small labeled dataset. We study two practical types of labels: 1) noisy measurements of a real-valued reward function and 2) human preference based on pairwise comparisons. The goal is to generate new designs that are near-optimal and preserve the designed latent structures. Our proposed method reformulates the design optimization problem into a conditional sampling problem, which allows us to leverage the power of diffusion models for modeling complex distributions. In particular, we propose a reward-directed conditional diffusion model, to be trained on the mixed data, for sampling a near-optimal solution conditioned on high predicted rewards. Theoretically, we establish sub-optimality error bounds for the generated designs. The sub-optimality gap nearly matches the optimal guarantee in off-policy bandits, demonstrating the efficiency of reward-directed diffusion models for black-box optimization. Moreover, when the data admits a low-dimensional latent subspace structure, our model efficiently generates high-fidelity designs that closely respect the latent structure. We provide empirical experiments validating our model in decision-making and content-creation tasks.","sentences":["Generative AI has redefined artificial intelligence, enabling the creation of innovative content and customized solutions that drive business practices into a new era of efficiency and creativity.","In this paper, we focus on diffusion models, a powerful generative AI technology, and investigate their potential for black-box optimization over complex structured variables.","Consider the practical scenario where one wants to optimize some structured design in a high-dimensional space, based on massive unlabeled data (representing design variables) and a small labeled dataset.","We study two practical types of labels: 1) noisy measurements of a real-valued reward function and 2) human preference based on pairwise comparisons.","The goal is to generate new designs that are near-optimal and preserve the designed latent structures.","Our proposed method reformulates the design optimization problem into a conditional sampling problem, which allows us to leverage the power of diffusion models for modeling complex distributions.","In particular, we propose a reward-directed conditional diffusion model, to be trained on the mixed data, for sampling a near-optimal solution conditioned on high predicted rewards.","Theoretically, we establish sub-optimality error bounds for the generated designs.","The sub-optimality gap nearly matches the optimal guarantee in off-policy bandits, demonstrating the efficiency of reward-directed diffusion models for black-box optimization.","Moreover, when the data admits a low-dimensional latent subspace structure, our model efficiently generates high-fidelity designs that closely respect the latent structure.","We provide empirical experiments validating our model in decision-making and content-creation tasks."],"url":"http://arxiv.org/abs/2403.13219v1"}
{"created":"2024-03-20 00:37:19","title":"Self-Attention Based Semantic Decomposition in Vector Symbolic Architectures","abstract":"Vector Symbolic Architectures (VSAs) have emerged as a novel framework for enabling interpretable machine learning algorithms equipped with the ability to reason and explain their decision processes. The basic idea is to represent discrete information through high dimensional random vectors. Complex data structures can be built up with operations over vectors such as the \"binding\" operation involving element-wise vector multiplication, which associates data together. The reverse task of decomposing the associated elements is a combinatorially hard task, with an exponentially large search space. The main algorithm for performing this search is the resonator network, inspired by Hopfield network-based memory search operations.   In this work, we introduce a new variant of the resonator network, based on self-attention based update rules in the iterative search problem. This update rule, based on the Hopfield network with log-sum-exp energy function and norm-bounded states, is shown to substantially improve the performance and rate of convergence. As a result, our algorithm enables a larger capacity for associative memory, enabling applications in many tasks like perception based pattern recognition, scene decomposition, and object reasoning. We substantiate our algorithm with a thorough evaluation and comparisons to baselines.","sentences":["Vector Symbolic Architectures (VSAs) have emerged as a novel framework for enabling interpretable machine learning algorithms equipped with the ability to reason and explain their decision processes.","The basic idea is to represent discrete information through high dimensional random vectors.","Complex data structures can be built up with operations over vectors such as the \"binding\" operation involving element-wise vector multiplication, which associates data together.","The reverse task of decomposing the associated elements is a combinatorially hard task, with an exponentially large search space.","The main algorithm for performing this search is the resonator network, inspired by Hopfield network-based memory search operations.   ","In this work, we introduce a new variant of the resonator network, based on self-attention based update rules in the iterative search problem.","This update rule, based on the Hopfield network with log-sum-exp energy function and norm-bounded states, is shown to substantially improve the performance and rate of convergence.","As a result, our algorithm enables a larger capacity for associative memory, enabling applications in many tasks like perception based pattern recognition, scene decomposition, and object reasoning.","We substantiate our algorithm with a thorough evaluation and comparisons to baselines."],"url":"http://arxiv.org/abs/2403.13218v1"}
{"created":"2024-03-20 00:24:23","title":"What makes a small-world network? Leveraging machine learning for the robust prediction and classification of networks","abstract":"The ability to simulate realistic networks based on empirical data is an important task across scientific disciplines, from epidemiology to computer science. Often simulation approaches involve selecting a suitable network generative model such as Erd\\\"os-R\\'enyi or small-world. However, few tools are available to quantify if a particular generative model is suitable for capturing a given network structure or organization. We utilize advances in interpretable machine learning to classify simulated networks by our generative models based on various network attributes, using both primary features and their interactions. Our study underscores the significance of specific network features and their interactions in distinguishing generative models, comprehending complex network structures, and forming real-world networks","sentences":["The ability to simulate realistic networks based on empirical data is an important task across scientific disciplines, from epidemiology to computer science.","Often simulation approaches involve selecting a suitable network generative model such as Erd\\\"os-R\\'enyi or small-world.","However, few tools are available to quantify if a particular generative model is suitable for capturing a given network structure or organization.","We utilize advances in interpretable machine learning to classify simulated networks by our generative models based on various network attributes, using both primary features and their interactions.","Our study underscores the significance of specific network features and their interactions in distinguishing generative models, comprehending complex network structures, and forming real-world networks"],"url":"http://arxiv.org/abs/2403.13215v1"}
{"created":"2024-03-19 23:57:55","title":"CaDRE: Controllable and Diverse Generation of Safety-Critical Driving Scenarios using Real-World Trajectories","abstract":"Simulation is an indispensable tool in the development and testing of autonomous vehicles (AVs), offering an efficient and safe alternative to road testing by allowing the exploration of a wide range of scenarios. Despite its advantages, a significant challenge within simulation-based testing is the generation of safety-critical scenarios, which are essential to ensure that AVs can handle rare but potentially fatal situations. This paper addresses this challenge by introducing a novel generative framework, CaDRE, which is specifically designed for generating diverse and controllable safety-critical scenarios using real-world trajectories. Our approach optimizes for both the quality and diversity of scenarios by employing a unique formulation and algorithm that integrates real-world data, domain knowledge, and black-box optimization techniques. We validate the effectiveness of our framework through extensive testing in three representative types of traffic scenarios. The results demonstrate superior performance in generating diverse and high-quality scenarios with greater sample efficiency than existing reinforcement learning and sampling-based methods.","sentences":["Simulation is an indispensable tool in the development and testing of autonomous vehicles (AVs), offering an efficient and safe alternative to road testing by allowing the exploration of a wide range of scenarios.","Despite its advantages, a significant challenge within simulation-based testing is the generation of safety-critical scenarios, which are essential to ensure that AVs can handle rare but potentially fatal situations.","This paper addresses this challenge by introducing a novel generative framework, CaDRE, which is specifically designed for generating diverse and controllable safety-critical scenarios using real-world trajectories.","Our approach optimizes for both the quality and diversity of scenarios by employing a unique formulation and algorithm that integrates real-world data, domain knowledge, and black-box optimization techniques.","We validate the effectiveness of our framework through extensive testing in three representative types of traffic scenarios.","The results demonstrate superior performance in generating diverse and high-quality scenarios with greater sample efficiency than existing reinforcement learning and sampling-based methods."],"url":"http://arxiv.org/abs/2403.13208v1"}
{"created":"2024-03-19 23:23:35","title":"DecentNeRFs: Decentralized Neural Radiance Fields from Crowdsourced Images","abstract":"Neural radiance fields (NeRFs) show potential for transforming images captured worldwide into immersive 3D visual experiences. However, most of this captured visual data remains siloed in our camera rolls as these images contain personal details. Even if made public, the problem of learning 3D representations of billions of scenes captured daily in a centralized manner is computationally intractable. Our approach, DecentNeRF, is the first attempt at decentralized, crowd-sourced NeRFs that require $\\sim 10^4\\times$ less server computing for a scene than a centralized approach. Instead of sending the raw data, our approach requires users to send a 3D representation, distributing the high computation cost of training centralized NeRFs between the users. It learns photorealistic scene representations by decomposing users' 3D views into personal and global NeRFs and a novel optimally weighted aggregation of only the latter. We validate the advantage of our approach to learn NeRFs with photorealism and minimal server computation cost on structured synthetic and real-world photo tourism datasets. We further analyze how secure aggregation of global NeRFs in DecentNeRF minimizes the undesired reconstruction of personal content by the server.","sentences":["Neural radiance fields (NeRFs) show potential for transforming images captured worldwide into immersive 3D visual experiences.","However, most of this captured visual data remains siloed in our camera rolls as these images contain personal details.","Even if made public, the problem of learning 3D representations of billions of scenes captured daily in a centralized manner is computationally intractable.","Our approach, DecentNeRF, is the first attempt at decentralized, crowd-sourced NeRFs that require $\\sim 10^4\\times$ less server computing for a scene than a centralized approach.","Instead of sending the raw data, our approach requires users to send a 3D representation, distributing the high computation cost of training centralized NeRFs between the users.","It learns photorealistic scene representations by decomposing users' 3D views into personal and global NeRFs and a novel optimally weighted aggregation of only the latter.","We validate the advantage of our approach to learn NeRFs with photorealism and minimal server computation cost on structured synthetic and real-world photo tourism datasets.","We further analyze how secure aggregation of global NeRFs in DecentNeRF minimizes the undesired reconstruction of personal content by the server."],"url":"http://arxiv.org/abs/2403.13199v1"}
{"created":"2024-03-19 23:01:14","title":"3D Semantic MapNet: Building Maps for Multi-Object Re-Identification in 3D","abstract":"We study the task of 3D multi-object re-identification from embodied tours. Specifically, an agent is given two tours of an environment (e.g. an apartment) under two different layouts (e.g. arrangements of furniture). Its task is to detect and re-identify objects in 3D - e.g. a \"sofa\" moved from location A to B, a new \"chair\" in the second layout at location C, or a \"lamp\" from location D in the first layout missing in the second. To support this task, we create an automated infrastructure to generate paired egocentric tours of initial/modified layouts in the Habitat simulator using Matterport3D scenes, YCB and Google-scanned objects. We present 3D Semantic MapNet (3D-SMNet) - a two-stage re-identification model consisting of (1) a 3D object detector that operates on RGB-D videos with known pose, and (2) a differentiable object matching module that solves correspondence estimation between two sets of 3D bounding boxes. Overall, 3D-SMNet builds object-based maps of each layout and then uses a differentiable matcher to re-identify objects across the tours. After training 3D-SMNet on our generated episodes, we demonstrate zero-shot transfer to real-world rearrangement scenarios by instantiating our task in Replica, Active Vision, and RIO environments depicting rearrangements. On all datasets, we find 3D-SMNet outperforms competitive baselines. Further, we show jointly training on real and generated episodes can lead to significant improvements over training on real data alone.","sentences":["We study the task of 3D multi-object re-identification from embodied tours.","Specifically, an agent is given two tours of an environment (e.g. an apartment) under two different layouts (e.g. arrangements of furniture).","Its task is to detect and re-identify objects in 3D - e.g. a \"sofa\" moved from location A to B, a new \"chair\" in the second layout at location C, or a \"lamp\" from location D in the first layout missing in the second.","To support this task, we create an automated infrastructure to generate paired egocentric tours of initial/modified layouts in the Habitat simulator using Matterport3D scenes, YCB and Google-scanned objects.","We present 3D Semantic MapNet (3D-SMNet) - a two-stage re-identification model consisting of (1) a 3D object detector that operates on RGB-D videos with known pose, and (2) a differentiable object matching module that solves correspondence estimation between two sets of 3D bounding boxes.","Overall, 3D-SMNet builds object-based maps of each layout and then uses a differentiable matcher to re-identify objects across the tours.","After training 3D-SMNet on our generated episodes, we demonstrate zero-shot transfer to real-world rearrangement scenarios by instantiating our task in Replica, Active Vision, and RIO environments depicting rearrangements.","On all datasets, we find 3D-SMNet outperforms competitive baselines.","Further, we show jointly training on real and generated episodes can lead to significant improvements over training on real data alone."],"url":"http://arxiv.org/abs/2403.13190v1"}
{"created":"2024-03-19 22:56:53","title":"Evolutionary Optimization of Model Merging Recipes","abstract":"We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models. While model merging has emerged as a promising approach for LLM development due to its cost-effectiveness, it currently relies on human intuition and domain knowledge, limiting its potential. Here, we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute. Our approach operates in both parameter space and data flow space, allowing for optimization beyond just the weights of the individual models. This approach even facilitates cross-domain merging, generating models like a Japanese LLM with Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese VLMs. This work not only contributes new state-of-the-art models back to the open-source community, but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development.","sentences":["We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models.","While model merging has emerged as a promising approach for LLM development due to its cost-effectiveness, it currently relies on human intuition and domain knowledge, limiting its potential.","Here, we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute.","Our approach operates in both parameter space and data flow space, allowing for optimization beyond just the weights of the individual models.","This approach even facilitates cross-domain merging, generating models like a Japanese LLM with Math reasoning capabilities.","Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks.","Furthermore, a culturally-aware Japanese VLM generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese VLMs.","This work not only contributes new state-of-the-art models back to the open-source community, but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development."],"url":"http://arxiv.org/abs/2403.13187v1"}
{"created":"2024-03-19 22:30:56","title":"Efficient k-step Weighted Reachability Query Processing Algorithms","abstract":"Given a data graph G, a source vertex u and a target vertex v of a reachability query, the reachability query is used to answer whether there exists a path from u to v in G. Reachability query processing is one of the fundamental operations in graph data management, which is widely used in biological networks, communication networks, and social networks to assist data analysis. The data graphs in practical applications usually contain information such as quantization weights associated with the structural relationships, in addition to the structural relationships between vertices. Thus, in addition to the traditional reachability relationships, users may want to further understand whether such reachability relationships satisfy specific constraints. In this paper, we study the problem of efficiently processing k -step reachability queries with weighted constraints in weighted graphs. The k -step weighted reachability query questions are used to answer the question of whether there exists a path from a source vertex u to a goal vertex v in a given weighted graph. If it exists, the path needs to satisfy 1) all edges in the path satisfy the given weight constraints, and 2) the length of the path does not exceed the given distance threshold k. To address the problem, firstly, WKRI index supporting k -step weighted reachability query processing and index construction methods based on efficient pruning strategies are proposed. Secondly, the idea of constructing index based on part of the vertexs is proposed to reduce the size of the index. We design and implement two optimized indexes GWKRI and LWKRI based on the vertex coverage set. Finally, experiments are conducted on several real datasets. The experimental results verify the efficiency of the method proposed in this paper in answering k -step weighted reachability queries.","sentences":["Given a data graph G, a source vertex u and a target vertex v of a reachability query, the reachability query is used to answer whether there exists a path from u to v in G. Reachability query processing is one of the fundamental operations in graph data management, which is widely used in biological networks, communication networks, and social networks to assist data analysis.","The data graphs in practical applications usually contain information such as quantization weights associated with the structural relationships, in addition to the structural relationships between vertices.","Thus, in addition to the traditional reachability relationships, users may want to further understand whether such reachability relationships satisfy specific constraints.","In this paper, we study the problem of efficiently processing k -step reachability queries with weighted constraints in weighted graphs.","The k -step weighted reachability query questions are used to answer the question of whether there exists a path from a source vertex u to a goal vertex v in a given weighted graph.","If it exists, the path needs to satisfy 1) all edges in the path satisfy the given weight constraints, and 2) the length of the path does not exceed the given distance threshold k.","To address the problem, firstly, WKRI index supporting k -step weighted reachability query processing and index construction methods based on efficient pruning strategies are proposed.","Secondly, the idea of constructing index based on part of the vertexs is proposed to reduce the size of the index.","We design and implement two optimized indexes GWKRI and LWKRI based on the vertex coverage set.","Finally, experiments are conducted on several real datasets.","The experimental results verify the efficiency of the method proposed in this paper in answering k -step weighted reachability queries."],"url":"http://arxiv.org/abs/2403.13181v1"}
{"created":"2024-03-19 22:05:32","title":"Castor: Competing shapelets for fast and accurate time series classification","abstract":"Shapelets are discriminative subsequences, originally embedded in shapelet-based decision trees but have since been extended to shapelet-based transformations. We propose Castor, a simple, efficient, and accurate time series classification algorithm that utilizes shapelets to transform time series. The transformation organizes shapelets into groups with varying dilation and allows the shapelets to compete over the time context to construct a diverse feature representation. By organizing the shapelets into groups, we enable the transformation to transition between levels of competition, resulting in methods that more closely resemble distance-based transformations or dictionary-based transformations. We demonstrate, through an extensive empirical investigation, that Castor yields transformations that result in classifiers that are significantly more accurate than several state-of-the-art classifiers. In an extensive ablation study, we examine the effect of choosing hyperparameters and suggest accurate and efficient default values.","sentences":["Shapelets are discriminative subsequences, originally embedded in shapelet-based decision trees but have since been extended to shapelet-based transformations.","We propose Castor, a simple, efficient, and accurate time series classification algorithm that utilizes shapelets to transform time series.","The transformation organizes shapelets into groups with varying dilation and allows the shapelets to compete over the time context to construct a diverse feature representation.","By organizing the shapelets into groups, we enable the transformation to transition between levels of competition, resulting in methods that more closely resemble distance-based transformations or dictionary-based transformations.","We demonstrate, through an extensive empirical investigation, that Castor yields transformations that result in classifiers that are significantly more accurate than several state-of-the-art classifiers.","In an extensive ablation study, we examine the effect of choosing hyperparameters and suggest accurate and efficient default values."],"url":"http://arxiv.org/abs/2403.13176v1"}
{"created":"2024-03-19 21:55:43","title":"GerontoVis: Data Visualization at the Confluence of Aging","abstract":"Despite the explosive growth of the aging population worldwide, older adults have been largely overlooked by visualization research. This paper is a critical reflection on the underrepresentation of older adults in visualization research. We discuss why investigating visualization at the intersection of aging matters, why older adults may have been omitted from sample populations in visualization research, how aging may affect visualization use, and how this differs from traditional accessibility research. To encourage further discussion and novel scholarship in this area, we introduce GerontoVis, a term which encapsulates research and practice of data visualization design that primarily focuses on older adults. By introducing this new subfield of visualization research, we hope to shine a spotlight on this growing user population and stimulate innovation toward the development of aging-aware visualization tools. We offer a birds-eye view of the GerontoVis landscape, explore some of its unique challenges, and identify promising areas for future research.","sentences":["Despite the explosive growth of the aging population worldwide, older adults have been largely overlooked by visualization research.","This paper is a critical reflection on the underrepresentation of older adults in visualization research.","We discuss why investigating visualization at the intersection of aging matters, why older adults may have been omitted from sample populations in visualization research, how aging may affect visualization use, and how this differs from traditional accessibility research.","To encourage further discussion and novel scholarship in this area, we introduce GerontoVis, a term which encapsulates research and practice of data visualization design that primarily focuses on older adults.","By introducing this new subfield of visualization research, we hope to shine a spotlight on this growing user population and stimulate innovation toward the development of aging-aware visualization tools.","We offer a birds-eye view of the GerontoVis landscape, explore some of its unique challenges, and identify promising areas for future research."],"url":"http://arxiv.org/abs/2403.13173v1"}
{"created":"2024-03-19 21:40:20","title":"Improved EATFormer: A Vision Transformer for Medical Image Classification","abstract":"The accurate analysis of medical images is vital for diagnosing and predicting medical conditions. Traditional approaches relying on radiologists and clinicians suffer from inconsistencies and missed diagnoses. Computer-aided diagnosis systems can assist in achieving early, accurate, and efficient diagnoses. This paper presents an improved Evolutionary Algorithm-based Transformer architecture for medical image classification using Vision Transformers. The proposed EATFormer architecture combines the strengths of Convolutional Neural Networks and Vision Transformers, leveraging their ability to identify patterns in data and adapt to specific characteristics. The architecture incorporates novel components, including the Enhanced EA-based Transformer block with Feed-Forward Network, Global and Local Interaction , and Multi-Scale Region Aggregation modules. It also introduces the Modulated Deformable MSA module for dynamic modeling of irregular locations. The paper discusses the Vision Transformer (ViT) model's key features, such as patch-based processing, positional context incorporation, and Multi-Head Attention mechanism. It introduces the Multi-Scale Region Aggregation module, which aggregates information from different receptive fields to provide an inductive bias. The Global and Local Interaction module enhances the MSA-based global module by introducing a local path for extracting discriminative local information. Experimental results on the Chest X-ray and Kvasir datasets demonstrate that the proposed EATFormer significantly improves prediction speed and accuracy compared to baseline models.","sentences":["The accurate analysis of medical images is vital for diagnosing and predicting medical conditions.","Traditional approaches relying on radiologists and clinicians suffer from inconsistencies and missed diagnoses.","Computer-aided diagnosis systems can assist in achieving early, accurate, and efficient diagnoses.","This paper presents an improved Evolutionary Algorithm-based Transformer architecture for medical image classification using Vision Transformers.","The proposed EATFormer architecture combines the strengths of Convolutional Neural Networks and Vision Transformers, leveraging their ability to identify patterns in data and adapt to specific characteristics.","The architecture incorporates novel components, including the Enhanced EA-based Transformer block with Feed-Forward Network, Global and Local Interaction , and Multi-Scale Region Aggregation modules.","It also introduces the Modulated Deformable MSA module for dynamic modeling of irregular locations.","The paper discusses the Vision Transformer (ViT) model's key features, such as patch-based processing, positional context incorporation, and Multi-Head Attention mechanism.","It introduces the Multi-Scale Region Aggregation module, which aggregates information from different receptive fields to provide an inductive bias.","The Global and Local Interaction module enhances the MSA-based global module by introducing a local path for extracting discriminative local information.","Experimental results on the Chest X-ray and Kvasir datasets demonstrate that the proposed EATFormer significantly improves prediction speed and accuracy compared to baseline models."],"url":"http://arxiv.org/abs/2403.13167v1"}
{"created":"2024-03-19 21:31:16","title":"A simpler data structure for dynamic strings","abstract":"We consider the problem of maintaining a collection of strings while efficiently supporting splits and concatenations on them, as well as comparing two substrings, and computing the longest common prefix between two suffixes. This problem can be solved in optimal time $\\mathcal{O}(\\log N)$ whp for the updates and $\\mathcal{O}(1)$ worst-case time for the queries, where $N$ is the total collection size [Gawrychowski et al., SODA 2018]. We present here a much simpler solution based on a forest of enhanced splay trees (FeST), where both the updates and the substring comparison take $\\mathcal{O}(\\log n)$ amortized time, $n$ being the lengths of the strings involved, and not the total length $N$ of the strings in the collection. The longest common prefix of length $\\ell$ is computed in $\\mathcal{O}(\\log n + \\log^2\\ell)$ amortized time. Our query results are correct whp. Our simpler solution enables other more general updates in $\\mathcal{O}(\\log n)$ amortized time, such as reversing a substring and/or mapping its symbols. We can also regard substrings as circular or as their omega extension.","sentences":["We consider the problem of maintaining a collection of strings while efficiently supporting splits and concatenations on them, as well as comparing two substrings, and computing the longest common prefix between two suffixes.","This problem can be solved in optimal time $\\mathcal{O}(\\log N)$ whp for the updates and $\\mathcal{O}(1)$ worst-case time for the queries, where $N$ is the total collection size [Gawrychowski et al., SODA 2018].","We present here a much simpler solution based on a forest of enhanced splay trees (FeST), where both the updates and the substring comparison take $\\mathcal{O}(\\log n)$ amortized time, $n$ being the lengths of the strings involved, and not the total length $N$ of the strings in the collection.","The longest common prefix of length $\\ell$ is computed in $\\mathcal{O}(\\log n + \\log^2\\ell)$ amortized time.","Our query results are correct whp.","Our simpler solution enables other more general updates in $\\mathcal{O}(\\log n)$ amortized time, such as reversing a substring and/or mapping its symbols.","We can also regard substrings as circular or as their omega extension."],"url":"http://arxiv.org/abs/2403.13162v1"}
{"created":"2024-03-19 20:58:38","title":"Training Survival Models using Scoring Rules","abstract":"Survival Analysis provides critical insights for partially incomplete time-to-event data in various domains. It is also an important example of probabilistic machine learning. The probabilistic nature of the predictions can be exploited by using (proper) scoring rules in the model fitting process instead of likelihood-based optimization. Our proposal does so in a generic manner and can be used for a variety of model classes. We establish different parametric and non-parametric sub-frameworks that allow different degrees of flexibility. Incorporated into neural networks, it leads to a computationally efficient and scalable optimization routine, yielding state-of-the-art predictive performance. Finally, we show that using our framework, we can recover various parametric models and demonstrate that optimization works equally well when compared to likelihood-based methods.","sentences":["Survival Analysis provides critical insights for partially incomplete time-to-event data in various domains.","It is also an important example of probabilistic machine learning.","The probabilistic nature of the predictions can be exploited by using (proper) scoring rules in the model fitting process instead of likelihood-based optimization.","Our proposal does so in a generic manner and can be used for a variety of model classes.","We establish different parametric and non-parametric sub-frameworks that allow different degrees of flexibility.","Incorporated into neural networks, it leads to a computationally efficient and scalable optimization routine, yielding state-of-the-art predictive performance.","Finally, we show that using our framework, we can recover various parametric models and demonstrate that optimization works equally well when compared to likelihood-based methods."],"url":"http://arxiv.org/abs/2403.13150v1"}
{"created":"2024-03-19 20:50:20","title":"Meta-Learning for Fast Adaptation in Intent Inferral on a Robotic Hand Orthosis for Stroke","abstract":"We propose MetaEMG, a meta-learning approach for fast adaptation in intent inferral on a robotic hand orthosis for stroke. One key challenge in machine learning for assistive and rehabilitative robotics with disabled-bodied subjects is the difficulty of collecting labeled training data. Muscle tone and spasticity often vary significantly among stroke subjects, and hand function can even change across different use sessions of the device for the same subject. We investigate the use of meta-learning to mitigate the burden of data collection needed to adapt high-capacity neural networks to a new session or subject. Our experiments on real clinical data collected from five stroke subjects show that MetaEMG can improve the intent inferral accuracy with a small session- or subject-specific dataset and very few fine-tuning epochs. To the best of our knowledge, we are the first to formulate intent inferral on stroke subjects as a meta-learning problem and demonstrate fast adaptation to a new session or subject for controlling a robotic hand orthosis with EMG signals.","sentences":["We propose MetaEMG, a meta-learning approach for fast adaptation in intent inferral on a robotic hand orthosis for stroke.","One key challenge in machine learning for assistive and rehabilitative robotics with disabled-bodied subjects is the difficulty of collecting labeled training data.","Muscle tone and spasticity often vary significantly among stroke subjects, and hand function can even change across different use sessions of the device for the same subject.","We investigate the use of meta-learning to mitigate the burden of data collection needed to adapt high-capacity neural networks to a new session or subject.","Our experiments on real clinical data collected from five stroke subjects show that MetaEMG can improve the intent inferral accuracy with a small session- or subject-specific dataset and very few fine-tuning epochs.","To the best of our knowledge, we are the first to formulate intent inferral on stroke subjects as a meta-learning problem and demonstrate fast adaptation to a new session or subject for controlling a robotic hand orthosis with EMG signals."],"url":"http://arxiv.org/abs/2403.13147v1"}
{"created":"2024-03-19 20:12:46","title":"Multi-fidelity surrogate with heterogeneous input spaces for modeling melt pools in laser-directed energy deposition","abstract":"Multi-fidelity (MF) modeling is a powerful statistical approach that can intelligently blend data from varied fidelity sources. This approach finds a compelling application in predicting melt pool geometry for laser-directed energy deposition (L-DED). One major challenge in using MF surrogates to merge a hierarchy of melt pool models is the variability in input spaces. To address this challenge, this paper introduces a novel approach for constructing an MF surrogate for predicting melt pool geometry by integrating models of varying complexity, that operate on heterogeneous input spaces. The first thermal model incorporates five input parameters i.e., laser power, scan velocity, powder flow rate, carrier gas flow rate, and nozzle height. In contrast, the second thermal model can only handle laser power and scan velocity. A mapping is established between the heterogeneous input spaces so that the five-dimensional space can be morphed into a pseudo two-dimensional space. Predictions are then blended using a Gaussian process-based co-kriging method. The resulting heterogeneous multi-fidelity Gaussian process (Het-MFGP) surrogate not only improves predictive accuracy but also offers computational efficiency by reducing evaluations required from the high-dimensional, high-fidelity thermal model. The results underscore the benefits of employing Het-MFGP for modeling melt pool behavior in L-DED. The framework successfully demonstrates how to leverage multimodal data and handle scenarios where certain input parameters may be difficult to model or measure.","sentences":["Multi-fidelity (MF) modeling is a powerful statistical approach that can intelligently blend data from varied fidelity sources.","This approach finds a compelling application in predicting melt pool geometry for laser-directed energy deposition (L-DED).","One major challenge in using MF surrogates to merge a hierarchy of melt pool models is the variability in input spaces.","To address this challenge, this paper introduces a novel approach for constructing an MF surrogate for predicting melt pool geometry by integrating models of varying complexity, that operate on heterogeneous input spaces.","The first thermal model incorporates five input parameters i.e., laser power, scan velocity, powder flow rate, carrier gas flow rate, and nozzle height.","In contrast, the second thermal model can only handle laser power and scan velocity.","A mapping is established between the heterogeneous input spaces so that the five-dimensional space can be morphed into a pseudo two-dimensional space.","Predictions are then blended using a Gaussian process-based co-kriging method.","The resulting heterogeneous multi-fidelity Gaussian process (Het-MFGP) surrogate not only improves predictive accuracy but also offers computational efficiency by reducing evaluations required from the high-dimensional, high-fidelity thermal model.","The results underscore the benefits of employing Het-MFGP for modeling melt pool behavior in L-DED.","The framework successfully demonstrates how to leverage multimodal data and handle scenarios where certain input parameters may be difficult to model or measure."],"url":"http://arxiv.org/abs/2403.13136v1"}
{"created":"2024-03-19 20:10:50","title":"A Parallel Workflow for Polar Sea-Ice Classification using Auto-labeling of Sentinel-2 Imagery","abstract":"The observation of the advancing and retreating pattern of polar sea ice cover stands as a vital indicator of global warming. This research aims to develop a robust, effective, and scalable system for classifying polar sea ice as thick/snow-covered, young/thin, or open water using Sentinel-2 (S2) images. Since the S2 satellite is actively capturing high-resolution imagery over the earth's surface, there are lots of images that need to be classified. One major obstacle is the absence of labeled S2 training data (images) to act as the ground truth. We demonstrate a scalable and accurate method for segmenting and automatically labeling S2 images using carefully determined color thresholds. We employ a parallel workflow using PySpark to scale and achieve 9-fold data loading and 16-fold map-reduce speedup on auto-labeling S2 images based on thin cloud and shadow-filtered color-based segmentation to generate label data. The auto-labeled data generated from this process are then employed to train a U-Net machine learning model, resulting in good classification accuracy. As training the U-Net classification model is computationally heavy and time-consuming, we distribute the U-Net model training to scale it over 8 GPUs using the Horovod framework over a DGX cluster with a 7.21x speedup without affecting the accuracy of the model. Using the Antarctic's Ross Sea region as an example, the U-Net model trained on auto-labeled data achieves a classification accuracy of 98.97% for auto-labeled training datasets when the thin clouds and shadows from the S2 images are filtered out.","sentences":["The observation of the advancing and retreating pattern of polar sea ice cover stands as a vital indicator of global warming.","This research aims to develop a robust, effective, and scalable system for classifying polar sea ice as thick/snow-covered, young/thin, or open water using Sentinel-2 (S2) images.","Since the S2 satellite is actively capturing high-resolution imagery over the earth's surface, there are lots of images that need to be classified.","One major obstacle is the absence of labeled S2 training data (images) to act as the ground truth.","We demonstrate a scalable and accurate method for segmenting and automatically labeling S2 images using carefully determined color thresholds.","We employ a parallel workflow using PySpark to scale and achieve 9-fold data loading and 16-fold map-reduce speedup on auto-labeling S2 images based on thin cloud and shadow-filtered color-based segmentation to generate label data.","The auto-labeled data generated from this process are then employed to train a U-Net machine learning model, resulting in good classification accuracy.","As training the U-Net classification model is computationally heavy and time-consuming, we distribute the U-Net model training to scale it over 8 GPUs using the Horovod framework over a DGX cluster with a 7.21x speedup without affecting the accuracy of the model.","Using the Antarctic's Ross Sea region as an example, the U-Net model trained on auto-labeled data achieves a classification accuracy of 98.97% for auto-labeled training datasets when the thin clouds and shadows from the S2 images are filtered out."],"url":"http://arxiv.org/abs/2403.13135v1"}
{"created":"2024-03-19 20:10:23","title":"Robust NAS under adversarial training: benchmark, theory, and beyond","abstract":"Recent developments in neural architecture search (NAS) emphasize the significance of considering robust architectures against malicious data. However, there is a notable absence of benchmark evaluations and theoretical guarantees for searching these robust architectures, especially when adversarial training is considered. In this work, we aim to address these two challenges, making twofold contributions. First, we release a comprehensive data set that encompasses both clean accuracy and robust accuracy for a vast array of adversarially trained networks from the NAS-Bench-201 search space on image datasets. Then, leveraging the neural tangent kernel (NTK) tool from deep learning theory, we establish a generalization theory for searching architecture in terms of clean accuracy and robust accuracy under multi-objective adversarial training. We firmly believe that our benchmark and theoretical insights will significantly benefit the NAS community through reliable reproducibility, efficient assessment, and theoretical foundation, particularly in the pursuit of robust architectures.","sentences":["Recent developments in neural architecture search (NAS) emphasize the significance of considering robust architectures against malicious data.","However, there is a notable absence of benchmark evaluations and theoretical guarantees for searching these robust architectures, especially when adversarial training is considered.","In this work, we aim to address these two challenges, making twofold contributions.","First, we release a comprehensive data set that encompasses both clean accuracy and robust accuracy for a vast array of adversarially trained networks from the NAS-Bench-201 search space on image datasets.","Then, leveraging the neural tangent kernel (NTK) tool from deep learning theory, we establish a generalization theory for searching architecture in terms of clean accuracy and robust accuracy under multi-objective adversarial training.","We firmly believe that our benchmark and theoretical insights will significantly benefit the NAS community through reliable reproducibility, efficient assessment, and theoretical foundation, particularly in the pursuit of robust architectures."],"url":"http://arxiv.org/abs/2403.13134v1"}
