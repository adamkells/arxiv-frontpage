{"created":"2025-03-04 13:12:39","title":"MCiteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs","abstract":"Multimodal Large Language Models (MLLMs) have advanced in integrating diverse modalities but frequently suffer from hallucination. A promising solution to mitigate this issue is to generate text with citations, providing a transparent chain for verification. However, existing work primarily focuses on generating citations for text-only content, overlooking the challenges and opportunities of multimodal contexts. To address this gap, we introduce MCiteBench, the first benchmark designed to evaluate and analyze the multimodal citation text generation ability of MLLMs. Our benchmark comprises data derived from academic papers and review-rebuttal interactions, featuring diverse information sources and multimodal content. We comprehensively evaluate models from multiple dimensions, including citation quality, source reliability, and answer accuracy. Through extensive experiments, we observe that MLLMs struggle with multimodal citation text generation. We also conduct deep analyses of models' performance, revealing that the bottleneck lies in attributing the correct sources rather than understanding the multimodal content.","sentences":["Multimodal Large Language Models (MLLMs) have advanced in integrating diverse modalities but frequently suffer from hallucination.","A promising solution to mitigate this issue is to generate text with citations, providing a transparent chain for verification.","However, existing work primarily focuses on generating citations for text-only content, overlooking the challenges and opportunities of multimodal contexts.","To address this gap, we introduce MCiteBench, the first benchmark designed to evaluate and analyze the multimodal citation text generation ability of MLLMs.","Our benchmark comprises data derived from academic papers and review-rebuttal interactions, featuring diverse information sources and multimodal content.","We comprehensively evaluate models from multiple dimensions, including citation quality, source reliability, and answer accuracy.","Through extensive experiments, we observe that MLLMs struggle with multimodal citation text generation.","We also conduct deep analyses of models' performance, revealing that the bottleneck lies in attributing the correct sources rather than understanding the multimodal content."],"url":"http://arxiv.org/abs/2503.02589v2"}
