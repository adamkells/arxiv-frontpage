{"created":"2024-11-13 18:51:10","title":"Large Wireless Model (LWM): A Foundation Model for Wireless Channels","abstract":"This paper presents the Large Wireless Model (LWM) -- the world's first foundation model for wireless channels. Designed as a task-agnostic model, LWM generates universal, rich, contextualized channel embeddings (features) that potentially enhance performance across a wide range of downstream tasks in wireless communication and sensing systems. Towards this objective, LWM, which has a transformer-based architecture, was pre-trained in a self-supervised manner on large-scale wireless channel datasets. Our results show consistent improvements in classification and regression tasks when using the LWM embeddings compared to raw channel representations, especially in scenarios with high-complexity machine learning tasks and limited training datasets. This LWM's ability to learn from large-scale wireless data opens a promising direction for intelligent systems that can efficiently adapt to diverse tasks with limited data, paving the way for addressing key challenges in wireless communication and sensing systems.","sentences":["This paper presents the Large Wireless Model (LWM) -- the world's first foundation model for wireless channels.","Designed as a task-agnostic model, LWM generates universal, rich, contextualized channel embeddings (features) that potentially enhance performance across a wide range of downstream tasks in wireless communication and sensing systems.","Towards this objective, LWM, which has a transformer-based architecture, was pre-trained in a self-supervised manner on large-scale wireless channel datasets.","Our results show consistent improvements in classification and regression tasks when using the LWM embeddings compared to raw channel representations, especially in scenarios with high-complexity machine learning tasks and limited training datasets.","This LWM's ability to learn from large-scale wireless data opens a promising direction for intelligent systems that can efficiently adapt to diverse tasks with limited data, paving the way for addressing key challenges in wireless communication and sensing systems."],"url":"http://arxiv.org/abs/2411.08872v1"}
{"created":"2024-11-13 18:49:35","title":"CamemBERT 2.0: A Smarter French Language Model Aged to Perfection","abstract":"French language models, such as CamemBERT, have been widely adopted across industries for natural language processing (NLP) tasks, with models like CamemBERT seeing over 4 million downloads per month. However, these models face challenges due to temporal concept drift, where outdated training data leads to a decline in performance, especially when encountering new topics and terminology. This issue emphasizes the need for updated models that reflect current linguistic trends. In this paper, we introduce two new versions of the CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these challenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use of the Replaced Token Detection (RTD) objective for better contextual understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked Language Modeling (MLM) objective. Both models are trained on a significantly larger and more recent dataset with longer context length and an updated tokenizer that enhances tokenization performance for French. We evaluate the performance of these models on both general-domain NLP tasks and domain-specific applications, such as medical field tasks, demonstrating their versatility and effectiveness across a range of use cases. Our results show that these updated models vastly outperform their predecessors, making them valuable tools for modern NLP systems. All our new models, as well as intermediate checkpoints, are made openly available on Huggingface.","sentences":["French language models, such as CamemBERT, have been widely adopted across industries for natural language processing (NLP) tasks, with models like CamemBERT seeing over 4 million downloads per month.","However, these models face challenges due to temporal concept drift, where outdated training data leads to a decline in performance, especially when encountering new topics and terminology.","This issue emphasizes the need for updated models that reflect current linguistic trends.","In this paper, we introduce two new versions of the CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these challenges.","CamemBERTav2 is based on the DeBERTaV3 architecture and makes use of the Replaced Token Detection (RTD) objective for better contextual understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked Language Modeling (MLM) objective.","Both models are trained on a significantly larger and more recent dataset with longer context length and an updated tokenizer that enhances tokenization performance for French.","We evaluate the performance of these models on both general-domain NLP tasks and domain-specific applications, such as medical field tasks, demonstrating their versatility and effectiveness across a range of use cases.","Our results show that these updated models vastly outperform their predecessors, making them valuable tools for modern NLP systems.","All our new models, as well as intermediate checkpoints, are made openly available on Huggingface."],"url":"http://arxiv.org/abs/2411.08868v1"}
{"created":"2024-11-13 18:48:51","title":"Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier Profiles","abstract":"In machine learning and data mining, outliers are data points that significantly differ from the dataset and often introduce irrelevant information that can induce bias in its statistics and models. Therefore, unsupervised methods are crucial to detect outliers if there is limited or no information about them. Global-Local Outlier Scores based on Hierarchies (GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a state-of-the-art hierarchical clustering method. GLOSH estimates outlier scores for each data point by comparing its density to the highest density of the region they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to HDBSCAN*'s minpts parameter that influences density estimation. With limited knowledge about the data, choosing an appropriate minpts value beforehand is challenging as one or some minpts values may better represent the underlying cluster structure than others. Additionally, in the process of searching for ``potential outliers'', one has to define the number of outliers n a dataset has, which may be impractical and is often unknown. In this paper, we propose an unsupervised strategy to find the ``best'' minpts value, leveraging the range of GLOSH scores across minpts values to identify the value for which GLOSH scores can best identify outliers from the rest of the dataset. Moreover, we propose an unsupervised strategy to estimate a threshold for classifying points into inliers and (potential) outliers without the need to pre-define any value. Our experiments show that our strategies can automatically find the minpts value and threshold that yield the best or near best outlier detection results using GLOSH.","sentences":["In machine learning and data mining, outliers are data points that significantly differ from the dataset and often introduce irrelevant information that can induce bias in its statistics and models.","Therefore, unsupervised methods are crucial to detect outliers if there is limited or no information about them.","Global-Local Outlier Scores based on Hierarchies (GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a state-of-the-art hierarchical clustering method.","GLOSH estimates outlier scores for each data point by comparing its density to the highest density of the region they reside in the HDBSCAN* hierarchy.","GLOSH may be sensitive to HDBSCAN*'s minpts parameter that influences density estimation.","With limited knowledge about the data, choosing an appropriate minpts value beforehand is challenging as one or some minpts values may better represent the underlying cluster structure than others.","Additionally, in the process of searching for ``potential outliers'', one has to define the number of outliers n a dataset has, which may be impractical and is often unknown.","In this paper, we propose an unsupervised strategy to find the ``best'' minpts value, leveraging the range of GLOSH scores across minpts values to identify the value for which GLOSH scores can best identify outliers from the rest of the dataset.","Moreover, we propose an unsupervised strategy to estimate a threshold for classifying points into inliers and (potential) outliers without the need to pre-define any value.","Our experiments show that our strategies can automatically find the minpts value and threshold that yield the best or near best outlier detection results using GLOSH."],"url":"http://arxiv.org/abs/2411.08867v1"}
{"created":"2024-11-13 18:00:35","title":"A probabilistic reduced-order modeling framework for patient-specific cardio-mechanical analysis","abstract":"Cardio-mechanical models can be used to support clinical decision-making. Unfortunately, the substantial computational effort involved in many cardiac models hinders their application in the clinic, despite the fact that they may provide valuable information. In this work, we present a probabilistic reduced-order modeling (ROM) framework to dramatically reduce the computational effort of such models while providing a credibility interval. In the online stage, a fast-to-evaluate generalized one-fiber model is considered. This generalized one-fiber model incorporates correction factors to emulate patient-specific attributes, such as local geometry variations. In the offline stage, Bayesian inference is used to calibrate these correction factors on training data generated using a full-order isogeometric cardiac model (FOM). A Gaussian process is used in the online stage to predict the correction factors for geometries that are not in the training data. The proposed framework is demonstrated using two examples. The first example considers idealized left-ventricle geometries, for which the behavior of the ROM framework can be studied in detail. In the second example, the ROM framework is applied to scan-based geometries, based on which the application of the ROM framework in the clinical setting is discussed. The results for the two examples convey that the ROM framework can provide accurate online predictions, provided that adequate FOM training data is available. The uncertainty bands provided by the ROM framework give insight into the trustworthiness of its results. Large uncertainty bands can be considered as an indicator for the further population of the training data set.","sentences":["Cardio-mechanical models can be used to support clinical decision-making.","Unfortunately, the substantial computational effort involved in many cardiac models hinders their application in the clinic, despite the fact that they may provide valuable information.","In this work, we present a probabilistic reduced-order modeling (ROM) framework to dramatically reduce the computational effort of such models while providing a credibility interval.","In the online stage, a fast-to-evaluate generalized one-fiber model is considered.","This generalized one-fiber model incorporates correction factors to emulate patient-specific attributes, such as local geometry variations.","In the offline stage, Bayesian inference is used to calibrate these correction factors on training data generated using a full-order isogeometric cardiac model (FOM).","A Gaussian process is used in the online stage to predict the correction factors for geometries that are not in the training data.","The proposed framework is demonstrated using two examples.","The first example considers idealized left-ventricle geometries, for which the behavior of the ROM framework can be studied in detail.","In the second example, the ROM framework is applied to scan-based geometries, based on which the application of the ROM framework in the clinical setting is discussed.","The results for the two examples convey that the ROM framework can provide accurate online predictions, provided that adequate FOM training data is available.","The uncertainty bands provided by the ROM framework give insight into the trustworthiness of its results.","Large uncertainty bands can be considered as an indicator for the further population of the training data set."],"url":"http://arxiv.org/abs/2411.08822v1"}
{"created":"2024-11-13 17:53:23","title":"Process-aware Human Activity Recognition","abstract":"Humans naturally follow distinct patterns when conducting their daily activities, which are driven by established practices and processes, such as production workflows, social norms and daily routines. Human activity recognition (HAR) algorithms usually use neural networks or machine learning techniques to analyse inherent relationships within the data. However, these approaches often overlook the contextual information in which the data are generated, potentially limiting their effectiveness. We propose a novel approach that incorporates process information from context to enhance the HAR performance. Specifically, we align probabilistic events generated by machine learning models with process models derived from contextual information. This alignment adaptively weighs these two sources of information to optimise HAR accuracy. Our experiments demonstrate that our approach achieves better accuracy and Macro F1-score compared to baseline models.","sentences":["Humans naturally follow distinct patterns when conducting their daily activities, which are driven by established practices and processes, such as production workflows, social norms and daily routines.","Human activity recognition (HAR) algorithms usually use neural networks or machine learning techniques to analyse inherent relationships within the data.","However, these approaches often overlook the contextual information in which the data are generated, potentially limiting their effectiveness.","We propose a novel approach that incorporates process information from context to enhance the HAR performance.","Specifically, we align probabilistic events generated by machine learning models with process models derived from contextual information.","This alignment adaptively weighs these two sources of information to optimise HAR accuracy.","Our experiments demonstrate that our approach achieves better accuracy and Macro F1-score compared to baseline models."],"url":"http://arxiv.org/abs/2411.08814v1"}
{"created":"2024-11-13 17:41:56","title":"Stochastic Matching via In-n-Out Local Computation Algorithms","abstract":"Consider the following stochastic matching problem. Given a graph $G=(V, E)$, an unknown subgraph $G_p = (V, E_p)$ is realized where $E_p$ includes every edge of $E$ independently with some probability $p \\in (0, 1]$. The goal is to query a sparse subgraph $H$ of $G$, such that the realized edges in $H$ include an approximate maximum matching of $G_p$.   This problem has been studied extensively over the last decade due to its numerous applications in kidney exchange, online dating, and online labor markets. For any fixed $\\epsilon > 0$, [BDH STOC'20] showed that any graph $G$ has a subgraph $H$ with $\\text{quasipoly}(1/p) = (1/p)^{\\text{poly}(\\log(1/p))}$ maximum degree, achieving a $(1-\\epsilon)$-approximation. A major open question is the best approximation achievable with $\\text{poly}(1/p)$-degree subgraphs. A long line of work has progressively improved the approximation in the $\\text{poly}(1/p)$-degree regime from .5 [BDH+ EC'15] to .501 [AKL EC'17], .656 [BHFR SODA'19], .666 [AB SOSA'19], .731 [BBD SODA'22] (bipartite graphs), and most recently to .68 [DS '24]. In this work, we show that a $\\text{poly}(1/p)$-degree subgraph can obtain a $(1-\\epsilon)$-approximation for any desirably small fixed $\\epsilon > 0$, achieving the best of both worlds.   Beyond its quantitative improvement, a key conceptual contribution of our work is to connect local computation algorithms (LCAs) to the stochastic matching problem for the first time. While prior work on LCAs mainly focuses on their out-queries (the number of vertices probed to produce the output of a given vertex), our analysis also bounds the in-queries (the number of vertices that probe a given vertex). We prove that the outputs of LCAs with bounded in- and out-queries (in-n-out LCAs for short) have limited correlation, a property that our analysis crucially relies on and might find applications beyond stochastic matchings.","sentences":["Consider the following stochastic matching problem.","Given a graph $G=(V, E)$, an unknown subgraph $G_p = (V, E_p)$ is realized where $E_p$ includes every edge of $E$ independently with some probability $p \\in (0, 1]$. The goal is to query a sparse subgraph $H$ of $G$, such that the realized edges in $H$ include an approximate maximum matching of $G_p$.   This problem has been studied extensively over the last decade due to its numerous applications in kidney exchange, online dating, and online labor markets.","For any fixed $\\epsilon > 0$, [BDH STOC'20] showed that any graph $G$ has a subgraph $H$ with $\\text{quasipoly}(1/p) = (1/p)^{\\text{poly}(\\log(1/p))}$ maximum degree, achieving a $(1-\\epsilon)$-approximation.","A major open question is the best approximation achievable with $\\text{poly}(1/p)$-degree subgraphs.","A long line of work has progressively improved the approximation in the $\\text{poly}(1/p)$-degree regime from .5","[BDH+ EC'15] to .501","[AKL EC'17], .656","[BHFR SODA'19], .666","[AB SOSA'19], .731","[BBD SODA'22] (bipartite graphs), and most recently to .68","[DS '24].","In this work, we show that a $\\text{poly}(1/p)$-degree subgraph can obtain a $(1-\\epsilon)$-approximation for any desirably small fixed $\\epsilon > 0$, achieving the best of both worlds.   ","Beyond its quantitative improvement, a key conceptual contribution of our work is to connect local computation algorithms (LCAs) to the stochastic matching problem for the first time.","While prior work on LCAs mainly focuses on their out-queries (the number of vertices probed to produce the output of a given vertex), our analysis also bounds the in-queries (the number of vertices that probe a given vertex).","We prove that the outputs of LCAs with bounded in- and out-queries (in-n-out LCAs for short) have limited correlation, a property that our analysis crucially relies on and might find applications beyond stochastic matchings."],"url":"http://arxiv.org/abs/2411.08805v1"}
{"created":"2024-11-13 17:25:25","title":"Learning Gaussian Multi-Index Models with Gradient Flow: Time Complexity and Directional Convergence","abstract":"This work focuses on the gradient flow dynamics of a neural network model that uses correlation loss to approximate a multi-index function on high-dimensional standard Gaussian data. Specifically, the multi-index function we consider is a sum of neurons $f^*(x) \\!=\\! \\sum_{j=1}^k \\! \\sigma^*(v_j^T x)$ where $v_1, \\dots, v_k$ are unit vectors, and $\\sigma^*$ lacks the first and second Hermite polynomials in its Hermite expansion. It is known that, for the single-index case ($k\\!=\\!1$), overcoming the search phase requires polynomial time complexity. We first generalize this result to multi-index functions characterized by vectors in arbitrary directions. After the search phase, it is not clear whether the network neurons converge to the index vectors, or get stuck at a sub-optimal solution. When the index vectors are orthogonal, we give a complete characterization of the fixed points and prove that neurons converge to the nearest index vectors. Therefore, using $n \\! \\asymp \\! k \\log k$ neurons ensures finding the full set of index vectors with gradient flow with high probability over random initialization. When $ v_i^T v_j \\!=\\! \\beta \\! \\geq \\! 0$ for all $i \\neq j$, we prove the existence of a sharp threshold $\\beta_c \\!=\\! c/(c+k)$ at which the fixed point that computes the average of the index vectors transitions from a saddle point to a minimum. Numerical simulations show that using a correlation loss and a mild overparameterization suffices to learn all of the index vectors when they are nearly orthogonal, however, the correlation loss fails when the dot product between the index vectors exceeds a certain threshold.","sentences":["This work focuses on the gradient flow dynamics of a neural network model that uses correlation loss to approximate a multi-index function on high-dimensional standard Gaussian data.","Specifically, the multi-index function we consider is a sum of neurons $f^*(x) \\!=\\!","\\sum_{j=1}^k \\!","\\sigma^*(v_j^T x)$ where $v_1, \\dots, v_k$ are unit vectors, and $\\sigma^*$ lacks the first and second Hermite polynomials in its Hermite expansion.","It is known that, for the single-index case ($k\\!=\\!1$), overcoming the search phase requires polynomial time complexity.","We first generalize this result to multi-index functions characterized by vectors in arbitrary directions.","After the search phase, it is not clear whether the network neurons converge to the index vectors, or get stuck at a sub-optimal solution.","When the index vectors are orthogonal, we give a complete characterization of the fixed points and prove that neurons converge to the nearest index vectors.","Therefore, using $n \\!","\\asymp \\!","k \\log k$ neurons ensures finding the full set of index vectors with gradient flow with high probability over random initialization.","When $ v_i^T v_j \\!=\\!","\\beta \\!","\\geq \\!","0$ for all $i \\neq j$, we prove the existence of a sharp threshold $\\beta_c \\!=\\!","c/(c+k)$ at which the fixed point that computes the average of the index vectors transitions from a saddle point to a minimum.","Numerical simulations show that using a correlation loss and a mild overparameterization suffices to learn all of the index vectors when they are nearly orthogonal, however, the correlation loss fails when the dot product between the index vectors exceeds a certain threshold."],"url":"http://arxiv.org/abs/2411.08798v1"}
{"created":"2024-11-13 17:17:52","title":"An alignment problem","abstract":"This work concerns an alignment problem that has applications in many geospatial problems such as resource allocation and building reliable disease maps. Here, we introduce the problem of optimally aligning $k$ collections of $m$ spatial supports over $n$ spatial units in a $d$-dimensional Euclidean space. We show that the 1-dimensional case is solvable in time polynomial in $k$, $m$ and $n$. We then show that the 2-dimensional case is NP-hard for 2 collections of 2 supports. Finally, we devise a heuristic for aligning a set of collections in the 2-dimensional case.","sentences":["This work concerns an alignment problem that has applications in many geospatial problems such as resource allocation and building reliable disease maps.","Here, we introduce the problem of optimally aligning $k$ collections of $m$ spatial supports over $n$ spatial units in a $d$-dimensional Euclidean space.","We show that the 1-dimensional case is solvable in time polynomial in $k$, $m$ and $n$. We then show that the 2-dimensional case is NP-hard for 2 collections of 2 supports.","Finally, we devise a heuristic for aligning a set of collections in the 2-dimensional case."],"url":"http://arxiv.org/abs/2411.08792v1"}
{"created":"2024-11-13 17:17:16","title":"Locally Private Sampling with Public Data","abstract":"Local differential privacy (LDP) is increasingly employed in privacy-preserving machine learning to protect user data before sharing it with an untrusted aggregator. Most LDP methods assume that users possess only a single data record, which is a significant limitation since users often gather extensive datasets (e.g., images, text, time-series data) and frequently have access to public datasets. To address this limitation, we propose a locally private sampling framework that leverages both the private and public datasets of each user. Specifically, we assume each user has two distributions: $p$ and $q$ that represent their private dataset and the public dataset, respectively. The objective is to design a mechanism that generates a private sample approximating $p$ while simultaneously preserving $q$. We frame this objective as a minimax optimization problem using $f$-divergence as the utility measure. We fully characterize the minimax optimal mechanisms for general $f$-divergences provided that $p$ and $q$ are discrete distributions. Remarkably, we demonstrate that this optimal mechanism is universal across all $f$-divergences. Experiments validate the effectiveness of our minimax optimal sampler compared to the state-of-the-art locally private sampler.","sentences":["Local differential privacy (LDP) is increasingly employed in privacy-preserving machine learning to protect user data before sharing it with an untrusted aggregator.","Most LDP methods assume that users possess only a single data record, which is a significant limitation since users often gather extensive datasets (e.g., images, text, time-series data) and frequently have access to public datasets.","To address this limitation, we propose a locally private sampling framework that leverages both the private and public datasets of each user.","Specifically, we assume each user has two distributions: $p$ and $q$ that represent their private dataset and the public dataset, respectively.","The objective is to design a mechanism that generates a private sample approximating $p$ while simultaneously preserving $q$. We frame this objective as a minimax optimization problem using $f$-divergence as the utility measure.","We fully characterize the minimax optimal mechanisms for general $f$-divergences provided that $p$ and $q$ are discrete distributions.","Remarkably, we demonstrate that this optimal mechanism is universal across all $f$-divergences.","Experiments validate the effectiveness of our minimax optimal sampler compared to the state-of-the-art locally private sampler."],"url":"http://arxiv.org/abs/2411.08791v1"}
{"created":"2024-11-13 17:13:25","title":"Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training","abstract":"The majority of previous researches addressing multi-lingual IE are limited to zero-shot cross-lingual single-transfer (one-to-one) setting, with high-resource languages predominantly as source training data. As a result, these works provide little understanding and benefit for the realistic goal of developing a multi-lingual IE system that can generalize to as many languages as possible. Our study aims to fill this gap by providing a detailed analysis on Cross-Lingual Multi-Transferability (many-to-many transfer learning), for the recent IE corpora that cover a diverse set of languages. Specifically, we first determine the correlation between single-transfer performance and a wide range of linguistic-based distances. From the obtained insights, a combined language distance metric can be developed that is not only highly correlated but also robust across different tasks and model scales. Next, we investigate the more general zero-shot multi-lingual transfer settings where multiple languages are involved in the training and evaluation processes. Language clustering based on the newly defined distance can provide directions for achieving the optimal cost-performance trade-off in data (languages) selection problem. Finally, a relational-transfer setting is proposed to further incorporate multi-lingual unlabeled data based on adversarial training using the relation induced from the above linguistic distance.","sentences":["The majority of previous researches addressing multi-lingual IE are limited to zero-shot cross-lingual single-transfer (one-to-one) setting, with high-resource languages predominantly as source training data.","As a result, these works provide little understanding and benefit for the realistic goal of developing a multi-lingual IE system that can generalize to as many languages as possible.","Our study aims to fill this gap by providing a detailed analysis on Cross-Lingual Multi-Transferability (many-to-many transfer learning), for the recent IE corpora that cover a diverse set of languages.","Specifically, we first determine the correlation between single-transfer performance and a wide range of linguistic-based distances.","From the obtained insights, a combined language distance metric can be developed that is not only highly correlated but also robust across different tasks and model scales.","Next, we investigate the more general zero-shot multi-lingual transfer settings where multiple languages are involved in the training and evaluation processes.","Language clustering based on the newly defined distance can provide directions for achieving the optimal cost-performance trade-off in data (languages) selection problem.","Finally, a relational-transfer setting is proposed to further incorporate multi-lingual unlabeled data based on adversarial training using the relation induced from the above linguistic distance."],"url":"http://arxiv.org/abs/2411.08785v1"}
{"created":"2024-11-13 16:58:51","title":"Optimal Oblivious Subspace Embeddings with Near-optimal Sparsity","abstract":"An oblivious subspace embedding is a random $m\\times n$ matrix $\\Pi$ such that, for any $d$-dimensional subspace, with high probability $\\Pi$ preserves the norms of all vectors in that subspace within a $1\\pm\\epsilon$ factor. In this work, we give an oblivious subspace embedding with the optimal dimension $m=\\Theta(d/\\epsilon^2)$ that has a near-optimal sparsity of $\\tilde O(1/\\epsilon)$ non-zero entries per column of $\\Pi$. This is the first result to nearly match the conjecture of Nelson and Nguyen [FOCS 2013] in terms of the best sparsity attainable by an optimal oblivious subspace embedding, improving on a prior bound of $\\tilde O(1/\\epsilon^6)$ non-zeros per column [Chenakkod et al., STOC 2024]. We further extend our approach to the non-oblivious setting, proposing a new family of Leverage Score Sparsified embeddings with Independent Columns, which yield faster runtimes for matrix approximation and regression tasks.   In our analysis, we develop a new method which uses a decoupling argument together with the cumulant method for bounding the edge universality error of isotropic random matrices. To achieve near-optimal sparsity, we combine this general-purpose approach with new traces inequalities that leverage the specific structure of our subspace embedding construction.","sentences":["An oblivious subspace embedding is a random $m\\times n$ matrix $\\Pi$ such that, for any $d$-dimensional subspace, with high probability $\\Pi$ preserves the norms of all vectors in that subspace within a $1\\pm\\epsilon$ factor.","In this work, we give an oblivious subspace embedding with the optimal dimension $m=\\Theta(d/\\epsilon^2)$ that has a near-optimal sparsity of $\\tilde O(1/\\epsilon)$ non-zero entries per column of $\\Pi$. This is the first result to nearly match the conjecture of Nelson and Nguyen","[FOCS 2013] in terms of the best sparsity attainable by an optimal oblivious subspace embedding, improving on a prior bound of $\\tilde O(1/\\epsilon^6)$ non-zeros per column [Chenakkod et al., STOC 2024].","We further extend our approach to the non-oblivious setting, proposing a new family of Leverage Score Sparsified embeddings with Independent Columns, which yield faster runtimes for matrix approximation and regression tasks.   ","In our analysis, we develop a new method which uses a decoupling argument together with the cumulant method for bounding the edge universality error of isotropic random matrices.","To achieve near-optimal sparsity, we combine this general-purpose approach with new traces inequalities that leverage the specific structure of our subspace embedding construction."],"url":"http://arxiv.org/abs/2411.08773v1"}
{"created":"2024-11-13 16:53:29","title":"Sharingan: Extract User Action Sequence from Desktop Recordings","abstract":"Video recordings of user activities, particularly desktop recordings, offer a rich source of data for understanding user behaviors and automating processes. However, despite advancements in Vision-Language Models (VLMs) and their increasing use in video analysis, extracting user actions from desktop recordings remains an underexplored area. This paper addresses this gap by proposing two novel VLM-based methods for user action extraction: the Direct Frame-Based Approach (DF), which inputs sampled frames directly into VLMs, and the Differential Frame-Based Approach (DiffF), which incorporates explicit frame differences detected via computer vision techniques. We evaluate these methods using a basic self-curated dataset and an advanced benchmark adapted from prior work. Our results show that the DF approach achieves an accuracy of 70% to 80% in identifying user actions, with the extracted action sequences being re-playable though Robotic Process Automation. We find that while VLMs show potential, incorporating explicit UI changes can degrade performance, making the DF approach more reliable. This work represents the first application of VLMs for extracting user action sequences from desktop recordings, contributing new methods, benchmarks, and insights for future research.","sentences":["Video recordings of user activities, particularly desktop recordings, offer a rich source of data for understanding user behaviors and automating processes.","However, despite advancements in Vision-Language Models (VLMs) and their increasing use in video analysis, extracting user actions from desktop recordings remains an underexplored area.","This paper addresses this gap by proposing two novel VLM-based methods for user action extraction: the Direct Frame-Based Approach (DF), which inputs sampled frames directly into VLMs, and the Differential Frame-Based Approach (DiffF), which incorporates explicit frame differences detected via computer vision techniques.","We evaluate these methods using a basic self-curated dataset and an advanced benchmark adapted from prior work.","Our results show that the DF approach achieves an accuracy of 70% to 80% in identifying user actions, with the extracted action sequences being re-playable though Robotic Process Automation.","We find that while VLMs show potential, incorporating explicit UI changes can degrade performance, making the DF approach more reliable.","This work represents the first application of VLMs for extracting user action sequences from desktop recordings, contributing new methods, benchmarks, and insights for future research."],"url":"http://arxiv.org/abs/2411.08768v1"}
{"created":"2024-11-13 16:52:30","title":"Mapping Methane -- The Impact of Dairy Farm Practices on Emissions Through Satellite Data and Machine Learning","abstract":"This study investigates the correlation between dairy farm characteristics and methane concentrations as derived from satellite observations in Eastern Canada. Utilizing data from 11 dairy farms collected between January 2020 and December 2022, we integrated Sentinel-5P satellite methane data with critical farm-level attributes, including herd genetics, feeding practices, and management strategies. Initial analyses revealed significant correlations with methane concentrations, leading to the application of Variance Inflation Factor (VIF) and Principal Component Analysis (PCA) to address multicollinearity and enhance model stability. Subsequently, machine learning models - specifically Random Forest and Neural Networks - were employed to evaluate feature importance and predict methane emissions. Our findings indicate a strong negative correlation between the Estimated Breeding Value (EBV) for protein percentage and methane concentrations, suggesting that genetic selection for higher milk protein content could be an effective strategy for emissions reduction. The integration of atmospheric transport models with satellite data further refined our emission estimates, significantly enhancing accuracy and spatial resolution. This research underscores the potential of advanced satellite monitoring, machine learning techniques, and atmospheric modeling in improving methane emission assessments within the dairy sector. It emphasizes the critical role of farm-specific characteristics in developing effective mitigation strategies. Future investigations should focus on expanding the dataset and incorporating inversion modeling for more precise emission quantification. Balancing ecological impacts with economic viability will be essential for fostering sustainable dairy farming practices.","sentences":["This study investigates the correlation between dairy farm characteristics and methane concentrations as derived from satellite observations in Eastern Canada.","Utilizing data from 11 dairy farms collected between January 2020 and December 2022, we integrated Sentinel-5P satellite methane data with critical farm-level attributes, including herd genetics, feeding practices, and management strategies.","Initial analyses revealed significant correlations with methane concentrations, leading to the application of Variance Inflation Factor (VIF) and Principal Component Analysis (PCA) to address multicollinearity and enhance model stability.","Subsequently, machine learning models - specifically Random Forest and Neural Networks - were employed to evaluate feature importance and predict methane emissions.","Our findings indicate a strong negative correlation between the Estimated Breeding Value (EBV) for protein percentage and methane concentrations, suggesting that genetic selection for higher milk protein content could be an effective strategy for emissions reduction.","The integration of atmospheric transport models with satellite data further refined our emission estimates, significantly enhancing accuracy and spatial resolution.","This research underscores the potential of advanced satellite monitoring, machine learning techniques, and atmospheric modeling in improving methane emission assessments within the dairy sector.","It emphasizes the critical role of farm-specific characteristics in developing effective mitigation strategies.","Future investigations should focus on expanding the dataset and incorporating inversion modeling for more precise emission quantification.","Balancing ecological impacts with economic viability will be essential for fostering sustainable dairy farming practices."],"url":"http://arxiv.org/abs/2411.08766v1"}
{"created":"2024-11-13 16:49:56","title":"Flow reconstruction in time-varying geometries using graph neural networks","abstract":"The paper presents a Graph Attention Convolutional Network (GACN) for flow reconstruction from very sparse data in time-varying geometries. The model incorporates a feature propagation algorithm as a preprocessing step to handle extremely sparse inputs, leveraging information from neighboring nodes to initialize missing features. In addition, a binary indicator is introduced as a validity mask to distinguish between the original and propagated data points, enabling more effective learning from sparse inputs. Trained on a unique data set of Direct Numerical Simulations (DNS) of a motored engine at a technically relevant operating condition, the GACN shows robust performance across different resolutions and domain sizes and can effectively handle unstructured data and variable input sizes. The model is tested on previously unseen DNS data as well as on an experimental data set from Particle Image Velocimetry (PIV) measurements that were not considered during training. A comparative analysis shows that the GACN consistently outperforms both a conventional Convolutional Neural Network (CNN) and cubic interpolation methods on the DNS and PIV test sets by achieving lower reconstruction errors and better capturing fine-scale turbulent structures. In particular, the GACN effectively reconstructs flow fields from domains up to 14 times larger than those observed during training, with the performance advantage increasing for larger domains.","sentences":["The paper presents a Graph Attention Convolutional Network (GACN) for flow reconstruction from very sparse data in time-varying geometries.","The model incorporates a feature propagation algorithm as a preprocessing step to handle extremely sparse inputs, leveraging information from neighboring nodes to initialize missing features.","In addition, a binary indicator is introduced as a validity mask to distinguish between the original and propagated data points, enabling more effective learning from sparse inputs.","Trained on a unique data set of Direct Numerical Simulations (DNS) of a motored engine at a technically relevant operating condition, the GACN shows robust performance across different resolutions and domain sizes and can effectively handle unstructured data and variable input sizes.","The model is tested on previously unseen DNS data as well as on an experimental data set from Particle Image Velocimetry (PIV) measurements that were not considered during training.","A comparative analysis shows that the GACN consistently outperforms both a conventional Convolutional Neural Network (CNN) and cubic interpolation methods on the DNS and PIV test sets by achieving lower reconstruction errors and better capturing fine-scale turbulent structures.","In particular, the GACN effectively reconstructs flow fields from domains up to 14 times larger than those observed during training, with the performance advantage increasing for larger domains."],"url":"http://arxiv.org/abs/2411.08764v1"}
{"created":"2024-11-13 16:42:59","title":"ScaleNet: Scale Invariance Learning in Directed Graphs","abstract":"Graph Neural Networks (GNNs) have advanced relational data analysis but lack invariance learning techniques common in image classification. In node classification with GNNs, it is actually the ego-graph of the center node that is classified. This research extends the scale invariance concept to node classification by drawing an analogy to image processing: just as scale invariance being used in image classification to capture multi-scale features, we propose the concept of ``scaled ego-graphs''. Scaled ego-graphs generalize traditional ego-graphs by replacing undirected single-edges with ``scaled-edges'', which are ordered sequences of multiple directed edges. We empirically assess the performance of the proposed scale invariance in graphs on seven benchmark datasets, across both homophilic and heterophilic structures. Our scale-invariance-based graph learning outperforms inception models derived from random walks by being simpler, faster, and more accurate. The scale invariance explains inception models' success on homophilic graphs and limitations on heterophilic graphs. To ensure applicability of inception model to heterophilic graphs as well, we further present ScaleNet, an architecture that leverages multi-scaled features. ScaleNet achieves state-of-the-art results on five out of seven datasets (four homophilic and one heterophilic) and matches top performance on the remaining two, demonstrating its excellent applicability. This represents a significant advance in graph learning, offering a unified framework that enhances node classification across various graph types. Our code is available at https://github.com/Qin87/ScaleNet/tree/July25.","sentences":["Graph Neural Networks (GNNs) have advanced relational data analysis but lack invariance learning techniques common in image classification.","In node classification with GNNs, it is actually the ego-graph of the center node that is classified.","This research extends the scale invariance concept to node classification by drawing an analogy to image processing: just as scale invariance being used in image classification to capture multi-scale features, we propose the concept of ``scaled ego-graphs''.","Scaled ego-graphs generalize traditional ego-graphs by replacing undirected single-edges with ``scaled-edges'', which are ordered sequences of multiple directed edges.","We empirically assess the performance of the proposed scale invariance in graphs on seven benchmark datasets, across both homophilic and heterophilic structures.","Our scale-invariance-based graph learning outperforms inception models derived from random walks by being simpler, faster, and more accurate.","The scale invariance explains inception models' success on homophilic graphs and limitations on heterophilic graphs.","To ensure applicability of inception model to heterophilic graphs as well, we further present ScaleNet, an architecture that leverages multi-scaled features.","ScaleNet achieves state-of-the-art results on five out of seven datasets (four homophilic and one heterophilic) and matches top performance on the remaining two, demonstrating its excellent applicability.","This represents a significant advance in graph learning, offering a unified framework that enhances node classification across various graph types.","Our code is available at https://github.com/Qin87/ScaleNet/tree/July25."],"url":"http://arxiv.org/abs/2411.08758v1"}
{"created":"2024-11-13 16:42:07","title":"Masked Image Modeling Boosting Semi-Supervised Semantic Segmentation","abstract":"In view of the fact that semi- and self-supervised learning share a fundamental principle, effectively modeling knowledge from unlabeled data, various semi-supervised semantic segmentation methods have integrated representative self-supervised learning paradigms for further regularization. However, the potential of the state-of-the-art generative self-supervised paradigm, masked image modeling, has been scarcely studied. This paradigm learns the knowledge through establishing connections between the masked and visible parts of masked image, during the pixel reconstruction process. By inheriting and extending this insight, we successfully leverage masked image modeling to boost semi-supervised semantic segmentation. Specifically, we introduce a novel class-wise masked image modeling that independently reconstructs different image regions according to their respective classes. In this way, the mask-induced connections are established within each class, mitigating the semantic confusion that arises from plainly reconstructing images in basic masked image modeling. To strengthen these intra-class connections, we further develop a feature aggregation strategy that minimizes the distances between features corresponding to the masked and visible parts within the same class. Additionally, in semantic space, we explore the application of masked image modeling to enhance regularization. Extensive experiments conducted on well-known benchmarks demonstrate that our approach achieves state-of-the-art performance. The code will be available at https://github.com/haoxt/S4MIM.","sentences":["In view of the fact that semi- and self-supervised learning share a fundamental principle, effectively modeling knowledge from unlabeled data, various semi-supervised semantic segmentation methods have integrated representative self-supervised learning paradigms for further regularization.","However, the potential of the state-of-the-art generative self-supervised paradigm, masked image modeling, has been scarcely studied.","This paradigm learns the knowledge through establishing connections between the masked and visible parts of masked image, during the pixel reconstruction process.","By inheriting and extending this insight, we successfully leverage masked image modeling to boost semi-supervised semantic segmentation.","Specifically, we introduce a novel class-wise masked image modeling that independently reconstructs different image regions according to their respective classes.","In this way, the mask-induced connections are established within each class, mitigating the semantic confusion that arises from plainly reconstructing images in basic masked image modeling.","To strengthen these intra-class connections, we further develop a feature aggregation strategy that minimizes the distances between features corresponding to the masked and visible parts within the same class.","Additionally, in semantic space, we explore the application of masked image modeling to enhance regularization.","Extensive experiments conducted on well-known benchmarks demonstrate that our approach achieves state-of-the-art performance.","The code will be available at https://github.com/haoxt/S4MIM."],"url":"http://arxiv.org/abs/2411.08756v1"}
{"created":"2024-11-13 16:10:14","title":"Polymetis:Large Language Modeling for Multiple Material Domains","abstract":"As the application of large language models in various fields continues to expand, materials science also ushers in opportunities for AI-driven innovation. The traditional way of relying on manual search for materials science-related information is now using artificial intelligence technology as an auxiliary tool to improve the efficiency of materials science research. To accelerate researchers' knowledge acquisition and intelligent decision-making support in materials science research, this paper proposes a large language model Polymetis model for a variety of materials fields, aiming to provide highly professional knowledge answers in the field of materials, covering energy materials, functional materials, alloy materials, physical chemistry, biology, and other material directions. The model uses a dataset of about 2 million material knowledge instructions, and in the process of building the dataset, we developed the Intelligent Extraction Large Model (IELM), which is specially used to extract and form structured knowledge from scientific texts, avoiding a large number of costs that need to be manually annotated, and improving efficiency. We inject this data into the GLM4-9B model for learning to enhance its inference capabilities in a variety of material domains. In addition, we have introduced enhanced prompt strategies to ensure that the answers to the model are more organized and comprehensive, providing efficient and comprehensive intelligent support for the diverse needs of materials science exploration, and promoting the development of material science.","sentences":["As the application of large language models in various fields continues to expand, materials science also ushers in opportunities for AI-driven innovation.","The traditional way of relying on manual search for materials science-related information is now using artificial intelligence technology as an auxiliary tool to improve the efficiency of materials science research.","To accelerate researchers' knowledge acquisition and intelligent decision-making support in materials science research, this paper proposes a large language model Polymetis model for a variety of materials fields, aiming to provide highly professional knowledge answers in the field of materials, covering energy materials, functional materials, alloy materials, physical chemistry, biology, and other material directions.","The model uses a dataset of about 2 million material knowledge instructions, and in the process of building the dataset, we developed the Intelligent Extraction Large Model (IELM), which is specially used to extract and form structured knowledge from scientific texts, avoiding a large number of costs that need to be manually annotated, and improving efficiency.","We inject this data into the GLM4-9B model for learning to enhance its inference capabilities in a variety of material domains.","In addition, we have introduced enhanced prompt strategies to ensure that the answers to the model are more organized and comprehensive, providing efficient and comprehensive intelligent support for the diverse needs of materials science exploration, and promoting the development of material science."],"url":"http://arxiv.org/abs/2411.08728v1"}
{"created":"2024-11-13 15:59:15","title":"Short note on the mapping of heritage sites impacted by the 2024 floods in Valencia, Spain","abstract":"This short note presents preliminary findings on the impact of the October 2024 floods on cultural heritage sites in Valencia, Spain. Using publicly available data, we assess the extent of potential damage by overlaying flood maps with heritage site coordinates. We identify that 3.3\\% of heritage sites in the region have been potentially impacted, with churches and shrines (81), outdoor religious iconography (78), and historic irrigation features (45) being the most heavily affected. Our analysis utilizes data from OpenStreetMap and listings from the Generalitat Valenciana, suggesting that while OpenStreetMap's crowd-sourced data can provide useful estimates of the proportion of impacted sites, it may not be suitable for a detailed damage assessment. By sharing this data openly, we aim to contribute to international efforts in preserving cultural heritage after the disaster and provide a foundation for future assessments of heritage site vulnerability to climate-related events.","sentences":["This short note presents preliminary findings on the impact of the October 2024 floods on cultural heritage sites in Valencia, Spain.","Using publicly available data, we assess the extent of potential damage by overlaying flood maps with heritage site coordinates.","We identify that 3.3\\% of heritage sites in the region have been potentially impacted, with churches and shrines (81), outdoor religious iconography (78), and historic irrigation features (45) being the most heavily affected.","Our analysis utilizes data from OpenStreetMap and listings from the Generalitat Valenciana, suggesting that while OpenStreetMap's crowd-sourced data can provide useful estimates of the proportion of impacted sites, it may not be suitable for a detailed damage assessment.","By sharing this data openly, we aim to contribute to international efforts in preserving cultural heritage after the disaster and provide a foundation for future assessments of heritage site vulnerability to climate-related events."],"url":"http://arxiv.org/abs/2411.08717v1"}
{"created":"2024-11-13 15:55:05","title":"High-resolution optical and acoustic remote sensing datasets of the Puck Lagoon, Southern Baltic","abstract":"The very shallow marine basin of Puck Lagoon in the southern Baltic Sea, on the Northern coast of Poland, hosts valuable benthic habitats and cultural heritage sites. These include, among others, protected Zostera marina meadows, one of the Baltic's major medieval harbours, a ship graveyard, and likely other submerged features that are yet to be discovered. Prior to this project, no comprehensive high-resolution remote sensing data were available for this area. This article describes the first Digital Elevation Models (DEMs) derived from a combination of airborne bathymetric LiDAR, multibeam echosounder, airborne photogrammetry and satellite imagery. These datasets also include multibeam echosounder backscatter and LiDAR intensity, allowing determination of the character and properties of the seafloor. Combined, these datasets are a vital resource for assessing and understanding seafloor morphology, benthic habitats, cultural heritage, and submerged landscapes. Given the significance of Puck Lagoon's hydrographical, ecological, geological, and archaeological environs, the high-resolution bathymetry, acquired by our project, can provide the foundation for sustainable management and informed decision-making for this area of interest.","sentences":["The very shallow marine basin of Puck Lagoon in the southern Baltic Sea, on the Northern coast of Poland, hosts valuable benthic habitats and cultural heritage sites.","These include, among others, protected Zostera marina meadows, one of the Baltic's major medieval harbours, a ship graveyard, and likely other submerged features that are yet to be discovered.","Prior to this project, no comprehensive high-resolution remote sensing data were available for this area.","This article describes the first Digital Elevation Models (DEMs) derived from a combination of airborne bathymetric LiDAR, multibeam echosounder, airborne photogrammetry and satellite imagery.","These datasets also include multibeam echosounder backscatter and LiDAR intensity, allowing determination of the character and properties of the seafloor.","Combined, these datasets are a vital resource for assessing and understanding seafloor morphology, benthic habitats, cultural heritage, and submerged landscapes.","Given the significance of Puck Lagoon's hydrographical, ecological, geological, and archaeological environs, the high-resolution bathymetry, acquired by our project, can provide the foundation for sustainable management and informed decision-making for this area of interest."],"url":"http://arxiv.org/abs/2411.08712v1"}
{"created":"2024-11-13 15:50:38","title":"Are Triggers Needed for Document-Level Event Extraction?","abstract":"Most existing work on event extraction has focused on sentence-level texts and presumes the identification of a trigger-span -- a word or phrase in the input that evokes the occurrence of an event of interest. Event arguments are then extracted with respect to the trigger. Indeed, triggers are treated as integral to, and trigger detection as an essential component of, event extraction. In this paper, we provide the first investigation of the role of triggers for the more difficult and much less studied task of document-level event extraction. We analyze their usefulness in multiple end-to-end and pipelined neural event extraction models for three document-level event extraction datasets, measuring performance using triggers of varying quality (human-annotated, LLM-generated, keyword-based, and random). Our research shows that trigger effectiveness varies based on the extraction task's characteristics and data quality, with basic, automatically-generated triggers serving as a viable alternative to human-annotated ones. Furthermore, providing detailed event descriptions to the extraction model helps maintain robust performance even when trigger quality degrades. Perhaps surprisingly, we also find that the mere existence of trigger input, even random ones, is important for prompt-based LLM approaches to the task.","sentences":["Most existing work on event extraction has focused on sentence-level texts and presumes the identification of a trigger-span -- a word or phrase in the input that evokes the occurrence of an event of interest.","Event arguments are then extracted with respect to the trigger.","Indeed, triggers are treated as integral to, and trigger detection as an essential component of, event extraction.","In this paper, we provide the first investigation of the role of triggers for the more difficult and much less studied task of document-level event extraction.","We analyze their usefulness in multiple end-to-end and pipelined neural event extraction models for three document-level event extraction datasets, measuring performance using triggers of varying quality (human-annotated, LLM-generated, keyword-based, and random).","Our research shows that trigger effectiveness varies based on the extraction task's characteristics and data quality, with basic, automatically-generated triggers serving as a viable alternative to human-annotated ones.","Furthermore, providing detailed event descriptions to the extraction model helps maintain robust performance even when trigger quality degrades.","Perhaps surprisingly, we also find that the mere existence of trigger input, even random ones, is important for prompt-based LLM approaches to the task."],"url":"http://arxiv.org/abs/2411.08708v1"}
{"created":"2024-11-13 15:45:46","title":"MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification","abstract":"The distinct characteristics of multiomics data, including complex interactions within and across biological layers and disease heterogeneity (e.g., heterogeneity in etiology and clinical symptoms), drive us to develop novel designs to address unique challenges in multiomics prediction. In this paper, we propose the multi-view knowledge transfer learning (MVKTrans) framework, which transfers intra- and inter-omics knowledge in an adaptive manner by reviewing data heterogeneity and suppressing bias transfer, thereby enhancing classification performance. Specifically, we design a graph contrastive module that is trained on unlabeled data to effectively learn and transfer the underlying intra-omics patterns to the supervised task. This unsupervised pretraining promotes learning general and unbiased representations for each modality, regardless of the downstream tasks. In light of the varying discriminative capacities of modalities across different diseases and/or samples, we introduce an adaptive and bi-directional cross-omics distillation module. This module automatically identifies richer modalities and facilitates dynamic knowledge transfer from more informative to less informative omics, thereby enabling a more robust and generalized integration. Extensive experiments on four real biomedical datasets demonstrate the superior performance and robustness of MVKTrans compared to the state-of-the-art. Code and data are available at https://github.com/Yaolab-fantastic/MVKTrans.","sentences":["The distinct characteristics of multiomics data, including complex interactions within and across biological layers and disease heterogeneity (e.g., heterogeneity in etiology and clinical symptoms), drive us to develop novel designs to address unique challenges in multiomics prediction.","In this paper, we propose the multi-view knowledge transfer learning (MVKTrans) framework, which transfers intra- and inter-omics knowledge in an adaptive manner by reviewing data heterogeneity and suppressing bias transfer, thereby enhancing classification performance.","Specifically, we design a graph contrastive module that is trained on unlabeled data to effectively learn and transfer the underlying intra-omics patterns to the supervised task.","This unsupervised pretraining promotes learning general and unbiased representations for each modality, regardless of the downstream tasks.","In light of the varying discriminative capacities of modalities across different diseases and/or samples, we introduce an adaptive and bi-directional cross-omics distillation module.","This module automatically identifies richer modalities and facilitates dynamic knowledge transfer from more informative to less informative omics, thereby enabling a more robust and generalized integration.","Extensive experiments on four real biomedical datasets demonstrate the superior performance and robustness of MVKTrans compared to the state-of-the-art.","Code and data are available at https://github.com/Yaolab-fantastic/MVKTrans."],"url":"http://arxiv.org/abs/2411.08703v1"}
{"created":"2024-11-13 15:42:28","title":"TRACE: Transformer-based Risk Assessment for Clinical Evaluation","abstract":"We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation), a novel method for clinical risk assessment based on clinical data, leveraging the self-attention mechanism for enhanced feature interaction and result interpretation. Our approach is able to handle different data modalities, including continuous, categorical and multiple-choice (checkbox) attributes. The proposed architecture features a shared representation of the clinical data obtained by integrating specialized embeddings of each data modality, enabling the detection of high-risk individuals using Transformer encoder layers. To assess the effectiveness of the proposed method, a strong baseline based on non-negative multi-layer perceptrons (MLPs) is introduced. The proposed method outperforms various baselines widely used in the domain of clinical risk assessment, while effectively handling missing values. In terms of explainability, our Transformer-based method offers easily interpretable results via attention weights, further enhancing the clinicians' decision-making process.","sentences":["We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation), a novel method for clinical risk assessment based on clinical data, leveraging the self-attention mechanism for enhanced feature interaction and result interpretation.","Our approach is able to handle different data modalities, including continuous, categorical and multiple-choice (checkbox) attributes.","The proposed architecture features a shared representation of the clinical data obtained by integrating specialized embeddings of each data modality, enabling the detection of high-risk individuals using Transformer encoder layers.","To assess the effectiveness of the proposed method, a strong baseline based on non-negative multi-layer perceptrons (MLPs) is introduced.","The proposed method outperforms various baselines widely used in the domain of clinical risk assessment, while effectively handling missing values.","In terms of explainability, our Transformer-based method offers easily interpretable results via attention weights, further enhancing the clinicians' decision-making process."],"url":"http://arxiv.org/abs/2411.08701v1"}
{"created":"2024-11-13 15:42:09","title":"FedSub: Introducing class-aware Subnetworks Fusion to Enhance Personalized Federated Learning in Ubiquitous Systems","abstract":"Personalized Federated Learning is essential in AI-driven ubiquitous systems, supporting the distributed development of models able to adapt to diverse and evolving user behaviors while safeguarding privacy. Despite addressing heterogeneous user data distributions in collaborative model training, existing methods often face limitations balancing personalization and generalization, oversimplifying user similarities, or relying heavily on global models. In this paper, we propose FedSub, a novel federated approach designed to enhance personalization through the use of class-aware prototypes and model subnetworks. Prototypes serve as compact representations of user data, clustered on the server to identify similarities based on specific label patterns. Concurrently, subnetworks -- model components necessary to process each class -- are extracted locally and fused by the server according to these clusters, producing highly tailored model updates for each user. This fine-grained, class-specific aggregation of clients' models allows FedSub to capture the unique characteristics of individual user data patterns. The effectiveness of FedSub is validated in three real-world scenarios characterized by high data heterogeneity, derived from human activity recognition and mobile health applications. Experimental evaluations demonstrate FedSub's performance improvements with respect to the state-of-the-art and significant advancements in personalization for ubiquitous systems based on personal mobile and wearable devices.","sentences":["Personalized Federated Learning is essential in AI-driven ubiquitous systems, supporting the distributed development of models able to adapt to diverse and evolving user behaviors while safeguarding privacy.","Despite addressing heterogeneous user data distributions in collaborative model training, existing methods often face limitations balancing personalization and generalization, oversimplifying user similarities, or relying heavily on global models.","In this paper, we propose FedSub, a novel federated approach designed to enhance personalization through the use of class-aware prototypes and model subnetworks.","Prototypes serve as compact representations of user data, clustered on the server to identify similarities based on specific label patterns.","Concurrently, subnetworks -- model components necessary to process each class -- are extracted locally and fused by the server according to these clusters, producing highly tailored model updates for each user.","This fine-grained, class-specific aggregation of clients' models allows FedSub to capture the unique characteristics of individual user data patterns.","The effectiveness of FedSub is validated in three real-world scenarios characterized by high data heterogeneity, derived from human activity recognition and mobile health applications.","Experimental evaluations demonstrate FedSub's performance improvements with respect to the state-of-the-art and significant advancements in personalization for ubiquitous systems based on personal mobile and wearable devices."],"url":"http://arxiv.org/abs/2411.08699v1"}
{"created":"2024-11-13 15:34:52","title":"Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata using LLMs","abstract":"Several initiatives have been undertaken to conceptually model the domain of scholarly data using ontologies and to create respective Knowledge Graphs. Yet, the full potential seems unleashed, as automated means for automatic population of said ontologies are lacking, and respective initiatives from the Semantic Web community are not necessarily connected: we propose to make scholarly data more sustainably accessible by leveraging Wikidata's infrastructure and automating its population in a sustainable manner through LLMs by tapping into unstructured sources like conference Web sites and proceedings texts as well as already existing structured conference datasets. While an initial analysis shows that Semantic Web conferences are only minimally represented in Wikidata, we argue that our methodology can help to populate, evolve and maintain scholarly data as a community within Wikidata. Our main contributions include (a) an analysis of ontologies for representing scholarly data to identify gaps and relevant entities/properties in Wikidata, (b) semi-automated extraction -- requiring (minimal) manual validation -- of conference metadata (e.g., acceptance rates, organizer roles, programme committee members, best paper awards, keynotes, and sponsors) from websites and proceedings texts using LLMs. Finally, we discuss (c) extensions to visualization tools in the Wikidata context for data exploration of the generated scholarly data. Our study focuses on data from 105 Semantic Web-related conferences and extends/adds more than 6000 entities in Wikidata. It is important to note that the method can be more generally applicable beyond Semantic Web-related conferences for enhancing Wikidata's utility as a comprehensive scholarly resource.   Source Repository: https://github.com/scholarly-wikidata/   DOI: https://doi.org/10.5281/zenodo.10989709   License: Creative Commons CC0 (Data), MIT (Code)","sentences":["Several initiatives have been undertaken to conceptually model the domain of scholarly data using ontologies and to create respective Knowledge Graphs.","Yet, the full potential seems unleashed, as automated means for automatic population of said ontologies are lacking, and respective initiatives from the Semantic Web community are not necessarily connected: we propose to make scholarly data more sustainably accessible by leveraging Wikidata's infrastructure and automating its population in a sustainable manner through LLMs by tapping into unstructured sources like conference Web sites and proceedings texts as well as already existing structured conference datasets.","While an initial analysis shows that Semantic Web conferences are only minimally represented in Wikidata, we argue that our methodology can help to populate, evolve and maintain scholarly data as a community within Wikidata.","Our main contributions include (a) an analysis of ontologies for representing scholarly data to identify gaps and relevant entities/properties in Wikidata, (b) semi-automated extraction -- requiring (minimal) manual validation -- of conference metadata (e.g., acceptance rates, organizer roles, programme committee members, best paper awards, keynotes, and sponsors) from websites and proceedings texts using LLMs.","Finally, we discuss (c) extensions to visualization tools in the Wikidata context for data exploration of the generated scholarly data.","Our study focuses on data from 105 Semantic Web-related conferences and extends/adds more than 6000 entities in Wikidata.","It is important to note that the method can be more generally applicable beyond Semantic Web-related conferences for enhancing Wikidata's utility as a comprehensive scholarly resource.   ","Source Repository: https://github.com/scholarly-wikidata/   DOI: https://doi.org/10.5281/zenodo.10989709   License: Creative Commons CC0 (Data), MIT (Code)"],"url":"http://arxiv.org/abs/2411.08696v1"}
{"created":"2024-11-13 15:04:02","title":"Theoretical Analysis of Byte-Pair Encoding","abstract":"Byte-Pair Encoding (BPE) is a widely used method for subword tokenization, with origins in grammar-based text compression. It is employed in a variety of language processing tasks such as machine translation or large language model (LLM) pretraining, to create a token dictionary of a prescribed size. Most evaluations of BPE to date are empirical, and the reasons for its good practical performance are not well understood.   In this paper we focus on the optimization problem underlying BPE: finding a pair encoding that achieves optimal compression utility. We show that this problem is APX-complete, indicating that it is unlikely to admit a polynomial-time approximation scheme. This answers, in a stronger form, a question recently raised by Zouhar et al.   On the positive side, we show that BPE approximates the compression utility of the optimal pair encoding to a worst-case factor between $0.333$ and $0.625$. Our results aim to explain the ongoing success of BPE and are, to our knowledge, the first rigorous guarantees on its compression utility that hold for all inputs.","sentences":["Byte-Pair Encoding (BPE) is a widely used method for subword tokenization, with origins in grammar-based text compression.","It is employed in a variety of language processing tasks such as machine translation or large language model (LLM) pretraining, to create a token dictionary of a prescribed size.","Most evaluations of BPE to date are empirical, and the reasons for its good practical performance are not well understood.   ","In this paper we focus on the optimization problem underlying BPE: finding a pair encoding that achieves optimal compression utility.","We show that this problem is APX-complete, indicating that it is unlikely to admit a polynomial-time approximation scheme.","This answers, in a stronger form, a question recently raised by Zouhar et al.   ","On the positive side, we show that BPE approximates the compression utility of the optimal pair encoding to a worst-case factor between $0.333$ and $0.625$. Our results aim to explain the ongoing success of BPE and are, to our knowledge, the first rigorous guarantees on its compression utility that hold for all inputs."],"url":"http://arxiv.org/abs/2411.08671v1"}
{"created":"2024-11-13 14:59:41","title":"A Survey on Vision Autoregressive Model","abstract":"Autoregressive models have demonstrated great performance in natural language processing (NLP) with impressive scalability, adaptability and generalizability. Inspired by their notable success in NLP field, autoregressive models have been intensively investigated recently for computer vision, which perform next-token predictions by representing visual data as visual tokens and enables autoregressive modelling for a wide range of vision tasks, ranging from visual generation and visual understanding to the very recent multimodal generation that unifies visual generation and understanding with a single autoregressive model. This paper provides a systematic review of vision autoregressive models, including the development of a taxonomy of existing methods and highlighting their major contributions, strengths, and limitations, covering various vision tasks such as image generation, video generation, image editing, motion generation, medical image analysis, 3D generation, robotic manipulation, unified multimodal generation, etc. Besides, we investigate and analyze the latest advancements in autoregressive models, including thorough benchmarking and discussion of existing methods across various evaluation datasets. Finally, we outline key challenges and promising directions for future research, offering a roadmap to guide further advancements in vision autoregressive models.","sentences":["Autoregressive models have demonstrated great performance in natural language processing (NLP) with impressive scalability, adaptability and generalizability.","Inspired by their notable success in NLP field, autoregressive models have been intensively investigated recently for computer vision, which perform next-token predictions by representing visual data as visual tokens and enables autoregressive modelling for a wide range of vision tasks, ranging from visual generation and visual understanding to the very recent multimodal generation that unifies visual generation and understanding with a single autoregressive model.","This paper provides a systematic review of vision autoregressive models, including the development of a taxonomy of existing methods and highlighting their major contributions, strengths, and limitations, covering various vision tasks such as image generation, video generation, image editing, motion generation, medical image analysis, 3D generation, robotic manipulation, unified multimodal generation, etc.","Besides, we investigate and analyze the latest advancements in autoregressive models, including thorough benchmarking and discussion of existing methods across various evaluation datasets.","Finally, we outline key challenges and promising directions for future research, offering a roadmap to guide further advancements in vision autoregressive models."],"url":"http://arxiv.org/abs/2411.08666v1"}
{"created":"2024-11-13 14:59:00","title":"OSMLoc: Single Image-Based Visual Localization in OpenStreetMap with Geometric and Semantic Guidances","abstract":"OpenStreetMap (OSM), an online and versatile source of volunteered geographic information (VGI), is widely used for human self-localization by matching nearby visual observations with vectorized map data. However, due to the divergence in modalities and views, image-to-OSM (I2O) matching and localization remain challenging for robots, preventing the full utilization of VGI data in the unmanned ground vehicles and logistic industry. Inspired by the fact that the human brain relies on geometric and semantic understanding of sensory information for spatial localization tasks, we propose the OSMLoc in this paper. OSMLoc is a brain-inspired single-image visual localization method with semantic and geometric guidance to improve accuracy, robustness, and generalization ability. First, we equip the OSMLoc with the visual foundational model to extract powerful image features. Second, a geometry-guided depth distribution adapter is proposed to bridge the monocular depth estimation and camera-to-BEV transform. Thirdly, the semantic embeddings from the OSM data are utilized as auxiliary guidance for image-to-OSM feature matching. To validate the proposed OSMLoc, we collect a worldwide cross-area and cross-condition (CC) benchmark for extensive evaluation. Experiments on the MGL dataset, CC validation benchmark, and KITTI dataset have demonstrated the superiority of our method. Code, pre-trained models, CC validation benchmark, and additional results are available on: https://github.com/WHU-USI3DV/OSMLoc","sentences":["OpenStreetMap (OSM), an online and versatile source of volunteered geographic information (VGI), is widely used for human self-localization by matching nearby visual observations with vectorized map data.","However, due to the divergence in modalities and views, image-to-OSM (I2O) matching and localization remain challenging for robots, preventing the full utilization of VGI data in the unmanned ground vehicles and logistic industry.","Inspired by the fact that the human brain relies on geometric and semantic understanding of sensory information for spatial localization tasks, we propose the OSMLoc in this paper.","OSMLoc is a brain-inspired single-image visual localization method with semantic and geometric guidance to improve accuracy, robustness, and generalization ability.","First, we equip the OSMLoc with the visual foundational model to extract powerful image features.","Second, a geometry-guided depth distribution adapter is proposed to bridge the monocular depth estimation and camera-to-BEV transform.","Thirdly, the semantic embeddings from the OSM data are utilized as auxiliary guidance for image-to-OSM feature matching.","To validate the proposed OSMLoc, we collect a worldwide cross-area and cross-condition (CC) benchmark for extensive evaluation.","Experiments on the MGL dataset, CC validation benchmark, and KITTI dataset have demonstrated the superiority of our method.","Code, pre-trained models, CC validation benchmark, and additional results are available on: https://github.com/WHU-USI3DV/OSMLoc"],"url":"http://arxiv.org/abs/2411.08665v1"}
{"created":"2024-11-13 14:55:08","title":"UniMat: Unifying Materials Embeddings through Multi-modal Learning","abstract":"Materials science datasets are inherently heterogeneous and are available in different modalities such as characterization spectra, atomic structures, microscopic images, and text-based synthesis conditions. The advancements in multi-modal learning, particularly in vision and language models, have opened new avenues for integrating data in different forms. In this work, we evaluate common techniques in multi-modal learning (alignment and fusion) in unifying some of the most important modalities in materials science: atomic structure, X-ray diffraction patterns (XRD), and composition. We show that structure graph modality can be enhanced by aligning with XRD patterns. Additionally, we show that aligning and fusing more experimentally accessible data formats, such as XRD patterns and compositions, can create more robust joint embeddings than individual modalities across various tasks. This lays the groundwork for future studies aiming to exploit the full potential of multi-modal data in materials science, facilitating more informed decision-making in materials design and discovery.","sentences":["Materials science datasets are inherently heterogeneous and are available in different modalities such as characterization spectra, atomic structures, microscopic images, and text-based synthesis conditions.","The advancements in multi-modal learning, particularly in vision and language models, have opened new avenues for integrating data in different forms.","In this work, we evaluate common techniques in multi-modal learning (alignment and fusion) in unifying some of the most important modalities in materials science: atomic structure, X-ray diffraction patterns (XRD), and composition.","We show that structure graph modality can be enhanced by aligning with XRD patterns.","Additionally, we show that aligning and fusing more experimentally accessible data formats, such as XRD patterns and compositions, can create more robust joint embeddings than individual modalities across various tasks.","This lays the groundwork for future studies aiming to exploit the full potential of multi-modal data in materials science, facilitating more informed decision-making in materials design and discovery."],"url":"http://arxiv.org/abs/2411.08664v1"}
{"created":"2024-11-13 14:54:47","title":"Toward Human Understanding with Controllable Synthesis","abstract":"Training methods to perform robust 3D human pose and shape (HPS) estimation requires diverse training images with accurate ground truth. While BEDLAM demonstrates the potential of traditional procedural graphics to generate such data, the training images are clearly synthetic. In contrast, generative image models produce highly realistic images but without ground truth. Putting these methods together seems straightforward: use a generative model with the body ground truth as controlling signal. However, we find that, the more realistic the generated images, the more they deviate from the ground truth, making them inappropriate for training and evaluation. Enhancements of realistic details, such as clothing and facial expressions, can lead to subtle yet significant deviations from the ground truth, potentially misleading training models. We empirically verify that this misalignment causes the accuracy of HPS networks to decline when trained with generated images. To address this, we design a controllable synthesis method that effectively balances image realism with precise ground truth. We use this to create the Generative BEDLAM (Gen-B) dataset, which improves the realism of the existing synthetic BEDLAM dataset while preserving ground truth accuracy. We perform extensive experiments, with various noise-conditioning strategies, to evaluate the tradeoff between visual realism and HPS accuracy. We show, for the first time, that generative image models can be controlled by traditional graphics methods to produce training data that increases the accuracy of HPS methods.","sentences":["Training methods to perform robust 3D human pose and shape (HPS) estimation requires diverse training images with accurate ground truth.","While BEDLAM demonstrates the potential of traditional procedural graphics to generate such data, the training images are clearly synthetic.","In contrast, generative image models produce highly realistic images but without ground truth.","Putting these methods together seems straightforward: use a generative model with the body ground truth as controlling signal.","However, we find that, the more realistic the generated images, the more they deviate from the ground truth, making them inappropriate for training and evaluation.","Enhancements of realistic details, such as clothing and facial expressions, can lead to subtle yet significant deviations from the ground truth, potentially misleading training models.","We empirically verify that this misalignment causes the accuracy of HPS networks to decline when trained with generated images.","To address this, we design a controllable synthesis method that effectively balances image realism with precise ground truth.","We use this to create the Generative BEDLAM (Gen-B) dataset, which improves the realism of the existing synthetic BEDLAM dataset while preserving ground truth accuracy.","We perform extensive experiments, with various noise-conditioning strategies, to evaluate the tradeoff between visual realism and HPS accuracy.","We show, for the first time, that generative image models can be controlled by traditional graphics methods to produce training data that increases the accuracy of HPS methods."],"url":"http://arxiv.org/abs/2411.08663v1"}
{"created":"2024-11-13 14:36:12","title":"A System Level Performance Evaluation for Superconducting Digital Systems","abstract":"Superconducting Digital (SCD) technology offers significant potential for enhancing the performance of next generation large scale compute workloads. By leveraging advanced lithography and a 300 mm platform, SCD devices can reduce energy consumption and boost computational power. This paper presents a cross-layer modeling approach to evaluate the system-level performance benefits of SCD architectures for Large Language Model (LLM) training and inference. Our findings, based on experimental data and Pulse Conserving Logic (PCL) design principles, demonstrate substantial performance gain in both training and inference. We are, thus, able to convincingly show that the SCD technology can address memory and interconnect limitations of present day solutions for next-generation compute systems.","sentences":["Superconducting Digital (SCD) technology offers significant potential for enhancing the performance of next generation large scale compute workloads.","By leveraging advanced lithography and a 300 mm platform, SCD devices can reduce energy consumption and boost computational power.","This paper presents a cross-layer modeling approach to evaluate the system-level performance benefits of SCD architectures for Large Language Model (LLM) training and inference.","Our findings, based on experimental data and Pulse Conserving Logic (PCL) design principles, demonstrate substantial performance gain in both training and inference.","We are, thus, able to convincingly show that the SCD technology can address memory and interconnect limitations of present day solutions for next-generation compute systems."],"url":"http://arxiv.org/abs/2411.08645v1"}
{"created":"2024-11-13 14:32:28","title":"Towards More Accurate Fake Detection on Images Generated from Advanced Generative and Neural Rendering Models","abstract":"The remarkable progress in neural-network-driven visual data generation, especially with neural rendering techniques like Neural Radiance Fields and 3D Gaussian splatting, offers a powerful alternative to GANs and diffusion models. These methods can produce high-fidelity images and lifelike avatars, highlighting the need for robust detection methods. In response, an unsupervised training technique is proposed that enables the model to extract comprehensive features from the Fourier spectrum magnitude, thereby overcoming the challenges of reconstructing the spectrum due to its centrosymmetric properties. By leveraging the spectral domain and dynamically combining it with spatial domain information, we create a robust multimodal detector that demonstrates superior generalization capabilities in identifying challenging synthetic images generated by the latest image synthesis techniques. To address the absence of a 3D neural rendering-based fake image database, we develop a comprehensive database that includes images generated by diverse neural rendering techniques, providing a robust foundation for evaluating and advancing detection methods.","sentences":["The remarkable progress in neural-network-driven visual data generation, especially with neural rendering techniques like Neural Radiance Fields and 3D Gaussian splatting, offers a powerful alternative to GANs and diffusion models.","These methods can produce high-fidelity images and lifelike avatars, highlighting the need for robust detection methods.","In response, an unsupervised training technique is proposed that enables the model to extract comprehensive features from the Fourier spectrum magnitude, thereby overcoming the challenges of reconstructing the spectrum due to its centrosymmetric properties.","By leveraging the spectral domain and dynamically combining it with spatial domain information, we create a robust multimodal detector that demonstrates superior generalization capabilities in identifying challenging synthetic images generated by the latest image synthesis techniques.","To address the absence of a 3D neural rendering-based fake image database, we develop a comprehensive database that includes images generated by diverse neural rendering techniques, providing a robust foundation for evaluating and advancing detection methods."],"url":"http://arxiv.org/abs/2411.08642v1"}
{"created":"2024-11-13 14:26:04","title":"Gaussian Mixture Models Based Augmentation Enhances GNN Generalization","abstract":"Graph Neural Networks (GNNs) have shown great promise in tasks like node and graph classification, but they often struggle to generalize, particularly to unseen or out-of-distribution (OOD) data. These challenges are exacerbated when training data is limited in size or diversity. To address these issues, we introduce a theoretical framework using Rademacher complexity to compute a regret bound on the generalization error and then characterize the effect of data augmentation. This framework informs the design of GMM-GDA, an efficient graph data augmentation (GDA) algorithm leveraging the capability of Gaussian Mixture Models (GMMs) to approximate any distribution. Our approach not only outperforms existing augmentation techniques in terms of generalization but also offers improved time complexity, making it highly suitable for real-world applications.","sentences":["Graph Neural Networks (GNNs) have shown great promise in tasks like node and graph classification, but they often struggle to generalize, particularly to unseen or out-of-distribution (OOD) data.","These challenges are exacerbated when training data is limited in size or diversity.","To address these issues, we introduce a theoretical framework using Rademacher complexity to compute a regret bound on the generalization error and then characterize the effect of data augmentation.","This framework informs the design of GMM-GDA, an efficient graph data augmentation (GDA) algorithm leveraging the capability of Gaussian Mixture Models (GMMs) to approximate any distribution.","Our approach not only outperforms existing augmentation techniques in terms of generalization but also offers improved time complexity, making it highly suitable for real-world applications."],"url":"http://arxiv.org/abs/2411.08638v1"}
{"created":"2024-11-13 13:45:54","title":"Lo-MARVE: A Low Cost Autonomous Underwater Vehicle for Marine Exploration","abstract":"This paper presents Low-cost Marine Autonomous Robotic Vehicle Explorer (Lo-MARVE), a novel autonomous underwater vehicle (AUV) designed to provide a low cost solution for underwater exploration and environmental monitoring in shallow water environments. Lo-MARVE offers a cost-effective alternative to existing AUVs, featuring a modular design, low-cost sensors, and wireless communication capabilities. The total cost of Lo-MARVE is approximately EUR 500. Lo-MARVE is developed using the Raspberry Pi 4B microprocessor, with control software written in Python. The proposed AUV was validated through field testing outside of a laboratory setting, in the freshwater environment of the River Corrib in Galway, Ireland. This demonstrates its ability to navigate autonomously, collect data, and communicate effectively outside of a controlled laboratory setting. The successful deployment of Lo-MARVE in a real-world environment validates its proof of concept.","sentences":["This paper presents Low-cost Marine Autonomous Robotic Vehicle Explorer (Lo-MARVE), a novel autonomous underwater vehicle (AUV) designed to provide a low cost solution for underwater exploration and environmental monitoring in shallow water environments.","Lo-MARVE offers a cost-effective alternative to existing AUVs, featuring a modular design, low-cost sensors, and wireless communication capabilities.","The total cost of Lo-MARVE is approximately EUR 500.","Lo-MARVE is developed using the Raspberry Pi 4B microprocessor, with control software written in Python.","The proposed AUV was validated through field testing outside of a laboratory setting, in the freshwater environment of the River Corrib in Galway, Ireland.","This demonstrates its ability to navigate autonomously, collect data, and communicate effectively outside of a controlled laboratory setting.","The successful deployment of Lo-MARVE in a real-world environment validates its proof of concept."],"url":"http://arxiv.org/abs/2411.08605v1"}
{"created":"2024-11-13 13:40:27","title":"Generalized Pose Space Embeddings for Training In-the-Wild using Anaylis-by-Synthesis","abstract":"Modern pose estimation models are trained on large, manually-labelled datasets which are costly and may not cover the full extent of human poses and appearances in the real world. With advances in neural rendering, analysis-by-synthesis and the ability to not only predict, but also render the pose, is becoming an appealing framework, which could alleviate the need for large scale manual labelling efforts. While recent work have shown the feasibility of this approach, the predictions admit many flips due to a simplistic intermediate skeleton representation, resulting in low precision and inhibiting the acquisition of any downstream knowledge such as three-dimensional positioning. We solve this problem with a more expressive intermediate skeleton representation capable of capturing the semantics of the pose (left and right), which significantly reduces flips. To successfully train this new representation, we extend the analysis-by-synthesis framework with a training protocol based on synthetic data. We show that our representation results in less flips and more accurate predictions. Our approach outperforms previous models trained with analysis-by-synthesis on standard benchmarks.","sentences":["Modern pose estimation models are trained on large, manually-labelled datasets which are costly and may not cover the full extent of human poses and appearances in the real world.","With advances in neural rendering, analysis-by-synthesis and the ability to not only predict, but also render the pose, is becoming an appealing framework, which could alleviate the need for large scale manual labelling efforts.","While recent work have shown the feasibility of this approach, the predictions admit many flips due to a simplistic intermediate skeleton representation, resulting in low precision and inhibiting the acquisition of any downstream knowledge such as three-dimensional positioning.","We solve this problem with a more expressive intermediate skeleton representation capable of capturing the semantics of the pose (left and right), which significantly reduces flips.","To successfully train this new representation, we extend the analysis-by-synthesis framework with a training protocol based on synthetic data.","We show that our representation results in less flips and more accurate predictions.","Our approach outperforms previous models trained with analysis-by-synthesis on standard benchmarks."],"url":"http://arxiv.org/abs/2411.08603v1"}
{"created":"2024-11-13 13:13:07","title":"Hopfield-Fenchel-Young Networks: A Unified Framework for Associative Memory Retrieval","abstract":"Associative memory models, such as Hopfield networks and their modern variants, have garnered renewed interest due to advancements in memory capacity and connections with self-attention in transformers. In this work, we introduce a unified framework-Hopfield-Fenchel-Young networks-which generalizes these models to a broader family of energy functions. Our energies are formulated as the difference between two Fenchel-Young losses: one, parameterized by a generalized entropy, defines the Hopfield scoring mechanism, while the other applies a post-transformation to the Hopfield output. By utilizing Tsallis and norm entropies, we derive end-to-end differentiable update rules that enable sparse transformations, uncovering new connections between loss margins, sparsity, and exact retrieval of single memory patterns. We further extend this framework to structured Hopfield networks using the SparseMAP transformation, allowing the retrieval of pattern associations rather than a single pattern. Our framework unifies and extends traditional and modern Hopfield networks and provides an energy minimization perspective for widely used post-transformations like $\\ell_2$-normalization and layer normalization-all through suitable choices of Fenchel-Young losses and by using convex analysis as a building block. Finally, we validate our Hopfield-Fenchel-Young networks on diverse memory recall tasks, including free and sequential recall. Experiments on simulated data, image retrieval, multiple instance learning, and text rationalization demonstrate the effectiveness of our approach.","sentences":["Associative memory models, such as Hopfield networks and their modern variants, have garnered renewed interest due to advancements in memory capacity and connections with self-attention in transformers.","In this work, we introduce a unified framework-Hopfield-Fenchel-Young networks-which generalizes these models to a broader family of energy functions.","Our energies are formulated as the difference between two Fenchel-Young losses: one, parameterized by a generalized entropy, defines the Hopfield scoring mechanism, while the other applies a post-transformation to the Hopfield output.","By utilizing Tsallis and norm entropies, we derive end-to-end differentiable update rules that enable sparse transformations, uncovering new connections between loss margins, sparsity, and exact retrieval of single memory patterns.","We further extend this framework to structured Hopfield networks using the SparseMAP transformation, allowing the retrieval of pattern associations rather than a single pattern.","Our framework unifies and extends traditional and modern Hopfield networks and provides an energy minimization perspective for widely used post-transformations like $\\ell_2$-normalization and layer normalization-all through suitable choices of Fenchel-Young losses and by using convex analysis as a building block.","Finally, we validate our Hopfield-Fenchel-Young networks on diverse memory recall tasks, including free and sequential recall.","Experiments on simulated data, image retrieval, multiple instance learning, and text rationalization demonstrate the effectiveness of our approach."],"url":"http://arxiv.org/abs/2411.08590v1"}
{"created":"2024-11-13 13:11:49","title":"DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods","abstract":"Assessing the quality of aleatoric uncertainty estimates from uncertainty quantification (UQ) deep learning methods is important in scientific contexts, where uncertainty is physically meaningful and important to characterize and interpret exactly. We systematically compare aleatoric uncertainty measured by two UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER). Our method focuses on both zero-dimensional (0D) and two-dimensional (2D) data, to explore how the UQ methods function for different data dimensionalities. We investigate uncertainty injected on the input and output variables and include a method to propagate uncertainty in the case of input uncertainty so that we can compare the predicted aleatoric uncertainty to the known values. We experiment with three levels of noise. The aleatoric uncertainty predicted across all models and experiments scales with the injected noise level. However, the predicted uncertainty is miscalibrated to $\\rm{std}(\\sigma_{\\rm al})$ with the true uncertainty for half of the DE experiments and almost all of the DER experiments. The predicted uncertainty is the least accurate for both UQ methods for the 2D input uncertainty experiment and the high-noise level. While these results do not apply to more complex data, they highlight that further research on post-facto calibration for these methods would be beneficial, particularly for high-noise and high-dimensional settings.","sentences":["Assessing the quality of aleatoric uncertainty estimates from uncertainty quantification (UQ) deep learning methods is important in scientific contexts, where uncertainty is physically meaningful and important to characterize and interpret exactly.","We systematically compare aleatoric uncertainty measured by two UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER).","Our method focuses on both zero-dimensional (0D) and two-dimensional (2D) data, to explore how the UQ methods function for different data dimensionalities.","We investigate uncertainty injected on the input and output variables and include a method to propagate uncertainty in the case of input uncertainty so that we can compare the predicted aleatoric uncertainty to the known values.","We experiment with three levels of noise.","The aleatoric uncertainty predicted across all models and experiments scales with the injected noise level.","However, the predicted uncertainty is miscalibrated to $\\rm{std}(\\sigma_{\\rm al})$ with the true uncertainty for half of the DE experiments and almost all of the DER experiments.","The predicted uncertainty is the least accurate for both UQ methods for the 2D input uncertainty experiment and the high-noise level.","While these results do not apply to more complex data, they highlight that further research on post-facto calibration for these methods would be beneficial, particularly for high-noise and high-dimensional settings."],"url":"http://arxiv.org/abs/2411.08587v1"}
{"created":"2024-11-13 12:51:49","title":"NavAgent: Multi-scale Urban Street View Fusion For UAV Embodied Vision-and-Language Navigation","abstract":"Vision-and-Language Navigation (VLN), as a widely discussed research direction in embodied intelligence, aims to enable embodied agents to navigate in complicated visual environments through natural language commands. Most existing VLN methods focus on indoor ground robot scenarios. However, when applied to UAV VLN in outdoor urban scenes, it faces two significant challenges. First, urban scenes contain numerous objects, which makes it challenging to match fine-grained landmarks in images with complex textual descriptions of these landmarks. Second, overall environmental information encompasses multiple modal dimensions, and the diversity of representations significantly increases the complexity of the encoding process. To address these challenges, we propose NavAgent, the first urban UAV embodied navigation model driven by a large Vision-Language Model. NavAgent undertakes navigation tasks by synthesizing multi-scale environmental information, including topological maps (global), panoramas (medium), and fine-grained landmarks (local). Specifically, we utilize GLIP to build a visual recognizer for landmark capable of identifying and linguisticizing fine-grained landmarks. Subsequently, we develop dynamically growing scene topology map that integrate environmental information and employ Graph Convolutional Networks to encode global environmental data. In addition, to train the visual recognizer for landmark, we develop NavAgent-Landmark2K, the first fine-grained landmark dataset for real urban street scenes. In experiments conducted on the Touchdown and Map2seq datasets, NavAgent outperforms strong baseline models. The code and dataset will be released to the community to facilitate the exploration and development of outdoor VLN.","sentences":["Vision-and-Language Navigation (VLN), as a widely discussed research direction in embodied intelligence, aims to enable embodied agents to navigate in complicated visual environments through natural language commands.","Most existing VLN methods focus on indoor ground robot scenarios.","However, when applied to UAV VLN in outdoor urban scenes, it faces two significant challenges.","First, urban scenes contain numerous objects, which makes it challenging to match fine-grained landmarks in images with complex textual descriptions of these landmarks.","Second, overall environmental information encompasses multiple modal dimensions, and the diversity of representations significantly increases the complexity of the encoding process.","To address these challenges, we propose NavAgent, the first urban UAV embodied navigation model driven by a large Vision-Language Model.","NavAgent undertakes navigation tasks by synthesizing multi-scale environmental information, including topological maps (global), panoramas (medium), and fine-grained landmarks (local).","Specifically, we utilize GLIP to build a visual recognizer for landmark capable of identifying and linguisticizing fine-grained landmarks.","Subsequently, we develop dynamically growing scene topology map that integrate environmental information and employ Graph Convolutional Networks to encode global environmental data.","In addition, to train the visual recognizer for landmark, we develop NavAgent-Landmark2K, the first fine-grained landmark dataset for real urban street scenes.","In experiments conducted on the Touchdown and Map2seq datasets, NavAgent outperforms strong baseline models.","The code and dataset will be released to the community to facilitate the exploration and development of outdoor VLN."],"url":"http://arxiv.org/abs/2411.08579v1"}
{"created":"2024-11-13 12:29:44","title":"UIFormer: A Unified Transformer-based Framework for Incremental Few-Shot Object Detection and Instance Segmentation","abstract":"This paper introduces a novel framework for unified incremental few-shot object detection (iFSOD) and instance segmentation (iFSIS) using the Transformer architecture. Our goal is to create an optimal solution for situations where only a few examples of novel object classes are available, with no access to training data for base or old classes, while maintaining high performance across both base and novel classes. To achieve this, We extend Mask-DINO into a two-stage incremental learning framework. Stage 1 focuses on optimizing the model using the base dataset, while Stage 2 involves fine-tuning the model on novel classes. Besides, we incorporate a classifier selection strategy that assigns appropriate classifiers to the encoder and decoder according to their distinct functions. Empirical evidence indicates that this approach effectively mitigates the over-fitting on novel classes learning. Furthermore, we implement knowledge distillation to prevent catastrophic forgetting of base classes. Comprehensive evaluations on the COCO and LVIS datasets for both iFSIS and iFSOD tasks demonstrate that our method significantly outperforms state-of-the-art approaches.","sentences":["This paper introduces a novel framework for unified incremental few-shot object detection (iFSOD) and instance segmentation (iFSIS) using the Transformer architecture.","Our goal is to create an optimal solution for situations where only a few examples of novel object classes are available, with no access to training data for base or old classes, while maintaining high performance across both base and novel classes.","To achieve this, We extend Mask-DINO into a two-stage incremental learning framework.","Stage 1 focuses on optimizing the model using the base dataset, while Stage 2 involves fine-tuning the model on novel classes.","Besides, we incorporate a classifier selection strategy that assigns appropriate classifiers to the encoder and decoder according to their distinct functions.","Empirical evidence indicates that this approach effectively mitigates the over-fitting on novel classes learning.","Furthermore, we implement knowledge distillation to prevent catastrophic forgetting of base classes.","Comprehensive evaluations on the COCO and LVIS datasets for both iFSIS and iFSOD tasks demonstrate that our method significantly outperforms state-of-the-art approaches."],"url":"http://arxiv.org/abs/2411.08569v1"}
{"created":"2024-11-13 12:21:13","title":"Leveraging LLMs for Predictive Insights in Food Policy and Behavioral Interventions","abstract":"Food consumption and production contribute significantly to global greenhouse gas emissions, making them crucial entry points for mitigating climate change and maintaining a liveable planet. Over the past two decades, food policy initiatives have explored interventions to reshape production and consumption patterns, focusing on reducing food waste and curbing ruminant meat consumption. While the evidence of \"what works\" improves, evaluating which policies are appropriate and effective in specific contexts remains difficult due to external validity challenges. This paper demonstrates that a fine-tuned large language model (LLM) can accurately predict the direction of outcomes in approximately 80\\% of empirical studies measuring dietary-based impacts (e.g. food choices, sales, waste) resulting from behavioral interventions and policies. Approximately 75 prompts were required to achieve optimal results, with performance showing signs of catastrophic loss beyond this point. Our findings indicate that greater input detail enhances predictive accuracy, although the model still faces challenges with unseen studies, underscoring the importance of a representative training sample. As LLMs continue to improve and diversify, they hold promise for advancing data-driven, evidence-based policymaking.","sentences":["Food consumption and production contribute significantly to global greenhouse gas emissions, making them crucial entry points for mitigating climate change and maintaining a liveable planet.","Over the past two decades, food policy initiatives have explored interventions to reshape production and consumption patterns, focusing on reducing food waste and curbing ruminant meat consumption.","While the evidence of \"what works\" improves, evaluating which policies are appropriate and effective in specific contexts remains difficult due to external validity challenges.","This paper demonstrates that a fine-tuned large language model (LLM) can accurately predict the direction of outcomes in approximately 80\\% of empirical studies measuring dietary-based impacts (e.g. food choices, sales, waste) resulting from behavioral interventions and policies.","Approximately 75 prompts were required to achieve optimal results, with performance showing signs of catastrophic loss beyond this point.","Our findings indicate that greater input detail enhances predictive accuracy, although the model still faces challenges with unseen studies, underscoring the importance of a representative training sample.","As LLMs continue to improve and diversify, they hold promise for advancing data-driven, evidence-based policymaking."],"url":"http://arxiv.org/abs/2411.08563v1"}
{"created":"2024-11-13 12:19:46","title":"Neural Corrective Machine Unranking","abstract":"Machine unlearning in neural information retrieval (IR) systems requires removing specific data whilst maintaining model performance. Applying existing machine unlearning methods to IR may compromise retrieval effectiveness or inadvertently expose unlearning actions due to the removal of particular items from the retrieved results presented to users. We formalise corrective unranking, which extends machine unlearning in (neural) IR context by integrating substitute documents to preserve ranking integrity, and propose a novel teacher-student framework, Corrective unRanking Distillation (CuRD), for this task. CuRD (1) facilitates forgetting by adjusting the (trained) neural IR model such that its output relevance scores of to-be-forgotten samples mimic those of low-ranking, non-retrievable samples; (2) enables correction by fine-tuning the relevance scores for the substitute samples to match those of corresponding to-be-forgotten samples closely; (3) seeks to preserve performance on samples that are not targeted for forgetting. We evaluate CuRD on four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and TREC CAR datasets. Experiments with forget set sizes from 1 % and 20 % of the training dataset demonstrate that CuRD outperforms seven state-of-the-art baselines in terms of forgetting and correction while maintaining model retention and generalisation capabilities.","sentences":["Machine unlearning in neural information retrieval (IR) systems requires removing specific data whilst maintaining model performance.","Applying existing machine unlearning methods to IR may compromise retrieval effectiveness or inadvertently expose unlearning actions due to the removal of particular items from the retrieved results presented to users.","We formalise corrective unranking, which extends machine unlearning in (neural) IR context by integrating substitute documents to preserve ranking integrity, and propose a novel teacher-student framework, Corrective unRanking Distillation (CuRD), for this task.","CuRD (1) facilitates forgetting by adjusting the (trained) neural IR model such that its output relevance scores of to-be-forgotten samples mimic those of low-ranking, non-retrievable samples; (2) enables correction by fine-tuning the relevance scores for the substitute samples to match those of corresponding to-be-forgotten samples closely; (3) seeks to preserve performance on samples that are not targeted for forgetting.","We evaluate CuRD on four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and TREC CAR datasets.","Experiments with forget set sizes from 1 % and 20 % of the training dataset demonstrate that CuRD outperforms seven state-of-the-art baselines in terms of forgetting and correction while maintaining model retention and generalisation capabilities."],"url":"http://arxiv.org/abs/2411.08562v1"}
{"created":"2024-11-13 12:18:00","title":"LogLLM: Log-based Anomaly Detection Using Large Language Models","abstract":"Software systems often record important runtime information in logs to help with troubleshooting. Log-based anomaly detection has become a key research area that aims to identify system issues through log data, ultimately enhancing the reliability of software systems. Traditional deep learning methods often struggle to capture the semantic information embedded in log data, which is typically organized in natural language. In this paper, we propose LogLLM, a log-based anomaly detection framework that leverages large language models (LLMs). LogLLM employs BERT for extracting semantic vectors from log messages, while utilizing Llama, a transformer decoder-based model, for classifying log sequences. Additionally, we introduce a projector to align the vector representation spaces of BERT and Llama, ensuring a cohesive understanding of log semantics. Unlike conventional methods that require log parsers to extract templates, LogLLM preprocesses log messages with regular expressions, streamlining the entire process. Our framework is trained through a novel three-stage procedure designed to enhance performance and adaptability. Experimental results across four public datasets demonstrate that LogLLM outperforms state-of-the-art methods. Even when handling unstable logs, it effectively captures the semantic meaning of log messages and detects anomalies accurately.","sentences":["Software systems often record important runtime information in logs to help with troubleshooting.","Log-based anomaly detection has become a key research area that aims to identify system issues through log data, ultimately enhancing the reliability of software systems.","Traditional deep learning methods often struggle to capture the semantic information embedded in log data, which is typically organized in natural language.","In this paper, we propose LogLLM, a log-based anomaly detection framework that leverages large language models (LLMs).","LogLLM employs BERT for extracting semantic vectors from log messages, while utilizing Llama, a transformer decoder-based model, for classifying log sequences.","Additionally, we introduce a projector to align the vector representation spaces of BERT and Llama, ensuring a cohesive understanding of log semantics.","Unlike conventional methods that require log parsers to extract templates, LogLLM preprocesses log messages with regular expressions, streamlining the entire process.","Our framework is trained through a novel three-stage procedure designed to enhance performance and adaptability.","Experimental results across four public datasets demonstrate that LogLLM outperforms state-of-the-art methods.","Even when handling unstable logs, it effectively captures the semantic meaning of log messages and detects anomalies accurately."],"url":"http://arxiv.org/abs/2411.08561v1"}
{"created":"2024-11-13 12:13:15","title":"Learning Locally Adaptive Metrics that Enhance Structural Representation with $\\texttt{LAMINAR}$","abstract":"We present $\\texttt{LAMINAR}$, a novel unsupervised machine learning pipeline designed to enhance the representation of structure within data via producing a more-informative distance metric. Analysis methods in the physical sciences often rely on standard metrics to define geometric relationships in data, which may fail to capture the underlying structure of complex data sets. $\\texttt{LAMINAR}$ addresses this by using a continuous-normalising-flow and inverse-transform-sampling to define a Riemannian manifold in the data space without the need for the user to specify a metric over the data a-priori. The result is a locally-adaptive-metric that produces structurally-informative density-based distances. We demonstrate the utility of $\\texttt{LAMINAR}$ by comparing its output to the Euclidean metric for structured data sets.","sentences":["We present $\\texttt{LAMINAR}$, a novel unsupervised machine learning pipeline designed to enhance the representation of structure within data via producing a more-informative distance metric.","Analysis methods in the physical sciences often rely on standard metrics to define geometric relationships in data, which may fail to capture the underlying structure of complex data sets.","$\\texttt{LAMINAR}$ addresses this by using a continuous-normalising-flow and inverse-transform-sampling to define a Riemannian manifold in the data space without the need for the user to specify a metric over the data a-priori.","The result is a locally-adaptive-metric that produces structurally-informative density-based distances.","We demonstrate the utility of $\\texttt{LAMINAR}$ by comparing its output to the Euclidean metric for structured data sets."],"url":"http://arxiv.org/abs/2411.08557v1"}
{"created":"2024-11-13 12:09:23","title":"CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs","abstract":"Large language models (LLMs) have demonstrated remarkable performance in diverse tasks using zero-shot and few-shot prompting. Even though their capabilities of data synthesis have been studied well in recent years, the generated data suffers from a lack of diversity, less adherence to the prompt, and potential biases that creep into the data from the generator model. In this work, we tackle the challenge of generating datasets with high diversity, upon which a student model is trained for downstream tasks. Taking the route of decoding-time guidance-based approaches, we propose CorrSynth, which generates data that is more diverse and faithful to the input prompt using a correlated sampling strategy. Further, our method overcomes the complexity drawbacks of some other guidance-based techniques like classifier-based guidance. With extensive experiments, we show the effectiveness of our approach and substantiate our claims. In particular, we perform intrinsic evaluation to show the improvements in diversity. Our experiments show that CorrSynth improves both student metrics and intrinsic metrics upon competitive baselines across four datasets, showing the innate advantage of our method.","sentences":["Large language models (LLMs) have demonstrated remarkable performance in diverse tasks using zero-shot and few-shot prompting.","Even though their capabilities of data synthesis have been studied well in recent years, the generated data suffers from a lack of diversity, less adherence to the prompt, and potential biases that creep into the data from the generator model.","In this work, we tackle the challenge of generating datasets with high diversity, upon which a student model is trained for downstream tasks.","Taking the route of decoding-time guidance-based approaches, we propose CorrSynth, which generates data that is more diverse and faithful to the input prompt using a correlated sampling strategy.","Further, our method overcomes the complexity drawbacks of some other guidance-based techniques like classifier-based guidance.","With extensive experiments, we show the effectiveness of our approach and substantiate our claims.","In particular, we perform intrinsic evaluation to show the improvements in diversity.","Our experiments show that CorrSynth improves both student metrics and intrinsic metrics upon competitive baselines across four datasets, showing the innate advantage of our method."],"url":"http://arxiv.org/abs/2411.08553v1"}
{"created":"2024-11-13 11:46:42","title":"APDDv2: Aesthetics of Paintings and Drawings Dataset with Artist Labeled Scores and Comments","abstract":"Datasets play a pivotal role in training visual models, facilitating the development of abstract understandings of visual features through diverse image samples and multidimensional attributes. However, in the realm of aesthetic evaluation of artistic images, datasets remain relatively scarce. Existing painting datasets are often characterized by limited scoring dimensions and insufficient annotations, thereby constraining the advancement and application of automatic aesthetic evaluation methods in the domain of painting. To bridge this gap, we introduce the Aesthetics Paintings and Drawings Dataset (APDD), the first comprehensive collection of paintings encompassing 24 distinct artistic categories and 10 aesthetic attributes. Building upon the initial release of APDDv1, our ongoing research has identified opportunities for enhancement in data scale and annotation precision. Consequently, APDDv2 boasts an expanded image corpus and improved annotation quality, featuring detailed language comments to better cater to the needs of both researchers and practitioners seeking high-quality painting datasets. Furthermore, we present an updated version of the Art Assessment Network for Specific Painting Styles, denoted as ArtCLIP. Experimental validation demonstrates the superior performance of this revised model in the realm of aesthetic evaluation, surpassing its predecessor in accuracy and efficacy. The dataset and model are available at https://github.com/BestiVictory/APDDv2.git.","sentences":["Datasets play a pivotal role in training visual models, facilitating the development of abstract understandings of visual features through diverse image samples and multidimensional attributes.","However, in the realm of aesthetic evaluation of artistic images, datasets remain relatively scarce.","Existing painting datasets are often characterized by limited scoring dimensions and insufficient annotations, thereby constraining the advancement and application of automatic aesthetic evaluation methods in the domain of painting.","To bridge this gap, we introduce the Aesthetics Paintings and Drawings Dataset (APDD), the first comprehensive collection of paintings encompassing 24 distinct artistic categories and 10 aesthetic attributes.","Building upon the initial release of APDDv1, our ongoing research has identified opportunities for enhancement in data scale and annotation precision.","Consequently, APDDv2 boasts an expanded image corpus and improved annotation quality, featuring detailed language comments to better cater to the needs of both researchers and practitioners seeking high-quality painting datasets.","Furthermore, we present an updated version of the Art Assessment Network for Specific Painting Styles, denoted as ArtCLIP.","Experimental validation demonstrates the superior performance of this revised model in the realm of aesthetic evaluation, surpassing its predecessor in accuracy and efficacy.","The dataset and model are available at https://github.com/BestiVictory/APDDv2.git."],"url":"http://arxiv.org/abs/2411.08545v1"}
{"created":"2024-11-13 11:45:39","title":"Deeper Insights into Learning Performance of Stochastic Configuration Networks","abstract":"Stochastic Configuration Networks (SCNs) are a class of randomized neural networks that integrate randomized algorithms within an incremental learning framework. A defining feature of SCNs is the supervisory mechanism, which adaptively adjusts the distribution to generate effective random basis functions, thereby enabling error-free learning. In this paper, we present a comprehensive analysis of the impact of the supervisory mechanism on the learning performance of SCNs. Our findings reveal that the current SCN framework evaluates the effectiveness of each random basis function in reducing residual errors using a lower bound on its error reduction potential, which constrains SCNs' overall learning efficiency. Specifically, SCNs may fail to consistently select the most effective random candidate as the new basis function during each training iteration. To overcome this problem, we propose a novel method for evaluating the hidden layer's output matrix, supported by a new supervisory mechanism that accurately assesses the error reduction potential of random basis functions without requiring the computation of the Moore-Penrose inverse of the output matrix. This approach enhances the selection of basis functions, reducing computational complexity and improving the overall scalability and learning capabilities of SCNs. We introduce a Recursive Moore-Penrose Inverse-SCN (RMPI-SCN) training scheme based on the new supervisory mechanism and demonstrate its effectiveness through simulations over some benchmark datasets. Experiments show that RMPI-SCN outperforms the conventional SCN in terms of learning capability, underscoring its potential to advance the SCN framework for large-scale data modeling applications.","sentences":["Stochastic Configuration Networks (SCNs) are a class of randomized neural networks that integrate randomized algorithms within an incremental learning framework.","A defining feature of SCNs is the supervisory mechanism, which adaptively adjusts the distribution to generate effective random basis functions, thereby enabling error-free learning.","In this paper, we present a comprehensive analysis of the impact of the supervisory mechanism on the learning performance of SCNs.","Our findings reveal that the current SCN framework evaluates the effectiveness of each random basis function in reducing residual errors using a lower bound on its error reduction potential, which constrains SCNs' overall learning efficiency.","Specifically, SCNs may fail to consistently select the most effective random candidate as the new basis function during each training iteration.","To overcome this problem, we propose a novel method for evaluating the hidden layer's output matrix, supported by a new supervisory mechanism that accurately assesses the error reduction potential of random basis functions without requiring the computation of the Moore-Penrose inverse of the output matrix.","This approach enhances the selection of basis functions, reducing computational complexity and improving the overall scalability and learning capabilities of SCNs.","We introduce a Recursive Moore-Penrose Inverse-SCN (RMPI-SCN) training scheme based on the new supervisory mechanism and demonstrate its effectiveness through simulations over some benchmark datasets.","Experiments show that RMPI-SCN outperforms the conventional SCN in terms of learning capability, underscoring its potential to advance the SCN framework for large-scale data modeling applications."],"url":"http://arxiv.org/abs/2411.08544v1"}
{"created":"2024-11-13 11:29:14","title":"ACROSS: A Deformation-Based Cross-Modal Representation for Robotic Tactile Perception","abstract":"Tactile perception is essential for human interaction with the environment and is becoming increasingly crucial in robotics. Tactile sensors like the BioTac mimic human fingertips and provide detailed interaction data. Despite its utility in applications like slip detection and object identification, this sensor is now deprecated, making many existing valuable datasets obsolete. However, recreating similar datasets with newer sensor technologies is both tedious and time-consuming. Therefore, it is crucial to adapt these existing datasets for use with new setups and modalities. In response, we introduce ACROSS, a novel framework for translating data between tactile sensors by exploiting sensor deformation information. We demonstrate the approach by translating BioTac signals into the DIGIT sensor. Our framework consists of first converting the input signals into 3D deformation meshes. We then transition from the 3D deformation mesh of one sensor to the mesh of another, and finally convert the generated 3D deformation mesh into the corresponding output space. We demonstrate our approach to the most challenging problem of going from a low-dimensional tactile representation to a high-dimensional one. In particular, we transfer the tactile signals of a BioTac sensor to DIGIT tactile images. Our approach enables the continued use of valuable datasets and the exchange of data between groups with different setups.","sentences":["Tactile perception is essential for human interaction with the environment and is becoming increasingly crucial in robotics.","Tactile sensors like the BioTac mimic human fingertips and provide detailed interaction data.","Despite its utility in applications like slip detection and object identification, this sensor is now deprecated, making many existing valuable datasets obsolete.","However, recreating similar datasets with newer sensor technologies is both tedious and time-consuming.","Therefore, it is crucial to adapt these existing datasets for use with new setups and modalities.","In response, we introduce ACROSS, a novel framework for translating data between tactile sensors by exploiting sensor deformation information.","We demonstrate the approach by translating BioTac signals into the DIGIT sensor.","Our framework consists of first converting the input signals into 3D deformation meshes.","We then transition from the 3D deformation mesh of one sensor to the mesh of another, and finally convert the generated 3D deformation mesh into the corresponding output space.","We demonstrate our approach to the most challenging problem of going from a low-dimensional tactile representation to a high-dimensional one.","In particular, we transfer the tactile signals of a BioTac sensor to DIGIT tactile images.","Our approach enables the continued use of valuable datasets and the exchange of data between groups with different setups."],"url":"http://arxiv.org/abs/2411.08533v1"}
{"created":"2024-11-13 11:07:59","title":"On the Design of Variable Modulation and Adaptive Modulation for Uplink Sparse Code Multiple Access","abstract":"Sparse code multiple access (SCMA) is a promising non-orthogonal multiple access scheme for enabling massive connectivity in next generation wireless networks. However, current SCMA codebooks are designed with the same size, leading to inflexibility of user grouping and supporting diverse data rates. To address this issue, we propose a variable modulation SCMA (VM-SCMA) that allows users to employ codebooks with different modulation orders. To guide the VM-SCMA design, a VM matrix (VMM) that assigns modulation orders based on the SCMA factor graph is first introduced. We formulate the VM-SCMA design using the proposed average inverse product distance and the asymptotic upper bound of sum-rate, and jointly optimize the VMM, VM codebooks, power and codebook allocations. The proposed VM-SCMA not only enables diverse date rates but also supports different modulation order combinations for each rate. Leveraging these distinct advantages, we further propose an adaptive VM-SCMA (AVM-SCMA) scheme which adaptively selects the rate and the corresponding VM codebooks to adapt to the users' channel conditions by maximizing the proposed effective throughput. Simulation results show that the overall designs are able to simultaneously achieve a high-level system flexibility, enhanced error rate results, and significantly improved throughput performance, when compared to conventional SCMA schemes.","sentences":["Sparse code multiple access (SCMA) is a promising non-orthogonal multiple access scheme for enabling massive connectivity in next generation wireless networks.","However, current SCMA codebooks are designed with the same size, leading to inflexibility of user grouping and supporting diverse data rates.","To address this issue, we propose a variable modulation SCMA (VM-SCMA) that allows users to employ codebooks with different modulation orders.","To guide the VM-SCMA design, a VM matrix (VMM) that assigns modulation orders based on the SCMA factor graph is first introduced.","We formulate the VM-SCMA design using the proposed average inverse product distance and the asymptotic upper bound of sum-rate, and jointly optimize the VMM, VM codebooks, power and codebook allocations.","The proposed VM-SCMA not only enables diverse date rates but also supports different modulation order combinations for each rate.","Leveraging these distinct advantages, we further propose an adaptive VM-SCMA (AVM-SCMA) scheme which adaptively selects the rate and the corresponding VM codebooks to adapt to the users' channel conditions by maximizing the proposed effective throughput.","Simulation results show that the overall designs are able to simultaneously achieve a high-level system flexibility, enhanced error rate results, and significantly improved throughput performance, when compared to conventional SCMA schemes."],"url":"http://arxiv.org/abs/2411.08520v1"}
{"created":"2024-11-13 11:02:04","title":"Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding","abstract":"The ubiquity and value of tables as semi-structured data across various domains necessitate advanced methods for understanding their complexity and vast amounts of information. Despite the impressive capabilities of large language models (LLMs) in advancing the natural language understanding frontier, their application to large-scale tabular data presents significant challenges, specifically regarding table size and complex intricate relationships. Existing works have shown promise with small-scale tables but often flounder when tasked with the complex reasoning required by larger, interconnected tables found in real-world scenarios. To address this gap, we introduce \"Tree-of-Table\", a novel approach designed to enhance LLMs' reasoning capabilities over large and complex tables. Our method employs Table Condensation and Decomposition to distill and reorganize relevant data into a manageable format, followed by the construction of a hierarchical Table-Tree that facilitates tree-structured reasoning. Through a meticulous Table-Tree Execution process, we systematically unravel the tree-structured reasoning chain to derive the solutions. Experiments across diverse datasets, including WikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new benchmark with superior performance, showcasing remarkable efficiency and generalization capabilities in large-scale table reasoning.","sentences":["The ubiquity and value of tables as semi-structured data across various domains necessitate advanced methods for understanding their complexity and vast amounts of information.","Despite the impressive capabilities of large language models (LLMs) in advancing the natural language understanding frontier, their application to large-scale tabular data presents significant challenges, specifically regarding table size and complex intricate relationships.","Existing works have shown promise with small-scale tables but often flounder when tasked with the complex reasoning required by larger, interconnected tables found in real-world scenarios.","To address this gap, we introduce \"Tree-of-Table\", a novel approach designed to enhance LLMs' reasoning capabilities over large and complex tables.","Our method employs Table Condensation and Decomposition to distill and reorganize relevant data into a manageable format, followed by the construction of a hierarchical Table-Tree that facilitates tree-structured reasoning.","Through a meticulous Table-Tree Execution process, we systematically unravel the tree-structured reasoning chain to derive the solutions.","Experiments across diverse datasets, including WikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new benchmark with superior performance, showcasing remarkable efficiency and generalization capabilities in large-scale table reasoning."],"url":"http://arxiv.org/abs/2411.08516v1"}
{"created":"2024-11-13 10:43:31","title":"An Information Theoretic Approach to Operationalize Right to Data Protection","abstract":"The widespread practice of indiscriminate data scraping to fine-tune language models (LMs) raises significant legal and ethical concerns, particularly regarding compliance with data protection laws such as the General Data Protection Regulation (GDPR). This practice often results in the unauthorized use of personal information, prompting growing debate within the academic and regulatory communities. Recent works have introduced the concept of generating unlearnable datasets (by adding imperceptible noise to the clean data), such that the underlying model achieves lower loss during training but fails to generalize to the unseen test setting. Though somewhat effective, these approaches are predominantly designed for images and are limited by several practical constraints like requiring knowledge of the target model. To this end, we introduce RegText, a framework that injects imperceptible spurious correlations into natural language datasets, effectively rendering them unlearnable without affecting semantic content. We demonstrate RegText's utility through rigorous empirical analysis of small and large LMs. Notably, RegText can restrict newer models like GPT-4o and Llama from learning on our generated data, resulting in a drop in their test accuracy compared to their zero-shot performance and paving the way for generating unlearnable text to protect public data.","sentences":["The widespread practice of indiscriminate data scraping to fine-tune language models (LMs) raises significant legal and ethical concerns, particularly regarding compliance with data protection laws such as the General Data Protection Regulation (GDPR).","This practice often results in the unauthorized use of personal information, prompting growing debate within the academic and regulatory communities.","Recent works have introduced the concept of generating unlearnable datasets (by adding imperceptible noise to the clean data), such that the underlying model achieves lower loss during training but fails to generalize to the unseen test setting.","Though somewhat effective, these approaches are predominantly designed for images and are limited by several practical constraints like requiring knowledge of the target model.","To this end, we introduce RegText, a framework that injects imperceptible spurious correlations into natural language datasets, effectively rendering them unlearnable without affecting semantic content.","We demonstrate RegText's utility through rigorous empirical analysis of small and large LMs.","Notably, RegText can restrict newer models like GPT-4o and Llama from learning on our generated data, resulting in a drop in their test accuracy compared to their zero-shot performance and paving the way for generating unlearnable text to protect public data."],"url":"http://arxiv.org/abs/2411.08506v1"}
{"created":"2024-11-13 10:42:11","title":"Towards Objective and Unbiased Decision Assessments with LLM-Enhanced Hierarchical Attention Networks","abstract":"How objective and unbiased are we while making decisions? This work investigates cognitive bias identification in high-stake decision making process by human experts, questioning its effectiveness in real-world settings, such as candidates assessments for university admission. We begin with a statistical analysis assessing correlations among different decision points among in the current process, which discovers discrepancies that imply cognitive bias and inconsistency in decisions. This motivates our exploration of bias-aware AI-augmented workflow that surpass human judgment. We propose BGM-HAN, a hierarchical attention network enhanced by byte-pair encoding, multi-head attention and gated residual connection. Using it as backbone model, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow, which simulate real-world decision-making. In our experiments, both the proposed model and the agentic workflow significantly improves on both human judgment and alternative models, validated with real-world data.","sentences":["How objective and unbiased are we while making decisions?","This work investigates cognitive bias identification in high-stake decision making process by human experts, questioning its effectiveness in real-world settings, such as candidates assessments for university admission.","We begin with a statistical analysis assessing correlations among different decision points among in the current process, which discovers discrepancies that imply cognitive bias and inconsistency in decisions.","This motivates our exploration of bias-aware AI-augmented workflow that surpass human judgment.","We propose BGM-HAN, a hierarchical attention network enhanced by byte-pair encoding, multi-head attention and gated residual connection.","Using it as backbone model, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow, which simulate real-world decision-making.","In our experiments, both the proposed model and the agentic workflow significantly improves on both human judgment and alternative models, validated with real-world data."],"url":"http://arxiv.org/abs/2411.08504v1"}
{"created":"2024-11-13 10:15:27","title":"Impact of Iris Pigmentation on Performance Bias in Visible Iris Verification Systems: A Comparative Study","abstract":"Iris recognition technology plays a critical role in biometric identification systems, but their performance can be affected by variations in iris pigmentation. In this work, we investigate the impact of iris pigmentation on the efficacy of biometric recognition systems, focusing on a comparative analysis of blue and dark irises. Data sets were collected using multiple devices, including P1, P2, and P3 smartphones [4], to assess the robustness of the systems in different capture environments [19]. Both traditional machine learning techniques and deep learning models were used, namely Open-Iris, ViT-b, and ResNet50, to evaluate performance metrics such as Equal Error Rate (EER) and True Match Rate (TMR). Our results indicate that iris recognition systems generally exhibit higher accuracy for blue irises compared to dark irises. Furthermore, we examined the generalization capabilities of these systems across different iris colors and devices, finding that while training on diverse datasets enhances recognition performance, the degree of improvement is contingent on the specific model and device used. Our analysis also identifies inherent biases in recognition performance related to iris color and cross-device variability. These findings underscore the need for more inclusive dataset collection and model refinement to reduce bias and promote equitable biometric recognition across varying iris pigmentation and device configurations.","sentences":["Iris recognition technology plays a critical role in biometric identification systems, but their performance can be affected by variations in iris pigmentation.","In this work, we investigate the impact of iris pigmentation on the efficacy of biometric recognition systems, focusing on a comparative analysis of blue and dark irises.","Data sets were collected using multiple devices, including P1, P2, and P3 smartphones","[4], to assess the robustness of the systems in different capture environments [19].","Both traditional machine learning techniques and deep learning models were used, namely Open-Iris, ViT-b, and ResNet50, to evaluate performance metrics such as Equal Error Rate (EER) and True Match Rate (TMR).","Our results indicate that iris recognition systems generally exhibit higher accuracy for blue irises compared to dark irises.","Furthermore, we examined the generalization capabilities of these systems across different iris colors and devices, finding that while training on diverse datasets enhances recognition performance, the degree of improvement is contingent on the specific model and device used.","Our analysis also identifies inherent biases in recognition performance related to iris color and cross-device variability.","These findings underscore the need for more inclusive dataset collection and model refinement to reduce bias and promote equitable biometric recognition across varying iris pigmentation and device configurations."],"url":"http://arxiv.org/abs/2411.08490v1"}
{"created":"2024-11-13 09:55:59","title":"Learning Model Agnostic Explanations via Constraint Programming","abstract":"Interpretable Machine Learning faces a recurring challenge of explaining the predictions made by opaque classifiers such as ensemble models, kernel methods, or neural networks in terms that are understandable to humans. When the model is viewed as a black box, the objective is to identify a small set of features that jointly determine the black box response with minimal error. However, finding such model-agnostic explanations is computationally demanding, as the problem is intractable even for binary classifiers. In this paper, the task is framed as a Constraint Optimization Problem, where the constraint solver seeks an explanation of minimum error and bounded size for an input data instance and a set of samples generated by the black box. From a theoretical perspective, this constraint programming approach offers PAC-style guarantees for the output explanation. We evaluate the approach empirically on various datasets and show that it statistically outperforms the state-of-the-art heuristic Anchors method.","sentences":["Interpretable Machine Learning faces a recurring challenge of explaining the predictions made by opaque classifiers such as ensemble models, kernel methods, or neural networks in terms that are understandable to humans.","When the model is viewed as a black box, the objective is to identify a small set of features that jointly determine the black box response with minimal error.","However, finding such model-agnostic explanations is computationally demanding, as the problem is intractable even for binary classifiers.","In this paper, the task is framed as a Constraint Optimization Problem, where the constraint solver seeks an explanation of minimum error and bounded size for an input data instance and a set of samples generated by the black box.","From a theoretical perspective, this constraint programming approach offers PAC-style guarantees for the output explanation.","We evaluate the approach empirically on various datasets and show that it statistically outperforms the state-of-the-art heuristic Anchors method."],"url":"http://arxiv.org/abs/2411.08478v1"}
{"created":"2024-11-13 09:47:00","title":"A Cost-effective, Stand-alone, and Real-time TinyML-Based Gait Diagnosis Unit Aimed at Lower-limb Robotic Prostheses and Exoskeletons","abstract":"Robotic prostheses and exoskeletons can do wonders compared to their non-robotic counterpart. However, in a cost-soaring world where 1 in every 10 patients has access to normal medical prostheses, access to advanced ones is, unfortunately, extremely limited especially due to their high cost, a significant portion of which is contributed to by the diagnosis and controlling units. However, affordability is often not a major concern for developing such devices as with cost reduction, performance is also found to be deducted due to the cost vs. performance trade-off. Considering the gravity of such circumstances, the goal of this research was to propose an affordable wearable real-time gait diagnosis unit (GDU) aimed at robotic prostheses and exoskeletons. As a proof of concept, it has also developed the GDU prototype which leveraged TinyML to run two parallel quantized int8 models into an ESP32 NodeMCU development board (7.30 USD) to effectively classify five gait scenarios (idle, walk, run, hopping, and skip) and generate an anomaly score based on acceleration data received from two attached IMUs. The developed wearable gait diagnosis stand-alone unit could be fitted to any prosthesis or exoskeleton and could effectively classify the gait scenarios with an overall accuracy of 92% and provide anomaly scores within 95-96 ms with only 3 seconds of gait data in real-time.","sentences":["Robotic prostheses and exoskeletons can do wonders compared to their non-robotic counterpart.","However, in a cost-soaring world where 1 in every 10 patients has access to normal medical prostheses, access to advanced ones is, unfortunately, extremely limited especially due to their high cost, a significant portion of which is contributed to by the diagnosis and controlling units.","However, affordability is often not a major concern for developing such devices as with cost reduction, performance is also found to be deducted due to the cost vs. performance trade-off.","Considering the gravity of such circumstances, the goal of this research was to propose an affordable wearable real-time gait diagnosis unit (GDU) aimed at robotic prostheses and exoskeletons.","As a proof of concept, it has also developed the GDU prototype which leveraged TinyML to run two parallel quantized int8 models into an ESP32 NodeMCU development board (7.30 USD) to effectively classify five gait scenarios (idle, walk, run, hopping, and skip) and generate an anomaly score based on acceleration data received from two attached IMUs.","The developed wearable gait diagnosis stand-alone unit could be fitted to any prosthesis or exoskeleton and could effectively classify the gait scenarios with an overall accuracy of 92% and provide anomaly scores within 95-96 ms with only 3 seconds of gait data in real-time."],"url":"http://arxiv.org/abs/2411.08474v1"}
{"created":"2024-11-13 09:36:50","title":"Crystal Structure Generation Based On Material Properties","abstract":"The discovery of new materials is very important to the field of materials science. When researchers explore new materials, they often have expected performance requirements for their crystal structure. In recent years, data-driven methods have made great progress in the direction plane of crystal structure generation, but there is still a lack of methods that can effectively map material properties to crystal structure. In this paper, we propose a Crystal DiT model to generate the crystal structure from the expected material properties by embedding the material properties and combining the symmetry information predicted by the large language model. Experimental verification shows that our proposed method has good performance.","sentences":["The discovery of new materials is very important to the field of materials science.","When researchers explore new materials, they often have expected performance requirements for their crystal structure.","In recent years, data-driven methods have made great progress in the direction plane of crystal structure generation, but there is still a lack of methods that can effectively map material properties to crystal structure.","In this paper, we propose a Crystal DiT model to generate the crystal structure from the expected material properties by embedding the material properties and combining the symmetry information predicted by the large language model.","Experimental verification shows that our proposed method has good performance."],"url":"http://arxiv.org/abs/2411.08464v1"}
{"created":"2024-11-13 09:31:06","title":"Trap-MID: Trapdoor-based Defense against Model Inversion Attacks","abstract":"Model Inversion (MI) attacks pose a significant threat to the privacy of Deep Neural Networks by recovering training data distribution from well-trained models. While existing defenses often rely on regularization techniques to reduce information leakage, they remain vulnerable to recent attacks. In this paper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to mislead MI attacks. A trapdoor is integrated into the model to predict a specific label when the input is injected with the corresponding trigger. Consequently, this trapdoor information serves as the \"shortcut\" for MI attacks, leading them to extract trapdoor triggers rather than private data. We provide theoretical insights into the impacts of trapdoor's effectiveness and naturalness on deceiving MI attacks. In addition, empirical experiments demonstrate the state-of-the-art defense performance of Trap-MID against various MI attacks without the requirements for extra data or large computational overhead. Our source code is publicly available at https://github.com/ntuaislab/Trap-MID.","sentences":["Model Inversion (MI) attacks pose a significant threat to the privacy of Deep Neural Networks by recovering training data distribution from well-trained models.","While existing defenses often rely on regularization techniques to reduce information leakage, they remain vulnerable to recent attacks.","In this paper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to mislead MI attacks.","A trapdoor is integrated into the model to predict a specific label when the input is injected with the corresponding trigger.","Consequently, this trapdoor information serves as the \"shortcut\" for MI attacks, leading them to extract trapdoor triggers rather than private data.","We provide theoretical insights into the impacts of trapdoor's effectiveness and naturalness on deceiving MI attacks.","In addition, empirical experiments demonstrate the state-of-the-art defense performance of Trap-MID against various MI attacks without the requirements for extra data or large computational overhead.","Our source code is publicly available at https://github.com/ntuaislab/Trap-MID."],"url":"http://arxiv.org/abs/2411.08460v1"}
{"created":"2024-11-13 08:57:59","title":"LSH-MoE: Communication-efficient MoE Training via Locality-Sensitive Hashing","abstract":"Larger transformer models always perform better on various tasks but require more costs to scale up the model size. To efficiently enlarge models, the mixture-of-experts (MoE) architecture is widely adopted, which consists of a gate network and a series of experts and keep the training cost constant by routing the input data to a fixed number of experts instead of all. In existing large-scale MoE training systems, experts would be distributed among different GPUs for parallelization, and thus input data requires additional all-to-all communications to access the target experts and conduct corresponding computations. However, upon evaluating the training process of three mainstream MoE models on commonly used GPU clusters, we found that the all-to-all communication ratio averaged around 45%, which significantly hinders the efficiency and scalability of training MoE models.   In this paper, we propose LSH-MoE, a communication-efficient MoE training framework using locality-sensitive hashing (LSH). We first present the problems of scaling MoE training in existing systems and highlight the potential of exploiting token similarity to facilitate data compression. Then, we introduce an efficient LSH-based compression technique, which utilizes the cross-polytope hashing for rapid clustering and implements a residual-based error compensation scheme to alleviate the adverse impact of compression. To verify the effectiveness of our methods, we conduct experiments on both language models (e.g., RoBERTa, GPT, and T5) and vision models (e.g., Swin) for pre-training and fine-tuning tasks. The results demonstrate that our method substantially outperforms its counterparts across different tasks by 1.28x - 2.2x of speedup.","sentences":["Larger transformer models always perform better on various tasks but require more costs to scale up the model size.","To efficiently enlarge models, the mixture-of-experts (MoE) architecture is widely adopted, which consists of a gate network and a series of experts and keep the training cost constant by routing the input data to a fixed number of experts instead of all.","In existing large-scale MoE training systems, experts would be distributed among different GPUs for parallelization, and thus input data requires additional all-to-all communications to access the target experts and conduct corresponding computations.","However, upon evaluating the training process of three mainstream MoE models on commonly used GPU clusters, we found that the all-to-all communication ratio averaged around 45%, which significantly hinders the efficiency and scalability of training MoE models.   ","In this paper, we propose LSH-MoE, a communication-efficient MoE training framework using locality-sensitive hashing (LSH).","We first present the problems of scaling MoE training in existing systems and highlight the potential of exploiting token similarity to facilitate data compression.","Then, we introduce an efficient LSH-based compression technique, which utilizes the cross-polytope hashing for rapid clustering and implements a residual-based error compensation scheme to alleviate the adverse impact of compression.","To verify the effectiveness of our methods, we conduct experiments on both language models (e.g., RoBERTa, GPT, and T5) and vision models (e.g., Swin) for pre-training and fine-tuning tasks.","The results demonstrate that our method substantially outperforms its counterparts across different tasks by 1.28x - 2.2x of speedup."],"url":"http://arxiv.org/abs/2411.08446v1"}
{"created":"2024-11-13 08:56:35","title":"Machine Unlearning on Pre-trained Models by Residual Feature Alignment Using LoRA","abstract":"Machine unlearning is new emerged technology that removes a subset of the training data from a trained model without affecting the model performance on the remaining data. This topic is becoming increasingly important in protecting user privacy and eliminating harmful or outdated data. The key challenge lies in effectively and efficiently unlearning specific information without compromising the model's utility on the retained data. For the pre-trained models, fine-tuning is an important way to achieve the unlearning target. Previous work typically fine-tuned the entire model's parameters, which incurs significant computation costs. In addition, the fine-tuning process may cause shifts in the intermediate layer features, affecting the model's overall utility. In this work, we propose a novel and efficient machine unlearning method on pre-trained models. We term the method as Residual Feature Alignment Unlearning. Specifically, we leverage LoRA (Low-Rank Adaptation) to decompose the model's intermediate features into pre-trained features and residual features. By adjusting the residual features, we align the unlearned model with the pre-trained model at the intermediate feature level to achieve both unlearning and remaining targets. The method aims to learn the zero residuals on the retained set and shifted residuals on the unlearning set. Extensive experiments on numerous datasets validate the effectiveness of our approach.","sentences":["Machine unlearning is new emerged technology that removes a subset of the training data from a trained model without affecting the model performance on the remaining data.","This topic is becoming increasingly important in protecting user privacy and eliminating harmful or outdated data.","The key challenge lies in effectively and efficiently unlearning specific information without compromising the model's utility on the retained data.","For the pre-trained models, fine-tuning is an important way to achieve the unlearning target.","Previous work typically fine-tuned the entire model's parameters, which incurs significant computation costs.","In addition, the fine-tuning process may cause shifts in the intermediate layer features, affecting the model's overall utility.","In this work, we propose a novel and efficient machine unlearning method on pre-trained models.","We term the method as Residual Feature Alignment Unlearning.","Specifically, we leverage LoRA (Low-Rank Adaptation) to decompose the model's intermediate features into pre-trained features and residual features.","By adjusting the residual features, we align the unlearned model with the pre-trained model at the intermediate feature level to achieve both unlearning and remaining targets.","The method aims to learn the zero residuals on the retained set and shifted residuals on the unlearning set.","Extensive experiments on numerous datasets validate the effectiveness of our approach."],"url":"http://arxiv.org/abs/2411.08443v1"}
{"created":"2024-11-13 08:43:37","title":"Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data","abstract":"Given the growing trend of many organizations integrating Retrieval Augmented Generation (RAG) into their operations, we assess RAG on domain-specific data and test state-of-the-art models across various optimization techniques. We incorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble Retriever, and In-Context-Learning, to enhance the functionality and performance in the academic domain. We focus on data retrieval, specifically targeting various study programs at a large technical university. We additionally introduce a novel evaluation approach, the RAG Confusion Matrix designed to assess the effectiveness of various configurations within the RAG framework. By exploring the integration of both open-source (e.g., Llama2, Mistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer valuable insights into the application and optimization of RAG frameworks in domain-specific contexts. Our experiments show a significant performance increase when including multi-query in the retrieval phase.","sentences":["Given the growing trend of many organizations integrating Retrieval Augmented Generation (RAG) into their operations, we assess RAG on domain-specific data and test state-of-the-art models across various optimization techniques.","We incorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble Retriever, and In-Context-Learning, to enhance the functionality and performance in the academic domain.","We focus on data retrieval, specifically targeting various study programs at a large technical university.","We additionally introduce a novel evaluation approach, the RAG Confusion Matrix designed to assess the effectiveness of various configurations within the RAG framework.","By exploring the integration of both open-source (e.g., Llama2, Mistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer valuable insights into the application and optimization of RAG frameworks in domain-specific contexts.","Our experiments show a significant performance increase when including multi-query in the retrieval phase."],"url":"http://arxiv.org/abs/2411.08438v1"}
{"created":"2024-11-13 08:34:18","title":"Anonymous Distributed Localisation via Spatial Population Protocols","abstract":"In the distributed localization problem (DLP), n anonymous robots (agents) A0, A1, ..., A(n-1) begin at arbitrary positions p0, ..., p(n-1) in S, where S is a Euclidean space. The primary goal in DLP is for agents to reach a consensus on a unified coordinate system that accurately reflects the relative positions of all points, p0, ... , p(n-1), in S. Extensive research on DLP has primarily focused on the feasibility and complexity of achieving consensus when agents have limited access to inter-agent distances, often due to missing or imprecise data. In this paper, however, we examine a minimalist, computationally efficient model of distributed computing in which agents have access to all pairwise distances, if needed. Specifically, we introduce a novel variant of population protocols, referred to as the spatial population protocols model. In this variant each agent can memorise one or a fixed number of coordinates, and when agents A(i) and A(j) interact, they can not only exchange their current knowledge but also either determine the distance d(i,j) between them in S (distance query model) or obtain the vector v(i,j) spanning points p(i) and p(j) (vector query model).   We examine three DLP scenarios:   - Self-stabilising localisation protocol with distance queries We propose and analyse self-stabilising localisation protocol based on pairwise distance adjustment. We also discuss several hard instances in this scenario, and suggest possible improvements for the considered protocol,   - Leader-based localisation protocol with distance queries We propose and analyse several leader-based protocols which stabilise in o(n) parallel time. These protocols rely on efficient solution to multi-contact epidemic, and   - Self-stabilising localisation protocol with vector queries We propose and analyse superfast self-stabilising DLP protocol which stabilises in O(log n) parallel time.","sentences":["In the distributed localization problem (DLP), n anonymous robots (agents) A0, A1, ..., A(n-1) begin at arbitrary positions p0, ..., p(n-1) in S, where S is a Euclidean space.","The primary goal in DLP is for agents to reach a consensus on a unified coordinate system that accurately reflects the relative positions of all points, p0, ... , p(n-1), in S. Extensive research on DLP has primarily focused on the feasibility and complexity of achieving consensus when agents have limited access to inter-agent distances, often due to missing or imprecise data.","In this paper, however, we examine a minimalist, computationally efficient model of distributed computing in which agents have access to all pairwise distances, if needed.","Specifically, we introduce a novel variant of population protocols, referred to as the spatial population protocols model.","In this variant each agent can memorise one or a fixed number of coordinates, and when agents A(i) and A(j) interact, they can not only exchange their current knowledge but also either determine the distance d(i,j) between them in S (distance query model) or obtain the vector v(i,j) spanning points p(i) and p(j) (vector query model).   ","We examine three DLP scenarios:   - Self-stabilising localisation protocol with distance queries We propose and analyse self-stabilising localisation protocol based on pairwise distance adjustment.","We also discuss several hard instances in this scenario, and suggest possible improvements for the considered protocol,   - Leader-based localisation protocol with distance queries We propose and analyse several leader-based protocols which stabilise in o(n) parallel time.","These protocols rely on efficient solution to multi-contact epidemic, and   - Self-stabilising localisation protocol with vector queries We propose and analyse superfast self-stabilising DLP protocol which stabilises in O(log n) parallel time."],"url":"http://arxiv.org/abs/2411.08434v1"}
{"created":"2024-11-13 08:34:07","title":"3D Multi-Object Tracking with Semi-Supervised GRU-Kalman Filter","abstract":"3D Multi-Object Tracking (MOT), a fundamental component of environmental perception, is essential for intelligent systems like autonomous driving and robotic sensing. Although Tracking-by-Detection frameworks have demonstrated excellent performance in recent years, their application in real-world scenarios faces significant challenges. Object movement in complex environments is often highly nonlinear, while existing methods typically rely on linear approximations of motion. Furthermore, system noise is frequently modeled as a Gaussian distribution, which fails to capture the true complexity of the noise dynamics. These oversimplified modeling assumptions can lead to significant reductions in tracking precision. To address this, we propose a GRU-based MOT method, which introduces a learnable Kalman filter into the motion module. This approach is able to learn object motion characteristics through data-driven learning, thereby avoiding the need for manual model design and model error. At the same time, to avoid abnormal supervision caused by the wrong association between annotations and trajectories, we design a semi-supervised learning strategy to accelerate the convergence speed and improve the robustness of the model. Evaluation experiment on the nuScenes and Argoverse2 datasets demonstrates that our system exhibits superior performance and significant potential compared to traditional TBD methods.","sentences":["3D Multi-Object Tracking (MOT), a fundamental component of environmental perception, is essential for intelligent systems like autonomous driving and robotic sensing.","Although Tracking-by-Detection frameworks have demonstrated excellent performance in recent years, their application in real-world scenarios faces significant challenges.","Object movement in complex environments is often highly nonlinear, while existing methods typically rely on linear approximations of motion.","Furthermore, system noise is frequently modeled as a Gaussian distribution, which fails to capture the true complexity of the noise dynamics.","These oversimplified modeling assumptions can lead to significant reductions in tracking precision.","To address this, we propose a GRU-based MOT method, which introduces a learnable Kalman filter into the motion module.","This approach is able to learn object motion characteristics through data-driven learning, thereby avoiding the need for manual model design and model error.","At the same time, to avoid abnormal supervision caused by the wrong association between annotations and trajectories, we design a semi-supervised learning strategy to accelerate the convergence speed and improve the robustness of the model.","Evaluation experiment on the nuScenes and Argoverse2 datasets demonstrates that our system exhibits superior performance and significant potential compared to traditional TBD methods."],"url":"http://arxiv.org/abs/2411.08433v1"}
{"created":"2024-11-13 08:17:52","title":"A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis","abstract":"Brain connectivity alternations associated with brain disorders have been widely reported in resting-state functional imaging (rs-fMRI) and diffusion tensor imaging (DTI). While many dual-modal fusion methods based on graph neural networks (GNNs) have been proposed, they generally follow homogenous fusion ways ignoring rich heterogeneity of dual-modal information. To address this issue, we propose a novel method that integrates functional and structural connectivity based on heterogeneous graph neural networks (HGNNs) to better leverage the rich heterogeneity in dual-modal images. We firstly use blood oxygen level dependency and whiter matter structure information provided by rs-fMRI and DTI to establish homo-meta-path, capturing node relationships within the same modality. At the same time, we propose to establish hetero-meta-path based on structure-function coupling and brain community searching to capture relations among cross-modal nodes. Secondly, we further introduce a heterogeneous graph pooling strategy that automatically balances homo- and hetero-meta-path, effectively leveraging heterogeneous information and preventing feature confusion after pooling. Thirdly, based on the flexibility of heterogeneous graphs, we propose a heterogeneous graph data augmentation approach that can conveniently address the sample imbalance issue commonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset for mild cognitive impairment (MCI) diagnosis. Experimental results indicate the proposed method is effective and superior to other algorithms, with a mean classification accuracy of 93.3%.","sentences":["Brain connectivity alternations associated with brain disorders have been widely reported in resting-state functional imaging (rs-fMRI) and diffusion tensor imaging (DTI).","While many dual-modal fusion methods based on graph neural networks (GNNs) have been proposed, they generally follow homogenous fusion ways ignoring rich heterogeneity of dual-modal information.","To address this issue, we propose a novel method that integrates functional and structural connectivity based on heterogeneous graph neural networks (HGNNs) to better leverage the rich heterogeneity in dual-modal images.","We firstly use blood oxygen level dependency and whiter matter structure information provided by rs-fMRI and DTI to establish homo-meta-path, capturing node relationships within the same modality.","At the same time, we propose to establish hetero-meta-path based on structure-function coupling and brain community searching to capture relations among cross-modal nodes.","Secondly, we further introduce a heterogeneous graph pooling strategy that automatically balances homo- and hetero-meta-path, effectively leveraging heterogeneous information and preventing feature confusion after pooling.","Thirdly, based on the flexibility of heterogeneous graphs, we propose a heterogeneous graph data augmentation approach that can conveniently address the sample imbalance issue commonly seen in clinical diagnosis.","We evaluate our method on ADNI-3 dataset for mild cognitive impairment (MCI) diagnosis.","Experimental results indicate the proposed method is effective and superior to other algorithms, with a mean classification accuracy of 93.3%."],"url":"http://arxiv.org/abs/2411.08424v1"}
{"created":"2024-11-13 07:55:41","title":"DiVR: incorporating context from diverse VR scenes for human trajectory prediction","abstract":"Virtual environments provide a rich and controlled setting for collecting detailed data on human behavior, offering unique opportunities for predicting human trajectories in dynamic scenes. However, most existing approaches have overlooked the potential of these environments, focusing instead on static contexts without considering userspecific factors. Employing the CREATTIVE3D dataset, our work models trajectories recorded in virtual reality (VR) scenes for diverse situations including road-crossing tasks with user interactions and simulated visual impairments. We propose Diverse Context VR Human Motion Prediction (DiVR), a cross-modal transformer based on the Perceiver architecture that integrates both static and dynamic scene context using a heterogeneous graph convolution network. We conduct extensive experiments comparing DiVR against existing architectures including MLP, LSTM, and transformers with gaze and point cloud context. Additionally, we also stress test our model's generalizability across different users, tasks, and scenes. Results show that DiVR achieves higher accuracy and adaptability compared to other models and to static graphs. This work highlights the advantages of using VR datasets for context-aware human trajectory modeling, with potential applications in enhancing user experiences in the metaverse. Our source code is publicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model.","sentences":["Virtual environments provide a rich and controlled setting for collecting detailed data on human behavior, offering unique opportunities for predicting human trajectories in dynamic scenes.","However, most existing approaches have overlooked the potential of these environments, focusing instead on static contexts without considering userspecific factors.","Employing the CREATTIVE3D dataset, our work models trajectories recorded in virtual reality (VR) scenes for diverse situations including road-crossing tasks with user interactions and simulated visual impairments.","We propose Diverse Context VR Human Motion Prediction (DiVR), a cross-modal transformer based on the Perceiver architecture that integrates both static and dynamic scene context using a heterogeneous graph convolution network.","We conduct extensive experiments comparing DiVR against existing architectures including MLP, LSTM, and transformers with gaze and point cloud context.","Additionally, we also stress test our model's generalizability across different users, tasks, and scenes.","Results show that DiVR achieves higher accuracy and adaptability compared to other models and to static graphs.","This work highlights the advantages of using VR datasets for context-aware human trajectory modeling, with potential applications in enhancing user experiences in the metaverse.","Our source code is publicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model."],"url":"http://arxiv.org/abs/2411.08409v1"}
{"created":"2024-11-13 07:41:47","title":"V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion","abstract":"Current Vehicle-to-Everything (V2X) systems have significantly enhanced 3D object detection using LiDAR and camera data. However, these methods suffer from performance degradation in adverse weather conditions. The weatherrobust 4D radar provides Doppler and additional geometric information, raising the possibility of addressing this challenge. To this end, we present V2X-R, the first simulated V2X dataset incorporating LiDAR, camera, and 4D radar. V2X-R contains 12,079 scenarios with 37,727 frames of LiDAR and 4D radar point clouds, 150,908 images, and 170,859 annotated 3D vehicle bounding boxes. Subsequently, we propose a novel cooperative LiDAR-4D radar fusion pipeline for 3D object detection and implement it with various fusion strategies. To achieve weather-robust detection, we additionally propose a Multi-modal Denoising Diffusion (MDD) module in our fusion pipeline. MDD utilizes weather-robust 4D radar feature as a condition to prompt the diffusion model to denoise noisy LiDAR features. Experiments show that our LiDAR-4D radar fusion pipeline demonstrates superior performance in the V2X-R dataset. Over and above this, our MDD module further improved the performance of basic fusion model by up to 5.73%/6.70% in foggy/snowy conditions with barely disrupting normal performance. The dataset and code will be publicly available at: https://github.com/ylwhxht/V2X-R.","sentences":["Current Vehicle-to-Everything (V2X) systems have significantly enhanced 3D object detection using LiDAR and camera data.","However, these methods suffer from performance degradation in adverse weather conditions.","The weatherrobust 4D radar provides Doppler and additional geometric information, raising the possibility of addressing this challenge.","To this end, we present V2X-R, the first simulated V2X dataset incorporating LiDAR, camera, and 4D radar.","V2X-R contains 12,079 scenarios with 37,727 frames of LiDAR and 4D radar point clouds, 150,908 images, and 170,859 annotated 3D vehicle bounding boxes.","Subsequently, we propose a novel cooperative LiDAR-4D radar fusion pipeline for 3D object detection and implement it with various fusion strategies.","To achieve weather-robust detection, we additionally propose a Multi-modal Denoising Diffusion (MDD) module in our fusion pipeline.","MDD utilizes weather-robust 4D radar feature as a condition to prompt the diffusion model to denoise noisy LiDAR features.","Experiments show that our LiDAR-4D radar fusion pipeline demonstrates superior performance in the V2X-R dataset.","Over and above this, our MDD module further improved the performance of basic fusion model by up to 5.73%/6.70% in foggy/snowy conditions with barely disrupting normal performance.","The dataset and code will be publicly available at: https://github.com/ylwhxht/V2X-R."],"url":"http://arxiv.org/abs/2411.08402v1"}
{"created":"2024-11-13 07:32:58","title":"CLaSP: Learning Concepts for Time-Series Signals from Natural Language Supervision","abstract":"This paper proposes a foundation model called \"CLaSP\" that can search time series signals using natural language that describes the characteristics of the signals as queries. Previous efforts to represent time series signal data in natural language have had challenges in designing a conventional class of time series signal characteristics, formulating their quantification, and creating a dictionary of synonyms. To overcome these limitations, the proposed method introduces a neural network based on contrastive learning. This network is first trained using the datasets TRUCE and SUSHI, which consist of time series signals and their corresponding natural language descriptions. Previous studies have proposed vocabularies that data analysts use to describe signal characteristics, and SUSHI was designed to cover these terms. We believe that a neural network trained on these datasets will enable data analysts to search using natural language vocabulary. Furthermore, our method does not require a dictionary of predefined synonyms, and it leverages common sense knowledge embedded in a large-scale language model (LLM). Experimental results demonstrate that CLaSP enables natural language search of time series signal data and can accurately learn the points at which signal data changes.","sentences":["This paper proposes a foundation model called \"CLaSP\" that can search time series signals using natural language that describes the characteristics of the signals as queries.","Previous efforts to represent time series signal data in natural language have had challenges in designing a conventional class of time series signal characteristics, formulating their quantification, and creating a dictionary of synonyms.","To overcome these limitations, the proposed method introduces a neural network based on contrastive learning.","This network is first trained using the datasets TRUCE and SUSHI, which consist of time series signals and their corresponding natural language descriptions.","Previous studies have proposed vocabularies that data analysts use to describe signal characteristics, and SUSHI was designed to cover these terms.","We believe that a neural network trained on these datasets will enable data analysts to search using natural language vocabulary.","Furthermore, our method does not require a dictionary of predefined synonyms, and it leverages common sense knowledge embedded in a large-scale language model (LLM).","Experimental results demonstrate that CLaSP enables natural language search of time series signal data and can accurately learn the points at which signal data changes."],"url":"http://arxiv.org/abs/2411.08397v1"}
{"created":"2024-11-13 07:05:40","title":"EgoVid-5M: A Large-Scale Video-Action Dataset for Egocentric Video Generation","abstract":"Video generation has emerged as a promising tool for world simulation, leveraging visual data to replicate real-world environments. Within this context, egocentric video generation, which centers on the human perspective, holds significant potential for enhancing applications in virtual reality, augmented reality, and gaming. However, the generation of egocentric videos presents substantial challenges due to the dynamic nature of egocentric viewpoints, the intricate diversity of actions, and the complex variety of scenes encountered. Existing datasets are inadequate for addressing these challenges effectively. To bridge this gap, we present EgoVid-5M, the first high-quality dataset specifically curated for egocentric video generation. EgoVid-5M encompasses 5 million egocentric video clips and is enriched with detailed action annotations, including fine-grained kinematic control and high-level textual descriptions. To ensure the integrity and usability of the dataset, we implement a sophisticated data cleaning pipeline designed to maintain frame consistency, action coherence, and motion smoothness under egocentric conditions. Furthermore, we introduce EgoDreamer, which is capable of generating egocentric videos driven simultaneously by action descriptions and kinematic control signals. The EgoVid-5M dataset, associated action annotations, and all data cleansing metadata will be released for the advancement of research in egocentric video generation.","sentences":["Video generation has emerged as a promising tool for world simulation, leveraging visual data to replicate real-world environments.","Within this context, egocentric video generation, which centers on the human perspective, holds significant potential for enhancing applications in virtual reality, augmented reality, and gaming.","However, the generation of egocentric videos presents substantial challenges due to the dynamic nature of egocentric viewpoints, the intricate diversity of actions, and the complex variety of scenes encountered.","Existing datasets are inadequate for addressing these challenges effectively.","To bridge this gap, we present EgoVid-5M, the first high-quality dataset specifically curated for egocentric video generation.","EgoVid-5","M encompasses 5 million egocentric video clips and is enriched with detailed action annotations, including fine-grained kinematic control and high-level textual descriptions.","To ensure the integrity and usability of the dataset, we implement a sophisticated data cleaning pipeline designed to maintain frame consistency, action coherence, and motion smoothness under egocentric conditions.","Furthermore, we introduce EgoDreamer, which is capable of generating egocentric videos driven simultaneously by action descriptions and kinematic control signals.","The EgoVid-5M dataset, associated action annotations, and all data cleansing metadata will be released for the advancement of research in egocentric video generation."],"url":"http://arxiv.org/abs/2411.08380v1"}
{"created":"2024-11-13 06:54:05","title":"Federated Graph Learning with Graphless Clients","abstract":"Federated Graph Learning (FGL) is tasked with training machine learning models, such as Graph Neural Networks (GNNs), for multiple clients, each with its own graph data. Existing methods usually assume that each client has both node features and graph structure of its graph data. In real-world scenarios, however, there exist federated systems where only a part of the clients have such data while other clients (i.e. graphless clients) may only have node features. This naturally leads to a novel problem in FGL: how to jointly train a model over distributed graph data with graphless clients? In this paper, we propose a novel framework FedGLS to tackle the problem in FGL with graphless clients. In FedGLS, we devise a local graph learner on each graphless client which learns the local graph structure with the structure knowledge transferred from other clients. To enable structure knowledge transfer, we design a GNN model and a feature encoder on each client. During local training, the feature encoder retains the local graph structure knowledge together with the GNN model via knowledge distillation, and the structure knowledge is transferred among clients in global update. Our extensive experiments demonstrate the superiority of the proposed FedGLS over five baselines.","sentences":["Federated Graph Learning (FGL) is tasked with training machine learning models, such as Graph Neural Networks (GNNs), for multiple clients, each with its own graph data.","Existing methods usually assume that each client has both node features and graph structure of its graph data.","In real-world scenarios, however, there exist federated systems where only a part of the clients have such data while other clients (i.e. graphless clients) may only have node features.","This naturally leads to a novel problem in FGL: how to jointly train a model over distributed graph data with graphless clients?","In this paper, we propose a novel framework FedGLS to tackle the problem in FGL with graphless clients.","In FedGLS, we devise a local graph learner on each graphless client which learns the local graph structure with the structure knowledge transferred from other clients.","To enable structure knowledge transfer, we design a GNN model and a feature encoder on each client.","During local training, the feature encoder retains the local graph structure knowledge together with the GNN model via knowledge distillation, and the structure knowledge is transferred among clients in global update.","Our extensive experiments demonstrate the superiority of the proposed FedGLS over five baselines."],"url":"http://arxiv.org/abs/2411.08374v1"}
{"created":"2024-11-13 06:40:17","title":"A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants","abstract":"Early fault detection and timely maintenance scheduling can significantly mitigate operational risks in NPPs and enhance the reliability of operator decision-making. Therefore, it is necessary to develop an efficient Prognostics and Health Management (PHM) multi-step prediction model for predicting of system health status and prompt execution of maintenance operations. In this study, we propose a novel predictive model that integrates reinforcement learning with Long Short-Term Memory (LSTM) neural networks and the Expert Fuzzy Evaluation Method. The model is validated using parameter data for 20 different breach sizes in the Main Steam Line Break (MSLB) accident condition of the CPR1000 pressurized water reactor simulation model and it demonstrates a remarkable capability in accurately forecasting NPP parameter changes up to 128 steps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds), thereby satisfying the temporal advance requirement for fault prognostics in NPPs. Furthermore, this method provides an effective reference solution for PHM applications such as anomaly detection and remaining useful life prediction.","sentences":["Early fault detection and timely maintenance scheduling can significantly mitigate operational risks in NPPs and enhance the reliability of operator decision-making.","Therefore, it is necessary to develop an efficient Prognostics and Health Management (PHM) multi-step prediction model for predicting of system health status and prompt execution of maintenance operations.","In this study, we propose a novel predictive model that integrates reinforcement learning with Long Short-Term Memory (LSTM) neural networks and the Expert Fuzzy Evaluation Method.","The model is validated using parameter data for 20 different breach sizes in the Main Steam Line Break (MSLB) accident condition of the CPR1000 pressurized water reactor simulation model and it demonstrates a remarkable capability in accurately forecasting NPP parameter changes up to 128 steps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds), thereby satisfying the temporal advance requirement for fault prognostics in NPPs.","Furthermore, this method provides an effective reference solution for PHM applications such as anomaly detection and remaining useful life prediction."],"url":"http://arxiv.org/abs/2411.08370v1"}
{"created":"2024-11-13 06:23:54","title":"On Algorithmic Fairness and the EU Regulations","abstract":"The paper discusses algorithmic fairness by focusing on non-discrimination and a few important laws in the European Union (EU). In addition to the EU laws addressing discrimination explicitly, the discussion is based on the EU's recently enacted regulation for artificial intelligence (AI) and the older General Data Protection Regulation (GDPR). Through theoretical case analysis, on one hand, the paper demonstrates that correcting discriminatory biases in AI systems can be legally done under the EU regulations. On the other hand, the cases also illustrate some practical scenarios from which legal non-compliance may follow. With these cases and the accompanying discussion, the paper contributes to the algorithmic fairness research with a few legal insights, enlarging and strengthening also the growing research domain of compliance in software engineering.","sentences":["The paper discusses algorithmic fairness by focusing on non-discrimination and a few important laws in the European Union (EU).","In addition to the EU laws addressing discrimination explicitly, the discussion is based on the EU's recently enacted regulation for artificial intelligence (AI) and the older General Data Protection Regulation (GDPR).","Through theoretical case analysis, on one hand, the paper demonstrates that correcting discriminatory biases in AI systems can be legally done under the EU regulations.","On the other hand, the cases also illustrate some practical scenarios from which legal non-compliance may follow.","With these cases and the accompanying discussion, the paper contributes to the algorithmic fairness research with a few legal insights, enlarging and strengthening also the growing research domain of compliance in software engineering."],"url":"http://arxiv.org/abs/2411.08363v1"}
{"created":"2024-11-13 06:16:12","title":"Coverage Analysis for Digital Cousin Selection -- Improving Multi-Environment Q-Learning","abstract":"Q-learning is widely employed for optimizing various large-dimensional networks with unknown system dynamics. Recent advancements include multi-environment mixed Q-learning (MEMQ) algorithms, which utilize multiple independent Q-learning algorithms across multiple, structurally related but distinct environments and outperform several state-of-the-art Q-learning algorithms in terms of accuracy, complexity, and robustness. We herein conduct a comprehensive probabilistic coverage analysis to ensure optimal data coverage conditions for MEMQ algorithms. First, we derive upper and lower bounds on the expectation and variance of different coverage coefficients (CC) for MEMQ algorithms. Leveraging these bounds, we develop a simple way of comparing the utilities of multiple environments in MEMQ algorithms. This approach appears to be near optimal versus our previously proposed partial ordering approach. We also present a novel CC-based MEMQ algorithm to improve the accuracy and complexity of existing MEMQ algorithms. Numerical experiments are conducted using random network graphs with four different graph properties. Our algorithm can reduce the average policy error (APE) by 65% compared to partial ordering and is 95% faster than the exhaustive search. It also achieves 60% less APE than several state-of-the-art reinforcement learning and prior MEMQ algorithms. Additionally, we numerically verify the theoretical results and show their scalability with the action-space size.","sentences":["Q-learning is widely employed for optimizing various large-dimensional networks with unknown system dynamics.","Recent advancements include multi-environment mixed Q-learning (MEMQ) algorithms, which utilize multiple independent Q-learning algorithms across multiple, structurally related but distinct environments and outperform several state-of-the-art Q-learning algorithms in terms of accuracy, complexity, and robustness.","We herein conduct a comprehensive probabilistic coverage analysis to ensure optimal data coverage conditions for MEMQ algorithms.","First, we derive upper and lower bounds on the expectation and variance of different coverage coefficients (CC) for MEMQ algorithms.","Leveraging these bounds, we develop a simple way of comparing the utilities of multiple environments in MEMQ algorithms.","This approach appears to be near optimal versus our previously proposed partial ordering approach.","We also present a novel CC-based MEMQ algorithm to improve the accuracy and complexity of existing MEMQ algorithms.","Numerical experiments are conducted using random network graphs with four different graph properties.","Our algorithm can reduce the average policy error (APE) by 65% compared to partial ordering and is 95% faster than the exhaustive search.","It also achieves 60% less APE than several state-of-the-art reinforcement learning and prior MEMQ algorithms.","Additionally, we numerically verify the theoretical results and show their scalability with the action-space size."],"url":"http://arxiv.org/abs/2411.08360v1"}
{"created":"2024-11-13 06:15:48","title":"MultiKG: Multi-Source Threat Intelligence Aggregation for High-Quality Knowledge Graph Representation of Attack Techniques","abstract":"The construction of attack technique knowledge graphs aims to transform various types of attack knowledge into structured representations for more effective attack procedure modeling. Existing methods typically rely on textual data, such as Cyber Threat Intelligence (CTI) reports, which are often coarse-grained and unstructured, resulting in incomplete and inaccurate knowledge graphs. To address these issues, we expand attack knowledge sources by incorporating audit logs and static code analysis alongside CTI reports, providing finer-grained data for constructing attack technique knowledge graphs.   We propose MultiKG, a fully automated framework that integrates multiple threat knowledge sources. MultiKG processes data from CTI reports, dynamic logs, and static code separately, then merges them into a unified attack knowledge graph. Through system design and the utilization of the Large Language Model (LLM), MultiKG automates the analysis, construction, and merging of attack graphs across these sources, producing a fine-grained, multi-source attack knowledge graph.   We implemented MultiKG and evaluated it using 1,015 real attack techniques and 9,006 attack intelligence entries from CTI reports. Results show that MultiKG effectively extracts attack knowledge graphs from diverse sources and aggregates them into accurate, comprehensive representations. Through case studies, we demonstrate that our approach directly benefits security tasks such as attack reconstruction and detection.","sentences":["The construction of attack technique knowledge graphs aims to transform various types of attack knowledge into structured representations for more effective attack procedure modeling.","Existing methods typically rely on textual data, such as Cyber Threat Intelligence (CTI) reports, which are often coarse-grained and unstructured, resulting in incomplete and inaccurate knowledge graphs.","To address these issues, we expand attack knowledge sources by incorporating audit logs and static code analysis alongside CTI reports, providing finer-grained data for constructing attack technique knowledge graphs.   ","We propose MultiKG, a fully automated framework that integrates multiple threat knowledge sources.","MultiKG processes data from CTI reports, dynamic logs, and static code separately, then merges them into a unified attack knowledge graph.","Through system design and the utilization of the Large Language Model (LLM), MultiKG automates the analysis, construction, and merging of attack graphs across these sources, producing a fine-grained, multi-source attack knowledge graph.   ","We implemented MultiKG and evaluated it using 1,015 real attack techniques and 9,006 attack intelligence entries from CTI reports.","Results show that MultiKG effectively extracts attack knowledge graphs from diverse sources and aggregates them into accurate, comprehensive representations.","Through case studies, we demonstrate that our approach directly benefits security tasks such as attack reconstruction and detection."],"url":"http://arxiv.org/abs/2411.08359v1"}
{"created":"2024-11-13 05:38:55","title":"A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users","abstract":"Emotion and personality are central elements in understanding human psychological states. Emotions reflect an individual subjective experiences, while personality reveals relatively stable behavioral and cognitive patterns. Existing affective computing datasets often annotate emotion and personality traits separately, lacking fine-grained labeling of micro-emotions and emotion intensity in both single-label and multi-label classifications. Chinese emotion datasets are extremely scarce, and datasets capturing Chinese user personality traits are even more limited. To address these gaps, this study collected data from the major social media platform Weibo, screening 11,338 valid users from over 50,000 individuals with diverse MBTI personality labels and acquiring 566,900 posts along with the user MBTI personality tags. Using the EQN method, we compiled a multi-label Chinese affective computing dataset that integrates the same user's personality traits with six emotions and micro-emotions, each annotated with intensity levels. Validation results across multiple NLP classification models demonstrate the dataset strong utility. This dataset is designed to advance machine recognition of complex human emotions and provide data support for research in psychology, education, marketing, finance, and politics.","sentences":["Emotion and personality are central elements in understanding human psychological states.","Emotions reflect an individual subjective experiences, while personality reveals relatively stable behavioral and cognitive patterns.","Existing affective computing datasets often annotate emotion and personality traits separately, lacking fine-grained labeling of micro-emotions and emotion intensity in both single-label and multi-label classifications.","Chinese emotion datasets are extremely scarce, and datasets capturing Chinese user personality traits are even more limited.","To address these gaps, this study collected data from the major social media platform Weibo, screening 11,338 valid users from over 50,000 individuals with diverse MBTI personality labels and acquiring 566,900 posts along with the user MBTI personality tags.","Using the EQN method, we compiled a multi-label Chinese affective computing dataset that integrates the same user's personality traits with six emotions and micro-emotions, each annotated with intensity levels.","Validation results across multiple NLP classification models demonstrate the dataset strong utility.","This dataset is designed to advance machine recognition of complex human emotions and provide data support for research in psychology, education, marketing, finance, and politics."],"url":"http://arxiv.org/abs/2411.08347v1"}
{"created":"2024-11-13 05:15:25","title":"Generative AI for Data Augmentation in Wireless Networks: Analysis, Applications, and Case Study","abstract":"Data augmentation is a powerful technique to mitigate data scarcity. However, owing to fundamental differences in wireless data structures, traditional data augmentation techniques may not be suitable for wireless data. Fortunately, Generative Artificial Intelligence (GenAI) can be an effective alternative to wireless data augmentation due to its excellent data generation capability. This article systemically explores the potential and effectiveness of GenAI-driven data augmentation in wireless networks. We first briefly review data augmentation techniques, discuss their limitations in wireless networks, and introduce generative data augmentation, including reviewing GenAI models and their applications in data augmentation. We then explore the application prospects of GenAI-driven data augmentation in wireless networks from the physical, network, and application layers, which provides a GenAI-driven data augmentation architecture for each application. Subsequently, we propose a general generative diffusion model-based data augmentation framework for Wi-Fi gesture recognition, which uses transformer-based diffusion models to generate high-quality channel state information data. Furthermore, we develop residual neural network models for Wi-Fi gesture recognition to evaluate the role of augmented data and conduct a case study based on a real dataset. Simulation results demonstrate the effectiveness of the proposed framework. Finally, we discuss research directions for generative data augmentation.","sentences":["Data augmentation is a powerful technique to mitigate data scarcity.","However, owing to fundamental differences in wireless data structures, traditional data augmentation techniques may not be suitable for wireless data.","Fortunately, Generative Artificial Intelligence (GenAI) can be an effective alternative to wireless data augmentation due to its excellent data generation capability.","This article systemically explores the potential and effectiveness of GenAI-driven data augmentation in wireless networks.","We first briefly review data augmentation techniques, discuss their limitations in wireless networks, and introduce generative data augmentation, including reviewing GenAI models and their applications in data augmentation.","We then explore the application prospects of GenAI-driven data augmentation in wireless networks from the physical, network, and application layers, which provides a GenAI-driven data augmentation architecture for each application.","Subsequently, we propose a general generative diffusion model-based data augmentation framework for Wi-Fi gesture recognition, which uses transformer-based diffusion models to generate high-quality channel state information data.","Furthermore, we develop residual neural network models for Wi-Fi gesture recognition to evaluate the role of augmented data and conduct a case study based on a real dataset.","Simulation results demonstrate the effectiveness of the proposed framework.","Finally, we discuss research directions for generative data augmentation."],"url":"http://arxiv.org/abs/2411.08341v1"}
{"created":"2024-11-13 05:09:28","title":"DyConfidMatch: Dynamic Thresholding and Re-sampling for 3D Semi-supervised Learning","abstract":"Semi-supervised learning (SSL) leverages limited labeled and abundant unlabeled data but often faces challenges with data imbalance, especially in 3D contexts. This study investigates class-level confidence as an indicator of learning status in 3D SSL, proposing a novel method that utilizes dynamic thresholding to better use unlabeled data, particularly from underrepresented classes. A re-sampling strategy is also introduced to mitigate bias towards well-represented classes, ensuring equitable class representation. Through extensive experiments in 3D SSL, our method surpasses state-of-the-art counterparts in classification and detection tasks, highlighting its effectiveness in tackling data imbalance. This approach presents a significant advancement in SSL for 3D datasets, providing a robust solution for data imbalance issues.","sentences":["Semi-supervised learning (SSL) leverages limited labeled and abundant unlabeled data but often faces challenges with data imbalance, especially in 3D contexts.","This study investigates class-level confidence as an indicator of learning status in 3D SSL, proposing a novel method that utilizes dynamic thresholding to better use unlabeled data, particularly from underrepresented classes.","A re-sampling strategy is also introduced to mitigate bias towards well-represented classes, ensuring equitable class representation.","Through extensive experiments in 3D SSL, our method surpasses state-of-the-art counterparts in classification and detection tasks, highlighting its effectiveness in tackling data imbalance.","This approach presents a significant advancement in SSL for 3D datasets, providing a robust solution for data imbalance issues."],"url":"http://arxiv.org/abs/2411.08340v1"}
{"created":"2024-11-13 04:49:32","title":"DEEGITS: Deep Learning based Framework for Measuring Heterogenous Traffic State in Challenging Traffic Scenarios","abstract":"This paper presents DEEGITS (Deep Learning Based Heterogeneous Traffic State Measurement), a comprehensive framework that leverages state-of-the-art convolutional neural network (CNN) techniques to accurately and rapidly detect vehicles and pedestrians, as well as to measure traffic states in challenging scenarios (i.e., congestion, occlusion). In this study, we enhance the training dataset through data fusion, enabling simultaneous detection of vehicles and pedestrians. Image preprocessing and augmentation are subsequently performed to improve the quality and quantity of the dataset. Transfer learning is applied on the YOLOv8 pretrained model to increase the model's capability to identify a diverse array of vehicles. Optimal hyperparameters are obtained using the Grid Search algorithm, with the Stochastic Gradient Descent (SGD) optimizer outperforming other optimizers under these settings. Extensive experimentation and evaluation demonstrate substantial accuracy within the detection framework, with the model achieving 0.794 mAP@0.5 on the validation set and 0.786 mAP@0.5 on the test set, surpassing previous benchmarks on similar datasets. The DeepSORT multi-object tracking algorithm is incorporated to track detected vehicles and pedestrians in this study. Finally, the framework is tested to measure heterogeneous traffic states in mixed traffic conditions. Two locations with differing traffic compositions and congestion levels are selected: one motorized-dominant location with moderate density and one non-motorized-dominant location with higher density. Errors are statistically insignificant for both cases, showing correlations from 0.99 to 0.88 and 0.91 to 0.97 for heterogeneous traffic flow and speed measurements, respectively.","sentences":["This paper presents DEEGITS (Deep Learning Based Heterogeneous Traffic State Measurement), a comprehensive framework that leverages state-of-the-art convolutional neural network (CNN) techniques to accurately and rapidly detect vehicles and pedestrians, as well as to measure traffic states in challenging scenarios (i.e., congestion, occlusion).","In this study, we enhance the training dataset through data fusion, enabling simultaneous detection of vehicles and pedestrians.","Image preprocessing and augmentation are subsequently performed to improve the quality and quantity of the dataset.","Transfer learning is applied on the YOLOv8 pretrained model to increase the model's capability to identify a diverse array of vehicles.","Optimal hyperparameters are obtained using the Grid Search algorithm, with the Stochastic Gradient Descent (SGD) optimizer outperforming other optimizers under these settings.","Extensive experimentation and evaluation demonstrate substantial accuracy within the detection framework, with the model achieving 0.794 mAP@0.5 on the validation set and 0.786 mAP@0.5 on the test set, surpassing previous benchmarks on similar datasets.","The DeepSORT multi-object tracking algorithm is incorporated to track detected vehicles and pedestrians in this study.","Finally, the framework is tested to measure heterogeneous traffic states in mixed traffic conditions.","Two locations with differing traffic compositions and congestion levels are selected: one motorized-dominant location with moderate density and one non-motorized-dominant location with higher density.","Errors are statistically insignificant for both cases, showing correlations from 0.99 to 0.88 and 0.91 to 0.97 for heterogeneous traffic flow and speed measurements, respectively."],"url":"http://arxiv.org/abs/2411.08335v1"}
{"created":"2024-11-13 04:27:25","title":"Learning-Augmented Algorithms for Online Concave Packing and Convex Covering Problems","abstract":"Learning-augmented algorithms have been extensively studied across the computer science community in the recent years, driven by advances in machine learning predictors, which can provide additional information to augment classical algorithms. Such predictions are especially powerful in the context of online problems, where decisions have to be made without knowledge of the future, and which traditionally exhibits impossibility results bounding the performance of any online algorithm. The study of learning-augmented algorithms thus aims to use external advice prudently, to overcome classical impossibility results when the advice is accurate, and still perform comparably to the state-of-the-art online algorithms even when the advice is inaccurate.   In this paper, we present learning-augmented algorithmic frameworks for two fundamental optimizations settings, extending and generalizing prior works. For online packing with concave objectives, we present a simple but overarching strategy that switches between the advice and the state-of-the-art online algorithm. For online covering with convex objectives, we greatly extend primal-dual methods for online convex covering programs by Azar et al. (FOCS 2016) and previous learning-augmented framework for online covering linear programs from the literature, to many new applications. We show that our algorithms break impossibility results when the advice is accurate, while maintaining comparable performance with state-of-the-art classical online algorithms even when the advice is erroneous.","sentences":["Learning-augmented algorithms have been extensively studied across the computer science community in the recent years, driven by advances in machine learning predictors, which can provide additional information to augment classical algorithms.","Such predictions are especially powerful in the context of online problems, where decisions have to be made without knowledge of the future, and which traditionally exhibits impossibility results bounding the performance of any online algorithm.","The study of learning-augmented algorithms thus aims to use external advice prudently, to overcome classical impossibility results when the advice is accurate, and still perform comparably to the state-of-the-art online algorithms even when the advice is inaccurate.   ","In this paper, we present learning-augmented algorithmic frameworks for two fundamental optimizations settings, extending and generalizing prior works.","For online packing with concave objectives, we present a simple but overarching strategy that switches between the advice and the state-of-the-art online algorithm.","For online covering with convex objectives, we greatly extend primal-dual methods for online convex covering programs by Azar et al.","(FOCS 2016) and previous learning-augmented framework for online covering linear programs from the literature, to many new applications.","We show that our algorithms break impossibility results when the advice is accurate, while maintaining comparable performance with state-of-the-art classical online algorithms even when the advice is erroneous."],"url":"http://arxiv.org/abs/2411.08332v1"}
{"created":"2024-11-13 04:20:20","title":"Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle","abstract":"Many existing evaluation benchmarks for Large Language Models (LLMs) quickly become outdated due to the emergence of new models and training data. These benchmarks also fall short in assessing how LLM performance changes over time, as they consist of static questions without a temporal dimension. To address these limitations, we propose using future event prediction as a continuous evaluation method to assess LLMs' temporal generalization and forecasting abilities. Our benchmark, Daily Oracle, automatically generates question-answer (QA) pairs from daily news, challenging LLMs to predict \"future\" event outcomes. Our findings reveal that as pre-training data becomes outdated, LLM performance degrades over time. While Retrieval Augmented Generation (RAG) has the potential to enhance prediction accuracy, the performance degradation pattern persists, highlighting the need for continuous model updates.","sentences":["Many existing evaluation benchmarks for Large Language Models (LLMs) quickly become outdated due to the emergence of new models and training data.","These benchmarks also fall short in assessing how LLM performance changes over time, as they consist of static questions without a temporal dimension.","To address these limitations, we propose using future event prediction as a continuous evaluation method to assess LLMs' temporal generalization and forecasting abilities.","Our benchmark, Daily Oracle, automatically generates question-answer (QA) pairs from daily news, challenging LLMs to predict \"future\" event outcomes.","Our findings reveal that as pre-training data becomes outdated, LLM performance degrades over time.","While Retrieval Augmented Generation (RAG) has the potential to enhance prediction accuracy, the performance degradation pattern persists, highlighting the need for continuous model updates."],"url":"http://arxiv.org/abs/2411.08324v1"}
{"created":"2024-11-13 03:42:55","title":"Conditional Variable Flow Matching: Transforming Conditional Densities with Amortized Conditional Optimal Transport","abstract":"Forecasting stochastic nonlinear dynamical systems under the influence of conditioning variables is a fundamental challenge repeatedly encountered across the biological and physical sciences. While flow-based models can impressively predict the temporal evolution of probability distributions representing possible outcomes of a specific process, existing frameworks cannot satisfactorily account for the impact of conditioning variables on these dynamics. Amongst several limitations, existing methods require training data with paired conditions and are developed for discrete conditioning variables. We propose Conditional Variable Flow Matching (CVFM), a framework for learning flows transforming conditional distributions with amortization across continuous conditioning variables - permitting predictions across the conditional density manifold. This is accomplished through several novel advances, in particular, simultaneous sample conditioned flows over the main and conditioning variables, alongside a conditional Wasserstein distance and kernel facilitating conditional optimal transport. Collectively, these advances allow for learning system dynamics provided measurement data whose states and conditioning variables are not in correspondence. We demonstrate CVFM on a suite of increasingly challenging problems, including discrete and continuous conditional mapping benchmarks, image-to-image domain transfer, and modeling the temporal evolution of materials internal structure during manufacturing processes. We observe that CVFM results in improved performance and convergence characteristics over alternative conditional variants.","sentences":["Forecasting stochastic nonlinear dynamical systems under the influence of conditioning variables is a fundamental challenge repeatedly encountered across the biological and physical sciences.","While flow-based models can impressively predict the temporal evolution of probability distributions representing possible outcomes of a specific process, existing frameworks cannot satisfactorily account for the impact of conditioning variables on these dynamics.","Amongst several limitations, existing methods require training data with paired conditions and are developed for discrete conditioning variables.","We propose Conditional Variable Flow Matching (CVFM), a framework for learning flows transforming conditional distributions with amortization across continuous conditioning variables - permitting predictions across the conditional density manifold.","This is accomplished through several novel advances, in particular, simultaneous sample conditioned flows over the main and conditioning variables, alongside a conditional Wasserstein distance and kernel facilitating conditional optimal transport.","Collectively, these advances allow for learning system dynamics provided measurement data whose states and conditioning variables are not in correspondence.","We demonstrate CVFM on a suite of increasingly challenging problems, including discrete and continuous conditional mapping benchmarks, image-to-image domain transfer, and modeling the temporal evolution of materials internal structure during manufacturing processes.","We observe that CVFM results in improved performance and convergence characteristics over alternative conditional variants."],"url":"http://arxiv.org/abs/2411.08314v1"}
{"created":"2024-11-13 03:28:44","title":"A Novel Extensible Simulation Framework for CXL-Enabled Systems","abstract":"Compute Express Link (CXL) serves as a rising industry standard, delivering high-speed cache-coherent links to a variety of devices, including host CPUs, computational accelerators, and memory devices. It is designed to promote system scalability, enable peer-to-peer exchanges, and accelerate data transmissions. To achieve these objectives, the most recent CXL protocol has brought forth several innovative features, such as port-focused routing, device-handled coherence, and PCIe 6.0 compatibility. However, due to the limited availability of hardware prototypes and simulators compatible with CXL, earlier CXL research has largely depended on emulating CXL devices using remote NUMA nodes. Unfortunately, these NUMA-based emulators have difficulties in accurately representing the new features due to fundamental differences in hardware and protocols. Moreover, the absence of support for non-tree topology and PCIe links makes it complex to merely adapt existing simulators for CXL simulation. To overcome these problems, we introduce ESF, a simulation framework specifically designed for CXL systems. ESF has been developed to accurately reflect the unique features of the latest CXL protocol from the ground up. It uses a specialized interconnect layer to facilitate connections within a wide range of system topologies and also includes key components to carry out specific functions required by these features. By utilizing ESF, we thoroughly investigate various aspects of CXL systems, including system topology, device-handled coherence, and the effects of PCIe characteristics, leading to important findings that can guide the creation of high-performance CXL systems. The ESF source codes are fully open-source and can be accessed at https://anonymous.4open.science/r/ESF-1CE3.","sentences":["Compute Express Link (CXL) serves as a rising industry standard, delivering high-speed cache-coherent links to a variety of devices, including host CPUs, computational accelerators, and memory devices.","It is designed to promote system scalability, enable peer-to-peer exchanges, and accelerate data transmissions.","To achieve these objectives, the most recent CXL protocol has brought forth several innovative features, such as port-focused routing, device-handled coherence, and PCIe 6.0 compatibility.","However, due to the limited availability of hardware prototypes and simulators compatible with CXL, earlier CXL research has largely depended on emulating CXL devices using remote NUMA nodes.","Unfortunately, these NUMA-based emulators have difficulties in accurately representing the new features due to fundamental differences in hardware and protocols.","Moreover, the absence of support for non-tree topology and PCIe links makes it complex to merely adapt existing simulators for CXL simulation.","To overcome these problems, we introduce ESF, a simulation framework specifically designed for CXL systems.","ESF has been developed to accurately reflect the unique features of the latest CXL protocol from the ground up.","It uses a specialized interconnect layer to facilitate connections within a wide range of system topologies and also includes key components to carry out specific functions required by these features.","By utilizing ESF, we thoroughly investigate various aspects of CXL systems, including system topology, device-handled coherence, and the effects of PCIe characteristics, leading to important findings that can guide the creation of high-performance CXL systems.","The ESF source codes are fully open-source and can be accessed at https://anonymous.4open.science/r/ESF-1CE3."],"url":"http://arxiv.org/abs/2411.08312v1"}
{"created":"2024-11-13 03:08:33","title":"SDDBench: A Benchmark for Synthesizable Drug Design","abstract":"A significant challenge in wet lab experiments with current drug design generative models is the trade-off between pharmacological properties and synthesizability. Molecules predicted to have highly desirable properties are often difficult to synthesize, while those that are easily synthesizable tend to exhibit less favorable properties. As a result, evaluating the synthesizability of molecules in general drug design scenarios remains a significant challenge in the field of drug discovery. The commonly used synthetic accessibility (SA) score aims to evaluate the ease of synthesizing generated molecules, but it falls short of guaranteeing that synthetic routes can actually be found. Inspired by recent advances in top-down synthetic route generation, we propose a new, data-driven metric to evaluate molecule synthesizability. Our approach directly assesses the feasibility of synthetic routes for a given molecule through our proposed round-trip score. This novel metric leverages the synergistic duality between retrosynthetic planners and reaction predictors, both of which are trained on extensive reaction datasets. To demonstrate the efficacy of our method, we conduct a comprehensive evaluation of round-trip scores alongside search success rate across a range of representative molecule generative models. Code is available at https://github.com/SongtaoLiu0823/SDDBench.","sentences":["A significant challenge in wet lab experiments with current drug design generative models is the trade-off between pharmacological properties and synthesizability.","Molecules predicted to have highly desirable properties are often difficult to synthesize, while those that are easily synthesizable tend to exhibit less favorable properties.","As a result, evaluating the synthesizability of molecules in general drug design scenarios remains a significant challenge in the field of drug discovery.","The commonly used synthetic accessibility (SA) score aims to evaluate the ease of synthesizing generated molecules, but it falls short of guaranteeing that synthetic routes can actually be found.","Inspired by recent advances in top-down synthetic route generation, we propose a new, data-driven metric to evaluate molecule synthesizability.","Our approach directly assesses the feasibility of synthetic routes for a given molecule through our proposed round-trip score.","This novel metric leverages the synergistic duality between retrosynthetic planners and reaction predictors, both of which are trained on extensive reaction datasets.","To demonstrate the efficacy of our method, we conduct a comprehensive evaluation of round-trip scores alongside search success rate across a range of representative molecule generative models.","Code is available at https://github.com/SongtaoLiu0823/SDDBench."],"url":"http://arxiv.org/abs/2411.08306v1"}
{"created":"2024-11-13 02:41:02","title":"DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multi-Agent Reinforcement Learning Approach","abstract":"Unmanned Aerial Vehicles (UAVs) possess high mobility and flexible deployment capabilities, prompting the development of UAVs for various application scenarios within the Internet of Things (IoT). The unique capabilities of UAVs give rise to increasingly critical and complex tasks in uncertain and potentially harsh environments. The substantial amount of data generated from these applications necessitates processing and analysis through deep neural networks (DNNs). However, UAVs encounter challenges due to their limited computing resources when managing DNN models. This paper presents a joint approach that combines multiple-agent reinforcement learning (MARL) and generative diffusion models (GDM) for assigning DNN tasks to a UAV swarm, aimed at reducing latency from task capture to result output. To address these challenges, we first consider the task size of the target area to be inspected and the shortest flying path as optimization constraints, employing a greedy algorithm to resolve the subproblem with a focus on minimizing the UAV's flying path and the overall system cost. In the second stage, we introduce a novel DNN task assignment algorithm, termed GDM-MADDPG, which utilizes the reverse denoising process of GDM to replace the actor network in multi-agent deep deterministic policy gradient (MADDPG). This approach generates specific DNN task assignment actions based on agents' observations in a dynamic environment. Simulation results indicate that our algorithm performs favorably compared to benchmarks in terms of path planning, Age of Information (AoI), energy consumption, and task load balancing.","sentences":["Unmanned Aerial Vehicles (UAVs) possess high mobility and flexible deployment capabilities, prompting the development of UAVs for various application scenarios within the Internet of Things (IoT).","The unique capabilities of UAVs give rise to increasingly critical and complex tasks in uncertain and potentially harsh environments.","The substantial amount of data generated from these applications necessitates processing and analysis through deep neural networks (DNNs).","However, UAVs encounter challenges due to their limited computing resources when managing DNN models.","This paper presents a joint approach that combines multiple-agent reinforcement learning (MARL) and generative diffusion models (GDM) for assigning DNN tasks to a UAV swarm, aimed at reducing latency from task capture to result output.","To address these challenges, we first consider the task size of the target area to be inspected and the shortest flying path as optimization constraints, employing a greedy algorithm to resolve the subproblem with a focus on minimizing the UAV's flying path and the overall system cost.","In the second stage, we introduce a novel DNN task assignment algorithm, termed GDM-MADDPG, which utilizes the reverse denoising process of GDM to replace the actor network in multi-agent deep deterministic policy gradient (MADDPG).","This approach generates specific DNN task assignment actions based on agents' observations in a dynamic environment.","Simulation results indicate that our algorithm performs favorably compared to benchmarks in terms of path planning, Age of Information (AoI), energy consumption, and task load balancing."],"url":"http://arxiv.org/abs/2411.08299v1"}
{"created":"2024-11-13 02:21:59","title":"Collaborative Participatory Research with LLM Agents in South Asia: An Empirically-Grounded Methodological Initiative and Agenda from Field Evidence in Sri Lanka","abstract":"The integration of artificial intelligence into development research methodologies presents unprecedented opportunities for addressing persistent challenges in participatory research, particularly in linguistically diverse regions like South Asia. Drawing from an empirical implementation in Sri Lanka's Sinhala-speaking communities, this paper presents an empirically grounded methodological framework designed to transform participatory development research, situated in the challenging multilingual context of Sri Lanka's flood-prone Nilwala River Basin. Moving beyond conventional translation and data collection tools, this framework deploys a multi-agent system architecture that redefines how data collection, analysis, and community engagement are conducted in linguistically and culturally diverse research settings. This structured agent-based approach enables participatory research that is both scalable and responsive, ensuring that community perspectives remain integral to research outcomes. Field experiences reveal the immense potential of LLM-based systems in addressing long-standing issues in development research across resource-limited regions, offering both quantitative efficiencies and qualitative improvements in inclusivity. At a broader methodological level, this research agenda advocates for AI-driven participatory research tools that maintain ethical considerations, cultural respect, and operational efficiency, highlighting strategic pathways for deploying AI systems that reinforce community agency and equitable knowledge generation, potentially informing broader research agendas across the Global South.","sentences":["The integration of artificial intelligence into development research methodologies presents unprecedented opportunities for addressing persistent challenges in participatory research, particularly in linguistically diverse regions like South Asia.","Drawing from an empirical implementation in Sri Lanka's Sinhala-speaking communities, this paper presents an empirically grounded methodological framework designed to transform participatory development research, situated in the challenging multilingual context of Sri Lanka's flood-prone Nilwala River Basin.","Moving beyond conventional translation and data collection tools, this framework deploys a multi-agent system architecture that redefines how data collection, analysis, and community engagement are conducted in linguistically and culturally diverse research settings.","This structured agent-based approach enables participatory research that is both scalable and responsive, ensuring that community perspectives remain integral to research outcomes.","Field experiences reveal the immense potential of LLM-based systems in addressing long-standing issues in development research across resource-limited regions, offering both quantitative efficiencies and qualitative improvements in inclusivity.","At a broader methodological level, this research agenda advocates for AI-driven participatory research tools that maintain ethical considerations, cultural respect, and operational efficiency, highlighting strategic pathways for deploying AI systems that reinforce community agency and equitable knowledge generation, potentially informing broader research agendas across the Global South."],"url":"http://arxiv.org/abs/2411.08294v1"}
{"created":"2024-11-13 02:17:03","title":"RESOLVE: Relational Reasoning with Symbolic and Object-Level Features Using Vector Symbolic Processing","abstract":"Modern transformer-based encoder-decoder architectures struggle with reasoning tasks due to their inability to effectively extract relational information between input objects (data/tokens). Recent work introduced the Abstractor module, embedded between transformer layers, to address this gap. However, the Abstractor layer while excelling at capturing relational information (pure relational reasoning), faces challenges in tasks that require both object and relational-level reasoning (partial relational reasoning). To address this, we propose RESOLVE, a neuro-vector symbolic architecture that combines object-level features with relational representations in high-dimensional spaces, using fast and efficient operations such as bundling (summation) and binding (Hadamard product) allowing both object-level features and relational representations to coexist within the same structure without interfering with one another. RESOLVE is driven by a novel attention mechanism that operates in a bipolar high dimensional space, allowing fast attention score computation compared to the state-of-the-art. By leveraging this design, the model achieves both low compute latency and memory efficiency. RESOLVE also offers better generalizability while achieving higher accuracy in purely relational reasoning tasks such as sorting as well as partial relational reasoning tasks such as math problem-solving compared to state-of-the-art methods.","sentences":["Modern transformer-based encoder-decoder architectures struggle with reasoning tasks due to their inability to effectively extract relational information between input objects (data/tokens).","Recent work introduced the Abstractor module, embedded between transformer layers, to address this gap.","However, the Abstractor layer while excelling at capturing relational information (pure relational reasoning), faces challenges in tasks that require both object and relational-level reasoning (partial relational reasoning).","To address this, we propose RESOLVE, a neuro-vector symbolic architecture that combines object-level features with relational representations in high-dimensional spaces, using fast and efficient operations such as bundling (summation) and binding (Hadamard product) allowing both object-level features and relational representations to coexist within the same structure without interfering with one another.","RESOLVE is driven by a novel attention mechanism that operates in a bipolar high dimensional space, allowing fast attention score computation compared to the state-of-the-art.","By leveraging this design, the model achieves both low compute latency and memory efficiency.","RESOLVE also offers better generalizability while achieving higher accuracy in purely relational reasoning tasks such as sorting as well as partial relational reasoning tasks such as math problem-solving compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2411.08290v1"}
{"created":"2024-11-13 01:50:44","title":"Dynamic Thresholding Algorithm with Memory for Linear Inverse Problems","abstract":"The relaxed optimal $k$-thresholding pursuit (ROTP) is a recent algorithm for linear inverse problems. This algorithm is based on the optimal $k$-thresholding technique which performs vector thresholding and error metric reduction simultaneously. Although ROTP can be used to solve small to medium-sized linear inverse problems, the computational cost of this algorithm is high when solving large-scale problems. By merging the optimal $k$-thresholding technique and iterative method with memory as well as optimization with sparse search directions, we propose the so-called dynamic thresholding algorithm with memory (DTAM), which iteratively and dynamically selects vector bases to construct the problem solution. At every step, the algorithm uses more than one or all iterates generated so far to construct a new search direction, and solves only the small-sized quadratic subproblems at every iteration. Thus the computational complexity of DTAM is remarkably lower than that of ROTP-type methods. It turns out that DTAM can locate the solution of linear inverse problems if the matrix involved satisfies the restricted isometry property. Experiments on synthetic data, audio signal reconstruction and image denoising demonstrate that the proposed algorithm performs comparably to several mainstream thresholding and greedy algorithms, and it works much faster than the ROTP-type algorithms especially when the sparsity level of signal is relatively low.","sentences":["The relaxed optimal $k$-thresholding pursuit (ROTP) is a recent algorithm for linear inverse problems.","This algorithm is based on the optimal $k$-thresholding technique which performs vector thresholding and error metric reduction simultaneously.","Although ROTP can be used to solve small to medium-sized linear inverse problems, the computational cost of this algorithm is high when solving large-scale problems.","By merging the optimal $k$-thresholding technique and iterative method with memory as well as optimization with sparse search directions, we propose the so-called dynamic thresholding algorithm with memory (DTAM), which iteratively and dynamically selects vector bases to construct the problem solution.","At every step, the algorithm uses more than one or all iterates generated so far to construct a new search direction, and solves only the small-sized quadratic subproblems at every iteration.","Thus the computational complexity of DTAM is remarkably lower than that of ROTP-type methods.","It turns out that DTAM can locate the solution of linear inverse problems if the matrix involved satisfies the restricted isometry property.","Experiments on synthetic data, audio signal reconstruction and image denoising demonstrate that the proposed algorithm performs comparably to several mainstream thresholding and greedy algorithms, and it works much faster than the ROTP-type algorithms especially when the sparsity level of signal is relatively low."],"url":"http://arxiv.org/abs/2411.08284v1"}
{"created":"2024-11-13 01:08:37","title":"Flo: a Semantic Foundation for Progressive Stream Processing","abstract":"Streaming systems are present throughout modern applications, processing continuous data in real-time. Existing streaming languages have a variety of semantic models and guarantees that are often incompatible. Yet all these languages are considered \"streaming\" -- what do they have in common? In this paper, we identify two general yet precise semantic properties: streaming progress and eager execution. Together, they ensure that streaming outputs are deterministic and kept fresh with respect to streaming inputs. We formally define these properties in the context of Flo, a parameterized streaming language that abstracts over dataflow operators and the underlying structure of streams. It leverages a lightweight type system to distinguish bounded streams, which allow operators to block on termination, from unbounded ones. Furthermore, Flo provides constructs for dataflow composition and nested graphs with cycles. To demonstrate the generality of our properties, we show how key ideas from representative streaming and incremental computation systems -- Flink, LVars, and DBSP -- have semantics that can be modeled in Flo and guarantees that map to our properties.","sentences":["Streaming systems are present throughout modern applications, processing continuous data in real-time.","Existing streaming languages have a variety of semantic models and guarantees that are often incompatible.","Yet all these languages are considered \"streaming\" -- what do they have in common?","In this paper, we identify two general yet precise semantic properties: streaming progress and eager execution.","Together, they ensure that streaming outputs are deterministic and kept fresh with respect to streaming inputs.","We formally define these properties in the context of Flo, a parameterized streaming language that abstracts over dataflow operators and the underlying structure of streams.","It leverages a lightweight type system to distinguish bounded streams, which allow operators to block on termination, from unbounded ones.","Furthermore, Flo provides constructs for dataflow composition and nested graphs with cycles.","To demonstrate the generality of our properties, we show how key ideas from representative streaming and incremental computation systems -- Flink, LVars, and DBSP -- have semantics that can be modeled in Flo and guarantees that map to our properties."],"url":"http://arxiv.org/abs/2411.08274v1"}
{"created":"2024-11-13 00:14:09","title":"GPTree: Towards Explainable Decision-Making via LLM-powered Decision Trees","abstract":"Traditional decision tree algorithms are explainable but struggle with non-linear, high-dimensional data, limiting its applicability in complex decision-making. Neural networks excel at capturing complex patterns but sacrifice explainability in the process. In this work, we present GPTree, a novel framework combining explainability of decision trees with the advanced reasoning capabilities of LLMs. GPTree eliminates the need for feature engineering and prompt chaining, requiring only a task-specific prompt and leveraging a tree-based structure to dynamically split samples. We also introduce an expert-in-the-loop feedback mechanism to further enhance performance by enabling human intervention to refine and rebuild decision paths, emphasizing the harmony between human expertise and machine intelligence. Our decision tree achieved a 7.8% precision rate for identifying \"unicorn\" startups at the inception stage of a startup, surpassing gpt-4o with few-shot learning as well as the best human decision-makers (3.1% to 5.6%).","sentences":["Traditional decision tree algorithms are explainable but struggle with non-linear, high-dimensional data, limiting its applicability in complex decision-making.","Neural networks excel at capturing complex patterns but sacrifice explainability in the process.","In this work, we present GPTree, a novel framework combining explainability of decision trees with the advanced reasoning capabilities of LLMs.","GPTree eliminates the need for feature engineering and prompt chaining, requiring only a task-specific prompt and leveraging a tree-based structure to dynamically split samples.","We also introduce an expert-in-the-loop feedback mechanism to further enhance performance by enabling human intervention to refine and rebuild decision paths, emphasizing the harmony between human expertise and machine intelligence.","Our decision tree achieved a 7.8% precision rate for identifying \"unicorn\" startups at the inception stage of a startup, surpassing gpt-4o with few-shot learning as well as the best human decision-makers (3.1% to 5.6%)."],"url":"http://arxiv.org/abs/2411.08257v1"}
{"created":"2024-11-13 00:02:32","title":"Open-World Task and Motion Planning via Vision-Language Model Inferred Constraints","abstract":"Foundation models trained on internet-scale data, such as Vision-Language Models (VLMs), excel at performing tasks involving common sense, such as visual question answering. Despite their impressive capabilities, these models cannot currently be directly applied to challenging robot manipulation problems that require complex and precise continuous reasoning. Task and Motion Planning (TAMP) systems can control high-dimensional continuous systems over long horizons through combining traditional primitive robot operations. However, these systems require detailed model of how the robot can impact its environment, preventing them from directly interpreting and addressing novel human objectives, for example, an arbitrary natural language goal. We propose deploying VLMs within TAMP systems by having them generate discrete and continuous language-parameterized constraints that enable TAMP to reason about open-world concepts. Specifically, we propose algorithms for VLM partial planning that constrain a TAMP system's discrete temporal search and VLM continuous constraints interpretation to augment the traditional manipulation constraints that TAMP systems seek to satisfy. We demonstrate our approach on two robot embodiments, including a real world robot, across several manipulation tasks, where the desired objectives are conveyed solely through language.","sentences":["Foundation models trained on internet-scale data, such as Vision-Language Models (VLMs), excel at performing tasks involving common sense, such as visual question answering.","Despite their impressive capabilities, these models cannot currently be directly applied to challenging robot manipulation problems that require complex and precise continuous reasoning.","Task and Motion Planning (TAMP) systems can control high-dimensional continuous systems over long horizons through combining traditional primitive robot operations.","However, these systems require detailed model of how the robot can impact its environment, preventing them from directly interpreting and addressing novel human objectives, for example, an arbitrary natural language goal.","We propose deploying VLMs within TAMP systems by having them generate discrete and continuous language-parameterized constraints that enable TAMP to reason about open-world concepts.","Specifically, we propose algorithms for VLM partial planning that constrain a TAMP system's discrete temporal search and VLM continuous constraints interpretation to augment the traditional manipulation constraints that TAMP systems seek to satisfy.","We demonstrate our approach on two robot embodiments, including a real world robot, across several manipulation tasks, where the desired objectives are conveyed solely through language."],"url":"http://arxiv.org/abs/2411.08253v1"}
{"created":"2024-11-12 23:55:11","title":"Retrieval Augmented Time Series Forecasting","abstract":"Retrieval-augmented generation (RAG) is a central component of modern LLM systems, particularly in scenarios where up-to-date information is crucial for accurately responding to user queries or when queries exceed the scope of the training data. The advent of time-series foundation models (TSFM), such as Chronos, and the need for effective zero-shot forecasting performance across various time-series domains motivates the question: Do benefits of RAG similarly carry over to time series forecasting? In this paper, we advocate that the dynamic and event-driven nature of time-series data makes RAG a crucial component of TSFMs and introduce a principled RAG framework for time-series forecasting, called Retrieval Augmented Forecasting (RAF). Within RAF, we develop efficient strategies for retrieving related time-series examples and incorporating them into forecast. Through experiments and mechanistic studies, we demonstrate that RAF indeed improves the forecasting accuracy across diverse time series domains and the improvement is more significant for larger TSFM sizes.","sentences":["Retrieval-augmented generation (RAG) is a central component of modern LLM systems, particularly in scenarios where up-to-date information is crucial for accurately responding to user queries or when queries exceed the scope of the training data.","The advent of time-series foundation models (TSFM), such as Chronos, and the need for effective zero-shot forecasting performance across various time-series domains motivates the question: Do benefits of RAG similarly carry over to time series forecasting?","In this paper, we advocate that the dynamic and event-driven nature of time-series data makes RAG a crucial component of TSFMs and introduce a principled RAG framework for time-series forecasting, called Retrieval Augmented Forecasting (RAF).","Within RAF, we develop efficient strategies for retrieving related time-series examples and incorporating them into forecast.","Through experiments and mechanistic studies, we demonstrate that RAF indeed improves the forecasting accuracy across diverse time series domains and the improvement is more significant for larger TSFM sizes."],"url":"http://arxiv.org/abs/2411.08249v1"}
{"created":"2024-11-12 23:43:20","title":"NVCiM-PT: An NVCiM-assisted Prompt Tuning Framework for Edge LLMs","abstract":"Large Language Models (LLMs) deployed on edge devices, known as edge LLMs, need to continuously fine-tune their model parameters from user-generated data under limited resource constraints. However, most existing learning methods are not applicable for edge LLMs because of their reliance on high resources and low learning capacity. Prompt tuning (PT) has recently emerged as an effective fine-tuning method for edge LLMs by only modifying a small portion of LLM parameters, but it suffers from user domain shifts, resulting in repetitive training and losing resource efficiency. Conventional techniques to address domain shift issues often involve complex neural networks and sophisticated training, which are incompatible for PT for edge LLMs. Therefore, an open research question is how to address domain shift issues for edge LLMs with limited resources. In this paper, we propose a prompt tuning framework for edge LLMs, exploiting the benefits offered by non-volatile computing-in-memory (NVCiM) architectures. We introduce a novel NVCiM-assisted PT framework, where we narrow down the core operations to matrix-matrix multiplication, which can then be accelerated by performing in-situ computation on NVCiM. To the best of our knowledge, this is the first work employing NVCiM to improve the edge LLM PT performance.","sentences":["Large Language Models (LLMs) deployed on edge devices, known as edge LLMs, need to continuously fine-tune their model parameters from user-generated data under limited resource constraints.","However, most existing learning methods are not applicable for edge LLMs because of their reliance on high resources and low learning capacity.","Prompt tuning (PT) has recently emerged as an effective fine-tuning method for edge LLMs by only modifying a small portion of LLM parameters, but it suffers from user domain shifts, resulting in repetitive training and losing resource efficiency.","Conventional techniques to address domain shift issues often involve complex neural networks and sophisticated training, which are incompatible for PT for edge LLMs.","Therefore, an open research question is how to address domain shift issues for edge LLMs with limited resources.","In this paper, we propose a prompt tuning framework for edge LLMs, exploiting the benefits offered by non-volatile computing-in-memory (NVCiM) architectures.","We introduce a novel NVCiM-assisted PT framework, where we narrow down the core operations to matrix-matrix multiplication, which can then be accelerated by performing in-situ computation on NVCiM. To the best of our knowledge, this is the first work employing NVCiM to improve the edge LLM PT performance."],"url":"http://arxiv.org/abs/2411.08244v1"}
{"created":"2024-11-12 22:53:09","title":"Enhanced Monocular Visual Odometry with AR Poses and Integrated INS-GPS for Robust Localization in Urban Environments","abstract":"This paper introduces a cost effective localization system combining monocular visual odometry , augmented reality (AR) poses, and integrated INS-GPS data. We address monocular VO scale factor issues using AR poses and enhance accuracy with INS and GPS data, filtered through an Extended Kalman Filter . Our approach, tested using manually annotated trajectories from Google Street View, achieves an RMSE of 1.529 meters over a 1 km track. Future work will focus on real-time mobile implementation and further integration of visual-inertial odometry for robust localization. This method offers lane-level accuracy with minimal hardware, making advanced navigation more accessible.","sentences":["This paper introduces a cost effective localization system combining monocular visual odometry , augmented reality (AR) poses, and integrated INS-GPS data.","We address monocular VO scale factor issues using AR poses and enhance accuracy with INS and GPS data, filtered through an Extended Kalman Filter .","Our approach, tested using manually annotated trajectories from Google Street View, achieves an RMSE of 1.529 meters over a 1 km track.","Future work will focus on real-time mobile implementation and further integration of visual-inertial odometry for robust localization.","This method offers lane-level accuracy with minimal hardware, making advanced navigation more accessible."],"url":"http://arxiv.org/abs/2411.08231v1"}
{"created":"2024-11-12 22:47:23","title":"Virtual Steps: The Experience of Walking for a Lifelong Wheelchair User in Virtual Reality","abstract":"Many people often take walking for granted, but for individuals with mobility disabilities, this seemingly simple act can feel out of reach. This reality can foster a sense of disconnect from the world since walking is a fundamental way in which people interact with each other and the environment. Advances in virtual reality and its immersive capabilities have made it possible to enable those who have never walked in their life to virtually experience walking. We co-designed a VR walking experience with a person with Spinal Muscular Atrophy who has been a lifelong wheelchair user. Over 9 days, we collected data on this person's experience through a diary study and analyzed this data to better understand the design elements required. Given that they had only ever seen others walking and had not experienced it first-hand, determining which design parameters must be considered in order to match the virtual experience to their idea of walking was challenging. Generally, we found the experience of walking to be quite positive, providing a perspective from a higher vantage point than what was available in a wheelchair. Our findings provide insights into the emotional complexities and evolving sense of agency accompanying virtual walking. These findings have implications for designing more inclusive and emotionally engaging virtual reality experiences.","sentences":["Many people often take walking for granted, but for individuals with mobility disabilities, this seemingly simple act can feel out of reach.","This reality can foster a sense of disconnect from the world since walking is a fundamental way in which people interact with each other and the environment.","Advances in virtual reality and its immersive capabilities have made it possible to enable those who have never walked in their life to virtually experience walking.","We co-designed a VR walking experience with a person with Spinal Muscular Atrophy who has been a lifelong wheelchair user.","Over 9 days, we collected data on this person's experience through a diary study and analyzed this data to better understand the design elements required.","Given that they had only ever seen others walking and had not experienced it first-hand, determining which design parameters must be considered in order to match the virtual experience to their idea of walking was challenging.","Generally, we found the experience of walking to be quite positive, providing a perspective from a higher vantage point than what was available in a wheelchair.","Our findings provide insights into the emotional complexities and evolving sense of agency accompanying virtual walking.","These findings have implications for designing more inclusive and emotionally engaging virtual reality experiences."],"url":"http://arxiv.org/abs/2411.08229v1"}
{"created":"2024-11-12 22:46:34","title":"Virtual Buddy: Redefining Conversational AI Interactions for Individuals with Hand Motor Disabilities","abstract":"Advances in artificial intelligence have transformed the paradigm of human-computer interaction, with the development of conversational AI systems playing a pivotal role. These systems employ technologies such as natural language processing and machine learning to simulate intelligent and human-like conversations. Driven by the personal experience of an individual with a neuromuscular disease who faces challenges with leaving home and contends with limited hand-motor control when operating digital systems, including conversational AI platforms, we propose a method aimed at enriching their interaction with conversational AI. Our prototype allows the creation of multiple agent personas based on hobbies and interests, to support topic-based conversations. In contrast with existing systems, such as Replika, that offer a 1:1 relation with a virtual agent, our design enables one-to-many relationships, easing the process of interaction for this individual by reducing the need for constant data input. We can imagine our prototype potentially helping others who are in a similar situation with reduced typing/input ability.","sentences":["Advances in artificial intelligence have transformed the paradigm of human-computer interaction, with the development of conversational AI systems playing a pivotal role.","These systems employ technologies such as natural language processing and machine learning to simulate intelligent and human-like conversations.","Driven by the personal experience of an individual with a neuromuscular disease who faces challenges with leaving home and contends with limited hand-motor control when operating digital systems, including conversational AI platforms, we propose a method aimed at enriching their interaction with conversational AI.","Our prototype allows the creation of multiple agent personas based on hobbies and interests, to support topic-based conversations.","In contrast with existing systems, such as Replika, that offer a 1:1 relation with a virtual agent, our design enables one-to-many relationships, easing the process of interaction for this individual by reducing the need for constant data input.","We can imagine our prototype potentially helping others who are in a similar situation with reduced typing/input ability."],"url":"http://arxiv.org/abs/2411.08228v1"}
{"created":"2024-11-12 22:43:16","title":"DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection","abstract":"Out-of-distribution (OOD) detection is essential for ensuring the robustness of machine learning models by identifying samples that deviate from the training distribution. While traditional OOD detection has primarily focused on single-modality inputs, such as images, recent advances in multimodal models have demonstrated the potential of leveraging multiple modalities (e.g., video, optical flow, audio) to enhance detection performance. However, existing methods often overlook intra-class variability within in-distribution (ID) data, assuming that samples of the same class are perfectly cohesive and consistent. This assumption can lead to performance degradation, especially when prediction discrepancies are uniformly amplified across all samples. To address this issue, we propose Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection that accounts for intra-class variations. Our method dynamically updates class center representations for each class by measuring the variance of similar samples within each batch, enabling adaptive adjustments. This approach allows us to amplify prediction discrepancies based on the updated class centers, thereby improving the model's robustness and generalization across different modalities. Extensive experiments on two tasks, five datasets, and nine base OOD algorithms demonstrate that DPU significantly improves OOD detection performance, setting a new state-of-the-art in multimodal OOD detection, with improvements of up to 80 percent in Far-OOD detection. To facilitate accessibility and reproducibility, our code is publicly available on GitHub.","sentences":["Out-of-distribution (OOD) detection is essential for ensuring the robustness of machine learning models by identifying samples that deviate from the training distribution.","While traditional OOD detection has primarily focused on single-modality inputs, such as images, recent advances in multimodal models have demonstrated the potential of leveraging multiple modalities (e.g., video, optical flow, audio) to enhance detection performance.","However, existing methods often overlook intra-class variability within in-distribution (ID) data, assuming that samples of the same class are perfectly cohesive and consistent.","This assumption can lead to performance degradation, especially when prediction discrepancies are uniformly amplified across all samples.","To address this issue, we propose Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection that accounts for intra-class variations.","Our method dynamically updates class center representations for each class by measuring the variance of similar samples within each batch, enabling adaptive adjustments.","This approach allows us to amplify prediction discrepancies based on the updated class centers, thereby improving the model's robustness and generalization across different modalities.","Extensive experiments on two tasks, five datasets, and nine base OOD algorithms demonstrate that DPU significantly improves OOD detection performance, setting a new state-of-the-art in multimodal OOD detection, with improvements of up to 80 percent in Far-OOD detection.","To facilitate accessibility and reproducibility, our code is publicly available on GitHub."],"url":"http://arxiv.org/abs/2411.08227v1"}
{"created":"2024-11-12 22:35:44","title":"Joint Diffusion models in Continual Learning","abstract":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models. Neural networks suffer from catastrophic forgetting defined as abrupt loss in the model's performance when retrained with additional data coming from a different distribution. Generative-replay-based continual learning methods try to mitigate this issue by retraining a model with a combination of new and rehearsal data sampled from a generative model. In this work, we propose to extend this idea by combining a continually trained classifier with a diffusion-based generative model into a single - jointly optimized neural network. We show that such shared parametrization, combined with the knowledge distillation technique allows for stable adaptation to new tasks without catastrophic forgetting. We evaluate our approach on several benchmarks, where it outperforms recent state-of-the-art generative replay techniques. Additionally, we extend our method to the semi-supervised continual learning setup, where it outperforms competing buffer-based replay techniques, and evaluate, in a self-supervised manner, the quality of trained representations.","sentences":["In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models.","Neural networks suffer from catastrophic forgetting defined as abrupt loss in the model's performance when retrained with additional data coming from a different distribution.","Generative-replay-based continual learning methods try to mitigate this issue by retraining a model with a combination of new and rehearsal data sampled from a generative model.","In this work, we propose to extend this idea by combining a continually trained classifier with a diffusion-based generative model into a single - jointly optimized neural network.","We show that such shared parametrization, combined with the knowledge distillation technique allows for stable adaptation to new tasks without catastrophic forgetting.","We evaluate our approach on several benchmarks, where it outperforms recent state-of-the-art generative replay techniques.","Additionally, we extend our method to the semi-supervised continual learning setup, where it outperforms competing buffer-based replay techniques, and evaluate, in a self-supervised manner, the quality of trained representations."],"url":"http://arxiv.org/abs/2411.08224v1"}
{"created":"2024-11-12 22:21:09","title":"Improved Approximations for Stationary Bipartite Matching: Beyond Probabilistic Independence","abstract":"We study stationary online bipartite matching, where both types of nodes--offline and online--arrive according to Poisson processes. Offline nodes wait to be matched for some random time, determined by an exponential distribution, while online nodes need to be matched immediately. This model captures scenarios such as deceased organ donation and time-sensitive task assignments, where there is an inflow of patients and workers (offline nodes) with limited patience, while organs and tasks (online nodes) must be assigned upon arrival.   We present an efficient online algorithm that achieves a $(1-1/e+\\delta)$-approximation to the optimal online policy's reward for a constant $\\delta > 0$, simplifying and improving previous work by Aouad and Sarita\\c{c} (2022). Our solution combines recent online matching techniques, particularly pivotal sampling, which enables correlated rounding of tighter linear programming approximations, and a greedy-like algorithm. A key technical component is the analysis of a stochastic process that exploits subtle correlations between offline nodes, using renewal theory. A byproduct of our result is an improvement to the best-known competitive ratio--that compares an algorithm's performance to the optimal offline policy--via a $(1-1/\\sqrt{e} + \\eta)$-competitive algorithm for a universal constant $\\eta > 0$, advancing the results of Patel and Wajc (2024).","sentences":["We study stationary online bipartite matching, where both types of nodes--offline and online--arrive according to Poisson processes.","Offline nodes wait to be matched for some random time, determined by an exponential distribution, while online nodes need to be matched immediately.","This model captures scenarios such as deceased organ donation and time-sensitive task assignments, where there is an inflow of patients and workers (offline nodes) with limited patience, while organs and tasks (online nodes) must be assigned upon arrival.   ","We present an efficient online algorithm that achieves a $(1-1/e+\\delta)$-approximation to the optimal online policy's reward for a constant $\\delta > 0$, simplifying and improving previous work by Aouad and Sarita\\c{c} (2022).","Our solution combines recent online matching techniques, particularly pivotal sampling, which enables correlated rounding of tighter linear programming approximations, and a greedy-like algorithm.","A key technical component is the analysis of a stochastic process that exploits subtle correlations between offline nodes, using renewal theory.","A byproduct of our result is an improvement to the best-known competitive ratio--that compares an algorithm's performance to the optimal offline policy--via a $(1-1/\\sqrt{e} + \\eta)$-competitive algorithm for a universal constant $\\eta > 0$, advancing the results of Patel and Wajc (2024)."],"url":"http://arxiv.org/abs/2411.08218v1"}
{"created":"2024-11-12 21:50:03","title":"FaaS and Furious: abstractions and differential caching for efficient data pre-processing","abstract":"Data pre-processing pipelines are the bread and butter of any successful AI project. We introduce a novel programming model for pipelines in a data lakehouse, allowing users to interact declaratively with assets in object storage. Motivated by real-world industry usage patterns, we exploit these new abstractions with a columnar and differential cache to maximize iteration speed for data scientists, who spent most of their time in pre-processing - adding or removing features, restricting or relaxing time windows, wrangling current or older datasets. We show how the new cache works transparently across programming languages, schemas and time windows, and provide preliminary evidence on its efficiency on standard data workloads.","sentences":["Data pre-processing pipelines are the bread and butter of any successful AI project.","We introduce a novel programming model for pipelines in a data lakehouse, allowing users to interact declaratively with assets in object storage.","Motivated by real-world industry usage patterns, we exploit these new abstractions with a columnar and differential cache to maximize iteration speed for data scientists, who spent most of their time in pre-processing - adding or removing features, restricting or relaxing time windows, wrangling current or older datasets.","We show how the new cache works transparently across programming languages, schemas and time windows, and provide preliminary evidence on its efficiency on standard data workloads."],"url":"http://arxiv.org/abs/2411.08203v1"}
{"created":"2024-11-12 21:33:11","title":"An Explainable Machine Learning Approach for Age and Gender Estimation in Living Individuals Using Dental Biometrics","abstract":"Objectives: Age and gender estimation is crucial for various applications, including forensic investigations and anthropological studies. This research aims to develop a predictive system for age and gender estimation in living individuals, leveraging dental measurements such as Coronal Height (CH), Coronal Pulp Cavity Height (CPCH), and Tooth Coronal Index (TCI). Methods: Machine learning models were employed in our study, including Cat Boost Classifier (Catboost), Gradient Boosting Machine (GBM), Ada Boost Classifier (AdaBoost), Random Forest (RF), eXtreme Gradient Boosting (XGB), Light Gradient Boosting Machine (LGB), and Extra Trees Classifier (ETC), to analyze dental data from 862 living individuals (459 males and 403 females). Specifically, periapical radiographs from six teeth per individual were utilized, including premolars and molars from both maxillary and mandibular. A novel ensemble learning technique was developed, which uses multiple models each tailored to distinct dental metrics, to estimate age and gender accurately. Furthermore, an explainable AI model has been created utilizing SHAP, enabling dental experts to make judicious decisions based on comprehensible insight. Results: The RF and XGB models were particularly effective, yielding the highest F1 score for age and gender estimation. Notably, the XGB model showed a slightly better performance in age estimation, achieving an F1 score of 73.26%. A similar trend for the RF model was also observed in gender estimation, achieving a F1 score of 77.53%. Conclusions: This study marks a significant advancement in dental forensic methods, showcasing the potential of machine learning to automate age and gender estimation processes with improved accuracy.","sentences":["Objectives: Age and gender estimation is crucial for various applications, including forensic investigations and anthropological studies.","This research aims to develop a predictive system for age and gender estimation in living individuals, leveraging dental measurements such as Coronal Height (CH), Coronal Pulp Cavity Height (CPCH), and Tooth Coronal Index (TCI).","Methods: Machine learning models were employed in our study, including Cat Boost Classifier (Catboost), Gradient Boosting Machine (GBM), Ada Boost Classifier (AdaBoost), Random Forest (RF), eXtreme Gradient Boosting (XGB), Light Gradient Boosting Machine (LGB), and Extra Trees Classifier (ETC), to analyze dental data from 862 living individuals (459 males and 403 females).","Specifically, periapical radiographs from six teeth per individual were utilized, including premolars and molars from both maxillary and mandibular.","A novel ensemble learning technique was developed, which uses multiple models each tailored to distinct dental metrics, to estimate age and gender accurately.","Furthermore, an explainable AI model has been created utilizing SHAP, enabling dental experts to make judicious decisions based on comprehensible insight.","Results: The RF and XGB models were particularly effective, yielding the highest F1 score for age and gender estimation.","Notably, the XGB model showed a slightly better performance in age estimation, achieving an F1 score of 73.26%.","A similar trend for the RF model was also observed in gender estimation, achieving a F1 score of 77.53%.","Conclusions:","This study marks a significant advancement in dental forensic methods, showcasing the potential of machine learning to automate age and gender estimation processes with improved accuracy."],"url":"http://arxiv.org/abs/2411.08195v1"}
{"created":"2024-11-12 21:12:51","title":"TractoEmbed: Modular Multi-level Embedding framework for white matter tract segmentation","abstract":"White matter tract segmentation is crucial for studying brain structural connectivity and neurosurgical planning. However, segmentation remains challenging due to issues like class imbalance between major and minor tracts, structural similarity, subject variability, symmetric streamlines between hemispheres etc. To address these challenges, we propose TractoEmbed, a modular multi-level embedding framework, that encodes localized representations through learning tasks in respective encoders. In this paper, TractoEmbed introduces a novel hierarchical streamline data representation that captures maximum spatial information at each level i.e. individual streamlines, clusters, and patches. Experiments show that TractoEmbed outperforms state-of-the-art methods in white matter tract segmentation across different datasets, and spanning various age groups. The modular framework directly allows the integration of additional embeddings in future works.","sentences":["White matter tract segmentation is crucial for studying brain structural connectivity and neurosurgical planning.","However, segmentation remains challenging due to issues like class imbalance between major and minor tracts, structural similarity, subject variability, symmetric streamlines between hemispheres etc.","To address these challenges, we propose TractoEmbed, a modular multi-level embedding framework, that encodes localized representations through learning tasks in respective encoders.","In this paper, TractoEmbed introduces a novel hierarchical streamline data representation that captures maximum spatial information at each level i.e. individual streamlines, clusters, and patches.","Experiments show that TractoEmbed outperforms state-of-the-art methods in white matter tract segmentation across different datasets, and spanning various age groups.","The modular framework directly allows the integration of additional embeddings in future works."],"url":"http://arxiv.org/abs/2411.08187v1"}
{"created":"2024-11-12 20:58:04","title":"SCORE: Syntactic Code Representations for Static Script Malware Detection","abstract":"As businesses increasingly adopt cloud technologies, they also need to be aware of new security challenges, such as server-side script attacks, to ensure the integrity of their systems and data. These scripts can steal data, compromise credentials, and disrupt operations. Unlike executables with standardized formats (e.g., ELF, PE), scripts are plaintext files with diverse syntax, making them harder to detect using traditional methods. As a result, more sophisticated approaches are needed to protect cloud infrastructures from these evolving threats. In this paper, we propose novel feature extraction and deep learning (DL)-based approaches for static script malware detection, targeting server-side threats. We extract features from plain-text code using two techniques: syntactic code highlighting (SCH) and abstract syntax tree (AST) construction. SCH leverages complex regexes to parse syntactic elements of code, such as keywords, variable names, etc. ASTs generate a hierarchical representation of a program's syntactic structure. We then propose a sequential and a graph-based model that exploits these feature representations to detect script malware. We evaluate our approach on more than 400K server-side scripts in Bash, Python and Perl. We use a balanced dataset of 90K scripts for training, validation, and testing, with the remaining from 400K reserved for further analysis. Experiments show that our method achieves a true positive rate (TPR) up to 81% higher than leading signature-based antivirus solutions, while maintaining a low false positive rate (FPR) of 0.17%. Moreover, our approach outperforms various neural network-based detectors, demonstrating its effectiveness in learning code maliciousness for accurate detection of script malware.","sentences":["As businesses increasingly adopt cloud technologies, they also need to be aware of new security challenges, such as server-side script attacks, to ensure the integrity of their systems and data.","These scripts can steal data, compromise credentials, and disrupt operations.","Unlike executables with standardized formats (e.g., ELF, PE), scripts are plaintext files with diverse syntax, making them harder to detect using traditional methods.","As a result, more sophisticated approaches are needed to protect cloud infrastructures from these evolving threats.","In this paper, we propose novel feature extraction and deep learning (DL)-based approaches for static script malware detection, targeting server-side threats.","We extract features from plain-text code using two techniques: syntactic code highlighting (SCH) and abstract syntax tree (AST) construction.","SCH leverages complex regexes to parse syntactic elements of code, such as keywords, variable names, etc.","ASTs generate a hierarchical representation of a program's syntactic structure.","We then propose a sequential and a graph-based model that exploits these feature representations to detect script malware.","We evaluate our approach on more than 400K server-side scripts in Bash, Python and Perl.","We use a balanced dataset of 90K scripts for training, validation, and testing, with the remaining from 400K reserved for further analysis.","Experiments show that our method achieves a true positive rate (TPR) up to 81% higher than leading signature-based antivirus solutions, while maintaining a low false positive rate (FPR) of 0.17%.","Moreover, our approach outperforms various neural network-based detectors, demonstrating its effectiveness in learning code maliciousness for accurate detection of script malware."],"url":"http://arxiv.org/abs/2411.08182v1"}
{"created":"2024-11-12 20:32:36","title":"Fault Localization in Deep Learning-based Software: A System-level Approach","abstract":"Over the past decade, Deep Learning (DL) has become an integral part of our daily lives. This surge in DL usage has heightened the need for developing reliable DL software systems. Given that fault localization is a critical task in reliability assessment, researchers have proposed several fault localization techniques for DL-based software, primarily focusing on faults within the DL model. While the DL model is central to DL components, there are other elements that significantly impact the performance of DL components. As a result, fault localization methods that concentrate solely on the DL model overlook a large portion of the system. To address this, we introduce FL4Deep, a system-level fault localization approach considering the entire DL development pipeline to effectively localize faults across the DL-based systems. In an evaluation using 100 faulty DL scripts, FL4Deep outperformed four previous approaches in terms of accuracy for three out of six DL-related faults, including issues related to data (84%), mismatched libraries between training and deployment (100%), and loss function (69%). Additionally, FL4Deep demonstrated superior precision and recall in fault localization for five categories of faults including three mentioned fault types in terms of accuracy, plus insufficient training iteration and activation function.","sentences":["Over the past decade, Deep Learning (DL) has become an integral part of our daily lives.","This surge in DL usage has heightened the need for developing reliable DL software systems.","Given that fault localization is a critical task in reliability assessment, researchers have proposed several fault localization techniques for DL-based software, primarily focusing on faults within the DL model.","While the DL model is central to DL components, there are other elements that significantly impact the performance of DL components.","As a result, fault localization methods that concentrate solely on the DL model overlook a large portion of the system.","To address this, we introduce FL4Deep, a system-level fault localization approach considering the entire DL development pipeline to effectively localize faults across the DL-based systems.","In an evaluation using 100 faulty DL scripts, FL4Deep outperformed four previous approaches in terms of accuracy for three out of six DL-related faults, including issues related to data (84%), mismatched libraries between training and deployment (100%), and loss function (69%).","Additionally, FL4Deep demonstrated superior precision and recall in fault localization for five categories of faults including three mentioned fault types in terms of accuracy, plus insufficient training iteration and activation function."],"url":"http://arxiv.org/abs/2411.08172v1"}
{"created":"2024-11-12 20:30:23","title":"Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection","abstract":"Contemporary Artificial Intelligence (AI) and Machine Learning (ML) research places a significant emphasis on transfer learning, showcasing its transformative potential in enhancing model performance across diverse domains. This paper examines the efficiency and effectiveness of transfer learning in the context of wildfire detection. Three purpose-built models -- Visual Geometry Group (VGG)-7, VGG-10, and Convolutional Neural Network (CNN)-Support Vector Machine(SVM) CNN-SVM -- are rigorously compared with three pretrained models -- VGG-16, VGG-19, and Residual Neural Network (ResNet) ResNet101. We trained and evaluated these models using a dataset that captures the complexities of wildfires, incorporating variables such as varying lighting conditions, time of day, and diverse terrains. The objective is to discern how transfer learning performs against models trained from scratch in addressing the intricacies of the wildfire detection problem. By assessing the performance metrics, including accuracy, precision, recall, and F1 score, a comprehensive understanding of the advantages and disadvantages of transfer learning in this specific domain is obtained. This study contributes valuable insights to the ongoing discourse, guiding future directions in AI and ML research. Keywords: Wildfire prediction, deep learning, machine learning fire, detection","sentences":["Contemporary Artificial Intelligence (AI) and Machine Learning (ML) research places a significant emphasis on transfer learning, showcasing its transformative potential in enhancing model performance across diverse domains.","This paper examines the efficiency and effectiveness of transfer learning in the context of wildfire detection.","Three purpose-built models -- Visual Geometry Group (VGG)-7, VGG-10, and Convolutional Neural Network (CNN)-Support Vector Machine(SVM) CNN-SVM -- are rigorously compared with three pretrained models -- VGG-16, VGG-19, and Residual Neural Network (ResNet) ResNet101.","We trained and evaluated these models using a dataset that captures the complexities of wildfires, incorporating variables such as varying lighting conditions, time of day, and diverse terrains.","The objective is to discern how transfer learning performs against models trained from scratch in addressing the intricacies of the wildfire detection problem.","By assessing the performance metrics, including accuracy, precision, recall, and F1 score, a comprehensive understanding of the advantages and disadvantages of transfer learning in this specific domain is obtained.","This study contributes valuable insights to the ongoing discourse, guiding future directions in AI and ML research.","Keywords: Wildfire prediction, deep learning, machine learning fire, detection"],"url":"http://arxiv.org/abs/2411.08171v1"}
{"created":"2024-11-12 20:15:32","title":"EAPCR: A Universal Feature Extractor for Scientific Data without Explicit Feature Relation Patterns","abstract":"Conventional methods, including Decision Tree (DT)-based methods, have been effective in scientific tasks, such as non-image medical diagnostics, system anomaly detection, and inorganic catalysis efficiency prediction. However, most deep-learning techniques have struggled to surpass or even match this level of success as traditional machine-learning methods. The primary reason is that these applications involve multi-source, heterogeneous data where features lack explicit relationships. This contrasts with image data, where pixels exhibit spatial relationships; textual data, where words have sequential dependencies; and graph data, where nodes are connected through established associations. The absence of explicit Feature Relation Patterns (FRPs) presents a significant challenge for deep learning techniques in scientific applications that are not image, text, and graph-based. In this paper, we introduce EAPCR, a universal feature extractor designed for data without explicit FRPs. Tested across various scientific tasks, EAPCR consistently outperforms traditional methods and bridges the gap where deep learning models fall short. To further demonstrate its robustness, we synthesize a dataset without explicit FRPs. While Kolmogorov-Arnold Network (KAN) and feature extractors like Convolutional Neural Networks (CNNs), Graph Convolutional Networks (GCNs), and Transformers struggle, EAPCR excels, demonstrating its robustness and superior performance in scientific tasks without FRPs.","sentences":["Conventional methods, including Decision Tree (DT)-based methods, have been effective in scientific tasks, such as non-image medical diagnostics, system anomaly detection, and inorganic catalysis efficiency prediction.","However, most deep-learning techniques have struggled to surpass or even match this level of success as traditional machine-learning methods.","The primary reason is that these applications involve multi-source, heterogeneous data where features lack explicit relationships.","This contrasts with image data, where pixels exhibit spatial relationships; textual data, where words have sequential dependencies; and graph data, where nodes are connected through established associations.","The absence of explicit Feature Relation Patterns (FRPs) presents a significant challenge for deep learning techniques in scientific applications that are not image, text, and graph-based.","In this paper, we introduce EAPCR, a universal feature extractor designed for data without explicit FRPs.","Tested across various scientific tasks, EAPCR consistently outperforms traditional methods and bridges the gap where deep learning models fall short.","To further demonstrate its robustness, we synthesize a dataset without explicit FRPs.","While Kolmogorov-Arnold Network (KAN) and feature extractors like Convolutional Neural Networks (CNNs), Graph Convolutional Networks (GCNs), and Transformers struggle, EAPCR excels, demonstrating its robustness and superior performance in scientific tasks without FRPs."],"url":"http://arxiv.org/abs/2411.08164v1"}
{"created":"2024-11-12 19:56:22","title":"New Separations and Reductions for Directed Preservers and Hopsets","abstract":"We study distance preservers, hopsets, and shortcut sets in $n$-node, $m$-edge directed graphs, and show improved bounds and new reductions for various settings of these problems. Our first set of results is about exact and approximate distance preservers. We give the following bounds on the size of directed distance preservers with $p$ demand pairs: 1) $\\tilde{O}(n^{5/6}p^{2/3} + n)$ edges for exact distance preservers in unweighted graphs; and 2) $\\Omega(n^{2/3}p^{2/3})$ edges for approximate distance preservers with any given finite stretch, in graphs with arbitrary aspect ratio.   Additionally, we establish a new directed-to-undirected reduction for exact distance preservers. We show that if undirected distance preservers have size $O(n^{\\lambda}p^{\\mu} + n)$ for constants $\\lambda, \\mu > 0$, then directed distance preservers have size $O\\left( n^{\\frac{1}{2-\\lambda}}p^{\\frac{1+\\mu-\\lambda}{2-\\lambda}} + n^{1/2}p + n\\right).$ As a consequence of the reduction, if current upper bounds for undirected preservers can be improved for some $p \\leq n$, then so can current upper bounds for directed preservers.   Our second set of results is about directed hopsets and shortcut sets. For hopsets in directed graphs, we prove that the hopbound is: 1) $\\Omega(n^{2/9})$ for $O(m)$-size shortcut sets, improving the previous $\\Omega(n^{1/5})$ bound [Vassilevska Williams, Xu and Xu, SODA 2024]; 2) $\\Omega(n^{2/7})$ for $O(m)$-size exact hopsets in unweighted graphs, improving the previous $\\Omega(n^{1/4})$ bound [Bodwin and Hoppenworth, FOCS 2023]; and 3) $\\Omega(n^{1/2})$ for $O(n)$-size approximate hopsets with any given finite stretch, in graphs with arbitrary aspect ratio. This result establishes a separation between this setting and $O(n)$-size approximate hopsets for graphs with polynomial aspect ratio, which have hopbound $\\widetilde{O}(n^{1/3})$ [Bernstein and Wein, SODA 2023].","sentences":["We study distance preservers, hopsets, and shortcut sets in $n$-node, $m$-edge directed graphs, and show improved bounds and new reductions for various settings of these problems.","Our first set of results is about exact and approximate distance preservers.","We give the following bounds on the size of directed distance preservers with $p$ demand pairs: 1) $\\tilde{O}(n^{5/6}p^{2/3} + n)$ edges for exact distance preservers in unweighted graphs; and 2) $\\Omega(n^{2/3}p^{2/3})$ edges for approximate distance preservers with any given finite stretch, in graphs with arbitrary aspect ratio.   ","Additionally, we establish a new directed-to-undirected reduction for exact distance preservers.","We show that if undirected distance preservers have size $O(n^{\\lambda}p^{\\mu} + n)$ for constants $\\lambda, \\mu > 0$, then directed distance preservers have size $O\\left( n^{\\frac{1}{2-\\lambda}}p^{\\frac{1+\\mu-\\lambda}{2-\\lambda}} + n^{1/2}p + n\\right).$","As a consequence of the reduction, if current upper bounds for undirected preservers can be improved for some $p \\leq n$, then so can current upper bounds for directed preservers.   ","Our second set of results is about directed hopsets and shortcut sets.","For hopsets in directed graphs, we prove that the hopbound is: 1) $\\Omega(n^{2/9})$ for $O(m)$-size shortcut sets, improving the previous $\\Omega(n^{1/5})$ bound [Vassilevska Williams, Xu and Xu, SODA 2024]; 2) $\\Omega(n^{2/7})$ for $O(m)$-size exact hopsets in unweighted graphs, improving the previous $\\Omega(n^{1/4})$ bound [Bodwin and Hoppenworth, FOCS 2023]; and 3) $\\Omega(n^{1/2})$ for $O(n)$-size approximate hopsets with any given finite stretch, in graphs with arbitrary aspect ratio.","This result establishes a separation between this setting and $O(n)$-size approximate hopsets for graphs with polynomial aspect ratio, which have hopbound $\\widetilde{O}(n^{1/3})$","[Bernstein and Wein, SODA 2023]."],"url":"http://arxiv.org/abs/2411.08151v1"}
{"created":"2024-11-12 19:55:49","title":"Design optimization of semiconductor manufacturing equipment using a novel multi-fidelity surrogate modeling approach","abstract":"Careful design of semiconductor manufacturing equipment is crucial for ensuring the performance, yield, and reliability of semiconductor devices. Despite this, numerical optimization methods are seldom applied to optimize the design of such equipment due to the difficulty of obtaining accurate simulation models. In this paper, we address a practical and industrially relevant electrostatic chuck (ESC) design optimization problem by proposing a novel multi-fidelity surrogate modeling approach. The optimization aims to improve the temperature uniformity of the wafer during the etching process by adjusting seven parameters associated with the coolant path and embossing. Our approach combines low-fidelity (LF) and high-fidelity (HF) simulation data to efficiently predict spatial-field quantities, even with a limited number of data points. We use proper orthogonal decomposition (POD) to project the spatially interpolated HF and LF field data onto a shared latent space, followed by the construction of a multi-fidelity kriging model to predict the latent variables of the HF output field. In the ESC design problem, with hundreds or fewer data, our approach achieves a more than 10% reduction in prediction error compared to using kriging models with only HF or LF data. Additionally, in the ESC optimization problem, our proposed method yields better solutions with improvements in all of the quantities of interest, while requiring 20% less data generation cost compared to the HF surrogate modeling approach.","sentences":["Careful design of semiconductor manufacturing equipment is crucial for ensuring the performance, yield, and reliability of semiconductor devices.","Despite this, numerical optimization methods are seldom applied to optimize the design of such equipment due to the difficulty of obtaining accurate simulation models.","In this paper, we address a practical and industrially relevant electrostatic chuck (ESC) design optimization problem by proposing a novel multi-fidelity surrogate modeling approach.","The optimization aims to improve the temperature uniformity of the wafer during the etching process by adjusting seven parameters associated with the coolant path and embossing.","Our approach combines low-fidelity (LF) and high-fidelity (HF) simulation data to efficiently predict spatial-field quantities, even with a limited number of data points.","We use proper orthogonal decomposition (POD) to project the spatially interpolated HF and LF field data onto a shared latent space, followed by the construction of a multi-fidelity kriging model to predict the latent variables of the HF output field.","In the ESC design problem, with hundreds or fewer data, our approach achieves a more than 10% reduction in prediction error compared to using kriging models with only HF or LF data.","Additionally, in the ESC optimization problem, our proposed method yields better solutions with improvements in all of the quantities of interest, while requiring 20% less data generation cost compared to the HF surrogate modeling approach."],"url":"http://arxiv.org/abs/2411.08149v1"}
{"created":"2024-11-12 19:55:07","title":"Adaptive Meta-Learning for Robust Deepfake Detection: A Multi-Agent Framework to Data Drift and Model Generalization","abstract":"Pioneering advancements in artificial intelligence, especially in genAI, have enabled significant possibilities for content creation, but also led to widespread misinformation and false content. The growing sophistication and realism of deepfakes is raising concerns about privacy invasion, identity theft, and has societal, business impacts, including reputational damage and financial loss. Many deepfake detectors have been developed to tackle this problem. Nevertheless, as for every AI model, the deepfake detectors face the wrath of lack of considerable generalization to unseen scenarios and cross-domain deepfakes. Besides, adversarial robustness is another critical challenge, as detectors drastically underperform to the slightest imperceptible change. Most state-of-the-art detectors are trained on static datasets and lack the ability to adapt to emerging deepfake attack trends. These three crucial challenges though hold paramount importance for reliability in practise, particularly in the deepfake domain, are also the problems with any other AI application. This paper proposes an adversarial meta-learning algorithm using task-specific adaptive sample synthesis and consistency regularization, in a refinement phase. By focussing on the classifier's strengths and weaknesses, it boosts both robustness and generalization of the model. Additionally, the paper introduces a hierarchical multi-agent retrieval-augmented generation workflow with a sample synthesis module to dynamically adapt the model to new data trends by generating custom deepfake samples. The paper further presents a framework integrating the meta-learning algorithm with the hierarchical multi-agent workflow, offering a holistic solution for enhancing generalization, robustness, and adaptability. Experimental results demonstrate the model's consistent performance across various datasets, outperforming the models in comparison.","sentences":["Pioneering advancements in artificial intelligence, especially in genAI, have enabled significant possibilities for content creation, but also led to widespread misinformation and false content.","The growing sophistication and realism of deepfakes is raising concerns about privacy invasion, identity theft, and has societal, business impacts, including reputational damage and financial loss.","Many deepfake detectors have been developed to tackle this problem.","Nevertheless, as for every AI model, the deepfake detectors face the wrath of lack of considerable generalization to unseen scenarios and cross-domain deepfakes.","Besides, adversarial robustness is another critical challenge, as detectors drastically underperform to the slightest imperceptible change.","Most state-of-the-art detectors are trained on static datasets and lack the ability to adapt to emerging deepfake attack trends.","These three crucial challenges though hold paramount importance for reliability in practise, particularly in the deepfake domain, are also the problems with any other AI application.","This paper proposes an adversarial meta-learning algorithm using task-specific adaptive sample synthesis and consistency regularization, in a refinement phase.","By focussing on the classifier's strengths and weaknesses, it boosts both robustness and generalization of the model.","Additionally, the paper introduces a hierarchical multi-agent retrieval-augmented generation workflow with a sample synthesis module to dynamically adapt the model to new data trends by generating custom deepfake samples.","The paper further presents a framework integrating the meta-learning algorithm with the hierarchical multi-agent workflow, offering a holistic solution for enhancing generalization, robustness, and adaptability.","Experimental results demonstrate the model's consistent performance across various datasets, outperforming the models in comparison."],"url":"http://arxiv.org/abs/2411.08148v1"}
{"created":"2024-11-12 19:53:00","title":"Large Language Models Can Self-Improve in Long-context Reasoning","abstract":"Large language models (LLMs) have achieved substantial progress in processing long contexts but still struggle with long-context reasoning. Existing approaches typically involve fine-tuning LLMs with synthetic data, which depends on annotations from human experts or advanced models like GPT-4, thus restricting further advancements. To address this issue, we investigate the potential for LLMs to self-improve in long-context reasoning and propose \\ours, an approach specifically designed for this purpose. This approach is straightforward: we sample multiple outputs for each question, score them with Minimum Bayes Risk, and then apply supervised fine-tuning or preference optimization based on these outputs. Extensive experiments on several leading LLMs demonstrate the effectiveness of \\ours, with an absolute improvement of $4.2$ points for Llama-3.1-8B-Instruct. Furthermore, \\ours achieves superior performance compared to prior approaches that depend on data produced by human experts or advanced models. We anticipate that this work will open new avenues for self-improvement techniques in long-context scenarios, which are essential for the continual advancement of LLMs.","sentences":["Large language models (LLMs) have achieved substantial progress in processing long contexts but still struggle with long-context reasoning.","Existing approaches typically involve fine-tuning LLMs with synthetic data, which depends on annotations from human experts or advanced models like GPT-4, thus restricting further advancements.","To address this issue, we investigate the potential for LLMs to self-improve in long-context reasoning and propose \\ours, an approach specifically designed for this purpose.","This approach is straightforward: we sample multiple outputs for each question, score them with Minimum Bayes Risk, and then apply supervised fine-tuning or preference optimization based on these outputs.","Extensive experiments on several leading LLMs demonstrate the effectiveness of \\ours, with an absolute improvement of $4.2$ points for Llama-3.1-8B-Instruct.","Furthermore, \\ours achieves superior performance compared to prior approaches that depend on data produced by human experts or advanced models.","We anticipate that this work will open new avenues for self-improvement techniques in long-context scenarios, which are essential for the continual advancement of LLMs."],"url":"http://arxiv.org/abs/2411.08147v1"}
{"created":"2024-11-12 19:27:12","title":"Simultaneous Locomotion Mode Classification and Continuous Gait Phase Estimation for Transtibial Prostheses","abstract":"Recognizing and identifying human locomotion is a critical step to ensuring fluent control of wearable robots, such as transtibial prostheses. In particular, classifying the intended locomotion mode and estimating the gait phase are key. In this work, a novel, interpretable, and computationally efficient algorithm is presented for simultaneously predicting locomotion mode and gait phase. Using able-bodied (AB) and transtibial prosthesis (PR) data, seven locomotion modes are tested including slow, medium, and fast level walking (0.6, 0.8, and 1.0 m/s), ramp ascent/descent (5 degrees), and stair ascent/descent (20 cm height). Overall classification accuracy was 99.1$\\%$ and 99.3$\\%$ for the AB and PR conditions, respectively. The average gait phase error across all data was less than 4$\\%$. Exploiting the structure of the data, computational efficiency reached 2.91 $\\mu$s per time step. The time complexity of this algorithm scales as $O(N\\cdot M)$ with the number of locomotion modes $M$ and samples per gait cycle $N$. This efficiency and high accuracy could accommodate a much larger set of locomotion modes ($\\sim$ 700 on Open-Source Leg Prosthesis) to handle the wide range of activities pursued by individuals during daily living.","sentences":["Recognizing and identifying human locomotion is a critical step to ensuring fluent control of wearable robots, such as transtibial prostheses.","In particular, classifying the intended locomotion mode and estimating the gait phase are key.","In this work, a novel, interpretable, and computationally efficient algorithm is presented for simultaneously predicting locomotion mode and gait phase.","Using able-bodied (AB) and transtibial prosthesis (PR) data, seven locomotion modes are tested including slow, medium, and fast level walking (0.6, 0.8, and 1.0 m/s), ramp ascent/descent (5 degrees), and stair ascent/descent (20 cm height).","Overall classification accuracy was 99.1$\\%$ and 99.3$\\%$ for the AB and PR conditions, respectively.","The average gait phase error across all data was less than 4$\\%$. Exploiting the structure of the data, computational efficiency reached 2.91 $\\mu$s per time step.","The time complexity of this algorithm scales as $O(N\\cdot M)$ with the number of locomotion modes $M$ and samples per gait cycle $N$. This efficiency and high accuracy could accommodate a much larger set of locomotion modes ($\\sim$ 700 on Open-Source Leg Prosthesis) to handle the wide range of activities pursued by individuals during daily living."],"url":"http://arxiv.org/abs/2411.08136v1"}
{"created":"2024-11-12 19:26:43","title":"On the Role of Speech Data in Reducing Toxicity Detection Bias","abstract":"Text toxicity detection systems exhibit significant biases, producing disproportionate rates of false positives on samples mentioning demographic groups. But what about toxicity detection in speech? To investigate the extent to which text-based biases are mitigated by speech-based systems, we produce a set of high-quality group annotations for the multilingual MuTox dataset, and then leverage these annotations to systematically compare speech- and text-based toxicity classifiers. Our findings indicate that access to speech data during inference supports reduced bias against group mentions, particularly for ambiguous and disagreement-inducing samples. Our results also suggest that improving classifiers, rather than transcription pipelines, is more helpful for reducing group bias. We publicly release our annotations and provide recommendations for future toxicity dataset construction.","sentences":["Text toxicity detection systems exhibit significant biases, producing disproportionate rates of false positives on samples mentioning demographic groups.","But what about toxicity detection in speech?","To investigate the extent to which text-based biases are mitigated by speech-based systems, we produce a set of high-quality group annotations for the multilingual MuTox dataset, and then leverage these annotations to systematically compare speech- and text-based toxicity classifiers.","Our findings indicate that access to speech data during inference supports reduced bias against group mentions, particularly for ambiguous and disagreement-inducing samples.","Our results also suggest that improving classifiers, rather than transcription pipelines, is more helpful for reducing group bias.","We publicly release our annotations and provide recommendations for future toxicity dataset construction."],"url":"http://arxiv.org/abs/2411.08135v1"}
{"created":"2024-11-12 19:24:42","title":"Impactful Bit-Flip Search on Full-precision Models","abstract":"Neural networks have shown remarkable performance in various tasks, yet they remain susceptible to subtle changes in their input or model parameters. One particularly impactful vulnerability arises through the Bit-Flip Attack (BFA), where flipping a small number of critical bits in a model's parameters can severely degrade its performance. A common technique for inducing bit flips in DRAM is the Row-Hammer attack, which exploits frequent uncached memory accesses to alter data. Identifying susceptible bits can be achieved through exhaustive search or progressive layer-by-layer analysis, especially in quantized networks. In this work, we introduce Impactful Bit-Flip Search (IBS), a novel method for efficiently pinpointing and flipping critical bits in full-precision networks. Additionally, we propose a Weight-Stealth technique that strategically modifies the model's parameters in a way that maintains the float values within the original distribution, thereby bypassing simple range checks often used in tamper detection.","sentences":["Neural networks have shown remarkable performance in various tasks, yet they remain susceptible to subtle changes in their input or model parameters.","One particularly impactful vulnerability arises through the Bit-Flip Attack (BFA), where flipping a small number of critical bits in a model's parameters can severely degrade its performance.","A common technique for inducing bit flips in DRAM is the Row-Hammer attack, which exploits frequent uncached memory accesses to alter data.","Identifying susceptible bits can be achieved through exhaustive search or progressive layer-by-layer analysis, especially in quantized networks.","In this work, we introduce Impactful Bit-Flip Search (IBS), a novel method for efficiently pinpointing and flipping critical bits in full-precision networks.","Additionally, we propose a Weight-Stealth technique that strategically modifies the model's parameters in a way that maintains the float values within the original distribution, thereby bypassing simple range checks often used in tamper detection."],"url":"http://arxiv.org/abs/2411.08133v1"}
{"created":"2024-11-12 19:12:12","title":"CameraHMR: Aligning People with Perspective","abstract":"We address the challenge of accurate 3D human pose and shape estimation from monocular images. The key to accuracy and robustness lies in high-quality training data. Existing training datasets containing real images with pseudo ground truth (pGT) use SMPLify to fit SMPL to sparse 2D joint locations, assuming a simplified camera with default intrinsics. We make two contributions that improve pGT accuracy. First, to estimate camera intrinsics, we develop a field-of-view prediction model (HumanFoV) trained on a dataset of images containing people. We use the estimated intrinsics to enhance the 4D-Humans dataset by incorporating a full perspective camera model during SMPLify fitting. Second, 2D joints provide limited constraints on 3D body shape, resulting in average-looking bodies. To address this, we use the BEDLAM dataset to train a dense surface keypoint detector. We apply this detector to the 4D-Humans dataset and modify SMPLify to fit the detected keypoints, resulting in significantly more realistic body shapes. Finally, we upgrade the HMR2.0 architecture to include the estimated camera parameters. We iterate model training and SMPLify fitting initialized with the previously trained model. This leads to more accurate pGT and a new model, CameraHMR, with state-of-the-art accuracy. Code and pGT are available for research purposes.","sentences":["We address the challenge of accurate 3D human pose and shape estimation from monocular images.","The key to accuracy and robustness lies in high-quality training data.","Existing training datasets containing real images with pseudo ground truth (pGT) use SMPLify to fit SMPL to sparse 2D joint locations, assuming a simplified camera with default intrinsics.","We make two contributions that improve pGT accuracy.","First, to estimate camera intrinsics, we develop a field-of-view prediction model (HumanFoV) trained on a dataset of images containing people.","We use the estimated intrinsics to enhance the 4D-Humans dataset by incorporating a full perspective camera model during SMPLify fitting.","Second, 2D joints provide limited constraints on 3D body shape, resulting in average-looking bodies.","To address this, we use the BEDLAM dataset to train a dense surface keypoint detector.","We apply this detector to the 4D-Humans dataset and modify SMPLify to fit the detected keypoints, resulting in significantly more realistic body shapes.","Finally, we upgrade the HMR2.0 architecture to include the estimated camera parameters.","We iterate model training and SMPLify fitting initialized with the previously trained model.","This leads to more accurate pGT and a new model, CameraHMR, with state-of-the-art accuracy.","Code and pGT are available for research purposes."],"url":"http://arxiv.org/abs/2411.08128v1"}
