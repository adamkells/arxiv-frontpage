{"created":"2024-09-10 17:59:55","title":"GeoCalib: Learning Single-image Calibration with Geometric Optimization","abstract":"From a single image, visual cues can help deduce intrinsic and extrinsic camera parameters like the focal length and the gravity direction. This single-image calibration can benefit various downstream applications like image editing and 3D mapping. Current approaches to this problem are based on either classical geometry with lines and vanishing points or on deep neural networks trained end-to-end. The learned approaches are more robust but struggle to generalize to new environments and are less accurate than their classical counterparts. We hypothesize that they lack the constraints that 3D geometry provides. In this work, we introduce GeoCalib, a deep neural network that leverages universal rules of 3D geometry through an optimization process. GeoCalib is trained end-to-end to estimate camera parameters and learns to find useful visual cues from the data. Experiments on various benchmarks show that GeoCalib is more robust and more accurate than existing classical and learned approaches. Its internal optimization estimates uncertainties, which help flag failure cases and benefit downstream applications like visual localization. The code and trained models are publicly available at https://github.com/cvg/GeoCalib.","sentences":["From a single image, visual cues can help deduce intrinsic and extrinsic camera parameters like the focal length and the gravity direction.","This single-image calibration can benefit various downstream applications like image editing and 3D mapping.","Current approaches to this problem are based on either classical geometry with lines and vanishing points or on deep neural networks trained end-to-end.","The learned approaches are more robust but struggle to generalize to new environments and are less accurate than their classical counterparts.","We hypothesize that they lack the constraints that 3D geometry provides.","In this work, we introduce GeoCalib, a deep neural network that leverages universal rules of 3D geometry through an optimization process.","GeoCalib is trained end-to-end to estimate camera parameters and learns to find useful visual cues from the data.","Experiments on various benchmarks show that GeoCalib is more robust and more accurate than existing classical and learned approaches.","Its internal optimization estimates uncertainties, which help flag failure cases and benefit downstream applications like visual localization.","The code and trained models are publicly available at https://github.com/cvg/GeoCalib."],"url":"http://arxiv.org/abs/2409.06704v1"}
{"created":"2024-09-10 17:54:28","title":"Geometric-Averaged Preference Optimization for Soft Preference Labels","abstract":"Many algorithms for aligning LLMs with human preferences assume that human preferences are binary and deterministic. However, it is reasonable to think that they can vary with different individuals, and thus should be distributional to reflect the fine-grained relationship between the responses. In this work, we introduce the distributional soft preference labels and improve Direct Preference Optimization (DPO) with a weighted geometric average of the LLM output likelihood in the loss function. In doing so, the scale of learning loss is adjusted based on the soft labels, and the loss with equally preferred responses would be close to zero. This simple modification can be easily applied to any DPO family and helps the models escape from the over-optimization and objective mismatch prior works suffer from. In our experiments, we simulate the soft preference labels with AI feedback from LLMs and demonstrate that geometric averaging consistently improves performance on standard benchmarks for alignment research. In particular, we observe more preferable responses than binary labels and significant improvements with data where modestly-confident labels are in the majority.","sentences":["Many algorithms for aligning LLMs with human preferences assume that human preferences are binary and deterministic.","However, it is reasonable to think that they can vary with different individuals, and thus should be distributional to reflect the fine-grained relationship between the responses.","In this work, we introduce the distributional soft preference labels and improve Direct Preference Optimization (DPO) with a weighted geometric average of the LLM output likelihood in the loss function.","In doing so, the scale of learning loss is adjusted based on the soft labels, and the loss with equally preferred responses would be close to zero.","This simple modification can be easily applied to any DPO family and helps the models escape from the over-optimization and objective mismatch prior works suffer from.","In our experiments, we simulate the soft preference labels with AI feedback from LLMs and demonstrate that geometric averaging consistently improves performance on standard benchmarks for alignment research.","In particular, we observe more preferable responses than binary labels and significant improvements with data where modestly-confident labels are in the majority."],"url":"http://arxiv.org/abs/2409.06691v1"}
{"created":"2024-09-10 17:34:07","title":"Data Collection-free Masked Video Modeling","abstract":"Pre-training video transformers generally requires a large amount of data, presenting significant challenges in terms of data collection costs and concerns related to privacy, licensing, and inherent biases. Synthesizing data is one of the promising ways to solve these issues, yet pre-training solely on synthetic data has its own challenges. In this paper, we introduce an effective self-supervised learning framework for videos that leverages readily available and less costly static images. Specifically, we define the Pseudo Motion Generator (PMG) module that recursively applies image transformations to generate pseudo-motion videos from images. These pseudo-motion videos are then leveraged in masked video modeling. Our approach is applicable to synthetic images as well, thus entirely freeing video pre-training from data collection costs and other concerns in real data. Through experiments in action recognition tasks, we demonstrate that this framework allows effective learning of spatio-temporal features through pseudo-motion videos, significantly improving over existing methods which also use static images and partially outperforming those using both real and synthetic videos. These results uncover fragments of what video transformers learn through masked video modeling.","sentences":["Pre-training video transformers generally requires a large amount of data, presenting significant challenges in terms of data collection costs and concerns related to privacy, licensing, and inherent biases.","Synthesizing data is one of the promising ways to solve these issues, yet pre-training solely on synthetic data has its own challenges.","In this paper, we introduce an effective self-supervised learning framework for videos that leverages readily available and less costly static images.","Specifically, we define the Pseudo Motion Generator (PMG) module that recursively applies image transformations to generate pseudo-motion videos from images.","These pseudo-motion videos are then leveraged in masked video modeling.","Our approach is applicable to synthetic images as well, thus entirely freeing video pre-training from data collection costs and other concerns in real data.","Through experiments in action recognition tasks, we demonstrate that this framework allows effective learning of spatio-temporal features through pseudo-motion videos, significantly improving over existing methods which also use static images and partially outperforming those using both real and synthetic videos.","These results uncover fragments of what video transformers learn through masked video modeling."],"url":"http://arxiv.org/abs/2409.06665v1"}
{"created":"2024-09-10 17:00:19","title":"EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis","abstract":"Early detection of eye diseases like glaucoma, macular degeneration, and diabetic retinopathy is crucial for preventing vision loss. While artificial intelligence (AI) foundation models hold significant promise for addressing these challenges, existing ophthalmic foundation models primarily focus on a single modality, whereas diagnosing eye diseases requires multiple modalities. A critical yet often overlooked aspect is harnessing the multi-view information across various modalities for the same patient. Additionally, due to the long-tail nature of ophthalmic diseases, standard fully supervised or unsupervised learning approaches often struggle. Therefore, it is essential to integrate clinical text to capture a broader spectrum of diseases. We propose EyeCLIP, a visual-language foundation model developed using over 2.77 million multi-modal ophthalmology images with partial text data. To fully leverage the large multi-modal unlabeled and labeled data, we introduced a pretraining strategy that combines self-supervised reconstructions, multi-modal image contrastive learning, and image-text contrastive learning to learn a shared representation of multiple modalities. Through evaluation using 14 benchmark datasets, EyeCLIP can be transferred to a wide range of downstream tasks involving ocular and systemic diseases, achieving state-of-the-art performance in disease classification, visual question answering, and cross-modal retrieval. EyeCLIP represents a significant advancement over previous methods, especially showcasing few-shot, even zero-shot capabilities in real-world long-tail scenarios.","sentences":["Early detection of eye diseases like glaucoma, macular degeneration, and diabetic retinopathy is crucial for preventing vision loss.","While artificial intelligence (AI) foundation models hold significant promise for addressing these challenges, existing ophthalmic foundation models primarily focus on a single modality, whereas diagnosing eye diseases requires multiple modalities.","A critical yet often overlooked aspect is harnessing the multi-view information across various modalities for the same patient.","Additionally, due to the long-tail nature of ophthalmic diseases, standard fully supervised or unsupervised learning approaches often struggle.","Therefore, it is essential to integrate clinical text to capture a broader spectrum of diseases.","We propose EyeCLIP, a visual-language foundation model developed using over 2.77 million multi-modal ophthalmology images with partial text data.","To fully leverage the large multi-modal unlabeled and labeled data, we introduced a pretraining strategy that combines self-supervised reconstructions, multi-modal image contrastive learning, and image-text contrastive learning to learn a shared representation of multiple modalities.","Through evaluation using 14 benchmark datasets, EyeCLIP can be transferred to a wide range of downstream tasks involving ocular and systemic diseases, achieving state-of-the-art performance in disease classification, visual question answering, and cross-modal retrieval.","EyeCLIP represents a significant advancement over previous methods, especially showcasing few-shot, even zero-shot capabilities in real-world long-tail scenarios."],"url":"http://arxiv.org/abs/2409.06644v1"}
{"created":"2024-09-10 16:59:33","title":"Strategic management analysis: from data to strategy diagram by LLM","abstract":"Strategy management analyses are created by business consultants with common analysis frameworks (i.e. comparative analyses) and associated diagrams. We show these can be largely constructed using LLMs, starting with the extraction of insights from data, organization of those insights according to a strategy management framework, and then depiction in the typical strategy management diagram for that framework (static textual visualizations). We discuss caveats and future directions to generalize for broader uses.","sentences":["Strategy management analyses are created by business consultants with common analysis frameworks (i.e. comparative analyses) and associated diagrams.","We show these can be largely constructed using LLMs, starting with the extraction of insights from data, organization of those insights according to a strategy management framework, and then depiction in the typical strategy management diagram for that framework (static textual visualizations).","We discuss caveats and future directions to generalize for broader uses."],"url":"http://arxiv.org/abs/2409.06643v1"}
{"created":"2024-09-10 16:54:32","title":"TeXBLEU: Automatic Metric for Evaluate LaTeX Format","abstract":"LaTeX is highly suited to creating documents with special formatting, particularly in the fields of science, technology, mathematics, and computer science. Despite the increasing use of mathematical expressions in LaTeX format with language models, there are no evaluation metrics for evaluating them. In this study, we propose TeXBLEU, an evaluation metric tailored for mathematical expressions in LaTeX format, based on the n-gram-based BLEU metric that is widely used for translation tasks. The proposed TeXBLEU includes a predefined tokenizer trained on the arXiv paper dataset and a finetuned embedding model. It also considers the positional embedding of tokens. Simultaneously, TeXBLEU compares tokens based on n-grams and computes the score using exponentiation of a logarithmic sum, similar to the original BLEU. Experimental results show that TeXBLEU outperformed traditional evaluation metrics such as BLEU, Rouge, CER, and WER when compared to human evaluation data on the test dataset of the MathBridge dataset, which contains 1,000 data points. The average correlation coefficient with human evaluation was 0.71, which is an improvement of 87% compared with BLEU, which had the highest correlation with human evaluation data among the existing metrics. The code is available at https://github.com/KyuDan1/TeXBLEU.","sentences":["LaTeX is highly suited to creating documents with special formatting, particularly in the fields of science, technology, mathematics, and computer science.","Despite the increasing use of mathematical expressions in LaTeX format with language models, there are no evaluation metrics for evaluating them.","In this study, we propose TeXBLEU, an evaluation metric tailored for mathematical expressions in LaTeX format, based on the n-gram-based BLEU metric that is widely used for translation tasks.","The proposed TeXBLEU includes a predefined tokenizer trained on the arXiv paper dataset and a finetuned embedding model.","It also considers the positional embedding of tokens.","Simultaneously, TeXBLEU compares tokens based on n-grams and computes the score using exponentiation of a logarithmic sum, similar to the original BLEU.","Experimental results show that TeXBLEU outperformed traditional evaluation metrics such as BLEU, Rouge, CER, and WER when compared to human evaluation data on the test dataset of the MathBridge dataset, which contains 1,000 data points.","The average correlation coefficient with human evaluation was 0.71, which is an improvement of 87% compared with BLEU, which had the highest correlation with human evaluation data among the existing metrics.","The code is available at https://github.com/KyuDan1/TeXBLEU."],"url":"http://arxiv.org/abs/2409.06639v1"}
{"created":"2024-09-10 16:48:05","title":"Critical Features Tracking on Triangulated Irregular Networks by a Scale-Space Method","abstract":"The scale-space method is a well-established framework that constructs a hierarchical representation of an input signal and facilitates coarse-to-fine visual reasoning. Considering the terrain elevation function as the input signal, the scale-space method can identify and track significant topographic features across different scales. The number of scales a feature persists, called its life span, indicates the importance of that feature. In this way, important topographic features of a landscape can be selected, which are useful for many applications, including cartography, nautical charting, and land-use planning. The scale-space methods developed for terrain data use gridded Digital Elevation Models (DEMs) to represent the terrain. However, gridded DEMs lack the flexibility to adapt to the irregular distribution of input data and the varied topological complexity of different regions. Instead, Triangulated Irregular Networks (TINs) can be directly generated from irregularly distributed point clouds and accurately preserve important features. In this work, we introduce a novel scale-space analysis pipeline for TINs, addressing the multiple challenges in extending grid-based scale-space methods to TINs. Our pipeline can efficiently identify and track topologically important features on TINs. Moreover, it is capable of analyzing terrains with irregular boundaries, which poses challenges for grid-based methods. Comprehensive experiments show that, compared to grid-based methods, our TIN-based pipeline is more efficient, accurate, and has better resolution robustness.","sentences":["The scale-space method is a well-established framework that constructs a hierarchical representation of an input signal and facilitates coarse-to-fine visual reasoning.","Considering the terrain elevation function as the input signal, the scale-space method can identify and track significant topographic features across different scales.","The number of scales a feature persists, called its life span, indicates the importance of that feature.","In this way, important topographic features of a landscape can be selected, which are useful for many applications, including cartography, nautical charting, and land-use planning.","The scale-space methods developed for terrain data use gridded Digital Elevation Models (DEMs) to represent the terrain.","However, gridded DEMs lack the flexibility to adapt to the irregular distribution of input data and the varied topological complexity of different regions.","Instead, Triangulated Irregular Networks (TINs) can be directly generated from irregularly distributed point clouds and accurately preserve important features.","In this work, we introduce a novel scale-space analysis pipeline for TINs, addressing the multiple challenges in extending grid-based scale-space methods to TINs.","Our pipeline can efficiently identify and track topologically important features on TINs.","Moreover, it is capable of analyzing terrains with irregular boundaries, which poses challenges for grid-based methods.","Comprehensive experiments show that, compared to grid-based methods, our TIN-based pipeline is more efficient, accurate, and has better resolution robustness."],"url":"http://arxiv.org/abs/2409.06638v1"}
{"created":"2024-09-10 16:30:20","title":"Advanced Gaze Analytics Dashboard","abstract":"Eye movements can provide informative cues to understand human visual scan/search behavior and cognitive load during varying tasks. Visualizations of real-time gaze measures during tasks, provide an understanding of human behavior as the experiment is being conducted. Even though existing eye tracking analysis tools provide calculation and visualization of eye-tracking data, none of them support real-time visualizations of advanced gaze measures, such as ambient or focal processing, or eye-tracked measures of cognitive load. In this paper, we present an eye movements analytics dashboard that enables visualizations of various gaze measures, fixations, saccades, cognitive load, ambient-focal attention, and gaze transitions analysis by extracting eye movements from participants utilizing common off-the-shelf eye trackers. We validate the proposed eye movement visualizations by using two publicly available eye-tracking datasets. We showcase that, the proposed dashboard could be utilized to visualize advanced eye movement measures generated using multiple data sources.","sentences":["Eye movements can provide informative cues to understand human visual scan/search behavior and cognitive load during varying tasks.","Visualizations of real-time gaze measures during tasks, provide an understanding of human behavior as the experiment is being conducted.","Even though existing eye tracking analysis tools provide calculation and visualization of eye-tracking data, none of them support real-time visualizations of advanced gaze measures, such as ambient or focal processing, or eye-tracked measures of cognitive load.","In this paper, we present an eye movements analytics dashboard that enables visualizations of various gaze measures, fixations, saccades, cognitive load, ambient-focal attention, and gaze transitions analysis by extracting eye movements from participants utilizing common off-the-shelf eye trackers.","We validate the proposed eye movement visualizations by using two publicly available eye-tracking datasets.","We showcase that, the proposed dashboard could be utilized to visualize advanced eye movement measures generated using multiple data sources."],"url":"http://arxiv.org/abs/2409.06628v1"}
{"created":"2024-09-10 16:29:30","title":"\"The struggle is a part of the experience\": Engaging Discontents in the Design of Family Meal Technologies","abstract":"Meals are a central (and messy) part of family life. Previous design framings for mealtime technologies have focused on supporting dietary needs or social and celebratory interactions at the dinner table; however, family meals involve the coordination of many activities and complicated family dynamics. In this paper, we report on findings from interviews and design sessions with 18 families from the Midwestern United States (including both partners/parents and children) to uncover important family differences and tensions that arise around domestic meal experiences. Drawing on feminist theory, we unpack the work of feeding a family as a form of care, drawing attention to the social and emotional complexity of family meals. Critically situating our data within current design narratives, we propose the sensitizing concepts of generative and systemic discontents as a productive way towards troubling the design space of family-food interaction to contend with the struggles that are a part of everyday family meal experiences.","sentences":["Meals are a central (and messy) part of family life.","Previous design framings for mealtime technologies have focused on supporting dietary needs or social and celebratory interactions at the dinner table; however, family meals involve the coordination of many activities and complicated family dynamics.","In this paper, we report on findings from interviews and design sessions with 18 families from the Midwestern United States (including both partners/parents and children) to uncover important family differences and tensions that arise around domestic meal experiences.","Drawing on feminist theory, we unpack the work of feeding a family as a form of care, drawing attention to the social and emotional complexity of family meals.","Critically situating our data within current design narratives, we propose the sensitizing concepts of generative and systemic discontents as a productive way towards troubling the design space of family-food interaction to contend with the struggles that are a part of everyday family meal experiences."],"url":"http://arxiv.org/abs/2409.06627v1"}
{"created":"2024-09-10 16:28:09","title":"Towards Localizing Structural Elements: Merging Geometrical Detection with Semantic Verification in RGB-D Data","abstract":"RGB-D cameras supply rich and dense visual and spatial information for various robotics tasks such as scene understanding, map reconstruction, and localization. Integrating depth and visual information can aid robots in localization and element mapping, advancing applications like 3D scene graph generation and Visual Simultaneous Localization and Mapping (VSLAM). While point cloud data containing such information is primarily used for enhanced scene understanding, exploiting their potential to capture and represent rich semantic information has yet to be adequately targeted. This paper presents a real-time pipeline for localizing building components, including wall and ground surfaces, by integrating geometric calculations for pure 3D plane detection followed by validating their semantic category using point cloud data from RGB-D cameras. It has a parallel multi-thread architecture to precisely estimate poses and equations of all the planes detected in the environment, filters the ones forming the map structure using a panoptic segmentation validation, and keeps only the validated building components. Incorporating the proposed method into a VSLAM framework confirmed that constraining the map with the detected environment-driven semantic elements can improve scene understanding and map reconstruction accuracy. It can also ensure (re-)association of these detected components into a unified 3D scene graph, bridging the gap between geometric accuracy and semantic understanding. Additionally, the pipeline allows for the detection of potential higher-level structural entities, such as rooms, by identifying the relationships between building components based on their layout.","sentences":["RGB-D cameras supply rich and dense visual and spatial information for various robotics tasks such as scene understanding, map reconstruction, and localization.","Integrating depth and visual information can aid robots in localization and element mapping, advancing applications like 3D scene graph generation and Visual Simultaneous Localization and Mapping (VSLAM).","While point cloud data containing such information is primarily used for enhanced scene understanding, exploiting their potential to capture and represent rich semantic information has yet to be adequately targeted.","This paper presents a real-time pipeline for localizing building components, including wall and ground surfaces, by integrating geometric calculations for pure 3D plane detection followed by validating their semantic category using point cloud data from RGB-D cameras.","It has a parallel multi-thread architecture to precisely estimate poses and equations of all the planes detected in the environment, filters the ones forming the map structure using a panoptic segmentation validation, and keeps only the validated building components.","Incorporating the proposed method into a VSLAM framework confirmed that constraining the map with the detected environment-driven semantic elements can improve scene understanding and map reconstruction accuracy.","It can also ensure (re-)association of these detected components into a unified 3D scene graph, bridging the gap between geometric accuracy and semantic understanding.","Additionally, the pipeline allows for the detection of potential higher-level structural entities, such as rooms, by identifying the relationships between building components based on their layout."],"url":"http://arxiv.org/abs/2409.06625v1"}
{"created":"2024-09-10 16:22:18","title":"Exploring Italian sentence embeddings properties through multi-tasking","abstract":"We investigate to what degree existing LLMs encode abstract linguistic information in Italian in a multi-task setting. We exploit curated synthetic data on a large scale -- several Blackbird Language Matrices (BLMs) problems in Italian -- and use them to study how sentence representations built using pre-trained language models encode specific syntactic and semantic information. We use a two-level architecture to model separately a compression of the sentence embeddings into a representation that contains relevant information for a task, and a BLM task. We then investigate whether we can obtain compressed sentence representations that encode syntactic and semantic information relevant to several BLM tasks. While we expected that the sentence structure -- in terms of sequence of phrases/chunks -- and chunk properties could be shared across tasks, performance and error analysis show that the clues for the different tasks are encoded in different manners in the sentence embeddings, suggesting that abstract linguistic notions such as constituents or thematic roles does not seem to be present in the pretrained sentence embeddings.","sentences":["We investigate to what degree existing LLMs encode abstract linguistic information in Italian in a multi-task setting.","We exploit curated synthetic data on a large scale -- several Blackbird Language Matrices (BLMs) problems in Italian -- and use them to study how sentence representations built using pre-trained language models encode specific syntactic and semantic information.","We use a two-level architecture to model separately a compression of the sentence embeddings into a representation that contains relevant information for a task, and a BLM task.","We then investigate whether we can obtain compressed sentence representations that encode syntactic and semantic information relevant to several BLM tasks.","While we expected that the sentence structure -- in terms of sequence of phrases/chunks -- and chunk properties could be shared across tasks, performance and error analysis show that the clues for the different tasks are encoded in different manners in the sentence embeddings, suggesting that abstract linguistic notions such as constituents or thematic roles does not seem to be present in the pretrained sentence embeddings."],"url":"http://arxiv.org/abs/2409.06622v1"}
{"created":"2024-09-10 16:15:01","title":"Hierarchical Multi-Label Classification with Missing Information for Benthic Habitat Imagery","abstract":"In this work, we apply state-of-the-art self-supervised learning techniques on a large dataset of seafloor imagery, \\textit{BenthicNet}, and study their performance for a complex hierarchical multi-label (HML) classification downstream task. In particular, we demonstrate the capacity to conduct HML training in scenarios where there exist multiple levels of missing annotation information, an important scenario for handling heterogeneous real-world data collected by multiple research groups with differing data collection protocols. We find that, when using smaller one-hot image label datasets typical of local or regional scale benthic science projects, models pre-trained with self-supervision on a larger collection of in-domain benthic data outperform models pre-trained on ImageNet. In the HML setting, we find the model can attain a deeper and more precise classification if it is pre-trained with self-supervision on in-domain data. We hope this work can establish a benchmark for future models in the field of automated underwater image annotation tasks and can guide work in other domains with hierarchical annotations of mixed resolution.","sentences":["In this work, we apply state-of-the-art self-supervised learning techniques on a large dataset of seafloor imagery, \\textit{BenthicNet}, and study their performance for a complex hierarchical multi-label (HML) classification downstream task.","In particular, we demonstrate the capacity to conduct HML training in scenarios where there exist multiple levels of missing annotation information, an important scenario for handling heterogeneous real-world data collected by multiple research groups with differing data collection protocols.","We find that, when using smaller one-hot image label datasets typical of local or regional scale benthic science projects, models pre-trained with self-supervision on a larger collection of in-domain benthic data outperform models pre-trained on ImageNet.","In the HML setting, we find the model can attain a deeper and more precise classification if it is pre-trained with self-supervision on in-domain data.","We hope this work can establish a benchmark for future models in the field of automated underwater image annotation tasks and can guide work in other domains with hierarchical annotations of mixed resolution."],"url":"http://arxiv.org/abs/2409.06618v1"}
{"created":"2024-09-10 16:11:57","title":"One-Shot Imitation under Mismatched Execution","abstract":"Human demonstrations as prompts are a powerful way to program robots to do long-horizon manipulation tasks. However, directly translating such demonstrations into robot-executable actions poses significant challenges due to execution mismatches, such as different movement styles and physical capabilities. Existing methods either rely on robot-demonstrator paired data, which is infeasible to scale, or overly rely on frame-level visual similarities, which fail to hold. To address these challenges, we propose RHyME, a novel framework that automatically establishes task execution correspondences between the robot and the demonstrator by using optimal transport costs. Given long-horizon robot demonstrations, RHyME synthesizes semantically equivalent human demonstrations by retrieving and composing similar short-horizon human clips, facilitating effective policy training without the need for paired data. We show that RHyME outperforms a range of baselines across various cross-embodiment datasets on all degrees of mismatches. Through detailed analysis, we uncover insights for learning and leveraging cross-embodiment visual representations.","sentences":["Human demonstrations as prompts are a powerful way to program robots to do long-horizon manipulation tasks.","However, directly translating such demonstrations into robot-executable actions poses significant challenges due to execution mismatches, such as different movement styles and physical capabilities.","Existing methods either rely on robot-demonstrator paired data, which is infeasible to scale, or overly rely on frame-level visual similarities, which fail to hold.","To address these challenges, we propose RHyME, a novel framework that automatically establishes task execution correspondences between the robot and the demonstrator by using optimal transport costs.","Given long-horizon robot demonstrations, RHyME synthesizes semantically equivalent human demonstrations by retrieving and composing similar short-horizon human clips, facilitating effective policy training without the need for paired data.","We show that RHyME outperforms a range of baselines across various cross-embodiment datasets on all degrees of mismatches.","Through detailed analysis, we uncover insights for learning and leveraging cross-embodiment visual representations."],"url":"http://arxiv.org/abs/2409.06615v1"}
{"created":"2024-09-10 16:04:10","title":"Label-free Monitoring of Self-Supervised Learning Progress","abstract":"Self-supervised learning (SSL) is an effective method for exploiting unlabelled data to learn a high-level embedding space that can be used for various downstream tasks. However, existing methods to monitor the quality of the encoder -- either during training for one model or to compare several trained models -- still rely on access to annotated data. When SSL methodologies are applied to new data domains, a sufficiently large labelled dataset may not always be available. In this study, we propose several evaluation metrics which can be applied on the embeddings of unlabelled data and investigate their viability by comparing them to linear probe accuracy (a common metric which utilizes an annotated dataset). In particular, we apply $k$-means clustering and measure the clustering quality with the silhouette score and clustering agreement. We also measure the entropy of the embedding distribution. We find that while the clusters did correspond better to the ground truth annotations as training of the network progressed, label-free clustering metrics correlated with the linear probe accuracy only when training with SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally, although entropy did not always have strong correlations with LP accuracy, this appears to be due to instability arising from early training, with the metric stabilizing and becoming more reliable at later stages of learning. Furthermore, while entropy generally decreases as learning progresses, this trend reverses for SimSiam. More research is required to establish the cause for this unexpected behaviour. Lastly, we find that while clustering based approaches are likely only viable for same-architecture comparisons, entropy may be architecture-independent.","sentences":["Self-supervised learning (SSL) is an effective method for exploiting unlabelled data to learn a high-level embedding space that can be used for various downstream tasks.","However, existing methods to monitor the quality of the encoder -- either during training for one model or to compare several trained models -- still rely on access to annotated data.","When SSL methodologies are applied to new data domains, a sufficiently large labelled dataset may not always be available.","In this study, we propose several evaluation metrics which can be applied on the embeddings of unlabelled data and investigate their viability by comparing them to linear probe accuracy (a common metric which utilizes an annotated dataset).","In particular, we apply $k$-means clustering and measure the clustering quality with the silhouette score and clustering agreement.","We also measure the entropy of the embedding distribution.","We find that while the clusters did correspond better to the ground truth annotations as training of the network progressed, label-free clustering metrics correlated with the linear probe accuracy only when training with SSL methods SimCLR and MoCo-v2, but not with SimSiam.","Additionally, although entropy did not always have strong correlations with LP accuracy, this appears to be due to instability arising from early training, with the metric stabilizing and becoming more reliable at later stages of learning.","Furthermore, while entropy generally decreases as learning progresses, this trend reverses for SimSiam.","More research is required to establish the cause for this unexpected behaviour.","Lastly, we find that while clustering based approaches are likely only viable for same-architecture comparisons, entropy may be architecture-independent."],"url":"http://arxiv.org/abs/2409.06612v1"}
{"created":"2024-09-10 16:02:12","title":"Improving the Precision of CNNs for Magnetic Resonance Spectral Modeling","abstract":"Magnetic resonance spectroscopic imaging is a widely available imaging modality that can non-invasively provide a metabolic profile of the tissue of interest, yet is challenging to integrate clinically. One major reason is the expensive, expert data processing and analysis that is required. Using machine learning to predict MRS-related quantities offers avenues around this problem, but deep learning models bring their own challenges, especially model trust. Current research trends focus primarily on mean error metrics, but comprehensive precision metrics are also needed, e.g. standard deviations, confidence intervals, etc.. This work highlights why more comprehensive error characterization is important and how to improve the precision of CNNs for spectral modeling, a quantitative task. The results highlight advantages and trade-offs of these techniques that should be considered when addressing such regression tasks with CNNs. Detailed insights into the underlying mechanisms of each technique, and how they interact with other techniques, are discussed in depth.","sentences":["Magnetic resonance spectroscopic imaging is a widely available imaging modality that can non-invasively provide a metabolic profile of the tissue of interest, yet is challenging to integrate clinically.","One major reason is the expensive, expert data processing and analysis that is required.","Using machine learning to predict MRS-related quantities offers avenues around this problem, but deep learning models bring their own challenges, especially model trust.","Current research trends focus primarily on mean error metrics, but comprehensive precision metrics are also needed, e.g. standard deviations, confidence intervals, etc.. This work highlights why more comprehensive error characterization is important and how to improve the precision of CNNs for spectral modeling, a quantitative task.","The results highlight advantages and trade-offs of these techniques that should be considered when addressing such regression tasks with CNNs.","Detailed insights into the underlying mechanisms of each technique, and how they interact with other techniques, are discussed in depth."],"url":"http://arxiv.org/abs/2409.06609v1"}
{"created":"2024-09-10 16:00:26","title":"Simulation-based Scenario Generation for Robust Hybrid AI for Autonomy","abstract":"Application of Unmanned Aerial Vehicles (UAVs) in search and rescue, emergency management, and law enforcement has gained traction with the advent of low-cost platforms and sensor payloads. The emergence of hybrid neural and symbolic AI approaches for complex reasoning is expected to further push the boundaries of these applications with decreasing levels of human intervention. However, current UAV simulation environments lack semantic context suited to this hybrid approach. To address this gap, HAMERITT (Hybrid Ai Mission Environment for RapId Training and Testing) provides a simulation-based autonomy software framework that supports the training, testing and assurance of neuro-symbolic algorithms for autonomous maneuver and perception reasoning. HAMERITT includes scenario generation capabilities that offer mission-relevant contextual symbolic information in addition to raw sensor data. Scenarios include symbolic descriptions for entities of interest and their relations to scene elements, as well as spatial-temporal constraints in the form of time-bounded areas of interest with prior probabilities and restricted zones within those areas. HAMERITT also features support for training distinct algorithm threads for maneuver vs. perception within an end-to-end mission run. Future work includes improving scenario realism and scaling symbolic context generation through automated workflow.","sentences":["Application of Unmanned Aerial Vehicles (UAVs) in search and rescue, emergency management, and law enforcement has gained traction with the advent of low-cost platforms and sensor payloads.","The emergence of hybrid neural and symbolic AI approaches for complex reasoning is expected to further push the boundaries of these applications with decreasing levels of human intervention.","However, current UAV simulation environments lack semantic context suited to this hybrid approach.","To address this gap, HAMERITT (Hybrid Ai Mission Environment for RapId Training and Testing) provides a simulation-based autonomy software framework that supports the training, testing and assurance of neuro-symbolic algorithms for autonomous maneuver and perception reasoning.","HAMERITT includes scenario generation capabilities that offer mission-relevant contextual symbolic information in addition to raw sensor data.","Scenarios include symbolic descriptions for entities of interest and their relations to scene elements, as well as spatial-temporal constraints in the form of time-bounded areas of interest with prior probabilities and restricted zones within those areas.","HAMERITT also features support for training distinct algorithm threads for maneuver vs. perception within an end-to-end mission run.","Future work includes improving scenario realism and scaling symbolic context generation through automated workflow."],"url":"http://arxiv.org/abs/2409.06608v1"}
{"created":"2024-09-10 15:51:15","title":"Alleviating Hallucinations in Large Language Models with Scepticism Modeling","abstract":"Hallucinations is a major challenge for large language models (LLMs), prevents adoption in diverse fields. Uncertainty estimation could be used for alleviating the damages of hallucinations. The skeptical emotion of human could be useful for enhancing the ability of self estimation. Inspirited by this observation, we proposed a new approach called Skepticism Modeling (SM). This approach is formalized by combining the information of token and logits for self estimation. We construct the doubt emotion aware data, perform continual pre-training, and then fine-tune the LLMs, improve their ability of self estimation. Experimental results demonstrate this new approach effectively enhances a model's ability to estimate their uncertainty, and validate its generalization ability of other tasks by out-of-domain experiments.","sentences":["Hallucinations is a major challenge for large language models (LLMs), prevents adoption in diverse fields.","Uncertainty estimation could be used for alleviating the damages of hallucinations.","The skeptical emotion of human could be useful for enhancing the ability of self estimation.","Inspirited by this observation, we proposed a new approach called Skepticism Modeling (SM).","This approach is formalized by combining the information of token and logits for self estimation.","We construct the doubt emotion aware data, perform continual pre-training, and then fine-tune the LLMs, improve their ability of self estimation.","Experimental results demonstrate this new approach effectively enhances a model's ability to estimate their uncertainty, and validate its generalization ability of other tasks by out-of-domain experiments."],"url":"http://arxiv.org/abs/2409.06601v1"}
{"created":"2024-09-10 15:22:05","title":"Semi-Supervised 3D Object Detection with Chanel Augmentation using Transformation Equivariance","abstract":"Accurate 3D object detection is crucial for autonomous vehicles and robots to navigate and interact with the environment safely and effectively. Meanwhile, the performance of 3D detector relies on the data size and annotation which is expensive. Consequently, the demand of training with limited labeled data is growing. We explore a novel teacher-student framework employing channel augmentation for 3D semi-supervised object detection. The teacher-student SSL typically adopts a weak augmentation and strong augmentation to teacher and student, respectively. In this work, we apply multiple channel augmentations to both networks using the transformation equivariance detector (TED). The TED allows us to explore different combinations of augmentation on point clouds and efficiently aggregates multi-channel transformation equivariance features. In principle, by adopting fixed channel augmentations for the teacher network, the student can train stably on reliable pseudo-labels. Adopting strong channel augmentations can enrich the diversity of data, fostering robustness to transformations and enhancing generalization performance of the student network. We use SOTA hierarchical supervision as a baseline and adapt its dual-threshold to TED, which is called channel IoU consistency. We evaluate our method with KITTI dataset, and achieved a significant performance leap, surpassing SOTA 3D semi-supervised object detection models.","sentences":["Accurate 3D object detection is crucial for autonomous vehicles and robots to navigate and interact with the environment safely and effectively.","Meanwhile, the performance of 3D detector relies on the data size and annotation which is expensive.","Consequently, the demand of training with limited labeled data is growing.","We explore a novel teacher-student framework employing channel augmentation for 3D semi-supervised object detection.","The teacher-student SSL typically adopts a weak augmentation and strong augmentation to teacher and student, respectively.","In this work, we apply multiple channel augmentations to both networks using the transformation equivariance detector (TED).","The TED allows us to explore different combinations of augmentation on point clouds and efficiently aggregates multi-channel transformation equivariance features.","In principle, by adopting fixed channel augmentations for the teacher network, the student can train stably on reliable pseudo-labels.","Adopting strong channel augmentations can enrich the diversity of data, fostering robustness to transformations and enhancing generalization performance of the student network.","We use SOTA hierarchical supervision as a baseline and adapt its dual-threshold to TED, which is called channel IoU consistency.","We evaluate our method with KITTI dataset, and achieved a significant performance leap, surpassing SOTA 3D semi-supervised object detection models."],"url":"http://arxiv.org/abs/2409.06583v1"}
{"created":"2024-09-10 15:19:40","title":"Quantifying and Enabling the Interpretability of CLIP-like Models","abstract":"CLIP is one of the most popular foundational models and is heavily used for many vision-language tasks. However, little is known about the inner workings of CLIP. To bridge this gap we propose a study to quantify the interpretability in CLIP like models. We conduct this study on six different CLIP models from OpenAI and OpenCLIP which vary by size, type of pre-training data and patch size. Our approach begins with using the TEXTSPAN algorithm and in-context learning to break down individual attention heads into specific properties. We then evaluate how easily these heads can be interpreted using new metrics which measure property consistency within heads and property disentanglement across heads. Our findings reveal that larger CLIP models are generally more interpretable than their smaller counterparts. To further assist users in understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a tool designed for interpretability analysis. CLIP-InterpreT offers five types of analyses: property-based nearest neighbor search, per-head topic segmentation, contrastive segmentation, per-head nearest neighbors of an image, and per-head nearest neighbors of text.","sentences":["CLIP is one of the most popular foundational models and is heavily used for many vision-language tasks.","However, little is known about the inner workings of CLIP.","To bridge this gap we propose a study to quantify the interpretability in CLIP like models.","We conduct this study on six different CLIP models from OpenAI and OpenCLIP which vary by size, type of pre-training data and patch size.","Our approach begins with using the TEXTSPAN algorithm and in-context learning to break down individual attention heads into specific properties.","We then evaluate how easily these heads can be interpreted using new metrics which measure property consistency within heads and property disentanglement across heads.","Our findings reveal that larger CLIP models are generally more interpretable than their smaller counterparts.","To further assist users in understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a tool designed for interpretability analysis.","CLIP-InterpreT offers five types of analyses: property-based nearest neighbor search, per-head topic segmentation, contrastive segmentation, per-head nearest neighbors of an image, and per-head nearest neighbors of text."],"url":"http://arxiv.org/abs/2409.06579v1"}
{"created":"2024-09-10 14:58:55","title":"Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement","abstract":"In this paper, our goal is to investigate to what degree multilingual pretrained language models capture cross-linguistically valid abstract linguistic representations. We take the approach of developing curated synthetic data on a large scale, with specific properties, and using them to study sentence representations built using pretrained language models. We use a new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to focus on a specific grammatical structural phenomenon -- subject-verb agreement across a variety of sentence structures -- in several languages. Finding a solution to this task requires a system detecting complex linguistic patterns and paradigms in text representations. Using a two-level architecture that solves the problem in two steps -- detect syntactic objects and their properties in individual sentences, and find patterns across an input sequence of sentences -- we show that despite having been trained on multilingual texts in a consistent manner, multilingual pretrained language models have language-specific differences, and syntactic structure is not shared, even across closely related languages.","sentences":["In this paper, our goal is to investigate to what degree multilingual pretrained language models capture cross-linguistically valid abstract linguistic representations.","We take the approach of developing curated synthetic data on a large scale, with specific properties, and using them to study sentence representations built using pretrained language models.","We use a new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to focus on a specific grammatical structural phenomenon -- subject-verb agreement across a variety of sentence structures -- in several languages.","Finding a solution to this task requires a system detecting complex linguistic patterns and paradigms in text representations.","Using a two-level architecture that solves the problem in two steps -- detect syntactic objects and their properties in individual sentences, and find patterns across an input sequence of sentences -- we show that despite having been trained on multilingual texts in a consistent manner, multilingual pretrained language models have language-specific differences, and syntactic structure is not shared, even across closely related languages."],"url":"http://arxiv.org/abs/2409.06567v1"}
{"created":"2024-09-10 14:56:51","title":"Advancing Android Privacy Assessments with Automation","abstract":"Android apps collecting data from users must comply with legal frameworks to ensure data protection. This requirement has become even more important since the implementation of the General Data Protection Regulation (GDPR) by the European Union in 2018. Moreover, with the proposed Cyber Resilience Act on the horizon, stakeholders will soon need to assess software against even more stringent security and privacy standards. Effective privacy assessments require collaboration among groups with diverse expertise to function effectively as a cohesive unit.   This paper motivates the need for an automated approach that enhances understanding of data protection in Android apps and improves communication between the various parties involved in privacy assessments. We propose the Assessor View, a tool designed to bridge the knowledge gap between these parties, facilitating more effective privacy assessments of Android applications.","sentences":["Android apps collecting data from users must comply with legal frameworks to ensure data protection.","This requirement has become even more important since the implementation of the General Data Protection Regulation (GDPR) by the European Union in 2018.","Moreover, with the proposed Cyber Resilience Act on the horizon, stakeholders will soon need to assess software against even more stringent security and privacy standards.","Effective privacy assessments require collaboration among groups with diverse expertise to function effectively as a cohesive unit.   ","This paper motivates the need for an automated approach that enhances understanding of data protection in Android apps and improves communication between the various parties involved in privacy assessments.","We propose the Assessor View, a tool designed to bridge the knowledge gap between these parties, facilitating more effective privacy assessments of Android applications."],"url":"http://arxiv.org/abs/2409.06564v1"}
{"created":"2024-09-10 14:37:43","title":"Adversary Resilient Learned Bloom Filters","abstract":"Creating an adversary resilient Learned Bloom Filter \\cite{learnedindexstructures} with provable guarantees is an open problem \\cite{reviriego1}. We define a strong adversarial model for the Learned Bloom Filter. We also construct two adversary resilient variants of the Learned Bloom Filter called the Uptown Bodega Filter and the Downtown Bodega Filter. Our adversarial model extends an existing adversarial model designed for the Classical (i.e not ``Learned'') Bloom Filter by Naor Yogev~\\cite{moni1} and considers computationally bounded adversaries that run in probabilistic polynomial time (PPT). We show that if pseudo-random permutations exist, then a secure Learned Bloom Filter may be constructed with $\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path. We further show that, if pseudo-random permutations exist, then a \\textit{high utility} Learned Bloom Filter may be constructed with $2\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path. Finally, we construct a hybrid adversarial model for the case where a fraction of the workload is chosen by an adversary. We show realistic scenarios where using the Downtown Bodega Filter gives better performance guarantees compared to alternative approaches in this hybrid model.","sentences":["Creating an adversary resilient Learned Bloom Filter \\cite{learnedindexstructures} with provable guarantees is an open problem \\cite{reviriego1}.","We define a strong adversarial model for the Learned Bloom Filter.","We also construct two adversary resilient variants of the Learned Bloom Filter called the Uptown Bodega Filter and the Downtown Bodega Filter.","Our adversarial model extends an existing adversarial model designed for the Classical (i.e not ``Learned'') Bloom Filter by Naor Yogev~\\cite{moni1} and considers computationally bounded adversaries that run in probabilistic polynomial time (PPT).","We show that if pseudo-random permutations exist, then a secure Learned Bloom Filter may be constructed with $\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path.","We further show that, if pseudo-random permutations exist, then a \\textit{high utility} Learned Bloom Filter may be constructed with $2\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path.","Finally, we construct a hybrid adversarial model for the case where a fraction of the workload is chosen by an adversary.","We show realistic scenarios where using the Downtown Bodega Filter gives better performance guarantees compared to alternative approaches in this hybrid model."],"url":"http://arxiv.org/abs/2409.06556v1"}
{"created":"2024-09-10 14:26:12","title":"From LIMA to DeepLIMA: following a new path of interoperability","abstract":"In this article, we describe the architecture of the LIMA (Libre Multilingual Analyzer) framework and its recent evolution with the addition of new text analysis modules based on deep neural networks. We extended the functionality of LIMA in terms of the number of supported languages while preserving existing configurable architecture and the availability of previously developed rule-based and statistical analysis components. Models were trained for more than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora, and CoNLL-03 dataset. Universal Dependencies allowed us to increase the number of supported languages and to generate models that could be integrated into other platforms. This integration of ubiquitous Deep Learning Natural Language Processing models and the use of standard annotated collections using Universal Dependencies can be viewed as a new path of interoperability, through the normalization of models and data, that are complementary to a more standard technical interoperability, implemented in LIMA through services available in Docker containers on Docker Hub.","sentences":["In this article, we describe the architecture of the LIMA (Libre Multilingual Analyzer) framework and its recent evolution with the addition of new text analysis modules based on deep neural networks.","We extended the functionality of LIMA in terms of the number of supported languages while preserving existing configurable architecture and the availability of previously developed rule-based and statistical analysis components.","Models were trained for more than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora, and CoNLL-03 dataset.","Universal Dependencies allowed us to increase the number of supported languages and to generate models that could be integrated into other platforms.","This integration of ubiquitous Deep Learning Natural Language Processing models and the use of standard annotated collections using Universal Dependencies can be viewed as a new path of interoperability, through the normalization of models and data, that are complementary to a more standard technical interoperability, implemented in LIMA through services available in Docker containers on Docker Hub."],"url":"http://arxiv.org/abs/2409.06550v1"}
{"created":"2024-09-10 13:56:54","title":"Deep Learning for Koopman Operator Estimation in Idealized Atmospheric Dynamics","abstract":"Deep learning is revolutionizing weather forecasting, with new data-driven models achieving accuracy on par with operational physical models for medium-term predictions. However, these models often lack interpretability, making their underlying dynamics difficult to understand and explain. This paper proposes methodologies to estimate the Koopman operator, providing a linear representation of complex nonlinear dynamics to enhance the transparency of data-driven models. Despite its potential, applying the Koopman operator to large-scale problems, such as atmospheric modeling, remains challenging. This study aims to identify the limitations of existing methods, refine these models to overcome various bottlenecks, and introduce novel convolutional neural network architectures that capture simplified dynamics.","sentences":["Deep learning is revolutionizing weather forecasting, with new data-driven models achieving accuracy on par with operational physical models for medium-term predictions.","However, these models often lack interpretability, making their underlying dynamics difficult to understand and explain.","This paper proposes methodologies to estimate the Koopman operator, providing a linear representation of complex nonlinear dynamics to enhance the transparency of data-driven models.","Despite its potential, applying the Koopman operator to large-scale problems, such as atmospheric modeling, remains challenging.","This study aims to identify the limitations of existing methods, refine these models to overcome various bottlenecks, and introduce novel convolutional neural network architectures that capture simplified dynamics."],"url":"http://arxiv.org/abs/2409.06522v1"}
{"created":"2024-09-10 13:40:37","title":"DroneXNFT: An NFT-Driven Framework for Secure Autonomous UAV Operations and Flight Data Management","abstract":"Non-Fungible Tokens (NFTs) have emerged as a revolutionary method for managing digital assets, providing transparency and secure ownership records on a blockchain. In this paper, we present a theoretical framework for leveraging NFTs to manage UAV (Unmanned Aerial Vehicle) flight data. Our approach focuses on ensuring data integrity, ownership transfer, and secure data sharing among stakeholders. This framework utilizes cryptographic methods, smart contracts, and access control mechanisms to enable a tamper-proof and privacy-preserving management system for UAV flight data.","sentences":["Non-Fungible Tokens (NFTs) have emerged as a revolutionary method for managing digital assets, providing transparency and secure ownership records on a blockchain.","In this paper, we present a theoretical framework for leveraging NFTs to manage UAV (Unmanned Aerial Vehicle) flight data.","Our approach focuses on ensuring data integrity, ownership transfer, and secure data sharing among stakeholders.","This framework utilizes cryptographic methods, smart contracts, and access control mechanisms to enable a tamper-proof and privacy-preserving management system for UAV flight data."],"url":"http://arxiv.org/abs/2409.06507v1"}
{"created":"2024-09-10 13:34:53","title":"A Novel Ternary Evolving Estimator for Positioning Unmanned Aerial Vehicle in Harsh Environments","abstract":"Obtaining reliable position estimation is fundamental for unmanned aerial vehicles during mission execution, especially in harsh environments. But environmental interference and abrupt changes usually degrade measurement reliability, leading to estimation divergence. To address this, existing works explore adaptive adjustment of sensor confidence. Unfortunately, existing methods typically lack synchronous evaluation of estimation precision, thereby rendering adjustments sensitive to abnormal data and susceptible to divergence. To tackle this issue, we propose a novel ternary-channel adaptive evolving estimator equipped with an online error monitor, where the ternary channels, states, noise covariance matrices and especially aerial drag, evolve simultaneously with environment. Firstly, an augmented filter is employed to pre-processes multidimensional data, followed by an inverse-Wishart smoother utilized to obtain posterior states and covariance matrices. Error propagation relation during estimation is analysed and hence an indicator is devised for online monitoring estimation errors. Under this premise, several restrictions are applied to suppress potential divergence led by interference. Additionally, considering motion dynamics, aerial drag matrix is reformulated based on updated states and covariance matrices. Finally, the observability, numerical sensitivity and arithmetic complexity of the proposed estimator are mathematically analyzed. Extensive experiments are conducted in both common and harsh environments (with average RMSE 0.17m and 0.39m respectively) to verify adaptability of algorithm and effectiveness of restriction design, which shows our method significantly outperforms the state-of-the-art.","sentences":["Obtaining reliable position estimation is fundamental for unmanned aerial vehicles during mission execution, especially in harsh environments.","But environmental interference and abrupt changes usually degrade measurement reliability, leading to estimation divergence.","To address this, existing works explore adaptive adjustment of sensor confidence.","Unfortunately, existing methods typically lack synchronous evaluation of estimation precision, thereby rendering adjustments sensitive to abnormal data and susceptible to divergence.","To tackle this issue, we propose a novel ternary-channel adaptive evolving estimator equipped with an online error monitor, where the ternary channels, states, noise covariance matrices and especially aerial drag, evolve simultaneously with environment.","Firstly, an augmented filter is employed to pre-processes multidimensional data, followed by an inverse-Wishart smoother utilized to obtain posterior states and covariance matrices.","Error propagation relation during estimation is analysed and hence an indicator is devised for online monitoring estimation errors.","Under this premise, several restrictions are applied to suppress potential divergence led by interference.","Additionally, considering motion dynamics, aerial drag matrix is reformulated based on updated states and covariance matrices.","Finally, the observability, numerical sensitivity and arithmetic complexity of the proposed estimator are mathematically analyzed.","Extensive experiments are conducted in both common and harsh environments (with average RMSE 0.17m and 0.39m respectively) to verify adaptability of algorithm and effectiveness of restriction design, which shows our method significantly outperforms the state-of-the-art."],"url":"http://arxiv.org/abs/2409.06501v1"}
{"created":"2024-09-10 13:15:32","title":"Coordinated Motion Planning: Multi-Agent Path Finding in a Densely Packed, Bounded Domain","abstract":"We study Multi-Agent Path Finding for arrangements of labeled agents in the interior of a simply connected domain: Given a unique start and target position for each agent, the goal is to find a sequence of parallel, collision-free agent motions that minimizes the overall time (the makespan) until all agents have reached their respective targets. A natural case is that of a simply connected polygonal domain with axis-parallel boundaries and integer coordinates, i.e., a simple polyomino, which amounts to a simply connected union of lattice unit squares or cells. We focus on the particularly challenging setting of densely packed agents, i.e., one per cell, which strongly restricts the mobility of agents, and requires intricate coordination of motion.   We provide a variety of novel results for this problem, including (1) a characterization of polyominoes in which a reconfiguration plan is guaranteed to exist; (2) a characterization of shape parameters that induce worst-case bounds on the makespan; (3) a suite of algorithms to achieve asymptotically worst-case optimal performance with respect to the achievable stretch for cases with severely limited maneuverability. This corresponds to bounding the ratio between obtained makespan and the lower bound provided by the max-min distance between the start and target position of any agent and our shape parameters.   Our results extend findings by Demaine et al. (SIAM Journal on Computing, 2019) who investigated the problem for solid rectangular domains, and in the closely related field of Permutation Routing, as presented by Alpert et al. (Computational Geometry, 2022) for convex pieces of grid graphs.","sentences":["We study Multi-Agent Path Finding for arrangements of labeled agents in the interior of a simply connected domain:","Given a unique start and target position for each agent, the goal is to find a sequence of parallel, collision-free agent motions that minimizes the overall time (the makespan) until all agents have reached their respective targets.","A natural case is that of a simply connected polygonal domain with axis-parallel boundaries and integer coordinates, i.e., a simple polyomino, which amounts to a simply connected union of lattice unit squares or cells.","We focus on the particularly challenging setting of densely packed agents, i.e., one per cell, which strongly restricts the mobility of agents, and requires intricate coordination of motion.   ","We provide a variety of novel results for this problem, including (1) a characterization of polyominoes in which a reconfiguration plan is guaranteed to exist; (2) a characterization of shape parameters that induce worst-case bounds on the makespan; (3) a suite of algorithms to achieve asymptotically worst-case optimal performance with respect to the achievable stretch for cases with severely limited maneuverability.","This corresponds to bounding the ratio between obtained makespan and the lower bound provided by the max-min distance between the start and target position of any agent and our shape parameters.   ","Our results extend findings by Demaine et al.","(SIAM Journal on Computing, 2019) who investigated the problem for solid rectangular domains, and in the closely related field of Permutation Routing, as presented by Alpert et al.","(Computational Geometry, 2022) for convex pieces of grid graphs."],"url":"http://arxiv.org/abs/2409.06486v1"}
{"created":"2024-09-10 13:04:13","title":"Advancing Hybrid Defense for Byzantine Attacks in Federated Learning","abstract":"Federated learning (FL) enables multiple clients to collaboratively train a global model without sharing their local data. Recent studies have highlighted the vulnerability of FL to Byzantine attacks, where malicious clients send poisoned updates to degrade model performance. Notably, many attacks have been developed targeting specific aggregation rules, whereas various defense mechanisms have been designed for dedicated threat models. This paper studies the resilience of an attack-agnostic FL scenario, where the server lacks prior knowledge of both the attackers' strategies and the number of malicious clients involved. We first introduce a hybrid defense against state-of-the-art attacks. Our goal is to identify a general-purpose aggregation rule that performs well on average while also avoiding worst-case vulnerabilities. By adaptively selecting from available defenses, we demonstrate that the server remains robust even when confronted with a substantial proportion of poisoned updates. To better understand this resilience, we then assess the attackers' capability using a proxy called client heterogeneity. We also emphasize that the existing FL defenses should not be regarded as secure, as demonstrated through the newly proposed Trapsetter attack. The proposed attack outperforms other state-of-the-art attacks by further reducing the model test accuracy by 8-10%. Our findings highlight the ongoing need for the development of Byzantine-resilient aggregation algorithms in FL.","sentences":["Federated learning (FL) enables multiple clients to collaboratively train a global model without sharing their local data.","Recent studies have highlighted the vulnerability of FL to Byzantine attacks, where malicious clients send poisoned updates to degrade model performance.","Notably, many attacks have been developed targeting specific aggregation rules, whereas various defense mechanisms have been designed for dedicated threat models.","This paper studies the resilience of an attack-agnostic FL scenario, where the server lacks prior knowledge of both the attackers' strategies and the number of malicious clients involved.","We first introduce a hybrid defense against state-of-the-art attacks.","Our goal is to identify a general-purpose aggregation rule that performs well on average while also avoiding worst-case vulnerabilities.","By adaptively selecting from available defenses, we demonstrate that the server remains robust even when confronted with a substantial proportion of poisoned updates.","To better understand this resilience, we then assess the attackers' capability using a proxy called client heterogeneity.","We also emphasize that the existing FL defenses should not be regarded as secure, as demonstrated through the newly proposed Trapsetter attack.","The proposed attack outperforms other state-of-the-art attacks by further reducing the model test accuracy by 8-10%.","Our findings highlight the ongoing need for the development of Byzantine-resilient aggregation algorithms in FL."],"url":"http://arxiv.org/abs/2409.06474v1"}
{"created":"2024-09-10 12:52:36","title":"An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition","abstract":"End-to-end (E2E) automatic speech recognition (ASR) models have become standard practice for various commercial applications. However, in real-world scenarios, the long-tailed nature of word distribution often leads E2E ASR models to perform well on common words but fall short in recognizing uncommon ones. Recently, the notion of a contextual adapter (CA) was proposed to infuse external knowledge represented by a context word list into E2E ASR models. Although CA can improve recognition performance on rare words, two crucial data imbalance problems remain. First, when using low-frequency words as context words during training, since these words rarely occur in the utterance, CA becomes prone to overfit on attending to the <no-context> token due to higher-frequency words not being present in the context list. Second, the long-tailed distribution within the context list itself still causes the model to perform poorly on low-frequency context words. In light of this, we explore in-depth the impact of altering the context list to have words with different frequency distributions on model performance, and meanwhile extend CA with a simple yet effective context-balanced learning objective. A series of experiments conducted on the AISHELL-1 benchmark dataset suggests that using all vocabulary words from the training corpus as the context list and pairing them with our balanced objective yields the best performance, demonstrating a significant reduction in character error rate (CER) by up to 1.21% and a more pronounced 9.44% reduction in the error rate of zero-shot words.","sentences":["End-to-end (E2E) automatic speech recognition (ASR) models have become standard practice for various commercial applications.","However, in real-world scenarios, the long-tailed nature of word distribution often leads E2E ASR models to perform well on common words but fall short in recognizing uncommon ones.","Recently, the notion of a contextual adapter (CA) was proposed to infuse external knowledge represented by a context word list into E2E ASR models.","Although CA can improve recognition performance on rare words, two crucial data imbalance problems remain.","First, when using low-frequency words as context words during training, since these words rarely occur in the utterance, CA becomes prone to overfit on attending to the <no-context> token due to higher-frequency words not being present in the context list.","Second, the long-tailed distribution within the context list itself still causes the model to perform poorly on low-frequency context words.","In light of this, we explore in-depth the impact of altering the context list to have words with different frequency distributions on model performance, and meanwhile extend CA with a simple yet effective context-balanced learning objective.","A series of experiments conducted on the AISHELL-1 benchmark dataset suggests that using all vocabulary words from the training corpus as the context list and pairing them with our balanced objective yields the best performance, demonstrating a significant reduction in character error rate (CER) by up to 1.21% and a more pronounced 9.44% reduction in the error rate of zero-shot words."],"url":"http://arxiv.org/abs/2409.06468v1"}
{"created":"2024-09-10 12:20:06","title":"Learning Multiple Secrets in Mastermind","abstract":"In the Generalized Mastermind problem, there is an unknown subset $H$ of the hypercube $\\{0,1\\}^d$ containing $n$ points. The goal is to learn $H$ by making a few queries to an oracle, which, given a point $q$ in $\\{0,1\\}^d$, returns the point in $H$ nearest to $q$. We give a two-round adaptive algorithm for this problem that learns $H$ while making at most $\\exp(\\tilde{O}(\\sqrt{d \\log n}))$ queries. Furthermore, we show that any $r$-round adaptive randomized algorithm that learns $H$ with constant probability must make $\\exp(\\Omega(d^{3^{-(r-1)}}))$ queries even when the input has $\\text{poly}(d)$ points; thus, any $\\text{poly}(d)$ query algorithm must necessarily use $\\Omega(\\log \\log d)$ rounds of adaptivity. We give optimal query complexity bounds for the variant of the problem where queries are allowed to be from $\\{0,1,2\\}^d$. We also study a continuous variant of the problem in which $H$ is a subset of unit vectors in $\\mathbb{R}^d$, and one can query unit vectors in $\\mathbb{R}^d$. For this setting, we give an $O(n^{d/2})$ query deterministic algorithm to learn the hidden set of points.","sentences":["In the Generalized Mastermind problem, there is an unknown subset $H$ of the hypercube $\\{0,1\\}^d$ containing $n$ points.","The goal is to learn $H$ by making a few queries to an oracle, which, given a point $q$ in $\\{0,1\\}^d$, returns the point in $H$ nearest to $q$. We give a two-round adaptive algorithm for this problem that learns $H$ while making at most $\\exp(\\tilde{O}(\\sqrt{d \\log n}))$ queries.","Furthermore, we show that any $r$-round adaptive randomized algorithm that learns $H$ with constant probability must make $\\exp(\\Omega(d^{3^{-(r-1)}}))$ queries even when the input has $\\text{poly}(d)$ points; thus, any $\\text{poly}(d)$ query algorithm must necessarily use $\\Omega(\\log \\log d)$ rounds of adaptivity.","We give optimal query complexity bounds for the variant of the problem where queries are allowed to be from $\\{0,1,2\\}^d$. We also study a continuous variant of the problem in which $H$ is a subset of unit vectors in $\\mathbb{R}^d$, and one can query unit vectors in $\\mathbb{R}^d$. For this setting, we give an $O(n^{d/2})$ query deterministic algorithm to learn the hidden set of points."],"url":"http://arxiv.org/abs/2409.06453v1"}
{"created":"2024-09-10 12:17:23","title":"Ransomware Detection Using Machine Learning in the Linux Kernel","abstract":"Linux-based cloud environments have become lucrative targets for ransomware attacks, employing various encryption schemes at unprecedented speeds. Addressing the urgency for real-time ransomware protection, we propose leveraging the extended Berkeley Packet Filter (eBPF) to collect system call information regarding active processes and infer about the data directly at the kernel level. In this study, we implement two Machine Learning (ML) models in eBPF - a decision tree and a multilayer perceptron. Benchmarking latency and accuracy against their user space counterparts, our findings underscore the efficacy of this approach.","sentences":["Linux-based cloud environments have become lucrative targets for ransomware attacks, employing various encryption schemes at unprecedented speeds.","Addressing the urgency for real-time ransomware protection, we propose leveraging the extended Berkeley Packet Filter (eBPF) to collect system call information regarding active processes and infer about the data directly at the kernel level.","In this study, we implement two Machine Learning (ML) models in eBPF - a decision tree and a multilayer perceptron.","Benchmarking latency and accuracy against their user space counterparts, our findings underscore the efficacy of this approach."],"url":"http://arxiv.org/abs/2409.06452v1"}
{"created":"2024-09-10 12:01:43","title":"HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data","abstract":"Large language models (LLMs) have shown great potential for automatic code generation and form the basis for various tools such as GitHub Copilot. However, recent studies highlight that many LLM-generated code contains serious security vulnerabilities. While previous work tries to address this by training models that generate secure code, these attempts remain constrained by limited access to training data and labor-intensive data preparation.   In this paper, we introduce HexaCoder, a novel approach to enhance the ability of LLMs to generate secure codes by automatically synthesizing secure codes, which reduces the effort of finding suitable training data. HexaCoder comprises two key components: an oracle-guided data synthesis pipeline and a two-step process for secure code generation. The data synthesis pipeline generates pairs of vulnerable and fixed codes for specific Common Weakness Enumeration (CWE) types by utilizing a state-of-the-art LLM for repairing vulnerable code. A security oracle identifies vulnerabilities, and a state-of-the-art LLM repairs them by extending and/or editing the codes, creating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA) method. Each example of our fine-tuning dataset includes the necessary security-related libraries and code that form the basis of our novel two-step generation approach. This allows the model to integrate security-relevant libraries before generating the main code, significantly reducing the number of generated vulnerable codes by up to 85% compared to the baseline methods. We perform extensive evaluations on three different benchmarks for four LLMs, demonstrating that HexaCoder not only improves the security of the generated code but also maintains a high level of functional correctness.","sentences":["Large language models (LLMs) have shown great potential for automatic code generation and form the basis for various tools such as GitHub Copilot.","However, recent studies highlight that many LLM-generated code contains serious security vulnerabilities.","While previous work tries to address this by training models that generate secure code, these attempts remain constrained by limited access to training data and labor-intensive data preparation.   ","In this paper, we introduce HexaCoder, a novel approach to enhance the ability of LLMs to generate secure codes by automatically synthesizing secure codes, which reduces the effort of finding suitable training data.","HexaCoder comprises two key components: an oracle-guided data synthesis pipeline and a two-step process for secure code generation.","The data synthesis pipeline generates pairs of vulnerable and fixed codes for specific Common Weakness Enumeration (CWE) types by utilizing a state-of-the-art LLM for repairing vulnerable code.","A security oracle identifies vulnerabilities, and a state-of-the-art LLM repairs them by extending and/or editing the codes, creating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA) method.","Each example of our fine-tuning dataset includes the necessary security-related libraries and code that form the basis of our novel two-step generation approach.","This allows the model to integrate security-relevant libraries before generating the main code, significantly reducing the number of generated vulnerable codes by up to 85% compared to the baseline methods.","We perform extensive evaluations on three different benchmarks for four LLMs, demonstrating that HexaCoder not only improves the security of the generated code but also maintains a high level of functional correctness."],"url":"http://arxiv.org/abs/2409.06446v1"}
{"created":"2024-09-10 12:00:40","title":"Learning Generative Interactive Environments By Trained Agent Exploration","abstract":"World models are increasingly pivotal in interpreting and simulating the rules and actions of complex environments. Genie, a recent model, excels at learning from visually diverse environments but relies on costly human-collected data. We observe that their alternative method of using random agents is too limited to explore the environment. We propose to improve the model by employing reinforcement learning based agents for data generation. This approach produces diverse datasets that enhance the model's ability to adapt and perform well across various scenarios and realistic actions within the environment. In this paper, we first release the model GenieRedux - an implementation based on Genie. Additionally, we introduce GenieRedux-G, a variant that uses the agent's readily available actions to factor out action prediction uncertainty during validation. Our evaluation, including a replication of the Coinrun case study, shows that GenieRedux-G achieves superior visual fidelity and controllability using the trained agent exploration. The proposed approach is reproducable, scalable and adaptable to new types of environments. Our codebase is available at https://github.com/insait-institute/GenieRedux .","sentences":["World models are increasingly pivotal in interpreting and simulating the rules and actions of complex environments.","Genie, a recent model, excels at learning from visually diverse environments but relies on costly human-collected data.","We observe that their alternative method of using random agents is too limited to explore the environment.","We propose to improve the model by employing reinforcement learning based agents for data generation.","This approach produces diverse datasets that enhance the model's ability to adapt and perform well across various scenarios and realistic actions within the environment.","In this paper, we first release the model GenieRedux - an implementation based on Genie.","Additionally, we introduce GenieRedux-G, a variant that uses the agent's readily available actions to factor out action prediction uncertainty during validation.","Our evaluation, including a replication of the Coinrun case study, shows that GenieRedux-G achieves superior visual fidelity and controllability using the trained agent exploration.","The proposed approach is reproducable, scalable and adaptable to new types of environments.","Our codebase is available at https://github.com/insait-institute/GenieRedux ."],"url":"http://arxiv.org/abs/2409.06445v1"}
{"created":"2024-09-10 11:31:02","title":"Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization","abstract":"The increasing amount of published scholarly articles, exceeding 2.5 million yearly, raises the challenge for researchers in following scientific progress. Integrating the contributions from scholarly articles into a novel type of cognitive knowledge graph (CKG) will be a crucial element for accessing and organizing scholarly knowledge, surpassing the insights provided by titles and abstracts. This research focuses on effectively conveying structured scholarly knowledge by utilizing large language models (LLMs) to categorize scholarly articles and describe their contributions in a structured and comparable manner. While previous studies explored language models within specific research domains, the extensive domain-independent knowledge captured by LLMs offers a substantial opportunity for generating structured contribution descriptions as CKGs. Additionally, LLMs offer customizable pathways through prompt engineering or fine-tuning, thus facilitating to leveraging of smaller LLMs known for their efficiency, cost-effectiveness, and environmental considerations. Our methodology involves harnessing LLM knowledge, and complementing it with domain expert-verified scholarly data sourced from a CKG. This strategic fusion significantly enhances LLM performance, especially in tasks like scholarly article categorization and predicate recommendation. Our method involves fine-tuning LLMs with CKG knowledge and additionally injecting knowledge from a CKG with a novel prompting technique significantly increasing the accuracy of scholarly knowledge extraction. We integrated our approach in the Open Research Knowledge Graph (ORKG), thus enabling precise access to organized scholarly knowledge, crucially benefiting domain-independent scholarly knowledge exchange and dissemination among policymakers, industrial practitioners, and the general public.","sentences":["The increasing amount of published scholarly articles, exceeding 2.5 million yearly, raises the challenge for researchers in following scientific progress.","Integrating the contributions from scholarly articles into a novel type of cognitive knowledge graph (CKG) will be a crucial element for accessing and organizing scholarly knowledge, surpassing the insights provided by titles and abstracts.","This research focuses on effectively conveying structured scholarly knowledge by utilizing large language models (LLMs) to categorize scholarly articles and describe their contributions in a structured and comparable manner.","While previous studies explored language models within specific research domains, the extensive domain-independent knowledge captured by LLMs offers a substantial opportunity for generating structured contribution descriptions as CKGs.","Additionally, LLMs offer customizable pathways through prompt engineering or fine-tuning, thus facilitating to leveraging of smaller LLMs known for their efficiency, cost-effectiveness, and environmental considerations.","Our methodology involves harnessing LLM knowledge, and complementing it with domain expert-verified scholarly data sourced from a CKG.","This strategic fusion significantly enhances LLM performance, especially in tasks like scholarly article categorization and predicate recommendation.","Our method involves fine-tuning LLMs with CKG knowledge and additionally injecting knowledge from a CKG with a novel prompting technique significantly increasing the accuracy of scholarly knowledge extraction.","We integrated our approach in the Open Research Knowledge Graph (ORKG), thus enabling precise access to organized scholarly knowledge, crucially benefiting domain-independent scholarly knowledge exchange and dissemination among policymakers, industrial practitioners, and the general public."],"url":"http://arxiv.org/abs/2409.06433v1"}
{"created":"2024-09-10 11:16:45","title":"Collecting Information Needs for Egocentric Visualizations while Running","abstract":"We investigate research challenges and opportunities for visualization in motion during outdoor physical activities via an initial corpus of real-world recordings that pair egocentric video, biometrics, and think-aloud observations. With the increasing use of tracking and recording devices, such as smartwatches and head-mounted displays, more and more data are available in real-time about a person's activity and the context of the activity. However, not all data will be relevant all the time. Instead, athletes have information needs that change throughout their activity depending on the context and their performance. To address this challenge, we describe the collection of a diverse corpus of information needs paired with contextualizing audio, video, and sensor data. Next, we propose a first set of research challenges and design considerations that explore the difficulties of visualizing those real data needs in-context and demonstrate a prototype tool for browsing, aggregating, and analyzing this information. Our ultimate goal is to understand and support embedding visualizations into outdoor contexts with changing environments and varying data needs.","sentences":["We investigate research challenges and opportunities for visualization in motion during outdoor physical activities via an initial corpus of real-world recordings that pair egocentric video, biometrics, and think-aloud observations.","With the increasing use of tracking and recording devices, such as smartwatches and head-mounted displays, more and more data are available in real-time about a person's activity and the context of the activity.","However, not all data will be relevant all the time.","Instead, athletes have information needs that change throughout their activity depending on the context and their performance.","To address this challenge, we describe the collection of a diverse corpus of information needs paired with contextualizing audio, video, and sensor data.","Next, we propose a first set of research challenges and design considerations that explore the difficulties of visualizing those real data needs in-context and demonstrate a prototype tool for browsing, aggregating, and analyzing this information.","Our ultimate goal is to understand and support embedding visualizations into outdoor contexts with changing environments and varying data needs."],"url":"http://arxiv.org/abs/2409.06426v1"}
{"created":"2024-09-10 11:07:01","title":"Position Fair Mechanisms Allocating Indivisible Goods","abstract":"In the fair division problem for indivisible goods, mechanisms that output allocations satisfying fairness concepts, such as envy-freeness up to one good (EF1), have been extensively studied. These mechanisms usually require an arbitrary order of agents as input, which may cause some agents to feel unfair since the order affects the output allocations. In the context of the cake-cutting problem, Manabe and Okamoto (2012) introduced meta-envy-freeness to capture such kind of fairness, which guarantees the absence of envy compared to different orders of agents.   In this paper, we introduce position envy-freeness and its relaxation, position envy-freeness up to $k$ goods (PEF$k$), for mechanisms in the fair division problem for indivisible goods, analogous to the meta-envy-freeness. While the round-robin or the envy-cycle mechanism is not PEF1, we propose a PEF1 mechanism that always outputs an EF1 allocation. In addition, in the case of two agents, we prove that any mechanism that always returns a maximum Nash social welfare allocation is PEF1, and propose a modified adjusted winner mechanism satisfying PEF1. We further investigate the round-robin and the envy-cycle mechanisms to measure how far they are from position envy-freeness.","sentences":["In the fair division problem for indivisible goods, mechanisms that output allocations satisfying fairness concepts, such as envy-freeness up to one good (EF1), have been extensively studied.","These mechanisms usually require an arbitrary order of agents as input, which may cause some agents to feel unfair since the order affects the output allocations.","In the context of the cake-cutting problem, Manabe and Okamoto (2012) introduced meta-envy-freeness to capture such kind of fairness, which guarantees the absence of envy compared to different orders of agents.   ","In this paper, we introduce position envy-freeness and its relaxation, position envy-freeness up to $k$ goods (PEF$k$), for mechanisms in the fair division problem for indivisible goods, analogous to the meta-envy-freeness.","While the round-robin or the envy-cycle mechanism is not PEF1, we propose a PEF1 mechanism that always outputs an EF1 allocation.","In addition, in the case of two agents, we prove that any mechanism that always returns a maximum Nash social welfare allocation is PEF1, and propose a modified adjusted winner mechanism satisfying PEF1.","We further investigate the round-robin and the envy-cycle mechanisms to measure how far they are from position envy-freeness."],"url":"http://arxiv.org/abs/2409.06423v1"}
{"created":"2024-09-10 11:04:14","title":"A Pervasive, Efficient and Private Future: Realizing Privacy-Preserving Machine Learning Through Hybrid Homomorphic Encryption","abstract":"Machine Learning (ML) has become one of the most impactful fields of data science in recent years. However, a significant concern with ML is its privacy risks due to rising attacks against ML models. Privacy-Preserving Machine Learning (PPML) methods have been proposed to mitigate the privacy and security risks of ML models. A popular approach to achieving PPML uses Homomorphic Encryption (HE). However, the highly publicized inefficiencies of HE make it unsuitable for highly scalable scenarios with resource-constrained devices. Hence, Hybrid Homomorphic Encryption (HHE) -- a modern encryption scheme that combines symmetric cryptography with HE -- has recently been introduced to overcome these challenges. HHE potentially provides a foundation to build new efficient and privacy-preserving services that transfer expensive HE operations to the cloud. This work introduces HHE to the ML field by proposing resource-friendly PPML protocols for edge devices. More precisely, we utilize HHE as the primary building block of our PPML protocols. We assess the performance of our protocols by first extensively evaluating each party's communication and computational cost on a dummy dataset and show the efficiency of our protocols by comparing them with similar protocols implemented using plain BFV. Subsequently, we demonstrate the real-world applicability of our construction by building an actual PPML application that uses HHE as its foundation to classify heart disease based on sensitive ECG data.","sentences":["Machine Learning (ML) has become one of the most impactful fields of data science in recent years.","However, a significant concern with ML is its privacy risks due to rising attacks against ML models.","Privacy-Preserving Machine Learning (PPML) methods have been proposed to mitigate the privacy and security risks of ML models.","A popular approach to achieving PPML uses Homomorphic Encryption (HE).","However, the highly publicized inefficiencies of HE make it unsuitable for highly scalable scenarios with resource-constrained devices.","Hence, Hybrid Homomorphic Encryption (HHE) -- a modern encryption scheme that combines symmetric cryptography with HE -- has recently been introduced to overcome these challenges.","HHE potentially provides a foundation to build new efficient and privacy-preserving services that transfer expensive HE operations to the cloud.","This work introduces HHE to the ML field by proposing resource-friendly PPML protocols for edge devices.","More precisely, we utilize HHE as the primary building block of our PPML protocols.","We assess the performance of our protocols by first extensively evaluating each party's communication and computational cost on a dummy dataset and show the efficiency of our protocols by comparing them with similar protocols implemented using plain BFV.","Subsequently, we demonstrate the real-world applicability of our construction by building an actual PPML application that uses HHE as its foundation to classify heart disease based on sensitive ECG data."],"url":"http://arxiv.org/abs/2409.06422v1"}
{"created":"2024-09-10 10:49:38","title":"Length Desensitization in Directed Preference Optimization","abstract":"Direct Preference Optimization (DPO) is widely utilized in the Reinforcement Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs) with human preferences, thereby enhancing both their harmlessness and efficacy. However, it has been observed that DPO tends to over-optimize for verbosity, which can detrimentally affect both performance and user experience. In this paper, we conduct an in-depth theoretical analysis of DPO's optimization objective and reveal a strong correlation between its implicit reward and data length. This correlation misguides the optimization direction, resulting in length sensitivity during the DPO training and leading to verbosity. To address this issue, we propose a length-desensitization improvement method for DPO, termed LD-DPO. The proposed method aims to desensitize DPO to data length by decoupling explicit length preference, which is relatively insignificant, from the other implicit preferences, thereby enabling more effective learning of the intrinsic preferences. We utilized two settings (Base and Instruct) of Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various benchmarks including MT-Bench and AlpacaEval 2. The experimental results indicate that LD-DPO consistently outperforms DPO and other baseline methods, achieving more concise responses with a 10-40\\% reduction in length compared to DPO. We conducted in-depth experimental analyses to demonstrate that LD-DPO can indeed achieve length desensitization and align the model more closely with human-real preferences.","sentences":["Direct Preference Optimization (DPO) is widely utilized in the Reinforcement Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs) with human preferences, thereby enhancing both their harmlessness and efficacy.","However, it has been observed that DPO tends to over-optimize for verbosity, which can detrimentally affect both performance and user experience.","In this paper, we conduct an in-depth theoretical analysis of DPO's optimization objective and reveal a strong correlation between its implicit reward and data length.","This correlation misguides the optimization direction, resulting in length sensitivity during the DPO training and leading to verbosity.","To address this issue, we propose a length-desensitization improvement method for DPO, termed LD-DPO.","The proposed method aims to desensitize DPO to data length by decoupling explicit length preference, which is relatively insignificant, from the other implicit preferences, thereby enabling more effective learning of the intrinsic preferences.","We utilized two settings (Base and Instruct) of Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various benchmarks including MT-Bench and AlpacaEval 2.","The experimental results indicate that LD-DPO consistently outperforms DPO and other baseline methods, achieving more concise responses with a 10-40\\% reduction in length compared to DPO.","We conducted in-depth experimental analyses to demonstrate that LD-DPO can indeed achieve length desensitization and align the model more closely with human-real preferences."],"url":"http://arxiv.org/abs/2409.06411v1"}
{"created":"2024-09-10 10:35:29","title":"Reflections on Visualization in Motion for Fitness Trackers","abstract":"In this paper, we reflect on our past work towards understanding how to design visualizations for fitness trackers that are used in motion. We have coined the term \"visualization in motion\" for visualizations that are used in the presence of relative motion between a viewer and the visualization. Here, we describe how visualization in motion is relevant to sports scenarios. We also provide new data on current smartwatch visualizations for sports and discuss future challenges for visualizations in motion for fitness tracker.","sentences":["In this paper, we reflect on our past work towards understanding how to design visualizations for fitness trackers that are used in motion.","We have coined the term \"visualization in motion\" for visualizations that are used in the presence of relative motion between a viewer and the visualization.","Here, we describe how visualization in motion is relevant to sports scenarios.","We also provide new data on current smartwatch visualizations for sports and discuss future challenges for visualizations in motion for fitness tracker."],"url":"http://arxiv.org/abs/2409.06401v1"}
{"created":"2024-09-10 09:56:15","title":"SpeechTaxi: On Multilingual Semantic Speech Classification","abstract":"Recent advancements in multilingual speech encoding as well as transcription raise the question of the most effective approach to semantic speech classification. Concretely, can (1) end-to-end (E2E) classifiers obtained by fine-tuning state-of-the-art multilingual speech encoders (MSEs) match or surpass the performance of (2) cascading (CA), where speech is first transcribed into text and classification is delegated to a text-based classifier. To answer this, we first construct SpeechTaxi, an 80-hour multilingual dataset for semantic speech classification of Bible verses, covering 28 diverse languages. We then leverage SpeechTaxi to conduct a wide range of experiments comparing E2E and CA in monolingual semantic speech classification as well as in cross-lingual transfer. We find that E2E based on MSEs outperforms CA in monolingual setups, i.e., when trained on in-language data. However, MSEs seem to have poor cross-lingual transfer abilities, with E2E substantially lagging CA both in (1) zero-shot transfer to languages unseen in training and (2) multilingual training, i.e., joint training on multiple languages. Finally, we devise a novel CA approach based on transcription to Romanized text as a language-agnostic intermediate representation and show that it represents a robust solution for languages without native ASR support. Our SpeechTaxi dataset is publicly available at: https://huggingface.co/ datasets/LennartKeller/SpeechTaxi/.","sentences":["Recent advancements in multilingual speech encoding as well as transcription raise the question of the most effective approach to semantic speech classification.","Concretely, can (1) end-to-end (E2E) classifiers obtained by fine-tuning state-of-the-art multilingual speech encoders (MSEs) match or surpass the performance of (2) cascading (CA), where speech is first transcribed into text and classification is delegated to a text-based classifier.","To answer this, we first construct SpeechTaxi, an 80-hour multilingual dataset for semantic speech classification of Bible verses, covering 28 diverse languages.","We then leverage SpeechTaxi to conduct a wide range of experiments comparing E2E and CA in monolingual semantic speech classification as well as in cross-lingual transfer.","We find that E2E based on MSEs outperforms CA in monolingual setups, i.e., when trained on in-language data.","However, MSEs seem to have poor cross-lingual transfer abilities, with E2E substantially lagging CA both in (1) zero-shot transfer to languages unseen in training and (2) multilingual training, i.e., joint training on multiple languages.","Finally, we devise a novel CA approach based on transcription to Romanized text as a language-agnostic intermediate representation and show that it represents a robust solution for languages without native ASR support.","Our SpeechTaxi dataset is publicly available at: https://huggingface.co/ datasets/LennartKeller/SpeechTaxi/."],"url":"http://arxiv.org/abs/2409.06372v1"}
{"created":"2024-09-10 09:44:38","title":"Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development","abstract":"Anomaly detection is a crucial process in industrial manufacturing and has made significant advancements recently. However, there is a large variance between the data used in the development and the data collected by the production environment. Therefore, we present the Texture-AD benchmark based on representative texture-based anomaly detection to evaluate the effectiveness of unsupervised anomaly detection algorithms in real-world applications. This dataset includes images of 15 different cloth, 14 semiconductor wafers and 10 metal plates acquired under different optical schemes. In addition, it includes more than 10 different types of defects produced during real manufacturing processes, such as scratches, wrinkles, color variations and point defects, which are often more difficult to detect than existing datasets. All anomalous areas are provided with pixel-level annotations to facilitate comprehensive evaluation using anomaly detection models. Specifically, to adapt to diverse products in automated pipelines, we present a new evaluation method and results of baseline algorithms. The experimental results show that Texture-AD is a difficult challenge for state-of-the-art algorithms. To our knowledge, Texture-AD is the first dataset to be devoted to evaluating industrial defect detection algorithms in the real world. The dataset is available at https://XXX.","sentences":["Anomaly detection is a crucial process in industrial manufacturing and has made significant advancements recently.","However, there is a large variance between the data used in the development and the data collected by the production environment.","Therefore, we present the Texture-AD benchmark based on representative texture-based anomaly detection to evaluate the effectiveness of unsupervised anomaly detection algorithms in real-world applications.","This dataset includes images of 15 different cloth, 14 semiconductor wafers and 10 metal plates acquired under different optical schemes.","In addition, it includes more than 10 different types of defects produced during real manufacturing processes, such as scratches, wrinkles, color variations and point defects, which are often more difficult to detect than existing datasets.","All anomalous areas are provided with pixel-level annotations to facilitate comprehensive evaluation using anomaly detection models.","Specifically, to adapt to diverse products in automated pipelines, we present a new evaluation method and results of baseline algorithms.","The experimental results show that Texture-AD is a difficult challenge for state-of-the-art algorithms.","To our knowledge, Texture-AD is the first dataset to be devoted to evaluating industrial defect detection algorithms in the real world.","The dataset is available at https://XXX."],"url":"http://arxiv.org/abs/2409.06367v1"}
{"created":"2024-09-10 09:42:58","title":"What happens to diffusion model likelihood when your model is conditional?","abstract":"Diffusion Models (DMs) iteratively denoise random samples to produce high-quality data. The iterative sampling process is derived from Stochastic Differential Equations (SDEs), allowing a speed-quality trade-off chosen at inference. Another advantage of sampling with differential equations is exact likelihood computation. These likelihoods have been used to rank unconditional DMs and for out-of-domain classification. Despite the many existing and possible uses of DM likelihoods, the distinct properties captured are unknown, especially in conditional contexts such as Text-To-Image (TTI) or Text-To-Speech synthesis (TTS). Surprisingly, we find that TTS DM likelihoods are agnostic to the text input. TTI likelihood is more expressive but cannot discern confounding prompts. Our results show that applying DMs to conditional tasks reveals inconsistencies and strengthens claims that the properties of DM likelihood are unknown. This impact sheds light on the previously unknown nature of DM likelihoods. Although conditional DMs maximise likelihood, the likelihood in question is not as sensitive to the conditioning input as one expects. This investigation provides a new point-of-view on diffusion likelihoods.","sentences":["Diffusion Models (DMs) iteratively denoise random samples to produce high-quality data.","The iterative sampling process is derived from Stochastic Differential Equations (SDEs), allowing a speed-quality trade-off chosen at inference.","Another advantage of sampling with differential equations is exact likelihood computation.","These likelihoods have been used to rank unconditional DMs and for out-of-domain classification.","Despite the many existing and possible uses of DM likelihoods, the distinct properties captured are unknown, especially in conditional contexts such as Text-To-Image (TTI) or Text-To-Speech synthesis (TTS).","Surprisingly, we find that TTS DM likelihoods are agnostic to the text input.","TTI likelihood is more expressive but cannot discern confounding prompts.","Our results show that applying DMs to conditional tasks reveals inconsistencies and strengthens claims that the properties of DM likelihood are unknown.","This impact sheds light on the previously unknown nature of DM likelihoods.","Although conditional DMs maximise likelihood, the likelihood in question is not as sensitive to the conditioning input as one expects.","This investigation provides a new point-of-view on diffusion likelihoods."],"url":"http://arxiv.org/abs/2409.06364v1"}
{"created":"2024-09-10 09:32:16","title":"Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks","abstract":"Understanding how neural networks align with human cognitive processes is a crucial step toward developing more interpretable and reliable AI systems. Motivated by theories of human cognition, this study examines the relationship between \\emph{convexity} in neural network representations and \\emph{human-machine alignment} based on behavioral data. We identify a correlation between these two dimensions in pretrained and fine-tuned vision transformer models. Our findings suggest that the convex regions formed in latent spaces of neural networks to some extent align with human-defined categories and reflect the similarity relations humans use in cognitive tasks. While optimizing for alignment generally enhances convexity, increasing convexity through fine-tuning yields inconsistent effects on alignment, which suggests a complex relationship between the two. This study presents a first step toward understanding the relationship between the convexity of latent representations and human-machine alignment.","sentences":["Understanding how neural networks align with human cognitive processes is a crucial step toward developing more interpretable and reliable AI systems.","Motivated by theories of human cognition, this study examines the relationship between \\emph{convexity} in neural network representations and \\emph{human-machine alignment} based on behavioral data.","We identify a correlation between these two dimensions in pretrained and fine-tuned vision transformer models.","Our findings suggest that the convex regions formed in latent spaces of neural networks to some extent align with human-defined categories and reflect the similarity relations humans use in cognitive tasks.","While optimizing for alignment generally enhances convexity, increasing convexity through fine-tuning yields inconsistent effects on alignment, which suggests a complex relationship between the two.","This study presents a first step toward understanding the relationship between the convexity of latent representations and human-machine alignment."],"url":"http://arxiv.org/abs/2409.06362v1"}
{"created":"2024-09-10 09:10:30","title":"MAGDA: Multi-agent guideline-driven diagnostic assistance","abstract":"In emergency departments, rural hospitals, or clinics in less developed regions, clinicians often lack fast image analysis by trained radiologists, which can have a detrimental effect on patients' healthcare. Large Language Models (LLMs) have the potential to alleviate some pressure from these clinicians by providing insights that can help them in their decision-making. While these LLMs achieve high test results on medical exams showcasing their great theoretical medical knowledge, they tend not to follow medical guidelines. In this work, we introduce a new approach for zero-shot guideline-driven decision support. We model a system of multiple LLM agents augmented with a contrastive vision-language model that collaborate to reach a patient diagnosis. After providing the agents with simple diagnostic guidelines, they will synthesize prompts and screen the image for findings following these guidelines. Finally, they provide understandable chain-of-thought reasoning for their diagnosis, which is then self-refined to consider inter-dependencies between diseases. As our method is zero-shot, it is adaptable to settings with rare diseases, where training data is limited, but expert-crafted disease descriptions are available. We evaluate our method on two chest X-ray datasets, CheXpert and ChestX-ray 14 Longtail, showcasing performance improvement over existing zero-shot methods and generalizability to rare diseases.","sentences":["In emergency departments, rural hospitals, or clinics in less developed regions, clinicians often lack fast image analysis by trained radiologists, which can have a detrimental effect on patients' healthcare.","Large Language Models (LLMs) have the potential to alleviate some pressure from these clinicians by providing insights that can help them in their decision-making.","While these LLMs achieve high test results on medical exams showcasing their great theoretical medical knowledge, they tend not to follow medical guidelines.","In this work, we introduce a new approach for zero-shot guideline-driven decision support.","We model a system of multiple LLM agents augmented with a contrastive vision-language model that collaborate to reach a patient diagnosis.","After providing the agents with simple diagnostic guidelines, they will synthesize prompts and screen the image for findings following these guidelines.","Finally, they provide understandable chain-of-thought reasoning for their diagnosis, which is then self-refined to consider inter-dependencies between diseases.","As our method is zero-shot, it is adaptable to settings with rare diseases, where training data is limited, but expert-crafted disease descriptions are available.","We evaluate our method on two chest X-ray datasets, CheXpert and ChestX-ray 14 Longtail, showcasing performance improvement over existing zero-shot methods and generalizability to rare diseases."],"url":"http://arxiv.org/abs/2409.06351v1"}
{"created":"2024-09-10 09:07:47","title":"Improving Conditional Level Generation using Automated Validation in Match-3 Games","abstract":"Generative models for level generation have shown great potential in game production. However, they often provide limited control over the generation, and the validity of the generated levels is unreliable. Despite this fact, only a few approaches that learn from existing data provide the users with ways of controlling the generation, simultaneously addressing the generation of unsolvable levels. %One of the main challenges it faces is that levels generated through automation may not be solvable thus requiring validation. are not always engaging, challenging, or even solvable. This paper proposes Avalon, a novel method to improve models that learn from existing level designs using difficulty statistics extracted from gameplay. In particular, we use a conditional variational autoencoder to generate layouts for match-3 levels, conditioning the model on pre-collected statistics such as game mechanics like difficulty and relevant visual features like size and symmetry. Our method is general enough that multiple approaches could potentially be used to generate these statistics. We quantitatively evaluate our approach by comparing it to an ablated model without difficulty conditioning. Additionally, we analyze both quantitatively and qualitatively whether the style of the dataset is preserved in the generated levels. Our approach generates more valid levels than the same method without difficulty conditioning.","sentences":["Generative models for level generation have shown great potential in game production.","However, they often provide limited control over the generation, and the validity of the generated levels is unreliable.","Despite this fact, only a few approaches that learn from existing data provide the users with ways of controlling the generation, simultaneously addressing the generation of unsolvable levels.","%One of the main challenges it faces is that levels generated through automation may not be solvable thus requiring validation.","are not always engaging, challenging, or even solvable.","This paper proposes Avalon, a novel method to improve models that learn from existing level designs using difficulty statistics extracted from gameplay.","In particular, we use a conditional variational autoencoder to generate layouts for match-3 levels, conditioning the model on pre-collected statistics such as game mechanics like difficulty and relevant visual features like size and symmetry.","Our method is general enough that multiple approaches could potentially be used to generate these statistics.","We quantitatively evaluate our approach by comparing it to an ablated model without difficulty conditioning.","Additionally, we analyze both quantitatively and qualitatively whether the style of the dataset is preserved in the generated levels.","Our approach generates more valid levels than the same method without difficulty conditioning."],"url":"http://arxiv.org/abs/2409.06349v1"}
{"created":"2024-09-10 09:07:12","title":"VoiceWukong: Benchmarking Deepfake Voice Detection","abstract":"With the rapid advancement of technologies like text-to-speech (TTS) and voice conversion (VC), detecting deepfake voices has become increasingly crucial. However, both academia and industry lack a comprehensive and intuitive benchmark for evaluating detectors. Existing datasets are limited in language diversity and lack many manipulations encountered in real-world production environments.   To fill this gap, we propose VoiceWukong, a benchmark designed to evaluate the performance of deepfake voice detectors. To build the dataset, we first collected deepfake voices generated by 19 advanced and widely recognized commercial tools and 15 open-source tools. We then created 38 data variants covering six types of manipulations, constructing the evaluation dataset for deepfake voice detection. VoiceWukong thus includes 265,200 English and 148,200 Chinese deepfake voice samples. Using VoiceWukong, we evaluated 12 state-of-the-art detectors. AASIST2 achieved the best equal error rate (EER) of 13.50%, while all others exceeded 20%. Our findings reveal that these detectors face significant challenges in real-world applications, with dramatically declining performance. In addition, we conducted a user study with more than 300 participants. The results are compared with the performance of the 12 detectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio, where different detectors and humans exhibit varying identification capabilities for deepfake voices at different deception levels, while the LALM demonstrates no detection ability at all. Furthermore, we provide a leaderboard for deepfake voice detection, publicly available at {https://voicewukong.github.io}.","sentences":["With the rapid advancement of technologies like text-to-speech (TTS) and voice conversion (VC), detecting deepfake voices has become increasingly crucial.","However, both academia and industry lack a comprehensive and intuitive benchmark for evaluating detectors.","Existing datasets are limited in language diversity and lack many manipulations encountered in real-world production environments.   ","To fill this gap, we propose VoiceWukong, a benchmark designed to evaluate the performance of deepfake voice detectors.","To build the dataset, we first collected deepfake voices generated by 19 advanced and widely recognized commercial tools and 15 open-source tools.","We then created 38 data variants covering six types of manipulations, constructing the evaluation dataset for deepfake voice detection.","VoiceWukong thus includes 265,200 English and 148,200 Chinese deepfake voice samples.","Using VoiceWukong, we evaluated 12 state-of-the-art detectors.","AASIST2 achieved the best equal error rate (EER) of 13.50%, while all others exceeded 20%.","Our findings reveal that these detectors face significant challenges in real-world applications, with dramatically declining performance.","In addition, we conducted a user study with more than 300 participants.","The results are compared with the performance of the 12 detectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio, where different detectors and humans exhibit varying identification capabilities for deepfake voices at different deception levels, while the LALM demonstrates no detection ability at all.","Furthermore, we provide a leaderboard for deepfake voice detection, publicly available at {https://voicewukong.github.io}."],"url":"http://arxiv.org/abs/2409.06348v1"}
{"created":"2024-09-10 08:52:24","title":"Compute-Update Federated Learning: A Lattice Coding Approach","abstract":"This paper introduces a federated learning framework that enables over-the-air computation via digital communications, using a new joint source-channel coding scheme. Without relying on channel state information at devices, this scheme employs lattice codes to both quantize model parameters and exploit interference from the devices. We propose a novel receiver structure at the server, designed to reliably decode an integer combination of the quantized model parameters as a lattice point for the purpose of aggregation. We present a mathematical approach to derive a convergence bound for the proposed scheme and offer design remarks. In this context, we suggest an aggregation metric and a corresponding algorithm to determine effective integer coefficients for the aggregation in each communication round. Our results illustrate that, regardless of channel dynamics and data heterogeneity, our scheme consistently delivers superior learning accuracy across various parameters and markedly surpasses other over-the-air methodologies.","sentences":["This paper introduces a federated learning framework that enables over-the-air computation via digital communications, using a new joint source-channel coding scheme.","Without relying on channel state information at devices, this scheme employs lattice codes to both quantize model parameters and exploit interference from the devices.","We propose a novel receiver structure at the server, designed to reliably decode an integer combination of the quantized model parameters as a lattice point for the purpose of aggregation.","We present a mathematical approach to derive a convergence bound for the proposed scheme and offer design remarks.","In this context, we suggest an aggregation metric and a corresponding algorithm to determine effective integer coefficients for the aggregation in each communication round.","Our results illustrate that, regardless of channel dynamics and data heterogeneity, our scheme consistently delivers superior learning accuracy across various parameters and markedly surpasses other over-the-air methodologies."],"url":"http://arxiv.org/abs/2409.06343v1"}
{"created":"2024-09-10 08:27:19","title":"G3PT: Unleash the power of Autoregressive Modeling in 3D Generation via Cross-scale Querying Transformer","abstract":"Autoregressive transformers have revolutionized generative models in language processing and shown substantial promise in image and video generation. However, these models face significant challenges when extended to 3D generation tasks due to their reliance on next-token prediction to learn token sequences, which is incompatible with the unordered nature of 3D data. Instead of imposing an artificial order on 3D data, in this paper, we introduce G3PT, a scalable coarse-to-fine 3D generative model utilizing a cross-scale querying transformer. The key is to map point-based 3D data into discrete tokens with different levels of detail, naturally establishing a sequential relationship between different levels suitable for autoregressive modeling. Additionally, the cross-scale querying transformer connects tokens globally across different levels of detail without requiring an ordered sequence. Benefiting from this approach, G3PT features a versatile 3D generation pipeline that effortlessly supports diverse conditional structures, enabling the generation of 3D shapes from various types of conditions. Extensive experiments demonstrate that G3PT achieves superior generation quality and generalization ability compared to previous 3D generation methods. Most importantly, for the first time in 3D generation, scaling up G3PT reveals distinct power-law scaling behaviors.","sentences":["Autoregressive transformers have revolutionized generative models in language processing and shown substantial promise in image and video generation.","However, these models face significant challenges when extended to 3D generation tasks due to their reliance on next-token prediction to learn token sequences, which is incompatible with the unordered nature of 3D data.","Instead of imposing an artificial order on 3D data, in this paper, we introduce G3PT, a scalable coarse-to-fine 3D generative model utilizing a cross-scale querying transformer.","The key is to map point-based 3D data into discrete tokens with different levels of detail, naturally establishing a sequential relationship between different levels suitable for autoregressive modeling.","Additionally, the cross-scale querying transformer connects tokens globally across different levels of detail without requiring an ordered sequence.","Benefiting from this approach, G3PT features a versatile 3D generation pipeline that effortlessly supports diverse conditional structures, enabling the generation of 3D shapes from various types of conditions.","Extensive experiments demonstrate that G3PT achieves superior generation quality and generalization ability compared to previous 3D generation methods.","Most importantly, for the first time in 3D generation, scaling up G3PT reveals distinct power-law scaling behaviors."],"url":"http://arxiv.org/abs/2409.06322v1"}
{"created":"2024-09-10 08:22:01","title":"Rate-Constrained Quantization for Communication-Efficient Federated Learning","abstract":"Quantization is a common approach to mitigate the communication cost of federated learning (FL). In practice, the quantized local parameters are further encoded via an entropy coding technique, such as Huffman coding, for efficient data compression. In this case, the exact communication overhead is determined by the bit rate of the encoded gradients. Recognizing this fact, this work deviates from the existing approaches in the literature and develops a novel quantized FL framework, called \\textbf{r}ate-\\textbf{c}onstrained \\textbf{fed}erated learning (RC-FED), in which the gradients are quantized subject to both fidelity and data rate constraints. We formulate this scheme, as a joint optimization in which the quantization distortion is minimized while the rate of encoded gradients is kept below a target threshold. This enables for a tunable trade-off between quantization distortion and communication cost. We analyze the convergence behavior of RC-FED, and show its superior performance against baseline quantized FL schemes on several datasets.","sentences":["Quantization is a common approach to mitigate the communication cost of federated learning (FL).","In practice, the quantized local parameters are further encoded via an entropy coding technique, such as Huffman coding, for efficient data compression.","In this case, the exact communication overhead is determined by the bit rate of the encoded gradients.","Recognizing this fact, this work deviates from the existing approaches in the literature and develops a novel quantized FL framework, called \\textbf{r}ate-\\textbf{c}onstrained \\textbf{fed}erated learning (RC-FED), in which the gradients are quantized subject to both fidelity and data rate constraints.","We formulate this scheme, as a joint optimization in which the quantization distortion is minimized while the rate of encoded gradients is kept below a target threshold.","This enables for a tunable trade-off between quantization distortion and communication cost.","We analyze the convergence behavior of RC-FED, and show its superior performance against baseline quantized FL schemes on several datasets."],"url":"http://arxiv.org/abs/2409.06319v1"}
{"created":"2024-09-10 08:17:06","title":"PharmacoMatch: Efficient 3D Pharmacophore Screening through Neural Subgraph Matching","abstract":"The increasing size of screening libraries poses a significant challenge for the development of virtual screening methods for drug discovery, necessitating a re-evaluation of traditional approaches in the era of big data. Although 3D pharmacophore screening remains a prevalent technique, its application to very large datasets is limited by the computational cost associated with matching query pharmacophores to database ligands. In this study, we introduce PharmacoMatch, a novel contrastive learning approach based on neural subgraph matching. Our method reinterprets pharmacophore screening as an approximate subgraph matching problem and enables efficient querying of conformational databases by encoding query-target relationships in the embedding space. We conduct comprehensive evaluations of the learned representations and benchmark our method on virtual screening datasets in a zero-shot setting. Our findings demonstrate significantly shorter runtimes for pharmacophore matching, offering a promising speed-up for screening very large datasets.","sentences":["The increasing size of screening libraries poses a significant challenge for the development of virtual screening methods for drug discovery, necessitating a re-evaluation of traditional approaches in the era of big data.","Although 3D pharmacophore screening remains a prevalent technique, its application to very large datasets is limited by the computational cost associated with matching query pharmacophores to database ligands.","In this study, we introduce PharmacoMatch, a novel contrastive learning approach based on neural subgraph matching.","Our method reinterprets pharmacophore screening as an approximate subgraph matching problem and enables efficient querying of conformational databases by encoding query-target relationships in the embedding space.","We conduct comprehensive evaluations of the learned representations and benchmark our method on virtual screening datasets in a zero-shot setting.","Our findings demonstrate significantly shorter runtimes for pharmacophore matching, offering a promising speed-up for screening very large datasets."],"url":"http://arxiv.org/abs/2409.06316v1"}
{"created":"2024-09-10 07:42:47","title":"EntAugment: Entropy-Driven Adaptive Data Augmentation Framework for Image Classification","abstract":"Data augmentation (DA) has been widely used to improve the generalization of deep neural networks. While existing DA methods have proven effective, they often rely on augmentation operations with random magnitudes to each sample. However, this approach can inadvertently introduce noise, induce distribution shifts, and increase the risk of overfitting. In this paper, we propose EntAugment, a tuning-free and adaptive DA framework. Unlike previous work, EntAugment dynamically assesses and adjusts the augmentation magnitudes for each sample during training, leveraging insights into both the inherent complexities of training samples and the evolving status of deep models. Specifically, in EntAugment, the magnitudes are determined by the information entropy derived from the probability distribution obtained by applying the softmax function to the model's output. In addition, to further enhance the efficacy of EntAugment, we introduce a novel entropy regularization term, EntLoss, which complements the EntAugment approach. Theoretical analysis further demonstrates that EntLoss, compared to traditional cross-entropy loss, achieves closer alignment between the model distributions and underlying dataset distributions. Moreover, EntAugment and EntLoss can be utilized separately or jointly. We conduct extensive experiments across multiple image classification tasks and network architectures with thorough comparisons of existing DA methods. Importantly, the proposed methods outperform others without introducing any auxiliary models or noticeable extra computational costs, highlighting both effectiveness and efficiency. Code is available at https://github.com/Jackbrocp/EntAugment.","sentences":["Data augmentation (DA) has been widely used to improve the generalization of deep neural networks.","While existing DA methods have proven effective, they often rely on augmentation operations with random magnitudes to each sample.","However, this approach can inadvertently introduce noise, induce distribution shifts, and increase the risk of overfitting.","In this paper, we propose EntAugment, a tuning-free and adaptive DA framework.","Unlike previous work, EntAugment dynamically assesses and adjusts the augmentation magnitudes for each sample during training, leveraging insights into both the inherent complexities of training samples and the evolving status of deep models.","Specifically, in EntAugment, the magnitudes are determined by the information entropy derived from the probability distribution obtained by applying the softmax function to the model's output.","In addition, to further enhance the efficacy of EntAugment, we introduce a novel entropy regularization term, EntLoss, which complements the EntAugment approach.","Theoretical analysis further demonstrates that EntLoss, compared to traditional cross-entropy loss, achieves closer alignment between the model distributions and underlying dataset distributions.","Moreover, EntAugment and EntLoss can be utilized separately or jointly.","We conduct extensive experiments across multiple image classification tasks and network architectures with thorough comparisons of existing DA methods.","Importantly, the proposed methods outperform others without introducing any auxiliary models or noticeable extra computational costs, highlighting both effectiveness and efficiency.","Code is available at https://github.com/Jackbrocp/EntAugment."],"url":"http://arxiv.org/abs/2409.06290v1"}
{"created":"2024-09-10 07:34:19","title":"Learning Augmentation Policies from A Model Zoo for Time Series Forecasting","abstract":"Time series forecasting models typically rely on a fixed-size training set and treat all data uniformly, which may not effectively capture the specific patterns present in more challenging training samples. To address this issue, we introduce AutoTSAug, a learnable data augmentation method based on reinforcement learning. Our approach begins with an empirical analysis to determine which parts of the training data should be augmented. Specifically, we identify the so-called marginal samples by considering the prediction diversity across a set of pretrained forecasting models. Next, we propose using variational masked autoencoders as the augmentation model and applying the REINFORCE algorithm to transform the marginal samples into new data. The goal of this generative model is not only to mimic the distribution of real data but also to reduce the variance of prediction errors across the model zoo. By augmenting the marginal samples with a learnable policy, AutoTSAug substantially improves forecasting performance, advancing the prior art in this field with minimal additional computational cost.","sentences":["Time series forecasting models typically rely on a fixed-size training set and treat all data uniformly, which may not effectively capture the specific patterns present in more challenging training samples.","To address this issue, we introduce AutoTSAug, a learnable data augmentation method based on reinforcement learning.","Our approach begins with an empirical analysis to determine which parts of the training data should be augmented.","Specifically, we identify the so-called marginal samples by considering the prediction diversity across a set of pretrained forecasting models.","Next, we propose using variational masked autoencoders as the augmentation model and applying the REINFORCE algorithm to transform the marginal samples into new data.","The goal of this generative model is not only to mimic the distribution of real data but also to reduce the variance of prediction errors across the model zoo.","By augmenting the marginal samples with a learnable policy, AutoTSAug substantially improves forecasting performance, advancing the prior art in this field with minimal additional computational cost."],"url":"http://arxiv.org/abs/2409.06282v1"}
{"created":"2024-09-10 07:31:56","title":"Catch Me if You Can: Detecting Unauthorized Data Use in Deep Learning Models","abstract":"The rise of deep learning (DL) has led to a surging demand for training data, which incentivizes the creators of DL models to trawl through the Internet for training materials. Meanwhile, users often have limited control over whether their data (e.g., facial images) are used to train DL models without their consent, which has engendered pressing concerns.   This work proposes MembershipTracker, a practical data provenance tool that can empower ordinary users to take agency in detecting the unauthorized use of their data in training DL models. We view tracing data provenance through the lens of membership inference (MI). MembershipTracker consists of a lightweight data marking component to mark the target data with small and targeted changes, which can be strongly memorized by the model trained on them; and a specialized MI-based verification process to audit whether the model exhibits strong memorization on the target samples.   Overall, MembershipTracker only requires the users to mark a small fraction of data (0.005% to 0.1% in proportion to the training set), and it enables the users to reliably detect the unauthorized use of their data (average 0% FPR@100% TPR). We show that MembershipTracker is highly effective across various settings, including industry-scale training on the full-size ImageNet-1k dataset. We finally evaluate MembershipTracker under multiple classes of countermeasures.","sentences":["The rise of deep learning (DL) has led to a surging demand for training data, which incentivizes the creators of DL models to trawl through the Internet for training materials.","Meanwhile, users often have limited control over whether their data (e.g., facial images) are used to train DL models without their consent, which has engendered pressing concerns.   ","This work proposes MembershipTracker, a practical data provenance tool that can empower ordinary users to take agency in detecting the unauthorized use of their data in training DL models.","We view tracing data provenance through the lens of membership inference (MI).","MembershipTracker consists of a lightweight data marking component to mark the target data with small and targeted changes, which can be strongly memorized by the model trained on them; and a specialized MI-based verification process to audit whether the model exhibits strong memorization on the target samples.   ","Overall, MembershipTracker only requires the users to mark a small fraction of data (0.005% to 0.1% in proportion to the training set), and it enables the users to reliably detect the unauthorized use of their data (average 0% FPR@100% TPR).","We show that MembershipTracker is highly effective across various settings, including industry-scale training on the full-size ImageNet-1k dataset.","We finally evaluate MembershipTracker under multiple classes of countermeasures."],"url":"http://arxiv.org/abs/2409.06280v1"}
{"created":"2024-09-10 07:28:13","title":"Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models","abstract":"Large Language Models (LLMs) have become indispensable in numerous real-world applications. Unfortunately, fine-tuning these models at scale, especially in federated settings where data privacy and communication efficiency are critical, presents significant challenges. Existing methods often resort to parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but this typically comes at the cost of model accuracy. To address these limitations, we propose federated full-parameter tuning at scale for LLMs (Ferret), the first first-order method with shared randomness to enable scalable full-parameter tuning of LLMs across decentralized data sources while maintaining competitive model accuracy. Ferret accomplishes this through three aspects: (1) it employs widely applied first-order methods for efficient local updates; (2) it projects these updates into a low-dimensional space to considerably reduce communication overhead; and (3) it reconstructs local updates from this low-dimensional space with shared randomness to facilitate effective full-parameter global aggregation, ensuring fast convergence and competitive final performance. Our rigorous theoretical analyses and insights along with extensive experiments, show that Ferret significantly enhances the scalability of existing federated full-parameter tuning approaches by achieving high computational efficiency, reduced communication overhead, and fast convergence, all while maintaining competitive model accuracy. Our implementation is available at https://github.com/allen4747/Ferret.","sentences":["Large Language Models (LLMs) have become indispensable in numerous real-world applications.","Unfortunately, fine-tuning these models at scale, especially in federated settings where data privacy and communication efficiency are critical, presents significant challenges.","Existing methods often resort to parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but this typically comes at the cost of model accuracy.","To address these limitations, we propose federated full-parameter tuning at scale for LLMs (Ferret), the first first-order method with shared randomness to enable scalable full-parameter tuning of LLMs across decentralized data sources while maintaining competitive model accuracy.","Ferret accomplishes this through three aspects: (1) it employs widely applied first-order methods for efficient local updates; (2) it projects these updates into a low-dimensional space to considerably reduce communication overhead; and (3) it reconstructs local updates from this low-dimensional space with shared randomness to facilitate effective full-parameter global aggregation, ensuring fast convergence and competitive final performance.","Our rigorous theoretical analyses and insights along with extensive experiments, show that Ferret significantly enhances the scalability of existing federated full-parameter tuning approaches by achieving high computational efficiency, reduced communication overhead, and fast convergence, all while maintaining competitive model accuracy.","Our implementation is available at https://github.com/allen4747/Ferret."],"url":"http://arxiv.org/abs/2409.06277v1"}
{"created":"2024-09-10 07:18:57","title":"Towards Robust Uncertainty-Aware Incomplete Multi-View Classification","abstract":"Handling incomplete data in multi-view classification is challenging, especially when traditional imputation methods introduce biases that compromise uncertainty estimation. Existing Evidential Deep Learning (EDL) based approaches attempt to address these issues, but they often struggle with conflicting evidence due to the limitations of the Dempster-Shafer combination rule, leading to unreliable decisions. To address these challenges, we propose the Alternating Progressive Learning Network (APLN), specifically designed to enhance EDL-based methods in incomplete MVC scenarios. Our approach mitigates bias from corrupted observed data by first applying coarse imputation, followed by mapping the data to a latent space. In this latent space, we progressively learn an evidence distribution aligned with the target domain, incorporating uncertainty considerations through EDL. Additionally, we introduce a conflict-aware Dempster-Shafer combination rule (DSCR) to better handle conflicting evidence. By sampling from the learned distribution, we optimize the latent representations of missing views, reducing bias and enhancing decision-making robustness. Extensive experiments demonstrate that APLN, combined with DSCR, significantly outperforms traditional methods, particularly in environments characterized by high uncertainty and conflicting evidence, establishing it as a promising solution for incomplete multi-view classification.","sentences":["Handling incomplete data in multi-view classification is challenging, especially when traditional imputation methods introduce biases that compromise uncertainty estimation.","Existing Evidential Deep Learning (EDL) based approaches attempt to address these issues, but they often struggle with conflicting evidence due to the limitations of the Dempster-Shafer combination rule, leading to unreliable decisions.","To address these challenges, we propose the Alternating Progressive Learning Network (APLN), specifically designed to enhance EDL-based methods in incomplete MVC scenarios.","Our approach mitigates bias from corrupted observed data by first applying coarse imputation, followed by mapping the data to a latent space.","In this latent space, we progressively learn an evidence distribution aligned with the target domain, incorporating uncertainty considerations through EDL.","Additionally, we introduce a conflict-aware Dempster-Shafer combination rule (DSCR) to better handle conflicting evidence.","By sampling from the learned distribution, we optimize the latent representations of missing views, reducing bias and enhancing decision-making robustness.","Extensive experiments demonstrate that APLN, combined with DSCR, significantly outperforms traditional methods, particularly in environments characterized by high uncertainty and conflicting evidence, establishing it as a promising solution for incomplete multi-view classification."],"url":"http://arxiv.org/abs/2409.06270v1"}
{"created":"2024-09-10 07:06:40","title":"Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking","abstract":"Dialogue State Tracking (DST) is a key part of task-oriented dialogue systems, identifying important information in conversations. However, its accuracy drops significantly in spoken dialogue environments due to named entity errors from Automatic Speech Recognition (ASR) systems. We introduce a simple yet effective data augmentation method that targets those entities to improve the robustness of DST model. Our novel method can control the placement of errors using keyword-highlighted prompts while introducing phonetically similar errors. As a result, our method generated sufficient error patterns on keywords, leading to improved accuracy in noised and low-accuracy ASR environments.","sentences":["Dialogue State Tracking (DST) is a key part of task-oriented dialogue systems, identifying important information in conversations.","However, its accuracy drops significantly in spoken dialogue environments due to named entity errors from Automatic Speech Recognition (ASR) systems.","We introduce a simple yet effective data augmentation method that targets those entities to improve the robustness of DST model.","Our novel method can control the placement of errors using keyword-highlighted prompts while introducing phonetically similar errors.","As a result, our method generated sufficient error patterns on keywords, leading to improved accuracy in noised and low-accuracy ASR environments."],"url":"http://arxiv.org/abs/2409.06263v1"}
{"created":"2024-09-10 06:31:17","title":"Differential Degradation Vulnerabilities in Censorship Circumvention Systems","abstract":"Several recently proposed censorship circumvention systems use encrypted network channels of popular applications to hide their communications. For example, a Tor pluggable transport called Snowflake uses the WebRTC data channel, while a system called Protozoa substitutes content in a WebRTC video-call application. By using the same channel as the cover application and (in the case of Protozoa) matching its observable traffic characteristics, these systems aim to resist powerful network-based censors capable of large-scale traffic analysis. Protozoa, in particular, achieves a strong indistinguishability property known as behavioral independence.   We demonstrate that this class of systems is generically vulnerable to a new type of active attacks we call \"differential degradation.\" These attacks do not require multi-flow measurements or traffic classification and are thus available to all real-world censors. They exploit the discrepancies between the respective network requirements of the circumvention system and its cover application. We show how a censor can use the minimal application-level information exposed by WebRTC to create network conditions that cause the circumvention system to suffer a much bigger degradation in performance than the cover application. Even when the attack causes no observable differences in network traffic and behavioral independence still holds, the censor can block circumvention at a low cost, without resorting to traffic analysis, and with minimal collateral damage to non-circumvention users.   We present effective differential degradation attacks against Snowflake and Protozoa. We explain the root cause of these vulnerabilities, analyze the tradeoffs faced by the designers of circumvention systems, and propose a modified version of Protozoa that resists differential degradation attacks.","sentences":["Several recently proposed censorship circumvention systems use encrypted network channels of popular applications to hide their communications.","For example, a Tor pluggable transport called Snowflake uses the WebRTC data channel, while a system called Protozoa substitutes content in a WebRTC video-call application.","By using the same channel as the cover application and (in the case of Protozoa) matching its observable traffic characteristics, these systems aim to resist powerful network-based censors capable of large-scale traffic analysis.","Protozoa, in particular, achieves a strong indistinguishability property known as behavioral independence.   ","We demonstrate that this class of systems is generically vulnerable to a new type of active attacks we call \"differential degradation.\"","These attacks do not require multi-flow measurements or traffic classification and are thus available to all real-world censors.","They exploit the discrepancies between the respective network requirements of the circumvention system and its cover application.","We show how a censor can use the minimal application-level information exposed by WebRTC to create network conditions that cause the circumvention system to suffer a much bigger degradation in performance than the cover application.","Even when the attack causes no observable differences in network traffic and behavioral independence still holds, the censor can block circumvention at a low cost, without resorting to traffic analysis, and with minimal collateral damage to non-circumvention users.   ","We present effective differential degradation attacks against Snowflake and Protozoa.","We explain the root cause of these vulnerabilities, analyze the tradeoffs faced by the designers of circumvention systems, and propose a modified version of Protozoa that resists differential degradation attacks."],"url":"http://arxiv.org/abs/2409.06247v1"}
{"created":"2024-09-10 06:24:46","title":"Inference is All You Need: Self Example Retriever for Cross-domain Dialogue State Tracking with ChatGPT","abstract":"Traditional dialogue state tracking approaches heavily rely on extensive training data and handcrafted features, limiting their scalability and adaptability to new domains. In this paper, we propose a novel method that leverages inference and in-context learning with ChatGPT for domain transfer in dialogue state tracking, without any parameter updates. By guiding ChatGPT's chain of thought, we enable it to retrieve relevant examples and generalize knowledge to accurately infer dialogue states, solely through inference. Experimental results on the MultiWOZ dataset demonstrate competitive performance and promising generalization across domains. Our parameter-free approach offers a scalable and adaptable solution, opening new research directions in domain transfer learning.","sentences":["Traditional dialogue state tracking approaches heavily rely on extensive training data and handcrafted features, limiting their scalability and adaptability to new domains.","In this paper, we propose a novel method that leverages inference and in-context learning with ChatGPT for domain transfer in dialogue state tracking, without any parameter updates.","By guiding ChatGPT's chain of thought, we enable it to retrieve relevant examples and generalize knowledge to accurately infer dialogue states, solely through inference.","Experimental results on the MultiWOZ dataset demonstrate competitive performance and promising generalization across domains.","Our parameter-free approach offers a scalable and adaptable solution, opening new research directions in domain transfer learning."],"url":"http://arxiv.org/abs/2409.06243v1"}
{"created":"2024-09-10 06:17:27","title":"DiPT: Enhancing LLM reasoning through diversified perspective-taking","abstract":"Existing work on improving language model reasoning typically explores a single solution path, which can be prone to errors. Inspired by perspective-taking in social studies, this paper introduces DiPT, a novel approach that complements current reasoning methods by explicitly incorporating diversified viewpoints. This approach allows the model to gain a deeper understanding of the problem's context and identify the most effective solution path during the inference stage. Additionally, it provides a general data-centric AI recipe for augmenting existing data to improve their quality for fine-tuning.   Our empirical results demonstrate that DiPT can be flexibly integrated into existing methods that focus on a single reasoning approach, enhancing their reasoning performance and stability when presented with paraphrased problems. Furthermore, we illustrate improved context understanding by maintaining the model's safe outputs against \"jailbreaking\" prompts intentionally designed to bypass safeguards built into deployed models. Lastly, we show that fine-tuning with data enriched with diverse perspectives can boost the reasoning capabilities of the model compared to fine-tuning with raw data alone.","sentences":["Existing work on improving language model reasoning typically explores a single solution path, which can be prone to errors.","Inspired by perspective-taking in social studies, this paper introduces DiPT, a novel approach that complements current reasoning methods by explicitly incorporating diversified viewpoints.","This approach allows the model to gain a deeper understanding of the problem's context and identify the most effective solution path during the inference stage.","Additionally, it provides a general data-centric AI recipe for augmenting existing data to improve their quality for fine-tuning.   ","Our empirical results demonstrate that DiPT can be flexibly integrated into existing methods that focus on a single reasoning approach, enhancing their reasoning performance and stability when presented with paraphrased problems.","Furthermore, we illustrate improved context understanding by maintaining the model's safe outputs against \"jailbreaking\" prompts intentionally designed to bypass safeguards built into deployed models.","Lastly, we show that fine-tuning with data enriched with diverse perspectives can boost the reasoning capabilities of the model compared to fine-tuning with raw data alone."],"url":"http://arxiv.org/abs/2409.06241v1"}
{"created":"2024-09-10 06:17:07","title":"Test-Time Certifiable Self-Supervision to Bridge the Sim2Real Gap in Event-Based Satellite Pose Estimation","abstract":"Deep learning plays a critical role in vision-based satellite pose estimation. However, the scarcity of real data from the space environment means that deep models need to be trained using synthetic data, which raises the Sim2Real domain gap problem. A major cause of the Sim2Real gap are novel lighting conditions encountered during test time. Event sensors have been shown to provide some robustness against lighting variations in vision-based pose estimation. However, challenging lighting conditions due to strong directional light can still cause undesirable effects in the output of commercial off-the-shelf event sensors, such as noisy/spurious events and inhomogeneous event densities on the object. Such effects are non-trivial to simulate in software, thus leading to Sim2Real gap in the event domain. To close the Sim2Real gap in event-based satellite pose estimation, the paper proposes a test-time self-supervision scheme with a certifier module. Self-supervision is enabled by an optimisation routine that aligns a dense point cloud of the predicted satellite pose with the event data to attempt to rectify the inaccurately estimated pose. The certifier attempts to verify the corrected pose, and only certified test-time inputs are backpropagated via implicit differentiation to refine the predicted landmarks, thus improving the pose estimates and closing the Sim2Real gap. Results show that the our method outperforms established test-time adaptation schemes.","sentences":["Deep learning plays a critical role in vision-based satellite pose estimation.","However, the scarcity of real data from the space environment means that deep models need to be trained using synthetic data, which raises the Sim2Real domain gap problem.","A major cause of the Sim2Real gap are novel lighting conditions encountered during test time.","Event sensors have been shown to provide some robustness against lighting variations in vision-based pose estimation.","However, challenging lighting conditions due to strong directional light can still cause undesirable effects in the output of commercial off-the-shelf event sensors, such as noisy/spurious events and inhomogeneous event densities on the object.","Such effects are non-trivial to simulate in software, thus leading to Sim2Real gap in the event domain.","To close the Sim2Real gap in event-based satellite pose estimation, the paper proposes a test-time self-supervision scheme with a certifier module.","Self-supervision is enabled by an optimisation routine that aligns a dense point cloud of the predicted satellite pose with the event data to attempt to rectify the inaccurately estimated pose.","The certifier attempts to verify the corrected pose, and only certified test-time inputs are backpropagated via implicit differentiation to refine the predicted landmarks, thus improving the pose estimates and closing the Sim2Real gap.","Results show that the our method outperforms established test-time adaptation schemes."],"url":"http://arxiv.org/abs/2409.06240v1"}
{"created":"2024-09-10 06:07:20","title":"Recurrent Neural Networks for Still Images","abstract":"In this paper, we explore the application of Recurrent Neural Network (RNN) for still images. Typically, Convolutional Neural Networks (CNNs) are the prevalent method applied for this type of data, and more recently, transformers have gained popularity, although they often require large models. Unlike these methods, RNNs are generally associated with processing sequences over time rather than single images. We argue that RNNs can effectively handle still images by interpreting the pixels as a sequence. This approach could be particularly advantageous for compact models designed for embedded systems, where resources are limited. Additionally, we introduce a novel RNN design tailored for two-dimensional inputs, such as images, and a custom version of BiDirectional RNN (BiRNN) that is more memory-efficient than traditional implementations. In our research, we have tested these layers in Convolutional Recurrent Neural Networks (CRNNs), predominantly composed of Conv2D layers, with RNN layers at or close to the end. Experiments on the COCO and CIFAR100 datasets show better results, particularly for small networks.","sentences":["In this paper, we explore the application of Recurrent Neural Network (RNN) for still images.","Typically, Convolutional Neural Networks (CNNs) are the prevalent method applied for this type of data, and more recently, transformers have gained popularity, although they often require large models.","Unlike these methods, RNNs are generally associated with processing sequences over time rather than single images.","We argue that RNNs can effectively handle still images by interpreting the pixels as a sequence.","This approach could be particularly advantageous for compact models designed for embedded systems, where resources are limited.","Additionally, we introduce a novel RNN design tailored for two-dimensional inputs, such as images, and a custom version of BiDirectional RNN (BiRNN) that is more memory-efficient than traditional implementations.","In our research, we have tested these layers in Convolutional Recurrent Neural Networks (CRNNs), predominantly composed of Conv2D layers, with RNN layers at or close to the end.","Experiments on the COCO and CIFAR100 datasets show better results, particularly for small networks."],"url":"http://arxiv.org/abs/2409.06235v1"}
{"created":"2024-09-10 06:00:50","title":"VBIT: Towards Enhancing Privacy Control Over IoT Devices","abstract":"Internet-of-Things (IoT) devices are increasingly deployed at home, at work, and in other shared and public spaces. IoT devices collect and share data with service providers and third parties, which poses privacy concerns. Although privacy enhancing tools are quite advanced in other applications domains (\\eg~ advertising and tracker blockers for browsers), users have currently no convenient way to know or manage what and how data is collected and shared by IoT devices. In this paper, we present VBIT, an interactive system combining Mixed Reality (MR) and web-based applications that allows users to: (1) uncover and visualize tracking services by IoT devices in an instrumented space and (2) take action to stop or limit that tracking. We design and implement VBIT to operate at the network traffic level, and we show that it has negligible performance overhead, and offers flexibility and good usability. We perform a mixed-method user study consisting of an online survey and an in-person interview study. We show that VBIT users appreciate VBIT's transparency, control, and customization features, and they become significantly more willing to install an IoT advertising and tracking blocker, after using VBIT. In the process, we obtain design insights that can be used to further iterate and improve the design of VBIT and other systems for IoT transparency and control.","sentences":["Internet-of-Things (IoT) devices are increasingly deployed at home, at work, and in other shared and public spaces.","IoT devices collect and share data with service providers and third parties, which poses privacy concerns.","Although privacy enhancing tools are quite advanced in other applications domains (\\eg~ advertising and tracker blockers for browsers), users have currently no convenient way to know or manage what and how data is collected and shared by IoT devices.","In this paper, we present VBIT, an interactive system combining Mixed Reality (MR) and web-based applications that allows users to: (1) uncover and visualize tracking services by IoT devices in an instrumented space and (2) take action to stop or limit that tracking.","We design and implement VBIT to operate at the network traffic level, and we show that it has negligible performance overhead, and offers flexibility and good usability.","We perform a mixed-method user study consisting of an online survey and an in-person interview study.","We show that VBIT users appreciate VBIT's transparency, control, and customization features, and they become significantly more willing to install an IoT advertising and tracking blocker, after using VBIT.","In the process, we obtain design insights that can be used to further iterate and improve the design of VBIT and other systems for IoT transparency and control."],"url":"http://arxiv.org/abs/2409.06233v1"}
{"created":"2024-09-10 05:41:40","title":"NLP-Powered Repository and Search Engine for Academic Papers: A Case Study on Cyber Risk Literature with CyLit","abstract":"As the body of academic literature continues to grow, researchers face increasing difficulties in effectively searching for relevant resources. Existing databases and search engines often fall short of providing a comprehensive and contextually relevant collection of academic literature. To address this issue, we propose a novel framework that leverages Natural Language Processing (NLP) techniques. This framework automates the retrieval, summarization, and clustering of academic literature within a specific research domain. To demonstrate the effectiveness of our approach, we introduce CyLit, an NLP-powered repository specifically designed for the cyber risk literature. CyLit empowers researchers by providing access to context-specific resources and enabling the tracking of trends in the dynamic and rapidly evolving field of cyber risk. Through the automatic processing of large volumes of data, our NLP-powered solution significantly enhances the efficiency and specificity of academic literature searches. We compare the literature categorization results of CyLit to those presented in survey papers or generated by ChatGPT, highlighting the distinctive insights this tool provides into cyber risk research literature. Using NLP techniques, we aim to revolutionize the way researchers discover, analyze, and utilize academic resources, ultimately fostering advancements in various domains of knowledge.","sentences":["As the body of academic literature continues to grow, researchers face increasing difficulties in effectively searching for relevant resources.","Existing databases and search engines often fall short of providing a comprehensive and contextually relevant collection of academic literature.","To address this issue, we propose a novel framework that leverages Natural Language Processing (NLP) techniques.","This framework automates the retrieval, summarization, and clustering of academic literature within a specific research domain.","To demonstrate the effectiveness of our approach, we introduce CyLit, an NLP-powered repository specifically designed for the cyber risk literature.","CyLit empowers researchers by providing access to context-specific resources and enabling the tracking of trends in the dynamic and rapidly evolving field of cyber risk.","Through the automatic processing of large volumes of data, our NLP-powered solution significantly enhances the efficiency and specificity of academic literature searches.","We compare the literature categorization results of CyLit to those presented in survey papers or generated by ChatGPT, highlighting the distinctive insights this tool provides into cyber risk research literature.","Using NLP techniques, we aim to revolutionize the way researchers discover, analyze, and utilize academic resources, ultimately fostering advancements in various domains of knowledge."],"url":"http://arxiv.org/abs/2409.06226v1"}
{"created":"2024-09-10 05:28:38","title":"MIP-GAF: A MLLM-annotated Benchmark for Most Important Person Localization and Group Context Understanding","abstract":"Estimating the Most Important Person (MIP) in any social event setup is a challenging problem mainly due to contextual complexity and scarcity of labeled data. Moreover, the causality aspects of MIP estimation are quite subjective and diverse. To this end, we aim to address the problem by annotating a large-scale `in-the-wild' dataset for identifying human perceptions about the `Most Important Person (MIP)' in an image. The paper provides a thorough description of our proposed Multimodal Large Language Model (MLLM) based data annotation strategy, and a thorough data quality analysis. Further, we perform a comprehensive benchmarking of the proposed dataset utilizing state-of-the-art MIP localization methods, indicating a significant drop in performance compared to existing datasets. The performance drop shows that the existing MIP localization algorithms must be more robust with respect to `in-the-wild' situations. We believe the proposed dataset will play a vital role in building the next-generation social situation understanding methods. The code and data is available at https://github.com/surbhimadan92/MIP-GAF.","sentences":["Estimating the Most Important Person (MIP) in any social event setup is a challenging problem mainly due to contextual complexity and scarcity of labeled data.","Moreover, the causality aspects of MIP estimation are quite subjective and diverse.","To this end, we aim to address the problem by annotating a large-scale `in-the-wild' dataset for identifying human perceptions about the `Most Important Person (MIP)' in an image.","The paper provides a thorough description of our proposed Multimodal Large Language Model (MLLM) based data annotation strategy, and a thorough data quality analysis.","Further, we perform a comprehensive benchmarking of the proposed dataset utilizing state-of-the-art MIP localization methods, indicating a significant drop in performance compared to existing datasets.","The performance drop shows that the existing MIP localization algorithms must be more robust with respect to `in-the-wild' situations.","We believe the proposed dataset will play a vital role in building the next-generation social situation understanding methods.","The code and data is available at https://github.com/surbhimadan92/MIP-GAF."],"url":"http://arxiv.org/abs/2409.06224v1"}
{"created":"2024-09-10 05:26:53","title":"Enhancing Temporal Understanding in Audio Question Answering for Large Audio Language Models","abstract":"The Audio Question Answering task includes audio event classification, audio captioning, and open ended reasoning. Recently, Audio Question Answering has garnered attention due to the advent of Large Audio Language Models. Current literature focuses on constructing LALMs by integrating audio encoders with text only Large Language Models through a projection module. While Large Audio Language Models excel in general audio understanding, they are limited in temporal reasoning which may hinder their commercial applications and on device deployment. This paper addresses these challenges and limitations in audio temporal reasoning. First, we introduce a data augmentation technique for generating reliable audio temporal questions and answers using an LLM. Second, we propose a continued finetuning curriculum learning strategy to specialize in temporal reasoning without compromising performance on finetuned tasks. Finally, we develop a reliable and transparent automated metric, assisted by an LLM, to measure the correlation between Large Audio Language Model responses and ground truth data intelligently. We demonstrate the effectiveness of our proposed techniques using SOTA LALMs on public audio benchmark datasets.","sentences":["The Audio Question Answering task includes audio event classification, audio captioning, and open ended reasoning.","Recently, Audio Question Answering has garnered attention due to the advent of Large Audio Language Models.","Current literature focuses on constructing LALMs by integrating audio encoders with text only Large Language Models through a projection module.","While Large Audio Language Models excel in general audio understanding, they are limited in temporal reasoning which may hinder their commercial applications and on device deployment.","This paper addresses these challenges and limitations in audio temporal reasoning.","First, we introduce a data augmentation technique for generating reliable audio temporal questions and answers using an LLM.","Second, we propose a continued finetuning curriculum learning strategy to specialize in temporal reasoning without compromising performance on finetuned tasks.","Finally, we develop a reliable and transparent automated metric, assisted by an LLM, to measure the correlation between Large Audio Language Model responses and ground truth data intelligently.","We demonstrate the effectiveness of our proposed techniques using SOTA LALMs on public audio benchmark datasets."],"url":"http://arxiv.org/abs/2409.06223v1"}
{"created":"2024-09-10 05:24:36","title":"Advancing Topic Segmentation of Broadcasted Speech with Multilingual Semantic Embeddings","abstract":"Recent advancements in speech-based topic segmentation have highlighted the potential of pretrained speech encoders to capture semantic representations directly from speech. Traditionally, topic segmentation has relied on a pipeline approach in which transcripts of the automatic speech recognition systems are generated, followed by text-based segmentation algorithms. In this paper, we introduce an end-to-end scheme that bypasses this conventional two-step process by directly employing semantic speech encoders for segmentation. Focused on the broadcasted news domain, which poses unique challenges due to the diversity of speakers and topics within single recordings, we address the challenge of accessing topic change points efficiently in an end-to-end manner. Furthermore, we propose a new benchmark for spoken news topic segmentation by utilizing a dataset featuring approximately 1000 hours of publicly available recordings across six European languages and including an evaluation set in Hindi to test the model's cross-domain performance in a cross-lingual, zero-shot scenario. This setup reflects real-world diversity and the need for models adapting to various linguistic settings. Our results demonstrate that while the traditional pipeline approach achieves a state-of-the-art $P_k$ score of 0.2431 for English, our end-to-end model delivers a competitive $P_k$ score of 0.2564. When trained multilingually, these scores further improve to 0.1988 and 0.2370, respectively. To support further research, we release our model along with data preparation scripts, facilitating open research on multilingual spoken news topic segmentation.","sentences":["Recent advancements in speech-based topic segmentation have highlighted the potential of pretrained speech encoders to capture semantic representations directly from speech.","Traditionally, topic segmentation has relied on a pipeline approach in which transcripts of the automatic speech recognition systems are generated, followed by text-based segmentation algorithms.","In this paper, we introduce an end-to-end scheme that bypasses this conventional two-step process by directly employing semantic speech encoders for segmentation.","Focused on the broadcasted news domain, which poses unique challenges due to the diversity of speakers and topics within single recordings, we address the challenge of accessing topic change points efficiently in an end-to-end manner.","Furthermore, we propose a new benchmark for spoken news topic segmentation by utilizing a dataset featuring approximately 1000 hours of publicly available recordings across six European languages and including an evaluation set in Hindi to test the model's cross-domain performance in a cross-lingual, zero-shot scenario.","This setup reflects real-world diversity and the need for models adapting to various linguistic settings.","Our results demonstrate that while the traditional pipeline approach achieves a state-of-the-art $P_k$ score of 0.2431 for English, our end-to-end model delivers a competitive $P_k$ score of 0.2564.","When trained multilingually, these scores further improve to 0.1988 and 0.2370, respectively.","To support further research, we release our model along with data preparation scripts, facilitating open research on multilingual spoken news topic segmentation."],"url":"http://arxiv.org/abs/2409.06222v1"}
{"created":"2024-09-10 04:29:59","title":"Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis","abstract":"Survival analysis holds a crucial role across diverse disciplines, such as economics, engineering and healthcare. It empowers researchers to analyze both time-invariant and time-varying data, encompassing phenomena like customer churn, material degradation and various medical outcomes. Given the complexity and heterogeneity of such data, recent endeavors have demonstrated successful integration of deep learning methodologies to address limitations in conventional statistical approaches. However, current methods typically involve cluttered probability distribution function (PDF), have lower sensitivity in censoring prediction, only model static datasets, or only rely on recurrent neural networks for dynamic modelling. In this paper, we propose a novel survival regression method capable of producing high-quality unimodal PDFs without any prior distribution assumption, by optimizing novel Margin-Mean-Variance loss and leveraging the flexibility of Transformer to handle both temporal and non-temporal data, coined UniSurv. Extensive experiments on several datasets demonstrate that UniSurv places a significantly higher emphasis on censoring compared to other methods.","sentences":["Survival analysis holds a crucial role across diverse disciplines, such as economics, engineering and healthcare.","It empowers researchers to analyze both time-invariant and time-varying data, encompassing phenomena like customer churn, material degradation and various medical outcomes.","Given the complexity and heterogeneity of such data, recent endeavors have demonstrated successful integration of deep learning methodologies to address limitations in conventional statistical approaches.","However, current methods typically involve cluttered probability distribution function (PDF), have lower sensitivity in censoring prediction, only model static datasets, or only rely on recurrent neural networks for dynamic modelling.","In this paper, we propose a novel survival regression method capable of producing high-quality unimodal PDFs without any prior distribution assumption, by optimizing novel Margin-Mean-Variance loss and leveraging the flexibility of Transformer to handle both temporal and non-temporal data, coined UniSurv.","Extensive experiments on several datasets demonstrate that UniSurv places a significantly higher emphasis on censoring compared to other methods."],"url":"http://arxiv.org/abs/2409.06209v1"}
{"created":"2024-09-10 04:24:22","title":"Design and Implementation of Online Live Streaming System Using A 3D Engine","abstract":"With the growing demand for live video streaming, there is an increasing need for low-latency and high-quality transmission, especially with the advent of 5G networks. While 5G offers hardware-level improvements, effective software solutions for minimizing latency remain essential. Current methods, such as multi-channel streaming, fail to address latency issues fundamentally, often only adding new channels without optimizing overall performance. This thesis proposes a novel approach using a 3D engine (e.g., Unity 3D) to stream multi-input video data through a single channel with reduced latency. By leveraging 3D engine capabilities, such as World/Screen Space Cameras, 3D Canvases, and Webcam Textures, the proposed system consolidates video streams from multiple external cameras into a unified, low-latency output. The affiliated project of this thesis demonstrates the implementation of a low-latency multi-channel live video streaming system. It employs the RTSP protocol and examines video encoding techniques, alongside a client-side application based on Unity 3D. The system architecture includes a WebSocket server for persistent connections, an HTTP server for communication, a MySQL database for storage, Redis for caching, and Nginx for load balancing. Each module operates independently, ensuring flexibility and scalability in the system's design. A key innovation of this system is its use of a 3D scene to map multiple video inputs onto a virtual canvas, recorded by an in-engine camera for transmission. This design minimizes redundant data, enabling an efficient and director-guided live streaming network. The thesis concludes by discussing challenges encountered during the project and provides solutions for future improvement.","sentences":["With the growing demand for live video streaming, there is an increasing need for low-latency and high-quality transmission, especially with the advent of 5G networks.","While 5G offers hardware-level improvements, effective software solutions for minimizing latency remain essential.","Current methods, such as multi-channel streaming, fail to address latency issues fundamentally, often only adding new channels without optimizing overall performance.","This thesis proposes a novel approach using a 3D engine (e.g., Unity 3D) to stream multi-input video data through a single channel with reduced latency.","By leveraging 3D engine capabilities, such as World/Screen Space Cameras, 3D Canvases, and Webcam Textures, the proposed system consolidates video streams from multiple external cameras into a unified, low-latency output.","The affiliated project of this thesis demonstrates the implementation of a low-latency multi-channel live video streaming system.","It employs the RTSP protocol and examines video encoding techniques, alongside a client-side application based on","Unity 3D.","The system architecture includes a WebSocket server for persistent connections, an HTTP server for communication, a MySQL database for storage, Redis for caching, and Nginx for load balancing.","Each module operates independently, ensuring flexibility and scalability in the system's design.","A key innovation of this system is its use of a 3D scene to map multiple video inputs onto a virtual canvas, recorded by an in-engine camera for transmission.","This design minimizes redundant data, enabling an efficient and director-guided live streaming network.","The thesis concludes by discussing challenges encountered during the project and provides solutions for future improvement."],"url":"http://arxiv.org/abs/2409.06207v1"}
{"created":"2024-09-10 04:18:12","title":"PIM-MMU: A Memory Management Unit for Accelerating Data Transfers in Commercial PIM Systems","abstract":"Processing-in-memory (PIM) has emerged as a promising solution for accelerating memory-intensive workloads as they provide high memory bandwidth to the processing units. This approach has drawn attention not only from the academic community but also from the industry, leading to the development of real-world commercial PIM devices. In this work, we first conduct an in-depth characterization on UPMEM's general purpose PIM system and analyze the bottlenecks caused by the data transfers across the DRAM and PIM address space. Our characterization study reveals several critical challenges associated with DRAM to/from PIM data transfers in memory bus integrated PIM systems, for instance, its high CPU core utilization, high power consumption, and low read/write throughput for both DRAM and PIM. Driven by our key findings, we introduce the PIM-MMU architecture which is a hardware/software codesign that enables energy-efficient DRAM to/from PIM transfers for PIM systems. PIM-MMU synergistically combines a hardwarebased data copy engine, a PIM-optimized memory scheduler, and a heterogeneity-aware memory mapping function, the utilization of which is supported by our PIM-MMU software stack, significantly improving the efficiency of DRAM to/from PIM data transfers. Experimental results show that PIM-MMU improves the DRAM to/from PIM data transfer throughput by an average 4.1x and enhances its energy-efficiency by 4.1x, leading to a 2.2x end-to-end speedup for real-world PIM workloads.","sentences":["Processing-in-memory (PIM) has emerged as a promising solution for accelerating memory-intensive workloads as they provide high memory bandwidth to the processing units.","This approach has drawn attention not only from the academic community but also from the industry, leading to the development of real-world commercial PIM devices.","In this work, we first conduct an in-depth characterization on UPMEM's general purpose PIM system and analyze the bottlenecks caused by the data transfers across the DRAM and PIM address space.","Our characterization study reveals several critical challenges associated with DRAM to/from PIM data transfers in memory bus integrated PIM systems, for instance, its high CPU core utilization, high power consumption, and low read/write throughput for both DRAM and PIM.","Driven by our key findings, we introduce the PIM-MMU architecture which is a hardware/software codesign that enables energy-efficient DRAM to/from PIM transfers for PIM systems.","PIM-MMU synergistically combines a hardwarebased data copy engine, a PIM-optimized memory scheduler, and a heterogeneity-aware memory mapping function, the utilization of which is supported by our PIM-MMU software stack, significantly improving the efficiency of DRAM to/from PIM data transfers.","Experimental results show that PIM-MMU improves the DRAM to/from PIM data transfer throughput by an average 4.1x and enhances its energy-efficiency by 4.1x, leading to a 2.2x end-to-end speedup for real-world PIM workloads."],"url":"http://arxiv.org/abs/2409.06204v1"}
{"created":"2024-09-10 04:01:34","title":"Structured Downsampling for Fast, Memory-efficient Curation of Online Data Streams","abstract":"Operations over data streams typically hinge on efficient mechanisms to aggregate or summarize history on a rolling basis. For high-volume data steams, it is critical to manage state in a manner that is fast and memory efficient -- particularly in resource-constrained or real-time contexts. Here, we address the problem of extracting a fixed-capacity, rolling subsample from a data stream. Specifically, we explore ``data stream curation'' strategies to fulfill requirements on the composition of sample time points retained. Our ``DStream'' suite of algorithms targets three temporal coverage criteria: (1) steady coverage, where retained samples should spread evenly across elapsed data stream history; (2) stretched coverage, where early data items should be proportionally favored; and (3) tilted coverage, where recent data items should be proportionally favored. For each algorithm, we prove worst-case bounds on rolling coverage quality. We focus on the more practical, application-driven case of maximizing coverage quality given a fixed memory capacity. As a core simplifying assumption, we restrict algorithm design to a single update operation: writing from the data stream to a calculated buffer site -- with data never being read back, no metadata stored (e.g., sample timestamps), and data eviction occurring only implicitly via overwrite. Drawing only on primitive, low-level operations and ensuring full, overhead-free use of available memory, this ``DStream'' framework ideally suits domains that are resource-constrained, performance-critical, and fine-grained (e.g., individual data items as small as single bits or bytes). The proposed approach supports $\\mathcal{O}(1)$ data ingestion via concise bit-level operations. To further practical applications, we provide plug-and-play open-source implementations targeting both scripted and compiled application domains.","sentences":["Operations over data streams typically hinge on efficient mechanisms to aggregate or summarize history on a rolling basis.","For high-volume data steams, it is critical to manage state in a manner that is fast and memory efficient -- particularly in resource-constrained or real-time contexts.","Here, we address the problem of extracting a fixed-capacity, rolling subsample from a data stream.","Specifically, we explore ``data stream curation'' strategies to fulfill requirements on the composition of sample time points retained.","Our ``DStream'' suite of algorithms targets three temporal coverage criteria: (1) steady coverage, where retained samples should spread evenly across elapsed data stream history; (2) stretched coverage, where early data items should be proportionally favored; and (3) tilted coverage, where recent data items should be proportionally favored.","For each algorithm, we prove worst-case bounds on rolling coverage quality.","We focus on the more practical, application-driven case of maximizing coverage quality given a fixed memory capacity.","As a core simplifying assumption, we restrict algorithm design to a single update operation: writing from the data stream to a calculated buffer site -- with data never being read back, no metadata stored (e.g., sample timestamps), and data eviction occurring only implicitly via overwrite.","Drawing only on primitive, low-level operations and ensuring full, overhead-free use of available memory, this ``DStream'' framework ideally suits domains that are resource-constrained, performance-critical, and fine-grained (e.g., individual data items as small as single bits or bytes).","The proposed approach supports $\\mathcal{O}(1)$ data ingestion via concise bit-level operations.","To further practical applications, we provide plug-and-play open-source implementations targeting both scripted and compiled application domains."],"url":"http://arxiv.org/abs/2409.06199v1"}
{"created":"2024-09-10 03:57:31","title":"Deep kernel representations of latent space features for low-dose PET-MR imaging robust to variable dose reduction","abstract":"Low-dose positron emission tomography (PET) image reconstruction methods have potential to significantly improve PET as an imaging modality. Deep learning provides a promising means of incorporating prior information into the image reconstruction problem to produce quantitatively accurate images from compromised signal. Deep learning-based methods for low-dose PET are generally poorly conditioned and perform unreliably on images with features not present in the training distribution. We present a method which explicitly models deep latent space features using a robust kernel representation, providing robust performance on previously unseen dose reduction factors. Additional constraints on the information content of deep latent features allow for tuning in-distribution accuracy and generalisability. Tests with out-of-distribution dose reduction factors ranging from $\\times 10$ to $\\times 1000$ and with both paired and unpaired MR, demonstrate significantly improved performance relative to conventional deep-learning methods trained using the same data. Code:https://github.com/cameronPain","sentences":["Low-dose positron emission tomography (PET) image reconstruction methods have potential to significantly improve PET as an imaging modality.","Deep learning provides a promising means of incorporating prior information into the image reconstruction problem to produce quantitatively accurate images from compromised signal.","Deep learning-based methods for low-dose PET are generally poorly conditioned and perform unreliably on images with features not present in the training distribution.","We present a method which explicitly models deep latent space features using a robust kernel representation, providing robust performance on previously unseen dose reduction factors.","Additional constraints on the information content of deep latent features allow for tuning in-distribution accuracy and generalisability.","Tests with out-of-distribution dose reduction factors ranging from $\\times 10$ to $\\times 1000$ and with both paired and unpaired MR, demonstrate significantly improved performance relative to conventional deep-learning methods trained using the same data.","Code:https://github.com/cameronPain"],"url":"http://arxiv.org/abs/2409.06198v1"}
{"created":"2024-09-10 03:57:30","title":"UdeerLID+: Integrating LiDAR, Image, and Relative Depth with Semi-Supervised","abstract":"Road segmentation is a critical task for autonomous driving systems, requiring accurate and robust methods to classify road surfaces from various environmental data. Our work introduces an innovative approach that integrates LiDAR point cloud data, visual image, and relative depth maps derived from images. The integration of multiple data sources in road segmentation presents both opportunities and challenges. One of the primary challenges is the scarcity of large-scale, accurately labeled datasets that are necessary for training robust deep learning models. To address this, we have developed the [UdeerLID+] framework under a semi-supervised learning paradigm. Experiments results on KITTI datasets validate the superior performance.","sentences":["Road segmentation is a critical task for autonomous driving systems, requiring accurate and robust methods to classify road surfaces from various environmental data.","Our work introduces an innovative approach that integrates LiDAR point cloud data, visual image, and relative depth maps derived from images.","The integration of multiple data sources in road segmentation presents both opportunities and challenges.","One of the primary challenges is the scarcity of large-scale, accurately labeled datasets that are necessary for training robust deep learning models.","To address this, we have developed the [UdeerLID+] framework under a semi-supervised learning paradigm.","Experiments results on KITTI datasets validate the superior performance."],"url":"http://arxiv.org/abs/2409.06197v1"}
{"created":"2024-09-10 03:43:26","title":"NOVI : Chatbot System for University Novice with BERT and LLMs","abstract":"To mitigate the difficulties of university freshmen in adapting to university life, we developed NOVI, a chatbot system based on GPT-4o. This system utilizes post and comment data from SKKU 'Everytime', a university community site. Developed using LangChain, NOVI's performance has been evaluated with a BLEU score, Perplexity score, ROUGE-1 score, ROUGE-2 score, ROUGE-L score and METEOR score. This approach is not only limited to help university freshmen but is also expected to help various people adapting to new environments with different data. This research explores the development and potential application of new educational technology tools, contributing to easier social adaptation for beginners and settling a foundation for future advancement in LLM studies.","sentences":["To mitigate the difficulties of university freshmen in adapting to university life, we developed NOVI, a chatbot system based on GPT-4o.","This system utilizes post and comment data from SKKU 'Everytime', a university community site.","Developed using LangChain, NOVI's performance has been evaluated with a BLEU score, Perplexity score, ROUGE-1 score, ROUGE-2 score, ROUGE-L score and METEOR score.","This approach is not only limited to help university freshmen but is also expected to help various people adapting to new environments with different data.","This research explores the development and potential application of new educational technology tools, contributing to easier social adaptation for beginners and settling a foundation for future advancement in LLM studies."],"url":"http://arxiv.org/abs/2409.06192v1"}
{"created":"2024-09-10 03:39:08","title":"MyGo: Consistent and Controllable Multi-View Driving Video Generation with Camera Control","abstract":"High-quality driving video generation is crucial for providing training data for autonomous driving models. However, current generative models rarely focus on enhancing camera motion control under multi-view tasks, which is essential for driving video generation. Therefore, we propose MyGo, an end-to-end framework for video generation, introducing motion of onboard cameras as conditions to make progress in camera controllability and multi-view consistency. MyGo employs additional plug-in modules to inject camera parameters into the pre-trained video diffusion model, which retains the extensive knowledge of the pre-trained model as much as possible. Furthermore, we use epipolar constraints and neighbor view information during the generation process of each view to enhance spatial-temporal consistency. Experimental results show that MyGo has achieved state-of-the-art results in both general camera-controlled video generation and multi-view driving video generation tasks, which lays the foundation for more accurate environment simulation in autonomous driving. Project page: \\href{https://metadrivescape.github.io/papers_project/MyGo/page.html}{metadrivescape.github.io/papers\\_project/MyGo/page.html}","sentences":["High-quality driving video generation is crucial for providing training data for autonomous driving models.","However, current generative models rarely focus on enhancing camera motion control under multi-view tasks, which is essential for driving video generation.","Therefore, we propose MyGo, an end-to-end framework for video generation, introducing motion of onboard cameras as conditions to make progress in camera controllability and multi-view consistency.","MyGo employs additional plug-in modules to inject camera parameters into the pre-trained video diffusion model, which retains the extensive knowledge of the pre-trained model as much as possible.","Furthermore, we use epipolar constraints and neighbor view information during the generation process of each view to enhance spatial-temporal consistency.","Experimental results show that MyGo has achieved state-of-the-art results in both general camera-controlled video generation and multi-view driving video generation tasks, which lays the foundation for more accurate environment simulation in autonomous driving.","Project page: \\href{https://metadrivescape.github.io/papers_project/MyGo/page.html}{metadrivescape.github.io/papers\\_project/MyGo/page.html}"],"url":"http://arxiv.org/abs/2409.06189v1"}
{"created":"2024-09-10 03:31:18","title":"Bottleneck-based Encoder-decoder ARchitecture (BEAR) for Learning Unbiased Consumer-to-Consumer Image Representations","abstract":"Unbiased representation learning is still an object of study under specific applications and contexts. Novel architectures are usually crafted to resolve particular problems using mixtures of fundamental pieces. This paper presents different image feature extraction mechanisms that work together with residual connections to encode perceptual image information in an autoencoder configuration. We use image data that aims to support a larger research agenda dealing with issues regarding criminal activity in consumer-to-consumer online platforms. Preliminary results suggest that the proposed architecture can learn rich spaces using ours and other image datasets resolving important challenges that are identified.","sentences":["Unbiased representation learning is still an object of study under specific applications and contexts.","Novel architectures are usually crafted to resolve particular problems using mixtures of fundamental pieces.","This paper presents different image feature extraction mechanisms that work together with residual connections to encode perceptual image information in an autoencoder configuration.","We use image data that aims to support a larger research agenda dealing with issues regarding criminal activity in consumer-to-consumer online platforms.","Preliminary results suggest that the proposed architecture can learn rich spaces using ours and other image datasets resolving important challenges that are identified."],"url":"http://arxiv.org/abs/2409.06187v1"}
{"created":"2024-09-10 03:25:24","title":"EDADepth: Enhanced Data Augmentation for Monocular Depth Estimation","abstract":"Due to their text-to-image synthesis feature, diffusion models have recently seen a rise in visual perception tasks, such as depth estimation. The lack of good-quality datasets makes the extraction of a fine-grain semantic context challenging for the diffusion models. The semantic context with fewer details further worsens the process of creating effective text embeddings that will be used as input for diffusion models. In this paper, we propose a novel EDADepth, an enhanced data augmentation method to estimate monocular depth without using additional training data. We use Swin2SR, a super-resolution model, to enhance the quality of input images. We employ the BEiT pre-trained semantic segmentation model for better extraction of text embeddings. We introduce BLIP-2 tokenizer to generate tokens from these text embeddings. The novelty of our approach is the introduction of Swin2SR, the BEiT model, and the BLIP-2 tokenizer in the diffusion-based pipeline for the monocular depth estimation. Our model achieves state-of-the-art results (SOTA) on the {\\delta}3 metric on NYUv2 and KITTI datasets. It also achieves results comparable to those of the SOTA models in the RMSE and REL metrics. Finally, we also show improvements in the visualization of the estimated depth compared to the SOTA diffusion-based monocular depth estimation models. Code: https://github.com/edadepthmde/EDADepth_ICMLA.","sentences":["Due to their text-to-image synthesis feature, diffusion models have recently seen a rise in visual perception tasks, such as depth estimation.","The lack of good-quality datasets makes the extraction of a fine-grain semantic context challenging for the diffusion models.","The semantic context with fewer details further worsens the process of creating effective text embeddings that will be used as input for diffusion models.","In this paper, we propose a novel EDADepth, an enhanced data augmentation method to estimate monocular depth without using additional training data.","We use Swin2SR, a super-resolution model, to enhance the quality of input images.","We employ the BEiT pre-trained semantic segmentation model for better extraction of text embeddings.","We introduce BLIP-2 tokenizer to generate tokens from these text embeddings.","The novelty of our approach is the introduction of Swin2SR, the BEiT model, and the BLIP-2 tokenizer in the diffusion-based pipeline for the monocular depth estimation.","Our model achieves state-of-the-art results (SOTA) on the {\\delta}3 metric on NYUv2 and KITTI datasets.","It also achieves results comparable to those of the SOTA models in the RMSE and REL metrics.","Finally, we also show improvements in the visualization of the estimated depth compared to the SOTA diffusion-based monocular depth estimation models.","Code: https://github.com/edadepthmde/EDADepth_ICMLA."],"url":"http://arxiv.org/abs/2409.06183v1"}
{"created":"2024-09-10 03:02:39","title":"Loss Distillation via Gradient Matching for Point Cloud Completion with Weighted Chamfer Distance","abstract":"3D point clouds enhanced the robot's ability to perceive the geometrical information of the environments, making it possible for many downstream tasks such as grasp pose detection and scene understanding. The performance of these tasks, though, heavily relies on the quality of data input, as incomplete can lead to poor results and failure cases. Recent training loss functions designed for deep learning-based point cloud completion, such as Chamfer distance (CD) and its variants (\\eg HyperCD ), imply a good gradient weighting scheme can significantly boost performance. However, these CD-based loss functions usually require data-related parameter tuning, which can be time-consuming for data-extensive tasks. To address this issue, we aim to find a family of weighted training losses ({\\em weighted CD}) that requires no parameter tuning. To this end, we propose a search scheme, {\\em Loss Distillation via Gradient Matching}, to find good candidate loss functions by mimicking the learning behavior in backpropagation between HyperCD and weighted CD. Once this is done, we propose a novel bilevel optimization formula to train the backbone network based on the weighted CD loss. We observe that: (1) with proper weighted functions, the weighted CD can always achieve similar performance to HyperCD, and (2) the Landau weighted CD, namely {\\em Landau CD}, can outperform HyperCD for point cloud completion and lead to new state-of-the-art results on several benchmark datasets. {\\it Our demo code is available at \\url{https://github.com/Zhang-VISLab/IROS2024-LossDistillationWeightedCD}.}","sentences":["3D point clouds enhanced the robot's ability to perceive the geometrical information of the environments, making it possible for many downstream tasks such as grasp pose detection and scene understanding.","The performance of these tasks, though, heavily relies on the quality of data input, as incomplete can lead to poor results and failure cases.","Recent training loss functions designed for deep learning-based point cloud completion, such as Chamfer distance (CD) and its variants (\\eg HyperCD ), imply a good gradient weighting scheme can significantly boost performance.","However, these CD-based loss functions usually require data-related parameter tuning, which can be time-consuming for data-extensive tasks.","To address this issue, we aim to find a family of weighted training losses ({\\em weighted CD}) that requires no parameter tuning.","To this end, we propose a search scheme, {\\em Loss Distillation via Gradient Matching}, to find good candidate loss functions by mimicking the learning behavior in backpropagation between HyperCD and weighted CD.","Once this is done, we propose a novel bilevel optimization formula to train the backbone network based on the weighted CD loss.","We observe that: (1) with proper weighted functions, the weighted CD can always achieve similar performance to HyperCD, and (2) the Landau weighted CD, namely {\\em Landau CD}, can outperform HyperCD for point cloud completion and lead to new state-of-the-art results on several benchmark datasets.","{\\it Our demo code is available at \\url{https://github.com/Zhang-VISLab/IROS2024-LossDistillationWeightedCD}.}"],"url":"http://arxiv.org/abs/2409.06171v1"}
{"created":"2024-09-10 02:21:29","title":"MCDGLN: Masked Connection-based Dynamic Graph Learning Network for Autism Spectrum Disorder","abstract":"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by complex physiological processes. Previous research has predominantly focused on static cerebral interactions, often neglecting the brain's dynamic nature and the challenges posed by network noise. To address these gaps, we introduce the Masked Connection-based Dynamic Graph Learning Network (MCDGLN). Our approach first segments BOLD signals using sliding temporal windows to capture dynamic brain characteristics. We then employ a specialized weighted edge aggregation (WEA) module, which uses the cross convolution with channel-wise element-wise convolutional kernel, to integrate dynamic functional connectivity and to isolating task-relevant connections. This is followed by topological feature extraction via a hierarchical graph convolutional network (HGCN), with key attributes highlighted by a self-attention module. Crucially, we refine static functional connections using a customized task-specific mask, reducing noise and pruning irrelevant links. The attention-based connection encoder (ACE) then enhances critical connections and compresses static features. The combined features are subsequently used for classification. Applied to the Autism Brain Imaging Data Exchange I (ABIDE I) dataset, our framework achieves a 73.3\\% classification accuracy between ASD and Typical Control (TC) groups among 1,035 subjects. The pivotal roles of WEA and ACE in refining connectivity and enhancing classification accuracy underscore their importance in capturing ASD-specific features, offering new insights into the disorder.","sentences":["Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by complex physiological processes.","Previous research has predominantly focused on static cerebral interactions, often neglecting the brain's dynamic nature and the challenges posed by network noise.","To address these gaps, we introduce the Masked Connection-based Dynamic Graph Learning Network (MCDGLN).","Our approach first segments BOLD signals using sliding temporal windows to capture dynamic brain characteristics.","We then employ a specialized weighted edge aggregation (WEA) module, which uses the cross convolution with channel-wise element-wise convolutional kernel, to integrate dynamic functional connectivity and to isolating task-relevant connections.","This is followed by topological feature extraction via a hierarchical graph convolutional network (HGCN), with key attributes highlighted by a self-attention module.","Crucially, we refine static functional connections using a customized task-specific mask, reducing noise and pruning irrelevant links.","The attention-based connection encoder (ACE) then enhances critical connections and compresses static features.","The combined features are subsequently used for classification.","Applied to the Autism Brain Imaging Data Exchange","I (ABIDE I) dataset, our framework achieves a 73.3\\% classification accuracy between ASD and Typical Control (TC) groups among 1,035 subjects.","The pivotal roles of WEA and ACE in refining connectivity and enhancing classification accuracy underscore their importance in capturing ASD-specific features, offering new insights into the disorder."],"url":"http://arxiv.org/abs/2409.06163v1"}
{"created":"2024-09-10 01:57:57","title":"UniLearn: Enhancing Dynamic Facial Expression Recognition through Unified Pre-Training and Fine-Tuning on Images and Videos","abstract":"Dynamic facial expression recognition (DFER) is essential for understanding human emotions and behavior. However, conventional DFER methods, which primarily use dynamic facial data, often underutilize static expression images and their labels, limiting their performance and robustness. To overcome this, we introduce UniLearn, a novel unified learning paradigm that integrates static facial expression recognition (SFER) data to enhance DFER task. UniLearn employs a dual-modal self-supervised pre-training method, leveraging both facial expression images and videos to enhance a ViT model's spatiotemporal representation capability. Then, the pre-trained model is fine-tuned on both static and dynamic expression datasets using a joint fine-tuning strategy. To prevent negative transfer during joint fine-tuning, we introduce an innovative Mixture of Adapter Experts (MoAE) module that enables task-specific knowledge acquisition and effectively integrates information from both static and dynamic expression data. Extensive experiments demonstrate UniLearn's effectiveness in leveraging complementary information from static and dynamic facial data, leading to more accurate and robust DFER. UniLearn consistently achieves state-of-the-art performance on FERV39K, MAFW, and DFEW benchmarks, with weighted average recall (WAR) of 53.65\\%, 58.44\\%, and 76.68\\%, respectively. The source code and model weights will be publicly available at \\url{https://github.com/MSA-LMC/UniLearn}.","sentences":["Dynamic facial expression recognition (DFER) is essential for understanding human emotions and behavior.","However, conventional DFER methods, which primarily use dynamic facial data, often underutilize static expression images and their labels, limiting their performance and robustness.","To overcome this, we introduce UniLearn, a novel unified learning paradigm that integrates static facial expression recognition (SFER) data to enhance DFER task.","UniLearn employs a dual-modal self-supervised pre-training method, leveraging both facial expression images and videos to enhance a ViT model's spatiotemporal representation capability.","Then, the pre-trained model is fine-tuned on both static and dynamic expression datasets using a joint fine-tuning strategy.","To prevent negative transfer during joint fine-tuning, we introduce an innovative Mixture of Adapter Experts (MoAE) module that enables task-specific knowledge acquisition and effectively integrates information from both static and dynamic expression data.","Extensive experiments demonstrate UniLearn's effectiveness in leveraging complementary information from static and dynamic facial data, leading to more accurate and robust DFER.","UniLearn consistently achieves state-of-the-art performance on FERV39K, MAFW, and DFEW benchmarks, with weighted average recall (WAR) of 53.65\\%, 58.44\\%, and 76.68\\%, respectively.","The source code and model weights will be publicly available at \\url{https://github.com/MSA-LMC/UniLearn}."],"url":"http://arxiv.org/abs/2409.06154v1"}
{"created":"2024-09-10 01:42:10","title":"Configuration Interaction Guided Sampling with Interpretable Restricted Boltzmann Machine","abstract":"We propose a data-driven approach using a Restricted Boltzmann Machine (RBM) to solve the Schr\\\"odinger equation in configuration space. Traditional Configuration Interaction (CI) methods, while powerful, are computationally expensive due to the large number of determinants required. Our approach leverages RBMs to efficiently identify and sample the most significant determinants, accelerating convergence and reducing computational cost. This method achieves up to 99.99\\% of the correlation energy even by four orders of magnitude less determinants compared to full CI calculations and up to two orders of magnitude less than previous state of the art works. Additionally, our study demonstrate that the RBM can learn the underlying quantum properties, providing more detail insights than other methods . This innovative data-driven approach offers a promising tool for quantum chemistry, enhancing both efficiency and understanding of complex systems.","sentences":["We propose a data-driven approach using a Restricted Boltzmann Machine (RBM) to solve the Schr\\\"odinger equation in configuration space.","Traditional Configuration Interaction (CI) methods, while powerful, are computationally expensive due to the large number of determinants required.","Our approach leverages RBMs to efficiently identify and sample the most significant determinants, accelerating convergence and reducing computational cost.","This method achieves up to 99.99\\% of the correlation energy even by four orders of magnitude less determinants compared to full CI calculations and up to two orders of magnitude less than previous state of the art works.","Additionally, our study demonstrate that the RBM can learn the underlying quantum properties, providing more detail insights than other methods .","This innovative data-driven approach offers a promising tool for quantum chemistry, enhancing both efficiency and understanding of complex systems."],"url":"http://arxiv.org/abs/2409.06146v1"}
{"created":"2024-09-10 01:30:48","title":"The Lynchpin of In-Memory Computing: A Benchmarking Framework for Vector-Matrix Multiplication in RRAMs","abstract":"The Von Neumann bottleneck, a fundamental challenge in conventional computer architecture, arises from the inability to execute fetch and data operations simultaneously due to a shared bus linking processing and memory units. This bottleneck significantly limits system performance, increases energy consumption, and exacerbates computational complexity. Emerging technologies such as Resistive Random Access Memories (RRAMs), leveraging crossbar arrays, offer promising alternatives for addressing the demands of data-intensive computational tasks through in-memory computing of analog vector-matrix multiplication (VMM) operations. However, the propagation of errors due to device and circuit-level imperfections remains a significant challenge. In this study, we introduce MELISO (In-Memory Linear Solver), a comprehensive end-to-end VMM benchmarking framework tailored for RRAM-based systems. MELISO evaluates the error propagation in VMM operations, analyzing the impact of RRAM device metrics on error magnitude and distribution. This paper introduces the MELISO framework and demonstrates its utility in characterizing and mitigating VMM error propagation using state-of-the-art RRAM device metrics.","sentences":["The Von Neumann bottleneck, a fundamental challenge in conventional computer architecture, arises from the inability to execute fetch and data operations simultaneously due to a shared bus linking processing and memory units.","This bottleneck significantly limits system performance, increases energy consumption, and exacerbates computational complexity.","Emerging technologies such as Resistive Random Access Memories (RRAMs), leveraging crossbar arrays, offer promising alternatives for addressing the demands of data-intensive computational tasks through in-memory computing of analog vector-matrix multiplication (VMM) operations.","However, the propagation of errors due to device and circuit-level imperfections remains a significant challenge.","In this study, we introduce MELISO (In-Memory Linear Solver), a comprehensive end-to-end VMM benchmarking framework tailored for RRAM-based systems.","MELISO evaluates the error propagation in VMM operations, analyzing the impact of RRAM device metrics on error magnitude and distribution.","This paper introduces the MELISO framework and demonstrates its utility in characterizing and mitigating VMM error propagation using state-of-the-art RRAM device metrics."],"url":"http://arxiv.org/abs/2409.06140v1"}
{"created":"2024-09-10 00:59:18","title":"Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review","abstract":"Large Language Model (LLM) pretraining traditionally relies on autoregressive language modeling on randomly sampled data blocks from web-scale datasets. We take inspiration from human learning techniques like spaced repetition to hypothesize that random data sampling for LLMs leads to high training cost and low quality models which tend to forget data. In order to effectively commit web-scale information to long-term memory, we propose the LFR (Learn, Focus, and Review) pedagogy, a new dynamic training paradigm which focuses and repeatedly reviews complex data blocks at systematic intervals based on the model's learning pace and progress. LFR records the model perplexities for different data blocks and frequently revisits blocks with higher perplexity which are more likely to be forgotten. We pretrain the GPT-2 models (124M - 1.5B) from scratch on the OpenWebText dataset using LFR. We test on downstream tasks from the language modeling, question answering, translation, and problem solving domains to achieve consistently lower perplexity and higher accuracy than the baseline OpenAI models, while obtaining a 20x pretraining speed-up.","sentences":["Large Language Model (LLM) pretraining traditionally relies on autoregressive language modeling on randomly sampled data blocks from web-scale datasets.","We take inspiration from human learning techniques like spaced repetition to hypothesize that random data sampling for LLMs leads to high training cost and low quality models which tend to forget data.","In order to effectively commit web-scale information to long-term memory, we propose the LFR (Learn, Focus, and Review) pedagogy, a new dynamic training paradigm which focuses and repeatedly reviews complex data blocks at systematic intervals based on the model's learning pace and progress.","LFR records the model perplexities for different data blocks and frequently revisits blocks with higher perplexity which are more likely to be forgotten.","We pretrain the GPT-2 models (124M - 1.5B) from scratch on the OpenWebText dataset using LFR.","We test on downstream tasks from the language modeling, question answering, translation, and problem solving domains to achieve consistently lower perplexity and higher accuracy than the baseline OpenAI models, while obtaining a 20x pretraining speed-up."],"url":"http://arxiv.org/abs/2409.06131v1"}
{"created":"2024-09-10 00:24:59","title":"Contrastive Federated Learning with Tabular Data Silos","abstract":"Learning from data silos is a difficult task for organizations that need to obtain knowledge of objects that appeared in multiple independent data silos. Objects in multi-organizations, such as government agents, are referred by different identifiers, such as driver license, passport number, and tax file number. The data distributions in data silos are mostly non-IID (Independently and Identically Distributed), labelless, and vertically partitioned (i.e., having different attributes). Privacy concerns harden the above issues. Conditions inhibit enthusiasm for collaborative work. While Federated Learning (FL) has been proposed to address these issues, the difficulty of labeling, namely, label costliness, often hinders optimal model performance. A potential solution lies in contrastive learning, an unsupervised self-learning technique to represent semantic data by contrasting similar data pairs. However, contrastive learning is currently not designed to handle tabular data silos that existed within multiple organizations where data linkage by quasi identifiers are needed. To address these challenges, we propose using semi-supervised contrastive federated learning, which we refer to as Contrastive Federated Learning with Data Silos (CFL). Our approach tackles the aforementioned issues with an integrated solution. Our experimental results demonstrate that CFL outperforms current methods in addressing these challenges and providing improvements in accuracy. Additionally, we present positive results that showcase the advantages of our contrastive federated learning approach in complex client environments.","sentences":["Learning from data silos is a difficult task for organizations that need to obtain knowledge of objects that appeared in multiple independent data silos.","Objects in multi-organizations, such as government agents, are referred by different identifiers, such as driver license, passport number, and tax file number.","The data distributions in data silos are mostly non-IID (Independently and Identically Distributed), labelless, and vertically partitioned (i.e., having different attributes).","Privacy concerns harden the above issues.","Conditions inhibit enthusiasm for collaborative work.","While Federated Learning (FL) has been proposed to address these issues, the difficulty of labeling, namely, label costliness, often hinders optimal model performance.","A potential solution lies in contrastive learning, an unsupervised self-learning technique to represent semantic data by contrasting similar data pairs.","However, contrastive learning is currently not designed to handle tabular data silos that existed within multiple organizations where data linkage by quasi identifiers are needed.","To address these challenges, we propose using semi-supervised contrastive federated learning, which we refer to as Contrastive Federated Learning with Data Silos (CFL).","Our approach tackles the aforementioned issues with an integrated solution.","Our experimental results demonstrate that CFL outperforms current methods in addressing these challenges and providing improvements in accuracy.","Additionally, we present positive results that showcase the advantages of our contrastive federated learning approach in complex client environments."],"url":"http://arxiv.org/abs/2409.06123v1"}
{"created":"2024-09-09 23:34:24","title":"PaRCE: Probabilistic and Reconstruction-Based Competency Estimation for Safe Navigation Under Perception Uncertainty","abstract":"Perception-based navigation systems are useful for unmanned ground vehicle (UGV) navigation in complex terrains, where traditional depth-based navigation schemes are insufficient. However, these data-driven methods are highly dependent on their training data and can fail in surprising and dramatic ways with little warning. To ensure the safety of the vehicle and the surrounding environment, it is imperative that the navigation system is able to recognize the predictive uncertainty of the perception model and respond safely and effectively in the face of uncertainty. In an effort to enable safe navigation under perception uncertainty, we develop a probabilistic and reconstruction-based competency estimation (PaRCE) method to estimate the model's level of familiarity with an input image as a whole and with specific regions in the image. We find that the overall competency score can correctly predict correctly classified, misclassified, and out-of-distribution (OOD) samples. We also confirm that the regional competency maps can accurately distinguish between familiar and unfamiliar regions across images. We then use this competency information to develop a planning and control scheme that enables effective navigation while maintaining a low probability of error. We find that the competency-aware scheme greatly reduces the number of collisions with unfamiliar obstacles, compared to a baseline controller with no competency awareness. Furthermore, the regional competency information is very valuable in enabling efficient navigation.","sentences":["Perception-based navigation systems are useful for unmanned ground vehicle (UGV) navigation in complex terrains, where traditional depth-based navigation schemes are insufficient.","However, these data-driven methods are highly dependent on their training data and can fail in surprising and dramatic ways with little warning.","To ensure the safety of the vehicle and the surrounding environment, it is imperative that the navigation system is able to recognize the predictive uncertainty of the perception model and respond safely and effectively in the face of uncertainty.","In an effort to enable safe navigation under perception uncertainty, we develop a probabilistic and reconstruction-based competency estimation (PaRCE) method to estimate the model's level of familiarity with an input image as a whole and with specific regions in the image.","We find that the overall competency score can correctly predict correctly classified, misclassified, and out-of-distribution (OOD) samples.","We also confirm that the regional competency maps can accurately distinguish between familiar and unfamiliar regions across images.","We then use this competency information to develop a planning and control scheme that enables effective navigation while maintaining a low probability of error.","We find that the competency-aware scheme greatly reduces the number of collisions with unfamiliar obstacles, compared to a baseline controller with no competency awareness.","Furthermore, the regional competency information is very valuable in enabling efficient navigation."],"url":"http://arxiv.org/abs/2409.06111v1"}
{"created":"2024-09-09 23:11:46","title":"LSE-NeRF: Learning Sensor Modeling Errors for Deblured Neural Radiance Fields with RGB-Event Stereo","abstract":"We present a method for reconstructing a clear Neural Radiance Field (NeRF) even with fast camera motions. To address blur artifacts, we leverage both (blurry) RGB images and event camera data captured in a binocular configuration. Importantly, when reconstructing our clear NeRF, we consider the camera modeling imperfections that arise from the simple pinhole camera model as learned embeddings for each camera measurement, and further learn a mapper that connects event camera measurements with RGB data. As no previous dataset exists for our binocular setting, we introduce an event camera dataset with captures from a 3D-printed stereo configuration between RGB and event cameras. Empirically, we evaluate our introduced dataset and EVIMOv2 and show that our method leads to improved reconstructions. Our code and dataset are available at https://github.com/ubc-vision/LSENeRF.","sentences":["We present a method for reconstructing a clear Neural Radiance Field (NeRF) even with fast camera motions.","To address blur artifacts, we leverage both (blurry) RGB images and event camera data captured in a binocular configuration.","Importantly, when reconstructing our clear NeRF, we consider the camera modeling imperfections that arise from the simple pinhole camera model as learned embeddings for each camera measurement, and further learn a mapper that connects event camera measurements with RGB data.","As no previous dataset exists for our binocular setting, we introduce an event camera dataset with captures from a 3D-printed stereo configuration between RGB and event cameras.","Empirically, we evaluate our introduced dataset and EVIMOv2 and show that our method leads to improved reconstructions.","Our code and dataset are available at https://github.com/ubc-vision/LSENeRF."],"url":"http://arxiv.org/abs/2409.06104v1"}
{"created":"2024-09-09 22:16:48","title":"Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer","abstract":"Music timbre transfer is a challenging task that involves modifying the timbral characteristics of an audio signal while preserving its melodic structure. In this paper, we propose a novel method based on dual diffusion bridges, trained using the CocoChorales Dataset, which consists of unpaired monophonic single-instrument audio data. Each diffusion model is trained on a specific instrument with a Gaussian prior. During inference, a model is designated as the source model to map the input audio to its corresponding Gaussian prior, and another model is designated as the target model to reconstruct the target audio from this Gaussian prior, thereby facilitating timbre transfer. We compare our approach against existing unsupervised timbre transfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental results demonstrate that our method achieves both better Fr\\'echet Audio Distance (FAD) and melody preservation, as reflected by lower pitch distances (DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise level from the Gaussian prior, $\\sigma$, can be adjusted to control the degree of melody preservation and amount of timbre transferred.","sentences":["Music timbre transfer is a challenging task that involves modifying the timbral characteristics of an audio signal while preserving its melodic structure.","In this paper, we propose a novel method based on dual diffusion bridges, trained using the CocoChorales Dataset, which consists of unpaired monophonic single-instrument audio data.","Each diffusion model is trained on a specific instrument with a Gaussian prior.","During inference, a model is designated as the source model to map the input audio to its corresponding Gaussian prior, and another model is designated as the target model to reconstruct the target audio from this Gaussian prior, thereby facilitating timbre transfer.","We compare our approach against existing unsupervised timbre transfer models such as VAEGAN and Gaussian Flow Bridges (GFB).","Experimental results demonstrate that our method achieves both better Fr\\'echet Audio Distance (FAD) and melody preservation, as reflected by lower pitch distances (DPD) compared to VAEGAN and GFB.","Additionally, we discover that the noise level from the Gaussian prior, $\\sigma$, can be adjusted to control the degree of melody preservation and amount of timbre transferred."],"url":"http://arxiv.org/abs/2409.06096v1"}
{"created":"2024-09-09 22:00:00","title":"Harmonic Chain Barcode and Stability","abstract":"The persistence barcode is a topological descriptor of data that plays a fundamental role in topological data analysis. Given a filtration of the space of data, a persistence barcode tracks the evolution of its homological features. In this paper, we introduce a novel type of barcode, referred to as the canonical barcode of harmonic chains, or harmonic chain barcode for short, which tracks the evolution of harmonic chains. As our main result, we show that the harmonic chain barcode is stable and it captures both geometric and topological information of data. Moreover, given a filtration of a simplicial complex of size $n$ with $m$ time steps, we can compute its harmonic chain barcode in $O(m^2n^{\\omega} + mn^3)$ time, where $n^\\omega$ is the matrix multiplication time. Consequently, a harmonic chain barcode can be utilized in applications in which a persistence barcode is applicable, such as feature vectorization and machine learning. Our work provides strong evidence in a growing list of literature that geometric (not just topological) information can be recovered from a persistence filtration.","sentences":["The persistence barcode is a topological descriptor of data that plays a fundamental role in topological data analysis.","Given a filtration of the space of data, a persistence barcode tracks the evolution of its homological features.","In this paper, we introduce a novel type of barcode, referred to as the canonical barcode of harmonic chains, or harmonic chain barcode for short, which tracks the evolution of harmonic chains.","As our main result, we show that the harmonic chain barcode is stable and it captures both geometric and topological information of data.","Moreover, given a filtration of a simplicial complex of size $n$ with $m$ time steps, we can compute its harmonic chain barcode in $O(m^2n^{\\omega} + mn^3)$ time, where $n^\\omega$ is the matrix multiplication time.","Consequently, a harmonic chain barcode can be utilized in applications in which a persistence barcode is applicable, such as feature vectorization and machine learning.","Our work provides strong evidence in a growing list of literature that geometric (not just topological) information can be recovered from a persistence filtration."],"url":"http://arxiv.org/abs/2409.06093v1"}
{"created":"2024-09-09 21:59:27","title":"Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity","abstract":"Multitask learning is a widely used paradigm for training models on diverse tasks, with applications ranging from graph neural networks to language model fine-tuning. Since tasks may interfere with each other, a key notion for modeling their relationships is task affinity. This includes pairwise task affinity, computed among pairs of tasks, and higher-order affinity, computed among subsets of tasks. Naively computing either of them requires repeatedly training on data from various task combinations, which is computationally intensive. We present a new algorithm Grad-TAG that can estimate task affinities without this repeated training.   The key idea of Grad-TAG is to train a \"base\" model for all tasks and then use a linearization technique to estimate the loss of the model for a specific task combination. The linearization works by computing a gradient-based approximation of the loss, using low-dimensional projections of gradients as features in a logistic regression to predict labels for the task combination. We show that the linearized model can provably approximate the loss when the gradient-based approximation is accurate, and also empirically verify that on several large models. Then, given the estimated task affinity, we design a semi-definite program for clustering similar tasks by maximizing the average density of clusters.   We evaluate Grad-TAG's performance across seven datasets, including multi-label classification on graphs, and instruction fine-tuning of language models. Our task affinity estimates are within 2.7% distance to the true affinities while needing only 3% of FLOPs in full training. On our largest graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates within 5% distance to the true affinities, using only 112 GPU hours. Our results show that Grad-TAG achieves excellent performance and runtime tradeoffs compared to existing approaches.","sentences":["Multitask learning is a widely used paradigm for training models on diverse tasks, with applications ranging from graph neural networks to language model fine-tuning.","Since tasks may interfere with each other, a key notion for modeling their relationships is task affinity.","This includes pairwise task affinity, computed among pairs of tasks, and higher-order affinity, computed among subsets of tasks.","Naively computing either of them requires repeatedly training on data from various task combinations, which is computationally intensive.","We present a new algorithm Grad-TAG that can estimate task affinities without this repeated training.   ","The key idea of Grad-TAG is to train a \"base\" model for all tasks and then use a linearization technique to estimate the loss of the model for a specific task combination.","The linearization works by computing a gradient-based approximation of the loss, using low-dimensional projections of gradients as features in a logistic regression to predict labels for the task combination.","We show that the linearized model can provably approximate the loss when the gradient-based approximation is accurate, and also empirically verify that on several large models.","Then, given the estimated task affinity, we design a semi-definite program for clustering similar tasks by maximizing the average density of clusters.   ","We evaluate Grad-TAG's performance across seven datasets, including multi-label classification on graphs, and instruction fine-tuning of language models.","Our task affinity estimates are within 2.7% distance to the true affinities while needing only 3% of FLOPs in full training.","On our largest graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates within 5% distance to the true affinities, using only 112 GPU hours.","Our results show that Grad-TAG achieves excellent performance and runtime tradeoffs compared to existing approaches."],"url":"http://arxiv.org/abs/2409.06091v1"}
{"created":"2024-09-09 21:51:09","title":"Hevelius Report: Visualizing Web-Based Mobility Test Data For Clinical Decision and Learning Support","abstract":"Hevelius, a web-based computer mouse test, measures arm movement and has been shown to accurately evaluate severity for patients with Parkinson's disease and ataxias. A Hevelius session produces 32 numeric features, which may be hard to interpret, especially in time-constrained clinical settings. This work aims to support clinicians (and other stakeholders) in interpreting and connecting Hevelius features to clinical concepts. Through an iterative design process, we developed a visualization tool (Hevelius Report) that (1) abstracts six clinically relevant concepts from 32 features, (2) visualizes patient test results, and compares them to results from healthy controls and other patients, and (3) is an interactive app to meet the specific needs in different usage scenarios. Then, we conducted a preliminary user study through an online interview with three clinicians who were not involved in the project. They expressed interest in using Hevelius Report, especially for identifying subtle changes in their patients' mobility that are hard to capture with existing clinical tests. Future work will integrate the visualization tool into the current clinical workflow of a neurology team and conduct systematic evaluations of the tool's usefulness, usability, and effectiveness. Hevelius Report represents a promising solution for analyzing fine-motor test results and monitoring patients' conditions and progressions.","sentences":["Hevelius, a web-based computer mouse test, measures arm movement and has been shown to accurately evaluate severity for patients with Parkinson's disease and ataxias.","A Hevelius session produces 32 numeric features, which may be hard to interpret, especially in time-constrained clinical settings.","This work aims to support clinicians (and other stakeholders) in interpreting and connecting Hevelius features to clinical concepts.","Through an iterative design process, we developed a visualization tool (Hevelius Report) that (1) abstracts six clinically relevant concepts from 32 features, (2) visualizes patient test results, and compares them to results from healthy controls and other patients, and (3) is an interactive app to meet the specific needs in different usage scenarios.","Then, we conducted a preliminary user study through an online interview with three clinicians who were not involved in the project.","They expressed interest in using Hevelius Report, especially for identifying subtle changes in their patients' mobility that are hard to capture with existing clinical tests.","Future work will integrate the visualization tool into the current clinical workflow of a neurology team and conduct systematic evaluations of the tool's usefulness, usability, and effectiveness.","Hevelius Report represents a promising solution for analyzing fine-motor test results and monitoring patients' conditions and progressions."],"url":"http://arxiv.org/abs/2409.06088v1"}
{"created":"2024-09-09 21:36:08","title":"Symmetry constrained neural networks for detection and localization of damage in metal plates","abstract":"The present paper is concerned with deep learning techniques applied to detection and localization of damage in a thin aluminum plate. We used data generated on a tabletop apparatus by mounting to the plate four piezoelectric transducers, each of which took turn to generate a Lamb wave that then traversed the region of interest before being received by the remaining three sensors. On training a neural network to analyze time-series data of the material response, which displayed damage-reflective features whenever the plate guided waves interacted with a contact load, we achieved a model that detected with greater than 99% accuracy in addition to a model that localized with $3.14 \\pm 0.21$ mm mean distance error and captured more than 60% of test examples within the diffraction limit. For each task, the best-performing model was designed according to the inductive bias that our transducers were both similar and arranged in a square pattern on a nearly uniform plate.","sentences":["The present paper is concerned with deep learning techniques applied to detection and localization of damage in a thin aluminum plate.","We used data generated on a tabletop apparatus by mounting to the plate four piezoelectric transducers, each of which took turn to generate a Lamb wave that then traversed the region of interest before being received by the remaining three sensors.","On training a neural network to analyze time-series data of the material response, which displayed damage-reflective features whenever the plate guided waves interacted with a contact load, we achieved a model that detected with greater than 99% accuracy in addition to a model that localized with $3.14 \\pm 0.21$ mm mean distance error and captured more than 60% of test examples within the diffraction limit.","For each task, the best-performing model was designed according to the inductive bias that our transducers were both similar and arranged in a square pattern on a nearly uniform plate."],"url":"http://arxiv.org/abs/2409.06084v1"}
{"created":"2024-09-09 21:22:35","title":"PEERNet: An End-to-End Profiling Tool for Real-Time Networked Robotic Systems","abstract":"Networked robotic systems balance compute, power, and latency constraints in applications such as self-driving vehicles, drone swarms, and teleoperated surgery. A core problem in this domain is deciding when to offload a computationally expensive task to the cloud, a remote server, at the cost of communication latency. Task offloading algorithms often rely on precise knowledge of system-specific performance metrics, such as sensor data rates, network bandwidth, and machine learning model latency. While these metrics can be modeled during system design, uncertainties in connection quality, server load, and hardware conditions introduce real-time performance variations, hindering overall performance. We introduce PEERNet, an end-to-end and real-time profiling tool for cloud robotics. PEERNet enables performance monitoring on heterogeneous hardware through targeted yet adaptive profiling of system components such as sensors, networks, deep-learning pipelines, and devices. We showcase PEERNet's capabilities through networked robotics tasks, such as image-based teleoperation of a Franka Emika Panda arm and querying vision language models using an Nvidia Jetson Orin. PEERNet reveals non-intuitive behavior in robotic systems, such as asymmetric network transmission and bimodal language model output. Our evaluation underscores the effectiveness and importance of benchmarking in networked robotics, demonstrating PEERNet's adaptability. Our code is open-source and available at github.com/UTAustin-SwarmLab/PEERNet.","sentences":["Networked robotic systems balance compute, power, and latency constraints in applications such as self-driving vehicles, drone swarms, and teleoperated surgery.","A core problem in this domain is deciding when to offload a computationally expensive task to the cloud, a remote server, at the cost of communication latency.","Task offloading algorithms often rely on precise knowledge of system-specific performance metrics, such as sensor data rates, network bandwidth, and machine learning model latency.","While these metrics can be modeled during system design, uncertainties in connection quality, server load, and hardware conditions introduce real-time performance variations, hindering overall performance.","We introduce PEERNet, an end-to-end and real-time profiling tool for cloud robotics.","PEERNet enables performance monitoring on heterogeneous hardware through targeted yet adaptive profiling of system components such as sensors, networks, deep-learning pipelines, and devices.","We showcase PEERNet's capabilities through networked robotics tasks, such as image-based teleoperation of a Franka Emika Panda arm and querying vision language models using an Nvidia Jetson Orin.","PEERNet reveals non-intuitive behavior in robotic systems, such as asymmetric network transmission and bimodal language model output.","Our evaluation underscores the effectiveness and importance of benchmarking in networked robotics, demonstrating PEERNet's adaptability.","Our code is open-source and available at github.com/UTAustin-SwarmLab/PEERNet."],"url":"http://arxiv.org/abs/2409.06078v1"}
{"created":"2024-09-09 21:20:36","title":"MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization","abstract":"Electronic Design Automation (EDA) is essential for IC design and has recently benefited from AI-based techniques to improve efficiency. Logic synthesis, a key EDA stage, transforms high-level hardware descriptions into optimized netlists. Recent research has employed machine learning to predict Quality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis recipes. However, the severe scarcity of data due to a very limited number of available AIGs results in overfitting, significantly hindering performance. Additionally, the complexity and large number of nodes in AIGs make plain GNNs less effective for learning expressive graph-level representations. To tackle these challenges, we propose MTLSO - a Multi-Task Learning approach for Logic Synthesis Optimization. On one hand, it maximizes the use of limited data by training the model across different tasks. This includes introducing an auxiliary task of binary multi-label graph classification alongside the primary regression task, allowing the model to benefit from diverse supervision sources. On the other hand, we employ a hierarchical graph representation learning strategy to improve the model's capacity for learning expressive graph-level representations of large AIGs, surpassing traditional plain GNNs. Extensive experiments across multiple datasets and against state-of-the-art baselines demonstrate the superiority of our method, achieving an average performance gain of 8.22\\% for delay and 5.95\\% for area.","sentences":["Electronic Design Automation (EDA) is essential for IC design and has recently benefited from AI-based techniques to improve efficiency.","Logic synthesis, a key EDA stage, transforms high-level hardware descriptions into optimized netlists.","Recent research has employed machine learning to predict Quality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis recipes.","However, the severe scarcity of data due to a very limited number of available AIGs results in overfitting, significantly hindering performance.","Additionally, the complexity and large number of nodes in AIGs make plain GNNs less effective for learning expressive graph-level representations.","To tackle these challenges, we propose MTLSO - a Multi-Task Learning approach for Logic Synthesis Optimization.","On one hand, it maximizes the use of limited data by training the model across different tasks.","This includes introducing an auxiliary task of binary multi-label graph classification alongside the primary regression task, allowing the model to benefit from diverse supervision sources.","On the other hand, we employ a hierarchical graph representation learning strategy to improve the model's capacity for learning expressive graph-level representations of large AIGs, surpassing traditional plain GNNs.","Extensive experiments across multiple datasets and against state-of-the-art baselines demonstrate the superiority of our method, achieving an average performance gain of 8.22\\% for delay and 5.95\\% for area."],"url":"http://arxiv.org/abs/2409.06077v1"}
{"created":"2024-09-09 21:14:44","title":"SVS-GAN: Leveraging GANs for Semantic Video Synthesis","abstract":"In recent years, there has been a growing interest in Semantic Image Synthesis (SIS) through the use of Generative Adversarial Networks (GANs) and diffusion models. This field has seen innovations such as the implementation of specialized loss functions tailored for this task, diverging from the more general approaches in Image-to-Image (I2I) translation. While the concept of Semantic Video Synthesis (SVS)$\\unicode{x2013}$the generation of temporally coherent, realistic sequences of images from semantic maps$\\unicode{x2013}$is newly formalized in this paper, some existing methods have already explored aspects of this field. Most of these approaches rely on generic loss functions designed for video-to-video translation or require additional data to achieve temporal coherence. In this paper, we introduce the SVS-GAN, a framework specifically designed for SVS, featuring a custom architecture and loss functions. Our approach includes a triple-pyramid generator that utilizes SPADE blocks. Additionally, we employ a U-Net-based network for the image discriminator, which performs semantic segmentation for the OASIS loss. Through this combination of tailored architecture and objective engineering, our framework aims to bridge the existing gap between SIS and SVS, outperforming current state-of-the-art models on datasets like Cityscapes and KITTI-360.","sentences":["In recent years, there has been a growing interest in Semantic Image Synthesis (SIS) through the use of Generative Adversarial Networks (GANs) and diffusion models.","This field has seen innovations such as the implementation of specialized loss functions tailored for this task, diverging from the more general approaches in Image-to-Image (I2I) translation.","While the concept of Semantic Video Synthesis (SVS)$\\unicode{x2013}$the generation of temporally coherent, realistic sequences of images from semantic maps$\\unicode{x2013}$is newly formalized in this paper, some existing methods have already explored aspects of this field.","Most of these approaches rely on generic loss functions designed for video-to-video translation or require additional data to achieve temporal coherence.","In this paper, we introduce the SVS-GAN, a framework specifically designed for SVS, featuring a custom architecture and loss functions.","Our approach includes a triple-pyramid generator that utilizes SPADE blocks.","Additionally, we employ a U-Net-based network for the image discriminator, which performs semantic segmentation for the OASIS loss.","Through this combination of tailored architecture and objective engineering, our framework aims to bridge the existing gap between SIS and SVS, outperforming current state-of-the-art models on datasets like Cityscapes and KITTI-360."],"url":"http://arxiv.org/abs/2409.06074v1"}
{"created":"2024-09-09 21:12:03","title":"DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks. However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further exploration. The existing applications often narrowly focus on specific tasks like toxicity or hate speech detection. In this paper, we present a comprehensive benchmark suite designed to assess the performance of LLMs in identifying and mitigating fraudulent and abusive language across various real-world scenarios. Our benchmark encompasses a diverse set of tasks, including detecting spam emails, hate speech, misogynistic language, and more. We evaluated several state-of-the-art LLMs, including models from Anthropic, Mistral AI, and the AI21 family, to provide a comprehensive assessment of their capabilities in this critical domain. The results indicate that while LLMs exhibit proficient baseline performance in individual fraud and abuse detection tasks, their performance varies considerably across tasks, particularly struggling with tasks that demand nuanced pragmatic reasoning, such as identifying diverse forms of misogynistic language. These findings have important implications for the responsible development and deployment of LLMs in high-risk applications. Our benchmark suite can serve as a tool for researchers and practitioners to systematically evaluate LLMs for multi-task fraud detection and drive the creation of more robust, trustworthy, and ethically-aligned systems for fraud and abuse detection.","sentences":["Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks.","However, their practical application in high-stake domains, such as fraud and abuse detection, remains an area that requires further exploration.","The existing applications often narrowly focus on specific tasks like toxicity or hate speech detection.","In this paper, we present a comprehensive benchmark suite designed to assess the performance of LLMs in identifying and mitigating fraudulent and abusive language across various real-world scenarios.","Our benchmark encompasses a diverse set of tasks, including detecting spam emails, hate speech, misogynistic language, and more.","We evaluated several state-of-the-art LLMs, including models from Anthropic, Mistral AI, and the AI21 family, to provide a comprehensive assessment of their capabilities in this critical domain.","The results indicate that while LLMs exhibit proficient baseline performance in individual fraud and abuse detection tasks, their performance varies considerably across tasks, particularly struggling with tasks that demand nuanced pragmatic reasoning, such as identifying diverse forms of misogynistic language.","These findings have important implications for the responsible development and deployment of LLMs in high-risk applications.","Our benchmark suite can serve as a tool for researchers and practitioners to systematically evaluate LLMs for multi-task fraud detection and drive the creation of more robust, trustworthy, and ethically-aligned systems for fraud and abuse detection."],"url":"http://arxiv.org/abs/2409.06072v1"}
{"created":"2024-09-09 21:07:13","title":"Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research","abstract":"Digital agriculture leverages technology to enhance crop yield, disease resilience, and soil health, playing a critical role in agricultural research. However, it raises privacy concerns such as adverse pricing, price discrimination, higher insurance costs, and manipulation of resources, deterring farm operators from sharing data due to potential misuse. This study introduces a privacy-preserving framework that addresses these risks while allowing secure data sharing for digital agriculture. Our framework enables comprehensive data analysis while protecting privacy. It allows stakeholders to harness research-driven policies that link public and private datasets. The proposed algorithm achieves this by: (1) identifying similar farmers based on private datasets, (2) providing aggregate information like time and location, (3) determining trends in price and product availability, and (4) correlating trends with public policy data, such as food insecurity statistics. We validate the framework with real-world Farmer's Market datasets, demonstrating its efficacy through machine learning models trained on linked privacy-preserved data. The results support policymakers and researchers in addressing food insecurity and pricing issues. This work significantly contributes to digital agriculture by providing a secure method for integrating and analyzing data, driving advancements in agricultural technology and development.","sentences":["Digital agriculture leverages technology to enhance crop yield, disease resilience, and soil health, playing a critical role in agricultural research.","However, it raises privacy concerns such as adverse pricing, price discrimination, higher insurance costs, and manipulation of resources, deterring farm operators from sharing data due to potential misuse.","This study introduces a privacy-preserving framework that addresses these risks while allowing secure data sharing for digital agriculture.","Our framework enables comprehensive data analysis while protecting privacy.","It allows stakeholders to harness research-driven policies that link public and private datasets.","The proposed algorithm achieves this by: (1) identifying similar farmers based on private datasets, (2) providing aggregate information like time and location, (3) determining trends in price and product availability, and (4) correlating trends with public policy data, such as food insecurity statistics.","We validate the framework with real-world Farmer's Market datasets, demonstrating its efficacy through machine learning models trained on linked privacy-preserved data.","The results support policymakers and researchers in addressing food insecurity and pricing issues.","This work significantly contributes to digital agriculture by providing a secure method for integrating and analyzing data, driving advancements in agricultural technology and development."],"url":"http://arxiv.org/abs/2409.06069v1"}
{"created":"2024-09-09 21:04:16","title":"MLLM-FL: Multimodal Large Language Model Assisted Federated Learning on Heterogeneous and Long-tailed Data","abstract":"Previous studies on federated learning (FL) often encounter performance degradation due to data heterogeneity among different clients. In light of the recent advances in multimodal large language models (MLLMs), such as GPT-4v and LLaVA, which demonstrate their exceptional proficiency in multimodal tasks, such as image captioning and multimodal question answering. We introduce a novel federated learning framework, named Multimodal Large Language Model Assisted Federated Learning (MLLM-FL), which which employs powerful MLLMs at the server end to address the heterogeneous and long-tailed challenges. Owing to the advanced cross-modality representation capabilities and the extensive open-vocabulary prior knowledge of MLLMs, our framework is adept at harnessing the extensive, yet previously underexploited, open-source data accessible from websites and powerful server-side computational resources. Hence, the MLLM-FL not only enhances the performance but also avoids increasing the risk of privacy leakage and the computational burden on local devices, distinguishing it from prior methodologies. Our framework has three key stages. Initially, prior to local training on local datasets of clients, we conduct global visual-text pretraining of the model. This pretraining is facilitated by utilizing the extensive open-source data available online, with the assistance of multimodal large language models. Subsequently, the pretrained model is distributed among various clients for local training. Finally, once the locally trained models are transmitted back to the server, a global alignment is carried out under the supervision of MLLMs to further enhance the performance. Experimental evaluations on established benchmarks, show that our framework delivers promising performance in the typical scenarios with data heterogeneity and long-tail distribution across different clients in FL.","sentences":["Previous studies on federated learning (FL) often encounter performance degradation due to data heterogeneity among different clients.","In light of the recent advances in multimodal large language models (MLLMs), such as GPT-4v and LLaVA, which demonstrate their exceptional proficiency in multimodal tasks, such as image captioning and multimodal question answering.","We introduce a novel federated learning framework, named Multimodal Large Language Model Assisted Federated Learning (MLLM-FL), which which employs powerful MLLMs at the server end to address the heterogeneous and long-tailed challenges.","Owing to the advanced cross-modality representation capabilities and the extensive open-vocabulary prior knowledge of MLLMs, our framework is adept at harnessing the extensive, yet previously underexploited, open-source data accessible from websites and powerful server-side computational resources.","Hence, the MLLM-FL not only enhances the performance but also avoids increasing the risk of privacy leakage and the computational burden on local devices, distinguishing it from prior methodologies.","Our framework has three key stages.","Initially, prior to local training on local datasets of clients, we conduct global visual-text pretraining of the model.","This pretraining is facilitated by utilizing the extensive open-source data available online, with the assistance of multimodal large language models.","Subsequently, the pretrained model is distributed among various clients for local training.","Finally, once the locally trained models are transmitted back to the server, a global alignment is carried out under the supervision of MLLMs to further enhance the performance.","Experimental evaluations on established benchmarks, show that our framework delivers promising performance in the typical scenarios with data heterogeneity and long-tail distribution across different clients in FL."],"url":"http://arxiv.org/abs/2409.06067v1"}
{"created":"2024-09-09 20:58:40","title":"A Thorough Investigation of Content-Defined Chunking Algorithms for Data Deduplication","abstract":"Data deduplication emerged as a powerful solution for reducing storage and bandwidth costs by eliminating redundancies at the level of chunks. This has spurred the development of numerous Content-Defined Chunking (CDC) algorithms over the past two decades. Despite advancements, the current state-of-the-art remains obscure, as a thorough and impartial analysis and comparison is lacking. We conduct a rigorous theoretical analysis and impartial experimental comparison of several leading CDC algorithms. Using four realistic datasets, we evaluate these algorithms against four key metrics: throughput, deduplication ratio, average chunk size, and chunk-size variance. Our analyses, in many instances, extend the findings of their original publications by reporting new results and putting existing ones into context. Moreover, we highlight limitations that have previously gone unnoticed. Our findings provide valuable insights that inform the selection and optimization of CDC algorithms for practical applications in data deduplication.","sentences":["Data deduplication emerged as a powerful solution for reducing storage and bandwidth costs by eliminating redundancies at the level of chunks.","This has spurred the development of numerous Content-Defined Chunking (CDC) algorithms over the past two decades.","Despite advancements, the current state-of-the-art remains obscure, as a thorough and impartial analysis and comparison is lacking.","We conduct a rigorous theoretical analysis and impartial experimental comparison of several leading CDC algorithms.","Using four realistic datasets, we evaluate these algorithms against four key metrics: throughput, deduplication ratio, average chunk size, and chunk-size variance.","Our analyses, in many instances, extend the findings of their original publications by reporting new results and putting existing ones into context.","Moreover, we highlight limitations that have previously gone unnoticed.","Our findings provide valuable insights that inform the selection and optimization of CDC algorithms for practical applications in data deduplication."],"url":"http://arxiv.org/abs/2409.06066v1"}
{"created":"2024-09-09 20:58:25","title":"DiffusionPen: Towards Controlling the Style of Handwritten Text Generation","abstract":"Handwritten Text Generation (HTG) conditioned on text and style is a challenging task due to the variability of inter-user characteristics and the unlimited combinations of characters that form new words unseen during training. Diffusion Models have recently shown promising results in HTG but still remain under-explored. We present DiffusionPen (DiffPen), a 5-shot style handwritten text generation approach based on Latent Diffusion Models. By utilizing a hybrid style extractor that combines metric learning and classification, our approach manages to capture both textual and stylistic characteristics of seen and unseen words and styles, generating realistic handwritten samples. Moreover, we explore several variation strategies of the data with multi-style mixtures and noisy embeddings, enhancing the robustness and diversity of the generated data. Extensive experiments using IAM offline handwriting database show that our method outperforms existing methods qualitatively and quantitatively, and its additional generated data can improve the performance of Handwriting Text Recognition (HTR) systems. The code is available at: https://github.com/koninik/DiffusionPen.","sentences":["Handwritten Text Generation (HTG) conditioned on text and style is a challenging task due to the variability of inter-user characteristics and the unlimited combinations of characters that form new words unseen during training.","Diffusion Models have recently shown promising results in HTG but still remain under-explored.","We present DiffusionPen (DiffPen), a 5-shot style handwritten text generation approach based on Latent Diffusion Models.","By utilizing a hybrid style extractor that combines metric learning and classification, our approach manages to capture both textual and stylistic characteristics of seen and unseen words and styles, generating realistic handwritten samples.","Moreover, we explore several variation strategies of the data with multi-style mixtures and noisy embeddings, enhancing the robustness and diversity of the generated data.","Extensive experiments using IAM offline handwriting database show that our method outperforms existing methods qualitatively and quantitatively, and its additional generated data can improve the performance of Handwriting Text Recognition (HTR) systems.","The code is available at: https://github.com/koninik/DiffusionPen."],"url":"http://arxiv.org/abs/2409.06065v1"}
{"created":"2024-09-09 20:49:52","title":"Exploring monotonic priority queues for Dijkstra optimization","abstract":"This paper presents a comprehensive overview of monotone priority queues, focusing on their evolution and application in shortest path algorithms. Monotone priority queues are characterized by the property that their minimum key does not decrease over time, making them particularly effective for label-setting algorithms like Dijkstra's. Some key data structures within this category are explored, emphasizing those derived directly from Dial's algorithm, including variations of multi-level bucket structures and radix heaps. Theoretical complexities and practical considerations of these structures are discussed, with insights into their development and refinement provided through a historical timeline.","sentences":["This paper presents a comprehensive overview of monotone priority queues, focusing on their evolution and application in shortest path algorithms.","Monotone priority queues are characterized by the property that their minimum key does not decrease over time, making them particularly effective for label-setting algorithms like Dijkstra's.","Some key data structures within this category are explored, emphasizing those derived directly from Dial's algorithm, including variations of multi-level bucket structures and radix heaps.","Theoretical complexities and practical considerations of these structures are discussed, with insights into their development and refinement provided through a historical timeline."],"url":"http://arxiv.org/abs/2409.06061v1"}
{"created":"2024-09-09 20:24:19","title":"Statistical Mechanics of Min-Max Problems","abstract":"Min-max optimization problems, also known as saddle point problems, have attracted significant attention due to their applications in various fields, such as fair beamforming, generative adversarial networks (GANs), and adversarial learning. However, understanding the properties of these min-max problems has remained a substantial challenge. This study introduces a statistical mechanical formalism for analyzing the equilibrium values of min-max problems in the high-dimensional limit, while appropriately addressing the order of operations for min and max. As a first step, we apply this formalism to bilinear min-max games and simple GANs, deriving the relationship between the amount of training data and generalization error and indicating the optimal ratio of fake to real data for effective learning. This formalism provides a groundwork for a deeper theoretical analysis of the equilibrium properties in various machine learning methods based on min-max problems and encourages the development of new algorithms and architectures.","sentences":["Min-max optimization problems, also known as saddle point problems, have attracted significant attention due to their applications in various fields, such as fair beamforming, generative adversarial networks (GANs), and adversarial learning.","However, understanding the properties of these min-max problems has remained a substantial challenge.","This study introduces a statistical mechanical formalism for analyzing the equilibrium values of min-max problems in the high-dimensional limit, while appropriately addressing the order of operations for min and max.","As a first step, we apply this formalism to bilinear min-max games and simple GANs, deriving the relationship between the amount of training data and generalization error and indicating the optimal ratio of fake to real data for effective learning.","This formalism provides a groundwork for a deeper theoretical analysis of the equilibrium properties in various machine learning methods based on min-max problems and encourages the development of new algorithms and architectures."],"url":"http://arxiv.org/abs/2409.06053v1"}
{"created":"2024-09-09 20:11:08","title":"Identifying the sources of ideological bias in GPT models through linguistic variation in output","abstract":"Extant work shows that generative AI models such as GPT-3.5 and 4 perpetuate social stereotypes and biases. One concerning but less explored source of bias is ideology. Do GPT models take ideological stances on politically sensitive topics? In this article, we provide an original approach to identifying ideological bias in generative models, showing that bias can stem from both the training data and the filtering algorithm. We leverage linguistic variation in countries with contrasting political attitudes to evaluate bias in average GPT responses to sensitive political topics in those languages. First, we find that GPT output is more conservative in languages that map well onto conservative societies (i.e., Polish), and more liberal in languages used uniquely in liberal societies (i.e., Swedish). This result provides strong evidence of training data bias in GPT models. Second, differences across languages observed in GPT-3.5 persist in GPT-4, even though GPT-4 is significantly more liberal due to OpenAI's filtering policy. Our main takeaway is that generative model training must focus on high-quality, curated datasets to reduce bias, even if it entails a compromise in training data size. Filtering responses after training only introduces new biases and does not remove the underlying training biases.","sentences":["Extant work shows that generative AI models such as GPT-3.5 and 4 perpetuate social stereotypes and biases.","One concerning but less explored source of bias is ideology.","Do GPT models take ideological stances on politically sensitive topics?","In this article, we provide an original approach to identifying ideological bias in generative models, showing that bias can stem from both the training data and the filtering algorithm.","We leverage linguistic variation in countries with contrasting political attitudes to evaluate bias in average GPT responses to sensitive political topics in those languages.","First, we find that GPT output is more conservative in languages that map well onto conservative societies (i.e., Polish), and more liberal in languages used uniquely in liberal societies (i.e., Swedish).","This result provides strong evidence of training data bias in GPT models.","Second, differences across languages observed in GPT-3.5 persist in GPT-4, even though GPT-4 is significantly more liberal due to OpenAI's filtering policy.","Our main takeaway is that generative model training must focus on high-quality, curated datasets to reduce bias, even if it entails a compromise in training data size.","Filtering responses after training only introduces new biases and does not remove the underlying training biases."],"url":"http://arxiv.org/abs/2409.06043v1"}
{"created":"2024-09-09 19:58:42","title":"Online 3D reconstruction and dense tracking in endoscopic videos","abstract":"3D scene reconstruction from stereo endoscopic video data is crucial for advancing surgical interventions. In this work, we present an online framework for online, dense 3D scene reconstruction and tracking, aimed at enhancing surgical scene understanding and assisting interventions. Our method dynamically extends a canonical scene representation using Gaussian splatting, while modeling tissue deformations through a sparse set of control points. We introduce an efficient online fitting algorithm that optimizes the scene parameters, enabling consistent tracking and accurate reconstruction. Through experiments on the StereoMIS dataset, we demonstrate the effectiveness of our approach, outperforming state-of-the-art tracking methods and achieving comparable performance to offline reconstruction techniques. Our work enables various downstream applications thus contributing to advancing the capabilities of surgical assistance systems.","sentences":["3D scene reconstruction from stereo endoscopic video data is crucial for advancing surgical interventions.","In this work, we present an online framework for online, dense 3D scene reconstruction and tracking, aimed at enhancing surgical scene understanding and assisting interventions.","Our method dynamically extends a canonical scene representation using Gaussian splatting, while modeling tissue deformations through a sparse set of control points.","We introduce an efficient online fitting algorithm that optimizes the scene parameters, enabling consistent tracking and accurate reconstruction.","Through experiments on the StereoMIS dataset, we demonstrate the effectiveness of our approach, outperforming state-of-the-art tracking methods and achieving comparable performance to offline reconstruction techniques.","Our work enables various downstream applications thus contributing to advancing the capabilities of surgical assistance systems."],"url":"http://arxiv.org/abs/2409.06037v1"}
{"created":"2024-09-09 19:47:57","title":"Investigating Causal Cues: Strengthening Spoofed Audio Detection with Human-Discernible Linguistic Features","abstract":"Several types of spoofed audio, such as mimicry, replay attacks, and deepfakes, have created societal challenges to information integrity. Recently, researchers have worked with sociolinguistics experts to label spoofed audio samples with Expert Defined Linguistic Features (EDLFs) that can be discerned by the human ear: pitch, pause, word-initial and word-final release bursts of consonant stops, audible intake or outtake of breath, and overall audio quality. It is established that there is an improvement in several deepfake detection algorithms when they augmented the traditional and common features of audio data with these EDLFs. In this paper, using a hybrid dataset comprised of multiple types of spoofed audio augmented with sociolinguistic annotations, we investigate causal discovery and inferences between the discernible linguistic features and the label in the audio clips, comparing the findings of the causal models with the expert ground truth validation labeling process. Our findings suggest that the causal models indicate the utility of incorporating linguistic features to help discern spoofed audio, as well as the overall need and opportunity to incorporate human knowledge into models and techniques for strengthening AI models. The causal discovery and inference can be used as a foundation of training humans to discern spoofed audio as well as automating EDLFs labeling for the purpose of performance improvement of the common AI-based spoofed audio detectors.","sentences":["Several types of spoofed audio, such as mimicry, replay attacks, and deepfakes, have created societal challenges to information integrity.","Recently, researchers have worked with sociolinguistics experts to label spoofed audio samples with Expert Defined Linguistic Features (EDLFs) that can be discerned by the human ear: pitch, pause, word-initial and word-final release bursts of consonant stops, audible intake or outtake of breath, and overall audio quality.","It is established that there is an improvement in several deepfake detection algorithms when they augmented the traditional and common features of audio data with these EDLFs.","In this paper, using a hybrid dataset comprised of multiple types of spoofed audio augmented with sociolinguistic annotations, we investigate causal discovery and inferences between the discernible linguistic features and the label in the audio clips, comparing the findings of the causal models with the expert ground truth validation labeling process.","Our findings suggest that the causal models indicate the utility of incorporating linguistic features to help discern spoofed audio, as well as the overall need and opportunity to incorporate human knowledge into models and techniques for strengthening AI models.","The causal discovery and inference can be used as a foundation of training humans to discern spoofed audio as well as automating EDLFs labeling for the purpose of performance improvement of the common AI-based spoofed audio detectors."],"url":"http://arxiv.org/abs/2409.06033v1"}
{"created":"2024-09-09 19:12:22","title":"Robust Max Selection","abstract":"We introduce a new model to study algorithm design under unreliable information, and apply this model for the problem of finding the uncorrupted maximum element of a list containing $n$ elements, among which are $k$ corrupted elements. Under our model, algorithms can perform black-box comparison queries between any pair of elements. However, queries regarding corrupted elements may have arbitrary output. In particular, corrupted elements do not need to behave as any consistent values, and may introduce cycles in the elements' ordering. This imposes new challenges for designing correct algorithms under this setting. For example, one cannot simply output a single element, as it is impossible to distinguish elements of a list containing one corrupted and one uncorrupted element. To ensure correctness, algorithms under this setting must output a set to make sure the uncorrupted maximum element is included.   We first show that any algorithm must output a set of size at least $\\min\\{n, 2k + 1\\}$ to ensure that the uncorrupted maximum is contained in the output set. Restricted to algorithms whose output size is exactly $\\min\\{n, 2k + 1\\}$, for deterministic algorithms, we show matching upper and lower bounds of $\\Theta(nk)$ comparison queries to produce a set of elements that contains the uncorrupted maximum. On the randomized side, we propose a 2-stage algorithm that, with high probability, uses $O(n + k \\operatorname{polylog} k)$ comparison queries to find such a set, almost matching the $\\Omega(n)$ queries necessary for any randomized algorithm to obtain a constant probability of being correct.","sentences":["We introduce a new model to study algorithm design under unreliable information, and apply this model for the problem of finding the uncorrupted maximum element of a list containing $n$ elements, among which are $k$ corrupted elements.","Under our model, algorithms can perform black-box comparison queries between any pair of elements.","However, queries regarding corrupted elements may have arbitrary output.","In particular, corrupted elements do not need to behave as any consistent values, and may introduce cycles in the elements' ordering.","This imposes new challenges for designing correct algorithms under this setting.","For example, one cannot simply output a single element, as it is impossible to distinguish elements of a list containing one corrupted and one uncorrupted element.","To ensure correctness, algorithms under this setting must output a set to make sure the uncorrupted maximum element is included.   ","We first show that any algorithm must output a set of size at least $\\min\\{n, 2k + 1\\}$ to ensure that the uncorrupted maximum is contained in the output set.","Restricted to algorithms whose output size is exactly $\\min\\{n, 2k + 1\\}$, for deterministic algorithms, we show matching upper and lower bounds of $\\Theta(nk)$ comparison queries to produce a set of elements that contains the uncorrupted maximum.","On the randomized side, we propose a 2-stage algorithm that, with high probability, uses $O(n + k \\operatorname{polylog} k)$ comparison queries to find such a set, almost matching the $\\Omega(n)$ queries necessary for any randomized algorithm to obtain a constant probability of being correct."],"url":"http://arxiv.org/abs/2409.06014v1"}
{"created":"2024-09-09 19:10:42","title":"Investigating the effects of housing instability on depression, anxiety, and mental health treatment in childhood and adolescence","abstract":"Housing instability is a widespread phenomenon in the United States. In combination with other social determinants of health, housing instability affects children's overall health and development. Drawing on data from the 2022 National Survey of Children's Health, we employed multiple logistic regression models to understand how sociodemographic factors, especially housing instability, affect mental health outcomes and treatment access for youth aged 6-17 years. Our results show that youth facing housing instability have a higher likelihood of experiencing anxiety (OR: 1.42, p<0.001) and depression (OR: 1.57, p<0.001). Furthermore, youth experiencing both mental health conditions and housing instability are significantly less likely to receive mental health services in the past year, indicating the substantial barriers they face in accessing mental health care. Based on our findings, we highlight opportunities for digital mental health interventions to provide children experiencing housing instability with more accessible and consistent mental health services.","sentences":["Housing instability is a widespread phenomenon in the United States.","In combination with other social determinants of health, housing instability affects children's overall health and development.","Drawing on data from the 2022 National Survey of Children's Health, we employed multiple logistic regression models to understand how sociodemographic factors, especially housing instability, affect mental health outcomes and treatment access for youth aged 6-17 years.","Our results show that youth facing housing instability have a higher likelihood of experiencing anxiety (OR: 1.42, p<0.001) and depression (OR: 1.57, p<0.001).","Furthermore, youth experiencing both mental health conditions and housing instability are significantly less likely to receive mental health services in the past year, indicating the substantial barriers they face in accessing mental health care.","Based on our findings, we highlight opportunities for digital mental health interventions to provide children experiencing housing instability with more accessible and consistent mental health services."],"url":"http://arxiv.org/abs/2409.06011v1"}
{"created":"2024-09-09 19:02:45","title":"OciorCOOL: Faster Byzantine Agreement and Reliable Broadcast","abstract":"COOL (Chen'21) is an error-free and deterministic Byzantine agreement protocol that achieves consensus on an $\\ell$-bit message with a communication complexity of $O(\\max\\{n\\ell, n t \\log t \\})$ bits in four phases, given $n\\geq 3t + 1$, for a network of $n$ nodes, where up to $t$ nodes may be dishonest. In this work we show that COOL can be optimized by reducing one communication round. The new protocol is called OciorCOOL. Additionally, building on OciorCOOL, we design an optimal reliable broadcast protocol that requires only six communication rounds.","sentences":["COOL (Chen'21) is an error-free and deterministic Byzantine agreement protocol that achieves consensus on an $\\ell$-bit message with a communication complexity of $O(\\max\\{n\\ell, n t \\log t \\})$ bits in four phases, given $n\\geq 3t + 1$, for a network of $n$ nodes, where up to $t$ nodes may be dishonest.","In this work we show that COOL can be optimized by reducing one communication round.","The new protocol is called OciorCOOL.","Additionally, building on OciorCOOL, we design an optimal reliable broadcast protocol that requires only six communication rounds."],"url":"http://arxiv.org/abs/2409.06008v1"}
{"created":"2024-09-09 19:01:14","title":"Enhanced Generative Data Augmentation for Semantic Segmentation via Stronger Guidance","abstract":"Data augmentation is a widely used technique for creating training data for tasks that require labeled data, such as semantic segmentation. This method benefits pixel-wise annotation tasks requiring much effort and intensive labor. Traditional data augmentation methods involve simple transformations like rotations and flips to create new images from existing ones. However, these new images may lack diversity along the main semantic axes in the data and not change high-level semantic properties. To address this issue, generative models have emerged as an effective solution for augmenting data by generating synthetic images. Controllable generative models offer a way to augment data for semantic segmentation tasks using a prompt and visual reference from the original image. However, using these models directly presents challenges, such as creating an effective prompt and visual reference to generate a synthetic image that accurately reflects the content and structure of the original. In this work, we introduce an effective data augmentation method for semantic segmentation using the Controllable Diffusion Model. Our proposed method includes efficient prompt generation using Class-Prompt Appending and Visual Prior Combination to enhance attention to labeled classes in real images. These techniques allow us to generate images that accurately depict segmented classes in the real image. In addition, we employ the class balancing algorithm to ensure efficiency when merging the synthetic and original images to generate balanced data for the training dataset. We evaluated our method on the PASCAL VOC datasets and found it highly effective for synthesizing images in semantic segmentation.","sentences":["Data augmentation is a widely used technique for creating training data for tasks that require labeled data, such as semantic segmentation.","This method benefits pixel-wise annotation tasks requiring much effort and intensive labor.","Traditional data augmentation methods involve simple transformations like rotations and flips to create new images from existing ones.","However, these new images may lack diversity along the main semantic axes in the data and not change high-level semantic properties.","To address this issue, generative models have emerged as an effective solution for augmenting data by generating synthetic images.","Controllable generative models offer a way to augment data for semantic segmentation tasks using a prompt and visual reference from the original image.","However, using these models directly presents challenges, such as creating an effective prompt and visual reference to generate a synthetic image that accurately reflects the content and structure of the original.","In this work, we introduce an effective data augmentation method for semantic segmentation using the Controllable Diffusion Model.","Our proposed method includes efficient prompt generation using Class-Prompt Appending and Visual Prior Combination to enhance attention to labeled classes in real images.","These techniques allow us to generate images that accurately depict segmented classes in the real image.","In addition, we employ the class balancing algorithm to ensure efficiency when merging the synthetic and original images to generate balanced data for the training dataset.","We evaluated our method on the PASCAL VOC datasets and found it highly effective for synthesizing images in semantic segmentation."],"url":"http://arxiv.org/abs/2409.06002v1"}
{"created":"2024-09-09 18:45:43","title":"Adapting to Shifting Correlations with Unlabeled Data Calibration","abstract":"Distribution shifts between sites can seriously degrade model performance since models are prone to exploiting unstable correlations. Thus, many methods try to find features that are stable across sites and discard unstable features. However, unstable features might have complementary information that, if used appropriately, could increase accuracy. More recent methods try to adapt to unstable features at the new sites to achieve higher accuracy. However, they make unrealistic assumptions or fail to scale to multiple confounding features. We propose Generalized Prevalence Adjustment (GPA for short), a flexible method that adjusts model predictions to the shifting correlations between prediction target and confounders to safely exploit unstable features. GPA can infer the interaction between target and confounders in new sites using unlabeled samples from those sites. We evaluate GPA on several real and synthetic datasets, and show that it outperforms competitive baselines.","sentences":["Distribution shifts between sites can seriously degrade model performance since models are prone to exploiting unstable correlations.","Thus, many methods try to find features that are stable across sites and discard unstable features.","However, unstable features might have complementary information that, if used appropriately, could increase accuracy.","More recent methods try to adapt to unstable features at the new sites to achieve higher accuracy.","However, they make unrealistic assumptions or fail to scale to multiple confounding features.","We propose Generalized Prevalence Adjustment (GPA for short), a flexible method that adjusts model predictions to the shifting correlations between prediction target and confounders to safely exploit unstable features.","GPA can infer the interaction between target and confounders in new sites using unlabeled samples from those sites.","We evaluate GPA on several real and synthetic datasets, and show that it outperforms competitive baselines."],"url":"http://arxiv.org/abs/2409.05996v1"}
{"created":"2024-09-09 18:45:04","title":"MessIRve: A Large-Scale Spanish Information Retrieval Dataset","abstract":"Information retrieval (IR) is the task of finding relevant documents in response to a user query. Although Spanish is the second most spoken native language, current IR benchmarks lack Spanish data, hindering the development of information access tools for Spanish speakers. We introduce MessIRve, a large-scale Spanish IR dataset with around 730 thousand queries from Google's autocomplete API and relevant documents sourced from Wikipedia. MessIRve's queries reflect diverse Spanish-speaking regions, unlike other datasets that are translated from English or do not consider dialectal variations. The large size of the dataset allows it to cover a wide variety of topics, unlike smaller datasets. We provide a comprehensive description of the dataset, comparisons with existing datasets, and baseline evaluations of prominent IR models. Our contributions aim to advance Spanish IR research and improve information access for Spanish speakers.","sentences":["Information retrieval (IR) is the task of finding relevant documents in response to a user query.","Although Spanish is the second most spoken native language, current IR benchmarks lack Spanish data, hindering the development of information access tools for Spanish speakers.","We introduce MessIRve, a large-scale Spanish IR dataset with around 730 thousand queries from Google's autocomplete API and relevant documents sourced from Wikipedia.","MessIRve's queries reflect diverse Spanish-speaking regions, unlike other datasets that are translated from English or do not consider dialectal variations.","The large size of the dataset allows it to cover a wide variety of topics, unlike smaller datasets.","We provide a comprehensive description of the dataset, comparisons with existing datasets, and baseline evaluations of prominent IR models.","Our contributions aim to advance Spanish IR research and improve information access for Spanish speakers."],"url":"http://arxiv.org/abs/2409.05994v1"}
{"created":"2024-09-09 18:31:39","title":"A Comprehensive Comparison Between ANNs and KANs For Classifying EEG Alzheimer's Data","abstract":"Alzheimer's Disease is an incurable cognitive condition that affects thousands of people globally. While some diagnostic methods exist for Alzheimer's Disease, many of these methods cannot detect Alzheimer's in its earlier stages. Recently, researchers have explored the use of Electroencephalogram (EEG) technology for diagnosing Alzheimer's. EEG is a noninvasive method of recording the brain's electrical signals, and EEG data has shown distinct differences between patients with and without Alzheimer's. In the past, Artificial Neural Networks (ANNs) have been used to predict Alzheimer's from EEG data, but these models sometimes produce false positive diagnoses. This study aims to compare losses between ANNs and Kolmogorov-Arnold Networks (KANs) across multiple types of epochs, learning rates, and nodes. The results show that across these different parameters, ANNs are more accurate in predicting Alzheimer's Disease from EEG signals.","sentences":["Alzheimer's Disease is an incurable cognitive condition that affects thousands of people globally.","While some diagnostic methods exist for Alzheimer's Disease, many of these methods cannot detect Alzheimer's in its earlier stages.","Recently, researchers have explored the use of Electroencephalogram (EEG) technology for diagnosing Alzheimer's.","EEG is a noninvasive method of recording the brain's electrical signals, and EEG data has shown distinct differences between patients with and without Alzheimer's.","In the past, Artificial Neural Networks (ANNs) have been used to predict Alzheimer's from EEG data, but these models sometimes produce false positive diagnoses.","This study aims to compare losses between ANNs and Kolmogorov-Arnold Networks (KANs) across multiple types of epochs, learning rates, and nodes.","The results show that across these different parameters, ANNs are more accurate in predicting Alzheimer's Disease from EEG signals."],"url":"http://arxiv.org/abs/2409.05989v1"}
{"created":"2024-09-09 18:21:23","title":"FLoRA: Federated Fine-Tuning Large Language Models with Heterogeneous Low-Rank Adaptations","abstract":"The rapid development of Large Language Models (LLMs) has been pivotal in advancing AI, with pre-trained LLMs being adaptable to diverse downstream tasks through fine-tuning. Federated learning (FL) further enhances fine-tuning in a privacy-aware manner by utilizing clients' local data through in-situ computation, eliminating the need for data movement. However, fine-tuning LLMs, given their massive scale of parameters, poses challenges for clients with constrained and heterogeneous resources in FL. Previous methods employed low-rank adaptation (LoRA) for efficient federated fine-tuning but utilized traditional FL aggregation strategies on LoRA adapters. These approaches led to mathematically inaccurate aggregation noise, reducing fine-tuning effectiveness and failing to address heterogeneous LoRAs. In this work, we first highlight the mathematical incorrectness of LoRA aggregation in existing federated fine-tuning methods. We introduce a new approach called FLORA that enables federated fine-tuning on heterogeneous LoRA adapters across clients through a novel stacking-based aggregation method. Our approach is noise-free and seamlessly supports heterogeneous LoRA adapters. Extensive experiments demonstrate FLORA' s superior performance in both homogeneous and heterogeneous settings, surpassing state-of-the-art methods. We envision this work as a milestone for efficient, privacy-preserving, and accurate federated fine-tuning of LLMs. Our code is available at https://github.com/ATP-1010/FederatedLLM.","sentences":["The rapid development of Large Language Models (LLMs) has been pivotal in advancing AI, with pre-trained LLMs being adaptable to diverse downstream tasks through fine-tuning.","Federated learning (FL) further enhances fine-tuning in a privacy-aware manner by utilizing clients' local data through in-situ computation, eliminating the need for data movement.","However, fine-tuning LLMs, given their massive scale of parameters, poses challenges for clients with constrained and heterogeneous resources in FL.","Previous methods employed low-rank adaptation (LoRA) for efficient federated fine-tuning but utilized traditional FL aggregation strategies on LoRA adapters.","These approaches led to mathematically inaccurate aggregation noise, reducing fine-tuning effectiveness and failing to address heterogeneous LoRAs.","In this work, we first highlight the mathematical incorrectness of LoRA aggregation in existing federated fine-tuning methods.","We introduce a new approach called FLORA that enables federated fine-tuning on heterogeneous LoRA adapters across clients through a novel stacking-based aggregation method.","Our approach is noise-free and seamlessly supports heterogeneous LoRA adapters.","Extensive experiments demonstrate FLORA' s superior performance in both homogeneous and heterogeneous settings, surpassing state-of-the-art methods.","We envision this work as a milestone for efficient, privacy-preserving, and accurate federated fine-tuning of LLMs.","Our code is available at https://github.com/ATP-1010/FederatedLLM."],"url":"http://arxiv.org/abs/2409.05976v1"}
{"created":"2024-09-09 18:18:47","title":"CoDiCast: Conditional Diffusion Model for Weather Prediction with Uncertainty Quantification","abstract":"Accurate weather forecasting is critical for science and society. Yet, existing methods have not managed to simultaneously have the properties of high accuracy, low uncertainty, and high computational efficiency. On one hand, to quantify the uncertainty in weather predictions, the strategy of ensemble forecast (i.e., generating a set of diverse predictions) is often employed. However, traditional ensemble numerical weather prediction (NWP) is computationally intensive. On the other hand, most existing machine learning-based weather prediction (MLWP) approaches are efficient and accurate. Nevertheless, they are deterministic and cannot capture the uncertainty of weather forecasting. In this work, we propose CoDiCast, a conditional diffusion model to generate accurate global weather prediction, while achieving uncertainty quantification with ensemble forecasts and modest computational cost. The key idea is to simulate a conditional version of the reverse denoising process in diffusion models, which starts from pure Gaussian noise to generate realistic weather scenarios for a future time point. Each denoising step is conditioned on observations from the recent past. Ensemble forecasts are achieved by repeatedly sampling from stochastic Gaussian noise to represent uncertainty quantification. CoDiCast is trained on a decade of ERA5 reanalysis data from the European Centre for Medium-Range Weather Forecasts (ECMWF). Experimental results demonstrate that our approach outperforms several existing data-driven methods in accuracy. Our conditional diffusion model, CoDiCast, can generate 3-day global weather forecasts, at 6-hour steps and $5.625^\\circ$ latitude-longitude resolution, for over 5 variables, in about 12 minutes on a commodity A100 GPU machine with 80GB memory. The open-souced code is provided at \\url{https://github.com/JimengShi/CoDiCast}.","sentences":["Accurate weather forecasting is critical for science and society.","Yet, existing methods have not managed to simultaneously have the properties of high accuracy, low uncertainty, and high computational efficiency.","On one hand, to quantify the uncertainty in weather predictions, the strategy of ensemble forecast (i.e., generating a set of diverse predictions) is often employed.","However, traditional ensemble numerical weather prediction (NWP) is computationally intensive.","On the other hand, most existing machine learning-based weather prediction (MLWP) approaches are efficient and accurate.","Nevertheless, they are deterministic and cannot capture the uncertainty of weather forecasting.","In this work, we propose CoDiCast, a conditional diffusion model to generate accurate global weather prediction, while achieving uncertainty quantification with ensemble forecasts and modest computational cost.","The key idea is to simulate a conditional version of the reverse denoising process in diffusion models, which starts from pure Gaussian noise to generate realistic weather scenarios for a future time point.","Each denoising step is conditioned on observations from the recent past.","Ensemble forecasts are achieved by repeatedly sampling from stochastic Gaussian noise to represent uncertainty quantification.","CoDiCast is trained on a decade of ERA5 reanalysis data from the European Centre for Medium-Range Weather Forecasts (ECMWF).","Experimental results demonstrate that our approach outperforms several existing data-driven methods in accuracy.","Our conditional diffusion model, CoDiCast, can generate 3-day global weather forecasts, at 6-hour steps and $5.625^\\circ$ latitude-longitude resolution, for over 5 variables, in about 12 minutes on a commodity A100 GPU machine with 80GB memory.","The open-souced code is provided at \\url{https://github.com/JimengShi/CoDiCast}."],"url":"http://arxiv.org/abs/2409.05975v1"}
{"created":"2024-09-09 18:10:05","title":"A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets","abstract":"Recent advances in language modelling has significantly decreased the need of labelled data in text classification tasks. Transformer-based models, pre-trained on unlabeled data, can outmatch the performance of models trained from scratch for each task. However, the amount of labelled data need to fine-tune such type of model is still considerably high for domains requiring expert-level annotators, like the legal domain. This paper investigates the best strategies for optimizing the use of a small labeled dataset and large amounts of unlabeled data and perform a classification task in the legal area with 50 predefined topics. More specifically, we use the records of demands to a Brazilian Public Prosecutor's Office aiming to assign the descriptions in one of the subjects, which currently demands deep legal knowledge for manual filling. The task of optimizing the performance of classifiers in this scenario is especially challenging, given the low amount of resources available regarding the Portuguese language, especially in the legal domain. Our results demonstrate that classic supervised models such as logistic regression and SVM and the ensembles random forest and gradient boosting achieve better performance along with embeddings extracted with word2vec when compared to BERT language model. The latter demonstrates superior performance in association with the architecture of the model itself as a classifier, having surpassed all previous models in that regard. The best result was obtained with Unsupervised Data Augmentation (UDA), which jointly uses BERT, data augmentation, and strategies of semi-supervised learning, with an accuracy of 80.7% in the aforementioned task.","sentences":["Recent advances in language modelling has significantly decreased the need of labelled data in text classification tasks.","Transformer-based models, pre-trained on unlabeled data, can outmatch the performance of models trained from scratch for each task.","However, the amount of labelled data need to fine-tune such type of model is still considerably high for domains requiring expert-level annotators, like the legal domain.","This paper investigates the best strategies for optimizing the use of a small labeled dataset and large amounts of unlabeled data and perform a classification task in the legal area with 50 predefined topics.","More specifically, we use the records of demands to a Brazilian Public Prosecutor's Office aiming to assign the descriptions in one of the subjects, which currently demands deep legal knowledge for manual filling.","The task of optimizing the performance of classifiers in this scenario is especially challenging, given the low amount of resources available regarding the Portuguese language, especially in the legal domain.","Our results demonstrate that classic supervised models such as logistic regression and SVM and the ensembles random forest and gradient boosting achieve better performance along with embeddings extracted with word2vec when compared to BERT language model.","The latter demonstrates superior performance in association with the architecture of the model itself as a classifier, having surpassed all previous models in that regard.","The best result was obtained with Unsupervised Data Augmentation (UDA), which jointly uses BERT, data augmentation, and strategies of semi-supervised learning, with an accuracy of 80.7% in the aforementioned task."],"url":"http://arxiv.org/abs/2409.05972v1"}
{"created":"2024-09-09 18:06:25","title":"Challenges and Opportunities of Teaching Data Visualization Together with Data Science","abstract":"With the increasing amount of data globally, analyzing and visualizing data are becoming essential skills across various professions. It is important to equip university students with these essential data skills. To learn, design, and develop data visualization, students need knowledge of programming and data science topics. Many university programs lack dedicated data science courses for undergraduate students, making it important to introduce these concepts through integrated courses. However, combining data science and data visualization into one course can be challenging due to the time constraints and the heavy load of learning. In this paper, we discuss the development of teaching data science and data visualization together in one course and share the results of the post-course evaluation survey. From the survey's results, we identified four challenges, including difficulty in learning multiple tools and diverse data science topics, varying proficiency levels with tools and libraries, and selecting and cleaning datasets. We also distilled five opportunities for developing a successful data science and visualization course. These opportunities include clarifying the course structure, emphasizing visualization literacy early in the course, updating the course content according to student needs, using large real-world datasets, learning from industry professionals, and promoting collaboration among students.","sentences":["With the increasing amount of data globally, analyzing and visualizing data are becoming essential skills across various professions.","It is important to equip university students with these essential data skills.","To learn, design, and develop data visualization, students need knowledge of programming and data science topics.","Many university programs lack dedicated data science courses for undergraduate students, making it important to introduce these concepts through integrated courses.","However, combining data science and data visualization into one course can be challenging due to the time constraints and the heavy load of learning.","In this paper, we discuss the development of teaching data science and data visualization together in one course and share the results of the post-course evaluation survey.","From the survey's results, we identified four challenges, including difficulty in learning multiple tools and diverse data science topics, varying proficiency levels with tools and libraries, and selecting and cleaning datasets.","We also distilled five opportunities for developing a successful data science and visualization course.","These opportunities include clarifying the course structure, emphasizing visualization literacy early in the course, updating the course content according to student needs, using large real-world datasets, learning from industry professionals, and promoting collaboration among students."],"url":"http://arxiv.org/abs/2409.05969v1"}
