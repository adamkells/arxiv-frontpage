{"created":"2024-08-14 17:50:27","title":"End-to-end Semantic-centric Video-based Multimodal Affective Computing","abstract":"In the pathway toward Artificial General Intelligence (AGI), understanding human's affection is essential to enhance machine's cognition abilities. For achieving more sensual human-AI interaction, Multimodal Affective Computing (MAC) in human-spoken videos has attracted increasing attention. However, previous methods are mainly devoted to designing multimodal fusion algorithms, suffering from two issues: semantic imbalance caused by diverse pre-processing operations and semantic mismatch raised by inconsistent affection content contained in different modalities comparing with the multimodal ground truth. Besides, the usage of manual features extractors make they fail in building end-to-end pipeline for multiple MAC downstream tasks. To address above challenges, we propose a novel end-to-end framework named SemanticMAC to compute multimodal semantic-centric affection for human-spoken videos. We firstly employ pre-trained Transformer model in multimodal data pre-processing and design Affective Perceiver module to capture unimodal affective information. Moreover, we present a semantic-centric approach to unify multimodal representation learning in three ways, including gated feature interaction, multi-task pseudo label generation, and intra-/inter-sample contrastive learning. Finally, SemanticMAC effectively learn specific- and shared-semantic representations in the guidance of semantic-centric labels. Extensive experimental results demonstrate that our approach surpass the state-of-the-art methods on 7 public datasets in four MAC downstream tasks.","sentences":["In the pathway toward Artificial General Intelligence (AGI), understanding human's affection is essential to enhance machine's cognition abilities.","For achieving more sensual human-AI interaction, Multimodal Affective Computing (MAC) in human-spoken videos has attracted increasing attention.","However, previous methods are mainly devoted to designing multimodal fusion algorithms, suffering from two issues: semantic imbalance caused by diverse pre-processing operations and semantic mismatch raised by inconsistent affection content contained in different modalities comparing with the multimodal ground truth.","Besides, the usage of manual features extractors make they fail in building end-to-end pipeline for multiple MAC downstream tasks.","To address above challenges, we propose a novel end-to-end framework named SemanticMAC to compute multimodal semantic-centric affection for human-spoken videos.","We firstly employ pre-trained Transformer model in multimodal data pre-processing and design Affective Perceiver module to capture unimodal affective information.","Moreover, we present a semantic-centric approach to unify multimodal representation learning in three ways, including gated feature interaction, multi-task pseudo label generation, and intra-/inter-sample contrastive learning.","Finally, SemanticMAC effectively learn specific- and shared-semantic representations in the guidance of semantic-centric labels.","Extensive experimental results demonstrate that our approach surpass the state-of-the-art methods on 7 public datasets in four MAC downstream tasks."],"url":"http://arxiv.org/abs/2408.07694v1"}
{"created":"2024-08-14 17:45:13","title":"Detecting Near-Duplicate Face Images","abstract":"Near-duplicate images are often generated when applying repeated photometric and geometric transformations that produce imperceptible variants of the original image. Consequently, a deluge of near-duplicates can be circulated online posing copyright infringement concerns. The concerns are more severe when biometric data is altered through such nuanced transformations. In this work, we address the challenge of near-duplicate detection in face images by, firstly, identifying the original image from a set of near-duplicates and, secondly, deducing the relationship between the original image and the near-duplicates. We construct a tree-like structure, called an Image Phylogeny Tree (IPT) using a graph-theoretic approach to estimate the relationship, i.e., determine the sequence in which they have been generated. We further extend our method to create an ensemble of IPTs known as Image Phylogeny Forests (IPFs). We rigorously evaluate our method to demonstrate robustness across other modalities, unseen transformations by latest generative models and IPT configurations, thereby significantly advancing the state-of-the-art performance by 42% on IPF reconstruction accuracy.","sentences":["Near-duplicate images are often generated when applying repeated photometric and geometric transformations that produce imperceptible variants of the original image.","Consequently, a deluge of near-duplicates can be circulated online posing copyright infringement concerns.","The concerns are more severe when biometric data is altered through such nuanced transformations.","In this work, we address the challenge of near-duplicate detection in face images by, firstly, identifying the original image from a set of near-duplicates and, secondly, deducing the relationship between the original image and the near-duplicates.","We construct a tree-like structure, called an Image Phylogeny Tree (IPT) using a graph-theoretic approach to estimate the relationship, i.e., determine the sequence in which they have been generated.","We further extend our method to create an ensemble of IPTs known as Image Phylogeny Forests (IPFs).","We rigorously evaluate our method to demonstrate robustness across other modalities, unseen transformations by latest generative models and IPT configurations, thereby significantly advancing the state-of-the-art performance by 42% on IPF reconstruction accuracy."],"url":"http://arxiv.org/abs/2408.07689v1"}
{"created":"2024-08-14 17:16:50","title":"Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data","abstract":"A grid search, at the cost of training and testing a large number of models, is an effective way to optimize the prediction performance of deep learning models. A challenging task concerning grid search is the time management. Without a good time management scheme, a grid search can easily be set off as a mission that will not finish in our lifetime. In this study, we introduce a heuristic three-stage mechanism for managing the running time of low-budget grid searches, and the sweet-spot grid search (SSGS) and randomized grid search (RGS) strategies for improving model prediction performance, in predicting the 5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep feedforward neural network (DFNN) models and optimize them through grid searches. We conduct eight cycles of grid searches by applying our three-stage mechanism and SSGS and RGS strategies. We conduct various SHAP analyses including unique ones that interpret the importance of the DFNN-model hyperparameters. Our results show that grid search can greatly improve model prediction. The grid searches we conducted improved the risk prediction of 5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and 17.3% respectively, over the average performance of all corresponding models we trained. We not only demonstrate best model performance but also characterize grid searches from various aspects such as their capabilities of discovering decent models and the unit grid search time. The three-stage mechanism worked effectively. It made our low-budget grid searches feasible and manageable, and in the meantime helped improve model prediction performance. Our SHAP analyses identified both clinical risk factors important for the prediction of future risk of breast cancer metastasis, and DFNN-model hyperparameters important to the prediction of performance scores.","sentences":["A grid search, at the cost of training and testing a large number of models, is an effective way to optimize the prediction performance of deep learning models.","A challenging task concerning grid search is the time management.","Without a good time management scheme, a grid search can easily be set off as a mission that will not finish in our lifetime.","In this study, we introduce a heuristic three-stage mechanism for managing the running time of low-budget grid searches, and the sweet-spot grid search (SSGS) and randomized grid search (RGS) strategies for improving model prediction performance, in predicting the 5-year, 10-year, and 15-year risk of breast cancer metastasis.","We develop deep feedforward neural network (DFNN) models and optimize them through grid searches.","We conduct eight cycles of grid searches by applying our three-stage mechanism and SSGS and RGS strategies.","We conduct various SHAP analyses including unique ones that interpret the importance of the DFNN-model hyperparameters.","Our results show that grid search can greatly improve model prediction.","The grid searches we conducted improved the risk prediction of 5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and 17.3% respectively, over the average performance of all corresponding models we trained.","We not only demonstrate best model performance but also characterize grid searches from various aspects such as their capabilities of discovering decent models and the unit grid search time.","The three-stage mechanism worked effectively.","It made our low-budget grid searches feasible and manageable, and in the meantime helped improve model prediction performance.","Our SHAP analyses identified both clinical risk factors important for the prediction of future risk of breast cancer metastasis, and DFNN-model hyperparameters important to the prediction of performance scores."],"url":"http://arxiv.org/abs/2408.07673v1"}
{"created":"2024-08-14 16:58:48","title":"Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities","abstract":"Model merging is an efficient empowerment technique in the machine learning community that does not require the collection of raw training data and does not require expensive computation. As model merging becomes increasingly prevalent across various fields, it is crucial to understand the available model merging techniques comprehensively. However, there is a significant gap in the literature regarding a systematic and thorough review of these techniques. This survey provides a comprehensive overview of model merging methods and theories, their applications in various domains and settings, and future research directions. Specifically, we first propose a new taxonomic approach that exhaustively discusses existing model merging methods. Secondly, we discuss the application of model merging techniques in large language models, multimodal large language models, and 10+ machine learning subfields, including continual learning, multi-task learning, few-shot learning, etc. Finally, we highlight the remaining challenges of model merging and discuss future research directions. A comprehensive list of papers about model merging is available at \\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.","sentences":["Model merging is an efficient empowerment technique in the machine learning community that does not require the collection of raw training data and does not require expensive computation.","As model merging becomes increasingly prevalent across various fields, it is crucial to understand the available model merging techniques comprehensively.","However, there is a significant gap in the literature regarding a systematic and thorough review of these techniques.","This survey provides a comprehensive overview of model merging methods and theories, their applications in various domains and settings, and future research directions.","Specifically, we first propose a new taxonomic approach that exhaustively discusses existing model merging methods.","Secondly, we discuss the application of model merging techniques in large language models, multimodal large language models, and 10+ machine learning subfields, including continual learning, multi-task learning, few-shot learning, etc.","Finally, we highlight the remaining challenges of model merging and discuss future research directions.","A comprehensive list of papers about model merging is available at \\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}."],"url":"http://arxiv.org/abs/2408.07666v1"}
{"created":"2024-08-14 16:55:06","title":"Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models","abstract":"Warning: This paper may contain texts with uncomfortable content.   Large Language Models (LLMs) have achieved remarkable performance in various tasks, including those involving multimodal data like speech. However, these models often exhibit biases due to the nature of their training data. Recently, more Speech Large Language Models (SLLMs) have emerged, underscoring the urgent need to address these biases. This study introduces Spoken Stereoset, a dataset specifically designed to evaluate social biases in SLLMs. By examining how different models respond to speech from diverse demographic groups, we aim to identify these biases. Our experiments reveal significant insights into their performance and bias levels. The findings indicate that while most models show minimal bias, some still exhibit slightly stereotypical or anti-stereotypical tendencies.","sentences":["Warning: This paper may contain texts with uncomfortable content.   ","Large Language Models (LLMs) have achieved remarkable performance in various tasks, including those involving multimodal data like speech.","However, these models often exhibit biases due to the nature of their training data.","Recently, more Speech Large Language Models (SLLMs) have emerged, underscoring the urgent need to address these biases.","This study introduces Spoken Stereoset, a dataset specifically designed to evaluate social biases in SLLMs.","By examining how different models respond to speech from diverse demographic groups, we aim to identify these biases.","Our experiments reveal significant insights into their performance and bias levels.","The findings indicate that while most models show minimal bias, some still exhibit slightly stereotypical or anti-stereotypical tendencies."],"url":"http://arxiv.org/abs/2408.07665v1"}
{"created":"2024-08-14 16:49:25","title":"Interpretable Graph Neural Networks for Heterogeneous Tabular Data","abstract":"Many machine learning algorithms for tabular data produce black-box models, which prevent users from understanding the rationale behind the model predictions. In their unconstrained form, graph neural networks fall into this category, and they have further limited abilities to handle heterogeneous data. To overcome these limitations, an approach is proposed, called IGNH (Interpretable Graph Neural Network for Heterogeneous tabular data), which handles both categorical and numerical features, while constraining the learning process to generate exact feature attributions together with the predictions. A large-scale empirical investigation is presented, showing that the feature attributions provided by IGNH align with Shapley values that are computed post hoc. Furthermore, the results show that IGNH outperforms two powerful machine learning algorithms for tabular data, Random Forests and TabNet, while reaching a similar level of performance as XGBoost.","sentences":["Many machine learning algorithms for tabular data produce black-box models, which prevent users from understanding the rationale behind the model predictions.","In their unconstrained form, graph neural networks fall into this category, and they have further limited abilities to handle heterogeneous data.","To overcome these limitations, an approach is proposed, called IGNH (Interpretable Graph Neural Network for Heterogeneous tabular data), which handles both categorical and numerical features, while constraining the learning process to generate exact feature attributions together with the predictions.","A large-scale empirical investigation is presented, showing that the feature attributions provided by IGNH align with Shapley values that are computed post hoc.","Furthermore, the results show that IGNH outperforms two powerful machine learning algorithms for tabular data, Random Forests and TabNet, while reaching a similar level of performance as XGBoost."],"url":"http://arxiv.org/abs/2408.07661v1"}
{"created":"2024-08-14 16:29:57","title":"Development of simulation model for Single Carrier Transceiver for Nanosatellite","abstract":"CubeSat is a nanosatellite concept emerged from a paper published by Stanford University and with their low cost nature and extreme feasibility , more started researching on nano satellites. New technology emerged , paving path to many academics and small vendors to create their own CubeSat models .   This nanosatellite requires a transceiver to maintain its communication between it's systems and the ground station, which helps it navigate and collects data gained from its programmed functions. This transceiver system consists mainly of a transmitter and a receiver. The transmitter manages sending data from the satellite to ground station while the receiver captures the data and instruction sent from the ground station to the satellite. These systems were built using separate digital communication devices in the beginning, with many critical limitations with respect to the space and scalability of the modules to be attached and the programmability of hardware materials and the concept of system-on -board emerged. Meanwhile, As the size of electronic devices minimized with the research conducted, FPGA (Filed Programmable Logic Array) was introduced as an architecture to be used in various applications and research needs. The reason FPGA was mention was for the fact that it provides flexibility in the designing of transceiver ed with design and prototypes implementation at a low cost competitional electronic ware and the system -on chip Concept was introduced . This research describes the development a system-on-chip transceiver model for nanosatellites which contains a single carrier . Keywords-Single Carrier, transceiver, system C, FPGA","sentences":["CubeSat is a nanosatellite concept emerged from a paper published by Stanford University and with their low cost nature and extreme feasibility , more started researching on nano satellites.","New technology emerged , paving path to many academics and small vendors to create their own CubeSat models .   ","This nanosatellite requires a transceiver to maintain its communication between it's systems and the ground station, which helps it navigate and collects data gained from its programmed functions.","This transceiver system consists mainly of a transmitter and a receiver.","The transmitter manages sending data from the satellite to ground station while the receiver captures the data and instruction sent from the ground station to the satellite.","These systems were built using separate digital communication devices in the beginning, with many critical limitations with respect to the space and scalability of the modules to be attached and the programmability of hardware materials and the concept of system-on -board emerged.","Meanwhile, As the size of electronic devices minimized with the research conducted, FPGA (Filed Programmable Logic Array) was introduced as an architecture to be used in various applications and research needs.","The reason FPGA was mention was for the fact that it provides flexibility in the designing of transceiver ed with design and prototypes implementation at a low cost competitional electronic ware and the system -on chip Concept was introduced .","This research describes the development a system-on-chip transceiver model for nanosatellites which contains a single carrier .","Keywords-Single Carrier, transceiver, system C, FPGA"],"url":"http://arxiv.org/abs/2408.07655v1"}
{"created":"2024-08-14 16:27:16","title":"The Semantics of Metapropramming in Prolog","abstract":"This paper describes a semantics for pure Prolog programs with negation that provides meaning to metaprograms. Metaprograms are programs that construct and use data structures as programs. In Prolog a primary mataprogramming construct is the use of a variable as a literal in the body of a clause. The traditional Prolog 3-line metainterpreter is another example of a metaprogram. The account given here also supplies a meaning for clauses that have a variable as head, even though most Prolog systems do not support such clauses. This semantics naturally includes such programs, giving them their intuitive meaning.   Ideas from M. Denecker and his colleagues form the basis of this approach. The key idea is to notice that if we give meanings to all propositional programs and treat Prolog rules with variables as the set of their ground instances, then we can give meanings to all programs. We must treat Prolog rules (which may be metarules) as templates for generating ground propositional rules, and not as first-order formulas, which they may not be. We use parameterized inductive definitions to give propositional models to Prolog programs, in which the propositions are expressions. Then the set of expressions of a propositional model determine a first-order Herbrand Model, providing a first-order logical semantics for all (pure) Prolog programs, including metaprograms.   We give examples to show the applicability of this theory. We also demonstrate how this theory makes proofs of some important properties of metaprograms very straightforward.","sentences":["This paper describes a semantics for pure Prolog programs with negation that provides meaning to metaprograms.","Metaprograms are programs that construct and use data structures as programs.","In Prolog a primary mataprogramming construct is the use of a variable as a literal in the body of a clause.","The traditional Prolog 3-line metainterpreter is another example of a metaprogram.","The account given here also supplies a meaning for clauses that have a variable as head, even though most Prolog systems do not support such clauses.","This semantics naturally includes such programs, giving them their intuitive meaning.   Ideas from M. Denecker and his colleagues form the basis of this approach.","The key idea is to notice that if we give meanings to all propositional programs and treat Prolog rules with variables as the set of their ground instances, then we can give meanings to all programs.","We must treat Prolog rules (which may be metarules) as templates for generating ground propositional rules, and not as first-order formulas, which they may not be.","We use parameterized inductive definitions to give propositional models to Prolog programs, in which the propositions are expressions.","Then the set of expressions of a propositional model determine a first-order Herbrand Model, providing a first-order logical semantics for all (pure) Prolog programs, including metaprograms.   ","We give examples to show the applicability of this theory.","We also demonstrate how this theory makes proofs of some important properties of metaprograms very straightforward."],"url":"http://arxiv.org/abs/2408.07652v1"}
{"created":"2024-08-14 16:21:28","title":"Exact Trajectory Similarity Search With N-tree: An Efficient Metric Index for kNN and Range Queries","abstract":"Similarity search is the problem of finding in a collection of objects those that are similar to a given query object. It is a fundamental problem in modern applications and the objects considered may be as diverse as locations in space, text documents, images, twitter messages, or trajectories of moving objects.   In this paper we are motivated by the latter application. Trajectories are recorded movements of mobile objects such as vehicles, animals, public transportation, or parts of the human body. We propose a novel distance function called DistanceAvg to capture the similarity of such movements. To be practical, it is necessary to provide indexing for this distance measure.   Fortunately we do not need to start from scratch. A generic and unifying approach is metric space, which organizes the set of objects solely by a distance (similarity) function with certain natural properties. Our function DistanceAvg is a metric.   Although metric indexes have been studied for decades and many such structures are available, they do not offer the best performance with trajectories. In this paper we propose a new design, which outperforms the best existing indexes for kNN queries and is equally good for range queries. It is especially suitable for expensive distance functions as they occur in trajectory similarity search. In many applications, kNN queries are more practical than range queries as it may be difficult to determine an appropriate search radius. Our index provides exact result sets for the given distance function.","sentences":["Similarity search is the problem of finding in a collection of objects those that are similar to a given query object.","It is a fundamental problem in modern applications and the objects considered may be as diverse as locations in space, text documents, images, twitter messages, or trajectories of moving objects.   ","In this paper we are motivated by the latter application.","Trajectories are recorded movements of mobile objects such as vehicles, animals, public transportation, or parts of the human body.","We propose a novel distance function called DistanceAvg to capture the similarity of such movements.","To be practical, it is necessary to provide indexing for this distance measure.   ","Fortunately we do not need to start from scratch.","A generic and unifying approach is metric space, which organizes the set of objects solely by a distance (similarity) function with certain natural properties.","Our function DistanceAvg is a metric.   ","Although metric indexes have been studied for decades and many such structures are available, they do not offer the best performance with trajectories.","In this paper we propose a new design, which outperforms the best existing indexes for kNN queries and is equally good for range queries.","It is especially suitable for expensive distance functions as they occur in trajectory similarity search.","In many applications, kNN queries are more practical than range queries as it may be difficult to determine an appropriate search radius.","Our index provides exact result sets for the given distance function."],"url":"http://arxiv.org/abs/2408.07650v1"}
{"created":"2024-08-14 16:18:51","title":"Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services","abstract":"Pharmacies are critical in healthcare systems, particularly in low- and middle-income countries. Procuring pharmacists with the right behavioral interventions or nudges can enhance their skills, public health awareness, and pharmacy inventory management, ensuring access to essential medicines that ultimately benefit their patients. We introduce a reinforcement learning operational system to deliver personalized behavioral interventions through mobile health applications. We illustrate its potential by discussing a series of initial experiments run with SwipeRx, an all-in-one app for pharmacists, including B2B e-commerce, in Indonesia. The proposed method has broader applications extending beyond pharmacy operations to optimize healthcare delivery.","sentences":["Pharmacies are critical in healthcare systems, particularly in low- and middle-income countries.","Procuring pharmacists with the right behavioral interventions or nudges can enhance their skills, public health awareness, and pharmacy inventory management, ensuring access to essential medicines that ultimately benefit their patients.","We introduce a reinforcement learning operational system to deliver personalized behavioral interventions through mobile health applications.","We illustrate its potential by discussing a series of initial experiments run with SwipeRx, an all-in-one app for pharmacists, including B2B e-commerce, in Indonesia.","The proposed method has broader applications extending beyond pharmacy operations to optimize healthcare delivery."],"url":"http://arxiv.org/abs/2408.07647v1"}
{"created":"2024-08-14 16:13:03","title":"Boosting Unconstrained Face Recognition with Targeted Style Adversary","abstract":"While deep face recognition models have demonstrated remarkable performance, they often struggle on the inputs from domains beyond their training data. Recent attempts aim to expand the training set by relying on computationally expensive and inherently challenging image-space augmentation of image generation modules. In an orthogonal direction, we present a simple yet effective method to expand the training data by interpolating between instance-level feature statistics across labeled and unlabeled sets. Our method, dubbed Targeted Style Adversary (TSA), is motivated by two observations: (i) the input domain is reflected in feature statistics, and (ii) face recognition model performance is influenced by style information. Shifting towards an unlabeled style implicitly synthesizes challenging training instances. We devise a recognizability metric to constraint our framework to preserve the inherent identity-related information of labeled instances. The efficacy of our method is demonstrated through evaluations on unconstrained benchmarks, outperforming or being on par with its competitors while offering nearly a 70\\% improvement in training speed and 40\\% less memory consumption.","sentences":["While deep face recognition models have demonstrated remarkable performance, they often struggle on the inputs from domains beyond their training data.","Recent attempts aim to expand the training set by relying on computationally expensive and inherently challenging image-space augmentation of image generation modules.","In an orthogonal direction, we present a simple yet effective method to expand the training data by interpolating between instance-level feature statistics across labeled and unlabeled sets.","Our method, dubbed Targeted Style Adversary (TSA), is motivated by two observations: (i) the input domain is reflected in feature statistics, and (ii) face recognition model performance is influenced by style information.","Shifting towards an unlabeled style implicitly synthesizes challenging training instances.","We devise a recognizability metric to constraint our framework to preserve the inherent identity-related information of labeled instances.","The efficacy of our method is demonstrated through evaluations on unconstrained benchmarks, outperforming or being on par with its competitors while offering nearly a 70\\% improvement in training speed and 40\\% less memory consumption."],"url":"http://arxiv.org/abs/2408.07642v1"}
{"created":"2024-08-14 15:56:27","title":"Towards Fair and Rigorous Evaluations: Hyperparameter Optimization for Top-N Recommendation Task with Implicit Feedback","abstract":"The widespread use of the internet has led to an overwhelming amount of data, which has resulted in the problem of information overload. Recommender systems have emerged as a solution to this problem by providing personalized recommendations to users based on their preferences and historical data. However, as recommendation models become increasingly complex, finding the best hyperparameter combination for different models has become a challenge. The high-dimensional hyperparameter search space poses numerous challenges for researchers, and failure to disclose hyperparameter settings may impede the reproducibility of research results. In this paper, we investigate the Top-N implicit recommendation problem and focus on optimizing the benchmark recommendation algorithm commonly used in comparative experiments using hyperparameter optimization algorithms. We propose a research methodology that follows the principles of a fair comparison, employing seven types of hyperparameter search algorithms to fine-tune six common recommendation algorithms on three datasets. We have identified the most suitable hyperparameter search algorithms for various recommendation algorithms on different types of datasets as a reference for later study. This study contributes to algorithmic research in recommender systems based on hyperparameter optimization, providing a fair basis for comparison.","sentences":["The widespread use of the internet has led to an overwhelming amount of data, which has resulted in the problem of information overload.","Recommender systems have emerged as a solution to this problem by providing personalized recommendations to users based on their preferences and historical data.","However, as recommendation models become increasingly complex, finding the best hyperparameter combination for different models has become a challenge.","The high-dimensional hyperparameter search space poses numerous challenges for researchers, and failure to disclose hyperparameter settings may impede the reproducibility of research results.","In this paper, we investigate the Top-N implicit recommendation problem and focus on optimizing the benchmark recommendation algorithm commonly used in comparative experiments using hyperparameter optimization algorithms.","We propose a research methodology that follows the principles of a fair comparison, employing seven types of hyperparameter search algorithms to fine-tune six common recommendation algorithms on three datasets.","We have identified the most suitable hyperparameter search algorithms for various recommendation algorithms on different types of datasets as a reference for later study.","This study contributes to algorithmic research in recommender systems based on hyperparameter optimization, providing a fair basis for comparison."],"url":"http://arxiv.org/abs/2408.07630v1"}
{"created":"2024-08-14 15:55:31","title":"Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings","abstract":"By providing evidence-based clinical decision support, digital tools and electronic health records can revolutionize patient management, especially in resource-poor settings where fewer health workers are available and often need more training. When these tools are integrated with AI, they can offer personalized support and adaptive interventions, effectively connecting community health workers (CHWs) and healthcare facilities. The CHARM (Community Health Access & Resource Management) app is an AI-native mobile app for CHWs. Developed through a joint partnership of Causal Foundry (CF) and mothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining case management, enhancing learning, and improving communication. This paper details CHARM's development, integration, and upcoming reinforcement learning-based adaptive interventions, all aimed at enhancing health worker engagement, efficiency, and patient outcomes, thereby enhancing CHWs' capabilities and community health.","sentences":["By providing evidence-based clinical decision support, digital tools and electronic health records can revolutionize patient management, especially in resource-poor settings where fewer health workers are available and often need more training.","When these tools are integrated with AI, they can offer personalized support and adaptive interventions, effectively connecting community health workers (CHWs) and healthcare facilities.","The CHARM (Community Health Access & Resource Management) app is an AI-native mobile app for CHWs.","Developed through a joint partnership of Causal Foundry (CF) and mothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining case management, enhancing learning, and improving communication.","This paper details CHARM's development, integration, and upcoming reinforcement learning-based adaptive interventions, all aimed at enhancing health worker engagement, efficiency, and patient outcomes, thereby enhancing CHWs' capabilities and community health."],"url":"http://arxiv.org/abs/2408.07629v1"}
{"created":"2024-08-14 15:54:00","title":"Embodied Biocomputing Sequential Circuits with Data Processing and Storage for Neurons-on-a-chip","abstract":"With conventional silicon-based computing approaching its physical and efficiency limits, biocomputing emerges as a promising alternative. This approach utilises biomaterials such as DNA and neurons as an interesting alternative to data processing and storage. This study explores the potential of neuronal biocomputing to rival silicon-based systems. We explore neuronal logic gates and sequential circuits that mimic conventional computer architectures. Through mathematical modelling, optimisation, and computer simulation, we demonstrate the operational capabilities of neuronal sequential circuits. These circuits include a neuronal NAND gate, SR Latch flip-flop, and D flip-flop memory units. Our approach involves manipulating neuron communication, synaptic conductance, spike buffers, neuron types, and specific neuronal network topology designs. The experiments demonstrate the practicality of encoding binary information using patterns of neuronal activity and overcoming synchronization difficulties with neuronal buffers and inhibition strategies. Our results confirm the effectiveness and scalability of neuronal logic circuits, showing that they maintain a stable metabolic burden even in complex data storage configurations. Our study not only demonstrates the concept of embodied biocomputing by manipulating neuronal properties for digital signal processing but also establishes the foundation for cutting-edge biocomputing technologies. Our designs open up possibilities for using neurons as energy-efficient computing solutions. These solutions have the potential to become an alternate to silicon-based systems by providing a carbon-neutral, biologically feasible alternative.","sentences":["With conventional silicon-based computing approaching its physical and efficiency limits, biocomputing emerges as a promising alternative.","This approach utilises biomaterials such as DNA and neurons as an interesting alternative to data processing and storage.","This study explores the potential of neuronal biocomputing to rival silicon-based systems.","We explore neuronal logic gates and sequential circuits that mimic conventional computer architectures.","Through mathematical modelling, optimisation, and computer simulation, we demonstrate the operational capabilities of neuronal sequential circuits.","These circuits include a neuronal NAND gate, SR Latch flip-flop, and D flip-flop memory units.","Our approach involves manipulating neuron communication, synaptic conductance, spike buffers, neuron types, and specific neuronal network topology designs.","The experiments demonstrate the practicality of encoding binary information using patterns of neuronal activity and overcoming synchronization difficulties with neuronal buffers and inhibition strategies.","Our results confirm the effectiveness and scalability of neuronal logic circuits, showing that they maintain a stable metabolic burden even in complex data storage configurations.","Our study not only demonstrates the concept of embodied biocomputing by manipulating neuronal properties for digital signal processing but also establishes the foundation for cutting-edge biocomputing technologies.","Our designs open up possibilities for using neurons as energy-efficient computing solutions.","These solutions have the potential to become an alternate to silicon-based systems by providing a carbon-neutral, biologically feasible alternative."],"url":"http://arxiv.org/abs/2408.07628v1"}
{"created":"2024-08-14 15:44:51","title":"Latent Anomaly Detection Through Density Matrices","abstract":"This paper introduces a novel anomaly detection framework that combines the robust statistical principles of density-estimation-based anomaly detection methods with the representation-learning capabilities of deep learning models. The method originated from this framework is presented in two different versions: a shallow approach employing a density-estimation model based on adaptive Fourier features and density matrices, and a deep approach that integrates an autoencoder to learn a low-dimensional representation of the data. By estimating the density of new samples, both methods are able to find normality scores. The methods can be seamlessly integrated into an end-to-end architecture and optimized using gradient-based optimization techniques. To evaluate their performance, extensive experiments were conducted on various benchmark datasets. The results demonstrate that both versions of the method can achieve comparable or superior performance when compared to other state-of-the-art methods. Notably, the shallow approach performs better on datasets with fewer dimensions, while the autoencoder-based approach shows improved performance on datasets with higher dimensions.","sentences":["This paper introduces a novel anomaly detection framework that combines the robust statistical principles of density-estimation-based anomaly detection methods with the representation-learning capabilities of deep learning models.","The method originated from this framework is presented in two different versions: a shallow approach employing a density-estimation model based on adaptive Fourier features and density matrices, and a deep approach that integrates an autoencoder to learn a low-dimensional representation of the data.","By estimating the density of new samples, both methods are able to find normality scores.","The methods can be seamlessly integrated into an end-to-end architecture and optimized using gradient-based optimization techniques.","To evaluate their performance, extensive experiments were conducted on various benchmark datasets.","The results demonstrate that both versions of the method can achieve comparable or superior performance when compared to other state-of-the-art methods.","Notably, the shallow approach performs better on datasets with fewer dimensions, while the autoencoder-based approach shows improved performance on datasets with higher dimensions."],"url":"http://arxiv.org/abs/2408.07623v1"}
{"created":"2024-08-14 15:31:15","title":"Prophet Inequalities: Competing with the Top $\\ell$ Items is Easy","abstract":"We explore a novel variant of the classical prophet inequality problem, where the values of a sequence of items are drawn i.i.d. from some distribution, and an online decision maker must select one item irrevocably. We establish that the competitive ratio between the expected optimal performance of the online decision maker compared to that of a prophet, who uses the average of the top $\\ell$ items, must be greater than $\\ell/c_{\\ell}$, with $c_{\\ell}$ the solution to an integral equation. We prove that this lower bound is larger than $1-1/(\\exp(\\ell)-1)$. This implies that the bound converges exponentially fast to $1$ as $\\ell$ grows. In particular, the bound for $\\ell=2$ is $2/c_{2} \\approx 0.966$ which is much closer to $1$ than the classical bound of $0.745$ for $\\ell=1$. Additionally, the proposed algorithm can be extended to a more general scenario, where the decision maker is permitted to select $k$ items. This subsumes the $k$ multi-unit i.i.d. prophet problem and provides the current best asymptotic guarantees, as well as enables broader understanding in the more general framework. Finally, we prove a nearly tight competitive ratio when only static threshold policies are allowed.","sentences":["We explore a novel variant of the classical prophet inequality problem, where the values of a sequence of items are drawn i.i.d.","from some distribution, and an online decision maker must select one item irrevocably.","We establish that the competitive ratio between the expected optimal performance of the online decision maker compared to that of a prophet, who uses the average of the top $\\ell$ items, must be greater than $\\ell/c_{\\ell}$, with $c_{\\ell}$ the solution to an integral equation.","We prove that this lower bound is larger than $1-1/(\\exp(\\ell)-1)$.","This implies that the bound converges exponentially fast to $1$ as $\\ell$ grows.","In particular, the bound for $\\ell=2$ is $2/c_{2} \\approx 0.966$ which is much closer to $1$ than the classical bound of $0.745$ for $\\ell=1$. Additionally, the proposed algorithm can be extended to a more general scenario, where the decision maker is permitted to select $k$ items.","This subsumes the $k$ multi-unit i.i.d. prophet problem and provides the current best asymptotic guarantees, as well as enables broader understanding in the more general framework.","Finally, we prove a nearly tight competitive ratio when only static threshold policies are allowed."],"url":"http://arxiv.org/abs/2408.07616v1"}
{"created":"2024-08-14 15:28:28","title":"Practical Considerations for Differential Privacy","abstract":"Differential privacy is the gold standard for statistical data release. Used by governments, companies, and academics, its mathematically rigorous guarantees and worst-case assumptions on the strength and knowledge of attackers make it a robust and compelling framework for reasoning about privacy. However, even with landmark successes, differential privacy has not achieved widespread adoption in everyday data use and data protection. In this work we examine some of the practical obstacles that stand in the way.","sentences":["Differential privacy is the gold standard for statistical data release.","Used by governments, companies, and academics, its mathematically rigorous guarantees and worst-case assumptions on the strength and knowledge of attackers make it a robust and compelling framework for reasoning about privacy.","However, even with landmark successes, differential privacy has not achieved widespread adoption in everyday data use and data protection.","In this work we examine some of the practical obstacles that stand in the way."],"url":"http://arxiv.org/abs/2408.07614v1"}
{"created":"2024-08-14 15:26:10","title":"Rethinking the Key Factors for the Generalization of Remote Sensing Stereo Matching Networks","abstract":"Stereo matching, a critical step of 3D reconstruction, has fully shifted towards deep learning due to its strong feature representation of remote sensing images. However, ground truth for stereo matching task relies on expensive airborne LiDAR data, thus making it difficult to obtain enough samples for supervised learning. To improve the generalization ability of stereo matching networks on cross-domain data from different sensors and scenarios, in this paper, we dedicate to study key training factors from three perspectives. (1) For the selection of training dataset, it is important to select data with similar regional target distribution as the test set instead of utilizing data from the same sensor. (2) For model structure, cascaded structure that flexibly adapts to different sizes of features is preferred. (3) For training manner, unsupervised methods generalize better than supervised methods, and we design an unsupervised early-stop strategy to help retain the best model with pre-trained weights as the basis. Extensive experiments are conducted to support the previous findings, on the basis of which we present an unsupervised stereo matching network with good generalization performance. We release the source code and the datasets at https://github.com/Elenairene/RKF_RSSM to reproduce the results and encourage future work.","sentences":["Stereo matching, a critical step of 3D reconstruction, has fully shifted towards deep learning due to its strong feature representation of remote sensing images.","However, ground truth for stereo matching task relies on expensive airborne LiDAR data, thus making it difficult to obtain enough samples for supervised learning.","To improve the generalization ability of stereo matching networks on cross-domain data from different sensors and scenarios, in this paper, we dedicate to study key training factors from three perspectives.","(1) For the selection of training dataset, it is important to select data with similar regional target distribution as the test set instead of utilizing data from the same sensor.","(2) For model structure, cascaded structure that flexibly adapts to different sizes of features is preferred.","(3) For training manner, unsupervised methods generalize better than supervised methods, and we design an unsupervised early-stop strategy to help retain the best model with pre-trained weights as the basis.","Extensive experiments are conducted to support the previous findings, on the basis of which we present an unsupervised stereo matching network with good generalization performance.","We release the source code and the datasets at https://github.com/Elenairene/RKF_RSSM to reproduce the results and encourage future work."],"url":"http://arxiv.org/abs/2408.07613v1"}
{"created":"2024-08-14 15:10:13","title":"Panacea+: Panoramic and Controllable Video Generation for Autonomous Driving","abstract":"The field of autonomous driving increasingly demands high-quality annotated video training data. In this paper, we propose Panacea+, a powerful and universally applicable framework for generating video data in driving scenes. Built upon the foundation of our previous work, Panacea, Panacea+ adopts a multi-view appearance noise prior mechanism and a super-resolution module for enhanced consistency and increased resolution. Extensive experiments show that the generated video samples from Panacea+ greatly benefit a wide range of tasks on different datasets, including 3D object tracking, 3D object detection, and lane detection tasks on the nuScenes and Argoverse 2 dataset. These results strongly prove Panacea+ to be a valuable data generation framework for autonomous driving.","sentences":["The field of autonomous driving increasingly demands high-quality annotated video training data.","In this paper, we propose Panacea+, a powerful and universally applicable framework for generating video data in driving scenes.","Built upon the foundation of our previous work, Panacea, Panacea+ adopts a multi-view appearance noise prior mechanism and a super-resolution module for enhanced consistency and increased resolution.","Extensive experiments show that the generated video samples from Panacea+ greatly benefit a wide range of tasks on different datasets, including 3D object tracking, 3D object detection, and lane detection tasks on the nuScenes and Argoverse 2 dataset.","These results strongly prove Panacea+ to be a valuable data generation framework for autonomous driving."],"url":"http://arxiv.org/abs/2408.07605v1"}
{"created":"2024-08-14 14:49:25","title":"Crossover Designs in Software Engineering Experiments: Review of the State of Analysis","abstract":"Experimentation is an essential method for causal inference in any empirical discipline. Crossover-design experiments are common in Software Engineering (SE) research. In these, subjects apply more than one treatment in different orders. This design increases the amount of obtained data and deals with subject variability but introduces threats to internal validity like the learning and carryover effect. Vegas et al. reviewed the state of practice for crossover designs in SE research and provided guidelines on how to address its threats during data analysis while still harnessing its benefits. In this paper, we reflect on the impact of these guidelines and review the state of analysis of crossover design experiments in SE publications between 2015 and March 2024. To this end, by conducting a forward snowballing of the guidelines, we survey 136 publications reporting 67 crossover-design experiments and evaluate their data analysis against the provided guidelines. The results show that the validity of data analyses has improved compared to the original state of analysis. Still, despite the explicit guidelines, only 29.5% of all threats to validity were addressed properly. While the maturation and the optimal sequence threats are properly addressed in 35.8% and 38.8% of all studies in our sample respectively, the carryover threat is only modeled in about 3% of the observed cases. The lack of adherence to the analysis guidelines threatens the validity of the conclusions drawn from crossover design experiments","sentences":["Experimentation is an essential method for causal inference in any empirical discipline.","Crossover-design experiments are common in Software Engineering (SE) research.","In these, subjects apply more than one treatment in different orders.","This design increases the amount of obtained data and deals with subject variability but introduces threats to internal validity like the learning and carryover effect.","Vegas et al. reviewed the state of practice for crossover designs in SE research and provided guidelines on how to address its threats during data analysis while still harnessing its benefits.","In this paper, we reflect on the impact of these guidelines and review the state of analysis of crossover design experiments in SE publications between 2015 and March 2024.","To this end, by conducting a forward snowballing of the guidelines, we survey 136 publications reporting 67 crossover-design experiments and evaluate their data analysis against the provided guidelines.","The results show that the validity of data analyses has improved compared to the original state of analysis.","Still, despite the explicit guidelines, only 29.5% of all threats to validity were addressed properly.","While the maturation and the optimal sequence threats are properly addressed in 35.8% and 38.8% of all studies in our sample respectively, the carryover threat is only modeled in about 3% of the observed cases.","The lack of adherence to the analysis guidelines threatens the validity of the conclusions drawn from crossover design experiments"],"url":"http://arxiv.org/abs/2408.07594v1"}
{"created":"2024-08-14 14:41:51","title":"Creating Data Art: Authentic Learning and Visualisation Exhibition","abstract":"We present an authentic learning task designed for computing students, centred on the creation of data-art visualisations from chosen datasets for a public exhibition. This exhibition was showcased in the cinema foyer for two weeks in June, providing a real-world platform for students to display their work. Over the course of two years, we implemented this active learning task with two different cohorts of students. In this paper, we share our experiences and insights from these activities, highlighting the impact on student engagement and learning outcomes. We also provide a detailed description of the seven individual tasks that learners must perform: topic and data selection and analysis, research and art inspiration, design conceptualisation, proposed solution, visualisation creation, exhibition curation, and reflection. By integrating these tasks, students not only develop technical skills but also gain practical experience in presenting their work to a public audience, bridging the gap between academic learning and professional practice.","sentences":["We present an authentic learning task designed for computing students, centred on the creation of data-art visualisations from chosen datasets for a public exhibition.","This exhibition was showcased in the cinema foyer for two weeks in June, providing a real-world platform for students to display their work.","Over the course of two years, we implemented this active learning task with two different cohorts of students.","In this paper, we share our experiences and insights from these activities, highlighting the impact on student engagement and learning outcomes.","We also provide a detailed description of the seven individual tasks that learners must perform: topic and data selection and analysis, research and art inspiration, design conceptualisation, proposed solution, visualisation creation, exhibition curation, and reflection.","By integrating these tasks, students not only develop technical skills but also gain practical experience in presenting their work to a public audience, bridging the gap between academic learning and professional practice."],"url":"http://arxiv.org/abs/2408.07590v1"}
{"created":"2024-08-14 14:36:28","title":"FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher","abstract":"Federated Learning (FL) promises better privacy guarantees for individuals' data when machine learning models are collaboratively trained. When an FL participant exercises its right to be forgotten, i.e., to detach from the FL framework it has participated and to remove its past contributions to the global model, the FL solution should perform all the necessary steps to make it possible without sacrificing the overall performance of the global model, which is not supported in state-of-the-art related solutions nowadays. In this paper, we propose FedQUIT, a novel algorithm that uses knowledge distillation to scrub the contribution of the forgetting data from an FL global model while preserving its generalization ability. FedQUIT directly works on clients' devices and does not require sharing additional information if compared with a regular FL process, nor does it assume the availability of publicly available proxy data. Our solution is efficient, effective, and applicable in both centralized and federated settings. Our experimental results show that, on average, FedQUIT requires less than 2.5% additional communication rounds to recover generalization performances after unlearning, obtaining a sanitized global model whose predictions are comparable to those of a global model that has never seen the data to be forgotten.","sentences":["Federated Learning (FL) promises better privacy guarantees for individuals' data when machine learning models are collaboratively trained.","When an FL participant exercises its right to be forgotten, i.e., to detach from the FL framework it has participated and to remove its past contributions to the global model, the FL solution should perform all the necessary steps to make it possible without sacrificing the overall performance of the global model, which is not supported in state-of-the-art related solutions nowadays.","In this paper, we propose FedQUIT, a novel algorithm that uses knowledge distillation to scrub the contribution of the forgetting data from an FL global model while preserving its generalization ability.","FedQUIT directly works on clients' devices and does not require sharing additional information if compared with a regular FL process, nor does it assume the availability of publicly available proxy data.","Our solution is efficient, effective, and applicable in both centralized and federated settings.","Our experimental results show that, on average, FedQUIT requires less than 2.5% additional communication rounds to recover generalization performances after unlearning, obtaining a sanitized global model whose predictions are comparable to those of a global model that has never seen the data to be forgotten."],"url":"http://arxiv.org/abs/2408.07587v1"}
{"created":"2024-08-14 14:28:11","title":"Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey","abstract":"With significant advancements in Transformers LLMs, NLP has extended its reach into many research fields due to its enhanced capabilities in text generation and user interaction. One field benefiting greatly from these advancements is cybersecurity. In cybersecurity, many parameters that need to be protected and exchanged between senders and receivers are in the form of text and tabular data, making NLP a valuable tool in enhancing the security measures of communication protocols. This survey paper provides a comprehensive analysis of the utilization of Transformers and LLMs in cyber-threat detection systems. The methodology of paper selection and bibliometric analysis is outlined to establish a rigorous framework for evaluating existing research. The fundamentals of Transformers are discussed, including background information on various cyber-attacks and datasets commonly used in this field. The survey explores the application of Transformers in IDSs, focusing on different architectures such as Attention-based models, LLMs like BERT and GPT, CNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others. Furthermore, it explores the diverse environments and applications where Transformers and LLMs-based IDS have been implemented, including computer networks, IoT devices, critical infrastructure protection, cloud computing, SDN, as well as in autonomous vehicles. The paper also addresses research challenges and future directions in this area, identifying key issues such as interpretability, scalability, and adaptability to evolving threats, and more. Finally, the conclusion summarizes the findings and highlights the significance of Transformers and LLMs in enhancing cyber-threat detection capabilities, while also outlining potential avenues for further research and development.","sentences":["With significant advancements in Transformers LLMs, NLP has extended its reach into many research fields due to its enhanced capabilities in text generation and user interaction.","One field benefiting greatly from these advancements is cybersecurity.","In cybersecurity, many parameters that need to be protected and exchanged between senders and receivers are in the form of text and tabular data, making NLP a valuable tool in enhancing the security measures of communication protocols.","This survey paper provides a comprehensive analysis of the utilization of Transformers and LLMs in cyber-threat detection systems.","The methodology of paper selection and bibliometric analysis is outlined to establish a rigorous framework for evaluating existing research.","The fundamentals of Transformers are discussed, including background information on various cyber-attacks and datasets commonly used in this field.","The survey explores the application of Transformers in IDSs, focusing on different architectures such as Attention-based models, LLMs like BERT and GPT, CNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others.","Furthermore, it explores the diverse environments and applications where Transformers and LLMs-based IDS have been implemented, including computer networks, IoT devices, critical infrastructure protection, cloud computing, SDN, as well as in autonomous vehicles.","The paper also addresses research challenges and future directions in this area, identifying key issues such as interpretability, scalability, and adaptability to evolving threats, and more.","Finally, the conclusion summarizes the findings and highlights the significance of Transformers and LLMs in enhancing cyber-threat detection capabilities, while also outlining potential avenues for further research and development."],"url":"http://arxiv.org/abs/2408.07583v1"}
{"created":"2024-08-14 14:23:12","title":"TabularBench: Benchmarking Adversarial Robustness for Tabular Deep Learning in Real-world Use-cases","abstract":"While adversarial robustness in computer vision is a mature research field, fewer researchers have tackled the evasion attacks against tabular deep learning, and even fewer investigated robustification mechanisms and reliable defenses. We hypothesize that this lag in the research on tabular adversarial attacks is in part due to the lack of standardized benchmarks. To fill this gap, we propose TabularBench, the first comprehensive benchmark of robustness of tabular deep learning classification models. We evaluated adversarial robustness with CAA, an ensemble of gradient and search attacks which was recently demonstrated as the most effective attack against a tabular model. In addition to our open benchmark (https://github.com/serval-uni-lu/tabularbench) where we welcome submissions of new models and defenses, we implement 7 robustification mechanisms inspired by state-of-the-art defenses in computer vision and propose the largest benchmark of robust tabular deep learning over 200 models across five critical scenarios in finance, healthcare and security. We curated real datasets for each use case, augmented with hundreds of thousands of realistic synthetic inputs, and trained and assessed our models with and without data augmentations. We open-source our library that provides API access to all our pre-trained robust tabular models, and the largest datasets of real and synthetic tabular inputs. Finally, we analyze the impact of various defenses on the robustness and provide actionable insights to design new defenses and robustification mechanisms.","sentences":["While adversarial robustness in computer vision is a mature research field, fewer researchers have tackled the evasion attacks against tabular deep learning, and even fewer investigated robustification mechanisms and reliable defenses.","We hypothesize that this lag in the research on tabular adversarial attacks is in part due to the lack of standardized benchmarks.","To fill this gap, we propose TabularBench, the first comprehensive benchmark of robustness of tabular deep learning classification models.","We evaluated adversarial robustness with CAA, an ensemble of gradient and search attacks which was recently demonstrated as the most effective attack against a tabular model.","In addition to our open benchmark (https://github.com/serval-uni-lu/tabularbench) where we welcome submissions of new models and defenses, we implement 7 robustification mechanisms inspired by state-of-the-art defenses in computer vision and propose the largest benchmark of robust tabular deep learning over 200 models across five critical scenarios in finance, healthcare and security.","We curated real datasets for each use case, augmented with hundreds of thousands of realistic synthetic inputs, and trained and assessed our models with and without data augmentations.","We open-source our library that provides API access to all our pre-trained robust tabular models, and the largest datasets of real and synthetic tabular inputs.","Finally, we analyze the impact of various defenses on the robustness and provide actionable insights to design new defenses and robustification mechanisms."],"url":"http://arxiv.org/abs/2408.07579v1"}
{"created":"2024-08-14 14:18:51","title":"A Nested Graph Reinforcement Learning-based Decision-making Strategy for Eco-platooning","abstract":"Platooning technology is renowned for its precise vehicle control, traffic flow optimization, and energy efficiency enhancement. However, in large-scale mixed platoons, vehicle heterogeneity and unpredictable traffic conditions lead to virtual bottlenecks. These bottlenecks result in reduced traffic throughput and increased energy consumption within the platoon. To address these challenges, we introduce a decision-making strategy based on nested graph reinforcement learning. This strategy improves collaborative decision-making, ensuring energy efficiency and alleviating congestion. We propose a theory of nested traffic graph representation that maps dynamic interactions between vehicles and platoons in non-Euclidean spaces. By incorporating spatio-temporal weighted graph into a multi-head attention mechanism, we further enhance the model's capacity to process both local and global data. Additionally, we have developed a nested graph reinforcement learning framework to enhance the self-iterative learning capabilities of platooning. Using the I-24 dataset, we designed and conducted comparative algorithm experiments, generalizability testing, and permeability ablation experiments, thereby validating the proposed strategy's effectiveness. Compared to the baseline, our strategy increases throughput by 10% and decreases energy use by 9%. Specifically, increasing the penetration rate of CAVs significantly enhances traffic throughput, though it also increases energy consumption.","sentences":["Platooning technology is renowned for its precise vehicle control, traffic flow optimization, and energy efficiency enhancement.","However, in large-scale mixed platoons, vehicle heterogeneity and unpredictable traffic conditions lead to virtual bottlenecks.","These bottlenecks result in reduced traffic throughput and increased energy consumption within the platoon.","To address these challenges, we introduce a decision-making strategy based on nested graph reinforcement learning.","This strategy improves collaborative decision-making, ensuring energy efficiency and alleviating congestion.","We propose a theory of nested traffic graph representation that maps dynamic interactions between vehicles and platoons in non-Euclidean spaces.","By incorporating spatio-temporal weighted graph into a multi-head attention mechanism, we further enhance the model's capacity to process both local and global data.","Additionally, we have developed a nested graph reinforcement learning framework to enhance the self-iterative learning capabilities of platooning.","Using the I-24 dataset, we designed and conducted comparative algorithm experiments, generalizability testing, and permeability ablation experiments, thereby validating the proposed strategy's effectiveness.","Compared to the baseline, our strategy increases throughput by 10% and decreases energy use by 9%.","Specifically, increasing the penetration rate of CAVs significantly enhances traffic throughput, though it also increases energy consumption."],"url":"http://arxiv.org/abs/2408.07578v1"}
{"created":"2024-08-14 14:06:13","title":"Multi-task Heterogeneous Graph Learning on Electronic Health Records","abstract":"Learning electronic health records (EHRs) has received emerging attention because of its capability to facilitate accurate medical diagnosis. Since the EHRs contain enriched information specifying complex interactions between entities, modeling EHRs with graphs is shown to be effective in practice. The EHRs, however, present a great degree of heterogeneity, sparsity, and complexity, which hamper the performance of most of the models applied to them. Moreover, existing approaches modeling EHRs often focus on learning the representations for a single task, overlooking the multi-task nature of EHR analysis problems and resulting in limited generalizability across different tasks. In view of these limitations, we propose a novel framework for EHR modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous graph to mine the complex relations and model the heterogeneity in the EHRs. To mitigate the large degree of noise, we introduce a denoising module based on the causal inference framework to adjust for severe confounding effects and reduce noise in the EHR data. Additionally, since our model adopts a single graph neural network for simultaneous multi-task prediction, we design a multi-task learning module to leverage the inter-task knowledge to regularize the training process. Extensive empirical studies on MIMIC-III and MIMIC-IV datasets validate that the proposed method consistently outperforms the state-of-the-art designs in four popular EHR analysis tasks -- drug recommendation, and predictions of the length of stay, mortality, and readmission. Thorough ablation studies demonstrate the robustness of our method upon variations to key components and hyperparameters.","sentences":["Learning electronic health records (EHRs) has received emerging attention because of its capability to facilitate accurate medical diagnosis.","Since the EHRs contain enriched information specifying complex interactions between entities, modeling EHRs with graphs is shown to be effective in practice.","The EHRs, however, present a great degree of heterogeneity, sparsity, and complexity, which hamper the performance of most of the models applied to them.","Moreover, existing approaches modeling EHRs often focus on learning the representations for a single task, overlooking the multi-task nature of EHR analysis problems and resulting in limited generalizability across different tasks.","In view of these limitations, we propose a novel framework for EHR modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous graph to mine the complex relations and model the heterogeneity in the EHRs.","To mitigate the large degree of noise, we introduce a denoising module based on the causal inference framework to adjust for severe confounding effects and reduce noise in the EHR data.","Additionally, since our model adopts a single graph neural network for simultaneous multi-task prediction, we design a multi-task learning module to leverage the inter-task knowledge to regularize the training process.","Extensive empirical studies on MIMIC-III and MIMIC-IV datasets validate that the proposed method consistently outperforms the state-of-the-art designs in four popular EHR analysis tasks -- drug recommendation, and predictions of the length of stay, mortality, and readmission.","Thorough ablation studies demonstrate the robustness of our method upon variations to key components and hyperparameters."],"url":"http://arxiv.org/abs/2408.07569v1"}
{"created":"2024-08-14 13:43:59","title":"Sonic: Fast and Transferable Data Poisoning on Clustering Algorithms","abstract":"Data poisoning attacks on clustering algorithms have received limited attention, with existing methods struggling to scale efficiently as dataset sizes and feature counts increase. These attacks typically require re-clustering the entire dataset multiple times to generate predictions and assess the attacker's objectives, significantly hindering their scalability. This paper addresses these limitations by proposing Sonic, a novel genetic data poisoning attack that leverages incremental and scalable clustering algorithms, e.g., FISHDBC, as surrogates to accelerate poisoning attacks against graph-based and density-based clustering methods, such as HDBSCAN. We empirically demonstrate the effectiveness and efficiency of Sonic in poisoning the target clustering algorithms. We then conduct a comprehensive analysis of the factors affecting the scalability and transferability of poisoning attacks against clustering algorithms, and we conclude by examining the robustness of hyperparameters in our attack strategy Sonic.","sentences":["Data poisoning attacks on clustering algorithms have received limited attention, with existing methods struggling to scale efficiently as dataset sizes and feature counts increase.","These attacks typically require re-clustering the entire dataset multiple times to generate predictions and assess the attacker's objectives, significantly hindering their scalability.","This paper addresses these limitations by proposing Sonic, a novel genetic data poisoning attack that leverages incremental and scalable clustering algorithms, e.g., FISHDBC, as surrogates to accelerate poisoning attacks against graph-based and density-based clustering methods, such as HDBSCAN.","We empirically demonstrate the effectiveness and efficiency of Sonic in poisoning the target clustering algorithms.","We then conduct a comprehensive analysis of the factors affecting the scalability and transferability of poisoning attacks against clustering algorithms, and we conclude by examining the robustness of hyperparameters in our attack strategy Sonic."],"url":"http://arxiv.org/abs/2408.07558v1"}
{"created":"2024-08-14 13:31:32","title":"$\u03c7$SPN: Characteristic Interventional Sum-Product Networks for Causal Inference in Hybrid Domains","abstract":"Causal inference in hybrid domains, characterized by a mixture of discrete and continuous variables, presents a formidable challenge. We take a step towards this direction and propose Characteristic Interventional Sum-Product Network ($\\chi$SPN) that is capable of estimating interventional distributions in presence of random variables drawn from mixed distributions. $\\chi$SPN uses characteristic functions in the leaves of an interventional SPN (iSPN) thereby providing a unified view for discrete and continuous random variables through the Fourier-Stieltjes transform of the probability measures. A neural network is used to estimate the parameters of the learned iSPN using the intervened data. Our experiments on 3 synthetic heterogeneous datasets suggest that $\\chi$SPN can effectively capture the interventional distributions for both discrete and continuous variables while being expressive and causally adequate. We also show that $\\chi$SPN generalize to multiple interventions while being trained only on a single intervention data.","sentences":["Causal inference in hybrid domains, characterized by a mixture of discrete and continuous variables, presents a formidable challenge.","We take a step towards this direction and propose Characteristic Interventional Sum-Product Network ($\\chi$SPN) that is capable of estimating interventional distributions in presence of random variables drawn from mixed distributions.","$\\chi$SPN uses characteristic functions in the leaves of an interventional SPN (iSPN) thereby providing a unified view for discrete and continuous random variables through the Fourier-Stieltjes transform of the probability measures.","A neural network is used to estimate the parameters of the learned iSPN using the intervened data.","Our experiments on 3 synthetic heterogeneous datasets suggest that $\\chi$SPN can effectively capture the interventional distributions for both discrete and continuous variables while being expressive and causally adequate.","We also show that $\\chi$SPN generalize to multiple interventions while being trained only on a single intervention data."],"url":"http://arxiv.org/abs/2408.07545v1"}
{"created":"2024-08-14 13:14:27","title":"Usefulness of data flow diagrams and large language models for security threat validation: a registered report","abstract":"The arrival of recent cybersecurity standards has raised the bar for security assessments in organizations, but existing techniques don't always scale well. Threat analysis and risk assessment are used to identify security threats for new or refactored systems. Still, there is a lack of definition-of-done, so identified threats have to be validated which slows down the analysis. Existing literature has focused on the overall performance of threat analysis, but no previous work has investigated how deep must the analysts dig into the material before they can effectively validate the identified security threats. We propose a controlled experiment with practitioners to investigate whether some analysis material (like LLM-generated advice) is better than none and whether more material (the system's data flow diagram and LLM-generated advice) is better than some material. In addition, we present key findings from running a pilot with 41 MSc students, which are used to improve the study design. Finally, we also provide an initial replication package, including experimental material and data analysis scripts and a plan to extend it to include new materials based on the final data collection campaign with practitioners (e.g., pre-screening questions).","sentences":["The arrival of recent cybersecurity standards has raised the bar for security assessments in organizations, but existing techniques don't always scale well.","Threat analysis and risk assessment are used to identify security threats for new or refactored systems.","Still, there is a lack of definition-of-done, so identified threats have to be validated which slows down the analysis.","Existing literature has focused on the overall performance of threat analysis, but no previous work has investigated how deep must the analysts dig into the material before they can effectively validate the identified security threats.","We propose a controlled experiment with practitioners to investigate whether some analysis material (like LLM-generated advice) is better than none and whether more material (the system's data flow diagram and LLM-generated advice) is better than some material.","In addition, we present key findings from running a pilot with 41 MSc students, which are used to improve the study design.","Finally, we also provide an initial replication package, including experimental material and data analysis scripts and a plan to extend it to include new materials based on the final data collection campaign with practitioners (e.g., pre-screening questions)."],"url":"http://arxiv.org/abs/2408.07537v1"}
{"created":"2024-08-14 13:04:34","title":"Information-Theoretic Measures on Lattices for High-Order Interactions","abstract":"Traditional models reliant solely on pairwise associations often prove insufficient in capturing the complex statistical structure inherent in multivariate data. Yet existing methods for identifying information shared among groups of $d>3$ variables are often intractable; asymmetric around a target variable; or unable to consider all factorisations of the joint probability distribution. Here, we present a framework that systematically derives high-order measures using lattice and operator function pairs, whereby the lattice captures the algebraic relational structure of the variables and the operator function computes measures over the lattice. We show that many existing information-theoretic high-order measures can be derived by using divergences as operator functions on sublattices of the partition lattice, thus preventing the accurate quantification of all interactions for $d>3$. Similarly, we show that using the KL divergence as the operator function also leads to unwanted cancellation of interactions for $d>3$. To characterise all interactions among $d$ variables, we introduce the Streitberg information defined on the full partition lattice using generalisations of the KL divergence as operator functions. We validate our results numerically on synthetic data, and illustrate the use of the Streitberg information through applications to stock market returns and neural electrophysiology data.","sentences":["Traditional models reliant solely on pairwise associations often prove insufficient in capturing the complex statistical structure inherent in multivariate data.","Yet existing methods for identifying information shared among groups of $d>3$ variables are often intractable; asymmetric around a target variable; or unable to consider all factorisations of the joint probability distribution.","Here, we present a framework that systematically derives high-order measures using lattice and operator function pairs, whereby the lattice captures the algebraic relational structure of the variables and the operator function computes measures over the lattice.","We show that many existing information-theoretic high-order measures can be derived by using divergences as operator functions on sublattices of the partition lattice, thus preventing the accurate quantification of all interactions for $d>3$. Similarly, we show that using the KL divergence as the operator function also leads to unwanted cancellation of interactions for $d>3$. To characterise all interactions among $d$ variables, we introduce the Streitberg information defined on the full partition lattice using generalisations of the KL divergence as operator functions.","We validate our results numerically on synthetic data, and illustrate the use of the Streitberg information through applications to stock market returns and neural electrophysiology data."],"url":"http://arxiv.org/abs/2408.07533v1"}
{"created":"2024-08-14 13:03:31","title":"Towards Real-time Video Compressive Sensing on Mobile Devices","abstract":"Video Snapshot Compressive Imaging (SCI) uses a low-speed 2D camera to capture high-speed scenes as snapshot compressed measurements, followed by a reconstruction algorithm to retrieve the high-speed video frames. The fast evolving mobile devices and existing high-performance video SCI reconstruction algorithms motivate us to develop mobile reconstruction methods for real-world applications. Yet, it is still challenging to deploy previous reconstruction algorithms on mobile devices due to the complex inference process, let alone real-time mobile reconstruction. To the best of our knowledge, there is no video SCI reconstruction model designed to run on the mobile devices. Towards this end, in this paper, we present an effective approach for video SCI reconstruction, dubbed MobileSCI, which can run at real-time speed on the mobile devices for the first time. Specifically, we first build a U-shaped 2D convolution-based architecture, which is much more efficient and mobile-friendly than previous state-of-the-art reconstruction methods. Besides, an efficient feature mixing block, based on the channel splitting and shuffling mechanisms, is introduced as a novel bottleneck block of our proposed MobileSCI to alleviate the computational burden. Finally, a customized knowledge distillation strategy is utilized to further improve the reconstruction quality. Extensive results on both simulated and real data show that our proposed MobileSCI can achieve superior reconstruction quality with high efficiency on the mobile devices. Particularly, we can reconstruct a 256 X 256 X 8 snapshot compressed measurement with real-time performance (about 35 FPS) on an iPhone 15. Code is available at https://github.com/mcao92/MobileSCI.","sentences":["Video Snapshot Compressive Imaging (SCI) uses a low-speed 2D camera to capture high-speed scenes as snapshot compressed measurements, followed by a reconstruction algorithm to retrieve the high-speed video frames.","The fast evolving mobile devices and existing high-performance video SCI reconstruction algorithms motivate us to develop mobile reconstruction methods for real-world applications.","Yet, it is still challenging to deploy previous reconstruction algorithms on mobile devices due to the complex inference process, let alone real-time mobile reconstruction.","To the best of our knowledge, there is no video SCI reconstruction model designed to run on the mobile devices.","Towards this end, in this paper, we present an effective approach for video SCI reconstruction, dubbed MobileSCI, which can run at real-time speed on the mobile devices for the first time.","Specifically, we first build a U-shaped 2D convolution-based architecture, which is much more efficient and mobile-friendly than previous state-of-the-art reconstruction methods.","Besides, an efficient feature mixing block, based on the channel splitting and shuffling mechanisms, is introduced as a novel bottleneck block of our proposed MobileSCI to alleviate the computational burden.","Finally, a customized knowledge distillation strategy is utilized to further improve the reconstruction quality.","Extensive results on both simulated and real data show that our proposed MobileSCI can achieve superior reconstruction quality with high efficiency on the mobile devices.","Particularly, we can reconstruct a 256 X 256 X 8 snapshot compressed measurement with real-time performance (about 35 FPS) on an iPhone 15.","Code is available at https://github.com/mcao92/MobileSCI."],"url":"http://arxiv.org/abs/2408.07530v1"}
{"created":"2024-08-14 13:02:20","title":"Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation","abstract":"In this paper, we firstly tackle a more realistic Domain Adaptation (DA) setting: Source-Free Blending-Target Domain Adaptation (SF-BTDA), where we can not access to source domain data while facing mixed multiple target domains without any domain labels in prior. Compared to existing DA scenarios, SF-BTDA generally faces the co-existence of different label shifts in different targets, along with noisy target pseudo labels generated from the source model. In this paper, we propose a new method called Evidential Contrastive Alignment (ECA) to decouple the blending target domain and alleviate the effect from noisy target pseudo labels. First, to improve the quality of pseudo target labels, we propose a calibrated evidential learning module to iteratively improve both the accuracy and certainty of the resulting model and adaptively generate high-quality pseudo target labels. Second, we design a graph contrastive learning with the domain distance matrix and confidence-uncertainty criterion, to minimize the distribution gap of samples of a same class in the blended target domains, which alleviates the co-existence of different label shifts in blended targets. We conduct a new benchmark based on three standard DA datasets and ECA outperforms other methods with considerable gains and achieves comparable results compared with those that have domain labels or source data in prior.","sentences":["In this paper, we firstly tackle a more realistic Domain Adaptation (DA) setting: Source-Free Blending-Target Domain Adaptation (SF-BTDA), where we can not access to source domain data while facing mixed multiple target domains without any domain labels in prior.","Compared to existing DA scenarios, SF-BTDA generally faces the co-existence of different label shifts in different targets, along with noisy target pseudo labels generated from the source model.","In this paper, we propose a new method called Evidential Contrastive Alignment (ECA) to decouple the blending target domain and alleviate the effect from noisy target pseudo labels.","First, to improve the quality of pseudo target labels, we propose a calibrated evidential learning module to iteratively improve both the accuracy and certainty of the resulting model and adaptively generate high-quality pseudo target labels.","Second, we design a graph contrastive learning with the domain distance matrix and confidence-uncertainty criterion, to minimize the distribution gap of samples of a same class in the blended target domains, which alleviates the co-existence of different label shifts in blended targets.","We conduct a new benchmark based on three standard DA datasets and ECA outperforms other methods with considerable gains and achieves comparable results compared with those that have domain labels or source data in prior."],"url":"http://arxiv.org/abs/2408.07527v1"}
{"created":"2024-08-14 13:00:24","title":"Dinkel: Testing Graph Database Engines via State-Aware Query Generation","abstract":"Graph database management systems (GDBMSs) store and manipulate graph data and form a core part of many data-driven applications. To ensure their reliability, several approaches have been proposed to test GDBMSs by generating queries in Cypher, the most popular graph query language. However, Cypher allows queries with complicated state changes and data dependencies, which existing approaches do not support and thus fail to generate valid, complex queries, thereby missing many bugs in GDBMSs.   In this paper, we propose a novel state-aware testing approach to generate complex Cypher queries for GDBMSs. Our approach models two kinds of graph state, query context and graph schema. Query context describes the available Cypher variables and their corresponding scopes, whereas graph schema summarizes the manipulated graph labels and properties. While generating Cypher queries, we modify the graph states on the fly to ensure each clause within the query can reference the correct state information. In this way, our approach can generate Cypher queries with multiple state changes and complicated data dependencies while retaining high query validity. We implemented this approach as a fully automatic GDBMS testing framework, Dinkel, and evaluated it on three popular open-source GDBMSs, namely Neo4j, RedisGraph, and Apache AGE. In total, Dinkel found 60 bugs, among which 58 were confirmed and 51 fixed. Our evaluation results show that Dinkel can effectively generate complex queries with high validity (93.43%). Compared to existing approaches, Dinkel can cover over 60% more code and find more bugs within the 48-hour testing campaign. We expect Dinkel's powerful test-case generation to benefit GDBMS testing and help strengthen the reliability of GDBMSs.","sentences":["Graph database management systems (GDBMSs) store and manipulate graph data and form a core part of many data-driven applications.","To ensure their reliability, several approaches have been proposed to test GDBMSs by generating queries in Cypher, the most popular graph query language.","However, Cypher allows queries with complicated state changes and data dependencies, which existing approaches do not support and thus fail to generate valid, complex queries, thereby missing many bugs in GDBMSs.   ","In this paper, we propose a novel state-aware testing approach to generate complex Cypher queries for GDBMSs.","Our approach models two kinds of graph state, query context and graph schema.","Query context describes the available Cypher variables and their corresponding scopes, whereas graph schema summarizes the manipulated graph labels and properties.","While generating Cypher queries, we modify the graph states on the fly to ensure each clause within the query can reference the correct state information.","In this way, our approach can generate Cypher queries with multiple state changes and complicated data dependencies while retaining high query validity.","We implemented this approach as a fully automatic GDBMS testing framework, Dinkel, and evaluated it on three popular open-source GDBMSs, namely Neo4j, RedisGraph, and Apache AGE.","In total, Dinkel found 60 bugs, among which 58 were confirmed and 51 fixed.","Our evaluation results show that Dinkel can effectively generate complex queries with high validity (93.43%).","Compared to existing approaches, Dinkel can cover over 60% more code and find more bugs within the 48-hour testing campaign.","We expect Dinkel's powerful test-case generation to benefit GDBMS testing and help strengthen the reliability of GDBMSs."],"url":"http://arxiv.org/abs/2408.07525v1"}
{"created":"2024-08-14 12:09:58","title":"Towards Enhanced Context Awareness with Vision-based Multimodal Interfaces","abstract":"Vision-based Interfaces (VIs) are pivotal in advancing Human-Computer Interaction (HCI), particularly in enhancing context awareness. However, there are significant opportunities for these interfaces due to rapid advancements in multimodal Artificial Intelligence (AI), which promise a future of tight coupling between humans and intelligent systems. AI-driven VIs, when integrated with other modalities, offer a robust solution for effectively capturing and interpreting user intentions and complex environmental information, thereby facilitating seamless and efficient interactions. This PhD study explores three application cases of multimodal interfaces to augment context awareness, respectively focusing on three dimensions of visual modality: scale, depth, and time: a fine-grained analysis of physical surfaces via microscopic image, precise projection of the real world using depth data, and rendering haptic feedback from video background in virtual environments.","sentences":["Vision-based Interfaces (VIs) are pivotal in advancing Human-Computer Interaction (HCI), particularly in enhancing context awareness.","However, there are significant opportunities for these interfaces due to rapid advancements in multimodal Artificial Intelligence (AI), which promise a future of tight coupling between humans and intelligent systems.","AI-driven VIs, when integrated with other modalities, offer a robust solution for effectively capturing and interpreting user intentions and complex environmental information, thereby facilitating seamless and efficient interactions.","This PhD study explores three application cases of multimodal interfaces to augment context awareness, respectively focusing on three dimensions of visual modality: scale, depth, and time: a fine-grained analysis of physical surfaces via microscopic image, precise projection of the real world using depth data, and rendering haptic feedback from video background in virtual environments."],"url":"http://arxiv.org/abs/2408.07488v1"}
{"created":"2024-08-14 12:05:07","title":"OMR: Occlusion-Aware Memory-Based Refinement for Video Lane Detection","abstract":"A novel algorithm for video lane detection is proposed in this paper. First, we extract a feature map for a current frame and detect a latent mask for obstacles occluding lanes. Then, we enhance the feature map by developing an occlusion-aware memory-based refinement (OMR) module. It takes the obstacle mask and feature map from the current frame, previous output, and memory information as input, and processes them recursively in a video. Moreover, we apply a novel data augmentation scheme for training the OMR module effectively. Experimental results show that the proposed algorithm outperforms existing techniques on video lane datasets. Our codes are available at https://github.com/dongkwonjin/OMR.","sentences":["A novel algorithm for video lane detection is proposed in this paper.","First, we extract a feature map for a current frame and detect a latent mask for obstacles occluding lanes.","Then, we enhance the feature map by developing an occlusion-aware memory-based refinement (OMR) module.","It takes the obstacle mask and feature map from the current frame, previous output, and memory information as input, and processes them recursively in a video.","Moreover, we apply a novel data augmentation scheme for training the OMR module effectively.","Experimental results show that the proposed algorithm outperforms existing techniques on video lane datasets.","Our codes are available at https://github.com/dongkwonjin/OMR."],"url":"http://arxiv.org/abs/2408.07486v1"}
{"created":"2024-08-14 11:55:50","title":"Visualization Atlases: Explaining and Exploring Complex Topics through Data, Visualization, and Narration","abstract":"This paper defines, analyzes, and discusses the emerging genre of visualization atlases. We currently witness an increase in web-based, data-driven initiatives that call themselves \"atlases\" while explaining complex, contemporary issues through data and visualizations: climate change, sustainability, AI, or cultural discoveries. To understand this emerging genre and inform their design, study, and authoring support, we conducted a systematic analysis of 33 visualization atlases and semi-structured interviews with eight visualization atlas creators. Based on our results, we contribute (1) a definition of a visualization atlas as a compendium of (web) pages aimed at explaining and supporting exploration of data about a dedicated topic through data, visualizations and narration. (2) a set of design patterns of 8 design dimensions, (3) insights into the atlas creation from interviews and (4) the definition of 5 visualization atlas genres. We found that visualization atlases are unique in the way they combine i) exploratory visualization, ii) narrative elements from data-driven storytelling and iii) structured navigation mechanisms. They target a wide range of audiences with different levels of domain knowledge, acting as tools for study, communication, and discovery. We conclude with a discussion of current design practices and emerging questions around the ethics and potential real-world impact of visualization atlases, aimed to inform the design and study of visualization atlases.","sentences":["This paper defines, analyzes, and discusses the emerging genre of visualization atlases.","We currently witness an increase in web-based, data-driven initiatives that call themselves \"atlases\" while explaining complex, contemporary issues through data and visualizations: climate change, sustainability, AI, or cultural discoveries.","To understand this emerging genre and inform their design, study, and authoring support, we conducted a systematic analysis of 33 visualization atlases and semi-structured interviews with eight visualization atlas creators.","Based on our results, we contribute (1) a definition of a visualization atlas as a compendium of (web) pages aimed at explaining and supporting exploration of data about a dedicated topic through data, visualizations and narration.","(2) a set of design patterns of 8 design dimensions, (3) insights into the atlas creation from interviews and (4) the definition of 5 visualization atlas genres.","We found that visualization atlases are unique in the way they combine i) exploratory visualization, ii) narrative elements from data-driven storytelling and iii) structured navigation mechanisms.","They target a wide range of audiences with different levels of domain knowledge, acting as tools for study, communication, and discovery.","We conclude with a discussion of current design practices and emerging questions around the ethics and potential real-world impact of visualization atlases, aimed to inform the design and study of visualization atlases."],"url":"http://arxiv.org/abs/2408.07483v1"}
{"created":"2024-08-14 11:49:24","title":"A Study on Bias Detection and Classification in Natural Language Processing","abstract":"Human biases have been shown to influence the performance of models and algorithms in various fields, including Natural Language Processing. While the study of this phenomenon is garnering focus in recent years, the available resources are still relatively scarce, often focusing on different forms or manifestations of biases. The aim of our work is twofold: 1) gather publicly-available datasets and determine how to better combine them to effectively train models in the task of hate speech detection and classification; 2) analyse the main issues with these datasets, such as scarcity, skewed resources, and reliance on non-persistent data. We discuss these issues in tandem with the development of our experiments, in which we show that the combinations of different datasets greatly impact the models' performance.","sentences":["Human biases have been shown to influence the performance of models and algorithms in various fields, including Natural Language Processing.","While the study of this phenomenon is garnering focus in recent years, the available resources are still relatively scarce, often focusing on different forms or manifestations of biases.","The aim of our work is twofold: 1) gather publicly-available datasets and determine how to better combine them to effectively train models in the task of hate speech detection and classification; 2) analyse the main issues with these datasets, such as scarcity, skewed resources, and reliance on non-persistent data.","We discuss these issues in tandem with the development of our experiments, in which we show that the combinations of different datasets greatly impact the models' performance."],"url":"http://arxiv.org/abs/2408.07479v1"}
{"created":"2024-08-14 11:48:09","title":"Optical Networks","abstract":"Optical networks play a crucial role in todays digital topography, enabling the high-speed and reliable transmission of vast amounts of data over optical fibre for long distances. This paper provides an overview of optical networks, especially emphasising on their evolution with time.","sentences":["Optical networks play a crucial role in todays digital topography, enabling the high-speed and reliable transmission of vast amounts of data over optical fibre for long distances.","This paper provides an overview of optical networks, especially emphasising on their evolution with time."],"url":"http://arxiv.org/abs/2408.07478v1"}
{"created":"2024-08-14 11:47:22","title":"One Step Diffusion-based Super-Resolution with Time-Aware Distillation","abstract":"Diffusion-based image super-resolution (SR) methods have shown promise in reconstructing high-resolution images with fine details from low-resolution counterparts. However, these approaches typically require tens or even hundreds of iterative samplings, resulting in significant latency. Recently, techniques have been devised to enhance the sampling efficiency of diffusion-based SR models via knowledge distillation. Nonetheless, when aligning the knowledge of student and teacher models, these solutions either solely rely on pixel-level loss constraints or neglect the fact that diffusion models prioritize varying levels of information at different time steps. To accomplish effective and efficient image super-resolution, we propose a time-aware diffusion distillation method, named TAD-SR. Specifically, we introduce a novel score distillation strategy to align the data distribution between the outputs of the student and teacher models after minor noise perturbation. This distillation strategy enables the student network to concentrate more on the high-frequency details. Furthermore, to mitigate performance limitations stemming from distillation, we integrate a latent adversarial loss and devise a time-aware discriminator that leverages diffusion priors to effectively distinguish between real images and generated images. Extensive experiments conducted on synthetic and real-world datasets demonstrate that the proposed method achieves comparable or even superior performance compared to both previous state-of-the-art (SOTA) methods and the teacher model in just one sampling step. Codes are available at https://github.com/LearningHx/TAD-SR.","sentences":["Diffusion-based image super-resolution (SR) methods have shown promise in reconstructing high-resolution images with fine details from low-resolution counterparts.","However, these approaches typically require tens or even hundreds of iterative samplings, resulting in significant latency.","Recently, techniques have been devised to enhance the sampling efficiency of diffusion-based SR models via knowledge distillation.","Nonetheless, when aligning the knowledge of student and teacher models, these solutions either solely rely on pixel-level loss constraints or neglect the fact that diffusion models prioritize varying levels of information at different time steps.","To accomplish effective and efficient image super-resolution, we propose a time-aware diffusion distillation method, named TAD-SR.","Specifically, we introduce a novel score distillation strategy to align the data distribution between the outputs of the student and teacher models after minor noise perturbation.","This distillation strategy enables the student network to concentrate more on the high-frequency details.","Furthermore, to mitigate performance limitations stemming from distillation, we integrate a latent adversarial loss and devise a time-aware discriminator that leverages diffusion priors to effectively distinguish between real images and generated images.","Extensive experiments conducted on synthetic and real-world datasets demonstrate that the proposed method achieves comparable or even superior performance compared to both previous state-of-the-art (SOTA) methods and the teacher model in just one sampling step.","Codes are available at https://github.com/LearningHx/TAD-SR."],"url":"http://arxiv.org/abs/2408.07476v1"}
{"created":"2024-08-14 11:29:47","title":"Bridging and Modeling Correlations in Pairwise Data for Direct Preference Optimization","abstract":"Direct preference optimization (DPO), a widely adopted offline preference optimization algorithm, aims to align large language models (LLMs) with human-desired behaviors using pairwise preference data. However, the winning response and the losing response within pairwise data are generated isolatedly, leading to weak correlations between them as well as suboptimal alignment performance. To address this issue, we propose an effective framework named BMC, for bridging and modeling correlations in pairwise data. Firstly, we increase the consistency and informativeness of the pairwise preference signals by targeted modifications, synthesizing a pseudo winning response through improving the losing response based on the winning response. Secondly, we identify that DPO alone is insufficient to model these correlations and capture nuanced variations. Therefore, we propose learning token-level correlations by dynamically leveraging the policy model's confidence during training. Comprehensive experiments on QA, math, and instruction-following tasks demonstrate the effectiveness of our approach, significantly surpassing competitive baselines, including DPO. Additionally, our in-depth quantitative analysis reveals the reasons behind our method's superior performance over DPO and showcases its versatility to other DPO variants.","sentences":["Direct preference optimization (DPO), a widely adopted offline preference optimization algorithm, aims to align large language models (LLMs) with human-desired behaviors using pairwise preference data.","However, the winning response and the losing response within pairwise data are generated isolatedly, leading to weak correlations between them as well as suboptimal alignment performance.","To address this issue, we propose an effective framework named BMC, for bridging and modeling correlations in pairwise data.","Firstly, we increase the consistency and informativeness of the pairwise preference signals by targeted modifications, synthesizing a pseudo winning response through improving the losing response based on the winning response.","Secondly, we identify that DPO alone is insufficient to model these correlations and capture nuanced variations.","Therefore, we propose learning token-level correlations by dynamically leveraging the policy model's confidence during training.","Comprehensive experiments on QA, math, and instruction-following tasks demonstrate the effectiveness of our approach, significantly surpassing competitive baselines, including DPO.","Additionally, our in-depth quantitative analysis reveals the reasons behind our method's superior performance over DPO and showcases its versatility to other DPO variants."],"url":"http://arxiv.org/abs/2408.07471v1"}
{"created":"2024-08-14 11:19:28","title":"Large Language Models Prompting With Episodic Memory","abstract":"Prompt optimization is essential for enhancing the performance of Large Language Models (LLMs) in a range of Natural Language Processing (NLP) tasks, particularly in scenarios of few-shot learning where training examples are incorporated directly into the prompt. Despite the growing interest in optimizing prompts with few-shot examples, existing methods for prompt optimization are often resource-intensive or perform inadequately. In this work, we propose PrOmpting with Episodic Memory (POEM), a novel prompt optimization technique that is simple, efficient, and demonstrates strong generalization capabilities. We approach prompt optimization as a Reinforcement Learning (RL) challenge, using episodic memory to archive combinations of input data, permutations of few-shot examples, and the rewards observed during training. In the testing phase, we optimize the sequence of examples for each test query by selecting the sequence that yields the highest total rewards from the top-k most similar training examples in the episodic memory. Our results show that POEM outperforms recent techniques like TEMPERA and RLPrompt by over 5.3% in various text classification tasks. Furthermore, our approach adapts well to broader language understanding tasks, consistently outperforming conventional heuristic methods for ordering examples.","sentences":["Prompt optimization is essential for enhancing the performance of Large Language Models (LLMs) in a range of Natural Language Processing (NLP) tasks, particularly in scenarios of few-shot learning where training examples are incorporated directly into the prompt.","Despite the growing interest in optimizing prompts with few-shot examples, existing methods for prompt optimization are often resource-intensive or perform inadequately.","In this work, we propose PrOmpting with Episodic Memory (POEM), a novel prompt optimization technique that is simple, efficient, and demonstrates strong generalization capabilities.","We approach prompt optimization as a Reinforcement Learning (RL) challenge, using episodic memory to archive combinations of input data, permutations of few-shot examples, and the rewards observed during training.","In the testing phase, we optimize the sequence of examples for each test query by selecting the sequence that yields the highest total rewards from the top-k most similar training examples in the episodic memory.","Our results show that POEM outperforms recent techniques like TEMPERA and RLPrompt by over 5.3% in various text classification tasks.","Furthermore, our approach adapts well to broader language understanding tasks, consistently outperforming conventional heuristic methods for ordering examples."],"url":"http://arxiv.org/abs/2408.07465v1"}
{"created":"2024-08-14 10:58:48","title":"From Brazilian Portuguese to European Portuguese","abstract":"Brazilian Portuguese and European Portuguese are two varieties of the same language and, despite their close similarities, they exhibit several differences. However, there is a significant disproportion in the availability of resources between the two variants, with Brazilian Portuguese having more abundant resources. This inequity can impact the quality of translation services accessible to European Portuguese speakers. To address this issue, we propose the development of a Brazilian Portuguese to European Portuguese translation system, leveraging recent advancements in neural architectures and models. To evaluate the performance of such systems, we manually curated a gold test set comprising 500 sentences across five different topics. Each sentence in the gold test set has two distinct references, facilitating a straightforward evaluation of future translation models. We experimented with various models by fine-tuning existing Large Language Models using parallel data extracted from movie subtitles and TED Talks transcripts in both Brazilian and European Portuguese. Our evaluation involved the use of conventional automatic metrics as well as a human evaluation. In addition, all models were compared against ChatGPT 3.5 Turbo, which currently yields the best results.","sentences":["Brazilian Portuguese and European Portuguese are two varieties of the same language and, despite their close similarities, they exhibit several differences.","However, there is a significant disproportion in the availability of resources between the two variants, with Brazilian Portuguese having more abundant resources.","This inequity can impact the quality of translation services accessible to European Portuguese speakers.","To address this issue, we propose the development of a Brazilian Portuguese to European Portuguese translation system, leveraging recent advancements in neural architectures and models.","To evaluate the performance of such systems, we manually curated a gold test set comprising 500 sentences across five different topics.","Each sentence in the gold test set has two distinct references, facilitating a straightforward evaluation of future translation models.","We experimented with various models by fine-tuning existing Large Language Models using parallel data extracted from movie subtitles and TED Talks transcripts in both Brazilian and European Portuguese.","Our evaluation involved the use of conventional automatic metrics as well as a human evaluation.","In addition, all models were compared against ChatGPT 3.5 Turbo, which currently yields the best results."],"url":"http://arxiv.org/abs/2408.07457v1"}
{"created":"2024-08-14 10:49:39","title":"A Survey on Immersive Cyber Situational Awareness Systems","abstract":"Cyber situational awareness systems are increasingly used for creating cyber common operating pictures for cybersecurity analysis and education. However, these systems face data occlusion and convolution issues due to the burgeoning complexity, dimensionality, and heterogeneity of cybersecurity data, which damages cyber Situational Awareness (SA) of end-users. Moreover, conventional ways of human-computer interactions, such as mouse and keyboard, increase the mental effort and cognitive load of cybersecurity practitioners, when analyzing cyber situations of large-scale infrastructures. Therefore, immersive technologies, such as virtual reality, augmented reality, and mixed reality, are employed in the cybersecurity realm to create intuitive, engaging, and interactive cyber common operating pictures. The Immersive Cyber Situational Awareness (ICSA) systems provide several unique visualization techniques and interaction features for the perception, comprehension, and projection of cyber SA. However, there has been no attempt to comprehensively investigate and classify the existing state of the art in the use of immersive technologies for cyber SA. Therefore, in this paper, we have gathered, analyzed, and synthesized the existing body of knowledge on ICSA systems. In particular, our survey has identified visualization and interaction techniques, evaluation mechanisms, and different levels of cyber SA (i.e., perception, comprehension, and projection) for ICSA systems. Consequently, our survey has enabled us to propose: (i) a reference framework for designing and analyzing ICSA systems by mapping immersive visualization and interaction techniques to the different levels of ICSA; (ii) future research directions for advancing the state-of-the-art on ICSA systems; and (iii) an in-depth analysis of the industrial implications of ICSA systems to enhance cybersecurity operations.","sentences":["Cyber situational awareness systems are increasingly used for creating cyber common operating pictures for cybersecurity analysis and education.","However, these systems face data occlusion and convolution issues due to the burgeoning complexity, dimensionality, and heterogeneity of cybersecurity data, which damages cyber Situational Awareness (SA) of end-users.","Moreover, conventional ways of human-computer interactions, such as mouse and keyboard, increase the mental effort and cognitive load of cybersecurity practitioners, when analyzing cyber situations of large-scale infrastructures.","Therefore, immersive technologies, such as virtual reality, augmented reality, and mixed reality, are employed in the cybersecurity realm to create intuitive, engaging, and interactive cyber common operating pictures.","The Immersive Cyber Situational Awareness (ICSA) systems provide several unique visualization techniques and interaction features for the perception, comprehension, and projection of cyber SA.","However, there has been no attempt to comprehensively investigate and classify the existing state of the art in the use of immersive technologies for cyber SA.","Therefore, in this paper, we have gathered, analyzed, and synthesized the existing body of knowledge on ICSA systems.","In particular, our survey has identified visualization and interaction techniques, evaluation mechanisms, and different levels of cyber SA (i.e., perception, comprehension, and projection) for ICSA systems.","Consequently, our survey has enabled us to propose: (i) a reference framework for designing and analyzing ICSA systems by mapping immersive visualization and interaction techniques to the different levels of ICSA; (ii) future research directions for advancing the state-of-the-art on ICSA systems; and (iii) an in-depth analysis of the industrial implications of ICSA systems to enhance cybersecurity operations."],"url":"http://arxiv.org/abs/2408.07456v1"}
{"created":"2024-08-14 10:44:51","title":"CMU's IWSLT 2024 Simultaneous Speech Translation System","abstract":"This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech Translation (SST) task for translating English speech to German text in a streaming manner. Our end-to-end speech-to-text (ST) system integrates the WavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the decoder. We employ a two-stage training approach: initially, we align the representations of speech and text, followed by full fine-tuning. Both stages are trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST model for SST using a simple fixed hold-n policy. Experiments show that our model obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2 seconds latency on the MuST-C-v2 tst-COMMON.","sentences":["This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech Translation (SST) task for translating English speech to German text in a streaming manner.","Our end-to-end speech-to-text (ST) system integrates the WavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the decoder.","We employ a two-stage training approach: initially, we align the representations of speech and text, followed by full fine-tuning.","Both stages are trained on MuST-c v2 data with cross-entropy loss.","We adapt our offline ST model for SST using a simple fixed hold-n policy.","Experiments show that our model obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2 seconds latency on the MuST-C-v2 tst-COMMON."],"url":"http://arxiv.org/abs/2408.07452v1"}
{"created":"2024-08-14 10:18:42","title":"BAPLe: Backdoor Attacks on Medical Foundational Models using Prompt Learning","abstract":"Medical foundation models are gaining prominence in the medical community for their ability to derive general representations from extensive collections of medical image-text pairs. Recent research indicates that these models are susceptible to backdoor attacks, which allow them to classify clean images accurately but fail when specific triggers are introduced. However, traditional backdoor attacks necessitate a considerable amount of additional data to maliciously pre-train a model. This requirement is often impractical in medical imaging applications due to the usual scarcity of data. Inspired by the latest developments in learnable prompts, this work introduces a method to embed a backdoor into the medical foundation model during the prompt learning phase. By incorporating learnable prompts within the text encoder and introducing imperceptible learnable noise trigger to the input images, we exploit the full capabilities of the medical foundation models (Med-FM). Our method, BAPLe, requires only a minimal subset of data to adjust the noise trigger and the text prompts for downstream tasks, enabling the creation of an effective backdoor attack. Through extensive experiments with four medical foundation models, each pre-trained on different modalities and evaluated across six downstream datasets, we demonstrate the efficacy of our approach. BAPLe achieves a high backdoor success rate across all models and datasets, outperforming the baseline backdoor attack methods. Our work highlights the vulnerability of Med-FMs towards backdoor attacks and strives to promote the safe adoption of Med-FMs before their deployment in real-world applications. Code is available at https://asif-hanif.github.io/baple/.","sentences":["Medical foundation models are gaining prominence in the medical community for their ability to derive general representations from extensive collections of medical image-text pairs.","Recent research indicates that these models are susceptible to backdoor attacks, which allow them to classify clean images accurately but fail when specific triggers are introduced.","However, traditional backdoor attacks necessitate a considerable amount of additional data to maliciously pre-train a model.","This requirement is often impractical in medical imaging applications due to the usual scarcity of data.","Inspired by the latest developments in learnable prompts, this work introduces a method to embed a backdoor into the medical foundation model during the prompt learning phase.","By incorporating learnable prompts within the text encoder and introducing imperceptible learnable noise trigger to the input images, we exploit the full capabilities of the medical foundation models (Med-FM).","Our method, BAPLe, requires only a minimal subset of data to adjust the noise trigger and the text prompts for downstream tasks, enabling the creation of an effective backdoor attack.","Through extensive experiments with four medical foundation models, each pre-trained on different modalities and evaluated across six downstream datasets, we demonstrate the efficacy of our approach.","BAPLe achieves a high backdoor success rate across all models and datasets, outperforming the baseline backdoor attack methods.","Our work highlights the vulnerability of Med-FMs towards backdoor attacks and strives to promote the safe adoption of Med-FMs before their deployment in real-world applications.","Code is available at https://asif-hanif.github.io/baple/."],"url":"http://arxiv.org/abs/2408.07440v1"}
{"created":"2024-08-14 10:15:34","title":"Achieving Data Efficient Neural Networks with Hybrid Concept-based Models","abstract":"Most datasets used for supervised machine learning consist of a single label per data point. However, in cases where more information than just the class label is available, would it be possible to train models more efficiently? We introduce two novel model architectures, which we call hybrid concept-based models, that train using both class labels and additional information in the dataset referred to as concepts. In order to thoroughly assess their performance, we introduce ConceptShapes, an open and flexible class of datasets with concept labels. We show that the hybrid concept-based models outperform standard computer vision models and previously proposed concept-based models with respect to accuracy, especially in sparse data settings. We also introduce an algorithm for performing adversarial concept attacks, where an image is perturbed in a way that does not change a concept-based model's concept predictions, but changes the class prediction. The existence of such adversarial examples raises questions about the interpretable qualities promised by concept-based models.","sentences":["Most datasets used for supervised machine learning consist of a single label per data point.","However, in cases where more information than just the class label is available, would it be possible to train models more efficiently?","We introduce two novel model architectures, which we call hybrid concept-based models, that train using both class labels and additional information in the dataset referred to as concepts.","In order to thoroughly assess their performance, we introduce ConceptShapes, an open and flexible class of datasets with concept labels.","We show that the hybrid concept-based models outperform standard computer vision models and previously proposed concept-based models with respect to accuracy, especially in sparse data settings.","We also introduce an algorithm for performing adversarial concept attacks, where an image is perturbed in a way that does not change a concept-based model's concept predictions, but changes the class prediction.","The existence of such adversarial examples raises questions about the interpretable qualities promised by concept-based models."],"url":"http://arxiv.org/abs/2408.07438v1"}
{"created":"2024-08-14 10:14:07","title":"M2L Translation Operators for Kernel Independent Fast Multipole Methods on Modern Architectures","abstract":"Current and future trends in computer hardware, in which the disparity between available flops and memory bandwidth continues to grow, favour algorithm implementations which minimise data movement even at the cost of more flops. In this study we review the requirements for high performance implementations of the kernel independent Fast Multipole Method (kiFMM), a variant of the crucial FMM algorithm for the rapid evaluation of N-body potential problems. Performant implementations of the kiFMM typically rely on Fast Fourier Transforms for the crucial M2L (Multipole-to-Local) operation. However, in recent years for other FMM variants such as the black-box FMM also BLAS based M2L translation operators have become popular that rely on direct matrix compression techniques. In this paper we present algorithmic improvements for BLAS based M2L translation operator and benchmark them against FFT based M2L translation operators. In order to allow a fair comparison we have implemented our own high-performance kiFMM algorithm in Rust that performs competitively against other implementations, and allows us to flexibly switch between BLAS and FFT based translation operators.","sentences":["Current and future trends in computer hardware, in which the disparity between available flops and memory bandwidth continues to grow, favour algorithm implementations which minimise data movement even at the cost of more flops.","In this study we review the requirements for high performance implementations of the kernel independent Fast Multipole Method (kiFMM), a variant of the crucial FMM algorithm for the rapid evaluation of N-body potential problems.","Performant implementations of the kiFMM typically rely on Fast Fourier Transforms for the crucial M2L (Multipole-to-Local) operation.","However, in recent years for other FMM variants such as the black-box FMM also BLAS based M2L translation operators have become popular that rely on direct matrix compression techniques.","In this paper we present algorithmic improvements for BLAS based M2L translation operator and benchmark them against FFT based M2L translation operators.","In order to allow a fair comparison we have implemented our own high-performance kiFMM algorithm in Rust that performs competitively against other implementations, and allows us to flexibly switch between BLAS and FFT based translation operators."],"url":"http://arxiv.org/abs/2408.07436v1"}
{"created":"2024-08-14 10:09:00","title":"Object Augmentation Algorithm: Computing virtual object motion and object induced interaction wrench from optical markers","abstract":"This study addresses the critical need for diverse and comprehensive data focused on human arm joint torques while performing activities of daily living (ADL). Previous studies have often overlooked the influence of objects on joint torques during ADL, resulting in limited datasets for analysis. To address this gap, we propose an Object Augmentation Algorithm (OAA) capable of augmenting existing marker-based databases with virtual object motions and object-induced joint torque estimations. The OAA consists of five phases: (1) computing hand coordinate systems from optical markers, (2) characterising object movements with virtual markers, (3) calculating object motions through inverse kinematics (IK), (4) determining the wrench necessary for prescribed object motion using inverse dynamics (ID), and (5) computing joint torques resulting from object manipulation. The algorithm's accuracy is validated through trajectory tracking and torque analysis on a 7+4 degree of freedom (DoF) robotic hand-arm system, manipulating three unique objects. The results show that the OAA can accurately and precisely estimate 6 DoF object motion and object-induced joint torques. Correlations between computed and measured quantities were > 0.99 for object trajectories and > 0.93 for joint torques. The OAA was further shown to be robust to variations in the number and placement of input markers, which are expected between databases. Differences between repeated experiments were minor but significant (p < 0.05). The algorithm expands the scope of available data and facilitates more comprehensive analyses of human-object interaction dynamics.","sentences":["This study addresses the critical need for diverse and comprehensive data focused on human arm joint torques while performing activities of daily living (ADL).","Previous studies have often overlooked the influence of objects on joint torques during ADL, resulting in limited datasets for analysis.","To address this gap, we propose an Object Augmentation Algorithm (OAA) capable of augmenting existing marker-based databases with virtual object motions and object-induced joint torque estimations.","The OAA consists of five phases: (1) computing hand coordinate systems from optical markers, (2) characterising object movements with virtual markers, (3) calculating object motions through inverse kinematics (IK), (4) determining the wrench necessary for prescribed object motion using inverse dynamics (ID), and (5) computing joint torques resulting from object manipulation.","The algorithm's accuracy is validated through trajectory tracking and torque analysis on a 7+4 degree of freedom (DoF) robotic hand-arm system, manipulating three unique objects.","The results show that the OAA can accurately and precisely estimate 6 DoF object motion and object-induced joint torques.","Correlations between computed and measured quantities were > 0.99 for object trajectories and > 0.93 for joint torques.","The OAA was further shown to be robust to variations in the number and placement of input markers, which are expected between databases.","Differences between repeated experiments were minor but significant (p < 0.05).","The algorithm expands the scope of available data and facilitates more comprehensive analyses of human-object interaction dynamics."],"url":"http://arxiv.org/abs/2408.07434v1"}
{"created":"2024-08-14 09:34:19","title":"Aquila2 Technical Report","abstract":"This paper introduces the Aquila2 series, which comprises a wide range of bilingual models with parameter sizes of 7, 34, and 70 billion. These models are trained based on an innovative framework named HeuriMentor (HM), which offers real-time insights into model convergence and enhances the training process and data management. The HM System, comprising the Adaptive Training Engine (ATE), Training State Monitor (TSM), and Data Management Unit (DMU), allows for precise monitoring of the model's training progress and enables efficient optimization of data distribution, thereby enhancing training effectiveness. Extensive evaluations show that the Aquila2 model series performs comparably well on both English and Chinese benchmarks. Specifically, Aquila2-34B demonstrates only a slight decrease in performance when quantized to Int4. Furthermore, we have made our training code (https://github.com/FlagOpen/FlagScale) and model weights (https://github.com/FlagAI-Open/Aquila2) publicly available to support ongoing research and the development of applications.","sentences":["This paper introduces the Aquila2 series, which comprises a wide range of bilingual models with parameter sizes of 7, 34, and 70 billion.","These models are trained based on an innovative framework named HeuriMentor (HM), which offers real-time insights into model convergence and enhances the training process and data management.","The HM System, comprising the Adaptive Training Engine (ATE), Training State Monitor (TSM), and Data Management Unit (DMU), allows for precise monitoring of the model's training progress and enables efficient optimization of data distribution, thereby enhancing training effectiveness.","Extensive evaluations show that the Aquila2 model series performs comparably well on both English and Chinese benchmarks.","Specifically, Aquila2-34B demonstrates only a slight decrease in performance when quantized to Int4.","Furthermore, we have made our training code (https://github.com/FlagOpen/FlagScale) and model weights (https://github.com/FlagAI-Open/Aquila2) publicly available to support ongoing research and the development of applications."],"url":"http://arxiv.org/abs/2408.07410v1"}
{"created":"2024-08-14 09:24:00","title":"Efficient Edge AI: Deploying Convolutional Neural Networks on FPGA with the Gemmini Accelerator","abstract":"The growing concerns regarding energy consumption and privacy have prompted the development of AI solutions deployable on the edge, circumventing the substantial CO2 emissions associated with cloud servers and mitigating risks related to sharing sensitive data. But deploying Convolutional Neural Networks (CNNs) on non-off-the-shelf edge devices remains a complex and labor-intensive task. In this paper, we present and end-to-end workflow for deployment of CNNs on Field Programmable Gate Arrays (FPGAs) using the Gemmini accelerator, which we modified for efficient implementation on FPGAs. We describe how we leverage the use of open source software on each optimization step of the deployment process, the customizations we added to them and its impact on the final system's performance. We were able to achieve real-time performance by deploying a YOLOv7 model on a Xilinx ZCU102 FPGA with an energy efficiency of 36.5 GOP/s/W. Our FPGA-based solution demonstrates superior power efficiency compared with other embedded hardware devices, and even outperforms other FPGA reference implementations. Finally, we present how this kind of solution can be integrated into a wider system, by testing our proposed platform in a traffic monitoring scenario.","sentences":["The growing concerns regarding energy consumption and privacy have prompted the development of AI solutions deployable on the edge, circumventing the substantial CO2 emissions associated with cloud servers and mitigating risks related to sharing sensitive data.","But deploying Convolutional Neural Networks (CNNs) on non-off-the-shelf edge devices remains a complex and labor-intensive task.","In this paper, we present and end-to-end workflow for deployment of CNNs on Field Programmable Gate Arrays (FPGAs) using the Gemmini accelerator, which we modified for efficient implementation on FPGAs.","We describe how we leverage the use of open source software on each optimization step of the deployment process, the customizations we added to them and its impact on the final system's performance.","We were able to achieve real-time performance by deploying a YOLOv7 model on a Xilinx ZCU102 FPGA with an energy efficiency of 36.5 GOP/s/W. Our FPGA-based solution demonstrates superior power efficiency compared with other embedded hardware devices, and even outperforms other FPGA reference implementations.","Finally, we present how this kind of solution can be integrated into a wider system, by testing our proposed platform in a traffic monitoring scenario."],"url":"http://arxiv.org/abs/2408.07404v1"}
{"created":"2024-08-14 09:20:17","title":"DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization","abstract":"Data visualization (DV) is the fundamental and premise tool to improve the efficiency in conveying the insights behind the big data, which has been widely accepted in existing data-driven world. Task automation in DV, such as converting natural language queries to visualizations (i.e., text-to-vis), generating explanations from visualizations (i.e., vis-to-text), answering DV-related questions in free form (i.e. FeVisQA), and explicating tabular data (i.e., table-to-text), is vital for advancing the field. Despite their potential, the application of pre-trained language models (PLMs) like T5 and BERT in DV has been limited by high costs and challenges in handling cross-modal information, leading to few studies on PLMs for DV. We introduce \\textbf{DataVisT5}, a novel PLM tailored for DV that enhances the T5 architecture through a hybrid objective pre-training and multi-task fine-tuning strategy, integrating text and DV datasets to effectively interpret cross-modal semantics. Extensive evaluations on public datasets show that DataVisT5 consistently outperforms current state-of-the-art models on various DV-related tasks. We anticipate that DataVisT5 will not only inspire further research on vertical PLMs but also expand the range of applications for PLMs.","sentences":["Data visualization (DV) is the fundamental and premise tool to improve the efficiency in conveying the insights behind the big data, which has been widely accepted in existing data-driven world.","Task automation in DV, such as converting natural language queries to visualizations (i.e., text-to-vis), generating explanations from visualizations (i.e., vis-to-text), answering DV-related questions in free form (i.e. FeVisQA), and explicating tabular data (i.e., table-to-text), is vital for advancing the field.","Despite their potential, the application of pre-trained language models (PLMs) like T5 and BERT in DV has been limited by high costs and challenges in handling cross-modal information, leading to few studies on PLMs for DV.","We introduce \\textbf{DataVisT5}, a novel PLM tailored for DV that enhances the T5 architecture through a hybrid objective pre-training and multi-task fine-tuning strategy, integrating text and DV datasets to effectively interpret cross-modal semantics.","Extensive evaluations on public datasets show that DataVisT5 consistently outperforms current state-of-the-art models on various DV-related tasks.","We anticipate that DataVisT5 will not only inspire further research on vertical PLMs but also expand the range of applications for PLMs."],"url":"http://arxiv.org/abs/2408.07401v1"}
{"created":"2024-08-14 09:13:27","title":"Sum-Product-Set Networks","abstract":"Daily internet communication relies heavily on tree-structured graphs, embodied by popular data formats such as XML and JSON. However, many recent generative (probabilistic) models utilize neural networks to learn a probability distribution over undirected cyclic graphs. This assumption of a generic graph structure brings various computational challenges, and, more importantly, the presence of non-linearities in neural networks does not permit tractable probabilistic inference. We address these problems by proposing sum-product-set networks, an extension of probabilistic circuits from unstructured tensor data to tree-structured graph data. To this end, we use random finite sets to reflect a variable number of nodes and edges in the graph and to allow for exact and efficient inference. We demonstrate that our tractable model performs comparably to various intractable models based on neural networks.","sentences":["Daily internet communication relies heavily on tree-structured graphs, embodied by popular data formats such as XML and JSON.","However, many recent generative (probabilistic) models utilize neural networks to learn a probability distribution over undirected cyclic graphs.","This assumption of a generic graph structure brings various computational challenges, and, more importantly, the presence of non-linearities in neural networks does not permit tractable probabilistic inference.","We address these problems by proposing sum-product-set networks, an extension of probabilistic circuits from unstructured tensor data to tree-structured graph data.","To this end, we use random finite sets to reflect a variable number of nodes and edges in the graph and to allow for exact and efficient inference.","We demonstrate that our tractable model performs comparably to various intractable models based on neural networks."],"url":"http://arxiv.org/abs/2408.07394v1"}
{"created":"2024-08-14 09:13:06","title":"Segment Using Just One Example","abstract":"Semantic segmentation is an important topic in computer vision with many relevant application in Earth observation. While supervised methods exist, the constraints of limited annotated data has encouraged development of unsupervised approaches. However, existing unsupervised methods resemble clustering and cannot be directly mapped to explicit target classes. In this paper, we deal with single shot semantic segmentation, where one example for the target class is provided, which is used to segment the target class from query/test images. Our approach exploits recently popular Segment Anything (SAM), a promptable foundation model. We specifically design several techniques to automatically generate prompts from the only example/key image in such a way that the segmentation is successfully achieved on a stitch or concatenation of the example/key and query/test images. Proposed technique does not involve any training phase and just requires one example image to grasp the concept. Furthermore, no text-based prompt is required for the proposed method. We evaluated the proposed techniques on building and car classes.","sentences":["Semantic segmentation is an important topic in computer vision with many relevant application in Earth observation.","While supervised methods exist, the constraints of limited annotated data has encouraged development of unsupervised approaches.","However, existing unsupervised methods resemble clustering and cannot be directly mapped to explicit target classes.","In this paper, we deal with single shot semantic segmentation, where one example for the target class is provided, which is used to segment the target class from query/test images.","Our approach exploits recently popular Segment Anything (SAM), a promptable foundation model.","We specifically design several techniques to automatically generate prompts from the only example/key image in such a way that the segmentation is successfully achieved on a stitch or concatenation of the example/key and query/test images.","Proposed technique does not involve any training phase and just requires one example image to grasp the concept.","Furthermore, no text-based prompt is required for the proposed method.","We evaluated the proposed techniques on building and car classes."],"url":"http://arxiv.org/abs/2408.07393v1"}
{"created":"2024-08-14 08:34:00","title":"ProCom: A Few-shot Targeted Community Detection Algorithm","abstract":"Targeted community detection aims to distinguish a particular type of community in the network. This is an important task with a lot of real-world applications, e.g., identifying fraud groups in transaction networks. Traditional community detection methods fail to capture the specific features of the targeted community and detect all types of communities indiscriminately. Semi-supervised community detection algorithms, emerged as a feasible alternative, are inherently constrained by their limited adaptability and substantial reliance on a large amount of labeled data, which demands extensive domain knowledge and manual effort.   In this paper, we address the aforementioned weaknesses in targeted community detection by focusing on few-shot scenarios. We propose ProCom, a novel framework that extends the ``pre-train, prompt'' paradigm, offering a low-resource, high-efficiency, and transferable solution. Within the framework, we devise a dual-level context-aware pre-training method that fosters a deep understanding of latent communities in the network, establishing a rich knowledge foundation for downstream task. In the prompt learning stage, we reformulate the targeted community detection task into pre-training objectives, allowing the extraction of specific knowledge relevant to the targeted community to facilitate effective and efficient inference. By leveraging both the general community knowledge acquired during pre-training and the specific insights gained from the prompt communities, ProCom exhibits remarkable adaptability across different datasets. We conduct extensive experiments on five benchmarks to evaluate the ProCom framework, demonstrating its SOTA performance under few-shot scenarios, strong efficiency, and transferability across diverse datasets.","sentences":["Targeted community detection aims to distinguish a particular type of community in the network.","This is an important task with a lot of real-world applications, e.g., identifying fraud groups in transaction networks.","Traditional community detection methods fail to capture the specific features of the targeted community and detect all types of communities indiscriminately.","Semi-supervised community detection algorithms, emerged as a feasible alternative, are inherently constrained by their limited adaptability and substantial reliance on a large amount of labeled data, which demands extensive domain knowledge and manual effort.   ","In this paper, we address the aforementioned weaknesses in targeted community detection by focusing on few-shot scenarios.","We propose ProCom, a novel framework that extends the ``pre-train, prompt'' paradigm, offering a low-resource, high-efficiency, and transferable solution.","Within the framework, we devise a dual-level context-aware pre-training method that fosters a deep understanding of latent communities in the network, establishing a rich knowledge foundation for downstream task.","In the prompt learning stage, we reformulate the targeted community detection task into pre-training objectives, allowing the extraction of specific knowledge relevant to the targeted community to facilitate effective and efficient inference.","By leveraging both the general community knowledge acquired during pre-training and the specific insights gained from the prompt communities, ProCom exhibits remarkable adaptability across different datasets.","We conduct extensive experiments on five benchmarks to evaluate the ProCom framework, demonstrating its SOTA performance under few-shot scenarios, strong efficiency, and transferability across diverse datasets."],"url":"http://arxiv.org/abs/2408.07369v1"}
{"created":"2024-08-14 08:26:50","title":"Risk Occupancy: A New and Efficient Paradigm through Vehicle-Road-Cloud Collaboration","abstract":"This study introduces the 4D Risk Occupancy within a vehicle-road-cloud architecture, integrating the road surface spatial, risk, and temporal dimensions, and endowing the algorithm with beyond-line-of-sight, all-angles, and efficient abilities. The algorithm simplifies risk modeling by focusing on directly observable information and key factors, drawing on the concept of Occupancy Grid Maps (OGM), and incorporating temporal prediction to effectively map current and future risk occupancy.   Compared to conventional driving risk fields and grid occupancy maps, this algorithm can map global risks more efficiently, simply, and reliably. It can integrate future risk information, adapting to dynamic traffic environments. The 4D Risk Occupancy also unifies the expression of BEV detection and lane line detection results, enhancing the intuitiveness and unity of environmental perception. Using DAIR-V2X data, this paper validates the 4D Risk Occupancy algorithm and develops a local path planning model based on it. Qualitative experiments under various road conditions demonstrate the practicality and robustness of this local path planning model. Quantitative analysis shows that the path planning based on risk occupation significantly improves trajectory planning performance, increasing safety redundancy by 12.5% and reducing average deceleration by 5.41% at an initial braking speed of 8 m/s, thereby improving safety and comfort. This work provides a new global perception method and local path planning method through Vehicle-Road-Cloud architecture, offering a new perceptual paradigm for achieving safer and more efficient autonomous driving.","sentences":["This study introduces the 4D Risk Occupancy within a vehicle-road-cloud architecture, integrating the road surface spatial, risk, and temporal dimensions, and endowing the algorithm with beyond-line-of-sight, all-angles, and efficient abilities.","The algorithm simplifies risk modeling by focusing on directly observable information and key factors, drawing on the concept of Occupancy Grid Maps (OGM), and incorporating temporal prediction to effectively map current and future risk occupancy.   ","Compared to conventional driving risk fields and grid occupancy maps, this algorithm can map global risks more efficiently, simply, and reliably.","It can integrate future risk information, adapting to dynamic traffic environments.","The 4D Risk Occupancy also unifies the expression of BEV detection and lane line detection results, enhancing the intuitiveness and unity of environmental perception.","Using DAIR-V2X data, this paper validates the 4D Risk Occupancy algorithm and develops a local path planning model based on it.","Qualitative experiments under various road conditions demonstrate the practicality and robustness of this local path planning model.","Quantitative analysis shows that the path planning based on risk occupation significantly improves trajectory planning performance, increasing safety redundancy by 12.5% and reducing average deceleration by 5.41% at an initial braking speed of 8 m/s, thereby improving safety and comfort.","This work provides a new global perception method and local path planning method through Vehicle-Road-Cloud architecture, offering a new perceptual paradigm for achieving safer and more efficient autonomous driving."],"url":"http://arxiv.org/abs/2408.07367v1"}
{"created":"2024-08-14 07:37:24","title":"RTAT: A Robust Two-stage Association Tracker for Multi-Object Tracking","abstract":"Data association is an essential part in the tracking-by-detection based Multi-Object Tracking (MOT). Most trackers focus on how to design a better data association strategy to improve the tracking performance. The rule-based handcrafted association methods are simple and highly efficient but lack generalization capability to deal with complex scenes. While the learnt association methods can learn high-order contextual information to deal with various complex scenes, but they have the limitations of higher complexity and cost. To address these limitations, we propose a Robust Two-stage Association Tracker, named RTAT. The first-stage association is performed between tracklets and detections to generate tracklets with high purity, and the second-stage association is performed between tracklets to form complete trajectories. For the first-stage association, we use a simple data association strategy to generate tracklets with high purity by setting a low threshold for the matching cost in the assignment process. We conduct the tracklet association in the second-stage based on the framework of message-passing GNN. Our method models the tracklet association as a series of edge classification problem in hierarchical graphs, which can recursively merge short tracklets into longer ones. Our tracker RTAT ranks first on the test set of MOT17 and MOT20 benchmarks in most of the main MOT metrics: HOTA, IDF1, and AssA. We achieve 67.2 HOTA, 84.7 IDF1, and 69.7 AssA on MOT17, and 66.2 HOTA, 82.5 IDF1, and 68.1 AssA on MOT20.","sentences":["Data association is an essential part in the tracking-by-detection based Multi-Object Tracking (MOT).","Most trackers focus on how to design a better data association strategy to improve the tracking performance.","The rule-based handcrafted association methods are simple and highly efficient but lack generalization capability to deal with complex scenes.","While the learnt association methods can learn high-order contextual information to deal with various complex scenes, but they have the limitations of higher complexity and cost.","To address these limitations, we propose a Robust Two-stage Association Tracker, named RTAT.","The first-stage association is performed between tracklets and detections to generate tracklets with high purity, and the second-stage association is performed between tracklets to form complete trajectories.","For the first-stage association, we use a simple data association strategy to generate tracklets with high purity by setting a low threshold for the matching cost in the assignment process.","We conduct the tracklet association in the second-stage based on the framework of message-passing GNN.","Our method models the tracklet association as a series of edge classification problem in hierarchical graphs, which can recursively merge short tracklets into longer ones.","Our tracker RTAT ranks first on the test set of MOT17 and MOT20 benchmarks in most of the main MOT metrics: HOTA, IDF1, and AssA. We achieve 67.2 HOTA, 84.7 IDF1, and 69.7 AssA on MOT17, and 66.2 HOTA, 82.5 IDF1, and 68.1 AssA on MOT20."],"url":"http://arxiv.org/abs/2408.07344v1"}
{"created":"2024-08-14 07:37:07","title":"Gradient Alignment Improves Test-Time Adaptation for Medical Image Segmentation","abstract":"Although recent years have witnessed significant advancements in medical image segmentation, the pervasive issue of domain shift among medical images from diverse centres hinders the effective deployment of pre-trained models. Many Test-time Adaptation (TTA) methods have been proposed to address this issue by fine-tuning pre-trained models with test data during inference. These methods, however, often suffer from less-satisfactory optimization due to suboptimal optimization direction (dictated by the gradient) and fixed step-size (predicated on the learning rate). In this paper, we propose the Gradient alignment-based Test-time adaptation (GraTa) method to improve both the gradient direction and learning rate in the optimization procedure. Unlike conventional TTA methods, which primarily optimize the pseudo gradient derived from a self-supervised objective, our method incorporates an auxiliary gradient with the pseudo one to facilitate gradient alignment. Such gradient alignment enables the model to excavate the similarities between different gradients and correct the gradient direction to approximate the empirical gradient related to the current segmentation task. Additionally, we design a dynamic learning rate based on the cosine similarity between the pseudo and auxiliary gradients, thereby empowering the adaptive fine-tuning of pre-trained models on diverse test data. Extensive experiments establish the effectiveness of the proposed gradient alignment and dynamic learning rate and substantiate the superiority of our GraTa method over other state-of-the-art TTA methods on a benchmark medical image segmentation task. The code and weights of pre-trained source models will be available.","sentences":["Although recent years have witnessed significant advancements in medical image segmentation, the pervasive issue of domain shift among medical images from diverse centres hinders the effective deployment of pre-trained models.","Many Test-time Adaptation (TTA) methods have been proposed to address this issue by fine-tuning pre-trained models with test data during inference.","These methods, however, often suffer from less-satisfactory optimization due to suboptimal optimization direction (dictated by the gradient) and fixed step-size (predicated on the learning rate).","In this paper, we propose the Gradient alignment-based Test-time adaptation (GraTa) method to improve both the gradient direction and learning rate in the optimization procedure.","Unlike conventional TTA methods, which primarily optimize the pseudo gradient derived from a self-supervised objective, our method incorporates an auxiliary gradient with the pseudo one to facilitate gradient alignment.","Such gradient alignment enables the model to excavate the similarities between different gradients and correct the gradient direction to approximate the empirical gradient related to the current segmentation task.","Additionally, we design a dynamic learning rate based on the cosine similarity between the pseudo and auxiliary gradients, thereby empowering the adaptive fine-tuning of pre-trained models on diverse test data.","Extensive experiments establish the effectiveness of the proposed gradient alignment and dynamic learning rate and substantiate the superiority of our GraTa method over other state-of-the-art TTA methods on a benchmark medical image segmentation task.","The code and weights of pre-trained source models will be available."],"url":"http://arxiv.org/abs/2408.07343v1"}
{"created":"2024-08-14 07:34:12","title":"Robust Semi-supervised Multimodal Medical Image Segmentation via Cross Modality Collaboration","abstract":"Multimodal learning leverages complementary information derived from different modalities, thereby enhancing performance in medical image segmentation. However, prevailing multimodal learning methods heavily rely on extensive well-annotated data from various modalities to achieve accurate segmentation performance. This dependence often poses a challenge in clinical settings due to limited availability of such data. Moreover, the inherent anatomical misalignment between different imaging modalities further complicates the endeavor to enhance segmentation performance. To address this problem, we propose a novel semi-supervised multimodal segmentation framework that is robust to scarce labeled data and misaligned modalities. Our framework employs a novel cross modality collaboration strategy to distill modality-independent knowledge, which is inherently associated with each modality, and integrates this information into a unified fusion layer for feature amalgamation. With a channel-wise semantic consistency loss, our framework ensures alignment of modality-independent information from a feature-wise perspective across modalities, thereby fortifying it against misalignments in multimodal scenarios. Furthermore, our framework effectively integrates contrastive consistent learning to regulate anatomical structures, facilitating anatomical-wise prediction alignment on unlabeled data in semi-supervised segmentation tasks. Our method achieves competitive performance compared to other multimodal methods across three tasks: cardiac, abdominal multi-organ, and thyroid-associated orbitopathy segmentations. It also demonstrates outstanding robustness in scenarios involving scarce labeled data and misaligned modalities.","sentences":["Multimodal learning leverages complementary information derived from different modalities, thereby enhancing performance in medical image segmentation.","However, prevailing multimodal learning methods heavily rely on extensive well-annotated data from various modalities to achieve accurate segmentation performance.","This dependence often poses a challenge in clinical settings due to limited availability of such data.","Moreover, the inherent anatomical misalignment between different imaging modalities further complicates the endeavor to enhance segmentation performance.","To address this problem, we propose a novel semi-supervised multimodal segmentation framework that is robust to scarce labeled data and misaligned modalities.","Our framework employs a novel cross modality collaboration strategy to distill modality-independent knowledge, which is inherently associated with each modality, and integrates this information into a unified fusion layer for feature amalgamation.","With a channel-wise semantic consistency loss, our framework ensures alignment of modality-independent information from a feature-wise perspective across modalities, thereby fortifying it against misalignments in multimodal scenarios.","Furthermore, our framework effectively integrates contrastive consistent learning to regulate anatomical structures, facilitating anatomical-wise prediction alignment on unlabeled data in semi-supervised segmentation tasks.","Our method achieves competitive performance compared to other multimodal methods across three tasks: cardiac, abdominal multi-organ, and thyroid-associated orbitopathy segmentations.","It also demonstrates outstanding robustness in scenarios involving scarce labeled data and misaligned modalities."],"url":"http://arxiv.org/abs/2408.07341v1"}
{"created":"2024-08-14 07:31:11","title":"Towards Few-shot Self-explaining Graph Neural Networks","abstract":"Recent advancements in Graph Neural Networks (GNNs) have spurred an upsurge of research dedicated to enhancing the explainability of GNNs, particularly in critical domains such as medicine. A promising approach is the self-explaining method, which outputs explanations along with predictions. However, existing self-explaining models require a large amount of training data, rendering them unavailable in few-shot scenarios. To address this challenge, in this paper, we propose a Meta-learned Self-Explaining GNN (MSE-GNN), a novel framework that generates explanations to support predictions in few-shot settings. MSE-GNN adopts a two-stage self-explaining structure, consisting of an explainer and a predictor. Specifically, the explainer first imitates the attention mechanism of humans to select the explanation subgraph, whereby attention is naturally paid to regions containing important characteristics. Subsequently, the predictor mimics the decision-making process, which makes predictions based on the generated explanation. Moreover, with a novel meta-training process and a designed mechanism that exploits task information, MSE-GNN can achieve remarkable performance on new few-shot tasks. Extensive experimental results on four datasets demonstrate that MSE-GNN can achieve superior performance on prediction tasks while generating high-quality explanations compared with existing methods. The code is publicly available at https://github.com/jypeng28/MSE-GNN.","sentences":["Recent advancements in Graph Neural Networks (GNNs) have spurred an upsurge of research dedicated to enhancing the explainability of GNNs, particularly in critical domains such as medicine.","A promising approach is the self-explaining method, which outputs explanations along with predictions.","However, existing self-explaining models require a large amount of training data, rendering them unavailable in few-shot scenarios.","To address this challenge, in this paper, we propose a Meta-learned Self-Explaining GNN (MSE-GNN), a novel framework that generates explanations to support predictions in few-shot settings.","MSE-GNN adopts a two-stage self-explaining structure, consisting of an explainer and a predictor.","Specifically, the explainer first imitates the attention mechanism of humans to select the explanation subgraph, whereby attention is naturally paid to regions containing important characteristics.","Subsequently, the predictor mimics the decision-making process, which makes predictions based on the generated explanation.","Moreover, with a novel meta-training process and a designed mechanism that exploits task information, MSE-GNN can achieve remarkable performance on new few-shot tasks.","Extensive experimental results on four datasets demonstrate that MSE-GNN can achieve superior performance on prediction tasks while generating high-quality explanations compared with existing methods.","The code is publicly available at https://github.com/jypeng28/MSE-GNN."],"url":"http://arxiv.org/abs/2408.07340v1"}
{"created":"2024-08-14 07:13:36","title":"RSEA-MVGNN: Multi-View Graph Neural Network with Reliable Structural Enhancement and Aggregation","abstract":"Graph Neural Networks (GNNs) have exhibited remarkable efficacy in learning from multi-view graph data. In the framework of multi-view graph neural networks, a critical challenge lies in effectively combining diverse views, where each view has distinct graph structure features (GSFs). Existing approaches to this challenge primarily focus on two aspects: 1) prioritizing the most important GSFs, 2) utilizing GNNs for feature aggregation. However, prioritizing the most important GSFs can lead to limited feature diversity, and existing GNN-based aggregation strategies equally treat each view without considering view quality. To address these issues, we propose a novel Multi-View Graph Neural Network with Reliable Structural Enhancement and Aggregation (RSEA-MVGNN). Firstly, we estimate view-specific uncertainty employing subjective logic. Based on this uncertainty, we design reliable structural enhancement by feature de-correlation algorithm. This approach enables each enhancement to focus on different GSFs, thereby achieving diverse feature representation in the enhanced structure. Secondly, the model learns view-specific beliefs and uncertainty as opinions, which are utilized to evaluate view quality. Based on these opinions, the model enables high-quality views to dominate GNN aggregation, thereby facilitating representation learning. Experimental results conducted on five real-world datasets demonstrate that RSEA-MVGNN outperforms several state-of-the-art GNN-based methods.","sentences":["Graph Neural Networks (GNNs) have exhibited remarkable efficacy in learning from multi-view graph data.","In the framework of multi-view graph neural networks, a critical challenge lies in effectively combining diverse views, where each view has distinct graph structure features (GSFs).","Existing approaches to this challenge primarily focus on two aspects: 1) prioritizing the most important GSFs, 2) utilizing GNNs for feature aggregation.","However, prioritizing the most important GSFs can lead to limited feature diversity, and existing GNN-based aggregation strategies equally treat each view without considering view quality.","To address these issues, we propose a novel Multi-View Graph Neural Network with Reliable Structural Enhancement and Aggregation (RSEA-MVGNN).","Firstly, we estimate view-specific uncertainty employing subjective logic.","Based on this uncertainty, we design reliable structural enhancement by feature de-correlation algorithm.","This approach enables each enhancement to focus on different GSFs, thereby achieving diverse feature representation in the enhanced structure.","Secondly, the model learns view-specific beliefs and uncertainty as opinions, which are utilized to evaluate view quality.","Based on these opinions, the model enables high-quality views to dominate GNN aggregation, thereby facilitating representation learning.","Experimental results conducted on five real-world datasets demonstrate that RSEA-MVGNN outperforms several state-of-the-art GNN-based methods."],"url":"http://arxiv.org/abs/2408.07331v1"}
{"created":"2024-08-14 06:56:20","title":"LPU: A Latency-Optimized and Highly Scalable Processor for Large Language Model Inference","abstract":"The explosive arrival of OpenAI's ChatGPT has fueled the globalization of large language model (LLM), which consists of billions of pretrained parameters that embodies the aspects of syntax and semantics. HyperAccel introduces latency processing unit (LPU), a latency-optimized and highly scalable processor architecture for the acceleration of LLM inference. LPU perfectly balances the memory bandwidth and compute logic with streamlined dataflow to maximize performance and efficiency. LPU is equipped with expandable synchronization link (ESL) that hides data synchronization latency between multiple LPUs. HyperDex complements LPU as an intuitive software framework to run LLM applications. LPU achieves 1.25 ms/token and 20.9 ms/token for 1.3B and 66B model, respectively, which is 2.09x and 1.37x faster than the GPU. LPU, synthesized using Samsung 4nm process, has total area of 0.824 mm2 and power consumption of 284.31 mW. LPU-based servers achieve 1.33x and 1.32x energy efficiency over NVIDIA H100 and L4 servers, respectively.","sentences":["The explosive arrival of OpenAI's ChatGPT has fueled the globalization of large language model (LLM), which consists of billions of pretrained parameters that embodies the aspects of syntax and semantics.","HyperAccel introduces latency processing unit (LPU), a latency-optimized and highly scalable processor architecture for the acceleration of LLM inference.","LPU perfectly balances the memory bandwidth and compute logic with streamlined dataflow to maximize performance and efficiency.","LPU is equipped with expandable synchronization link (ESL) that hides data synchronization latency between multiple LPUs.","HyperDex complements LPU as an intuitive software framework to run LLM applications.","LPU achieves 1.25 ms/token and 20.9 ms/token for 1.3B and 66B model, respectively, which is 2.09x and 1.37x faster than the GPU.","LPU, synthesized using Samsung 4nm process, has total area of 0.824 mm2 and power consumption of 284.31 mW. LPU-based servers achieve 1.33x and 1.32x energy efficiency over NVIDIA H100 and L4 servers, respectively."],"url":"http://arxiv.org/abs/2408.07326v1"}
{"created":"2024-08-14 06:44:52","title":"Encoding and Decoding Algorithms of ANS Variants and Evaluation of Their Average Code Lengths","abstract":"Asymmetric Numeral Systems (ANS) proposed by Jarek Duda are high-performance distortionless data compression schemes that can achieve almost the same compression performance as arithmetic codes with less arithmetic operations than arithmetic coding. The ANS is widely used in various practical systems like Facebook, Apple, Google, Dropbox, Microsoft, and Pixar, due to their high performance, but many researchers still lack much knowledge about the ANS. This paper thoroughly explains the encoding and decoding algorithms of the ANS, and theoretically analyzes the average code length achievable by the ANS.","sentences":["Asymmetric Numeral Systems (ANS) proposed by Jarek Duda are high-performance distortionless data compression schemes that can achieve almost the same compression performance as arithmetic codes with less arithmetic operations than arithmetic coding.","The ANS is widely used in various practical systems like Facebook, Apple, Google, Dropbox, Microsoft, and Pixar, due to their high performance, but many researchers still lack much knowledge about the ANS.","This paper thoroughly explains the encoding and decoding algorithms of the ANS, and theoretically analyzes the average code length achievable by the ANS."],"url":"http://arxiv.org/abs/2408.07322v1"}
{"created":"2024-08-14 06:37:30","title":"A systematic dataset generation technique applied to data-driven automotive aerodynamics","abstract":"A novel strategy for generating datasets is developed within the context of drag prediction for automotive geometries using neural networks. A primary challenge in this space is constructing a training databse of sufficient size and diversity. Our method relies on a small number of starting data points, and provides a recipe to interpolate systematically between them, generating an arbitrary number of samples at the desired quality. We test this strategy using a realistic automotive geometry, and demonstrate that convolutional neural networks perform exceedingly well at predicting drag coefficients and surface pressures. Promising results are obtained in testing extrapolation performance. Our method can be applied to other problems of aerodynamic shape optimization.","sentences":["A novel strategy for generating datasets is developed within the context of drag prediction for automotive geometries using neural networks.","A primary challenge in this space is constructing a training databse of sufficient size and diversity.","Our method relies on a small number of starting data points, and provides a recipe to interpolate systematically between them, generating an arbitrary number of samples at the desired quality.","We test this strategy using a realistic automotive geometry, and demonstrate that convolutional neural networks perform exceedingly well at predicting drag coefficients and surface pressures.","Promising results are obtained in testing extrapolation performance.","Our method can be applied to other problems of aerodynamic shape optimization."],"url":"http://arxiv.org/abs/2408.07318v1"}
{"created":"2024-08-14 06:15:55","title":"Kolmogorov-Arnold Networks (KAN) for Time Series Classification and Robust Analysis","abstract":"Kolmogorov-Arnold Networks (KAN) has recently attracted significant attention as a promising alternative to traditional Multi-Layer Perceptrons (MLP). Despite their theoretical appeal, KAN require validation on large-scale benchmark datasets. Time series data, which has become increasingly prevalent in recent years, especially univariate time series are naturally suited for validating KAN. Therefore, we conducted a fair comparison among KAN, MLP, and mixed structures. The results indicate that KAN can achieve performance comparable to, or even slightly better than, MLP across 128 time series datasets. We also performed an ablation study on KAN, revealing that the output is primarily determined by the base component instead of b-spline function. Furthermore, we assessed the robustness of these models and found that KAN and the hybrid structure MLP\\_KAN exhibit significant robustness advantages, attributed to their lower Lipschitz constants. This suggests that KAN and KAN layers hold strong potential to be robust models or to improve the adversarial robustness of other models.","sentences":["Kolmogorov-Arnold Networks (KAN) has recently attracted significant attention as a promising alternative to traditional Multi-Layer Perceptrons (MLP).","Despite their theoretical appeal, KAN require validation on large-scale benchmark datasets.","Time series data, which has become increasingly prevalent in recent years, especially univariate time series are naturally suited for validating KAN.","Therefore, we conducted a fair comparison among KAN, MLP, and mixed structures.","The results indicate that KAN can achieve performance comparable to, or even slightly better than, MLP across 128 time series datasets.","We also performed an ablation study on KAN, revealing that the output is primarily determined by the base component instead of b-spline function.","Furthermore, we assessed the robustness of these models and found that KAN and the hybrid structure MLP\\_KAN exhibit significant robustness advantages, attributed to their lower Lipschitz constants.","This suggests that KAN and KAN layers hold strong potential to be robust models or to improve the adversarial robustness of other models."],"url":"http://arxiv.org/abs/2408.07314v1"}
{"created":"2024-08-14 06:14:02","title":"Exploring Large-Scale Language Models to Evaluate EEG-Based Multimodal Data for Mental Health","abstract":"Integrating physiological signals such as electroencephalogram (EEG), with other data such as interview audio, may offer valuable multimodal insights into psychological states or neurological disorders. Recent advancements with Large Language Models (LLMs) position them as prospective ``health agents'' for mental health assessment. However, current research predominantly focus on single data modalities, presenting an opportunity to advance understanding through multimodal data. Our study aims to advance this approach by investigating multimodal data using LLMs for mental health assessment, specifically through zero-shot and few-shot prompting. Three datasets are adopted for depression and emotion classifications incorporating EEG, facial expressions, and audio (text). The results indicate that multimodal information confers substantial advantages over single modality approaches in mental health assessment. Notably, integrating EEG alongside commonly used LLM modalities such as audio and images demonstrates promising potential. Moreover, our findings reveal that 1-shot learning offers greater benefits compared to zero-shot learning methods.","sentences":["Integrating physiological signals such as electroencephalogram (EEG), with other data such as interview audio, may offer valuable multimodal insights into psychological states or neurological disorders.","Recent advancements with Large Language Models (LLMs) position them as prospective ``health agents'' for mental health assessment.","However, current research predominantly focus on single data modalities, presenting an opportunity to advance understanding through multimodal data.","Our study aims to advance this approach by investigating multimodal data using LLMs for mental health assessment, specifically through zero-shot and few-shot prompting.","Three datasets are adopted for depression and emotion classifications incorporating EEG, facial expressions, and audio (text).","The results indicate that multimodal information confers substantial advantages over single modality approaches in mental health assessment.","Notably, integrating EEG alongside commonly used LLM modalities such as audio and images demonstrates promising potential.","Moreover, our findings reveal that 1-shot learning offers greater benefits compared to zero-shot learning methods."],"url":"http://arxiv.org/abs/2408.07313v1"}
{"created":"2024-08-14 06:07:01","title":"MultiSurf-GPT: Facilitating Context-Aware Reasoning with Large-Scale Language Models for Multimodal Surface Sensing","abstract":"Surface sensing is widely employed in health diagnostics, manufacturing and safety monitoring. Advances in mobile sensing affords this potential for context awareness in mobile computing, typically with a single sensing modality. Emerging multimodal large-scale language models offer new opportunities. We propose MultiSurf-GPT, which utilizes the advanced capabilities of GPT-4o to process and interpret diverse modalities (radar, microscope and multispectral data) uniformly based on prompting strategies (zero-shot and few-shot prompting). We preliminarily validated our framework by using MultiSurf-GPT to identify low-level information, and to infer high-level context-aware analytics, demonstrating the capability of augmenting context-aware insights. This framework shows promise as a tool to expedite the development of more complex context-aware applications in the future, providing a faster, more cost-effective, and integrated solution.","sentences":["Surface sensing is widely employed in health diagnostics, manufacturing and safety monitoring.","Advances in mobile sensing affords this potential for context awareness in mobile computing, typically with a single sensing modality.","Emerging multimodal large-scale language models offer new opportunities.","We propose MultiSurf-GPT, which utilizes the advanced capabilities of GPT-4o to process and interpret diverse modalities (radar, microscope and multispectral data) uniformly based on prompting strategies (zero-shot and few-shot prompting).","We preliminarily validated our framework by using MultiSurf-GPT to identify low-level information, and to infer high-level context-aware analytics, demonstrating the capability of augmenting context-aware insights.","This framework shows promise as a tool to expedite the development of more complex context-aware applications in the future, providing a faster, more cost-effective, and integrated solution."],"url":"http://arxiv.org/abs/2408.07311v1"}
{"created":"2024-08-14 05:57:56","title":"Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery","abstract":"Despite the recent popularity of attention-based neural architectures in core AI fields like natural language processing (NLP) and computer vision (CV), their potential in modeling complex physical systems remains under-explored. Learning problems in physical systems are often characterized as discovering operators that map between function spaces based on a few instances of function pairs. This task frequently presents a severely ill-posed PDE inverse problem. In this work, we propose a novel neural operator architecture based on the attention mechanism, which we coin Nonlocal Attention Operator (NAO), and explore its capability towards developing a foundation physical model. In particular, we show that the attention mechanism is equivalent to a double integral operator that enables nonlocal interactions among spatial tokens, with a data-dependent kernel characterizing the inverse mapping from data to the hidden parameter field of the underlying operator. As such, the attention mechanism extracts global prior information from training data generated by multiple systems, and suggests the exploratory space in the form of a nonlinear kernel map. Consequently, NAO can address ill-posedness and rank deficiency in inverse PDE problems by encoding regularization and achieving generalizability. We empirically demonstrate the advantages of NAO over baseline neural models in terms of generalizability to unseen data resolutions and system states. Our work not only suggests a novel neural operator architecture for learning interpretable foundation models of physical systems, but also offers a new perspective towards understanding the attention mechanism.","sentences":["Despite the recent popularity of attention-based neural architectures in core AI fields like natural language processing (NLP) and computer vision (CV), their potential in modeling complex physical systems remains under-explored.","Learning problems in physical systems are often characterized as discovering operators that map between function spaces based on a few instances of function pairs.","This task frequently presents a severely ill-posed PDE inverse problem.","In this work, we propose a novel neural operator architecture based on the attention mechanism, which we coin Nonlocal Attention Operator (NAO), and explore its capability towards developing a foundation physical model.","In particular, we show that the attention mechanism is equivalent to a double integral operator that enables nonlocal interactions among spatial tokens, with a data-dependent kernel characterizing the inverse mapping from data to the hidden parameter field of the underlying operator.","As such, the attention mechanism extracts global prior information from training data generated by multiple systems, and suggests the exploratory space in the form of a nonlinear kernel map.","Consequently, NAO can address ill-posedness and rank deficiency in inverse PDE problems by encoding regularization and achieving generalizability.","We empirically demonstrate the advantages of NAO over baseline neural models in terms of generalizability to unseen data resolutions and system states.","Our work not only suggests a novel neural operator architecture for learning interpretable foundation models of physical systems, but also offers a new perspective towards understanding the attention mechanism."],"url":"http://arxiv.org/abs/2408.07307v1"}
{"created":"2024-08-14 05:44:56","title":"Learning Decisions Offline from Censored Observations with \u03b5-insensitive Operational Costs","abstract":"Many important managerial decisions are made based on censored observations. Making decisions without adequately handling the censoring leads to inferior outcomes. We investigate the data-driven decision-making problem with an offline dataset containing the feature data and the censored historical data of the variable of interest without the censoring indicators. Without assuming the underlying distribution, we design and leverage {\\epsilon}-insensitive operational costs to deal with the unobserved censoring in an offline data-driven fashion. We demonstrate the customization of the {\\epsilon}-insensitive operational costs for a newsvendor problem and use such costs to train two representative ML models, including linear regression (LR) models and neural networks (NNs). We derive tight generalization bounds for the custom LR model without regularization (LR-{\\epsilon}NVC) and with regularization (LR-{\\epsilon}NVC-R), and a high-probability generalization bound for the custom NN (NN-{\\epsilon}NVC) trained by stochastic gradient descent. The theoretical results reveal the stability and learnability of LR-{\\epsilon}NVC, LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC. We conduct extensive numerical experiments to compare LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC with two existing approaches, estimate-as-solution (EAS) and integrated estimation and optimization (IEO). The results show that LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC outperform both EAS and IEO, with maximum cost savings up to 14.40% and 12.21% compared to the lowest cost generated by the two existing approaches. In addition, LR-{\\epsilon}NVC-R's and NN-{\\epsilon}NVC's order quantities are statistically significantly closer to the optimal solutions should the underlying distribution be known.","sentences":["Many important managerial decisions are made based on censored observations.","Making decisions without adequately handling the censoring leads to inferior outcomes.","We investigate the data-driven decision-making problem with an offline dataset containing the feature data and the censored historical data of the variable of interest without the censoring indicators.","Without assuming the underlying distribution, we design and leverage {\\epsilon}-insensitive operational costs to deal with the unobserved censoring in an offline data-driven fashion.","We demonstrate the customization of the {\\epsilon}-insensitive operational costs for a newsvendor problem and use such costs to train two representative ML models, including linear regression (LR) models and neural networks (NNs).","We derive tight generalization bounds for the custom LR model without regularization (LR-{\\epsilon}NVC) and with regularization (LR-{\\epsilon}NVC-R), and a high-probability generalization bound for the custom NN (NN-{\\epsilon}NVC) trained by stochastic gradient descent.","The theoretical results reveal the stability and learnability of LR-{\\epsilon}NVC, LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC.","We conduct extensive numerical experiments to compare LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC with two existing approaches, estimate-as-solution (EAS) and integrated estimation and optimization (IEO).","The results show that LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC outperform both EAS and IEO, with maximum cost savings up to 14.40% and 12.21% compared to the lowest cost generated by the two existing approaches.","In addition, LR-{\\epsilon}NVC-R's and NN-{\\epsilon}NVC's order quantities are statistically significantly closer to the optimal solutions should the underlying distribution be known."],"url":"http://arxiv.org/abs/2408.07305v1"}
{"created":"2024-08-14 05:42:35","title":"At Least Factor-of-Two Optimization for RWLE-Based Homomorphic Encryption","abstract":"Many modern applications that deal with sensitive data, such as healthcare and government services, outsource computation to cloud platforms. In such untrusted environments, privacy is of vital importance. One solution to this problem is homomorphic encryption (HE), a family of cryptographic schemes that support certain algebraic operations on encrypted data without the need for decryption. However, despite major advancements, encryption in modern HE schemes still comes with a non-trivial computational overhead that can hamper data-intensive workloads. To resolve this, recent research has shown that leveraging caching techniques, such as Rache, can significantly enhance the performance of HE schemes while maintaining security. Rache unfortunately displays a key limitation in the time complexity of its caching procedure, which scales with the size of the plaintext space. Smuche is another caching scheme that simultaneously improves the scalability of the caching procedure and turns the encryption process into a constant-time operation, utilizing only a single scalar multiplication. Even still, more can be done. In this paper, we present an encryption method we call ``Zinc\" which entirely forgoes the multiple caching process, replacing it with a single scalar addition, and then injecting randomness that takes constant time with respect to the plaintext space. This injection of randomness is similar to Smuche, and a great improvement from Rache, allowing Zinc to achieve efficiency without compromising security. We implement the scheme using Microsoft SEAL and compare its performance to vanilla CKKS.","sentences":["Many modern applications that deal with sensitive data, such as healthcare and government services, outsource computation to cloud platforms.","In such untrusted environments, privacy is of vital importance.","One solution to this problem is homomorphic encryption (HE), a family of cryptographic schemes that support certain algebraic operations on encrypted data without the need for decryption.","However, despite major advancements, encryption in modern HE schemes still comes with a non-trivial computational overhead that can hamper data-intensive workloads.","To resolve this, recent research has shown that leveraging caching techniques, such as Rache, can significantly enhance the performance of HE schemes while maintaining security.","Rache unfortunately displays a key limitation in the time complexity of its caching procedure, which scales with the size of the plaintext space.","Smuche is another caching scheme that simultaneously improves the scalability of the caching procedure and turns the encryption process into a constant-time operation, utilizing only a single scalar multiplication.","Even still, more can be done.","In this paper, we present an encryption method we call ``Zinc\" which entirely forgoes the multiple caching process, replacing it with a single scalar addition, and then injecting randomness that takes constant time with respect to the plaintext space.","This injection of randomness is similar to Smuche, and a great improvement from Rache, allowing Zinc to achieve efficiency without compromising security.","We implement the scheme using Microsoft SEAL and compare its performance to vanilla CKKS."],"url":"http://arxiv.org/abs/2408.07304v1"}
{"created":"2024-08-14 04:51:33","title":"LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models","abstract":"Language models have achieved remarkable success in various natural language processing tasks. However, their application to time series data, a crucial component in many domains, remains limited. This paper proposes LiPCoT (Linear Predictive Coding based Tokenizer for time series), a novel tokenizer that encodes time series data into a sequence of tokens, enabling self-supervised learning of time series using existing Language model architectures such as BERT. Unlike traditional time series tokenizers that rely heavily on CNN encoder for time series feature generation, LiPCoT employs stochastic modeling through linear predictive coding to create a latent space for time series providing a compact yet rich representation of the inherent stochastic nature of the data. Furthermore, LiPCoT is computationally efficient and can effectively handle time series data with varying sampling rates and lengths, overcoming common limitations of existing time series tokenizers. In this proof-of-concept work, we present the effectiveness of LiPCoT in classifying Parkinson's disease (PD) using an EEG dataset from 46 participants. In particular, we utilize LiPCoT to encode EEG data into a small vocabulary of tokens and then use BERT for self-supervised learning and the downstream task of PD classification. We benchmark our approach against several state-of-the-art CNN-based deep learning architectures for PD detection. Our results reveal that BERT models utilizing self-supervised learning outperformed the best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5% in accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for self-supervised learning even on small datasets. Our work will inform future foundational models for time series, particularly for self-supervised learning.","sentences":["Language models have achieved remarkable success in various natural language processing tasks.","However, their application to time series data, a crucial component in many domains, remains limited.","This paper proposes LiPCoT (Linear Predictive Coding based Tokenizer for time series), a novel tokenizer that encodes time series data into a sequence of tokens, enabling self-supervised learning of time series using existing Language model architectures such as BERT.","Unlike traditional time series tokenizers that rely heavily on CNN encoder for time series feature generation, LiPCoT employs stochastic modeling through linear predictive coding to create a latent space for time series providing a compact yet rich representation of the inherent stochastic nature of the data.","Furthermore, LiPCoT is computationally efficient and can effectively handle time series data with varying sampling rates and lengths, overcoming common limitations of existing time series tokenizers.","In this proof-of-concept work, we present the effectiveness of LiPCoT in classifying Parkinson's disease (PD) using an EEG dataset from 46 participants.","In particular, we utilize LiPCoT to encode EEG data into a small vocabulary of tokens and then use BERT for self-supervised learning and the downstream task of PD classification.","We benchmark our approach against several state-of-the-art CNN-based deep learning architectures for PD detection.","Our results reveal that BERT models utilizing self-supervised learning outperformed the best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5% in accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for self-supervised learning even on small datasets.","Our work will inform future foundational models for time series, particularly for self-supervised learning."],"url":"http://arxiv.org/abs/2408.07292v1"}
{"created":"2024-08-14 04:49:30","title":"Evaluating Large Language Model based Personal Information Extraction and Countermeasures","abstract":"Automatically extracting personal information--such as name, phone number, and email address--from publicly available profiles at a large scale is a stepstone to many other security attacks including spear phishing. Traditional methods--such as regular expression, keyword search, and entity detection--achieve limited success at such personal information extraction. In this work, we perform a systematic measurement study to benchmark large language model (LLM) based personal information extraction and countermeasures. Towards this goal, we present a framework for LLM-based extraction attacks; collect three datasets including a synthetic dataset generated by GPT-4 and two real-world datasets with manually labeled 8 categories of personal information; introduce a novel mitigation strategy based on \\emph{prompt injection}; and systematically benchmark LLM-based attacks and countermeasures using 10 LLMs and our 3 datasets. Our key findings include: LLM can be misused by attackers to accurately extract various personal information from personal profiles; LLM outperforms conventional methods at such extraction; and prompt injection can mitigate such risk to a large extent and outperforms conventional countermeasures. Our code and data are available at: \\url{https://github.com/liu00222/LLM-Based-Personal-Profile-Extraction}.","sentences":["Automatically extracting personal information--such as name, phone number, and email address--from publicly available profiles at a large scale is a stepstone to many other security attacks including spear phishing.","Traditional methods--such as regular expression, keyword search, and entity detection--achieve limited success at such personal information extraction.","In this work, we perform a systematic measurement study to benchmark large language model (LLM) based personal information extraction and countermeasures.","Towards this goal, we present a framework for LLM-based extraction attacks; collect three datasets including a synthetic dataset generated by GPT-4 and two real-world datasets with manually labeled 8 categories of personal information; introduce a novel mitigation strategy based on \\emph{prompt injection}; and systematically benchmark LLM-based attacks and countermeasures using 10 LLMs and our 3 datasets.","Our key findings include: LLM can be misused by attackers to accurately extract various personal information from personal profiles; LLM outperforms conventional methods at such extraction; and prompt injection can mitigate such risk to a large extent and outperforms conventional countermeasures.","Our code and data are available at: \\url{https://github.com/liu00222/LLM-Based-Personal-Profile-Extraction}."],"url":"http://arxiv.org/abs/2408.07291v1"}
{"created":"2024-08-14 03:35:11","title":"Image-Based Leopard Seal Recognition: Approaches and Challenges in Current Automated Systems","abstract":"This paper examines the challenges and advancements in recognizing seals within their natural habitats using conventional photography, underscored by the emergence of machine learning technologies. We used the leopard seal, \\emph{Hydrurga leptonyx}, a key species within Antarctic ecosystems, to review the different available methods found. As apex predators, Leopard seals are characterized by their significant ecological role and elusive nature so studying them is crucial to understand the health of their ecosystem. Traditional methods of monitoring seal species are often constrained by the labor-intensive and time-consuming processes required for collecting data, compounded by the limited insights these methods provide. The advent of machine learning, particularly through the application of vision transformers, heralds a new era of efficiency and precision in species monitoring. By leveraging state-of-the-art approaches in detection, segmentation, and recognition within digital imaging, this paper presents a synthesis of the current landscape, highlighting both the cutting-edge methodologies and the predominant challenges faced in accurately identifying seals through photographic data.","sentences":["This paper examines the challenges and advancements in recognizing seals within their natural habitats using conventional photography, underscored by the emergence of machine learning technologies.","We used the leopard seal, \\emph{Hydrurga leptonyx}, a key species within Antarctic ecosystems, to review the different available methods found.","As apex predators, Leopard seals are characterized by their significant ecological role and elusive nature so studying them is crucial to understand the health of their ecosystem.","Traditional methods of monitoring seal species are often constrained by the labor-intensive and time-consuming processes required for collecting data, compounded by the limited insights these methods provide.","The advent of machine learning, particularly through the application of vision transformers, heralds a new era of efficiency and precision in species monitoring.","By leveraging state-of-the-art approaches in detection, segmentation, and recognition within digital imaging, this paper presents a synthesis of the current landscape, highlighting both the cutting-edge methodologies and the predominant challenges faced in accurately identifying seals through photographic data."],"url":"http://arxiv.org/abs/2408.07269v1"}
{"created":"2024-08-14 03:18:04","title":"Enhanced Scale-aware Depth Estimation for Monocular Endoscopic Scenes with Geometric Modeling","abstract":"Scale-aware monocular depth estimation poses a significant challenge in computer-aided endoscopic navigation. However, existing depth estimation methods that do not consider the geometric priors struggle to learn the absolute scale from training with monocular endoscopic sequences. Additionally, conventional methods face difficulties in accurately estimating details on tissue and instruments boundaries. In this paper, we tackle these problems by proposing a novel enhanced scale-aware framework that only uses monocular images with geometric modeling for depth estimation. Specifically, we first propose a multi-resolution depth fusion strategy to enhance the quality of monocular depth estimation. To recover the precise scale between relative depth and real-world values, we further calculate the 3D poses of instruments in the endoscopic scenes by algebraic geometry based on the image-only geometric primitives (i.e., boundaries and tip of instruments). Afterwards, the 3D poses of surgical instruments enable the scale recovery of relative depth maps. By coupling scale factors and relative depth estimation, the scale-aware depth of the monocular endoscopic scenes can be estimated. We evaluate the pipeline on in-house endoscopic surgery videos and simulated data. The results demonstrate that our method can learn the absolute scale with geometric modeling and accurately estimate scale-aware depth for monocular scenes.","sentences":["Scale-aware monocular depth estimation poses a significant challenge in computer-aided endoscopic navigation.","However, existing depth estimation methods that do not consider the geometric priors struggle to learn the absolute scale from training with monocular endoscopic sequences.","Additionally, conventional methods face difficulties in accurately estimating details on tissue and instruments boundaries.","In this paper, we tackle these problems by proposing a novel enhanced scale-aware framework that only uses monocular images with geometric modeling for depth estimation.","Specifically, we first propose a multi-resolution depth fusion strategy to enhance the quality of monocular depth estimation.","To recover the precise scale between relative depth and real-world values, we further calculate the 3D poses of instruments in the endoscopic scenes by algebraic geometry based on the image-only geometric primitives (i.e., boundaries and tip of instruments).","Afterwards, the 3D poses of surgical instruments enable the scale recovery of relative depth maps.","By coupling scale factors and relative depth estimation, the scale-aware depth of the monocular endoscopic scenes can be estimated.","We evaluate the pipeline on in-house endoscopic surgery videos and simulated data.","The results demonstrate that our method can learn the absolute scale with geometric modeling and accurately estimate scale-aware depth for monocular scenes."],"url":"http://arxiv.org/abs/2408.07266v1"}
{"created":"2024-08-14 03:03:05","title":"Eavesdropping Mobile Apps and Actions through Wireless Traffic in the Open World","abstract":"While smartphones and WiFi networks are bringing many positive changes to people's lives, they are susceptible to traffic analysis attacks, which infer user's private information from encrypted traffic. Existing traffic analysis attacks mainly target TCP/IP layers or are limited to the closed-world assumption, where all possible apps and actions have been involved in the model training. To overcome these limitations, we propose MACPrint, a novel system that infers mobile apps and in-app actions based on WiFi MAC layer traffic in the open-world setting. MACPrint first extracts rich statistical and contextual features of encrypted wireless traffic. Then, we develop Label Recorder, an automatic traffic labeling app, to improve labeling accuracy in the training phase. Finally, TCN models with OpenMax functions are used to recognize mobile apps and actions in the open world accurately. To evaluate our system, we collect MAC layer traffic data over 125 hours from more than 40 apps. The experimental results show that MAC-Print can achieve an accuracy of over 96% for recognizing apps and actions in the closed-world setting, and obtains an accuracy of over 86% in the open-world setting.","sentences":["While smartphones and WiFi networks are bringing many positive changes to people's lives, they are susceptible to traffic analysis attacks, which infer user's private information from encrypted traffic.","Existing traffic analysis attacks mainly target TCP/IP layers or are limited to the closed-world assumption, where all possible apps and actions have been involved in the model training.","To overcome these limitations, we propose MACPrint, a novel system that infers mobile apps and in-app actions based on WiFi MAC layer traffic in the open-world setting.","MACPrint first extracts rich statistical and contextual features of encrypted wireless traffic.","Then, we develop Label Recorder, an automatic traffic labeling app, to improve labeling accuracy in the training phase.","Finally, TCN models with OpenMax functions are used to recognize mobile apps and actions in the open world accurately.","To evaluate our system, we collect MAC layer traffic data over 125 hours from more than 40 apps.","The experimental results show that MAC-Print can achieve an accuracy of over 96% for recognizing apps and actions in the closed-world setting, and obtains an accuracy of over 86% in the open-world setting."],"url":"http://arxiv.org/abs/2408.07263v1"}
{"created":"2024-08-14 01:24:09","title":"GQE: Generalized Query Expansion for Enhanced Text-Video Retrieval","abstract":"In the rapidly expanding domain of web video content, the task of text-video retrieval has become increasingly critical, bridging the semantic gap between textual queries and video data. This paper introduces a novel data-centric approach, Generalized Query Expansion (GQE), to address the inherent information imbalance between text and video, enhancing the effectiveness of text-video retrieval systems. Unlike traditional model-centric methods that focus on designing intricate cross-modal interaction mechanisms, GQE aims to expand the text queries associated with videos both during training and testing phases. By adaptively segmenting videos into short clips and employing zero-shot captioning, GQE enriches the training dataset with comprehensive scene descriptions, effectively bridging the data imbalance gap. Furthermore, during retrieval, GQE utilizes Large Language Models (LLM) to generate a diverse set of queries and a query selection module to filter these queries based on relevance and diversity, thus optimizing retrieval performance while reducing computational overhead. Our contributions include a detailed examination of the information imbalance challenge, a novel approach to query expansion in video-text datasets, and the introduction of a query selection strategy that enhances retrieval accuracy without increasing computational costs. GQE achieves state-of-the-art performance on several benchmarks, including MSR-VTT, MSVD, LSMDC, and VATEX, demonstrating the effectiveness of addressing text-video retrieval from a data-centric perspective.","sentences":["In the rapidly expanding domain of web video content, the task of text-video retrieval has become increasingly critical, bridging the semantic gap between textual queries and video data.","This paper introduces a novel data-centric approach, Generalized Query Expansion (GQE), to address the inherent information imbalance between text and video, enhancing the effectiveness of text-video retrieval systems.","Unlike traditional model-centric methods that focus on designing intricate cross-modal interaction mechanisms, GQE aims to expand the text queries associated with videos both during training and testing phases.","By adaptively segmenting videos into short clips and employing zero-shot captioning, GQE enriches the training dataset with comprehensive scene descriptions, effectively bridging the data imbalance gap.","Furthermore, during retrieval, GQE utilizes Large Language Models (LLM) to generate a diverse set of queries and a query selection module to filter these queries based on relevance and diversity, thus optimizing retrieval performance while reducing computational overhead.","Our contributions include a detailed examination of the information imbalance challenge, a novel approach to query expansion in video-text datasets, and the introduction of a query selection strategy that enhances retrieval accuracy without increasing computational costs.","GQE achieves state-of-the-art performance on several benchmarks, including MSR-VTT, MSVD, LSMDC, and VATEX, demonstrating the effectiveness of addressing text-video retrieval from a data-centric perspective."],"url":"http://arxiv.org/abs/2408.07249v1"}
{"created":"2024-08-14 01:16:40","title":"Seeing and Understanding: Bridging Vision with Chemical Knowledge Via ChemVLM","abstract":"In this technical report, we propose ChemVLM, the first open-source multimodal large language model dedicated to the fields of chemistry, designed to address the incompatibility between chemical image understanding and text analysis. Built upon the VIT-MLP-LLM architecture, we leverage ChemLLM-20B as the foundational large model, endowing our model with robust capabilities in understanding and utilizing chemical text knowledge. Additionally, we employ InternVIT-6B as a powerful image encoder. We have curated high-quality data from the chemical domain, including molecules, reaction formulas, and chemistry examination data, and compiled these into a bilingual multimodal question-answering dataset. We test the performance of our model on multiple open-source benchmarks and three custom evaluation sets. Experimental results demonstrate that our model achieves excellent performance, securing state-of-the-art results in five out of six involved tasks. Our model can be found at https://huggingface.co/AI4Chem/ChemVLM-26B.","sentences":["In this technical report, we propose ChemVLM, the first open-source multimodal large language model dedicated to the fields of chemistry, designed to address the incompatibility between chemical image understanding and text analysis.","Built upon the VIT-MLP-LLM architecture, we leverage ChemLLM-20B as the foundational large model, endowing our model with robust capabilities in understanding and utilizing chemical text knowledge.","Additionally, we employ InternVIT-6B as a powerful image encoder.","We have curated high-quality data from the chemical domain, including molecules, reaction formulas, and chemistry examination data, and compiled these into a bilingual multimodal question-answering dataset.","We test the performance of our model on multiple open-source benchmarks and three custom evaluation sets.","Experimental results demonstrate that our model achieves excellent performance, securing state-of-the-art results in five out of six involved tasks.","Our model can be found at https://huggingface.co/AI4Chem/ChemVLM-26B."],"url":"http://arxiv.org/abs/2408.07246v1"}
{"created":"2024-08-14 00:08:28","title":"Enhancing Autonomous Vehicle Perception in Adverse Weather through Image Augmentation during Semantic Segmentation Training","abstract":"Robust perception is crucial in autonomous vehicle navigation and localization. Visual processing tasks, like semantic segmentation, should work in varying weather conditions and during different times of day. Semantic segmentation is where each pixel is assigned a class, which is useful for locating overall features (1). Training a segmentation model requires large amounts of data, and the labeling process for segmentation data is especially tedious. Additionally, many large datasets include only images taken in clear weather. This is a problem because training a model exclusively on clear weather data hinders performance in adverse weather conditions like fog or rain. We hypothesize that given a dataset of only clear days images, applying image augmentation (such as random rain, fog, and brightness) during training allows for domain adaptation to diverse weather conditions. We used CARLA, a 3D realistic autonomous vehicle simulator, to collect 1200 images in clear weather composed of 29 classes from 10 different towns (2). We also collected 1200 images of random weather effects. We trained encoder-decoder UNet models to perform semantic segmentation. Applying augmentations significantly improved segmentation under weathered night conditions (p < 0.001). However, models trained on weather data have significantly lower losses than those trained on augmented data in all conditions except for clear days. This shows there is room for improvement in the domain adaptation approach. Future work should test more types of augmentations and also use real-life images instead of CARLA. Ideally, the augmented model meets or exceeds the performance of the weather model.","sentences":["Robust perception is crucial in autonomous vehicle navigation and localization.","Visual processing tasks, like semantic segmentation, should work in varying weather conditions and during different times of day.","Semantic segmentation is where each pixel is assigned a class, which is useful for locating overall features (1).","Training a segmentation model requires large amounts of data, and the labeling process for segmentation data is especially tedious.","Additionally, many large datasets include only images taken in clear weather.","This is a problem because training a model exclusively on clear weather data hinders performance in adverse weather conditions like fog or rain.","We hypothesize that given a dataset of only clear days images, applying image augmentation (such as random rain, fog, and brightness) during training allows for domain adaptation to diverse weather conditions.","We used CARLA, a 3D realistic autonomous vehicle simulator, to collect 1200 images in clear weather composed of 29 classes from 10 different towns (2).","We also collected 1200 images of random weather effects.","We trained encoder-decoder UNet models to perform semantic segmentation.","Applying augmentations significantly improved segmentation under weathered night conditions (p < 0.001).","However, models trained on weather data have significantly lower losses than those trained on augmented data in all conditions except for clear days.","This shows there is room for improvement in the domain adaptation approach.","Future work should test more types of augmentations and also use real-life images instead of CARLA.","Ideally, the augmented model meets or exceeds the performance of the weather model."],"url":"http://arxiv.org/abs/2408.07239v1"}
{"created":"2024-08-13 23:58:45","title":"Neural embedding of beliefs reveals the role of relative dissonance in human decision-making","abstract":"Beliefs serve as the foundation for human cognition and decision-making. They guide individuals in deriving meaning from their lives, shaping their behaviors, and forming social connections. Therefore, a model that encapsulates beliefs and their interrelationships is crucial for quantitatively studying the influence of beliefs on our actions. Despite its importance, research on the interplay between human beliefs has often been limited to a small set of beliefs pertaining to specific issues, with a heavy reliance on surveys or experiments. Here, we propose a method for extracting nuanced relations between thousands of beliefs by leveraging large-scale user participation data from an online debate platform and mapping these beliefs to an embedding space using a fine-tuned large language model (LLM). This belief embedding space effectively encapsulates the interconnectedness of diverse beliefs as well as polarization across various social issues. We discover that the positions within this belief space predict new beliefs of individuals. Furthermore, we find that the relative distance between one's existing beliefs and new beliefs can serve as a quantitative estimate of cognitive dissonance, allowing us to predict new beliefs. Our study highlights how modern LLMs, when combined with collective online records of human beliefs, can offer insights into the fundamental principles that govern human belief formation and decision-making processes.","sentences":["Beliefs serve as the foundation for human cognition and decision-making.","They guide individuals in deriving meaning from their lives, shaping their behaviors, and forming social connections.","Therefore, a model that encapsulates beliefs and their interrelationships is crucial for quantitatively studying the influence of beliefs on our actions.","Despite its importance, research on the interplay between human beliefs has often been limited to a small set of beliefs pertaining to specific issues, with a heavy reliance on surveys or experiments.","Here, we propose a method for extracting nuanced relations between thousands of beliefs by leveraging large-scale user participation data from an online debate platform and mapping these beliefs to an embedding space using a fine-tuned large language model (LLM).","This belief embedding space effectively encapsulates the interconnectedness of diverse beliefs as well as polarization across various social issues.","We discover that the positions within this belief space predict new beliefs of individuals.","Furthermore, we find that the relative distance between one's existing beliefs and new beliefs can serve as a quantitative estimate of cognitive dissonance, allowing us to predict new beliefs.","Our study highlights how modern LLMs, when combined with collective online records of human beliefs, can offer insights into the fundamental principles that govern human belief formation and decision-making processes."],"url":"http://arxiv.org/abs/2408.07237v1"}
{"created":"2024-08-13 23:55:56","title":"TaPS: A Performance Evaluation Suite for Task-based Execution Frameworks","abstract":"Task-based execution frameworks, such as parallel programming libraries, computational workflow systems, and function-as-a-service platforms, enable the composition of distinct tasks into a single, unified application designed to achieve a computational goal. Task-based execution frameworks abstract the parallel execution of an application's tasks on arbitrary hardware. Research into these task executors has accelerated as computational sciences increasingly need to take advantage of parallel compute and/or heterogeneous hardware. However, the lack of evaluation standards makes it challenging to compare and contrast novel systems against existing implementations. Here, we introduce TaPS, the Task Performance Suite, to support continued research in parallel task executor frameworks. TaPS provides (1) a unified, modular interface for writing and evaluating applications using arbitrary execution frameworks and data management systems and (2) an initial set of reference synthetic and real-world science applications. We discuss how the design of TaPS supports the reliable evaluation of frameworks and demonstrate TaPS through a survey of benchmarks using the provided reference applications.","sentences":["Task-based execution frameworks, such as parallel programming libraries, computational workflow systems, and function-as-a-service platforms, enable the composition of distinct tasks into a single, unified application designed to achieve a computational goal.","Task-based execution frameworks abstract the parallel execution of an application's tasks on arbitrary hardware.","Research into these task executors has accelerated as computational sciences increasingly need to take advantage of parallel compute and/or heterogeneous hardware.","However, the lack of evaluation standards makes it challenging to compare and contrast novel systems against existing implementations.","Here, we introduce TaPS, the Task Performance Suite, to support continued research in parallel task executor frameworks.","TaPS provides (1) a unified, modular interface for writing and evaluating applications using arbitrary execution frameworks and data management systems and (2) an initial set of reference synthetic and real-world science applications.","We discuss how the design of TaPS supports the reliable evaluation of frameworks and demonstrate TaPS through a survey of benchmarks using the provided reference applications."],"url":"http://arxiv.org/abs/2408.07236v1"}
{"created":"2024-08-13 22:13:25","title":"Causal Effect Estimation using identifiable Variational AutoEncoder with Latent Confounders and Post-Treatment Variables","abstract":"Estimating causal effects from observational data is challenging, especially in the presence of latent confounders. Much work has been done on addressing this challenge, but most of the existing research ignores the bias introduced by the post-treatment variables. In this paper, we propose a novel method of joint Variational AutoEncoder (VAE) and identifiable Variational AutoEncoder (iVAE) for learning the representations of latent confounders and latent post-treatment variables from their proxy variables, termed CPTiVAE, to achieve unbiased causal effect estimation from observational data. We further prove the identifiability in terms of the representation of latent post-treatment variables. Extensive experiments on synthetic and semi-synthetic datasets demonstrate that the CPTiVAE outperforms the state-of-the-art methods in the presence of latent confounders and post-treatment variables. We further apply CPTiVAE to a real-world dataset to show its potential application.","sentences":["Estimating causal effects from observational data is challenging, especially in the presence of latent confounders.","Much work has been done on addressing this challenge, but most of the existing research ignores the bias introduced by the post-treatment variables.","In this paper, we propose a novel method of joint Variational AutoEncoder (VAE) and identifiable Variational AutoEncoder (iVAE) for learning the representations of latent confounders and latent post-treatment variables from their proxy variables, termed CPTiVAE, to achieve unbiased causal effect estimation from observational data.","We further prove the identifiability in terms of the representation of latent post-treatment variables.","Extensive experiments on synthetic and semi-synthetic datasets demonstrate that the CPTiVAE outperforms the state-of-the-art methods in the presence of latent confounders and post-treatment variables.","We further apply CPTiVAE to a real-world dataset to show its potential application."],"url":"http://arxiv.org/abs/2408.07219v1"}
{"created":"2024-08-13 21:54:10","title":"Can Large Language Models Reason? A Characterization via 3-SAT","abstract":"Large Language Models (LLMs) are said to possess advanced reasoning abilities. However, some skepticism exists as recent works show how LLMs often bypass true reasoning using shortcuts. Current methods for assessing the reasoning abilities of LLMs typically rely on open-source benchmarks that may be overrepresented in LLM training data, potentially skewing performance. We instead provide a computational theory perspective of reasoning, using 3-SAT -- the prototypical NP-complete problem that lies at the core of logical reasoning and constraint satisfaction tasks. By examining the phase transitions in 3-SAT, we empirically characterize the reasoning abilities of LLMs and show how they vary with the inherent hardness of the problems. Our experimental evidence shows that LLMs cannot perform true reasoning, as is required for solving 3-SAT problems.","sentences":["Large Language Models (LLMs) are said to possess advanced reasoning abilities.","However, some skepticism exists as recent works show how LLMs often bypass true reasoning using shortcuts.","Current methods for assessing the reasoning abilities of LLMs typically rely on open-source benchmarks that may be overrepresented in LLM training data, potentially skewing performance.","We instead provide a computational theory perspective of reasoning, using 3-SAT -- the prototypical NP-complete problem that lies at the core of logical reasoning and constraint satisfaction tasks.","By examining the phase transitions in 3-SAT, we empirically characterize the reasoning abilities of LLMs and show how they vary with the inherent hardness of the problems.","Our experimental evidence shows that LLMs cannot perform true reasoning, as is required for solving 3-SAT problems."],"url":"http://arxiv.org/abs/2408.07215v1"}
{"created":"2024-08-13 21:10:39","title":"Quantification of total uncertainty in the physics-informed reconstruction of CVSim-6 physiology","abstract":"When predicting physical phenomena through simulation, quantification of the total uncertainty due to multiple sources is as crucial as making sure the underlying numerical model is accurate. Possible sources include irreducible aleatoric uncertainty due to noise in the data, epistemic uncertainty induced by insufficient data or inadequate parameterization, and model-form uncertainty related to the use of misspecified model equations. Physics-based regularization interacts in nontrivial ways with aleatoric, epistemic and model-form uncertainty and their combination, and a better understanding of this interaction is needed to improve the predictive performance of physics-informed digital twins that operate under real conditions. With a specific focus on biological and physiological models, this study investigates the decomposition of total uncertainty in the estimation of states and parameters of a differential system simulated with MC X-TFC, a new physics-informed approach for uncertainty quantification based on random projections and Monte-Carlo sampling. MC X-TFC is applied to a six-compartment stiff ODE system, the CVSim-6 model, developed in the context of human physiology. The system is analyzed by progressively removing data while estimating an increasing number of parameters and by investigating total uncertainty under model-form misspecification of non-linear resistance in the pulmonary compartment. In particular, we focus on the interaction between the formulation of the discrepancy term and quantification of model-form uncertainty, and show how additional physics can help in the estimation process. The method demonstrates robustness and efficiency in estimating unknown states and parameters, even with limited, sparse, and noisy data. It also offers great flexibility in integrating data with physics for improved estimation, even in cases of model misspecification.","sentences":["When predicting physical phenomena through simulation, quantification of the total uncertainty due to multiple sources is as crucial as making sure the underlying numerical model is accurate.","Possible sources include irreducible aleatoric uncertainty due to noise in the data, epistemic uncertainty induced by insufficient data or inadequate parameterization, and model-form uncertainty related to the use of misspecified model equations.","Physics-based regularization interacts in nontrivial ways with aleatoric, epistemic and model-form uncertainty and their combination, and a better understanding of this interaction is needed to improve the predictive performance of physics-informed digital twins that operate under real conditions.","With a specific focus on biological and physiological models, this study investigates the decomposition of total uncertainty in the estimation of states and parameters of a differential system simulated with MC X-TFC, a new physics-informed approach for uncertainty quantification based on random projections and Monte-Carlo sampling.","MC X-TFC is applied to a six-compartment stiff ODE system, the CVSim-6 model, developed in the context of human physiology.","The system is analyzed by progressively removing data while estimating an increasing number of parameters and by investigating total uncertainty under model-form misspecification of non-linear resistance in the pulmonary compartment.","In particular, we focus on the interaction between the formulation of the discrepancy term and quantification of model-form uncertainty, and show how additional physics can help in the estimation process.","The method demonstrates robustness and efficiency in estimating unknown states and parameters, even with limited, sparse, and noisy data.","It also offers great flexibility in integrating data with physics for improved estimation, even in cases of model misspecification."],"url":"http://arxiv.org/abs/2408.07201v1"}
{"created":"2024-08-13 20:52:13","title":"Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents","abstract":"Large Language Models (LLMs) have shown remarkable capabilities in natural language tasks requiring complex reasoning, yet their application in agentic, multi-step reasoning within interactive environments remains a difficult challenge. Traditional supervised pre-training on static datasets falls short in enabling autonomous agent capabilities needed to perform complex decision-making in dynamic settings like web navigation. Previous attempts to bridge this ga-through supervised fine-tuning on curated expert demonstrations-often suffer from compounding errors and limited exploration data, resulting in sub-optimal policy outcomes. To overcome these challenges, we propose a framework that combines guided Monte Carlo Tree Search (MCTS) search with a self-critique mechanism and iterative fine-tuning on agent interactions using an off-policy variant of the Direct Preference Optimization (DPO) algorithm. Our method allows LLM agents to learn effectively from both successful and unsuccessful trajectories, thereby improving their generalization in complex, multi-step reasoning tasks. We validate our approach in the WebShop environment-a simulated e-commerce platform where it consistently outperforms behavior cloning and reinforced fine-tuning baseline, and beats average human performance when equipped with the capability to do online search. In real-world booking scenarios, our methodology boosts Llama-3 70B model's zero-shot performance from 18.6% to 81.7% success rate (a 340% relative increase) after a single day of data collection and further to 95.4% with online search. We believe this represents a substantial leap forward in the capabilities of autonomous agents, paving the way for more sophisticated and reliable decision-making in real-world settings.","sentences":["Large Language Models (LLMs) have shown remarkable capabilities in natural language tasks requiring complex reasoning, yet their application in agentic, multi-step reasoning within interactive environments remains a difficult challenge.","Traditional supervised pre-training on static datasets falls short in enabling autonomous agent capabilities needed to perform complex decision-making in dynamic settings like web navigation.","Previous attempts to bridge this ga-through supervised fine-tuning on curated expert demonstrations-often suffer from compounding errors and limited exploration data, resulting in sub-optimal policy outcomes.","To overcome these challenges, we propose a framework that combines guided Monte Carlo Tree Search (MCTS) search with a self-critique mechanism and iterative fine-tuning on agent interactions using an off-policy variant of the Direct Preference Optimization (DPO) algorithm.","Our method allows LLM agents to learn effectively from both successful and unsuccessful trajectories, thereby improving their generalization in complex, multi-step reasoning tasks.","We validate our approach in the WebShop environment-a simulated e-commerce platform where it consistently outperforms behavior cloning and reinforced fine-tuning baseline, and beats average human performance when equipped with the capability to do online search.","In real-world booking scenarios, our methodology boosts Llama-3 70B model's zero-shot performance from 18.6% to 81.7% success rate (a 340% relative increase) after a single day of data collection and further to 95.4% with online search.","We believe this represents a substantial leap forward in the capabilities of autonomous agents, paving the way for more sophisticated and reliable decision-making in real-world settings."],"url":"http://arxiv.org/abs/2408.07199v1"}
{"created":"2024-08-13 20:32:02","title":"SeLoRA: Self-Expanding Low-Rank Adaptation of Latent Diffusion Model for Medical Image Synthesis","abstract":"The persistent challenge of medical image synthesis posed by the scarcity of annotated data and the need to synthesize `missing modalities' for multi-modal analysis, underscored the imperative development of effective synthesis methods. Recently, the combination of Low-Rank Adaptation (LoRA) with latent diffusion models (LDMs) has emerged as a viable approach for efficiently adapting pre-trained large language models, in the medical field. However, the direct application of LoRA assumes uniform ranking across all linear layers, overlooking the significance of different weight matrices, and leading to sub-optimal outcomes. Prior works on LoRA prioritize the reduction of trainable parameters, and there exists an opportunity to further tailor this adaptation process to the intricate demands of medical image synthesis. In response, we present SeLoRA, a Self-Expanding Low-Rank Adaptation Module, that dynamically expands its ranking across layers during training, strategically placing additional ranks on crucial layers, to allow the model to elevate synthesis quality where it matters most. The proposed method not only enables LDMs to fine-tune on medical data efficiently but also empowers the model to achieve improved image quality with minimal ranking. The code of our SeLoRA method is publicly available on https://anonymous.4open.science/r/SeLoRA-980D .","sentences":["The persistent challenge of medical image synthesis posed by the scarcity of annotated data and the need to synthesize `missing modalities' for multi-modal analysis, underscored the imperative development of effective synthesis methods.","Recently, the combination of Low-Rank Adaptation (LoRA) with latent diffusion models (LDMs) has emerged as a viable approach for efficiently adapting pre-trained large language models, in the medical field.","However, the direct application of LoRA assumes uniform ranking across all linear layers, overlooking the significance of different weight matrices, and leading to sub-optimal outcomes.","Prior works on LoRA prioritize the reduction of trainable parameters, and there exists an opportunity to further tailor this adaptation process to the intricate demands of medical image synthesis.","In response, we present SeLoRA, a Self-Expanding Low-Rank Adaptation Module, that dynamically expands its ranking across layers during training, strategically placing additional ranks on crucial layers, to allow the model to elevate synthesis quality where it matters most.","The proposed method not only enables LDMs to fine-tune on medical data efficiently but also empowers the model to achieve improved image quality with minimal ranking.","The code of our SeLoRA method is publicly available on https://anonymous.4open.science/r/SeLoRA-980D ."],"url":"http://arxiv.org/abs/2408.07196v1"}
{"created":"2024-08-13 20:16:11","title":"Joint Graph Rewiring and Feature Denoising via Spectral Resonance","abstract":"Graph neural networks (GNNs) take as input the graph structure and the feature vectors associated with the nodes. Both contain noisy information about the labels. Here we propose joint denoising and rewiring (JDR)--an algorithm to jointly denoise the graph structure and features, which can improve the performance of any downstream algorithm. We do this by defining and maximizing the alignment between the leading eigenspaces of graph and feature matrices. To approximately solve this computationally hard problem, we propose a heuristic that efficiently handles real-world graph datasets with many classes and different levels of homophily or heterophily. We experimentally verify the effectiveness of our approach on synthetic data and real-world graph datasets. The results show that JDR consistently outperforms existing rewiring methods on node classification tasks using GNNs as downstream models.","sentences":["Graph neural networks (GNNs) take as input the graph structure and the feature vectors associated with the nodes.","Both contain noisy information about the labels.","Here we propose joint denoising and rewiring (JDR)--an algorithm to jointly denoise the graph structure and features, which can improve the performance of any downstream algorithm.","We do this by defining and maximizing the alignment between the leading eigenspaces of graph and feature matrices.","To approximately solve this computationally hard problem, we propose a heuristic that efficiently handles real-world graph datasets with many classes and different levels of homophily or heterophily.","We experimentally verify the effectiveness of our approach on synthetic data and real-world graph datasets.","The results show that JDR consistently outperforms existing rewiring methods on node classification tasks using GNNs as downstream models."],"url":"http://arxiv.org/abs/2408.07191v1"}
{"created":"2024-08-13 19:52:06","title":"A New Dataset, Notation Software, and Representation for Computational Schenkerian Analysis","abstract":"Schenkerian Analysis (SchA) is a uniquely expressive method of music analysis, combining elements of melody, harmony, counterpoint, and form to describe the hierarchical structure supporting a work of music. However, despite its powerful analytical utility and potential to improve music understanding and generation, SchA has rarely been utilized by the computer music community. This is in large part due to the paucity of available high-quality data in a computer-readable format. With a larger corpus of Schenkerian data, it may be possible to infuse machine learning models with a deeper understanding of musical structure, thus leading to more \"human\" results. To encourage further research in Schenkerian analysis and its potential benefits for music informatics and generation, this paper presents three main contributions: 1) a new and growing dataset of SchAs, the largest in human- and computer-readable formats to date (>140 excerpts), 2) a novel software for visualization and collection of SchA data, and 3) a novel, flexible representation of SchA as a heterogeneous-edge graph data structure.","sentences":["Schenkerian Analysis (SchA) is a uniquely expressive method of music analysis, combining elements of melody, harmony, counterpoint, and form to describe the hierarchical structure supporting a work of music.","However, despite its powerful analytical utility and potential to improve music understanding and generation, SchA has rarely been utilized by the computer music community.","This is in large part due to the paucity of available high-quality data in a computer-readable format.","With a larger corpus of Schenkerian data, it may be possible to infuse machine learning models with a deeper understanding of musical structure, thus leading to more \"human\" results.","To encourage further research in Schenkerian analysis and its potential benefits for music informatics and generation, this paper presents three main contributions: 1) a new and growing dataset of SchAs, the largest in human- and computer-readable formats to date (>140 excerpts), 2) a novel software for visualization and collection of SchA data, and 3) a novel, flexible representation of SchA as a heterogeneous-edge graph data structure."],"url":"http://arxiv.org/abs/2408.07184v1"}
{"created":"2024-08-13 19:38:59","title":"V3rified: Revelation vs Non-Revelation Mechanisms for Decentralized Verifiable Computation","abstract":"In the era of Web3, decentralized technologies have emerged as the cornerstone of a new digital paradigm. Backed by a decentralized blockchain architecture, the Web3 space aims to democratize all aspects of the web. From data-sharing to learning models, outsourcing computation is an established, prevalent practice. Verifiable computation makes this practice trustworthy as clients/users can now efficiently validate the integrity of a computation. As verifiable computation gets considered for applications in the Web3 space, decentralization is crucial for system reliability, ensuring that no single entity can suppress clients. At the same time, however, decentralization needs to be balanced with efficiency: clients want their computations done as quickly as possible.   Motivated by these issues, we study the trade-off between decentralization and efficiency when outsourcing computational tasks to strategic, rational solution providers. Specifically, we examine this trade-off when the client employs (1) revelation mechanisms, i.e. auctions, where solution providers bid their desired reward for completing the task by a specific deadline and then the client selects which of them will do the task and how much they will be rewarded, and (2) simple, non-revelation mechanisms, where the client commits to the set of rules she will use to map solutions at specific times to rewards and then solution providers decide whether they want to do the task or not. We completely characterize the power and limitations of revelation and non-revelation mechanisms in our model.","sentences":["In the era of Web3, decentralized technologies have emerged as the cornerstone of a new digital paradigm.","Backed by a decentralized blockchain architecture, the Web3 space aims to democratize all aspects of the web.","From data-sharing to learning models, outsourcing computation is an established, prevalent practice.","Verifiable computation makes this practice trustworthy as clients/users can now efficiently validate the integrity of a computation.","As verifiable computation gets considered for applications in the Web3 space, decentralization is crucial for system reliability, ensuring that no single entity can suppress clients.","At the same time, however, decentralization needs to be balanced with efficiency: clients want their computations done as quickly as possible.   ","Motivated by these issues, we study the trade-off between decentralization and efficiency when outsourcing computational tasks to strategic, rational solution providers.","Specifically, we examine this trade-off when the client employs (1) revelation mechanisms, i.e. auctions, where solution providers bid their desired reward for completing the task by a specific deadline and then the client selects which of them will do the task and how much they will be rewarded, and (2) simple, non-revelation mechanisms, where the client commits to the set of rules she will use to map solutions at specific times to rewards and then solution providers decide whether they want to do the task or not.","We completely characterize the power and limitations of revelation and non-revelation mechanisms in our model."],"url":"http://arxiv.org/abs/2408.07177v1"}
{"created":"2024-08-13 19:37:20","title":"On the Local Ultrametricity of Finite Metric Data","abstract":"New local ultrametricity measures for finite metric data are proposed through the viewpoint that their Vietoris-Rips corners are samples from p-adic Mumford curves endowed with a Radon measure coming from a regular differential 1-form. This is experimentally applied to the iris dataset.","sentences":["New local ultrametricity measures for finite metric data are proposed through the viewpoint that their Vietoris-Rips corners are samples from p-adic Mumford curves endowed with a Radon measure coming from a regular differential 1-form.","This is experimentally applied to the iris dataset."],"url":"http://arxiv.org/abs/2408.07174v1"}
{"created":"2024-08-13 18:58:17","title":"Fast and Accurate Algorithms to Calculate Expected Modularity in Probabilistic Networks","abstract":"Modularity maximization is a widely used community detection technique for deterministic networks. However, little research has been performed to develop efficient modularity calculation algorithms for probabilistic networks. Particularly, it is challenging to efficiently calculate expected modularity when all possible worlds are considered. To address this problem, we propose two algorithms, namely $\\mathrm{PWP}^{\\mathrm{EMOD}}$ and $\\mathrm{APWP}^{\\mathrm{EMOD}}$, partitioning the possible worlds based on their modularities to significantly reduce the number of probability calculations. We evaluate the accuracy and time efficiency of our algorithms through comprehensive experiments.","sentences":["Modularity maximization is a widely used community detection technique for deterministic networks.","However, little research has been performed to develop efficient modularity calculation algorithms for probabilistic networks.","Particularly, it is challenging to efficiently calculate expected modularity when all possible worlds are considered.","To address this problem, we propose two algorithms, namely $\\mathrm{PWP}^{\\mathrm{EMOD}}$ and $\\mathrm{APWP}^{\\mathrm{EMOD}}$, partitioning the possible worlds based on their modularities to significantly reduce the number of probability calculations.","We evaluate the accuracy and time efficiency of our algorithms through comprehensive experiments."],"url":"http://arxiv.org/abs/2408.07161v1"}
{"created":"2024-08-13 18:42:34","title":"FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method","abstract":"The rapid proliferation of Internet of Things (IoT) devices across multiple sectors has escalated serious network security concerns. This has prompted ongoing research in Machine Learning (ML)-based Intrusion Detection Systems (IDSs) for cyber-attack classification. Traditional ML models require data transmission from IoT devices to a centralized server for traffic analysis, raising severe privacy concerns. To address this issue, researchers have studied Federated Learning (FL)-based IDSs that train models across IoT devices while keeping their data localized. However, the heterogeneity of data, stemming from distinct vulnerabilities of devices and complexity of attack vectors, poses a significant challenge to the effectiveness of FL models. While current research focuses on adapting various ML models within the FL framework, they fail to effectively address the issue of attack class imbalance among devices, which significantly degrades the classification accuracy of minority attacks. To overcome this challenge, we introduce FedMADE, a novel dynamic aggregation method, which clusters devices by their traffic patterns and aggregates local models based on their contributions towards overall performance. We evaluate FedMADE against other FL algorithms designed for non-IID data and observe up to 71.07% improvement in minority attack classification accuracy. We further show that FedMADE is robust to poisoning attacks and incurs only a 4.7% (5.03 seconds) latency overhead in each communication round compared to FedAvg, without increasing the computational load of IoT devices.","sentences":["The rapid proliferation of Internet of Things (IoT) devices across multiple sectors has escalated serious network security concerns.","This has prompted ongoing research in Machine Learning (ML)-based Intrusion Detection Systems (IDSs) for cyber-attack classification.","Traditional ML models require data transmission from IoT devices to a centralized server for traffic analysis, raising severe privacy concerns.","To address this issue, researchers have studied Federated Learning (FL)-based IDSs that train models across IoT devices while keeping their data localized.","However, the heterogeneity of data, stemming from distinct vulnerabilities of devices and complexity of attack vectors, poses a significant challenge to the effectiveness of FL models.","While current research focuses on adapting various ML models within the FL framework, they fail to effectively address the issue of attack class imbalance among devices, which significantly degrades the classification accuracy of minority attacks.","To overcome this challenge, we introduce FedMADE, a novel dynamic aggregation method, which clusters devices by their traffic patterns and aggregates local models based on their contributions towards overall performance.","We evaluate FedMADE against other FL algorithms designed for non-IID data and observe up to 71.07% improvement in minority attack classification accuracy.","We further show that FedMADE is robust to poisoning attacks and incurs only a 4.7% (5.03 seconds) latency overhead in each communication round compared to FedAvg, without increasing the computational load of IoT devices."],"url":"http://arxiv.org/abs/2408.07152v1"}
{"created":"2024-08-13 18:33:45","title":"Controlling the World by Sleight of Hand","abstract":"Humans naturally build mental models of object interactions and dynamics, allowing them to imagine how their surroundings will change if they take a certain action. While generative models today have shown impressive results on generating/editing images unconditionally or conditioned on text, current methods do not provide the ability to perform object manipulation conditioned on actions, an important tool for world modeling and action planning. Therefore, we propose to learn an action-conditional generative models by learning from unlabeled videos of human hands interacting with objects. The vast quantity of such data on the internet allows for efficient scaling which can enable high-performing action-conditional models. Given an image, and the shape/location of a desired hand interaction, CosHand, synthesizes an image of a future after the interaction has occurred. Experiments show that the resulting model can predict the effects of hand-object interactions well, with strong generalization particularly to translation, stretching, and squeezing interactions of unseen objects in unseen environments. Further, CosHand can be sampled many times to predict multiple possible effects, modeling the uncertainty of forces in the interaction/environment. Finally, method generalizes to different embodiments, including non-human hands, i.e. robot hands, suggesting that generative video models can be powerful models for robotics.","sentences":["Humans naturally build mental models of object interactions and dynamics, allowing them to imagine how their surroundings will change if they take a certain action.","While generative models today have shown impressive results on generating/editing images unconditionally or conditioned on text, current methods do not provide the ability to perform object manipulation conditioned on actions, an important tool for world modeling and action planning.","Therefore, we propose to learn an action-conditional generative models by learning from unlabeled videos of human hands interacting with objects.","The vast quantity of such data on the internet allows for efficient scaling which can enable high-performing action-conditional models.","Given an image, and the shape/location of a desired hand interaction, CosHand, synthesizes an image of a future after the interaction has occurred.","Experiments show that the resulting model can predict the effects of hand-object interactions well, with strong generalization particularly to translation, stretching, and squeezing interactions of unseen objects in unseen environments.","Further, CosHand can be sampled many times to predict multiple possible effects, modeling the uncertainty of forces in the interaction/environment.","Finally, method generalizes to different embodiments, including non-human hands, i.e. robot hands, suggesting that generative video models can be powerful models for robotics."],"url":"http://arxiv.org/abs/2408.07147v1"}
{"created":"2024-08-13 18:26:04","title":"Language Models as Models of Language","abstract":"This chapter critically examines the potential contributions of modern language models to theoretical linguistics. Despite their focus on engineering goals, these models' ability to acquire sophisticated linguistic knowledge from mere exposure to data warrants a careful reassessment of their relevance to linguistic theory. I review a growing body of empirical evidence suggesting that language models can learn hierarchical syntactic structure and exhibit sensitivity to various linguistic phenomena, even when trained on developmentally plausible amounts of data. While the competence/performance distinction has been invoked to dismiss the relevance of such models to linguistic theory, I argue that this assessment may be premature. By carefully controlling learning conditions and making use of causal intervention methods, experiments with language models can potentially constrain hypotheses about language acquisition and competence. I conclude that closer collaboration between theoretical linguists and computational researchers could yield valuable insights, particularly in advancing debates about linguistic nativism.","sentences":["This chapter critically examines the potential contributions of modern language models to theoretical linguistics.","Despite their focus on engineering goals, these models' ability to acquire sophisticated linguistic knowledge from mere exposure to data warrants a careful reassessment of their relevance to linguistic theory.","I review a growing body of empirical evidence suggesting that language models can learn hierarchical syntactic structure and exhibit sensitivity to various linguistic phenomena, even when trained on developmentally plausible amounts of data.","While the competence/performance distinction has been invoked to dismiss the relevance of such models to linguistic theory, I argue that this assessment may be premature.","By carefully controlling learning conditions and making use of causal intervention methods, experiments with language models can potentially constrain hypotheses about language acquisition and competence.","I conclude that closer collaboration between theoretical linguists and computational researchers could yield valuable insights, particularly in advancing debates about linguistic nativism."],"url":"http://arxiv.org/abs/2408.07144v1"}
{"created":"2024-08-13 18:10:06","title":"The Adaptive Strategies of Anti-Kremlin Digital Dissent in Telegram during the Russian Invasion of Ukraine","abstract":"During Russia's invasion of Ukraine in February 2022, Telegram became an essential social media platform for Kremlin-sponsored propaganda dissemination. Over time, Anti-Kremlin Russian opposition channels have also emerged as a prominent voice of dissent against the state-sponsored propaganda. This study examines the dynamics of Anti-Kremlin content on Telegram over seven phases of the invasion, inspired by the concept of breach in narrative theory. A data-driven, computational analysis of emerging topics revealed the Russian economy, combat updates, international politics, and Russian domestic affairs, among others. Using a common set of statistical contrasts by phases of the invasion, a longitudinal analysis of topic prevalence allowed us to examine associations with documented offline events and viewer reactions, suggesting an adaptive breach-oriented communications strategy that maintained viewer interest. Viewer approval of those events that threaten Kremlin control suggests that Telegram levels the online playing field for the opposition, surprising given the Kremlin's suppression of free speech offline.","sentences":["During Russia's invasion of Ukraine in February 2022, Telegram became an essential social media platform for Kremlin-sponsored propaganda dissemination.","Over time, Anti-Kremlin Russian opposition channels have also emerged as a prominent voice of dissent against the state-sponsored propaganda.","This study examines the dynamics of Anti-Kremlin content on Telegram over seven phases of the invasion, inspired by the concept of breach in narrative theory.","A data-driven, computational analysis of emerging topics revealed the Russian economy, combat updates, international politics, and Russian domestic affairs, among others.","Using a common set of statistical contrasts by phases of the invasion, a longitudinal analysis of topic prevalence allowed us to examine associations with documented offline events and viewer reactions, suggesting an adaptive breach-oriented communications strategy that maintained viewer interest.","Viewer approval of those events that threaten Kremlin control suggests that Telegram levels the online playing field for the opposition, surprising given the Kremlin's suppression of free speech offline."],"url":"http://arxiv.org/abs/2408.07135v1"}
{"created":"2024-08-13 17:57:14","title":"Fingerspelling within Sign Language Translation","abstract":"Fingerspelling poses challenges for sign language processing due to its high-frequency motion and use for open-vocabulary terms. While prior work has studied fingerspelling recognition, there has been little attention to evaluating how well sign language translation models understand fingerspelling in the context of entire sentences -- and improving this capability. We manually annotate instances of fingerspelling within FLEURS-ASL and use them to evaluate the effect of two simple measures to improve fingerspelling recognition within American Sign Language to English translation: 1) use a model family (ByT5) with character- rather than subword-level tokenization, and 2) mix fingerspelling recognition data into the translation training mixture. We find that 1) substantially improves understanding of fingerspelling (and therefore translation quality overall), but the effect of 2) is mixed.","sentences":["Fingerspelling poses challenges for sign language processing due to its high-frequency motion and use for open-vocabulary terms.","While prior work has studied fingerspelling recognition, there has been little attention to evaluating how well sign language translation models understand fingerspelling in the context of entire sentences -- and improving this capability.","We manually annotate instances of fingerspelling within FLEURS-ASL and use them to evaluate the effect of two simple measures to improve fingerspelling recognition within American Sign Language to English translation: 1) use a model family (ByT5) with character- rather than subword-level tokenization, and 2) mix fingerspelling recognition data into the translation training mixture.","We find that 1) substantially improves understanding of fingerspelling (and therefore translation quality overall), but the effect of 2) is mixed."],"url":"http://arxiv.org/abs/2408.07065v1"}
{"created":"2024-08-13 17:56:51","title":"HADRON: Human-friendly Control and Artificial Intelligence for Military Drone Operations","abstract":"As drones are getting more and more entangled in our society, more untrained users require the capability to operate them. This scenario is to be achieved through the development of artificial intelligence capabilities assisting the human operator in controlling the Unmanned Aerial System (UAS) and processing the sensor data, thereby alleviating the need for extensive operator training. This paper presents the HADRON project that seeks to develop and test multiple novel technologies to enable human-friendly control of drone swarms. This project is divided into three main parts. The first part consists of the integration of different technologies for the intuitive control of drones, focusing on novice or inexperienced pilots and operators. The second part focuses on the development of a multi-drone system that will be controlled from a command and control station, in which an expert pilot can supervise the operations of the multiple drones. The third part of the project will focus on reducing the cognitive load on human operators, whether they are novice or expert pilots. For this, we will develop AI tools that will assist drone operators with semi-automated real-time data processing.","sentences":["As drones are getting more and more entangled in our society, more untrained users require the capability to operate them.","This scenario is to be achieved through the development of artificial intelligence capabilities assisting the human operator in controlling the Unmanned Aerial System (UAS) and processing the sensor data, thereby alleviating the need for extensive operator training.","This paper presents the HADRON project that seeks to develop and test multiple novel technologies to enable human-friendly control of drone swarms.","This project is divided into three main parts.","The first part consists of the integration of different technologies for the intuitive control of drones, focusing on novice or inexperienced pilots and operators.","The second part focuses on the development of a multi-drone system that will be controlled from a command and control station, in which an expert pilot can supervise the operations of the multiple drones.","The third part of the project will focus on reducing the cognitive load on human operators, whether they are novice or expert pilots.","For this, we will develop AI tools that will assist drone operators with semi-automated real-time data processing."],"url":"http://arxiv.org/abs/2408.07063v1"}
{"created":"2024-08-13 17:46:12","title":"LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs","abstract":"Current long context large language models (LLMs) can process inputs up to 100,000 tokens, yet struggle to generate outputs exceeding even a modest length of 2,000 words. Through controlled experiments, we find that the model's effective generation length is inherently bounded by the sample it has seen during supervised fine-tuning (SFT). In other words, their output limitation is due to the scarcity of long-output examples in existing SFT datasets. To address this, we introduce AgentWrite, an agent-based pipeline that decomposes ultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to generate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, we construct LongWriter-6k, a dataset containing 6,000 SFT data with output lengths ranging from 2k to 32k words. By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10,000 words while maintaining output quality. We also develop LongBench-Write, a comprehensive benchmark for evaluating ultra-long generation capabilities. Our 9B parameter model, further improved through DPO, achieves state-of-the-art performance on this benchmark, surpassing even much larger proprietary models. In general, our work demonstrates that existing long context LLM already possesses the potential for a larger output window--all you need is data with extended output during model alignment to unlock this capability. Our code & models are at: https://github.com/THUDM/LongWriter.","sentences":["Current long context large language models (LLMs) can process inputs up to 100,000 tokens, yet struggle to generate outputs exceeding even a modest length of 2,000 words.","Through controlled experiments, we find that the model's effective generation length is inherently bounded by the sample it has seen during supervised fine-tuning (SFT).","In other words, their output limitation is due to the scarcity of long-output examples in existing SFT datasets.","To address this, we introduce AgentWrite, an agent-based pipeline that decomposes ultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to generate coherent outputs exceeding 20,000 words.","Leveraging AgentWrite, we construct LongWriter-6k, a dataset containing 6,000 SFT data with output lengths ranging from 2k to 32k words.","By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10,000 words while maintaining output quality.","We also develop LongBench-Write, a comprehensive benchmark for evaluating ultra-long generation capabilities.","Our 9B parameter model, further improved through DPO, achieves state-of-the-art performance on this benchmark, surpassing even much larger proprietary models.","In general, our work demonstrates that existing long context LLM already possesses the potential for a larger output window--all you need is data with extended output during model alignment to unlock this capability.","Our code & models are at: https://github.com/THUDM/LongWriter."],"url":"http://arxiv.org/abs/2408.07055v1"}
{"created":"2024-08-13 17:37:40","title":"PSM: Learning Probabilistic Embeddings for Multi-scale Zero-Shot Soundscape Mapping","abstract":"A soundscape is defined by the acoustic environment a person perceives at a location. In this work, we propose a framework for mapping soundscapes across the Earth. Since soundscapes involve sound distributions that span varying spatial scales, we represent locations with multi-scale satellite imagery and learn a joint representation among this imagery, audio, and text. To capture the inherent uncertainty in the soundscape of a location, we design the representation space to be probabilistic. We also fuse ubiquitous metadata (including geolocation, time, and data source) to enable learning of spatially and temporally dynamic representations of soundscapes. We demonstrate the utility of our framework by creating large-scale soundscape maps integrating both audio and text with temporal control. To facilitate future research on this task, we also introduce a large-scale dataset, GeoSound, containing over $300k$ geotagged audio samples paired with both low- and high-resolution satellite imagery. We demonstrate that our method outperforms the existing state-of-the-art on both GeoSound and the existing SoundingEarth dataset. Our dataset and code is available at https://github.com/mvrl/PSM.","sentences":["A soundscape is defined by the acoustic environment a person perceives at a location.","In this work, we propose a framework for mapping soundscapes across the Earth.","Since soundscapes involve sound distributions that span varying spatial scales, we represent locations with multi-scale satellite imagery and learn a joint representation among this imagery, audio, and text.","To capture the inherent uncertainty in the soundscape of a location, we design the representation space to be probabilistic.","We also fuse ubiquitous metadata (including geolocation, time, and data source) to enable learning of spatially and temporally dynamic representations of soundscapes.","We demonstrate the utility of our framework by creating large-scale soundscape maps integrating both audio and text with temporal control.","To facilitate future research on this task, we also introduce a large-scale dataset, GeoSound, containing over $300k$ geotagged audio samples paired with both low- and high-resolution satellite imagery.","We demonstrate that our method outperforms the existing state-of-the-art on both GeoSound and the existing SoundingEarth dataset.","Our dataset and code is available at https://github.com/mvrl/PSM."],"url":"http://arxiv.org/abs/2408.07050v1"}
{"created":"2024-08-13 17:20:52","title":"TableGuard -- Securing Structured & Unstructured Data","abstract":"With the increasing demand for data sharing across platforms and organizations, ensuring the privacy and security of sensitive information has become a critical challenge. This paper introduces \"TableGuard\". An innovative approach to data obfuscation tailored for relational databases. Building on the principles and techniques developed in prior work on context-sensitive obfuscation, TableGuard applies these methods to ensure that API calls return only obfuscated data, thereby safeguarding privacy when sharing data with third parties. TableGuard leverages advanced context-sensitive obfuscation techniques to replace sensitive data elements with contextually appropriate alternatives. By maintaining the relational integrity and coherence of the data, our approach mitigates the risks of cognitive dissonance and data leakage. We demonstrate the implementation of TableGuard using a BERT based transformer model, which identifies and obfuscates sensitive entities within relational tables. Our evaluation shows that TableGuard effectively balances privacy protection with data utility, minimizing information loss while ensuring that the obfuscated data remains functionally useful for downstream applications. The results highlight the importance of domain-specific obfuscation strategies and the role of context length in preserving data integrity. The implications of this research are significant for organizations that need to share data securely with external parties. TableGuard offers a robust framework for implementing privacy-preserving data sharing mechanisms, thereby contributing to the broader field of data privacy and security.","sentences":["With the increasing demand for data sharing across platforms and organizations, ensuring the privacy and security of sensitive information has become a critical challenge.","This paper introduces \"TableGuard\".","An innovative approach to data obfuscation tailored for relational databases.","Building on the principles and techniques developed in prior work on context-sensitive obfuscation, TableGuard applies these methods to ensure that API calls return only obfuscated data, thereby safeguarding privacy when sharing data with third parties.","TableGuard leverages advanced context-sensitive obfuscation techniques to replace sensitive data elements with contextually appropriate alternatives.","By maintaining the relational integrity and coherence of the data, our approach mitigates the risks of cognitive dissonance and data leakage.","We demonstrate the implementation of TableGuard using a BERT based transformer model, which identifies and obfuscates sensitive entities within relational tables.","Our evaluation shows that TableGuard effectively balances privacy protection with data utility, minimizing information loss while ensuring that the obfuscated data remains functionally useful for downstream applications.","The results highlight the importance of domain-specific obfuscation strategies and the role of context length in preserving data integrity.","The implications of this research are significant for organizations that need to share data securely with external parties.","TableGuard offers a robust framework for implementing privacy-preserving data sharing mechanisms, thereby contributing to the broader field of data privacy and security."],"url":"http://arxiv.org/abs/2408.07045v1"}
{"created":"2024-08-13 16:36:33","title":"Improved Counting under Continual Observation with Pure Differential Privacy","abstract":"Counting under continual observation is a well-studied problem in the area of differential privacy. Given a stream of updates $x_1,x_2,\\dots,x_T \\in \\{0,1\\}$ the problem is to continuously release estimates of the prefix sums $\\sum_{i=1}^t x_i$ for $t=1,\\dots,T$ while protecting each input $x_i$ in the stream with differential privacy. Recently, significant leaps have been made in our understanding of this problem under $\\textit{approximate}$ differential privacy, aka. $(\\varepsilon,\\delta)$$\\textit{-differential privacy}$. However, for the classical case of $\\varepsilon$-differential privacy, we are not aware of any improvement in mean squared error since the work of Honaker (TPDP 2015). In this paper we present such an improvement, reducing the mean squared error by a factor of about 4, asymptotically. The key technique is a new generalization of the binary tree mechanism that uses a $k$-ary number system with $\\textit{negative digits}$ to improve the privacy-accuracy trade-off. Our mechanism improves the mean squared error over all 'optimal' $(\\varepsilon,\\delta)$-differentially private factorization mechanisms based on Gaussian noise whenever $\\delta$ is sufficiently small. Specifically, using $k=19$ we get an asymptotic improvement over the bound given in the work by Henzinger, Upadhyay and Upadhyay (SODA 2023) when $\\delta = O(T^{-0.92})$.","sentences":["Counting under continual observation is a well-studied problem in the area of differential privacy.","Given a stream of updates $x_1,x_2,\\dots,x_T","\\in \\{0,1\\}$ the problem is to continuously release estimates of the prefix sums $\\sum_{i=1}^t x_i$ for $t=1,\\dots,T$ while protecting each input $x_i$ in the stream with differential privacy.","Recently, significant leaps have been made in our understanding of this problem under $\\textit{approximate}$ differential privacy, aka.","$(\\varepsilon,\\delta)$$\\textit{-differential privacy}$.","However, for the classical case of $\\varepsilon$-differential privacy, we are not aware of any improvement in mean squared error since the work of Honaker (TPDP 2015).","In this paper we present such an improvement, reducing the mean squared error by a factor of about 4, asymptotically.","The key technique is a new generalization of the binary tree mechanism that uses a $k$-ary number system with $\\textit{negative digits}$ to improve the privacy-accuracy trade-off.","Our mechanism improves the mean squared error over all 'optimal' $(\\varepsilon,\\delta)$-differentially private factorization mechanisms based on Gaussian noise whenever $\\delta$ is sufficiently small.","Specifically, using $k=19$ we get an asymptotic improvement over the bound given in the work by Henzinger, Upadhyay and Upadhyay (SODA 2023) when $\\delta = O(T^{-0.92})$."],"url":"http://arxiv.org/abs/2408.07021v1"}
{"created":"2024-08-13 16:35:22","title":"A $5/4$ Approximation for Two-Edge-Connectivity","abstract":"The $2$-Edge Connected Spanning Subgraph problem (2ECSS) is among the most basic survivable network design problems: given an undirected unweighted graph, find a subgraph with the minimum number of edges which is 2-edge-connected (i.e., it remains connected after the removal of any single edge). This NP-hard problem is well-studied in terms of approximation algorithms. The current-best approximation factor for 2ECSS is $1.3+\\varepsilon$ for any constant $\\varepsilon >0$ [Garg, Grandoni, Jabal-Ameli'23; Kobayashi,Noguchi'23]. In this paper we present a much simpler $9/7$ approximation algorithm, and a more complex $5/4$ one. Our algorithms are also faster: their running time is $n^{O(1)}$ instead of $n^{O(1/\\varepsilon)}$.","sentences":["The $2$-Edge Connected Spanning Subgraph problem (2ECSS) is among the most basic survivable network design problems: given an undirected unweighted graph, find a subgraph with the minimum number of edges which is 2-edge-connected (i.e., it remains connected after the removal of any single edge).","This NP-hard problem is well-studied in terms of approximation algorithms.","The current-best approximation factor for 2ECSS is $1.3+\\varepsilon$ for any constant $\\varepsilon >0$","[Garg, Grandoni, Jabal-Ameli'23; Kobayashi,Noguchi'23].","In this paper we present a much simpler $9/7$ approximation algorithm, and a more complex $5/4$ one.","Our algorithms are also faster: their running time is $n^{O(1)}$ instead of $n^{O(1/\\varepsilon)}$."],"url":"http://arxiv.org/abs/2408.07019v1"}
{"created":"2024-08-13 16:30:36","title":"Defining and Measuring Disentanglement for non-Independent Factors of Variation","abstract":"Representation learning is an approach that allows to discover and extract the factors of variation from the data. Intuitively, a representation is said to be disentangled if it separates the different factors of variation in a way that is understandable to humans. Definitions of disentanglement and metrics to measure it usually assume that the factors of variation are independent of each other. However, this is generally false in the real world, which limits the use of these definitions and metrics to very specific and unrealistic scenarios. In this paper we give a definition of disentanglement based on information theory that is also valid when the factors of variation are not independent. Furthermore, we relate this definition to the Information Bottleneck Method. Finally, we propose a method to measure the degree of disentanglement from the given definition that works when the factors of variation are not independent. We show through different experiments that the method proposed in this paper correctly measures disentanglement with non-independent factors of variation, while other methods fail in this scenario.","sentences":["Representation learning is an approach that allows to discover and extract the factors of variation from the data.","Intuitively, a representation is said to be disentangled if it separates the different factors of variation in a way that is understandable to humans.","Definitions of disentanglement and metrics to measure it usually assume that the factors of variation are independent of each other.","However, this is generally false in the real world, which limits the use of these definitions and metrics to very specific and unrealistic scenarios.","In this paper we give a definition of disentanglement based on information theory that is also valid when the factors of variation are not independent.","Furthermore, we relate this definition to the Information Bottleneck Method.","Finally, we propose a method to measure the degree of disentanglement from the given definition that works when the factors of variation are not independent.","We show through different experiments that the method proposed in this paper correctly measures disentanglement with non-independent factors of variation, while other methods fail in this scenario."],"url":"http://arxiv.org/abs/2408.07016v1"}
{"created":"2024-08-13 16:08:37","title":"Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models","abstract":"Web-based Large Language Model (LLM) services have been widely adopted and have become an integral part of our Internet experience. Third-party plugins enhance the functionalities of LLM by enabling access to real-world data and services. However, the privacy consequences associated with these services and their third-party plugins are not well understood. Sensitive prompt data are stored, processed, and shared by cloud-based LLM providers and third-party plugins. In this paper, we propose Casper, a prompt sanitization technique that aims to protect user privacy by detecting and removing sensitive information from user inputs before sending them to LLM services. Casper runs entirely on the user's device as a browser extension and does not require any changes to the online LLM services. At the core of Casper is a three-layered sanitization mechanism consisting of a rule-based filter, a Machine Learning (ML)-based named entity recognizer, and a browser-based local LLM topic identifier. We evaluate Casper on a dataset of 4000 synthesized prompts and show that it can effectively filter out Personal Identifiable Information (PII) and privacy-sensitive topics with high accuracy, at 98.5% and 89.9%, respectively.","sentences":["Web-based Large Language Model (LLM) services have been widely adopted and have become an integral part of our Internet experience.","Third-party plugins enhance the functionalities of LLM by enabling access to real-world data and services.","However, the privacy consequences associated with these services and their third-party plugins are not well understood.","Sensitive prompt data are stored, processed, and shared by cloud-based LLM providers and third-party plugins.","In this paper, we propose Casper, a prompt sanitization technique that aims to protect user privacy by detecting and removing sensitive information from user inputs before sending them to LLM services.","Casper runs entirely on the user's device as a browser extension and does not require any changes to the online LLM services.","At the core of Casper is a three-layered sanitization mechanism consisting of a rule-based filter, a Machine Learning (ML)-based named entity recognizer, and a browser-based local LLM topic identifier.","We evaluate Casper on a dataset of 4000 synthesized prompts and show that it can effectively filter out Personal Identifiable Information (PII) and privacy-sensitive topics with high accuracy, at 98.5% and 89.9%, respectively."],"url":"http://arxiv.org/abs/2408.07004v1"}
{"created":"2024-08-13 16:00:30","title":"Faster Private Minimum Spanning Trees","abstract":"Motivated by applications in clustering and synthetic data generation, we consider the problem of releasing a minimum spanning tree (MST) under edge-weight differential privacy constraints where a graph topology $G=(V,E)$ with $n$ vertices and $m$ edges is public, the weight matrix $\\vec{W}\\in \\mathbb{R}^{n \\times n}$ is private, and we wish to release an approximate MST under $\\rho$-zero-concentrated differential privacy. Weight matrices are considered neighboring if they differ by at most $\\Delta_\\infty$ in each entry, i.e., we consider an $\\ell_\\infty$ neighboring relationship. Existing private MST algorithms either add noise to each entry in $\\vec{W}$ and estimate the MST by post-processing or add noise to weights in-place during the execution of a specific MST algorithm. Using the post-processing approach with an efficient MST algorithm takes $O(n^2)$ time on dense graphs but results in an additive error on the weight of the MST of magnitude $O(n^2\\log n)$. In-place algorithms give asymptotically better utility, but the running time of existing in-place algorithms is $O(n^3)$ for dense graphs. Our main result is a new differentially private MST algorithm that matches the utility of existing in-place methods while running in time $O(m + n^{3/2}\\log n)$ for fixed privacy parameter $\\rho$. The technical core of our algorithm is an efficient sublinear time simulation of Report-Noisy-Max that works by discretizing all edge weights to a multiple of $\\Delta_\\infty$ and forming groups of edges with identical weights. Specifically, we present a data structure that allows us to sample a noisy minimum weight edge among at most $O(n^2)$ cut edges in $O(\\sqrt{n} \\log n)$ time. Experimental evaluations support our claims that our algorithm significantly improves previous algorithms either in utility or running time.","sentences":["Motivated by applications in clustering and synthetic data generation, we consider the problem of releasing a minimum spanning tree (MST) under edge-weight differential privacy constraints where a graph topology $G=(V,E)$ with $n$ vertices and $m$ edges is public, the weight matrix $\\vec{W}\\in \\mathbb{R}^{n \\times n}$ is private, and we wish to release an approximate MST under $\\rho$-zero-concentrated differential privacy.","Weight matrices are considered neighboring if they differ by at most $\\Delta_\\infty$ in each entry, i.e., we consider an $\\ell_\\infty$ neighboring relationship.","Existing private MST algorithms either add noise to each entry in $\\vec{W}$ and estimate the MST by post-processing or add noise to weights in-place during the execution of a specific MST algorithm.","Using the post-processing approach with an efficient MST algorithm takes $O(n^2)$ time on dense graphs but results in an additive error on the weight of the MST of magnitude $O(n^2\\log n)$.","In-place algorithms give asymptotically better utility, but the running time of existing in-place algorithms is $O(n^3)$ for dense graphs.","Our main result is a new differentially private MST algorithm that matches the utility of existing in-place methods while running in time $O(m + n^{3/2}\\log n)$ for fixed privacy parameter $\\rho$. The technical core of our algorithm is an efficient sublinear time simulation of Report-Noisy-Max that works by discretizing all edge weights to a multiple of $\\Delta_\\infty$ and forming groups of edges with identical weights.","Specifically, we present a data structure that allows us to sample a noisy minimum weight edge among at most $O(n^2)$ cut edges in $O(\\sqrt{n} \\log n)$ time.","Experimental evaluations support our claims that our algorithm significantly improves previous algorithms either in utility or running time."],"url":"http://arxiv.org/abs/2408.06997v1"}
{"created":"2024-08-13 15:56:42","title":"Blessing of Dimensionality for Approximating Sobolev Classes on Manifolds","abstract":"The manifold hypothesis says that natural high-dimensional data is actually supported on or around a low-dimensional manifold. Recent success of statistical and learning-based methods empirically supports this hypothesis, due to outperforming classical statistical intuition in very high dimensions. A natural step for analysis is thus to assume the manifold hypothesis and derive bounds that are independent of any embedding space. Theoretical implications in this direction have recently been explored in terms of generalization of ReLU networks and convergence of Langevin methods. We complement existing results by providing theoretical statistical complexity results, which directly relates to generalization properties. In particular, we demonstrate that the statistical complexity required to approximate a class of bounded Sobolev functions on a compact manifold is bounded from below, and moreover that this bound is dependent only on the intrinsic properties of the manifold. These provide complementary bounds for existing approximation results for ReLU networks on manifolds, which give upper bounds on generalization capacity.","sentences":["The manifold hypothesis says that natural high-dimensional data is actually supported on or around a low-dimensional manifold.","Recent success of statistical and learning-based methods empirically supports this hypothesis, due to outperforming classical statistical intuition in very high dimensions.","A natural step for analysis is thus to assume the manifold hypothesis and derive bounds that are independent of any embedding space.","Theoretical implications in this direction have recently been explored in terms of generalization of ReLU networks and convergence of Langevin methods.","We complement existing results by providing theoretical statistical complexity results, which directly relates to generalization properties.","In particular, we demonstrate that the statistical complexity required to approximate a class of bounded Sobolev functions on a compact manifold is bounded from below, and moreover that this bound is dependent only on the intrinsic properties of the manifold.","These provide complementary bounds for existing approximation results for ReLU networks on manifolds, which give upper bounds on generalization capacity."],"url":"http://arxiv.org/abs/2408.06996v1"}
{"created":"2024-08-13 15:47:10","title":"Catamorphic Abstractions for Constrained Horn Clause Satisfiability","abstract":"Catamorphisms are functions that are recursively defined on list and trees and, in general, on Algebraic Data Types (ADTs), and are often used to compute suitable abstractions of programs that manipulate ADTs. Examples of catamorphisms include functions that compute size of lists, orderedness of lists, and height of trees. It is well known that program properties specified through catamorphisms can be proved by showing the satisfiability of suitable sets of Constrained Horn Clauses (CHCs). We address the problem of checking the satisfiability of those sets of CHCs, and we propose a method for transforming sets of CHCs into equisatisfiable sets where catamorphisms are no longer present. As a consequence, clauses with catamorphisms can be handled without extending the satisfiability algorithms used by existing CHC solvers. Through an experimental evaluation on a non-trivial benchmark consisting of many list and tree processing algorithms expressed as sets of CHCs, we show that our technique is indeed effective and significantly enhances the performance of state-of-the-art CHC solvers.","sentences":["Catamorphisms are functions that are recursively defined on list and trees and, in general, on Algebraic Data Types (ADTs), and are often used to compute suitable abstractions of programs that manipulate ADTs.","Examples of catamorphisms include functions that compute size of lists, orderedness of lists, and height of trees.","It is well known that program properties specified through catamorphisms can be proved by showing the satisfiability of suitable sets of Constrained Horn Clauses (CHCs).","We address the problem of checking the satisfiability of those sets of CHCs, and we propose a method for transforming sets of CHCs into equisatisfiable sets where catamorphisms are no longer present.","As a consequence, clauses with catamorphisms can be handled without extending the satisfiability algorithms used by existing CHC solvers.","Through an experimental evaluation on a non-trivial benchmark consisting of many list and tree processing algorithms expressed as sets of CHCs, we show that our technique is indeed effective and significantly enhances the performance of state-of-the-art CHC solvers."],"url":"http://arxiv.org/abs/2408.06988v1"}
{"created":"2024-08-13 15:27:43","title":"Prompt-Based Segmentation at Multiple Resolutions and Lighting Conditions using Segment Anything Model 2","abstract":"This paper provides insight into the effectiveness of zero-shot, prompt-based, Segment Anything Model (SAM), and its updated version, SAM 2, and the non-promptable, conventional convolutional network (CNN), in segmenting solar panels, in RGB aerial imagery, across lighting conditions, spatial resolutions, and prompt strategies. SAM 2 demonstrates improvements over SAM, particularly in sub-optimal lighting conditions when prompted by points. Both SAMs, prompted by user-box, outperformed CNN, in all scenarios. Additionally, YOLOv9 prompting outperformed user points prompting. In high-resolution imagery, both in optimal and sub-optimal lighting conditions, Eff-UNet outperformed both SAM models prompted by YOLOv9 boxes, positioning Eff-UNet as the appropriate model for automatic segmentation in high-resolution data. In low-resolution data, user box prompts were found crucial to achieve a reasonable performance. This paper provides details on strengths and limitations of each model and outlines robustness of user prompted image segmentation models in inconsistent resolution and lighting conditions of remotely sensed data.","sentences":["This paper provides insight into the effectiveness of zero-shot, prompt-based, Segment Anything Model (SAM), and its updated version, SAM 2, and the non-promptable, conventional convolutional network (CNN), in segmenting solar panels, in RGB aerial imagery, across lighting conditions, spatial resolutions, and prompt strategies.","SAM 2 demonstrates improvements over SAM, particularly in sub-optimal lighting conditions when prompted by points.","Both SAMs, prompted by user-box, outperformed CNN, in all scenarios.","Additionally, YOLOv9 prompting outperformed user points prompting.","In high-resolution imagery, both in optimal and sub-optimal lighting conditions, Eff-UNet outperformed both SAM models prompted by YOLOv9 boxes, positioning Eff-UNet as the appropriate model for automatic segmentation in high-resolution data.","In low-resolution data, user box prompts were found crucial to achieve a reasonable performance.","This paper provides details on strengths and limitations of each model and outlines robustness of user prompted image segmentation models in inconsistent resolution and lighting conditions of remotely sensed data."],"url":"http://arxiv.org/abs/2408.06970v1"}
{"created":"2024-08-13 15:21:46","title":"DyG-Mamba: Continuous State Space Modeling on Dynamic Graphs","abstract":"Dynamic graph learning aims to uncover evolutionary laws in real-world systems, enabling accurate social recommendation (link prediction) or early detection of cancer cells (classification). Inspired by the success of state space models, e.g., Mamba, for efficiently capturing long-term dependencies in language modeling, we propose DyG-Mamba, a new continuous state space model (SSM) for dynamic graph learning. Specifically, we first found that using inputs as control signals for SSM is not suitable for continuous-time dynamic network data with irregular sampling intervals, resulting in models being insensitive to time information and lacking generalization properties. Drawing inspiration from the Ebbinghaus forgetting curve, which suggests that memory of past events is strongly correlated with time intervals rather than specific details of the events themselves, we directly utilize irregular time spans as control signals for SSM to achieve significant robustness and generalization. Through exhaustive experiments on 12 datasets for dynamic link prediction and dynamic node classification tasks, we found that DyG-Mamba achieves state-of-the-art performance on most of the datasets, while also demonstrating significantly improved computation and memory efficiency.","sentences":["Dynamic graph learning aims to uncover evolutionary laws in real-world systems, enabling accurate social recommendation (link prediction) or early detection of cancer cells (classification).","Inspired by the success of state space models, e.g., Mamba, for efficiently capturing long-term dependencies in language modeling, we propose DyG-Mamba, a new continuous state space model (SSM) for dynamic graph learning.","Specifically, we first found that using inputs as control signals for SSM is not suitable for continuous-time dynamic network data with irregular sampling intervals, resulting in models being insensitive to time information and lacking generalization properties.","Drawing inspiration from the Ebbinghaus forgetting curve, which suggests that memory of past events is strongly correlated with time intervals rather than specific details of the events themselves, we directly utilize irregular time spans as control signals for SSM to achieve significant robustness and generalization.","Through exhaustive experiments on 12 datasets for dynamic link prediction and dynamic node classification tasks, we found that DyG-Mamba achieves state-of-the-art performance on most of the datasets, while also demonstrating significantly improved computation and memory efficiency."],"url":"http://arxiv.org/abs/2408.06966v1"}
{"created":"2024-08-13 15:17:03","title":"Measuring User Understanding in Dialogue-based XAI Systems","abstract":"The field of eXplainable Artificial Intelligence (XAI) is increasingly recognizing the need to personalize and/or interactively adapt the explanation to better reflect users' explanation needs. While dialogue-based approaches to XAI have been proposed recently, the state-of-the-art in XAI is still characterized by what we call one-shot, non-personalized and one-way explanations. In contrast, dialogue-based systems that can adapt explanations through interaction with a user promise to be superior to GUI-based or dashboard explanations as they offer a more intuitive way of requesting information. In general, while interactive XAI systems are often evaluated in terms of user satisfaction, there are limited studies that access user's objective model understanding. This is in particular the case for dialogue-based XAI approaches. In this paper, we close this gap by carrying out controlled experiments within a dialogue framework in which we measure understanding of users in three phases by asking them to simulate the predictions of the model they are learning about. By this, we can quantify the level of (improved) understanding w.r.t. how the model works, comparing the state prior, and after the interaction. We further analyze the data to reveal patterns of how the interaction between groups with high vs. low understanding gain differ. Overall, our work thus contributes to our understanding about the effectiveness of XAI approaches.","sentences":["The field of eXplainable Artificial Intelligence (XAI) is increasingly recognizing the need to personalize and/or interactively adapt the explanation to better reflect users' explanation needs.","While dialogue-based approaches to XAI have been proposed recently, the state-of-the-art in XAI is still characterized by what we call one-shot, non-personalized and one-way explanations.","In contrast, dialogue-based systems that can adapt explanations through interaction with a user promise to be superior to GUI-based or dashboard explanations as they offer a more intuitive way of requesting information.","In general, while interactive XAI systems are often evaluated in terms of user satisfaction, there are limited studies that access user's objective model understanding.","This is in particular the case for dialogue-based XAI approaches.","In this paper, we close this gap by carrying out controlled experiments within a dialogue framework in which we measure understanding of users in three phases by asking them to simulate the predictions of the model they are learning about.","By this, we can quantify the level of (improved) understanding w.r.t.","how the model works, comparing the state prior, and after the interaction.","We further analyze the data to reveal patterns of how the interaction between groups with high vs. low understanding gain differ.","Overall, our work thus contributes to our understanding about the effectiveness of XAI approaches."],"url":"http://arxiv.org/abs/2408.06960v2"}
{"created":"2024-08-13 15:15:37","title":"AuToMATo: A Parameter-Free Persistence-Based Clustering Algorithm","abstract":"We present AuToMATo, a novel parameter-free clustering algorithm based on persistent homology. AuToMATo combines the existing ToMATo clustering algorithm with a bootstrapping procedure in order to separate significant peaks of an estimated density function from non-significant ones. We perform a thorough comparison of AuToMATo against many other state-of-the-art clustering algorithms. We find that not only that AuToMATo compares favorably against other parameter-free clustering algorithms, but in many instances also significantly outperforms even the best selection of parameters for other algorithms. AuToMATo is motivated by applications in topological data analysis, in particular the Mapper algorithm, where it is desirable to work with a parameter-free clustering algorithm. Indeed, we provide evidence that AuToMATo performs well when used with Mapper. Finally, we provide an open-source implementation of AuToMATo in Python that is fully compatible with the standardscikit-learn architecture.","sentences":["We present AuToMATo, a novel parameter-free clustering algorithm based on persistent homology.","AuToMATo combines the existing ToMATo clustering algorithm with a bootstrapping procedure in order to separate significant peaks of an estimated density function from non-significant ones.","We perform a thorough comparison of AuToMATo against many other state-of-the-art clustering algorithms.","We find that not only that AuToMATo compares favorably against other parameter-free clustering algorithms, but in many instances also significantly outperforms even the best selection of parameters for other algorithms.","AuToMATo is motivated by applications in topological data analysis, in particular the Mapper algorithm, where it is desirable to work with a parameter-free clustering algorithm.","Indeed, we provide evidence that AuToMATo performs well when used with Mapper.","Finally, we provide an open-source implementation of AuToMATo in Python that is fully compatible with the standardscikit-learn architecture."],"url":"http://arxiv.org/abs/2408.06958v1"}
{"created":"2024-08-13 15:15:10","title":"Rural Handover Parameter Tuning to Achieve End to End Latency Requirements of Future Railway Mobile Communication Systems","abstract":"GSM-R (GSM for Railways) is a 2G-based standardized ground-to-train communications system that enabled interoperability across different countries. However, as a 2G-based system, it is nearing its lifetime and therefore, it will be replaced with 5G-based Future Railway Mobile Communications System (FRMCS). FRMCS is expected to bring in new use cases that demand low latency and high reliability. However, from a mobility perspective, it is not clear how the low latency and high reliability will be achieved. This paper investigates the effect of handover procedure on latency and reliability and analyzes which use cases of FRMCS can be satisfied using baseline handover. We also sweep through different handover parameter configurations and analyze their effect on mobility performance. Then, we analyze the effect of mobility performance on packet latency and reliability. Our results show that, with baseline handover, Standard Data Communications Scenario is met and optimizing for baseline handover performance can reduce latency by up to 18.5%, indicating that optimizing for mobility performance is crucial in FRMCS.","sentences":["GSM-R (GSM for Railways) is a 2G-based standardized ground-to-train communications system that enabled interoperability across different countries.","However, as a 2G-based system, it is nearing its lifetime and therefore, it will be replaced with 5G-based Future Railway Mobile Communications System (FRMCS).","FRMCS is expected to bring in new use cases that demand low latency and high reliability.","However, from a mobility perspective, it is not clear how the low latency and high reliability will be achieved.","This paper investigates the effect of handover procedure on latency and reliability and analyzes which use cases of FRMCS can be satisfied using baseline handover.","We also sweep through different handover parameter configurations and analyze their effect on mobility performance.","Then, we analyze the effect of mobility performance on packet latency and reliability.","Our results show that, with baseline handover, Standard Data Communications Scenario is met and optimizing for baseline handover performance can reduce latency by up to 18.5%, indicating that optimizing for mobility performance is crucial in FRMCS."],"url":"http://arxiv.org/abs/2408.06957v1"}
{"created":"2024-08-13 15:13:21","title":"Neural Speech and Audio Coding","abstract":"This paper explores the integration of model-based and data-driven approaches within the realm of neural speech and audio coding systems. It highlights the challenges posed by the subjective evaluation processes of speech and audio codecs and discusses the limitations of purely data-driven approaches, which often require inefficiently large architectures to match the performance of model-based methods. The study presents hybrid systems as a viable solution, offering significant improvements to the performance of conventional codecs through meticulously chosen design enhancements. Specifically, it introduces a neural network-based signal enhancer designed to post-process existing codecs' output, along with the autoencoder-based end-to-end models and LPCNet--hybrid systems that combine linear predictive coding (LPC) with neural networks. Furthermore, the paper delves into predictive models operating within custom feature spaces (TF-Codec) or predefined transform domains (MDCTNet) and examines the use of psychoacoustically calibrated loss functions to train end-to-end neural audio codecs. Through these investigations, the paper demonstrates the potential of hybrid systems to advance the field of speech and audio coding by bridging the gap between traditional model-based approaches and modern data-driven techniques.","sentences":["This paper explores the integration of model-based and data-driven approaches within the realm of neural speech and audio coding systems.","It highlights the challenges posed by the subjective evaluation processes of speech and audio codecs and discusses the limitations of purely data-driven approaches, which often require inefficiently large architectures to match the performance of model-based methods.","The study presents hybrid systems as a viable solution, offering significant improvements to the performance of conventional codecs through meticulously chosen design enhancements.","Specifically, it introduces a neural network-based signal enhancer designed to post-process existing codecs' output, along with the autoencoder-based end-to-end models and LPCNet--hybrid systems that combine linear predictive coding (LPC) with neural networks.","Furthermore, the paper delves into predictive models operating within custom feature spaces (TF-Codec) or predefined transform domains (MDCTNet) and examines the use of psychoacoustically calibrated loss functions to train end-to-end neural audio codecs.","Through these investigations, the paper demonstrates the potential of hybrid systems to advance the field of speech and audio coding by bridging the gap between traditional model-based approaches and modern data-driven techniques."],"url":"http://arxiv.org/abs/2408.06954v1"}
{"created":"2024-08-13 15:01:33","title":"Towards Holistic Disease Risk Prediction using Small Language Models","abstract":"Data in the healthcare domain arise from a variety of sources and modalities, such as x-ray images, continuous measurements, and clinical notes. Medical practitioners integrate these diverse data types daily to make informed and accurate decisions. With recent advancements in language models capable of handling multimodal data, it is a logical progression to apply these models to the healthcare sector. In this work, we introduce a framework that connects small language models to multiple data sources, aiming to predict the risk of various diseases simultaneously. Our experiments encompass 12 different tasks within a multitask learning setup. Although our approach does not surpass state-of-the-art methods specialized for single tasks, it demonstrates competitive performance and underscores the potential of small language models for multimodal reasoning in healthcare.","sentences":["Data in the healthcare domain arise from a variety of sources and modalities, such as x-ray images, continuous measurements, and clinical notes.","Medical practitioners integrate these diverse data types daily to make informed and accurate decisions.","With recent advancements in language models capable of handling multimodal data, it is a logical progression to apply these models to the healthcare sector.","In this work, we introduce a framework that connects small language models to multiple data sources, aiming to predict the risk of various diseases simultaneously.","Our experiments encompass 12 different tasks within a multitask learning setup.","Although our approach does not surpass state-of-the-art methods specialized for single tasks, it demonstrates competitive performance and underscores the potential of small language models for multimodal reasoning in healthcare."],"url":"http://arxiv.org/abs/2408.06943v1"}
{"created":"2024-08-13 15:01:03","title":"Speech-based Mark for Data Sonification","abstract":"Sonification serves as a powerful tool for data accessibility, especially for people with vision loss. Among various modalities, speech is a familiar means of communication similar to the role of text in visualization. However, speech-based sonification is underexplored. We introduce SpeechTone, a novel speech-based mark for data sonification and extension to the existing Erie declarative grammar for sonification. It encodes data into speech attributes such as pitch, speed, voice and speech content. We demonstrate the efficacy of SpeechTone through three examples.","sentences":["Sonification serves as a powerful tool for data accessibility, especially for people with vision loss.","Among various modalities, speech is a familiar means of communication similar to the role of text in visualization.","However, speech-based sonification is underexplored.","We introduce SpeechTone, a novel speech-based mark for data sonification and extension to the existing Erie declarative grammar for sonification.","It encodes data into speech attributes such as pitch, speed, voice and speech content.","We demonstrate the efficacy of SpeechTone through three examples."],"url":"http://arxiv.org/abs/2408.06942v1"}
{"created":"2024-08-13 14:34:59","title":"The advantages of context specific language models: the case of the Erasmian Language Model","abstract":"The current trend to improve language model performance seems to be based on scaling up with the number of parameters (e.g. the state of the art GPT4 model has approximately 1.7 trillion parameters) or the amount of training data fed into the model. However this comes at significant costs in terms of computational resources and energy costs that compromise the sustainability of AI solutions, as well as risk relating to privacy and misuse. In this paper we present the Erasmian Language Model (ELM) a small context specific, 900 million parameter model, pre-trained and fine-tuned by and for Erasmus University Rotterdam. We show how the model performs adequately in a classroom context for essay writing, and how it achieves superior performance in subjects that are part of its context. This has implications for a wide range of institutions and organizations, showing that context specific language models may be a viable alternative for resource constrained, privacy sensitive use cases.","sentences":["The current trend to improve language model performance seems to be based on scaling up with the number of parameters (e.g. the state of the art GPT4 model has approximately 1.7 trillion parameters) or the amount of training data fed into the model.","However this comes at significant costs in terms of computational resources and energy costs that compromise the sustainability of AI solutions, as well as risk relating to privacy and misuse.","In this paper we present the Erasmian Language Model (ELM) a small context specific, 900 million parameter model, pre-trained and fine-tuned by and for Erasmus University Rotterdam.","We show how the model performs adequately in a classroom context for essay writing, and how it achieves superior performance in subjects that are part of its context.","This has implications for a wide range of institutions and organizations, showing that context specific language models may be a viable alternative for resource constrained, privacy sensitive use cases."],"url":"http://arxiv.org/abs/2408.06931v1"}
{"created":"2024-08-13 14:33:32","title":"Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification","abstract":"Clinical machine learning research and AI driven clinical decision support models rely on clinically accurate labels. Manually extracting these labels with the help of clinical specialists is often time-consuming and expensive. This study tests the feasibility of automatic span- and document-level diagnosis extraction from unstructured Dutch echocardiogram reports.   We included 115,692 unstructured echocardiogram reports from the UMCU a large university hospital in the Netherlands. A randomly selected subset was manually annotated for the occurrence and severity of eleven commonly described cardiac characteristics. We developed and tested several automatic labelling techniques at both span and document levels, using weighted and macro F1-score, precision, and recall for performance evaluation. We compared the performance of span labelling against document labelling methods, which included both direct document classifiers and indirect document classifiers that rely on span classification results.   The SpanCategorizer and MedRoBERTa.nl models outperformed all other span and document classifiers, respectively. The weighted F1-score varied between characteristics, ranging from 0.60 to 0.93 in SpanCategorizer and 0.96 to 0.98 in MedRoBERTa.nl. Direct document classification was superior to indirect document classification using span classifiers. SetFit achieved competitive document classification performance using only 10\\% of the training data. Utilizing a reduced label set yielded near-perfect document classification results.   We recommend using our published SpanCategorizer and MedRoBERTa.nl models for span- and document-level diagnosis extraction from Dutch echocardiography reports. For settings with limited training data, SetFit may be a promising alternative for document classification.","sentences":["Clinical machine learning research and AI driven clinical decision support models rely on clinically accurate labels.","Manually extracting these labels with the help of clinical specialists is often time-consuming and expensive.","This study tests the feasibility of automatic span- and document-level diagnosis extraction from unstructured Dutch echocardiogram reports.   ","We included 115,692 unstructured echocardiogram reports from the UMCU a large university hospital in the Netherlands.","A randomly selected subset was manually annotated for the occurrence and severity of eleven commonly described cardiac characteristics.","We developed and tested several automatic labelling techniques at both span and document levels, using weighted and macro F1-score, precision, and recall for performance evaluation.","We compared the performance of span labelling against document labelling methods, which included both direct document classifiers and indirect document classifiers that rely on span classification results.   ","The SpanCategorizer and MedRoBERTa.nl models outperformed all other span and document classifiers, respectively.","The weighted F1-score varied between characteristics, ranging from 0.60 to 0.93 in SpanCategorizer and 0.96 to 0.98 in MedRoBERTa.nl.","Direct document classification was superior to indirect document classification using span classifiers.","SetFit achieved competitive document classification performance using only 10\\% of the training data.","Utilizing a reduced label set yielded near-perfect document classification results.   ","We recommend using our published SpanCategorizer and MedRoBERTa.nl models for span- and document-level diagnosis extraction from Dutch echocardiography reports.","For settings with limited training data, SetFit may be a promising alternative for document classification."],"url":"http://arxiv.org/abs/2408.06930v1"}
