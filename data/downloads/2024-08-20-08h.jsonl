{"created":"2024-08-19 17:59:04","title":"KAN 2.0: Kolmogorov-Arnold Networks Meet Science","abstract":"A major challenge of AI + Science lies in their inherent incompatibility: today's AI is primarily based on connectionism, while science depends on symbolism. To bridge the two worlds, we propose a framework to seamlessly synergize Kolmogorov-Arnold Networks (KANs) and science. The framework highlights KANs' usage for three aspects of scientific discovery: identifying relevant features, revealing modular structures, and discovering symbolic formulas. The synergy is bidirectional: science to KAN (incorporating scientific knowledge into KANs), and KAN to science (extracting scientific insights from KANs). We highlight major new functionalities in the pykan package: (1) MultKAN: KANs with multiplication nodes. (2) kanpiler: a KAN compiler that compiles symbolic formulas into KANs. (3) tree converter: convert KANs (or any neural networks) to tree graphs. Based on these tools, we demonstrate KANs' capability to discover various types of physical laws, including conserved quantities, Lagrangians, symmetries, and constitutive laws.","sentences":["A major challenge of AI + Science lies in their inherent incompatibility: today's AI is primarily based on connectionism, while science depends on symbolism.","To bridge the two worlds, we propose a framework to seamlessly synergize Kolmogorov-Arnold Networks (KANs) and science.","The framework highlights KANs' usage for three aspects of scientific discovery: identifying relevant features, revealing modular structures, and discovering symbolic formulas.","The synergy is bidirectional: science to KAN (incorporating scientific knowledge into KANs), and KAN to science (extracting scientific insights from KANs).","We highlight major new functionalities in the pykan package: (1) MultKAN: KANs with multiplication nodes.","(2) kanpiler: a KAN compiler that compiles symbolic formulas into KANs.","(3) tree converter: convert KANs (or any neural networks) to tree graphs.","Based on these tools, we demonstrate KANs' capability to discover various types of physical laws, including conserved quantities, Lagrangians, symmetries, and constitutive laws."],"url":"http://arxiv.org/abs/2408.10205v1"}
{"created":"2024-08-19 17:58:03","title":"Criticality Leveraged Adversarial Training (CLAT) for Boosted Performance via Parameter Efficiency","abstract":"Adversarial training enhances neural network robustness but suffers from a tendency to overfit and increased generalization errors on clean data. This work introduces CLAT, an innovative approach that mitigates adversarial overfitting by introducing parameter efficiency into the adversarial training process, improving both clean accuracy and adversarial robustness. Instead of tuning the entire model, CLAT identifies and fine-tunes robustness-critical layers - those predominantly learning non-robust features - while freezing the remaining model to enhance robustness. It employs dynamic critical layer selection to adapt to changes in layer criticality throughout the fine-tuning process. Empirically, CLAT can be applied on top of existing adversarial training methods, significantly reduces the number of trainable parameters by approximately 95%, and achieves more than a 2% improvement in adversarial robustness compared to baseline methods.","sentences":["Adversarial training enhances neural network robustness but suffers from a tendency to overfit and increased generalization errors on clean data.","This work introduces CLAT, an innovative approach that mitigates adversarial overfitting by introducing parameter efficiency into the adversarial training process, improving both clean accuracy and adversarial robustness.","Instead of tuning the entire model, CLAT identifies and fine-tunes robustness-critical layers - those predominantly learning non-robust features - while freezing the remaining model to enhance robustness.","It employs dynamic critical layer selection to adapt to changes in layer criticality throughout the fine-tuning process.","Empirically, CLAT can be applied on top of existing adversarial training methods, significantly reduces the number of trainable parameters by approximately 95%, and achieves more than a 2% improvement in adversarial robustness compared to baseline methods."],"url":"http://arxiv.org/abs/2408.10204v1"}
{"created":"2024-08-19 17:54:29","title":"Demystifying the Communication Characteristics for Distributed Transformer Models","abstract":"Deep learning (DL) models based on the transformer architecture have revolutionized many DL applications such as large language models (LLMs), vision transformers, audio generation, and time series prediction. Much of this progress has been fueled by distributed training, yet distributed communication remains a substantial bottleneck to training progress. This paper examines the communication behavior of transformer models - that is, how different parallelism schemes used in multi-node/multi-GPU DL Training communicate data in the context of transformers. We use GPT-based language models as a case study of the transformer architecture due to their ubiquity. We validate the empirical results obtained from our communication logs using analytical models. At a high level, our analysis reveals a need to optimize small message point-to-point communication further, correlations between sequence length, per-GPU throughput, model size, and optimizations used, and where to potentially guide further optimizations in framework and HPC middleware design and optimization.","sentences":["Deep learning (DL) models based on the transformer architecture have revolutionized many DL applications such as large language models (LLMs), vision transformers, audio generation, and time series prediction.","Much of this progress has been fueled by distributed training, yet distributed communication remains a substantial bottleneck to training progress.","This paper examines the communication behavior of transformer models - that is, how different parallelism schemes used in multi-node/multi-GPU DL Training communicate data in the context of transformers.","We use GPT-based language models as a case study of the transformer architecture due to their ubiquity.","We validate the empirical results obtained from our communication logs using analytical models.","At a high level, our analysis reveals a need to optimize small message point-to-point communication further, correlations between sequence length, per-GPU throughput, model size, and optimizations used, and where to potentially guide further optimizations in framework and HPC middleware design and optimization."],"url":"http://arxiv.org/abs/2408.10197v1"}
{"created":"2024-08-19 17:51:00","title":"A Graph-based Approach to Human Activity Recognition","abstract":"Advanced wearable sensor devices have enabled the recording of vast amounts of movement data from individuals regarding their physical activities. This data offers valuable insights that enhance our understanding of how physical activities contribute to improved physical health and overall quality of life. Consequently, there is a growing need for efficient methods to extract significant insights from these rapidly expanding real-time datasets. This paper presents a methodology to efficiently extract substantial insights from these expanding datasets, focusing on professional sports but applicable to various human activities. By utilizing data from Inertial Measurement Units (IMU) and Global Navigation Satellite Systems (GNSS) receivers, athletic performance can be analyzed using directed graphs to encode knowledge of complex movements. Our approach is demonstrated on biathlon data and detects specific points of interest and complex movement sequences, facilitating the comparison and analysis of human physical performance.","sentences":["Advanced wearable sensor devices have enabled the recording of vast amounts of movement data from individuals regarding their physical activities.","This data offers valuable insights that enhance our understanding of how physical activities contribute to improved physical health and overall quality of life.","Consequently, there is a growing need for efficient methods to extract significant insights from these rapidly expanding real-time datasets.","This paper presents a methodology to efficiently extract substantial insights from these expanding datasets, focusing on professional sports but applicable to various human activities.","By utilizing data from Inertial Measurement Units (IMU) and Global Navigation Satellite Systems (GNSS) receivers, athletic performance can be analyzed using directed graphs to encode knowledge of complex movements.","Our approach is demonstrated on biathlon data and detects specific points of interest and complex movement sequences, facilitating the comparison and analysis of human physical performance."],"url":"http://arxiv.org/abs/2408.10191v1"}
{"created":"2024-08-19 17:48:11","title":"Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models","abstract":"Transformer architectures have become a dominant paradigm for domains like language modeling but suffer in many inference settings due to their quadratic-time self-attention. Recently proposed subquadratic architectures, such as Mamba, have shown promise, but have been pretrained with substantially less computational resources than the strongest Transformer models. In this work, we present a method that is able to distill a pretrained Transformer architecture into alternative architectures such as state space models (SSMs). The key idea to our approach is that we can view both Transformers and SSMs as applying different forms of mixing matrices over the token sequences. We can thus progressively distill the Transformer architecture by matching different degrees of granularity in the SSM: first matching the mixing matrices themselves, then the hidden units at each block, and finally the end-to-end predictions. Our method, called MOHAWK, is able to distill a Mamba-2 variant based on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid version (Hybrid Phi-Mamba) using 5B tokens. Despite using less than 1% of the training data typically used to train models from scratch, Phi-Mamba boasts substantially stronger performance compared to all past open-source non-Transformer models. MOHAWK allows models like SSMs to leverage computational resources invested in training Transformer-based architectures, highlighting a new avenue for building such models.","sentences":["Transformer architectures have become a dominant paradigm for domains like language modeling but suffer in many inference settings due to their quadratic-time self-attention.","Recently proposed subquadratic architectures, such as Mamba, have shown promise, but have been pretrained with substantially less computational resources than the strongest Transformer models.","In this work, we present a method that is able to distill a pretrained Transformer architecture into alternative architectures such as state space models (SSMs).","The key idea to our approach is that we can view both Transformers and SSMs as applying different forms of mixing matrices over the token sequences.","We can thus progressively distill the Transformer architecture by matching different degrees of granularity in the SSM: first matching the mixing matrices themselves, then the hidden units at each block, and finally the end-to-end predictions.","Our method, called MOHAWK, is able to distill a Mamba-2 variant based on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid version (Hybrid Phi-Mamba) using 5B tokens.","Despite using less than 1% of the training data typically used to train models from scratch, Phi-Mamba boasts substantially stronger performance compared to all past open-source non-Transformer models.","MOHAWK allows models like SSMs to leverage computational resources invested in training Transformer-based architectures, highlighting a new avenue for building such models."],"url":"http://arxiv.org/abs/2408.10189v1"}
{"created":"2024-08-19 17:47:22","title":"Assessment of Spectral based Solutions for the Detection of Floating Marine Debris","abstract":"Typically, the detection of marine debris relies on in-situ campaigns that are characterized by huge human effort and limited spatial coverage. Following the need of a rapid solution for the detection of floating plastic, methods based on remote sensing data have been proposed recently. Their main limitation is represented by the lack of a general reference for evaluating performance. Recently, the Marine Debris Archive (MARIDA) has been released as a standard dataset to develop and evaluate Machine Learning (ML) algorithms for detection of Marine Plastic Debris. The MARIDA dataset has been created for simplifying the comparison between detection solutions with the aim of stimulating the research in the field of marine environment preservation. In this work, an assessment of spectral based solutions is proposed by evaluating performance on MARIDA dataset. The outcome highlights the need of precise reference for fair evaluation.","sentences":["Typically, the detection of marine debris relies on in-situ campaigns that are characterized by huge human effort and limited spatial coverage.","Following the need of a rapid solution for the detection of floating plastic, methods based on remote sensing data have been proposed recently.","Their main limitation is represented by the lack of a general reference for evaluating performance.","Recently, the Marine Debris Archive (MARIDA) has been released as a standard dataset to develop and evaluate Machine Learning (ML) algorithms for detection of Marine Plastic Debris.","The MARIDA dataset has been created for simplifying the comparison between detection solutions with the aim of stimulating the research in the field of marine environment preservation.","In this work, an assessment of spectral based solutions is proposed by evaluating performance on MARIDA dataset.","The outcome highlights the need of precise reference for fair evaluation."],"url":"http://arxiv.org/abs/2408.10187v1"}
{"created":"2024-08-19 17:40:18","title":"Imbalance-Aware Culvert-Sewer Defect Segmentation Using an Enhanced Feature Pyramid Network","abstract":"Imbalanced datasets are a significant challenge in real-world scenarios. They lead to models that underperform on underrepresented classes, which is a critical issue in infrastructure inspection. This paper introduces the Enhanced Feature Pyramid Network (E-FPN), a deep learning model for the semantic segmentation of culverts and sewer pipes within imbalanced datasets. The E-FPN incorporates architectural innovations like sparsely connected blocks and depth-wise separable convolutions to improve feature extraction and handle object variations. To address dataset imbalance, the model employs strategies like class decomposition and data augmentation. Experimental results on the culvert-sewer defects dataset and a benchmark aerial semantic segmentation drone dataset show that the E-FPN outperforms state-of-the-art methods, achieving an average Intersection over Union (IoU) improvement of 13.8% and 27.2%, respectively. Additionally, class decomposition and data augmentation together boost the model's performance by approximately 6.9% IoU. The proposed E-FPN presents a promising solution for enhancing object segmentation in challenging, multi-class real-world datasets, with potential applications extending beyond culvert-sewer defect detection.","sentences":["Imbalanced datasets are a significant challenge in real-world scenarios.","They lead to models that underperform on underrepresented classes, which is a critical issue in infrastructure inspection.","This paper introduces the Enhanced Feature Pyramid Network (E-FPN), a deep learning model for the semantic segmentation of culverts and sewer pipes within imbalanced datasets.","The E-FPN incorporates architectural innovations like sparsely connected blocks and depth-wise separable convolutions to improve feature extraction and handle object variations.","To address dataset imbalance, the model employs strategies like class decomposition and data augmentation.","Experimental results on the culvert-sewer defects dataset and a benchmark aerial semantic segmentation drone dataset show that the E-FPN outperforms state-of-the-art methods, achieving an average Intersection over Union (IoU) improvement of 13.8% and 27.2%, respectively.","Additionally, class decomposition and data augmentation together boost the model's performance by approximately 6.9% IoU.","The proposed E-FPN presents a promising solution for enhancing object segmentation in challenging, multi-class real-world datasets, with potential applications extending beyond culvert-sewer defect detection."],"url":"http://arxiv.org/abs/2408.10181v1"}
{"created":"2024-08-19 17:35:07","title":"Perfectly Undetectable Reflection and Scaling False Data Injection Attacks via Affine Transformation on Mobile Robot Trajectory Tracking Control","abstract":"With the increasing integration of cyber-physical systems (CPS) into critical applications, ensuring their resilience against cyberattacks is paramount. A particularly concerning threat is the vulnerability of CPS to deceptive attacks that degrade system performance while remaining undetected. This paper investigates perfectly undetectable false data injection attacks (FDIAs) targeting the trajectory tracking control of a non-holonomic mobile robot. The proposed attack method utilizes affine transformations of intercepted signals, exploiting weaknesses inherent in the partially linear dynamic properties and symmetry of the nonlinear plant. The feasibility and potential impact of these attacks are validated through experiments using a Turtlebot 3 platform, highlighting the urgent need for sophisticated detection mechanisms and resilient control strategies to safeguard CPS against such threats. Furthermore, a novel approach for detection of these attacks called the state monitoring signature function (SMSF) is introduced. An example SMSF, a carefully designed function resilient to FDIA, is shown to be able to detect the presence of a FDIA through signatures based on systems states.","sentences":["With the increasing integration of cyber-physical systems (CPS) into critical applications, ensuring their resilience against cyberattacks is paramount.","A particularly concerning threat is the vulnerability of CPS to deceptive attacks that degrade system performance while remaining undetected.","This paper investigates perfectly undetectable false data injection attacks (FDIAs) targeting the trajectory tracking control of a non-holonomic mobile robot.","The proposed attack method utilizes affine transformations of intercepted signals, exploiting weaknesses inherent in the partially linear dynamic properties and symmetry of the nonlinear plant.","The feasibility and potential impact of these attacks are validated through experiments using a Turtlebot 3 platform, highlighting the urgent need for sophisticated detection mechanisms and resilient control strategies to safeguard CPS against such threats.","Furthermore, a novel approach for detection of these attacks called the state monitoring signature function (SMSF) is introduced.","An example SMSF, a carefully designed function resilient to FDIA, is shown to be able to detect the presence of a FDIA through signatures based on systems states."],"url":"http://arxiv.org/abs/2408.10177v1"}
{"created":"2024-08-19 17:32:15","title":"SMILE: Zero-Shot Sparse Mixture of Low-Rank Experts Construction From Pre-Trained Foundation Models","abstract":"Deep model training on extensive datasets is increasingly becoming cost-prohibitive, prompting the widespread adoption of deep model fusion techniques to leverage knowledge from pre-existing models. From simple weight averaging to more sophisticated methods like AdaMerging, model fusion effectively improves model performance and accelerates the development of new models. However, potential interference between parameters of individual models and the lack of interpretability in the fusion progress remain significant challenges. Existing methods often try to resolve the parameter interference issue by evaluating attributes of parameters, such as their magnitude or sign, or by parameter pruning. In this study, we begin by examining the fine-tuning of linear layers through the lens of subspace analysis and explicitly define parameter interference as an optimization problem to shed light on this subject. Subsequently, we introduce an innovative approach to model fusion called zero-shot Sparse MIxture of Low-rank Experts (SMILE) construction, which allows for the upscaling of source models into an MoE model without extra data or further training. Our approach relies on the observation that fine-tuning mostly keeps the important parts from the pre-training, but it uses less significant or unused areas to adapt to new tasks. Also, the issue of parameter interference, which is intrinsically intractable in the original parameter space, can be managed by expanding the dimensions. We conduct extensive experiments across diverse scenarios, such as image classification and text generalization tasks, using full fine-tuning and LoRA fine-tuning, and we apply our method to large language models (CLIP models, Flan-T5 models, and Mistral-7B models), highlighting the adaptability and scalability of SMILE. Code is available at https://github.com/tanganke/fusion_bench","sentences":["Deep model training on extensive datasets is increasingly becoming cost-prohibitive, prompting the widespread adoption of deep model fusion techniques to leverage knowledge from pre-existing models.","From simple weight averaging to more sophisticated methods like AdaMerging, model fusion effectively improves model performance and accelerates the development of new models.","However, potential interference between parameters of individual models and the lack of interpretability in the fusion progress remain significant challenges.","Existing methods often try to resolve the parameter interference issue by evaluating attributes of parameters, such as their magnitude or sign, or by parameter pruning.","In this study, we begin by examining the fine-tuning of linear layers through the lens of subspace analysis and explicitly define parameter interference as an optimization problem to shed light on this subject.","Subsequently, we introduce an innovative approach to model fusion called zero-shot Sparse MIxture of Low-rank Experts (SMILE) construction, which allows for the upscaling of source models into an MoE model without extra data or further training.","Our approach relies on the observation that fine-tuning mostly keeps the important parts from the pre-training, but it uses less significant or unused areas to adapt to new tasks.","Also, the issue of parameter interference, which is intrinsically intractable in the original parameter space, can be managed by expanding the dimensions.","We conduct extensive experiments across diverse scenarios, such as image classification and text generalization tasks, using full fine-tuning and LoRA fine-tuning, and we apply our method to large language models (CLIP models, Flan-T5 models, and Mistral-7B models), highlighting the adaptability and scalability of SMILE.","Code is available at https://github.com/tanganke/fusion_bench"],"url":"http://arxiv.org/abs/2408.10174v1"}
{"created":"2024-08-19 17:26:59","title":"Eulerian Graph Sparsification by Effective Resistance Decomposition","abstract":"We provide an algorithm that, given an $n$-vertex $m$-edge Eulerian graph with polynomially bounded weights, computes an $\\breve{O}(n\\log^{2} n \\cdot \\varepsilon^{-2})$-edge $\\varepsilon$-approximate Eulerian sparsifier with high probability in $\\breve{O}(m\\log^3 n)$ time (where $\\breve{O}(\\cdot)$ hides $\\text{polyloglog}(n)$ factors). Due to a reduction from [Peng-Song, STOC '22], this yields an $\\breve{O}(m\\log^3 n + n\\log^6 n)$-time algorithm for solving $n$-vertex $m$-edge Eulerian Laplacian systems with polynomially-bounded weights with high probability, improving upon the previous state-of-the-art runtime of $\\Omega(m\\log^8 n + n\\log^{23} n)$. We also give a polynomial-time algorithm that computes $O(\\min(n\\log n \\cdot \\varepsilon^{-2} + n\\log^{5/3} n \\cdot \\varepsilon^{-4/3}, n\\log^{3/2} n \\cdot \\varepsilon^{-2}))$-edge sparsifiers, improving the best such sparsity bound of $O(n\\log^2 n \\cdot \\varepsilon^{-2} + n\\log^{8/3} n \\cdot \\varepsilon^{-4/3})$ [Sachdeva-Thudi-Zhao, ICALP '24]. Finally, we show that our techniques extend to yield the first $O(m\\cdot\\text{polylog}(n))$ time algorithm for computing $O(n\\varepsilon^{-1}\\cdot\\text{polylog}(n))$-edge graphical spectral sketches, as well as a natural Eulerian generalization we introduce.   In contrast to prior Eulerian graph sparsification algorithms which used either short cycle or expander decompositions, our algorithms use a simple efficient effective resistance decomposition scheme we introduce. Our algorithms apply a natural sampling scheme and electrical routing (to achieve degree balance) to such decompositions. Our analysis leverages new asymmetric variance bounds specialized to Eulerian Laplacians and tools from discrepancy theory.","sentences":["We provide an algorithm that, given an $n$-vertex $m$-edge Eulerian graph with polynomially bounded weights, computes an $\\breve{O}(n\\log^{2} n \\cdot \\varepsilon^{-2})$-edge $\\varepsilon$-approximate Eulerian sparsifier with high probability in $\\breve{O}(m\\log^3 n)$ time (where $\\breve{O}(\\cdot)$ hides $\\text{polyloglog}(n)$ factors).","Due to a reduction from [Peng-Song, STOC '22], this yields an $\\breve{O}(m\\log^3 n + n\\log^6 n)$-time algorithm for solving $n$-vertex $m$-edge Eulerian Laplacian systems with polynomially-bounded weights with high probability, improving upon the previous state-of-the-art runtime of $\\Omega(m\\log^8 n + n\\log^{23} n)$. We also give a polynomial-time algorithm that computes $O(\\min(n\\log n \\cdot \\varepsilon^{-2} + n\\log^{5/3} n \\cdot \\varepsilon^{-4/3}, n\\log^{3/2} n \\cdot \\varepsilon^{-2}))$-edge sparsifiers, improving the best such sparsity bound of $O(n\\log^2 n \\cdot \\varepsilon^{-2} + n\\log^{8/3} n \\cdot \\varepsilon^{-4/3})$","[Sachdeva-Thudi-Zhao, ICALP '24].","Finally, we show that our techniques extend to yield the first $O(m\\cdot\\text{polylog}(n))$ time algorithm for computing $O(n\\varepsilon^{-1}\\cdot\\text{polylog}(n))$-edge graphical spectral sketches, as well as a natural Eulerian generalization we introduce.   ","In contrast to prior Eulerian graph sparsification algorithms which used either short cycle or expander decompositions, our algorithms use a simple efficient effective resistance decomposition scheme we introduce.","Our algorithms apply a natural sampling scheme and electrical routing (to achieve degree balance) to such decompositions.","Our analysis leverages new asymmetric variance bounds specialized to Eulerian Laplacians and tools from discrepancy theory."],"url":"http://arxiv.org/abs/2408.10172v1"}
{"created":"2024-08-19 17:16:59","title":"Towards UAV-USV Collaboration in Harsh Maritime Conditions Including Large Waves","abstract":"This paper introduces a system designed for tight collaboration between Unmanned Aerial Vehicles (UAVs) and Unmanned Surface Vehicles (USVs) in harsh maritime conditions characterized by large waves. This onboard UAV system aims to enhance collaboration with USVs for following and landing tasks under such challenging conditions. The main contribution of our system is the novel mathematical USV model, describing the movement of the USV in 6 degrees of freedom on a wavy water surface, which is used to estimate and predict USV states. The estimator fuses data from multiple global and onboard sensors, ensuring accurate USV state estimation. The predictor computes future USV states using the novel mathematical USV model and the last estimated states. The estimated and predicted USV states are forwarded into a trajectory planner that generates a UAV trajectory for following the USV or landing on its deck, even in harsh environmental conditions. The proposed approach was verified in numerous simulations and deployed to the real world, where the UAV was able to follow the USV and land on its deck repeatedly.","sentences":["This paper introduces a system designed for tight collaboration between Unmanned Aerial Vehicles (UAVs) and Unmanned Surface Vehicles (USVs) in harsh maritime conditions characterized by large waves.","This onboard UAV system aims to enhance collaboration with USVs for following and landing tasks under such challenging conditions.","The main contribution of our system is the novel mathematical USV model, describing the movement of the USV in 6 degrees of freedom on a wavy water surface, which is used to estimate and predict USV states.","The estimator fuses data from multiple global and onboard sensors, ensuring accurate USV state estimation.","The predictor computes future USV states using the novel mathematical USV model and the last estimated states.","The estimated and predicted USV states are forwarded into a trajectory planner that generates a UAV trajectory for following the USV or landing on its deck, even in harsh environmental conditions.","The proposed approach was verified in numerous simulations and deployed to the real world, where the UAV was able to follow the USV and land on its deck repeatedly."],"url":"http://arxiv.org/abs/2408.10163v1"}
{"created":"2024-08-19 17:13:34","title":"NeuFlow v2: High-Efficiency Optical Flow Estimation on Edge Devices","abstract":"Real-time high-accuracy optical flow estimation is crucial for various real-world applications. While recent learning-based optical flow methods have achieved high accuracy, they often come with significant computational costs. In this paper, we propose a highly efficient optical flow method that balances high accuracy with reduced computational demands. Building upon NeuFlow v1, we introduce new components including a much more light-weight backbone and a fast refinement module. Both these modules help in keeping the computational demands light while providing close to state of the art accuracy. Compares to other state of the art methods, our model achieves a 10x-70x speedup while maintaining comparable performance on both synthetic and real-world data. It is capable of running at over 20 FPS on 512x384 resolution images on a Jetson Orin Nano. The full training and evaluation code is available at https://github.com/neufieldrobotics/NeuFlow_v2.","sentences":["Real-time high-accuracy optical flow estimation is crucial for various real-world applications.","While recent learning-based optical flow methods have achieved high accuracy, they often come with significant computational costs.","In this paper, we propose a highly efficient optical flow method that balances high accuracy with reduced computational demands.","Building upon NeuFlow v1, we introduce new components including a much more light-weight backbone and a fast refinement module.","Both these modules help in keeping the computational demands light while providing close to state of the art accuracy.","Compares to other state of the art methods, our model achieves a 10x-70x speedup while maintaining comparable performance on both synthetic and real-world data.","It is capable of running at over 20 FPS on 512x384 resolution images on a Jetson Orin Nano.","The full training and evaluation code is available at https://github.com/neufieldrobotics/NeuFlow_v2."],"url":"http://arxiv.org/abs/2408.10161v1"}
{"created":"2024-08-19 17:02:16","title":"Structure-preserving Image Translation for Depth Estimation in Colonoscopy Video","abstract":"Monocular depth estimation in colonoscopy video aims to overcome the unusual lighting properties of the colonoscopic environment. One of the major challenges in this area is the domain gap between annotated but unrealistic synthetic data and unannotated but realistic clinical data. Previous attempts to bridge this domain gap directly target the depth estimation task itself. We propose a general pipeline of structure-preserving synthetic-to-real (sim2real) image translation (producing a modified version of the input image) to retain depth geometry through the translation process. This allows us to generate large quantities of realistic-looking synthetic images for supervised depth estimation with improved generalization to the clinical domain. We also propose a dataset of hand-picked sequences from clinical colonoscopies to improve the image translation process. We demonstrate the simultaneous realism of the translated images and preservation of depth maps via the performance of downstream depth estimation on various datasets.","sentences":["Monocular depth estimation in colonoscopy video aims to overcome the unusual lighting properties of the colonoscopic environment.","One of the major challenges in this area is the domain gap between annotated but unrealistic synthetic data and unannotated but realistic clinical data.","Previous attempts to bridge this domain gap directly target the depth estimation task itself.","We propose a general pipeline of structure-preserving synthetic-to-real (sim2real) image translation (producing a modified version of the input image) to retain depth geometry through the translation process.","This allows us to generate large quantities of realistic-looking synthetic images for supervised depth estimation with improved generalization to the clinical domain.","We also propose a dataset of hand-picked sequences from clinical colonoscopies to improve the image translation process.","We demonstrate the simultaneous realism of the translated images and preservation of depth maps via the performance of downstream depth estimation on various datasets."],"url":"http://arxiv.org/abs/2408.10153v1"}
{"created":"2024-08-19 16:42:34","title":"Data-Driven Analysis to Understand GPU Hardware Resource Usage of Optimizations","abstract":"With heterogeneous systems, the number of GPUs per chip increases to provide computational capabilities for solving science at a nanoscopic scale. However, low utilization for single GPUs defies the need to invest more money for expensive ccelerators. While related work develops optimizations for improving application performance, none studies how these optimizations impact hardware resource usage or the average GPU utilization. This paper takes a data-driven analysis approach in addressing this gap by (1) characterizing how hardware resource usage affects device utilization, execution time, or both, (2) presenting a multi-objective metric to identify important application-device interactions that can be optimized to improve device utilization and application performance jointly, (3) studying hardware resource usage behaviors of several optimizations for a benchmark application, and finally (4) identifying optimization opportunities for several scientific proxy applications based on their hardware resource usage behaviors. Furthermore, we demonstrate the applicability of our methodology by applying the identified optimizations to a proxy application, which improves the execution time, device utilization and power consumption by up to 29.6%, 5.3% and 26.5% respectively.","sentences":["With heterogeneous systems, the number of GPUs per chip increases to provide computational capabilities for solving science at a nanoscopic scale.","However, low utilization for single GPUs defies the need to invest more money for expensive ccelerators.","While related work develops optimizations for improving application performance, none studies how these optimizations impact hardware resource usage or the average GPU utilization.","This paper takes a data-driven analysis approach in addressing this gap by (1) characterizing how hardware resource usage affects device utilization, execution time, or both, (2) presenting a multi-objective metric to identify important application-device interactions that can be optimized to improve device utilization and application performance jointly, (3) studying hardware resource usage behaviors of several optimizations for a benchmark application, and finally (4) identifying optimization opportunities for several scientific proxy applications based on their hardware resource usage behaviors.","Furthermore, we demonstrate the applicability of our methodology by applying the identified optimizations to a proxy application, which improves the execution time, device utilization and power consumption by up to 29.6%, 5.3% and 26.5% respectively."],"url":"http://arxiv.org/abs/2408.10143v1"}
{"created":"2024-08-19 16:15:09","title":"Advancing Voice Cloning for Nepali: Leveraging Transfer Learning in a Low-Resource Language","abstract":"Voice cloning is a prominent feature in personalized speech interfaces. A neural vocal cloning system can mimic someone's voice using just a few audio samples. Both speaker encoding and speaker adaptation are topics of research in the field of voice cloning. Speaker adaptation relies on fine-tuning a multi-speaker generative model, which involves training a separate model to infer a new speaker embedding used for speaker encoding. Both methods can achieve excellent performance, even with a small number of cloning audios, in terms of the speech's naturalness and similarity to the original speaker. Speaker encoding approaches are more appropriate for low-resource deployment since they require significantly less memory and have a faster cloning time than speaker adaption, which can offer slightly greater naturalness and similarity. The main goal is to create a vocal cloning system that produces audio output with a Nepali accent or that sounds like Nepali. For the further advancement of TTS, the idea of transfer learning was effectively used to address several issues that were encountered in the development of this system, including the poor audio quality and the lack of available data.","sentences":["Voice cloning is a prominent feature in personalized speech interfaces.","A neural vocal cloning system can mimic someone's voice using just a few audio samples.","Both speaker encoding and speaker adaptation are topics of research in the field of voice cloning.","Speaker adaptation relies on fine-tuning a multi-speaker generative model, which involves training a separate model to infer a new speaker embedding used for speaker encoding.","Both methods can achieve excellent performance, even with a small number of cloning audios, in terms of the speech's naturalness and similarity to the original speaker.","Speaker encoding approaches are more appropriate for low-resource deployment since they require significantly less memory and have a faster cloning time than speaker adaption, which can offer slightly greater naturalness and similarity.","The main goal is to create a vocal cloning system that produces audio output with a Nepali accent or that sounds like Nepali.","For the further advancement of TTS, the idea of transfer learning was effectively used to address several issues that were encountered in the development of this system, including the poor audio quality and the lack of available data."],"url":"http://arxiv.org/abs/2408.10128v1"}
{"created":"2024-08-19 16:13:14","title":"Video Object Segmentation via SAM 2: The 4th Solution for LSVOS Challenge VOS Track","abstract":"Video Object Segmentation (VOS) task aims to segmenting a particular object instance throughout the entire video sequence given only the object mask of the first frame. Recently, Segment Anything Model 2 (SAM 2) is proposed, which is a foundation model towards solving promptable visual segmentation in images and videos. SAM 2 builds a data engine, which improves model and data via user interaction, to collect the largest video segmentation dataset to date. SAM 2 is a simple transformer architecture with streaming memory for real-time video processing, which trained on the date provides strong performance across a wide range of tasks. In this work, we evaluate the zero-shot performance of SAM 2 on the more challenging VOS datasets MOSE and LVOS. Without fine-tuning on the training set, SAM 2 achieved 75.79 J&F on the test set and ranked 4th place for 6th LSVOS Challenge VOS Track.","sentences":["Video Object Segmentation (VOS) task aims to segmenting a particular object instance throughout the entire video sequence given only the object mask of the first frame.","Recently, Segment Anything Model 2 (SAM 2) is proposed, which is a foundation model towards solving promptable visual segmentation in images and videos.","SAM 2 builds a data engine, which improves model and data via user interaction, to collect the largest video segmentation dataset to date.","SAM 2 is a simple transformer architecture with streaming memory for real-time video processing, which trained on the date provides strong performance across a wide range of tasks.","In this work, we evaluate the zero-shot performance of SAM 2 on the more challenging VOS datasets MOSE and LVOS.","Without fine-tuning on the training set, SAM 2 achieved 75.79 J&F on the test set and ranked 4th place for 6th LSVOS Challenge VOS Track."],"url":"http://arxiv.org/abs/2408.10125v1"}
{"created":"2024-08-19 16:11:47","title":"Learning Precise Affordances from Egocentric Videos for Robotic Manipulation","abstract":"Affordance, defined as the potential actions that an object offers, is crucial for robotic manipulation tasks. A deep understanding of affordance can lead to more intelligent AI systems. For example, such knowledge directs an agent to grasp a knife by the handle for cutting and by the blade when passing it to someone. In this paper, we present a streamlined affordance learning system that encompasses data collection, effective model training, and robot deployment. First, we collect training data from egocentric videos in an automatic manner. Different from previous methods that focus only on the object graspable affordance and represent it as coarse heatmaps, we cover both graspable (e.g., object handles) and functional affordances (e.g., knife blades, hammer heads) and extract data with precise segmentation masks. We then propose an effective model, termed Geometry-guided Affordance Transformer (GKT), to train on the collected data. GKT integrates an innovative Depth Feature Injector (DFI) to incorporate 3D shape and geometric priors, enhancing the model's understanding of affordances. To enable affordance-oriented manipulation, we further introduce Aff-Grasp, a framework that combines GKT with a grasp generation model. For comprehensive evaluation, we create an affordance evaluation dataset with pixel-wise annotations, and design real-world tasks for robot experiments. The results show that GKT surpasses the state-of-the-art by 15.9% in mIoU, and Aff-Grasp achieves high success rates of 95.5% in affordance prediction and 77.1% in successful grasping among 179 trials, including evaluations with seen, unseen objects, and cluttered scenes.","sentences":["Affordance, defined as the potential actions that an object offers, is crucial for robotic manipulation tasks.","A deep understanding of affordance can lead to more intelligent AI systems.","For example, such knowledge directs an agent to grasp a knife by the handle for cutting and by the blade when passing it to someone.","In this paper, we present a streamlined affordance learning system that encompasses data collection, effective model training, and robot deployment.","First, we collect training data from egocentric videos in an automatic manner.","Different from previous methods that focus only on the object graspable affordance and represent it as coarse heatmaps, we cover both graspable (e.g., object handles) and functional affordances (e.g., knife blades, hammer heads) and extract data with precise segmentation masks.","We then propose an effective model, termed Geometry-guided Affordance Transformer (GKT), to train on the collected data.","GKT integrates an innovative Depth Feature Injector (DFI) to incorporate 3D shape and geometric priors, enhancing the model's understanding of affordances.","To enable affordance-oriented manipulation, we further introduce Aff-Grasp, a framework that combines GKT with a grasp generation model.","For comprehensive evaluation, we create an affordance evaluation dataset with pixel-wise annotations, and design real-world tasks for robot experiments.","The results show that GKT surpasses the state-of-the-art by 15.9% in mIoU, and Aff-Grasp achieves high success rates of 95.5% in affordance prediction and 77.1% in successful grasping among 179 trials, including evaluations with seen, unseen objects, and cluttered scenes."],"url":"http://arxiv.org/abs/2408.10123v1"}
{"created":"2024-08-19 16:08:00","title":"Factorized-Dreamer: Training A High-Quality Video Generator with Limited and Low-Quality Data","abstract":"Text-to-video (T2V) generation has gained significant attention due to its wide applications to video generation, editing, enhancement and translation, \\etc. However, high-quality (HQ) video synthesis is extremely challenging because of the diverse and complex motions existed in real world. Most existing works struggle to address this problem by collecting large-scale HQ videos, which are inaccessible to the community. In this work, we show that publicly available limited and low-quality (LQ) data are sufficient to train a HQ video generator without recaptioning or finetuning. We factorize the whole T2V generation process into two steps: generating an image conditioned on a highly descriptive caption, and synthesizing the video conditioned on the generated image and a concise caption of motion details. Specifically, we present \\emph{Factorized-Dreamer}, a factorized spatiotemporal framework with several critical designs for T2V generation, including an adapter to combine text and image embeddings, a pixel-aware cross attention module to capture pixel-level image information, a T5 text encoder to better understand motion description, and a PredictNet to supervise optical flows. We further present a noise schedule, which plays a key role in ensuring the quality and stability of video generation. Our model lowers the requirements in detailed captions and HQ videos, and can be directly trained on limited LQ datasets with noisy and brief captions such as WebVid-10M, largely alleviating the cost to collect large-scale HQ video-text pairs. Extensive experiments in a variety of T2V and image-to-video generation tasks demonstrate the effectiveness of our proposed Factorized-Dreamer. Our source codes are available at \\url{https://github.com/yangxy/Factorized-Dreamer/}.","sentences":["Text-to-video (T2V) generation has gained significant attention due to its wide applications to video generation, editing, enhancement and translation, \\etc.","However, high-quality (HQ) video synthesis is extremely challenging because of the diverse and complex motions existed in real world.","Most existing works struggle to address this problem by collecting large-scale HQ videos, which are inaccessible to the community.","In this work, we show that publicly available limited and low-quality (LQ) data are sufficient to train a HQ video generator without recaptioning or finetuning.","We factorize the whole T2V generation process into two steps: generating an image conditioned on a highly descriptive caption, and synthesizing the video conditioned on the generated image and a concise caption of motion details.","Specifically, we present \\emph{Factorized-Dreamer}, a factorized spatiotemporal framework with several critical designs for T2V generation, including an adapter to combine text and image embeddings, a pixel-aware cross attention module to capture pixel-level image information, a T5 text encoder to better understand motion description, and a PredictNet to supervise optical flows.","We further present a noise schedule, which plays a key role in ensuring the quality and stability of video generation.","Our model lowers the requirements in detailed captions and HQ videos, and can be directly trained on limited LQ datasets with noisy and brief captions such as WebVid-10M, largely alleviating the cost to collect large-scale HQ video-text pairs.","Extensive experiments in a variety of T2V and image-to-video generation tasks demonstrate the effectiveness of our proposed Factorized-Dreamer.","Our source codes are available at \\url{https://github.com/yangxy/Factorized-Dreamer/}."],"url":"http://arxiv.org/abs/2408.10119v1"}
{"created":"2024-08-19 15:59:46","title":"PLUTUS: A Well Pre-trained Large Unified Transformer can Unveil Financial Time Series Regularities","abstract":"Financial time series modeling is crucial for understanding and predicting market behaviors but faces challenges such as non-linearity, non-stationarity, and high noise levels. Traditional models struggle to capture complex patterns due to these issues, compounded by limitations in computational resources and model capacity. Inspired by the success of large language models in NLP, we introduce \\textbf{PLUTUS}, a \\textbf{P}re-trained \\textbf{L}arge \\textbf{U}nified \\textbf{T}ransformer-based model that \\textbf{U}nveils regularities in financial time \\textbf{S}eries. PLUTUS uses an invertible embedding module with contrastive learning and autoencoder techniques to create an approximate one-to-one mapping between raw data and patch embeddings. TimeFormer, an attention based architecture, forms the core of PLUTUS, effectively modeling high-noise time series. We incorporate a novel attention mechanisms to capture features across both variable and temporal dimensions. PLUTUS is pre-trained on an unprecedented dataset of 100 billion observations, designed to thrive in noisy financial environments. To our knowledge, PLUTUS is the first open-source, large-scale, pre-trained financial time series model with over one billion parameters. It achieves state-of-the-art performance in various tasks, demonstrating strong transferability and establishing a robust foundational model for finance. Our research provides technical guidance for pre-training financial time series data, setting a new standard in the field.","sentences":["Financial time series modeling is crucial for understanding and predicting market behaviors but faces challenges such as non-linearity, non-stationarity, and high noise levels.","Traditional models struggle to capture complex patterns due to these issues, compounded by limitations in computational resources and model capacity.","Inspired by the success of large language models in NLP, we introduce \\textbf{PLUTUS}, a \\textbf{P}re-trained \\textbf{L}arge \\textbf{U}nified \\textbf{T}ransformer-based model that \\textbf{U}nveils regularities in financial time \\textbf{S}eries.","PLUTUS uses an invertible embedding module with contrastive learning and autoencoder techniques to create an approximate one-to-one mapping between raw data and patch embeddings.","TimeFormer, an attention based architecture, forms the core of PLUTUS, effectively modeling high-noise time series.","We incorporate a novel attention mechanisms to capture features across both variable and temporal dimensions.","PLUTUS is pre-trained on an unprecedented dataset of 100 billion observations, designed to thrive in noisy financial environments.","To our knowledge, PLUTUS is the first open-source, large-scale, pre-trained financial time series model with over one billion parameters.","It achieves state-of-the-art performance in various tasks, demonstrating strong transferability and establishing a robust foundational model for finance.","Our research provides technical guidance for pre-training financial time series data, setting a new standard in the field."],"url":"http://arxiv.org/abs/2408.10111v1"}
{"created":"2024-08-19 15:55:46","title":"Envisioning Possibilities and Challenges of AI for Personalized Cancer Care","abstract":"The use of Artificial Intelligence (AI) in healthcare, including in caring for cancer survivors, has gained significant interest. However, gaps remain in our understanding of how such AI systems can provide care, especially for ethnic and racial minority groups who continue to face care disparities. Through interviews with six cancer survivors, we identify critical gaps in current healthcare systems such as a lack of personalized care and insufficient cultural and linguistic accommodation. AI, when applied to care, was seen as a way to address these issues by enabling real-time, culturally aligned, and linguistically appropriate interactions. We also uncovered concerns about the implications of AI-driven personalization, such as data privacy, loss of human touch in caregiving, and the risk of echo chambers that limit exposure to diverse information. We conclude by discussing the trade-offs between AI-enhanced personalization and the need for structural changes in healthcare that go beyond technological solutions, leading us to argue that we should begin by asking, ``Why personalization?''","sentences":["The use of Artificial Intelligence (AI) in healthcare, including in caring for cancer survivors, has gained significant interest.","However, gaps remain in our understanding of how such AI systems can provide care, especially for ethnic and racial minority groups who continue to face care disparities.","Through interviews with six cancer survivors, we identify critical gaps in current healthcare systems such as a lack of personalized care and insufficient cultural and linguistic accommodation.","AI, when applied to care, was seen as a way to address these issues by enabling real-time, culturally aligned, and linguistically appropriate interactions.","We also uncovered concerns about the implications of AI-driven personalization, such as data privacy, loss of human touch in caregiving, and the risk of echo chambers that limit exposure to diverse information.","We conclude by discussing the trade-offs between AI-enhanced personalization and the need for structural changes in healthcare that go beyond technological solutions, leading us to argue that we should begin by asking, ``Why personalization?''"],"url":"http://arxiv.org/abs/2408.10108v1"}
{"created":"2024-08-19 15:33:59","title":"Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision","abstract":"Low resource of parallel data is the key challenge of accent conversion(AC) problem in which both the pronunciation units and prosody pattern need to be converted. We propose a two-stage generative framework \"convert-and-speak\" in which the conversion is only operated on the semantic token level and the speech is synthesized conditioned on the converted semantic token with a speech generative model in target accent domain. The decoupling design enables the \"speaking\" module to use massive amount of target accent speech and relieves the parallel data required for the \"conversion\" module. Conversion with the bridge of semantic token also relieves the requirement for the data with text transcriptions and unlocks the usage of language pre-training technology to further efficiently reduce the need of parallel accent speech data. To reduce the complexity and latency of \"speaking\", a single-stage AR generative model is designed to achieve good quality as well as lower computation cost. Experiments on Indian-English to general American-English conversion show that the proposed framework achieves state-of-the-art performance in accent similarity, speech quality, and speaker maintenance with only 15 minutes of weakly parallel data which is not constrained to the same speaker. Extensive experimentation with diverse accent types suggests that this framework possesses a high degree of adaptability, making it readily scalable to accommodate other accents with low-resource data. Audio samples are available at https://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/.","sentences":["Low resource of parallel data is the key challenge of accent conversion(AC) problem in which both the pronunciation units and prosody pattern need to be converted.","We propose a two-stage generative framework \"convert-and-speak\" in which the conversion is only operated on the semantic token level and the speech is synthesized conditioned on the converted semantic token with a speech generative model in target accent domain.","The decoupling design enables the \"speaking\" module to use massive amount of target accent speech and relieves the parallel data required for the \"conversion\" module.","Conversion with the bridge of semantic token also relieves the requirement for the data with text transcriptions and unlocks the usage of language pre-training technology to further efficiently reduce the need of parallel accent speech data.","To reduce the complexity and latency of \"speaking\", a single-stage AR generative model is designed to achieve good quality as well as lower computation cost.","Experiments on Indian-English to general American-English conversion show that the proposed framework achieves state-of-the-art performance in accent similarity, speech quality, and speaker maintenance with only 15 minutes of weakly parallel data which is not constrained to the same speaker.","Extensive experimentation with diverse accent types suggests that this framework possesses a high degree of adaptability, making it readily scalable to accommodate other accents with low-resource data.","Audio samples are available at https://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/."],"url":"http://arxiv.org/abs/2408.10096v1"}
{"created":"2024-08-19 15:32:29","title":"Selecting Relay Nodes Based on Evaluation Results to Enhance P2P Broadcasting Efficiency","abstract":"The existence of node failures is inevitable in distributed systems, thus many P2P broadcasting networks adopt highly robust Flooding-based broadcast algorithms. High redundancy inevitably leads to high network resource consumption, and it may constrain the data transmission rate of the network. To address excessive network resource consumption, many studies have explored broadcasting mechanisms in structured P2P overlay networks. However, existing DHT-based algorithms cannot assess the quality of neighbors, which is crucial for broadcast efficiency. In this paper, we introduce the Neighbor Evaluation mechanism to select relay nodes based on their evaluated contributions. According to experimental results, the Neighbor Evaluation mechanism has a significant effect on both broadcast latency and coverage rate.","sentences":["The existence of node failures is inevitable in distributed systems, thus many P2P broadcasting networks adopt highly robust Flooding-based broadcast algorithms.","High redundancy inevitably leads to high network resource consumption, and it may constrain the data transmission rate of the network.","To address excessive network resource consumption, many studies have explored broadcasting mechanisms in structured P2P overlay networks.","However, existing DHT-based algorithms cannot assess the quality of neighbors, which is crucial for broadcast efficiency.","In this paper, we introduce the Neighbor Evaluation mechanism to select relay nodes based on their evaluated contributions.","According to experimental results, the Neighbor Evaluation mechanism has a significant effect on both broadcast latency and coverage rate."],"url":"http://arxiv.org/abs/2408.10092v1"}
{"created":"2024-08-19 15:31:06","title":"Federated Frank-Wolfe Algorithm","abstract":"Federated learning (FL) has gained a lot of attention in recent years for building privacy-preserving collaborative learning systems. However, FL algorithms for constrained machine learning problems are still limited, particularly when the projection step is costly. To this end, we propose a Federated Frank-Wolfe Algorithm (FedFW). FedFW features data privacy, low per-iteration cost, and communication of sparse signals. In the deterministic setting, FedFW achieves an $\\varepsilon$-suboptimal solution within $O(\\varepsilon^{-2})$ iterations for smooth and convex objectives, and $O(\\varepsilon^{-3})$ iterations for smooth but non-convex objectives. Furthermore, we present a stochastic variant of FedFW and show that it finds a solution within $O(\\varepsilon^{-3})$ iterations in the convex setting. We demonstrate the empirical performance of FedFW on several machine learning tasks.","sentences":["Federated learning (FL) has gained a lot of attention in recent years for building privacy-preserving collaborative learning systems.","However, FL algorithms for constrained machine learning problems are still limited, particularly when the projection step is costly.","To this end, we propose a Federated Frank-Wolfe Algorithm (FedFW).","FedFW features data privacy, low per-iteration cost, and communication of sparse signals.","In the deterministic setting, FedFW achieves an $\\varepsilon$-suboptimal solution within $O(\\varepsilon^{-2})$ iterations for smooth and convex objectives, and $O(\\varepsilon^{-3})$ iterations for smooth but non-convex objectives.","Furthermore, we present a stochastic variant of FedFW and show that it finds a solution within $O(\\varepsilon^{-3})$ iterations in the convex setting.","We demonstrate the empirical performance of FedFW on several machine learning tasks."],"url":"http://arxiv.org/abs/2408.10090v1"}
{"created":"2024-08-19 15:29:56","title":"Recent Surge in Public Interest in Transportation: Sentiment Analysis of Baidu Apollo Go Using Weibo Data","abstract":"Urban mobility and transportation systems have been profoundly transformed by the advancement of autonomous vehicle technologies. Baidu Apollo Go, a pioneer robotaxi service from the Chinese tech giant Baidu, has recently been widely deployed in major cities like Beijing and Wuhan, sparking increased conversation and offering a glimpse into the future of urban mobility.   This study investigates public attitudes towards Apollo Go across China using Sentiment Analysis with a hybrid BERT model on 36,096 Weibo posts from January to July 2024. The analysis shows that 89.56\\% of posts related to Apollo Go are clustered in July. From January to July, public sentiment was mostly positive, but negative comments began to rise after it became a hot topic on July 21.   Spatial analysis indicates a strong correlation between provinces with high discussion intensity and those where Apollo Go operates. Initially, Hubei and Guangdong dominated online posting volume, but by July, Guangdong, Beijing, and international regions had overtaken Hubei. Attitudes varied significantly among provinces, with Xinjiang and Qinghai showing optimism and Tibet and Gansu expressing concerns about the impact on traditional taxi services.   Sentiment analysis revealed that positive comments focused on technology applications and personal experiences, while negative comments centered on job displacement and safety concerns. In summary, this study highlights the divergence in public perceptions of autonomous ride-hailing services, providing valuable insights for planners, policymakers, and service providers. The model is published on Hugging Face at https://huggingface.co/wsqstar/bert-finetuned-weibo-luobokuaipao and the repository on GitHub at https://github.com/GIStudio/trb2024.","sentences":["Urban mobility and transportation systems have been profoundly transformed by the advancement of autonomous vehicle technologies.","Baidu Apollo Go, a pioneer robotaxi service from the Chinese tech giant Baidu, has recently been widely deployed in major cities like Beijing and Wuhan, sparking increased conversation and offering a glimpse into the future of urban mobility.   ","This study investigates public attitudes towards Apollo Go across China using Sentiment Analysis with a hybrid BERT model on 36,096 Weibo posts from January to July 2024.","The analysis shows that 89.56\\% of posts related to Apollo Go are clustered in July.","From January to July, public sentiment was mostly positive, but negative comments began to rise after it became a hot topic on July 21.   ","Spatial analysis indicates a strong correlation between provinces with high discussion intensity and those where Apollo Go operates.","Initially, Hubei and Guangdong dominated online posting volume, but by July, Guangdong, Beijing, and international regions had overtaken Hubei.","Attitudes varied significantly among provinces, with Xinjiang and Qinghai showing optimism and Tibet and Gansu expressing concerns about the impact on traditional taxi services.   ","Sentiment analysis revealed that positive comments focused on technology applications and personal experiences, while negative comments centered on job displacement and safety concerns.","In summary, this study highlights the divergence in public perceptions of autonomous ride-hailing services, providing valuable insights for planners, policymakers, and service providers.","The model is published on Hugging Face at https://huggingface.co/wsqstar/bert-finetuned-weibo-luobokuaipao and the repository on GitHub at https://github.com/GIStudio/trb2024."],"url":"http://arxiv.org/abs/2408.10088v1"}
{"created":"2024-08-19 15:27:25","title":"ARMADA: Attribute-Based Multimodal Data Augmentation","abstract":"In Multimodal Language Models (MLMs), the cost of manually annotating high-quality image-text pair data for fine-tuning and alignment is extremely high. While existing multimodal data augmentation frameworks propose ways to augment image-text pairs, they either suffer from semantic inconsistency between texts and images, or generate unrealistic images, causing knowledge gap with real world examples. To address these issues, we propose Attribute-based Multimodal Data Augmentation (ARMADA), a novel multimodal data augmentation method via knowledge-guided manipulation of visual attributes of the mentioned entities. Specifically, we extract entities and their visual attributes from the original text data, then search for alternative values for the visual attributes under the guidance of knowledge bases (KBs) and large language models (LLMs). We then utilize an image-editing model to edit the images with the extracted attributes. ARMADA is a novel multimodal data generation framework that: (i) extracts knowledge-grounded attributes from symbolic KBs for semantically consistent yet distinctive image-text pair generation, (ii) generates visually similar images of disparate categories using neighboring entities in the KB hierarchy, and (iii) uses the commonsense knowledge of LLMs to modulate auxiliary visual attributes such as backgrounds for more robust representation of original entities. Our empirical results over four downstream tasks demonstrate the efficacy of our framework to produce high-quality data and enhance the model performance. This also highlights the need to leverage external knowledge proxies for enhanced interpretability and real-world grounding.","sentences":["In Multimodal Language Models (MLMs), the cost of manually annotating high-quality image-text pair data for fine-tuning and alignment is extremely high.","While existing multimodal data augmentation frameworks propose ways to augment image-text pairs, they either suffer from semantic inconsistency between texts and images, or generate unrealistic images, causing knowledge gap with real world examples.","To address these issues, we propose Attribute-based Multimodal Data Augmentation (ARMADA), a novel multimodal data augmentation method via knowledge-guided manipulation of visual attributes of the mentioned entities.","Specifically, we extract entities and their visual attributes from the original text data, then search for alternative values for the visual attributes under the guidance of knowledge bases (KBs) and large language models (LLMs).","We then utilize an image-editing model to edit the images with the extracted attributes.","ARMADA is a novel multimodal data generation framework that: (i) extracts knowledge-grounded attributes from symbolic KBs for semantically consistent yet distinctive image-text pair generation, (ii) generates visually similar images of disparate categories using neighboring entities in the KB hierarchy, and (iii) uses the commonsense knowledge of LLMs to modulate auxiliary visual attributes such as backgrounds for more robust representation of original entities.","Our empirical results over four downstream tasks demonstrate the efficacy of our framework to produce high-quality data and enhance the model performance.","This also highlights the need to leverage external knowledge proxies for enhanced interpretability and real-world grounding."],"url":"http://arxiv.org/abs/2408.10086v1"}
{"created":"2024-08-19 15:25:40","title":"Tywaves: A Typed Waveform Viewer for Chisel","abstract":"Chisel (Constructing Hardware In a Scala Embedded Language) is a broadly adopted HDL that brings object-oriented and functional programming, type-safety, and parameterization to hardware design. However, while these language features significantly improve the process of writing code, debugging Chisel designs with open source tools loses many of the advantages of the source language, as type information and data structure hierarchies are lost in the translation, simulator output, and waveform viewer. This work, Tywaves, presents a new type-centered debugging format that brings the same level of abstraction found in contemporary hardware languages to waveform viewers. Contributions to the Chisel library and CIRCT MLIR compiler as well as the Surfer waveform viewer result in a waveform viewer that better supports the Chisel HDL.   Project url: https://github.com/rameloni/tywaves-chisel-demo","sentences":["Chisel (Constructing Hardware In a Scala Embedded Language) is a broadly adopted HDL that brings object-oriented and functional programming, type-safety, and parameterization to hardware design.","However, while these language features significantly improve the process of writing code, debugging Chisel designs with open source tools loses many of the advantages of the source language, as type information and data structure hierarchies are lost in the translation, simulator output, and waveform viewer.","This work, Tywaves, presents a new type-centered debugging format that brings the same level of abstraction found in contemporary hardware languages to waveform viewers.","Contributions to the Chisel library and CIRCT MLIR compiler as well as the Surfer waveform viewer result in a waveform viewer that better supports the Chisel HDL.   ","Project url: https://github.com/rameloni/tywaves-chisel-demo"],"url":"http://arxiv.org/abs/2408.10082v1"}
{"created":"2024-08-19 15:18:30","title":"Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning","abstract":"Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for aligning foundation models to human values and preferences. However, current RLHF techniques cannot account for the naturally occurring differences in individual human preferences across a diverse population. When these differences arise, traditional RLHF frameworks simply average over them, leading to inaccurate rewards and poor performance for individual subgroups. To address the need for pluralistic alignment, we develop a class of multimodal RLHF methods. Our proposed techniques are based on a latent variable formulation - inferring a novel user-specific latent and learning reward models and policies conditioned on this latent without additional user-specific data. While conceptually simple, we show that in practice, this reward modeling requires careful algorithmic considerations around model architecture and reward scaling. To empirically validate our proposed technique, we first show that it can provide a way to combat underspecification in simulated control problems, inferring and optimizing user-specific reward functions. Next, we conduct experiments on pluralistic language datasets representing diverse user preferences and demonstrate improved reward function accuracy. We additionally show the benefits of this probabilistic framework in terms of measuring uncertainty, and actively learning user preferences. This work enables learning from diverse populations of users with divergent preferences, an important challenge that naturally occurs in problems from robot learning to foundation model alignment.","sentences":["Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for aligning foundation models to human values and preferences.","However, current RLHF techniques cannot account for the naturally occurring differences in individual human preferences across a diverse population.","When these differences arise, traditional RLHF frameworks simply average over them, leading to inaccurate rewards and poor performance for individual subgroups.","To address the need for pluralistic alignment, we develop a class of multimodal RLHF methods.","Our proposed techniques are based on a latent variable formulation - inferring a novel user-specific latent and learning reward models and policies conditioned on this latent without additional user-specific data.","While conceptually simple, we show that in practice, this reward modeling requires careful algorithmic considerations around model architecture and reward scaling.","To empirically validate our proposed technique, we first show that it can provide a way to combat underspecification in simulated control problems, inferring and optimizing user-specific reward functions.","Next, we conduct experiments on pluralistic language datasets representing diverse user preferences and demonstrate improved reward function accuracy.","We additionally show the benefits of this probabilistic framework in terms of measuring uncertainty, and actively learning user preferences.","This work enables learning from diverse populations of users with divergent preferences, an important challenge that naturally occurs in problems from robot learning to foundation model alignment."],"url":"http://arxiv.org/abs/2408.10075v1"}
{"created":"2024-08-19 15:16:36","title":"Modelling the Distribution of Human Motion for Sign Language Assessment","abstract":"Sign Language Assessment (SLA) tools are useful to aid in language learning and are underdeveloped. Previous work has focused on isolated signs or comparison against a single reference video to assess Sign Languages (SL). This paper introduces a novel SLA tool designed to evaluate the comprehensibility of SL by modelling the natural distribution of human motion. We train our pipeline on data from native signers and evaluate it using SL learners. We compare our results to ratings from a human raters study and find strong correlation between human ratings and our tool. We visually demonstrate our tools ability to detect anomalous results spatio-temporally, providing actionable feedback to aid in SL learning and assessment.","sentences":["Sign Language Assessment (SLA) tools are useful to aid in language learning and are underdeveloped.","Previous work has focused on isolated signs or comparison against a single reference video to assess Sign Languages (SL).","This paper introduces a novel SLA tool designed to evaluate the comprehensibility of SL by modelling the natural distribution of human motion.","We train our pipeline on data from native signers and evaluate it using SL learners.","We compare our results to ratings from a human raters study and find strong correlation between human ratings and our tool.","We visually demonstrate our tools ability to detect anomalous results spatio-temporally, providing actionable feedback to aid in SL learning and assessment."],"url":"http://arxiv.org/abs/2408.10073v1"}
{"created":"2024-08-19 15:11:01","title":"LNQ 2023 challenge: Benchmark of weakly-supervised techniques for mediastinal lymph node quantification","abstract":"Accurate assessment of lymph node size in 3D CT scans is crucial for cancer staging, therapeutic management, and monitoring treatment response. Existing state-of-the-art segmentation frameworks in medical imaging often rely on fully annotated datasets. However, for lymph node segmentation, these datasets are typically small due to the extensive time and expertise required to annotate the numerous lymph nodes in 3D CT scans. Weakly-supervised learning, which leverages incomplete or noisy annotations, has recently gained interest in the medical imaging community as a potential solution. Despite the variety of weakly-supervised techniques proposed, most have been validated only on private datasets or small publicly available datasets. To address this limitation, the Mediastinal Lymph Node Quantification (LNQ) challenge was organized in conjunction with the 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023). This challenge aimed to advance weakly-supervised segmentation methods by providing a new, partially annotated dataset and a robust evaluation framework. A total of 16 teams from 5 countries submitted predictions to the validation leaderboard, and 6 teams from 3 countries participated in the evaluation phase. The results highlighted both the potential and the current limitations of weakly-supervised approaches. On one hand, weakly-supervised approaches obtained relatively good performance with a median Dice score of $61.0\\%$. On the other hand, top-ranked teams, with a median Dice score exceeding $70\\%$, boosted their performance by leveraging smaller but fully annotated datasets to combine weak supervision and full supervision. This highlights both the promise of weakly-supervised methods and the ongoing need for high-quality, fully annotated data to achieve higher segmentation performance.","sentences":["Accurate assessment of lymph node size in 3D CT scans is crucial for cancer staging, therapeutic management, and monitoring treatment response.","Existing state-of-the-art segmentation frameworks in medical imaging often rely on fully annotated datasets.","However, for lymph node segmentation, these datasets are typically small due to the extensive time and expertise required to annotate the numerous lymph nodes in 3D CT scans.","Weakly-supervised learning, which leverages incomplete or noisy annotations, has recently gained interest in the medical imaging community as a potential solution.","Despite the variety of weakly-supervised techniques proposed, most have been validated only on private datasets or small publicly available datasets.","To address this limitation, the Mediastinal Lymph Node Quantification (LNQ) challenge was organized in conjunction with the 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023).","This challenge aimed to advance weakly-supervised segmentation methods by providing a new, partially annotated dataset and a robust evaluation framework.","A total of 16 teams from 5 countries submitted predictions to the validation leaderboard, and 6 teams from 3 countries participated in the evaluation phase.","The results highlighted both the potential and the current limitations of weakly-supervised approaches.","On one hand, weakly-supervised approaches obtained relatively good performance with a median Dice score of $61.0\\%$. On the other hand, top-ranked teams, with a median Dice score exceeding $70\\%$, boosted their performance by leveraging smaller but fully annotated datasets to combine weak supervision and full supervision.","This highlights both the promise of weakly-supervised methods and the ongoing need for high-quality, fully annotated data to achieve higher segmentation performance."],"url":"http://arxiv.org/abs/2408.10069v1"}
{"created":"2024-08-19 14:58:25","title":"Understanding cyclists' perception of driverless vehicles through eye-tracking and interviews","abstract":"As automated vehicles (AVs) become increasingly popular, the question arises as to how cyclists will interact with such vehicles. This study investigated (1) whether cyclists spontaneously notice if a vehicle is driverless, (2) how well they perform a driver-detection task when explicitly instructed, and (3) how they carry out such tasks. Using a Wizard-of-Oz method, 37 participants cycled a designated route and encountered an AV multiple times in two experimental sessions. In Session 1, participants cycled the route uninstructed, while in Session 2, they were instructed to verbally report whether they detected the presence or absence of a driver. Additionally, we recorded the participants' gaze behaviour with eye-tracking and their responses in post-session interviews. The interviews revealed that 30% of the cyclists spontaneously mentioned the absence of a driver (Session 1), and when instructed (Session 2), they detected the absence and presence of the driver with 93% accuracy. The eye-tracking data showed that cyclists looked more frequently and longer at the vehicle in Session 2 compared to Session 1. Furthermore, participants exhibited intermittent sampling of the vehicle, and they looked in front of the vehicle when it was far away and towards the windshield region when it was closer. The post-session interviews also indicated that participants were curious, felt safe, and reported a need to receive information about the AV's driving state. In conclusion, cyclists can detect the absence of a driver in the AV, and this detection may influence their perceptions of safety. Further research is needed to explore these findings in real-world traffic conditions.","sentences":["As automated vehicles (AVs) become increasingly popular, the question arises as to how cyclists will interact with such vehicles.","This study investigated (1) whether cyclists spontaneously notice if a vehicle is driverless, (2) how well they perform a driver-detection task when explicitly instructed, and (3) how they carry out such tasks.","Using a Wizard-of-Oz method, 37 participants cycled a designated route and encountered an AV multiple times in two experimental sessions.","In Session 1, participants cycled the route uninstructed, while in Session 2, they were instructed to verbally report whether they detected the presence or absence of a driver.","Additionally, we recorded the participants' gaze behaviour with eye-tracking and their responses in post-session interviews.","The interviews revealed that 30% of the cyclists spontaneously mentioned the absence of a driver (Session 1), and when instructed (Session 2), they detected the absence and presence of the driver with 93% accuracy.","The eye-tracking data showed that cyclists looked more frequently and longer at the vehicle in Session 2 compared to Session 1.","Furthermore, participants exhibited intermittent sampling of the vehicle, and they looked in front of the vehicle when it was far away and towards the windshield region when it was closer.","The post-session interviews also indicated that participants were curious, felt safe, and reported a need to receive information about the AV's driving state.","In conclusion, cyclists can detect the absence of a driver in the AV, and this detection may influence their perceptions of safety.","Further research is needed to explore these findings in real-world traffic conditions."],"url":"http://arxiv.org/abs/2408.10064v1"}
{"created":"2024-08-19 14:54:12","title":"Facial Wrinkle Segmentation for Cosmetic Dermatology: Pretraining with Texture Map-Based Weak Supervision","abstract":"Facial wrinkle detection plays a crucial role in cosmetic dermatology. Precise manual segmentation of facial wrinkles is challenging and time-consuming, with inherent subjectivity leading to inconsistent results among graders. To address this issue, we propose two solutions. First, we build and release the first public facial wrinkle dataset, `FFHQ-Wrinkle', an extension of the NVIDIA FFHQ dataset. This dataset includes 1,000 images with human labels and 50,000 images with automatically generated weak labels. This dataset can foster the research community to develop advanced wrinkle detection algorithms. Second, we introduce a training strategy for U-Net-like encoder-decoder models to detect wrinkles across the face automatically. Our method employs a two-stage training strategy: texture map pretraining and finetuning on human-labeled data. Initially, we pretrain models on a large dataset with weak labels (N=50k) or masked texture maps generated through computer vision techniques, without human intervention. Subsequently, we finetune the models using human-labeled data (N=1k), which consists of manually labeled wrinkle masks. During finetuning, the network inputs a combination of RGB and masked texture maps, comprising four channels. We effectively combine labels from multiple annotators to minimize subjectivity in manual labeling. Our strategies demonstrate improved segmentation performance in facial wrinkle segmentation both quantitatively and visually compared to existing pretraining methods.","sentences":["Facial wrinkle detection plays a crucial role in cosmetic dermatology.","Precise manual segmentation of facial wrinkles is challenging and time-consuming, with inherent subjectivity leading to inconsistent results among graders.","To address this issue, we propose two solutions.","First, we build and release the first public facial wrinkle dataset, `FFHQ-Wrinkle', an extension of the NVIDIA FFHQ dataset.","This dataset includes 1,000 images with human labels and 50,000 images with automatically generated weak labels.","This dataset can foster the research community to develop advanced wrinkle detection algorithms.","Second, we introduce a training strategy for U-Net-like encoder-decoder models to detect wrinkles across the face automatically.","Our method employs a two-stage training strategy: texture map pretraining and finetuning on human-labeled data.","Initially, we pretrain models on a large dataset with weak labels (N=50k) or masked texture maps generated through computer vision techniques, without human intervention.","Subsequently, we finetune the models using human-labeled data (N=1k), which consists of manually labeled wrinkle masks.","During finetuning, the network inputs a combination of RGB and masked texture maps, comprising four channels.","We effectively combine labels from multiple annotators to minimize subjectivity in manual labeling.","Our strategies demonstrate improved segmentation performance in facial wrinkle segmentation both quantitatively and visually compared to existing pretraining methods."],"url":"http://arxiv.org/abs/2408.10060v1"}
{"created":"2024-08-19 14:50:48","title":"Efficient Exploration in Deep Reinforcement Learning: A Novel Bayesian Actor-Critic Algorithm","abstract":"Reinforcement learning (RL) and Deep Reinforcement Learning (DRL), in particular, have the potential to disrupt and are already changing the way we interact with the world. One of the key indicators of their applicability is their ability to scale and work in real-world scenarios, that is in large-scale problems. This scale can be achieved via a combination of factors, the algorithm's ability to make use of large amounts of data and computational resources and the efficient exploration of the environment for viable solutions (i.e. policies).   In this work, we investigate and motivate some theoretical foundations for deep reinforcement learning. We start with exact dynamic programming and work our way up to stochastic approximations and stochastic approximations for a model-free scenario, which forms the theoretical basis of modern reinforcement learning. We present an overview of this highly varied and rapidly changing field from the perspective of Approximate Dynamic Programming. We then focus our study on the short-comings with respect to exploration of the cornerstone approaches (i.e. DQN, DDQN, A2C) in deep reinforcement learning. On the theory side, our main contribution is the proposal of a novel Bayesian actor-critic algorithm. On the empirical side, we evaluate Bayesian exploration as well as actor-critic algorithms on standard benchmarks as well as state-of-the-art evaluation suites and show the benefits of both of these approaches over current state-of-the-art deep RL methods. We release all the implementations and provide a full python library that is easy to install and hopefully will serve the reinforcement learning community in a meaningful way, and provide a strong foundation for future work.","sentences":["Reinforcement learning (RL) and Deep Reinforcement Learning (DRL), in particular, have the potential to disrupt and are already changing the way we interact with the world.","One of the key indicators of their applicability is their ability to scale and work in real-world scenarios, that is in large-scale problems.","This scale can be achieved via a combination of factors, the algorithm's ability to make use of large amounts of data and computational resources and the efficient exploration of the environment for viable solutions (i.e. policies).   ","In this work, we investigate and motivate some theoretical foundations for deep reinforcement learning.","We start with exact dynamic programming and work our way up to stochastic approximations and stochastic approximations for a model-free scenario, which forms the theoretical basis of modern reinforcement learning.","We present an overview of this highly varied and rapidly changing field from the perspective of Approximate Dynamic Programming.","We then focus our study on the short-comings with respect to exploration of the cornerstone approaches (i.e. DQN, DDQN, A2C) in deep reinforcement learning.","On the theory side, our main contribution is the proposal of a novel Bayesian actor-critic algorithm.","On the empirical side, we evaluate Bayesian exploration as well as actor-critic algorithms on standard benchmarks as well as state-of-the-art evaluation suites and show the benefits of both of these approaches over current state-of-the-art deep RL methods.","We release all the implementations and provide a full python library that is easy to install and hopefully will serve the reinforcement learning community in a meaningful way, and provide a strong foundation for future work."],"url":"http://arxiv.org/abs/2408.10055v1"}
{"created":"2024-08-19 14:48:04","title":"Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory","abstract":"Privacy research has attracted wide attention as individuals worry that their private data can be easily leaked during interactions with smart devices, social platforms, and AI applications. Computer science researchers, on the other hand, commonly study privacy issues through privacy attacks and defenses on segmented fields. Privacy research is conducted on various sub-fields, including Computer Vision (CV), Natural Language Processing (NLP), and Computer Networks. Within each field, privacy has its own formulation. Though pioneering works on attacks and defenses reveal sensitive privacy issues, they are narrowly trapped and cannot fully cover people's actual privacy concerns. Consequently, the research on general and human-centric privacy research remains rather unexplored. In this paper, we formulate the privacy issue as a reasoning problem rather than simple pattern matching. We ground on the Contextual Integrity (CI) theory which posits that people's perceptions of privacy are highly correlated with the corresponding social context. Based on such an assumption, we develop the first comprehensive checklist that covers social identities, private attributes, and existing privacy regulations. Unlike prior works on CI that either cover limited expert annotated norms or model incomplete social context, our proposed privacy checklist uses the whole Health Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to show that we can resort to large language models (LLMs) to completely cover the HIPAA's regulations. Additionally, our checklist also gathers expert annotations across multiple ontologies to determine private information including but not limited to personally identifiable information (PII). We use our preliminary results on the HIPAA to shed light on future context-centric privacy research to cover more privacy regulations, social norms and standards.","sentences":["Privacy research has attracted wide attention as individuals worry that their private data can be easily leaked during interactions with smart devices, social platforms, and AI applications.","Computer science researchers, on the other hand, commonly study privacy issues through privacy attacks and defenses on segmented fields.","Privacy research is conducted on various sub-fields, including Computer Vision (CV), Natural Language Processing (NLP), and Computer Networks.","Within each field, privacy has its own formulation.","Though pioneering works on attacks and defenses reveal sensitive privacy issues, they are narrowly trapped and cannot fully cover people's actual privacy concerns.","Consequently, the research on general and human-centric privacy research remains rather unexplored.","In this paper, we formulate the privacy issue as a reasoning problem rather than simple pattern matching.","We ground on the Contextual Integrity (CI) theory which posits that people's perceptions of privacy are highly correlated with the corresponding social context.","Based on such an assumption, we develop the first comprehensive checklist that covers social identities, private attributes, and existing privacy regulations.","Unlike prior works on CI that either cover limited expert annotated norms or model incomplete social context, our proposed privacy checklist uses the whole Health Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to show that we can resort to large language models (LLMs) to completely cover the HIPAA's regulations.","Additionally, our checklist also gathers expert annotations across multiple ontologies to determine private information including but not limited to personally identifiable information (PII).","We use our preliminary results on the HIPAA to shed light on future context-centric privacy research to cover more privacy regulations, social norms and standards."],"url":"http://arxiv.org/abs/2408.10053v1"}
{"created":"2024-08-19 14:34:36","title":"Stacked Intelligent Metasurfaces for Integrated Sensing and Communications","abstract":"Stacked intelligent metasurfaces (SIM) have recently emerged as a promising technology, which can realize transmit precoding in the wave domain. In this paper, we investigate a SIM-aided integrated sensing and communications system, in which SIM is capable of generating a desired beam pattern for simultaneously communicating with multiple downlink users and detecting a radar target. Specifically, we formulate an optimization problem of maximizing the spectrum efficiency, while satisfying the power constraint of the desired direction. This requires jointly designing the phase shifts of the SIM and the power allocation at the base station. By incorporating the sensing power constraint into the objective functions as a penalty term, we further simplify the optimization problem and solve it by customizing an efficient gradient ascent algorithm. Finally, extensive numerical results demonstrate the effectiveness of the proposed wave-domain precoder for automatically mitigating the inter-user interference and generating a desired beampattern for the sensing task, as multiple separate data streams transmit through the SIM.","sentences":["Stacked intelligent metasurfaces (SIM) have recently emerged as a promising technology, which can realize transmit precoding in the wave domain.","In this paper, we investigate a SIM-aided integrated sensing and communications system, in which SIM is capable of generating a desired beam pattern for simultaneously communicating with multiple downlink users and detecting a radar target.","Specifically, we formulate an optimization problem of maximizing the spectrum efficiency, while satisfying the power constraint of the desired direction.","This requires jointly designing the phase shifts of the SIM and the power allocation at the base station.","By incorporating the sensing power constraint into the objective functions as a penalty term, we further simplify the optimization problem and solve it by customizing an efficient gradient ascent algorithm.","Finally, extensive numerical results demonstrate the effectiveness of the proposed wave-domain precoder for automatically mitigating the inter-user interference and generating a desired beampattern for the sensing task, as multiple separate data streams transmit through the SIM."],"url":"http://arxiv.org/abs/2408.10043v1"}
{"created":"2024-08-19 14:34:17","title":"Implicit Gaussian Splatting with Efficient Multi-Level Tri-Plane Representation","abstract":"Recent advancements in photo-realistic novel view synthesis have been significantly driven by Gaussian Splatting (3DGS). Nevertheless, the explicit nature of 3DGS data entails considerable storage requirements, highlighting a pressing need for more efficient data representations. To address this, we present Implicit Gaussian Splatting (IGS), an innovative hybrid model that integrates explicit point clouds with implicit feature embeddings through a multi-level tri-plane architecture. This architecture features 2D feature grids at various resolutions across different levels, facilitating continuous spatial domain representation and enhancing spatial correlations among Gaussian primitives. Building upon this foundation, we introduce a level-based progressive training scheme, which incorporates explicit spatial regularization. This method capitalizes on spatial correlations to enhance both the rendering quality and the compactness of the IGS representation. Furthermore, we propose a novel compression pipeline tailored for both point clouds and 2D feature grids, considering the entropy variations across different levels. Extensive experimental evaluations demonstrate that our algorithm can deliver high-quality rendering using only a few MBs, effectively balancing storage efficiency and rendering fidelity, and yielding results that are competitive with the state-of-the-art.","sentences":["Recent advancements in photo-realistic novel view synthesis have been significantly driven by Gaussian Splatting (3DGS).","Nevertheless, the explicit nature of 3DGS data entails considerable storage requirements, highlighting a pressing need for more efficient data representations.","To address this, we present Implicit Gaussian Splatting (IGS), an innovative hybrid model that integrates explicit point clouds with implicit feature embeddings through a multi-level tri-plane architecture.","This architecture features 2D feature grids at various resolutions across different levels, facilitating continuous spatial domain representation and enhancing spatial correlations among Gaussian primitives.","Building upon this foundation, we introduce a level-based progressive training scheme, which incorporates explicit spatial regularization.","This method capitalizes on spatial correlations to enhance both the rendering quality and the compactness of the IGS representation.","Furthermore, we propose a novel compression pipeline tailored for both point clouds and 2D feature grids, considering the entropy variations across different levels.","Extensive experimental evaluations demonstrate that our algorithm can deliver high-quality rendering using only a few MBs, effectively balancing storage efficiency and rendering fidelity, and yielding results that are competitive with the state-of-the-art."],"url":"http://arxiv.org/abs/2408.10041v1"}
{"created":"2024-08-19 14:12:20","title":"\"EBK\" : Leveraging Crowd-Sourced Social Media Data to Quantify How Hyperlocal Gang Affiliations Shape Personal Networks and Violence in Chicago's Contemporary Southside","abstract":"Recent ethnographic research reveals that gang dynamics in Chicago's Southside have evolved with decentralized micro-gang \"set\" factions and cross-gang interpersonal networks marking the contemporary landscape. However, standard police datasets lack the depth to analyze gang violence with such granularity. To address this, we employed a natural language processing strategy to analyze text from a Chicago gangs message board. By identifying proper nouns, probabilistically linking them to gang sets, and assuming social connections among names mentioned together, we created a social network dataset of 271 individuals across 11 gang sets. Using Louvain community detection, we found that these individuals often connect with gang-affiliated peers from various gang sets that are physically proximal. Hierarchical logistic regression revealed that individuals with ties to homicide victims and central positions in the overall gang network were at increased risk of victimization, regardless of gang affiliation. This research demonstrates that utilizing crowd-sourced information online can enable the study of otherwise inaccessible topics and populations.","sentences":["Recent ethnographic research reveals that gang dynamics in Chicago's Southside have evolved with decentralized micro-gang \"set\" factions and cross-gang interpersonal networks marking the contemporary landscape.","However, standard police datasets lack the depth to analyze gang violence with such granularity.","To address this, we employed a natural language processing strategy to analyze text from a Chicago gangs message board.","By identifying proper nouns, probabilistically linking them to gang sets, and assuming social connections among names mentioned together, we created a social network dataset of 271 individuals across 11 gang sets.","Using Louvain community detection, we found that these individuals often connect with gang-affiliated peers from various gang sets that are physically proximal.","Hierarchical logistic regression revealed that individuals with ties to homicide victims and central positions in the overall gang network were at increased risk of victimization, regardless of gang affiliation.","This research demonstrates that utilizing crowd-sourced information online can enable the study of otherwise inaccessible topics and populations."],"url":"http://arxiv.org/abs/2408.10018v1"}
{"created":"2024-08-19 14:10:41","title":"Improved Distance (Sensitivity) Oracles with Subquadratic Space","abstract":"A distance oracle (DO) with stretch $(\\alpha, \\beta)$ for a graph $G$ is a data structure that, when queried with vertices $s$ and $t$, returns a value $\\widehat{d}(s,t)$ such that $d(s,t) \\le \\widehat{d}(s,t) \\le \\alpha \\cdot d(s,t) + \\beta$. An $f$-edge fault-tolerant distance sensitivity oracle ($f$-DSO) additionally receives a set $F$ of up to $f$ edges and estimates the $s$-$t$-distance in $G{-}F$. Our first contribution is a new distance oracle with subquadratic space for undirected graphs. Introducing a small additive stretch $\\beta > 0$ allows us to make the multiplicative stretch $\\alpha$ arbitrarily small. This sidesteps a known lower bound of $\\alpha \\ge 3$ (for $\\beta = 0$ and subquadratic space) [Thorup & Zwick, JACM 2005]. We present a DO for graphs with edge weights in $[0,W]$ that, for any positive integer $t$ and any $c \\in (0, \\ell/2]$, has stretch $(1{+}\\frac{1}{\\ell}, 2W)$, space $\\widetilde{O}(n^{2-\\frac{c}{t}})$, and query time $O(n^c)$. These are the first subquadratic-space DOs with $(1+\\epsilon, O(1))$-stretch generalizing Agarwal and Godfrey's results for sparse graphs [SODA 2013] to general undirected graphs. Our second contribution is a framework that turns a $(\\alpha,\\beta)$-stretch DO for unweighted graphs into an $(\\alpha (1{+}\\varepsilon),\\beta)$-stretch $f$-DSO with sensitivity $f = o(\\log(n)/\\log\\log n)$ and retains subquadratic space. This generalizes a result by Bil\\`o, Chechik, Choudhary, Cohen, Friedrich, Krogmann, and Schirneck [STOC 2023, TheoretiCS 2024] for the special case of stretch $(3,0)$ and $f = O(1)$. By combining the framework with our new distance oracle, we obtain an $f$-DSO that, for any $\\gamma \\in (0, (\\ell{+}1)/2]$, has stretch $((1{+}\\frac{1}{\\ell}) (1{+}\\varepsilon), 2)$, space $n^{ 2- \\frac{\\gamma}{(\\ell+1)(f+1)} + o(1)}/\\varepsilon^{f+2}$, and query time $\\widetilde{O}(n^{\\gamma} /{\\varepsilon}^2)$.","sentences":["A distance oracle (DO) with stretch $(\\alpha, \\beta)$ for a graph $G$ is a data structure that, when queried with vertices $s$ and $t$, returns a value $\\widehat{d}(s,t)$ such that $d(s,t) \\le \\widehat{d}(s,t) \\le \\alpha \\cdot d(s,t)","+","\\beta$.","An $f$-edge fault-tolerant distance sensitivity oracle ($f$-DSO) additionally receives a set $F$ of up to $f$ edges and estimates the $s$-$t$-distance in $G{-}F$. Our first contribution is a new distance oracle with subquadratic space for undirected graphs.","Introducing a small additive stretch $\\beta > 0$ allows us to make the multiplicative stretch $\\alpha$ arbitrarily small.","This sidesteps a known lower bound of $\\alpha \\ge 3$ (for $\\beta = 0$ and subquadratic space)","[Thorup & Zwick, JACM 2005].","We present a DO for graphs with edge weights in $[0,W]$ that, for any positive integer $t$ and any $c \\in (0, \\ell/2]$, has stretch $(1{+}\\frac{1}{\\ell}, 2W)$, space $\\widetilde{O}(n^{2-\\frac{c}{t}})$, and query time $O(n^c)$. These are the first subquadratic-space DOs with $(1+\\epsilon, O(1))$-stretch generalizing Agarwal and Godfrey's results for sparse graphs [SODA 2013] to general undirected graphs.","Our second contribution is a framework that turns a $(\\alpha,\\beta)$-stretch DO for unweighted graphs into an $(\\alpha (1{+}\\varepsilon),\\beta)$-stretch $f$-DSO with sensitivity $f = o(\\log(n)/\\log\\log n)$ and retains subquadratic space.","This generalizes a result by Bil\\`o, Chechik, Choudhary, Cohen, Friedrich, Krogmann, and Schirneck","[STOC 2023, TheoretiCS 2024] for the special case of stretch $(3,0)$ and $f = O(1)$. By combining the framework with our new distance oracle, we obtain an $f$-DSO that, for any $\\gamma \\in (0, (\\ell{+}1)/2]$, has stretch $((1{+}\\frac{1}{\\ell})","(1{+}\\varepsilon), 2)$, space $n^{","2- \\frac{\\gamma}{(\\ell+1)(f+1)}","+ o(1)}/\\varepsilon^{f+2}$, and query time $\\widetilde{O}(n^{\\gamma} /{\\varepsilon}^2)$."],"url":"http://arxiv.org/abs/2408.10014v1"}
{"created":"2024-08-19 14:09:48","title":"TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading","abstract":"The growth rate of the GPU memory capacity has not been able to keep up with that of the size of large language models (LLMs), hindering the model training process. In particular, activations -- the intermediate tensors produced during forward propagation and reused in backward propagation -- dominate the GPU memory use. To address this challenge, we propose TBA to efficiently offload activations to high-capacity NVMe SSDs. This approach reduces GPU memory usage without impacting performance by adaptively overlapping data transfers with computation. TBA is compatible with popular deep learning frameworks like PyTorch, Megatron, and DeepSpeed, and it employs techniques such as tensor deduplication, forwarding, and adaptive offloading to further enhance efficiency. We conduct extensive experiments on GPT, BERT, and T5. Results demonstrate that TBA effectively reduces 47% of the activation peak memory usage. At the same time, TBA perfectly overlaps the I/O with the computation and incurs negligible performance overhead. We introduce the recompute-offload-keep (ROK) curve to compare the TBA offloading with other two tensor placement strategies, keeping activations in memory and layerwise full recomputation. We find that TBA achieves better memory savings than layerwise full recomputation while retaining the performance of keeping the activations in memory.","sentences":["The growth rate of the GPU memory capacity has not been able to keep up with that of the size of large language models (LLMs), hindering the model training process.","In particular, activations -- the intermediate tensors produced during forward propagation and reused in backward propagation -- dominate the GPU memory use.","To address this challenge, we propose TBA to efficiently offload activations to high-capacity NVMe SSDs.","This approach reduces GPU memory usage without impacting performance by adaptively overlapping data transfers with computation.","TBA is compatible with popular deep learning frameworks like PyTorch, Megatron, and DeepSpeed, and it employs techniques such as tensor deduplication, forwarding, and adaptive offloading to further enhance efficiency.","We conduct extensive experiments on GPT, BERT, and T5.","Results demonstrate that TBA effectively reduces 47% of the activation peak memory usage.","At the same time, TBA perfectly overlaps the I/O with the computation and incurs negligible performance overhead.","We introduce the recompute-offload-keep (ROK) curve to compare the TBA offloading with other two tensor placement strategies, keeping activations in memory and layerwise full recomputation.","We find that TBA achieves better memory savings than layerwise full recomputation while retaining the performance of keeping the activations in memory."],"url":"http://arxiv.org/abs/2408.10013v1"}
{"created":"2024-08-19 13:59:53","title":"P3P: Pseudo-3D Pre-training for Scaling 3D Masked Autoencoders","abstract":"3D pre-training is crucial to 3D perception tasks. However, limited by the difficulties in collecting clean 3D data, 3D pre-training consistently faced data scaling challenges. Inspired by semi-supervised learning leveraging limited labeled data and a large amount of unlabeled data, in this work, we propose a novel self-supervised pre-training framework utilizing the real 3D data and the pseudo-3D data lifted from images by a large depth estimation model. Another challenge lies in the efficiency. Previous methods such as Point-BERT and Point-MAE, employ k nearest neighbors to embed 3D tokens, requiring quadratic time complexity. To efficiently pre-train on such a large amount of data, we propose a linear-time-complexity token embedding strategy and a training-efficient 2D reconstruction target. Our method achieves state-of-the-art performance in 3D classification and few-shot learning while maintaining high pre-training and downstream fine-tuning efficiency.","sentences":["3D pre-training is crucial to 3D perception tasks.","However, limited by the difficulties in collecting clean 3D data, 3D pre-training consistently faced data scaling challenges.","Inspired by semi-supervised learning leveraging limited labeled data and a large amount of unlabeled data, in this work, we propose a novel self-supervised pre-training framework utilizing the real 3D data and the pseudo-3D data lifted from images by a large depth estimation model.","Another challenge lies in the efficiency.","Previous methods such as Point-BERT and Point-MAE, employ k nearest neighbors to embed 3D tokens, requiring quadratic time complexity.","To efficiently pre-train on such a large amount of data, we propose a linear-time-complexity token embedding strategy and a training-efficient 2D reconstruction target.","Our method achieves state-of-the-art performance in 3D classification and few-shot learning while maintaining high pre-training and downstream fine-tuning efficiency."],"url":"http://arxiv.org/abs/2408.10007v1"}
{"created":"2024-08-19 13:57:49","title":"Towards a Knowledge Graph for Models and Algorithms in Applied Mathematics","abstract":"Mathematical models and algorithms are an essential part of mathematical research data, as they are epistemically grounding numerical data. In order to represent models and algorithms as well as their relationship semantically to make this research data FAIR, two previously distinct ontologies were merged and extended, becoming a living knowledge graph. The link between the two ontologies is established by introducing computational tasks, as they occur in modeling, corresponding to algorithmic tasks. Moreover, controlled vocabularies are incorporated and a new class, distinguishing base quantities from specific use case quantities, was introduced. Also, both models and algorithms can now be enriched with metadata. Subject-specific metadata is particularly relevant here, such as the symmetry of a matrix or the linearity of a mathematical model. This is the only way to express specific workflows with concrete models and algorithms, as the feasible solution algorithm can only be determined if the mathematical properties of a model are known. We demonstrate this using two examples from different application areas of applied mathematics. In addition, we have already integrated over 250 research assets from applied mathematics into our knowledge graph.","sentences":["Mathematical models and algorithms are an essential part of mathematical research data, as they are epistemically grounding numerical data.","In order to represent models and algorithms as well as their relationship semantically to make this research data FAIR, two previously distinct ontologies were merged and extended, becoming a living knowledge graph.","The link between the two ontologies is established by introducing computational tasks, as they occur in modeling, corresponding to algorithmic tasks.","Moreover, controlled vocabularies are incorporated and a new class, distinguishing base quantities from specific use case quantities, was introduced.","Also, both models and algorithms can now be enriched with metadata.","Subject-specific metadata is particularly relevant here, such as the symmetry of a matrix or the linearity of a mathematical model.","This is the only way to express specific workflows with concrete models and algorithms, as the feasible solution algorithm can only be determined if the mathematical properties of a model are known.","We demonstrate this using two examples from different application areas of applied mathematics.","In addition, we have already integrated over 250 research assets from applied mathematics into our knowledge graph."],"url":"http://arxiv.org/abs/2408.10003v1"}
{"created":"2024-08-19 13:53:35","title":"Working in Extended Reality in the Wild: Worker and Bystander Experiences of XR Virtual Displays in Real-World Settings","abstract":"Although access to sufficient screen space is crucial to knowledge work, workers often find themselves with limited access to display infrastructure in remote or public settings. While virtual displays can be used to extend the available screen space through extended reality (XR) head-worn displays (HWD), we must better understand the implications of working with them in public settings from both users' and bystanders' viewpoints. To this end, we conducted two user studies. We first explored the usage of a hybrid AR display across real-world settings and tasks. We focused on how users take advantage of virtual displays and what social and environmental factors impact their usage of the system. A second study investigated the differences between working with a laptop, an AR system, or a VR system in public. We focused on a single location and participants performed a predefined task to enable direct comparisons between the conditions while also gathering data from bystanders. The combined results suggest a positive acceptance of XR technology in public settings and show that virtual displays can be used to accompany existing devices. We highlighted some environmental and social factors. We saw that previous XR experience and personality can influence how people perceive the use of XR in public. In addition, we confirmed that using XR in public still makes users stand out and that bystanders are curious about the devices, yet have no clear understanding of how they can be used.","sentences":["Although access to sufficient screen space is crucial to knowledge work, workers often find themselves with limited access to display infrastructure in remote or public settings.","While virtual displays can be used to extend the available screen space through extended reality (XR) head-worn displays (HWD), we must better understand the implications of working with them in public settings from both users' and bystanders' viewpoints.","To this end, we conducted two user studies.","We first explored the usage of a hybrid AR display across real-world settings and tasks.","We focused on how users take advantage of virtual displays and what social and environmental factors impact their usage of the system.","A second study investigated the differences between working with a laptop, an AR system, or a VR system in public.","We focused on a single location and participants performed a predefined task to enable direct comparisons between the conditions while also gathering data from bystanders.","The combined results suggest a positive acceptance of XR technology in public settings and show that virtual displays can be used to accompany existing devices.","We highlighted some environmental and social factors.","We saw that previous XR experience and personality can influence how people perceive the use of XR in public.","In addition, we confirmed that using XR in public still makes users stand out and that bystanders are curious about the devices, yet have no clear understanding of how they can be used."],"url":"http://arxiv.org/abs/2408.10000v1"}
{"created":"2024-08-19 13:47:17","title":"Uniting contrastive and generative learning for event sequences models","abstract":"High-quality representation of transactional sequences is vital for modern banking applications, including risk management, churn prediction, and personalized customer offers. Different tasks require distinct representation properties: local tasks benefit from capturing the client's current state, while global tasks rely on general behavioral patterns. Previous research has demonstrated that various self-supervised approaches yield representations that better capture either global or local qualities.   This study investigates the integration of two self-supervised learning techniques - instance-wise contrastive learning and a generative approach based on restoring masked events in latent space. The combined approach creates representations that balance local and global transactional data characteristics. Experiments conducted on several public datasets, focusing on sequence classification and next-event type prediction, show that the integrated method achieves superior performance compared to individual approaches and demonstrates synergistic effects. These findings suggest that the proposed approach offers a robust framework for advancing event sequences representation learning in the financial sector.","sentences":["High-quality representation of transactional sequences is vital for modern banking applications, including risk management, churn prediction, and personalized customer offers.","Different tasks require distinct representation properties: local tasks benefit from capturing the client's current state, while global tasks rely on general behavioral patterns.","Previous research has demonstrated that various self-supervised approaches yield representations that better capture either global or local qualities.   ","This study investigates the integration of two self-supervised learning techniques - instance-wise contrastive learning and a generative approach based on restoring masked events in latent space.","The combined approach creates representations that balance local and global transactional data characteristics.","Experiments conducted on several public datasets, focusing on sequence classification and next-event type prediction, show that the integrated method achieves superior performance compared to individual approaches and demonstrates synergistic effects.","These findings suggest that the proposed approach offers a robust framework for advancing event sequences representation learning in the financial sector."],"url":"http://arxiv.org/abs/2408.09995v1"}
{"created":"2024-08-19 13:43:48","title":"Efficient Inference of Sub-Item Id-based Sequential Recommendation Models with Millions of Items","abstract":"Transformer-based recommender systems, such as BERT4Rec or SASRec, achieve state-of-the-art results in sequential recommendation. However, it is challenging to use these models in production environments with catalogues of millions of items: scaling Transformers beyond a few thousand items is problematic for several reasons, including high model memory consumption and slow inference. In this respect, RecJPQ is a state-of-the-art method of reducing the models' memory consumption; RecJPQ compresses item catalogues by decomposing item IDs into a small number of shared sub-item IDs. Despite reporting the reduction of memory consumption by a factor of up to 50x, the original RecJPQ paper did not report inference efficiency improvements over the baseline Transformer-based models. Upon analysing RecJPQ's scoring algorithm, we find that its efficiency is limited by its use of score accumulators for each item, which prevents parallelisation. In contrast, LightRec (a non-sequential method that uses a similar idea of sub-ids) reported large inference efficiency improvements using an algorithm we call PQTopK. We show that it is also possible to improve RecJPQ-based models' inference efficiency using the PQTopK algorithm. In particular, we speed up RecJPQ-enhanced SASRec by a factor of 4.5 x compared to the original SASRec's inference method and by a factor of 1.56 x compared to the method implemented in RecJPQ code on a large-scale Gowalla dataset with more than a million items. Further, using simulated data, we show that PQTopK remains efficient with catalogues of up to tens of millions of items, removing one of the last obstacles to using Transformer-based models in production environments with large catalogues.","sentences":["Transformer-based recommender systems, such as BERT4Rec or SASRec, achieve state-of-the-art results in sequential recommendation.","However, it is challenging to use these models in production environments with catalogues of millions of items: scaling Transformers beyond a few thousand items is problematic for several reasons, including high model memory consumption and slow inference.","In this respect, RecJPQ is a state-of-the-art method of reducing the models' memory consumption; RecJPQ compresses item catalogues by decomposing item IDs into a small number of shared sub-item IDs.","Despite reporting the reduction of memory consumption by a factor of up to 50x, the original RecJPQ paper did not report inference efficiency improvements over the baseline Transformer-based models.","Upon analysing RecJPQ's scoring algorithm, we find that its efficiency is limited by its use of score accumulators for each item, which prevents parallelisation.","In contrast, LightRec (a non-sequential method that uses a similar idea of sub-ids) reported large inference efficiency improvements using an algorithm we call PQTopK.","We show that it is also possible to improve RecJPQ-based models' inference efficiency using the PQTopK algorithm.","In particular, we speed up RecJPQ-enhanced SASRec by a factor of 4.5 x compared to the original SASRec's inference method and by a factor of 1.56 x compared to the method implemented in RecJPQ code on a large-scale Gowalla dataset with more than a million items.","Further, using simulated data, we show that PQTopK remains efficient with catalogues of up to tens of millions of items, removing one of the last obstacles to using Transformer-based models in production environments with large catalogues."],"url":"http://arxiv.org/abs/2408.09992v1"}
{"created":"2024-08-19 13:23:07","title":"Preference-Optimized Pareto Set Learning for Blackbox Optimization","abstract":"Multi-Objective Optimization (MOO) is an important problem in real-world applications. However, for a non-trivial problem, no single solution exists that can optimize all the objectives simultaneously. In a typical MOO problem, the goal is to find a set of optimum solutions (Pareto set) that trades off the preferences among objectives. Scalarization in MOO is a well-established method for finding a finite set approximation of the whole Pareto set (PS). However, in real-world experimental design scenarios, it's beneficial to obtain the whole PS for flexible exploration of the design space. Recently Pareto set learning (PSL) has been introduced to approximate the whole PS. PSL involves creating a manifold representing the Pareto front of a multi-objective optimization problem. A naive approach includes finding discrete points on the Pareto front through randomly generated preference vectors and connecting them by regression. However, this approach is computationally expensive and leads to a poor PS approximation. We propose to optimize the preference points to be distributed evenly on the Pareto front. Our formulation leads to a bilevel optimization problem that can be solved by e.g. differentiable cross-entropy methods. We demonstrated the efficacy of our method for complex and difficult black-box MOO problems using both synthetic and real-world benchmark data.","sentences":["Multi-Objective Optimization (MOO) is an important problem in real-world applications.","However, for a non-trivial problem, no single solution exists that can optimize all the objectives simultaneously.","In a typical MOO problem, the goal is to find a set of optimum solutions (Pareto set) that trades off the preferences among objectives.","Scalarization in MOO is a well-established method for finding a finite set approximation of the whole Pareto set (PS).","However, in real-world experimental design scenarios, it's beneficial to obtain the whole PS for flexible exploration of the design space.","Recently Pareto set learning (PSL) has been introduced to approximate the whole PS.","PSL involves creating a manifold representing the Pareto front of a multi-objective optimization problem.","A naive approach includes finding discrete points on the Pareto front through randomly generated preference vectors and connecting them by regression.","However, this approach is computationally expensive and leads to a poor PS approximation.","We propose to optimize the preference points to be distributed evenly on the Pareto front.","Our formulation leads to a bilevel optimization problem that can be solved by e.g. differentiable cross-entropy methods.","We demonstrated the efficacy of our method for complex and difficult black-box MOO problems using both synthetic and real-world benchmark data."],"url":"http://arxiv.org/abs/2408.09976v1"}
{"created":"2024-08-19 13:19:15","title":"Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models","abstract":"Integrating large language models (LLMs) into autonomous driving enhances personalization and adaptability in open-world scenarios. However, traditional edge computing models still face significant challenges in processing complex driving data, particularly regarding real-time performance and system efficiency. To address these challenges, this study introduces EC-Drive, a novel edge-cloud collaborative autonomous driving system with data drift detection capabilities. EC-Drive utilizes drift detection algorithms to selectively upload critical data, including new obstacles and traffic pattern changes, to the cloud for processing by GPT-4, while routine data is efficiently managed by smaller LLMs on edge devices. This approach not only reduces inference latency but also improves system efficiency by optimizing communication resource use. Experimental validation confirms the system's robust processing capabilities and practical applicability in real-world driving conditions, demonstrating the effectiveness of this edge-cloud collaboration framework. Our data and system demonstration will be released at https://sites.google.com/view/ec-drive.","sentences":["Integrating large language models (LLMs) into autonomous driving enhances personalization and adaptability in open-world scenarios.","However, traditional edge computing models still face significant challenges in processing complex driving data, particularly regarding real-time performance and system efficiency.","To address these challenges, this study introduces EC-Drive, a novel edge-cloud collaborative autonomous driving system with data drift detection capabilities.","EC-Drive utilizes drift detection algorithms to selectively upload critical data, including new obstacles and traffic pattern changes, to the cloud for processing by GPT-4, while routine data is efficiently managed by smaller LLMs on edge devices.","This approach not only reduces inference latency but also improves system efficiency by optimizing communication resource use.","Experimental validation confirms the system's robust processing capabilities and practical applicability in real-world driving conditions, demonstrating the effectiveness of this edge-cloud collaboration framework.","Our data and system demonstration will be released at https://sites.google.com/view/ec-drive."],"url":"http://arxiv.org/abs/2408.09972v1"}
{"created":"2024-08-19 13:05:32","title":"Validation of the Results of Cross-chain Smart Contract Based on Confirmation Method","abstract":"Smart contracts are widely utilized in cross-chain interactions, where their results are transmitted from one blockchain (the producer blockchain) to another (the consumer blockchain). Unfortunately, the consumer blockchain often accepts these results without executing the smart contracts for validation, posing potential security risks. To address this, we propose a method for validating cross-chain smart contract results. Our approach emphasizes consumer blockchain execution of cross-chain smart contracts of producer blockchain, allowing comparison of results with the transmitted ones to detect potential discrepancies and ensure data integrity during cross-chain data dissemination. Additionally, we introduce the confirmation with proof method, which involves incorporating the chain of blocks and relevant cross-chain smart contract data from the producer blockchain into the consumer blockchain as evidence (or proof), establishing a unified and secure perspective of cross-chain smart contract results. Our verification results highlight the feasibility of cross-chain validation at the smart contract level.","sentences":["Smart contracts are widely utilized in cross-chain interactions, where their results are transmitted from one blockchain (the producer blockchain) to another (the consumer blockchain).","Unfortunately, the consumer blockchain often accepts these results without executing the smart contracts for validation, posing potential security risks.","To address this, we propose a method for validating cross-chain smart contract results.","Our approach emphasizes consumer blockchain execution of cross-chain smart contracts of producer blockchain, allowing comparison of results with the transmitted ones to detect potential discrepancies and ensure data integrity during cross-chain data dissemination.","Additionally, we introduce the confirmation with proof method, which involves incorporating the chain of blocks and relevant cross-chain smart contract data from the producer blockchain into the consumer blockchain as evidence (or proof), establishing a unified and secure perspective of cross-chain smart contract results.","Our verification results highlight the feasibility of cross-chain validation at the smart contract level."],"url":"http://arxiv.org/abs/2408.09962v1"}
{"created":"2024-08-19 12:58:51","title":"AdaResNet: Enhancing Residual Networks with Dynamic Weight Adjustment for Improved Feature Integration","abstract":"In very deep neural networks, gradients can become extremely small during backpropagation, making it challenging to train the early layers. ResNet (Residual Network) addresses this issue by enabling gradients to flow directly through the network via skip connections, facilitating the training of much deeper networks. However, in these skip connections, the input ipd is directly added to the transformed data tfd, treating ipd and tfd equally, without adapting to different scenarios. In this paper, we propose AdaResNet (Auto-Adapting Residual Network), which automatically adjusts the ratio between ipd and tfd based on the training data. We introduce a variable, weight}_{tfd}^{ipd, to represent this ratio. This variable is dynamically adjusted during backpropagation, allowing it to adapt to the training data rather than remaining fixed. Experimental results demonstrate that AdaResNet achieves a maximum accuracy improvement of over 50\\% compared to traditional ResNet.","sentences":["In very deep neural networks, gradients can become extremely small during backpropagation, making it challenging to train the early layers.","ResNet (Residual Network) addresses this issue by enabling gradients to flow directly through the network via skip connections, facilitating the training of much deeper networks.","However, in these skip connections, the input ipd is directly added to the transformed data tfd, treating ipd and tfd equally, without adapting to different scenarios.","In this paper, we propose AdaResNet (Auto-Adapting Residual Network), which automatically adjusts the ratio between ipd and tfd based on the training data.","We introduce a variable, weight}_{tfd}^{ipd, to represent this ratio.","This variable is dynamically adjusted during backpropagation, allowing it to adapt to the training data rather than remaining fixed.","Experimental results demonstrate that AdaResNet achieves a maximum accuracy improvement of over 50\\% compared to traditional ResNet."],"url":"http://arxiv.org/abs/2408.09958v1"}
{"created":"2024-08-19 12:53:51","title":"Experiment-based Models for Air Time and Current Consumption of LoRaWAN LR-FHSS","abstract":"Long Range - Frequency Hopping Spread Spectrum (LR-FHSS) is an emerging and promising technology recently introduced into the LoRaWAN protocol specification for both terrestrial and non-terrestrial networks, notably satellites. The higher capacity, long-range and robustness to Doppler effect make LR-FHSS a primary candidate for direct-to-satellite (DtS) connectivity for enabling Internet-of-things (IoT) in remote areas. The LR-FHSS devices envisioned for DtS IoT will be primarily battery-powered. Therefore, it is crucial to investigate the current consumption characteristics and Time-on-Air (ToA) of LR-FHSS technology. However, to our knowledge, no prior research has presented the accurate ToA and current consumption models for this newly introduced scheme. This paper addresses this shortcoming through extensive field measurements and the development of analytical models. Specifically, we have measured the current consumption and ToA for variable transmit power, message payload, and two new LR-FHSS-based Data Rates (DR8 and DR9). We also develop current consumption and ToA analytical models demonstrating a strong correlation with the measurement results exhibiting a relative error of less than 0.3%. Thus, it confirms the validity of our models. Conversely, the existing analytical models exhibit a higher relative error rate of -9.2 to 3.4% compared to our measurement results. The presented in this paper results can be further used for simulators or in analytical studies to accurately model the on-air time and energy consumption of LR-FHSS devices.","sentences":["Long Range - Frequency Hopping Spread Spectrum (LR-FHSS) is an emerging and promising technology recently introduced into the LoRaWAN protocol specification for both terrestrial and non-terrestrial networks, notably satellites.","The higher capacity, long-range and robustness to Doppler effect make LR-FHSS a primary candidate for direct-to-satellite (DtS) connectivity for enabling Internet-of-things (IoT) in remote areas.","The LR-FHSS devices envisioned for DtS IoT will be primarily battery-powered.","Therefore, it is crucial to investigate the current consumption characteristics and Time-on-Air (ToA) of LR-FHSS technology.","However, to our knowledge, no prior research has presented the accurate ToA and current consumption models for this newly introduced scheme.","This paper addresses this shortcoming through extensive field measurements and the development of analytical models.","Specifically, we have measured the current consumption and ToA for variable transmit power, message payload, and two new LR-FHSS-based Data Rates (DR8 and DR9).","We also develop current consumption and ToA analytical models demonstrating a strong correlation with the measurement results exhibiting a relative error of less than 0.3%.","Thus, it confirms the validity of our models.","Conversely, the existing analytical models exhibit a higher relative error rate of -9.2 to 3.4% compared to our measurement results.","The presented in this paper results can be further used for simulators or in analytical studies to accurately model the on-air time and energy consumption of LR-FHSS devices."],"url":"http://arxiv.org/abs/2408.09954v1"}
{"created":"2024-08-19 12:47:47","title":"Weakly Supervised Pretraining and Multi-Annotator Supervised Finetuning for Facial Wrinkle Detection","abstract":"1. Research question: With the growing interest in skin diseases and skin aesthetics, the ability to predict facial wrinkles is becoming increasingly important. This study aims to evaluate whether a computational model, convolutional neural networks (CNN), can be trained for automated facial wrinkle segmentation. 2. Findings: Our study presents an effective technique for integrating data from multiple annotators and illustrates that transfer learning can enhance performance, resulting in dependable segmentation of facial wrinkles. 3. Meaning: This approach automates intricate and time-consuming tasks of wrinkle analysis with a deep learning framework. It could be used to facilitate skin treatments and diagnostics.","sentences":["1.","Research question: With the growing interest in skin diseases and skin aesthetics, the ability to predict facial wrinkles is becoming increasingly important.","This study aims to evaluate whether a computational model, convolutional neural networks (CNN), can be trained for automated facial wrinkle segmentation.","2. Findings: Our study presents an effective technique for integrating data from multiple annotators and illustrates that transfer learning can enhance performance, resulting in dependable segmentation of facial wrinkles.","3. Meaning: This approach automates intricate and time-consuming tasks of wrinkle analysis with a deep learning framework.","It could be used to facilitate skin treatments and diagnostics."],"url":"http://arxiv.org/abs/2408.09952v1"}
{"created":"2024-08-19 12:44:00","title":"Principle Driven Parameterized Fiber Model based on GPT-PINN Neural Network","abstract":"In cater the need of Beyond 5G communications, large numbers of data driven artificial intelligence based fiber models has been put forward as to utilize artificial intelligence's regression ability to predict pulse evolution in fiber transmission at a much faster speed compared with the traditional split step Fourier method. In order to increase the physical interpretabiliy, principle driven fiber models have been proposed which inserts the Nonlinear Schodinger Equation into their loss functions. However, regardless of either principle driven or data driven models, they need to be re-trained the whole model under different transmission conditions. Unfortunately, this situation can be unavoidable when conducting the fiber communication optimization work. If the scale of different transmission conditions is large, then the whole model needs to be retrained large numbers of time with relatively large scale of parameters which may consume higher time costs. Computing efficiency will be dragged down as well. In order to address this problem, we propose the principle driven parameterized fiber model in this manuscript. This model breaks down the predicted NLSE solution with respect to one set of transmission condition into the linear combination of several eigen solutions which were outputted by each pre-trained principle driven fiber model via the reduced basis method. Therefore, the model can greatly alleviate the heavy burden of re-training since only the linear combination coefficients need to be found when changing the transmission condition. Not only strong physical interpretability can the model posses, but also higher computing efficiency can be obtained. Under the demonstration, the model's computational complexity is 0.0113% of split step Fourier method and 1% of the previously proposed principle driven fiber model.","sentences":["In cater the need of Beyond 5G communications, large numbers of data driven artificial intelligence based fiber models has been put forward as to utilize artificial intelligence's regression ability to predict pulse evolution in fiber transmission at a much faster speed compared with the traditional split step Fourier method.","In order to increase the physical interpretabiliy, principle driven fiber models have been proposed which inserts the Nonlinear Schodinger Equation into their loss functions.","However, regardless of either principle driven or data driven models, they need to be re-trained the whole model under different transmission conditions.","Unfortunately, this situation can be unavoidable when conducting the fiber communication optimization work.","If the scale of different transmission conditions is large, then the whole model needs to be retrained large numbers of time with relatively large scale of parameters which may consume higher time costs.","Computing efficiency will be dragged down as well.","In order to address this problem, we propose the principle driven parameterized fiber model in this manuscript.","This model breaks down the predicted NLSE solution with respect to one set of transmission condition into the linear combination of several eigen solutions which were outputted by each pre-trained principle driven fiber model via the reduced basis method.","Therefore, the model can greatly alleviate the heavy burden of re-training since only the linear combination coefficients need to be found when changing the transmission condition.","Not only strong physical interpretability can the model posses, but also higher computing efficiency can be obtained.","Under the demonstration, the model's computational complexity is 0.0113% of split step Fourier method and 1% of the previously proposed principle driven fiber model."],"url":"http://arxiv.org/abs/2408.09951v1"}
{"created":"2024-08-19 12:32:50","title":"Calibrating Noise for Group Privacy in Subsampled Mechanisms","abstract":"Given a group size m and a sensitive dataset D, group privacy (GP) releases information about D with the guarantee that the adversary cannot infer with high confidence whether the underlying data is D or a neighboring dataset D' that differs from D by m records. GP generalizes the well-established notion of differential privacy (DP) for protecting individuals' privacy; in particular, when m=1, GP reduces to DP. Compared to DP, GP is capable of protecting the sensitive aggregate information of a group of up to m individuals, e.g., the average annual income among members of a yacht club. Despite its longstanding presence in the research literature and its promising applications, GP is often treated as an afterthought, with most approaches first developing a DP mechanism and then using a generic conversion to adapt it for GP, treating the DP solution as a black box. As we point out in the paper, this methodology is suboptimal when the underlying DP solution involves subsampling, e.g., in the classic DP-SGD method for training deep learning models. In this case, the DP-to-GP conversion is overly pessimistic in its analysis, leading to low utility in the published results under GP.   Motivated by this, we propose a novel analysis framework that provides tight privacy accounting for subsampled GP mechanisms. Instead of converting a black-box DP mechanism to GP, our solution carefully analyzes and utilizes the inherent randomness in subsampled mechanisms, leading to a substantially improved bound on the privacy loss with respect to GP. The proposed solution applies to a wide variety of foundational mechanisms with subsampling. Extensive experiments with real datasets demonstrate that compared to the baseline convert-from-blackbox-DP approach, our GP mechanisms achieve noise reductions of over an order of magnitude in several practical settings, including deep neural network training.","sentences":["Given a group size m and a sensitive dataset D, group privacy (GP) releases information about D with the guarantee that the adversary cannot infer with high confidence whether the underlying data is D or a neighboring dataset D' that differs from D by m records.","GP generalizes the well-established notion of differential privacy (DP) for protecting individuals' privacy; in particular, when m=1, GP reduces to DP.","Compared to DP, GP is capable of protecting the sensitive aggregate information of a group of up to m individuals, e.g., the average annual income among members of a yacht club.","Despite its longstanding presence in the research literature and its promising applications, GP is often treated as an afterthought, with most approaches first developing a DP mechanism and then using a generic conversion to adapt it for GP, treating the DP solution as a black box.","As we point out in the paper, this methodology is suboptimal when the underlying DP solution involves subsampling, e.g., in the classic DP-SGD method for training deep learning models.","In this case, the DP-to-GP conversion is overly pessimistic in its analysis, leading to low utility in the published results under GP.   ","Motivated by this, we propose a novel analysis framework that provides tight privacy accounting for subsampled GP mechanisms.","Instead of converting a black-box DP mechanism to GP, our solution carefully analyzes and utilizes the inherent randomness in subsampled mechanisms, leading to a substantially improved bound on the privacy loss with respect to GP.","The proposed solution applies to a wide variety of foundational mechanisms with subsampling.","Extensive experiments with real datasets demonstrate that compared to the baseline convert-from-blackbox-DP approach, our GP mechanisms achieve noise reductions of over an order of magnitude in several practical settings, including deep neural network training."],"url":"http://arxiv.org/abs/2408.09943v1"}
{"created":"2024-08-19 12:21:34","title":"\"Image, Tell me your story!\" Predicting the original meta-context of visual misinformation","abstract":"To assist human fact-checkers, researchers have developed automated approaches for visual misinformation detection. These methods assign veracity scores by identifying inconsistencies between the image and its caption, or by detecting forgeries in the image. However, they neglect a crucial point of the human fact-checking process: identifying the original meta-context of the image. By explaining what is actually true about the image, fact-checkers can better detect misinformation, focus their efforts on check-worthy visual content, engage in counter-messaging before misinformation spreads widely, and make their explanation more convincing. Here, we fill this gap by introducing the task of automated image contextualization. We create 5Pils, a dataset of 1,676 fact-checked images with question-answer pairs about their original meta-context. Annotations are based on the 5 Pillars fact-checking framework. We implement a first baseline that grounds the image in its original meta-context using the content of the image and textual evidence retrieved from the open web. Our experiments show promising results while highlighting several open challenges in retrieval and reasoning. We make our code and data publicly available.","sentences":["To assist human fact-checkers, researchers have developed automated approaches for visual misinformation detection.","These methods assign veracity scores by identifying inconsistencies between the image and its caption, or by detecting forgeries in the image.","However, they neglect a crucial point of the human fact-checking process: identifying the original meta-context of the image.","By explaining what is actually true about the image, fact-checkers can better detect misinformation, focus their efforts on check-worthy visual content, engage in counter-messaging before misinformation spreads widely, and make their explanation more convincing.","Here, we fill this gap by introducing the task of automated image contextualization.","We create 5Pils, a dataset of 1,676 fact-checked images with question-answer pairs about their original meta-context.","Annotations are based on the 5 Pillars fact-checking framework.","We implement a first baseline that grounds the image in its original meta-context using the content of the image and textual evidence retrieved from the open web.","Our experiments show promising results while highlighting several open challenges in retrieval and reasoning.","We make our code and data publicly available."],"url":"http://arxiv.org/abs/2408.09939v1"}
{"created":"2024-08-19 12:13:53","title":"Privacy Technologies for Financial Intelligence","abstract":"Financial crimes like terrorism financing and money laundering can have real impacts on society, including the abuse and mismanagement of public funds, increase in societal problems such as drug trafficking and illicit gambling with attendant economic costs, and loss of innocent lives in the case of terrorism activities. Complex financial crimes can be hard to detect primarily because data related to different pieces of the overall puzzle is usually distributed across a network of financial institutions, regulators, and law-enforcement agencies and they cannot be easily shared due to privacy constraints. Recent advances in Privacy-Preserving Data Matching and Machine Learning provide an opportunity for regulators and the financial industry to come together to solve the risk-discovery problem with technology. This paper provides a survey of the financial intelligence landscape and where opportunities lie for privacy technologies to improve the state-of-the-art in financial-crime detection.","sentences":["Financial crimes like terrorism financing and money laundering can have real impacts on society, including the abuse and mismanagement of public funds, increase in societal problems such as drug trafficking and illicit gambling with attendant economic costs, and loss of innocent lives in the case of terrorism activities.","Complex financial crimes can be hard to detect primarily because data related to different pieces of the overall puzzle is usually distributed across a network of financial institutions, regulators, and law-enforcement agencies and they cannot be easily shared due to privacy constraints.","Recent advances in Privacy-Preserving Data Matching and Machine Learning provide an opportunity for regulators and the financial industry to come together to solve the risk-discovery problem with technology.","This paper provides a survey of the financial intelligence landscape and where opportunities lie for privacy technologies to improve the state-of-the-art in financial-crime detection."],"url":"http://arxiv.org/abs/2408.09935v1"}
{"created":"2024-08-19 12:12:29","title":"SZU-AFS Antispoofing System for the ASVspoof 5 Challenge","abstract":"This paper presents the SZU-AFS anti-spoofing system, designed for Track 1 of the ASVspoof 5 Challenge under open conditions. The system is built with four stages: selecting a baseline model, exploring effective data augmentation (DA) methods for fine-tuning, applying a co-enhancement strategy based on gradient norm aware minimization (GAM) for secondary fine-tuning, and fusing logits scores from the two best-performing fine-tuned models. The system utilizes the Wav2Vec2 front-end feature extractor and the AASIST back-end classifier as the baseline model. During model fine-tuning, three distinct DA policies have been investigated: single-DA, random-DA, and cascade-DA. Moreover, the employed GAM-based co-enhancement strategy, designed to fine-tune the augmented model at both data and optimizer levels, helps the Adam optimizer find flatter minima, thereby boosting model generalization. Overall, the final fusion system achieves a minDCF of 0.115 and an EER of 4.04% on the evaluation set.","sentences":["This paper presents the SZU-AFS anti-spoofing system, designed for Track 1 of the ASVspoof 5 Challenge under open conditions.","The system is built with four stages: selecting a baseline model, exploring effective data augmentation (DA) methods for fine-tuning, applying a co-enhancement strategy based on gradient norm aware minimization (GAM) for secondary fine-tuning, and fusing logits scores from the two best-performing fine-tuned models.","The system utilizes the Wav2Vec2 front-end feature extractor and the AASIST back-end classifier as the baseline model.","During model fine-tuning, three distinct DA policies have been investigated: single-DA, random-DA, and cascade-DA.","Moreover, the employed GAM-based co-enhancement strategy, designed to fine-tune the augmented model at both data and optimizer levels, helps the Adam optimizer find flatter minima, thereby boosting model generalization.","Overall, the final fusion system achieves a minDCF of 0.115 and an EER of 4.04% on the evaluation set."],"url":"http://arxiv.org/abs/2408.09933v1"}
{"created":"2024-08-19 12:07:42","title":"Data Augmentation of Contrastive Learning is Estimating Positive-incentive Noise","abstract":"Inspired by the idea of Positive-incentive Noise (Pi-Noise or $\\pi$-Noise) that aims at learning the reliable noise beneficial to tasks, we scientifically investigate the connection between contrastive learning and $\\pi$-noise in this paper. By converting the contrastive loss to an auxiliary Gaussian distribution to quantitatively measure the difficulty of the specific contrastive model under the information theory framework, we properly define the task entropy, the core concept of $\\pi$-noise, of contrastive learning. It is further proved that the predefined data augmentation in the standard contrastive learning paradigm can be regarded as a kind of point estimation of $\\pi$-noise. Inspired by the theoretical study, a framework that develops a $\\pi$-noise generator to learn the beneficial noise (instead of estimation) as data augmentations for contrast is proposed. The designed framework can be applied to diverse types of data and is also completely compatible with the existing contrastive models. From the visualization, we surprisingly find that the proposed method successfully learns effective augmentations.","sentences":["Inspired by the idea of Positive-incentive Noise (Pi-Noise or $\\pi$-Noise) that aims at learning the reliable noise beneficial to tasks, we scientifically investigate the connection between contrastive learning and $\\pi$-noise in this paper.","By converting the contrastive loss to an auxiliary Gaussian distribution to quantitatively measure the difficulty of the specific contrastive model under the information theory framework, we properly define the task entropy, the core concept of $\\pi$-noise, of contrastive learning.","It is further proved that the predefined data augmentation in the standard contrastive learning paradigm can be regarded as a kind of point estimation of $\\pi$-noise.","Inspired by the theoretical study, a framework that develops a $\\pi$-noise generator to learn the beneficial noise (instead of estimation) as data augmentations for contrast is proposed.","The designed framework can be applied to diverse types of data and is also completely compatible with the existing contrastive models.","From the visualization, we surprisingly find that the proposed method successfully learns effective augmentations."],"url":"http://arxiv.org/abs/2408.09929v1"}
{"created":"2024-08-19 12:03:51","title":"WoW -- A System for Self-Service Collaborative Design Workshops","abstract":"In many working environments, users have to solve complex problems relying on large and multi-source data. Such problems require several experts to collaborate on solving them, or a single analyst to reconcile multiple complementary standpoints. Previous research has shown that wall-sized displays supports different collaboration styles, based most often on abstract tasks as proxies of real work. We present the design and implementation of WoW, short for ``Workspace on Wall'', a multi-user Web-based portal for collaborative meetings and workshops in multi-surface environments. We report on a two-year effort spanning context inquiry studies, system design iterations, development, and real testing rounds targeting design engineers in the tire industry. The pneumatic tires found on the market result from a highly collaborative and iterative development process that reconciles conflicting constraints through a series of product design workshops. WoW was found to be a flexible solution to build multi-view set-ups in a self-service manner and an effective means to access more content at once. Our users also felt more engaged in their collaborative problem-solving work using WoW than in conventional meeting rooms.","sentences":["In many working environments, users have to solve complex problems relying on large and multi-source data.","Such problems require several experts to collaborate on solving them, or a single analyst to reconcile multiple complementary standpoints.","Previous research has shown that wall-sized displays supports different collaboration styles, based most often on abstract tasks as proxies of real work.","We present the design and implementation of WoW, short for ``Workspace on Wall'', a multi-user Web-based portal for collaborative meetings and workshops in multi-surface environments.","We report on a two-year effort spanning context inquiry studies, system design iterations, development, and real testing rounds targeting design engineers in the tire industry.","The pneumatic tires found on the market result from a highly collaborative and iterative development process that reconciles conflicting constraints through a series of product design workshops.","WoW was found to be a flexible solution to build multi-view set-ups in a self-service manner and an effective means to access more content at once.","Our users also felt more engaged in their collaborative problem-solving work using WoW than in conventional meeting rooms."],"url":"http://arxiv.org/abs/2408.09926v1"}
{"created":"2024-08-19 11:40:20","title":"Active Learning for Identifying Disaster-Related Tweets: A Comparison with Keyword Filtering and Generic Fine-Tuning","abstract":"Information from social media can provide essential information for emergency response during natural disasters in near real-time. However, it is difficult to identify the disaster-related posts among the large amounts of unstructured data available. Previous methods often use keyword filtering, topic modelling or classification-based techniques to identify such posts. Active Learning (AL) presents a promising sub-field of Machine Learning (ML) that has not been used much in the field of text classification of social media content. This study therefore investigates the potential of AL for identifying disaster-related Tweets. We compare a keyword filtering approach, a RoBERTa model fine-tuned with generic data from CrisisLex, a base RoBERTa model trained with AL and a fine-tuned RoBERTa model trained with AL regarding classification performance. For testing, data from CrisisLex and manually labelled data from the 2021 flood in Germany and the 2023 Chile forest fires were considered. The results show that generic fine-tuning combined with 10 rounds of AL outperformed all other approaches. Consequently, a broadly applicable model for the identification of disaster-related Tweets could be trained with very little labelling effort. The model can be applied to use cases beyond this study and provides a useful tool for further research in social media analysis.","sentences":["Information from social media can provide essential information for emergency response during natural disasters in near real-time.","However, it is difficult to identify the disaster-related posts among the large amounts of unstructured data available.","Previous methods often use keyword filtering, topic modelling or classification-based techniques to identify such posts.","Active Learning (AL) presents a promising sub-field of Machine Learning (ML) that has not been used much in the field of text classification of social media content.","This study therefore investigates the potential of AL for identifying disaster-related Tweets.","We compare a keyword filtering approach, a RoBERTa model fine-tuned with generic data from CrisisLex, a base RoBERTa model trained with AL and a fine-tuned RoBERTa model trained with AL regarding classification performance.","For testing, data from CrisisLex and manually labelled data from the 2021 flood in Germany and the 2023 Chile forest fires were considered.","The results show that generic fine-tuning combined with 10 rounds of AL outperformed all other approaches.","Consequently, a broadly applicable model for the identification of disaster-related Tweets could be trained with very little labelling effort.","The model can be applied to use cases beyond this study and provides a useful tool for further research in social media analysis."],"url":"http://arxiv.org/abs/2408.09914v1"}
{"created":"2024-08-19 11:09:15","title":"Instruction-Based Molecular Graph Generation with Unified Text-Graph Diffusion Model","abstract":"Recent advancements in computational chemistry have increasingly focused on synthesizing molecules based on textual instructions. Integrating graph generation with these instructions is complex, leading most current methods to use molecular sequences with pre-trained large language models. In response to this challenge, we propose a novel framework, named $\\textbf{UTGDiff (Unified Text-Graph Diffusion Model)}$, which utilizes language models for discrete graph diffusion to generate molecular graphs from instructions. UTGDiff features a unified text-graph transformer as the denoising network, derived from pre-trained language models and minimally modified to process graph data through attention bias. Our experimental results demonstrate that UTGDiff consistently outperforms sequence-based baselines in tasks involving instruction-based molecule generation and editing, achieving superior performance with fewer parameters given an equivalent level of pretraining corpus. Our code is availble at https://github.com/ran1812/UTGDiff.","sentences":["Recent advancements in computational chemistry have increasingly focused on synthesizing molecules based on textual instructions.","Integrating graph generation with these instructions is complex, leading most current methods to use molecular sequences with pre-trained large language models.","In response to this challenge, we propose a novel framework, named $\\textbf{UTGDiff (Unified Text-Graph Diffusion Model)}$, which utilizes language models for discrete graph diffusion to generate molecular graphs from instructions.","UTGDiff features a unified text-graph transformer as the denoising network, derived from pre-trained language models and minimally modified to process graph data through attention bias.","Our experimental results demonstrate that UTGDiff consistently outperforms sequence-based baselines in tasks involving instruction-based molecule generation and editing, achieving superior performance with fewer parameters given an equivalent level of pretraining corpus.","Our code is availble at https://github.com/ran1812/UTGDiff."],"url":"http://arxiv.org/abs/2408.09896v1"}
{"created":"2024-08-19 11:09:12","title":"Performance Law of Large Language Models","abstract":"Guided by the belief of the scaling law, large language models (LLMs) have achieved impressive performance in recent years. However, scaling law only gives a qualitative estimation of loss, which is influenced by various factors such as model architectures, data distributions, tokenizers, and computation precision. Thus, estimating the real performance of LLMs with different training settings rather than loss may be quite useful in practical development. In this article, we present an empirical equation named \"Performance Law\" to directly predict the MMLU score of an LLM, which is a widely used metric to indicate the general capability of LLMs in real-world conversations and applications. Based on only a few key hyperparameters of the LLM architecture and the size of training data, we obtain a quite accurate MMLU prediction of various LLMs with diverse sizes and architectures developed by different organizations in different years. Performance law can be used to guide the choice of LLM architecture and the effective allocation of computational resources without extensive experiments.","sentences":["Guided by the belief of the scaling law, large language models (LLMs) have achieved impressive performance in recent years.","However, scaling law only gives a qualitative estimation of loss, which is influenced by various factors such as model architectures, data distributions, tokenizers, and computation precision.","Thus, estimating the real performance of LLMs with different training settings rather than loss may be quite useful in practical development.","In this article, we present an empirical equation named \"Performance Law\" to directly predict the MMLU score of an LLM, which is a widely used metric to indicate the general capability of LLMs in real-world conversations and applications.","Based on only a few key hyperparameters of the LLM architecture and the size of training data, we obtain a quite accurate MMLU prediction of various LLMs with diverse sizes and architectures developed by different organizations in different years.","Performance law can be used to guide the choice of LLM architecture and the effective allocation of computational resources without extensive experiments."],"url":"http://arxiv.org/abs/2408.09895v1"}
{"created":"2024-08-19 11:07:05","title":"Differential Private Stochastic Optimization with Heavy-tailed Data: Towards Optimal Rates","abstract":"We study convex optimization problems under differential privacy (DP). With heavy-tailed gradients, existing works achieve suboptimal rates. The main obstacle is that existing gradient estimators have suboptimal tail properties, resulting in a superfluous factor of $d$ in the union bound. In this paper, we explore algorithms achieving optimal rates of DP optimization with heavy-tailed gradients. Our first method is a simple clipping approach. Under bounded $p$-th order moments of gradients, with $n$ samples, it achieves $\\tilde{O}(\\sqrt{d/n}+\\sqrt{d}(\\sqrt{d}/n\\epsilon)^{1-1/p})$ population risk with $\\epsilon\\leq 1/\\sqrt{d}$. We then propose an iterative updating method, which is more complex but achieves this rate for all $\\epsilon\\leq 1$. The results significantly improve over existing methods. Such improvement relies on a careful treatment of the tail behavior of gradient estimators. Our results match the minimax lower bound in \\cite{kamath2022improved}, indicating that the theoretical limit of stochastic convex optimization under DP is achievable.","sentences":["We study convex optimization problems under differential privacy (DP).","With heavy-tailed gradients, existing works achieve suboptimal rates.","The main obstacle is that existing gradient estimators have suboptimal tail properties, resulting in a superfluous factor of $d$ in the union bound.","In this paper, we explore algorithms achieving optimal rates of DP optimization with heavy-tailed gradients.","Our first method is a simple clipping approach.","Under bounded $p$-th order moments of gradients, with $n$ samples, it achieves $\\tilde{O}(\\sqrt{d/n}+\\sqrt{d}(\\sqrt{d}/n\\epsilon)^{1-1/p})$ population risk with $\\epsilon\\leq 1/\\sqrt{d}$.","We then propose an iterative updating method, which is more complex but achieves this rate for all $\\epsilon\\leq 1$.","The results significantly improve over existing methods.","Such improvement relies on a careful treatment of the tail behavior of gradient estimators.","Our results match the minimax lower bound in \\cite{kamath2022improved}, indicating that the theoretical limit of stochastic convex optimization under DP is achievable."],"url":"http://arxiv.org/abs/2408.09891v1"}
{"created":"2024-08-19 10:59:04","title":"Joint Auction in the Online Advertising Market","abstract":"Online advertising is a primary source of income for e-commerce platforms. In the current advertising pattern, the oriented targets are the online store owners who are willing to pay extra fees to enhance the position of their stores. On the other hand, brand suppliers are also desirable to advertise their products in stores to boost brand sales. However, the currently used advertising mode cannot satisfy the demand of both stores and brand suppliers simultaneously. To address this, we innovatively propose a joint advertising model termed Joint Auction, allowing brand suppliers and stores to collaboratively bid for advertising slots, catering to both their needs. However, conventional advertising auction mechanisms are not suitable for this novel scenario. In this paper, we propose JRegNet, a neural network architecture for the optimal joint auction design, to generate mechanisms that can achieve the optimal revenue and guarantee near dominant strategy incentive compatibility and individual rationality. Finally, multiple experiments are conducted on synthetic and real data to demonstrate that our proposed joint auction significantly improves platform revenue compared to the known baselines.","sentences":["Online advertising is a primary source of income for e-commerce platforms.","In the current advertising pattern, the oriented targets are the online store owners who are willing to pay extra fees to enhance the position of their stores.","On the other hand, brand suppliers are also desirable to advertise their products in stores to boost brand sales.","However, the currently used advertising mode cannot satisfy the demand of both stores and brand suppliers simultaneously.","To address this, we innovatively propose a joint advertising model termed Joint Auction, allowing brand suppliers and stores to collaboratively bid for advertising slots, catering to both their needs.","However, conventional advertising auction mechanisms are not suitable for this novel scenario.","In this paper, we propose JRegNet, a neural network architecture for the optimal joint auction design, to generate mechanisms that can achieve the optimal revenue and guarantee near dominant strategy incentive compatibility and individual rationality.","Finally, multiple experiments are conducted on synthetic and real data to demonstrate that our proposed joint auction significantly improves platform revenue compared to the known baselines."],"url":"http://arxiv.org/abs/2408.09885v1"}
{"created":"2024-08-19 10:46:19","title":"Uncertainty Quantification of Pre-Trained and Fine-Tuned Surrogate Models using Conformal Prediction","abstract":"Data-driven surrogate models have shown immense potential as quick, inexpensive approximations to complex numerical and experimental modelling tasks. However, most surrogate models characterising physical systems do not quantify their uncertainty, rendering their predictions unreliable, and needing further validation. Though Bayesian approximations offer some solace in estimating the error associated with these models, they cannot provide they cannot provide guarantees, and the quality of their inferences depends on the availability of prior information and good approximations to posteriors for complex problems. This is particularly pertinent to multi-variable or spatio-temporal problems. Our work constructs and formalises a conformal prediction framework that satisfies marginal coverage for spatio-temporal predictions in a model-agnostic manner, requiring near-zero computational costs. The paper provides an extensive empirical study of the application of the framework to ascertain valid error bars that provide guaranteed coverage across the surrogate model's domain of operation. The application scope of our work extends across a large range of spatio-temporal models, ranging from solving partial differential equations to weather forecasting. Through the applications, the paper looks at providing statistically valid error bars for deterministic models, as well as crafting guarantees to the error bars of probabilistic models. The paper concludes with a viable conformal prediction formalisation that provides guaranteed coverage of the surrogate model, regardless of model architecture, and its training regime and is unbothered by the curse of dimensionality.","sentences":["Data-driven surrogate models have shown immense potential as quick, inexpensive approximations to complex numerical and experimental modelling tasks.","However, most surrogate models characterising physical systems do not quantify their uncertainty, rendering their predictions unreliable, and needing further validation.","Though Bayesian approximations offer some solace in estimating the error associated with these models, they cannot provide they cannot provide guarantees, and the quality of their inferences depends on the availability of prior information and good approximations to posteriors for complex problems.","This is particularly pertinent to multi-variable or spatio-temporal problems.","Our work constructs and formalises a conformal prediction framework that satisfies marginal coverage for spatio-temporal predictions in a model-agnostic manner, requiring near-zero computational costs.","The paper provides an extensive empirical study of the application of the framework to ascertain valid error bars that provide guaranteed coverage across the surrogate model's domain of operation.","The application scope of our work extends across a large range of spatio-temporal models, ranging from solving partial differential equations to weather forecasting.","Through the applications, the paper looks at providing statistically valid error bars for deterministic models, as well as crafting guarantees to the error bars of probabilistic models.","The paper concludes with a viable conformal prediction formalisation that provides guaranteed coverage of the surrogate model, regardless of model architecture, and its training regime and is unbothered by the curse of dimensionality."],"url":"http://arxiv.org/abs/2408.09881v1"}
{"created":"2024-08-19 10:24:57","title":"New spectral imaging biomarkers for sepsis and mortality in intensive care","abstract":"With sepsis remaining a leading cause of mortality, early identification of septic patients and those at high risk of death is a challenge of high socioeconomic importance. The driving hypothesis of this study was that hyperspectral imaging (HSI) could provide novel biomarkers for sepsis diagnosis and treatment management due to its potential to monitor microcirculatory alterations. We conducted a comprehensive study involving HSI data of the palm and fingers from more than 480 patients on the day of their intensive care unit (ICU) admission. The findings demonstrate that HSI measurements can predict sepsis with an area under the receiver operating characteristic curve (AUROC) of 0.80 (95 % confidence interval (CI) [0.76; 0.84]) and mortality with an AUROC of 0.72 (95 % CI [0.65; 0.79]). The predictive performance improves substantially when additional clinical data is incorporated, leading to an AUROC of up to 0.94 (95 % CI [0.92; 0.96]) for sepsis and 0.84 (95 % CI [0.78; 0.89]) for mortality. We conclude that HSI presents novel imaging biomarkers for the rapid, non-invasive prediction of sepsis and mortality, suggesting its potential as an important modality for guiding diagnosis and treatment.","sentences":["With sepsis remaining a leading cause of mortality, early identification of septic patients and those at high risk of death is a challenge of high socioeconomic importance.","The driving hypothesis of this study was that hyperspectral imaging (HSI) could provide novel biomarkers for sepsis diagnosis and treatment management due to its potential to monitor microcirculatory alterations.","We conducted a comprehensive study involving HSI data of the palm and fingers from more than 480 patients on the day of their intensive care unit (ICU) admission.","The findings demonstrate that HSI measurements can predict sepsis with an area under the receiver operating characteristic curve (AUROC) of 0.80 (95 % confidence interval (CI)","[0.76; 0.84]) and mortality with an AUROC of 0.72 (95 % CI","[0.65; 0.79]).","The predictive performance improves substantially when additional clinical data is incorporated, leading to an AUROC of up to 0.94 (95 % CI","[0.92; 0.96]) for sepsis and 0.84 (95 % CI","[0.78; 0.89]) for mortality.","We conclude that HSI presents novel imaging biomarkers for the rapid, non-invasive prediction of sepsis and mortality, suggesting its potential as an important modality for guiding diagnosis and treatment."],"url":"http://arxiv.org/abs/2408.09873v1"}
{"created":"2024-08-19 10:12:52","title":"MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation","abstract":"Explainable Recommendation task is designed to receive a pair of user and item and output explanations to justify why an item is recommended to a user. Many models treat review-generation as a proxy of explainable recommendation. Although they are able to generate fluent and grammatical sentences, they suffer from generality and hallucination issues. We propose a personalized, aspect-controlled model called Multi-Aspect Prompt LEarner (MAPLE), in which it integrates aspect category as another input dimension to facilitate the memorization of fine-grained aspect terms. Experiments on two real-world review datasets in restaurant domain show that MAPLE outperforms the baseline review-generation models in terms of text and feature diversity while maintaining excellent coherence and factual relevance. We further treat MAPLE as a retriever component in the retriever-reader framework and employ a Large-Language Model (LLM) as the reader, showing that MAPLE's explanation along with the LLM's comprehension ability leads to enriched and personalized explanation as a result. We will release the code and data in this http upon acceptance.","sentences":["Explainable Recommendation task is designed to receive a pair of user and item and output explanations to justify why an item is recommended to a user.","Many models treat review-generation as a proxy of explainable recommendation.","Although they are able to generate fluent and grammatical sentences, they suffer from generality and hallucination issues.","We propose a personalized, aspect-controlled model called Multi-Aspect Prompt LEarner (MAPLE), in which it integrates aspect category as another input dimension to facilitate the memorization of fine-grained aspect terms.","Experiments on two real-world review datasets in restaurant domain show that MAPLE outperforms the baseline review-generation models in terms of text and feature diversity while maintaining excellent coherence and factual relevance.","We further treat MAPLE as a retriever component in the retriever-reader framework and employ a Large-Language Model (LLM) as the reader, showing that MAPLE's explanation along with the LLM's comprehension ability leads to enriched and personalized explanation as a result.","We will release the code and data in this http upon acceptance."],"url":"http://arxiv.org/abs/2408.09865v1"}
{"created":"2024-08-19 09:51:02","title":"Importance Weighting Can Help Large Language Models Self-Improve","abstract":"Large language models (LLMs) have shown remarkable capability in numerous tasks and applications. However, fine-tuning LLMs using high-quality datasets under external supervision remains prohibitively expensive. In response, LLM self-improvement approaches have been vibrantly developed recently. The typical paradigm of LLM self-improvement involves training LLM on self-generated data, part of which may be detrimental and should be filtered out due to the unstable data quality. While current works primarily employs filtering strategies based on answer correctness, in this paper, we demonstrate that filtering out correct but with high distribution shift extent (DSE) samples could also benefit the results of self-improvement. Given that the actual sample distribution is usually inaccessible, we propose a new metric called DS weight to approximate DSE, inspired by the Importance Weighting methods. Consequently, we integrate DS weight with self-consistency to comprehensively filter the self-generated samples and fine-tune the language model. Experiments show that with only a tiny valid set (up to 5\\% size of the training set) to compute DS weight, our approach can notably promote the reasoning ability of current LLM self-improvement methods. The resulting performance is on par with methods that rely on external supervision from pre-trained reward models.","sentences":["Large language models (LLMs) have shown remarkable capability in numerous tasks and applications.","However, fine-tuning LLMs using high-quality datasets under external supervision remains prohibitively expensive.","In response, LLM self-improvement approaches have been vibrantly developed recently.","The typical paradigm of LLM self-improvement involves training LLM on self-generated data, part of which may be detrimental and should be filtered out due to the unstable data quality.","While current works primarily employs filtering strategies based on answer correctness, in this paper, we demonstrate that filtering out correct but with high distribution shift extent (DSE) samples could also benefit the results of self-improvement.","Given that the actual sample distribution is usually inaccessible, we propose a new metric called DS weight to approximate DSE, inspired by the Importance Weighting methods.","Consequently, we integrate DS weight with self-consistency to comprehensively filter the self-generated samples and fine-tune the language model.","Experiments show that with only a tiny valid set (up to 5\\% size of the training set) to compute DS weight, our approach can notably promote the reasoning ability of current LLM self-improvement methods.","The resulting performance is on par with methods that rely on external supervision from pre-trained reward models."],"url":"http://arxiv.org/abs/2408.09849v1"}
{"created":"2024-08-19 09:50:20","title":"Fashion Image-to-Image Translation for Complementary Item Retrieval","abstract":"The increasing demand for online fashion retail has boosted research in fashion compatibility modeling and item retrieval, focusing on matching user queries (textual descriptions or reference images) with compatible fashion items. A key challenge is top-bottom retrieval, where precise compatibility modeling is essential. Traditional methods, often based on Bayesian Personalized Ranking (BPR), have shown limited performance. Recent efforts have explored using generative models in compatibility modeling and item retrieval, where generated images serve as additional inputs. However, these approaches often overlook the quality of generated images, which could be crucial for model performance. Additionally, generative models typically require large datasets, posing challenges when such data is scarce.   To address these issues, we introduce the Generative Compatibility Model (GeCo), a two-stage approach that improves fashion image retrieval through paired image-to-image translation. First, the Complementary Item Generation Model (CIGM), built on Conditional Generative Adversarial Networks (GANs), generates target item images (e.g., bottoms) from seed items (e.g., tops), offering conditioning signals for retrieval. These generated samples are then integrated into GeCo, enhancing compatibility modeling and retrieval accuracy. Evaluations on three datasets show that GeCo outperforms state-of-the-art baselines. Key contributions include: (i) the GeCo model utilizing paired image-to-image translation within the Composed Image Retrieval framework, (ii) comprehensive evaluations on benchmark datasets, and (iii) the release of a new Fashion Taobao dataset designed for top-bottom retrieval, promoting further research.","sentences":["The increasing demand for online fashion retail has boosted research in fashion compatibility modeling and item retrieval, focusing on matching user queries (textual descriptions or reference images) with compatible fashion items.","A key challenge is top-bottom retrieval, where precise compatibility modeling is essential.","Traditional methods, often based on Bayesian Personalized Ranking (BPR), have shown limited performance.","Recent efforts have explored using generative models in compatibility modeling and item retrieval, where generated images serve as additional inputs.","However, these approaches often overlook the quality of generated images, which could be crucial for model performance.","Additionally, generative models typically require large datasets, posing challenges when such data is scarce.   ","To address these issues, we introduce the Generative Compatibility Model (GeCo), a two-stage approach that improves fashion image retrieval through paired image-to-image translation.","First, the Complementary Item Generation Model (CIGM), built on Conditional Generative Adversarial Networks (GANs), generates target item images (e.g., bottoms) from seed items (e.g., tops), offering conditioning signals for retrieval.","These generated samples are then integrated into GeCo, enhancing compatibility modeling and retrieval accuracy.","Evaluations on three datasets show that GeCo outperforms state-of-the-art baselines.","Key contributions include: (i) the GeCo model utilizing paired image-to-image translation within the Composed Image Retrieval framework, (ii) comprehensive evaluations on benchmark datasets, and (iii) the release of a new Fashion Taobao dataset designed for top-bottom retrieval, promoting further research."],"url":"http://arxiv.org/abs/2408.09847v1"}
{"created":"2024-08-19 09:48:50","title":"Continual Dialogue State Tracking via Reason-of-Select Distillation","abstract":"An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge. Dialogue State Tracking (DST), vital in these systems, often involves learning new services and confronting catastrophic forgetting, along with a critical capability loss termed the \"Value Selection Quandary.\" To address these challenges, we introduce the Reason-of-Select (RoS) distillation method by enhancing smaller models with a novel 'meta-reasoning' capability. Meta-reasoning employs an enhanced multi-domain perspective, combining fragments of meta-knowledge from domain-specific dialogues during continual learning. This transcends traditional single-perspective reasoning. The domain bootstrapping process enhances the model's ability to dissect intricate dialogues from multiple possible values. Its domain-agnostic property aligns data distribution across different domains, effectively mitigating forgetting. Additionally, two novel improvements, \"multi-value resolution\" strategy and Semantic Contrastive Reasoning Selection method, significantly enhance RoS by generating DST-specific selection chains and mitigating hallucinations in teachers' reasoning, ensuring effective and reliable knowledge transfer. Extensive experiments validate the exceptional performance and robust generalization capabilities of our method. The source code is provided for reproducibility.","sentences":["An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge.","Dialogue State Tracking (DST), vital in these systems, often involves learning new services and confronting catastrophic forgetting, along with a critical capability loss termed the \"Value Selection Quandary.\"","To address these challenges, we introduce the Reason-of-Select (RoS) distillation method by enhancing smaller models with a novel 'meta-reasoning' capability.","Meta-reasoning employs an enhanced multi-domain perspective, combining fragments of meta-knowledge from domain-specific dialogues during continual learning.","This transcends traditional single-perspective reasoning.","The domain bootstrapping process enhances the model's ability to dissect intricate dialogues from multiple possible values.","Its domain-agnostic property aligns data distribution across different domains, effectively mitigating forgetting.","Additionally, two novel improvements, \"multi-value resolution\" strategy and Semantic Contrastive Reasoning Selection method, significantly enhance RoS by generating DST-specific selection chains and mitigating hallucinations in teachers' reasoning, ensuring effective and reliable knowledge transfer.","Extensive experiments validate the exceptional performance and robust generalization capabilities of our method.","The source code is provided for reproducibility."],"url":"http://arxiv.org/abs/2408.09846v1"}
{"created":"2024-08-19 09:41:16","title":"Can we measure the impact of a database?","abstract":"In disseminating scientific and statistical data, on-line databases have almost completely replaced traditional paper-based media such as journals and reference works. Given this, can we measure the impact of a database in the same way that we measure an author's or journal's impact? To do this, we need somehow to represent a database as a set of publications, and databases typically allow a large number of possible decompositions into parts, any of which could be treated as a publication.   We show that the definition of the h-index naturally extends to hierarchies, so that if a database admits some kind of hierarchical interpretation we can use this as one measure of the importance of a database; moreover, this can be computed as efficiently as one can compute the normal h-index. This also gives us a decomposition of the database that might be used for other purposes such as giving credit to the curators or contributors to the database. We illustrate the process by analyzing three widely used databases.","sentences":["In disseminating scientific and statistical data, on-line databases have almost completely replaced traditional paper-based media such as journals and reference works.","Given this, can we measure the impact of a database in the same way that we measure an author's or journal's impact?","To do this, we need somehow to represent a database as a set of publications, and databases typically allow a large number of possible decompositions into parts, any of which could be treated as a publication.   ","We show that the definition of the h-index naturally extends to hierarchies, so that if a database admits some kind of hierarchical interpretation we can use this as one measure of the importance of a database; moreover, this can be computed as efficiently as one can compute the normal h-index.","This also gives us a decomposition of the database that might be used for other purposes such as giving credit to the curators or contributors to the database.","We illustrate the process by analyzing three widely used databases."],"url":"http://arxiv.org/abs/2408.09842v1"}
{"created":"2024-08-19 09:36:07","title":"Machine Learning with Physics Knowledge for Prediction: A Survey","abstract":"This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning.","sentences":["This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations.","These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases.","The survey has two parts.","The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation.","The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion.","Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning."],"url":"http://arxiv.org/abs/2408.09840v1"}
{"created":"2024-08-19 09:35:51","title":"Segment-Anything Models Achieve Zero-shot Robustness in Autonomous Driving","abstract":"Semantic segmentation is a significant perception task in autonomous driving. It suffers from the risks of adversarial examples. In the past few years, deep learning has gradually transitioned from convolutional neural network (CNN) models with a relatively small number of parameters to foundation models with a huge number of parameters. The segment-anything model (SAM) is a generalized image segmentation framework that is capable of handling various types of images and is able to recognize and segment arbitrary objects in an image without the need to train on a specific object. It is a unified model that can handle diverse downstream tasks, including semantic segmentation, object detection, and tracking. In the task of semantic segmentation for autonomous driving, it is significant to study the zero-shot adversarial robustness of SAM. Therefore, we deliver a systematic empirical study on the robustness of SAM without additional training. Based on the experimental results, the zero-shot adversarial robustness of the SAM under the black-box corruptions and white-box adversarial attacks is acceptable, even without the need for additional training. The finding of this study is insightful in that the gigantic model parameters and huge amounts of training data lead to the phenomenon of emergence, which builds a guarantee of adversarial robustness. SAM is a vision foundation model that can be regarded as an early prototype of an artificial general intelligence (AGI) pipeline. In such a pipeline, a unified model can handle diverse tasks. Therefore, this research not only inspects the impact of vision foundation models on safe autonomous driving but also provides a perspective on developing trustworthy AGI. The code is available at: https://github.com/momo1986/robust_sam_iv.","sentences":["Semantic segmentation is a significant perception task in autonomous driving.","It suffers from the risks of adversarial examples.","In the past few years, deep learning has gradually transitioned from convolutional neural network (CNN) models with a relatively small number of parameters to foundation models with a huge number of parameters.","The segment-anything model (SAM) is a generalized image segmentation framework that is capable of handling various types of images and is able to recognize and segment arbitrary objects in an image without the need to train on a specific object.","It is a unified model that can handle diverse downstream tasks, including semantic segmentation, object detection, and tracking.","In the task of semantic segmentation for autonomous driving, it is significant to study the zero-shot adversarial robustness of SAM.","Therefore, we deliver a systematic empirical study on the robustness of SAM without additional training.","Based on the experimental results, the zero-shot adversarial robustness of the SAM under the black-box corruptions and white-box adversarial attacks is acceptable, even without the need for additional training.","The finding of this study is insightful in that the gigantic model parameters and huge amounts of training data lead to the phenomenon of emergence, which builds a guarantee of adversarial robustness.","SAM is a vision foundation model that can be regarded as an early prototype of an artificial general intelligence (AGI) pipeline.","In such a pipeline, a unified model can handle diverse tasks.","Therefore, this research not only inspects the impact of vision foundation models on safe autonomous driving but also provides a perspective on developing trustworthy AGI.","The code is available at: https://github.com/momo1986/robust_sam_iv."],"url":"http://arxiv.org/abs/2408.09839v1"}
{"created":"2024-08-19 09:31:27","title":"Effects of the Plan V\u00e9lo I and II on vehicular flow in Paris -- An Empirical Analysis","abstract":"In recent years, Paris, France, transformed its transportation infrastructure, marked by a notable reallocation of space away from cars to active modes of transportation. Key initiatives driving this transformation included Plan V\\'elo I and II, during which the city created over 1,000 kilometres of new bike paths to encourage cycling. For this, substantial road capacity has been removed from the system. This transformation provides a unique opportunity to investigate the impact of the large-scale network re-configuration on the network-wide traffic flow. Using the Network Fundamental Diagram (NFD) and a re-sampling methodology for its estimation, we investigate with empirical loop detector data from 2010 and 2023 the impact on the network's capacity, critical density, and free-flow speed resulting from these policy interventions. We find that in the urban core with the most policy interventions, per lane capacity decreased by over 50%, accompanied by a 60% drop in free-flow speed. Similarly, in the zone with fewer interventions, capacity declined by 34%, with a 40% reduction in free-flow speed. While these changes seem substantial, the NFDs show that overall congestion did not increase, indicating a modal shift to other modes of transport and hence presumably more sustainable urban mobility.","sentences":["In recent years, Paris, France, transformed its transportation infrastructure, marked by a notable reallocation of space away from cars to active modes of transportation.","Key initiatives driving this transformation included Plan V\\'elo","I and II, during which the city created over 1,000 kilometres of new bike paths to encourage cycling.","For this, substantial road capacity has been removed from the system.","This transformation provides a unique opportunity to investigate the impact of the large-scale network re-configuration on the network-wide traffic flow.","Using the Network Fundamental Diagram (NFD) and a re-sampling methodology for its estimation, we investigate with empirical loop detector data from 2010 and 2023 the impact on the network's capacity, critical density, and free-flow speed resulting from these policy interventions.","We find that in the urban core with the most policy interventions, per lane capacity decreased by over 50%, accompanied by a 60% drop in free-flow speed.","Similarly, in the zone with fewer interventions, capacity declined by 34%, with a 40% reduction in free-flow speed.","While these changes seem substantial, the NFDs show that overall congestion did not increase, indicating a modal shift to other modes of transport and hence presumably more sustainable urban mobility."],"url":"http://arxiv.org/abs/2408.09836v1"}
{"created":"2024-08-19 09:29:52","title":"Experimental Characterization of Hydrodynamic Gating-Based Molecular Communication Transmitter","abstract":"Molecular communication (MC) is a bio-inspired method of transmitting information using biochemical signals, promising for novel medical, agricultural, and environmental applications at the intersection of bio-, nano-, and communication technologies. Developing reliable MC systems for high-rate information transfer remains challenging due to the complex and dynamic nature of application environments and the physical and resource limitations of micro/nanoscale transmitters and receivers. Microfluidics can help overcome many such practical challenges by enabling testbeds that can replicate the application media with precise control over flow conditions. However, existing microfluidic MC testbeds face significant limitations in chemical signal generation with programmable signal waveforms, e.g., in terms of pulse width. To tackle this, we previously proposed a practical microfluidic MC transmitter architecture based on the hydrodynamic gating technique, a prevalent chemical waveform generation method. This paper reports the experimental validation and characterization of this method, examining its precision in terms of spatiotemporal control on the generated molecular concentration pulses. We detail the fabrication of the transmitter, its working mechanism and discuss its potential limitations based on empirical data. We show that the microfluidic transmitter is capable of providing precise, programmable, and reproducible molecular concentration pulses, which would facilitate the experimental research in MC.","sentences":["Molecular communication (MC) is a bio-inspired method of transmitting information using biochemical signals, promising for novel medical, agricultural, and environmental applications at the intersection of bio-, nano-, and communication technologies.","Developing reliable MC systems for high-rate information transfer remains challenging due to the complex and dynamic nature of application environments and the physical and resource limitations of micro/nanoscale transmitters and receivers.","Microfluidics can help overcome many such practical challenges by enabling testbeds that can replicate the application media with precise control over flow conditions.","However, existing microfluidic MC testbeds face significant limitations in chemical signal generation with programmable signal waveforms, e.g., in terms of pulse width.","To tackle this, we previously proposed a practical microfluidic MC transmitter architecture based on the hydrodynamic gating technique, a prevalent chemical waveform generation method.","This paper reports the experimental validation and characterization of this method, examining its precision in terms of spatiotemporal control on the generated molecular concentration pulses.","We detail the fabrication of the transmitter, its working mechanism and discuss its potential limitations based on empirical data.","We show that the microfluidic transmitter is capable of providing precise, programmable, and reproducible molecular concentration pulses, which would facilitate the experimental research in MC."],"url":"http://arxiv.org/abs/2408.09835v1"}
{"created":"2024-08-19 09:29:31","title":"Minor DPO reject penalty to increase training robustness","abstract":"Learning from human preference is a paradigm used in large-scale language model (LLM) fine-tuning step to better align pretrained LLM to human preference for downstream task. In the past it uses reinforcement learning from human feedback (RLHF) algorithm to optimize the LLM policy to align with these preferences and not to draft too far from the original model. Recently, Direct Preference Optimization (DPO) has been proposed to solve the alignment problem with a simplified RL-free method. Using preference pairs of chosen and reject data, DPO models the relative log probability as implicit reward function and optimize LLM policy using a simple binary cross entropy objective directly. DPO is quite straight forward and easy to be understood. It perform efficiently and well in most cases. In this article, we analyze the working mechanism of $\\beta$ in DPO, disclose its syntax difference between RL algorithm and DPO, and understand the potential shortage brought by the DPO simplification. With these insights, we propose MinorDPO, which is better aligned to the original RL algorithm, and increase the stability of preference optimization process.","sentences":["Learning from human preference is a paradigm used in large-scale language model (LLM) fine-tuning step to better align pretrained LLM to human preference for downstream task.","In the past it uses reinforcement learning from human feedback (RLHF) algorithm to optimize the LLM policy to align with these preferences and not to draft too far from the original model.","Recently, Direct Preference Optimization (DPO) has been proposed to solve the alignment problem with a simplified RL-free method.","Using preference pairs of chosen and reject data, DPO models the relative log probability as implicit reward function and optimize LLM policy using a simple binary cross entropy objective directly.","DPO is quite straight forward and easy to be understood.","It perform efficiently and well in most cases.","In this article, we analyze the working mechanism of $\\beta$ in DPO, disclose its syntax difference between RL algorithm and DPO, and understand the potential shortage brought by the DPO simplification.","With these insights, we propose MinorDPO, which is better aligned to the original RL algorithm, and increase the stability of preference optimization process."],"url":"http://arxiv.org/abs/2408.09834v1"}
{"created":"2024-08-19 09:29:00","title":"Automated Vehicle Driver Monitoring Dataset from Real-World Scenarios","abstract":"From SAE Level 3 of automation onwards, drivers are allowed to engage in activities that are not directly related to driving during their travel. However, in level 3, a misunderstanding of the capabilities of the system might lead drivers to engage in secondary tasks, which could impair their ability to react to challenging traffic situations.   Anticipating driver activity allows for early detection of risky behaviors, to prevent accidents. To be able to predict the driver activity, a Deep Learning network needs to be trained on a dataset. However, the use of datasets based on simulation for training and the migration to real-world data for prediction has proven to be suboptimal. Hence, this paper presents a real-world driver activity dataset, openly accessible on IEEE Dataport, which encompasses various activities that occur in autonomous driving scenarios under various illumination and weather conditions. Results from the training process showed that the dataset provides an excellent benchmark for implementing models for driver activity recognition.","sentences":["From SAE Level 3 of automation onwards, drivers are allowed to engage in activities that are not directly related to driving during their travel.","However, in level 3, a misunderstanding of the capabilities of the system might lead drivers to engage in secondary tasks, which could impair their ability to react to challenging traffic situations.   ","Anticipating driver activity allows for early detection of risky behaviors, to prevent accidents.","To be able to predict the driver activity, a Deep Learning network needs to be trained on a dataset.","However, the use of datasets based on simulation for training and the migration to real-world data for prediction has proven to be suboptimal.","Hence, this paper presents a real-world driver activity dataset, openly accessible on IEEE Dataport, which encompasses various activities that occur in autonomous driving scenarios under various illumination and weather conditions.","Results from the training process showed that the dataset provides an excellent benchmark for implementing models for driver activity recognition."],"url":"http://arxiv.org/abs/2408.09833v1"}
{"created":"2024-08-19 09:20:31","title":"TDNetGen: Empowering Complex Network Resilience Prediction with Generative Augmentation of Topology and Dynamics","abstract":"Predicting the resilience of complex networks, which represents the ability to retain fundamental functionality amidst external perturbations or internal failures, plays a critical role in understanding and improving real-world complex systems. Traditional theoretical approaches grounded in nonlinear dynamical systems rely on prior knowledge of network dynamics. On the other hand, data-driven approaches frequently encounter the challenge of insufficient labeled data, a predicament commonly observed in real-world scenarios. In this paper, we introduce a novel resilience prediction framework for complex networks, designed to tackle this issue through generative data augmentation of network topology and dynamics. The core idea is the strategic utilization of the inherent joint distribution present in unlabeled network data, facilitating the learning process of the resilience predictor by illuminating the relationship between network topology and dynamics. Experiment results on three network datasets demonstrate that our proposed framework TDNetGen can achieve high prediction accuracy up to 85%-95%. Furthermore, the framework still demonstrates a pronounced augmentation capability in extreme low-data regimes, thereby underscoring its utility and robustness in enhancing the prediction of network resilience. We have open-sourced our code in the following link, https://github.com/tsinghua-fib-lab/TDNetGen.","sentences":["Predicting the resilience of complex networks, which represents the ability to retain fundamental functionality amidst external perturbations or internal failures, plays a critical role in understanding and improving real-world complex systems.","Traditional theoretical approaches grounded in nonlinear dynamical systems rely on prior knowledge of network dynamics.","On the other hand, data-driven approaches frequently encounter the challenge of insufficient labeled data, a predicament commonly observed in real-world scenarios.","In this paper, we introduce a novel resilience prediction framework for complex networks, designed to tackle this issue through generative data augmentation of network topology and dynamics.","The core idea is the strategic utilization of the inherent joint distribution present in unlabeled network data, facilitating the learning process of the resilience predictor by illuminating the relationship between network topology and dynamics.","Experiment results on three network datasets demonstrate that our proposed framework TDNetGen can achieve high prediction accuracy up to 85%-95%.","Furthermore, the framework still demonstrates a pronounced augmentation capability in extreme low-data regimes, thereby underscoring its utility and robustness in enhancing the prediction of network resilience.","We have open-sourced our code in the following link, https://github.com/tsinghua-fib-lab/TDNetGen."],"url":"http://arxiv.org/abs/2408.09825v1"}
{"created":"2024-08-19 09:19:25","title":"SurgicaL-CD: Generating Surgical Images via Unpaired Image Translation with Latent Consistency Diffusion Models","abstract":"Computer-assisted surgery (CAS) systems are designed to assist surgeons during procedures, thereby reducing complications and enhancing patient care. Training machine learning models for these systems requires a large corpus of annotated datasets, which is challenging to obtain in the surgical domain due to patient privacy concerns and the significant labeling effort required from doctors. Previous methods have explored unpaired image translation using generative models to create realistic surgical images from simulations. However, these approaches have struggled to produce high-quality, diverse surgical images. In this work, we introduce \\emph{SurgicaL-CD}, a consistency-distilled diffusion method to generate realistic surgical images with only a few sampling steps without paired data. We evaluate our approach on three datasets, assessing the generated images in terms of quality and utility as downstream training datasets. Our results demonstrate that our method outperforms GANs and diffusion-based approaches. Our code is available at \\url{https://gitlab.com/nct_tso_public/gan2diffusion}.","sentences":["Computer-assisted surgery (CAS) systems are designed to assist surgeons during procedures, thereby reducing complications and enhancing patient care.","Training machine learning models for these systems requires a large corpus of annotated datasets, which is challenging to obtain in the surgical domain due to patient privacy concerns and the significant labeling effort required from doctors.","Previous methods have explored unpaired image translation using generative models to create realistic surgical images from simulations.","However, these approaches have struggled to produce high-quality, diverse surgical images.","In this work, we introduce \\emph{SurgicaL-CD}, a consistency-distilled diffusion method to generate realistic surgical images with only a few sampling steps without paired data.","We evaluate our approach on three datasets, assessing the generated images in terms of quality and utility as downstream training datasets.","Our results demonstrate that our method outperforms GANs and diffusion-based approaches.","Our code is available at \\url{https://gitlab.com/nct_tso_public/gan2diffusion}."],"url":"http://arxiv.org/abs/2408.09822v1"}
{"created":"2024-08-19 09:15:35","title":"CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models","abstract":"What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the society and 2) a collection of Chinese moral anomies from various newspapers and academic papers on morality. With these sources, we aim to create a moral evaluation dataset characterized by diversity and authenticity. We develop a morality taxonomy and a set of fundamental moral principles that are not only rooted in traditional Chinese culture but also consistent with contemporary societal norms. To facilitate efficient construction and annotation of instances in CMoralEval, we establish a platform with AI-assisted instance generation to streamline the annotation process. These help us curate CMoralEval that encompasses both explicit moral scenarios (14,964 instances) and moral dilemma scenarios (15,424 instances), each with instances from different data sources. We conduct extensive experiments with CMoralEval to examine a variety of Chinese LLMs. Experiment results demonstrate that CMoralEval is a challenging benchmark for Chinese LLMs. The dataset is publicly available at \\url{https://github.com/tjunlp-lab/CMoralEval}.","sentences":["What a large language model (LLM) would respond in ethically relevant context?","In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs.","The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the society and 2) a collection of Chinese moral anomies from various newspapers and academic papers on morality.","With these sources, we aim to create a moral evaluation dataset characterized by diversity and authenticity.","We develop a morality taxonomy and a set of fundamental moral principles that are not only rooted in traditional Chinese culture but also consistent with contemporary societal norms.","To facilitate efficient construction and annotation of instances in CMoralEval, we establish a platform with AI-assisted instance generation to streamline the annotation process.","These help us curate CMoralEval that encompasses both explicit moral scenarios (14,964 instances) and moral dilemma scenarios (15,424 instances), each with instances from different data sources.","We conduct extensive experiments with CMoralEval to examine a variety of Chinese LLMs.","Experiment results demonstrate that CMoralEval is a challenging benchmark for Chinese LLMs.","The dataset is publicly available at \\url{https://github.com/tjunlp-lab/CMoralEval}."],"url":"http://arxiv.org/abs/2408.09819v1"}
{"created":"2024-08-19 09:13:52","title":"Contextual Dual Learning Algorithm with Listwise Distillation for Unbiased Learning to Rank","abstract":"Unbiased Learning to Rank (ULTR) aims to leverage biased implicit user feedback (e.g., click) to optimize an unbiased ranking model. The effectiveness of the existing ULTR methods has primarily been validated on synthetic datasets. However, their performance on real-world click data remains unclear. Recently, Baidu released a large publicly available dataset of their web search logs. Subsequently, the NTCIR-17 ULTRE-2 task released a subset dataset extracted from it. We conduct experiments on commonly used or effective ULTR methods on this subset to determine whether they maintain their effectiveness. In this paper, we propose a Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD) to simultaneously address both position bias and contextual bias. We utilize a listwise-input ranking model to obtain reconstructed feature vectors incorporating local contextual information and employ the Dual Learning Algorithm (DLA) method to jointly train this ranking model and a propensity model to address position bias. As this ranking model learns the interaction information within the documents list of the training set, to enhance the ranking model's generalization ability, we additionally train a pointwise-input ranking model to learn the listwise-input ranking model's capability for relevance judgment in a listwise manner. Extensive experiments and analysis confirm the effectiveness of our approach.","sentences":["Unbiased Learning to Rank (ULTR) aims to leverage biased implicit user feedback (e.g., click) to optimize an unbiased ranking model.","The effectiveness of the existing ULTR methods has primarily been validated on synthetic datasets.","However, their performance on real-world click data remains unclear.","Recently, Baidu released a large publicly available dataset of their web search logs.","Subsequently, the NTCIR-17 ULTRE-2 task released a subset dataset extracted from it.","We conduct experiments on commonly used or effective ULTR methods on this subset to determine whether they maintain their effectiveness.","In this paper, we propose a Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD) to simultaneously address both position bias and contextual bias.","We utilize a listwise-input ranking model to obtain reconstructed feature vectors incorporating local contextual information and employ the Dual Learning Algorithm (DLA) method to jointly train this ranking model and a propensity model to address position bias.","As this ranking model learns the interaction information within the documents list of the training set, to enhance the ranking model's generalization ability, we additionally train a pointwise-input ranking model to learn the listwise-input ranking model's capability for relevance judgment in a listwise manner.","Extensive experiments and analysis confirm the effectiveness of our approach."],"url":"http://arxiv.org/abs/2408.09817v1"}
{"created":"2024-08-19 08:56:00","title":"World Models Increase Autonomy in Reinforcement Learning","abstract":"Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent's own autonomously acquired experience. However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments. To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision. We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance. MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states. It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision. Our findings suggest model-based methods hold significant promise for reducing human effort in RL. Website: https://sites.google.com/view/morefree","sentences":["Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent's own autonomously acquired experience.","However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments.","To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision.","We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance.","MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states.","It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision.","Our findings suggest model-based methods hold significant promise for reducing human effort in RL.","Website: https://sites.google.com/view/morefree"],"url":"http://arxiv.org/abs/2408.09807v1"}
{"created":"2024-08-19 08:46:16","title":"Latent Diffusion for Guided Document Table Generation","abstract":"Obtaining annotated table structure data for complex tables is a challenging task due to the inherent diversity and complexity of real-world document layouts. The scarcity of publicly available datasets with comprehensive annotations for intricate table structures hinders the development and evaluation of models designed for such scenarios. This research paper introduces a novel approach for generating annotated images for table structure by leveraging conditioned mask images of rows and columns through the application of latent diffusion models. The proposed method aims to enhance the quality of synthetic data used for training object detection models. Specifically, the study employs a conditioning mechanism to guide the generation of complex document table images, ensuring a realistic representation of table layouts. To evaluate the effectiveness of the generated data, we employ the popular YOLOv5 object detection model for training. The generated table images serve as valuable training samples, enriching the dataset with diverse table structures. The model is subsequently tested on the challenging pubtables-1m testset, a benchmark for table structure recognition in complex document layouts. Experimental results demonstrate that the introduced approach significantly improves the quality of synthetic data for training, leading to YOLOv5 models with enhanced performance. The mean Average Precision (mAP) values obtained on the pubtables-1m testset showcase results closely aligned with state-of-the-art methods. Furthermore, low FID results obtained on the synthetic data further validate the efficacy of the proposed methodology in generating annotated images for table structure.","sentences":["Obtaining annotated table structure data for complex tables is a challenging task due to the inherent diversity and complexity of real-world document layouts.","The scarcity of publicly available datasets with comprehensive annotations for intricate table structures hinders the development and evaluation of models designed for such scenarios.","This research paper introduces a novel approach for generating annotated images for table structure by leveraging conditioned mask images of rows and columns through the application of latent diffusion models.","The proposed method aims to enhance the quality of synthetic data used for training object detection models.","Specifically, the study employs a conditioning mechanism to guide the generation of complex document table images, ensuring a realistic representation of table layouts.","To evaluate the effectiveness of the generated data, we employ the popular YOLOv5 object detection model for training.","The generated table images serve as valuable training samples, enriching the dataset with diverse table structures.","The model is subsequently tested on the challenging pubtables-1m testset, a benchmark for table structure recognition in complex document layouts.","Experimental results demonstrate that the introduced approach significantly improves the quality of synthetic data for training, leading to YOLOv5 models with enhanced performance.","The mean Average Precision (mAP) values obtained on the pubtables-1m testset showcase results closely aligned with state-of-the-art methods.","Furthermore, low FID results obtained on the synthetic data further validate the efficacy of the proposed methodology in generating annotated images for table structure."],"url":"http://arxiv.org/abs/2408.09800v1"}
{"created":"2024-08-19 08:44:55","title":"Enhance Modality Robustness in Text-Centric Multimodal Alignment with Adversarial Prompting","abstract":"Converting different modalities into generalized text, which then serves as input prompts for large language models (LLMs), is a common approach for aligning multimodal models, particularly when pairwise data is limited. Text-centric alignment method leverages the unique properties of text as a modality space, transforming diverse inputs into a unified textual representation, thereby enabling downstream models to effectively interpret various modal inputs. This study evaluates the quality and robustness of multimodal representations in the face of noise imperfections, dynamic input order permutations, and missing modalities, revealing that current text-centric alignment methods can compromise downstream robustness. To address this issue, we propose a new text-centric adversarial training approach that significantly enhances robustness compared to traditional robust training methods and pre-trained multimodal foundation models. Our findings underscore the potential of this approach to improve the robustness and adaptability of multimodal representations, offering a promising solution for dynamic and real-world applications.","sentences":["Converting different modalities into generalized text, which then serves as input prompts for large language models (LLMs), is a common approach for aligning multimodal models, particularly when pairwise data is limited.","Text-centric alignment method leverages the unique properties of text as a modality space, transforming diverse inputs into a unified textual representation, thereby enabling downstream models to effectively interpret various modal inputs.","This study evaluates the quality and robustness of multimodal representations in the face of noise imperfections, dynamic input order permutations, and missing modalities, revealing that current text-centric alignment methods can compromise downstream robustness.","To address this issue, we propose a new text-centric adversarial training approach that significantly enhances robustness compared to traditional robust training methods and pre-trained multimodal foundation models.","Our findings underscore the potential of this approach to improve the robustness and adaptability of multimodal representations, offering a promising solution for dynamic and real-world applications."],"url":"http://arxiv.org/abs/2408.09798v1"}
{"created":"2024-08-19 08:41:09","title":"Unsupervised Composable Representations for Audio","abstract":"Current generative models are able to generate high-quality artefacts but have been shown to struggle with compositional reasoning, which can be defined as the ability to generate complex structures from simpler elements. In this paper, we focus on the problem of compositional representation learning for music data, specifically targeting the fully-unsupervised setting. We propose a simple and extensible framework that leverages an explicit compositional inductive bias, defined by a flexible auto-encoding objective that can leverage any of the current state-of-art generative models. We demonstrate that our framework, used with diffusion models, naturally addresses the task of unsupervised audio source separation, showing that our model is able to perform high-quality separation. Our findings reveal that our proposal achieves comparable or superior performance with respect to other blind source separation methods and, furthermore, it even surpasses current state-of-art supervised baselines on signal-to-interference ratio metrics. Additionally, by learning an a-posteriori masking diffusion model in the space of composable representations, we achieve a system capable of seamlessly performing unsupervised source separation, unconditional generation, and variation generation. Finally, as our proposal works in the latent space of pre-trained neural audio codecs, it also provides a lower computational cost with respect to other neural baselines.","sentences":["Current generative models are able to generate high-quality artefacts but have been shown to struggle with compositional reasoning, which can be defined as the ability to generate complex structures from simpler elements.","In this paper, we focus on the problem of compositional representation learning for music data, specifically targeting the fully-unsupervised setting.","We propose a simple and extensible framework that leverages an explicit compositional inductive bias, defined by a flexible auto-encoding objective that can leverage any of the current state-of-art generative models.","We demonstrate that our framework, used with diffusion models, naturally addresses the task of unsupervised audio source separation, showing that our model is able to perform high-quality separation.","Our findings reveal that our proposal achieves comparable or superior performance with respect to other blind source separation methods and, furthermore, it even surpasses current state-of-art supervised baselines on signal-to-interference ratio metrics.","Additionally, by learning an a-posteriori masking diffusion model in the space of composable representations, we achieve a system capable of seamlessly performing unsupervised source separation, unconditional generation, and variation generation.","Finally, as our proposal works in the latent space of pre-trained neural audio codecs, it also provides a lower computational cost with respect to other neural baselines."],"url":"http://arxiv.org/abs/2408.09792v1"}
{"created":"2024-08-19 08:39:08","title":"Structure-enhanced Contrastive Learning for Graph Clustering","abstract":"Graph clustering is a crucial task in network analysis with widespread applications, focusing on partitioning nodes into distinct groups with stronger intra-group connections than inter-group ones. Recently, contrastive learning has achieved significant progress in graph clustering. However, most methods suffer from the following issues: 1) an over-reliance on meticulously designed data augmentation strategies, which can undermine the potential of contrastive learning. 2) overlooking cluster-oriented structural information, particularly the higher-order cluster(community) structure information, which could unveil the mesoscopic cluster structure information of the network. In this study, Structure-enhanced Contrastive Learning (SECL) is introduced to addresses these issues by leveraging inherent network structures. SECL utilizes a cross-view contrastive learning mechanism to enhance node embeddings without elaborate data augmentations, a structural contrastive learning module for ensuring structural consistency, and a modularity maximization strategy for harnessing clustering-oriented information. This comprehensive approach results in robust node representations that greatly enhance clustering performance. Extensive experiments on six datasets confirm SECL's superiority over current state-of-the-art methods, indicating a substantial improvement in the domain of graph clustering.","sentences":["Graph clustering is a crucial task in network analysis with widespread applications, focusing on partitioning nodes into distinct groups with stronger intra-group connections than inter-group ones.","Recently, contrastive learning has achieved significant progress in graph clustering.","However, most methods suffer from the following issues: 1) an over-reliance on meticulously designed data augmentation strategies, which can undermine the potential of contrastive learning.","2) overlooking cluster-oriented structural information, particularly the higher-order cluster(community) structure information, which could unveil the mesoscopic cluster structure information of the network.","In this study, Structure-enhanced Contrastive Learning (SECL) is introduced to addresses these issues by leveraging inherent network structures.","SECL utilizes a cross-view contrastive learning mechanism to enhance node embeddings without elaborate data augmentations, a structural contrastive learning module for ensuring structural consistency, and a modularity maximization strategy for harnessing clustering-oriented information.","This comprehensive approach results in robust node representations that greatly enhance clustering performance.","Extensive experiments on six datasets confirm SECL's superiority over current state-of-the-art methods, indicating a substantial improvement in the domain of graph clustering."],"url":"http://arxiv.org/abs/2408.09790v1"}
{"created":"2024-08-19 08:27:31","title":"Anim-Director: A Large Multimodal Model Powered Agent for Controllable Animation Video Generation","abstract":"Traditional animation generation methods depend on training generative models with human-labelled data, entailing a sophisticated multi-stage pipeline that demands substantial human effort and incurs high training costs. Due to limited prompting plans, these methods typically produce brief, information-poor, and context-incoherent animations. To overcome these limitations and automate the animation process, we pioneer the introduction of large multimodal models (LMMs) as the core processor to build an autonomous animation-making agent, named Anim-Director. This agent mainly harnesses the advanced understanding and reasoning capabilities of LMMs and generative AI tools to create animated videos from concise narratives or simple instructions. Specifically, it operates in three main stages: Firstly, the Anim-Director generates a coherent storyline from user inputs, followed by a detailed director's script that encompasses settings of character profiles and interior/exterior descriptions, and context-coherent scene descriptions that include appearing characters, interiors or exteriors, and scene events. Secondly, we employ LMMs with the image generation tool to produce visual images of settings and scenes. These images are designed to maintain visual consistency across different scenes using a visual-language prompting method that combines scene descriptions and images of the appearing character and setting. Thirdly, scene images serve as the foundation for producing animated videos, with LMMs generating prompts to guide this process. The whole process is notably autonomous without manual intervention, as the LMMs interact seamlessly with generative tools to generate prompts, evaluate visual quality, and select the best one to optimize the final output.","sentences":["Traditional animation generation methods depend on training generative models with human-labelled data, entailing a sophisticated multi-stage pipeline that demands substantial human effort and incurs high training costs.","Due to limited prompting plans, these methods typically produce brief, information-poor, and context-incoherent animations.","To overcome these limitations and automate the animation process, we pioneer the introduction of large multimodal models (LMMs) as the core processor to build an autonomous animation-making agent, named Anim-Director.","This agent mainly harnesses the advanced understanding and reasoning capabilities of LMMs and generative AI tools to create animated videos from concise narratives or simple instructions.","Specifically, it operates in three main stages: Firstly, the Anim-Director generates a coherent storyline from user inputs, followed by a detailed director's script that encompasses settings of character profiles and interior/exterior descriptions, and context-coherent scene descriptions that include appearing characters, interiors or exteriors, and scene events.","Secondly, we employ LMMs with the image generation tool to produce visual images of settings and scenes.","These images are designed to maintain visual consistency across different scenes using a visual-language prompting method that combines scene descriptions and images of the appearing character and setting.","Thirdly, scene images serve as the foundation for producing animated videos, with LMMs generating prompts to guide this process.","The whole process is notably autonomous without manual intervention, as the LMMs interact seamlessly with generative tools to generate prompts, evaluate visual quality, and select the best one to optimize the final output."],"url":"http://arxiv.org/abs/2408.09787v1"}
{"created":"2024-08-19 08:22:20","title":"GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making","abstract":"Traditional methods for making software deployment decisions in the automotive industry typically rely on manual analysis of tabular software test data. These methods often lead to higher costs and delays in the software release cycle due to their labor-intensive nature. Large Language Models (LLMs) present a promising solution to these challenges. However, their application generally demands multiple rounds of human-driven prompt engineering, which limits their practical deployment, particularly for industrial end-users who need reliable and efficient results. In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive software deployment while meeting both functional requirements and practical industrial constraints. Unlike previous systems, GoNoGo is specifically tailored to address domain-specific and risk-sensitive systems. We evaluate GoNoGo's performance across different task difficulties using zero-shot and few-shot examples taken from industrial practice. Our results show that GoNoGo achieves a 100% success rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains high performance even for more complex tasks. We find that GoNoGo effectively automates decision-making for simpler tasks, significantly reducing the need for manual intervention. In summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently employed in our industrial partner's company to assist with software release decision-making, supporting more informed and timely decisions in the release process for risk-sensitive vehicle systems.","sentences":["Traditional methods for making software deployment decisions in the automotive industry typically rely on manual analysis of tabular software test data.","These methods often lead to higher costs and delays in the software release cycle due to their labor-intensive nature.","Large Language Models (LLMs) present a promising solution to these challenges.","However, their application generally demands multiple rounds of human-driven prompt engineering, which limits their practical deployment, particularly for industrial end-users who need reliable and efficient results.","In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive software deployment while meeting both functional requirements and practical industrial constraints.","Unlike previous systems, GoNoGo is specifically tailored to address domain-specific and risk-sensitive systems.","We evaluate GoNoGo's performance across different task difficulties using zero-shot and few-shot examples taken from industrial practice.","Our results show that GoNoGo achieves a 100% success rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains high performance even for more complex tasks.","We find that GoNoGo effectively automates decision-making for simpler tasks, significantly reducing the need for manual intervention.","In summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently employed in our industrial partner's company to assist with software release decision-making, supporting more informed and timely decisions in the release process for risk-sensitive vehicle systems."],"url":"http://arxiv.org/abs/2408.09785v1"}
{"created":"2024-08-19 08:05:33","title":"Faster Adaptive Decentralized Learning Algorithms","abstract":"Decentralized learning recently has received increasing attention in machine learning due to its advantages in implementation simplicity and system robustness, data privacy. Meanwhile, the adaptive gradient methods show superior performances in many machine learning tasks such as training neural networks. Although some works focus on studying decentralized optimization algorithms with adaptive learning rates, these adaptive decentralized algorithms still suffer from high sample complexity. To fill these gaps, we propose a class of faster adaptive decentralized algorithms (i.e., AdaMDOS and AdaMDOF) for distributed nonconvex stochastic and finite-sum optimization, respectively. Moreover, we provide a solid convergence analysis framework for our methods. In particular, we prove that our AdaMDOS obtains a near-optimal sample complexity of $\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary solution of nonconvex stochastic optimization. Meanwhile, our AdaMDOF obtains a near-optimal sample complexity of $O(\\sqrt{n}\\epsilon^{-2})$ for finding an $\\epsilon$-stationary solution of nonconvex finite-sum optimization, where $n$ denotes the sample size. To the best of our knowledge, our AdaMDOF algorithm is the first adaptive decentralized algorithm for nonconvex finite-sum optimization. Some experimental results demonstrate efficiency of our algorithms.","sentences":["Decentralized learning recently has received increasing attention in machine learning due to its advantages in implementation simplicity and system robustness, data privacy.","Meanwhile, the adaptive gradient methods show superior performances in many machine learning tasks such as training neural networks.","Although some works focus on studying decentralized optimization algorithms with adaptive learning rates, these adaptive decentralized algorithms still suffer from high sample complexity.","To fill these gaps, we propose a class of faster adaptive decentralized algorithms (i.e., AdaMDOS and AdaMDOF) for distributed nonconvex stochastic and finite-sum optimization, respectively.","Moreover, we provide a solid convergence analysis framework for our methods.","In particular, we prove that our AdaMDOS obtains a near-optimal sample complexity of $\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary solution of nonconvex stochastic optimization.","Meanwhile, our AdaMDOF obtains a near-optimal sample complexity of $O(\\sqrt{n}\\epsilon^{-2})$ for finding an $\\epsilon$-stationary solution of nonconvex finite-sum optimization, where $n$ denotes the sample size.","To the best of our knowledge, our AdaMDOF algorithm is the first adaptive decentralized algorithm for nonconvex finite-sum optimization.","Some experimental results demonstrate efficiency of our algorithms."],"url":"http://arxiv.org/abs/2408.09775v1"}
{"created":"2024-08-19 07:53:50","title":"Baby Bear: Seeking a Just Right Rating Scale for Scalar Annotations","abstract":"Our goal is a mechanism for efficiently assigning scalar ratings to each of a large set of elements. For example, \"what percent positive or negative is this product review?\" When sample sizes are small, prior work has advocated for methods such as Best Worst Scaling (BWS) as being more robust than direct ordinal annotation (\"Likert scales\"). Here we first introduce IBWS, which iteratively collects annotations through Best-Worst Scaling, resulting in robustly ranked crowd-sourced data. While effective, IBWS is too expensive for large-scale tasks. Using the results of IBWS as a best-desired outcome, we evaluate various direct assessment methods to determine what is both cost-efficient and best correlating to a large scale BWS annotation strategy. Finally, we illustrate in the domains of dialogue and sentiment how these annotations can support robust learning-to-rank models.","sentences":["Our goal is a mechanism for efficiently assigning scalar ratings to each of a large set of elements.","For example, \"what percent positive or negative is this product review?\"","When sample sizes are small, prior work has advocated for methods such as Best Worst Scaling (BWS) as being more robust than direct ordinal annotation (\"Likert scales\").","Here we first introduce IBWS, which iteratively collects annotations through Best-Worst Scaling, resulting in robustly ranked crowd-sourced data.","While effective, IBWS is too expensive for large-scale tasks.","Using the results of IBWS as a best-desired outcome, we evaluate various direct assessment methods to determine what is both cost-efficient and best correlating to a large scale BWS annotation strategy.","Finally, we illustrate in the domains of dialogue and sentiment how these annotations can support robust learning-to-rank models."],"url":"http://arxiv.org/abs/2408.09765v1"}
{"created":"2024-08-19 07:52:20","title":"Event Stream based Human Action Recognition: A High-Definition Benchmark Dataset and Algorithms","abstract":"Human Action Recognition (HAR) stands as a pivotal research domain in both computer vision and artificial intelligence, with RGB cameras dominating as the preferred tool for investigation and innovation in this field. However, in real-world applications, RGB cameras encounter numerous challenges, including light conditions, fast motion, and privacy concerns. Consequently, bio-inspired event cameras have garnered increasing attention due to their advantages of low energy consumption, high dynamic range, etc. Nevertheless, most existing event-based HAR datasets are low resolution ($346 \\times 260$). In this paper, we propose a large-scale, high-definition ($1280 \\times 800$) human action recognition dataset based on the CeleX-V event camera, termed CeleX-HAR. It encompasses 150 commonly occurring action categories, comprising a total of 124,625 video sequences. Various factors such as multi-view, illumination, action speed, and occlusion are considered when recording these data. To build a more comprehensive benchmark dataset, we report over 20 mainstream HAR models for future works to compare. In addition, we also propose a novel Mamba vision backbone network for event stream based HAR, termed EVMamba, which equips the spatial plane multi-directional scanning and novel voxel temporal scanning mechanism. By encoding and mining the spatio-temporal information of event streams, our EVMamba has achieved favorable results across multiple datasets. Both the dataset and source code will be released on \\url{https://github.com/Event-AHU/CeleX-HAR}","sentences":["Human Action Recognition (HAR) stands as a pivotal research domain in both computer vision and artificial intelligence, with RGB cameras dominating as the preferred tool for investigation and innovation in this field.","However, in real-world applications, RGB cameras encounter numerous challenges, including light conditions, fast motion, and privacy concerns.","Consequently, bio-inspired event cameras have garnered increasing attention due to their advantages of low energy consumption, high dynamic range, etc.","Nevertheless, most existing event-based HAR datasets are low resolution ($346 \\times 260$).","In this paper, we propose a large-scale, high-definition ($1280 \\times 800$) human action recognition dataset based on the CeleX-V event camera, termed CeleX-HAR.","It encompasses 150 commonly occurring action categories, comprising a total of 124,625 video sequences.","Various factors such as multi-view, illumination, action speed, and occlusion are considered when recording these data.","To build a more comprehensive benchmark dataset, we report over 20 mainstream HAR models for future works to compare.","In addition, we also propose a novel Mamba vision backbone network for event stream based HAR, termed EVMamba, which equips the spatial plane multi-directional scanning and novel voxel temporal scanning mechanism.","By encoding and mining the spatio-temporal information of event streams, our EVMamba has achieved favorable results across multiple datasets.","Both the dataset and source code will be released on \\url{https://github.com/Event-AHU/CeleX-HAR}"],"url":"http://arxiv.org/abs/2408.09764v1"}
{"created":"2024-08-19 07:43:35","title":"Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets","abstract":"In a real federated learning (FL) system, communication overhead for passing model parameters between the clients and the parameter server (PS) is often a bottleneck. Hierarchical federated learning (HFL) that poses multiple edge servers (ESs) between clients and the PS can partially alleviate communication pressure but still needs the aggregation of model parameters from multiple ESs at the PS. To further reduce communication overhead, we bring sequential FL (SFL) into HFL for the first time, which removes the central PS and enables the model training to be completed only through passing the global model between two adjacent ESs for each iteration, and propose a novel algorithm adaptive to such a combinational framework, referred to as Fed-CHS. Convergence results are derived for strongly convex and non-convex loss functions under various data heterogeneity setups, which show comparable convergence performance with the algorithms for HFL or SFL solely. Experimental results provide evidence of the superiority of our proposed Fed-CHS on both communication overhead saving and test accuracy over baseline methods.","sentences":["In a real federated learning (FL) system, communication overhead for passing model parameters between the clients and the parameter server (PS) is often a bottleneck.","Hierarchical federated learning (HFL) that poses multiple edge servers (ESs) between clients and the PS can partially alleviate communication pressure but still needs the aggregation of model parameters from multiple ESs at the PS.","To further reduce communication overhead, we bring sequential FL (SFL) into HFL for the first time, which removes the central PS and enables the model training to be completed only through passing the global model between two adjacent ESs for each iteration, and propose a novel algorithm adaptive to such a combinational framework, referred to as Fed-CHS.","Convergence results are derived for strongly convex and non-convex loss functions under various data heterogeneity setups, which show comparable convergence performance with the algorithms for HFL or SFL solely.","Experimental results provide evidence of the superiority of our proposed Fed-CHS on both communication overhead saving and test accuracy over baseline methods."],"url":"http://arxiv.org/abs/2408.09762v1"}
{"created":"2024-08-19 07:34:43","title":"Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning","abstract":"Recent studies highlight the effectiveness of using in-context learning (ICL) to steer large language models (LLMs) in processing tabular data, a challenging task given the structured nature of such data. Despite advancements in performance, the fairness implications of these methods are less understood. This study investigates how varying demonstrations within ICL prompts influence the fairness outcomes of LLMs. Our findings reveal that deliberately including minority group samples in prompts significantly boosts fairness without sacrificing predictive accuracy. Further experiments demonstrate that the proportion of minority to majority samples in demonstrations affects the trade-off between fairness and prediction accuracy. Based on these insights, we introduce a mitigation technique that employs clustering and evolutionary strategies to curate a diverse and representative sample set from the training data. This approach aims to enhance both predictive performance and fairness in ICL applications. Experimental results validate that our proposed method dramatically improves fairness across various metrics, showing its efficacy in real-world scenarios.","sentences":["Recent studies highlight the effectiveness of using in-context learning (ICL) to steer large language models (LLMs) in processing tabular data, a challenging task given the structured nature of such data.","Despite advancements in performance, the fairness implications of these methods are less understood.","This study investigates how varying demonstrations within ICL prompts influence the fairness outcomes of LLMs.","Our findings reveal that deliberately including minority group samples in prompts significantly boosts fairness without sacrificing predictive accuracy.","Further experiments demonstrate that the proportion of minority to majority samples in demonstrations affects the trade-off between fairness and prediction accuracy.","Based on these insights, we introduce a mitigation technique that employs clustering and evolutionary strategies to curate a diverse and representative sample set from the training data.","This approach aims to enhance both predictive performance and fairness in ICL applications.","Experimental results validate that our proposed method dramatically improves fairness across various metrics, showing its efficacy in real-world scenarios."],"url":"http://arxiv.org/abs/2408.09757v1"}
{"created":"2024-08-19 07:24:36","title":"A Unified Framework for Iris Anti-Spoofing: Introducing IrisGeneral Dataset and Masked-MoE Method","abstract":"Iris recognition is widely used in high-security scenarios due to its stability and distinctiveness. However, the acquisition of iris images typically requires near-infrared illumination and near-infrared band filters, leading to significant and consistent differences in imaging across devices. This underscores the importance of developing cross-domain capabilities in iris anti-spoofing methods. Despite this need, there is no dataset available that comprehensively evaluates the generalization ability of the iris anti-spoofing task. To address this gap, we propose the IrisGeneral dataset, which includes 10 subsets, belonging to 7 databases, published by 4 institutions, collected with 6 types of devices. IrisGeneral is designed with three protocols, aimed at evaluating average performance, cross-racial generalization, and cross-device generalization of iris anti-spoofing models. To tackle the challenge of integrating multiple sub-datasets in IrisGeneral, we employ multiple parameter sets to learn from the various subsets. Specifically, we utilize the Mixture of Experts (MoE) to fit complex data distributions using multiple sub-neural networks. To further enhance the generalization capabilities, we introduce a novel method Masked-MoE (MMoE). It randomly masks a portion of tokens for some experts and requires their outputs to be similar to the unmasked experts, which improves the generalization ability and effectively mitigates the overfitting issue produced by MoE. We selected ResNet50, VIT-B/16, CLIP, and FLIP as representative models and benchmarked them on the IrisGeneral dataset. Experimental results demonstrate that our proposed MMoE with CLIP achieves the best performance on IrisGeneral.","sentences":["Iris recognition is widely used in high-security scenarios due to its stability and distinctiveness.","However, the acquisition of iris images typically requires near-infrared illumination and near-infrared band filters, leading to significant and consistent differences in imaging across devices.","This underscores the importance of developing cross-domain capabilities in iris anti-spoofing methods.","Despite this need, there is no dataset available that comprehensively evaluates the generalization ability of the iris anti-spoofing task.","To address this gap, we propose the IrisGeneral dataset, which includes 10 subsets, belonging to 7 databases, published by 4 institutions, collected with 6 types of devices.","IrisGeneral is designed with three protocols, aimed at evaluating average performance, cross-racial generalization, and cross-device generalization of iris anti-spoofing models.","To tackle the challenge of integrating multiple sub-datasets in IrisGeneral, we employ multiple parameter sets to learn from the various subsets.","Specifically, we utilize the Mixture of Experts (MoE) to fit complex data distributions using multiple sub-neural networks.","To further enhance the generalization capabilities, we introduce a novel method Masked-MoE (MMoE).","It randomly masks a portion of tokens for some experts and requires their outputs to be similar to the unmasked experts, which improves the generalization ability and effectively mitigates the overfitting issue produced by MoE. We selected ResNet50, VIT-B/16, CLIP, and FLIP as representative models and benchmarked them on the IrisGeneral dataset.","Experimental results demonstrate that our proposed MMoE with CLIP achieves the best performance on IrisGeneral."],"url":"http://arxiv.org/abs/2408.09752v1"}
{"created":"2024-08-19 07:18:06","title":"Enhanced Cascade Prostate Cancer Classifier in mp-MRI Utilizing Recall Feedback Adaptive Loss and Prior Knowledge-Based Feature Extraction","abstract":"Prostate cancer is the second most common cancer in males worldwide, and mpMRI is commonly used for diagnosis. However, interpreting mpMRI is challenging and requires expertise from radiologists. This highlights the urgent need for automated grading in mpMRI. Existing studies lack integration of clinical prior information and suffer from uneven training sample distribution due to prevalence. Therefore, we propose a solution that incorporates prior knowledge, addresses the issue of uneven medical sample distribution, and maintains high interpretability in mpMRI. Firstly, we introduce Prior Knowledge-Based Feature Extraction, which mathematically models the PI-RADS criteria for prostate cancer as diagnostic information into model training. Secondly, we propose Adaptive Recall Feedback Loss to address the extremely imbalanced data problem. This method adjusts the training dynamically based on accuracy and recall in the validation set, resulting in high accuracy and recall simultaneously in the testing set.Thirdly, we design an Enhanced Cascade Prostate Cancer Classifier that classifies prostate cancer into different levels in an interpretable way, which refines the classification results and helps with clinical intervention. Our method is validated through experiments on the PI-CAI dataset and outperforms other methods with a more balanced result in both accuracy and recall rate.","sentences":["Prostate cancer is the second most common cancer in males worldwide, and mpMRI is commonly used for diagnosis.","However, interpreting mpMRI is challenging and requires expertise from radiologists.","This highlights the urgent need for automated grading in mpMRI.","Existing studies lack integration of clinical prior information and suffer from uneven training sample distribution due to prevalence.","Therefore, we propose a solution that incorporates prior knowledge, addresses the issue of uneven medical sample distribution, and maintains high interpretability in mpMRI.","Firstly, we introduce Prior Knowledge-Based Feature Extraction, which mathematically models the PI-RADS criteria for prostate cancer as diagnostic information into model training.","Secondly, we propose Adaptive Recall Feedback Loss to address the extremely imbalanced data problem.","This method adjusts the training dynamically based on accuracy and recall in the validation set, resulting in high accuracy and recall simultaneously in the testing set.","Thirdly, we design an Enhanced Cascade Prostate Cancer Classifier that classifies prostate cancer into different levels in an interpretable way, which refines the classification results and helps with clinical intervention.","Our method is validated through experiments on the PI-CAI dataset and outperforms other methods with a more balanced result in both accuracy and recall rate."],"url":"http://arxiv.org/abs/2408.09746v1"}
{"created":"2024-08-19 06:30:21","title":"Quantitative 3D Map Accuracy Evaluation Hardware and Algorithm for LiDAR(-Inertial) SLAM","abstract":"Accuracy evaluation of a 3D pointcloud map is crucial for the development of autonomous driving systems. In this work, we propose a user-independent software/hardware system that can quantitatively evaluate the accuracy of a 3D pointcloud map acquired from LiDAR(-Inertial) SLAM. We introduce a LiDAR target that functions robustly in the outdoor environment, while remaining observable by LiDAR. We also propose a software algorithm that automatically extracts representative points and calculates the accuracy of the 3D pointcloud map by leveraging GPS position data. This methodology overcomes the limitations of the manual selection method, that its result varies between users. Furthermore, two different error metrics, relative and absolute errors, are introduced to analyze the accuracy from different perspectives. Our implementations are available at: https://github.com/SangwooJung98/3D_Map_Evaluation","sentences":["Accuracy evaluation of a 3D pointcloud map is crucial for the development of autonomous driving systems.","In this work, we propose a user-independent software/hardware system that can quantitatively evaluate the accuracy of a 3D pointcloud map acquired from LiDAR(-Inertial) SLAM.","We introduce a LiDAR target that functions robustly in the outdoor environment, while remaining observable by LiDAR.","We also propose a software algorithm that automatically extracts representative points and calculates the accuracy of the 3D pointcloud map by leveraging GPS position data.","This methodology overcomes the limitations of the manual selection method, that its result varies between users.","Furthermore, two different error metrics, relative and absolute errors, are introduced to analyze the accuracy from different perspectives.","Our implementations are available at: https://github.com/SangwooJung98/3D_Map_Evaluation"],"url":"http://arxiv.org/abs/2408.09727v1"}
{"created":"2024-08-19 06:29:29","title":"State surveillance in the digital age: Factors associated with citizens' attitudes towards trust registers","abstract":"This paper investigates factors related to the acceptance of trust registers (e.g., the Chinese Social Credit System - SCS) in Western settings. To avoid a negative connotation, we first define the concept of trust register which encompasses surveillance systems in other settings beyond China, such as FICO in the US. Then, we explore which factors are associated with people's attitude towards trust registers leaning on the technology acceptance and privacy concern theories. A cross-sectional survey among Slovenian Facebook and Instagram users (N=147) was conducted. Covariance-based structural equation modeling (CB-SEM) was used to test the hypothesized associations between the studied constructs. Results indicate that attitude towards trust register is directly associated with perceived general usefulness of the trust register. Additionally, perceived general usefulness is associated with perceived usefulness of the trust register for ensuring national security and fighting crime, its ease of use, and privacy concern regarding data collection. As one of the first studies investigating attitude towards trust registers in a Western country, it provides pioneering insights into factors that may be relevant in case such registers would be implemented in a Western context, and provides some practical implications regarding messaging for would-be implementers of such systems.","sentences":["This paper investigates factors related to the acceptance of trust registers (e.g., the Chinese Social Credit System - SCS) in Western settings.","To avoid a negative connotation, we first define the concept of trust register which encompasses surveillance systems in other settings beyond China, such as FICO in the US.","Then, we explore which factors are associated with people's attitude towards trust registers leaning on the technology acceptance and privacy concern theories.","A cross-sectional survey among Slovenian Facebook and Instagram users (N=147) was conducted.","Covariance-based structural equation modeling (CB-SEM) was used to test the hypothesized associations between the studied constructs.","Results indicate that attitude towards trust register is directly associated with perceived general usefulness of the trust register.","Additionally, perceived general usefulness is associated with perceived usefulness of the trust register for ensuring national security and fighting crime, its ease of use, and privacy concern regarding data collection.","As one of the first studies investigating attitude towards trust registers in a Western country, it provides pioneering insights into factors that may be relevant in case such registers would be implemented in a Western context, and provides some practical implications regarding messaging for would-be implementers of such systems."],"url":"http://arxiv.org/abs/2408.09725v1"}
{"created":"2024-08-19 06:23:41","title":"sTransformer: A Modular Approach for Extracting Inter-Sequential and Temporal Information for Time-Series Forecasting","abstract":"In recent years, numerous Transformer-based models have been applied to long-term time-series forecasting (LTSF) tasks. However, recent studies with linear models have questioned their effectiveness, demonstrating that simple linear layers can outperform sophisticated Transformer-based models. In this work, we review and categorize existing Transformer-based models into two main types: (1) modifications to the model structure and (2) modifications to the input data. The former offers scalability but falls short in capturing inter-sequential information, while the latter preprocesses time-series data but is challenging to use as a scalable module. We propose $\\textbf{sTransformer}$, which introduces the Sequence and Temporal Convolutional Network (STCN) to fully capture both sequential and temporal information. Additionally, we introduce a Sequence-guided Mask Attention mechanism to capture global feature information. Our approach ensures the capture of inter-sequential information while maintaining module scalability. We compare our model with linear models and existing forecasting models on long-term time-series forecasting, achieving new state-of-the-art results. We also conducted experiments on other time-series tasks, achieving strong performance. These demonstrate that Transformer-based structures remain effective and our model can serve as a viable baseline for time-series tasks.","sentences":["In recent years, numerous Transformer-based models have been applied to long-term time-series forecasting (LTSF) tasks.","However, recent studies with linear models have questioned their effectiveness, demonstrating that simple linear layers can outperform sophisticated Transformer-based models.","In this work, we review and categorize existing Transformer-based models into two main types: (1) modifications to the model structure and (2) modifications to the input data.","The former offers scalability but falls short in capturing inter-sequential information, while the latter preprocesses time-series data but is challenging to use as a scalable module.","We propose $\\textbf{sTransformer}$, which introduces the Sequence and Temporal Convolutional Network (STCN) to fully capture both sequential and temporal information.","Additionally, we introduce a Sequence-guided Mask Attention mechanism to capture global feature information.","Our approach ensures the capture of inter-sequential information while maintaining module scalability.","We compare our model with linear models and existing forecasting models on long-term time-series forecasting, achieving new state-of-the-art results.","We also conducted experiments on other time-series tasks, achieving strong performance.","These demonstrate that Transformer-based structures remain effective and our model can serve as a viable baseline for time-series tasks."],"url":"http://arxiv.org/abs/2408.09723v1"}
{"created":"2024-08-19 06:23:21","title":"Towards Few-Shot Learning in the Open World: A Review and Beyond","abstract":"Human intelligence is characterized by our ability to absorb and apply knowledge from the world around us, especially in rapidly acquiring new concepts from minimal examples, underpinned by prior knowledge. Few-shot learning (FSL) aims to mimic this capacity by enabling significant generalizations and transferability. However, traditional FSL frameworks often rely on assumptions of clean, complete, and static data, conditions that are seldom met in real-world environments. Such assumptions falter in the inherently uncertain, incomplete, and dynamic contexts of the open world. This paper presents a comprehensive review of recent advancements designed to adapt FSL for use in open-world settings. We categorize existing methods into three distinct types of open-world few-shot learning: those involving varying instances, varying classes, and varying distributions. Each category is discussed in terms of its specific challenges and methods, as well as its strengths and weaknesses. We standardize experimental settings and metric benchmarks across scenarios, and provide a comparative analysis of the performance of various methods. In conclusion, we outline potential future research directions for this evolving field. It is our hope that this review will catalyze further development of effective solutions to these complex challenges, thereby advancing the field of artificial intelligence.","sentences":["Human intelligence is characterized by our ability to absorb and apply knowledge from the world around us, especially in rapidly acquiring new concepts from minimal examples, underpinned by prior knowledge.","Few-shot learning (FSL) aims to mimic this capacity by enabling significant generalizations and transferability.","However, traditional FSL frameworks often rely on assumptions of clean, complete, and static data, conditions that are seldom met in real-world environments.","Such assumptions falter in the inherently uncertain, incomplete, and dynamic contexts of the open world.","This paper presents a comprehensive review of recent advancements designed to adapt FSL for use in open-world settings.","We categorize existing methods into three distinct types of open-world few-shot learning: those involving varying instances, varying classes, and varying distributions.","Each category is discussed in terms of its specific challenges and methods, as well as its strengths and weaknesses.","We standardize experimental settings and metric benchmarks across scenarios, and provide a comparative analysis of the performance of various methods.","In conclusion, we outline potential future research directions for this evolving field.","It is our hope that this review will catalyze further development of effective solutions to these complex challenges, thereby advancing the field of artificial intelligence."],"url":"http://arxiv.org/abs/2408.09722v1"}
{"created":"2024-08-19 06:19:31","title":"Pedestrian Attribute Recognition: A New Benchmark Dataset and A Large Language Model Augmented Framework","abstract":"Pedestrian Attribute Recognition (PAR) is one of the indispensable tasks in human-centered research. However, existing datasets neglect different domains (e.g., environments, times, populations, and data sources), only conducting simple random splits, and the performance of these datasets has already approached saturation. In the past five years, no large-scale dataset has been opened to the public. To address this issue, this paper proposes a new large-scale, cross-domain pedestrian attribute recognition dataset to fill the data gap, termed MSP60K. It consists of 60,122 images and 57 attribute annotations across eight scenarios. Synthetic degradation is also conducted to further narrow the gap between the dataset and real-world challenging scenarios. To establish a more rigorous benchmark, we evaluate 17 representative PAR models under both random and cross-domain split protocols on our dataset. Additionally, we propose an innovative Large Language Model (LLM) augmented PAR framework, named LLM-PAR. This framework processes pedestrian images through a Vision Transformer (ViT) backbone to extract features and introduces a multi-embedding query Transformer to learn partial-aware features for attribute classification. Significantly, we enhance this framework with LLM for ensemble learning and visual feature augmentation. Comprehensive experiments across multiple PAR benchmark datasets have thoroughly validated the efficacy of our proposed framework. The dataset and source code accompanying this paper will be made publicly available at \\url{https://github.com/Event-AHU/OpenPAR}.","sentences":["Pedestrian Attribute Recognition (PAR) is one of the indispensable tasks in human-centered research.","However, existing datasets neglect different domains (e.g., environments, times, populations, and data sources), only conducting simple random splits, and the performance of these datasets has already approached saturation.","In the past five years, no large-scale dataset has been opened to the public.","To address this issue, this paper proposes a new large-scale, cross-domain pedestrian attribute recognition dataset to fill the data gap, termed MSP60K.","It consists of 60,122 images and 57 attribute annotations across eight scenarios.","Synthetic degradation is also conducted to further narrow the gap between the dataset and real-world challenging scenarios.","To establish a more rigorous benchmark, we evaluate 17 representative PAR models under both random and cross-domain split protocols on our dataset.","Additionally, we propose an innovative Large Language Model (LLM) augmented PAR framework, named LLM-PAR.","This framework processes pedestrian images through a Vision Transformer (ViT) backbone to extract features and introduces a multi-embedding query Transformer to learn partial-aware features for attribute classification.","Significantly, we enhance this framework with LLM for ensemble learning and visual feature augmentation.","Comprehensive experiments across multiple PAR benchmark datasets have thoroughly validated the efficacy of our proposed framework.","The dataset and source code accompanying this paper will be made publicly available at \\url{https://github.com/Event-AHU/OpenPAR}."],"url":"http://arxiv.org/abs/2408.09720v1"}
{"created":"2024-08-19 06:18:59","title":"Work-Efficient Parallel Counting via Sampling","abstract":"We study the problem of estimating the partition function $Z(\\beta) = \\sum_{x \\in \\Omega} \\exp[-\\beta \\cdot H(x)]$ of a Gibbs distribution defined by a Hamiltonian $H(\\cdot)$. It is well known that the partition function $Z(\\beta)$ can be well approximated by the simulated annealing method, assuming a sampling oracle that can generate samples according to the Gibbs distribution of any given inverse temperature $\\beta$. This method yields the most efficient reductions from counting to sampling, including:   $\\bullet$ classic non-adaptive (parallel) algorithms with sub-optimal cost [DFK89; Bez+08];   $\\bullet$ adaptive (sequential) algorithms with near-optimal cost [SVV09; Hub15; Kol18; HK23].   In this paper, we give an algorithm that achieves efficiency in both parallelism and total work. Specifically, it provides a reduction from counting to sampling using near-optimal total work and logarithmic depth of computation. Consequently, it gives work-efficient parallel counting algorithms for several important models, including the hardcore and Ising models in the uniqueness regime.","sentences":["We study the problem of estimating the partition function $Z(\\beta) = \\sum_{x \\in \\Omega} \\exp[-\\beta \\cdot H(x)]$ of a Gibbs distribution defined by a Hamiltonian $H(\\cdot)$.","It is well known that the partition function $Z(\\beta)$ can be well approximated by the simulated annealing method, assuming a sampling oracle that can generate samples according to the Gibbs distribution of any given inverse temperature $\\beta$. This method yields the most efficient reductions from counting to sampling, including:   $\\bullet$ classic non-adaptive (parallel) algorithms with sub-optimal cost [DFK89; Bez+08];   $\\bullet$ adaptive (sequential) algorithms with near-optimal cost [SVV09; Hub15; Kol18; HK23].   ","In this paper, we give an algorithm that achieves efficiency in both parallelism and total work.","Specifically, it provides a reduction from counting to sampling using near-optimal total work and logarithmic depth of computation.","Consequently, it gives work-efficient parallel counting algorithms for several important models, including the hardcore and Ising models in the uniqueness regime."],"url":"http://arxiv.org/abs/2408.09719v1"}
{"created":"2024-08-19 06:06:30","title":"HYDEN: Hyperbolic Density Representations for Medical Images and Reports","abstract":"In light of the inherent entailment relations between images and text, hyperbolic point vector embeddings, leveraging the hierarchical modeling advantages of hyperbolic space, have been utilized for visual semantic representation learning. However, point vector embedding approaches fail to address the issue of semantic uncertainty, where an image may have multiple interpretations, and text may refer to different images, a phenomenon particularly prevalent in the medical domain. Therefor, we propose \\textbf{HYDEN}, a novel hyperbolic density embedding based image-text representation learning approach tailored for specific medical domain data. This method integrates text-aware local features alongside global features from images, mapping image-text features to density features in hyperbolic space via using hyperbolic pseudo-Gaussian distributions. An encapsulation loss function is employed to model the partial order relations between image-text density distributions. Experimental results demonstrate the interpretability of our approach and its superior performance compared to the baseline methods across various zero-shot tasks and different datasets.","sentences":["In light of the inherent entailment relations between images and text, hyperbolic point vector embeddings, leveraging the hierarchical modeling advantages of hyperbolic space, have been utilized for visual semantic representation learning.","However, point vector embedding approaches fail to address the issue of semantic uncertainty, where an image may have multiple interpretations, and text may refer to different images, a phenomenon particularly prevalent in the medical domain.","Therefor, we propose \\textbf{HYDEN}, a novel hyperbolic density embedding based image-text representation learning approach tailored for specific medical domain data.","This method integrates text-aware local features alongside global features from images, mapping image-text features to density features in hyperbolic space via using hyperbolic pseudo-Gaussian distributions.","An encapsulation loss function is employed to model the partial order relations between image-text density distributions.","Experimental results demonstrate the interpretability of our approach and its superior performance compared to the baseline methods across various zero-shot tasks and different datasets."],"url":"http://arxiv.org/abs/2408.09715v1"}
{"created":"2024-08-19 05:37:35","title":"Community-Centric Graph Unlearning","abstract":"Graph unlearning technology has become increasingly important since the advent of the `right to be forgotten' and the growing concerns about the privacy and security of artificial intelligence. Graph unlearning aims to quickly eliminate the effects of specific data on graph neural networks (GNNs). However, most existing deterministic graph unlearning frameworks follow a balanced partition-submodel training-aggregation paradigm, resulting in a lack of structural information between subgraph neighborhoods and redundant unlearning parameter calculations. To address this issue, we propose a novel Graph Structure Mapping Unlearning paradigm (GSMU) and a novel method based on it named Community-centric Graph Eraser (CGE). CGE maps community subgraphs to nodes, thereby enabling the reconstruction of a node-level unlearning operation within a reduced mapped graph. CGE makes the exponential reduction of both the amount of training data and the number of unlearning parameters. Extensive experiments conducted on five real-world datasets and three widely used GNN backbones have verified the high performance and efficiency of our CGE method, highlighting its potential in the field of graph unlearning.","sentences":["Graph unlearning technology has become increasingly important since the advent of the `right to be forgotten' and the growing concerns about the privacy and security of artificial intelligence.","Graph unlearning aims to quickly eliminate the effects of specific data on graph neural networks (GNNs).","However, most existing deterministic graph unlearning frameworks follow a balanced partition-submodel training-aggregation paradigm, resulting in a lack of structural information between subgraph neighborhoods and redundant unlearning parameter calculations.","To address this issue, we propose a novel Graph Structure Mapping Unlearning paradigm (GSMU) and a novel method based on it named Community-centric Graph Eraser (CGE).","CGE maps community subgraphs to nodes, thereby enabling the reconstruction of a node-level unlearning operation within a reduced mapped graph.","CGE makes the exponential reduction of both the amount of training data and the number of unlearning parameters.","Extensive experiments conducted on five real-world datasets and three widely used GNN backbones have verified the high performance and efficiency of our CGE method, highlighting its potential in the field of graph unlearning."],"url":"http://arxiv.org/abs/2408.09705v1"}
{"created":"2024-08-19 05:11:46","title":"Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer","abstract":"The use of Large Language Models (LLMs) for program code generation has gained substantial attention, but their biases and limitations with non-English prompts challenge global inclusivity. This paper investigates the complexities of multilingual prompt-based code generation. Our evaluations of LLMs, including CodeLLaMa and CodeGemma, reveal significant disparities in code quality for non-English prompts; we also demonstrate the inadequacy of simple approaches like prompt translation, bootstrapped data augmentation, and fine-tuning. To address this, we propose a zero-shot cross-lingual approach using a neural projection technique, integrating a cross-lingual encoder like LASER artetxe2019massively to map multilingual embeddings from it into the LLM's token space. This method requires training only on English data and scales effectively to other languages. Results on a translated and quality-checked MBPP dataset show substantial improvements in code quality. This research promotes a more inclusive code generation landscape by empowering LLMs with multilingual capabilities to support the diverse linguistic spectrum in programming.","sentences":["The use of Large Language Models (LLMs) for program code generation has gained substantial attention, but their biases and limitations with non-English prompts challenge global inclusivity.","This paper investigates the complexities of multilingual prompt-based code generation.","Our evaluations of LLMs, including CodeLLaMa and CodeGemma, reveal significant disparities in code quality for non-English prompts; we also demonstrate the inadequacy of simple approaches like prompt translation, bootstrapped data augmentation, and fine-tuning.","To address this, we propose a zero-shot cross-lingual approach using a neural projection technique, integrating a cross-lingual encoder like LASER artetxe2019massively to map multilingual embeddings from it into the LLM's token space.","This method requires training only on English data and scales effectively to other languages.","Results on a translated and quality-checked MBPP dataset show substantial improvements in code quality.","This research promotes a more inclusive code generation landscape by empowering LLMs with multilingual capabilities to support the diverse linguistic spectrum in programming."],"url":"http://arxiv.org/abs/2408.09701v1"}
{"created":"2024-08-19 04:47:05","title":"Double-Precision Floating-Point Data Visualizations Using Vulkan API","abstract":"Proper representation of data in graphical visualizations becomes challenging when high accuracy in data types is required, especially in those situations where the difference between double-precision floating-point and single-precision floating-point values makes a significant difference. Some of the limitations of using single-precision over double-precision include lesser accuracy, which accumulates errors over time, and poor modeling of large or small numbers. In such scenarios, emulated double precision is often used as a solution. The proposed methodology uses a modern GPU pipeline and graphics library API specifications to use native double precision. In this research, the approach is implemented using the Vulkan API, C++, and GLSL. Experimental evaluation with a series of experiments on 2D and 3D point datasets is proposed to indicate the effectiveness of the approach. This evaluates performance comparisons between native double-precision implementations against their emulated double-precision approaches with respect to rendering performance and accuracy. This study provides insight into the benefits of using native double-precision in graphical applications, denoting limitations and problems with emulated double-precision usages. These results improve the general understanding of the precision involved in graphical visualizations and assist developers in making decisions about which precision methods to use during their applications.","sentences":["Proper representation of data in graphical visualizations becomes challenging when high accuracy in data types is required, especially in those situations where the difference between double-precision floating-point and single-precision floating-point values makes a significant difference.","Some of the limitations of using single-precision over double-precision include lesser accuracy, which accumulates errors over time, and poor modeling of large or small numbers.","In such scenarios, emulated double precision is often used as a solution.","The proposed methodology uses a modern GPU pipeline and graphics library API specifications to use native double precision.","In this research, the approach is implemented using the Vulkan API, C++, and GLSL.","Experimental evaluation with a series of experiments on 2D and 3D point datasets is proposed to indicate the effectiveness of the approach.","This evaluates performance comparisons between native double-precision implementations against their emulated double-precision approaches with respect to rendering performance and accuracy.","This study provides insight into the benefits of using native double-precision in graphical applications, denoting limitations and problems with emulated double-precision usages.","These results improve the general understanding of the precision involved in graphical visualizations and assist developers in making decisions about which precision methods to use during their applications."],"url":"http://arxiv.org/abs/2408.09699v1"}
{"created":"2024-08-19 04:44:32","title":"Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation","abstract":"Recent advances in Large Language Models (LLMs) have demonstrated significant potential in the field of Recommendation Systems (RSs). Most existing studies have focused on converting user behavior logs into textual prompts and leveraging techniques such as prompt tuning to enable LLMs for recommendation tasks. Meanwhile, research interest has recently grown in multimodal recommendation systems that integrate data from images, text, and other sources using modality fusion techniques. This introduces new challenges to the existing LLM-based recommendation paradigm which relies solely on text modality information. Moreover, although Multimodal Large Language Models (MLLMs) capable of processing multi-modal inputs have emerged, how to equip MLLMs with multi-modal recommendation capabilities remains largely unexplored. To this end, in this paper, we propose the Multimodal Large Language Model-enhanced Sequential Multimodal Recommendation (MLLM-MSR) model. To capture the dynamic user preference, we design a two-stage user preference summarization method. Specifically, we first utilize an MLLM-based item-summarizer to extract image feature given an item and convert the image into text. Then, we employ a recurrent user preference summarization generation paradigm to capture the dynamic changes in user preferences based on an LLM-based user-summarizer. Finally, to enable the MLLM for multi-modal recommendation task, we propose to fine-tune a MLLM-based recommender using Supervised Fine-Tuning (SFT) techniques. Extensive evaluations across various datasets validate the effectiveness of MLLM-MSR, showcasing its superior ability to capture and adapt to the evolving dynamics of user preferences.","sentences":["Recent advances in Large Language Models (LLMs) have demonstrated significant potential in the field of Recommendation Systems (RSs).","Most existing studies have focused on converting user behavior logs into textual prompts and leveraging techniques such as prompt tuning to enable LLMs for recommendation tasks.","Meanwhile, research interest has recently grown in multimodal recommendation systems that integrate data from images, text, and other sources using modality fusion techniques.","This introduces new challenges to the existing LLM-based recommendation paradigm which relies solely on text modality information.","Moreover, although Multimodal Large Language Models (MLLMs) capable of processing multi-modal inputs have emerged, how to equip MLLMs with multi-modal recommendation capabilities remains largely unexplored.","To this end, in this paper, we propose the Multimodal Large Language Model-enhanced Sequential Multimodal Recommendation (MLLM-MSR) model.","To capture the dynamic user preference, we design a two-stage user preference summarization method.","Specifically, we first utilize an MLLM-based item-summarizer to extract image feature given an item and convert the image into text.","Then, we employ a recurrent user preference summarization generation paradigm to capture the dynamic changes in user preferences based on an LLM-based user-summarizer.","Finally, to enable the MLLM for multi-modal recommendation task, we propose to fine-tune a MLLM-based recommender using Supervised Fine-Tuning (SFT) techniques.","Extensive evaluations across various datasets validate the effectiveness of MLLM-MSR, showcasing its superior ability to capture and adapt to the evolving dynamics of user preferences."],"url":"http://arxiv.org/abs/2408.09698v1"}
{"created":"2024-08-19 03:38:29","title":"MambaLoc: Efficient Camera Localisation via State Space Model","abstract":"Location information is pivotal for the automation and intelligence of terminal devices and edge-cloud IoT systems, such as autonomous vehicles and augmented reality. However, achieving reliable positioning across diverse IoT applications remains challenging due to significant training costs and the necessity of densely collected data. To tackle these issues, we have innovatively applied the selective state space (SSM) model to visual localization, introducing a new model named MambaLoc. The proposed model demonstrates exceptional training efficiency by capitalizing on the SSM model's strengths in efficient feature extraction, rapid computation, and memory optimization, and it further ensures robustness in sparse data environments due to its parameter sparsity. Additionally, we propose the Global Information Selector (GIS), which leverages selective SSM to implicitly achieve the efficient global feature extraction capabilities of Non-local Neural Networks. This design leverages the computational efficiency of the SSM model alongside the Non-local Neural Networks' capacity to capture long-range dependencies with minimal layers. Consequently, the GIS enables effective global information capture while significantly accelerating convergence. Our extensive experimental validation using public indoor and outdoor datasets first demonstrates our model's effectiveness, followed by evidence of its versatility with various existing localization models.","sentences":["Location information is pivotal for the automation and intelligence of terminal devices and edge-cloud IoT systems, such as autonomous vehicles and augmented reality.","However, achieving reliable positioning across diverse IoT applications remains challenging due to significant training costs and the necessity of densely collected data.","To tackle these issues, we have innovatively applied the selective state space (SSM) model to visual localization, introducing a new model named MambaLoc.","The proposed model demonstrates exceptional training efficiency by capitalizing on the SSM model's strengths in efficient feature extraction, rapid computation, and memory optimization, and it further ensures robustness in sparse data environments due to its parameter sparsity.","Additionally, we propose the Global Information Selector (GIS), which leverages selective SSM to implicitly achieve the efficient global feature extraction capabilities of Non-local Neural Networks.","This design leverages the computational efficiency of the SSM model alongside the Non-local Neural Networks' capacity to capture long-range dependencies with minimal layers.","Consequently, the GIS enables effective global information capture while significantly accelerating convergence.","Our extensive experimental validation using public indoor and outdoor datasets first demonstrates our model's effectiveness, followed by evidence of its versatility with various existing localization models."],"url":"http://arxiv.org/abs/2408.09680v1"}
{"created":"2024-08-19 03:33:39","title":"Image-based Freeform Handwriting Authentication with Energy-oriented Self-Supervised Learning","abstract":"Freeform handwriting authentication verifies a person's identity from their writing style and habits in messy handwriting data. This technique has gained widespread attention in recent years as a valuable tool for various fields, e.g., fraud prevention and cultural heritage protection. However, it still remains a challenging task in reality due to three reasons: (i) severe damage, (ii) complex high-dimensional features, and (iii) lack of supervision. To address these issues, we propose SherlockNet, an energy-oriented two-branch contrastive self-supervised learning framework for robust and fast freeform handwriting authentication. It consists of four stages: (i) pre-processing: converting manuscripts into energy distributions using a novel plug-and-play energy-oriented operator to eliminate the influence of noise; (ii) generalized pre-training: learning general representation through two-branch momentum-based adaptive contrastive learning with the energy distributions, which handles the high-dimensional features and spatial dependencies of handwriting; (iii) personalized fine-tuning: calibrating the learned knowledge using a small amount of labeled data from downstream tasks; and (iv) practical application: identifying individual handwriting from scrambled, missing, or forged data efficiently and conveniently. Considering the practicality, we construct EN-HA, a novel dataset that simulates data forgery and severe damage in real applications. Finally, we conduct extensive experiments on six benchmark datasets including our EN-HA, and the results prove the robustness and efficiency of SherlockNet.","sentences":["Freeform handwriting authentication verifies a person's identity from their writing style and habits in messy handwriting data.","This technique has gained widespread attention in recent years as a valuable tool for various fields, e.g., fraud prevention and cultural heritage protection.","However, it still remains a challenging task in reality due to three reasons: (i) severe damage, (ii) complex high-dimensional features, and (iii) lack of supervision.","To address these issues, we propose SherlockNet, an energy-oriented two-branch contrastive self-supervised learning framework for robust and fast freeform handwriting authentication.","It consists of four stages: (i) pre-processing: converting manuscripts into energy distributions using a novel plug-and-play energy-oriented operator to eliminate the influence of noise; (ii) generalized pre-training: learning general representation through two-branch momentum-based adaptive contrastive learning with the energy distributions, which handles the high-dimensional features and spatial dependencies of handwriting; (iii) personalized fine-tuning: calibrating the learned knowledge using a small amount of labeled data from downstream tasks; and (iv) practical application: identifying individual handwriting from scrambled, missing, or forged data efficiently and conveniently.","Considering the practicality, we construct EN-HA, a novel dataset that simulates data forgery and severe damage in real applications.","Finally, we conduct extensive experiments on six benchmark datasets including our EN-HA, and the results prove the robustness and efficiency of SherlockNet."],"url":"http://arxiv.org/abs/2408.09676v1"}
{"created":"2024-08-19 03:31:20","title":"Multi-Agent Reinforcement Learning for Autonomous Driving: A Survey","abstract":"Reinforcement Learning (RL) is a potent tool for sequential decision-making and has achieved performance surpassing human capabilities across many challenging real-world tasks. As the extension of RL in the multi-agent system domain, multi-agent RL (MARL) not only need to learn the control policy but also requires consideration regarding interactions with all other agents in the environment, mutual influences among different system components, and the distribution of computational resources. This augments the complexity of algorithmic design and poses higher requirements on computational resources. Simultaneously, simulators are crucial to obtain realistic data, which is the fundamentals of RL. In this paper, we first propose a series of metrics of simulators and summarize the features of existing benchmarks. Second, to ease comprehension, we recall the foundational knowledge and then synthesize the recently advanced studies of MARL-related autonomous driving and intelligent transportation systems. Specifically, we examine their environmental modeling, state representation, perception units, and algorithm design. Conclusively, we discuss open challenges as well as prospects and opportunities. We hope this paper can help the researchers integrate MARL technologies and trigger more insightful ideas toward the intelligent and autonomous driving.","sentences":["Reinforcement Learning (RL) is a potent tool for sequential decision-making and has achieved performance surpassing human capabilities across many challenging real-world tasks.","As the extension of RL in the multi-agent system domain, multi-agent RL (MARL) not only need to learn the control policy but also requires consideration regarding interactions with all other agents in the environment, mutual influences among different system components, and the distribution of computational resources.","This augments the complexity of algorithmic design and poses higher requirements on computational resources.","Simultaneously, simulators are crucial to obtain realistic data, which is the fundamentals of RL.","In this paper, we first propose a series of metrics of simulators and summarize the features of existing benchmarks.","Second, to ease comprehension, we recall the foundational knowledge and then synthesize the recently advanced studies of MARL-related autonomous driving and intelligent transportation systems.","Specifically, we examine their environmental modeling, state representation, perception units, and algorithm design.","Conclusively, we discuss open challenges as well as prospects and opportunities.","We hope this paper can help the researchers integrate MARL technologies and trigger more insightful ideas toward the intelligent and autonomous driving."],"url":"http://arxiv.org/abs/2408.09675v1"}
{"created":"2024-08-19 03:13:20","title":"GANPrompt: Enhancing Robustness in LLM-Based Recommendations with GAN-Enhanced Diversity Prompts","abstract":"In recent years, LLM has demonstrated remarkable proficiency in comprehending and generating natural language, with a growing prevalence in the domain of recommender systems. However, LLM continues to face a significant challenge in that it is highly susceptible to the influence of prompt words. This inconsistency in response to minor alterations in prompt input may compromise the accuracy and resilience of recommendation models. To address this issue, this paper proposes GANPrompt, a multi-dimensional large language model prompt diversity framework based on Generative Adversarial Networks (GANs). The framework enhances the model's adaptability and stability to diverse prompts by integrating GAN generation techniques with the deep semantic understanding capabilities of LLMs. GANPrompt first trains a generator capable of producing diverse prompts by analysing multidimensional user behavioural data. These diverse prompts are then used to train the LLM to improve its performance in the face of unseen prompts. Furthermore, to ensure a high degree of diversity and relevance of the prompts, this study introduces a mathematical theory-based diversity constraint mechanism that optimises the generated prompts to ensure that they are not only superficially distinct, but also semantically cover a wide range of user intentions. Through extensive experiments on multiple datasets, we demonstrate the effectiveness of the proposed framework, especially in improving the adaptability and robustness of recommender systems in complex and dynamic environments. The experimental results demonstrate that GANPrompt yields substantial enhancements in accuracy and robustness relative to existing state-of-the-art methodologies.","sentences":["In recent years, LLM has demonstrated remarkable proficiency in comprehending and generating natural language, with a growing prevalence in the domain of recommender systems.","However, LLM continues to face a significant challenge in that it is highly susceptible to the influence of prompt words.","This inconsistency in response to minor alterations in prompt input may compromise the accuracy and resilience of recommendation models.","To address this issue, this paper proposes GANPrompt, a multi-dimensional large language model prompt diversity framework based on Generative Adversarial Networks (GANs).","The framework enhances the model's adaptability and stability to diverse prompts by integrating GAN generation techniques with the deep semantic understanding capabilities of LLMs.","GANPrompt first trains a generator capable of producing diverse prompts by analysing multidimensional user behavioural data.","These diverse prompts are then used to train the LLM to improve its performance in the face of unseen prompts.","Furthermore, to ensure a high degree of diversity and relevance of the prompts, this study introduces a mathematical theory-based diversity constraint mechanism that optimises the generated prompts to ensure that they are not only superficially distinct, but also semantically cover a wide range of user intentions.","Through extensive experiments on multiple datasets, we demonstrate the effectiveness of the proposed framework, especially in improving the adaptability and robustness of recommender systems in complex and dynamic environments.","The experimental results demonstrate that GANPrompt yields substantial enhancements in accuracy and robustness relative to existing state-of-the-art methodologies."],"url":"http://arxiv.org/abs/2408.09671v1"}
{"created":"2024-08-19 02:59:35","title":"BLADE: Benchmarking Language Model Agents for Data-Driven Science","abstract":"Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider. LM-based agents equipped with planning, memory, and code execution capabilities have the potential to support data-driven science. However, evaluating agents on such open-ended tasks is challenging due to multiple valid approaches, partially correct steps, and different ways to express the same decisions. To address these challenges, we present BLADE, a benchmark to automatically evaluate agents' multifaceted approaches to open-ended research questions. BLADE consists of 12 datasets and research questions drawn from existing scientific literature, with ground truth collected from independent analyses by expert data scientists and researchers. To automatically evaluate agent responses, we developed corresponding computational methods to match different representations of analyses to this ground truth. Though language models possess considerable world knowledge, our evaluation shows that they are often limited to basic analyses. However, agents capable of interacting with the underlying data demonstrate improved, but still non-optimal, diversity in their analytical decision making. Our work enables the evaluation of agents for data-driven science and provides researchers deeper insights into agents' analysis approaches.","sentences":["Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider.","LM-based agents equipped with planning, memory, and code execution capabilities have the potential to support data-driven science.","However, evaluating agents on such open-ended tasks is challenging due to multiple valid approaches, partially correct steps, and different ways to express the same decisions.","To address these challenges, we present BLADE, a benchmark to automatically evaluate agents' multifaceted approaches to open-ended research questions.","BLADE consists of 12 datasets and research questions drawn from existing scientific literature, with ground truth collected from independent analyses by expert data scientists and researchers.","To automatically evaluate agent responses, we developed corresponding computational methods to match different representations of analyses to this ground truth.","Though language models possess considerable world knowledge, our evaluation shows that they are often limited to basic analyses.","However, agents capable of interacting with the underlying data demonstrate improved, but still non-optimal, diversity in their analytical decision making.","Our work enables the evaluation of agents for data-driven science and provides researchers deeper insights into agents' analysis approaches."],"url":"http://arxiv.org/abs/2408.09667v1"}
{"created":"2024-08-19 02:43:18","title":"An Algorithm for Enhancing Privacy-Utility Tradeoff in the Privacy Funnel and Other Lift-based Measures","abstract":"This paper investigates the privacy funnel, a privacy-utility tradeoff problem in which mutual information quantifies both privacy and utility. The objective is to maximize utility while adhering to a specified privacy budget. However, the privacy funnel represents a non-convex optimization problem, making it challenging to achieve an optimal solution. An existing proposed approach to this problem involves substituting the mutual information with the lift (the exponent of information density) and then solving the optimization. Since mutual information is the expectation of the information density, this substitution overestimates the privacy loss and results in a final smaller bound on the privacy of mutual information than what is allowed in the budget. This significantly compromises the utility. To overcome this limitation, we propose using a privacy measure that is more relaxed than the lift but stricter than mutual information while still allowing the optimization to be efficiently solved. Instead of directly using information density, our proposed measure is the average of information density over the sensitive data distribution for each observed data realization. We then introduce a heuristic algorithm capable of achieving solutions that produce extreme privacy values, which enhances utility. The numerical results confirm improved utility at the same privacy budget compared to existing solutions in the literature. Additionally, we explore two other privacy measures, $\\ell_{1}$-norm and strong $\\chi^2$-divergence, demonstrating the applicability of our algorithm to these lift-based measures. We evaluate the performance of our method by comparing its output with previous works. Finally, we validate our heuristic approach with a theoretical framework that estimates the optimal utility for strong $\\chi^2$-divergence, numerically showing a perfect match.","sentences":["This paper investigates the privacy funnel, a privacy-utility tradeoff problem in which mutual information quantifies both privacy and utility.","The objective is to maximize utility while adhering to a specified privacy budget.","However, the privacy funnel represents a non-convex optimization problem, making it challenging to achieve an optimal solution.","An existing proposed approach to this problem involves substituting the mutual information with the lift (the exponent of information density) and then solving the optimization.","Since mutual information is the expectation of the information density, this substitution overestimates the privacy loss and results in a final smaller bound on the privacy of mutual information than what is allowed in the budget.","This significantly compromises the utility.","To overcome this limitation, we propose using a privacy measure that is more relaxed than the lift but stricter than mutual information while still allowing the optimization to be efficiently solved.","Instead of directly using information density, our proposed measure is the average of information density over the sensitive data distribution for each observed data realization.","We then introduce a heuristic algorithm capable of achieving solutions that produce extreme privacy values, which enhances utility.","The numerical results confirm improved utility at the same privacy budget compared to existing solutions in the literature.","Additionally, we explore two other privacy measures, $\\ell_{1}$-norm and strong $\\chi^2$-divergence, demonstrating the applicability of our algorithm to these lift-based measures.","We evaluate the performance of our method by comparing its output with previous works.","Finally, we validate our heuristic approach with a theoretical framework that estimates the optimal utility for strong $\\chi^2$-divergence, numerically showing a perfect match."],"url":"http://arxiv.org/abs/2408.09659v1"}
{"created":"2024-08-19 02:36:07","title":"Impact of Large Language Models of Code on Fault Localization","abstract":"Identifying the point of error is imperative in software debugging. Traditional fault localization (FL) techniques rely on executing the program and using the code coverage matrix in tandem with test case results to calculate a suspiciousness score for each function or line. Recently, learning-based FL techniques have harnessed machine learning models to extract meaningful features from the code coverage matrix and improve FL performance. These techniques, however, require compilable source code, existing test cases, and specialized tools for generating the code coverage matrix for each programming language of interest.   In this paper, we propose, for the first time, a simple but effective sequence generation approach for fine-tuning large language models of code (LLMCs) for FL tasks. LLMCs have recently received much attention for various software engineering problems. In line with these, we leverage the innate understanding of code that LLMCs have acquired through pre-training on large code corpora. Specifically, we fine-tune representative encoder, encoder-decoder, and decoder-based 13 LLMCs for FL tasks. Unlike previous approaches, LLMCs can analyze code sequences even with syntactic errors, since they do not rely on compiled input. Still, they have a limitation on the length of the input data. Therefore, for a fair comparison with existing FL techniques, we extract methods with errors from the project-level benchmark, Defects4J, and analyze them at the line level. Experimental results show that LLMCs fine-tuned with our approach successfully pinpoint error positions in 50.6\\%, 64.2\\%, and 72.3\\% of 1,291 methods in Defects4J for Top-1/3/5 prediction, outperforming the best learning-based state-of-the-art technique by up to 1.35, 1.12, and 1.08 times, respectively. Our findings suggest promising research directions for FL and automated program repair tasks using LLMCs.","sentences":["Identifying the point of error is imperative in software debugging.","Traditional fault localization (FL) techniques rely on executing the program and using the code coverage matrix in tandem with test case results to calculate a suspiciousness score for each function or line.","Recently, learning-based FL techniques have harnessed machine learning models to extract meaningful features from the code coverage matrix and improve FL performance.","These techniques, however, require compilable source code, existing test cases, and specialized tools for generating the code coverage matrix for each programming language of interest.   ","In this paper, we propose, for the first time, a simple but effective sequence generation approach for fine-tuning large language models of code (LLMCs) for FL tasks.","LLMCs have recently received much attention for various software engineering problems.","In line with these, we leverage the innate understanding of code that LLMCs have acquired through pre-training on large code corpora.","Specifically, we fine-tune representative encoder, encoder-decoder, and decoder-based 13 LLMCs for FL tasks.","Unlike previous approaches, LLMCs can analyze code sequences even with syntactic errors, since they do not rely on compiled input.","Still, they have a limitation on the length of the input data.","Therefore, for a fair comparison with existing FL techniques, we extract methods with errors from the project-level benchmark, Defects4J, and analyze them at the line level.","Experimental results show that LLMCs fine-tuned with our approach successfully pinpoint error positions in 50.6\\%, 64.2\\%, and 72.3\\% of 1,291 methods in Defects4J for Top-1/3/5 prediction, outperforming the best learning-based state-of-the-art technique by up to 1.35, 1.12, and 1.08 times, respectively.","Our findings suggest promising research directions for FL and automated program repair tasks using LLMCs."],"url":"http://arxiv.org/abs/2408.09657v1"}
{"created":"2024-08-19 02:30:37","title":"Contextual Bandits for Unbounded Context Distributions","abstract":"Nonparametric contextual bandit is an important model of sequential decision making problems. Under $\\alpha$-Tsybakov margin condition, existing research has established a regret bound of $\\tilde{O}\\left(T^{1-\\frac{\\alpha+1}{d+2}}\\right)$ for bounded supports. However, the optimal regret with unbounded contexts has not been analyzed. The challenge of solving contextual bandit problems with unbounded support is to achieve both exploration-exploitation tradeoff and bias-variance tradeoff simultaneously. In this paper, we solve the nonparametric contextual bandit problem with unbounded contexts. We propose two nearest neighbor methods combined with UCB exploration. The first method uses a fixed $k$. Our analysis shows that this method achieves minimax optimal regret under a weak margin condition and relatively light-tailed context distributions. The second method uses adaptive $k$. By a proper data-driven selection of $k$, this method achieves an expected regret of $\\tilde{O}\\left(T^{1-\\frac{(\\alpha+1)\\beta}{\\alpha+(d+2)\\beta}}+T^{1-\\beta}\\right)$, in which $\\beta$ is a parameter describing the tail strength. This bound matches the minimax lower bound up to logarithm factors, indicating that the second method is approximately optimal.","sentences":["Nonparametric contextual bandit is an important model of sequential decision making problems.","Under $\\alpha$-Tsybakov margin condition, existing research has established a regret bound of $\\tilde{O}\\left(T^{1-\\frac{\\alpha+1}{d+2}}\\right)$ for bounded supports.","However, the optimal regret with unbounded contexts has not been analyzed.","The challenge of solving contextual bandit problems with unbounded support is to achieve both exploration-exploitation tradeoff and bias-variance tradeoff simultaneously.","In this paper, we solve the nonparametric contextual bandit problem with unbounded contexts.","We propose two nearest neighbor methods combined with UCB exploration.","The first method uses a fixed $k$. Our analysis shows that this method achieves minimax optimal regret under a weak margin condition and relatively light-tailed context distributions.","The second method uses adaptive $k$. By a proper data-driven selection of $k$, this method achieves an expected regret of $\\tilde{O}\\left(T^{1-\\frac{(\\alpha+1)\\beta}{\\alpha+(d+2)\\beta}}+T^{1-\\beta}\\right)$, in which $\\beta$ is a parameter describing the tail strength.","This bound matches the minimax lower bound up to logarithm factors, indicating that the second method is approximately optimal."],"url":"http://arxiv.org/abs/2408.09655v1"}
{"created":"2024-08-19 02:17:22","title":"Data-driven Conditional Instrumental Variables for Debiasing Recommender Systems","abstract":"In recommender systems, latent variables can cause user-item interaction data to deviate from true user preferences. This biased data is then used to train recommendation models, further amplifying the bias and ultimately compromising both recommendation accuracy and user satisfaction. Instrumental Variable (IV) methods are effective tools for addressing the confounding bias introduced by latent variables; however, identifying a valid IV is often challenging. To overcome this issue, we propose a novel data-driven conditional IV (CIV) debiasing method for recommender systems, called CIV4Rec. CIV4Rec automatically generates valid CIVs and their corresponding conditioning sets directly from interaction data, significantly reducing the complexity of IV selection while effectively mitigating the confounding bias caused by latent variables in recommender systems. Specifically, CIV4Rec leverages a variational autoencoder (VAE) to generate the representations of the CIV and its conditional set from interaction data, followed by the application of least squares to derive causal representations for click prediction. Extensive experiments on two real-world datasets, Movielens-10M and Douban-Movie, demonstrate that our CIV4Rec successfully identifies valid CIVs, effectively reduces bias, and consequently improves recommendation accuracy.","sentences":["In recommender systems, latent variables can cause user-item interaction data to deviate from true user preferences.","This biased data is then used to train recommendation models, further amplifying the bias and ultimately compromising both recommendation accuracy and user satisfaction.","Instrumental Variable (IV) methods are effective tools for addressing the confounding bias introduced by latent variables; however, identifying a valid IV is often challenging.","To overcome this issue, we propose a novel data-driven conditional IV (CIV) debiasing method for recommender systems, called CIV4Rec.","CIV4Rec automatically generates valid CIVs and their corresponding conditioning sets directly from interaction data, significantly reducing the complexity of IV selection while effectively mitigating the confounding bias caused by latent variables in recommender systems.","Specifically, CIV4Rec leverages a variational autoencoder (VAE) to generate the representations of the CIV and its conditional set from interaction data, followed by the application of least squares to derive causal representations for click prediction.","Extensive experiments on two real-world datasets, Movielens-10M and Douban-Movie, demonstrate that our CIV4Rec successfully identifies valid CIVs, effectively reduces bias, and consequently improves recommendation accuracy."],"url":"http://arxiv.org/abs/2408.09651v1"}
{"created":"2024-08-19 02:12:40","title":"Debiased Contrastive Representation Learning for Mitigating Dual Biases in Recommender Systems","abstract":"In recommender systems, popularity and conformity biases undermine recommender effectiveness by disproportionately favouring popular items, leading to their over-representation in recommendation lists and causing an unbalanced distribution of user-item historical data. We construct a causal graph to address both biases and describe the abstract data generation mechanism. Then, we use it as a guide to develop a novel Debiased Contrastive Learning framework for Mitigating Dual Biases, called DCLMDB. In DCLMDB, both popularity bias and conformity bias are handled in the model training process by contrastive learning to ensure that user choices and recommended items are not unduly influenced by conformity and popularity. Extensive experiments on two real-world datasets, Movielens-10M and Netflix, show that DCLMDB can effectively reduce the dual biases, as well as significantly enhance the accuracy and diversity of recommendations.","sentences":["In recommender systems, popularity and conformity biases undermine recommender effectiveness by disproportionately favouring popular items, leading to their over-representation in recommendation lists and causing an unbalanced distribution of user-item historical data.","We construct a causal graph to address both biases and describe the abstract data generation mechanism.","Then, we use it as a guide to develop a novel Debiased Contrastive Learning framework for Mitigating Dual Biases, called DCLMDB.","In DCLMDB, both popularity bias and conformity bias are handled in the model training process by contrastive learning to ensure that user choices and recommended items are not unduly influenced by conformity and popularity.","Extensive experiments on two real-world datasets, Movielens-10M and Netflix, show that DCLMDB can effectively reduce the dual biases, as well as significantly enhance the accuracy and diversity of recommendations."],"url":"http://arxiv.org/abs/2408.09646v1"}
{"created":"2024-08-19 01:39:12","title":"Meta-Learning on Augmented Gene Expression Profiles for Enhanced Lung Cancer Detection","abstract":"Gene expression profiles obtained through DNA microarray have proven successful in providing critical information for cancer detection classifiers. However, the limited number of samples in these datasets poses a challenge to employ complex methodologies such as deep neural networks for sophisticated analysis. To address this \"small data\" dilemma, Meta-Learning has been introduced as a solution to enhance the optimization of machine learning models by utilizing similar datasets, thereby facilitating a quicker adaptation to target datasets without the requirement of sufficient samples. In this study, we present a meta-learning-based approach for predicting lung cancer from gene expression profiles. We apply this framework to well-established deep learning methodologies and employ four distinct datasets for the meta-learning tasks, where one as the target dataset and the rest as source datasets. Our approach is evaluated against both traditional and deep learning methodologies, and the results show the superior performance of meta-learning on augmented source data compared to the baselines trained on single datasets. Moreover, we conduct the comparative analysis between meta-learning and transfer learning methodologies to highlight the efficiency of the proposed approach in addressing the challenges associated with limited sample sizes. Finally, we incorporate the explainability study to illustrate the distinctiveness of decisions made by meta-learning.","sentences":["Gene expression profiles obtained through DNA microarray have proven successful in providing critical information for cancer detection classifiers.","However, the limited number of samples in these datasets poses a challenge to employ complex methodologies such as deep neural networks for sophisticated analysis.","To address this \"small data\" dilemma, Meta-Learning has been introduced as a solution to enhance the optimization of machine learning models by utilizing similar datasets, thereby facilitating a quicker adaptation to target datasets without the requirement of sufficient samples.","In this study, we present a meta-learning-based approach for predicting lung cancer from gene expression profiles.","We apply this framework to well-established deep learning methodologies and employ four distinct datasets for the meta-learning tasks, where one as the target dataset and the rest as source datasets.","Our approach is evaluated against both traditional and deep learning methodologies, and the results show the superior performance of meta-learning on augmented source data compared to the baselines trained on single datasets.","Moreover, we conduct the comparative analysis between meta-learning and transfer learning methodologies to highlight the efficiency of the proposed approach in addressing the challenges associated with limited sample sizes.","Finally, we incorporate the explainability study to illustrate the distinctiveness of decisions made by meta-learning."],"url":"http://arxiv.org/abs/2408.09635v1"}
{"created":"2024-08-19 00:26:53","title":"Refining Packing and Shuffling Strategies for Enhanced Performance in Generative Language Models","abstract":"Packing and shuffling tokens is a common practice in training auto-regressive language models (LMs) to prevent overfitting and improve efficiency. Typically documents are concatenated to chunks of maximum sequence length (MSL) and then shuffled. However setting the atom size, the length for each data chunk accompanied by random shuffling, to MSL may lead to contextual incoherence due to tokens from different documents being packed into the same chunk. An alternative approach is to utilize padding, another common data packing strategy, to avoid contextual incoherence by only including one document in each shuffled chunk. To optimize both packing strategies (concatenation vs padding), we investigated the optimal atom size for shuffling and compared their performance and efficiency. We found that matching atom size to MSL optimizes performance for both packing methods (concatenation and padding), and padding yields lower final perplexity (higher performance) than concatenation at the cost of more training steps and lower compute efficiency. This trade-off informs the choice of packing methods in training language models.","sentences":["Packing and shuffling tokens is a common practice in training auto-regressive language models (LMs) to prevent overfitting and improve efficiency.","Typically documents are concatenated to chunks of maximum sequence length (MSL) and then shuffled.","However setting the atom size, the length for each data chunk accompanied by random shuffling, to MSL may lead to contextual incoherence due to tokens from different documents being packed into the same chunk.","An alternative approach is to utilize padding, another common data packing strategy, to avoid contextual incoherence by only including one document in each shuffled chunk.","To optimize both packing strategies (concatenation vs padding), we investigated the optimal atom size for shuffling and compared their performance and efficiency.","We found that matching atom size to MSL optimizes performance for both packing methods (concatenation and padding), and padding yields lower final perplexity (higher performance) than concatenation at the cost of more training steps and lower compute efficiency.","This trade-off informs the choice of packing methods in training language models."],"url":"http://arxiv.org/abs/2408.09621v1"}
{"created":"2024-08-18 21:45:03","title":"Antidote: Post-fine-tuning Safety Alignment for Large Language Models against Harmful Fine-tuning","abstract":"Safety aligned Large Language Models (LLMs) are vulnerable to harmful fine-tuning attacks \\cite{qi2023fine}-- a few harmful data mixed in the fine-tuning dataset can break the LLMs's safety alignment. Existing mitigation strategies include alignment stage solutions \\cite{huang2024vaccine, rosati2024representation} and fine-tuning stage solutions \\cite{huang2024lazy,mukhoti2023fine}. However, our evaluation shows that both categories of defenses fail \\textit{when some specific training hyper-parameters are chosen} -- a large learning rate or a large number of training epochs in the fine-tuning stage can easily invalidate the defense, which however, is necessary to guarantee finetune performance. To this end, we propose Antidote, a post-fine-tuning stage solution, which remains \\textbf{\\textit{agnostic to the training hyper-parameters in the fine-tuning stage}}. Antidote relies on the philosophy that by removing the harmful parameters, the harmful model can be recovered from the harmful behaviors, regardless of how those harmful parameters are formed in the fine-tuning stage. With this philosophy, we introduce a one-shot pruning stage after harmful fine-tuning to remove the harmful weights that are responsible for the generation of harmful content. Despite its embarrassing simplicity, empirical results show that Antidote can reduce harmful score while maintaining accuracy on downstream tasks.","sentences":["Safety aligned Large Language Models (LLMs) are vulnerable to harmful fine-tuning attacks \\cite{qi2023fine}-- a few harmful data mixed in the fine-tuning dataset can break the LLMs's safety alignment.","Existing mitigation strategies include alignment stage solutions \\cite{huang2024vaccine, rosati2024representation} and fine-tuning stage solutions \\cite{huang2024lazy,mukhoti2023fine}.","However, our evaluation shows that both categories of defenses fail \\textit{when some specific training hyper-parameters are chosen} -- a large learning rate or a large number of training epochs in the fine-tuning stage can easily invalidate the defense, which however, is necessary to guarantee finetune performance.","To this end, we propose Antidote, a post-fine-tuning stage solution, which remains \\textbf{\\textit{agnostic to the training hyper-parameters in the fine-tuning stage}}.","Antidote relies on the philosophy that by removing the harmful parameters, the harmful model can be recovered from the harmful behaviors, regardless of how those harmful parameters are formed in the fine-tuning stage.","With this philosophy, we introduce a one-shot pruning stage after harmful fine-tuning to remove the harmful weights that are responsible for the generation of harmful content.","Despite its embarrassing simplicity, empirical results show that Antidote can reduce harmful score while maintaining accuracy on downstream tasks."],"url":"http://arxiv.org/abs/2408.09600v1"}
{"created":"2024-08-18 20:59:59","title":"Moonshine: Distilling Game Content Generators into Steerable Generative Models","abstract":"Procedural Content Generation via Machine Learning (PCGML) has enhanced game content creation, yet challenges in controllability and limited training data persist. This study addresses these issues by distilling a constructive PCG algorithm into a controllable PCGML model. We first generate a large amount of content with a constructive algorithm and label it using a Large Language Model (LLM). We use these synthetic labels to condition two PCGML models for content-specific generation, a diffusion model and the five-dollar model. This neural network distillation process ensures that the generation aligns with the original algorithm while introducing controllability through plain text. We define this text-conditioned PCGML as a Text-to-game-Map (T2M) task, offering an alternative to prevalent text-to-image multi-modal tasks. We compare our distilled models with the baseline constructive algorithm. Our analysis of the variety, accuracy, and quality of our generation demonstrates the efficacy of distilling constructive methods into controllable text-conditioned PCGML models.","sentences":["Procedural Content Generation via Machine Learning (PCGML) has enhanced game content creation, yet challenges in controllability and limited training data persist.","This study addresses these issues by distilling a constructive PCG algorithm into a controllable PCGML model.","We first generate a large amount of content with a constructive algorithm and label it using a Large Language Model (LLM).","We use these synthetic labels to condition two PCGML models for content-specific generation, a diffusion model and the five-dollar model.","This neural network distillation process ensures that the generation aligns with the original algorithm while introducing controllability through plain text.","We define this text-conditioned PCGML as a Text-to-game-Map (T2M) task, offering an alternative to prevalent text-to-image multi-modal tasks.","We compare our distilled models with the baseline constructive algorithm.","Our analysis of the variety, accuracy, and quality of our generation demonstrates the efficacy of distilling constructive methods into controllable text-conditioned PCGML models."],"url":"http://arxiv.org/abs/2408.09594v1"}
{"created":"2024-08-18 20:58:54","title":"Osiris: A Systolic Approach to Accelerating Fully Homomorphic Encryption","abstract":"In this paper we show how fully homomorphic encryption (FHE) can be accelerated using a systolic architecture. We begin by analyzing FHE algorithms and then develop systolic or systolic-esque units for each major kernel. Connecting units is challenging due to the different data access and computational patterns of the kernels. We overcome this by proposing a new data tiling technique that we name limb interleaving. Limb interleaving creates a common data input/output pattern across all kernels that allows the entire architecture, named Osiris, to operate in lockstep. Osiris is capable of processing key-switches, bootstrapping, and full neural network inferences with high utilization across a range of FHE parameters. To achieve high performance, we propose a new giant-step centric (GSC) dataflow that efficiently maps state-of-the-art FHE matrix-vector product algorithms onto Osiris by optimizing for reuse and parallelism. Our evaluation of Osiris shows it outperforms the prior state-of-the-art accelerator on all standard benchmarks.","sentences":["In this paper we show how fully homomorphic encryption (FHE) can be accelerated using a systolic architecture.","We begin by analyzing FHE algorithms and then develop systolic or systolic-esque units for each major kernel.","Connecting units is challenging due to the different data access and computational patterns of the kernels.","We overcome this by proposing a new data tiling technique that we name limb interleaving.","Limb interleaving creates a common data input/output pattern across all kernels that allows the entire architecture, named Osiris, to operate in lockstep.","Osiris is capable of processing key-switches, bootstrapping, and full neural network inferences with high utilization across a range of FHE parameters.","To achieve high performance, we propose a new giant-step centric (GSC) dataflow that efficiently maps state-of-the-art FHE matrix-vector product algorithms onto Osiris by optimizing for reuse and parallelism.","Our evaluation of Osiris shows it outperforms the prior state-of-the-art accelerator on all standard benchmarks."],"url":"http://arxiv.org/abs/2408.09593v1"}
{"created":"2024-08-18 20:43:55","title":"Pre-assignment problem for unique minimum vertex cover on bounded clique-width graphs","abstract":"Horiyama et al. (AAAI 2024) considered the problem of generating instances with a unique minimum vertex cover under certain conditions. The Pre-assignment for Uniquification of Minimum Vertex Cover problem (shortly PAU-VC) is the problem, for given a graph $G$, to find a minimum set $S$ of vertices in $G$ such that there is a unique minimum vertex cover of $G$ containing $S$. We show that PAU-VC is fixed-parameter tractable parameterized by clique-width, which improves an exponential algorithm for trees given by Horiyama et al. Among natural graph classes with unbounded clique-width, we show that the problem can be solved in linear time on split graphs and unit interval graphs.","sentences":["Horiyama et al. (AAAI 2024) considered the problem of generating instances with a unique minimum vertex cover under certain conditions.","The Pre-assignment for Uniquification of Minimum Vertex Cover problem (shortly PAU-VC) is the problem, for given a graph $G$, to find a minimum set $S$ of vertices in $G$ such that there is a unique minimum vertex cover of $G$ containing $S$. We show that PAU-VC is fixed-parameter tractable parameterized by clique-width, which improves an exponential algorithm for trees given by Horiyama et al.","Among natural graph classes with unbounded clique-width, we show that the problem can be solved in linear time on split graphs and unit interval graphs."],"url":"http://arxiv.org/abs/2408.09591v1"}
{"created":"2024-08-18 20:08:42","title":"On the Necessity of World Knowledge for Mitigating Missing Labels in Extreme Classification","abstract":"Extreme Classification (XC) aims to map a query to the most relevant documents from a very large document set. XC algorithms used in real-world applications learn this mapping from datasets curated from implicit feedback, such as user clicks. However, these datasets inevitably suffer from missing labels. In this work, we observe that systematic missing labels lead to missing knowledge, which is critical for accurately modelling relevance between queries and documents. We formally show that this absence of knowledge cannot be recovered using existing methods such as propensity weighting and data imputation strategies that solely rely on the training dataset. While LLMs provide an attractive solution to augment the missing knowledge, leveraging them in applications with low latency requirements and large document sets is challenging. To incorporate missing knowledge at scale, we propose SKIM (Scalable Knowledge Infusion for Missing Labels), an algorithm that leverages a combination of small LM and abundant unstructured meta-data to effectively mitigate the missing label problem. We show the efficacy of our method on large-scale public datasets through exhaustive unbiased evaluation ranging from human annotations to simulations inspired from industrial settings. SKIM outperforms existing methods on Recall@100 by more than 10 absolute points. Additionally, SKIM scales to proprietary query-ad retrieval datasets containing 10 million documents, outperforming contemporary methods by 12% in offline evaluation and increased ad click-yield by 1.23% in an online A/B test conducted on a popular search engine. We release our code, prompts, trained XC models and finetuned SLMs at: https://github.com/bicycleman15/skim","sentences":["Extreme Classification (XC) aims to map a query to the most relevant documents from a very large document set.","XC algorithms used in real-world applications learn this mapping from datasets curated from implicit feedback, such as user clicks.","However, these datasets inevitably suffer from missing labels.","In this work, we observe that systematic missing labels lead to missing knowledge, which is critical for accurately modelling relevance between queries and documents.","We formally show that this absence of knowledge cannot be recovered using existing methods such as propensity weighting and data imputation strategies that solely rely on the training dataset.","While LLMs provide an attractive solution to augment the missing knowledge, leveraging them in applications with low latency requirements and large document sets is challenging.","To incorporate missing knowledge at scale, we propose SKIM (Scalable Knowledge Infusion for Missing Labels), an algorithm that leverages a combination of small LM and abundant unstructured meta-data to effectively mitigate the missing label problem.","We show the efficacy of our method on large-scale public datasets through exhaustive unbiased evaluation ranging from human annotations to simulations inspired from industrial settings.","SKIM outperforms existing methods on Recall@100 by more than 10 absolute points.","Additionally, SKIM scales to proprietary query-ad retrieval datasets containing 10 million documents, outperforming contemporary methods by 12% in offline evaluation and increased ad click-yield by 1.23% in an online A/B test conducted on a popular search engine.","We release our code, prompts, trained XC models and finetuned SLMs at: https://github.com/bicycleman15/skim"],"url":"http://arxiv.org/abs/2408.09585v1"}
{"created":"2024-08-18 19:27:30","title":"A Markov Random Field Multi-Modal Variational AutoEncoder","abstract":"Recent advancements in multimodal Variational AutoEncoders (VAEs) have highlighted their potential for modeling complex data from multiple modalities. However, many existing approaches use relatively straightforward aggregating schemes that may not fully capture the complex dynamics present between different modalities. This work introduces a novel multimodal VAE that incorporates a Markov Random Field (MRF) into both the prior and posterior distributions. This integration aims to capture complex intermodal interactions more effectively. Unlike previous models, our approach is specifically designed to model and leverage the intricacies of these relationships, enabling a more faithful representation of multimodal data. Our experiments demonstrate that our model performs competitively on the standard PolyMNIST dataset and shows superior performance in managing complex intermodal dependencies in a specially designed synthetic dataset, intended to test intricate relationships.","sentences":["Recent advancements in multimodal Variational AutoEncoders (VAEs) have highlighted their potential for modeling complex data from multiple modalities.","However, many existing approaches use relatively straightforward aggregating schemes that may not fully capture the complex dynamics present between different modalities.","This work introduces a novel multimodal VAE that incorporates a Markov Random Field (MRF) into both the prior and posterior distributions.","This integration aims to capture complex intermodal interactions more effectively.","Unlike previous models, our approach is specifically designed to model and leverage the intricacies of these relationships, enabling a more faithful representation of multimodal data.","Our experiments demonstrate that our model performs competitively on the standard PolyMNIST dataset and shows superior performance in managing complex intermodal dependencies in a specially designed synthetic dataset, intended to test intricate relationships."],"url":"http://arxiv.org/abs/2408.09576v1"}
{"created":"2024-08-18 17:53:26","title":"Generating Automatically Print/Scan Textures for Morphing Attack Detection Applications","abstract":"Morphing Attack Detection (MAD) is a relevant topic that aims to detect attempts by unauthorised individuals to access a \"valid\" identity. One of the main scenarios is printing morphed images and submitting the respective print in a passport application process. Today, small datasets are available to train the MAD algorithm because of privacy concerns and the limitations resulting from the effort associated with the printing and scanning of images at large numbers. In order to improve the detection capabilities and spot such morphing attacks, it will be necessary to have a larger and more realistic dataset representing the passport application scenario with the diversity of devices and the resulting printed scanned or compressed images. Creating training data representing the diversity of attacks is a very demanding task because the training material is developed manually. This paper proposes two different methods based on transfer-transfer for automatically creating digital print/scan face images and using such images in the training of a Morphing Attack Detection algorithm. Our proposed method can reach an Equal Error Rate (EER) of 3.84% and 1.92% on the FRGC/FERET database when including our synthetic and texture-transfer print/scan with 600 dpi to handcrafted images, respectively.","sentences":["Morphing Attack Detection (MAD) is a relevant topic that aims to detect attempts by unauthorised individuals to access a \"valid\" identity.","One of the main scenarios is printing morphed images and submitting the respective print in a passport application process.","Today, small datasets are available to train the MAD algorithm because of privacy concerns and the limitations resulting from the effort associated with the printing and scanning of images at large numbers.","In order to improve the detection capabilities and spot such morphing attacks, it will be necessary to have a larger and more realistic dataset representing the passport application scenario with the diversity of devices and the resulting printed scanned or compressed images.","Creating training data representing the diversity of attacks is a very demanding task because the training material is developed manually.","This paper proposes two different methods based on transfer-transfer for automatically creating digital print/scan face images and using such images in the training of a Morphing Attack Detection algorithm.","Our proposed method can reach an Equal Error Rate (EER) of 3.84% and 1.92% on the FRGC/FERET database when including our synthetic and texture-transfer print/scan with 600 dpi to handcrafted images, respectively."],"url":"http://arxiv.org/abs/2408.09558v1"}
{"created":"2024-08-18 17:49:44","title":"Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment","abstract":"Federated learning (FL) has emerged as a promising approach to training machine learning models across decentralized data sources while preserving data privacy, particularly in manufacturing and shared production environments. However, the presence of data heterogeneity variations in data distribution, quality, and volume across different or clients and production sites, poses significant challenges to the effectiveness and efficiency of FL. This paper provides a comprehensive overview of heterogeneity in FL within the context of manufacturing, detailing the types and sources of heterogeneity, including non-independent and identically distributed (non-IID) data, unbalanced data, variable data quality, and statistical heterogeneity. We discuss the impact of these types of heterogeneity on model training and review current methodologies for mitigating their adverse effects. These methodologies include personalized and customized models, robust aggregation techniques, and client selection techniques. By synthesizing existing research and proposing new strategies, this paper aims to provide insight for effectively managing data heterogeneity in FL, enhancing model robustness, and ensuring fair and efficient training across diverse environments. Future research directions are also identified, highlighting the need for adaptive and scalable solutions to further improve the FL paradigm in the context of Industry 4.0.","sentences":["Federated learning (FL) has emerged as a promising approach to training machine learning models across decentralized data sources while preserving data privacy, particularly in manufacturing and shared production environments.","However, the presence of data heterogeneity variations in data distribution, quality, and volume across different or clients and production sites, poses significant challenges to the effectiveness and efficiency of FL.","This paper provides a comprehensive overview of heterogeneity in FL within the context of manufacturing, detailing the types and sources of heterogeneity, including non-independent and identically distributed (non-IID) data, unbalanced data, variable data quality, and statistical heterogeneity.","We discuss the impact of these types of heterogeneity on model training and review current methodologies for mitigating their adverse effects.","These methodologies include personalized and customized models, robust aggregation techniques, and client selection techniques.","By synthesizing existing research and proposing new strategies, this paper aims to provide insight for effectively managing data heterogeneity in FL, enhancing model robustness, and ensuring fair and efficient training across diverse environments.","Future research directions are also identified, highlighting the need for adaptive and scalable solutions to further improve the FL paradigm in the context of Industry 4.0."],"url":"http://arxiv.org/abs/2408.09556v1"}
{"created":"2024-08-18 17:16:49","title":"Seamless Integration: Sampling Strategies in Federated Learning Systems","abstract":"Federated Learning (FL) represents a paradigm shift in the field of machine learning, offering an approach for a decentralized training of models across a multitude of devices while maintaining the privacy of local data. However, the dynamic nature of FL systems, characterized by the ongoing incorporation of new clients with potentially diverse data distributions and computational capabilities, poses a significant challenge to the stability and efficiency of these distributed learning networks. The seamless integration of new clients is imperative to sustain and enhance the performance and robustness of FL systems. This paper looks into the complexities of integrating new clients into existing FL systems and explores how data heterogeneity and varying data distribution (not independent and identically distributed) among them can affect model training, system efficiency, scalability and stability. Despite these challenges, the integration of new clients into FL systems presents opportunities to enhance data diversity, improve learning performance, and leverage distributed computational power. In contrast to other fields of application such as the distributed optimization of word predictions on Gboard (where federated learning once originated), there are usually only a few clients in the production environment, which is why information from each new client becomes all the more valuable. This paper outlines strategies for effective client selection strategies and solutions for ensuring system scalability and stability. Using the example of images from optical quality inspection, it offers insights into practical approaches. In conclusion, this paper proposes that addressing the challenges presented by new client integration is crucial to the advancement and efficiency of distributed learning networks, thus paving the way for the adoption of Federated Learning in production environments.","sentences":["Federated Learning (FL) represents a paradigm shift in the field of machine learning, offering an approach for a decentralized training of models across a multitude of devices while maintaining the privacy of local data.","However, the dynamic nature of FL systems, characterized by the ongoing incorporation of new clients with potentially diverse data distributions and computational capabilities, poses a significant challenge to the stability and efficiency of these distributed learning networks.","The seamless integration of new clients is imperative to sustain and enhance the performance and robustness of FL systems.","This paper looks into the complexities of integrating new clients into existing FL systems and explores how data heterogeneity and varying data distribution (not independent and identically distributed) among them can affect model training, system efficiency, scalability and stability.","Despite these challenges, the integration of new clients into FL systems presents opportunities to enhance data diversity, improve learning performance, and leverage distributed computational power.","In contrast to other fields of application such as the distributed optimization of word predictions on Gboard (where federated learning once originated), there are usually only a few clients in the production environment, which is why information from each new client becomes all the more valuable.","This paper outlines strategies for effective client selection strategies and solutions for ensuring system scalability and stability.","Using the example of images from optical quality inspection, it offers insights into practical approaches.","In conclusion, this paper proposes that addressing the challenges presented by new client integration is crucial to the advancement and efficiency of distributed learning networks, thus paving the way for the adoption of Federated Learning in production environments."],"url":"http://arxiv.org/abs/2408.09545v1"}
{"created":"2024-08-18 16:51:28","title":"Using ChatGPT to Score Essays and Short-Form Constructed Responses","abstract":"This study aimed to determine if ChatGPT's large language models could match the scoring accuracy of human and machine scores from the ASAP competition. The investigation focused on various prediction models, including linear regression, random forest, gradient boost, and boost. ChatGPT's performance was evaluated against human raters using quadratic weighted kappa (QWK) metrics. Results indicated that while ChatGPT's gradient boost model achieved QWKs close to human raters for some data sets, its overall performance was inconsistent and often lower than human scores. The study highlighted the need for further refinement, particularly in handling biases and ensuring scoring fairness. Despite these challenges, ChatGPT demonstrated potential for scoring efficiency, especially with domain-specific fine-tuning. The study concludes that ChatGPT can complement human scoring but requires additional development to be reliable for high-stakes assessments. Future research should improve model accuracy, address ethical considerations, and explore hybrid models combining ChatGPT with empirical methods.","sentences":["This study aimed to determine if ChatGPT's large language models could match the scoring accuracy of human and machine scores from the ASAP competition.","The investigation focused on various prediction models, including linear regression, random forest, gradient boost, and boost.","ChatGPT's performance was evaluated against human raters using quadratic weighted kappa (QWK) metrics.","Results indicated that while ChatGPT's gradient boost model achieved QWKs close to human raters for some data sets, its overall performance was inconsistent and often lower than human scores.","The study highlighted the need for further refinement, particularly in handling biases and ensuring scoring fairness.","Despite these challenges, ChatGPT demonstrated potential for scoring efficiency, especially with domain-specific fine-tuning.","The study concludes that ChatGPT can complement human scoring but requires additional development to be reliable for high-stakes assessments.","Future research should improve model accuracy, address ethical considerations, and explore hybrid models combining ChatGPT with empirical methods."],"url":"http://arxiv.org/abs/2408.09540v1"}
{"created":"2024-08-18 16:50:39","title":"Byzantine-resilient Federated Learning Employing Normalized Gradients on Non-IID Datasets","abstract":"In practical federated learning (FL) systems, the presence of malicious Byzantine attacks and data heterogeneity often introduces biases into the learning process. However, existing Byzantine-robust methods typically only achieve a compromise between adaptability to different loss function types (including both strongly convex and non-convex) and robustness to heterogeneous datasets, but with non-zero optimality gap. Moreover, this compromise often comes at the cost of high computational complexity for aggregation, which significantly slows down the training speed. To address this challenge, we propose a federated learning approach called Federated Normalized Gradients Algorithm (Fed-NGA). Fed-NGA simply normalizes the uploaded local gradients to be unit vectors before aggregation, achieving a time complexity of $\\mathcal{O}(pM)$, where $p$ represents the dimension of model parameters and $M$ is the number of participating clients. This complexity scale achieves the best level among all the existing Byzantine-robust methods. Furthermore, through rigorous proof, we demonstrate that Fed-NGA transcends the trade-off between adaptability to loss function type and data heterogeneity and the limitation of non-zero optimality gap in existing literature. Specifically, Fed-NGA can adapt to both non-convex loss functions and non-IID datasets simultaneously, with zero optimality gap at a rate of $\\mathcal{O} (1/T^{\\frac{1}{2} - \\delta})$, where T is the iteration number and $\\delta \\in (0,\\frac{1}{2})$. In cases where the loss function is strongly convex, the zero optimality gap achieving rate can be improved to be linear. Experimental results provide evidence of the superiority of our proposed Fed-NGA on time complexity and convergence performance over baseline methods.","sentences":["In practical federated learning (FL) systems, the presence of malicious Byzantine attacks and data heterogeneity often introduces biases into the learning process.","However, existing Byzantine-robust methods typically only achieve a compromise between adaptability to different loss function types (including both strongly convex and non-convex) and robustness to heterogeneous datasets, but with non-zero optimality gap.","Moreover, this compromise often comes at the cost of high computational complexity for aggregation, which significantly slows down the training speed.","To address this challenge, we propose a federated learning approach called Federated Normalized Gradients Algorithm (Fed-NGA).","Fed-NGA simply normalizes the uploaded local gradients to be unit vectors before aggregation, achieving a time complexity of $\\mathcal{O}(pM)$, where $p$ represents the dimension of model parameters and $M$ is the number of participating clients.","This complexity scale achieves the best level among all the existing Byzantine-robust methods.","Furthermore, through rigorous proof, we demonstrate that Fed-NGA transcends the trade-off between adaptability to loss function type and data heterogeneity and the limitation of non-zero optimality gap in existing literature.","Specifically, Fed-NGA can adapt to both non-convex loss functions and non-IID datasets simultaneously, with zero optimality gap at a rate of $\\mathcal{O} (1/T^{\\frac{1}{2} - \\delta})$, where T is the iteration number and $\\delta \\in (0,\\frac{1}{2})$.","In cases where the loss function is strongly convex, the zero optimality gap achieving rate can be improved to be linear.","Experimental results provide evidence of the superiority of our proposed Fed-NGA on time complexity and convergence performance over baseline methods."],"url":"http://arxiv.org/abs/2408.09539v1"}
{"created":"2024-08-18 16:40:11","title":"AnomalyFactory: Regard Anomaly Generation as Unsupervised Anomaly Localization","abstract":"Recent advances in anomaly generation approaches alleviate the effect of data insufficiency on task of anomaly localization. While effective, most of them learn multiple large generative models on different datasets and cumbersome anomaly prediction models for different classes. To address the limitations, we propose a novel scalable framework, named AnomalyFactory, that unifies unsupervised anomaly generation and localization with same network architecture. It starts with a BootGenerator that combines structure of a target edge map and appearance of a reference color image with the guidance of a learned heatmap. Then, it proceeds with a FlareGenerator that receives supervision signals from the BootGenerator and reforms the heatmap to indicate anomaly locations in the generated image. Finally, it easily transforms the same network architecture to a BlazeDetector that localizes anomaly pixels with the learned heatmap by converting the anomaly images generated by the FlareGenerator to normal images. By manipulating the target edge maps and combining them with various reference images, AnomalyFactory generates authentic and diversity samples cross domains. Comprehensive experiments carried on 5 datasets, including MVTecAD, VisA, MVTecLOCO, MADSim and RealIAD, demonstrate that our approach is superior to competitors in generation capability and scalability.","sentences":["Recent advances in anomaly generation approaches alleviate the effect of data insufficiency on task of anomaly localization.","While effective, most of them learn multiple large generative models on different datasets and cumbersome anomaly prediction models for different classes.","To address the limitations, we propose a novel scalable framework, named AnomalyFactory, that unifies unsupervised anomaly generation and localization with same network architecture.","It starts with a BootGenerator that combines structure of a target edge map and appearance of a reference color image with the guidance of a learned heatmap.","Then, it proceeds with a FlareGenerator that receives supervision signals from the BootGenerator and reforms the heatmap to indicate anomaly locations in the generated image.","Finally, it easily transforms the same network architecture to a BlazeDetector that localizes anomaly pixels with the learned heatmap by converting the anomaly images generated by the FlareGenerator to normal images.","By manipulating the target edge maps and combining them with various reference images, AnomalyFactory generates authentic and diversity samples cross domains.","Comprehensive experiments carried on 5 datasets, including MVTecAD, VisA, MVTecLOCO, MADSim and RealIAD, demonstrate that our approach is superior to competitors in generation capability and scalability."],"url":"http://arxiv.org/abs/2408.09533v1"}
{"created":"2024-08-18 16:34:21","title":"Swift Trust in Mobile Ad Hoc Human-Robot Teams","abstract":"Integrating robots into teams of humans is anticipated to bring significant capability improvements for tasks such as searching potentially hazardous buildings. Trust between humans and robots is recognized as a key enabler for human-robot teaming (HRT) activity: if trust during a mission falls below sufficient levels for cooperative tasks to be completed, it could critically affect success. Changes in trust could be particularly problematic in teams that have formed on an ad hoc basis (as might be expected in emergency situations) where team members may not have previously worked together. In such ad hoc teams, a foundational level of 'swift trust' may be fragile and challenging to sustain in the face of inevitable setbacks. We present results of an experiment focused on understanding trust building, violation and repair processes in ad hoc teams (one human and two robots). Trust violation occurred through robots becoming unresponsive, with limited communication and feedback. We perform exploratory analysis of a variety of data, including communications and performance logs, trust surveys and post-experiment interviews, toward understanding how autonomous systems can be designed into interdependent ad hoc human-robot teams where swift trust can be sustained.","sentences":["Integrating robots into teams of humans is anticipated to bring significant capability improvements for tasks such as searching potentially hazardous buildings.","Trust between humans and robots is recognized as a key enabler for human-robot teaming (HRT) activity: if trust during a mission falls below sufficient levels for cooperative tasks to be completed, it could critically affect success.","Changes in trust could be particularly problematic in teams that have formed on an ad hoc basis (as might be expected in emergency situations) where team members may not have previously worked together.","In such ad hoc teams, a foundational level of 'swift trust' may be fragile and challenging to sustain in the face of inevitable setbacks.","We present results of an experiment focused on understanding trust building, violation and repair processes in ad hoc teams (one human and two robots).","Trust violation occurred through robots becoming unresponsive, with limited communication and feedback.","We perform exploratory analysis of a variety of data, including communications and performance logs, trust surveys and post-experiment interviews, toward understanding how autonomous systems can be designed into interdependent ad hoc human-robot teams where swift trust can be sustained."],"url":"http://arxiv.org/abs/2408.09531v1"}
{"created":"2024-08-18 16:30:32","title":"PA-LLaVA: A Large Language-Vision Assistant for Human Pathology Image Understanding","abstract":"The previous advancements in pathology image understanding primarily involved developing models tailored to specific tasks. Recent studies has demonstrated that the large vision-language model can enhance the performance of various downstream tasks in medical image understanding. In this study, we developed a domain-specific large language-vision assistant (PA-LLaVA) for pathology image understanding. Specifically, (1) we first construct a human pathology image-text dataset by cleaning the public medical image-text data for domain-specific alignment; (2) Using the proposed image-text data, we first train a pathology language-image pretraining (PLIP) model as the specialized visual encoder for pathology image, and then we developed scale-invariant connector to avoid the information loss caused by image scaling; (3) We adopt two-stage learning to train PA-LLaVA, first stage for domain alignment, and second stage for end to end visual question \\& answering (VQA) task. In experiments, we evaluate our PA-LLaVA on both supervised and zero-shot VQA datasets, our model achieved the best overall performance among multimodal models of similar scale. The ablation experiments also confirmed the effectiveness of our design. We posit that our PA-LLaVA model and the datasets presented in this work can promote research in field of computational pathology. All codes are available at: https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA}{https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA","sentences":["The previous advancements in pathology image understanding primarily involved developing models tailored to specific tasks.","Recent studies has demonstrated that the large vision-language model can enhance the performance of various downstream tasks in medical image understanding.","In this study, we developed a domain-specific large language-vision assistant (PA-LLaVA) for pathology image understanding.","Specifically, (1) we first construct a human pathology image-text dataset by cleaning the public medical image-text data for domain-specific alignment; (2) Using the proposed image-text data, we first train a pathology language-image pretraining (PLIP) model as the specialized visual encoder for pathology image, and then we developed scale-invariant connector to avoid the information loss caused by image scaling; (3) We adopt two-stage learning to train PA-LLaVA, first stage for domain alignment, and second stage for end to end visual question \\& answering (VQA) task.","In experiments, we evaluate our PA-LLaVA on both supervised and zero-shot VQA datasets, our model achieved the best overall performance among multimodal models of similar scale.","The ablation experiments also confirmed the effectiveness of our design.","We posit that our PA-LLaVA model and the datasets presented in this work can promote research in field of computational pathology.","All codes are available at: https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA}{https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA"],"url":"http://arxiv.org/abs/2408.09530v1"}
{"created":"2024-08-18 16:24:05","title":"Fine-gained air quality inference based on low-quality sensing data using self-supervised learning","abstract":"Fine-grained air quality (AQ) mapping is made possible by the proliferation of cheap AQ micro-stations (MSs). However, their measurements are often inaccurate and sensitive to local disturbances, in contrast to standardized stations (SSs) that provide accurate readings but fall short in number. To simultaneously address the issues of low data quality (MSs) and high label sparsity (SSs), a multi-task spatio-temporal network (MTSTN) is proposed, which employs self-supervised learning to utilize massive unlabeled data, aided by seasonal and trend decomposition of MS data offering reliable information as features. The MTSTN is applied to infer NO$_2$, O$_3$ and PM$_{2.5}$ concentrations in a 250 km$^2$ area in Chengdu, China, at a resolution of 500m$\\times$500m$\\times$1hr. Data from 55 SSs and 323 MSs were used, along with meteorological, traffic, geographic and timestamp data as features. The MTSTN excels in accuracy compared to several benchmarks, and its performance is greatly enhanced by utilizing low-quality MS data. A series of ablation and pressure tests demonstrate the results' robustness and interpretability, showcasing the MTSTN's practical value for accurate and affordable AQ inference.","sentences":["Fine-grained air quality (AQ) mapping is made possible by the proliferation of cheap AQ micro-stations (MSs).","However, their measurements are often inaccurate and sensitive to local disturbances, in contrast to standardized stations (SSs) that provide accurate readings but fall short in number.","To simultaneously address the issues of low data quality (MSs) and high label sparsity (SSs), a multi-task spatio-temporal network (MTSTN) is proposed, which employs self-supervised learning to utilize massive unlabeled data, aided by seasonal and trend decomposition of MS data offering reliable information as features.","The MTSTN is applied to infer NO$_2$, O$_3$ and PM$_{2.5}$ concentrations in a 250 km$^2$ area in Chengdu, China, at a resolution of 500m$\\times$500m$\\times$1hr.","Data from 55 SSs and 323 MSs were used, along with meteorological, traffic, geographic and timestamp data as features.","The MTSTN excels in accuracy compared to several benchmarks, and its performance is greatly enhanced by utilizing low-quality MS data.","A series of ablation and pressure tests demonstrate the results' robustness and interpretability, showcasing the MTSTN's practical value for accurate and affordable AQ inference."],"url":"http://arxiv.org/abs/2408.09526v1"}
{"created":"2024-08-18 16:09:49","title":"Orchestrating Federated Learning in Space-Air-Ground Integrated Networks: Adaptive Data Offloading and Seamless Handover","abstract":"Devices located in remote regions often lack coverage from well-developed terrestrial communication infrastructure. This not only prevents them from experiencing high quality communication services but also hinders the delivery of machine learning services in remote regions. In this paper, we propose a new federated learning (FL) methodology tailored to space-air-ground integrated networks (SAGINs) to tackle this issue. Our approach strategically leverages the nodes within space and air layers as both (i) edge computing units and (ii) model aggregators during the FL process, addressing the challenges that arise from the limited computation powers of ground devices and the absence of terrestrial base stations in the target region. The key idea behind our methodology is the adaptive data offloading and handover procedures that incorporate various network dynamics in SAGINs, including the mobility, heterogeneous computation powers, and inconsistent coverage times of incoming satellites. We analyze the latency of our scheme and develop an adaptive data offloading optimizer, and also characterize the theoretical convergence bound of our proposed algorithm. Experimental results confirm the advantage of our SAGIN-assisted FL methodology in terms of training time and test accuracy compared with various baselines.","sentences":["Devices located in remote regions often lack coverage from well-developed terrestrial communication infrastructure.","This not only prevents them from experiencing high quality communication services but also hinders the delivery of machine learning services in remote regions.","In this paper, we propose a new federated learning (FL) methodology tailored to space-air-ground integrated networks (SAGINs) to tackle this issue.","Our approach strategically leverages the nodes within space and air layers as both (i) edge computing units and (ii) model aggregators during the FL process, addressing the challenges that arise from the limited computation powers of ground devices and the absence of terrestrial base stations in the target region.","The key idea behind our methodology is the adaptive data offloading and handover procedures that incorporate various network dynamics in SAGINs, including the mobility, heterogeneous computation powers, and inconsistent coverage times of incoming satellites.","We analyze the latency of our scheme and develop an adaptive data offloading optimizer, and also characterize the theoretical convergence bound of our proposed algorithm.","Experimental results confirm the advantage of our SAGIN-assisted FL methodology in terms of training time and test accuracy compared with various baselines."],"url":"http://arxiv.org/abs/2408.09522v1"}
