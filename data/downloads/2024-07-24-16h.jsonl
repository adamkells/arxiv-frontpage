{"created":"2024-07-23 17:59:59","title":"Diffusion Models for Monocular Depth Estimation: Overcoming Challenging Conditions","abstract":"We present a novel approach designed to address the complexities posed by challenging, out-of-distribution data in the single-image depth estimation task. Starting with images that facilitate depth prediction due to the absence of unfavorable factors, we systematically generate new, user-defined scenes with a comprehensive set of challenges and associated depth information. This is achieved by leveraging cutting-edge text-to-image diffusion models with depth-aware control, known for synthesizing high-quality image content from textual prompts while preserving the coherence of 3D structure between generated and source imagery. Subsequent fine-tuning of any monocular depth network is carried out through a self-distillation protocol that takes into account images generated using our strategy and its own depth predictions on simple, unchallenging scenes. Experiments on benchmarks tailored for our purposes demonstrate the effectiveness and versatility of our proposal.","sentences":["We present a novel approach designed to address the complexities posed by challenging, out-of-distribution data in the single-image depth estimation task.","Starting with images that facilitate depth prediction due to the absence of unfavorable factors, we systematically generate new, user-defined scenes with a comprehensive set of challenges and associated depth information.","This is achieved by leveraging cutting-edge text-to-image diffusion models with depth-aware control, known for synthesizing high-quality image content from textual prompts while preserving the coherence of 3D structure between generated and source imagery.","Subsequent fine-tuning of any monocular depth network is carried out through a self-distillation protocol that takes into account images generated using our strategy and its own depth predictions on simple, unchallenging scenes.","Experiments on benchmarks tailored for our purposes demonstrate the effectiveness and versatility of our proposal."],"url":"http://arxiv.org/abs/2407.16698v1"}
{"created":"2024-07-23 17:59:44","title":"AbdomenAtlas: A Large-Scale, Detailed-Annotated, & Multi-Center Dataset for Efficient Transfer Learning and Open Algorithmic Benchmarking","abstract":"We introduce the largest abdominal CT dataset (termed AbdomenAtlas) of 20,460 three-dimensional CT volumes sourced from 112 hospitals across diverse populations, geographies, and facilities. AbdomenAtlas provides 673K high-quality masks of anatomical structures in the abdominal region annotated by a team of 10 radiologists with the help of AI algorithms. We start by having expert radiologists manually annotate 22 anatomical structures in 5,246 CT volumes. Following this, a semi-automatic annotation procedure is performed for the remaining CT volumes, where radiologists revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from revised annotations. Such a large-scale, detailed-annotated, and multi-center dataset is needed for two reasons. Firstly, AbdomenAtlas provides important resources for AI development at scale, branded as large pre-trained models, which can alleviate the annotation workload of expert radiologists to transfer to broader clinical applications. Secondly, AbdomenAtlas establishes a large-scale benchmark for evaluating AI algorithms -- the more data we use to test the algorithms, the better we can guarantee reliable performance in complex clinical scenarios. An ISBI & MICCAI challenge named BodyMaps: Towards 3D Atlas of Human Body was launched using a subset of our AbdomenAtlas, aiming to stimulate AI innovation and to benchmark segmentation accuracy, inference efficiency, and domain generalizability. We hope our AbdomenAtlas can set the stage for larger-scale clinical trials and offer exceptional opportunities to practitioners in the medical imaging community. Codes, models, and datasets are available at https://www.zongweiz.com/dataset","sentences":["We introduce the largest abdominal CT dataset (termed AbdomenAtlas) of 20,460 three-dimensional CT volumes sourced from 112 hospitals across diverse populations, geographies, and facilities.","AbdomenAtlas provides 673K high-quality masks of anatomical structures in the abdominal region annotated by a team of 10 radiologists with the help of AI algorithms.","We start by having expert radiologists manually annotate 22 anatomical structures in 5,246 CT volumes.","Following this, a semi-automatic annotation procedure is performed for the remaining CT volumes, where radiologists revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from revised annotations.","Such a large-scale, detailed-annotated, and multi-center dataset is needed for two reasons.","Firstly, AbdomenAtlas provides important resources for AI development at scale, branded as large pre-trained models, which can alleviate the annotation workload of expert radiologists to transfer to broader clinical applications.","Secondly, AbdomenAtlas establishes a large-scale benchmark for evaluating AI algorithms -- the more data we use to test the algorithms, the better we can guarantee reliable performance in complex clinical scenarios.","An ISBI & MICCAI challenge named BodyMaps: Towards 3D Atlas of Human Body was launched using a subset of our AbdomenAtlas, aiming to stimulate AI innovation and to benchmark segmentation accuracy, inference efficiency, and domain generalizability.","We hope our AbdomenAtlas can set the stage for larger-scale clinical trials and offer exceptional opportunities to practitioners in the medical imaging community.","Codes, models, and datasets are available at https://www.zongweiz.com/dataset"],"url":"http://arxiv.org/abs/2407.16697v1"}
{"created":"2024-07-23 17:58:26","title":"PartGLEE: A Foundation Model for Recognizing and Parsing Any Objects","abstract":"We present PartGLEE, a part-level foundation model for locating and identifying both objects and parts in images. Through a unified framework, PartGLEE accomplishes detection, segmentation, and grounding of instances at any granularity in the open world scenario. Specifically, we propose a Q-Former to construct the hierarchical relationship between objects and parts, parsing every object into corresponding semantic parts. By incorporating a large amount of object-level data, the hierarchical relationships can be extended, enabling PartGLEE to recognize a rich variety of parts. We conduct comprehensive studies to validate the effectiveness of our method, PartGLEE achieves the state-of-the-art performance across various part-level tasks and obtain competitive results on object-level tasks. The proposed PartGLEE significantly enhances hierarchical modeling capabilities and part-level perception over our previous GLEE model. Further analysis indicates that the hierarchical cognitive ability of PartGLEE is able to facilitate a detailed comprehension in images for mLLMs. The model and code will be released at https://provencestar.github.io/PartGLEE-Vision/ .","sentences":["We present PartGLEE, a part-level foundation model for locating and identifying both objects and parts in images.","Through a unified framework, PartGLEE accomplishes detection, segmentation, and grounding of instances at any granularity in the open world scenario.","Specifically, we propose a Q-Former to construct the hierarchical relationship between objects and parts, parsing every object into corresponding semantic parts.","By incorporating a large amount of object-level data, the hierarchical relationships can be extended, enabling PartGLEE to recognize a rich variety of parts.","We conduct comprehensive studies to validate the effectiveness of our method, PartGLEE achieves the state-of-the-art performance across various part-level tasks and obtain competitive results on object-level tasks.","The proposed PartGLEE significantly enhances hierarchical modeling capabilities and part-level perception over our previous GLEE model.","Further analysis indicates that the hierarchical cognitive ability of PartGLEE is able to facilitate a detailed comprehension in images for mLLMs.","The model and code will be released at https://provencestar.github.io/PartGLEE-Vision/ ."],"url":"http://arxiv.org/abs/2407.16696v1"}
{"created":"2024-07-23 17:45:16","title":"A Simulation Benchmark for Autonomous Racing with Large-Scale Human Data","abstract":"Despite the availability of international prize-money competitions, scaled vehicles, and simulation environments, research on autonomous racing and the control of sports cars operating close to the limit of handling has been limited by the high costs of vehicle acquisition and management, as well as the limited physics accuracy of open-source simulators. In this paper, we propose a racing simulation platform based on the simulator Assetto Corsa to test, validate, and benchmark autonomous driving algorithms, including reinforcement learning (RL) and classical Model Predictive Control (MPC), in realistic and challenging scenarios. Our contributions include the development of this simulation platform, several state-of-the-art algorithms tailored to the racing environment, and a comprehensive dataset collected from human drivers. Additionally, we evaluate algorithms in the offline RL setting. All the necessary code (including environment and benchmarks), working examples, datasets, and videos are publicly released and can be found at: \\url{https://assetto-corsa-gym.github.io}.","sentences":["Despite the availability of international prize-money competitions, scaled vehicles, and simulation environments, research on autonomous racing and the control of sports cars operating close to the limit of handling has been limited by the high costs of vehicle acquisition and management, as well as the limited physics accuracy of open-source simulators.","In this paper, we propose a racing simulation platform based on the simulator Assetto Corsa to test, validate, and benchmark autonomous driving algorithms, including reinforcement learning (RL) and classical Model Predictive Control (MPC), in realistic and challenging scenarios.","Our contributions include the development of this simulation platform, several state-of-the-art algorithms tailored to the racing environment, and a comprehensive dataset collected from human drivers.","Additionally, we evaluate algorithms in the offline RL setting.","All the necessary code (including environment and benchmarks), working examples, datasets, and videos are publicly released and can be found at: \\url{https://assetto-corsa-gym.github.io}."],"url":"http://arxiv.org/abs/2407.16680v1"}
{"created":"2024-07-23 17:21:56","title":"Dynamic Subgraph Matching via Cost-Model-based Vertex Dominance Embeddings (Technical Report)","abstract":"In many real-world applications such as social network analysis, knowledge graph discovery, biological network analytics, and so on, graph data management has become increasingly important and has drawn much attention from the database community. While many graphs (e.g., Twitter, Wikipedia, etc.) are usually involving over time, it is of great importance to study the dynamic subgraph matching (DSM) problem, a fundamental yet challenging graph operator, which continuously monitors subgraph matching results over dynamic graphs with a stream of edge updates. To efficiently tackle the DSM problem, we carefully design a novel vertex dominance embedding approach, which effectively encodes vertex labels that can be incrementally maintained upon graph updates. Inspire by low pruning power for high-degree vertices, we propose a new degree grouping technique over basic subgraph patterns in different degree groups (i.e., groups of star substructures), and devise degree-aware star substructure synopses (DAS^3) to effectively facilitate our designed vertex dominance and range pruning strategies. We develop efficient algorithms to incrementally maintain dynamic graphs and answer DSM queries. Through extensive experiments, we confirm the efficiency of our proposed approaches over both real and synthetic graphs.","sentences":["In many real-world applications such as social network analysis, knowledge graph discovery, biological network analytics, and so on, graph data management has become increasingly important and has drawn much attention from the database community.","While many graphs (e.g., Twitter, Wikipedia, etc.) are usually involving over time, it is of great importance to study the dynamic subgraph matching (DSM) problem, a fundamental yet challenging graph operator, which continuously monitors subgraph matching results over dynamic graphs with a stream of edge updates.","To efficiently tackle the DSM problem, we carefully design a novel vertex dominance embedding approach, which effectively encodes vertex labels that can be incrementally maintained upon graph updates.","Inspire by low pruning power for high-degree vertices, we propose a new degree grouping technique over basic subgraph patterns in different degree groups (i.e., groups of star substructures), and devise degree-aware star substructure synopses (DAS^3) to effectively facilitate our designed vertex dominance and range pruning strategies.","We develop efficient algorithms to incrementally maintain dynamic graphs and answer DSM queries.","Through extensive experiments, we confirm the efficiency of our proposed approaches over both real and synthetic graphs."],"url":"http://arxiv.org/abs/2407.16660v1"}
{"created":"2024-07-23 16:56:59","title":"A Geometry-Aware Algorithm to Learn Hierarchical Embeddings in Hyperbolic Space","abstract":"Hyperbolic embeddings are a class of representation learning methods that offer competitive performances when data can be abstracted as a tree-like graph. However, in practice, learning hyperbolic embeddings of hierarchical data is difficult due to the different geometry between hyperbolic space and the Euclidean space. To address such difficulties, we first categorize three kinds of illness that harm the performance of the embeddings. Then, we develop a geometry-aware algorithm using a dilation operation and a transitive closure regularization to tackle these illnesses. We empirically validate these techniques and present a theoretical analysis of the mechanism behind the dilation operation. Experiments on synthetic and real-world datasets reveal superior performances of our algorithm.","sentences":["Hyperbolic embeddings are a class of representation learning methods that offer competitive performances when data can be abstracted as a tree-like graph.","However, in practice, learning hyperbolic embeddings of hierarchical data is difficult due to the different geometry between hyperbolic space and the Euclidean space.","To address such difficulties, we first categorize three kinds of illness that harm the performance of the embeddings.","Then, we develop a geometry-aware algorithm using a dilation operation and a transitive closure regularization to tackle these illnesses.","We empirically validate these techniques and present a theoretical analysis of the mechanism behind the dilation operation.","Experiments on synthetic and real-world datasets reveal superior performances of our algorithm."],"url":"http://arxiv.org/abs/2407.16641v1"}
{"created":"2024-07-23 16:55:04","title":"Unveiling and Mitigating Bias in Audio Visual Segmentation","abstract":"Community researchers have developed a range of advanced audio-visual segmentation models aimed at improving the quality of sounding objects' masks. While masks created by these models may initially appear plausible, they occasionally exhibit anomalies with incorrect grounding logic. We attribute this to real-world inherent preferences and distributions as a simpler signal for learning than the complex audio-visual grounding, which leads to the disregard of important modality information. Generally, the anomalous phenomena are often complex and cannot be directly observed systematically. In this study, we made a pioneering effort with the proper synthetic data to categorize and analyze phenomena as two types \"audio priming bias\" and \"visual prior\" according to the source of anomalies. For audio priming bias, to enhance audio sensitivity to different intensities and semantics, a perception module specifically for audio perceives the latent semantic information and incorporates information into a limited set of queries, namely active queries. Moreover, the interaction mechanism related to such active queries in the transformer decoder is customized to adapt to the need for interaction regulating among audio semantics. For visual prior, multiple contrastive training strategies are explored to optimize the model by incorporating a biased branch, without even changing the structure of the model. During experiments, observation demonstrates the presence and the impact that has been produced by the biases of the existing model. Finally, through experimental evaluation of AVS benchmarks, we demonstrate the effectiveness of our methods in handling both types of biases, achieving competitive performance across all three subsets.","sentences":["Community researchers have developed a range of advanced audio-visual segmentation models aimed at improving the quality of sounding objects' masks.","While masks created by these models may initially appear plausible, they occasionally exhibit anomalies with incorrect grounding logic.","We attribute this to real-world inherent preferences and distributions as a simpler signal for learning than the complex audio-visual grounding, which leads to the disregard of important modality information.","Generally, the anomalous phenomena are often complex and cannot be directly observed systematically.","In this study, we made a pioneering effort with the proper synthetic data to categorize and analyze phenomena as two types \"audio priming bias\" and \"visual prior\" according to the source of anomalies.","For audio priming bias, to enhance audio sensitivity to different intensities and semantics, a perception module specifically for audio perceives the latent semantic information and incorporates information into a limited set of queries, namely active queries.","Moreover, the interaction mechanism related to such active queries in the transformer decoder is customized to adapt to the need for interaction regulating among audio semantics.","For visual prior, multiple contrastive training strategies are explored to optimize the model by incorporating a biased branch, without even changing the structure of the model.","During experiments, observation demonstrates the presence and the impact that has been produced by the biases of the existing model.","Finally, through experimental evaluation of AVS benchmarks, we demonstrate the effectiveness of our methods in handling both types of biases, achieving competitive performance across all three subsets."],"url":"http://arxiv.org/abs/2407.16638v1"}
{"created":"2024-07-23 16:54:28","title":"Course-Correction: Safety Alignment Using Synthetic Preferences","abstract":"The risk of harmful content generated by large language models (LLMs) becomes a critical concern. This paper presents a systematic study on assessing and improving LLMs' capability to perform the task of \\textbf{course-correction}, \\ie, the model can steer away from generating harmful content autonomously. To start with, we introduce the \\textsc{C$^2$-Eval} benchmark for quantitative assessment and analyze 10 popular LLMs, revealing varying proficiency of current safety-tuned LLMs in course-correction. To improve, we propose fine-tuning LLMs with preference learning, emphasizing the preference for timely course-correction. Using an automated pipeline, we create \\textsc{C$^2$-Syn}, a synthetic dataset with 750K pairwise preferences, to teach models the concept of timely course-correction through data-driven preference learning. Experiments on 2 LLMs, \\textsc{Llama2-Chat 7B} and \\textsc{Qwen2 7B}, show that our method effectively enhances course-correction skills without affecting general performance. Additionally, it effectively improves LLMs' safety, particularly in resisting jailbreak attacks.","sentences":["The risk of harmful content generated by large language models (LLMs) becomes a critical concern.","This paper presents a systematic study on assessing and improving LLMs' capability to perform the task of \\textbf{course-correction}, \\ie, the model can steer away from generating harmful content autonomously.","To start with, we introduce the \\textsc{C$^2$-Eval} benchmark for quantitative assessment and analyze 10 popular LLMs, revealing varying proficiency of current safety-tuned LLMs in course-correction.","To improve, we propose fine-tuning LLMs with preference learning, emphasizing the preference for timely course-correction.","Using an automated pipeline, we create \\textsc{C$^2$-Syn}, a synthetic dataset with 750K pairwise preferences, to teach models the concept of timely course-correction through data-driven preference learning.","Experiments on 2 LLMs, \\textsc{Llama2-Chat 7B} and \\textsc{Qwen2 7B}, show that our method effectively enhances course-correction skills without affecting general performance.","Additionally, it effectively improves LLMs' safety, particularly in resisting jailbreak attacks."],"url":"http://arxiv.org/abs/2407.16637v1"}
{"created":"2024-07-23 16:52:42","title":"Velocity Driven Vision: Asynchronous Sensor Fusion Birds Eye View Models for Autonomous Vehicles","abstract":"Fusing different sensor modalities can be a difficult task, particularly if they are asynchronous. Asynchronisation may arise due to long processing times or improper synchronisation during calibration, and there must exist a way to still utilise this previous information for the purpose of safe driving, and object detection in ego vehicle/ multi-agent trajectory prediction. Difficulties arise in the fact that the sensor modalities have captured information at different times and also at different positions in space. Therefore, they are not spatially nor temporally aligned. This paper will investigate the challenge of radar and LiDAR sensors being asynchronous relative to the camera sensors, for various time latencies. The spatial alignment will be resolved before lifting into BEV space via the transformation of the radar/LiDAR point clouds into the new ego frame coordinate system. Only after this can we concatenate the radar/LiDAR point cloud and lifted camera features. Temporal alignment will be remedied for radar data only, we will implement a novel method of inferring the future radar point positions using the velocity information. Our approach to resolving the issue of sensor asynchrony yields promising results. We demonstrate velocity information can drastically improve IoU for asynchronous datasets, as for a time latency of 360 milliseconds (ms), IoU improves from 49.54 to 53.63. Additionally, for a time latency of 550ms, the camera+radar (C+R) model outperforms the camera+LiDAR (C+L) model by 0.18 IoU. This is an advancement in utilising the often-neglected radar sensor modality, which is less favoured than LiDAR for autonomous driving purposes.","sentences":["Fusing different sensor modalities can be a difficult task, particularly if they are asynchronous.","Asynchronisation may arise due to long processing times or improper synchronisation during calibration, and there must exist a way to still utilise this previous information for the purpose of safe driving, and object detection in ego vehicle/ multi-agent trajectory prediction.","Difficulties arise in the fact that the sensor modalities have captured information at different times and also at different positions in space.","Therefore, they are not spatially nor temporally aligned.","This paper will investigate the challenge of radar and LiDAR sensors being asynchronous relative to the camera sensors, for various time latencies.","The spatial alignment will be resolved before lifting into BEV space via the transformation of the radar/LiDAR point clouds into the new ego frame coordinate system.","Only after this can we concatenate the radar/LiDAR point cloud and lifted camera features.","Temporal alignment will be remedied for radar data only, we will implement a novel method of inferring the future radar point positions using the velocity information.","Our approach to resolving the issue of sensor asynchrony yields promising results.","We demonstrate velocity information can drastically improve IoU for asynchronous datasets, as for a time latency of 360 milliseconds (ms), IoU improves from 49.54 to 53.63.","Additionally, for a time latency of 550ms, the camera+radar (C+R) model outperforms the camera+LiDAR (C+L) model by 0.18 IoU.","This is an advancement in utilising the often-neglected radar sensor modality, which is less favoured than LiDAR for autonomous driving purposes."],"url":"http://arxiv.org/abs/2407.16636v1"}
{"created":"2024-07-23 16:23:04","title":"Lawma: The Power of Specialization for Legal Tasks","abstract":"Annotation and classification of legal text are central components of empirical legal research. Traditionally, these tasks are often delegated to trained research assistants. Motivated by the advances in language modeling, empirical legal scholars are increasingly turning to prompting commercial models, hoping that it will alleviate the significant cost of human annotation. Despite growing use, our understanding of how to best utilize large language models for legal tasks remains limited. We conduct a comprehensive study of 260 legal text classification tasks, nearly all new to the machine learning community. Starting from GPT-4 as a baseline, we show that it has non-trivial but highly varied zero-shot accuracy, often exhibiting performance that may be insufficient for legal work. We then demonstrate that a lightly fine-tuned Llama 3 model vastly outperforms GPT-4 on almost all tasks, typically by double-digit percentage points. We find that larger models respond better to fine-tuning than smaller models. A few tens to hundreds of examples suffice to achieve high classification accuracy. Notably, we can fine-tune a single model on all 260 tasks simultaneously at a small loss in accuracy relative to having a separate model for each task. Our work points to a viable alternative to the predominant practice of prompting commercial models. For concrete legal tasks with some available labeled data, researchers are better off using a fine-tuned open-source model.","sentences":["Annotation and classification of legal text are central components of empirical legal research.","Traditionally, these tasks are often delegated to trained research assistants.","Motivated by the advances in language modeling, empirical legal scholars are increasingly turning to prompting commercial models, hoping that it will alleviate the significant cost of human annotation.","Despite growing use, our understanding of how to best utilize large language models for legal tasks remains limited.","We conduct a comprehensive study of 260 legal text classification tasks, nearly all new to the machine learning community.","Starting from GPT-4 as a baseline, we show that it has non-trivial but highly varied zero-shot accuracy, often exhibiting performance that may be insufficient for legal work.","We then demonstrate that a lightly fine-tuned Llama 3 model vastly outperforms GPT-4 on almost all tasks, typically by double-digit percentage points.","We find that larger models respond better to fine-tuning than smaller models.","A few tens to hundreds of examples suffice to achieve high classification accuracy.","Notably, we can fine-tune a single model on all 260 tasks simultaneously at a small loss in accuracy relative to having a separate model for each task.","Our work points to a viable alternative to the predominant practice of prompting commercial models.","For concrete legal tasks with some available labeled data, researchers are better off using a fine-tuned open-source model."],"url":"http://arxiv.org/abs/2407.16615v1"}
{"created":"2024-07-23 16:13:22","title":"Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?","abstract":"The pretraining data of today's strongest language models is opaque. In particular, little is known about the proportions of various domains or languages represented. In this work, we tackle a task which we call data mixture inference, which aims to uncover the distributional make-up of training data. We introduce a novel attack based on a previously overlooked source of information -- byte-pair encoding (BPE) tokenizers, used by the vast majority of modern language models. Our key insight is that the ordered list of merge rules learned by a BPE tokenizer naturally reveals information about the token frequencies in its training data: the first merge is the most common byte pair, the second is the most common pair after merging the first token, and so on. Given a tokenizer's merge list along with data samples for each category of interest, we formulate a linear program that solves for the proportion of each category in the tokenizer's training set. Importantly, to the extent to which tokenizer training data is representative of the pretraining data, we indirectly learn about the pretraining data. In controlled experiments, we show that our attack recovers mixture ratios with high precision for tokenizers trained on known mixtures of natural languages, programming languages, and data sources. We then apply our approach to off-the-shelf tokenizers released with recent LMs. We confirm much publicly disclosed information about these models, and also make several new inferences: GPT-4o's tokenizer is much more multilingual than its predecessors, training on 39% non-English data; Llama3 extends GPT-3.5's tokenizer primarily for multilingual (48%) use; GPT-3.5's and Claude's tokenizers are trained on predominantly code (~60%). We hope our work sheds light on current design practices for pretraining data, and inspires continued research into data mixture inference for LMs.","sentences":["The pretraining data of today's strongest language models is opaque.","In particular, little is known about the proportions of various domains or languages represented.","In this work, we tackle a task which we call data mixture inference, which aims to uncover the distributional make-up of training data.","We introduce a novel attack based on a previously overlooked source of information -- byte-pair encoding (BPE) tokenizers, used by the vast majority of modern language models.","Our key insight is that the ordered list of merge rules learned by a BPE tokenizer naturally reveals information about the token frequencies in its training data: the first merge is the most common byte pair, the second is the most common pair after merging the first token, and so on.","Given a tokenizer's merge list along with data samples for each category of interest, we formulate a linear program that solves for the proportion of each category in the tokenizer's training set.","Importantly, to the extent to which tokenizer training data is representative of the pretraining data, we indirectly learn about the pretraining data.","In controlled experiments, we show that our attack recovers mixture ratios with high precision for tokenizers trained on known mixtures of natural languages, programming languages, and data sources.","We then apply our approach to off-the-shelf tokenizers released with recent LMs.","We confirm much publicly disclosed information about these models, and also make several new inferences: GPT-4o's tokenizer is much more multilingual than its predecessors, training on 39% non-English data; Llama3 extends GPT-3.5's tokenizer primarily for multilingual (48%) use; GPT-3.5's and Claude's tokenizers are trained on predominantly code (~60%).","We hope our work sheds light on current design practices for pretraining data, and inspires continued research into data mixture inference for LMs."],"url":"http://arxiv.org/abs/2407.16607v1"}
{"created":"2024-07-23 16:06:22","title":"Shared Imagination: LLMs Hallucinate Alike","abstract":"Despite the recent proliferation of large language models (LLMs), their training recipes -- model architecture, pre-training data and optimization algorithm -- are often very similar. This naturally raises the question of the similarity among the resulting models. In this paper, we propose a novel setting, imaginary question answering (IQA), to better understand model similarity. In IQA, we ask one model to generate purely imaginary questions (e.g., on completely made-up concepts in physics) and prompt another model to answer. Surprisingly, despite the total fictionality of these questions, all models can answer each other's questions with remarkable success, suggesting a \"shared imagination space\" in which these models operate during such hallucinations. We conduct a series of investigations into this phenomenon and discuss implications on model homogeneity, hallucination, and computational creativity.","sentences":["Despite the recent proliferation of large language models (LLMs), their training recipes -- model architecture, pre-training data and optimization algorithm -- are often very similar.","This naturally raises the question of the similarity among the resulting models.","In this paper, we propose a novel setting, imaginary question answering (IQA), to better understand model similarity.","In IQA, we ask one model to generate purely imaginary questions (e.g., on completely made-up concepts in physics) and prompt another model to answer.","Surprisingly, despite the total fictionality of these questions, all models can answer each other's questions with remarkable success, suggesting a \"shared imagination space\" in which these models operate during such hallucinations.","We conduct a series of investigations into this phenomenon and discuss implications on model homogeneity, hallucination, and computational creativity."],"url":"http://arxiv.org/abs/2407.16604v1"}
{"created":"2024-07-23 15:53:17","title":"GenRec: A Flexible Data Generator for Recommendations","abstract":"The scarcity of realistic datasets poses a significant challenge in benchmarking recommender systems and social network analysis methods and techniques. A common and effective solution is to generate synthetic data that simulates realistic interactions. However, although various methods have been proposed, the existing literature still lacks generators that are fully adaptable and allow easy manipulation of the underlying data distributions and structural properties. To address this issue, the present work introduces GenRec, a novel framework for generating synthetic user-item interactions that exhibit realistic and well-known properties observed in recommendation scenarios. The framework is based on a stochastic generative process based on latent factor modeling. Here, the latent factors can be exploited to yield long-tailed preference distributions, and at the same time they characterize subpopulations of users and topic-based item clusters. Notably, the proposed framework is highly flexible and offers a wide range of hyper-parameters for customizing the generation of user-item interactions. The code used to perform the experiments is publicly available at https://anonymous.4open.science/r/GenRec-DED3.","sentences":["The scarcity of realistic datasets poses a significant challenge in benchmarking recommender systems and social network analysis methods and techniques.","A common and effective solution is to generate synthetic data that simulates realistic interactions.","However, although various methods have been proposed, the existing literature still lacks generators that are fully adaptable and allow easy manipulation of the underlying data distributions and structural properties.","To address this issue, the present work introduces GenRec, a novel framework for generating synthetic user-item interactions that exhibit realistic and well-known properties observed in recommendation scenarios.","The framework is based on a stochastic generative process based on latent factor modeling.","Here, the latent factors can be exploited to yield long-tailed preference distributions, and at the same time they characterize subpopulations of users and topic-based item clusters.","Notably, the proposed framework is highly flexible and offers a wide range of hyper-parameters for customizing the generation of user-item interactions.","The code used to perform the experiments is publicly available at https://anonymous.4open.science/r/GenRec-DED3."],"url":"http://arxiv.org/abs/2407.16594v1"}
{"created":"2024-07-23 15:40:35","title":"A Faster Branching Algorithm for the Maximum $k$-Defective Clique Problem","abstract":"A $k$-defective clique of an undirected graph $G$ is a subset of its vertices that induces a nearly complete graph with a maximum of $k$ missing edges. The maximum $k$-defective clique problem, which asks for the largest $k$-defective clique from the given graph, is important in many applications, such as social and biological network analysis. In the paper, we propose a new branching algorithm that takes advantage of the structural properties of the $k$-defective clique and uses the efficient maximum clique algorithm as a subroutine. As a result, the algorithm has a better asymptotic running time than the existing ones. We also investigate upper-bounding techniques and propose a new upper bound utilizing the \\textit{conflict relationship} between vertex pairs. Because conflict relationship is common in many graph problems, we believe that this technique can be potentially generalized. Finally, experiments show that our algorithm outperforms state-of-the-art solvers on a wide range of open benchmarks.","sentences":["A $k$-defective clique of an undirected graph $G$ is a subset of its vertices that induces a nearly complete graph with a maximum of $k$ missing edges.","The maximum $k$-defective clique problem, which asks for the largest $k$-defective clique from the given graph, is important in many applications, such as social and biological network analysis.","In the paper, we propose a new branching algorithm that takes advantage of the structural properties of the $k$-defective clique and uses the efficient maximum clique algorithm as a subroutine.","As a result, the algorithm has a better asymptotic running time than the existing ones.","We also investigate upper-bounding techniques and propose a new upper bound utilizing the \\textit{conflict relationship} between vertex pairs.","Because conflict relationship is common in many graph problems, we believe that this technique can be potentially generalized.","Finally, experiments show that our algorithm outperforms state-of-the-art solvers on a wide range of open benchmarks."],"url":"http://arxiv.org/abs/2407.16588v1"}
{"created":"2024-07-23 15:39:07","title":"A Simple Algorithm for Near-Vizing Edge-Coloring in Near-Linear Time","abstract":"We present a simple $(1+\\varepsilon)\\Delta$-edge-coloring algorithm for graphs of maximum degree $\\Delta = \\Omega(\\log n / \\varepsilon)$ with running time $O\\left(m\\,\\log^3 n/\\varepsilon^3\\right)$. Our algorithm improves upon that of [Duan, He, and Zhang; SODA19], which was the first near-linear time algorithm for this problem. While our results are weaker than the current state-of-the-art, our approach is significantly simpler, both in terms of analysis as well as implementation, and may be of practical interest.","sentences":["We present a simple $(1+\\varepsilon)\\Delta$-edge-coloring algorithm for graphs of maximum degree $\\Delta = \\Omega(\\log n / \\varepsilon)$ with running time $O\\left(m\\,\\log^3 n/\\varepsilon^3\\right)$. Our algorithm improves upon that of [Duan, He, and Zhang; SODA19], which was the first near-linear time algorithm for this problem.","While our results are weaker than the current state-of-the-art, our approach is significantly simpler, both in terms of analysis as well as implementation, and may be of practical interest."],"url":"http://arxiv.org/abs/2407.16585v1"}
{"created":"2024-07-23 15:27:37","title":"TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback","abstract":"Reinforcement Learning from Human Feedback (RLHF) leverages human preference data to train language models to align more closely with human essence. These human preference data, however, are labeled at the sequence level, creating a mismatch between sequence-level preference labels and tokens, which are autoregressively generated from the language model. Although several recent approaches have tried to provide token-level (i.e., dense) rewards for each individual token, these typically rely on predefined discrete reward values (e.g., positive: +1, negative: -1, neutral: 0), failing to account for varying degrees of preference inherent to each token. To address this limitation, we introduce TLCR (Token-Level Continuous Reward) for RLHF, which incorporates a discriminator trained to distinguish positive and negative tokens, and the confidence of the discriminator is used to assign continuous rewards to each token considering the context. Extensive experiments show that our proposed TLCR leads to consistent performance improvements over previous sequence-level or token-level discrete rewards on open-ended generation benchmarks.","sentences":["Reinforcement Learning from Human Feedback (RLHF) leverages human preference data to train language models to align more closely with human essence.","These human preference data, however, are labeled at the sequence level, creating a mismatch between sequence-level preference labels and tokens, which are autoregressively generated from the language model.","Although several recent approaches have tried to provide token-level (i.e., dense) rewards for each individual token, these typically rely on predefined discrete reward values (e.g., positive: +1, negative: -1, neutral: 0), failing to account for varying degrees of preference inherent to each token.","To address this limitation, we introduce TLCR (Token-Level Continuous Reward) for RLHF, which incorporates a discriminator trained to distinguish positive and negative tokens, and the confidence of the discriminator is used to assign continuous rewards to each token considering the context.","Extensive experiments show that our proposed TLCR leads to consistent performance improvements over previous sequence-level or token-level discrete rewards on open-ended generation benchmarks."],"url":"http://arxiv.org/abs/2407.16574v1"}
{"created":"2024-07-23 15:14:39","title":"COALA: A Practical and Vision-Centric Federated Learning Platform","abstract":"We present COALA, a vision-centric Federated Learning (FL) platform, and a suite of benchmarks for practical FL scenarios, which we categorize into three levels: task, data, and model. At the task level, COALA extends support from simple classification to 15 computer vision tasks, including object detection, segmentation, pose estimation, and more. It also facilitates federated multiple-task learning, allowing clients to tackle multiple tasks simultaneously. At the data level, COALA goes beyond supervised FL to benchmark both semi-supervised FL and unsupervised FL. It also benchmarks feature distribution shifts other than commonly considered label distribution shifts. In addition to dealing with static data, it supports federated continual learning for continuously changing data in real-world scenarios. At the model level, COALA benchmarks FL with split models and different models in different clients. COALA platform offers three degrees of customization for these practical FL scenarios, including configuration customization, components customization, and workflow customization. We conduct systematic benchmarking experiments for the practical FL scenarios and highlight potential opportunities for further advancements in FL. Codes are open sourced at https://github.com/SonyResearch/COALA.","sentences":["We present COALA, a vision-centric Federated Learning (FL) platform, and a suite of benchmarks for practical FL scenarios, which we categorize into three levels: task, data, and model.","At the task level, COALA extends support from simple classification to 15 computer vision tasks, including object detection, segmentation, pose estimation, and more.","It also facilitates federated multiple-task learning, allowing clients to tackle multiple tasks simultaneously.","At the data level, COALA goes beyond supervised FL to benchmark both semi-supervised FL and unsupervised FL.","It also benchmarks feature distribution shifts other than commonly considered label distribution shifts.","In addition to dealing with static data, it supports federated continual learning for continuously changing data in real-world scenarios.","At the model level, COALA benchmarks FL with split models and different models in different clients.","COALA platform offers three degrees of customization for these practical FL scenarios, including configuration customization, components customization, and workflow customization.","We conduct systematic benchmarking experiments for the practical FL scenarios and highlight potential opportunities for further advancements in FL.","Codes are open sourced at https://github.com/SonyResearch/COALA."],"url":"http://arxiv.org/abs/2407.16560v1"}
{"created":"2024-07-23 14:53:47","title":"QPT V2: Masked Image Modeling Advances Visual Scoring","abstract":"Quality assessment and aesthetics assessment aim to evaluate the perceived quality and aesthetics of visual content. Current learning-based methods suffer greatly from the scarcity of labeled data and usually perform sub-optimally in terms of generalization. Although masked image modeling (MIM) has achieved noteworthy advancements across various high-level tasks (e.g., classification, detection etc.). In this work, we take on a novel perspective to investigate its capabilities in terms of quality- and aesthetics-awareness. To this end, we propose Quality- and aesthetics-aware pretraining (QPT V2), the first pretraining framework based on MIM that offers a unified solution to quality and aesthetics assessment. To perceive the high-level semantics and fine-grained details, pretraining data is curated. To comprehensively encompass quality- and aesthetics-related factors, degradation is introduced. To capture multi-scale quality and aesthetic information, model structure is modified. Extensive experimental results on 11 downstream benchmarks clearly show the superior performance of QPT V2 in comparison with current state-of-the-art approaches and other pretraining paradigms. Code and models will be released at \\url{https://github.com/KeiChiTse/QPT-V2}.","sentences":["Quality assessment and aesthetics assessment aim to evaluate the perceived quality and aesthetics of visual content.","Current learning-based methods suffer greatly from the scarcity of labeled data and usually perform sub-optimally in terms of generalization.","Although masked image modeling (MIM) has achieved noteworthy advancements across various high-level tasks (e.g., classification, detection etc.).","In this work, we take on a novel perspective to investigate its capabilities in terms of quality- and aesthetics-awareness.","To this end, we propose Quality- and aesthetics-aware pretraining (QPT V2), the first pretraining framework based on MIM that offers a unified solution to quality and aesthetics assessment.","To perceive the high-level semantics and fine-grained details, pretraining data is curated.","To comprehensively encompass quality- and aesthetics-related factors, degradation is introduced.","To capture multi-scale quality and aesthetic information, model structure is modified.","Extensive experimental results on 11 downstream benchmarks clearly show the superior performance of QPT V2 in comparison with current state-of-the-art approaches and other pretraining paradigms.","Code and models will be released at \\url{https://github.com/KeiChiTse/QPT-V2}."],"url":"http://arxiv.org/abs/2407.16541v1"}
{"created":"2024-07-23 14:49:17","title":"Enhancing Encrypted Internet Traffic Classification Through Advanced Data Augmentation Techniques","abstract":"The increasing popularity of online services has made Internet Traffic Classification a critical field of study. However, the rapid development of internet protocols and encryption limits usable data availability. This paper addresses the challenges of classifying encrypted internet traffic, focusing on the scarcity of open-source datasets and limitations of existing ones. We propose two Data Augmentation (DA) techniques to synthetically generate data based on real samples: Average augmentation and MTU augmentation. Both augmentations are aimed to improve the performance of the classifier, each from a different perspective: The Average augmentation aims to increase dataset size by generating new synthetic samples, while the MTU augmentation enhances classifier robustness to varying Maximum Transmission Units (MTUs). Our experiments, conducted on two well-known academic datasets and a commercial dataset, demonstrate the effectiveness of these approaches in improving model performance and mitigating constraints associated with limited and homogeneous datasets. Our findings underscore the potential of data augmentation in addressing the challenges of modern internet traffic classification. Specifically, we show that our augmentation techniques significantly enhance encrypted traffic classification models. This improvement can positively impact user Quality of Experience (QoE) by more accurately classifying traffic as video streaming (e.g., YouTube) or chat (e.g., Google Chat). Additionally, it can enhance Quality of Service (QoS) for file downloading activities (e.g., Google Docs).","sentences":["The increasing popularity of online services has made Internet Traffic Classification a critical field of study.","However, the rapid development of internet protocols and encryption limits usable data availability.","This paper addresses the challenges of classifying encrypted internet traffic, focusing on the scarcity of open-source datasets and limitations of existing ones.","We propose two Data Augmentation (DA) techniques to synthetically generate data based on real samples: Average augmentation and MTU augmentation.","Both augmentations are aimed to improve the performance of the classifier, each from a different perspective: The Average augmentation aims to increase dataset size by generating new synthetic samples, while the MTU augmentation enhances classifier robustness to varying Maximum Transmission Units (MTUs).","Our experiments, conducted on two well-known academic datasets and a commercial dataset, demonstrate the effectiveness of these approaches in improving model performance and mitigating constraints associated with limited and homogeneous datasets.","Our findings underscore the potential of data augmentation in addressing the challenges of modern internet traffic classification.","Specifically, we show that our augmentation techniques significantly enhance encrypted traffic classification models.","This improvement can positively impact user Quality of Experience (QoE) by more accurately classifying traffic as video streaming (e.g., YouTube) or chat (e.g., Google Chat).","Additionally, it can enhance Quality of Service (QoS) for file downloading activities (e.g., Google Docs)."],"url":"http://arxiv.org/abs/2407.16539v1"}
{"created":"2024-07-23 14:46:07","title":"HAPFI: History-Aware Planning based on Fused Information","abstract":"Embodied Instruction Following (EIF) is a task of planning a long sequence of sub-goals given high-level natural language instructions, such as \"Rinse a slice of lettuce and place on the white table next to the fork\". To successfully execute these long-term horizon tasks, we argue that an agent must consider its past, i.e., historical data, when making decisions in each step. Nevertheless, recent approaches in EIF often neglects the knowledge from historical data and also do not effectively utilize information across the modalities. To this end, we propose History-Aware Planning based on Fused Information (HAPFI), effectively leveraging the historical data from diverse modalities that agents collect while interacting with the environment. Specifically, HAPFI integrates multiple modalities, including historical RGB observations, bounding boxes, sub-goals, and high-level instructions, by effectively fusing modalities via our Mutually Attentive Fusion method. Through experiments with diverse comparisons, we show that an agent utilizing historical multi-modal information surpasses all the compared methods that neglect the historical data in terms of action planning capability, enabling the generation of well-informed action plans for the next step. Moreover, we provided qualitative evidence highlighting the significance of leveraging historical multi-modal data, particularly in scenarios where the agent encounters intermediate failures, showcasing its robust re-planning capabilities.","sentences":["Embodied Instruction Following (EIF) is a task of planning a long sequence of sub-goals given high-level natural language instructions, such as \"Rinse a slice of lettuce and place on the white table next to the fork\".","To successfully execute these long-term horizon tasks, we argue that an agent must consider its past, i.e., historical data, when making decisions in each step.","Nevertheless, recent approaches in EIF often neglects the knowledge from historical data and also do not effectively utilize information across the modalities.","To this end, we propose History-Aware Planning based on Fused Information (HAPFI), effectively leveraging the historical data from diverse modalities that agents collect while interacting with the environment.","Specifically, HAPFI integrates multiple modalities, including historical RGB observations, bounding boxes, sub-goals, and high-level instructions, by effectively fusing modalities via our Mutually Attentive Fusion method.","Through experiments with diverse comparisons, we show that an agent utilizing historical multi-modal information surpasses all the compared methods that neglect the historical data in terms of action planning capability, enabling the generation of well-informed action plans for the next step.","Moreover, we provided qualitative evidence highlighting the significance of leveraging historical multi-modal data, particularly in scenarios where the agent encounters intermediate failures, showcasing its robust re-planning capabilities."],"url":"http://arxiv.org/abs/2407.16533v1"}
{"created":"2024-07-23 14:39:40","title":"Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models","abstract":"Vision language models (VLMs) demonstrate impressive capabilities in visual question answering and image captioning, acting as a crucial link between visual and language models. However, existing open-source VLMs heavily rely on pretrained and frozen vision encoders (such as CLIP). Despite CLIP's robustness across diverse domains, it still exhibits non-negligible image understanding errors. These errors propagate to the VLM responses, resulting in sub-optimal performance. In our work, we propose an efficient and robust method for updating vision encoders within VLMs. Our approach selectively and locally updates encoders, leading to substantial performance improvements on data where previous mistakes occurred, while maintaining overall robustness. Furthermore, we demonstrate the effectiveness of our method during continual few-shot updates. Theoretical grounding, generality, and computational efficiency characterize our approach.","sentences":["Vision language models (VLMs) demonstrate impressive capabilities in visual question answering and image captioning, acting as a crucial link between visual and language models.","However, existing open-source VLMs heavily rely on pretrained and frozen vision encoders (such as CLIP).","Despite CLIP's robustness across diverse domains, it still exhibits non-negligible image understanding errors.","These errors propagate to the VLM responses, resulting in sub-optimal performance.","In our work, we propose an efficient and robust method for updating vision encoders within VLMs.","Our approach selectively and locally updates encoders, leading to substantial performance improvements on data where previous mistakes occurred, while maintaining overall robustness.","Furthermore, we demonstrate the effectiveness of our method during continual few-shot updates.","Theoretical grounding, generality, and computational efficiency characterize our approach."],"url":"http://arxiv.org/abs/2407.16526v1"}
{"created":"2024-07-23 14:31:59","title":"Assessing In-context Learning and Fine-tuning for Topic Classification of German Web Data","abstract":"Researchers in the political and social sciences often rely on classification models to analyze trends in information consumption by examining browsing histories of millions of webpages. Automated scalable methods are necessary due to the impracticality of manual labeling. In this paper, we model the detection of topic-related content as a binary classification task and compare the accuracy of fine-tuned pre-trained encoder models against in-context learning strategies. Using only a few hundred annotated data points per topic, we detect content related to three German policies in a database of scraped webpages. We compare multilingual and monolingual models, as well as zero and few-shot approaches, and investigate the impact of negative sampling strategies and the combination of URL & content-based features. Our results show that a small sample of annotated data is sufficient to train an effective classifier. Fine-tuning encoder-based models yields better results than in-context learning. Classifiers using both URL & content-based features perform best, while using URLs alone provides adequate results when content is unavailable.","sentences":["Researchers in the political and social sciences often rely on classification models to analyze trends in information consumption by examining browsing histories of millions of webpages.","Automated scalable methods are necessary due to the impracticality of manual labeling.","In this paper, we model the detection of topic-related content as a binary classification task and compare the accuracy of fine-tuned pre-trained encoder models against in-context learning strategies.","Using only a few hundred annotated data points per topic, we detect content related to three German policies in a database of scraped webpages.","We compare multilingual and monolingual models, as well as zero and few-shot approaches, and investigate the impact of negative sampling strategies and the combination of URL & content-based features.","Our results show that a small sample of annotated data is sufficient to train an effective classifier.","Fine-tuning encoder-based models yields better results than in-context learning.","Classifiers using both URL & content-based features perform best, while using URLs alone provides adequate results when content is unavailable."],"url":"http://arxiv.org/abs/2407.16516v1"}
{"created":"2024-07-23 14:30:53","title":"Spurious Correlations in Concept Drift: Can Explanatory Interaction Help?","abstract":"Long-running machine learning models face the issue of concept drift (CD), whereby the data distribution changes over time, compromising prediction performance. Updating the model requires detecting drift by monitoring the data and/or the model for unexpected changes. We show that, however, spurious correlations (SCs) can spoil the statistics tracked by detection algorithms. Motivated by this, we introduce ebc-exstream, a novel detector that leverages model explanations to identify potential SCs and human feedback to correct for them. It leverages an entropy-based heuristic to reduce the amount of necessary feedback, cutting annotation costs. Our preliminary experiments on artificially confounded data highlight the promise of ebc-exstream for reducing the impact of SCs on detection.","sentences":["Long-running machine learning models face the issue of concept drift (CD), whereby the data distribution changes over time, compromising prediction performance.","Updating the model requires detecting drift by monitoring the data and/or the model for unexpected changes.","We show that, however, spurious correlations (SCs) can spoil the statistics tracked by detection algorithms.","Motivated by this, we introduce ebc-exstream, a novel detector that leverages model explanations to identify potential SCs and human feedback to correct for them.","It leverages an entropy-based heuristic to reduce the amount of necessary feedback, cutting annotation costs.","Our preliminary experiments on artificially confounded data highlight the promise of ebc-exstream for reducing the impact of SCs on detection."],"url":"http://arxiv.org/abs/2407.16515v1"}
{"created":"2024-07-23 14:25:28","title":"DreamVTON: Customizing 3D Virtual Try-on with Personalized Diffusion Models","abstract":"Image-based 3D Virtual Try-ON (VTON) aims to sculpt the 3D human according to person and clothes images, which is data-efficient (i.e., getting rid of expensive 3D data) but challenging. Recent text-to-3D methods achieve remarkable improvement in high-fidelity 3D human generation, demonstrating its potential for 3D virtual try-on. Inspired by the impressive success of personalized diffusion models (e.g., Dreambooth and LoRA) for 2D VTON, it is straightforward to achieve 3D VTON by integrating the personalization technique into the diffusion-based text-to-3D framework. However, employing the personalized module in a pre-trained diffusion model (e.g., StableDiffusion (SD)) would degrade the model's capability for multi-view or multi-domain synthesis, which is detrimental to the geometry and texture optimization guided by Score Distillation Sampling (SDS) loss. In this work, we propose a novel customizing 3D human try-on model, named \\textbf{DreamVTON}, to separately optimize the geometry and texture of the 3D human. Specifically, a personalized SD with multi-concept LoRA is proposed to provide the generative prior about the specific person and clothes, while a Densepose-guided ControlNet is exploited to guarantee consistent prior about body pose across various camera views. Besides, to avoid the inconsistent multi-view priors from the personalized SD dominating the optimization, DreamVTON introduces a template-based optimization mechanism, which employs mask templates for geometry shape learning and normal/RGB templates for geometry/texture details learning. Furthermore, for the geometry optimization phase, DreamVTON integrates a normal-style LoRA into personalized SD to enhance normal map generative prior, facilitating smooth geometry modeling.","sentences":["Image-based 3D Virtual Try-ON (VTON) aims to sculpt the 3D human according to person and clothes images, which is data-efficient (i.e., getting rid of expensive 3D data) but challenging.","Recent text-to-3D methods achieve remarkable improvement in high-fidelity 3D human generation, demonstrating its potential for 3D virtual try-on.","Inspired by the impressive success of personalized diffusion models (e.g., Dreambooth and LoRA) for 2D VTON, it is straightforward to achieve 3D VTON by integrating the personalization technique into the diffusion-based text-to-3D framework.","However, employing the personalized module in a pre-trained diffusion model (e.g., StableDiffusion (SD)) would degrade the model's capability for multi-view or multi-domain synthesis, which is detrimental to the geometry and texture optimization guided by Score Distillation Sampling (SDS) loss.","In this work, we propose a novel customizing 3D human try-on model, named \\textbf{DreamVTON}, to separately optimize the geometry and texture of the 3D human.","Specifically, a personalized SD with multi-concept LoRA is proposed to provide the generative prior about the specific person and clothes, while a Densepose-guided ControlNet is exploited to guarantee consistent prior about body pose across various camera views.","Besides, to avoid the inconsistent multi-view priors from the personalized SD dominating the optimization, DreamVTON introduces a template-based optimization mechanism, which employs mask templates for geometry shape learning and normal/RGB templates for geometry/texture details learning.","Furthermore, for the geometry optimization phase, DreamVTON integrates a normal-style LoRA into personalized SD to enhance normal map generative prior, facilitating smooth geometry modeling."],"url":"http://arxiv.org/abs/2407.16511v1"}
{"created":"2024-07-23 14:21:27","title":"Language-Based Security for Low-Level MPC","abstract":"Secure Multi-Party Computation (MPC) is an important enabling technology for data privacy in modern distributed applications. Currently, proof methods for low-level MPC protocols are primarily manual and thus tedious and error-prone, and are also non-standardized and unfamiliar to most PL theorists. As a step towards better language support and language-based enforcement, we develop a new staged PL for defining a variety of low-level probabilistic MPC protocols. We also formulate a collection of confidentiality and integrity hyperproperties for our language model that are familiar from information flow, including conditional noninterference, gradual release, and robust declassification. We demonstrate their relation to standard MPC threat models of passive and malicious security, and how they can be leveraged in security verification of protocols. To prove these properties we develop automated tactics in $\\mathbb{F}_2$ that can be integrated with separation logic-style reasoning.","sentences":["Secure Multi-Party Computation (MPC) is an important enabling technology for data privacy in modern distributed applications.","Currently, proof methods for low-level MPC protocols are primarily manual and thus tedious and error-prone, and are also non-standardized and unfamiliar to most PL theorists.","As a step towards better language support and language-based enforcement, we develop a new staged PL for defining a variety of low-level probabilistic MPC protocols.","We also formulate a collection of confidentiality and integrity hyperproperties for our language model that are familiar from information flow, including conditional noninterference, gradual release, and robust declassification.","We demonstrate their relation to standard MPC threat models of passive and malicious security, and how they can be leveraged in security verification of protocols.","To prove these properties we develop automated tactics in $\\mathbb{F}_2$ that can be integrated with separation logic-style reasoning."],"url":"http://arxiv.org/abs/2407.16504v1"}
{"created":"2024-07-23 14:12:57","title":"Dynamic Retraining-Updating Mean Teacher for Source-Free Object Detection","abstract":"In object detection, unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain. However, UDA's reliance on labeled source data restricts its adaptability in privacy-related scenarios. This study focuses on source-free object detection (SFOD), which adapts a source-trained detector to an unlabeled target domain without using labeled source data. Recent advancements in self-training, particularly with the Mean Teacher (MT) framework, show promise for SFOD deployment. However, the absence of source supervision significantly compromises the stability of these approaches. We identify two primary issues, (1) uncontrollable degradation of the teacher model due to inopportune updates from the student model, and (2) the student model's tendency to replicate errors from incorrect pseudo labels, leading to it being trapped in a local optimum. Both factors contribute to a detrimental circular dependency, resulting in rapid performance degradation in recent self-training frameworks. To tackle these challenges, we propose the Dynamic Retraining-Updating (DRU) mechanism, which actively manages the student training and teacher updating processes to achieve co-evolutionary training. Additionally, we introduce Historical Student Loss to mitigate the influence of incorrect pseudo labels. Our method achieves state-of-the-art performance in the SFOD setting on multiple domain adaptation benchmarks, comparable to or even surpassing advanced UDA methods. The code will be released at https://github.com/lbktrinh/DRU","sentences":["In object detection, unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain.","However, UDA's reliance on labeled source data restricts its adaptability in privacy-related scenarios.","This study focuses on source-free object detection (SFOD), which adapts a source-trained detector to an unlabeled target domain without using labeled source data.","Recent advancements in self-training, particularly with the Mean Teacher (MT) framework, show promise for SFOD deployment.","However, the absence of source supervision significantly compromises the stability of these approaches.","We identify two primary issues, (1) uncontrollable degradation of the teacher model due to inopportune updates from the student model, and (2) the student model's tendency to replicate errors from incorrect pseudo labels, leading to it being trapped in a local optimum.","Both factors contribute to a detrimental circular dependency, resulting in rapid performance degradation in recent self-training frameworks.","To tackle these challenges, we propose the Dynamic Retraining-Updating (DRU) mechanism, which actively manages the student training and teacher updating processes to achieve co-evolutionary training.","Additionally, we introduce Historical Student Loss to mitigate the influence of incorrect pseudo labels.","Our method achieves state-of-the-art performance in the SFOD setting on multiple domain adaptation benchmarks, comparable to or even surpassing advanced UDA methods.","The code will be released at https://github.com/lbktrinh/DRU"],"url":"http://arxiv.org/abs/2407.16497v1"}
{"created":"2024-07-23 14:06:18","title":"Canadian Traveller Problems in Temporal Graphs","abstract":"This paper formalises the Canadian Traveller problem as a positional two-player game on graphs. We consider two variants depending on whether an edge is blocked. In the locally-informed variant, the traveller learns if an edge is blocked upon reaching one of its endpoints, while in the uninformed variant, they discover this only when the edge is supposed to appear. We provide a polynomial algorithm for each shortest path variant in the uninformed case. This algorithm also solves the case of directed acyclic non-temporal graphs.   In the locally-informed case, we prove that finding a winning strategy is PSPACE-complete. Moreover, we establish that the problem is polynomial-time solvable when $k=1$ but NP-hard for $k\\geq 2$.   Additionally, we show that the standard (non-temporal) Canadian Traveller Problem is NP-hard when there are $k\\geq 4$ blocked edges, which is, to the best of our knowledge, the first hardness result for CTP for a constant number of blocked edges.","sentences":["This paper formalises the Canadian Traveller problem as a positional two-player game on graphs.","We consider two variants depending on whether an edge is blocked.","In the locally-informed variant, the traveller learns if an edge is blocked upon reaching one of its endpoints, while in the uninformed variant, they discover this only when the edge is supposed to appear.","We provide a polynomial algorithm for each shortest path variant in the uninformed case.","This algorithm also solves the case of directed acyclic non-temporal graphs.   ","In the locally-informed case, we prove that finding a winning strategy is PSPACE-complete.","Moreover, we establish that the problem is polynomial-time solvable when $k=1$ but NP-hard for $k\\geq 2$.   Additionally, we show that the standard (non-temporal) Canadian Traveller Problem is NP-hard when there are $k\\geq 4$ blocked edges, which is, to the best of our knowledge, the first hardness result for CTP for a constant number of blocked edges."],"url":"http://arxiv.org/abs/2407.16491v1"}
{"created":"2024-07-23 14:00:18","title":"Learning General Continuous Constraint from Demonstrations via Positive-Unlabeled Learning","abstract":"Planning for a wide range of real-world tasks necessitates to know and write all constraints. However, instances exist where these constraints are either unknown or challenging to specify accurately. A possible solution is to infer the unknown constraints from expert demonstration. The majority of prior works limit themselves to learning simple linear constraints, or require strong knowledge of the true constraint parameterization or environmental model. To mitigate these problems, this paper presents a positive-unlabeled (PU) learning approach to infer a continuous, arbitrary and possibly nonlinear, constraint from demonstration. From a PU learning view, We treat all data in demonstrations as positive (feasible) data, and learn a (sub)-optimal policy to generate high-reward-winning but potentially infeasible trajectories, which serve as unlabeled data containing both feasible and infeasible states. Under an assumption on data distribution, a feasible-infeasible classifier (i.e., constraint model) is learned from the two datasets through a postprocessing PU learning technique. The entire method employs an iterative framework alternating between updating the policy, which generates and selects higher-reward policies, and updating the constraint model. Additionally, a memory buffer is introduced to record and reuse samples from previous iterations to prevent forgetting. The effectiveness of the proposed method is validated in two Mujoco environments, successfully inferring continuous nonlinear constraints and outperforming a baseline method in terms of constraint accuracy and policy safety.","sentences":["Planning for a wide range of real-world tasks necessitates to know and write all constraints.","However, instances exist where these constraints are either unknown or challenging to specify accurately.","A possible solution is to infer the unknown constraints from expert demonstration.","The majority of prior works limit themselves to learning simple linear constraints, or require strong knowledge of the true constraint parameterization or environmental model.","To mitigate these problems, this paper presents a positive-unlabeled (PU) learning approach to infer a continuous, arbitrary and possibly nonlinear, constraint from demonstration.","From a PU learning view, We treat all data in demonstrations as positive (feasible) data, and learn a (sub)-optimal policy to generate high-reward-winning but potentially infeasible trajectories, which serve as unlabeled data containing both feasible and infeasible states.","Under an assumption on data distribution, a feasible-infeasible classifier (i.e., constraint model) is learned from the two datasets through a postprocessing PU learning technique.","The entire method employs an iterative framework alternating between updating the policy, which generates and selects higher-reward policies, and updating the constraint model.","Additionally, a memory buffer is introduced to record and reuse samples from previous iterations to prevent forgetting.","The effectiveness of the proposed method is validated in two Mujoco environments, successfully inferring continuous nonlinear constraints and outperforming a baseline method in terms of constraint accuracy and policy safety."],"url":"http://arxiv.org/abs/2407.16485v1"}
{"created":"2024-07-23 13:56:42","title":"Joint Resource-Power Allocation and UE Rank Selection in Multi-User MIMO Systems with Linear Transceivers","abstract":"Next-generation wireless networks aim to deliver data speeds much faster than 5G. This requires base stations with lots of antennas and a large operating bandwidth. These advanced base stations are expected to serve several multi-antenna user-equipment (UEs) simultaneously on the same time-frequency resources on both the uplink and the downlink. The UE data rates are affected by the following three main factors: UE rank, which refers to the number of data layers used by each UE, UE frequency allocation, which refers to the assignment of slices of the overall frequency band to use for each UE in an orthogonal frequency-division multiplexing (OFDM) system, and UE power allocation/control, which refers to the power allocated by the base station for data transmission to each UE on the downlink or the power used by the UE to send data on the uplink. Since multiple UEs are to be simultaneously served, the type of precoder used for downlink transmission and the type of receiver used for uplink reception predominantly influence these three aforementioned factors and the resulting overall UE throughput. This paper addresses the problem of jointly selecting these three parameters specifically when zero-forcing (ZF) precoders are used for downlink transmission and linear minimum mean square error (LMMSE) receivers are employed for uplink reception.","sentences":["Next-generation wireless networks aim to deliver data speeds much faster than 5G.","This requires base stations with lots of antennas and a large operating bandwidth.","These advanced base stations are expected to serve several multi-antenna user-equipment (UEs) simultaneously on the same time-frequency resources on both the uplink and the downlink.","The UE data rates are affected by the following three main factors: UE rank, which refers to the number of data layers used by each UE, UE frequency allocation, which refers to the assignment of slices of the overall frequency band to use for each UE in an orthogonal frequency-division multiplexing (OFDM) system, and UE power allocation/control, which refers to the power allocated by the base station for data transmission to each UE on the downlink or the power used by the UE to send data on the uplink.","Since multiple UEs are to be simultaneously served, the type of precoder used for downlink transmission and the type of receiver used for uplink reception predominantly influence these three aforementioned factors and the resulting overall UE throughput.","This paper addresses the problem of jointly selecting these three parameters specifically when zero-forcing (ZF) precoders are used for downlink transmission and linear minimum mean square error (LMMSE) receivers are employed for uplink reception."],"url":"http://arxiv.org/abs/2407.16483v1"}
{"created":"2024-07-23 13:53:22","title":"BONES: a Benchmark fOr Neural Estimation of Shapley values","abstract":"Shapley Values are concepts established for eXplainable AI. They are used to explain black-box predictive models by quantifying the features' contributions to the model's outcomes. Since computing the exact Shapley Values is known to be computationally intractable on real-world datasets, neural estimators have emerged as alternative, more scalable approaches to get approximated Shapley Values estimates. However, experiments with neural estimators are currently hard to replicate as algorithm implementations, explainer evaluators, and results visualizations are neither standardized nor promptly usable. To bridge this gap, we present BONES, a new benchmark focused on neural estimation of Shapley Value. It provides researchers with a suite of state-of-the-art neural and traditional estimators, a set of commonly used benchmark datasets, ad hoc modules for training black-box models, as well as specific functions to easily compute the most popular evaluation metrics and visualize results. The purpose is to simplify XAI model usage, evaluation, and comparison. In this paper, we showcase BONES results and visualizations for XAI model benchmarking on both tabular and image data. The open-source library is available at the following link: https://github.com/DavideNapolitano/BONES.","sentences":["Shapley Values are concepts established for eXplainable AI.","They are used to explain black-box predictive models by quantifying the features' contributions to the model's outcomes.","Since computing the exact Shapley Values is known to be computationally intractable on real-world datasets, neural estimators have emerged as alternative, more scalable approaches to get approximated Shapley Values estimates.","However, experiments with neural estimators are currently hard to replicate as algorithm implementations, explainer evaluators, and results visualizations are neither standardized nor promptly usable.","To bridge this gap, we present BONES, a new benchmark focused on neural estimation of Shapley Value.","It provides researchers with a suite of state-of-the-art neural and traditional estimators, a set of commonly used benchmark datasets, ad hoc modules for training black-box models, as well as specific functions to easily compute the most popular evaluation metrics and visualize results.","The purpose is to simplify XAI model usage, evaluation, and comparison.","In this paper, we showcase BONES results and visualizations for XAI model benchmarking on both tabular and image data.","The open-source library is available at the following link: https://github.com/DavideNapolitano/BONES."],"url":"http://arxiv.org/abs/2407.16482v1"}
{"created":"2024-07-23 13:49:19","title":"qMRI Diffusor: Quantitative T1 Mapping of the Brain using a Denoising Diffusion Probabilistic Model","abstract":"Quantitative MRI (qMRI) offers significant advantages over weighted images by providing objective parameters related to tissue properties. Deep learning-based methods have demonstrated effectiveness in estimating quantitative maps from series of weighted images. In this study, we present qMRI Diffusor, a novel approach to qMRI utilising deep generative models. Specifically, we implemented denoising diffusion probabilistic models (DDPM) for T1 quantification in the brain, framing the estimation of quantitative maps as a conditional generation task. The proposed method is compared with the residual neural network (ResNet) and the recurrent inference machine (RIM) on both phantom and in vivo data. The results indicate that our method achieves improved accuracy and precision in parameter estimation, along with superior visual performance. Moreover, our method inherently incorporates stochasticity, enabling straightforward quantification of uncertainty. Hence, the proposed method holds significant promise for quantitative MR mapping.","sentences":["Quantitative MRI (qMRI) offers significant advantages over weighted images by providing objective parameters related to tissue properties.","Deep learning-based methods have demonstrated effectiveness in estimating quantitative maps from series of weighted images.","In this study, we present qMRI Diffusor, a novel approach to qMRI utilising deep generative models.","Specifically, we implemented denoising diffusion probabilistic models (DDPM) for T1 quantification in the brain, framing the estimation of quantitative maps as a conditional generation task.","The proposed method is compared with the residual neural network (ResNet) and the recurrent inference machine (RIM) on both phantom and in vivo data.","The results indicate that our method achieves improved accuracy and precision in parameter estimation, along with superior visual performance.","Moreover, our method inherently incorporates stochasticity, enabling straightforward quantification of uncertainty.","Hence, the proposed method holds significant promise for quantitative MR mapping."],"url":"http://arxiv.org/abs/2407.16477v1"}
{"created":"2024-07-23 13:28:07","title":"Sobolev neural network with residual weighting as a surrogate in linear and non-linear mechanics","abstract":"Areas of computational mechanics such as uncertainty quantification and optimization usually involve repeated evaluation of numerical models that represent the behavior of engineering systems. In the case of complex nonlinear systems however, these models tend to be expensive to evaluate, making surrogate models quite valuable. Artificial neural networks approximate systems very well by taking advantage of the inherent information of its given training data. In this context, this paper investigates the improvement of the training process by including sensitivity information, which are partial derivatives w.r.t. inputs, as outlined by Sobolev training. In computational mechanics, sensitivities can be applied to neural networks by expanding the training loss function with additional loss terms, thereby improving training convergence resulting in lower generalisation error. This improvement is shown in two examples of linear and non-linear material behavior. More specifically, the Sobolev designed loss function is expanded with residual weights adjusting the effect of each loss on the training step. Residual weighting is the given scaling to the different training data, which in this case are response and sensitivities. These residual weights are optimized by an adaptive scheme, whereby varying objective functions are explored, with some showing improvements in accuracy and precision of the general training convergence.","sentences":["Areas of computational mechanics such as uncertainty quantification and optimization usually involve repeated evaluation of numerical models that represent the behavior of engineering systems.","In the case of complex nonlinear systems however, these models tend to be expensive to evaluate, making surrogate models quite valuable.","Artificial neural networks approximate systems very well by taking advantage of the inherent information of its given training data.","In this context, this paper investigates the improvement of the training process by including sensitivity information, which are partial derivatives w.r.t. inputs, as outlined by Sobolev training.","In computational mechanics, sensitivities can be applied to neural networks by expanding the training loss function with additional loss terms, thereby improving training convergence resulting in lower generalisation error.","This improvement is shown in two examples of linear and non-linear material behavior.","More specifically, the Sobolev designed loss function is expanded with residual weights adjusting the effect of each loss on the training step.","Residual weighting is the given scaling to the different training data, which in this case are response and sensitivities.","These residual weights are optimized by an adaptive scheme, whereby varying objective functions are explored, with some showing improvements in accuracy and precision of the general training convergence."],"url":"http://arxiv.org/abs/2407.16466v1"}
{"created":"2024-07-23 12:59:48","title":"Constrained coding upper bounds via Goulden-Jackson cluster theorem","abstract":"Motivated by applications in DNA-based data storage, constrained codes have attracted a considerable amount of attention from both academia and industry. We study the maximum cardinality of constrained codes for which the constraints can be characterized by a set of forbidden substrings, where by a substring we mean some consecutive coordinates in a string.   For finite-type constrained codes (for which the set of forbidden substrings is finite), one can compute their capacity (code rate) by the ``spectral method'', i.e., by applying the Perron-Frobenious theorem to the de Brujin graph defined by the code. However, there was no systematic method to compute the exact cardinality of these codes.   We show that there is a surprisingly powerful method arising from enumerative combinatorics, which is based on the Goulden-Jackson cluster theorem (previously not known to the coding community), that can be used to compute not only the capacity, but also the exact formula for the cardinality of these codes, for each fixed code length. Moreover, this can be done by solving a system of linear equations of size equal to the number of constraints.   We also show that the spectral method and the cluster method are inherently related by establishing a direct connection between the spectral radius of the de Brujin graph used in the first method and the convergence radius of the generating function used in the second method.   Lastly, to demonstrate the flexibility of the new method, we use it to give an explicit upper bound on the maximum cardinality of variable-length non-overlapping codes, which are a class of constrained codes defined by an infinite number of forbidden substrings.","sentences":["Motivated by applications in DNA-based data storage, constrained codes have attracted a considerable amount of attention from both academia and industry.","We study the maximum cardinality of constrained codes for which the constraints can be characterized by a set of forbidden substrings, where by a substring we mean some consecutive coordinates in a string.   ","For finite-type constrained codes (for which the set of forbidden substrings is finite), one can compute their capacity (code rate) by the ``spectral method'', i.e., by applying the Perron-Frobenious theorem to the de Brujin graph defined by the code.","However, there was no systematic method to compute the exact cardinality of these codes.   ","We show that there is a surprisingly powerful method arising from enumerative combinatorics, which is based on the Goulden-Jackson cluster theorem (previously not known to the coding community), that can be used to compute not only the capacity, but also the exact formula for the cardinality of these codes, for each fixed code length.","Moreover, this can be done by solving a system of linear equations of size equal to the number of constraints.   ","We also show that the spectral method and the cluster method are inherently related by establishing a direct connection between the spectral radius of the de Brujin graph used in the first method and the convergence radius of the generating function used in the second method.   ","Lastly, to demonstrate the flexibility of the new method, we use it to give an explicit upper bound on the maximum cardinality of variable-length non-overlapping codes, which are a class of constrained codes defined by an infinite number of forbidden substrings."],"url":"http://arxiv.org/abs/2407.16449v1"}
{"created":"2024-07-23 12:54:06","title":"Can time series forecasting be automated? A benchmark and analysis","abstract":"In the field of machine learning and artificial intelligence, time series forecasting plays a pivotal role across various domains such as finance, healthcare, and weather. However, the task of selecting the most suitable forecasting method for a given dataset is a complex task due to the diversity of data patterns and characteristics. This research aims to address this challenge by proposing a comprehensive benchmark for evaluating and ranking time series forecasting methods across a wide range of datasets. This study investigates the comparative performance of many methods from two prominent time series forecasting frameworks, AutoGluon-Timeseries, and sktime to shed light on their applicability in different real-world scenarios. This research contributes to the field of time series forecasting by providing a robust benchmarking methodology and facilitating informed decision-making when choosing forecasting methods for achieving optimal prediction.","sentences":["In the field of machine learning and artificial intelligence, time series forecasting plays a pivotal role across various domains such as finance, healthcare, and weather.","However, the task of selecting the most suitable forecasting method for a given dataset is a complex task due to the diversity of data patterns and characteristics.","This research aims to address this challenge by proposing a comprehensive benchmark for evaluating and ranking time series forecasting methods across a wide range of datasets.","This study investigates the comparative performance of many methods from two prominent time series forecasting frameworks, AutoGluon-Timeseries, and sktime to shed light on their applicability in different real-world scenarios.","This research contributes to the field of time series forecasting by providing a robust benchmarking methodology and facilitating informed decision-making when choosing forecasting methods for achieving optimal prediction."],"url":"http://arxiv.org/abs/2407.16445v1"}
{"created":"2024-07-23 12:53:41","title":"Psychomatics -- A Multidisciplinary Framework for Understanding Artificial Minds","abstract":"Although LLMs and other artificial intelligence systems demonstrate cognitive skills similar to humans, like concept learning and language acquisition, the way they process information fundamentally differs from biological cognition. To better understand these differences this paper introduces Psychomatics, a multidisciplinary framework bridging cognitive science, linguistics, and computer science. It aims to better understand the high-level functioning of LLMs, focusing specifically on how LLMs acquire, learn, remember, and use information to produce their outputs. To achieve this goal, Psychomatics will rely on a comparative methodology, starting from a theory-driven research question - is the process of language development and use different in humans and LLMs? - drawing parallels between LLMs and biological systems. Our analysis shows how LLMs can map and manipulate complex linguistic patterns in their training data. Moreover, LLMs can follow Grice's Cooperative Principle to provide relevant and informative responses. However, human cognition draws from multiple sources of meaning, including experiential, emotional, and imaginative facets, which transcend mere language processing and are rooted in our social and developmental trajectories. Moreover, current LLMs lack physical embodiment, reducing their ability to make sense of the intricate interplay between perception, action, and cognition that shapes human understanding and expression. Ultimately, Psychomatics holds the potential to yield transformative insights into the nature of language, cognition, and intelligence, both artificial and biological. Moreover, by drawing parallels between LLMs and human cognitive processes, Psychomatics can inform the development of more robust and human-like AI systems.","sentences":["Although LLMs and other artificial intelligence systems demonstrate cognitive skills similar to humans, like concept learning and language acquisition, the way they process information fundamentally differs from biological cognition.","To better understand these differences this paper introduces Psychomatics, a multidisciplinary framework bridging cognitive science, linguistics, and computer science.","It aims to better understand the high-level functioning of LLMs, focusing specifically on how LLMs acquire, learn, remember, and use information to produce their outputs.","To achieve this goal, Psychomatics will rely on a comparative methodology, starting from a theory-driven research question - is the process of language development and use different in humans and LLMs?","- drawing parallels between LLMs and biological systems.","Our analysis shows how LLMs can map and manipulate complex linguistic patterns in their training data.","Moreover, LLMs can follow Grice's Cooperative Principle to provide relevant and informative responses.","However, human cognition draws from multiple sources of meaning, including experiential, emotional, and imaginative facets, which transcend mere language processing and are rooted in our social and developmental trajectories.","Moreover, current LLMs lack physical embodiment, reducing their ability to make sense of the intricate interplay between perception, action, and cognition that shapes human understanding and expression.","Ultimately, Psychomatics holds the potential to yield transformative insights into the nature of language, cognition, and intelligence, both artificial and biological.","Moreover, by drawing parallels between LLMs and human cognitive processes, Psychomatics can inform the development of more robust and human-like AI systems."],"url":"http://arxiv.org/abs/2407.16444v1"}
{"created":"2024-07-23 12:53:06","title":"Bounds and Algorithms for Alphabetic Codes and Binary Search Trees","abstract":"Alphabetic codes and binary search trees are combinatorial structures that abstract search procedures in ordered sets endowed with probability distributions. In this paper, we design new linear-time algorithms to construct alphabetic codes, and we show that the obtained codes are not too far from being optimal. Moreover, we exploit our results on alphabetic codes to provide new bounds on the average cost of optimal binary search trees. Our results improve on the best-known bounds on the average cost of optimal binary search trees present in the literature.","sentences":["Alphabetic codes and binary search trees are combinatorial structures that abstract search procedures in ordered sets endowed with probability distributions.","In this paper, we design new linear-time algorithms to construct alphabetic codes, and we show that the obtained codes are not too far from being optimal.","Moreover, we exploit our results on alphabetic codes to provide new bounds on the average cost of optimal binary search trees.","Our results improve on the best-known bounds on the average cost of optimal binary search trees present in the literature."],"url":"http://arxiv.org/abs/2407.16443v1"}
{"created":"2024-07-23 12:29:37","title":"FairFlow: An Automated Approach to Model-based Counterfactual Data Augmentation For NLP","abstract":"Despite the evolution of language models, they continue to portray harmful societal biases and stereotypes inadvertently learned from training data. These inherent biases often result in detrimental effects in various applications. Counterfactual Data Augmentation (CDA), which seeks to balance demographic attributes in training data, has been a widely adopted approach to mitigate bias in natural language processing. However, many existing CDA approaches rely on word substitution techniques using manually compiled word-pair dictionaries. These techniques often lead to out-of-context substitutions, resulting in potential quality issues. The advancement of model-based techniques, on the other hand, has been challenged by the need for parallel training data. Works in this area resort to manually generated parallel data that are expensive to collect and are consequently limited in scale. This paper proposes FairFlow, an automated approach to generating parallel data for training counterfactual text generator models that limits the need for human intervention. Furthermore, we show that FairFlow significantly overcomes the limitations of dictionary-based word-substitution approaches whilst maintaining good performance.","sentences":["Despite the evolution of language models, they continue to portray harmful societal biases and stereotypes inadvertently learned from training data.","These inherent biases often result in detrimental effects in various applications.","Counterfactual Data Augmentation (CDA), which seeks to balance demographic attributes in training data, has been a widely adopted approach to mitigate bias in natural language processing.","However, many existing CDA approaches rely on word substitution techniques using manually compiled word-pair dictionaries.","These techniques often lead to out-of-context substitutions, resulting in potential quality issues.","The advancement of model-based techniques, on the other hand, has been challenged by the need for parallel training data.","Works in this area resort to manually generated parallel data that are expensive to collect and are consequently limited in scale.","This paper proposes FairFlow, an automated approach to generating parallel data for training counterfactual text generator models that limits the need for human intervention.","Furthermore, we show that FairFlow significantly overcomes the limitations of dictionary-based word-substitution approaches whilst maintaining good performance."],"url":"http://arxiv.org/abs/2407.16431v1"}
{"created":"2024-07-23 12:28:59","title":"Rethinking Out-of-Distribution Detection on Imbalanced Data Distribution","abstract":"Detecting and rejecting unknown out-of-distribution (OOD) samples is critical for deployed neural networks to void unreliable predictions. In real-world scenarios, however, the efficacy of existing OOD detection methods is often impeded by the inherent imbalance of in-distribution (ID) data, which causes significant performance decline. Through statistical observations, we have identified two common challenges faced by different OOD detectors: misidentifying tail class ID samples as OOD, while erroneously predicting OOD samples as head class from ID. To explain this phenomenon, we introduce a generalized statistical framework, termed ImOOD, to formulate the OOD detection problem on imbalanced data distribution. Consequently, the theoretical analysis reveals that there exists a class-aware bias item between balanced and imbalanced OOD detection, which contributes to the performance gap. Building upon this finding, we present a unified training-time regularization technique to mitigate the bias and boost imbalanced OOD detectors across architecture designs. Our theoretically grounded method translates into consistent improvements on the representative CIFAR10-LT, CIFAR100-LT, and ImageNet-LT benchmarks against several state-of-the-art OOD detection approaches. Code will be made public soon.","sentences":["Detecting and rejecting unknown out-of-distribution (OOD) samples is critical for deployed neural networks to void unreliable predictions.","In real-world scenarios, however, the efficacy of existing OOD detection methods is often impeded by the inherent imbalance of in-distribution (ID) data, which causes significant performance decline.","Through statistical observations, we have identified two common challenges faced by different OOD detectors: misidentifying tail class ID samples as OOD, while erroneously predicting OOD samples as head class from ID.","To explain this phenomenon, we introduce a generalized statistical framework, termed ImOOD, to formulate the OOD detection problem on imbalanced data distribution.","Consequently, the theoretical analysis reveals that there exists a class-aware bias item between balanced and imbalanced OOD detection, which contributes to the performance gap.","Building upon this finding, we present a unified training-time regularization technique to mitigate the bias and boost imbalanced OOD detectors across architecture designs.","Our theoretically grounded method translates into consistent improvements on the representative CIFAR10-LT, CIFAR100-LT, and ImageNet-LT benchmarks against several state-of-the-art OOD detection approaches.","Code will be made public soon."],"url":"http://arxiv.org/abs/2407.16430v1"}
{"created":"2024-07-23 11:56:33","title":"Securing Tomorrow's Smart Cities: Investigating Software Security in Internet of Vehicles and Deep Learning Technologies","abstract":"Integrating Deep Learning (DL) techniques in the Internet of Vehicles (IoV) introduces many security challenges and issues that require thorough examination. This literature review delves into the inherent vulnerabilities and risks associated with DL in IoV systems, shedding light on the multifaceted nature of security threats. Through an extensive analysis of existing research, we explore potential threats posed by DL algorithms, including adversarial attacks, data privacy breaches, and model poisoning. Additionally, we investigate the impact of DL on critical aspects of IoV security, such as intrusion detection, anomaly detection, and secure communication protocols. Our review emphasizes the complexities of ensuring the robustness, reliability, and trustworthiness of DL-based IoV systems, given the dynamic and interconnected nature of vehicular networks. Furthermore, we discuss the need for novel security solutions tailored to address these challenges effectively and enhance the security posture of DL-enabled IoV environments. By offering insights into these critical issues, this chapter aims to stimulate further research, innovation, and collaboration in securing DL techniques within the context of the IoV, thereby fostering a safer and more resilient future for vehicular communication and connectivity.","sentences":["Integrating Deep Learning (DL) techniques in the Internet of Vehicles (IoV) introduces many security challenges and issues that require thorough examination.","This literature review delves into the inherent vulnerabilities and risks associated with DL in IoV systems, shedding light on the multifaceted nature of security threats.","Through an extensive analysis of existing research, we explore potential threats posed by DL algorithms, including adversarial attacks, data privacy breaches, and model poisoning.","Additionally, we investigate the impact of DL on critical aspects of IoV security, such as intrusion detection, anomaly detection, and secure communication protocols.","Our review emphasizes the complexities of ensuring the robustness, reliability, and trustworthiness of DL-based IoV systems, given the dynamic and interconnected nature of vehicular networks.","Furthermore, we discuss the need for novel security solutions tailored to address these challenges effectively and enhance the security posture of DL-enabled IoV environments.","By offering insights into these critical issues, this chapter aims to stimulate further research, innovation, and collaboration in securing DL techniques within the context of the IoV, thereby fostering a safer and more resilient future for vehicular communication and connectivity."],"url":"http://arxiv.org/abs/2407.16410v1"}
{"created":"2024-07-23 11:35:42","title":"On ADMM in Heterogeneous Federated Learning: Personalization, Robustness, and Fairness","abstract":"Statistical heterogeneity is a root cause of tension among accuracy, fairness, and robustness of federated learning (FL), and is key in paving a path forward. Personalized FL (PFL) is an approach that aims to reduce the impact of statistical heterogeneity by developing personalized models for individual users, while also inherently providing benefits in terms of fairness and robustness. However, existing PFL frameworks focus on improving the performance of personalized models while neglecting the global model. Moreover, these frameworks achieve sublinear convergence rates and rely on strong assumptions. In this paper, we propose FLAME, an optimization framework by utilizing the alternating direction method of multipliers (ADMM) to train personalized and global models. We propose a model selection strategy to improve performance in situations where clients have different types of heterogeneous data. Our theoretical analysis establishes the global convergence and two kinds of convergence rates for FLAME under mild assumptions. We theoretically demonstrate that FLAME is more robust and fair than the state-of-the-art methods on a class of linear problems. Our experimental findings show that FLAME outperforms state-of-the-art methods in convergence and accuracy, and it achieves higher test accuracy under various attacks and performs more uniformly across clients.","sentences":["Statistical heterogeneity is a root cause of tension among accuracy, fairness, and robustness of federated learning (FL), and is key in paving a path forward.","Personalized FL (PFL) is an approach that aims to reduce the impact of statistical heterogeneity by developing personalized models for individual users, while also inherently providing benefits in terms of fairness and robustness.","However, existing PFL frameworks focus on improving the performance of personalized models while neglecting the global model.","Moreover, these frameworks achieve sublinear convergence rates and rely on strong assumptions.","In this paper, we propose FLAME, an optimization framework by utilizing the alternating direction method of multipliers (ADMM) to train personalized and global models.","We propose a model selection strategy to improve performance in situations where clients have different types of heterogeneous data.","Our theoretical analysis establishes the global convergence and two kinds of convergence rates for FLAME under mild assumptions.","We theoretically demonstrate that FLAME is more robust and fair than the state-of-the-art methods on a class of linear problems.","Our experimental findings show that FLAME outperforms state-of-the-art methods in convergence and accuracy, and it achieves higher test accuracy under various attacks and performs more uniformly across clients."],"url":"http://arxiv.org/abs/2407.16397v1"}
{"created":"2024-07-23 11:35:33","title":"Learning Unsigned Distance Functions from Multi-view Images with Volume Rendering Priors","abstract":"Unsigned distance functions (UDFs) have been a vital representation for open surfaces. With different differentiable renderers, current methods are able to train neural networks to infer a UDF by minimizing the rendering errors on the UDF to the multi-view ground truth. However, these differentiable renderers are mainly handcrafted, which makes them either biased on ray-surface intersections, or sensitive to unsigned distance outliers, or not scalable to large scale scenes. To resolve these issues, we present a novel differentiable renderer to infer UDFs more accurately. Instead of using handcrafted equations, our differentiable renderer is a neural network which is pre-trained in a data-driven manner. It learns how to render unsigned distances into depth images, leading to a prior knowledge, dubbed volume rendering priors. To infer a UDF for an unseen scene from multiple RGB images, we generalize the learned volume rendering priors to map inferred unsigned distances in alpha blending for RGB image rendering. Our results show that the learned volume rendering priors are unbiased, robust, scalable, 3D aware, and more importantly, easy to learn. We evaluate our method on both widely used benchmarks and real scenes, and report superior performance over the state-of-the-art methods.","sentences":["Unsigned distance functions (UDFs) have been a vital representation for open surfaces.","With different differentiable renderers, current methods are able to train neural networks to infer a UDF by minimizing the rendering errors on the UDF to the multi-view ground truth.","However, these differentiable renderers are mainly handcrafted, which makes them either biased on ray-surface intersections, or sensitive to unsigned distance outliers, or not scalable to large scale scenes.","To resolve these issues, we present a novel differentiable renderer to infer UDFs more accurately.","Instead of using handcrafted equations, our differentiable renderer is a neural network which is pre-trained in a data-driven manner.","It learns how to render unsigned distances into depth images, leading to a prior knowledge, dubbed volume rendering priors.","To infer a UDF for an unseen scene from multiple RGB images, we generalize the learned volume rendering priors to map inferred unsigned distances in alpha blending for RGB image rendering.","Our results show that the learned volume rendering priors are unbiased, robust, scalable, 3D aware, and more importantly, easy to learn.","We evaluate our method on both widely used benchmarks and real scenes, and report superior performance over the state-of-the-art methods."],"url":"http://arxiv.org/abs/2407.16396v1"}
{"created":"2024-07-23 11:35:24","title":"Prisec II -- A Comprehensive Model for IoT Security: Cryptographic Algorithms and Cloud Integration","abstract":"This study addresses the critical issue of ensuring data security and efficiency in interconnected devices, especially in IoT environments. The objective is to design and implement a model using cryptographic algorithms to enhance data security in 5G networks. Challenges arise from the limited computational capabilities of IoT devices, which require the analysis and selection of cryptographic algorithms to achieve efficient data transmission. This study proposes a model that includes four levels of security, each employing different levels of encryption to provide better data security. Finally, cloud computing optimizes processing efficiency and resource utilization to improve data transmission.","sentences":["This study addresses the critical issue of ensuring data security and efficiency in interconnected devices, especially in IoT environments.","The objective is to design and implement a model using cryptographic algorithms to enhance data security in 5G networks.","Challenges arise from the limited computational capabilities of IoT devices, which require the analysis and selection of cryptographic algorithms to achieve efficient data transmission.","This study proposes a model that includes four levels of security, each employing different levels of encryption to provide better data security.","Finally, cloud computing optimizes processing efficiency and resource utilization to improve data transmission."],"url":"http://arxiv.org/abs/2407.16395v1"}
{"created":"2024-07-23 11:31:11","title":"SEDS: Semantically Enhanced Dual-Stream Encoder for Sign Language Retrieval","abstract":"Different from traditional video retrieval, sign language retrieval is more biased towards understanding the semantic information of human actions contained in video clips. Previous works typically only encode RGB videos to obtain high-level semantic features, resulting in local action details drowned in a large amount of visual information redundancy. Furthermore, existing RGB-based sign retrieval works suffer from the huge memory cost of dense visual data embedding in end-to-end training, and adopt offline RGB encoder instead, leading to suboptimal feature representation. To address these issues, we propose a novel sign language representation framework called Semantically Enhanced Dual-Stream Encoder (SEDS), which integrates Pose and RGB modalities to represent the local and global information of sign language videos. Specifically, the Pose encoder embeds the coordinates of keypoints corresponding to human joints, effectively capturing detailed action features. For better context-aware fusion of two video modalities, we propose a Cross Gloss Attention Fusion (CGAF) module to aggregate the adjacent clip features with similar semantic information from intra-modality and inter-modality. Moreover, a Pose-RGB Fine-grained Matching Objective is developed to enhance the aggregated fusion feature by contextual matching of fine-grained dual-stream features. Besides the offline RGB encoder, the whole framework only contains learnable lightweight networks, which can be trained end-to-end. Extensive experiments demonstrate that our framework significantly outperforms state-of-the-art methods on various datasets.","sentences":["Different from traditional video retrieval, sign language retrieval is more biased towards understanding the semantic information of human actions contained in video clips.","Previous works typically only encode RGB videos to obtain high-level semantic features, resulting in local action details drowned in a large amount of visual information redundancy.","Furthermore, existing RGB-based sign retrieval works suffer from the huge memory cost of dense visual data embedding in end-to-end training, and adopt offline RGB encoder instead, leading to suboptimal feature representation.","To address these issues, we propose a novel sign language representation framework called Semantically Enhanced Dual-Stream Encoder (SEDS), which integrates Pose and RGB modalities to represent the local and global information of sign language videos.","Specifically, the Pose encoder embeds the coordinates of keypoints corresponding to human joints, effectively capturing detailed action features.","For better context-aware fusion of two video modalities, we propose a Cross Gloss Attention Fusion (CGAF) module to aggregate the adjacent clip features with similar semantic information from intra-modality and inter-modality.","Moreover, a Pose-RGB Fine-grained Matching Objective is developed to enhance the aggregated fusion feature by contextual matching of fine-grained dual-stream features.","Besides the offline RGB encoder, the whole framework only contains learnable lightweight networks, which can be trained end-to-end.","Extensive experiments demonstrate that our framework significantly outperforms state-of-the-art methods on various datasets."],"url":"http://arxiv.org/abs/2407.16394v1"}
{"created":"2024-07-23 11:22:33","title":"Anwendung von Causal-Discovery-Algorithmen zur Root-Cause-Analyse in der Fahrzeugmontage","abstract":"Root Cause Analysis (RCA) is a quality management method that aims to systematically investigate and identify the cause-and-effect relationships of problems and their underlying causes. Traditional methods are based on the analysis of problems by subject matter experts. In modern production processes, large amounts of data are collected. For this reason, increasingly computer-aided and data-driven methods are used for RCA. One of these methods are Causal Discovery Algorithms (CDA). This publication demonstrates the application of CDA on data from the assembly of a leading automotive manufacturer. The algorithms used learn the causal structure between the characteristics of the manufactured vehicles, the ergonomics and the temporal scope of the involved assembly processes, and quality-relevant product features based on representative data. This publication compares various CDAs in terms of their suitability in the context of quality management. For this purpose, the causal structures learned by the algorithms as well as their runtime are compared. This publication provides a contribution to quality management and demonstrates how CDAs can be used for RCA in assembly processes.","sentences":["Root Cause Analysis (RCA) is a quality management method that aims to systematically investigate and identify the cause-and-effect relationships of problems and their underlying causes.","Traditional methods are based on the analysis of problems by subject matter experts.","In modern production processes, large amounts of data are collected.","For this reason, increasingly computer-aided and data-driven methods are used for RCA.","One of these methods are Causal Discovery Algorithms (CDA).","This publication demonstrates the application of CDA on data from the assembly of a leading automotive manufacturer.","The algorithms used learn the causal structure between the characteristics of the manufactured vehicles, the ergonomics and the temporal scope of the involved assembly processes, and quality-relevant product features based on representative data.","This publication compares various CDAs in terms of their suitability in the context of quality management.","For this purpose, the causal structures learned by the algorithms as well as their runtime are compared.","This publication provides a contribution to quality management and demonstrates how CDAs can be used for RCA in assembly processes."],"url":"http://arxiv.org/abs/2407.16388v1"}
{"created":"2024-07-23 11:21:31","title":"Deep Learning Assisted Inertial Dead Reckoning and Fusion","abstract":"The interest in mobile platforms across a variety of applications has increased significantly in recent years. One of the reasons is the ability to achieve accurate navigation by using low-cost sensors. To this end, inertial sensors are fused with global navigation satellite systems (GNSS) signals. GNSS outages during platform operation can result in pure inertial navigation, causing the navigation solution to drift. In such situations, periodic trajectories with dedicated algorithms were suggested to mitigate the drift. With periodic dynamics, inertial deep learning approaches can capture the motion more accurately and provide accurate dead-reckoning for drones and mobile robots. In this paper, we propose approaches to extend deep learning-assisted inertial sensing and fusion capabilities during periodic motion. We begin by demonstrating that fusion between GNSS and inertial sensors in periodic trajectories achieves better accuracy compared to straight-line trajectories. Next, we propose an empowered network architecture to accurately regress the change in distance of the platform. Utilizing this network, we drive a hybrid approach for a neural-inertial fusion filter. Finally, we utilize this approach for situations when GNSS is available and show its benefits. A dataset of 337 minutes of data collected from inertial sensors mounted on a mobile robot and a quadrotor is used to evaluate our approaches.","sentences":["The interest in mobile platforms across a variety of applications has increased significantly in recent years.","One of the reasons is the ability to achieve accurate navigation by using low-cost sensors.","To this end, inertial sensors are fused with global navigation satellite systems (GNSS) signals.","GNSS outages during platform operation can result in pure inertial navigation, causing the navigation solution to drift.","In such situations, periodic trajectories with dedicated algorithms were suggested to mitigate the drift.","With periodic dynamics, inertial deep learning approaches can capture the motion more accurately and provide accurate dead-reckoning for drones and mobile robots.","In this paper, we propose approaches to extend deep learning-assisted inertial sensing and fusion capabilities during periodic motion.","We begin by demonstrating that fusion between GNSS and inertial sensors in periodic trajectories achieves better accuracy compared to straight-line trajectories.","Next, we propose an empowered network architecture to accurately regress the change in distance of the platform.","Utilizing this network, we drive a hybrid approach for a neural-inertial fusion filter.","Finally, we utilize this approach for situations when GNSS is available and show its benefits.","A dataset of 337 minutes of data collected from inertial sensors mounted on a mobile robot and a quadrotor is used to evaluate our approaches."],"url":"http://arxiv.org/abs/2407.16387v1"}
{"created":"2024-07-23 11:12:47","title":"TookaBERT: A Step Forward for Persian NLU","abstract":"The field of natural language processing (NLP) has seen remarkable advancements, thanks to the power of deep learning and foundation models. Language models, and specifically BERT, have been key players in this progress. In this study, we trained and introduced two new BERT models using Persian data. We put our models to the test, comparing them to seven existing models across 14 diverse Persian natural language understanding (NLU) tasks. The results speak for themselves: our larger model outperforms the competition, showing an average improvement of at least +2.8 points. This highlights the effectiveness and potential of our new BERT models for Persian NLU tasks.","sentences":["The field of natural language processing (NLP) has seen remarkable advancements, thanks to the power of deep learning and foundation models.","Language models, and specifically BERT, have been key players in this progress.","In this study, we trained and introduced two new BERT models using Persian data.","We put our models to the test, comparing them to seven existing models across 14 diverse Persian natural language understanding (NLU) tasks.","The results speak for themselves: our larger model outperforms the competition, showing an average improvement of at least +2.8 points.","This highlights the effectiveness and potential of our new BERT models for Persian NLU tasks."],"url":"http://arxiv.org/abs/2407.16382v1"}
{"created":"2024-07-23 11:05:29","title":"SIC-based Random Multiple Access Protocol: Fixed or Adaptive Approach","abstract":"Efficient data collection from a multitude of Internet of Things (IoT) devices is crucial for various applications, yet existing solutions often struggle with minimizing access delay and Age of Information (AoI), especially when managing multiple simultaneous transmissions and access strategies. This challenge becomes increasingly critical as IoT deployments continue to expand, demanding robust mechanisms for handling diverse traffic scenarios. In this study, we propose a novel approach leveraging Successive Interference Cancellation (SIC) based on adaptive and fixed parameter schemes to address these limitations. By analyzing both throughput and AoI along with access delay, we demonstrate the effectiveness of our adaptive approach compared to the fixed approach, particularly in scenarios featuring heavy and light traffic. Our findings highlight the pivotal role of adaptive approaches in optimizing data collection processes in IoT ecosystems, with a particular focus on minimizing access delay, AoI, and spectral efficiency.","sentences":["Efficient data collection from a multitude of Internet of Things (IoT) devices is crucial for various applications, yet existing solutions often struggle with minimizing access delay and Age of Information (AoI), especially when managing multiple simultaneous transmissions and access strategies.","This challenge becomes increasingly critical as IoT deployments continue to expand, demanding robust mechanisms for handling diverse traffic scenarios.","In this study, we propose a novel approach leveraging Successive Interference Cancellation (SIC) based on adaptive and fixed parameter schemes to address these limitations.","By analyzing both throughput and AoI along with access delay, we demonstrate the effectiveness of our adaptive approach compared to the fixed approach, particularly in scenarios featuring heavy and light traffic.","Our findings highlight the pivotal role of adaptive approaches in optimizing data collection processes in IoT ecosystems, with a particular focus on minimizing access delay, AoI, and spectral efficiency."],"url":"http://arxiv.org/abs/2407.16378v1"}
{"created":"2024-07-23 10:11:56","title":"Harmonizing Visual Text Comprehension and Generation","abstract":"In this work, we present TextHarmony, a unified and versatile multimodal generative model proficient in comprehending and generating visual text. Simultaneously generating images and texts typically results in performance degradation due to the inherent inconsistency between vision and language modalities. To overcome this challenge, existing approaches resort to modality-specific data for supervised fine-tuning, necessitating distinct model instances. We propose Slide-LoRA, which dynamically aggregates modality-specific and modality-agnostic LoRA experts, partially decoupling the multimodal generation space. Slide-LoRA harmonizes the generation of vision and language within a singular model instance, thereby facilitating a more unified generative process. Additionally, we develop a high-quality image caption dataset, DetailedTextCaps-100K, synthesized with a sophisticated closed-source MLLM to enhance visual text generation capabilities further. Comprehensive experiments across various benchmarks demonstrate the effectiveness of the proposed approach. Empowered by Slide-LoRA, TextHarmony achieves comparable performance to modality-specific fine-tuning results with only a 2% increase in parameters and shows an average improvement of 2.5% in visual text comprehension tasks and 4.0% in visual text generation tasks. Our work delineates the viability of an integrated approach to multimodal generation within the visual text domain, setting a foundation for subsequent inquiries.","sentences":["In this work, we present TextHarmony, a unified and versatile multimodal generative model proficient in comprehending and generating visual text.","Simultaneously generating images and texts typically results in performance degradation due to the inherent inconsistency between vision and language modalities.","To overcome this challenge, existing approaches resort to modality-specific data for supervised fine-tuning, necessitating distinct model instances.","We propose Slide-LoRA, which dynamically aggregates modality-specific and modality-agnostic LoRA experts, partially decoupling the multimodal generation space.","Slide-LoRA harmonizes the generation of vision and language within a singular model instance, thereby facilitating a more unified generative process.","Additionally, we develop a high-quality image caption dataset, DetailedTextCaps-100K, synthesized with a sophisticated closed-source MLLM to enhance visual text generation capabilities further.","Comprehensive experiments across various benchmarks demonstrate the effectiveness of the proposed approach.","Empowered by Slide-LoRA, TextHarmony achieves comparable performance to modality-specific fine-tuning results with only a 2% increase in parameters and shows an average improvement of 2.5% in visual text comprehension tasks and 4.0% in visual text generation tasks.","Our work delineates the viability of an integrated approach to multimodal generation within the visual text domain, setting a foundation for subsequent inquiries."],"url":"http://arxiv.org/abs/2407.16364v1"}
{"created":"2024-07-23 09:58:20","title":"Strike a Balance in Continual Panoptic Segmentation","abstract":"This study explores the emerging area of continual panoptic segmentation, highlighting three key balances. First, we introduce past-class backtrace distillation to balance the stability of existing knowledge with the adaptability to new information. This technique retraces the features associated with past classes based on the final label assignment results, performing knowledge distillation targeting these specific features from the previous model while allowing other features to flexibly adapt to new information. Additionally, we introduce a class-proportional memory strategy, which aligns the class distribution in the replay sample set with that of the historical training data. This strategy maintains a balanced class representation during replay, enhancing the utility of the limited-capacity replay sample set in recalling prior classes. Moreover, recognizing that replay samples are annotated only for the classes of their original step, we devise balanced anti-misguidance losses, which combat the impact of incomplete annotations without incurring classification bias. Building upon these innovations, we present a new method named Balanced Continual Panoptic Segmentation (BalConpas). Our evaluation on the challenging ADE20K dataset demonstrates its superior performance compared to existing state-of-the-art methods. The official code is available at https://github.com/jinpeng0528/BalConpas.","sentences":["This study explores the emerging area of continual panoptic segmentation, highlighting three key balances.","First, we introduce past-class backtrace distillation to balance the stability of existing knowledge with the adaptability to new information.","This technique retraces the features associated with past classes based on the final label assignment results, performing knowledge distillation targeting these specific features from the previous model while allowing other features to flexibly adapt to new information.","Additionally, we introduce a class-proportional memory strategy, which aligns the class distribution in the replay sample set with that of the historical training data.","This strategy maintains a balanced class representation during replay, enhancing the utility of the limited-capacity replay sample set in recalling prior classes.","Moreover, recognizing that replay samples are annotated only for the classes of their original step, we devise balanced anti-misguidance losses, which combat the impact of incomplete annotations without incurring classification bias.","Building upon these innovations, we present a new method named Balanced Continual Panoptic Segmentation (BalConpas).","Our evaluation on the challenging ADE20K dataset demonstrates its superior performance compared to existing state-of-the-art methods.","The official code is available at https://github.com/jinpeng0528/BalConpas."],"url":"http://arxiv.org/abs/2407.16354v1"}
{"created":"2024-07-23 09:54:07","title":"Sizey: Memory-Efficient Execution of Scientific Workflow Tasks","abstract":"As the amount of available data continues to grow in fields as diverse as bioinformatics, physics, and remote sensing, the importance of scientific workflows in the design and implementation of reproducible data analysis pipelines increases. When developing workflows, resource requirements must be defined for each type of task in the workflow. Typically, task types vary widely in their computational demands because they are simply wrappers for arbitrary black-box analysis tools. Furthermore, the resource consumption for the same task type can vary considerably as well due to different inputs. Since underestimating memory resources leads to bottlenecks and task failures, workflow developers tend to overestimate memory resources. However, overprovisioning of memory wastes resources and limits cluster throughput.   Addressing this problem, we propose Sizey, a novel online memory prediction method for workflow tasks. During workflow execution, Sizey simultaneously trains multiple machine learning models and then dynamically selects the best model for each workflow task. To evaluate the quality of the model, we introduce a novel resource allocation quality (RAQ) score based on memory prediction accuracy and efficiency. Sizey's prediction models are retrained and re-evaluated online during workflow execution, continuously incorporating metrics from completed tasks.   Our evaluation with a prototype implementation of Sizey uses metrics from six real-world scientific workflows from the popular nf-core framework and shows a median reduction in memory waste over time of 24.68% compared to the respective best-performing state-of-the-art baseline.","sentences":["As the amount of available data continues to grow in fields as diverse as bioinformatics, physics, and remote sensing, the importance of scientific workflows in the design and implementation of reproducible data analysis pipelines increases.","When developing workflows, resource requirements must be defined for each type of task in the workflow.","Typically, task types vary widely in their computational demands because they are simply wrappers for arbitrary black-box analysis tools.","Furthermore, the resource consumption for the same task type can vary considerably as well due to different inputs.","Since underestimating memory resources leads to bottlenecks and task failures, workflow developers tend to overestimate memory resources.","However, overprovisioning of memory wastes resources and limits cluster throughput.   ","Addressing this problem, we propose Sizey, a novel online memory prediction method for workflow tasks.","During workflow execution, Sizey simultaneously trains multiple machine learning models and then dynamically selects the best model for each workflow task.","To evaluate the quality of the model, we introduce a novel resource allocation quality (RAQ) score based on memory prediction accuracy and efficiency.","Sizey's prediction models are retrained and re-evaluated online during workflow execution, continuously incorporating metrics from completed tasks.   ","Our evaluation with a prototype implementation of Sizey uses metrics from six real-world scientific workflows from the popular nf-core framework and shows a median reduction in memory waste over time of 24.68% compared to the respective best-performing state-of-the-art baseline."],"url":"http://arxiv.org/abs/2407.16353v1"}
{"created":"2024-07-23 09:53:44","title":"Hardness and Approximability of Dimension Reduction on the Probability Simplex","abstract":"Dimension reduction is a technique used to transform data from a high-dimensional space into a lower-dimensional space, aiming to retain as much of the original information as possible. This approach is crucial in many disciplines like engineering, biology, astronomy, and economics. In this paper, we consider the following dimensionality reduction instance: Given an n-dimensional probability distribution p and an integer m<n, we aim to find the m-dimensional probability distribution q that is the closest to p, using the Kullback-Leibler divergence as the measure of closeness. We prove that the problem is strongly NP-hard, and we present an approximation algorithm for it.","sentences":["Dimension reduction is a technique used to transform data from a high-dimensional space into a lower-dimensional space, aiming to retain as much of the original information as possible.","This approach is crucial in many disciplines like engineering, biology, astronomy, and economics.","In this paper, we consider the following dimensionality reduction instance: Given an n-dimensional probability distribution p and an integer m<n, we aim to find the m-dimensional probability distribution q that is the closest to p, using the Kullback-Leibler divergence as the measure of closeness.","We prove that the problem is strongly NP-hard, and we present an approximation algorithm for it."],"url":"http://arxiv.org/abs/2407.16352v1"}
{"created":"2024-07-23 09:52:39","title":"Datasets of Visualization for Machine Learning","abstract":"Datasets of visualization play a crucial role in automating data-driven visualization pipelines, serving as the foundation for supervised model training and algorithm benchmarking. In this paper, we survey the literature on visualization datasets and provide a comprehensive overview of existing visualization datasets, including their data types, formats, supported tasks, and openness. We propose a what-why-how model for visualization datasets, considering the content of the dataset (what), the supported tasks (why), and the dataset construction process (how). This model provides a clear understanding of the diversity and complexity of visualization datasets. Additionally, we highlight the challenges faced by existing visualization datasets, including the lack of standardization in data types and formats and the limited availability of large-scale datasets. To address these challenges, we suggest future research directions.","sentences":["Datasets of visualization play a crucial role in automating data-driven visualization pipelines, serving as the foundation for supervised model training and algorithm benchmarking.","In this paper, we survey the literature on visualization datasets and provide a comprehensive overview of existing visualization datasets, including their data types, formats, supported tasks, and openness.","We propose a what-why-how model for visualization datasets, considering the content of the dataset (what), the supported tasks (why), and the dataset construction process (how).","This model provides a clear understanding of the diversity and complexity of visualization datasets.","Additionally, we highlight the challenges faced by existing visualization datasets, including the lack of standardization in data types and formats and the limited availability of large-scale datasets.","To address these challenges, we suggest future research directions."],"url":"http://arxiv.org/abs/2407.16351v1"}
{"created":"2024-07-23 09:50:14","title":"FACTTRACK: Time-Aware World State Tracking in Story Outlines","abstract":"While accurately detecting and correcting factual contradictions in language model outputs has become increasingly important as their capabilities improve, doing so is highly challenging. We propose a novel method, FACTTRACK, for tracking atomic facts and addressing factual contradictions. Crucially, FACTTRACK also maintains time-aware validity intervals for each fact, allowing for change over time. At a high level, FACTTRACK consists of a four-step pipeline to update a world state data structure for each new event: (1) decompose the event into directional atomic facts; (2) determine the validity interval of each atomic fact using the world state; (3) detect contradictions with existing facts in the world state; and finally (4) add new facts to the world state and update existing atomic facts. When we apply FACTTRACK to contradiction detection on structured story outlines, we find that FACTTRACK using LLaMA2-7B-Chat substantially outperforms a fair baseline using LLaMA2-7B-Chat, and achieves performance comparable to a GPT4 baseline. Moreover, when using GPT4, FACTTRACK significantly outperforms the GPT4 baseline.","sentences":["While accurately detecting and correcting factual contradictions in language model outputs has become increasingly important as their capabilities improve, doing so is highly challenging.","We propose a novel method, FACTTRACK, for tracking atomic facts and addressing factual contradictions.","Crucially, FACTTRACK also maintains time-aware validity intervals for each fact, allowing for change over time.","At a high level, FACTTRACK consists of a four-step pipeline to update a world state data structure for each new event: (1) decompose the event into directional atomic facts; (2) determine the validity interval of each atomic fact using the world state; (3) detect contradictions with existing facts in the world state; and finally (4) add new facts to the world state and update existing atomic facts.","When we apply FACTTRACK to contradiction detection on structured story outlines, we find that FACTTRACK using LLaMA2-7B-Chat substantially outperforms a fair baseline using LLaMA2-7B-Chat, and achieves performance comparable to a GPT4 baseline.","Moreover, when using GPT4, FACTTRACK significantly outperforms the GPT4 baseline."],"url":"http://arxiv.org/abs/2407.16347v1"}
{"created":"2024-07-23 09:45:25","title":"SOAP: Enhancing Spatio-Temporal Relation and Motion Information Capturing for Few-Shot Action Recognition","abstract":"High frame-rate (HFR) videos of action recognition improve fine-grained expression while reducing the spatio-temporal relation and motion information density. Thus, large amounts of video samples are continuously required for traditional data-driven training. However, samples are not always sufficient in real-world scenarios, promoting few-shot action recognition (FSAR) research. We observe that most recent FSAR works build spatio-temporal relation of video samples via temporal alignment after spatial feature extraction, cutting apart spatial and temporal features within samples. They also capture motion information via narrow perspectives between adjacent frames without considering density, leading to insufficient motion information capturing. Therefore, we propose a novel plug-and-play architecture for FSAR called Spatio-tempOral frAme tuPle enhancer (SOAP) in this paper. The model we designed with such architecture refers to SOAP-Net. Temporal connections between different feature channels and spatio-temporal relation of features are considered instead of simple feature extraction. Comprehensive motion information is also captured, using frame tuples with multiple frames containing more motion information than adjacent frames. Combining frame tuples of diverse frame counts further provides a broader perspective. SOAP-Net achieves new state-of-the-art performance across well-known benchmarks such as SthSthV2, Kinetics, UCF101, and HMDB51. Extensive empirical evaluations underscore the competitiveness, pluggability, generalization, and robustness of SOAP. The code is released at https://github.com/wenbohuang1002/SOAP.","sentences":["High frame-rate (HFR) videos of action recognition improve fine-grained expression while reducing the spatio-temporal relation and motion information density.","Thus, large amounts of video samples are continuously required for traditional data-driven training.","However, samples are not always sufficient in real-world scenarios, promoting few-shot action recognition (FSAR) research.","We observe that most recent FSAR works build spatio-temporal relation of video samples via temporal alignment after spatial feature extraction, cutting apart spatial and temporal features within samples.","They also capture motion information via narrow perspectives between adjacent frames without considering density, leading to insufficient motion information capturing.","Therefore, we propose a novel plug-and-play architecture for FSAR called Spatio-tempOral frAme tuPle enhancer (SOAP) in this paper.","The model we designed with such architecture refers to SOAP-Net.","Temporal connections between different feature channels and spatio-temporal relation of features are considered instead of simple feature extraction.","Comprehensive motion information is also captured, using frame tuples with multiple frames containing more motion information than adjacent frames.","Combining frame tuples of diverse frame counts further provides a broader perspective.","SOAP-Net achieves new state-of-the-art performance across well-known benchmarks such as SthSthV2, Kinetics, UCF101, and HMDB51.","Extensive empirical evaluations underscore the competitiveness, pluggability, generalization, and robustness of SOAP.","The code is released at https://github.com/wenbohuang1002/SOAP."],"url":"http://arxiv.org/abs/2407.16344v1"}
{"created":"2024-07-23 09:41:10","title":"Motion Capture from Inertial and Vision Sensors","abstract":"Human motion capture is the foundation for many computer vision and graphics tasks. While industrial motion capture systems with complex camera arrays or expensive wearable sensors have been widely adopted in movie and game production, consumer-affordable and easy-to-use solutions for personal applications are still far from mature. To utilize a mixture of a monocular camera and very few inertial measurement units (IMUs) for accurate multi-modal human motion capture in daily life, we contribute MINIONS in this paper, a large-scale Motion capture dataset collected from INertial and visION Sensors. MINIONS has several featured properties: 1) large scale of over five million frames and 400 minutes duration; 2) multi-modality data of IMUs signals and RGB videos labeled with joint positions, joint rotations, SMPL parameters, etc.; 3) a diverse set of 146 fine-grained single and interactive actions with textual descriptions. With the proposed MINIONS, we conduct experiments on multi-modal motion capture and explore the possibilities of consumer-affordable motion capture using a monocular camera and very few IMUs. The experiment results emphasize the unique advantages of inertial and vision sensors, showcasing the promise of consumer-affordable multi-modal motion capture and providing a valuable resource for further research and development.","sentences":["Human motion capture is the foundation for many computer vision and graphics tasks.","While industrial motion capture systems with complex camera arrays or expensive wearable sensors have been widely adopted in movie and game production, consumer-affordable and easy-to-use solutions for personal applications are still far from mature.","To utilize a mixture of a monocular camera and very few inertial measurement units (IMUs) for accurate multi-modal human motion capture in daily life, we contribute MINIONS in this paper, a large-scale Motion capture dataset collected from INertial and visION Sensors.","MINIONS has several featured properties: 1) large scale of over five million frames and 400 minutes duration; 2) multi-modality data of IMUs signals and RGB videos labeled with joint positions, joint rotations, SMPL parameters, etc.; 3) a diverse set of 146 fine-grained single and interactive actions with textual descriptions.","With the proposed MINIONS, we conduct experiments on multi-modal motion capture and explore the possibilities of consumer-affordable motion capture using a monocular camera and very few IMUs.","The experiment results emphasize the unique advantages of inertial and vision sensors, showcasing the promise of consumer-affordable multi-modal motion capture and providing a valuable resource for further research and development."],"url":"http://arxiv.org/abs/2407.16341v1"}
{"created":"2024-07-23 09:35:59","title":"STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled Experiments","abstract":"Online controlled experiments play a crucial role in enabling data-driven decisions across a wide range of companies. Variance reduction is an effective technique to improve the sensitivity of experiments, achieving higher statistical power while using fewer samples and shorter experimental periods. However, typical variance reduction methods (e.g., regression-adjusted estimators) are built upon the intuitional assumption of Gaussian distributions and cannot properly characterize the real business metrics with heavy-tailed distributions. Furthermore, outliers diminish the correlation between pre-experiment covariates and outcome metrics, greatly limiting the effectiveness of variance reduction.   In this paper, we develop a novel framework that integrates the Student's t-distribution with machine learning tools to fit heavy-tailed metrics and construct a robust average treatment effect estimator in online controlled experiments, which we call STATE. By adopting a variational EM method to optimize the loglikehood function, we can infer a robust solution that greatly eliminates the negative impact of outliers and achieves significant variance reduction. Moreover, we extend the STATE method from count metrics to ratio metrics by utilizing linear transformation that preserves unbiased estimation, whose variance reduction is more complex but less investigated in existing works. Finally, both simulations on synthetic data and long-term empirical results on Meituan experiment platform demonstrate the effectiveness of our method. Compared with the state-of-the-art estimators (CUPAC/MLRATE), STATE achieves over 50% variance reduction, indicating it can reach the same statistical power with only half of the observations, or half the experimental duration.","sentences":["Online controlled experiments play a crucial role in enabling data-driven decisions across a wide range of companies.","Variance reduction is an effective technique to improve the sensitivity of experiments, achieving higher statistical power while using fewer samples and shorter experimental periods.","However, typical variance reduction methods (e.g., regression-adjusted estimators) are built upon the intuitional assumption of Gaussian distributions and cannot properly characterize the real business metrics with heavy-tailed distributions.","Furthermore, outliers diminish the correlation between pre-experiment covariates and outcome metrics, greatly limiting the effectiveness of variance reduction.   ","In this paper, we develop a novel framework that integrates the Student's t-distribution with machine learning tools to fit heavy-tailed metrics and construct a robust average treatment effect estimator in online controlled experiments, which we call STATE.","By adopting a variational EM method to optimize the loglikehood function, we can infer a robust solution that greatly eliminates the negative impact of outliers and achieves significant variance reduction.","Moreover, we extend the STATE method from count metrics to ratio metrics by utilizing linear transformation that preserves unbiased estimation, whose variance reduction is more complex but less investigated in existing works.","Finally, both simulations on synthetic data and long-term empirical results on Meituan experiment platform demonstrate the effectiveness of our method.","Compared with the state-of-the-art estimators (CUPAC/MLRATE), STATE achieves over 50% variance reduction, indicating it can reach the same statistical power with only half of the observations, or half the experimental duration."],"url":"http://arxiv.org/abs/2407.16337v1"}
{"created":"2024-07-23 09:29:17","title":"AutoLegend: A User Feedback-Driven Adaptive Legend Generator for Visualizations","abstract":"We propose AutoLegend to generate interactive visualization legends using online learning with user feedback. AutoLegend accurately extracts symbols and channels from visualizations and then generates quality legends. AutoLegend enables a two-way interaction between legends and interactions, including highlighting, filtering, data retrieval, and retargeting. After analyzing visualization legends from IEEE VIS papers over the past 20 years, we summarized the design space and evaluation metrics for legend design in visualizations, particularly charts. The generation process consists of three interrelated components: a legend search agent, a feedback model, and an adversarial loss model. The search agent determines suitable legend solutions by exploring the design space and receives guidance from the feedback model through scalar scores. The feedback model is continuously updated by the adversarial loss model based on user input. The user study revealed that AutoLegend can learn users' preferences through legend editing.","sentences":["We propose AutoLegend to generate interactive visualization legends using online learning with user feedback.","AutoLegend accurately extracts symbols and channels from visualizations and then generates quality legends.","AutoLegend enables a two-way interaction between legends and interactions, including highlighting, filtering, data retrieval, and retargeting.","After analyzing visualization legends from IEEE VIS papers over the past 20 years, we summarized the design space and evaluation metrics for legend design in visualizations, particularly charts.","The generation process consists of three interrelated components: a legend search agent, a feedback model, and an adversarial loss model.","The search agent determines suitable legend solutions by exploring the design space and receives guidance from the feedback model through scalar scores.","The feedback model is continuously updated by the adversarial loss model based on user input.","The user study revealed that AutoLegend can learn users' preferences through legend editing."],"url":"http://arxiv.org/abs/2407.16331v1"}
{"created":"2024-07-23 09:25:59","title":"PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets","abstract":"Acute stroke demands prompt diagnosis and treatment to achieve optimal patient outcomes. However, the intricate and irregular nature of clinical data associated with acute stroke, particularly blood pressure (BP) measurements, presents substantial obstacles to effective visual analytics and decision-making. Through a year-long collaboration with experienced neurologists, we developed PhenoFlow, a visual analytics system that leverages the collaboration between human and Large Language Models (LLMs) to analyze the extensive and complex data of acute ischemic stroke patients. PhenoFlow pioneers an innovative workflow, where the LLM serves as a data wrangler while neurologists explore and supervise the output using visualizations and natural language interactions. This approach enables neurologists to focus more on decision-making with reduced cognitive load. To protect sensitive patient information, PhenoFlow only utilizes metadata to make inferences and synthesize executable codes, without accessing raw patient data. This ensures that the results are both reproducible and interpretable while maintaining patient privacy. The system incorporates a slice-and-wrap design that employs temporal folding to create an overlaid circular visualization. Combined with a linear bar graph, this design aids in exploring meaningful patterns within irregularly measured BP data. Through case studies, PhenoFlow has demonstrated its capability to support iterative analysis of extensive clinical datasets, reducing cognitive load and enabling neurologists to make well-informed decisions. Grounded in long-term collaboration with domain experts, our research demonstrates the potential of utilizing LLMs to tackle current challenges in data-driven clinical decision-making for acute ischemic stroke patients.","sentences":["Acute stroke demands prompt diagnosis and treatment to achieve optimal patient outcomes.","However, the intricate and irregular nature of clinical data associated with acute stroke, particularly blood pressure (BP) measurements, presents substantial obstacles to effective visual analytics and decision-making.","Through a year-long collaboration with experienced neurologists, we developed PhenoFlow, a visual analytics system that leverages the collaboration between human and Large Language Models (LLMs) to analyze the extensive and complex data of acute ischemic stroke patients.","PhenoFlow pioneers an innovative workflow, where the LLM serves as a data wrangler while neurologists explore and supervise the output using visualizations and natural language interactions.","This approach enables neurologists to focus more on decision-making with reduced cognitive load.","To protect sensitive patient information, PhenoFlow only utilizes metadata to make inferences and synthesize executable codes, without accessing raw patient data.","This ensures that the results are both reproducible and interpretable while maintaining patient privacy.","The system incorporates a slice-and-wrap design that employs temporal folding to create an overlaid circular visualization.","Combined with a linear bar graph, this design aids in exploring meaningful patterns within irregularly measured BP data.","Through case studies, PhenoFlow has demonstrated its capability to support iterative analysis of extensive clinical datasets, reducing cognitive load and enabling neurologists to make well-informed decisions.","Grounded in long-term collaboration with domain experts, our research demonstrates the potential of utilizing LLMs to tackle current challenges in data-driven clinical decision-making for acute ischemic stroke patients."],"url":"http://arxiv.org/abs/2407.16329v1"}
{"created":"2024-07-23 09:23:00","title":"Improving multidimensional projection quality with user-specific metrics and optimal scaling","abstract":"The growing prevalence of high-dimensional data has fostered the development of multidimensional projection (MP) techniques, such as t-SNE, UMAP, and LAMP, for data visualization and exploration. However, conventional MP methods typically employ generic quality metrics, neglecting individual user preferences. This study proposes a new framework that tailors MP techniques based on user-specific quality criteria, enhancing projection interpretability.   Our approach combines three visual quality metrics, stress, neighborhood preservation, and silhouette score, to create a composite metric for a precise MP evaluation. We then optimize the projection scale by maximizing the composite metric value. We conducted an experiment involving two users with different projection preferences, generating projections using t-SNE, UMAP, and LAMP. Users rate projections according to their criteria, producing two training sets. We derive optimal weights for each set and apply them to other datasets to determine the best projections per user.   Our findings demonstrate that personalized projections effectively capture user preferences, fostering better data exploration and enabling more informed decision-making. This user-centric approach promotes advancements in multidimensional projection techniques that accommodate diverse user preferences and enhance interpretability.","sentences":["The growing prevalence of high-dimensional data has fostered the development of multidimensional projection (MP) techniques, such as t-SNE, UMAP, and LAMP, for data visualization and exploration.","However, conventional MP methods typically employ generic quality metrics, neglecting individual user preferences.","This study proposes a new framework that tailors MP techniques based on user-specific quality criteria, enhancing projection interpretability.   ","Our approach combines three visual quality metrics, stress, neighborhood preservation, and silhouette score, to create a composite metric for a precise MP evaluation.","We then optimize the projection scale by maximizing the composite metric value.","We conducted an experiment involving two users with different projection preferences, generating projections using t-SNE, UMAP, and LAMP.","Users rate projections according to their criteria, producing two training sets.","We derive optimal weights for each set and apply them to other datasets to determine the best projections per user.   ","Our findings demonstrate that personalized projections effectively capture user preferences, fostering better data exploration and enabling more informed decision-making.","This user-centric approach promotes advancements in multidimensional projection techniques that accommodate diverse user preferences and enhance interpretability."],"url":"http://arxiv.org/abs/2407.16328v1"}
{"created":"2024-07-23 09:19:11","title":"Two Results on LPT: A Near-Linear Time Algorithm and Parcel Delivery using Drones","abstract":"The focus of this paper is to increase our understanding of the Longest Processing Time First (LPT) heuristic. LPT is a classical heuristic for the fundamental problem of uniform machine scheduling. For different machine speeds, LPT was first considered by Gonzalez et al (SIAM J. Computing, 1977). Since then, extensive work has been done to improve the approximation factor of the LPT heuristic. However, all known implementations of the LPT heuristic take $O(mn)$ time, where $m$ is the number of machines and $n$ is the number of jobs. In this work, we come up with the first near-linear time implementation for LPT. Specifically, the running time is $O((n+m)(\\log^2{m}+\\log{n}))$. Somewhat surprisingly, the result is obtained by mapping the problem to dynamic maintenance of lower envelope of lines, which has been well studied in the computational geometry community.   Our second contribution is to analyze the performance of LPT for the Drones Warehouse Problem (DWP), which is a natural generalization of the uniform machine scheduling problem motivated by drone-based parcel delivery from a warehouse. In this problem, a warehouse has multiple drones and wants to deliver parcels to several customers. Each drone picks a parcel from the warehouse, delivers it, and returns to the warehouse (where it can also get charged). The speeds and battery lives of the drones could be different, and due to the limited battery life, each drone has a bounded range in which it can deliver parcels. The goal is to assign parcels to the drones so that the time taken to deliver all the parcels is minimized. We prove that the natural approach of solving this problem via the LPT heuristic has an approximation factor of $\\phi$, where $\\phi \\approx 1.62$ is the golden ratio.","sentences":["The focus of this paper is to increase our understanding of the Longest Processing Time First (LPT) heuristic.","LPT is a classical heuristic for the fundamental problem of uniform machine scheduling.","For different machine speeds, LPT was first considered by Gonzalez et al (SIAM J. Computing, 1977).","Since then, extensive work has been done to improve the approximation factor of the LPT heuristic.","However, all known implementations of the LPT heuristic take $O(mn)$ time, where $m$ is the number of machines and $n$ is the number of jobs.","In this work, we come up with the first near-linear time implementation for LPT.","Specifically, the running time is $O((n+m)(\\log^2{m}+\\log{n}))$. Somewhat surprisingly, the result is obtained by mapping the problem to dynamic maintenance of lower envelope of lines, which has been well studied in the computational geometry community.   ","Our second contribution is to analyze the performance of LPT for the Drones Warehouse Problem (DWP), which is a natural generalization of the uniform machine scheduling problem motivated by drone-based parcel delivery from a warehouse.","In this problem, a warehouse has multiple drones and wants to deliver parcels to several customers.","Each drone picks a parcel from the warehouse, delivers it, and returns to the warehouse (where it can also get charged).","The speeds and battery lives of the drones could be different, and due to the limited battery life, each drone has a bounded range in which it can deliver parcels.","The goal is to assign parcels to the drones so that the time taken to deliver all the parcels is minimized.","We prove that the natural approach of solving this problem via the LPT heuristic has an approximation factor of $\\phi$, where $\\phi \\approx 1.62$ is the golden ratio."],"url":"http://arxiv.org/abs/2407.16323v1"}
{"created":"2024-07-23 09:16:16","title":"A Lossless Compression Technique for the Downlink Control Information Message","abstract":"Improving the reliability and spectral efficiency of wireless systems is a key goal in wireless systems. However, most efforts have been devoted to improving data channel capacity, whereas control-plane capacity bottlenecks are often neglected. In this paper, we propose a means of improving the control-plane capacity and reliability by shrinking the bit size of a key signaling message - the 5G Downlink Control Information (DCI). In particular, a transformer model is studied as a probability distribution estimator for Arithmetic coding to achieve lossless compression. Feature engineering, neural model design, and training technique are comprehensively discussed in this paper. Both temporal and spatial correlations among DCI messages are explored by the transformer model to achieve reasonable lossless compression performance. Numerical results show that the proposed method achieves 21.7% higher compression ratio than Huffman coding in DCI compression for a single-cell scheduling scenario.","sentences":["Improving the reliability and spectral efficiency of wireless systems is a key goal in wireless systems.","However, most efforts have been devoted to improving data channel capacity, whereas control-plane capacity bottlenecks are often neglected.","In this paper, we propose a means of improving the control-plane capacity and reliability by shrinking the bit size of a key signaling message - the 5G Downlink Control Information (DCI).","In particular, a transformer model is studied as a probability distribution estimator for Arithmetic coding to achieve lossless compression.","Feature engineering, neural model design, and training technique are comprehensively discussed in this paper.","Both temporal and spatial correlations among DCI messages are explored by the transformer model to achieve reasonable lossless compression performance.","Numerical results show that the proposed method achieves 21.7% higher compression ratio than Huffman coding in DCI compression for a single-cell scheduling scenario."],"url":"http://arxiv.org/abs/2407.16319v1"}
{"created":"2024-07-23 09:02:46","title":"A new visual quality metric for Evaluating the performance of multidimensional projections","abstract":"Multidimensional projections (MP) are among the most essential approaches in the visual analysis of multidimensional data. It transforms multidimensional data into two-dimensional representations that may be shown as scatter plots while preserving their similarity with the original data. Human visual perception is frequently used to evaluate the quality of MP. In this work, we propose to study and improve on a well-known map called Local Affine Multidimensional Projection (LAMP), which takes a multidimensional instance and embeds it in Cartesian space via moving least squares deformation. We propose a new visual quality metric based on human perception. The new metric combines three previously used metrics: silhouette coefficient, neighborhood preservation, and silhouette ratio. We show that the proposed metric produces more precise results in analyzing the quality of MP than other previously used metrics. Finally, we describe an algorithm that attempts to overcome a limitation of the LAMP method which requires a similar scale for control points and their counterparts in the Cartesian space.","sentences":["Multidimensional projections (MP) are among the most essential approaches in the visual analysis of multidimensional data.","It transforms multidimensional data into two-dimensional representations that may be shown as scatter plots while preserving their similarity with the original data.","Human visual perception is frequently used to evaluate the quality of MP.","In this work, we propose to study and improve on a well-known map called Local Affine Multidimensional Projection (LAMP), which takes a multidimensional instance and embeds it in Cartesian space via moving least squares deformation.","We propose a new visual quality metric based on human perception.","The new metric combines three previously used metrics: silhouette coefficient, neighborhood preservation, and silhouette ratio.","We show that the proposed metric produces more precise results in analyzing the quality of MP than other previously used metrics.","Finally, we describe an algorithm that attempts to overcome a limitation of the LAMP method which requires a similar scale for control points and their counterparts in the Cartesian space."],"url":"http://arxiv.org/abs/2407.16309v1"}
{"created":"2024-07-23 09:00:52","title":"Multimodal Unlearnable Examples: Protecting Data against Multimodal Contrastive Learning","abstract":"Multimodal contrastive learning (MCL) has shown remarkable advances in zero-shot classification by learning from millions of image-caption pairs crawled from the Internet. However, this reliance poses privacy risks, as hackers may unauthorizedly exploit image-text data for model training, potentially including personal and privacy-sensitive information. Recent works propose generating unlearnable examples by adding imperceptible perturbations to training images to build shortcuts for protection. However, they are designed for unimodal classification, which remains largely unexplored in MCL. We first explore this context by evaluating the performance of existing methods on image-caption pairs, and they do not generalize effectively to multimodal data and exhibit limited impact to build shortcuts due to the lack of labels and the dispersion of pairs in MCL. In this paper, we propose Multi-step Error Minimization (MEM), a novel optimization process for generating multimodal unlearnable examples. It extends the Error-Minimization (EM) framework to optimize both image noise and an additional text trigger, thereby enlarging the optimized space and effectively misleading the model to learn the shortcut between the noise features and the text trigger. Specifically, we adopt projected gradient descent to solve the noise minimization problem and use HotFlip to approximate the gradient and replace words to find the optimal text trigger. Extensive experiments demonstrate the effectiveness of MEM, with post-protection retrieval results nearly half of random guessing, and its high transferability across different models. Our code is available on the https://github.com/thinwayliu/Multimodal-Unlearnable-Examples","sentences":["Multimodal contrastive learning (MCL) has shown remarkable advances in zero-shot classification by learning from millions of image-caption pairs crawled from the Internet.","However, this reliance poses privacy risks, as hackers may unauthorizedly exploit image-text data for model training, potentially including personal and privacy-sensitive information.","Recent works propose generating unlearnable examples by adding imperceptible perturbations to training images to build shortcuts for protection.","However, they are designed for unimodal classification, which remains largely unexplored in MCL.","We first explore this context by evaluating the performance of existing methods on image-caption pairs, and they do not generalize effectively to multimodal data and exhibit limited impact to build shortcuts due to the lack of labels and the dispersion of pairs in MCL.","In this paper, we propose Multi-step Error Minimization (MEM), a novel optimization process for generating multimodal unlearnable examples.","It extends the Error-Minimization (EM) framework to optimize both image noise and an additional text trigger, thereby enlarging the optimized space and effectively misleading the model to learn the shortcut between the noise features and the text trigger.","Specifically, we adopt projected gradient descent to solve the noise minimization problem and use HotFlip to approximate the gradient and replace words to find the optimal text trigger.","Extensive experiments demonstrate the effectiveness of MEM, with post-protection retrieval results nearly half of random guessing, and its high transferability across different models.","Our code is available on the https://github.com/thinwayliu/Multimodal-Unlearnable-Examples"],"url":"http://arxiv.org/abs/2407.16307v1"}
{"created":"2024-07-23 08:58:06","title":"Hidden Web Caches Discovery","abstract":"Web caches play a crucial role in web performance and scalability. However, detecting cached responses is challenging when web servers do not reliably communicate the cache status through standardized headers. This paper presents a novel methodology for cache detection using timing analysis. Our approach eliminates the dependency on cache status headers, making it applicable to any web server. The methodology relies on sending paired requests using HTTP multiplexing functionality and makes heavy use of cache-busting to control the origin of the responses. By measuring the time it takes to receive responses from paired requests, we can determine if a response is cached or not. In each pair, one request is cache-busted to force retrieval from the origin server, while the other request is not and might be served from the cache, if present. A faster response time for the non-cache-busted request compared to the cache-busted one suggests the first one is coming from the cache. We implemented this approach in a tool and achieved an estimated accuracy of 89.6% compared to state-of-the-art methods based on cache status headers. Leveraging our cache detection approach, we conducted a large-scale experiment on the Tranco Top 50k websites. We identified a significant presence of hidden caches (5.8%) that do not advertise themselves through headers. Additionally, we employed our methodology to detect Web Cache Deception (WCD) vulnerabilities in these hidden caches. We discovered that 1.020 of them are susceptible to WCD vulnerabilities, potentially leaking sensitive data. Our findings demonstrate the effectiveness of our timing analysis methodology for cache discovery and highlight the importance of a tool that does not rely on cache-communicated cache status headers.","sentences":["Web caches play a crucial role in web performance and scalability.","However, detecting cached responses is challenging when web servers do not reliably communicate the cache status through standardized headers.","This paper presents a novel methodology for cache detection using timing analysis.","Our approach eliminates the dependency on cache status headers, making it applicable to any web server.","The methodology relies on sending paired requests using HTTP multiplexing functionality and makes heavy use of cache-busting to control the origin of the responses.","By measuring the time it takes to receive responses from paired requests, we can determine if a response is cached or not.","In each pair, one request is cache-busted to force retrieval from the origin server, while the other request is not and might be served from the cache, if present.","A faster response time for the non-cache-busted request compared to the cache-busted one suggests the first one is coming from the cache.","We implemented this approach in a tool and achieved an estimated accuracy of 89.6% compared to state-of-the-art methods based on cache status headers.","Leveraging our cache detection approach, we conducted a large-scale experiment on the Tranco Top 50k websites.","We identified a significant presence of hidden caches (5.8%) that do not advertise themselves through headers.","Additionally, we employed our methodology to detect Web Cache Deception (WCD) vulnerabilities in these hidden caches.","We discovered that 1.020 of them are susceptible to WCD vulnerabilities, potentially leaking sensitive data.","Our findings demonstrate the effectiveness of our timing analysis methodology for cache discovery and highlight the importance of a tool that does not rely on cache-communicated cache status headers."],"url":"http://arxiv.org/abs/2407.16303v1"}
{"created":"2024-07-23 08:55:10","title":"A Programming Model for Disaggregated Memory over CXL","abstract":"CXL (Compute Express Link) is an emerging open industry-standard interconnect between processing and memory devices that is expected to revolutionize the way systems are designed in the near future. It enables cache-coherent shared memory pools in a disaggregated fashion at unprecedented scales, allowing algorithms to interact with a variety of storage devices using simple loads and stores in a cacheline granularity. Alongside with unleashing unique opportunities for a wide range of applications, CXL introduces new challenges of data management and crash consistency. Alas, CXL lacks an adequate programming model, which makes reasoning about the correctness and expected behaviors of algorithms and systems on top of it nearly impossible.   In this work, we present CXL0, the first programming model for concurrent programs running on top of CXL. We propose a high-level abstraction for CXL memory accesses and formally define operational semantics on top of that abstraction. We provide a set of general transformations that adapt concurrent algorithms to the new disruptive technology. Using these transformations, every linearizable algorithm can be easily transformed into its provably correct version in the face of a full-system or sub-system crash. We believe that this work will serve as the stepping stone for systems design and modelling on top of CXL, and support the development of future models as software and hardware evolve.","sentences":["CXL (Compute Express Link) is an emerging open industry-standard interconnect between processing and memory devices that is expected to revolutionize the way systems are designed in the near future.","It enables cache-coherent shared memory pools in a disaggregated fashion at unprecedented scales, allowing algorithms to interact with a variety of storage devices using simple loads and stores in a cacheline granularity.","Alongside with unleashing unique opportunities for a wide range of applications, CXL introduces new challenges of data management and crash consistency.","Alas, CXL lacks an adequate programming model, which makes reasoning about the correctness and expected behaviors of algorithms and systems on top of it nearly impossible.   ","In this work, we present CXL0, the first programming model for concurrent programs running on top of CXL.","We propose a high-level abstraction for CXL memory accesses and formally define operational semantics on top of that abstraction.","We provide a set of general transformations that adapt concurrent algorithms to the new disruptive technology.","Using these transformations, every linearizable algorithm can be easily transformed into its provably correct version in the face of a full-system or sub-system crash.","We believe that this work will serve as the stepping stone for systems design and modelling on top of CXL, and support the development of future models as software and hardware evolve."],"url":"http://arxiv.org/abs/2407.16300v1"}
{"created":"2024-07-23 08:31:24","title":"Efficient Detection of Commutative Factors in Factor Graphs","abstract":"Lifted probabilistic inference exploits symmetries in probabilistic graphical models to allow for tractable probabilistic inference with respect to domain sizes. To exploit symmetries in, e.g., factor graphs, it is crucial to identify commutative factors, i.e., factors having symmetries within themselves due to their arguments being exchangeable. The current state of the art to check whether a factor is commutative with respect to a subset of its arguments iterates over all possible subsets of the factor's arguments, i.e., $O(2^n)$ iterations for a factor with $n$ arguments in the worst case. In this paper, we efficiently solve the problem of detecting commutative factors in a factor graph. In particular, we introduce the detection of commutative factors (DECOR) algorithm, which allows us to drastically reduce the computational effort for checking whether a factor is commutative in practice. We prove that DECOR efficiently identifies restrictions to drastically reduce the number of required iterations and validate the efficiency of DECOR in our empirical evaluation.","sentences":["Lifted probabilistic inference exploits symmetries in probabilistic graphical models to allow for tractable probabilistic inference with respect to domain sizes.","To exploit symmetries in, e.g., factor graphs, it is crucial to identify commutative factors, i.e., factors having symmetries within themselves due to their arguments being exchangeable.","The current state of the art to check whether a factor is commutative with respect to a subset of its arguments iterates over all possible subsets of the factor's arguments, i.e., $O(2^n)$ iterations for a factor with $n$ arguments in the worst case.","In this paper, we efficiently solve the problem of detecting commutative factors in a factor graph.","In particular, we introduce the detection of commutative factors (DECOR) algorithm, which allows us to drastically reduce the computational effort for checking whether a factor is commutative in practice.","We prove that DECOR efficiently identifies restrictions to drastically reduce the number of required iterations and validate the efficiency of DECOR in our empirical evaluation."],"url":"http://arxiv.org/abs/2407.16280v1"}
{"created":"2024-07-23 08:30:43","title":"Re-expression of manual expertise through semi-automatic control of a teleoperated system","abstract":"While the search for new solvents in the chemical industry is of uttermost importance with respect to environmental considerations, this domain remains strongly tied to highly manual and visual inspection tasks by human experts. As the manipulated chemicals may imply a critical danger (CMR substances), mechanical protection barrier are used (fume hoods, gloveboxes). This, in turn, can induce postural discomfort in the long term. Carrying out this task using a remotely controlled robot to reproduce the desired vial motions would alleviate these postural constraints. Nevertheless, the adoption of such a system will depend on its ability to transcribe the users' expertise. Particular attention must be paid to the intuitiveness of the system : transparency of the actions performed, relevance of the perceptual feedback, etc. and, in particular, the fidelity of the movements performed in relation to the user's commands. However, the extent of the rotational movements to be generated and the task interactivity complicates the problem both from the point of view of the motor capacities of industrial robots and for the transparency/responsiveness of the control.To tackle the problen of guaranteeing a secure and reactive expression of the manual characteristics of this task, we propose to separate the control of movement into two parts: control of the path (set of spatial poses) and of the trajectories associated with this path (speed, direction of travel along the path). The user can then partially control the robot's movements, by choosing the type of generic, secure path and modulating the trajectory performed on this path in real time. Although this drastically limits the possibilities for interaction, we assume that this teleoperated system can enable this type of observation task to be carried out as effectively as for direct manipulation. This hypothesis was tested through an experiment in which a reading task, less dangerous but with similar characteristics to the application task, had to be performed using different variants of trajectory modulation. This experiment consisted in reading words printed on four white capsules (dimensions 6 x 12 mm) placed into cylindrical vials ( dimensions 16 mm x 70 mm). Four randomly selected vials were tested by each variant. Firstly, users had to perform the task via direct handling, then under conditions secured by a protection barrier. Users were then invited to perform the task using different trajectory modulation variants (modulation and passive viewing of a pre-recorded video, modulation of the trajectory of a Franka-Emika Panda robot performing the task in real time in front of a monocular Logitech Brio 4K camera). After each trial of a variant, users evaluate different aspects of this variant (manual and visual performance, ease of use, acceptability of the interface) through a questionnaire. During the trials, various objective criteria are also measured (number and nature of interaction with the interface, time and degree of success in the task). This experiment was carried out with 37 subjects (age : 27$\\pm$5, 20 females). The data recorded showed that the proportion of successes, as well as the subjects' perceptions of visual performance, comfort of use and acceptability of the interface, were similar and high for all the variants. This suggests that this task is indeed achievable via the proposed interface. However, data also showed that average task completion times when using the trajectory modulation variants were significantly higher than handling by hand variants, which implies that the proposed remote semi-automatic control procedure fails to achieve satisfactory performance regarding execution time. An interface allowing more reactive manipulation of the vial's movements seems necessary, and will be tested in a future experiment.","sentences":["While the search for new solvents in the chemical industry is of uttermost importance with respect to environmental considerations, this domain remains strongly tied to highly manual and visual inspection tasks by human experts.","As the manipulated chemicals may imply a critical danger (CMR substances), mechanical protection barrier are used (fume hoods, gloveboxes).","This, in turn, can induce postural discomfort in the long term.","Carrying out this task using a remotely controlled robot to reproduce the desired vial motions would alleviate these postural constraints.","Nevertheless, the adoption of such a system will depend on its ability to transcribe the users' expertise.","Particular attention must be paid to the intuitiveness of the system : transparency of the actions performed, relevance of the perceptual feedback, etc. and, in particular, the fidelity of the movements performed in relation to the user's commands.","However, the extent of the rotational movements to be generated and the task interactivity complicates the problem both from the point of view of the motor capacities of industrial robots and for the transparency/responsiveness of the control.","To tackle the problen of guaranteeing a secure and reactive expression of the manual characteristics of this task, we propose to separate the control of movement into two parts: control of the path (set of spatial poses) and of the trajectories associated with this path (speed, direction of travel along the path).","The user can then partially control the robot's movements, by choosing the type of generic, secure path and modulating the trajectory performed on this path in real time.","Although this drastically limits the possibilities for interaction, we assume that this teleoperated system can enable this type of observation task to be carried out as effectively as for direct manipulation.","This hypothesis was tested through an experiment in which a reading task, less dangerous but with similar characteristics to the application task, had to be performed using different variants of trajectory modulation.","This experiment consisted in reading words printed on four white capsules (dimensions 6 x 12 mm) placed into cylindrical vials ( dimensions 16 mm x 70 mm).","Four randomly selected vials were tested by each variant.","Firstly, users had to perform the task via direct handling, then under conditions secured by a protection barrier.","Users were then invited to perform the task using different trajectory modulation variants (modulation and passive viewing of a pre-recorded video, modulation of the trajectory of a Franka-Emika Panda robot performing the task in real time in front of a monocular Logitech Brio 4K camera).","After each trial of a variant, users evaluate different aspects of this variant (manual and visual performance, ease of use, acceptability of the interface) through a questionnaire.","During the trials, various objective criteria are also measured (number and nature of interaction with the interface, time and degree of success in the task).","This experiment was carried out with 37 subjects (age : 27$\\pm$5, 20 females).","The data recorded showed that the proportion of successes, as well as the subjects' perceptions of visual performance, comfort of use and acceptability of the interface, were similar and high for all the variants.","This suggests that this task is indeed achievable via the proposed interface.","However, data also showed that average task completion times when using the trajectory modulation variants were significantly higher than handling by hand variants, which implies that the proposed remote semi-automatic control procedure fails to achieve satisfactory performance regarding execution time.","An interface allowing more reactive manipulation of the vial's movements seems necessary, and will be tested in a future experiment."],"url":"http://arxiv.org/abs/2407.16278v1"}
{"created":"2024-07-23 08:26:05","title":"Comparative Analysis of AES, Blowfish, Twofish, Salsa20, and ChaCha20 for Image Encryption","abstract":"Nowadays, cybersecurity has grown into a more significant and difficult scientific issue. The recog-nition of threats and attacks meant for knowledge and safety on the internet is growing harder to detect. Since cybersecurity guarantees the privacy and security of data sent via the Internet, it is essential, while also providing protection against malicious attacks. Encrypt has grown into an an-swer that has become an essential element of information security systems. To ensure the security of shared data, including text, images, or videos, it is essential to employ various methods and strategies. This study delves into the prevalent cryptographic methods and algorithms utilized for prevention and stream encryption, examining their encoding techniques such as advanced encryp-tion standard (AES), Blowfish, Twofish, Salsa20, and ChaCha20. The primary objective of this re-search is to identify the optimal times and throughputs (speeds) for data encryption and decryption processes. The methodology of this study involved selecting five distinct types of images to com-pare the outcomes of the techniques evaluated in this research. The assessment focused on pro-cessing time and speed parameters, examining visual encoding and decoding using Java as the pri-mary platform. A comparative analysis of several symmetric key ciphers was performed, focusing on handling large datasets. Despite this limitation, comparing different images helped evaluate the techniques' novelty. The results showed that ChaCha20 had the best average time for both encryp-tion and decryption, being over 50% faster than some other algorithms. However, the Twofish algo-rithm had lower throughput during testing. The paper concludes with findings and suggestions for future improvements.","sentences":["Nowadays, cybersecurity has grown into a more significant and difficult scientific issue.","The recog-nition of threats and attacks meant for knowledge and safety on the internet is growing harder to detect.","Since cybersecurity guarantees the privacy and security of data sent via the Internet, it is essential, while also providing protection against malicious attacks.","Encrypt has grown into an an-swer that has become an essential element of information security systems.","To ensure the security of shared data, including text, images, or videos, it is essential to employ various methods and strategies.","This study delves into the prevalent cryptographic methods and algorithms utilized for prevention and stream encryption, examining their encoding techniques such as advanced encryp-tion standard (AES), Blowfish, Twofish, Salsa20, and ChaCha20.","The primary objective of this re-search is to identify the optimal times and throughputs (speeds) for data encryption and decryption processes.","The methodology of this study involved selecting five distinct types of images to com-pare the outcomes of the techniques evaluated in this research.","The assessment focused on pro-cessing time and speed parameters, examining visual encoding and decoding using Java as the pri-mary platform.","A comparative analysis of several symmetric key ciphers was performed, focusing on handling large datasets.","Despite this limitation, comparing different images helped evaluate the techniques' novelty.","The results showed that ChaCha20 had the best average time for both encryp-tion and decryption, being over 50% faster than some other algorithms.","However, the Twofish algo-rithm had lower throughput during testing.","The paper concludes with findings and suggestions for future improvements."],"url":"http://arxiv.org/abs/2407.16274v1"}
{"created":"2024-07-23 08:18:43","title":"HyTAS: A Hyperspectral Image Transformer Architecture Search Benchmark and Analysis","abstract":"Hyperspectral Imaging (HSI) plays an increasingly critical role in precise vision tasks within remote sensing, capturing a wide spectrum of visual data. Transformer architectures have significantly enhanced HSI task performance, while advancements in Transformer Architecture Search (TAS) have improved model discovery. To harness these advancements for HSI classification, we make the following contributions: i) We propose HyTAS, the first benchmark on transformer architecture search for Hyperspectral imaging, ii) We comprehensively evaluate 12 different methods to identify the optimal transformer over 5 different datasets, iii) We perform an extensive factor analysis on the Hyperspectral transformer search performance, greatly motivating future research in this direction. All benchmark materials are available at HyTAS.","sentences":["Hyperspectral Imaging (HSI) plays an increasingly critical role in precise vision tasks within remote sensing, capturing a wide spectrum of visual data.","Transformer architectures have significantly enhanced HSI task performance, while advancements in Transformer Architecture Search (TAS) have improved model discovery.","To harness these advancements for HSI classification, we make the following contributions: i) We propose HyTAS, the first benchmark on transformer architecture search for Hyperspectral imaging, ii) We comprehensively evaluate 12 different methods to identify the optimal transformer over 5 different datasets, iii) We perform an extensive factor analysis on the Hyperspectral transformer search performance, greatly motivating future research in this direction.","All benchmark materials are available at HyTAS."],"url":"http://arxiv.org/abs/2407.16269v1"}
{"created":"2024-07-23 07:51:01","title":"Telecommand Rejection Probability for CCSDS-compliant LDPC-Coded Transmissions with Tail Sequence","abstract":"According to the Consultative Committee for Space Data Systems (CCSDS) recommendation for TeleCommand (TC) synchronization and coding, the Communications Link Transmission Unit (CLTU) consists of a start sequence, followed by coded data, and a tail sequence, which might be optional depending on the employed coding scheme. With regard to the latter, these transmissions traditionally use a modified Bose-Chaudhuri-Hocquenghem (BCH) code, to which two state-of-the-art Low-Density Parity-Check (LDPC) codes were later added. As a lightweight technique to detect the presence of the tail sequence, an approach based on decoding failure has traditionally been used, choosing a non-correctable string as the tail sequence. This works very well with the BCH code, for which bounded-distance decoders are employed. When the same approach is employed with LDPC codes, it is necessary to design the tail sequence as a non-correctable string for the case of iterative decoders based on belief propagation. Moreover, the tail sequence might be corrupted by noise, potentially converting it into a correctable pattern. It is therefore important that the tail sequence is chosen to be as much distant as possible, according to some metric, from any legitimate codeword. In this paper we study such problem, and analyze the TC rejection probability both theoretically and through simulations. Such a performance figure, being the rate at which the CLTU is discarded, should clearly be minimized. Our analysis is performed considering many different choices of the system parameters (e.g., length of the CLTU, decoding algorithm, maximum number of decoding iterations).","sentences":["According to the Consultative Committee for Space Data Systems (CCSDS) recommendation for TeleCommand (TC) synchronization and coding, the Communications Link Transmission Unit (CLTU) consists of a start sequence, followed by coded data, and a tail sequence, which might be optional depending on the employed coding scheme.","With regard to the latter, these transmissions traditionally use a modified Bose-Chaudhuri-Hocquenghem (BCH) code, to which two state-of-the-art Low-Density Parity-Check (LDPC) codes were later added.","As a lightweight technique to detect the presence of the tail sequence, an approach based on decoding failure has traditionally been used, choosing a non-correctable string as the tail sequence.","This works very well with the BCH code, for which bounded-distance decoders are employed.","When the same approach is employed with LDPC codes, it is necessary to design the tail sequence as a non-correctable string for the case of iterative decoders based on belief propagation.","Moreover, the tail sequence might be corrupted by noise, potentially converting it into a correctable pattern.","It is therefore important that the tail sequence is chosen to be as much distant as possible, according to some metric, from any legitimate codeword.","In this paper we study such problem, and analyze the TC rejection probability both theoretically and through simulations.","Such a performance figure, being the rate at which the CLTU is discarded, should clearly be minimized.","Our analysis is performed considering many different choices of the system parameters (e.g., length of the CLTU, decoding algorithm, maximum number of decoding iterations)."],"url":"http://arxiv.org/abs/2407.16258v1"}
{"created":"2024-07-23 07:49:35","title":"Self-Reasoning Assistant Learning for non-Abelian Gauge Fields Design","abstract":"Non-Abelian braiding has attracted substantial attention because of its pivotal role in describing the exchange behaviour of anyons, in which the input and outcome of non-Abelian braiding are connected by a unitary matrix. Implementing braiding in a classical system can assist the experimental investigation of non-Abelian physics. However, the design of non-Abelian gauge fields faces numerous challenges stemmed from the intricate interplay of group structures, Lie algebra properties, representation theory, topology, and symmetry breaking. The extreme diversity makes it a powerful tool for the study of condensed matter physics. Whereas the widely used artificial intelligence with data-driven approaches has greatly promoted the development of physics, most works are limited on the data-to-data design. Here we propose a self-reasoning assistant learning framework capable of directly generating non-Abelian gauge fields. This framework utilizes the forward diffusion process to capture and reproduce the complex patterns and details inherent in the target distribution through continuous transformation. Then the reverse diffusion process is used to make the generated data closer to the distribution of the original situation. Thus, it owns strong self-reasoning capabilities, allowing to automatically discover the feature representation and capture more subtle relationships from the dataset. Moreover, the self-reasoning eliminates the need for manual feature engineering and simplifies the process of model building. Our framework offers a disruptive paradigm shift to parse complex physical processes, automatically uncovering patterns from massive datasets.","sentences":["Non-Abelian braiding has attracted substantial attention because of its pivotal role in describing the exchange behaviour of anyons, in which the input and outcome of non-Abelian braiding are connected by a unitary matrix.","Implementing braiding in a classical system can assist the experimental investigation of non-Abelian physics.","However, the design of non-Abelian gauge fields faces numerous challenges stemmed from the intricate interplay of group structures, Lie algebra properties, representation theory, topology, and symmetry breaking.","The extreme diversity makes it a powerful tool for the study of condensed matter physics.","Whereas the widely used artificial intelligence with data-driven approaches has greatly promoted the development of physics, most works are limited on the data-to-data design.","Here we propose a self-reasoning assistant learning framework capable of directly generating non-Abelian gauge fields.","This framework utilizes the forward diffusion process to capture and reproduce the complex patterns and details inherent in the target distribution through continuous transformation.","Then the reverse diffusion process is used to make the generated data closer to the distribution of the original situation.","Thus, it owns strong self-reasoning capabilities, allowing to automatically discover the feature representation and capture more subtle relationships from the dataset.","Moreover, the self-reasoning eliminates the need for manual feature engineering and simplifies the process of model building.","Our framework offers a disruptive paradigm shift to parse complex physical processes, automatically uncovering patterns from massive datasets."],"url":"http://arxiv.org/abs/2407.16255v1"}
{"created":"2024-07-23 07:44:17","title":"Negotiating Control: Neurosymbolic Variable Autonomy","abstract":"Variable autonomy equips a system, such as a robot, with mixed initiatives such that it can adjust its independence level based on the task's complexity and the surrounding environment. Variable autonomy solves two main problems in robotic planning: the first is the problem of humans being unable to keep focus in monitoring and intervening during robotic tasks without appropriate human factor indicators, and the second is achieving mission success in unforeseen and uncertain environments in the face of static reward structures. An open problem in variable autonomy is developing robust methods to dynamically balance autonomy and human intervention in real-time, ensuring optimal performance and safety in unpredictable and evolving environments. We posit that addressing unpredictable and evolving environments through an addition of rule-based symbolic logic has the potential to make autonomy adjustments more contextually reliable and adding feedback to reinforcement learning through data from mixed-initiative control further increases efficacy and safety of autonomous behaviour.","sentences":["Variable autonomy equips a system, such as a robot, with mixed initiatives such that it can adjust its independence level based on the task's complexity and the surrounding environment.","Variable autonomy solves two main problems in robotic planning: the first is the problem of humans being unable to keep focus in monitoring and intervening during robotic tasks without appropriate human factor indicators, and the second is achieving mission success in unforeseen and uncertain environments in the face of static reward structures.","An open problem in variable autonomy is developing robust methods to dynamically balance autonomy and human intervention in real-time, ensuring optimal performance and safety in unpredictable and evolving environments.","We posit that addressing unpredictable and evolving environments through an addition of rule-based symbolic logic has the potential to make autonomy adjustments more contextually reliable and adding feedback to reinforcement learning through data from mixed-initiative control further increases efficacy and safety of autonomous behaviour."],"url":"http://arxiv.org/abs/2407.16254v1"}
{"created":"2024-07-23 07:40:41","title":"LawLuo: A Chinese Law Firm Co-run by LLM Agents","abstract":"Large Language Models (LLMs) demonstrate substantial potential in delivering legal consultation services to users without a legal background, attributed to their superior text comprehension and generation capabilities. Nonetheless, existing Chinese legal LLMs limit interaction to a single model-user dialogue, unlike the collaborative consultations typical of law firms, where multiple staff members contribute to a single consultation. This limitation prevents an authentic consultation experience. Additionally, extant Chinese legal LLMs suffer from critical limitations: (1) insufficient control over the quality of instruction fine-tuning data; (2) increased model hallucination resulting from users' ambiguous queries; and (3) a reduction in the model's ability to follow instructions over multiple dialogue turns. In response to these challenges, we propose a novel legal dialogue framework that leverages the collaborative capabilities of multiple LLM agents, termed LawLuo. This framework encompasses four agents: a receptionist, a lawyer, a secretary, and a boss, each responsible for different functionalities, collaboratively providing a comprehensive legal consultation to users. Additionally, we constructed two high-quality legal dialogue datasets, KINLED and MURLED, and fine-tuned ChatGLM-3-6b using these datasets. We propose a legal query clarification algorithm called ToLC. Experimental results demonstrate that LawLuo outperforms baseline LLMs, including GPT-4, across three dimensions: lawyer-like language style, the usefulness of legal advice, and the accuracy of legal knowledge. Our code and datasets are available at https://github.com/NEFUJing/LawLuo.","sentences":["Large Language Models (LLMs) demonstrate substantial potential in delivering legal consultation services to users without a legal background, attributed to their superior text comprehension and generation capabilities.","Nonetheless, existing Chinese legal LLMs limit interaction to a single model-user dialogue, unlike the collaborative consultations typical of law firms, where multiple staff members contribute to a single consultation.","This limitation prevents an authentic consultation experience.","Additionally, extant Chinese legal LLMs suffer from critical limitations: (1) insufficient control over the quality of instruction fine-tuning data; (2) increased model hallucination resulting from users' ambiguous queries; and (3) a reduction in the model's ability to follow instructions over multiple dialogue turns.","In response to these challenges, we propose a novel legal dialogue framework that leverages the collaborative capabilities of multiple LLM agents, termed LawLuo.","This framework encompasses four agents: a receptionist, a lawyer, a secretary, and a boss, each responsible for different functionalities, collaboratively providing a comprehensive legal consultation to users.","Additionally, we constructed two high-quality legal dialogue datasets, KINLED and MURLED, and fine-tuned ChatGLM-3-6b using these datasets.","We propose a legal query clarification algorithm called ToLC.","Experimental results demonstrate that LawLuo outperforms baseline LLMs, including GPT-4, across three dimensions: lawyer-like language style, the usefulness of legal advice, and the accuracy of legal knowledge.","Our code and datasets are available at https://github.com/NEFUJing/LawLuo."],"url":"http://arxiv.org/abs/2407.16252v1"}
{"created":"2024-07-23 07:40:25","title":"Systematically Searching for Identity-Related Information in the Internet with OSINT Tools","abstract":"The increase of Internet services has not only created several digital identities but also more information available about the persons behind them. The data can be collected and used for attacks on digital identities as well as on identity management systems, which manage digital identities. In order to identify possible attack vectors and take countermeasures at an early stage, it is important for individuals and organizations to systematically search for and analyze the data. This paper proposes a classification of data and open-source intelligence (OSINT) tools related to identities. This classification helps to systematically search for data. In the next step, the data can be analyzed and countermeasures can be taken. Last but not least, an OSINT framework approach applying this classification for searching and analyzing data is presented and discussed.","sentences":["The increase of Internet services has not only created several digital identities but also more information available about the persons behind them.","The data can be collected and used for attacks on digital identities as well as on identity management systems, which manage digital identities.","In order to identify possible attack vectors and take countermeasures at an early stage, it is important for individuals and organizations to systematically search for and analyze the data.","This paper proposes a classification of data and open-source intelligence (OSINT) tools related to identities.","This classification helps to systematically search for data.","In the next step, the data can be analyzed and countermeasures can be taken.","Last but not least, an OSINT framework approach applying this classification for searching and analyzing data is presented and discussed."],"url":"http://arxiv.org/abs/2407.16251v1"}
{"created":"2024-07-23 07:35:33","title":"Evaluation Scheme to Analyze Keystroke Dynamics Methods","abstract":"Password authentication is a weak point for security as passwords are easily stolen and a user may ignore the security by using a simple password. Therefore, services increasingly demand a second factor. While this may enhance security, it comes with a lower level of usability and another factor to be forgotten. A smartphone is an important device in daily life. With the growing number of sensors and features in a smartphone, keystroke dynamics may provide an easy-to-use method. In this paper, we introduce requirements for biometric authentication and keystroke dynamics. This results in an evaluation scheme, which is applied to three selected approaches. Based on the comparison, keystroke dynamics and the evaluation scheme are discussed. The obtained results indicate that keystroke dynamics can be used as another authentication method but can be bypassed by stronger adversaries. For further research, a common data set would improve the comparability.","sentences":["Password authentication is a weak point for security as passwords are easily stolen and a user may ignore the security by using a simple password.","Therefore, services increasingly demand a second factor.","While this may enhance security, it comes with a lower level of usability and another factor to be forgotten.","A smartphone is an important device in daily life.","With the growing number of sensors and features in a smartphone, keystroke dynamics may provide an easy-to-use method.","In this paper, we introduce requirements for biometric authentication and keystroke dynamics.","This results in an evaluation scheme, which is applied to three selected approaches.","Based on the comparison, keystroke dynamics and the evaluation scheme are discussed.","The obtained results indicate that keystroke dynamics can be used as another authentication method but can be bypassed by stronger adversaries.","For further research, a common data set would improve the comparability."],"url":"http://arxiv.org/abs/2407.16247v1"}
{"created":"2024-07-23 07:26:38","title":"Identifiable latent bandits: Combining observational data and exploration for personalized healthcare","abstract":"Bandit algorithms hold great promise for improving personalized decision-making but are notoriously sample-hungry. In most health applications, it is infeasible to fit a new bandit for each patient, and observable variables are often insufficient to determine optimal treatments, ruling out applying contextual bandits learned from multiple patients. Latent bandits offer both rapid exploration and personalization beyond what context variables can reveal but require that a latent variable model can be learned consistently. In this work, we propose bandit algorithms based on nonlinear independent component analysis that can be provably identified from observational data to a degree sufficient to infer the optimal action in a new bandit instance consistently. We verify this strategy in simulated data, showing substantial improvement over learning independent multi-armed bandits for every instance.","sentences":["Bandit algorithms hold great promise for improving personalized decision-making but are notoriously sample-hungry.","In most health applications, it is infeasible to fit a new bandit for each patient, and observable variables are often insufficient to determine optimal treatments, ruling out applying contextual bandits learned from multiple patients.","Latent bandits offer both rapid exploration and personalization beyond what context variables can reveal but require that a latent variable model can be learned consistently.","In this work, we propose bandit algorithms based on nonlinear independent component analysis that can be provably identified from observational data to a degree sufficient to infer the optimal action in a new bandit instance consistently.","We verify this strategy in simulated data, showing substantial improvement over learning independent multi-armed bandits for every instance."],"url":"http://arxiv.org/abs/2407.16239v1"}
{"created":"2024-07-23 07:26:34","title":"How to Design a Blue Team Scenario for Beginners on the Example of Brute-Force Attacks on Authentications","abstract":"Cyber attacks are ubiquitous and a constantly growing threat in the age of digitization. In order to protect important data, developers and system administrators must be trained and made aware of possible threats. Practical training can be used for students alike to introduce them to the topic. A constant threat to websites that require user authentication is so-called brute-force attacks, which attempt to crack a password by systematically trying every possible combination. As this is a typical threat, but comparably easy to detect, it is ideal for beginners. Therefore, three open-source blue team scenarios are designed and systematically described. They are contiguous to maximize the learning effect.","sentences":["Cyber attacks are ubiquitous and a constantly growing threat in the age of digitization.","In order to protect important data, developers and system administrators must be trained and made aware of possible threats.","Practical training can be used for students alike to introduce them to the topic.","A constant threat to websites that require user authentication is so-called brute-force attacks, which attempt to crack a password by systematically trying every possible combination.","As this is a typical threat, but comparably easy to detect, it is ideal for beginners.","Therefore, three open-source blue team scenarios are designed and systematically described.","They are contiguous to maximize the learning effect."],"url":"http://arxiv.org/abs/2407.16238v1"}
{"created":"2024-07-23 07:15:37","title":"Advancements in Traffic Processing Using Programmable Hardware Flow Offload","abstract":"The exponential growth of data traffic and the increasing complexity of networked applications demand effective solutions capable of passively inspecting and analysing the network traffic for monitoring and security purposes. Implementing network probes in software using general-purpose operating systems has been made possible by advances in packet-capture technologies, such as kernel-bypass frameworks, and by multi-queue adapters designed to distribute the network workload in multi-core processors. Modern SmartNICs, in addition, have introduced stateful mechanisms to associate actions to network flows such as forwarding packets or updating traffic statistics for an individual flow. In this paper, we describe our experience in exploiting those functionalities in a modern network probe and we perform a detailed study of the performance characteristics under different scenarios. Compared to pure CPU-based solutions, SmartNICs with flow-offload technologies provide substantial benefits when implementing forwarding applications. However, the main limitation of having to keep large flow tables in the host memory remains largely unsolved for realistic monitoring and security applications.","sentences":["The exponential growth of data traffic and the increasing complexity of networked applications demand effective solutions capable of passively inspecting and analysing the network traffic for monitoring and security purposes.","Implementing network probes in software using general-purpose operating systems has been made possible by advances in packet-capture technologies, such as kernel-bypass frameworks, and by multi-queue adapters designed to distribute the network workload in multi-core processors.","Modern SmartNICs, in addition, have introduced stateful mechanisms to associate actions to network flows such as forwarding packets or updating traffic statistics for an individual flow.","In this paper, we describe our experience in exploiting those functionalities in a modern network probe and we perform a detailed study of the performance characteristics under different scenarios.","Compared to pure CPU-based solutions, SmartNICs with flow-offload technologies provide substantial benefits when implementing forwarding applications.","However, the main limitation of having to keep large flow tables in the host memory remains largely unsolved for realistic monitoring and security applications."],"url":"http://arxiv.org/abs/2407.16231v1"}
{"created":"2024-07-23 07:02:01","title":"Probabilistic Parameter Estimators and Calibration Metrics for Pose Estimation from Image Features","abstract":"This paper addresses the challenge of probabilistic parameter estimation given measurement uncertainty in real-time. We provide a general formulation and apply this to pose estimation for an autonomous visual landing system. We present three probabilistic parameter estimators: a least-squares sampling approach, a linear approximation method, and a probabilistic programming estimator. To evaluate these estimators, we introduce novel closed-form expressions for measuring calibration and sharpness specifically for multivariate normal distributions. Our experimental study compares the three estimators under various noise conditions. We demonstrate that the linear approximation estimator can produce sharp and well-calibrated pose predictions significantly faster than the other methods but may yield overconfident predictions in certain scenarios. Additionally, we demonstrate that these estimators can be integrated with a Kalman filter for continuous pose estimation during a runway approach where we observe a 50\\% improvement in sharpness while maintaining marginal calibration. This work contributes to the integration of data-driven computer vision models into complex safety-critical aircraft systems and provides a foundation for developing rigorous certification guidelines for such systems.","sentences":["This paper addresses the challenge of probabilistic parameter estimation given measurement uncertainty in real-time.","We provide a general formulation and apply this to pose estimation for an autonomous visual landing system.","We present three probabilistic parameter estimators: a least-squares sampling approach, a linear approximation method, and a probabilistic programming estimator.","To evaluate these estimators, we introduce novel closed-form expressions for measuring calibration and sharpness specifically for multivariate normal distributions.","Our experimental study compares the three estimators under various noise conditions.","We demonstrate that the linear approximation estimator can produce sharp and well-calibrated pose predictions significantly faster than the other methods but may yield overconfident predictions in certain scenarios.","Additionally, we demonstrate that these estimators can be integrated with a Kalman filter for continuous pose estimation during a runway approach where we observe a 50\\% improvement in sharpness while maintaining marginal calibration.","This work contributes to the integration of data-driven computer vision models into complex safety-critical aircraft systems and provides a foundation for developing rigorous certification guidelines for such systems."],"url":"http://arxiv.org/abs/2407.16223v1"}
{"created":"2024-07-23 06:45:52","title":"A Comprehensive Survey of LLM Alignment Techniques: RLHF, RLAIF, PPO, DPO and More","abstract":"With advancements in self-supervised learning, the availability of trillions tokens in a pre-training corpus, instruction fine-tuning, and the development of large Transformers with billions of parameters, large language models (LLMs) are now capable of generating factual and coherent responses to human queries. However, the mixed quality of training data can lead to the generation of undesired responses, presenting a significant challenge. Over the past two years, various methods have been proposed from different perspectives to enhance LLMs, particularly in aligning them with human expectation. Despite these efforts, there has not been a comprehensive survey paper that categorizes and details these approaches. In this work, we aim to address this gap by categorizing these papers into distinct topics and providing detailed explanations of each alignment method, thereby helping readers gain a thorough understanding of the current state of the field.","sentences":["With advancements in self-supervised learning, the availability of trillions tokens in a pre-training corpus, instruction fine-tuning, and the development of large Transformers with billions of parameters, large language models (LLMs) are now capable of generating factual and coherent responses to human queries.","However, the mixed quality of training data can lead to the generation of undesired responses, presenting a significant challenge.","Over the past two years, various methods have been proposed from different perspectives to enhance LLMs, particularly in aligning them with human expectation.","Despite these efforts, there has not been a comprehensive survey paper that categorizes and details these approaches.","In this work, we aim to address this gap by categorizing these papers into distinct topics and providing detailed explanations of each alignment method, thereby helping readers gain a thorough understanding of the current state of the field."],"url":"http://arxiv.org/abs/2407.16216v1"}
{"created":"2024-07-23 06:18:10","title":"Cluster Haptic Texture Database: Haptic Texture Database with Variety in Velocity and Direction of Sliding Contacts","abstract":"Human perception integrates multisensory information, with tactile perception playing a key role in object and surface recognition. While human-machine interfaces with haptic modalities offer enhanced system performance, existing datasets focus primarily on visual data, overlooking comprehensive haptic information. Previous haptic texture databases have recorded sound and acceleration signals, but often ignore the nuanced differences between probe-texture and finger-texture interactions. Recognizing this shortcoming, we present the Cluster Haptic Texture Database, a multimodal dataset that records visual, auditory, and haptic signals from an artificial urethane rubber fingertip interacting with different textured surfaces. This database, designed to mimic the properties of the human finger, includes five velocity levels and eight directional variations, providing a comprehensive study of tactile interactions. Our evaluations reveal the effectiveness of classifiers trained on this dataset in identifying surfaces, and the subtleties of estimating velocity and direction for each surface.","sentences":["Human perception integrates multisensory information, with tactile perception playing a key role in object and surface recognition.","While human-machine interfaces with haptic modalities offer enhanced system performance, existing datasets focus primarily on visual data, overlooking comprehensive haptic information.","Previous haptic texture databases have recorded sound and acceleration signals, but often ignore the nuanced differences between probe-texture and finger-texture interactions.","Recognizing this shortcoming, we present the Cluster Haptic Texture Database, a multimodal dataset that records visual, auditory, and haptic signals from an artificial urethane rubber fingertip interacting with different textured surfaces.","This database, designed to mimic the properties of the human finger, includes five velocity levels and eight directional variations, providing a comprehensive study of tactile interactions.","Our evaluations reveal the effectiveness of classifiers trained on this dataset in identifying surfaces, and the subtleties of estimating velocity and direction for each surface."],"url":"http://arxiv.org/abs/2407.16206v1"}
{"created":"2024-07-23 06:02:30","title":"INF-LLaVA: Dual-perspective Perception for High-Resolution Multimodal Large Language Model","abstract":"With advancements in data availability and computing resources, Multimodal Large Language Models (MLLMs) have showcased capabilities across various fields. However, the quadratic complexity of the vision encoder in MLLMs constrains the resolution of input images. Most current approaches mitigate this issue by cropping high-resolution images into smaller sub-images, which are then processed independently by the vision encoder. Despite capturing sufficient local details, these sub-images lack global context and fail to interact with one another. To address this limitation, we propose a novel MLLM, INF-LLaVA, designed for effective high-resolution image perception. INF-LLaVA incorporates two innovative components. First, we introduce a Dual-perspective Cropping Module (DCM), which ensures that each sub-image contains continuous details from a local perspective and comprehensive information from a global perspective. Second, we introduce Dual-perspective Enhancement Module (DEM) to enable the mutual enhancement of global and local features, allowing INF-LLaVA to effectively process high-resolution images by simultaneously capturing detailed local information and comprehensive global context. Extensive ablation studies validate the effectiveness of these components, and experiments on a diverse set of benchmarks demonstrate that INF-LLaVA outperforms existing MLLMs. Code and pretrained model are available at https://github.com/WeihuangLin/INF-LLaVA.","sentences":["With advancements in data availability and computing resources, Multimodal Large Language Models (MLLMs) have showcased capabilities across various fields.","However, the quadratic complexity of the vision encoder in MLLMs constrains the resolution of input images.","Most current approaches mitigate this issue by cropping high-resolution images into smaller sub-images, which are then processed independently by the vision encoder.","Despite capturing sufficient local details, these sub-images lack global context and fail to interact with one another.","To address this limitation, we propose a novel MLLM, INF-LLaVA, designed for effective high-resolution image perception.","INF-LLaVA incorporates two innovative components.","First, we introduce a Dual-perspective Cropping Module (DCM), which ensures that each sub-image contains continuous details from a local perspective and comprehensive information from a global perspective.","Second, we introduce Dual-perspective Enhancement Module (DEM) to enable the mutual enhancement of global and local features, allowing INF-LLaVA to effectively process high-resolution images by simultaneously capturing detailed local information and comprehensive global context.","Extensive ablation studies validate the effectiveness of these components, and experiments on a diverse set of benchmarks demonstrate that INF-LLaVA outperforms existing MLLMs.","Code and pretrained model are available at https://github.com/WeihuangLin/INF-LLaVA."],"url":"http://arxiv.org/abs/2407.16198v1"}
{"created":"2024-07-23 04:41:36","title":"Pixel Embedding: Fully Quantized Convolutional Neural Network with Differentiable Lookup Table","abstract":"By quantizing network weights and activations to low bitwidth, we can obtain hardware-friendly and energy-efficient networks. However, existing quantization techniques utilizing the straight-through estimator and piecewise constant functions face the issue of how to represent originally high-bit input data with low-bit values. To fully quantize deep neural networks, we propose pixel embedding, which replaces each float-valued input pixel with a vector of quantized values by using a lookup table. The lookup table or low-bit representation of pixels is differentiable and trainable by backpropagation. Such replacement of inputs with vectors is similar to word embedding in the natural language processing field. Experiments on ImageNet and CIFAR-100 show that pixel embedding reduces the top-5 error gap caused by quantizing the floating points at the first layer to only 1% for the ImageNet dataset, and the top-1 error gap caused by quantizing first and last layers to slightly over 1% for the CIFAR-100 dataset. The usefulness of pixel embedding is further demonstrated by inference time measurements, which demonstrate over 1.7 times speedup compared to floating point precision first layer.","sentences":["By quantizing network weights and activations to low bitwidth, we can obtain hardware-friendly and energy-efficient networks.","However, existing quantization techniques utilizing the straight-through estimator and piecewise constant functions face the issue of how to represent originally high-bit input data with low-bit values.","To fully quantize deep neural networks, we propose pixel embedding, which replaces each float-valued input pixel with a vector of quantized values by using a lookup table.","The lookup table or low-bit representation of pixels is differentiable and trainable by backpropagation.","Such replacement of inputs with vectors is similar to word embedding in the natural language processing field.","Experiments on ImageNet and CIFAR-100 show that pixel embedding reduces the top-5 error gap caused by quantizing the floating points at the first layer to only 1% for the ImageNet dataset, and the top-1 error gap caused by quantizing first and last layers to slightly over 1% for the CIFAR-100 dataset.","The usefulness of pixel embedding is further demonstrated by inference time measurements, which demonstrate over 1.7 times speedup compared to floating point precision first layer."],"url":"http://arxiv.org/abs/2407.16174v1"}
{"created":"2024-07-23 04:35:56","title":"Learning Trimodal Relation for AVQA with Missing Modality","abstract":"Recent Audio-Visual Question Answering (AVQA) methods rely on complete visual and audio input to answer questions accurately. However, in real-world scenarios, issues such as device malfunctions and data transmission errors frequently result in missing audio or visual modality. In such cases, existing AVQA methods suffer significant performance degradation. In this paper, we propose a framework that ensures robust AVQA performance even when a modality is missing. First, we propose a Relation-aware Missing Modal (RMM) generator with Relation-aware Missing Modal Recalling (RMMR) loss to enhance the ability of the generator to recall missing modal information by understanding the relationships and context among the available modalities. Second, we design an Audio-Visual Relation-aware (AVR) diffusion model with Audio-Visual Enhancing (AVE) loss to further enhance audio-visual features by leveraging the relationships and shared cues between the audio-visual modalities. As a result, our method can provide accurate answers by effectively utilizing available information even when input modalities are missing. We believe our method holds potential applications not only in AVQA research but also in various multi-modal scenarios.","sentences":["Recent Audio-Visual Question Answering (AVQA) methods rely on complete visual and audio input to answer questions accurately.","However, in real-world scenarios, issues such as device malfunctions and data transmission errors frequently result in missing audio or visual modality.","In such cases, existing AVQA methods suffer significant performance degradation.","In this paper, we propose a framework that ensures robust AVQA performance even when a modality is missing.","First, we propose a Relation-aware Missing Modal (RMM) generator with Relation-aware Missing Modal Recalling (RMMR) loss to enhance the ability of the generator to recall missing modal information by understanding the relationships and context among the available modalities.","Second, we design an Audio-Visual Relation-aware (AVR) diffusion model with Audio-Visual Enhancing (AVE) loss to further enhance audio-visual features by leveraging the relationships and shared cues between the audio-visual modalities.","As a result, our method can provide accurate answers by effectively utilizing available information even when input modalities are missing.","We believe our method holds potential applications not only in AVQA research but also in various multi-modal scenarios."],"url":"http://arxiv.org/abs/2407.16171v1"}
{"created":"2024-07-23 04:25:35","title":"Securing The Future Of Healthcare: Building A Resilient Defense System For Patient Data Protection","abstract":"The increasing importance of data in the healthcare sector has led to a rise in cybercrime targeting patient information. Data breaches pose significant financial and reputational risks to many healthcare organizations including clinics and hospitals. This study aims to propose the ideal approach to developing a defense system that ensures that patient data is protected from the insidious acts of healthcare data threat actors. Using a gradientboosting classifier machine learning model, the study predicts the severity of healthcare data breaches. Secondary data was collected from the U.S. Department of Health and Human Services Portal with key indicators. Also, the study gathers key cyber-security data from Kaggle, which was utilized for the study. The findings revealed that hacking and IT incidents are the most common type of breaches in the healthcare industry, with network servers being targeted in most cases. The model evaluation showed that the gradient boosting algorithm performs well. Therefore, the study recommends that organizations implement comprehensive security protocols, particularly focusing on robust network security to protect servers","sentences":["The increasing importance of data in the healthcare sector has led to a rise in cybercrime targeting patient information.","Data breaches pose significant financial and reputational risks to many healthcare organizations including clinics and hospitals.","This study aims to propose the ideal approach to developing a defense system that ensures that patient data is protected from the insidious acts of healthcare data threat actors.","Using a gradientboosting classifier machine learning model, the study predicts the severity of healthcare data breaches.","Secondary data was collected from the U.S. Department of Health and Human Services Portal with key indicators.","Also, the study gathers key cyber-security data from Kaggle, which was utilized for the study.","The findings revealed that hacking and IT incidents are the most common type of breaches in the healthcare industry, with network servers being targeted in most cases.","The model evaluation showed that the gradient boosting algorithm performs well.","Therefore, the study recommends that organizations implement comprehensive security protocols, particularly focusing on robust network security to protect servers"],"url":"http://arxiv.org/abs/2407.16170v1"}
{"created":"2024-07-23 04:20:14","title":"Robust Privacy Amidst Innovation with Large Language Models Through a Critical Assessment of the Risks","abstract":"This study examines integrating EHRs and NLP with large language models (LLMs) to improve healthcare data management and patient care. It focuses on using advanced models to create secure, HIPAA-compliant synthetic patient notes for biomedical research. The study used de-identified and re-identified MIMIC III datasets with GPT-3.5, GPT-4, and Mistral 7B to generate synthetic notes. Text generation employed templates and keyword extraction for contextually relevant notes, with one-shot generation for comparison. Privacy assessment checked PHI occurrence, while text utility was tested using an ICD-9 coding task. Text quality was evaluated with ROUGE and cosine similarity metrics to measure semantic similarity with source notes. Analysis of PHI occurrence and text utility via the ICD-9 coding task showed that the keyword-based method had low risk and good performance. One-shot generation showed the highest PHI exposure and PHI co-occurrence, especially in geographic location and date categories. The Normalized One-shot method achieved the highest classification accuracy. Privacy analysis revealed a critical balance between data utility and privacy protection, influencing future data use and sharing. Re-identified data consistently outperformed de-identified data. This study demonstrates the effectiveness of keyword-based methods in generating privacy-protecting synthetic clinical notes that retain data usability, potentially transforming clinical data-sharing practices. The superior performance of re-identified over de-identified data suggests a shift towards methods that enhance utility and privacy by using dummy PHIs to perplex privacy attacks.","sentences":["This study examines integrating EHRs and NLP with large language models (LLMs) to improve healthcare data management and patient care.","It focuses on using advanced models to create secure, HIPAA-compliant synthetic patient notes for biomedical research.","The study used de-identified and re-identified MIMIC III datasets with GPT-3.5, GPT-4, and Mistral 7B to generate synthetic notes.","Text generation employed templates and keyword extraction for contextually relevant notes, with one-shot generation for comparison.","Privacy assessment checked PHI occurrence, while text utility was tested using an ICD-9 coding task.","Text quality was evaluated with ROUGE and cosine similarity metrics to measure semantic similarity with source notes.","Analysis of PHI occurrence and text utility via the ICD-9 coding task showed that the keyword-based method had low risk and good performance.","One-shot generation showed the highest PHI exposure and PHI co-occurrence, especially in geographic location and date categories.","The Normalized One-shot method achieved the highest classification accuracy.","Privacy analysis revealed a critical balance between data utility and privacy protection, influencing future data use and sharing.","Re-identified data consistently outperformed de-identified data.","This study demonstrates the effectiveness of keyword-based methods in generating privacy-protecting synthetic clinical notes that retain data usability, potentially transforming clinical data-sharing practices.","The superior performance of re-identified over de-identified data suggests a shift towards methods that enhance utility and privacy by using dummy PHIs to perplex privacy attacks."],"url":"http://arxiv.org/abs/2407.16166v1"}
{"created":"2024-07-23 04:13:52","title":"Representation Magnitude has a Liability to Privacy Vulnerability","abstract":"The privacy-preserving approaches to machine learning (ML) models have made substantial progress in recent years. However, it is still opaque in which circumstances and conditions the model becomes privacy-vulnerable, leading to a challenge for ML models to maintain both performance and privacy. In this paper, we first explore the disparity between member and non-member data in the representation of models under common training frameworks. We identify how the representation magnitude disparity correlates with privacy vulnerability and address how this correlation impacts privacy vulnerability. Based on the observations, we propose Saturn Ring Classifier Module (SRCM), a plug-in model-level solution to mitigate membership privacy leakage. Through a confined yet effective representation space, our approach ameliorates models' privacy vulnerability while maintaining generalizability. The code of this work can be found here: \\url{https://github.com/JEKimLab/AIES2024_SRCM}","sentences":["The privacy-preserving approaches to machine learning (ML) models have made substantial progress in recent years.","However, it is still opaque in which circumstances and conditions the model becomes privacy-vulnerable, leading to a challenge for ML models to maintain both performance and privacy.","In this paper, we first explore the disparity between member and non-member data in the representation of models under common training frameworks.","We identify how the representation magnitude disparity correlates with privacy vulnerability and address how this correlation impacts privacy vulnerability.","Based on the observations, we propose Saturn Ring Classifier Module (SRCM), a plug-in model-level solution to mitigate membership privacy leakage.","Through a confined yet effective representation space, our approach ameliorates models' privacy vulnerability while maintaining generalizability.","The code of this work can be found here: \\url{https://github.com/JEKimLab/AIES2024_SRCM}"],"url":"http://arxiv.org/abs/2407.16164v1"}
{"created":"2024-07-23 04:06:23","title":"Plant robots","abstract":"Plants display physical displacements during their growth due to photosynthesis, which converts light into chemical energy. This can be interpreted as plants acting as actuators with a built-in power source. This paper presents a method to create plant robots that move and perform tasks by harnessing the actuation output of plants: displacement and force generated from the growing process. As the target plant, radish sprouts are employed, and their displacement and force are characterized, followed by the calculation of power and energy densities. Based on the characterization, two different plant robots are designed and fabricated: a rotational robot and a gripper. The former demonstrates ground locomotion, achieving a travel distance of 14.6 mm with an average speed of 0.8 mm/h. The latter demonstrates the picking and placing of an object with a 0.1-g mass by the light-controlled open-close motion of plant fingers. A good agreement between the experimental and model values is observed in the specific data of the mobile robot, suggesting that obtaining the actuation characteristics of plants can enable the design and prediction of behavior in plant robots. These results pave the way for the realization of novel types of environmentally friendly and sustainable robots.","sentences":["Plants display physical displacements during their growth due to photosynthesis, which converts light into chemical energy.","This can be interpreted as plants acting as actuators with a built-in power source.","This paper presents a method to create plant robots that move and perform tasks by harnessing the actuation output of plants: displacement and force generated from the growing process.","As the target plant, radish sprouts are employed, and their displacement and force are characterized, followed by the calculation of power and energy densities.","Based on the characterization, two different plant robots are designed and fabricated: a rotational robot and a gripper.","The former demonstrates ground locomotion, achieving a travel distance of 14.6 mm with an average speed of 0.8 mm/h. The latter demonstrates the picking and placing of an object with a 0.1-g mass by the light-controlled open-close motion of plant fingers.","A good agreement between the experimental and model values is observed in the specific data of the mobile robot, suggesting that obtaining the actuation characteristics of plants can enable the design and prediction of behavior in plant robots.","These results pave the way for the realization of novel types of environmentally friendly and sustainable robots."],"url":"http://arxiv.org/abs/2407.16162v1"}
{"created":"2024-07-23 04:05:29","title":"TransFeat-TPP: An Interpretable Deep Covariate Temporal Point Processes","abstract":"The classical temporal point process (TPP) constructs an intensity function by taking the occurrence times into account. Nevertheless, occurrence time may not be the only relevant factor, other contextual data, termed covariates, may also impact the event evolution. Incorporating such covariates into the model is beneficial, while distinguishing their relevance to the event dynamics is of great practical significance. In this work, we propose a Transformer-based covariate temporal point process (TransFeat-TPP) model to improve the interpretability of deep covariate-TPPs while maintaining powerful expressiveness. TransFeat-TPP can effectively model complex relationships between events and covariates, and provide enhanced interpretability by discerning the importance of various covariates. Experimental results on synthetic and real datasets demonstrate improved prediction accuracy and consistently interpretable feature importance when compared to existing deep covariate-TPPs.","sentences":["The classical temporal point process (TPP) constructs an intensity function by taking the occurrence times into account.","Nevertheless, occurrence time may not be the only relevant factor, other contextual data, termed covariates, may also impact the event evolution.","Incorporating such covariates into the model is beneficial, while distinguishing their relevance to the event dynamics is of great practical significance.","In this work, we propose a Transformer-based covariate temporal point process (TransFeat-TPP) model to improve the interpretability of deep covariate-TPPs while maintaining powerful expressiveness.","TransFeat-TPP can effectively model complex relationships between events and covariates, and provide enhanced interpretability by discerning the importance of various covariates.","Experimental results on synthetic and real datasets demonstrate improved prediction accuracy and consistently interpretable feature importance when compared to existing deep covariate-TPPs."],"url":"http://arxiv.org/abs/2407.16161v1"}
{"created":"2024-07-23 03:26:07","title":"Predicting Stock Prices with FinBERT-LSTM: Integrating News Sentiment Analysis","abstract":"The stock market's ascent typically mirrors the flourishing state of the economy, whereas its decline is often an indicator of an economic downturn. Therefore, for a long time, significant correlation elements for predicting trends in financial stock markets have been widely discussed, and people are becoming increasingly interested in the task of financial text mining. The inherent instability of stock prices makes them acutely responsive to fluctuations within the financial markets. In this article, we use deep learning networks, based on the history of stock prices and articles of financial, business, technical news that introduce market information to predict stock prices. We illustrate the enhancement of predictive precision by integrating weighted news categories into the forecasting model. We developed a pre-trained NLP model known as FinBERT, designed to discern the sentiments within financial texts. Subsequently, we advanced this model by incorporating the sophisticated Long Short Term Memory (LSTM) architecture, thus constructing the innovative FinBERT-LSTM model. This model utilizes news categories related to the stock market structure hierarchy, namely market, industry, and stock related news categories, combined with the stock market's stock price situation in the previous week for prediction. We selected NASDAQ-100 index stock data and trained the model on Benzinga news articles, and utilized Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Accuracy as the key metrics for the assessment and comparative analysis of the model's performance. The results indicate that FinBERT-LSTM performs the best, followed by LSTM, and DNN model ranks third in terms of effectiveness.","sentences":["The stock market's ascent typically mirrors the flourishing state of the economy, whereas its decline is often an indicator of an economic downturn.","Therefore, for a long time, significant correlation elements for predicting trends in financial stock markets have been widely discussed, and people are becoming increasingly interested in the task of financial text mining.","The inherent instability of stock prices makes them acutely responsive to fluctuations within the financial markets.","In this article, we use deep learning networks, based on the history of stock prices and articles of financial, business, technical news that introduce market information to predict stock prices.","We illustrate the enhancement of predictive precision by integrating weighted news categories into the forecasting model.","We developed a pre-trained NLP model known as FinBERT, designed to discern the sentiments within financial texts.","Subsequently, we advanced this model by incorporating the sophisticated Long Short Term Memory (LSTM) architecture, thus constructing the innovative FinBERT-LSTM model.","This model utilizes news categories related to the stock market structure hierarchy, namely market, industry, and stock related news categories, combined with the stock market's stock price situation in the previous week for prediction.","We selected NASDAQ-100 index stock data and trained the model on Benzinga news articles, and utilized Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Accuracy as the key metrics for the assessment and comparative analysis of the model's performance.","The results indicate that FinBERT-LSTM performs the best, followed by LSTM, and DNN model ranks third in terms of effectiveness."],"url":"http://arxiv.org/abs/2407.16150v1"}
{"created":"2024-07-23 03:09:42","title":"Improved Few-Shot Image Classification Through Multiple-Choice Questions","abstract":"Through a simple multiple choice language prompt a VQA model can operate as a zero-shot image classifier, producing a classification label. Compared to typical image encoders, VQA models offer an advantage: VQA-produced image embeddings can be infused with the most relevant visual information through tailored language prompts. Nevertheless, for most tasks, zero-shot VQA performance is lacking, either because of unfamiliar category names, or dissimilar pre-training data and test data distributions. We propose a simple method to boost VQA performance for image classification using only a handful of labeled examples and a multiple-choice question. This few-shot method is training-free and maintains the dynamic and flexible advantages of the VQA model. Rather than relying on the final language output, our approach uses multiple-choice questions to extract prompt-specific latent representations, which are enriched with relevant visual information. These representations are combined to create a final overall image embedding, which is decoded via reference to latent class prototypes constructed from the few labeled examples. We demonstrate this method outperforms both pure visual encoders and zero-shot VQA baselines to achieve impressive performance on common few-shot tasks including MiniImageNet, Caltech-UCSD Birds, and CIFAR-100. Finally, we show our approach does particularly well in settings with numerous diverse visual attributes such as the fabric, article-style, texture, and view of different articles of clothing, where other few-shot approaches struggle, as we can tailor our image representations only on the semantic features of interest.","sentences":["Through a simple multiple choice language prompt a VQA model can operate as a zero-shot image classifier, producing a classification label.","Compared to typical image encoders, VQA models offer an advantage: VQA-produced image embeddings can be infused with the most relevant visual information through tailored language prompts.","Nevertheless, for most tasks, zero-shot VQA performance is lacking, either because of unfamiliar category names, or dissimilar pre-training data and test data distributions.","We propose a simple method to boost VQA performance for image classification using only a handful of labeled examples and a multiple-choice question.","This few-shot method is training-free and maintains the dynamic and flexible advantages of the VQA model.","Rather than relying on the final language output, our approach uses multiple-choice questions to extract prompt-specific latent representations, which are enriched with relevant visual information.","These representations are combined to create a final overall image embedding, which is decoded via reference to latent class prototypes constructed from the few labeled examples.","We demonstrate this method outperforms both pure visual encoders and zero-shot VQA baselines to achieve impressive performance on common few-shot tasks including MiniImageNet, Caltech-UCSD Birds, and CIFAR-100.","Finally, we show our approach does particularly well in settings with numerous diverse visual attributes such as the fabric, article-style, texture, and view of different articles of clothing, where other few-shot approaches struggle, as we can tailor our image representations only on the semantic features of interest."],"url":"http://arxiv.org/abs/2407.16145v1"}
{"created":"2024-07-23 02:52:52","title":"Tackling Feature-Classifier Mismatch in Federated Learning via Prompt-Driven Feature Transformation","abstract":"In traditional Federated Learning approaches like FedAvg, the global model underperforms when faced with data heterogeneity. Personalized Federated Learning (PFL) enables clients to train personalized models to fit their local data distribution better. However, we surprisingly find that the feature extractor in FedAvg is superior to those in most PFL methods. More interestingly, by applying a linear transformation on local features extracted by the feature extractor to align with the classifier, FedAvg can surpass the majority of PFL methods. This suggests that the primary cause of FedAvg's inadequate performance stems from the mismatch between the locally extracted features and the classifier. While current PFL methods mitigate this issue to some extent, their designs compromise the quality of the feature extractor, thus limiting the full potential of PFL. In this paper, we propose a new PFL framework called FedPFT to address the mismatch problem while enhancing the quality of the feature extractor. FedPFT integrates a feature transformation module, driven by personalized prompts, between the global feature extractor and classifier. In each round, clients first train prompts to transform local features to match the global classifier, followed by training model parameters. This approach can also align the training objectives of clients, reducing the impact of data heterogeneity on model collaboration. Moreover, FedPFT's feature transformation module is highly scalable, allowing for the use of different prompts to tailor local features to various tasks. Leveraging this, we introduce a collaborative contrastive learning task to further refine feature extractor quality. Our experiments demonstrate that FedPFT outperforms state-of-the-art methods by up to 7.08%.","sentences":["In traditional Federated Learning approaches like FedAvg, the global model underperforms when faced with data heterogeneity.","Personalized Federated Learning (PFL) enables clients to train personalized models to fit their local data distribution better.","However, we surprisingly find that the feature extractor in FedAvg is superior to those in most PFL methods.","More interestingly, by applying a linear transformation on local features extracted by the feature extractor to align with the classifier, FedAvg can surpass the majority of PFL methods.","This suggests that the primary cause of FedAvg's inadequate performance stems from the mismatch between the locally extracted features and the classifier.","While current PFL methods mitigate this issue to some extent, their designs compromise the quality of the feature extractor, thus limiting the full potential of PFL.","In this paper, we propose a new PFL framework called FedPFT to address the mismatch problem while enhancing the quality of the feature extractor.","FedPFT integrates a feature transformation module, driven by personalized prompts, between the global feature extractor and classifier.","In each round, clients first train prompts to transform local features to match the global classifier, followed by training model parameters.","This approach can also align the training objectives of clients, reducing the impact of data heterogeneity on model collaboration.","Moreover, FedPFT's feature transformation module is highly scalable, allowing for the use of different prompts to tailor local features to various tasks.","Leveraging this, we introduce a collaborative contrastive learning task to further refine feature extractor quality.","Our experiments demonstrate that FedPFT outperforms state-of-the-art methods by up to 7.08%."],"url":"http://arxiv.org/abs/2407.16139v1"}
{"created":"2024-07-23 02:50:27","title":"3D-UGCN: A Unified Graph Convolutional Network for Robust 3D Human Pose Estimation from Monocular RGB Images","abstract":"Human pose estimation remains a multifaceted challenge in computer vision, pivotal across diverse domains such as behavior recognition, human-computer interaction, and pedestrian tracking. This paper proposes an improved method based on the spatial-temporal graph convolution net-work (UGCN) to address the issue of missing human posture skeleton sequences in single-view videos. We present the improved UGCN, which allows the network to process 3D human pose data and improves the 3D human pose skeleton sequence, thereby resolving the occlusion issue.","sentences":["Human pose estimation remains a multifaceted challenge in computer vision, pivotal across diverse domains such as behavior recognition, human-computer interaction, and pedestrian tracking.","This paper proposes an improved method based on the spatial-temporal graph convolution net-work (UGCN) to address the issue of missing human posture skeleton sequences in single-view videos.","We present the improved UGCN, which allows the network to process 3D human pose data and improves the 3D human pose skeleton sequence, thereby resolving the occlusion issue."],"url":"http://arxiv.org/abs/2407.16137v1"}
{"created":"2024-07-23 02:42:43","title":"Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory for Gaussian Process Data","abstract":"Diffusion Transformer, the backbone of Sora for video generation, successfully scales the capacity of diffusion models, pioneering new avenues for high-fidelity sequential data generation. Unlike static data such as images, sequential data consists of consecutive data frames indexed by time, exhibiting rich spatial and temporal dependencies. These dependencies represent the underlying dynamic model and are critical to validate the generated data. In this paper, we make the first theoretical step towards bridging diffusion transformers for capturing spatial-temporal dependencies. Specifically, we establish score approximation and distribution estimation guarantees of diffusion transformers for learning Gaussian process data with covariance functions of various decay patterns. We highlight how the spatial-temporal dependencies are captured and affect learning efficiency. Our study proposes a novel transformer approximation theory, where the transformer acts to unroll an algorithm. We support our theoretical results by numerical experiments, providing strong evidence that spatial-temporal dependencies are captured within attention layers, aligning with our approximation theory.","sentences":["Diffusion Transformer, the backbone of Sora for video generation, successfully scales the capacity of diffusion models, pioneering new avenues for high-fidelity sequential data generation.","Unlike static data such as images, sequential data consists of consecutive data frames indexed by time, exhibiting rich spatial and temporal dependencies.","These dependencies represent the underlying dynamic model and are critical to validate the generated data.","In this paper, we make the first theoretical step towards bridging diffusion transformers for capturing spatial-temporal dependencies.","Specifically, we establish score approximation and distribution estimation guarantees of diffusion transformers for learning Gaussian process data with covariance functions of various decay patterns.","We highlight how the spatial-temporal dependencies are captured and affect learning efficiency.","Our study proposes a novel transformer approximation theory, where the transformer acts to unroll an algorithm.","We support our theoretical results by numerical experiments, providing strong evidence that spatial-temporal dependencies are captured within attention layers, aligning with our approximation theory."],"url":"http://arxiv.org/abs/2407.16134v1"}
{"created":"2024-07-23 02:32:52","title":"Users Feel Guilty: Measurement of Illegal Software Installation Guide Videos on YouTube for Malware Distribution","abstract":"This study introduces and examines a sophisticated malware distribution technique that exploits popular video sharing platforms. In this attack, threat actors distribute malware through deceptive content that promises free versions of premium software and game cheats. Throughout this paper, we call this attack MalTube. MalTube is particularly insidious because it exploits the guilt feelings of users for engaging in potentially illegal activity, making them less likely to report the infection or ask for a help. To investigate this emerging threat, we developed video platform exploitation reconnaissance VIPER, a novel monitoring system designed to detect, monitor, and analyze MalTube activity at scale. Over a four-month data collection period, VIPER processed and analyzed 14,363 videos, 8,671 associated channels, and 1,269 unique fully qualified domain names associated with malware downloads. Our findings reveal that MalTube attackers primarily target young gamers, using the lure of free software and game cheats as infection vectors. The attackers employ various sophisticated social engineering techniques to maximize user engagement and ensure successful malware propagation. These techniques include the strategic use of platform-specific features such as trending keywords, emoticons, and eye-catching thumbnails. These tactics closely mimic legitimate content creation strategies while providing detailed instructions for malware infection. Based on our in-depth analysis, we propose a set of robust detection and mitigation strategies that exploit the invariant characteristics of MalTube videos, offering the potential for automated threat detection and prevention.","sentences":["This study introduces and examines a sophisticated malware distribution technique that exploits popular video sharing platforms.","In this attack, threat actors distribute malware through deceptive content that promises free versions of premium software and game cheats.","Throughout this paper, we call this attack MalTube.","MalTube is particularly insidious because it exploits the guilt feelings of users for engaging in potentially illegal activity, making them less likely to report the infection or ask for a help.","To investigate this emerging threat, we developed video platform exploitation reconnaissance VIPER, a novel monitoring system designed to detect, monitor, and analyze MalTube activity at scale.","Over a four-month data collection period, VIPER processed and analyzed 14,363 videos, 8,671 associated channels, and 1,269 unique fully qualified domain names associated with malware downloads.","Our findings reveal that MalTube attackers primarily target young gamers, using the lure of free software and game cheats as infection vectors.","The attackers employ various sophisticated social engineering techniques to maximize user engagement and ensure successful malware propagation.","These techniques include the strategic use of platform-specific features such as trending keywords, emoticons, and eye-catching thumbnails.","These tactics closely mimic legitimate content creation strategies while providing detailed instructions for malware infection.","Based on our in-depth analysis, we propose a set of robust detection and mitigation strategies that exploit the invariant characteristics of MalTube videos, offering the potential for automated threat detection and prevention."],"url":"http://arxiv.org/abs/2407.16132v1"}
{"created":"2024-07-23 02:27:52","title":"FoRA: Low-Rank Adaptation Model beyond Multimodal Siamese Network","abstract":"Multimodal object detection offers a promising prospect to facilitate robust detection in various visual conditions. However, existing two-stream backbone networks are challenged by complex fusion and substantial parameter increments. This is primarily due to large data distribution biases of multimodal homogeneous information. In this paper, we propose a novel multimodal object detector, named Low-rank Modal Adaptors (LMA) with a shared backbone. The shared parameters enhance the consistency of homogeneous information, while lightweight modal adaptors focus on modality unique features. Furthermore, we design an adaptive rank allocation strategy to adapt to the varying heterogeneity at different feature levels. When applied to two multimodal object detection datasets, experiments validate the effectiveness of our method. Notably, on DroneVehicle, LMA attains a 10.4% accuracy improvement over the state-of-the-art method with a 149M-parameters reduction. The code is available at https://github.com/zyszxhy/FoRA.   Our work was submitted to ACM MM in April 2024, but was rejected. We will continue to refine our work and paper writing next, mainly including proof of theory and multi-task applications of FoRA.","sentences":["Multimodal object detection offers a promising prospect to facilitate robust detection in various visual conditions.","However, existing two-stream backbone networks are challenged by complex fusion and substantial parameter increments.","This is primarily due to large data distribution biases of multimodal homogeneous information.","In this paper, we propose a novel multimodal object detector, named Low-rank Modal Adaptors (LMA) with a shared backbone.","The shared parameters enhance the consistency of homogeneous information, while lightweight modal adaptors focus on modality unique features.","Furthermore, we design an adaptive rank allocation strategy to adapt to the varying heterogeneity at different feature levels.","When applied to two multimodal object detection datasets, experiments validate the effectiveness of our method.","Notably, on DroneVehicle, LMA attains a 10.4% accuracy improvement over the state-of-the-art method with a 149M-parameters reduction.","The code is available at https://github.com/zyszxhy/FoRA.   ","Our work was submitted to ACM MM in April 2024, but was rejected.","We will continue to refine our work and paper writing next, mainly including proof of theory and multi-task applications of FoRA."],"url":"http://arxiv.org/abs/2407.16129v1"}
{"created":"2024-07-23 02:25:01","title":"Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion","abstract":"Traditional knowledge graph (KG) completion models learn embeddings to predict missing facts. Recent works attempt to complete KGs in a text-generation manner with large language models (LLMs). However, they need to ground the output of LLMs to KG entities, which inevitably brings errors. In this paper, we present a finetuning framework, DIFT, aiming to unleash the KG completion ability of LLMs and avoid grounding errors. Given an incomplete fact, DIFT employs a lightweight model to obtain candidate entities and finetunes an LLM with discrimination instructions to select the correct one from the given candidates. To improve performance while reducing instruction data, DIFT uses a truncated sampling method to select useful facts for finetuning and injects KG embeddings into the LLM. Extensive experiments on benchmark datasets demonstrate the effectiveness of our proposed framework.","sentences":["Traditional knowledge graph (KG) completion models learn embeddings to predict missing facts.","Recent works attempt to complete KGs in a text-generation manner with large language models (LLMs).","However, they need to ground the output of LLMs to KG entities, which inevitably brings errors.","In this paper, we present a finetuning framework, DIFT, aiming to unleash the KG completion ability of LLMs and avoid grounding errors.","Given an incomplete fact, DIFT employs a lightweight model to obtain candidate entities and finetunes an LLM with discrimination instructions to select the correct one from the given candidates.","To improve performance while reducing instruction data, DIFT uses a truncated sampling method to select useful facts for finetuning and injects KG embeddings into the LLM.","Extensive experiments on benchmark datasets demonstrate the effectiveness of our proposed framework."],"url":"http://arxiv.org/abs/2407.16127v1"}
{"created":"2024-07-23 02:21:11","title":"MxT: Mamba x Transformer for Image Inpainting","abstract":"Image inpainting, or image completion, is a crucial task in computer vision that aims to restore missing or damaged regions of images with semantically coherent content. This technique requires a precise balance of local texture replication and global contextual understanding to ensure the restored image integrates seamlessly with its surroundings. Traditional methods using Convolutional Neural Networks (CNNs) are effective at capturing local patterns but often struggle with broader contextual relationships due to the limited receptive fields. Recent advancements have incorporated transformers, leveraging their ability to understand global interactions. However, these methods face computational inefficiencies and struggle to maintain fine-grained details. To overcome these challenges, we introduce MxT composed of the proposed Hybrid Module (HM), which combines Mamba with the transformer in a synergistic manner. Mamba is adept at efficiently processing long sequences with linear computational costs, making it an ideal complement to the transformer for handling long-scale data interactions. Our HM facilitates dual-level interaction learning at both pixel and patch levels, greatly enhancing the model to reconstruct images with high quality and contextual accuracy. We evaluate MxT on the widely-used CelebA-HQ and Places2-standard datasets, where it consistently outperformed existing state-of-the-art methods.","sentences":["Image inpainting, or image completion, is a crucial task in computer vision that aims to restore missing or damaged regions of images with semantically coherent content.","This technique requires a precise balance of local texture replication and global contextual understanding to ensure the restored image integrates seamlessly with its surroundings.","Traditional methods using Convolutional Neural Networks (CNNs) are effective at capturing local patterns but often struggle with broader contextual relationships due to the limited receptive fields.","Recent advancements have incorporated transformers, leveraging their ability to understand global interactions.","However, these methods face computational inefficiencies and struggle to maintain fine-grained details.","To overcome these challenges, we introduce MxT composed of the proposed Hybrid Module (HM), which combines Mamba with the transformer in a synergistic manner.","Mamba is adept at efficiently processing long sequences with linear computational costs, making it an ideal complement to the transformer for handling long-scale data interactions.","Our HM facilitates dual-level interaction learning at both pixel and patch levels, greatly enhancing the model to reconstruct images with high quality and contextual accuracy.","We evaluate MxT on the widely-used CelebA-HQ and Places2-standard datasets, where it consistently outperformed existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2407.16126v1"}
{"created":"2024-07-23 02:14:18","title":"Diffusion Prior-Based Amortized Variational Inference for Noisy Inverse Problems","abstract":"Recent studies on inverse problems have proposed posterior samplers that leverage the pre-trained diffusion models as powerful priors. These attempts have paved the way for using diffusion models in a wide range of inverse problems. However, the existing methods entail computationally demanding iterative sampling procedures and optimize a separate solution for each measurement, which leads to limited scalability and lack of generalization capability across unseen samples. To address these limitations, we propose a novel approach, Diffusion prior-based Amortized Variational Inference (DAVI) that solves inverse problems with a diffusion prior from an amortized variational inference perspective. Specifically, instead of separate measurement-wise optimization, our amortized inference learns a function that directly maps measurements to the implicit posterior distributions of corresponding clean data, enabling a single-step posterior sampling even for unseen measurements. Extensive experiments on image restoration tasks, e.g., Gaussian deblur, 4$\\times$ super-resolution, and box inpainting with two benchmark datasets, demonstrate our approach's superior performance over strong baselines. Code is available at https://github.com/mlvlab/DAVI.","sentences":["Recent studies on inverse problems have proposed posterior samplers that leverage the pre-trained diffusion models as powerful priors.","These attempts have paved the way for using diffusion models in a wide range of inverse problems.","However, the existing methods entail computationally demanding iterative sampling procedures and optimize a separate solution for each measurement, which leads to limited scalability and lack of generalization capability across unseen samples.","To address these limitations, we propose a novel approach, Diffusion prior-based Amortized Variational Inference (DAVI) that solves inverse problems with a diffusion prior from an amortized variational inference perspective.","Specifically, instead of separate measurement-wise optimization, our amortized inference learns a function that directly maps measurements to the implicit posterior distributions of corresponding clean data, enabling a single-step posterior sampling even for unseen measurements.","Extensive experiments on image restoration tasks, e.g., Gaussian deblur, 4$\\times$ super-resolution, and box inpainting with two benchmark datasets, demonstrate our approach's superior performance over strong baselines.","Code is available at https://github.com/mlvlab/DAVI."],"url":"http://arxiv.org/abs/2407.16125v1"}
{"created":"2024-07-23 02:08:22","title":"Towards Effective Fusion and Forecasting of Multimodal Spatio-temporal Data for Smart Mobility","abstract":"With the rapid development of location based services, multimodal spatio-temporal (ST) data including trajectories, transportation modes, traffic flow and social check-ins are being collected for deep learning based methods. These deep learning based methods learn ST correlations to support the downstream tasks in the fields such as smart mobility, smart city and other intelligent transportation systems. Despite their effectiveness, ST data fusion and forecasting methods face practical challenges in real-world scenarios. First, forecasting performance for ST data-insufficient area is inferior, making it necessary to transfer meta knowledge from heterogeneous area to enhance the sparse representations. Second, it is nontrivial to accurately forecast in multi-transportation-mode scenarios due to the fine-grained ST features of similar transportation modes, making it necessary to distinguish and measure the ST correlations to alleviate the influence caused by entangled ST features. At last, partial data modalities (e.g., transportation mode) are lost due to privacy or technical issues in certain scenarios, making it necessary to effectively fuse the multimodal sparse ST features and enrich the ST representations. To tackle these challenges, our research work aim to develop effective fusion and forecasting methods for multimodal ST data in smart mobility scenario. In this paper, we will introduce our recent works that investigates the challenges in terms of various real-world applications and establish the open challenges in this field for future work.","sentences":["With the rapid development of location based services, multimodal spatio-temporal (ST) data including trajectories, transportation modes, traffic flow and social check-ins are being collected for deep learning based methods.","These deep learning based methods learn ST correlations to support the downstream tasks in the fields such as smart mobility, smart city and other intelligent transportation systems.","Despite their effectiveness, ST data fusion and forecasting methods face practical challenges in real-world scenarios.","First, forecasting performance for ST data-insufficient area is inferior, making it necessary to transfer meta knowledge from heterogeneous area to enhance the sparse representations.","Second, it is nontrivial to accurately forecast in multi-transportation-mode scenarios due to the fine-grained ST features of similar transportation modes, making it necessary to distinguish and measure the ST correlations to alleviate the influence caused by entangled ST features.","At last, partial data modalities (e.g., transportation mode) are lost due to privacy or technical issues in certain scenarios, making it necessary to effectively fuse the multimodal sparse ST features and enrich the ST representations.","To tackle these challenges, our research work aim to develop effective fusion and forecasting methods for multimodal ST data in smart mobility scenario.","In this paper, we will introduce our recent works that investigates the challenges in terms of various real-world applications and establish the open challenges in this field for future work."],"url":"http://arxiv.org/abs/2407.16123v1"}
{"created":"2024-07-23 01:59:58","title":"Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data","abstract":"The widespread use of Deep Neural Networks (DNNs) has recently resulted in their application to challenging scientific visualization tasks. While advanced DNNs demonstrate impressive generalization abilities, understanding factors like prediction quality, confidence, robustness, and uncertainty is crucial. These insights aid application scientists in making informed decisions. However, DNNs lack inherent mechanisms to measure prediction uncertainty, prompting the creation of distinct frameworks for constructing robust uncertainty-aware models tailored to various visualization tasks. In this work, we develop uncertainty-aware implicit neural representations to model steady-state vector fields effectively. We comprehensively evaluate the efficacy of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed visual analysis of features within steady vector field data. Our detailed exploration using several vector data sets indicate that uncertainty-aware models generate informative visualization results of vector field features. Furthermore, incorporating prediction uncertainty improves the resilience and interpretability of our DNN model, rendering it applicable for the analysis of non-trivial vector field data sets.","sentences":["The widespread use of Deep Neural Networks (DNNs) has recently resulted in their application to challenging scientific visualization tasks.","While advanced DNNs demonstrate impressive generalization abilities, understanding factors like prediction quality, confidence, robustness, and uncertainty is crucial.","These insights aid application scientists in making informed decisions.","However, DNNs lack inherent mechanisms to measure prediction uncertainty, prompting the creation of distinct frameworks for constructing robust uncertainty-aware models tailored to various visualization tasks.","In this work, we develop uncertainty-aware implicit neural representations to model steady-state vector fields effectively.","We comprehensively evaluate the efficacy of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed visual analysis of features within steady vector field data.","Our detailed exploration using several vector data sets indicate that uncertainty-aware models generate informative visualization results of vector field features.","Furthermore, incorporating prediction uncertainty improves the resilience and interpretability of our DNN model, rendering it applicable for the analysis of non-trivial vector field data sets."],"url":"http://arxiv.org/abs/2407.16119v1"}
{"created":"2024-07-22 23:31:10","title":"Universal Spectral Transfer with Physical Prior-Informed Deep Generative Learning","abstract":"Spectroscopy is a powerful analytical technique for characterizing matter across physical and biological realms1-5. However, its fundamental principle necessitates specialized instrumentation per physical phenomena probed, limiting broad adoption and use in all relevant research. In this study, we introduce SpectroGen, a novel physical prior-informed deep generative model for generating relevant spectral signatures across modalities using experimentally collected spectral input only from a single modality. We achieve this by reimagining the representation of spectral data as mathematical constructs of distributions instead of their traditional physical and molecular state representations. The results from 319 standard mineral samples tested demonstrate generating with 99% correlation and 0.01 root mean square error with superior resolution than experimentally acquired ground truth spectra. We showed transferring capability across Raman, Infrared, and X-ray Diffraction modalities with Gaussian, Lorentzian, and Voigt distribution priors respectively6-10. This approach however is globally generalizable for any spectral input that can be represented by a distribution prior, making it universally applicable. We believe our work revolutionizes the application sphere of spectroscopy, which has traditionally been limited by access to the required sophisticated and often expensive equipment towards accelerating material, pharmaceutical, and biological discoveries.","sentences":["Spectroscopy is a powerful analytical technique for characterizing matter across physical and biological realms1-5.","However, its fundamental principle necessitates specialized instrumentation per physical phenomena probed, limiting broad adoption and use in all relevant research.","In this study, we introduce SpectroGen, a novel physical prior-informed deep generative model for generating relevant spectral signatures across modalities using experimentally collected spectral input only from a single modality.","We achieve this by reimagining the representation of spectral data as mathematical constructs of distributions instead of their traditional physical and molecular state representations.","The results from 319 standard mineral samples tested demonstrate generating with 99% correlation and 0.01 root mean square error with superior resolution than experimentally acquired ground truth spectra.","We showed transferring capability across Raman, Infrared, and X-ray Diffraction modalities with Gaussian, Lorentzian, and Voigt distribution priors respectively6-10.","This approach however is globally generalizable for any spectral input that can be represented by a distribution prior, making it universally applicable.","We believe our work revolutionizes the application sphere of spectroscopy, which has traditionally been limited by access to the required sophisticated and often expensive equipment towards accelerating material, pharmaceutical, and biological discoveries."],"url":"http://arxiv.org/abs/2407.16094v1"}
{"created":"2024-07-22 22:59:26","title":"PECAN: Personalizing Robot Behaviors through a Learned Canonical Space","abstract":"Robots should personalize how they perform tasks to match the needs of individual human users. Today's robot achieve this personalization by asking for the human's feedback in the task space. For example, an autonomous car might show the human two different ways to decelerate at stoplights, and ask the human which of these motions they prefer. This current approach to personalization is indirect: based on the behaviors the human selects (e.g., decelerating slowly), the robot tries to infer their underlying preference (e.g., defensive driving). By contrast, our paper develops a learning and interface-based approach that enables humans to directly indicate their desired style. We do this by learning an abstract, low-dimensional, and continuous canonical space from human demonstration data. Each point in the canonical space corresponds to a different style (e.g., defensive or aggressive driving), and users can directly personalize the robot's behavior by simply clicking on a point. Given the human's selection, the robot then decodes this canonical style across each task in the dataset -- e.g., if the human selects a defensive style, the autonomous car personalizes its behavior to drive defensively when decelerating, passing other cars, or merging onto highways. We refer to our resulting approach as PECAN: Personalizing Robot Behaviors through a Learned Canonical Space. Our simulations and user studies suggest that humans prefer using PECAN to directly personalize robot behavior (particularly when those users become familiar with PECAN), and that users find the learned canonical space to be intuitive and consistent. See videos here: https://youtu.be/wRJpyr23PKI","sentences":["Robots should personalize how they perform tasks to match the needs of individual human users.","Today's robot achieve this personalization by asking for the human's feedback in the task space.","For example, an autonomous car might show the human two different ways to decelerate at stoplights, and ask the human which of these motions they prefer.","This current approach to personalization is indirect: based on the behaviors the human selects (e.g., decelerating slowly), the robot tries to infer their underlying preference (e.g., defensive driving).","By contrast, our paper develops a learning and interface-based approach that enables humans to directly indicate their desired style.","We do this by learning an abstract, low-dimensional, and continuous canonical space from human demonstration data.","Each point in the canonical space corresponds to a different style (e.g., defensive or aggressive driving), and users can directly personalize the robot's behavior by simply clicking on a point.","Given the human's selection, the robot then decodes this canonical style across each task in the dataset -- e.g., if the human selects a defensive style, the autonomous car personalizes its behavior to drive defensively when decelerating, passing other cars, or merging onto highways.","We refer to our resulting approach as PECAN:","Personalizing Robot Behaviors through a Learned Canonical Space.","Our simulations and user studies suggest that humans prefer using PECAN to directly personalize robot behavior (particularly when those users become familiar with PECAN), and that users find the learned canonical space to be intuitive and consistent.","See videos here: https://youtu.be/wRJpyr23PKI"],"url":"http://arxiv.org/abs/2407.16081v1"}
{"created":"2024-07-22 21:54:19","title":"LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies","abstract":"We tackle the challenge of predicting models' Out-of-Distribution (OOD) performance using in-distribution (ID) measurements without requiring OOD data. Existing evaluations with \"Effective Robustness\", which use ID accuracy as an indicator of OOD accuracy, encounter limitations when models are trained with diverse supervision and distributions, such as class labels (Vision Models, VMs, on ImageNet) and textual descriptions (Visual-Language Models, VLMs, on LAION). VLMs often generalize better to OOD data than VMs despite having similar or lower ID performance. To improve the prediction of models' OOD performance from ID measurements, we introduce the Lowest Common Ancestor (LCA)-on-the-Line framework. This approach revisits the established concept of LCA distance, which measures the hierarchical distance between labels and predictions within a predefined class hierarchy, such as WordNet. We assess 75 models using ImageNet as the ID dataset and five significantly shifted OOD variants, uncovering a strong linear correlation between ID LCA distance and OOD top-1 accuracy. Our method provides a compelling alternative for understanding why VLMs tend to generalize better. Additionally, we propose a technique to construct a taxonomic hierarchy on any dataset using K-means clustering, demonstrating that LCA distance is robust to the constructed taxonomic hierarchy. Moreover, we demonstrate that aligning model predictions with class taxonomies, through soft labels or prompt engineering, can enhance model generalization. Open source code in our Project Page: https://elvishelvis.github.io/papers/lca/.","sentences":["We tackle the challenge of predicting models' Out-of-Distribution (OOD) performance using in-distribution (ID) measurements without requiring OOD data.","Existing evaluations with \"Effective Robustness\", which use ID accuracy as an indicator of OOD accuracy, encounter limitations when models are trained with diverse supervision and distributions, such as class labels (Vision Models, VMs, on ImageNet) and textual descriptions (Visual-Language Models, VLMs, on LAION).","VLMs often generalize better to OOD data than VMs despite having similar or lower ID performance.","To improve the prediction of models' OOD performance from ID measurements, we introduce the Lowest Common Ancestor (LCA)-on-the-Line framework.","This approach revisits the established concept of LCA distance, which measures the hierarchical distance between labels and predictions within a predefined class hierarchy, such as WordNet.","We assess 75 models using ImageNet as the ID dataset and five significantly shifted OOD variants, uncovering a strong linear correlation between ID LCA distance and OOD top-1 accuracy.","Our method provides a compelling alternative for understanding why VLMs tend to generalize better.","Additionally, we propose a technique to construct a taxonomic hierarchy on any dataset using K-means clustering, demonstrating that LCA distance is robust to the constructed taxonomic hierarchy.","Moreover, we demonstrate that aligning model predictions with class taxonomies, through soft labels or prompt engineering, can enhance model generalization.","Open source code in our Project Page: https://elvishelvis.github.io/papers/lca/."],"url":"http://arxiv.org/abs/2407.16067v1"}
{"created":"2024-07-22 21:39:34","title":"Artificial Intelligence-based Decision Support Systems for Precision and Digital Health","abstract":"Precision health, increasingly supported by digital technologies, is a domain of research that broadens the paradigm of precision medicine, advancing everyday healthcare. This vision goes hand in hand with the groundbreaking advent of artificial intelligence (AI), which is reshaping the way we diagnose, treat, and monitor both clinical subjects and the general population. AI tools powered by machine learning have shown considerable improvements in a variety of healthcare domains. In particular, reinforcement learning (RL) holds great promise for sequential and dynamic problems such as dynamic treatment regimes and just-in-time adaptive interventions in digital health. In this work, we discuss the opportunity offered by AI, more specifically RL, to current trends in healthcare, providing a methodological survey of RL methods in the context of precision and digital health. Focusing on the area of adaptive interventions, we expand the methodological survey with illustrative case studies that used RL in real practice.   This invited article has undergone anonymous review and is intended as a book chapter for the volume \"Frontiers of Statistics and Data Science\" edited by Subhashis Ghoshal and Anindya Roy for the International Indian Statistical Association Series on Statistics and Data Science, published by Springer. It covers the material from a short course titled \"Artificial Intelligence in Precision and Digital Health\" taught by the author Bibhas Chakraborty at the IISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science, Bengaluru.","sentences":["Precision health, increasingly supported by digital technologies, is a domain of research that broadens the paradigm of precision medicine, advancing everyday healthcare.","This vision goes hand in hand with the groundbreaking advent of artificial intelligence (AI), which is reshaping the way we diagnose, treat, and monitor both clinical subjects and the general population.","AI tools powered by machine learning have shown considerable improvements in a variety of healthcare domains.","In particular, reinforcement learning (RL) holds great promise for sequential and dynamic problems such as dynamic treatment regimes and just-in-time adaptive interventions in digital health.","In this work, we discuss the opportunity offered by AI, more specifically RL, to current trends in healthcare, providing a methodological survey of RL methods in the context of precision and digital health.","Focusing on the area of adaptive interventions, we expand the methodological survey with illustrative case studies that used RL in real practice.   ","This invited article has undergone anonymous review and is intended as a book chapter for the volume \"Frontiers of Statistics and Data Science\" edited by Subhashis Ghoshal and Anindya Roy for the International Indian Statistical Association Series on Statistics and Data Science, published by Springer.","It covers the material from a short course titled \"Artificial Intelligence in Precision and Digital Health\" taught by the author Bibhas Chakraborty at the IISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science, Bengaluru."],"url":"http://arxiv.org/abs/2407.16062v1"}
{"created":"2024-07-22 21:02:26","title":"ElectionRumors2022: A Dataset of Election Rumors on Twitter During the 2022 US Midterms","abstract":"Understanding the spread of online rumors is a pressing societal challenge and an active area of research across domains. In the context of the 2022 U.S. midterm elections, one influential social media platform for sharing information -- including rumors that may be false, misleading, or unsubstantiated -- was Twitter (now renamed X). To increase understanding of the dynamics of online rumors about elections, we present and analyze a dataset of 1.81 million Twitter posts corresponding to 135 distinct rumors which spread online during the midterm election season (September 5 to December 1, 2022). We describe how this data was collected, compiled, and supplemented, and provide a series of exploratory analyses along with comparisons to a previously-published dataset on 2020 election rumors. We also conduct a mixed-methods analysis of three distinct rumors about the election in Arizona, a particularly prominent focus of 2022 election rumoring. Finally, we provide a set of potential future directions for how this dataset could be used to facilitate future research into online rumors, misinformation, and disinformation.","sentences":["Understanding the spread of online rumors is a pressing societal challenge and an active area of research across domains.","In the context of the 2022 U.S. midterm elections, one influential social media platform for sharing information -- including rumors that may be false, misleading, or unsubstantiated -- was Twitter (now renamed X).","To increase understanding of the dynamics of online rumors about elections, we present and analyze a dataset of 1.81 million Twitter posts corresponding to 135 distinct rumors which spread online during the midterm election season (September 5 to December 1, 2022).","We describe how this data was collected, compiled, and supplemented, and provide a series of exploratory analyses along with comparisons to a previously-published dataset on 2020 election rumors.","We also conduct a mixed-methods analysis of three distinct rumors about the election in Arizona, a particularly prominent focus of 2022 election rumoring.","Finally, we provide a set of potential future directions for how this dataset could be used to facilitate future research into online rumors, misinformation, and disinformation."],"url":"http://arxiv.org/abs/2407.16051v1"}
{"created":"2024-07-22 20:54:35","title":"Leveraging Large Language Models to Geolocate Linguistic Variations in Social Media Posts","abstract":"Geolocalization of social media content is the task of determining the geographical location of a user based on textual data, that may show linguistic variations and informal language. In this project, we address the GeoLingIt challenge of geolocalizing tweets written in Italian by leveraging large language models (LLMs). GeoLingIt requires the prediction of both the region and the precise coordinates of the tweet. Our approach involves fine-tuning pre-trained LLMs to simultaneously predict these geolocalization aspects. By integrating innovative methodologies, we enhance the models' ability to understand the nuances of Italian social media text to improve the state-of-the-art in this domain. This work is conducted as part of the Large Language Models course at the Bertinoro International Spring School 2024. We make our code publicly available on GitHub https://github.com/dawoz/geolingit-biss2024.","sentences":["Geolocalization of social media content is the task of determining the geographical location of a user based on textual data, that may show linguistic variations and informal language.","In this project, we address the GeoLingIt challenge of geolocalizing tweets written in Italian by leveraging large language models (LLMs).","GeoLingIt requires the prediction of both the region and the precise coordinates of the tweet.","Our approach involves fine-tuning pre-trained LLMs to simultaneously predict these geolocalization aspects.","By integrating innovative methodologies, we enhance the models' ability to understand the nuances of Italian social media text to improve the state-of-the-art in this domain.","This work is conducted as part of the Large Language Models course at the Bertinoro International Spring School 2024.","We make our code publicly available on GitHub https://github.com/dawoz/geolingit-biss2024."],"url":"http://arxiv.org/abs/2407.16047v1"}
{"created":"2024-07-22 20:34:35","title":"On Flange-based 3D Hand-Eye Calibration for Soft Robotic Tactile Welding","abstract":"This paper investigates the direct application of standardized designs on the robot for conducting robot hand-eye calibration by employing 3D scanners with collaborative robots. The well-established geometric features of the robot flange are exploited by directly capturing its point cloud data. In particular, an iterative method is proposed to facilitate point cloud processing toward a refined calibration outcome. Several extensive experiments are conducted over a range of collaborative robots, including Universal Robots UR5 & UR10 e-series, Franka Emika, and AUBO i5 using an industrial-grade 3D scanner Photoneo Phoxi S & M and a commercial-grade 3D scanner Microsoft Azure Kinect DK. Experimental results show that translational and rotational errors converge efficiently to less than 0.28 mm and 0.25 degrees, respectively, achieving a hand-eye calibration accuracy as high as the camera's resolution, probing the hardware limit. A welding seam tracking system is presented, combining the flange-based calibration method with soft tactile sensing. The experiment results show that the system enables the robot to adjust its motion in real-time, ensuring consistent weld quality and paving the way for more efficient and adaptable manufacturing processes.","sentences":["This paper investigates the direct application of standardized designs on the robot for conducting robot hand-eye calibration by employing 3D scanners with collaborative robots.","The well-established geometric features of the robot flange are exploited by directly capturing its point cloud data.","In particular, an iterative method is proposed to facilitate point cloud processing toward a refined calibration outcome.","Several extensive experiments are conducted over a range of collaborative robots, including Universal Robots UR5 & UR10 e-series, Franka Emika, and AUBO i5 using an industrial-grade 3D scanner","Photoneo Phoxi S & M and a commercial-grade 3D scanner Microsoft Azure Kinect DK.","Experimental results show that translational and rotational errors converge efficiently to less than 0.28 mm and 0.25 degrees, respectively, achieving a hand-eye calibration accuracy as high as the camera's resolution, probing the hardware limit.","A welding seam tracking system is presented, combining the flange-based calibration method with soft tactile sensing.","The experiment results show that the system enables the robot to adjust its motion in real-time, ensuring consistent weld quality and paving the way for more efficient and adaptable manufacturing processes."],"url":"http://arxiv.org/abs/2407.16041v1"}
{"created":"2024-07-22 20:21:40","title":"Transformer-based Capacity Prediction for Lithium-ion Batteries with Data Augmentation","abstract":"Lithium-ion batteries are pivotal to technological advancements in transportation, electronics, and clean energy storage. The optimal operation and safety of these batteries require proper and reliable estimation of battery capacities to monitor the state of health. Current methods for estimating the capacities fail to adequately account for long-term temporal dependencies of key variables (e.g., voltage, current, and temperature) associated with battery aging and degradation. In this study, we explore the usage of transformer networks to enhance the estimation of battery capacity. We develop a transformer-based battery capacity prediction model that accounts for both long-term and short-term patterns in battery data. Further, to tackle the data scarcity issue, data augmentation is used to increase the data size, which helps to improve the performance of the model. Our proposed method is validated with benchmark datasets. Simulation results show the effectiveness of data augmentation and the transformer network in improving the accuracy and robustness of battery capacity prediction.","sentences":["Lithium-ion batteries are pivotal to technological advancements in transportation, electronics, and clean energy storage.","The optimal operation and safety of these batteries require proper and reliable estimation of battery capacities to monitor the state of health.","Current methods for estimating the capacities fail to adequately account for long-term temporal dependencies of key variables (e.g., voltage, current, and temperature) associated with battery aging and degradation.","In this study, we explore the usage of transformer networks to enhance the estimation of battery capacity.","We develop a transformer-based battery capacity prediction model that accounts for both long-term and short-term patterns in battery data.","Further, to tackle the data scarcity issue, data augmentation is used to increase the data size, which helps to improve the performance of the model.","Our proposed method is validated with benchmark datasets.","Simulation results show the effectiveness of data augmentation and the transformer network in improving the accuracy and robustness of battery capacity prediction."],"url":"http://arxiv.org/abs/2407.16036v1"}
{"created":"2024-07-22 20:13:10","title":"Enhancing Temporal Understanding in LLMs for Semi-structured Tables","abstract":"Temporal reasoning over tabular data presents substantial challenges for large language models (LLMs), as evidenced by recent research. In this study, we conduct a comprehensive analysis of temporal datasets to pinpoint the specific limitations of LLMs. Our investigation leads to enhancements in TempTabQA, a dataset specifically designed for tabular temporal question answering. We provide critical insights for improving LLM performance in temporal reasoning tasks with tabular data. Furthermore, we introduce a novel approach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings demonstrate that our method significantly improves evidence-based reasoning across various models. Additionally, our experimental results reveal that indirect supervision with auxiliary data substantially boosts model performance in these tasks. This work contributes to a deeper understanding of LLMs' temporal reasoning abilities over tabular data and promotes advancements in their application across diverse fields.","sentences":["Temporal reasoning over tabular data presents substantial challenges for large language models (LLMs), as evidenced by recent research.","In this study, we conduct a comprehensive analysis of temporal datasets to pinpoint the specific limitations of LLMs.","Our investigation leads to enhancements in TempTabQA, a dataset specifically designed for tabular temporal question answering.","We provide critical insights for improving LLM performance in temporal reasoning tasks with tabular data.","Furthermore, we introduce a novel approach, C.L.E.A.R to strengthen LLM capabilities in this domain.","Our findings demonstrate that our method significantly improves evidence-based reasoning across various models.","Additionally, our experimental results reveal that indirect supervision with auxiliary data substantially boosts model performance in these tasks.","This work contributes to a deeper understanding of LLMs' temporal reasoning abilities over tabular data and promotes advancements in their application across diverse fields."],"url":"http://arxiv.org/abs/2407.16030v1"}
{"created":"2024-07-22 20:03:36","title":"Exploring and Addressing Reward Confusion in Offline Preference Learning","abstract":"Spurious correlations in a reward model's training data can prevent Reinforcement Learning from Human Feedback (RLHF) from identifying the desired goal and induce unwanted behaviors. This paper shows that offline RLHF is susceptible to reward confusion, especially in the presence of spurious correlations in offline data. We create a benchmark to study this problem and propose a method that can significantly reduce reward confusion by leveraging transitivity of preferences while building a global preference chain with active learning.","sentences":["Spurious correlations in a reward model's training data can prevent Reinforcement Learning from Human Feedback (RLHF) from identifying the desired goal and induce unwanted behaviors.","This paper shows that offline RLHF is susceptible to reward confusion, especially in the presence of spurious correlations in offline data.","We create a benchmark to study this problem and propose a method that can significantly reduce reward confusion by leveraging transitivity of preferences while building a global preference chain with active learning."],"url":"http://arxiv.org/abs/2407.16025v1"}
{"created":"2024-07-22 19:57:19","title":"Color Refinement for Relational Structures","abstract":"Color Refinement, also known as Naive Vertex Classification, is a classical method to distinguish graphs by iteratively computing a coloring of their vertices. While it is mainly used as an imperfect way to test for isomorphism, the algorithm permeated many other, seemingly unrelated, areas of computer science. The method is algorithmically simple, and it has a well-understood distinguishing power: It is logically characterized by Cai, F\\\"urer and Immerman (1992), who showed that it distinguishes precisely those graphs that can be distinguished by a sentence of first-order logic with counting quantifiers and only two variables. A combinatorial characterization is given by Dvo\\v{r}\\'ak (2010), who shows that it distinguishes precisely those graphs that can be distinguished by the number of homomorphisms from some tree.   In this paper, we introduce Relational Color Refinement (RCR, for short), a generalization of the Color Refinement method from graphs to arbitrary relational structures, whose distinguishing power admits the equivalent combinatorial and logical characterizations as Color Refinement has on graphs: We show that RCR distinguishes precisely those structures that can be distinguished by the number of homomorphisms from an acyclic relational structure. Further, we show that RCR distinguishes precisely those structures that can be distinguished by a sentence of the guarded fragment of first-order logic with counting quantifiers.","sentences":["Color Refinement, also known as Naive Vertex Classification, is a classical method to distinguish graphs by iteratively computing a coloring of their vertices.","While it is mainly used as an imperfect way to test for isomorphism, the algorithm permeated many other, seemingly unrelated, areas of computer science.","The method is algorithmically simple, and it has a well-understood distinguishing power: It is logically characterized by Cai, F\\\"urer and Immerman (1992), who showed that it distinguishes precisely those graphs that can be distinguished by a sentence of first-order logic with counting quantifiers and only two variables.","A combinatorial characterization is given by Dvo\\v{r}\\'ak (2010), who shows that it distinguishes precisely those graphs that can be distinguished by the number of homomorphisms from some tree.   ","In this paper, we introduce Relational Color Refinement (RCR, for short), a generalization of the Color Refinement method from graphs to arbitrary relational structures, whose distinguishing power admits the equivalent combinatorial and logical characterizations as Color Refinement has on graphs: We show that RCR distinguishes precisely those structures that can be distinguished by the number of homomorphisms from an acyclic relational structure.","Further, we show that RCR distinguishes precisely those structures that can be distinguished by a sentence of the guarded fragment of first-order logic with counting quantifiers."],"url":"http://arxiv.org/abs/2407.16022v1"}
{"created":"2024-07-22 19:56:03","title":"Pavement Fatigue Crack Detection and Severity Classification Based on Convolutional Neural Network","abstract":"Due to the varying intensity of pavement cracks, the complexity of topological structure, and the noise of texture background, image classification for asphalt pavement cracking has proven to be a challenging problem. Fatigue cracking, also known as alligator cracking, is one of the common distresses of asphalt pavement. It is thus important to detect and monitor the condition of alligator cracking on roadway pavements. Most research in this area has typically focused on pixel-level detection of cracking using limited datasets. A novel deep convolutional neural network that can achieve two objectives is proposed. The first objective of the proposed neural network is to classify presence of fatigue cracking based on pavement surface images. The second objective is to classify the fatigue cracking severity level based on the Distress Identification Manual (DIM) standard. In this paper, a databank of 4484 high-resolution pavement surface images is established in which images are taken locally in the Town of Blacksburg, Virginia, USA. In the data pre-preparation, over 4000 images are labeled into 4 categories manually according to DIM standards. A four-layer convolutional neural network model is then built to achieve the goal of classification of images by pavement crack severity category. The trained model reached the highest accuracy among all existing methods. After only 30 epochs of training, the model achieved a crack existence classification accuracy of 96.23% and a severity level classification accuracy of 96.74%. After 20 epochs of training, the model achieved a pavement marking presence classification accuracy of 97.64%.","sentences":["Due to the varying intensity of pavement cracks, the complexity of topological structure, and the noise of texture background, image classification for asphalt pavement cracking has proven to be a challenging problem.","Fatigue cracking, also known as alligator cracking, is one of the common distresses of asphalt pavement.","It is thus important to detect and monitor the condition of alligator cracking on roadway pavements.","Most research in this area has typically focused on pixel-level detection of cracking using limited datasets.","A novel deep convolutional neural network that can achieve two objectives is proposed.","The first objective of the proposed neural network is to classify presence of fatigue cracking based on pavement surface images.","The second objective is to classify the fatigue cracking severity level based on the Distress Identification Manual (DIM) standard.","In this paper, a databank of 4484 high-resolution pavement surface images is established in which images are taken locally in the Town of Blacksburg, Virginia, USA.","In the data pre-preparation, over 4000 images are labeled into 4 categories manually according to DIM standards.","A four-layer convolutional neural network model is then built to achieve the goal of classification of images by pavement crack severity category.","The trained model reached the highest accuracy among all existing methods.","After only 30 epochs of training, the model achieved a crack existence classification accuracy of 96.23% and a severity level classification accuracy of 96.74%.","After 20 epochs of training, the model achieved a pavement marking presence classification accuracy of 97.64%."],"url":"http://arxiv.org/abs/2407.16021v1"}
{"created":"2024-07-22 19:33:12","title":"AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations","abstract":"For many use-cases, it is often important to explain the prediction of a black-box model by identifying the most influential training data samples. Existing approaches lack customization for user intent and often provide a homogeneous set of explanation samples, failing to reveal the model's reasoning from different angles.   In this paper, we propose AIDE, an approach for providing antithetical (i.e., contrastive), intent-based, diverse explanations for opaque and complex models. AIDE distinguishes three types of explainability intents: interpreting a correct, investigating a wrong, and clarifying an ambiguous prediction. For each intent, AIDE selects an appropriate set of influential training samples that support or oppose the prediction either directly or by contrast. To provide a succinct summary, AIDE uses diversity-aware sampling to avoid redundancy and increase coverage of the training data.   We demonstrate the effectiveness of AIDE on image and text classification tasks, in three ways: quantitatively, assessing correctness and continuity; qualitatively, comparing anecdotal evidence from AIDE and other example-based approaches; and via a user study, evaluating multiple aspects of AIDE. The results show that AIDE addresses the limitations of existing methods and exhibits desirable traits for an explainability method.","sentences":["For many use-cases, it is often important to explain the prediction of a black-box model by identifying the most influential training data samples.","Existing approaches lack customization for user intent and often provide a homogeneous set of explanation samples, failing to reveal the model's reasoning from different angles.   ","In this paper, we propose AIDE, an approach for providing antithetical (i.e., contrastive), intent-based, diverse explanations for opaque and complex models.","AIDE distinguishes three types of explainability intents: interpreting a correct, investigating a wrong, and clarifying an ambiguous prediction.","For each intent, AIDE selects an appropriate set of influential training samples that support or oppose the prediction either directly or by contrast.","To provide a succinct summary, AIDE uses diversity-aware sampling to avoid redundancy and increase coverage of the training data.   ","We demonstrate the effectiveness of AIDE on image and text classification tasks, in three ways: quantitatively, assessing correctness and continuity; qualitatively, comparing anecdotal evidence from AIDE and other example-based approaches; and via a user study, evaluating multiple aspects of AIDE.","The results show that AIDE addresses the limitations of existing methods and exhibits desirable traits for an explainability method."],"url":"http://arxiv.org/abs/2407.16010v1"}
